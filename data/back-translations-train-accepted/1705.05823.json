{"id": "1705.05823", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2017", "title": "Real-Time Adaptive Image Compression", "abstract": "We present a machine learning-based approach to lossy image compression which outperforms all existing codecs, while running in real-time.", "histories": [["v1", "Tue, 16 May 2017 17:51:07 GMT  (8525kb,D)", "http://arxiv.org/abs/1705.05823v1", "Published at ICML 2017"]], "COMMENTS": "Published at ICML 2017", "reviews": [], "SUBJECTS": "stat.ML cs.CV cs.LG", "authors": ["oren rippel", "lubomir d bourdev"], "accepted": true, "id": "1705.05823"}, "pdf": {"name": "1705.05823.pdf", "metadata": {"source": "META", "title": "Real-Time Adaptive Image Compression", "authors": ["Oren Rippel", "Lubomir Bourdev"], "emails": ["<oren@wave.one>,", "<lubomir@wave.one>."], "sections": [{"heading": null, "text": "Our algorithm typically produces files 2.5 times smaller than JPEG and JPEG 2000, 2 times smaller than WebP, and 1.7 times smaller than BPG on generic image datasets of all quality levels. At the same time, our codec is designed to be lightweight and usable: for example, it can encode or decode the Kodak dataset in about 10 ms per image on GPU. Our architecture is an auto-encoder with pyramid analysis, an adaptive coding module, and the regulation of expected code length. We also add training specializing in using it in a compression setting: This enables us to create visually appealing reconstructions at very low bit rates."}, {"heading": "1. Introduction", "text": "However, it is difficult to adapt existing commercial compression algorithms to the growing demand and changing landscape of requirements and applications. While digital media is transmitted in a wide range of settings, the available codecs are \"one-size-fits-all\": they are hard coded and cannot be adapted to specific use cases that go beyond high hyperparameter tuning. In recent years, deep learning has revolutionized many tasks, such as machine translation, face recognition, and photo-realistic image generation. Although the world of compression is a natural domain for machine learning, it has not benefited from these processes."}, {"heading": "2. Background & Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Traditional compression techniques", "text": "In traditional codecs such as JPEG and JP2, this is achieved through a pipeline roughly divided into 3 modules: transformation, quantization, and encoding (Wallace (1992) and Rabbani & Joshi (2002) provide great overviews of the JPEG standards).In traditional codecs, all components are hard coded, and are therefore designed to fit into each other. For example, the encoding scheme is tailored to match the distribution of the results of the previous transformation. JPEG, for example, uses 8 x 8 block DCT transformations, followed by a runtime encoding that utilizes the scatter pattern of the resulting frequency coefficients. JP2 uses an adaptive arithmetic encoder to capture the distribution of metrics generated by the previous multiplicative resolution."}, {"heading": "2.2. ML-based lossy image compression", "text": "One of the first such efforts by Judge et al. (1998), for example, introduced the DjVu format for image compression of documents, where techniques such as segmentation and K-middle clusters separate the foreground from the background and analyze the contents of the document. At a high level, a natural approach to implementing the image compression pipeline of encoders and decoders is to use an auto encoder to map the target through a bit rate bottleneck and train the model to minimize a loss function that punishes it from its reconstruction, which requires careful construction of a feature extractor and synthesizer for the encoder and decoder, selection of a suitable target, and possibly the introduction of a coding scheme to further compress the fixed representation of the size (to achieve general length-based compression sets of the existing L)."}, {"heading": "2.3. Generative Adversarial Networks", "text": "One of the most exciting innovations in the field of machine learning in recent years is the idea of Generative Adversarial Networks (GANs) (Goodfellow et al., 2014).The idea is to construct a generator network whose goal is to synthesize the results using a target distribution ptrue, and a discriminator network whose goal is to distinguish between examples scanned from the basic truth distribution and those produced by the generator, which can be expressed specifically in relation to the Minimax problem: min \u0445 max, Ex, ptrue logD\u044b (x) + Ez, pz log [1 \u2212 D\u0432 (G\u0445 (z)].This idea enabled significant advances in photo-realistic image generation (Denton et al., 2015; Radford et al., 2015; Salimans et al., 2016), single image superresolution (Ledig et al., 2016), the most relevant image-conditional results are those of other primary and secondary school transmissions."}, {"heading": "3. Model", "text": "Our model architecture is illustrated in Figure 2 and includes a number of components, which we briefly outline below. In this section, we limit our focus to operations performed by the encoder: since the decoder simply performs the counterpart inverse operations, we only deal with exceptions that require special attention. Images show a number of different types of structure: across input channels, within individual scales, and across scales. To detect these, we design our architecture of function extraction. It consists of a pyramid-shaped decomposition that analyzes individual scales, followed by a cross-scale alignment method that utilizes the common structure. Code compression and regulation. This module is responsible for further compressing the extracted features. It quantifies the features and encodes them via an adaptive arithmetic coding scheme applied to their binary extensions."}, {"heading": "3.1. Feature extraction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1.1. PYRAMIDAL DECOMPOSITION", "text": "Our pyramid decomposition encoder is loosely inspired by the use of breakers for multi-resolution analysis, in which an input is analyzed recursively by feature extraction and downsampling operators (Mallat, 1989).The JPEG 2000 standard, for example, deals with discrete breakwater transformations with the Daubechies 9 / 7 cores (Antonini et al., 1992; Rabbani & Joshi, 2002).This transformation is in fact a linear operator that can be expressed entirely by compositions of breakers with only two hard-coded and separable 9 \u00d7 9 filters applied independently of scale, and independent of any channel. The idea of pyramid-like decomposition has been used in machine learning: for example, Mathieu et al. (2015) a pyramid-shaped composition is used for the next question, and Denton et al."}, {"heading": "3.1.2. INTERSCALE ALIGNMENT", "text": "Interscale alignment is designed to heverage information shared across different scales - a benefit not offered by the classic wavelet analysis. It takes as input the set of coefficients extracted from the different scales {cm} Mm = 1 \u0445 RCm \u00b7 Hm \u00b7 Wm, and generates a single tensor of a target output dimension C \u00b7 H \u00b7 W. To do this, we first map each input tensor cm to the target dimensionality via a parameterized function gm (\u00b7). This involves making sure that this function uses spatially cm to the corresponding output card size H \u00b7 B and outputs the corresponding number of channels. We then add gm (cm), m = 1,..., M, and apply another parameterized nonlinear transformation g (\u00b7) for common processing. The interscale alignment module can be seen in Figure 3."}, {"heading": "3.2. Code computation and regularization", "text": "This pipeline includes a number of components, which we outline here and describe in detail in this paragraph.Quantifiation. the tensor y is quantified with bit accuracy B: y: = QUANTIZEB (y).Bitplan decomposition. The quantified tensor y is transformed into a binary tensor suitable for encoding using a lossless bitplan decomposition: b: = BITPLANEDECOMPOSEB (y).0, 1} B \u00b7 C \u00b7 H \u00b7 W. The adaptive arithmetic encoder (AAC) is trained to effectively use the structure remaining in the data. It encodes b into its final variable length sequence (s): s: = AACENCODE (b).1} (the fit encoding)."}, {"heading": "3.2.1. QUANTIZATION", "text": "Considering the desired accuracy of B-bits, we quantify our characteristic tensor y into 2B containers of equal size asy-chw: = QUANTIZEB (ychw) = 1 2B \u2212 1 2B \u2212 1ychw. In the special case B = 1, this is reduced exactly to a binary quantization scheme. While some ML-based approaches to compression use such a threshold, we found better performance with the softer quantization described. We quantify with B = 6 for all models in this paper."}, {"heading": "3.2.2. BITPLANE DECOMPOSITION", "text": "This transformation maps any value y-chw into its binary expansion of B-bits. Therefore, each of the C space maps y-c-RH-W maps y-bits into binary bit planes. We illustrate this transformation in Figure 4 and designate its output as b-0, 1-B-C-H-W. This transformation is lossless. As described in Section 3.2.3, this decomposition will enable our entropy encoder to use the structure in the distribution of activations in y to achieve a compact representation. In Section 3.2.4, we present a strategy to encourage such a usable structure to display."}, {"heading": "3.2.3. ADAPTIVE ARITHMETIC CODING", "text": "Output b of bitmap decomposition is a binary tensor that contains a significant structure: higher bit levels are sparser, and spatially adjacent bits often have the same value (in Section 3.2.4 we propose a technique to guarantee the presence of these properties).We use this low entropy by lossless compression using adaptive arithmetic encoding, because we associate each bit position in b with a context that contains a set of characteristics indicating the bit value, based on the position of the bit and the values of neighboring bits. We train a classifier to predict the value of each bit by its context characteristics, and then use these probabilities to compress b using arithmetic encoding.During decoding, we decompress the code by performing the inverse operation."}, {"heading": "3.2.4. ADAPTIVE CODELENGTH REGULARIZATION", "text": "The bottleneck may be too small to render complex patterns well, affecting quality, and it may be too large for simple patterns, resulting in inefficient compression. What we need is a model that is able to render long representations for complex patterns and short for simple ones, while maintaining a target of code length over a large number of examples. To achieve this, the AAC is necessary, but not sufficient. We extend the architecture by increasing the dimensionality of b - but at the same time controlling its information content, leading to shorter compressed codes s = AACENCODE (b)."}, {"heading": "4. Realistic Reconstructions via Multiscale Adversarial Training", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Discriminator design", "text": "In our compression approach, we take the generator as an encoder decoder pipeline to which we attach a discriminator - albeit with some significant differences to existing GAN formulas. In many GAN approaches, which have both a loss of reconstruction and a loss of discrimination, target and reconstruction are treated independently of each other: each is labeled separately to indicate whether it is real or fake. In our formulation, we consider the target and its reconstruction together as a single example: We compare the two by asking which of the two images is the real one. To do this, we first exchange the discriminator in each input pair between target and reconstruction with uniform probability. After random swap, we propagate each set of examples through the network. However, instead of producing an output for classification on the very last layer of the pipeline, we accumulate scalar results along branches that are constructed at different depths."}, {"heading": "4.2. Adversarial training", "text": "The formation of a GAN system can be difficult due to the optimization instability. In our case, we were able to solve this by designing an adaptable training scheme. First, the reconstructor is trained both by the confusion signal gradient and by the reconstruction loss gradient: We balance the two as a function of their gradient sizes. Second, we train the discriminator at any time during the training or propagate the confusion signal by the reconstructor, as a function of the predictive accuracy of the discriminator. More specifically, if we specify the lower and upper accuracy limits L, U [0, 1] and the discriminatory accuracy a (D), we apply the following procedure: \u2022 If a < L: freeze the propagation of the confusion signal by the reconstructor and train the discriminator. \u2022 If L \u2264 a < U: we switch between propagating the confusion signal and the training of the disclaimer."}, {"heading": "5. Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Experimental setup", "text": "We trained and tested all models based on the Multi-Scale Structural Similarity Index Metric (MSSSIM) (Wang et al., 2003), which was specifically tailored to the human visual system and was chosen as being significantly more representative than losses in the \"p family and variants such as PSNR.Color space. Since the human visual system is much more sensitive to differences in brightness than in color, most codecs represent colors in the YCbCr color space to devote more bandwidth toward coding luma rather than chroma. When quantifying image similarities, it is then common to use the Y, Cb, Cr components with weights of 6 / 8, 1 / 8, 1 / 8, and 8. While many ML-based compression papers form similarity in the RGB space with the same color weights, this does not allow a fair comparison with standard codecs such as JPEG, JPEG 2000, and WebP, as they were not designed to be comparable in terms of both."}, {"heading": "5.2. Performance", "text": "We present several types of results: 1. Average MS-SSIM as a function of BPP fixed for each image, found in Figures 5 and 6, and Table 1.2. Average compressed file sizes relative to ours as a function of MS-SSIM fixed for each image, found in Figures 5 and 6, and Table 1.3. Encode and decoding as a function of MS-SSIM, found in Figure 7, in the appendix, and in Table 1.4. Visual examples of reconstructions of different compression approaches for the same BPP, found in Figure 1 and in the scope. To allow comparison with other approaches, we first have the current performance on the Kodak PhotoCD dataset1. While the Kodak dataset is very popular for testing compression performance, it contains only 24 images, and hence is susceptible to overadjustment and does not necessarily capture more comprehensive statistics of natural images."}], "references": [{"title": "Image coding using wavelet transform", "author": ["Antonini", "Marc", "Barlaud", "Michel", "Mathieu", "Pierre", "Daubechies", "Ingrid"], "venue": "IEEE Trans. Image Processing,", "citeRegEx": "Antonini et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Antonini et al\\.", "year": 1992}, {"title": "End-to-end optimized image compression", "author": ["Ball\u00e9", "Johannes", "Laparra", "Valero", "Simoncelli", "Eero P"], "venue": null, "citeRegEx": "Ball\u00e9 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ball\u00e9 et al\\.", "year": 2016}, {"title": "High quality document image compression with djvu", "author": ["Bottou", "L\u00e9on", "Haffner", "Patrick", "Howard", "Paul G", "Simard", "Patrice", "Bengio", "Yoshua", "LeCun", "Yann"], "venue": null, "citeRegEx": "Bottou et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Bottou et al\\.", "year": 1998}, {"title": "Raise: a raw images dataset for digital image forensics", "author": ["Dang-Nguyen", "Duc-Tien", "Pasquini", "Cecilia", "Conotter", "Valentina", "Boato", "Giulia"], "venue": "In Proceedings of the 6th ACM Multimedia Systems Conference,", "citeRegEx": "Dang.Nguyen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dang.Nguyen et al\\.", "year": 2015}, {"title": "Deep generative image models using a laplacian pyramid of adversarial networks", "author": ["Denton", "Emily L", "Chintala", "Soumith", "Fergus", "Rob"], "venue": "In NIPS,", "citeRegEx": "Denton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Denton et al\\.", "year": 2015}, {"title": "Generative adversarial nets", "author": ["Goodfellow", "Ian", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In NIPS,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Image-to-image translation with conditional adversarial networks", "author": ["Isola", "Phillip", "Zhu", "Jun-Yan", "Zhou", "Tinghui", "Efros", "Alexei A"], "venue": "arXiv preprint arXiv:1611.07004,", "citeRegEx": "Isola et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Isola et al\\.", "year": 2016}, {"title": "Silicon valley (tv series)", "author": ["Judge", "Mike", "Altschuler", "John", "Krinsky", "Dave"], "venue": null, "citeRegEx": "Judge et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Judge et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "A theory for multiresolution signal decomposition: The wavelet representation", "author": ["S.G. Mallat"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Mallat,? \\Q1989\\E", "shortCiteRegEx": "Mallat", "year": 1989}, {"title": "Deep multi-scale video prediction beyond mean square error", "author": ["Mathieu", "Michael", "Couprie", "Camille", "LeCun", "Yann"], "venue": "arXiv preprint arXiv:1511.05440,", "citeRegEx": "Mathieu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mathieu et al\\.", "year": 2015}, {"title": "An overview of the jpeg 2000 still image compression standard", "author": ["Rabbani", "Majid", "Joshi", "Rajan"], "venue": "Signal processing: Image communication,", "citeRegEx": "Rabbani et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Rabbani et al\\.", "year": 2002}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Radford", "Alec", "Metz", "Luke", "Chintala", "Soumith"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Spectral representations for convolutional neural networks", "author": ["Rippel", "Oren", "Snoek", "Jasper", "Adams", "Ryan P"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Rippel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rippel et al\\.", "year": 2015}, {"title": "Improved techniques for training gans", "author": ["Salimans", "Tim", "Goodfellow", "Ian", "Zaremba", "Wojciech", "Cheung", "Vicki", "Radford", "Alec", "Chen", "Xi"], "venue": "In NIPS,", "citeRegEx": "Salimans et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2016}, {"title": "Lossy image compression with compressive autoencoders", "author": ["Theis", "Lucas", "Shi", "Wenzhe", "Cunningham", "Andrew", "Huszar", "Ferenc"], "venue": null, "citeRegEx": "Theis et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Theis et al\\.", "year": 2016}, {"title": "Yfcc100m: The new data in multimedia research", "author": ["Thomee", "Bart", "Shamma", "David A", "Friedland", "Gerald", "Elizalde", "Benjamin", "Ni", "Karl", "Poland", "Douglas", "Borth", "Damian", "Li", "Li-Jia"], "venue": "Communications of the ACM,", "citeRegEx": "Thomee et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Thomee et al\\.", "year": 2016}, {"title": "Variable rate image compression with recurrent neural networks", "author": ["Toderici", "George", "O\u2019Malley", "Sean M", "Hwang", "Sung Jin", "Vincent", "Damien", "Minnen", "David", "Baluja", "Shumeet", "Covell", "Michele", "Sukthankar", "Rahul"], "venue": "arXiv preprint arXiv:1511.06085,", "citeRegEx": "Toderici et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Toderici et al\\.", "year": 2015}, {"title": "Full resolution image compression with recurrent neural networks", "author": ["Toderici", "George", "Vincent", "Damien", "Johnston", "Nick", "Hwang", "Sung Jin", "Minnen", "David", "Shor", "Joel", "Covell", "Michele"], "venue": "arXiv preprint arXiv:1608.05148,", "citeRegEx": "Toderici et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Toderici et al\\.", "year": 2016}, {"title": "The jpeg still picture compression standard", "author": ["Wallace", "Gregory K"], "venue": "IEEE transactions on consumer electronics,", "citeRegEx": "Wallace and K.,? \\Q1992\\E", "shortCiteRegEx": "Wallace and K.", "year": 1992}, {"title": "Multiscale structural similarity for image quality assessment", "author": ["Wang", "Zhou", "Simoncelli", "Eero P", "Bovik", "Alan C"], "venue": "In Signals, Systems and Computers,", "citeRegEx": "Wang et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2004}, {"title": "Image quality assessment: from error visibility to structural similarity", "author": ["Wang", "Zhou", "Bovik", "Alan C", "Sheikh", "Hamid R", "Simoncelli", "Eero P"], "venue": "IEEE transactions on image processing,", "citeRegEx": "Wang et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 14, "context": "(2015; 2016), Theis et al. (2016), Ball\u00e9 et al.", "startOffset": 14, "endOffset": 34}, {"referenceID": 1, "context": "(2016), Ball\u00e9 et al. (2016), and Johnston et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 1, "context": "(2016), Ball\u00e9 et al. (2016), and Johnston et al. (2017) towards alleviating this: see Section 2.", "startOffset": 8, "endOffset": 56}, {"referenceID": 2, "context": "One of the first such efforts by Bottou et al. (1998), for example, introduced the DjVu format for document image compression, which employs techniques such as segmentation and K-means clustering separate foreground from background, and analyze the document\u2019s contents.", "startOffset": 33, "endOffset": 54}, {"referenceID": 20, "context": "(2017) enabled another considerable leap in performance by introducing a loss weighted with SSIM (Wang et al., 2004), and spatiallyadaptive bit allocation.", "startOffset": 97, "endOffset": 116}, {"referenceID": 7, "context": "Finally, Pied Piper has recently claimed to employ ML techniques in its Middle-Out algorithm (Judge et al., 2016), although their nature is shrouded in mystery.", "startOffset": 93, "endOffset": 113}, {"referenceID": 5, "context": "Generative Adversarial Networks One of the most exciting innovations in machine learning in the last few years is the idea of Generative Adversarial Networks (GANs) (Goodfellow et al., 2014).", "startOffset": 165, "endOffset": 190}, {"referenceID": 13, "context": "Toderici et al. (2015; 2016) explored various transformations for binary feature extraction based on different types of recurrent neural networks; the binary representations were then entropy-coded. Johnston et al. (2017) enabled another considerable leap in performance by introducing a loss weighted with SSIM (Wang et al.", "startOffset": 0, "endOffset": 222}, {"referenceID": 12, "context": "Theis et al. (2016) and Ball\u00e9 et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "(2016) and Ball\u00e9 et al. (2016) quantize rather than binarize, and propose strategies to approximate the entropy of the quantized representation: this provides them with a proxy to penalize it.", "startOffset": 11, "endOffset": 31}, {"referenceID": 4, "context": "This idea has enabled significant progress in photo-realistic image generation (Denton et al., 2015; Radford et al., 2015; Salimans et al., 2016), single-image super-resolution (Ledig et al.", "startOffset": 79, "endOffset": 145}, {"referenceID": 12, "context": "This idea has enabled significant progress in photo-realistic image generation (Denton et al., 2015; Radford et al., 2015; Salimans et al., 2016), single-image super-resolution (Ledig et al.", "startOffset": 79, "endOffset": 145}, {"referenceID": 14, "context": "This idea has enabled significant progress in photo-realistic image generation (Denton et al., 2015; Radford et al., 2015; Salimans et al., 2016), single-image super-resolution (Ledig et al.", "startOffset": 79, "endOffset": 145}, {"referenceID": 6, "context": ", 2016), image-to-image conditional translation (Isola et al., 2016), and various other important problems.", "startOffset": 48, "endOffset": 68}, {"referenceID": 9, "context": "PYRAMIDAL DECOMPOSITION Our pyramidal decomposition encoder is loosely inspired by the use of wavelets for multiresolution analysis, in which an input is analyzed recursively via feature extraction and downsampling operators (Mallat, 1989).", "startOffset": 225, "endOffset": 239}, {"referenceID": 0, "context": "The JPEG 2000 standard, for example, employs discrete wavelet transforms with the Daubechies 9/7 kernels (Antonini et al., 1992; Rabbani & Joshi, 2002).", "startOffset": 105, "endOffset": 151}, {"referenceID": 0, "context": "The JPEG 2000 standard, for example, employs discrete wavelet transforms with the Daubechies 9/7 kernels (Antonini et al., 1992; Rabbani & Joshi, 2002). This transform is in fact a linear operator, which can be entirely expressed via compositions of convolutions with only two hard-coded and separable 9\u00d79 filters applied irrespective of scale, and independently for each channel. The idea of a pyramidal decomposition has been employed in machine learning: for instance, Mathieu et al. (2015) uses a pyramidal composition for next frame prediction, and Denton et al.", "startOffset": 106, "endOffset": 494}, {"referenceID": 0, "context": "The JPEG 2000 standard, for example, employs discrete wavelet transforms with the Daubechies 9/7 kernels (Antonini et al., 1992; Rabbani & Joshi, 2002). This transform is in fact a linear operator, which can be entirely expressed via compositions of convolutions with only two hard-coded and separable 9\u00d79 filters applied irrespective of scale, and independently for each channel. The idea of a pyramidal decomposition has been employed in machine learning: for instance, Mathieu et al. (2015) uses a pyramidal composition for next frame prediction, and Denton et al. (2015) uses it for image generation.", "startOffset": 106, "endOffset": 575}, {"referenceID": 0, "context": "The JPEG 2000 standard, for example, employs discrete wavelet transforms with the Daubechies 9/7 kernels (Antonini et al., 1992; Rabbani & Joshi, 2002). This transform is in fact a linear operator, which can be entirely expressed via compositions of convolutions with only two hard-coded and separable 9\u00d79 filters applied irrespective of scale, and independently for each channel. The idea of a pyramidal decomposition has been employed in machine learning: for instance, Mathieu et al. (2015) uses a pyramidal composition for next frame prediction, and Denton et al. (2015) uses it for image generation. The spectral representations of CNN activations have also been investigated by Rippel et al. (2015) to enable processing across a spectrum of scales, but this approach does not enable FIR processing as does wavelet analysis.", "startOffset": 106, "endOffset": 705}, {"referenceID": 15, "context": "We compare against commercial codecs JPEG, JPEG 2000, WebP and BPG (4:2:0 for YCbCr and 4:4:4 for RGB), as well as recent MLbased compression work by Toderici et al. (2016), Theis et al.", "startOffset": 150, "endOffset": 173}, {"referenceID": 14, "context": "(2016), Theis et al. (2016), Ball\u00e9 et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 1, "context": "(2016), Ball\u00e9 et al. (2016), and Johnston et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 1, "context": "(2016), Ball\u00e9 et al. (2016), and Johnston et al. (2017) in all settings where results exist.", "startOffset": 8, "endOffset": 56}, {"referenceID": 16, "context": "mons 100 Million dataset (Thomee et al., 2016).", "startOffset": 25, "endOffset": 46}, {"referenceID": 3, "context": "As such, we additionally present performance on the RAISE-1k dataset (Dang-Nguyen et al., 2015) which contains 1,000 raw images.", "startOffset": 69, "endOffset": 95}, {"referenceID": 2, "context": "As such, we additionally present performance on the RAISE-1k dataset (Dang-Nguyen et al., 2015) which contains 1,000 raw images. We resized each image to size 512\u00d7 768 (backwards if vertical): we intend to release our preparation code to enable reproduction of the dataset used. We remark it is important to use a dataset of raw, rather than previously compressed, images for codec evaluation. The Kodak PhotoCD dataset can be found at http:// r0k.us/graphics/kodak. The results of Toderici et al. (2016) on the Kodak RGB dataset are available at http://github.", "startOffset": 70, "endOffset": 505}, {"referenceID": 2, "context": "As such, we additionally present performance on the RAISE-1k dataset (Dang-Nguyen et al., 2015) which contains 1,000 raw images. We resized each image to size 512\u00d7 768 (backwards if vertical): we intend to release our preparation code to enable reproduction of the dataset used. We remark it is important to use a dataset of raw, rather than previously compressed, images for codec evaluation. The Kodak PhotoCD dataset can be found at http:// r0k.us/graphics/kodak. The results of Toderici et al. (2016) on the Kodak RGB dataset are available at http://github.com/ tensorflow/models/tree/master/compression. We have no access to reconstructions by Theis et al. (2016) and Johnston et al.", "startOffset": 70, "endOffset": 669}, {"referenceID": 2, "context": "As such, we additionally present performance on the RAISE-1k dataset (Dang-Nguyen et al., 2015) which contains 1,000 raw images. We resized each image to size 512\u00d7 768 (backwards if vertical): we intend to release our preparation code to enable reproduction of the dataset used. We remark it is important to use a dataset of raw, rather than previously compressed, images for codec evaluation. The Kodak PhotoCD dataset can be found at http:// r0k.us/graphics/kodak. The results of Toderici et al. (2016) on the Kodak RGB dataset are available at http://github.com/ tensorflow/models/tree/master/compression. We have no access to reconstructions by Theis et al. (2016) and Johnston et al. (2017), so we carefully transcribed their results, only available in RGB, from the graphs in their paper.", "startOffset": 70, "endOffset": 696}, {"referenceID": 1, "context": "Reconstructions by Ball\u00e9 et al. (2016) of images in the Kodak dataset can be found at http://www.", "startOffset": 19, "endOffset": 39}, {"referenceID": 15, "context": "We compare against commercial compression techniques JPEG, JPEG 2000, WebP, as well as recent MLbased compression work by Toderici et al. (2016)2, Theis et al.", "startOffset": 122, "endOffset": 145}, {"referenceID": 14, "context": "(2016)2, Theis et al. (2016)3, Ball\u00e9 et al.", "startOffset": 9, "endOffset": 29}, {"referenceID": 1, "context": "(2016)3, Ball\u00e9 et al. (2016)4, and Johnston et al.", "startOffset": 9, "endOffset": 29}, {"referenceID": 1, "context": "(2016)3, Ball\u00e9 et al. (2016)4, and Johnston et al. (2017)3 in all settings in which results are available.", "startOffset": 9, "endOffset": 58}, {"referenceID": 1, "context": "Each image has a separate RD curve computed from all available compression rates for a given codec: as Ball\u00e9 et al. (2016) discusses in detail, different summaries of these RD curves lead to disparate results.", "startOffset": 103, "endOffset": 123}], "year": 2017, "abstractText": "Streaming of digital media makes 70% of internet traffic, and is projected to reach 80% by 2020 (CIS, 2015). However, it has been challenging for existing commercial compression algorithms to adapt to the growing demand and the changing landscape of requirements and applications. While digital media are transmitted in a wide variety of settings, the available codecs are \u201cone-size-fits-all\u201d: they are hard-coded, and cannot be customized to particular use cases beyond high-level hyperparameter tuning.", "creator": "LaTeX with hyperref package"}}}