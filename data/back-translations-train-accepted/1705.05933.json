{"id": "1705.05933", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2017", "title": "Sub-sampled Cubic Regularization for Non-convex Optimization", "abstract": "We consider the minimization of non-convex functions that typically arise in machine learning. Specifically, we focus our attention on a variant of trust region methods known as cubic regularization. This approach is particularly attractive because it escapes strict saddle points and it provides stronger convergence guarantees than first- and second-order as well as classical trust region methods. However, it suffers from a high computational complexity that makes it impractical for large-scale learning. Here, we propose a novel method that uses sub-sampling to lower this computational cost. By the use of concentration inequalities we provide a sampling scheme that gives sufficiently accurate gradient and Hessian approximations to retain the strong global and local convergence guarantees of cubically regularized methods. To the best of our knowledge this is the first work that gives global convergence guarantees for a sub-sampled variant of cubic regularization on non-convex functions. Furthermore, we provide experimental results supporting our theory.", "histories": [["v1", "Tue, 16 May 2017 21:44:44 GMT  (1031kb,D)", "https://arxiv.org/abs/1705.05933v1", "ICML 2017"], ["v2", "Fri, 23 Jun 2017 11:49:57 GMT  (3667kb,D)", "http://arxiv.org/abs/1705.05933v2", "Proceedings of the 34th International Conference on Machine Learning"], ["v3", "Sat, 1 Jul 2017 11:17:59 GMT  (3667kb,D)", "http://arxiv.org/abs/1705.05933v3", "Proceedings of the 34th International Conference on Machine Learning"]], "COMMENTS": "ICML 2017", "reviews": [], "SUBJECTS": "cs.LG math.OC stat.ML", "authors": ["jonas moritz kohler", "aur\u00e9lien lucchi"], "accepted": true, "id": "1705.05933"}, "pdf": {"name": "1705.05933.pdf", "metadata": {"source": "META", "title": "Sub-sampled Cubic Regularization for Non-convex Optimization", "authors": ["Jonas Moritz Kohler", "Aurelien Lucchi"], "emails": ["<jonas.kohler@student.kit.edu>,", "lien.lucchi@inf.ethz.ch>."], "sections": [{"heading": "1. Introduction", "text": "In this paper, we address the problem of minimizing an objective function of the format that is responsible for many functions. (SGD) In this paper, we will address the problem of minimizing an objective function. (SGD) In this paper, we will not necessarily find an objective (regulated) loss function via n datapoints (SGD). (SGD) There will be a popular method to optimize this type of goal, especially in the context of computer science, ETH Zurich, Switzerland. Correspondence to: Jonas Moritz Kohler < jonas.kohler @ student.kit.edu >, aurelien Lucchi & lt.lucchi @ inf.ethz.ch > Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017."}, {"heading": "2. Related work", "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far."}, {"heading": "3. Formulation", "text": "We are interested in optimizing Eq.1 on a large scale when the number of data points n is so large that the cost of solving Eq.2 becomes precisely prohibitive. In this regard, we identify a sampling scheme that allows us to achieve the convergence results of the deterministic trust region and cubic regulatory methods, including square local convergence rates and second-order global convergence guarantees, as well as complexity limits for the worst case. A detailed theoretical analysis is given in Section 4. At this point, we will first explain the algorithm itself and further elaborate on the type of local nonlinear models we apply and how they can be efficiently solved."}, {"heading": "3.1. Objective function", "text": "Instead of using deterministic gradients and Hessian information as in Eq.2, we use unbiased estimates of the gradient and Hessian, based on two independent points denoted by Sg and SB. Then we construct a local cubic model, which is (approximately) minimized in each iteration: mk (sk): = f (xk) + s kgk + 1 2 skBksk + \u03c3k 3 [sk] 3 (4), where gk: = 1 | Sg | 3 (xk) and Bk: = 1 | SB | 3 (xk) and SB \u00b2 2fi (xk)."}, {"heading": "3.2. Algorithm", "text": "Our sub-sampled Cubic Regularization approach (SCR) is presented in algorithm 1. In iteration step k, we examine two sets of data points from which we calculate a stochastic estimate of the gradient and the Hessian. Subsequently, we solve the problem in Equation 4 roughly using the method described in Section 3.4 and update the regulation parameter \u03c3k depending on how well the model approaches the actual target. In particular, very successful steps indicate that the model is an appropriate approximation of the object (at least locally), so that the penalty parameter is reduced to allow for longer steps. In the case of unsuccessful iterations, we proceed exactly the other way round. Readers familiar with methods of the trust region might recognize that the penalty parameter \u03c3k can be interpreted as inversely proportional to the trust region in the radius \u0441k."}, {"heading": "3.3. Exact model minimization", "text": "Solving equation 4 requires minimizing an unrestricted nonconvex problem that may have isolated local minima. As shown in (Cartis et al., 2011a), the global model minimizer s * k is characterized by the following systems of equations: (Bk + \u043c kI) s * k = \u2212 gk, \u043c k = \u03c3k * k, (Bk + \u043c kI) 0. (9) To find a solution, we can express s * k: = (Bk + \u03bb kI) s * k = \u2212 gk, this applies in the second equation of (9) algorithm 1 sub \u2212 kb \u2212 kI) 1: input: starting point x0 \u0445 Rd (e.g x0 = 0) \u03b3 > 1, 1 > g \u00b2 kI * xxk, if the second equation of (1) kb \u2212 kb \u2212 kI, if the first stage of kb \u2212 kb \u2212 kb \u2212 kk."}, {"heading": "3.4. Approximate model minimization", "text": "(Cartis et al., 2011a) showed that it is possible to maintain the remarkable properties of the cubic regulating algorithm with an imprecise minimizer. A necessary condition is that sk fulfils the two requirements specified in A1.Assumption 1 (Approximate model minimizer). (s kBksgk + s kBksk bksk sk 3 = 0 (11) skBksk + \u0441\u0430\u0441k \u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u043d\u0435\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441flifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifliflifli"}, {"heading": "4. Theoretical analysis", "text": "In this section, we provide the convergence analysis of the SCR. For the sake of brevity, we assume that Lipschitz are continuous Hesse, but note that both a superlinear local convergence result and the first-order global convergence theorem can be achieved without the first assumption. First, we present some critical assumptions regarding the gradient and Hessian approximations. Second, we show that these assumptions can theoretically be satisfied with a high probability of first and second order sub-sampling information. Third, we provide a condensed convergence analysis of the SCR, which is largely based on (Cartis et al., 2011a) but adapted to the case of stochastic gradients. There, we show that the local and global convergence characteristics of the ARC can be maintained by sub-sampled versions at the price of slightly inferior constants."}, {"heading": "4.1. Assumptions", "text": "Assumption 3 (Continuity): The functions fi-C2 (Rd), gi, and Hi are Lipschitz continuous for all i, whereby the Lipschitz constants \u03baf, \u03bag, and \u03baH are each the same. It follows from the use of the triangular inequality that these assumptions apply to all g and H, regardless of the sample size. Furthermore, it should be noted that the Hessian norms and gradient norms as a result of A3.In each iteration, the Hessian approximation Bk fulfill condition AM.4 of (Cartis et al., 2011a), which we repeat here for the sake of completeness. Assumption 4 (Sufficient correspondence of H and B)."}, {"heading": "4.2. Sampling Conditions", "text": "Based on probabilistic deviation limits for random vectors and matrices 3, we now present sample conditions3These limits have recently become popular under the name Concentration Inequalities. Contrary to classical boundary theorems, such as the Central Limit Theorem, concentration inequalities, due to their non-asymptotic nature, are particularly attractive for use in machine learning. This inequality guarantees sufficient steepness and curvature information in each iteration. In particular, the Amber Inequality indicates exponentially decreasing boundaries for the probability of a random variable to differ by more than its mean for a specified number of samples. We use this inequality to set the '2-standard distance distance distance-f-g, as well as the spectral standard distance-B-H-distance-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-f-t-d-t-quantities resulting from this."}, {"heading": "4.2.1. GRADIENT SAMPLING", "text": "As described in the appendix, the following term results from the vector-amber inequality. Lemma 6 (gradient deviation bound). Let us define the sampled gradient gk as in Equation 4. For \u2264 2\u03baf, we have probability (1 \u2212 \u03b4) that the deviation from the gradient norms, which is highly probable, represents a non-asymptotic limit. Notice how the accuracy of the gradients increases in the sample size. This limit results in the following condition. Theorem 7 (gradient sensing). If | Sg, k | \u2265 32\u04452f (protocol (((((2d) / 2001) + 1 / 4) M2: skys 4, M: 0, \u0441k: 0 (17) then satisfies sufficient agreement with the probability (1 \u2212 5)."}, {"heading": "4.2.2. HESSIAN SAMPLING", "text": "In analogy to the gradient case, we use the matrix version of Bernstein's inequality to derive the following Lemma.Lemma 8 (Hessian deviation limit) from it. Let us define the sample-like Hessian B as in Equation 4. For \u2264 4\u03bag, we have probability (1 \u2212 \u03b4) that the sample-like Hessian B (xk) \u2212 H (xk) with a high probability fulfils the sufficient correspondence condition (A4). Theorem 9 (Hessian sampling) | SB, k |, (18) From this, in turn, a Hessian sampling condition can be derived that with a high probability fulfils the sufficient correspondence condition (A4)."}, {"heading": "4.3. Convergence Analysis", "text": "The entire analysis of cubically regulated methods is prohibitively tedious, and we will therefore only identify the key characteristics that ensure global and rapid local convergence and enhance the worst possible complexity of these methods over standard confidence region approaches. Besides the cubically regulated term itself, these characteristics are mainly derived from the penalty parameter updates and step acceptance criteria of the ARC framework, which result in a good relationship between regulation and step size. For more details, see (Cartis et al., 2011a)."}, {"heading": "4.3.1. PRELIMINARY RESULTS", "text": "Firstly, we note that the penalty parameter sequence is guaranteed to remain within a certain limited positive range, largely due to the fact that the SCR is guaranteed to succeed once the penalty parameter exceeds a critical value."}, {"heading": "4.3.2. LOCAL CONVERGENCE", "text": "We show here a proof of local convergence for each sample scheme that meets the conditions set out in Theorem 7 and Theorem 9, as well as the additional condition that the sample size does not decrease in unsuccessful iterations. We show that such sample schemes ultimately provide exact gradients and Hessian information. On the basis of this observation, we obtain the following local convergence result (as derived in the appendix).Theorem 13 (square local convergence).Let A3 apply and assume that gk and Bk are sampled in such a way that 17 and 19 hold and | Sg, k | and | SB, k | are not reduced in unsuccessful iterations. Also, let sk A1 and xk \u00b2 x \u00b2 be met as k \u00b2, (26) where H (x) is positively defined. Furthermore, we assume that the stop criterion TC (A2) + xk + xk k k \u00b2, c > \u00b2 (b) is high."}, {"heading": "4.3.3. GLOBAL CONVERGENCE TO FIRST-ORDER CRITICAL POINT", "text": "Lemma 10 and 11 allow us to reduce the functional decline of a successful step in relation to the full gradient \u0435fk (as we will elaborate in Eq.31). Combined with Lemma 10, this allows us to give deterministic global convergence guarantees using only first-order stochastic information.Theorem 14 (convergence to first-order critical points): Apply A1, A3, A4 and A5. Furthermore, limit {f (xk)} below any finf > \u2212 \u221e. Thenlim k \u2192 \u221e \u0441\u043d\u044bm f (xk) = 0 (28)"}, {"heading": "4.3.4. GLOBAL CONVERGENCE TO SECOND-ORDER CRITICAL POINT", "text": "Unsurprisingly, the second-order convergence guarantee is based mainly on the use of second-order information, so the stochastic gradients do not alter the result or the proof as found in section 5 of (Cartis et al., 2011a). We will restate them here for completeness. Theorem 15 (Second-order global convergence): Apply A3, A4, and A5. Furthermore, {f (xk)} below finf and sk is a global minimizer of mk over a subspaceLk spanned by the columns of the d \u00b7 l-orthogonal matrix Qk. Since B \u2192 H is asymptotic (Eq.20), any sub-sequence of negative left eigenvalues {vommin (QkH (xk) Qk (xk) Qk)}} converges to zero for sufficiently large, successful iterations."}, {"heading": "4.3.5. WORST-CASE ITERATION COMPLEXITY", "text": "For the worst-case analysis, we will determine the two disjunction index sets Uj and Sj, which represent the unsuccessful and successful SCR iterations that occurred up to a certain iteration j > 0. As indicated in Lemma 10, the penalty parameter \u03c3k is limited above and therefore the SCR can perform only a limited number of unsuccessful iterations. Consequently, the total number of unsuccessful iterations is at most a problem log that shows the number of successful iterations constantly times. Lemma 16 (number of unsuccessful iterations)."}, {"heading": "5. Experimental results", "text": "In this section we present experimental results on real datasets with n d 1. They largely confirm the analysis derived in the previous section. More detailed results and experiments on higher dimensional problems can be found in the appendix."}, {"heading": "5.1. Practical implementation of SCR", "text": "We implement SCR as specified in Algorithm 1 and observe the following details: Below (Erdogdu & Montanari, 2015) we request that the sample conditions derived in Section 4 be maintained with probability O (1 \u2212 1 / d), resulting in the following practically applicable sample schemes: Sk, H | \u2265 36\u03ba2g log (d) (C \u0441sk) 2, C > 0, \u0445k > 0 | Sk, g | \u2265 32\u04452f (log (d) + 1 / 4) M2 \u0441sk 4, M > 0, \u0441k > 0. (34) The positive constants C and M can be used to scale the sample size to a reasonable proportion of the entire data set and can also be used to balance \u0445g and \u0445f, which are usually expensive to capture. However, if we make the choice of | S | for the current iteration k, the incremental sk must still be determined based on the Lipata's previous results, we argue that the early evaluation functions involved in the Eemata are insufficient."}, {"heading": "5.2. Baselines and datasets", "text": "We compare SCR with different optimization methods from Section 2. These include SGD (with constant step size), SAGA, Newton's method, BFGS, L-BFGS and ARC. Further details on the selection of hyperparameters can be found in the appendix. We conducted experiments with the data sets a9a, covtype and higgs (see details in the appendix). We experimented with a binary logistic regression model with two different regularizers: a standard '2 penalty \u03bb x \u0445 2 and a non-convex regularization mechanism \u03bb \u2211 d i = 1 x 2 (i) / (1 + x2 (i)) (see (Reddi et al., 2016b))."}, {"heading": "5.3. Results", "text": "The results in Figure 1 confirm our intuition that the SCR can shorten the computation time of the ARCs without losing its global convergence property. Newton's method is closest in terms of performance, but it suffers greatly from an increase in the d, as additional results in the appendix show. Furthermore, it cannot optimize the non-convex version of the covtype due to a singular Hessian. Remarkably, the BFGS terminates the non-convex Higgs datasets early due to a local saddle point. Finally, the high condition number of covtype has a significant impact on the performance of SGD, SAGA and L-BFGS."}, {"heading": "6. Conclusion", "text": "We show that this method has the same convergence properties as its deterministic counterpart, the most well-known convergence properties of non-convex functions. Our proposed method is particularly interesting on a large scale when nd. Numerical experiments on both real and synthetic data sets demonstrate the performance of the proposed algorithm, which we have compared with its deterministic variant, as well as with more classical optimization methods. As a future work, we would like to investigate the appropriateness of our method of training neural networks, which are known to be difficult to optimize due to the presence of saddle points."}, {"heading": "A. Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1. Concentration Inequalities and Sampling Schemes", "text": "For the sake of simplicity, we drop the k subscript of iteration in the following results of this section."}, {"heading": "A.1.1. GRADIENT SAMPLING", "text": "First, we extend the vector-amber inequality as found in (Gross, 2011) to the average of the independent, zeromean vector-amber-weighted random variables (vector-amber inequality). Let's leave x1,.., xn are independent vector-weighted random variables with common dimension d and assume that each of them is centered, uniformly limited, and also the variance over: E [xi] = 0 and vector-weighted random variables [xi] 2 and [xi] n sum [xi] [xi xi] 2 + 14) and E [xi xi [xi] 2] \u2264. \"Letz = 1n n n n.\" Then we have for 0 < < p \"2 / \u00b5P\" (vector-weighted random variants)."}, {"heading": "Proof of Lemma 6:", "text": "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "Proof of Theorem 7:", "text": "By using lemmas 6 we can Eg (x) \u2212 Ef (x), Ei (m), Ei (2), Ei (2), Ei (2), Ei (2), Ei (1), Ei (1), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), Ei (2), (2), Ei (2), (2, 2, 2, Ei (2), (2, 2, 2, 2 (2), (2, 2, 2, 2, 2 (2), (2, 2, 2, Egg (2), (2, 2, 2, 2, 2, 2, 2 (2), (2, 2, 2, 2, 2, 2, 2 (2), (2, 2, 2, 2, 2, 2, 2 (2), (2, 2, 2, 2, 2, 2, 2 (2), (2, 2, 2, 2, 2, 2, 2, 2, 2, 2 (2), (2, 2, 2, 2, 2, 2, 2, 2, 2, 2 (2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), (2 (2, 2, 2, 2, 2), (2), (2, (2), 2, (2, 1, (2), (2), (2, (2), (2), (2, (2), (2), (2, (2), (2), (2), (2, (2), (2), (2, (2), (2), (2), (2, (2), (2), (2), (2"}, {"heading": "A.1.2. HESSIAN SAMPLING", "text": "Lemma 19 (Matrix Amber Inequality): Let us A1,.., An be independent random matrices with common dimension d \u00b7 d and take that each is centered, uniformally bounded and also the variance is bounded over: E [Ai] = 0 and improved... (A2i] as well of E [A2i]. (49) Proof: Theorem 12 in (Gross, 2011) returns the following operator amber inequalityP (0) as haveP (0) as 2d exp (\u2212 min {242, 2\u00b5}), Proof: Theorem 12 in (Gross, 2011) returns the following operator amber inequalityP (0). (1 Ai)."}, {"heading": "A.2. Convergence Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.2.1. PRELIMINARY RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Lemma 10:", "text": "The lower limit follows directly from step 7 in the algorithm construction (see algorithm 1). (see algorithm 1). (see algorithm 1) The lower limit (see algorithm 1) is very successful and will therefore be very successful. (see algorithm 1) The lower limit (see algorithm 2) is very successful. (see algorithm 2) The lower limit (see algorithm 2) is very successful. (see algorithm 2) The lower limit (see algorithm 2) is very successful. (see algorithm 2). (see algorithm 2). (see algorithm 2) is very successful. (see algorithm 2). (see algorithm 2) is very successful. (see algorithm 2). (see algorithm 2). (see algorithm 2). (see algorithm 2). (see algorithm 2). (see algorithm 2). (see). (see algorithm 2). (see). (see algorithm 2). (see). (see algorithm 2). (see). (see algorithm 2). (see algorithm 2)."}, {"heading": "A.2.2. LOCAL CONVERGENCE", "text": "Before we can direct our attention directly to the ratio on the ratio ratio, we must rely on the fact that we do not succeed in achieving such a ratio. (...) We must rely on the ratio on the ratio, on the ratio we rely on the ratio, on the ratio we rely on the ratio, on the ratio we rely on the ratio, on the ratio we rely on the ratio, on the ratio we rely on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio on the ratio, on the ratio, on the ratio on the ratio, on the ratio, on the ratio on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, the ratio, on the ratio, on the ratio, the ratio, on the ratio, on the ratio, the ratio, on the ratio, the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the ratio, on the"}, {"heading": "Proof of Theorem 13:", "text": "From Lemma 10 we have a quadratic convergence of the gradients. Furthermore, all the assumptions required for the increment limits of Lemma 12 and 23 hold. Finally, Lemma 25 states that all iterations are ultimately successful. Thus, we can combine the upper (69) and lower (24), which are bound to the increment size for all k, sufficiently large to obtain 1Rmin (wk). (wk + 1), which we can solve for the gradient norm ratio between f (wk + 1), f (wk), f (wk) and f (wk). (wk) Finally, we have a quadratic convergence of the gradients. (82) As a result, as long as the right side of (82) remains below infinity, i.e. the convergence of (wk) and f (wk) yields a quadratic convergence of the gradients."}, {"heading": "A.2.3. FIRST ORDER GLOBAL CONVERGENCE", "text": "Note that the preliminary results of Lemma 11 and 12 allow us to reduce the functional decline of a successful step in relation to the full gradient Fk + 1. Combined with Lemma 10, we can thus give a deterministic global convergence guarantee, while using only stochastic information of the first order 6."}, {"heading": "Proof of Theorem 14:", "text": "We consider two cases in terms of the number of successful steps for this proof. Case (i): SCR only takes an endless number of successful steps. Therefore, we have an index k0 that yields the very last successful iteration, and all subsequent iterations remain at the same point xk0 + 1. This is xk0 + 1 = xk0 + i, and we assume that all iterations k0 + 1 are unsuccessful iterations, e.g. these iterations k0 + 1 = > 0, but then contradict Lemma 10, which states that the above requirements are limited. (83) Moreover, since all iterations k0 + 1 are unsuccessful iterations, the number of iterations k0 + 1 does not increase and we have no iterations, e.g. these iterations k0 + k. (84) However, this contradicts Lemma 10, which states that iterations k0 + 1 are limited."}, {"heading": "A.2.4. SECOND ORDER GLOBAL CONVERGENCE AND WORST CASE ITERATION COMPLEXITY", "text": "For the proofs of theorem 15 and theorem 17, we refer the reader to theorem 5.4 in (Cartis et al., 2011a) and corollary 5.3 in (Cartis et al., 2011b). Note that, as explained above in the proofs of Lemma 10 and Lemma 11, the constants involved in the convergence theorems change due to the stochastic gradients used in our frame.A.3. Note that even without Lipschitz, this result changes continuity of H and less strong match conditions, as used in the experiments, as well as the choice of hyperparameters. All experiments were conducted on a CPU with a nominal clock rate of 2.4 GHz."}, {"heading": "Benchmark methods", "text": "We select a mini-batch of size dn / 10e on the real world classification - and dn / 100e on the multi-class problems. On the artificial datasets, which we use only at random 1 datapoint per iteration and update the parameters related to this point, we use a problem-dependent, constant step size, as this results in a faster initial convergence (Hofmann et al., 2015), (Roux et al., 2012). \u2022 SAGA: is a variance-reduced variant of the SGD, which only has 1 datapoint sample and uses a constant step size. \u2022 Broyden-Gold-Color-Shanno (BFGS) is the most popular and stable quasi-Newton method. \u2022 Limited-Memory BFGS is a variant of the BFGS, which only uses the one safe HFGS method."}], "references": [{"title": "Finding local minima for nonconvex optimization in linear time", "author": ["Agarwal", "Naman", "Allen-Zhu", "Zeyuan", "Bullins", "Brian", "Hazan", "Elad", "Ma", "Tengyu"], "venue": "arXiv preprint arXiv:1611.01146,", "citeRegEx": "Agarwal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2016}, {"title": "Convergence rate analysis of a stochastic trust region method for nonconvex optimization", "author": ["Blanchet", "Jose", "Cartis", "Coralia", "Menickelly", "Matt", "Scheinberg", "Katya"], "venue": "arXiv preprint arXiv:1609.07428,", "citeRegEx": "Blanchet et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Blanchet et al\\.", "year": 2016}, {"title": "On the use of stochastic hessian information in optimization methods for machine learning", "author": ["Byrd", "Richard H", "Chin", "Gillian M", "Neveitt", "Will", "Nocedal", "Jorge"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Byrd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Byrd et al\\.", "year": 2011}, {"title": "Gradient descent efficiently finds the cubic-regularized non-convex newton step", "author": ["Carmon", "Yair", "Duchi", "John C"], "venue": null, "citeRegEx": "Carmon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Carmon et al\\.", "year": 2016}, {"title": "Global convergence rate analysis of unconstrained optimization methods based on probabilistic models", "author": ["Cartis", "Coralia", "Scheinberg", "Katya"], "venue": "Mathematical Programming,", "citeRegEx": "Cartis et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Cartis et al\\.", "year": 2017}, {"title": "Adaptive cubic regularisation methods for unconstrained optimization. part i: motivation, convergence and numerical results", "author": ["Cartis", "Coralia", "Gould", "Nicholas IM", "Toint", "Philippe L"], "venue": "Mathematical Programming,", "citeRegEx": "Cartis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cartis et al\\.", "year": 2011}, {"title": "Adaptive cubic regularisation methods for unconstrained optimization. part ii: worst-case function-and derivativeevaluation complexity", "author": ["Cartis", "Coralia", "Gould", "Nicholas IM", "Toint", "Philippe L"], "venue": "Mathematical programming,", "citeRegEx": "Cartis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cartis et al\\.", "year": 2011}, {"title": "Libsvm: a library for support vector machines", "author": ["Chang", "Chih-Chung", "Lin", "Chih-Jen"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "Chang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2011}, {"title": "The loss surfaces of multilayer networks", "author": ["Choromanska", "Anna", "Henaff", "Mikael", "Mathieu", "Michael", "Arous", "G\u00e9rard Ben", "LeCun", "Yann"], "venue": "In AISTATS,", "citeRegEx": "Choromanska et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Choromanska et al\\.", "year": 2015}, {"title": "Starting small - learning with adaptive sample sizes", "author": ["Daneshmand", "Hadi", "Lucchi", "Aur\u00e9lien", "Hofmann", "Thomas"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Daneshmand et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Daneshmand et al\\.", "year": 2016}, {"title": "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives", "author": ["Defazio", "Aaron", "Bach", "Francis", "Lacoste-Julien", "Simon"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Defazio et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Defazio et al\\.", "year": 2014}, {"title": "Convergence rates of sub-sampled newton methods", "author": ["Erdogdu", "Murat A", "Montanari", "Andrea"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Erdogdu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Erdogdu et al\\.", "year": 2015}, {"title": "Hybrid deterministic-stochastic methods for data fitting", "author": ["Friedlander", "Michael P", "Schmidt", "Mark"], "venue": "SIAM Journal on Scientific Computing,", "citeRegEx": "Friedlander et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Friedlander et al\\.", "year": 2012}, {"title": "Escaping from saddle points-online stochastic gradient for tensor decomposition", "author": ["Ge", "Rong", "Huang", "Furong", "Jin", "Chi", "Yuan", "Yang"], "venue": "In COLT, pp", "citeRegEx": "Ge et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ge et al\\.", "year": 2015}, {"title": "Stochastic first-and zeroth-order methods for nonconvex stochastic programming", "author": ["Ghadimi", "Saeed", "Lan", "Guanghui"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Ghadimi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ghadimi et al\\.", "year": 2013}, {"title": "Updating the regularization parameter in the adaptive cubic regularization algorithm", "author": ["Gould", "Nicholas IM", "M Porcelli", "Toint", "Philippe L"], "venue": "Computational optimization and applications,", "citeRegEx": "Gould et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gould et al\\.", "year": 2012}, {"title": "Recovering low-rank matrices from few coefficients in any basis", "author": ["Gross", "David"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Gross and David.,? \\Q2011\\E", "shortCiteRegEx": "Gross and David.", "year": 2011}, {"title": "A linear-time algorithm for trust region problems", "author": ["Hazan", "Elad", "Koren", "Tomer"], "venue": "Mathematical Programming,", "citeRegEx": "Hazan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2016}, {"title": "Most tensor problems are np-hard", "author": ["Hillar", "Christopher J", "Lim", "Lek-Heng"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Hillar et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hillar et al\\.", "year": 2013}, {"title": "Variance reduced stochastic gradient descent with neighbors", "author": ["Hofmann", "Thomas", "Lucchi", "Aurelien", "Lacoste-Julien", "Simon", "McWilliams", "Brian"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Hofmann et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hofmann et al\\.", "year": 2015}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Johnson", "Rie", "Zhang", "Tong"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Johnson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2013}, {"title": "Learning multiple layers of features from tiny images", "author": ["Krizhevsky", "Alex", "Hinton", "Geoffrey"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2009}, {"title": "Introductory lectures on convex optimization", "author": ["Nesterov", "Yurii"], "venue": "applied optimization,", "citeRegEx": "Nesterov and Yurii.,? \\Q2004\\E", "shortCiteRegEx": "Nesterov and Yurii.", "year": 2004}, {"title": "Cubic regularization of newton method and its global performance", "author": ["Nesterov", "Yurii", "Polyak", "Boris T"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Nesterov et al\\.", "year": 2006}, {"title": "Stochastic variance reduction for nonconvex optimization", "author": ["Reddi", "Sashank J", "Hefny", "Ahmed", "Sra", "Suvrit", "Poczos", "Barnabas", "Smola", "Alex"], "venue": "arXiv preprint arXiv:1603.06160,", "citeRegEx": "Reddi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Reddi et al\\.", "year": 2016}, {"title": "Fast incremental method for nonconvex optimization", "author": ["Reddi", "Sashank J", "Sra", "Suvrit", "P\u00f3czos", "Barnab\u00e1s", "Smola", "Alex"], "venue": "arXiv preprint arXiv:1603.06159,", "citeRegEx": "Reddi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Reddi et al\\.", "year": 2016}, {"title": "A stochastic gradient method with an exponential convergence rate for finite training sets", "author": ["Roux", "Nicolas L", "Schmidt", "Mark", "Bach", "Francis R"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Roux et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Roux et al\\.", "year": 2012}, {"title": "When are nonconvex problems not scary", "author": ["Sun", "Ju", "Qu", "Qing", "Wright", "John"], "venue": "arXiv preprint arXiv:1510.06096,", "citeRegEx": "Sun et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "Yet, non-convex functions are extremely hard to optimize due to the presence of saddle points and local minima which are not global optima (Dauphin et al., 2014; Choromanska et al., 2015).", "startOffset": 139, "endOffset": 187}, {"referenceID": 13, "context": "In this regard, a lot of attention has focused on a specific type of functions known as strict saddle functions or ridable functions (Ge et al., 2015; Sun et al., 2015).", "startOffset": 133, "endOffset": 168}, {"referenceID": 27, "context": "In this regard, a lot of attention has focused on a specific type of functions known as strict saddle functions or ridable functions (Ge et al., 2015; Sun et al., 2015).", "startOffset": 133, "endOffset": 168}, {"referenceID": 13, "context": "Examples of strict saddle functions include dictionary learning, orthogonal tensor decomposition and generalized phase retrieval (Ge et al., 2015; Sun et al., 2015).", "startOffset": 129, "endOffset": 164}, {"referenceID": 27, "context": "Examples of strict saddle functions include dictionary learning, orthogonal tensor decomposition and generalized phase retrieval (Ge et al., 2015; Sun et al., 2015).", "startOffset": 129, "endOffset": 164}, {"referenceID": 10, "context": "Another way to recover a linear rate of convergence for strongly-convex functions is to use variance-reduced methods (Johnson & Zhang, 2013; Defazio et al., 2014; Roux et al., 2012; Hofmann et al., 2015; Daneshmand et al., 2016).", "startOffset": 117, "endOffset": 228}, {"referenceID": 26, "context": "Another way to recover a linear rate of convergence for strongly-convex functions is to use variance-reduced methods (Johnson & Zhang, 2013; Defazio et al., 2014; Roux et al., 2012; Hofmann et al., 2015; Daneshmand et al., 2016).", "startOffset": 117, "endOffset": 228}, {"referenceID": 19, "context": "Another way to recover a linear rate of convergence for strongly-convex functions is to use variance-reduced methods (Johnson & Zhang, 2013; Defazio et al., 2014; Roux et al., 2012; Hofmann et al., 2015; Daneshmand et al., 2016).", "startOffset": 117, "endOffset": 228}, {"referenceID": 9, "context": "Another way to recover a linear rate of convergence for strongly-convex functions is to use variance-reduced methods (Johnson & Zhang, 2013; Defazio et al., 2014; Roux et al., 2012; Hofmann et al., 2015; Daneshmand et al., 2016).", "startOffset": 117, "endOffset": 228}, {"referenceID": 13, "context": "However, the work of (Ge et al., 2015; Sun et al., 2015) recently showed that SGD can achieve stronger guarantees in the case of strict saddle functions.", "startOffset": 21, "endOffset": 56}, {"referenceID": 27, "context": "However, the work of (Ge et al., 2015; Sun et al., 2015) recently showed that SGD can achieve stronger guarantees in the case of strict saddle functions.", "startOffset": 21, "endOffset": 56}, {"referenceID": 2, "context": "An increasingly popular alternative is to use sub-sampling techniques to approximate the Hessian matrix, such as done for example in (Byrd et al., 2011) and (Erdogdu & Montanari, 2015).", "startOffset": 133, "endOffset": 152}, {"referenceID": 0, "context": "For example, (Agarwal et al., 2016) refined the approach of (Nesterov & Polyak, 2006) to return an approximate local minimum in time which is linear in the input representation.", "startOffset": 13, "endOffset": 35}, {"referenceID": 1, "context": "Finally, the work of (Blanchet et al., 2016) proposed a stochastic variant of a trust region method but their analysis does not specify any accuracy level required for the estimation of the stochastic Hessian.", "startOffset": 21, "endOffset": 44}, {"referenceID": 19, "context": "We use a problem-dependent, constant step-size as this yields faster initial convergence (Hofmann et al., 2015),(Roux et al.", "startOffset": 89, "endOffset": 111}, {"referenceID": 26, "context": ", 2015),(Roux et al., 2012).", "startOffset": 8, "endOffset": 27}, {"referenceID": 15, "context": "A more sophisticated approach can be found in (Gould et al., 2012).", "startOffset": 46, "endOffset": 66}], "year": 2017, "abstractText": "We consider the minimization of non-convex functions that typically arise in machine learning. Specifically, we focus our attention on a variant of trust region methods known as cubic regularization. This approach is particularly attractive because it escapes strict saddle points and it provides stronger convergence guarantees than firstand second-order as well as classical trust region methods. However, it suffers from a high computational complexity that makes it impractical for large-scale learning. Here, we propose a novel method that uses sub-sampling to lower this computational cost. By the use of concentration inequalities we provide a sampling scheme that gives sufficiently accurate gradient and Hessian approximations to retain the strong global and local convergence guarantees of cubically regularized methods. To the best of our knowledge this is the first work that gives global convergence guarantees for a sub-sampled variant of cubic regularization on non-convex functions. Furthermore, we provide experimental results supporting our theory.", "creator": "LaTeX with hyperref package"}}}