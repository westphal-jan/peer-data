{"id": "1705.08272", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-May-2017", "title": "Matching neural paths: transfer from recognition to correspondence search", "abstract": "Many machine learning tasks require finding per-part correspondences between objects. In this work we focus on low-level correspondences - a highly ambiguous matching problem. We propose to use a hierarchical semantic representation of the objects, coming from a convolutional neural network, to solve this ambiguity. Training it for low-level correspondence prediction directly might not be an option in some domains where the ground-truth correspondences are hard to obtain. We show how transfer from recognition can be used to avoid such training. Our idea is to mark parts as \"matching\" if their features are close to each other at all the levels of convolutional feature hierarchy (neural paths). Although the overall number of such paths is exponential in the number of layers, we propose a polynomial algorithm for aggregating all of them in a single backward pass. The empirical validation is done on the task of stereo correspondence and demonstrates that we achieve competitive results among the methods which do not use labeled target domain data.", "histories": [["v1", "Fri, 19 May 2017 16:40:35 GMT  (2894kb,D)", "https://arxiv.org/abs/1705.08272v1", "Submitted to NIPS 2017"], ["v2", "Wed, 24 May 2017 08:04:30 GMT  (2873kb,D)", "http://arxiv.org/abs/1705.08272v2", null]], "COMMENTS": "Submitted to NIPS 2017", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["nikolay savinov", "lubor ladicky", "marc pollefeys"], "accepted": true, "id": "1705.08272"}, "pdf": {"name": "1705.08272.pdf", "metadata": {"source": "CRF", "title": "Matching neural paths: transfer from recognition to correspondence search", "authors": ["Nikolay Savinov", "Lubor Ladicky", "Marc Pollefeys"], "emails": ["nikolay.savinov@inf.ethz.ch", "lubor.ladicky@inf.ethz.ch", "marc.pollefeys@inf.ethz.ch"], "sections": [{"heading": null, "text": "Many machine learning tasks require finding individual similarities between objects. In this work, we focus on subordinate similarities - a highly ambiguous matching problem. We suggest using a hierarchical semantic representation of objects originating from a Convolutionary Neural Network to solve this ambiguity. Training for subordinate correspondence predictions might not be an option in some areas where the similarities between reason and truth are hard to obtain. We show how transmissions from recognition can be used to avoid such training. Our idea is to label parts as \"matching\" when their characteristics are close together at all levels of the Convolutionary Characteristic Hierarchy (Neural Paths). Although the total number of such paths is exponential in the number of layers, we suggest a polynomial algorithm to use them all in a single backward regression to show that we are not competing with the target task."}, {"heading": "1 Introduction", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}, {"heading": "2 Notation", "text": "We assume that the input data will be a multi-dimensional network topology in cases where the input data has a multi-dimensional network topology, and in cases where the input data has a multi-dimensional network topology. We assume that the input objects in the series of (B + 1) -dimensional network types will be in the series of (B + 1) -dimensional network types. (D) The input data and activations will be characterized by a (B + 1) -dimensional network optics in the series of (B + 1) -dimensional network optics. (D) The input data and activations will be characterized by a (B + 1) -dimensional vector x (B + 1) -dimensional network optics in the series of (B + 1) -dimensional network optics in the series of (B + 1) -dimensional network optics (B)."}, {"heading": "3 Correspondence via path matching", "text": "The goal is to create correspondences between the input data levels A0 and A \u00b2 0. That is, each cell A0 (x) in the reference object o (x) has a certain shift d (we call this pair a Siamese path), and we want to estimate the cornerstones of our method: We determine the matching of A0 (x) with A \u00b2 0 (x \u2212 d) for a shift d (we call this pair a Siamese path), and we want to assign A0 (x) to A \u00b2 0 (x) for a shift d (x \u2212 d) for a shift d (we call this pair a Siamese path) that arises at these nodes and ends at the last layers."}, {"heading": "4 Linear-time backward algorithm", "text": "Theorem 1: \"For each m '( \u00b7), each x 'and all that are associative to each other, i.e. a (b'c) = a b'a c, we can use U (x, d) for all x' and d'in O (| A | + | E |). Proof: Since there is an association, we can use a dynamic programming approach that develops that for gradient traceability. First, let us introduce the subsampling functions k's (d) = (k's \u2212 1 (d)), k '( d) (d) = d ', s \u2265 (k0s = ks as introduced in Equation 1. Then we introduce auxiliary variables U '(d) for each layer' = 0,., L, which have the same definition as U (x, d), except for the fact that the patheities that are considered in them."}, {"heading": "5 Choice of neuron matching function m and operators \u2295,", "text": "For the wavelengths, we otherwise use the appropriate function mconv (w, v) = {0 if w = 0, v = 0, min (w, v) max (w, v). (9) For the max pooling layers, the computational graph can be truncated to only one active connection (since only one element affects superordinate attributes). Furthermore, max pooling does not create additional attributes, but only continues / continues the existing ones. Therefore, it does not make sense to consider the pre-activations for these layers, since they are the same as activations (up to subsampling). For these reasons, we use maxpool (w, v) =? (w = arg maxNw), (v = arg maxNv), (10) where Nw is the neighborhood of the max pooling node w."}, {"heading": "6 Experiments", "text": "We validate our approach in the field of computer vision, as our method requires a revolutionary neural network trained on a large recognition dataset. From the correspondence tasks of vision, we choose stereo matching to validate our method. For this task, the dimensionality of the input data is B = 2 and the displacement quantity is represented by horizontal displacements D = {(0, 0, 0),.... (Dmax, 0, 0)}. We always convert images to grayscale before executing CNNs, following the observation of [24] that the color does not help. For pre-trained CNN detection, we chose the VGG-16 network [19]. This network is summarized in Table 1. We refer further to layer disities from this table. It is important to mention that we did not use the full range of layers in our experiments. Specifically, we usually started from layer 2 and finished at layer 8. As such, the multichannel is still necessary to consider."}, {"heading": "6.1 Experimental setup", "text": "For stereo matching, we selected the largest data sets available, KITTI 2012 and KITTI 2015. All image pairs in these data sets are corrected so that matches can be found in the same line. For each training pair, the displacement between ground and truth is measured densely per pixel. This basic truth was obtained by projecting LIDAR's point cloud onto the reference image. The quality measure is the percentage error of pixels whose predicted displacement error is greater than a threshold of t-pixels. We considered a range of thresholds t = 1,.., 5, while the most important benchmark measure is Err3. This measure is calculated only for the pixels used in both images from the stereo pair. For comparison with baselines, we used the setup proposed in [24] - the pioneering work that introduced deep learning for stereo matching and which currently remains one of the best methods for comparing the extensive data sets [ITTI]."}, {"heading": "6.2 Baselines", "text": "We have two types of baselines in our assessment: those from [24] and our simpler versions of deep function transfer similar [12], which do not take paths into account; the first group of baselines from [24] are the following: the sum of absolute differences \"sad,\" the counting transforms \"censorship\" [22], the normalized cross-correlation \"ncc.\" We have also checked the learning-based methods \"fst\" and \"acrt\" [24] for completeness, although they use training data to learn characteristics, whereas our method does not. For the second group of baselines, we stack the activation volumes for the given layer area and stitch up the layer volumes if they have a reduced resolution; then we calculate a normalized cross-correlation of the stacked characteristics. These baselines are referred to as \"corr (s, t),\" where \"s\" is the baseline, \"figurative.\""}, {"heading": "6.3 KITTI 2012", "text": "The data set consists of 194 pairs of training images and 195 pairs of test images, excluding reflective surfaces such as windshields from the ground. Table 2 shows that our \"ours (2, 8)\" method performs better than baselines, while at the same time performing less well than learning-based methods from [24]. The main promise of our method is scalability: while we are testing it on a task where a huge amount of effort has been invested in collecting training data, there are other important tasks without such extensive data sets."}, {"heading": "6.4 Ablation study on KITTI 2012", "text": "The aim of this section is to understand how important the deep hierarchy of characteristics is to one or a few levels. We compared the following settings: \"our (2, 2)\" uses only the second level, \"our (2, 3)\" uses only the range from layer 2 to layer 3, \"our (2, 8)\" takes into account the entire range of layers, but only the central arcs in the coils (which connect the same pixel positions between the activations), which are taken into account in reverse, \"our (2, 8)\" is the complete method. The result in Table 3 shows that it is profitable to use the entire hierarchy both in terms of depth and coverage of the receptive field."}, {"heading": "6.5 KITTI 2015", "text": "The stereo dataset consists of 200 pairs of training images and 200 pairs of test images. The main difference to KITTI 2012 is that the images are coloured and the reflective surfaces are present in the evaluation. Similar conclusions as KITTI 2012 can be drawn from experimental results: Our method provides a reasonable transmission, as it is inferior only to learning-based methods - see Table 4. We show our depth imaging results in Fig. 2."}, {"heading": "6.6 Style transfer experiment on KITTI 2015", "text": "The aim of this experiment is to demonstrate the robustness of the recognition hierarchy for the transfer to correspondence search - something we advocated in the introduction as an advantage of our approach. We use the style transfer method implemented in the Prism app [4]. We performed different style transfers on the left and right images. Although the higher image descriptions are now very different at the pixel level, the overarching descriptions of the images remain the same, enabling the successful use of our method. Qualitative results show the robustness of our path-based method in Fig. 3 (see also Fig. 2 for visual comparison with normal data)."}, {"heading": "7 Conclusion", "text": "In this paper, we have presented a method for transferring from recognition to the lowest-level correspondence search, using activation paths from deep revolutionary neural networks and proposing an efficient polynomic algorithm to aggregate an exponential number of such paths. Empirical results of the stereo matching task show that our method is competitive with methods that do not use marked data from the target domain. It would be interesting to apply this technique to sound, which should be possible as soon as a high-quality deep revolutionary model becomes available to the public (e.g. [20])."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Many machine learning tasks require finding per-part correspondences between<lb>objects. In this work we focus on low-level correspondences \u2014 a highly ambiguous<lb>matching problem. We propose to use a hierarchical semantic representation of<lb>the objects, coming from a convolutional neural network, to solve this ambiguity.<lb>Training it for low-level correspondence prediction directly might not be an option<lb>in some domains where the ground-truth correspondences are hard to obtain. We<lb>show how transfer from recognition can be used to avoid such training. Our idea is<lb>to mark parts as \u201cmatching\u201d if their features are close to each other at all the levels<lb>of convolutional feature hierarchy (neural paths). Although the overall number<lb>of such paths is exponential in the number of layers, we propose a polynomial<lb>algorithm for aggregating all of them in a single backward pass. The empirical<lb>validation is done on the task of stereo correspondence and demonstrates that we<lb>achieve competitive results among the methods which do not use labeled target<lb>domain data.", "creator": "LaTeX with hyperref package"}}}