{"id": "1705.08430", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues", "abstract": "In this work we derive a variant of the classic Glivenko-Cantelli Theorem, which asserts uniform convergence of the empirical Cumulative Distribution Function (CDF) to the CDF of the underlying distribution. Our variant allows for tighter convergence bounds for extreme values of the CDF.", "histories": [["v1", "Tue, 23 May 2017 17:37:33 GMT  (18kb,D)", "https://arxiv.org/abs/1705.08430v1", null], ["v2", "Fri, 4 Aug 2017 12:40:36 GMT  (19kb,D)", "http://arxiv.org/abs/1705.08430v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.GT", "authors": ["noga alon", "moshe babaioff", "yannai a gonczarowski", "yishay mansour", "shay moran", "amir yehudayoff"], "accepted": true, "id": "1705.08430"}, "pdf": {"name": "1705.08430.pdf", "metadata": {"source": "CRF", "title": "Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues", "authors": ["Noga Alon", "Moshe Babaioff", "Yannai A. Gonczarowski", "Yishay Mansour", "Shay Moran", "Amir Yehudayoff"], "emails": ["nogaa@tau.ac.il.", "moshe@microsoft.com.", "yannai@gonch.name.", "mansour@tau.ac.il.", "shaymoran1@gmail.com.", "amir.yehudayoff@gmail.com."], "sections": [{"heading": null, "text": "We apply our boundary in the context of revenue learning, a well-studied problem in economics and algorithmic game theory. We derive sample complexity limits for the uniform convergence rate of empirical revenues to true revenues, starting from a boundary to the kth moment of valuations, for each (possibly broken) k > 1. For a uniform convergence within the boundary, we give a complete characterization and a zero-point law: when the first moment of valuations is finite, then almost certainly a uniform convergence occurs; conversely, when the first moment is infinite, then there is almost never a uniform convergence."}, {"heading": "1 Introduction", "text": "A basic task in machine research is to learn an unknown distribution."}, {"heading": "1.1 Related work", "text": "qqm (p), qm (p), qm (p), qm (p), qm (p), qm (p), qm (p), qm (p), qm (p), qm (p), qm (p), qm (p), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qm (qm), qqm), qm (qm), qm (qm), qm), qm (qm), qm (qm), qm (qm), qm), qm (qm), qqm, qqm, qm (qqm), qqm, qqqm, qqqqqqqqqqqqqqqqq"}, {"heading": "1.2 Paper organization", "text": "The rest of the paper is broken down as follows: First, we present the application of our Submultiplicative Glivenko-Cantelli to the revenue estimate in Section 2. In Section 3, we examine the Submultiplicative Glivenko-Cantelli variant and discuss some extensions thereof. Section 4 contains a discussion and possible directions for future work. Some of the evidence will be moved to the attachments."}, {"heading": "2 Uniform Convergence of Empirical Revenues", "text": "In this section, we will demonstrate the application of our submultiplicative Glivenko-Cantelli variant by setting uniform convergence limits for a family of unlimited random variables in the context of income estimation."}, {"heading": "2.1 Model", "text": "Consider a good g for which we want to set a price. Let V be a random variable that models the valuation of a random consumer for g. Technically, V is assumed to be a non-negative random variable, and we denote by \u00b5 its induced distribution via R +. A consumer who evaluates the revenue g at a valuation v is willing to buy the good at any price p \u2264 v, but not at a higher price. This implies that the realized revenue to the seller from a (booked) price p is the random variable p \u00b7 1 {p \u2264 V}. The quantum of a turnover v + isq (v) = q (v; p; \u00b5), p ({x: x = v}).This model models the percentage of consumers in the population who are willing to buy the good when the revenue from a (booked) price p + isr (p) is equal."}, {"heading": "2.2 Quantitative bounds on the uniform convergence rate", "text": "Remember that we are interested in deriving sample boundaries that would guarantee uniform convergence for the revenue estimation problem. We will show that, given an upper limit of the kth moment of V for some k > 1, we can derive a finite convergence from it. To this end, we will use our submultiplicative glivenko-cantelli limit (theorem 1,4). We will also consider the case of K = 1, namely that E [V] is limited and show that in this case there is still a uniform convergence in the boundary, but that there can be no guarantees for the convergence rate. Interestingly, it turns out that E [V] < s is not only sufficient, but also necessary, so that in the boundary the empirical convergence to the true income (see section 2.3). We start by showing that the boundaries of the kth moment for k > 1 yields are explicitly fixed on the convergence rate."}, {"heading": "2.3 A qualitative characterization of uniform convergence", "text": "The limits of complexity in Theorem 2.1 are significant as long as \u03b8 > 0, but deteriorate drastically as \u03b8 \u2192 0. In fact, as the following example shows, there is no limit to the uniform convergence of complexity, which depends only on the first moment of V, i.e., its expectation. Let us consider a distribution \u03b7p, so that with the probability p we have V = 1 / p and otherwise V = 0. Sure, E [V] = 1. However, let us consider the kth moment, for k = 1 / p) evaluations, to see a single non-expectation value. Therefore, there is no limit to sample size mp as a function of expectation, which is simply 1.We can consider the higher moments of expectation."}, {"heading": "3 Submultiplicative Glivenko-Cantelli", "text": "In this section it is a fixed but otherwise arbitrary distribution, with CDF and empirical CDF Fn.Theorem 1.3 is a consequence of the following problem, which results in a quantitative restriction of the confidence parameter."}, {"heading": "4 Discussion", "text": "Our main result is a submultiplicative variant of the Glivenko-Cantelli theorem, which allows for narrower convergence limits for extreme CDF values. We show that for revenue learning, our submultiplicative limit can be used to derive uniform convergence profile complexity limits, assuming a finite limit for the most recent moment of assessments, for each (possibly fractional) k > 1. For a uniform convergence within the limit, we give a complete characterization in which uniform convergence almost certainly occurs when the first moment is finite. It would be interesting to find other applications of our submultiplicative limits in other contexts. A potentially interesting direction is to consider limitless loss functions (e.g. square loss or log loss). Many works circumvent infinity in such cases by ensuring (implicitly) that losses are limited, e.g. by limiting the hypotheses and hypotheses."}, {"heading": "A Proof of Theorem 1.4", "text": "(1) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3)) (3) (3) (3) (3)) (3) (3) (3) (3) (3)) (3) (3) (3) (3) (3) (3) (3) (3)) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3)) (3) (3) (3) (3) (3)) (3) (3) (3) (3)) (3) (3) (3) (3)) (3) (3) (3)) (3) (3) (3)) (3) (3) (3) (3)) (3) (3) (3) (3) (3) (3)) (3) (3) (3) (3)) (3) (3) (3) (3) (3) (3) (3) (3)) (3) (3) (3) (3)) (3) (3) (3) (3) (3) (3) (3)) (3) (3) (3) (3) (3)) (3) (3) (3) (3) (3) (3) (3) (3) (3)) (3) (3) (3)) (3) (3) (3)) (3) (3) (3) (3)) (3) (3) (3) (3)) (3) (3) (3)) (3) ("}, {"heading": "B Proof of Theorem 2.5", "text": "The proof: Let > 0. Did we e\u00b5 [F] < \u221e imply that it is v0-R + so that e\u00b5 [1-V-v0-v0-v0] -v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v0-v"}, {"heading": "C Proof of Corollary 3.2", "text": "We start with the first point. It is sufficient to prove that Pr [\u03b2] \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (t) \u2212 Fn (t). It is sufficient to prove that Pr [\u03b2] \u03b2 (\u03b2) \u03b2 (\u03b2) \u2264 \u00b7 F (t) \u2264 \u00b7 F (n) \u2264 (n). For this purpose, we use q, p so that each of the first two sums in term 3.1 is at most the same. Concretely, q = \u00b2 n \u2212 n (1 + \u03b1 2\u03b1) ln (n) ln (n) ln (n) ln (n) ln (1 + \u03b1 2\u03b1) 2 \u2212 n (1 \u2212 1). (The other requirement, n \u2264 n \u2212 n) ln (n) ln (n) ln (n) ln (n) ln (n) ln (n) ln (n) ln.).) If we insert these values for p, q), then the last sum (n) becomes we (\u2212 4n)."}], "references": [{"title": "Vitercik. Sample complexity of automated mechanism design", "author": ["M.-F. Balcan", "T. Sandholm"], "venue": "In Proceedings of the 30th Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Balcan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2016}, {"title": "Rademacher and gaussian complexities: Risk bounds and structural results", "author": ["P.L. Bartlett", "S. Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bartlett and Mendelson.,? \\Q2002\\E", "shortCiteRegEx": "Bartlett and Mendelson.", "year": 2002}, {"title": "Les probabilit\u00e9s d\u00e9nombrables et leurs applications arithm\u00e9tiques", "author": ["\u00c9. Borel"], "venue": "Rendiconti del Circolo Matematico di Palermo (1884-1940),", "citeRegEx": "Borel.,? \\Q1909\\E", "shortCiteRegEx": "Borel.", "year": 1909}, {"title": "Sulla probabilit\u00e1 come limite della frequenza", "author": ["F.P. Cantelli"], "venue": "Atti Accad. Naz. Lincei,", "citeRegEx": "Cantelli.,? \\Q1917\\E", "shortCiteRegEx": "Cantelli.", "year": 1917}, {"title": "Sulla determinazione empirica delle leggi di probabilita", "author": ["F.P. Cantelli"], "venue": "Giornalle dell\u2019Istituto Italiano degli Attuari,", "citeRegEx": "Cantelli.,? \\Q1933\\E", "shortCiteRegEx": "Cantelli.", "year": 1933}, {"title": "The sample complexity of revenue maximization", "author": ["R. Cole", "T. Roughgarden"], "venue": "In Proceedings of the 46th Annual ACM Symposium on Theory of Computing (STOC),", "citeRegEx": "Cole and Roughgarden.,? \\Q2014\\E", "shortCiteRegEx": "Cole and Roughgarden.", "year": 2014}, {"title": "Learning bounds for importance weighting", "author": ["C. Cortes", "Y. Mansour", "M. Mohri"], "venue": "In Proceedings of the 24th Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Cortes et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 2010}, {"title": "Relative deviation learning bounds and generalization with unbounded loss functions", "author": ["C. Cortes", "S. Greenberg", "M. Mohri"], "venue": "CoRR, abs/1310.5796,", "citeRegEx": "Cortes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 2013}, {"title": "The sample complexity of auctions with side information", "author": ["N.R. Devanur", "Z. Huang", "C.-A. Psomas"], "venue": "In Proceedings of the 48th Annual ACM Symposium on Theory of Computing (STOC),", "citeRegEx": "Devanur et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Devanur et al\\.", "year": 2016}, {"title": "Revenue maximization with a single sample", "author": ["P. Dhangwatnotai", "T. Roughgarden", "Q. Yan"], "venue": "Games and Economic Behavior,", "citeRegEx": "Dhangwatnotai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dhangwatnotai et al\\.", "year": 2015}, {"title": "Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator", "author": ["A. Dvoretzky", "J. Kiefer", "J. Wolfowitz"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Dvoretzky et al\\.,? \\Q1956\\E", "shortCiteRegEx": "Dvoretzky et al\\.", "year": 1956}, {"title": "Sulla determinazione empirica delle leggi di probabilita", "author": ["V. Glivenko"], "venue": "Giornalle dell\u2019Istituto Italiano degli Attuari,", "citeRegEx": "Glivenko.,? \\Q1933\\E", "shortCiteRegEx": "Glivenko.", "year": 1933}, {"title": "Efficient empirical revenue maximization in single-parameter auction environments", "author": ["Y.A. Gonczarowski", "N. Nisan"], "venue": "In Proceedings of the 49th Annual ACM Symposium on Theory of Computing (STOC),", "citeRegEx": "Gonczarowski and Nisan.,? \\Q2017\\E", "shortCiteRegEx": "Gonczarowski and Nisan.", "year": 2017}, {"title": "Making the most of your samples", "author": ["Z. Huang", "Y. Mansour", "T. Roughgarden"], "venue": "In Proceedings of the 16th ACM Conference on Economics and Computation (EC),", "citeRegEx": "Huang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "Rademacher Processes and Bounding the Risk of Function Learning, pages 443\u2013457", "author": ["V. Koltchinskii", "D. Panchenko"], "venue": null, "citeRegEx": "Koltchinskii and Panchenko.,? \\Q2000\\E", "shortCiteRegEx": "Koltchinskii and Panchenko.", "year": 2000}, {"title": "The tight constant in the dvoretzky-kiefer-wolfowitz inequality", "author": ["P. Massart"], "venue": "The Annals of Probability,", "citeRegEx": "Massart.,? \\Q1990\\E", "shortCiteRegEx": "Massart.", "year": 1990}, {"title": "On the pseudo-dimension of nearly optimal auctions", "author": ["J. Morgenstern", "T. Roughgarden"], "venue": "In Proceedings of the 29th Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Morgenstern and Roughgarden.,? \\Q2015\\E", "shortCiteRegEx": "Morgenstern and Roughgarden.", "year": 2015}, {"title": "Learning simple auctions", "author": ["J. Morgenstern", "T. Roughgarden"], "venue": "In Proceedings of the 29th Annual Conference on Learning Theory (COLT),", "citeRegEx": "Morgenstern and Roughgarden.,? \\Q2016\\E", "shortCiteRegEx": "Morgenstern and Roughgarden.", "year": 2016}, {"title": "Optimal auction design", "author": ["R. Myerson"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Myerson.,? \\Q1981\\E", "shortCiteRegEx": "Myerson.", "year": 1981}, {"title": "Ironing in the dark", "author": ["T. Roughgarden", "O. Schrijvers"], "venue": "In Proceedings of the 17th ACM Conference on Economics and Computation (EC),", "citeRegEx": "Roughgarden and Schrijvers.,? \\Q2016\\E", "shortCiteRegEx": "Roughgarden and Schrijvers.", "year": 2016}, {"title": "Weak convergence and empirical processes : with applications to statistics. Springer series in statistics", "author": ["A.W. v. d. Vaart", "J.A. Wellner"], "venue": null, "citeRegEx": "Vaart and Wellner.,? \\Q1996\\E", "shortCiteRegEx": "Vaart and Wellner.", "year": 1996}, {"title": "On the uniform convergence of relative frequencies of events to their probabilities", "author": ["V. Vapnik", "A. Chervonenkis"], "venue": "Theory Probab. Appl.,", "citeRegEx": "Vapnik and Chervonenkis.,? \\Q1971\\E", "shortCiteRegEx": "Vapnik and Chervonenkis.", "year": 1971}], "referenceMentions": [{"referenceID": 11, "context": "The seminal Glivenko-Cantelli Theorem (Glivenko, 1933; Cantelli, 1933) addresses this question when the distribution \u03bc is over the real numbers.", "startOffset": 38, "endOffset": 70}, {"referenceID": 4, "context": "The seminal Glivenko-Cantelli Theorem (Glivenko, 1933; Cantelli, 1933) addresses this question when the distribution \u03bc is over the real numbers.", "startOffset": 38, "endOffset": 70}, {"referenceID": 3, "context": "Some twenty years after Glivenko and Cantelli discovered this theorem, Dvoretzky, Kiefer, and Wolfowitz (DKW) strengthened this result by giving an almost1 tight quantitative bound on the convergence rate. In 1990, Massart proved a tight inequality, confirming a conjecture due to Birnbaum and McCarty (1958):", "startOffset": 37, "endOffset": 309}, {"referenceID": 15, "context": "2 (Massart, 1990).", "startOffset": 2, "endOffset": 17}, {"referenceID": 3, "context": "3 and other generalizations of the Glivenko-Cantelli Theorem: for example, the seminal work of Vapnik and Chervonenkis (1971) shows that for every class of events F of VC dimension d, there is n0 = n0( , \u03b4, d) such that for every n \u2265 n0, with probability 1\u2212 \u03b4 it holds that \u2200A \u2208 F : \u2223\u2223p(A)\u2212 pn(A)\u2223\u2223 \u2264 .", "startOffset": 44, "endOffset": 126}, {"referenceID": 3, "context": "3 and other generalizations of the Glivenko-Cantelli Theorem: for example, the seminal work of Vapnik and Chervonenkis (1971) shows that for every class of events F of VC dimension d, there is n0 = n0( , \u03b4, d) such that for every n \u2265 n0, with probability 1\u2212 \u03b4 it holds that \u2200A \u2208 F : \u2223\u2223p(A)\u2212 pn(A)\u2223\u2223 \u2264 . This yields Glivenko-Cantelli by plugging F = { (\u2212\u221e, t] : t \u2208 R } , which has VC dimension 1. In contrast, the submultiplicative bound from Theorem 1.3 does not even extend to the VC dimension 1 class F = { {t} : t \u2208 R } . Indeed, pick any distribution p over R such that p ( {t} ) = 0 for every t, and observe that for every sample x1, . . . , xn, it holds that pn ( {xi} ) \u2265 1/n, however p ( {xi} ) = 0, and therefore, as long as \u03b1 > 0, it is never the case that \u2223\u2223\u2223p({xi}) \u2212 pn({xi})\u2223\u2223\u2223 \u2264 p({xi})\u03b1. Theorem 1.3 is proven in Section 3, which also includes other extensions. Our second main result gives an explicit upper bound on n0( , \u03b4, \u03b1): The inequality due to Dvoretzky et al. (1956) has a larger constant C in front of the exponent on the right hand side.", "startOffset": 44, "endOffset": 994}, {"referenceID": 14, "context": "These include uniform convergence bounds for more general classes of functions as well as more general loss functions (for example, Vapnik and Chervonenkis, 1971; Vapnik, 1998; Koltchinskii and Panchenko, 2000; Bartlett and Mendelson, 2002).", "startOffset": 118, "endOffset": 240}, {"referenceID": 1, "context": "These include uniform convergence bounds for more general classes of functions as well as more general loss functions (for example, Vapnik and Chervonenkis, 1971; Vapnik, 1998; Koltchinskii and Panchenko, 2000; Bartlett and Mendelson, 2002).", "startOffset": 118, "endOffset": 240}, {"referenceID": 1, "context": "These include uniform convergence bounds for more general classes of functions as well as more general loss functions (for example, Vapnik and Chervonenkis, 1971; Vapnik, 1998; Koltchinskii and Panchenko, 2000; Bartlett and Mendelson, 2002). The results that concern unbounded loss functions are most relevant to this work (for example, Cortes et al., 2010, 2013; Vapnik, 1998). We next briefly discuss the relevant results from Cortes et al. (2013) in the context of this paper; more specifically, in the context of Theorem 1.", "startOffset": 211, "endOffset": 450}, {"referenceID": 6, "context": "whereas, Cortes et al. (2013) analyzes the event where it is bounded it by:", "startOffset": 9, "endOffset": 30}, {"referenceID": 6, "context": "Thus, the main difference is the additive 1/n term in the bound from Cortes et al. (2013). In the context of uniform convergence of revenues, it is crucial to use the upper bound on the empirical quantile as we do, as it guarantees that large prices will not overfit, which is the main challenge in proving uniform convergence in this context.", "startOffset": 69, "endOffset": 90}, {"referenceID": 6, "context": "Thus, the main difference is the additive 1/n term in the bound from Cortes et al. (2013). In the context of uniform convergence of revenues, it is crucial to use the upper bound on the empirical quantile as we do, as it guarantees that large prices will not overfit, which is the main challenge in proving uniform convergence in this context. In particular, the upper bound from Cortes et al. (2013) does not provide any guarantee on the revenues of prices p >> n, as for such prices p \u00b7 1/n >> 1.", "startOffset": 69, "endOffset": 401}, {"referenceID": 6, "context": "Thus, the main difference is the additive 1/n term in the bound from Cortes et al. (2013). In the context of uniform convergence of revenues, it is crucial to use the upper bound on the empirical quantile as we do, as it guarantees that large prices will not overfit, which is the main challenge in proving uniform convergence in this context. In particular, the upper bound from Cortes et al. (2013) does not provide any guarantee on the revenues of prices p >> n, as for such prices p \u00b7 1/n >> 1. It is also worth pointing out that our lower bound on the empirical quantile implies that with high probability the quantile of the maximum sampled point is at least 1/n2 (or more generally, at least 1/n1/\u03b1 when \u03b1 6= 1/2), while the bound from Cortes et al. (2013) does not imply any non-trivial lower bound.", "startOffset": 69, "endOffset": 764}, {"referenceID": 6, "context": "Thus, the main difference is the additive 1/n term in the bound from Cortes et al. (2013). In the context of uniform convergence of revenues, it is crucial to use the upper bound on the empirical quantile as we do, as it guarantees that large prices will not overfit, which is the main challenge in proving uniform convergence in this context. In particular, the upper bound from Cortes et al. (2013) does not provide any guarantee on the revenues of prices p >> n, as for such prices p \u00b7 1/n >> 1. It is also worth pointing out that our lower bound on the empirical quantile implies that with high probability the quantile of the maximum sampled point is at least 1/n2 (or more generally, at least 1/n1/\u03b1 when \u03b1 6= 1/2), while the bound from Cortes et al. (2013) does not imply any non-trivial lower bound. Another, more qualitative difference is that unlike the bounds in Cortes et al. (2013) that apply for general VC classes, our bound is tailored for the class of thresholds (corresponding to CDF/quantiles), and does not extend even to other classes of VC dimension 1 (see the discussion after Theorem 1.", "startOffset": 69, "endOffset": 895}, {"referenceID": 16, "context": "Most papers in this direction assume that the distribution meets some tail condition that is considered \u201cnatural\u201d within the algorithmic game theory community, such as boundedness (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016; Gonczarowski and Nisan, 2017; Devanur et al., 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al.", "startOffset": 180, "endOffset": 357}, {"referenceID": 19, "context": "Most papers in this direction assume that the distribution meets some tail condition that is considered \u201cnatural\u201d within the algorithmic game theory community, such as boundedness (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016; Gonczarowski and Nisan, 2017; Devanur et al., 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al.", "startOffset": 180, "endOffset": 357}, {"referenceID": 17, "context": "Most papers in this direction assume that the distribution meets some tail condition that is considered \u201cnatural\u201d within the algorithmic game theory community, such as boundedness (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016; Gonczarowski and Nisan, 2017; Devanur et al., 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al.", "startOffset": 180, "endOffset": 357}, {"referenceID": 0, "context": "Most papers in this direction assume that the distribution meets some tail condition that is considered \u201cnatural\u201d within the algorithmic game theory community, such as boundedness (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016; Gonczarowski and Nisan, 2017; Devanur et al., 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al.", "startOffset": 180, "endOffset": 357}, {"referenceID": 12, "context": "Most papers in this direction assume that the distribution meets some tail condition that is considered \u201cnatural\u201d within the algorithmic game theory community, such as boundedness (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016; Gonczarowski and Nisan, 2017; Devanur et al., 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al.", "startOffset": 180, "endOffset": 357}, {"referenceID": 8, "context": "Most papers in this direction assume that the distribution meets some tail condition that is considered \u201cnatural\u201d within the algorithmic game theory community, such as boundedness (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016; Gonczarowski and Nisan, 2017; Devanur et al., 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al.", "startOffset": 180, "endOffset": 357}, {"referenceID": 9, "context": ", 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016), or such as a condition known as monotone hazard rate (Huang et al.", "startOffset": 58, "endOffset": 156}, {"referenceID": 13, "context": ", 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016), or such as a condition known as monotone hazard rate (Huang et al.", "startOffset": 58, "endOffset": 156}, {"referenceID": 5, "context": ", 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016), or such as a condition known as monotone hazard rate (Huang et al.", "startOffset": 58, "endOffset": 156}, {"referenceID": 8, "context": ", 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016), or such as a condition known as monotone hazard rate (Huang et al.", "startOffset": 58, "endOffset": 156}, {"referenceID": 13, "context": ", 2016), or such as a condition known as monotone hazard rate (Huang et al., 2015).", "startOffset": 62, "endOffset": 82}, {"referenceID": 16, "context": "Indeed, while some papers that studied bounded distributions (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016) did use uniform convergence bounds as part of their analysis, other papers, in particular those that considered unbounded distributions, had to bypass the usage of uniform convergence by more specialized arguments.", "startOffset": 61, "endOffset": 186}, {"referenceID": 19, "context": "Indeed, while some papers that studied bounded distributions (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016) did use uniform convergence bounds as part of their analysis, other papers, in particular those that considered unbounded distributions, had to bypass the usage of uniform convergence by more specialized arguments.", "startOffset": 61, "endOffset": 186}, {"referenceID": 17, "context": "Indeed, while some papers that studied bounded distributions (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016) did use uniform convergence bounds as part of their analysis, other papers, in particular those that considered unbounded distributions, had to bypass the usage of uniform convergence by more specialized arguments.", "startOffset": 61, "endOffset": 186}, {"referenceID": 0, "context": "Indeed, while some papers that studied bounded distributions (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016) did use uniform convergence bounds as part of their analysis, other papers, in particular those that considered unbounded distributions, had to bypass the usage of uniform convergence by more specialized arguments.", "startOffset": 61, "endOffset": 186}, {"referenceID": 9, "context": "Thus, it turns out that the works that studied the popular class of Myerson-regular distributions (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016) indeed could not have hoped to establish learnability via a uniform convergence argument.", "startOffset": 98, "endOffset": 196}, {"referenceID": 13, "context": "Thus, it turns out that the works that studied the popular class of Myerson-regular distributions (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016) indeed could not have hoped to establish learnability via a uniform convergence argument.", "startOffset": 98, "endOffset": 196}, {"referenceID": 5, "context": "Thus, it turns out that the works that studied the popular class of Myerson-regular distributions (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016) indeed could not have hoped to establish learnability via a uniform convergence argument.", "startOffset": 98, "endOffset": 196}, {"referenceID": 8, "context": "Thus, it turns out that the works that studied the popular class of Myerson-regular distributions (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016) indeed could not have hoped to establish learnability via a uniform convergence argument.", "startOffset": 98, "endOffset": 196}, {"referenceID": 10, "context": "The seminal work of Myerson (1981) shows that given a valuation distribution for a single good, the revenue-maximizing selling mechanism for this good is a posted-price mechanism.", "startOffset": 20, "endOffset": 35}, {"referenceID": 0, "context": "Most papers in this direction assume that the distribution meets some tail condition that is considered \u201cnatural\u201d within the algorithmic game theory community, such as boundedness (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016; Gonczarowski and Nisan, 2017; Devanur et al., 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016), or such as a condition known as monotone hazard rate (Huang et al., 2015).4 These papers then go on to derive computation- or sample-complexity bounds on learning an optimal price (or an optimal selling mechanism from a given class) for a distribution that meets the assumed condition. A recurring theme in statistical learning theory is that learnability guarantees are derived via a, sometimes implicit, uniform convergence bound. However, this has not been the case in the context of revenue learning. Indeed, while some papers that studied bounded distributions (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016) did use uniform convergence bounds as part of their analysis, other papers, in particular those that considered unbounded distributions, had to bypass the usage of uniform convergence by more specialized arguments. This is due to the fact that many unbounded distributions do not satisfy any uniform convergence bound. As a concrete example, the (unbounded, Myerson-regular) equal revenue distribution5 has an infinite expectation and therefore, by our Theorem 2.3, satisfies no uniform convergence, even in the limit. Thus, it turns out that the works that studied the popular class of Myerson-regular distributions (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016) indeed could not have hoped to establish learnability via a uniform convergence argument. For instance, the way Dhangwatnotai et al. (2015) and Cole and Roughgarden (2014)", "startOffset": 285, "endOffset": 2056}, {"referenceID": 0, "context": "Most papers in this direction assume that the distribution meets some tail condition that is considered \u201cnatural\u201d within the algorithmic game theory community, such as boundedness (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016; Gonczarowski and Nisan, 2017; Devanur et al., 2016)3, such as a condition known as Myerson-regularity (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016), or such as a condition known as monotone hazard rate (Huang et al., 2015).4 These papers then go on to derive computation- or sample-complexity bounds on learning an optimal price (or an optimal selling mechanism from a given class) for a distribution that meets the assumed condition. A recurring theme in statistical learning theory is that learnability guarantees are derived via a, sometimes implicit, uniform convergence bound. However, this has not been the case in the context of revenue learning. Indeed, while some papers that studied bounded distributions (Morgenstern and Roughgarden, 2015; Roughgarden and Schrijvers, 2016; Morgenstern and Roughgarden, 2016; Balcan et al., 2016) did use uniform convergence bounds as part of their analysis, other papers, in particular those that considered unbounded distributions, had to bypass the usage of uniform convergence by more specialized arguments. This is due to the fact that many unbounded distributions do not satisfy any uniform convergence bound. As a concrete example, the (unbounded, Myerson-regular) equal revenue distribution5 has an infinite expectation and therefore, by our Theorem 2.3, satisfies no uniform convergence, even in the limit. Thus, it turns out that the works that studied the popular class of Myerson-regular distributions (Dhangwatnotai et al., 2015; Huang et al., 2015; Cole and Roughgarden, 2014; Devanur et al., 2016) indeed could not have hoped to establish learnability via a uniform convergence argument. For instance, the way Dhangwatnotai et al. (2015) and Cole and Roughgarden (2014)", "startOffset": 285, "endOffset": 2088}, {"referenceID": 0, "context": "The analysis of Balcan et al. (2016) assumes a bound on the realized revenue (from any possible valuation profile) of any mechanism/auction in the class that they consider.", "startOffset": 16, "endOffset": 37}, {"referenceID": 2, "context": "Thus, since these events are independent, the second Borel-Cantelli Lemma (Borel, 1909; Cantelli, 1917) implies that almost surely, infinitely many of them occur and so infinitely often", "startOffset": 74, "endOffset": 103}, {"referenceID": 3, "context": "Thus, since these events are independent, the second Borel-Cantelli Lemma (Borel, 1909; Cantelli, 1917) implies that almost surely, infinitely many of them occur and so infinitely often", "startOffset": 74, "endOffset": 103}, {"referenceID": 20, "context": "3 from Vaart and Wellner (1996)).", "startOffset": 7, "endOffset": 32}, {"referenceID": 5, "context": "While in many more-complex environments, the revenue-maximizing mechanism/auction is still not understood well enough, for environments where it is understood (Cole and Roughgarden, 2014; Devanur et al., 2016; Gonczarowski and Nisan, 2017) (as well as for simple auction classes that do not necessarily contain a revenue-maximizing auction (Morgenstern and Roughgarden, 2016; Balcan et al.", "startOffset": 159, "endOffset": 239}, {"referenceID": 8, "context": "While in many more-complex environments, the revenue-maximizing mechanism/auction is still not understood well enough, for environments where it is understood (Cole and Roughgarden, 2014; Devanur et al., 2016; Gonczarowski and Nisan, 2017) (as well as for simple auction classes that do not necessarily contain a revenue-maximizing auction (Morgenstern and Roughgarden, 2016; Balcan et al.", "startOffset": 159, "endOffset": 239}, {"referenceID": 12, "context": "While in many more-complex environments, the revenue-maximizing mechanism/auction is still not understood well enough, for environments where it is understood (Cole and Roughgarden, 2014; Devanur et al., 2016; Gonczarowski and Nisan, 2017) (as well as for simple auction classes that do not necessarily contain a revenue-maximizing auction (Morgenstern and Roughgarden, 2016; Balcan et al.", "startOffset": 159, "endOffset": 239}, {"referenceID": 17, "context": ", 2016; Gonczarowski and Nisan, 2017) (as well as for simple auction classes that do not necessarily contain a revenue-maximizing auction (Morgenstern and Roughgarden, 2016; Balcan et al., 2016)) it would also be interesting to study relaxations of the restrictive tail or boundedness assumptions currently common in the literature.", "startOffset": 138, "endOffset": 194}, {"referenceID": 0, "context": ", 2016; Gonczarowski and Nisan, 2017) (as well as for simple auction classes that do not necessarily contain a revenue-maximizing auction (Morgenstern and Roughgarden, 2016; Balcan et al., 2016)) it would also be interesting to study relaxations of the restrictive tail or boundedness assumptions currently common in the literature.", "startOffset": 138, "endOffset": 194}], "year": 2017, "abstractText": "In this work we derive a variant of the classic Glivenko-Cantelli Theorem, which asserts uniform convergence of the empirical Cumulative Distribution Function (CDF) to the CDF of the underlying distribution. Our variant allows for tighter convergence bounds for extreme values of the CDF. We apply our bound in the context of revenue learning, which is a well-studied problem in economics and algorithmic game theory. We derive sample-complexity bounds on the uniform convergence rate of the empirical revenues to the true revenues, assuming a bound on the kth moment of the valuations, for any (possibly fractional) k > 1. For uniform convergence in the limit, we give a complete characterization and a zeroone law: if the first moment of the valuations is finite, then uniform convergence almost surely occurs; conversely, if the first moment is infinite, then uniform convergence almost never occurs.", "creator": "LaTeX with hyperref package"}}}