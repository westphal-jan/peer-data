{"id": "1705.08690", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2017", "title": "Continual Learning with Deep Generative Replay", "abstract": "Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model (\"generator\") and a task solving model (\"solver\"). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.", "histories": [["v1", "Wed, 24 May 2017 10:37:38 GMT  (6160kb,D)", "http://arxiv.org/abs/1705.08690v1", "Submitted to NIPS 2017"], ["v2", "Sat, 9 Sep 2017 15:31:38 GMT  (6160kb,D)", "http://arxiv.org/abs/1705.08690v2", "To appear in NIPS 2017"]], "COMMENTS": "Submitted to NIPS 2017", "reviews": [], "SUBJECTS": "cs.AI cs.CV cs.LG", "authors": ["hanul shin", "jung kwon lee", "jaehong kim", "jiwon kim"], "accepted": true, "id": "1705.08690"}, "pdf": {"name": "1705.08690.pdf", "metadata": {"source": "CRF", "title": "Continual Learning with Deep Generative Replay", "authors": ["Hanul Shin", "Jung Kwon Lee", "Jaehong Kim", "Jiwon Kim"], "emails": ["skyshin@mit.edu", "xhark@sktbrain.com", "jklee@sktbrain.com", "jk@sktbrain.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people are able to understand themselves and what they are doing."}, {"heading": "2 Related Works", "text": "The concept of catastrophic forgetfulness or catastrophic intervention was first introduced in the 1980s by McCloskey and Cohen [21], who claimed that catastrophic forgetfulness is a fundamental limitation of neural networks and a flip side of their high generalization capability. Although the cause of catastrophic forgetfulness has not been analytically investigated, neural networks are known to parameterize the internal characteristics of input factors and the training of networks on new samples causes changes in already established representations. Several papers illustrate empirical consequences in sequential learning environments [7, 27] and provide some primitive solutions [16, 28] such as the reproduction of all previous data."}, {"heading": "2.1 Comparable methods", "text": "This work focuses on optimizing network parameters while minimizing changes in already consolidated weights. It is suggested that regulatory methods such as dropout [31] and L2 regularization help reduce interference in new learning [12]. Furthermore, the elastic weight consolidation (EBR) proposed in [18] shows that the protection of certain weights, based on their importance for previous tasks, mitigates performance losses. Other attempts to sequentially train a deep neural network capable of solving multiple tasks reduce catastrophic interference by adding task-specific parameters to the networks. Generally, layers near inputs are shared to capture universal properties, and independent output layers produce task-specific results. Although separate output layers are free of interference, changes to earlier layers still cause some performance losses in older tasks."}, {"heading": "2.2 Complementary Learning System(CLS) theory", "text": "A handful of papers are devoted to designing a complementary network architecture to withstand catastrophic forgetting. If the training data is not accessible for earlier tasks, only pseudo-inputs and pseudo-targets generated by a storage network can be fed into the task network. This method is called a pseudo-earsal technique and claims to maintain old input-output patterns without being able to access real data. [29] If the tasks are as elementary as the coupling of two binary patterns, it is enough simply to feed in random sounds and corresponding reactions [2]. A recent paper suggests an architecture similar to the structure of the hippocampus to facilitate continuous learning for more complex data such as small binary pixel images [15]. However, none of them show scalability to reproduce high-dimensional inputs similar to those that occur in the real world, due to the difficulty of generating highly pseudo-inputs from other pseudo-dimensional ones."}, {"heading": "2.3 Deep Generative Models", "text": "Generative model refers to any model from which observable samples are generated. Specifically, we look at deep generative models based on deep neural networks that increase the probability that generated samples are in a real distribution [11]. Some deep generative models such as variation coders [17] and the GANs [10] are able to imitate complex samples such as images. The GANs framework defines a zero-sum game between a generator G and a discriminator D. While the discriminator learns to distinguish between generated samples and real samples by comparing two data distributions, the generator learns to imitate the real distribution as accurately as possible. Theoretically, the objective of two networks is defined as: min G max D V (D, G) = Ex-pdata (x) [logD (x)] + Ez \u0445 pz (z) [log (1 \u2212 D (G (z)))))]. Theoretically, the zero balance of this zero-sum match is impossible to differentiate from the zero-sum game if the generator resummarizes the zero data perfectly."}, {"heading": "3 Generative Replay", "text": "First of all, we define several terminologies. In our continuous learning framework, we define the sequence of tasks to be solved as task sequence T = (T1, T2, \u00b7 \u00b7, TN) of N tasks. Definition 1 Ti is the optimization of a model in the direction of a target for data distribution Di, from which the training examples (xi, yi) are taken. Next, we refer to our model as a scholar, since it is able to learn a new task and pass on its knowledge to other networks. Note that the term scholar differs from the standard concept of the teacher-student framework of ensemble models [5], in which the networks either only teach or learn. Definition 2 A scholar H is a swab < G, S >, in which a generator G is a generative model that produces a real pattern, and a solver S is a problem solution model that is parameterized by processes. The solver must complete all the tasks in D, whereby the T is the sequence of the tasks."}, {"heading": "3.1 Proposed Method", "text": "We look at sequential training according to our Scholar model. However, the formation of a single Scholar model with reference to the most recent copy of the network is equivalent to the formation of a sequence of Scholar models (Hi) N \u2032 i = 1, where the n-th Scholar Hn (n > 1) is the current task Tn and the knowledge of previous Scholar Hn \u2212 1. Therefore, we describe our complete training procedure as shown in Figure 1 (a).The formation of the Scholar model from another Scholar includes two independent procedures for training the generator and the solver. Firstly, the new generator receives current task input x and repeated input x \u2032 from previous tasks. Real and repeated samples are mixed in a ratio depending on the desired importance of a new task compared to the older tasks. The generator learns to reconstruct cumulative input space, and the new solver is trained to match the inputs and targets of the same mixture of real and repeated data."}, {"heading": "3.2 Preliminary Experiment", "text": "Before our main experiments, we demonstrated that the trained scholar model alone is sufficient to train an empty network. We tested our model on the classification of the handwritten MNIST numeral database [19]. The sequence of scholar models was trained from the ground up by generative reproduction of previous scholars. Accuracy of classification of complete test data is shown in Table 1. We observed that the scholar model transmits knowledge without losing information."}, {"heading": "4 Experiments", "text": "In this section, we will demonstrate the applicability of the framework for regenerative playback to different sequential learning situations. Generative playback based on a trained learning network is superior to other continuous learning approaches in that the quality of the generative model is the only limitation of task performance. In other words, the training of networks based on regenerative playback is equivalent to joint training on whole data when the generative model is optimal. In order to achieve the best possible result, we used WGAN-GP [14] technology in the training of the generator. As a basic experiment, we will test whether generative playback enables sequential learning processes and thereby compromises performance neither in the old tasks nor in a new task. In Section 4.1, we will train the networks sequentially on independent tasks to examine the extent of sound. In Section 4.2, we will train the networks in two different but relevant domains. We will show that generative playback is not only compatible with continuous learning in our design of the learning network, but also with other known structures."}, {"heading": "4.1 Learning independent tasks", "text": "The most common experimental formulation used in the literature for continuous learning [32, 18] is a simple image classification problem where the inputs are images from the MNIST handwritten numerical database, but the pixel values of the inputs are mixed by a random permutation sequence unique to each task. The solver must classify the permutated inputs into the original classes. As most, if not all, pixels are switched between the tasks, the tasks are technically independent of each other, which is a good measure of the memory strength of a network.We observed that generative reproduction preserves past knowledge by retrieving earlier task data.In Figure 2 (a), the solver with generative reproduction (orange) maintained previous task performance throughout the sequential training on multiple tasks, as opposed to naively trained solvers (violet).An average accuracy that is measured by cumulative repetition alone in generative tasks (2) is close to full performance in generative training (2)."}, {"heading": "4.2 Learning new domains", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "4.3 Learning new classes", "text": "To illustrate that generative reproduction can recall past knowledge even when the inputs and targets between tasks are highly distorted, we propose a new experiment in which the network is trained sequentially on discriminatory data. In particular, we assume that the agent can access examples of only a few classes at a time. Finally, the agent must correctly classify examples from all classes after being sequentially trained on mutually exclusive subsets of classes. We tested the networks on MNIST handwritten numerical databases. Note that training artificial neural networks independently of classes in default settings is difficult because network responses may change to conform to the new target distribution. Therefore, the reproduction of inputs and outputs representing former input and target distributions is inevitable to form a balanced network. We therefore compare the variants described in this section from the perspective of whether reproducible and reproducible classes are reproducible."}, {"heading": "5 Discussion", "text": "We are introducing a deep replay system that allows us to solve multiple tasks at the same time by searching for new ways."}], "references": [{"title": "Memory retention\u2013the synaptic stability versus plasticity dilemma", "author": ["W.C. Abraham", "A. Robins"], "venue": "Trends in neurosciences,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Avoiding catastrophic forgetting by coupling two reverberating neural networks", "author": ["B. Ans", "S. Rousset"], "venue": "Comptes Rendus de l\u2019Acade\u0301mie des Sciences-Series III-Sciences de la Vie,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Infants\u2019 ability to draw inferences about nonobvious object properties: Evidence from exploratory play", "author": ["D.A. Baldwin", "E.M. Markman", "R.L. Melartin"], "venue": "Child development,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1993}, {"title": "The development of object categorization in young children: Hierarchical inclusiveness, age, perceptual attribute, and group versus individual analyses", "author": ["M.H. Bornstein", "M.E. Arterberry"], "venue": "Developmental psychology,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Ensemble methods in machine learning", "author": ["T.G. Dietterich"], "venue": "In International workshop on multiple classifier systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Evidence for large long-term memory capacities in baboons and pigeons and its implications for learning and the evolution of cognition", "author": ["J. Fagot", "R.G. Cook"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Catastrophic forgetting in connectionist networks", "author": ["R.M. French"], "venue": "Trends in cognitive sciences,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1999}, {"title": "Internally generated reactivation of single neurons in human hippocampus during free recall", "author": ["H. Gelbard-Sagiv", "R. Mukamel", "M. Harel", "R. Malach", "I. Fried"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "NIPS 2016 tutorial", "author": ["I.J. Goodfellow"], "venue": "Generative adversarial networks. CoRR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2017}, {"title": "An empirical investigation of catastrophic forgetting in gradient-based neural networks", "author": ["I.J. Goodfellow", "M. Mirza", "D. Xiao", "A. Courville", "Y. Bengio"], "venue": "arXiv preprint arXiv:1312.6211,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Long-term dendritic spine stability in the adult", "author": ["J. Grutzendler", "N. Kasthuri", "W.-B. Gan"], "venue": "cortex. Nature,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "Improved training of wasserstein gans", "author": ["I. Gulrajani", "F. Ahmed", "M. Arjovsky", "V. Dumoulin", "A. Courville"], "venue": "arXiv preprint arXiv:1704.00028,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "A biologically inspired dual-network memory model for reduction of catastrophic forgetting", "author": ["M. Hattori"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Using fast weights to deblur old memories", "author": ["G.E. Hinton", "D.C. Plaut"], "venue": "In Proceedings of the ninth annual conference of the Cognitive Science Society,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1987}, {"title": "Auto-encoding variational bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Overcoming catastrophic forgetting in neural networks", "author": ["J. Kirkpatrick", "R. Pascanu", "N. Rabinowitz", "J. Veness", "G. Desjardins", "A.A. Rusu", "K. Milan", "J. Quan", "T. Ramalho", "A. Grabska-Barwinska"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2017}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "Learning without forgetting", "author": ["Z. Li", "D. Hoiem"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Catastrophic interference in connectionist networks: The sequential learning problem", "author": ["M. McCloskey", "N.J. Cohen"], "venue": "Psychology of learning and motivation,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1989}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Y. Netzer", "T. Wang", "A. Coates", "A. Bissacco", "B. Wu", "A.Y. Ng"], "venue": "In NIPS workshop on deep learning and unsupervised feature learning,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Hippocampal and neocortical contributions to memory: Advances in the complementary learning systems framework", "author": ["R.C. O\u2019Reilly", "K.A. Norman"], "venue": "Trends in cognitive sciences,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}, {"title": "Play it again: reactivation of waking experience and memory", "author": ["J. O\u2019Neill", "B. Pleydell-Bouverie", "D. Dupret", "J. Csicsvari"], "venue": "Trends in neurosciences,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}, {"title": "Creating a false memory in the hippocampus", "author": ["S. Ramirez", "X. Liu", "P.-A. Lin", "J. Suh", "M. Pignatelli", "R.L. Redondo", "T.J. Ryan", "S. Tonegawa"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Connectionist models of recognition memory: Constraints imposed by learning and forgetting functions", "author": ["R. Ratcliff"], "venue": "Psychological review,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1990}, {"title": "Catastrophic forgetting in neural networks: the role of rehearsal mechanisms", "author": ["A. Robins"], "venue": "In Artificial Neural Networks and Expert Systems,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1993}, {"title": "Catastrophic forgetting, rehearsal and pseudorehearsal", "author": ["A. Robins"], "venue": "Connection Science,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1995}, {"title": "Deep boltzmann machines", "author": ["R. Salakhutdinov", "G. Hinton"], "venue": "In Artificial Intelligence and Statistics,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2009}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G.E. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1929}, {"title": "Compete to compute", "author": ["R.K. Srivastava", "J. Masci", "S. Kazerounian", "F. Gomez", "J. Schmidhuber"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "One distinctive ability of humans and large primates is to continually learn new skills and accumulate knowledge throughout the lifetime [6].", "startOffset": 137, "endOffset": 140}, {"referenceID": 12, "context": "Even in small vertebrates such as rodents, established connections between neurons seem to last more than an year [13].", "startOffset": 114, "endOffset": 118}, {"referenceID": 0, "context": "The flexible memory system results from a good balance between synaptic plasticity and stability [1].", "startOffset": 97, "endOffset": 100}, {"referenceID": 20, "context": "Continual learning in deep neural networks, however, suffers from a phenomenon called catastrophic forgetting [21], in which the performance of a model on previously learned tasks abruptly degrades when trained for a new task.", "startOffset": 110, "endOffset": 114}, {"referenceID": 28, "context": "Previous attempts to alleviate catastrophic forgetting often relied on episodic memory system that stores past data [29].", "startOffset": 116, "endOffset": 120}, {"referenceID": 26, "context": "While a network trained in this manner performs as well as separate networks trained solely on each task [27], a major drawback of memory-based approach is that it requires large working memory to store and replay past inputs.", "startOffset": 105, "endOffset": 109}, {"referenceID": 23, "context": "While several biological mechanisms contribute to this at different levels, primate brain\u2019s the most apparent distinction from artificial neural networks is the existence of separate, interacting memory systems [24].", "startOffset": 211, "endOffset": 215}, {"referenceID": 24, "context": "experiences stored in the hippocampus [25]\u2013a mechanism which inspired the use of experience replay [22] in training deep reinforcement learning agents.", "startOffset": 38, "endOffset": 42}, {"referenceID": 21, "context": "experiences stored in the hippocampus [25]\u2013a mechanism which inspired the use of experience replay [22] in training deep reinforcement learning agents.", "startOffset": 99, "endOffset": 103}, {"referenceID": 7, "context": "Rather, it regenerates earlier inputs by synchronized reactivations that are induced during unconscious or conscious recall or specific phase of sleep [8].", "startOffset": 151, "endOffset": 154}, {"referenceID": 25, "context": "Stimulation of certain memory traces in the hippocampus can even create false memory that was never experienced [26].", "startOffset": 112, "endOffset": 116}, {"referenceID": 29, "context": "Specifically, deep generative models such as deep Boltzmann machines [30] or a variational autoencoder [17] can generate high-dimensional samples that closely match observed inputs.", "startOffset": 69, "endOffset": 73}, {"referenceID": 16, "context": "Specifically, deep generative models such as deep Boltzmann machines [30] or a variational autoencoder [17] can generate high-dimensional samples that closely match observed inputs.", "startOffset": 103, "endOffset": 107}, {"referenceID": 9, "context": "In particular, we train a deep generative model in the generative adversarial networks (GANs) framework [10] to mimic past data.", "startOffset": 104, "endOffset": 108}, {"referenceID": 20, "context": "The term catastrophic forgetting or catastrophic interference was first introduced by McCloskey and Cohen in 1980\u2019s [21].", "startOffset": 116, "endOffset": 120}, {"referenceID": 6, "context": "Several works illustrate empirical consequences in sequential learning settings [7, 27], and provide a few primitive solutions [16, 28] such as replaying all previous data.", "startOffset": 80, "endOffset": 87}, {"referenceID": 26, "context": "Several works illustrate empirical consequences in sequential learning settings [7, 27], and provide a few primitive solutions [16, 28] such as replaying all previous data.", "startOffset": 80, "endOffset": 87}, {"referenceID": 15, "context": "Several works illustrate empirical consequences in sequential learning settings [7, 27], and provide a few primitive solutions [16, 28] such as replaying all previous data.", "startOffset": 127, "endOffset": 135}, {"referenceID": 27, "context": "Several works illustrate empirical consequences in sequential learning settings [7, 27], and provide a few primitive solutions [16, 28] such as replaying all previous data.", "startOffset": 127, "endOffset": 135}, {"referenceID": 30, "context": "It is suggested that regularization methods such as dropout [31] and L2 regularization help reduce interference of new learning [12].", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "It is suggested that regularization methods such as dropout [31] and L2 regularization help reduce interference of new learning [12].", "startOffset": 128, "endOffset": 132}, {"referenceID": 17, "context": "Furthermore, elastic weight consolidation (EWC) proposed in [18] demonstrates that protecting certain weights based on their importance to the previous tasks tempers the performance loss.", "startOffset": 60, "endOffset": 64}, {"referenceID": 8, "context": "Lowering learning rates on some parameters is also known to reduce forgetting [9].", "startOffset": 78, "endOffset": 81}, {"referenceID": 19, "context": "A recently proposed method called Learning without Forgetting (LwF) [20] addresses the problem of sequential learning in image classification tasks while minimizing alteration on shared network parameters.", "startOffset": 68, "endOffset": 72}, {"referenceID": 28, "context": "Called a pseudorehearsal technique, this method is claimed to maintain old input-output patterns without accessing real data [29].", "startOffset": 125, "endOffset": 129}, {"referenceID": 1, "context": "When the tasks are as elementary as coupling two binary patterns, simply feeding random noises and corresponding responses suffices [2].", "startOffset": 132, "endOffset": 135}, {"referenceID": 14, "context": "A more recent work proposes an architecture that resembles the structure of the hippocampus to facilitate continual learning for more complex data such as small binary pixel images [15].", "startOffset": 181, "endOffset": 185}, {"referenceID": 10, "context": "Specifically, we consider deep generative models based on deep neural networks that maximize the likelihood of generated samples being in given real distribution [11].", "startOffset": 162, "endOffset": 166}, {"referenceID": 16, "context": "Some deep generative models such as variational autoencoders [17] and the GANs [10] are able to mimic complex samples like images.", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "Some deep generative models such as variational autoencoders [17] and the GANs [10] are able to mimic complex samples like images.", "startOffset": 79, "endOffset": 83}, {"referenceID": 4, "context": "Note that the term scholar differs from standard notion of teacher-student framework of ensemble models [5], in which the networks either teach or learn only.", "startOffset": 104, "endOffset": 107}, {"referenceID": 18, "context": "We tested our model on classifying MNIST handwritten digit database [19].", "startOffset": 68, "endOffset": 72}, {"referenceID": 13, "context": "To draw the best possible result, we used WGAN-GP [14] technique in training the generator.", "startOffset": 50, "endOffset": 54}, {"referenceID": 31, "context": "The most common experimental formulation used in continual learning literature [32, 18] is a simple image classification problem where the inputs are images from MNIST handwritten digit database [19], but pixel values of inputs are shuffled by a random permutation sequence unique to each task.", "startOffset": 79, "endOffset": 87}, {"referenceID": 17, "context": "The most common experimental formulation used in continual learning literature [32, 18] is a simple image classification problem where the inputs are images from MNIST handwritten digit database [19], but pixel values of inputs are shuffled by a random permutation sequence unique to each task.", "startOffset": 79, "endOffset": 87}, {"referenceID": 18, "context": "The most common experimental formulation used in continual learning literature [32, 18] is a simple image classification problem where the inputs are images from MNIST handwritten digit database [19], but pixel values of inputs are shuffled by a random permutation sequence unique to each task.", "startOffset": 195, "endOffset": 199}, {"referenceID": 2, "context": "Such phenomenon is also observed in infants learning to categorize objects [3, 4].", "startOffset": 75, "endOffset": 81}, {"referenceID": 3, "context": "Such phenomenon is also observed in infants learning to categorize objects [3, 4].", "startOffset": 75, "endOffset": 81}, {"referenceID": 22, "context": "In particular, we sequentially trained our model on classifying MNIST and Street View House Number (SVHN) dataset [23], and vice versa.", "startOffset": 114, "endOffset": 118}], "year": 2017, "abstractText": "Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model (\u201cgenerator\u201d) and a task solving model (\u201csolver\u201d). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.", "creator": "LaTeX with hyperref package"}}}