{"id": "1705.09655", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2017", "title": "Style Transfer from Non-Parallel Text by Cross-Alignment", "abstract": "This paper focuses on style transfer on the basis of non-parallel text. This is an instance of a broader family of problems including machine translation, decipherment, and sentiment modification. The key technical challenge is to separate the content from desired text characteristics such as sentiment. We leverage refined alignment of latent representations across mono-lingual text corpora with different characteristics. We deliberately modify encoded examples according to their characteristics, requiring the reproduced instances to match available examples with the altered characteristics as a population. We demonstrate the effectiveness of this cross-alignment method on three tasks: sentiment modification, decipherment of word substitution ciphers, and recovery of word order.", "histories": [["v1", "Fri, 26 May 2017 17:40:12 GMT  (120kb,D)", "http://arxiv.org/abs/1705.09655v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["tianxiao shen", "tao lei", "regina barzilay", "tommi jaakkola"], "accepted": true, "id": "1705.09655"}, "pdf": {"name": "1705.09655.pdf", "metadata": {"source": "CRF", "title": "Style Transfer from Non-Parallel Text by Cross-Alignment", "authors": ["Tianxiao Shen", "Tao Lei"], "emails": ["tianxiao@mit.edu", "tao@asapp.com", "regina@csail.mit.edu", "tommi@csail.mit.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, we can only assume access to non-parallel or monolingual data. Problems such as deciphering or style transfer are all instances of this type of task. This separation usually occurs in the latent vector representation. By accessing non-parallel data, we must ensure that the uprooted representation has truly independent degrees of freedom with consequent effects on the sentences received. This separation usually occurs in the latent vector representation."}, {"heading": "2 Related work", "text": "In fact, it is such that the greater part of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to fight, to move, to move, to fight, to fight, to move, to move, to move, to fight, to move, to fight, to move, to move, to fight, to move, to move, to move, to move, to move, to fight, to fight, to fight, to move, to fight, to move, to move, to move, to move, to fight, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "3 Formulation", "text": "In this section, we formalize the task of non-parallel style transfer and discuss the feasibility of the learning problem. We assume that the data is generated by the following process: 1. a latent style variable y is generated from a distribution p (y); 2. a latent content variable z is generated from a distribution p (z); 3. a datapoint x is generated from a conditional distribution p (x | y, z). We observe two datasets with the same content distribution but different styles y1 and y2, where y1 and y2 are unknown. Specifically, the two observed datasetsX 1 = {x (1) 1, \u00b7 \u00b7 \u00b7, x (n) 1} andX = {x (1). \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7, x (m) 2} consist of samples drawn from p (x1) and p (x2)."}, {"heading": "3.1 Example 1: Gaussian", "text": "Suppose a style y = (A, b) is an affine transformation, i.e. x = Az + b +, where is a noise variable. For b = 0 and any orthogonal matrixA, Az + b \u0445 N (0, I) and therefore x has the same distribution for all these styles y = (A, 0). In this case, the effect of rotation cannot be restored. Interestingly, affine transformations, if z has a more complex distribution, such as a Gaussian mixture, can be clearly determined. Lemma 1. Let z have a mixture of Gaussians p (z) = Kk = 1 \u03c0kN (z; \u00b5k, \u0451k). Suppose K \u2265 2, and there are two different formations of e.g. Suppose Y = (A, b) | A = 6} are all components of Gaussians p (z) and vice versa."}, {"heading": "3.2 Example 2: Word substitution", "text": "Consider here another example, where z is a bi-gram language model and a style y is a common vocabulary that maps each \"content word\" to its surface form (text form). If we observe two findings x1 and x2 of the same language z, the translation and recovery problem turns into a word alignment between x1 and x2. Note that this is a simplified version of the language decoding or translation, but the recovery problem is still sufficiently difficult. To detect this, let letM 1, M 2 and Rn use the estimated bi-gram probability matrix of the data X 1 and X 2, respectively. Searching for the word alignment is equivalent to searching for a permutation matrix such as P > M 1P \u2248 M 2, which can be expressed as an optimization problem, with P > M 1P-M \u00b2 -M 2 being the estimated probability matrix of the data X or X 2."}, {"heading": "4 Method", "text": "However, unlike vision, where images are continuous and therefore the transmission functions can be learned and optimized directly, the discretion of language requires us to operate through latent space. Since x1 and x2 are conditionally independent from the latent content variables z, p (x1 | x2; y2) = content of transmission z (x1, z | x2; y1, y2), which are conditionally independent from the latent content variables z, z) dz = Ez p (z | x2, y2) = content z p (x1, z | x2; y1, y2; y1), y2, y2; this indicates that we are learning an auto-encoder model."}, {"heading": "4.1 Aligned auto-encoder", "text": "The first variant forces both z1 = E (x1, y1) and z2 = E (x2, y2) to have the same distribution (where x1 \u0445 X 1 and x2 \u0445 X 2). To see this, consider the stochastic version of this encryption process, in which x \u00b2 p (x | y) and z \u00b2 p (z | x, y) are independent of each other. Note: y and z \u00b2 p (z | y1) = p (z | y2) = p (z). Following this motivation, we revise the reconstruction target (3) p (z | x, y) dx = p (z | y).Note: Since y and z are independent, p (z | y1) = p (z | y1) = p (z).On the basis of this motivation, we revise the reconstruction target (3) as a limited optimization problem: \u03b8 = arg min."}, {"heading": "4.2 Cross-aligned auto-encoder", "text": "The second variant, which is based on REINFORCE (1992), can achieve stable results with these methods; the second variant, which is based on REINFORCE, can be based on two different methods; the second variant, which is based on REINFORCE, can be applied to the two transferred techniques; the second variant, which is based on REINFORCE, can be applied with these methods; the second variant, which is based on REINFORCE, can be placed on a stable basis; and the second variant, which is based on REINFORCE, can be based on two different methods."}, {"heading": "5 Experimental Setup", "text": "This year, it will be able to fix and fix the mentioned bugs."}, {"heading": "6 Results", "text": "Sentiment modification table 1 shows the performance of various models on this task as measured by a supervised classifier. The cross-aligned auto-encoder achieves an accuracy of 78%, outperforming other models many times over. However, the low performance of the variational auto-encoder (23%) clearly shows that it is not suitable for this transfer task. Our manual analysis of the data shows that such errors often fall into two classes: content modification and grammaticality. The fourth pair in Table 2 is an instance of the first class - while making the sentence positive, it changes the subject from Mexican to Italian food."}, {"heading": "7 Conclusion", "text": "In this paper, we formulate the task as a deciphering problem with only access to unpaired data. It is assumed that the two sets of data are generated by a latently variable generative model. By using this view, our method optimizes neural networks by forcing an invariance across latent space or sentence populations. We demonstrate the effectiveness of our method on tasks that allow quantitative evaluation, such as emotion transfer, word substitution decoding, and word reordering. The deciphering view also offers an interesting open question - when can the common distribution p (x1, x2) be restored with only marginal distributions? We believe that answering this general question would improve style transfer research both in the field of vision and in the field of NLP."}, {"heading": "A Proof of lemma 1", "text": "Lemma 1. Let z be a mixture of Gaussian p (z) = \u2211 K (K) = 1 \u03c0kN (z; \u00b5k, \u0441k). Let's say K \u2265 2, and there are two different successi 6 = \u0441j. Let Y = {(A, b) | A | 6 = 0} be all invertable affine transformations, and p (x | y, z) = N (x; Az + b, 2I) in which there is noise. Then, for all y 6 = y \u2032 Y, p (x | y) and p (x | y \u2032) are different distributions. Explain p (x | y = (A, b)) = K \u2211 k = 1 \u03c0kN (x; A\u00b5k + b, A\u041akA > + 2I) For different y = (A, b) and y \u2032 s = (A \u2032, b \u2032), p (x \u2212 kkkkkkkk.k = 1 \u00b7 kA > K > K > K > K (K) is just the solution."}], "references": [{"title": "Maximum-likelihood augmented discrete generative adversarial networks", "author": ["Tong Che", "Yanran Li", "Ruixiang Zhang", "R Devon Hjelm", "Wenjie Li", "Yangqiu Song", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1702.07983,", "citeRegEx": "Che et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Che et al\\.", "year": 2017}, {"title": "Infogan: Interpretable representation learning by information maximizing generative adversarial nets", "author": ["Xi Chen", "Yan Duan", "Rein Houthooft", "John Schulman", "Ilya Sutskever", "Pieter Abbeel"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Large scale decipherment for out-of-domain machine translation", "author": ["Qing Dou", "Kevin Knight"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Dou and Knight.,? \\Q2012\\E", "shortCiteRegEx": "Dou and Knight.", "year": 2012}, {"title": "Image style transfer using convolutional neural networks", "author": ["Leon A Gatys", "Alexander S Ecker", "Matthias Bethge"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Gatys et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gatys et al\\.", "year": 2016}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Boundaryseeking generative adversarial networks", "author": ["R Devon Hjelm", "Athul Paul Jacob", "Tong Che", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1702.08431,", "citeRegEx": "Hjelm et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Hjelm et al\\.", "year": 2017}, {"title": "Controllable text generation", "author": ["Zhiting Hu", "Zichao Yang", "Xiaodan Liang", "Ruslan Salakhutdinov", "Eric P Xing"], "venue": "arXiv preprint arXiv:1703.00955,", "citeRegEx": "Hu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2017}, {"title": "Image-to-image translation with conditional adversarial networks", "author": ["Phillip Isola", "Jun-Yan Zhu", "Tinghui Zhou", "Alexei A Efros"], "venue": "arXiv preprint arXiv:1611.07004,", "citeRegEx": "Isola et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Isola et al\\.", "year": 2016}, {"title": "Learning to discover cross-domain relations with generative adversarial networks", "author": ["Taeksoo Kim", "Moonsu Cha", "Hyunsoo Kim", "Jungkwon Lee", "Jiwon Kim"], "venue": "arXiv preprint arXiv:1703.05192,", "citeRegEx": "Kim et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2017}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma and Welling.,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2013}, {"title": "Opennmt: Open-source toolkit for neural machine translation", "author": ["Guillaume Klein", "Yoon Kim", "Yuntian Deng", "Jean Senellart", "Alexander M Rush"], "venue": "arXiv preprint arXiv:1701.02810,", "citeRegEx": "Klein et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2017}, {"title": "Professor forcing: A new algorithm for training recurrent networks", "author": ["Alex M Lamb", "Anirudh Goyal ALIAS PARTH GOYAL", "Ying Zhang", "Saizheng Zhang", "Aaron C Courville", "Yoshua Bengio"], "venue": "In Advances In Neural Information Processing Systems,", "citeRegEx": "Lamb et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lamb et al\\.", "year": 2016}, {"title": "Coupled generative adversarial networks", "author": ["Ming-Yu Liu", "Oncel Tuzel"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Liu and Tuzel.,? \\Q2016\\E", "shortCiteRegEx": "Liu and Tuzel.", "year": 2016}, {"title": "Unsupervised image-to-image translation networks", "author": ["Ming-Yu Liu", "Thomas Breuel", "Jan Kautz"], "venue": "arXiv preprint arXiv:1703.00848,", "citeRegEx": "Liu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2017}, {"title": "Sequence to better sequence: continuous revision of combinatorial structures", "author": ["Jonas Mueller", "Tommi Jaakkola", "David Gifford"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "Mueller et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Mueller et al\\.", "year": 2017}, {"title": "Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 311\u2013318", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Unsupervised cross-domain image generation", "author": ["Yaniv Taigman", "Adam Polyak", "Lior Wolf"], "venue": "arXiv preprint arXiv:1611.02200,", "citeRegEx": "Taigman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Taigman et al\\.", "year": 2016}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["Ronald J Williams"], "venue": "Machine learning,", "citeRegEx": "Williams.,? \\Q1992\\E", "shortCiteRegEx": "Williams.", "year": 1992}, {"title": "Dualgan: Unsupervised dual learning for image-to-image translation", "author": ["Zili Yi", "Hao Zhang", "Ping Tan Gong"], "venue": "arXiv preprint arXiv:1704.02510,", "citeRegEx": "Yi et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Yi et al\\.", "year": 2017}, {"title": "Seqgan: sequence generative adversarial nets with policy gradient", "author": ["Lantao Yu", "Weinan Zhang", "Jun Wang", "Yong Yu"], "venue": "arXiv preprint arXiv:1609.05473,", "citeRegEx": "Yu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2016}, {"title": "Unpaired image-to-image translation using cycle-consistent adversarial networks", "author": ["Jun-Yan Zhu", "Taesung Park", "Phillip Isola", "Alexei A Efros"], "venue": "arXiv preprint arXiv:1703.10593,", "citeRegEx": "Zhu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2017}], "referenceMentions": [{"referenceID": 6, "context": "A recent approach to this problem builds on variational auto-encoders (VAEs), dividing the latent representation into two or more parts, and enforcing additionally that the latent characteristics used to generate text can be reliably inferred from the text alone (Hu et al., 2017).", "startOffset": 263, "endOffset": 280}, {"referenceID": 3, "context": "Style transfer in vision Non-parallel style transfer has been extensively studied in computer vision (Gatys et al., 2016; Zhu et al., 2017; Liu and Tuzel, 2016; Liu et al., 2017; Taigman et al., 2016; Kim et al., 2017; Yi et al., 2017).", "startOffset": 101, "endOffset": 235}, {"referenceID": 20, "context": "Style transfer in vision Non-parallel style transfer has been extensively studied in computer vision (Gatys et al., 2016; Zhu et al., 2017; Liu and Tuzel, 2016; Liu et al., 2017; Taigman et al., 2016; Kim et al., 2017; Yi et al., 2017).", "startOffset": 101, "endOffset": 235}, {"referenceID": 12, "context": "Style transfer in vision Non-parallel style transfer has been extensively studied in computer vision (Gatys et al., 2016; Zhu et al., 2017; Liu and Tuzel, 2016; Liu et al., 2017; Taigman et al., 2016; Kim et al., 2017; Yi et al., 2017).", "startOffset": 101, "endOffset": 235}, {"referenceID": 13, "context": "Style transfer in vision Non-parallel style transfer has been extensively studied in computer vision (Gatys et al., 2016; Zhu et al., 2017; Liu and Tuzel, 2016; Liu et al., 2017; Taigman et al., 2016; Kim et al., 2017; Yi et al., 2017).", "startOffset": 101, "endOffset": 235}, {"referenceID": 16, "context": "Style transfer in vision Non-parallel style transfer has been extensively studied in computer vision (Gatys et al., 2016; Zhu et al., 2017; Liu and Tuzel, 2016; Liu et al., 2017; Taigman et al., 2016; Kim et al., 2017; Yi et al., 2017).", "startOffset": 101, "endOffset": 235}, {"referenceID": 8, "context": "Style transfer in vision Non-parallel style transfer has been extensively studied in computer vision (Gatys et al., 2016; Zhu et al., 2017; Liu and Tuzel, 2016; Liu et al., 2017; Taigman et al., 2016; Kim et al., 2017; Yi et al., 2017).", "startOffset": 101, "endOffset": 235}, {"referenceID": 18, "context": "Style transfer in vision Non-parallel style transfer has been extensively studied in computer vision (Gatys et al., 2016; Zhu et al., 2017; Liu and Tuzel, 2016; Liu et al., 2017; Taigman et al., 2016; Kim et al., 2017; Yi et al., 2017).", "startOffset": 101, "endOffset": 235}, {"referenceID": 4, "context": "More recent approaches learn generative networks directly via generative adversarial training (Goodfellow et al., 2014) from two given data domains X 1 and X 2.", "startOffset": 94, "endOffset": 119}, {"referenceID": 12, "context": "For example, CoupledGANs (Liu and Tuzel, 2016) employ weight-sharing between networks to learn cross-domain representation, whereas CycleGAN (Zhu et al.", "startOffset": 25, "endOffset": 46}, {"referenceID": 20, "context": "For example, CoupledGANs (Liu and Tuzel, 2016) employ weight-sharing between networks to learn cross-domain representation, whereas CycleGAN (Zhu et al., 2017) introduces cycle consistency which relies on transitivity to regularize the transfer functions.", "startOffset": 141, "endOffset": 159}, {"referenceID": 3, "context": "Style transfer in vision Non-parallel style transfer has been extensively studied in computer vision (Gatys et al., 2016; Zhu et al., 2017; Liu and Tuzel, 2016; Liu et al., 2017; Taigman et al., 2016; Kim et al., 2017; Yi et al., 2017). Gatys et al. (2016) explicitly extract content and style features, and then synthesize a new image by combining \u201ccontent\u201d features of one image with \u201cstyle\u201d features from another.", "startOffset": 102, "endOffset": 257}, {"referenceID": 14, "context": "Our work most closely relates to approaches that do not utilize parallel data, but instead guide sentence generation from an indirect training signal (Mueller et al., 2017; Hu et al., 2017).", "startOffset": 150, "endOffset": 189}, {"referenceID": 6, "context": "Our work most closely relates to approaches that do not utilize parallel data, but instead guide sentence generation from an indirect training signal (Mueller et al., 2017; Hu et al., 2017).", "startOffset": 150, "endOffset": 189}, {"referenceID": 1, "context": "Using ideas from computer vision (Chen et al., 2016), this factorization is learned in an unsupervised manner.", "startOffset": 33, "endOffset": 52}, {"referenceID": 4, "context": "In contrast, our method utilizes adversarial training (Goodfellow et al., 2014) to guarantee distributional alignment of the common latent space driven by content/style independence.", "startOffset": 54, "endOffset": 79}, {"referenceID": 4, "context": ", 2017; Hu et al., 2017). For instance, Mueller et al. (2017) manipulate the hidden representation to generate sentences that satisfy a desired property (e.", "startOffset": 8, "endOffset": 62}, {"referenceID": 4, "context": ", 2017; Hu et al., 2017). For instance, Mueller et al. (2017) manipulate the hidden representation to generate sentences that satisfy a desired property (e.g., sentiment) as measured by a corresponding classifier. However, their model does not necessarily enforce content preservation. More similar to our work, Hu et al. (2017) facilitate content preservation by explicitly modeling the style and content factorization.", "startOffset": 8, "endOffset": 329}, {"referenceID": 1, "context": "Using ideas from computer vision (Chen et al., 2016), this factorization is learned in an unsupervised manner. The factorization algorithm of Hu et al. (2017) is primarily driven by the predictions of the property classifier.", "startOffset": 34, "endOffset": 159}, {"referenceID": 19, "context": "Adversarial training over discrete samples Recently, a wide range of techniques addresses challenges associated with adversarial training over discrete samples generated by recurrent networks (Yu et al., 2016; Lamb et al., 2016; Che et al., 2017; Hjelm et al., 2017).", "startOffset": 192, "endOffset": 266}, {"referenceID": 11, "context": "Adversarial training over discrete samples Recently, a wide range of techniques addresses challenges associated with adversarial training over discrete samples generated by recurrent networks (Yu et al., 2016; Lamb et al., 2016; Che et al., 2017; Hjelm et al., 2017).", "startOffset": 192, "endOffset": 266}, {"referenceID": 0, "context": "Adversarial training over discrete samples Recently, a wide range of techniques addresses challenges associated with adversarial training over discrete samples generated by recurrent networks (Yu et al., 2016; Lamb et al., 2016; Che et al., 2017; Hjelm et al., 2017).", "startOffset": 192, "endOffset": 266}, {"referenceID": 5, "context": "Adversarial training over discrete samples Recently, a wide range of techniques addresses challenges associated with adversarial training over discrete samples generated by recurrent networks (Yu et al., 2016; Lamb et al., 2016; Che et al., 2017; Hjelm et al., 2017).", "startOffset": 192, "endOffset": 266}, {"referenceID": 11, "context": "In our work, we employ the Professor-Forcing algorithm (Lamb et al., 2016) which was originally proposed to close the gap between teacher-forcing during training and self-feeding during testing for recurrent networks.", "startOffset": 55, "endOffset": 74}, {"referenceID": 9, "context": "One option is to apply a variational auto-encoder (Kingma and Welling, 2013) and maximize the variational lower bound of data likelihood.", "startOffset": 50, "endOffset": 76}, {"referenceID": 17, "context": "Although sampling-based gradient computation such as REINFORCE (Williams, 1992) can by adopted, training with these methods can be unstable due to the high variance of the sampled gradient.", "startOffset": 63, "endOffset": 79}, {"referenceID": 6, "context": "Instead, we employ two recent techniques to approximate the discrete training (Hu et al., 2017; Lamb et al., 2016).", "startOffset": 78, "endOffset": 114}, {"referenceID": 11, "context": "Instead, we employ two recent techniques to approximate the discrete training (Hu et al., 2017; Lamb et al., 2016).", "startOffset": 78, "endOffset": 114}, {"referenceID": 11, "context": "Secondly, we use Professor-Forcing (Lamb et al., 2016) to match the sequence of hidden states instead of the output words, which contains the information about outputs and is smoothly distributed.", "startOffset": 35, "endOffset": 54}, {"referenceID": 7, "context": "To quantitatively evaluate the transfered sentences, we adopt a model-based evaluation metric similar to the one used for image transfer (Isola et al., 2016).", "startOffset": 137, "endOffset": 157}, {"referenceID": 2, "context": "Word substitution decipherment Our second set of experiments involves decoding of word substitution ciphers, which has been previously explored in NLP literature (Dou and Knight, 2012; Nuhn and Ney, 2013).", "startOffset": 162, "endOffset": 204}, {"referenceID": 15, "context": "We can quantitatively compare betweenD1 and transferred (deciphered)D2 using Bleu score (Papineni et al., 2002).", "startOffset": 88, "endOffset": 111}, {"referenceID": 10, "context": "Finally, to assess the difficulty of the task, we report the accuracy of machine translation system trained on a parallel corpus (Klein et al., 2017).", "startOffset": 129, "endOffset": 149}], "year": 2017, "abstractText": "This paper focuses on style transfer on the basis of non-parallel text. This is an instance of a broader family of problems including machine translation, decipherment, and sentiment modification. The key technical challenge is to separate the content from desired text characteristics such as sentiment. We leverage refined alignment of latent representations across mono-lingual text corpora with different characteristics. We deliberately modify encoded examples according to their characteristics, requiring the reproduced instances to match available examples with the altered characteristics as a population. We demonstrate the effectiveness of this cross-alignment method on three tasks: sentiment modification, decipherment of word substitution ciphers, and recovery of word order.", "creator": "LaTeX with hyperref package"}}}