{"id": "1705.10229", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2017", "title": "Latent Intention Dialogue Models", "abstract": "Developing a dialogue agent that is capable of making autonomous decisions and communicating by natural language is one of the long-term goals of machine learning research. Traditional approaches either rely on hand-crafting a small state-action set for applying reinforcement learning that is not scalable or constructing deterministic models for learning dialogue sentences that fail to capture natural conversational variability. In this paper, we propose a Latent Intention Dialogue Model (LIDM) that employs a discrete latent variable to learn underlying dialogue intentions in the framework of neural variational inference. In a goal-oriented dialogue scenario, these latent intentions can be interpreted as actions guiding the generation of machine responses, which can be further refined autonomously by reinforcement learning. The experimental evaluation of LIDM shows that the model out-performs published benchmarks for both corpus-based and human evaluation, demonstrating the effectiveness of discrete latent variable models for learning goal-oriented dialogues.", "histories": [["v1", "Mon, 29 May 2017 15:01:44 GMT  (397kb,D)", "http://arxiv.org/abs/1705.10229v1", "Accepted at ICML 2017"]], "COMMENTS": "Accepted at ICML 2017", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE stat.ML", "authors": ["tsung-hsien wen", "yishu miao", "phil blunsom", "steve j young"], "accepted": true, "id": "1705.10229"}, "pdf": {"name": "1705.10229.pdf", "metadata": {"source": "CRF", "title": "Latent Intention Dialogue Models", "authors": ["Tsung-Hsien Wen", "Yishu Miao", "Phil Blunsom", "Steve Young"], "emails": ["<thw28@cam.ac.uk>,", "<yishu.miao@cs.ox.ac.uk>."], "sections": [{"heading": "1. Introduction", "text": "These discriminatory models are designed to learn only conditional output distribution via strings and despite demanding architectures and condition- * Equal contribution 1Department of Engineering, Cambridge, United Kingdom 2Department of Computer Science, Oxford, United Kingdom. Correspondence to: Tsung-Hsien Wen < thw28 @ cam.ac.uk >, Yishu Miao < yishu.miao @ cs.ox.ac.uk >.Proceedings of the 34 International Conference on Machine Learning, Sydney, Australia, 2017."}, {"heading": "2. Latent Intention Dialogue Model for Goal-oriented Dialogue", "text": "Target-oriented dialogue1 (Young et al., 2013) aims to build models that can help the user perform certain tasks by interacting with natural language. In the face of a user-input statement ut at turn t and a knowledge base (KB), the model to1Like most goal-oriented dialog research, we focus on searching for information dialogues. Analyze the input into actionable commands Q and access the KB to search for useful information to answer the query. Based on the search result, the model must summarize its results and respond with an appropriate answer mt in natural language."}, {"heading": "2.1. Model", "text": "The LIDM is based on the end-to-end system architecture as described in (Wen et al) 2017. It comprises three components: (1) the user intention and the user intention, (2) the user intention and align it with the knowledge of the system, (1) the user intention, (2) the user intentions, (2) the user intentions, (2) the user intentions to a bidirectional LSTM (Hochreiter & Schmidhuber, 1997) and the linking of the hidden states, ut = biLSTMI (ut). (1) The belief vector bt bt bt bt bt bt bt bt bt bt bt bt, which represents a series of probability distributions over domain specific slot-value pairs, is extracted from a series of recited RNN-CNN beliefs (Wal, 2017)."}, {"heading": "2.2. Inference", "text": "To draw conclusions for the LIDM, we present an inference network q\u03a6 (zt, mt) to approximate the posterior distribution p (zt, mt) so that we can optimize the variational lower limit of common probability in a neural variation frame (Miao et al., 2016). We can then derive the variational lower limit as, L = Eq3 (zt, st), where the variational lower limit of common probability is derived in a neuronal variation frame (Miao et al., 2016). We can then derive the variational lower limit as, L = Eq3 (zt, st), where the variational lower limit of common probability (zt, st) is derived."}, {"heading": "2.3. Semi-Supervision", "text": "Despite the steps described above to reduce the deviation, there are two major difficulties in learning latent intentions in a completely unsupervised manner: (1) the high variance of the inference network prevents it from generating meaningful intent samples in the early stages of training, and (2) the excessively discriminatory power of the LSTM language model tends to separate the LSTM decoder from the other components, with the decoder learning to ignore the samples and focusing solely on optimizing the language model. In order to ensure more stable education and prevent separation, a semi-supervised learning method is introduced; deriving the latent intentions underlying the utterances resembles an unsupervised cluster task. Standard cluster algorithms can therefore be used to pre-process the corpus and generate automatic labels that form z-deviations for a portion of the training examples (mt, st, z-z, z-z)."}, {"heading": "2.4. Reinforcement Learning", "text": "One of the main purposes of learning interpretable, discrete latent intentions within a dialog system is the ability to control and refine the behavior of the model with operational experience. As the learned generative network (zt | st) encodes the policy discovered based on the underlying data distribution, but this is not necessarily optimal for any specific task. As it is a parameterized political network itself, we can use the learning algorithms based on political gradients (Williams, 1992; Konda & Tsitsiklis, 2003) to refine the initial policy against other objective functions that interest us more. Based on the initial policy (zt | st), we review the training dialogues and update parameters based on the following strategy: When we come across unmarked examples U, the system tries an action from the learned policy z (n) t, the policy z (st), and receives a reward if we can subjectify the political problem (s)."}, {"heading": "3. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Dataset & Setup for Goal-oriented Dialogue", "text": "We explored the characteristics of the LIDM Model 3 using the CamRest676 corpus4 in Wen et al (2017), in which the task of the system is to help users find a restaurant in Cambridge, UK area. The corpus was collected on the basis of a modified wizard from Oz (Kelley, 1984), whether users can use the search and six requestable slots (addresses, addresses, zip codes and the three informative slots) that the user can ask between a user and an assistant to limit the search and six requestable slots (address, zip code plus the three informative slots) that a value has been offered for once a restaurant. There are 676 dialogs in the datasets (including ready and unfinished dialogs) and approximately 2750 applicable sets in total."}, {"heading": "3.2. Experiments on Goal-oriented Dialogue", "text": "This year it is more than ever before."}, {"heading": "4. Discussion", "text": "Discrete latent variable dialogue models such as LIDM are attractive because the latent variable can act as an interface for language learning and decision-making in internal dialogs.This dismantling can effectively help us solve the problem of lending, where different learning signals can be applied to different sub-modules to update parameters.In variable inference for discrete latent variables, the latent distribution is essentially updated by the reward from the variable lower boundary.While in enhanced learning, the latent distribution (i.e. the political network) is updated by the rewards from dialogue success and sentence value, the latent variable bridges the different learning paradigms such as Bayesian learning and reinforcement learning and brings them together under the same frame.This framework offers a more robust neural network-based approach than previous approaches, as it does not depend exclusively on sequential learning, but on continuous learning and hidden dialogue models that directly underlie dialogue."}, {"heading": "5. Related work", "text": "Modeling chat-based dialogues (Serban et al., 2015; Shang et al., 2015) as sequence-to-sequence learning (Sutskever et al., 2014) is a common theme in the deep learning community. Vinyals and Le (2015), however, have shown a seq2seq-based model that has been trained on an enormous amount of conversation corpora that can learn interesting answers to different user questions. However, due to the inability to conduct a model dialogue, these models generally suffer from the generic response problem (Li et al., 2016a; Serban et al., 2016). Several approaches have been proposed to mitigate this problem, such as modeling the person (Li et al., 2016b), enhanced learning (Li et al., 2016c), and the introduction of continuous latent variables (Serban et al., 2016; Cao & Clark, 2017). While in our case we are not just using the variable to inject dialogue."}, {"heading": "6. Conclusion", "text": "In this paper, we proposed a framework for learning dialog intentions using discrete latent variable models and introduced the Latent Intention Dialogue Model (LIDM) for goal-oriented dialog modeling. We demonstrated that LIDM can derive an effective initial policy from the underlying data distribution and is able to revise its strategy based on an external reward through reinforcement learning. We believe that this is a promising step in building autonomous dialog agents, as the learned discrete latent variable interface allows the agent to learn through various paradigms. Experiments showed that the proposed LIDM is capable of communicating with human subjects and exceeds previous published results."}, {"heading": "Acknowledgements", "text": "Tsung-Hsien Wen is supported by Toshiba Research Europe Ltd., Cambridge Research Laboratory. The authors thank the members of the Cambridge Dialogue Systems Group for their valuable comments."}], "references": [{"title": "Decoder integration and expected bleu training for recurrent neural network language models", "author": ["Auli", "Michael", "Gao", "Jianfeng"], "venue": "In ACL. Association for Computational Linguistics,", "citeRegEx": "Auli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Auli et al\\.", "year": 2014}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau", "Dzmitry", "Cho", "Kyunghyun", "Bengio", "Yoshua"], "venue": null, "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Learning end-to-end goal-oriented dialog", "author": ["Bordes", "Antoine", "Weston", "Jason"], "venue": "In ICLR,", "citeRegEx": "Bordes et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2017}, {"title": "Generating sentences from a continuous space", "author": ["Bowman", "Samuel R", "Vilnis", "Luke", "Vinyals", "Oriol", "Dai", "Andrew M", "J\u00f3zefowicz", "Rafal", "Bengio", "Samy"], "venue": "arXiv preprint:,", "citeRegEx": "Bowman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Latent variable dialogue models and their diversity", "author": ["Cao", "Kris", "Clark", "Stephen"], "venue": "In EACL,", "citeRegEx": "Cao et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2017}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Faruqui", "Manaal", "Dodge", "Jesse", "Jauhar", "Sujay Kumar", "Dyer", "Chris", "Hovy", "Eduard", "Smith", "Noah A"], "venue": "In NAACL-HLT,", "citeRegEx": "Faruqui et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "On-line policy optimisation of bayesian spoken dialogue systems via human interaction", "author": ["Ga\u0161i\u0107", "Milica", "Breslin", "Catherine", "Henderson", "Matthew", "Kim", "Dongho", "Szummer", "Martin", "Thomson", "Blaise", "Tsiakoulis", "Pirros", "Young", "Steve"], "venue": "In ICASSP,", "citeRegEx": "Ga\u0161i\u0107 et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ga\u0161i\u0107 et al\\.", "year": 2013}, {"title": "Machine learning for dialog state tracking: A review", "author": ["Henderson", "Matthew"], "venue": "In Machine Learning in Spoken Language Processing Workshop,", "citeRegEx": "Henderson and Matthew.,? \\Q2015\\E", "shortCiteRegEx": "Henderson and Matthew.", "year": 2015}, {"title": "Word-based dialog state tracking with recurrent neural networks", "author": ["Henderson", "Matthew", "Thomson", "Blaise", "Young", "Steve"], "venue": "In SigDial,", "citeRegEx": "Henderson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "beta-vae: Learning basic visual concepts with a constrained variational framework", "author": ["Higgins", "Irina", "Matthey", "Loic", "Pal", "Arka", "Burgess", "Christopher", "Glorot", "Xavier", "Botvinick", "Matthew", "Mohamed", "Shakir", "Lerchner", "Alexander"], "venue": "In ICLR,", "citeRegEx": "Higgins et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Higgins et al\\.", "year": 2017}, {"title": "The goldilocks principle: Reading children\u2019s books with explicit memory representations", "author": ["Hill", "Felix", "Bordes", "Antoine", "Chopra", "Sumit", "Weston", "Jason"], "venue": "In ICLR,", "citeRegEx": "Hill et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["Karpathy", "Andrej", "Fei-Fei", "Li"], "venue": "In CVPR,", "citeRegEx": "Karpathy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Karpathy et al\\.", "year": 2015}, {"title": "An iterative design methodology for userfriendly natural language office information applications", "author": ["Kelley", "John F"], "venue": "ACM Transaction on Information Systems,", "citeRegEx": "Kelley and F.,? \\Q1984\\E", "shortCiteRegEx": "Kelley and F.", "year": 1984}, {"title": "Globally coherent text generation with neural checklist models", "author": ["Kiddon", "Chlo\u00e9", "Zettlemoyer", "Luke", "Choi", "Yejin"], "venue": "In EMNLP,", "citeRegEx": "Kiddon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kiddon et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik P", "Ba", "Jimmy"], "venue": "arXiv preprint: 1412.6980,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Kingma", "Diederik P", "Welling", "Max"], "venue": "In ICML,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Semi-supervised learning with deep generative models", "author": ["Kingma", "Diederik P", "Mohamed", "Shakir", "Rezende", "Danilo J", "Welling", "Max"], "venue": "In NIPS,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "On actorcritic algorithms", "author": ["Konda", "Vijay R", "Tsitsiklis", "John N"], "venue": "SIAM J. Control Optim.,", "citeRegEx": "Konda et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Konda et al\\.", "year": 2003}, {"title": "Semantic parsing with semi-supervised sequential autoencoders", "author": ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", "Melis", "G\u00e1bor", "Grefenstette", "Edward", "Dyer", "Chris", "Ling", "Wang", "Blunsom", "Phil", "Hermann", "Karl Moritz"], "venue": "In EMNLP,", "citeRegEx": "Ko\u010disk\u00fd et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ko\u010disk\u00fd et al\\.", "year": 2016}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["Li", "Jiwei", "Galley", "Michel", "Brockett", "Chris", "Gao", "Jianfeng", "Dolan", "Bill"], "venue": "In NAACL-HLT,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "A personabased neural conversation model", "author": ["Li", "Jiwei", "Galley", "Michel", "Brockett", "Chris", "Spithourakis", "Georgios", "Gao", "Jianfeng", "Dolan", "Bill"], "venue": "In ACL,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Deep reinforcement learning for dialogue generation", "author": ["Li", "Jiwei", "Monroe", "Will", "Ritter", "Alan", "Jurafsky", "Dan", "Galley", "Michel", "Gao", "Jianfeng"], "venue": "In EMNLP,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Dialogue learning with human-in-the-loop", "author": ["Li", "Jiwei", "Miller", "Alexander H", "Chopra", "Sumit", "Ranzato", "Marc\u2019Aurelio", "Weston", "Jason"], "venue": "In ICLR,", "citeRegEx": "Li et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Li et al\\.", "year": 2017}, {"title": "Language as a latent variable: Discrete generative models for sentence compression", "author": ["Miao", "Yishu", "Blunsom", "Phil"], "venue": "In EMNLP,", "citeRegEx": "Miao et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Miao et al\\.", "year": 2016}, {"title": "Neural variational inference for text processing", "author": ["Miao", "Yishu", "Yu", "Lei", "Blunsom", "Phil"], "venue": "In ICML,", "citeRegEx": "Miao et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Miao et al\\.", "year": 2016}, {"title": "Neural variational inference and learning in belief networks", "author": ["Mnih", "Andriy", "Gregor", "Karol"], "venue": "In ICML,", "citeRegEx": "Mnih et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2014}, {"title": "Recurrent models of visual attention", "author": ["Mnih", "Volodymyr", "Heess", "Nicolas", "Graves", "Alex", "kavukcuoglu", "koray"], "venue": "In NIPS,", "citeRegEx": "Mnih et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2014}, {"title": "Neural belief tracker: Data-driven dialogue state tracking", "author": ["Mrk\u0161i\u0107", "Nikola", "\u00d3 S\u00e9aghdha", "Diarmuid", "Wen", "TsungHsien", "Thomson", "Blaise", "Young", "Steve"], "venue": "In ACL,", "citeRegEx": "Mrk\u0161i\u0107 et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Mrk\u0161i\u0107 et al\\.", "year": 2017}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Papineni", "Kishore", "Roukos", "Salim", "Ward", "Todd", "Zhu", "Wei-Jing"], "venue": "In ACL,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "A hierarchical latent variable encoderdecoder model for generating dialogues", "author": ["Serban", "Iulian V", "Sordoni", "Alessandro", "Lowe", "Ryan", "Charlin", "Laurent", "Pineau", "Joelle", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "arXiv preprint:", "citeRegEx": "Serban et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Serban et al\\.", "year": 2016}, {"title": "Hierarchical neural network generative models for movie dialogues", "author": ["Serban", "Iulian Vlad", "Sordoni", "Alessandro", "Bengio", "Yoshua", "Courville", "Aaron C", "Pineau", "Joelle"], "venue": "In AAAI,", "citeRegEx": "Serban et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Neural responding machine for short-text conversation", "author": ["Shang", "Lifeng", "Lu", "Zhengdong", "Li", "Hang"], "venue": "In ACL,", "citeRegEx": "Shang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "Learning syntactic patterns for automatic hypernym discovery", "author": ["Snow", "Rion", "Jurafsky", "Daniel", "Ng", "Andrew Y"], "venue": "In NIPS,", "citeRegEx": "Snow et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Snow et al\\.", "year": 2004}, {"title": "Learning from real users: Rating dialogue success with neural networks for reinforcement learning in spoken dialogue systems", "author": ["Su", "Pei-Hao", "Vandyke", "David", "Gasic", "Milica", "Kim", "Dongho", "Mrksic", "Nikola", "Wen", "Tsung-Hsien", "Young", "Steve"], "venue": "In Interspeech,", "citeRegEx": "Su et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Su et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Sutskever", "Ilya", "Vinyals", "Oriol", "Le", "Quoc V"], "venue": "In NIPS,", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Foundations of Rational Agency, chapter Speech Acts for Dialogue Agents", "author": ["Traum", "David R"], "venue": null, "citeRegEx": "Traum and R.,? \\Q1999\\E", "shortCiteRegEx": "Traum and R.", "year": 1999}, {"title": "A neural conversational model", "author": ["Vinyals", "Oriol", "Le", "Quoc V"], "venue": "In ICML Deep Learning Workshop,", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Semantically conditioned lstm-based natural language generation for spoken dialogue systems", "author": ["Wen", "Tsung-Hsien", "Gasic", "Milica", "Mrk\u0161i\u0107", "Nikola", "Su", "Pei-Hao", "Vandyke", "David", "Young", "Steve"], "venue": "In EMNLP,", "citeRegEx": "Wen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2015}, {"title": "A network-based endto-end trainable task-oriented dialogue system", "author": ["Wen", "Tsung-Hsien", "Vandyke", "David", "Mrk\u0161i\u0107", "Nikola", "Ga\u0161i\u0107", "Milica", "M. Rojas-Barahona", "Lina", "Su", "Pei-Hao", "Ultes", "Stefan", "Young", "Steve"], "venue": null, "citeRegEx": "Wen et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2017}, {"title": "Dialog-based language learning", "author": ["Weston", "Jason E"], "venue": "In NIPS,", "citeRegEx": "Weston and E.,? \\Q2016\\E", "shortCiteRegEx": "Weston and E.", "year": 2016}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["Williams", "Ronald J"], "venue": "Machine Learning,", "citeRegEx": "Williams and J.,? \\Q1992\\E", "shortCiteRegEx": "Williams and J.", "year": 1992}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Xu", "Kelvin", "Ba", "Jimmy", "Kiros", "Ryan", "Cho", "Kyunghyun", "Courville", "Aaron", "Salakhutdinov", "Ruslan", "Zemel", "Richard", "Bengio", "Yoshua"], "venue": "In ICML,", "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Pomdp-based statistical spoken dialog systems: A review", "author": ["Young", "Steve", "Ga\u0161i\u0107", "Milica", "Thomson", "Blaise", "Williams", "Jason D"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Young et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Young et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 35, "context": "Recurrent neural networks (RNNs) have shown impressive results in modeling generation tasks that have a sequential structured output form, such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2015), caption generation (Karpathy & Fei-Fei, 2015; Xu et al.", "startOffset": 167, "endOffset": 214}, {"referenceID": 1, "context": "Recurrent neural networks (RNNs) have shown impressive results in modeling generation tasks that have a sequential structured output form, such as machine translation (Sutskever et al., 2014; Bahdanau et al., 2015), caption generation (Karpathy & Fei-Fei, 2015; Xu et al.", "startOffset": 167, "endOffset": 214}, {"referenceID": 42, "context": ", 2015), caption generation (Karpathy & Fei-Fei, 2015; Xu et al., 2015), and natural language generation (Wen et al.", "startOffset": 28, "endOffset": 71}, {"referenceID": 38, "context": ", 2015), and natural language generation (Wen et al., 2015; Kiddon et al., 2016).", "startOffset": 41, "endOffset": 80}, {"referenceID": 14, "context": ", 2015), and natural language generation (Wen et al., 2015; Kiddon et al., 2016).", "startOffset": 41, "endOffset": 80}, {"referenceID": 39, "context": "For example both goal-oriented dialogue systems (Wen et al., 2017; Bordes & Weston, 2017) and sequence-to-sequence learning chatbots (Vinyals & Le, 2015; Shang et al.", "startOffset": 48, "endOffset": 89}, {"referenceID": 32, "context": ", 2017; Bordes & Weston, 2017) and sequence-to-sequence learning chatbots (Vinyals & Le, 2015; Shang et al., 2015; Serban et al., 2015) struggle to generate diverse yet causal responses (Li et al.", "startOffset": 74, "endOffset": 135}, {"referenceID": 31, "context": ", 2017; Bordes & Weston, 2017) and sequence-to-sequence learning chatbots (Vinyals & Le, 2015; Shang et al., 2015; Serban et al., 2015) struggle to generate diverse yet causal responses (Li et al.", "startOffset": 74, "endOffset": 135}, {"referenceID": 30, "context": ", 2015) struggle to generate diverse yet causal responses (Li et al., 2016a; Serban et al., 2016).", "startOffset": 58, "endOffset": 97}, {"referenceID": 3, "context": "Recent advances in neural variational inference (Kingma & Welling, 2014; Mnih & Gregor, 2014) have sparked a series of latent variable models applied to NLP (Bowman et al., 2015; Serban et al., 2016; Miao et al., 2016; Cao & Clark, 2017).", "startOffset": 157, "endOffset": 237}, {"referenceID": 30, "context": "Recent advances in neural variational inference (Kingma & Welling, 2014; Mnih & Gregor, 2014) have sparked a series of latent variable models applied to NLP (Bowman et al., 2015; Serban et al., 2016; Miao et al., 2016; Cao & Clark, 2017).", "startOffset": 157, "endOffset": 237}, {"referenceID": 24, "context": "Recent advances in neural variational inference (Kingma & Welling, 2014; Mnih & Gregor, 2014) have sparked a series of latent variable models applied to NLP (Bowman et al., 2015; Serban et al., 2016; Miao et al., 2016; Cao & Clark, 2017).", "startOffset": 157, "endOffset": 237}, {"referenceID": 15, "context": "In contrast, models with discrete latent variables are able to not only produce interpretable latent distributions but also provide a principled framework for semi-supervised learning (Kingma et al., 2014).", "startOffset": 184, "endOffset": 205}, {"referenceID": 5, "context": "This is critical for NLP tasks, especially where additional supervision and external knowledge can be utilized for bootstrapping (Faruqui et al., 2015; Miao & Blunsom, 2016; Ko\u010disk\u00fd et al., 2016).", "startOffset": 129, "endOffset": 195}, {"referenceID": 19, "context": "This is critical for NLP tasks, especially where additional supervision and external knowledge can be utilized for bootstrapping (Faruqui et al., 2015; Miao & Blunsom, 2016; Ko\u010disk\u00fd et al., 2016).", "startOffset": 129, "endOffset": 195}, {"referenceID": 43, "context": "Goal-oriented dialogue1 (Young et al., 2013) aims at building models that can help users to complete certain tasks via natural language interaction.", "startOffset": 24, "endOffset": 44}, {"referenceID": 39, "context": "The LIDM is based on the end-to-end system architecture described in (Wen et al., 2017).", "startOffset": 69, "endOffset": 87}, {"referenceID": 39, "context": "The belief vector bt, which is a concatenation of a set of probability distributions over domain specific slot-value pairs, is extracted by a set of pre-trained RNN-CNN belief trackers (Wen et al., 2017; Mrk\u0161i\u0107 et al., 2017), in which ut and mt\u22121 are processed by two different CNNs as shown in Figure 1,", "startOffset": 185, "endOffset": 224}, {"referenceID": 28, "context": "The belief vector bt, which is a concatenation of a set of probability distributions over domain specific slot-value pairs, is extracted by a set of pre-trained RNN-CNN belief trackers (Wen et al., 2017; Mrk\u0161i\u0107 et al., 2017), in which ut and mt\u22121 are processed by two different CNNs as shown in Figure 1,", "startOffset": 185, "endOffset": 224}, {"referenceID": 8, "context": "All sentences are pre-processed by delexicalisation (Henderson et al., 2014) where slot-value specific words are replaced with their corresponding generic tokens based on an ontology.", "startOffset": 52, "endOffset": 76}, {"referenceID": 43, "context": "based on dialogue state, we can also interpret the policy network here as a latent dialogue management component in the traditional POMDP-based framework (Young et al., 2013; Ga\u0161i\u0107 et al., 2013).", "startOffset": 154, "endOffset": 194}, {"referenceID": 6, "context": "based on dialogue state, we can also interpret the policy network here as a latent dialogue management component in the traditional POMDP-based framework (Young et al., 2013; Ga\u0161i\u0107 et al., 2013).", "startOffset": 154, "endOffset": 194}, {"referenceID": 24, "context": "To carry out inference for the LIDM, we introduce an inference network q\u03a6(zt|st,mt) to approximate the posterior distribution p(zt|st,mt) so that we can optimise the variational lower bound of the joint probability in a neural variational inference framework (Miao et al., 2016).", "startOffset": 259, "endOffset": 278}, {"referenceID": 9, "context": "Note that we use a modified version of the lower bound here by incorporating a trade-off factor \u03bb (Higgins et al., 2017).", "startOffset": 98, "endOffset": 120}, {"referenceID": 26, "context": "To reduce the variance during inference, we follow the REINFORCE algorithm (Mnih et al., 2014; Mnih & Gregor, 2014) and introduce two baselines b and b(st), the centered learning signal and input dependent baseline respectively to help reduce the variance.", "startOffset": 75, "endOffset": 115}, {"referenceID": 34, "context": "During reinforcement fine-tuning, we generated a sentence mt from the model to replace the ground truth m\u0302t at each turn and define an immediate reward as whether mt can improve the dialogue success (Su et al., 2015) relative to m\u0302t, plus the sentence BLEU score (Auli & Gao, 2014),", "startOffset": 199, "endOffset": 216}, {"referenceID": 34, "context": "We then evaluated our model on task success rate (Su et al., 2015) and BLEU score (Papineni et al.", "startOffset": 49, "endOffset": 66}, {"referenceID": 29, "context": ", 2015) and BLEU score (Papineni et al., 2002) as in Wen et al (2016; 2017) in which the model is used to predict each system response in the held-out test set.", "startOffset": 23, "endOffset": 46}, {"referenceID": 31, "context": "Modeling chat-based dialogues (Serban et al., 2015; Shang et al., 2015) as a sequence-to-sequence learning (Sutskever et al.", "startOffset": 30, "endOffset": 71}, {"referenceID": 32, "context": "Modeling chat-based dialogues (Serban et al., 2015; Shang et al., 2015) as a sequence-to-sequence learning (Sutskever et al.", "startOffset": 30, "endOffset": 71}, {"referenceID": 35, "context": ", 2015) as a sequence-to-sequence learning (Sutskever et al., 2014) problem is a common theme in the deep learning community.", "startOffset": 43, "endOffset": 67}, {"referenceID": 30, "context": "However, due to an inability to model dialogue context, these models generally suffer from the generic response problem (Li et al., 2016a; Serban et al., 2016).", "startOffset": 120, "endOffset": 159}, {"referenceID": 30, "context": ", 2016c), and introducing continuous latent variables (Serban et al., 2016; Cao & Clark, 2017).", "startOffset": 54, "endOffset": 94}, {"referenceID": 26, "context": "Modeling chat-based dialogues (Serban et al., 2015; Shang et al., 2015) as a sequence-to-sequence learning (Sutskever et al., 2014) problem is a common theme in the deep learning community. Vinyals and Le (2015) has demonstrated a seq2seq-based model trained on a huge amount of conversation corpora which learns interesting replies conditioned on different user queries.", "startOffset": 31, "endOffset": 212}, {"referenceID": 43, "context": "At the other end of the spectrum, goal-oriented dialogue systems typically adopt the POMDP framework (Young et al., 2013) and break down the development of the dialogue systems into a pipeline of modules: natural language understanding (Henderson, 2015), dialogue manage-", "startOffset": 101, "endOffset": 121}, {"referenceID": 6, "context": "ment (Ga\u0161i\u0107 et al., 2013), and natural language generation (Wen et al.", "startOffset": 5, "endOffset": 25}, {"referenceID": 38, "context": ", 2013), and natural language generation (Wen et al., 2015).", "startOffset": 41, "endOffset": 59}, {"referenceID": 15, "context": "For example, semi-supervised learning (Kingma et al., 2014) has been applied in the sample-based neural variational inference framework as a way to reduce sample variance.", "startOffset": 38, "endOffset": 59}, {"referenceID": 19, "context": "In practice, this relies on a discrete latent variable (Miao & Blunsom, 2016; Ko\u010disk\u00fd et al., 2016) as the vehicle for the supervision labels.", "startOffset": 55, "endOffset": 99}, {"referenceID": 6, "context": "As in reinforcement learning, which has been a very common learning paradigm in dialogue systems (Ga\u0161i\u0107 et al., 2013; Su et al., 2016; Li et al., 2017), the policy is also parameterised by a discrete set of actions.", "startOffset": 97, "endOffset": 151}, {"referenceID": 23, "context": "As in reinforcement learning, which has been a very common learning paradigm in dialogue systems (Ga\u0161i\u0107 et al., 2013; Su et al., 2016; Li et al., 2017), the policy is also parameterised by a discrete set of actions.", "startOffset": 97, "endOffset": 151}, {"referenceID": 33, "context": "In addition, selfsupervised learning (Snow et al., 2004) (or distant, weak supervision) as a simple way to generate automatic labels by heuristics is popular in many NLP tasks and has been applied to memory networks (Hill et al.", "startOffset": 37, "endOffset": 56}, {"referenceID": 10, "context": ", 2004) (or distant, weak supervision) as a simple way to generate automatic labels by heuristics is popular in many NLP tasks and has been applied to memory networks (Hill et al., 2016) and neural dialogue systems (Wen et al.", "startOffset": 167, "endOffset": 186}], "year": 2017, "abstractText": "Developing a dialogue agent that is capable of making autonomous decisions and communicating by natural language is one of the long-term goals of machine learning research. Traditional approaches either rely on hand-crafting a small state-action set for applying reinforcement learning that is not scalable or constructing deterministic models for learning dialogue sentences that fail to capture natural conversational variability. In this paper, we propose a Latent Intention Dialogue Model (LIDM) that employs a discrete latent variable to learn underlying dialogue intentions in the framework of neural variational inference. In a goal-oriented dialogue scenario, these latent intentions can be interpreted as actions guiding the generation of machine responses, which can be further refined autonomously by reinforcement learning. The experimental evaluation of LIDM shows that the model out-performs published benchmarks for both corpus-based and human evaluation, demonstrating the effectiveness of discrete latent variable models for learning goal-oriented dialogues.", "creator": "LaTeX with hyperref package"}}}