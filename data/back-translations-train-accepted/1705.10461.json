{"id": "1705.10461", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-May-2017", "title": "The Numerics of GANs", "abstract": "In this paper, we analyze the numerics of common algorithms for training Generative Adversarial Networks (GANs). Using the formalism of smooth two-player games we analyze the associated gradient vector field of GAN training objectives. Our findings suggest that the convergence of current algorithms suffers due to two factors: i) presence of eigenvalues of the Jacobian of the gradient vector field with zero real-part, and ii) eigenvalues with big imaginary part. Using these findings, we design a new algorithm that overcomes some of these limitations and has better convergence properties. Experimentally, we demonstrate its superiority on training common GAN architectures and show convergence on GAN architectures that are known to be notoriously hard to train.", "histories": [["v1", "Tue, 30 May 2017 05:54:59 GMT  (6041kb,D)", "http://arxiv.org/abs/1705.10461v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["lars mescheder", "sebastian nowozin", "reas geiger"], "accepted": true, "id": "1705.10461"}, "pdf": {"name": "1705.10461.pdf", "metadata": {"source": "CRF", "title": "The Numerics of GANs", "authors": ["Lars Mescheder"], "emails": ["lmescheder@tuebingen.mpg.de", "sebastian.nowozin@microsoft.com", "andreas.geiger@tuebingen.mpg.de"], "sections": [{"heading": "1 Introduction", "text": "Generative Adversarial Networks (GANs) [8] have been very successful in learning probability distributions. Since their first appearance, GANs have been successfully applied to a variety of tasks, including picture-to-picture translation [10], picture-to-painting [23], probabilistic conclusions [12, 7, 6] and many more. While this work is very powerful, we are known to be notoriously difficult to learn. The standard strategy for stabilizing the model is to adapt the model either by adapting it to the architecture [17] or by selecting an easy-to-optimize object function [20, 2, 9]."}, {"heading": "2 Background", "text": "In this section, we will first consider the concept of Generative Adversarial Networks (GANs) from the point of view of minimizing divergence, then introduce the concept of a smooth (non-convex) two-player game, and define the terminology used in the rest of the article. Finally, we will describe the simultaneous gradient ascent, the de facto standard algorithm for determining the Nash balance of such games, and derive some of its properties."}, {"heading": "2.1 Divergence Measures and GANs", "text": "Generative Adversarial Networks are best understood in the context of minimizing divergence: Suppose we get a divergence function D, i.e. a function that takes a pair of probability distributions as input, outputs an element [0, \u221e] and satisfies D (p, p) = 0 for all probability distributions p. Furthermore, we assume that we get a certain target distribution p0, from which we can i.e. draw samples and a parametric family of distribution sources, which also allows us to draw samples i.e. In practice, q\u03b8 is usually implemented as a neural network that acts on a hidden code z, which is sampled from a known distribution and outputs an element from the target area. Our goal is to find a divergence that minimizes the divergence authors D (p0, qhabi), i.e. we want to solve the optimization problem habi in group F (pqm)."}, {"heading": "2.2 Smooth Two-Player Games", "text": "A differentiable two-player game is defined by two auxiliary functions f (\u03c6, \u03b8) and g (\u03c6, \u03b8), which are defined over a common space (\u03c6, \u03b8), while player 2 tries to maximize g. In the context of the GAN game in Section 2.1, this results in a number of possible parameter values for the generator, whereas the sum of possible parameter values is for the discriminator. We call a game a zero-sum game if f = \u2212 g. Note that the derivative of the GAN game in Section 2.1 results in a zero-sum game, whereas in practice people usually use a variant of this formula that is not a zero-sum game for better convergence."}, {"heading": "2.3 Simultaneous Gradient Ascent", "text": "The de facto standard algorithm for finding Nash balances in general smooth two-player games is the Simultaneous Gradient Ascent (SimGA), which has been described in several papers, for example in [18] and, more recently, also in the context of GANs, in [14]. However, the idea is simple and is illustrated in Algorithm 1. We iteratively update the parameters of the two players by applying the gradient ascent to the utility functions of the two players at the same time. This can also be done by applying the Euler method to the ordinary differential equation dt x (t) = v (x (t)), (7) where v (x) is the associated gradient vector field of the two-player game. It can be shown that simultaneous gradient ascent unit converges locally to a Nash equilibrium value."}, {"heading": "3 Convergence Theory", "text": "In this section we will analyze the convergence properties of the most common method of forming GANs, simultaneous gradient ascendance1. < We show that two major causes of error for this algorithm are eigenvalues of the Jacobian of the associated gradient vector field with zero real parts and eigenvalues with large imaginary parts. < We start with the following classical theory of the convergence of fixed point iterations: Proposition 3. Let F: \"be a continuously differentiated function on an open subset of Rn and let x\" so that1. F (x) = x, \"and2. the absolute values of the eigenvalues of the Jacobian F\" (x) are all smaller than 1. Then there is an open neighborhood of x, \"so that for all x0.\" U, the iterate F (k) and the convergence F (x0) are at least linear."}, {"heading": "4 Consensus Optimization", "text": "In this section we deduce the proposed method and analyse its convergence characteristics."}, {"heading": "4.1 Derivation", "text": "The determination of stationary points of the vector field v (x) corresponds to the solution of the equation v (x) = 0. (11) A simple strategy for determining such stationary points is to minimize L (x) = 12 x (x) x 2 for x. Unfortunately, this can lead to unstable stationary points of v (x) or another local minimum of 12 x (x) x 2, and in practice we have found that it did not work well. Therefore, we consider a modified vector field w (x) that comes as close as possible to the original vector field v (x), but at the same time still minimizes L (x) (at least locally). A reasonable candidate for such a vector field is w (x) = v (x) \u2212 \u03b3 f (12)."}, {"heading": "4.2 Convergence", "text": "To analyze convergence, we consider a more general algorithm than in Section 4.1, which uses iterative application of a function F of formF (x) = x + hA (x). (15) for any increment h > 0 and an invertible matrix A (x) to x. Consensus optimization is a special case of this algorithm for A (x) = I \u2212 \u03b3 v (x) T. We assume that 1\u03b3 is not a eigenvalue of v \u00b2 (x) T for any x, so that A (x) is actually invertible.Algorithm 2 Consensus optimization 1: not converted, but 2: v\u03c6 v \u00b2 (f) \u2212 x T. We assume that a problem of v \u2032 (x) is not a eigenvalue of v \u2032 (x) T for any x, so that A (g) - and Lemconvertible (g) - a negative point of v \u00b2."}, {"heading": "5 Experiments", "text": "In our first experiment, we evaluate our method using a simple 2D example, where our goal is to learn a mix of 8 Gaussians with modes evenly distributed around the unit circle. [13] While discriminatory algorithms that form GANs often do not even converge on such simple examples, without extensive fine-tuning of the architecture and hyperparameters. [13] For both the generator and the critic, we use fully connected neural networks with 4 hidden layers and 256 hidden units for each layer. For all layers, we use RELU nonlinearity. We use a 64-dimensional Gaussian approach for the latent code z and set up the game between the generator and the critic using the supply functions as in [8]. To test our method, we run both SimGA and our method with RMSProp and a learning rate of 10 \u2212 4 for 10,000 steps. For our method, we use a regulation parameter of Euro of 10.000, we are presented in our GGA and GGA results of 5000, and the results of the GGA are presented in the RMSProp and RMSProp rule of 5000."}, {"heading": "6 Discussion", "text": "While we could demonstrate the local convergence of our method in Section 4, we believe that even more insights can be gained by studying global convergence properties. Specifically, our analysis in Section 4 cannot explain why generator and discriminator losses remain almost constant during training. Our theoretical results assume the existence of a Nash equilibrium. In particular, if we try to minimize f-divergence and misspecify the dimensionality of generator distribution, this may not be the case [1]. Nevertheless, we have found that our method works well in practice and we will leave a more accurate theoretical examination of this fact to future research. In practice, our method can potentially stabilize formerly unstable stationary points of the gradient vector field if the implicit regulation parameter is set high. This can lead to poor solutions. We have also found that our method becomes less stable for deeper architectures, which we attribute to the fact that the gradients may exhibit a very different scales in such Section 4 architectures, which may imply a penalty."}, {"heading": "7 Related Work", "text": "Saddle point problems arise not only in connection with the training of GANs. For example, the popular models of actors and critics [16] in reinforcement learning are also special cases of saddle point problems. Finding a stable algorithm for the training of GANs is a long-standing problem and several solutions have been proposed. Rolled-out GANs [13] roll out the optimization in relation to the critic, giving the generator more informative gradients. Although the rolling out of the optimization has been shown to stabilize the training, it can be cumbersome and moreover leads to a large model. As recently demonstrated, the stability of GAN training can be improved by using targets derived from the Wasserstein-1 distance (induced by the Kantorovich-Rubinstein standard) instead of f-divergences [2, 9]. While Wasserstein GANs often provide a good solution for stable training of GANs, they require an optimum adjustment that can only be achieved in practice such as prescribing critical time."}, {"heading": "8 Conclusion", "text": "In this paper, using the GAN lens functions, we analyzed the general difficulties in finding local Nash balances in smooth two-player games. We identified the major numerical difficulties encountered in the current state-of-the-art algorithms, and presented our findings as a new algorithm for building generative adversary networks. Our novel algorithm has favorable properties in theory and practice: From a theoretical point of view, we showed that it is locally convergent to a nashequilibrium, even if the Jacobin's own values are problematic. This is particularly interesting for games that occur in the context of GANs where such problems are widespread. From a practical point of view, our algorithm can be used in combination with any GAN architecture whose goal can be formulated as a two-player game to stabilize training. We experimentally demonstrated that our algorithm stabilizes training and successfully tackles training problems such as the breakdown of mode."}, {"heading": "Acknowledgements", "text": "This work was supported by Microsoft Research as part of its doctoral fellowship program."}, {"heading": "The Numerics of GANs: Supplementary Material", "text": "Lars Mescheder Autonomous Vision GroupMPI T\u00fcbingen 72076 Tuebingenlmescheder @ tuebingen.mpg.deSebastian Nowozin Microsoft ResearchCambridge sebastian.nowozin @ microsoft.com"}, {"heading": "Andreas Geiger", "text": "Autonomous Vision GroupMPI T\u00fcbingen 72076 Tuebingenandreas.geiger @ tuebingen.mpg.de"}, {"heading": "Abstract", "text": "This document contains evidence omitted from the main text of the paper \"The Numerics of GANs,\" as well as additional theoretical results. We also include additional experimental results and show that our method leads to stable formation of GANs on a variety of architectures and divergence measures."}, {"heading": "Proofs", "text": "This section contains evidence omitted from the main text."}, {"heading": "Smooth two player games", "text": "Lemma 1. In zero-sum games, v \u00b2 (x) is negative (semi-) definitive, if and only if it is a negative (semi-) definitive and in zero-sum games a positive (semi-) definitive. Proof. (19) Therefore, for all w = (w1, w2) 6 = 0wTv \u00b2 (x) w < 0 for all vectors w 6 = 0, if and only if wT1 \u00b2 f () wT1 < 0 and wT2 \u00b2 () wT2 > 0 for all vectors w < 0 for all vectors w \u00b2 6 = 0, if and only if wT1 \u00b2 f () wT2 < 0 and wT2 \u00b2 for all games w1 > 0 negative, w2 \u00b2 for all vectors w2 = 0.This shows that v \u00b2 (x) is negative if and only if it is negative."}, {"heading": "Convergence theory", "text": "Proposition 3. Let us F: + hA: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A: A:"}, {"heading": "Additional Theoretical Results", "text": "This section contains some additional theoretical results. On the one hand, we show how the convergence of gradient ascent and common modifications such as momentum and gradient recalculation with Proposition 3 can be analyzed in a natural way. On the other hand, we analyze alternating gradient ascents for two games and show that at small increments h > 0 it converges locally to a Nash equilibrium if all eigenvalues of the Jacobin of the associated gradient vector field have a negative real part."}, {"heading": "Gradient Ascent", "text": "(33) Then v \u2032 (x) = Hf (x) is the Hessen matrix of f at x. LetF (x) = x + h v (x). (34) A direct sequence of sentence 3 is sentence 10. Each fixed point of (34) is a stationary point of the gradient vector field v (x). Furthermore, if Hf (x) is defined negatively, the fixed point titeration for small h > 0.proofs is locally convergent to x. This results directly from sentence 3."}, {"heading": "Momentum", "text": "Let v (x) be a vector field. Using impulses, the operator F can be written as follows: asF (x, m) = 1 + hG (x, m) (35) with G (x, m) = (m, v (x) \u2212 \u03b3 m. The Jacobian of G is also given by G (x, m) = (0 Iv (x) \u2212 \u03b3I). (36) Lemma 11. \u03bb is an eigenvalue of G (x, m) if and only if it is an eigenvalue of v (x). Proof. Let (w1, w2) an eigenvector of G (x, m) as in (36) with the corresponding eigenvalue. Then\u03bbw1 = w2 (37) \u03bbw2 = v \u00b2 (x) w1 \u2212 own case, (38) show that the eigenvalue of v (38), the eigenvalue of w: eigenpoint of v (v), w1 = v \u00b2 (x) w1 = v \u00b2 Asw1 = 0."}, {"heading": "Gradient Rescaling", "text": "In this section, we examine the effects of gradient recalculation as used in ADAM and RMS Prop on local convergence, in particular, letF (x, \u03b2) = (x + h \u221a \u03b2 + v (x) (1 \u2212 \u03b1) \u03b2 + \u03b1 \u0445 v (x) 2) (40) is given for some \u03b1 > 0. The Jacobi approach of (40) is then given by F \"(x, \u03b2) = (I + h \u221a \u03b2 + v\" (x) \u2212 h 2 (\u03b2 +) 3 / 2 v (x) \u03b1 v \"(x) Tv (x) 1 \u2212 \u03b1). (41) Each fixed point (x, \u03b2) of (40) fulfills \u03b2 = 0 and v (x) = 0. Furthermore, we assume that these eigenvalues of I + h \u00b2 v \u00b2 (x \u00b2) are in the standard sphere."}, {"heading": "Alternating Gradient Ascent", "text": "Alternative Gradient Ascent (AltGA) uses gradient Ascent updates alternately for the two players (see Algorithm 3. For theoretical analysis, we generally consider fixed point methods that iteratively apply a function of formF (x) = F2 (F1 (x))) (43) to x. According to the chain rule, the Jacobian of F at x (x) = F \u2032 2 (F1 (x)))) is F \u2032 1 (x). (44) Let us now assume that F1 (x) = x + hG1 (x) and F2 (x) = x + hG2 (x). Then, if x \u00b2 is a fixed point of both F1 and F2, we have F \u2032 (x) = (I + hG \u00b2 2 (x)))) (I + hG1 (x \u00b2) = x \u00b2)."}, {"heading": "Additional Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "Towards principled methods for training generative adversarial networks", "author": ["Martin Arjovsky", "L\u00e9on Bottou"], "venue": "In NIPS 2016 Workshop on Adversarial Training. In review for ICLR,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2017}, {"title": "Generalization and equilibrium in generative adversarial nets (GANs)", "author": ["Sanjeev Arora", "Rong Ge", "Yingyu Liang", "Tengyu Ma", "Yi Zhang"], "venue": "arXiv preprint arXiv:1703.00573,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2017}, {"title": "Constrained optimization and Lagrange multiplier methods", "author": ["Dimitri P Bertsekas"], "venue": "Academic press,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Numerical methods for ordinary differential equations", "author": ["John Charles Butcher"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Adversarial feature learning", "author": ["Jeff Donahue", "Philipp Kr\u00e4henb\u00fchl", "Trevor Darrell"], "venue": "arXiv preprint arXiv:1605.09782,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Adversarially learned inference", "author": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "venue": "arXiv preprint arXiv:1606.00704,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Improved training of Wasserstein GANs", "author": ["Ishaan Gulrajani", "Faruk Ahmed", "Martin Arjovsky", "Vincent Dumoulin", "Aaron Courville"], "venue": "arXiv preprint arXiv:1704.00028,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2017}, {"title": "Image-to-image translation with conditional adversarial networks", "author": ["Phillip Isola", "Jun-Yan Zhu", "Tinghui Zhou", "Alexei A Efros"], "venue": "arXiv preprint arXiv:1611.07004,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Photorealistic single image super-resolution using a generative adversarial network", "author": ["Christian Ledig", "Lucas Theis", "Ferenc Husz\u00e1r", "Jose Caballero", "Andrew Cunningham", "Alejandro Acosta", "Andrew Aitken", "Alykhan Tejani", "Johannes Totz", "Zehan Wang"], "venue": "arXiv preprint arXiv:1609.04802,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Adversarial variational Bayes: Unifying variational autoencoders and generative adversarial networks", "author": ["Lars Mescheder", "Sebastian Nowozin", "Andreas Geiger"], "venue": "arXiv preprint arXiv:1701.04722,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2017}, {"title": "Unrolled generative adversarial networks", "author": ["Luke Metz", "Ben Poole", "David Pfau", "Jascha Sohl-Dickstein"], "venue": "arXiv preprint arXiv:1611.02163,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "f-GAN: Training generative neural samplers using variational divergence minimization", "author": ["Sebastian Nowozin", "Botond Cseke", "Ryota Tomioka"], "venue": "arXiv preprint arXiv:1606.00709,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Conditional image synthesis with auxiliary classifier GANs", "author": ["Augustus Odena", "Christopher Olah", "Jonathon Shlens"], "venue": "arXiv preprint arXiv:1610.09585,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Connecting generative adversarial networks and actor-critic methods", "author": ["David Pfau", "Oriol Vinyals"], "venue": "arXiv preprint arXiv:1610.01945,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Alec Radford", "Luke Metz", "Soumith Chintala"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Characterization and computation of local nash equilibria in continuous games", "author": ["Lillian J Ratliff", "Samuel A Burden", "S Shankar Sastry"], "venue": "In Communication, Control, and Computing (Allerton),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Improved techniques for training GANs", "author": ["Tim Salimans", "Ian Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Improved techniques for training", "author": ["Tim Salimans", "Ian J. Goodfellow", "Wojciech Zaremba", "Vicki Cheung", "Alec Radford", "Xi Chen"], "venue": "gans. CoRR,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Amortised map inference for image super-resolution", "author": ["Casper Kaae S\u00f8nderby", "Jose Caballero", "Lucas Theis", "Wenzhe Shi", "Ferenc Husz\u00e1r"], "venue": "arXiv preprint arXiv:1610.04490,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Adversarial discriminative domain adaptation", "author": ["Eric Tzeng", "Judy Hoffman", "Kate Saenko", "Trevor Darrell"], "venue": "arXiv preprint arXiv:1702.05464,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2017}], "referenceMentions": [{"referenceID": 6, "context": "Generative Adversarial Networks (GANs) [8] have been very successful in learning probability distributions.", "startOffset": 39, "endOffset": 42}, {"referenceID": 8, "context": "Since their first appearance, GANs have been successfully applied to a variety of tasks, including image-to-image translation [10], image super-resolution [11], image in-painting [23] domain adaptation [22], probabilistic inference [12, 7, 6] and many more.", "startOffset": 126, "endOffset": 130}, {"referenceID": 9, "context": "Since their first appearance, GANs have been successfully applied to a variety of tasks, including image-to-image translation [10], image super-resolution [11], image in-painting [23] domain adaptation [22], probabilistic inference [12, 7, 6] and many more.", "startOffset": 155, "endOffset": 159}, {"referenceID": 20, "context": "Since their first appearance, GANs have been successfully applied to a variety of tasks, including image-to-image translation [10], image super-resolution [11], image in-painting [23] domain adaptation [22], probabilistic inference [12, 7, 6] and many more.", "startOffset": 202, "endOffset": 206}, {"referenceID": 10, "context": "Since their first appearance, GANs have been successfully applied to a variety of tasks, including image-to-image translation [10], image super-resolution [11], image in-painting [23] domain adaptation [22], probabilistic inference [12, 7, 6] and many more.", "startOffset": 232, "endOffset": 242}, {"referenceID": 5, "context": "Since their first appearance, GANs have been successfully applied to a variety of tasks, including image-to-image translation [10], image super-resolution [11], image in-painting [23] domain adaptation [22], probabilistic inference [12, 7, 6] and many more.", "startOffset": 232, "endOffset": 242}, {"referenceID": 4, "context": "Since their first appearance, GANs have been successfully applied to a variety of tasks, including image-to-image translation [10], image super-resolution [11], image in-painting [23] domain adaptation [22], probabilistic inference [12, 7, 6] and many more.", "startOffset": 232, "endOffset": 242}, {"referenceID": 15, "context": "The standard strategy for stabilizing training is to carefully design the model, either by adapting the architecture [17] or by selecting an easy-to-optimize objective function [20, 2, 9].", "startOffset": 117, "endOffset": 121}, {"referenceID": 18, "context": "The standard strategy for stabilizing training is to carefully design the model, either by adapting the architecture [17] or by selecting an easy-to-optimize objective function [20, 2, 9].", "startOffset": 177, "endOffset": 187}, {"referenceID": 7, "context": "The standard strategy for stabilizing training is to carefully design the model, either by adapting the architecture [17] or by selecting an easy-to-optimize objective function [20, 2, 9].", "startOffset": 177, "endOffset": 187}, {"referenceID": 19, "context": "by adding instance noise [21] or by using the Wasserstein-divergence [2, 9]: while these strategies try to ensure the existence of Nash-equilibria, our paper deals with their computation and the numerical difficulties that can arise in practice.", "startOffset": 25, "endOffset": 29}, {"referenceID": 7, "context": "by adding instance noise [21] or by using the Wasserstein-divergence [2, 9]: while these strategies try to ensure the existence of Nash-equilibria, our paper deals with their computation and the numerical difficulties that can arise in practice.", "startOffset": 69, "endOffset": 75}, {"referenceID": 6, "context": "Most divergences that are used in practice can be represented in the following form [8, 14, 2]:", "startOffset": 84, "endOffset": 94}, {"referenceID": 12, "context": "Most divergences that are used in practice can be represented in the following form [8, 14, 2]:", "startOffset": 84, "endOffset": 94}, {"referenceID": 6, "context": "These divergences include the Jensen-Shannon divergence [8], all f-divergences [14], the Wasserstein divergence [2] and even the indicator divergence, which is 0 if p = q and\u221e otherwise.", "startOffset": 56, "endOffset": 59}, {"referenceID": 12, "context": "These divergences include the Jensen-Shannon divergence [8], all f-divergences [14], the Wasserstein divergence [2] and even the indicator divergence, which is 0 if p = q and\u221e otherwise.", "startOffset": 79, "endOffset": 83}, {"referenceID": 1, "context": "Therefore, some authors call these divergence functions neural network divergences [3].", "startOffset": 83, "endOffset": 86}, {"referenceID": 6, "context": "1 leads to a zero-sum game, whereas in practice people usually employ a variant of this formulation that is not a zero-sum game for better convergence [8].", "startOffset": 151, "endOffset": 154}, {"referenceID": 16, "context": "The de-facto standard algorithm for finding Nash-equilibria of general smooth two-player games is Simultaneous Gradient Ascent (SimGA), which was described in several works, for example in [18] and, more recently also in the context of GANs, in [14].", "startOffset": 189, "endOffset": 193}, {"referenceID": 12, "context": "The de-facto standard algorithm for finding Nash-equilibria of general smooth two-player games is Simultaneous Gradient Ascent (SimGA), which was described in several works, for example in [18] and, more recently also in the context of GANs, in [14].", "startOffset": 245, "endOffset": 249}, {"referenceID": 12, "context": "It can be shown that simultaneous gradient ascent converges locally to a Nash-equilibrium for a zero-sum-game, if the Hessian of both players is negative definite [14, 18] and the learning rate is small enough.", "startOffset": 163, "endOffset": 171}, {"referenceID": 16, "context": "It can be shown that simultaneous gradient ascent converges locally to a Nash-equilibrium for a zero-sum-game, if the Hessian of both players is negative definite [14, 18] and the learning rate is small enough.", "startOffset": 163, "endOffset": 171}, {"referenceID": 2, "context": "See [4], Proposition 4.", "startOffset": 4, "endOffset": 7}, {"referenceID": 11, "context": "While simplistic, algorithms training GANs often fail to converge even on such simple examples without extensive fine-tuning of the architecture and hyper parameters [13].", "startOffset": 166, "endOffset": 170}, {"referenceID": 6, "context": "We use a 64-dimensional Gaussian prior for the latent code z and set up the game between the generator and critic using the utility functions as in [8].", "startOffset": 148, "endOffset": 151}, {"referenceID": 15, "context": "(a) cifar-10 (b) celebA Figure 3: Samples generated from a model where both the generator and discriminator are given as in [17], but without batch-normalization.", "startOffset": 124, "endOffset": 128}, {"referenceID": 15, "context": "CIFAR-10 and CelebA In our second experiment, we apply our method to the cifar-10 and celebAdatasets, using a DC-GAN-like architecture [17] without batch normalization in the generator or the discriminator.", "startOffset": 135, "endOffset": 139}, {"referenceID": 15, "context": "These architectures are known to be hard to optimize using simultaneous (or alternating) gradient ascent [17, 2].", "startOffset": 105, "endOffset": 112}, {"referenceID": 17, "context": "For a quantitative evaluation, we also measured the inception-score [19] over time (Figure 4c), showing that our method compares favorably to a DC-GAN trained with alternating gradient ascent.", "startOffset": 68, "endOffset": 72}, {"referenceID": 0, "context": "When we are trying to minimize an f-divergence and the dimensionality of the generator distribution is misspecified, this might not be the case [1].", "startOffset": 144, "endOffset": 147}, {"referenceID": 3, "context": "It can be shown that the implicit Euler method has appealing stability properties [5] that can be translated into convergence theorems for local Nash-equilibria.", "startOffset": 82, "endOffset": 85}, {"referenceID": 14, "context": "For example, the popular actor-critic models [16] in reinforcement learning are also special cases of saddle-point problems.", "startOffset": 45, "endOffset": 49}, {"referenceID": 11, "context": "Unrolled GANs [13] unroll the optimization with respect to the critic, thereby giving the generator more informative gradients.", "startOffset": 14, "endOffset": 18}, {"referenceID": 7, "context": "As was recently shown, the stability of GAN-training can be improved by using objectives derived from the Wasserstein-1-distance (induced by the Kantorovich-Rubinstein-norm) instead of f-divergences [2, 9].", "startOffset": 199, "endOffset": 205}, {"referenceID": 10, "context": "Moreover, some methods like Adversarial Variational Bayes [12] explicitly prescribe the divergence measure to be used, thus making it impossible to apply Wasserstein-GANs.", "startOffset": 58, "endOffset": 62}, {"referenceID": 17, "context": "Other approaches that try to stabilize training, try to design an easy-to-optimize architecture [19, 17] or make use of additional labels [19, 15].", "startOffset": 96, "endOffset": 104}, {"referenceID": 15, "context": "Other approaches that try to stabilize training, try to design an easy-to-optimize architecture [19, 17] or make use of additional labels [19, 15].", "startOffset": 96, "endOffset": 104}, {"referenceID": 17, "context": "Other approaches that try to stabilize training, try to design an easy-to-optimize architecture [19, 17] or make use of additional labels [19, 15].", "startOffset": 138, "endOffset": 146}, {"referenceID": 13, "context": "Other approaches that try to stabilize training, try to design an easy-to-optimize architecture [19, 17] or make use of additional labels [19, 15].", "startOffset": 138, "endOffset": 146}], "year": 2017, "abstractText": "In this paper, we analyze the numerics of common algorithms for training Generative Adversarial Networks (GANs). Using the formalism of smooth two-player games we analyze the associated gradient vector field of GAN training objectives. Our findings suggest that the convergence of current algorithms suffers due to two factors: i) presence of eigenvalues of the Jacobian of the gradient vector field with zero real-part, and ii) eigenvalues with big imaginary part. Using these findings, we design a new algorithm that overcomes some of these limitations and has better convergence properties. Experimentally, we demonstrate its superiority on training common GAN architectures and show convergence on GAN architectures that are known to be notoriously hard to train.", "creator": "LaTeX with hyperref package"}}}