{"id": "1706.00374", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2017", "title": "Semantic Specialisation of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints", "abstract": "We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialised cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct high-quality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource ones. The effectiveness of our approach is demonstrated with state-of-the-art results on semantic similarity datasets in six languages. We next show that Attract-Repel-specialised vectors boost performance in the downstream task of dialogue state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our algorithm facilitate the training of multilingual DST models, which brings further performance improvements.", "histories": [["v1", "Thu, 1 Jun 2017 16:29:47 GMT  (71kb,D)", "http://arxiv.org/abs/1706.00374v1", "Accepted for publication at TACL (to be presented at EMNLP 2017)"]], "COMMENTS": "Accepted for publication at TACL (to be presented at EMNLP 2017)", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG", "authors": ["nikola mrk\\v{s}i\\'c", "ivan vuli\\'c", "diarmuid \\'o s\\'eaghdha", "ira leviant", "roi reichart", "milica ga\\v{s}i\\'c", "anna korhonen", "steve young"], "accepted": true, "id": "1706.00374"}, "pdf": {"name": "1706.00374.pdf", "metadata": {"source": "CRF", "title": "Semantic Specialisation of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints", "authors": ["Nikola Mrk\u0161i\u0107", "Ivan Vuli\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Ira Leviant", "Roi Reichart", "Milica Ga\u0161i\u0107", "Anna Korhonen", "Steve Young"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, it is such that we are able to move to another world, in which we move to another world, in which we move to another world, in which we move to another world, in which we move to another world, in which we move to another world, in which we move to another world, in which we live to another world, in which we move to another world, in which we move to another world, in which we move to another world, in which we move to another world, in which we move to another world, in which we move to another world, in which we move to another world, in which we move to live to another world, in which we move to live, in which we move to live, in which we move to live, in which we move to live, in which we move, in which we move, in which we move, in which we live, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, in which we move, we move, in which we move, in which we move, we move, in which we move, we move, in which we move, we move, in which we move, in which we move, in which we move, we move, in which we move, in which we move, in which we move, in which we move, we move, in which we move, we move, in which we move, we move, in which we move, in which we move, we move, we move, we move, in which we move, we move, we move, in which we move, in which we move, in which we move, in which we move, we move, we move, in which we move, in which we move, we move, we move, we move, in which we move, in which we move, we move, in which we move, in which we move, in which we move, we move, we move, we"}, {"heading": "2 Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Semantic Specialisation", "text": "The usefulness of distributed word representations has been demonstrated in many fields of application: part-of-speech (POS) et al., 2015), machine translation (Zou et al., 2013; Devlin et al., 2014), dependence and semantic analysis (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), designated entity recognition (Turian et al., 2010; Guo et al., 2014), and many others. The importance of semantic specialization for downstream tasks is relatively unexplored, with previously observed improvements in performance for dialogue tracking (Mrk\u0161ic)."}, {"heading": "2.2 Cross-Lingual Word Representations", "text": "Most existing models that generate cross-language word representations rely on cross-language distribution information (Klementiev et al., 2012; Zou et al., 2013; Soyer et al., 2015; Huang et al., 2015 and others), but these models differ in the cross-language signal / supervision functions they use to incorporate languages into uniform bilingual vector spaces: some models learn on the basis of parallel word-oriented data (Luong et al., 2015; Coulmance et al., 2015) or sentencealigned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015; Rastouws et al.); others require documented data (S\u00f8gaard et al., 2015; Vulic \u2012 and Moens, 2016)."}, {"heading": "3 The ATTRACT-REPEL Model", "text": "In this section, we will propose a new algorithm for generating semantically specialized pairs of words, in which we will compare the individual pairs of words of the individual pairs of words and pairs of the individual pairs of words. (...) We will compare the individual pairs of words of the individual pairs of words in terms of their ability to detect semantic similarities (...) Let us correspond the vocabulary, S the number of synonymous pairs of words (e.g. intelligent and brilliant), and A the pairs of words of the individual pairs of words (xl, xr) in these two pairs of sentences (xl, xr). The optimization procedures operate via mini-batches B in which each of these pairs of words forms a series of synonymous pairs of words."}, {"heading": "4 Experimental Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Distributional Vectors", "text": "First, we present our sixteen experimental languages: English (EN), German (DE), Italian (IT), Russian (RU), Dutch (NL), Swedish (SV), French (FR), Spanish (ES), Portuguese (PT), Polish (PL), Bulgarian (BG), Croatian (HR), Irish (GA), Persian (FA) and Vietnamese (VI). The first four languages are those of the multilingual SimLex 999 datasets. For the four SimLex languages, we use four well-known, high-quality word vectors: a) The Common Crawl GloVe English Vectors from Pennington et al. (2014); b) German Vectors from Vulic 'and Korhonen (2016a); c) Italian Vectors from Dinu et al al. (2015); and d) Russian Vectors from Kutuzov and Andreev (2015)."}, {"heading": "4.2 Linguistic Constraints", "text": "In fact, it is the case that most people are in a position to understand themselves, as if they see themselves in a position to surpass themselves, as if they see themselves in a position to surpass themselves, as if they saw themselves in a position to surpass themselves, as if they saw themselves in a position to surpass themselves, as if they saw themselves in a position to surpass themselves, as if they saw themselves in a position to surpass themselves, as if they saw themselves in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves, as if they were in a position to surpass themselves as if they surpass themselves, as if they surpass themselves as if they were in a thing, as if they surpass themselves, as if they surpass themselves, as if they surpass themselves as if they surpass themselves what they surpass themselves, as if they surpass themselves, as if they surpass themselves, as if they surpass themselves what they surpass themselves, as if they surpass themselves, if they surpass themselves as if they surpass themselves, as if they surpass themselves as if they surpass themselves, what they surpass themselves, as if they surpass themselves, what they surpass themselves, as if they surpass themselves, as if they surpass themselves, as if they surpass themselves"}, {"heading": "5 Intrinsic Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Datasets", "text": "Unlike other gold standard resources such as WordSim-353 (Finkelstein et al., 2002) or MEN (Bruni et al., 2014), SimLex-999 consists of pairs of words rated by commentators who are instructed to distinguish between semantic similarity and conceptual association, so that related but not similar words (e.g. book and reading) have a low rating. Leviant and Reichart (2015) translated SimLex999 into German, Italian, and Russian by crowdsourcing the similarity scores of native speakers of these languages. We use this resource for multilingual intrinsic ratings. To investigate the portability of our approach to lower-resource languages, we used the same experimental setup to collect SimLex999 data sets for Hebrew and Croatian."}, {"heading": "5.2 Experiments", "text": "We start with distribution vectors for the SimLex languages: English, German, Italian and Russian. For each language, we first perform semantic specialization of these spaces using: a) monolingual synonyms; b) monolingual antonyms; and c) the combination of the two. We then add cross-language synonyms and antonyms to these constraints and form a common four-language vector space for these languages. Compared to baseline methods, both monolingual and cross-language specializations have been performed using ATTRACT-REPEL and interlocutors to conclude which of the two methods has shown superior performance. Retrofitting and PARAGRAM methods only inject synonymically, and their cost functions can be expressed using sub-components of 8Leviant and Reichart (2015)."}, {"heading": "5.3 Results and Discussion", "text": "This results in very strong improvements in SimLex performance in all languages. However, translingual specialization brings further improvements, with all languages benefiting from the sharing of translingual vector space. Italy in particular shows strong evidence of effective transfer, with Italian vector systems applied close to the highest performing English. Compared to Baseline's Table 3, an exhaustive comparison of ATTRACT-REPEL to counterproductive languages is provided: ATTRACT-REPEL achieves significantly stronger performance in all languages. We believe that these results conclusively show that the finegrained updates and L2 regulation of ATTRACT-REPEL are a better alternative to the context-sensitive attractions and paired regulations applied."}, {"heading": "6 Downstream Task Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Dialogue State Tracking", "text": "The idea behind it is that it is a way in which people are able to put themselves in the world in which they want to move. (...) The idea behind it is not new. (...) The idea behind it is not new. (...) The idea behind it is not new. (...) The idea behind it is not new. (...) The idea behind it is not new. (...) The idea behind it is not new. (...) The idea behind it is not new. (...) The idea behind it is not new. (...) The idea behind it is not new. (...) The idea behind it is to have the idea behind it. \"(...) The idea behind it is behind it, the idea behind it is. (...) The idea behind it is behind it.\" (...) The idea behind it is behind it. \"(...) The idea behind it is behind it. (...) The idea behind it is behind it. (...) The idea behind it is behind it."}, {"heading": "6.2 DST Experiments", "text": "The most important evaluation metric in our DST experiments is common target accuracy, representing all domains.13 There are two variants of the NBT model: NBT-DNN and NBT-CNN. In this work, we limit our investigation to the latter, as they consistently achieve stronger DST performance.13 The proportion of test sentence dialogs turns to where all search constraints expressed up to this point in the conversation have been correctly decoded. Our DST experiments examine two suggestions: 1. Intrinsic vs. downstream evaluation If semantic specialization improves the semantic content of word vector collections according to intrinsic evaluation, we would expect the NBT model to perform high-quality faith tracking when using such improved vectors. We investigate the difference in DST performance for English, German and Italian when the NBT model uses the following word vector collections."}, {"heading": "6.3 Results and Discussion", "text": "The first five lines show the performance when the model uses the five base rector spaces. The following three lines show the performance of the multilingual DST model, which was trained using ontology grounding, combining training data from all three languages and using it to form an improved model. Figure 2 examines the usefulness of ontology grounding for bootstrapping DST models with less data: The two numbers show the performance of models trained with different proportions of the in-language training datasets. The top-performance dotted curves show the usefulness of ontology grounding of DST models for new languages with less data. The results in Table 8 show that both types of specializations were achieved over five years."}, {"heading": "7 Conclusion", "text": "We have presented a novel ATTRACT-REPEL method for injecting linguistic constraints into word vector space representations, specializing word vectors semantically by jointly injecting mono- and cross-language synonyms and antonymic constraints, creating unified lingual vector spaces that achieve state-of-the-art performance on the established SimLex 999 dataset and its multilingual variants. Next, we have shown that ATTRACTREPEL can induce high-quality vectors for low-resource languages by binding them into bilingual vector spaces with high resources. Finally, we have shown that the significant gains in intrinsic evaluation translate into gains in the downstream task of Dialog State Tracking (DST), for which we release two novel non-English datasets (in German and Italian)."}, {"heading": "7.1 Further Work", "text": "Our results, especially with regard to summertime, highlight the need to improve vector space models for morphologically rich languages. In addition, our intrinsic and task-based experiments have highlighted the discrepancies between the conclusions that can be drawn from these two types of evaluation."}, {"heading": "Acknowledgements", "text": "The authors would like to thank Anders Johannsen for his help in extracting BabelNet restrictions and our action editor Sebastian Pad\u00f3 and the anonymous TACL reviewers for their constructive feedback. Ivan Vulic, Roi Reichart and Anna Korhonen are supported by the ERC Consolidator Grant LEXICAL (number 648909). Roi Reichart is also supported by the Intel-ICRI Scholarship: Hybrid Models for Minimally Supervised Information Extraction from Conversations."}], "references": [{"title": "A hybrid distributional and knowledge-based model of lexical semantics", "author": ["Nikolaos Aletras", "Mark Stevenson."], "venue": "Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics, *SEM, pages 20\u201329.", "citeRegEx": "Aletras and Stevenson.,? 2015", "shortCiteRegEx": "Aletras and Stevenson.", "year": 2015}, {"title": "Many languages, one parser", "author": ["Waleed Ammar", "George Mulcaire", "Miguel Ballesteros", "Chris Dyer", "Noah Smith."], "venue": "Transactions of the ACL, 4:431\u2013444.", "citeRegEx": "Ammar et al\\.,? 2016", "shortCiteRegEx": "Ammar et al\\.", "year": 2016}, {"title": "The Berkeley FrameNet project", "author": ["Collin F. Baker", "Charles J. Fillmore", "John B. Lowe."], "venue": "Proceedings of ACL, pages 86\u201390.", "citeRegEx": "Baker et al\\.,? 1998", "shortCiteRegEx": "Baker et al\\.", "year": 1998}, {"title": "Tailoring continuous word representations for dependency parsing", "author": ["Mohit Bansal", "Kevin Gimpel", "Karen Livescu."], "venue": "Proceedings of ACL, pages 809\u2013815.", "citeRegEx": "Bansal et al\\.,? 2014", "shortCiteRegEx": "Bansal et al\\.", "year": 2014}, {"title": "Representation learning: A review and new perspectives", "author": ["Yoshua Bengio", "Aaron C. Courville", "Pascal Vincent."], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8):1798\u20131828.", "citeRegEx": "Bengio et al\\.,? 2013", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Knowledgepowered deep learning for word embedding", "author": ["Jiang Bian", "Bin Gao", "Tie-Yan Liu."], "venue": "Proceedings of ECML-PKDD, pages 132\u2013148.", "citeRegEx": "Bian et al\\.,? 2014", "shortCiteRegEx": "Bian et al\\.", "year": 2014}, {"title": "Multimodal distributional semantics", "author": ["Elia Bruni", "Nam-Khanh Tran", "Marco Baroni."], "venue": "Journal of Artificial Intelligence Research, 49:1\u201347.", "citeRegEx": "Bruni et al\\.,? 2014", "shortCiteRegEx": "Bruni et al\\.", "year": 2014}, {"title": "An autoencoder approach to learning bilingual word representations", "author": ["Sarath A.P. Chandar", "Stanislas Lauly", "Hugo Larochelle", "Mitesh M. Khapra", "Balaraman Ravindran", "Vikas C. Raykar", "Amrita Saha."], "venue": "Proceedings of NIPS, pages 1853\u20131861.", "citeRegEx": "Chandar et al\\.,? 2014", "shortCiteRegEx": "Chandar et al\\.", "year": 2014}, {"title": "A fast and accurate dependency parser using neural networks", "author": ["Danqi Chen", "Christopher D. Manning."], "venue": "Proceedings of EMNLP, pages 740\u2013750.", "citeRegEx": "Chen and Manning.,? 2014", "shortCiteRegEx": "Chen and Manning.", "year": 2014}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "Leon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research, 12:2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Trans-gram, fast crosslingual word embeddings", "author": ["Jocelyn Coulmance", "Jean-Marc Marty", "Guillaume Wenzek", "Amine Benhalloum."], "venue": "Proceedings of EMNLP, pages 1109\u20131113.", "citeRegEx": "Coulmance et al\\.,? 2015", "shortCiteRegEx": "Coulmance et al\\.", "year": 2015}, {"title": "Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words", "author": ["Dmitry Davidov", "Ari Rappoport."], "venue": "Proceedings of ACL, pages 297\u2013304.", "citeRegEx": "Davidov and Rappoport.,? 2006", "shortCiteRegEx": "Davidov and Rappoport.", "year": 2006}, {"title": "Fast and robust neural network joint models for statistical machine translation", "author": ["Jacob Devlin", "Rabih Zbib", "Zhongqiang Huang", "Thomas Lamar", "Richard M. Schwartz", "John Makhoul."], "venue": "Proceedings of ACL, pages 1370\u20131380.", "citeRegEx": "Devlin et al\\.,? 2014", "shortCiteRegEx": "Devlin et al\\.", "year": 2014}, {"title": "Eigenwords: Spectral word embeddings", "author": ["Paramveer S. Dhillon", "Dean P. Foster", "Lyle H. Ungar."], "venue": "Journal of Machine Learning Research, 16:3035\u20133078.", "citeRegEx": "Dhillon et al\\.,? 2015", "shortCiteRegEx": "Dhillon et al\\.", "year": 2015}, {"title": "Improving zero-shot learning by mitigating the hubness problem", "author": ["Georgiana Dinu", "Angeliki Lazaridou", "Marco Baroni."], "venue": "Proceedings of ICLR: Workshop Papers.", "citeRegEx": "Dinu et al\\.,? 2015", "shortCiteRegEx": "Dinu et al\\.", "year": 2015}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John C. Duchi", "Elad Hazan", "Yoram Singer."], "venue": "Journal of Machine Learning Research, 12:2121\u20132159.", "citeRegEx": "Duchi et al\\.,? 2011", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Learning crosslingual word embeddings without bilingual corpora", "author": ["Long Duong", "Hiroshi Kanayama", "Tengfei Ma", "Steven Bird", "Trevor Cohn."], "venue": "Proceedings of EMNLP, pages 1285\u20131295.", "citeRegEx": "Duong et al\\.,? 2016", "shortCiteRegEx": "Duong et al\\.", "year": 2016}, {"title": "Representing multilingual data as linked data: The case of BabelNet 2.0", "author": ["Maud Ehrmann", "Francesco Cecconi", "Daniele Vannella", "John Philip Mccrae", "Philipp Cimiano", "Roberto Navigli"], "venue": "In Proceedings of LREC,", "citeRegEx": "Ehrmann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ehrmann et al\\.", "year": 2014}, {"title": "Improving vector space word representations using multilingual correlation", "author": ["Manaal Faruqui", "Chris Dyer."], "venue": "Proceedings of EACL, pages 462\u2013471.", "citeRegEx": "Faruqui and Dyer.,? 2014", "shortCiteRegEx": "Faruqui and Dyer.", "year": 2014}, {"title": "Non-distributional word vector representations", "author": ["Manaal Faruqui", "Chris Dyer."], "venue": "Proceedings of ACL, pages 464\u2013469.", "citeRegEx": "Faruqui and Dyer.,? 2015", "shortCiteRegEx": "Faruqui and Dyer.", "year": 2015}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Manaal Faruqui", "Jesse Dodge", "Sujay K. Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A. Smith."], "venue": "Proceedings of NAACL, pages 1606\u20131615.", "citeRegEx": "Faruqui et al\\.,? 2015", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "Placing search in context: The concept revisited", "author": ["Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin."], "venue": "ACM Transactions on Information Systems, 20(1):116\u2013 131.", "citeRegEx": "Finkelstein et al\\.,? 2002", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2002}, {"title": "Simulating speech systems", "author": ["Norman M. Fraser", "G. Nigel Gilbert."], "venue": "Computer Speech and Language, 5(1):81\u201399.", "citeRegEx": "Fraser and Gilbert.,? 1991", "shortCiteRegEx": "Fraser and Gilbert.", "year": 1991}, {"title": "The Multilingual Paraphrase Database", "author": ["Juri Ganitkevitch", "Chris Callison-Burch."], "venue": "Proceedings of LREC, pages 4276\u20134283.", "citeRegEx": "Ganitkevitch and Callison.Burch.,? 2014", "shortCiteRegEx": "Ganitkevitch and Callison.Burch.", "year": 2014}, {"title": "PPDB: The Paraphrase Database", "author": ["Juri Ganitkevitch", "Benjamin Van Durme", "Chris Callison-burch."], "venue": "Proceedings of NAACL, pages 758\u2013764.", "citeRegEx": "Ganitkevitch et al\\.,? 2013", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2013}, {"title": "SimVerb-3500: A large-scale evaluation set of verb similarity", "author": ["Daniela Gerz", "Ivan Vuli\u0107", "Felix Hill", "Roi Reichart", "Anna Korhonen."], "venue": "Proceedings of EMNLP, pages 2173\u20132182.", "citeRegEx": "Gerz et al\\.,? 2016", "shortCiteRegEx": "Gerz et al\\.", "year": 2016}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["Xavier Glorot", "Yoshua Bengio."], "venue": "Proceedings of AISTATS, pages 249\u2013256.", "citeRegEx": "Glorot and Bengio.,? 2010", "shortCiteRegEx": "Glorot and Bengio.", "year": 2010}, {"title": "A primer on neural network models for natural language processing", "author": ["Yoav Goldberg."], "venue": "CoRR, abs/1510.00726.", "citeRegEx": "Goldberg.,? 2015", "shortCiteRegEx": "Goldberg.", "year": 2015}, {"title": "BilBOWA: Fast bilingual distributed representations without word alignments", "author": ["Stephan Gouws", "Yoshua Bengio", "Greg Corrado."], "venue": "Proceedings of ICML, pages 748\u2013756.", "citeRegEx": "Gouws et al\\.,? 2015", "shortCiteRegEx": "Gouws et al\\.", "year": 2015}, {"title": "Revisiting embedding features for simple semisupervised learning", "author": ["Jiang Guo", "Wanxiang Che", "Haifeng Wang", "Ting Liu."], "venue": "Proceedings of EMNLP, pages 110\u2013120.", "citeRegEx": "Guo et al\\.,? 2014", "shortCiteRegEx": "Guo et al\\.", "year": 2014}, {"title": "Cross-lingual dependency parsing based on distributed representations", "author": ["Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu."], "venue": "Proceedings of ACL, pages 1234\u20131244.", "citeRegEx": "Guo et al\\.,? 2015", "shortCiteRegEx": "Guo et al\\.", "year": 2015}, {"title": "The Second Dialog State Tracking Challenge", "author": ["Matthew Henderson", "Blaise Thomson", "Jason D. Wiliams."], "venue": "Proceedings of SIGDIAL, pages 263\u2013272.", "citeRegEx": "Henderson et al\\.,? 2014a", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "Robust dialog state tracking using delexicalised recurrent neural networks and unsupervised adaptation", "author": ["Matthew Henderson", "Blaise Thomson", "Steve Young."], "venue": "Proceedings of IEEE SLT, pages 360\u2013365.", "citeRegEx": "Henderson et al\\.,? 2014b", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "Word-based dialog state tracking with recurrent neural networks", "author": ["Matthew Henderson", "Blaise Thomson", "Steve Young."], "venue": "Proceedings of SIGDIAL, pages 292\u2013299.", "citeRegEx": "Henderson et al\\.,? 2014c", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "Multilingual Distributed Representations without Word Alignment", "author": ["Karl Moritz Hermann", "Phil Blunsom."], "venue": "Proceedings of ICLR.", "citeRegEx": "Hermann and Blunsom.,? 2014a", "shortCiteRegEx": "Hermann and Blunsom.", "year": 2014}, {"title": "Multilingual models for compositional distributed semantics", "author": ["Karl Moritz Hermann", "Phil Blunsom."], "venue": "Proceedings of ACL, pages 58\u201368.", "citeRegEx": "Hermann and Blunsom.,? 2014b", "shortCiteRegEx": "Hermann and Blunsom.", "year": 2014}, {"title": "SimLex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Felix Hill", "Roi Reichart", "Anna Korhonen."], "venue": "Computational Linguistics, 41(4):665\u2013695.", "citeRegEx": "Hill et al\\.,? 2015", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Translation invariant word embeddings", "author": ["Kejun Huang", "Matt Gardner", "Evangelos Papalexakis", "Christos Faloutsos", "Nikos Sidiropoulos", "Tom Mitchell", "Partha P. Talukdar", "Xiao Fu."], "venue": "Proceedings of EMNLP, pages 1084\u20131088.", "citeRegEx": "Huang et al\\.,? 2015", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "A Neural Network for Factoid Question Answering over Paragraphs", "author": ["Mohit Iyyer", "Jordan Boyd-Graber", "Leonardo Claudino", "Richard Socher", "Hal Daum\u00e9 III."], "venue": "Proceedings of EMLNP, pages 633\u2013644.", "citeRegEx": "Iyyer et al\\.,? 2014", "shortCiteRegEx": "Iyyer et al\\.", "year": 2014}, {"title": "Ontologically grounded multi-sense representation learning for semantic vector space models", "author": ["Sujay Kumar Jauhar", "Chris Dyer", "Eduard H. Hovy."], "venue": "Proceedings of NAACL, pages 683\u2013693.", "citeRegEx": "Jauhar et al\\.,? 2015", "shortCiteRegEx": "Jauhar et al\\.", "year": 2015}, {"title": "Any-language frame-semantic parsing", "author": ["Anders Johannsen", "H\u00e9ctor Mart\u00ednez Alonso", "Anders S\u00f8gaard."], "venue": "Proceedings of EMNLP, pages 2062\u20132066.", "citeRegEx": "Johannsen et al\\.,? 2015", "shortCiteRegEx": "Johannsen et al\\.", "year": 2015}, {"title": "Specializing word embeddings for similarity or relatedness", "author": ["Douwe Kiela", "Felix Hill", "Stephen Clark."], "venue": "Proceedings of EMNLP, pages 2044\u20132048.", "citeRegEx": "Kiela et al\\.,? 2015", "shortCiteRegEx": "Kiela et al\\.", "year": 2015}, {"title": "Adjusting word embeddings with semantic intensity orders", "author": ["Joo-Kyung Kim", "Marie-Catherine de Marneffe", "Eric Fosler-Lussier."], "venue": "Proceedings of the 1st Workshop on Representation Learning for NLP, pages 62\u201369.", "citeRegEx": "Kim et al\\.,? 2016a", "shortCiteRegEx": "Kim et al\\.", "year": 2016}, {"title": "Intent detection using semantically enriched word embeddings", "author": ["Joo-Kyung Kim", "Gokhan Tur", "Asli Celikyilmaz", "Bin Cao", "Ye-Yi Wang."], "venue": "Proceedings of SLT.", "citeRegEx": "Kim et al\\.,? 2016b", "shortCiteRegEx": "Kim et al\\.", "year": 2016}, {"title": "Inducing crosslingual distributed representations of words", "author": ["Alexandre Klementiev", "Ivan Titov", "Binod Bhattarai."], "venue": "Proceedings COLING, pages 1459\u20131474.", "citeRegEx": "Klementiev et al\\.,? 2012", "shortCiteRegEx": "Klementiev et al\\.", "year": 2012}, {"title": "Europarl: A parallel corpus for statistical machine translation", "author": ["Philipp Koehn."], "venue": "MT summit, volume", "citeRegEx": "Koehn.,? 2005", "shortCiteRegEx": "Koehn.", "year": 2005}, {"title": "Texts in, meaning out: neural language models in semantic similarity task for Russian", "author": ["Andrey Kutuzov", "Igor Andreev."], "venue": "Proceedings of DIALOG.", "citeRegEx": "Kutuzov and Andreev.,? 2015", "shortCiteRegEx": "Kutuzov and Andreev.", "year": 2015}, {"title": "Hubness and pollution: Delving into cross-space mapping for zero-shot learning", "author": ["Angeliki Lazaridou", "Georgiana Dinu", "Marco Baroni."], "venue": "Proceedings of ACL, pages 270\u2013280.", "citeRegEx": "Lazaridou et al\\.,? 2015", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2015}, {"title": "Separated by an Un-common Language: Towards Judgment Language Informed Vector Space Modeling", "author": ["Ira Leviant", "Roi Reichart."], "venue": "arXiv preprint: 1508.00106.", "citeRegEx": "Leviant and Reichart.,? 2015", "shortCiteRegEx": "Leviant and Reichart.", "year": 2015}, {"title": "Dependency-based word embeddings", "author": ["Omer Levy", "Yoav Goldberg."], "venue": "Proceedings of ACL, pages 302\u2013 308.", "citeRegEx": "Levy and Goldberg.,? 2014", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "Learning semantic word embeddings based on ordinal knowledge constraints", "author": ["Quan Liu", "Hui Jiang", "Si Wei", "Zhen-Hua Ling", "Yu Hu."], "venue": "Proceedings of ACL, pages 1501\u20131511.", "citeRegEx": "Liu et al\\.,? 2015", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Bilingual word representations with monolingual quality in mind", "author": ["Thang Luong", "Hieu Pham", "Christopher D. Manning."], "venue": "Proceedings of the 1st Workshop on Vector Space Modeling for NLP, pages 151\u2013159.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Tomas Mikolov", "Quoc V. Le", "Ilya Sutskever."], "venue": "arXiv preprint, CoRR, abs/1309.4168.", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Gregory S. Corrado", "Jeffrey Dean."], "venue": "Proceedings of NIPS, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "WordNet: A lexical database for English", "author": ["George A. Miller."], "venue": "Communications of the ACM, pages 39\u201341.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "A dual embedding space model for document ranking", "author": ["Bhaskar Mitra", "Eric T. Nalisnick", "Nick Craswell", "Rich Caruana."], "venue": "CoRR, abs/1602.01137.", "citeRegEx": "Mitra et al\\.,? 2016", "shortCiteRegEx": "Mitra et al\\.", "year": 2016}, {"title": "Multi-domain dialog state tracking using recurrent neural networks", "author": ["Nikola Mrk\u0161i\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Blaise Thomson", "Milica Ga\u0161i\u0107", "Pei-Hao Su", "David Vandyke", "TsungHsien Wen", "Steve Young."], "venue": "Proceedings of ACL, pages 794\u2013799.", "citeRegEx": "Mrk\u0161i\u0107 et al\\.,? 2015", "shortCiteRegEx": "Mrk\u0161i\u0107 et al\\.", "year": 2015}, {"title": "Counter-fitting word vectors to linguistic constraints", "author": ["Nikola Mrk\u0161i\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Blaise Thomson", "Milica Ga\u0161i\u0107", "Lina Rojas-Barahona", "Pei-Hao Su", "David Vandyke", "Tsung-Hsien Wen", "Steve Young."], "venue": "Proceedings of NAACL, pages 142\u2013148.", "citeRegEx": "Mrk\u0161i\u0107 et al\\.,? 2016", "shortCiteRegEx": "Mrk\u0161i\u0107 et al\\.", "year": 2016}, {"title": "Neural Belief Tracker: Data-driven dialogue state tracking", "author": ["Nikola Mrk\u0161i\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Blaise Thomson", "Tsung-Hsien Wen", "Steve Young."], "venue": "Proceedings of ACL.", "citeRegEx": "Mrk\u0161i\u0107 et al\\.,? 2017", "shortCiteRegEx": "Mrk\u0161i\u0107 et al\\.", "year": 2017}, {"title": "BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network", "author": ["Roberto Navigli", "Simone Paolo Ponzetto."], "venue": "Artificial Intelligence, 193:217\u2013250.", "citeRegEx": "Navigli and Ponzetto.,? 2012", "shortCiteRegEx": "Navigli and Ponzetto.", "year": 2012}, {"title": "Integrating distributional lexical contrast into word embeddings for antonymsynonym distinction", "author": ["Kim Anh Nguyen", "Sabine Schulte im Walde", "Ngoc Thang Vu."], "venue": "Proceedings of ACL, pages 454\u2013459.", "citeRegEx": "Nguyen et al\\.,? 2016", "shortCiteRegEx": "Nguyen et al\\.", "year": 2016}, {"title": "Word Embedding-based Antonym Detection using Thesauri and Distributional Information", "author": ["Masataka Ono", "Makoto Miwa", "Yutaka Sasaki."], "venue": "Proceedings of NAACL, pages 984\u2013989.", "citeRegEx": "Ono et al\\.,? 2015", "shortCiteRegEx": "Ono et al\\.", "year": 2015}, {"title": "Encoding prior knowledge with eigenword embeddings", "author": ["Dominique Osborne", "Shashi Narayan", "Shay Cohen."], "venue": "Transactions of the ACL, 4:417\u2013430.", "citeRegEx": "Osborne et al\\.,? 2016", "shortCiteRegEx": "Osborne et al\\.", "year": 2016}, {"title": "Probabilistic distributional semantics", "author": ["Diarmuid \u00d3 S\u00e9aghdha", "Anna Korhonen."], "venue": "Computational Linguistics, 40(3):587\u2013631.", "citeRegEx": "S\u00e9aghdha and Korhonen.,? 2014", "shortCiteRegEx": "S\u00e9aghdha and Korhonen.", "year": 2014}, {"title": "PPDB 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification", "author": ["Ellie Pavlick", "Pushpendre Rastogi", "Juri Ganitkevich", "Benjamin Van Durme", "Chris Callison-Burch"], "venue": "In Proceedings of ACL,", "citeRegEx": "Pavlick et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pavlick et al\\.", "year": 2015}, {"title": "GloVe: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning."], "venue": "Proceedings of EMNLP, pages 1532\u20131543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Multiview LSA: Representation learning via generalized CCA", "author": ["Pushpendre Rastogi", "Benjamin Van Durme", "Raman Arora."], "venue": "Proceedings of NAACL, pages 556\u2013566.", "citeRegEx": "Rastogi et al\\.,? 2015", "shortCiteRegEx": "Rastogi et al\\.", "year": 2015}, {"title": "Measuring Semantic Similarity of Words Using Concept Networks", "author": ["G\u00e1bor Recski", "Eszter Ikl\u00f3di", "Katalin Pajkossy", "Andras Kornai."], "venue": "Proceedings of the 1st Workshop on Representation Learning for NLP, pages 193\u2013200.", "citeRegEx": "Recski et al\\.,? 2016", "shortCiteRegEx": "Recski et al\\.", "year": 2016}, {"title": "Reasoning about Entailment with Neural Attention", "author": ["Tim Rockt\u00e4schel", "Edward Grefenstette", "Karl Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u00fd", "Phil Blunsom."], "venue": "Proceedings of ICLR.", "citeRegEx": "Rockt\u00e4schel et al\\.,? 2016", "shortCiteRegEx": "Rockt\u00e4schel et al\\.", "year": 2016}, {"title": "AutoExtend: Extending word embeddings to embeddings for synsets and lexemes", "author": ["Sascha Rothe", "Hinrich Sch\u00fctze."], "venue": "Proceedings of ACL, pages 1793\u2013 1803.", "citeRegEx": "Rothe and Sch\u00fctze.,? 2015", "shortCiteRegEx": "Rothe and Sch\u00fctze.", "year": 2015}, {"title": "Symmetric pattern based word embeddings for improved word similarity prediction", "author": ["Roy Schwartz", "Roi Reichart", "Ari Rappoport."], "venue": "Proceedings of CoNLL, pages 258\u2013267.", "citeRegEx": "Schwartz et al\\.,? 2015", "shortCiteRegEx": "Schwartz et al\\.", "year": 2015}, {"title": "Parsing with compositional vector grammars", "author": ["Richard Socher", "John Bauer", "Christopher D. Manning", "Andrew Y. Ng."], "venue": "Proceedings of ACL, pages 455\u2013 465.", "citeRegEx": "Socher et al\\.,? 2013a", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D. Manning", "Andrew Ng", "Christopher Potts."], "venue": "Proceedings of EMNLP, pages 1631\u20131642.", "citeRegEx": "Socher et al\\.,? 2013b", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Inverted indexing for cross-lingual NLP", "author": ["Anders S\u00f8gaard", "\u017deljko Agi\u0107", "H\u00e9ctor Mart\u00ednez Alonso", "Barbara Plank", "Bernd Bohnet", "Anders Johannsen."], "venue": "Proceedings ACL, pages 1713\u20131722.", "citeRegEx": "S\u00f8gaard et al\\.,? 2015", "shortCiteRegEx": "S\u00f8gaard et al\\.", "year": 2015}, {"title": "Leveraging monolingual data for crosslingual compositional word representations", "author": ["Hubert Soyer", "Pontus Stenetorp", "Akiko Aizawa."], "venue": "Proceedings of ICLR.", "citeRegEx": "Soyer et al\\.,? 2015", "shortCiteRegEx": "Soyer et al\\.", "year": 2015}, {"title": "Word representations: A simple and general method for semi-supervised learning", "author": ["Joseph Turian", "Lev-Arie Ratinov", "Yoshua Bengio."], "venue": "Proceedings of ACL, pages 384\u2013394.", "citeRegEx": "Turian et al\\.,? 2010", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Cross-lingual models of word embeddings: An empirical comparison", "author": ["Shyam Upadhyay", "Manaal Faruqui", "Chris Dyer", "Dan Roth."], "venue": "Proceedings of ACL, pages 1661\u20131670.", "citeRegEx": "Upadhyay et al\\.,? 2016", "shortCiteRegEx": "Upadhyay et al\\.", "year": 2016}, {"title": "Is \"universal syntax\" universally useful for learning distributed representations", "author": ["Ivan Vuli\u0107", "Anna Korhonen"], "venue": "In Proceedings of ACL,", "citeRegEx": "Vuli\u0107 and Korhonen.,? \\Q2016\\E", "shortCiteRegEx": "Vuli\u0107 and Korhonen.", "year": 2016}, {"title": "On the role of seed lexicons in learning bilingual word embeddings", "author": ["Ivan Vuli\u0107", "Anna Korhonen."], "venue": "Proceedings of ACL, pages 247\u2013257.", "citeRegEx": "Vuli\u0107 and Korhonen.,? 2016b", "shortCiteRegEx": "Vuli\u0107 and Korhonen.", "year": 2016}, {"title": "Monolingual and cross-lingual information retrieval models based on (bilingual) word embeddings", "author": ["Ivan Vuli\u0107", "Marie-Francine Moens."], "venue": "Proceedings of SIGIR, pages 363\u2013372.", "citeRegEx": "Vuli\u0107 and Moens.,? 2015", "shortCiteRegEx": "Vuli\u0107 and Moens.", "year": 2015}, {"title": "Bilingual distributed word representations from documentaligned comparable data", "author": ["Ivan Vuli\u0107", "Marie-Francine Moens."], "venue": "Journal of Artificial Intelligence Research, 55:953\u2013994.", "citeRegEx": "Vuli\u0107 and Moens.,? 2016", "shortCiteRegEx": "Vuli\u0107 and Moens.", "year": 2016}, {"title": "Hyperlex: A largescale evaluation of graded lexical entailment", "author": ["Ivan Vuli\u0107", "Daniela Gerz", "Douwe Kiela", "Felix Hill", "Anna Korhonen."], "venue": "CoRR, abs/1608.02117.", "citeRegEx": "Vuli\u0107 et al\\.,? 2016", "shortCiteRegEx": "Vuli\u0107 et al\\.", "year": 2016}, {"title": "A network-based end-to-end trainable task-oriented dialogue system", "author": ["Tsung-Hsien Wen", "David Vandyke", "Nikola Mrk\u0161i\u0107", "Milica Ga\u0161i\u0107", "Lina M. Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "Steve Young."], "venue": "Proceedings of EACL, pages 437\u2013449.", "citeRegEx": "Wen et al\\.,? 2017", "shortCiteRegEx": "Wen et al\\.", "year": 2017}, {"title": "From paraphrase database to compositional paraphrase model and back", "author": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu."], "venue": "Transactions of the ACL, 3:345\u2013358.", "citeRegEx": "Wieting et al\\.,? 2015", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "Charagram: Embedding words and sentences via character n-grams", "author": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu."], "venue": "Proceedings of EMNLP, pages 1504\u20131515.", "citeRegEx": "Wieting et al\\.,? 2016", "shortCiteRegEx": "Wieting et al\\.", "year": 2016}, {"title": "RC-NET: A general framework for incorporating knowledge into word representations", "author": ["Chang Xu", "Yalong Bai", "Jiang Bian", "Bin Gao", "Gang Wang", "Xiaoguang Liu", "Tie-Yan Liu."], "venue": "Proceedings of CIKM, pages 1219\u20131228.", "citeRegEx": "Xu et al\\.,? 2014", "shortCiteRegEx": "Xu et al\\.", "year": 2014}, {"title": "Polarity inducing Latent Semantic Analysis", "author": ["Wen-Tau Yih", "Geoffrey Zweig", "John C. Platt."], "venue": "Proceedings of ACL, pages 1212\u20131222.", "citeRegEx": "Yih et al\\.,? 2012", "shortCiteRegEx": "Yih et al\\.", "year": 2012}, {"title": "POMDP-Based Statistical Spoken Dialog Systems: A Review", "author": ["Steve J. Young", "Milica Ga\u0161i\u0107", "Blaise Thomson", "Jason D. Williams."], "venue": "Proceedings of the IEEE, 101(5):1160\u20131179.", "citeRegEx": "Young et al\\.,? 2013", "shortCiteRegEx": "Young et al\\.", "year": 2013}, {"title": "Still talking to machines (cognitively speaking)", "author": ["Steve Young."], "venue": "Proceedings of INTERSPEECH, pages 1\u201310.", "citeRegEx": "Young.,? 2010", "shortCiteRegEx": "Young.", "year": 2010}, {"title": "Improving lexical embeddings with semantic knowledge", "author": ["Mo Yu", "Mark Dredze."], "venue": "Proceedings of ACL, pages 545\u2013550.", "citeRegEx": "Yu and Dredze.,? 2014", "shortCiteRegEx": "Yu and Dredze.", "year": 2014}, {"title": "Bilingual word embeddings for phrase-based machine translation", "author": ["Will Y. Zou", "Richard Socher", "Daniel Cer", "Christopher D. Manning."], "venue": "Proceedings of EMNLP, pages 1393\u20131398.", "citeRegEx": "Zou et al\\.,? 2013", "shortCiteRegEx": "Zou et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 53, "context": "The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; \u00d3 S\u00e9aghdha and Korhonen, 2014; Levy and Goldberg, 2014).", "startOffset": 218, "endOffset": 322}, {"referenceID": 65, "context": "The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; \u00d3 S\u00e9aghdha and Korhonen, 2014; Levy and Goldberg, 2014).", "startOffset": 218, "endOffset": 322}, {"referenceID": 49, "context": "The common techniques for inducing distributed word representations are grounded in the distributional hypothesis, relying on co-occurrence information in large textual corpora to learn meaningful word representations (Mikolov et al., 2013b; Pennington et al., 2014; \u00d3 S\u00e9aghdha and Korhonen, 2014; Levy and Goldberg, 2014).", "startOffset": 218, "endOffset": 322}, {"referenceID": 20, "context": "processing step, where the distributional word vectors are refined to satisfy constraints extracted from a lexical resource such as WordNet (Faruqui et al., 2015; Wieting et al., 2015; Mrk\u0161i\u0107 et al., 2016).", "startOffset": 140, "endOffset": 205}, {"referenceID": 83, "context": "processing step, where the distributional word vectors are refined to satisfy constraints extracted from a lexical resource such as WordNet (Faruqui et al., 2015; Wieting et al., 2015; Mrk\u0161i\u0107 et al., 2016).", "startOffset": 140, "endOffset": 205}, {"referenceID": 57, "context": "processing step, where the distributional word vectors are refined to satisfy constraints extracted from a lexical resource such as WordNet (Faruqui et al., 2015; Wieting et al., 2015; Mrk\u0161i\u0107 et al., 2016).", "startOffset": 140, "endOffset": 205}, {"referenceID": 36, "context": "Our evaluation shows that ATTRACT-REPEL outperforms previous methods which make use of similar lexical resources, achieving state-of-the-art results on two word similarity datasets: SimLex-999 (Hill et al., 2015) and SimVerb-3500 (Gerz et al.", "startOffset": 193, "endOffset": 212}, {"referenceID": 25, "context": ", 2015) and SimVerb-3500 (Gerz et al., 2016).", "startOffset": 25, "endOffset": 44}, {"referenceID": 59, "context": "We then deploy the ATTRACT-REPEL algorithm in a multilingual setting, using semantic relations extracted from BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014), a cross-lingual lexical resource, to inject constraints between words of different languages into the word representations.", "startOffset": 119, "endOffset": 169}, {"referenceID": 17, "context": "We then deploy the ATTRACT-REPEL algorithm in a multilingual setting, using semantic relations extracted from BabelNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014), a cross-lingual lexical resource, to inject constraints between words of different languages into the word representations.", "startOffset": 119, "endOffset": 169}, {"referenceID": 48, "context": "2 We demonstrate its efficacy with state-of-theart results on the four languages in the Multilingual SimLex-999 dataset (Leviant and Reichart, 2015).", "startOffset": 120, "endOffset": 148}, {"referenceID": 38, "context": "question answering (Iyyer et al., 2014) or textual entailment (Rockt\u00e4schel et al.", "startOffset": 19, "endOffset": 39}, {"referenceID": 68, "context": ", 2014) or textual entailment (Rockt\u00e4schel et al., 2016).", "startOffset": 30, "endOffset": 56}, {"referenceID": 87, "context": "This task, which arises in the construction of statistical dialogue systems (Young et al., 2013), involves understanding the goals expressed by the user and updating the system\u2019s distribution over such goals as the conversation", "startOffset": 76, "endOffset": 96}, {"referenceID": 9, "context": "The usefulness of distributional word representations has been demonstrated across many application areas: Part-of-Speech (POS) tagging (Collobert et al., 2011), machine translation (Zou et al.", "startOffset": 136, "endOffset": 160}, {"referenceID": 71, "context": "2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al.", "startOffset": 39, "endOffset": 150}, {"referenceID": 3, "context": "2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al.", "startOffset": 39, "endOffset": 150}, {"referenceID": 8, "context": "2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al.", "startOffset": 39, "endOffset": 150}, {"referenceID": 40, "context": "2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al.", "startOffset": 39, "endOffset": 150}, {"referenceID": 1, "context": "2014), dependency and semantic parsing (Socher et al., 2013a; Bansal et al., 2014; Chen and Manning, 2014; Johannsen et al., 2015; Ammar et al., 2016), sentiment analysis (Socher et al.", "startOffset": 39, "endOffset": 150}, {"referenceID": 72, "context": ", 2016), sentiment analysis (Socher et al., 2013b), named entity recognition (Turian et al.", "startOffset": 28, "endOffset": 50}, {"referenceID": 75, "context": ", 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others.", "startOffset": 35, "endOffset": 74}, {"referenceID": 29, "context": ", 2013b), named entity recognition (Turian et al., 2010; Guo et al., 2014), and many others.", "startOffset": 35, "endOffset": 74}, {"referenceID": 57, "context": "cialisation for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrk\u0161i\u0107 et al., 2016; Mrk\u0161i\u0107 et al., 2017), spoken language understanding (Kim et al.", "startOffset": 136, "endOffset": 178}, {"referenceID": 58, "context": "cialisation for downstream tasks is relatively unexplored, with improvements in performance so far observed for dialogue state tracking (Mrk\u0161i\u0107 et al., 2016; Mrk\u0161i\u0107 et al., 2017), spoken language understanding (Kim et al.", "startOffset": 136, "endOffset": 178}, {"referenceID": 43, "context": ", 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and", "startOffset": 39, "endOffset": 77}, {"referenceID": 42, "context": ", 2017), spoken language understanding (Kim et al., 2016b; Kim et al., 2016a) and", "startOffset": 39, "endOffset": 77}, {"referenceID": 81, "context": "judging lexical entailment (Vuli\u0107 et al., 2016).", "startOffset": 27, "endOffset": 47}, {"referenceID": 54, "context": "Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al.", "startOffset": 100, "endOffset": 114}, {"referenceID": 2, "context": "Methods from both categories make use of similar lexical resources; common examples include WordNet (Miller, 1995), FrameNet (Baker et al., 1998) or the Paraphrase Databases", "startOffset": 125, "endOffset": 145}, {"referenceID": 24, "context": "(PPDB) (Ganitkevitch et al., 2013; Ganitkevitch and Callison-Burch, 2014; Pavlick et al., 2015).", "startOffset": 7, "endOffset": 95}, {"referenceID": 23, "context": "(PPDB) (Ganitkevitch et al., 2013; Ganitkevitch and Callison-Burch, 2014; Pavlick et al., 2015).", "startOffset": 7, "endOffset": 95}, {"referenceID": 64, "context": "(PPDB) (Ganitkevitch et al., 2013; Ganitkevitch and Callison-Burch, 2014; Pavlick et al., 2015).", "startOffset": 7, "endOffset": 95}, {"referenceID": 89, "context": "Learning from Scratch: some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015).", "startOffset": 150, "endOffset": 256}, {"referenceID": 85, "context": "Learning from Scratch: some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015).", "startOffset": 150, "endOffset": 256}, {"referenceID": 5, "context": "Learning from Scratch: some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015).", "startOffset": 150, "endOffset": 256}, {"referenceID": 41, "context": "Learning from Scratch: some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015).", "startOffset": 150, "endOffset": 256}, {"referenceID": 0, "context": "Learning from Scratch: some methods modify the prior or the regularization of the original training procedure using the set of linguistic constraints (Yu and Dredze, 2014; Xu et al., 2014; Bian et al., 2014; Kiela et al., 2015; Aletras and Stevenson, 2015).", "startOffset": 150, "endOffset": 256}, {"referenceID": 53, "context": "Other ones modify the skip-gram (Mikolov et al., 2013b) objective function by introducing semantic constraints (Yih et al.", "startOffset": 32, "endOffset": 55}, {"referenceID": 86, "context": ", 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasise word similarity over relatedness.", "startOffset": 64, "endOffset": 100}, {"referenceID": 50, "context": ", 2013b) objective function by introducing semantic constraints (Yih et al., 2012; Liu et al., 2015) to train word vectors which emphasise word similarity over relatedness.", "startOffset": 64, "endOffset": 100}, {"referenceID": 11, "context": "(2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in their pattern-based vector space.", "startOffset": 30, "endOffset": 59}, {"referenceID": 46, "context": ", 2012; Liu et al., 2015) to train word vectors which emphasise word similarity over relatedness. Osborne et al. (2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al.", "startOffset": 8, "endOffset": 120}, {"referenceID": 12, "context": "(2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings.", "startOffset": 119, "endOffset": 141}, {"referenceID": 12, "context": "(2016) propose a method for incorporating prior knowledge into the Canonical Correlation Analysis (CCA) method used by Dhillon et al. (2015) to learn spectral word embeddings. While such methods introduce semantic similarity constraints extracted from lexicons, approaches such as the one proposed by Schwartz et al. (2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in their pattern-based vector space.", "startOffset": 119, "endOffset": 324}, {"referenceID": 11, "context": "(2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in their pattern-based vector space. Ono et al. (2015) combine both approaches, using thesauri and distributional data to train embeddings specialised for capturing antonymy.", "startOffset": 31, "endOffset": 145}, {"referenceID": 11, "context": "(2015) use symmetric patterns (Davidov and Rappoport, 2006) to push away antonymous words in their pattern-based vector space. Ono et al. (2015) combine both approaches, using thesauri and distributional data to train embeddings specialised for capturing antonymy. Faruqui and Dyer (2015) use many", "startOffset": 31, "endOffset": 289}, {"referenceID": 20, "context": "Faruqui et al. (2015) and Jauhar et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 20, "context": "Faruqui et al. (2015) and Jauhar et al. (2015) use synonymy constraints in a procedure termed retrofitting to bring the vectors of semanti-", "startOffset": 0, "endOffset": 47}, {"referenceID": 80, "context": "cally similar words close together, while Wieting et al. (2015) modify the skip-gram objective function to fine-tune word vectors by injecting paraphrasing constraints from PPDB.", "startOffset": 42, "endOffset": 64}, {"referenceID": 56, "context": "Mrk\u0161i\u0107 et al. (2016) build on the retrofitting approach by jointly injecting synonymy", "startOffset": 0, "endOffset": 21}, {"referenceID": 58, "context": "and antonymy constraints; the same idea is reassessed by Nguyen et al. (2016). Kim et al.", "startOffset": 57, "endOffset": 78}, {"referenceID": 42, "context": "Kim et al. (2016a) further expand this line of work by incorporating semantic intensity information for the constraints, while Recski et al.", "startOffset": 0, "endOffset": 19}, {"referenceID": 42, "context": "Kim et al. (2016a) further expand this line of work by incorporating semantic intensity information for the constraints, while Recski et al. (2016) use ensembles of rich concept dictionaries to further improve a combined collection", "startOffset": 0, "endOffset": 148}, {"referenceID": 51, "context": "on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentencealigned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al.", "startOffset": 43, "endOffset": 87}, {"referenceID": 10, "context": "on the basis of parallel word-aligned data (Luong et al., 2015; Coulmance et al., 2015) or sentencealigned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al.", "startOffset": 43, "endOffset": 87}, {"referenceID": 34, "context": ", 2015) or sentencealigned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015).", "startOffset": 32, "endOffset": 130}, {"referenceID": 35, "context": ", 2015) or sentencealigned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015).", "startOffset": 32, "endOffset": 130}, {"referenceID": 7, "context": ", 2015) or sentencealigned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015).", "startOffset": 32, "endOffset": 130}, {"referenceID": 28, "context": ", 2015) or sentencealigned data (Hermann and Blunsom, 2014a; Hermann and Blunsom, 2014b; Chandar et al., 2014; Gouws et al., 2015).", "startOffset": 32, "endOffset": 130}, {"referenceID": 73, "context": "aligned data (S\u00f8gaard et al., 2015; Vuli\u0107 and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al.", "startOffset": 13, "endOffset": 58}, {"referenceID": 80, "context": "aligned data (S\u00f8gaard et al., 2015; Vuli\u0107 and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al.", "startOffset": 13, "endOffset": 58}, {"referenceID": 52, "context": ", 2015; Vuli\u0107 and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli\u0107 and Korhonen, 2016b; Duong et al., 2016).", "startOffset": 98, "endOffset": 216}, {"referenceID": 18, "context": ", 2015; Vuli\u0107 and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli\u0107 and Korhonen, 2016b; Duong et al., 2016).", "startOffset": 98, "endOffset": 216}, {"referenceID": 47, "context": ", 2015; Vuli\u0107 and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli\u0107 and Korhonen, 2016b; Duong et al., 2016).", "startOffset": 98, "endOffset": 216}, {"referenceID": 78, "context": ", 2015; Vuli\u0107 and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli\u0107 and Korhonen, 2016b; Duong et al., 2016).", "startOffset": 98, "endOffset": 216}, {"referenceID": 16, "context": ", 2015; Vuli\u0107 and Moens, 2016), while some learn on the basis of available bilingual dictionaries (Mikolov et al., 2013a; Faruqui and Dyer, 2014; Lazaridou et al., 2015; Vuli\u0107 and Korhonen, 2016b; Duong et al., 2016).", "startOffset": 98, "endOffset": 216}, {"referenceID": 77, "context": "(2016) and Vuli\u0107 and Korhonen (2016b) for an overview of cross-lingual word embedding work.", "startOffset": 11, "endOffset": 38}, {"referenceID": 18, "context": "boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al.", "startOffset": 63, "endOffset": 132}, {"referenceID": 66, "context": "boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al.", "startOffset": 63, "endOffset": 132}, {"referenceID": 76, "context": "boost performance on monolingual tasks such as word similarity (Faruqui and Dyer, 2014; Rastogi et al., 2015; Upadhyay et al., 2016); and b) support cross-lingual tasks such as bilingual lexicon induction (Mikolov et al.", "startOffset": 63, "endOffset": 132}, {"referenceID": 79, "context": ", 2016), cross-lingual information retrieval (Vuli\u0107 and Moens, 2015; Mitra et al., 2016), and transfer learning for resource-lean languages (S\u00f8gaard et al.", "startOffset": 45, "endOffset": 88}, {"referenceID": 55, "context": ", 2016), cross-lingual information retrieval (Vuli\u0107 and Moens, 2015; Mitra et al., 2016), and transfer learning for resource-lean languages (S\u00f8gaard et al.", "startOffset": 45, "endOffset": 88}, {"referenceID": 73, "context": ", 2016), and transfer learning for resource-lean languages (S\u00f8gaard et al., 2015; Guo et al., 2015).", "startOffset": 59, "endOffset": 99}, {"referenceID": 30, "context": ", 2016), and transfer learning for resource-lean languages (S\u00f8gaard et al., 2015; Guo et al., 2015).", "startOffset": 59, "endOffset": 99}, {"referenceID": 83, "context": "This procedure, which we term ATTRACT-REPEL, builds on the Paragram (Wieting et al., 2015) and counter-fitting procedures", "startOffset": 68, "endOffset": 90}, {"referenceID": 57, "context": "(Mrk\u0161i\u0107 et al., 2016), both of which inject linguistic constraints into existing vector spaces to improve their ability to capture semantic similarity.", "startOffset": 0, "endOffset": 21}, {"referenceID": 20, "context": "Comparison to Prior Work ATTRACT-REPEL draws inspiration from three methods: 1) retrofitting (Faruqui et al., 2015); 2) PARAGRAM (Wieting et al.", "startOffset": 93, "endOffset": 115}, {"referenceID": 83, "context": ", 2015); 2) PARAGRAM (Wieting et al., 2015); and 3) counter-fitting (Mrk\u0161i\u0107 et al.", "startOffset": 21, "endOffset": 43}, {"referenceID": 57, "context": ", 2015); and 3) counter-fitting (Mrk\u0161i\u0107 et al., 2016).", "startOffset": 32, "endOffset": 53}, {"referenceID": 15, "context": "(2015), we use the AdaGrad algorithm (Duchi et al., 2011) to train the word embeddings for five epochs, which", "startOffset": 37, "endOffset": 57}, {"referenceID": 82, "context": "Optimisation Following Wieting et al. (2015), we use the AdaGrad algorithm (Duchi et al.", "startOffset": 23, "endOffset": 45}, {"referenceID": 20, "context": "Similar to Faruqui et al. (2015), Wieting et al.", "startOffset": 11, "endOffset": 33}, {"referenceID": 20, "context": "Similar to Faruqui et al. (2015), Wieting et al. (2015) and Mrk\u0161i\u0107 et al.", "startOffset": 11, "endOffset": 56}, {"referenceID": 20, "context": "Similar to Faruqui et al. (2015), Wieting et al. (2015) and Mrk\u0161i\u0107 et al. (2016), we do not use early stopping.", "startOffset": 11, "endOffset": 81}, {"referenceID": 21, "context": "Hyperparameter Tuning We use Spearman\u2019s correlation of the final word vectors with the Multilingual WordSim-353 gold-standard association dataset (Finkelstein et al., 2002; Leviant and Reichart, 2015).", "startOffset": 146, "endOffset": 200}, {"referenceID": 48, "context": "Hyperparameter Tuning We use Spearman\u2019s correlation of the final word vectors with the Multilingual WordSim-353 gold-standard association dataset (Finkelstein et al., 2002; Leviant and Reichart, 2015).", "startOffset": 146, "endOffset": 200}, {"referenceID": 64, "context": "For the four SimLex languages, we employ four well-known, high-quality word vector collections: a) The Common Crawl GloVe English vectors from Pennington et al. (2014); b) German vectors from Vuli\u0107 and Korhonen (2016a); c) Italian vectors from Dinu et al.", "startOffset": 143, "endOffset": 168}, {"referenceID": 64, "context": "For the four SimLex languages, we employ four well-known, high-quality word vector collections: a) The Common Crawl GloVe English vectors from Pennington et al. (2014); b) German vectors from Vuli\u0107 and Korhonen (2016a); c) Italian vectors from Dinu et al.", "startOffset": 143, "endOffset": 219}, {"referenceID": 14, "context": "(2014); b) German vectors from Vuli\u0107 and Korhonen (2016a); c) Italian vectors from Dinu et al. (2015); and d) Russian vectors from Kutuzov", "startOffset": 83, "endOffset": 102}, {"referenceID": 53, "context": "In addition, for each of the 16 languages we also train the skip-gram with negative sampling variant of the word2vec model (Mikolov et al., 2013b), on the latest Wikipedia dump of each language, to induce 300-dimensional word vectors.", "startOffset": 123, "endOffset": 146}, {"referenceID": 59, "context": "Cross-Lingual Similarity We employ BabelNet, a multilingual semantic network automatically constructed by linking Wikipedia to WordNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014).", "startOffset": 135, "endOffset": 185}, {"referenceID": 17, "context": "Cross-Lingual Similarity We employ BabelNet, a multilingual semantic network automatically constructed by linking Wikipedia to WordNet (Navigli and Ponzetto, 2012; Ehrmann et al., 2014).", "startOffset": 135, "endOffset": 185}, {"referenceID": 20, "context": "Following Faruqui et al. (2015), who found PPDB constraints more beneficial than the WordNet ones,", "startOffset": 10, "endOffset": 32}, {"referenceID": 45, "context": "However, PPDB relies on large, high-quality parallel corpora such as Europarl (Koehn, 2005).", "startOffset": 78, "endOffset": 91}, {"referenceID": 36, "context": "Spearman\u2019s rank correlation with the SimLex-999 dataset (Hill et al., 2015) is used as the intrinsic eval-", "startOffset": 56, "endOffset": 75}, {"referenceID": 21, "context": "Unlike other gold standard resources such as WordSim-353 (Finkelstein et al., 2002) or MEN (Bruni et al.", "startOffset": 57, "endOffset": 83}, {"referenceID": 6, "context": ", 2002) or MEN (Bruni et al., 2014), SimLex-999 consists of word pairs scored by annotators instructed to discern between semantic similarity", "startOffset": 15, "endOffset": 35}, {"referenceID": 25, "context": "SimVerb-3500 (Gerz et al., 2016), a semantic similarity dataset that focuses on verb pair similarity.", "startOffset": 13, "endOffset": 32}, {"referenceID": 26, "context": "tional vectors trained on the latest Wikipedia dumps; and c) word vectors randomly initialised using the XAVIER initialisation (Glorot and Bengio, 2010).", "startOffset": 127, "endOffset": 152}, {"referenceID": 52, "context": "(Mikolov et al., 2013a), retrained using the constraints used by our model; and 2.", "startOffset": 0, "endOffset": 23}, {"referenceID": 34, "context": "(Hermann and Blunsom, 2014a; Gouws et al., 2015; Vuli\u0107 and Korhonen, 2016a; Vuli\u0107 and Moens, 2016).", "startOffset": 0, "endOffset": 98}, {"referenceID": 28, "context": "(Hermann and Blunsom, 2014a; Gouws et al., 2015; Vuli\u0107 and Korhonen, 2016a; Vuli\u0107 and Moens, 2016).", "startOffset": 0, "endOffset": 98}, {"referenceID": 80, "context": "(Hermann and Blunsom, 2014a; Gouws et al., 2015; Vuli\u0107 and Korhonen, 2016a; Vuli\u0107 and Moens, 2016).", "startOffset": 0, "endOffset": 98}, {"referenceID": 83, "context": "State-of-the-Art Wieting et al. (2016) note that the hyperparameters of the widely used Paragram-SL999", "startOffset": 17, "endOffset": 39}, {"referenceID": 83, "context": "vectors (Wieting et al., 2015) are tuned on SimLex999, and as such are not comparable to methods which holdout the dataset.", "startOffset": 8, "endOffset": 30}, {"referenceID": 57, "context": ", (Mrk\u0161i\u0107 et al., 2016; Recski et al., 2016)) as starting point does not yield meaningful high scores either.", "startOffset": 2, "endOffset": 44}, {"referenceID": 67, "context": ", (Mrk\u0161i\u0107 et al., 2016; Recski et al., 2016)) as starting point does not yield meaningful high scores either.", "startOffset": 2, "endOffset": 44}, {"referenceID": 82, "context": "706 score reported by Wieting et al. (2016) and sets a new high score for this dataset.", "startOffset": 22, "endOffset": 44}, {"referenceID": 25, "context": "628 reported by Gerz et al. (2016).", "startOffset": 16, "endOffset": 35}, {"referenceID": 27, "context": "This is a typical init method in neural nets research (Goldberg, 2015; Bengio et al., 2013).", "startOffset": 54, "endOffset": 91}, {"referenceID": 4, "context": "This is a typical init method in neural nets research (Goldberg, 2015; Bengio et al., 2013).", "startOffset": 54, "endOffset": 91}, {"referenceID": 18, "context": "English words which map to the same Irish word are likely to be synonyms, even if those English pairs are not present in the PPDB datasets (Faruqui and Dyer, 2014).", "startOffset": 139, "endOffset": 163}, {"referenceID": 52, "context": "Model EN-IT EN-DE EN IT EN DE (Mikolov et al., 2013a) 0.", "startOffset": 30, "endOffset": 53}, {"referenceID": 34, "context": "28 (Hermann and Blunsom, 2014a) 0.", "startOffset": 3, "endOffset": 31}, {"referenceID": 28, "context": "35 (Gouws et al., 2015) 0.", "startOffset": 3, "endOffset": 23}, {"referenceID": 80, "context": "33 (Vuli\u0107 and Moens, 2016) 0.", "startOffset": 3, "endOffset": 26}, {"referenceID": 88, "context": "In slot-based systems, application domains are defined by ontologies which enumerate the goals that users can express (Young, 2010).", "startOffset": 118, "endOffset": 131}, {"referenceID": 33, "context": "To overcome this problem, delexicalisation-based DST models (Henderson et al., 2014c; Henderson et al., 2014b; Mrk\u0161i\u0107 et al., 2015; Wen et al., 2017) replace occurrences of ontology values with generic tags which facilitate transfer learning across different ontology values.", "startOffset": 60, "endOffset": 149}, {"referenceID": 32, "context": "To overcome this problem, delexicalisation-based DST models (Henderson et al., 2014c; Henderson et al., 2014b; Mrk\u0161i\u0107 et al., 2015; Wen et al., 2017) replace occurrences of ontology values with generic tags which facilitate transfer learning across different ontology values.", "startOffset": 60, "endOffset": 149}, {"referenceID": 56, "context": "To overcome this problem, delexicalisation-based DST models (Henderson et al., 2014c; Henderson et al., 2014b; Mrk\u0161i\u0107 et al., 2015; Wen et al., 2017) replace occurrences of ontology values with generic tags which facilitate transfer learning across different ontology values.", "startOffset": 60, "endOffset": 149}, {"referenceID": 82, "context": "To overcome this problem, delexicalisation-based DST models (Henderson et al., 2014c; Henderson et al., 2014b; Mrk\u0161i\u0107 et al., 2015; Wen et al., 2017) replace occurrences of ontology values with generic tags which facilitate transfer learning across different ontology values.", "startOffset": 60, "endOffset": 149}, {"referenceID": 56, "context": "Mrk\u0161i\u0107 et al. (2016) showed that semantically specialised vector spaces can be used to automatically induce such lexicons for simple dialogue domains.", "startOffset": 0, "endOffset": 21}, {"referenceID": 58, "context": "Neural Belief Tracker (NBT) The NBT is a novel DST model which operates purely over distributed representations of words, learning to compose utterance and context representations which it then uses to decide which of the potentially many ontologydefined intents (goals) have been expressed by the user (Mrk\u0161i\u0107 et al., 2017).", "startOffset": 303, "endOffset": 324}, {"referenceID": 31, "context": "This dataset is based on the ontology used for the 2nd DST Challenge (DSTC2) (Henderson et al., 2014a).", "startOffset": 77, "endOffset": 102}, {"referenceID": 75, "context": "0 dataset introduced by Wen et al. (2017) and Mrk\u0161i\u0107 et al.", "startOffset": 24, "endOffset": 42}, {"referenceID": 52, "context": "(2017) and Mrk\u0161i\u0107 et al. (2017). This dataset is based on the ontology used for the 2nd DST Challenge (DSTC2) (Henderson et al.", "startOffset": 11, "endOffset": 32}, {"referenceID": 77, "context": "Interestingly, the bilingual vectors of Vuli\u0107 and Korhonen (2016a) outperform ours for EN (but not for IT and DE) despite their weaker SimLex performance, showing that intrinsic evaluation", "startOffset": 40, "endOffset": 67}, {"referenceID": 52, "context": "The multilingual DST model trained using ontology grounding offers substantial performance imWord Vector Space EN IT DE EN-IT/EN-DE (Mikolov et al., 2013a) 78.", "startOffset": 132, "endOffset": 155}, {"referenceID": 28, "context": "7 EN-IT/EN-DE (Gouws et al., 2015) 75.", "startOffset": 14, "endOffset": 34}, {"referenceID": 81, "context": "5 EN-IT/EN-DE (Vuli\u0107 et al., 2016) 72.", "startOffset": 14, "endOffset": 34}], "year": 2017, "abstractText": "We present ATTRACT-REPEL, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. ATTRACT-REPEL facilitates the use of constraints from monoand crosslingual resources, yielding semantically specialised cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct highquality vector spaces for a plethora of different languages, facilitating semantic transfer from highto lower-resource ones. The effectiveness of our approach is demonstrated with state-ofthe-art results on semantic similarity datasets in six languages. We next show that ATTRACTREPEL-specialised vectors boost performance in the downstream task of dialogue state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our algorithm facilitate the training of multilingual DST models, which brings further performance improvements.", "creator": "LaTeX with hyperref package"}}}