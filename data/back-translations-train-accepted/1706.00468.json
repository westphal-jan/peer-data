{"id": "1706.00468", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2017", "title": "Function Assistant: A Tool for NL Querying of APIs", "abstract": "In this paper, we describe Function Assistant, a lightweight Python-based toolkit for querying and exploring source code repositories using natural language. The toolkit is designed to help end-users of a target API quickly find information about functions through high-level natural language queries and descriptions. For a given text query and background API, the tool finds candidate functions by performing a translation from the text to known representations in the API using the semantic parsing approach of Richardson and Kuhn (2017). Translations are automatically learned from example text-code pairs in example APIs. The toolkit includes features for building translation pipelines and query engines for arbitrary source code projects. To explore this last feature, we perform new experiments on 27 well-known Python projects hosted on Github.", "histories": [["v1", "Thu, 1 Jun 2017 19:26:32 GMT  (1049kb,D)", "http://arxiv.org/abs/1706.00468v1", "In submission for EMNLP-2017 (demo track)"], ["v2", "Fri, 15 Sep 2017 11:57:36 GMT  (867kb,D)", "http://arxiv.org/abs/1706.00468v2", "in Proceedings of EMNLP-2017 (system demonstrations)"]], "COMMENTS": "In submission for EMNLP-2017 (demo track)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kyle richardson", "jonas kuhn"], "accepted": true, "id": "1706.00468"}, "pdf": {"name": "1706.00468.pdf", "metadata": {"source": "CRF", "title": "Function Assistant: A Tool for NL Querying of APIs", "authors": ["Kyle Richardson", "Jonas Kuhn"], "emails": ["kyle@ims.uni-stuttgart.de"], "sections": [{"heading": null, "text": "In this article, we describe the Function Assistant, a lightweight Python-based toolkit for querying and researching source code repositories using natural language. The toolkit is designed to help end-users of a target API quickly find information about functions through high-level queries and descriptions of natural language. For a given text query and background API, the tool finds candidate functions by performing a translation from text to familiar representations in the API using the semantic parsing approach of Richardson and Kuhn (2017). Translations are learned automatically using sample pairs of text code in sample APIs. The toolkit includes functions for building translation pipelines and query engines for arbitrary source code projects. To explore this last feature, we are conducting new experiments on 27 known Python projects hosted on Github1."}, {"heading": "1 Introduction", "text": "This year, it is only a matter of time before there is an agreement, until there is an agreement."}, {"heading": "2 Related Work", "text": "Queriing the natural language of APIs has long been a goal in software development related to the general problem of software reuse (Krueger, 1992). To date, a number of products are available in this area on an industrial scale.3To our knowledge, most implementations use superficial methods of terminology matching and / or information extraction (Lv et al., 2015) that differ from our methods that use more conventional NLP components and techniques. As we show in this paper and in RK, term matching and related techniques can sometimes serve as a competitive starting point, but are almost always surpassed by our translation approach. Recently, interest in machine learning in code representations of APIs has increased, especially using resources such as GitHub or StackOverflow. However, this work tends to look at learning from many API collections (Gu et al, 2016), making such systems difficult to evaluate and apply to specific APIs."}, {"heading": "3 Technical Approach", "text": "In this paper, we focus on learning function representations from text descriptions within source code collections or APIs. We refer to these target function representations as API components. Each component specifies a function name, a list of arguments, and other optional information such as a namespace.3for example, www.krugle.com, www.searchcode.com. Given a series of sample text component pairs from an example API, D = {(xi, zi)} ni = 1, the goal is to learn how to create correct, well-formed components z-C for each text x. Considering these methods as a semantic parsing problem, we can consider each z to be analogous to a logical target form. In this paper, we focus narrowly on Python source code projects and thus Python functions z, however our methods react agnostically to the input of natural language and output programming language as shown in K.3."}, {"heading": "3.1 Translation Model", "text": "Considering an input text (or query) sequence x = w1,.., w | x |, the goal is to generate an output API component z = ui,.., u | z | which involves learning a conditional distribution p (z | x). We take a noisy approach, with (z | x) p (x | z) p (z) p (z) p (x | z) p (x | z) p (x | z) being expressed in a word-based translation model: p (x | z) = \u2211 a p (x, a | z), with the summation covering the set of all the many-to-one (word) components. While many different formulations of word-based models exist, we have previously found that the simplest lexical translation model, or IBM Model 1 (Brown et al., 1993) implements a coding of conventional languages."}, {"heading": "3.2 Discriminative Reranking", "text": "Following most semantic parsing approaches (Zettlemoyer and Collins, 2009), we use a discriminatory log-linear model to recalculate the components generated from the underlying translation model. Such a model defines a conditional distribution: p (z | x; \u03b8) \u03c6 \u00b7 \u03c6 (x, z), for a parameter vector \u03b8 \u0432 Rb, and a number of feature functions \u03c6 (x, z).Our tool implements several different training and optimization methods. To this end, we train our models using an online stochastic gradient ascendancy algorithm using a maximum conditional log probability object."}, {"heading": "3.2.1 Features", "text": "By default, our pipeline implementation uses three classes of features that are identical to the feature set used in RK. The first class includes additional features at the word level, such as word / component match, overlap, component syntax information, and so on. The second class includes features of phrases and hierarchical phrases between text and component candidates that are extracted by default from symmetrical heuristics at the word level. The other category of features includes features at the document level, including information about the underlying hierarchy of the API class, as well as relationships between words / phrases and abstract classes within that hierarchy. We also use additional textual descriptions of parameters in the doctrines to indicate whether word / component candidate pairs intersect in these descriptions."}, {"heading": "4 Implementation and Usage", "text": "The tool is part of the accompanying software release for our previous work called Zubr. For efficiency reasons, the functionality is written in Cython 4, a compiled superset of the Python language that facilitates native C / C + + integration. It can be used in two ways: firstly as a black box pipeline to build custom translation pipelines and API query engines; and it can also be integrated with other components through our Cython and Python API. We are focusing on the first type of functionality."}, {"heading": "4.1 Library Design and Pipelines", "text": "These components interact via a class called Pipeline, which glues together various user-specific components and dependencies and builds a global configuration from these components. Subsequent instances and object sharing are dictated or injected by these global configuration settings, which can change dynamically during pipeline execution. Pipelines are created by writing pipeline scripts, such as the one in Figure 2. This file is an ordinary Python file, with two mandatory variables. The first parameter variable specifies various configuration parameters associated with the pipeline. In this case, there is a Set-4http: / cython.org / ting - an ordinary Python file with two mandatory variables."}, {"heading": "4.2 Web Server", "text": "The final step in this pipeline is to build an HTTP web server that can be used to query the input API. Internally, the server calls the trained translation model and discriminatory Reranker, which records user requests and tries to translate them into API function representations, which are then returned to the user as possible answers to the query. Depending on the result, the user can either reformulate his question if the target function is not found, or take a closer look at the implementation by associating it with the source code of the function. An example screenshot of the query server is shown in Figure 3. Here, the background API is the NLTK toolkit, and the query is Train a Sequence Tagger model. Although the model is not explicitly mentioned, it provides training functions for the HiddenMarkovModelTagger. The right side of the image shows the hyperlink path to the original source in the pull function."}, {"heading": "5 Experiments", "text": "Our current DocExtractor implementation supports building parallel datasets from raw Python source code collections. Internally, the tool reads source code using the abstract syntax tree branch in the Python standard library and extracts sets of function and description pairs. In addition, the tool also extracts class descriptions, parameter and return value descriptions, and information about the internal class hierarchy of the API. This last type of information is then used to define features at the document level. To experiment with this feature, we have built pipelines and conducted experiments for 27 popular Python projects to test the robustness of our extractor and see how well our models respond to unforeseen requests for these resources with our previous experimental setup."}, {"heading": "5.1 Datasets", "text": "The sample projects are shown in Table 1. Each dataset is quantified by # pairs or the number of parallel function component representations, the # symbols in the output language of the components, the # (NL) words, and the vocabulary size."}, {"heading": "5.2 Experimental Setup", "text": "Each data set is randomly divided into train, test and development sets, using a 70% -30% split. We can imagine that the sentences provided mimic queries that the user could make to the model. By default, all models are trained on the training sets, and hyperparameters are matched to the development sets. For invisible text input during the test, the model generates a candidate list of component output. An output is considered correct if it matches exactly the gold function representation. As before, we measure the accuracy @ 1, the accuracy within the top ten (Accuracy @ 10), and the MRR. As in our previous paper, three additional baselines are used: the first is a simple bag-of-words (BoW) model that uses word-component pairs as characteristics; the second is a term-match baseline that classifies candidates by the number of matches between input words and component words (We also classify the results without the translation)."}, {"heading": "6 Results and Discussion", "text": "The test results are presented in Table 2 and are largely consistent with our results to date. BoW and Term Match baselines are surpassed by all other models, which in turn shows that API queries are more complicated than simple component word matching. The Reranker model improves all data sets compared to the pure use of the translation model, suggesting that document-level functions and phrase descriptions can be helpful. We note that these experiments are synthetic in the sense that it is unclear whether the examples held are similar to actual user queries or not. However, assuming that each set held is a representative sample of the queries that real users would make, we can then interpret the results to show how well our models answer queries. Whether or not these held examples reflect real queries, we believe that they still provide a good benchmark for modeling. All the code and all the data will be published to facilitate further experiments and building."}, {"heading": "7 Conclusion", "text": "We introduce the Function Wizard, a lightweight tool for retrieving API collections using uncon-5 see demo here: http: / / zubr.ims.uni-stuttgart.de / strained natural language. Users can equip our tool with target code projects and build custom translation pipelines and query servers from scratch. In addition to the tool, we have also created new resources for studying the API query, in the form of data sets from 27 popular Github projects. We hope that our tool and resources will serve as a benchmark for future work in this area and ultimately help solve everyday software search and reusability problems."}], "references": [{"title": "Bimodal modelling of source code and natural language", "author": ["Miltiadis Allamanis", "Daniel Tarlow", "Andrew D Gordon", "Yi Wei."], "venue": "Proceedings of ICML.", "citeRegEx": "Allamanis et al\\.,? 2015", "shortCiteRegEx": "Allamanis et al\\.", "year": 2015}, {"title": "The mathematics of SMT", "author": ["Peter F Brown", "Vincent J Della Pietra", "Stephen A Della Pietra", "Robert L Mercer."], "venue": "Computational linguistics 19(2).", "citeRegEx": "Brown et al\\.,? 1993", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Deep API Learning", "author": ["Xiaodong Gu", "Hongyu Zhang", "Dongmei Zhang", "Sunghun Kim."], "venue": "arXiv preprint arXiv:1605.08535 .", "citeRegEx": "Gu et al\\.,? 2016", "shortCiteRegEx": "Gu et al\\.", "year": 2016}, {"title": "Software reuse", "author": ["Charles W. Krueger."], "venue": "ACM Comput. Surv. 24(2).", "citeRegEx": "Krueger.,? 1992", "shortCiteRegEx": "Krueger.", "year": 1992}, {"title": "Codehow: Effective code search based on api understanding and extended boolean model (e)", "author": ["Fei Lv", "Hongyu Zhang", "Jian-guang Lou", "Shaowei Wang", "Dongmei Zhang", "Jianjun Zhao."], "venue": "Proceedings of ASE.", "citeRegEx": "Lv et al\\.,? 2015", "shortCiteRegEx": "Lv et al\\.", "year": 2015}, {"title": "Learning semantic correspondences in technical documentation", "author": ["Kyle Richardson", "Jonas Kuhn."], "venue": "arXiv preprint arXiv:1705.04815 .", "citeRegEx": "Richardson and Kuhn.,? 2017", "shortCiteRegEx": "Richardson and Kuhn.", "year": 2017}, {"title": "Learning for Semantic Parsing with Statistical Machine Translation", "author": ["Yuk Wah Wong", "Raymond J. Mooney."], "venue": "Proceedings of HLT-NAACL-2006.", "citeRegEx": "Wong and Mooney.,? 2006", "shortCiteRegEx": "Wong and Mooney.", "year": 2006}, {"title": "Learning context-dependent mappings from sentences to logical form", "author": ["Luke S. Zettlemoyer", "Michael Collins."], "venue": "Proceedings of ACL-2009.", "citeRegEx": "Zettlemoyer and Collins.,? 2009", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2009}], "referenceMentions": [{"referenceID": 5, "context": "For a given text query and background API, the tool finds candidate functions by performing a translation from the text to known representations in the API using the semantic parsing approach of Richardson and Kuhn (2017). Translations are automatically learned from example textcode pairs in example APIs.", "startOffset": 195, "endOffset": 222}, {"referenceID": 5, "context": "In our previous work (Richardson and Kuhn (2017), henceforth RK), we look at learning these types of correspondences from example API collections in a variety of programming languages and source natural languages.", "startOffset": 22, "endOffset": 49}, {"referenceID": 3, "context": "Natural language querying of APIs has long been a goal in software engineering, related to the general problem of software reuse (Krueger, 1992).", "startOffset": 129, "endOffset": 144}, {"referenceID": 4, "context": "3To our knowledge, most implementations use shallow term matching and/or information-extraction techniques (Lv et al., 2015), differing from our methods that use more conventional NLP components and techniques.", "startOffset": 107, "endOffset": 124}, {"referenceID": 2, "context": "However, this work tends to look at learning from many API collections (Gu et al., 2016), making such systems hard to evaluate and to apply to querying specific APIs.", "startOffset": 71, "endOffset": 88}, {"referenceID": 0, "context": "Other work looks at learning to generate longer code from source code annotations for natural language programming (Allamanis et al., 2015), often focusing narrowly on a specific programming language (e.", "startOffset": 115, "endOffset": 139}, {"referenceID": 6, "context": "Many existing methods take direct inspiration from work on MT (Wong and Mooney, 2006) and parsing (Zettlemoyer and Collins, 2009).", "startOffset": 62, "endOffset": 85}, {"referenceID": 7, "context": "Many existing methods take direct inspiration from work on MT (Wong and Mooney, 2006) and parsing (Zettlemoyer and Collins, 2009).", "startOffset": 98, "endOffset": 129}, {"referenceID": 1, "context": "While many different formulations of wordbased models exist, we previously found that the simplest lexical translation model, or IBM Model 1 (Brown et al., 1993), outperforms even higherorder alignment models with location parameters.", "startOffset": 141, "endOffset": 161}, {"referenceID": 1, "context": "While many parameter estimation strategies exists for training word-based models, we similarly found that the simplest EM procedure of Brown et al. (1993) works the best.", "startOffset": 135, "endOffset": 155}, {"referenceID": 7, "context": "Following most semantic parsing approaches (Zettlemoyer and Collins, 2009), we use a discriminative log-linear model to rerank the components generated from the underlying translation model.", "startOffset": 43, "endOffset": 74}], "year": 2017, "abstractText": "In this paper, we describe Function Assistant, a lightweight Python-based toolkit for querying and exploring source code repositories using natural language. The toolkit is designed to help end-users of a target API quickly find information about functions through high-level natural language queries and descriptions. For a given text query and background API, the tool finds candidate functions by performing a translation from the text to known representations in the API using the semantic parsing approach of Richardson and Kuhn (2017). Translations are automatically learned from example textcode pairs in example APIs. The toolkit includes features for building translation pipelines and query engines for arbitrary source code projects. To explore this last feature, we perform new experiments on 27 well-known Python projects hosted on Github1.", "creator": "LaTeX with hyperref package"}}}