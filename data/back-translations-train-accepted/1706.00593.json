{"id": "1706.00593", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2017", "title": "Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora", "abstract": "Much of scientific progress stems from previously published findings, but searching through the vast sea of scientific publications is difficult. We often rely on metrics of scholarly authority to find the prominent authors but these authority indices do not differentiate authority based on research topics. We present Latent Topical-Authority Indexing (LTAI) for jointly modeling the topics, citations, and topical authority in a corpus of academic papers. Compared to previous models, LTAI differs in two main aspects. First, it explicitly models the generative process of the citations, rather than treating the citations as given. Second, it models each author's influence on citations of a paper based on the topics of the cited papers, as well as the citing papers. We fit LTAI to four academic corpora: CORA, Arxiv Physics, PNAS, and Citeseer. We compare the performance of LTAI against various baselines, starting with the latent Dirichlet allocation, to the more advanced models including author-link topic model and dynamic author citation topic model. The results show that LTAI achieves improved accuracy over other similar models when predicting words, citations and authors of publications.", "histories": [["v1", "Fri, 2 Jun 2017 08:52:47 GMT  (721kb,D)", "http://arxiv.org/abs/1706.00593v1", "Accepted by Transactions of the Association for Computational Linguistics (TACL); to appear"]], "COMMENTS": "Accepted by Transactions of the Association for Computational Linguistics (TACL); to appear", "reviews": [], "SUBJECTS": "cs.CL cs.DL cs.SI", "authors": ["jooyeon kim", "dongwoo kim", "alice oh"], "accepted": true, "id": "1706.00593"}, "pdf": {"name": "1706.00593.pdf", "metadata": {"source": "CRF", "title": "Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora", "authors": ["Jooyeon Kim", "Dongwoo Kim"], "emails": ["jooyeon.kim@kaist.ac.kr", "dongwoo.kim@anu.edu.au", "alice.oh@kaist.edu"], "sections": [{"heading": "1 Introduction", "text": "With a corpus of scientific literature, we can describe the complex and complex process of scientific progress. We can learn the most important topics in journal articles and conference minutes, follow authors who are productive and influential, and find papers that are highly quoted. However, the enormous number of publications and authors makes it virtually impossible to achieve a deep or detailed understanding beyond the very broad trends. For example, if we want to identify authors who are particularly influential in a particular field of research, it is difficult to do so without the help of automatic analysis. Online publication archives provide near real measurements of Scholars Xiv: 170 6.00 593v 1 [cs.C L] 2J 01arly impacts, such as the index of the journal \"Impact factor\" (Garfield, 2006), and quotation numbers. These indicators are still on the same level."}, {"heading": "2 Related Work", "text": "In this section, we review related work, first in the field of NLP and ML-based analysis of scientific corpora, then approaches based on Bayesian theme models for academic corpora, and finally common models of topics, authors, and citations. In analyzing scientific corpora, previous research presents the classification of scientific publications (Caragea et al., 2015) that recommend unlinked citations (Huang et al., 2015; Neiswanger et al., 2014; Wang et al., 2015; Jiang et al.), the summary and extraction of key phrases (Cohan et al., 2015; Caragea et al., 2014) that trigger a better adaptation of the model (He et al., 2015), which incorporates authority information to increase content and link predictability (Sim et al., 2015), the estimation of a paper on the potential influence of the academic community (Dong et al., the search for, the various functionalities, and the algorithms, and the classification of Murunga et."}, {"heading": "3 Latent Topical-Authority Indexing", "text": "The LTAI models the complex relationship between the topics of the publications, the current authority of the authors and the citations between these publications. The generative process of the LTAI can be divided into two parts: content creation and citation network generation. We assume that the authority of an author (i.e. the potential to generate citations) differs for each topic and that the thematic authority of an author positively correlates with the probability of citation between publications. Also, in the LTAI, if there are several authors in a single cited publication, their contribution to the formation of citations in relation to different citations varies according to their current authority."}, {"heading": "3.1 Content Generation", "text": "In order to model the contents of publications, we follow a standard document-generating process of latent Dirichlet allocation (LDA) (Blei et al., 2003). In addition, we inherit notations for variables from LDA; \u03b8 is the thematic distribution per document, \u03b2 is the word distribution per topic, z is the theme for each word in a document where w is the corresponding word, and \u03b1\u03b8, \u03b1\u03b2 are the dirichlet parameters of \u03b8 and \u03b2 respectively."}, {"heading": "3.2 Citation Generation", "text": "We formulate a continuous variable ri-j, which is a linear combination of authority variables and thematic proportional variables in the field of recommendation systems (Rennie and Srebro, 2005; Koren et al., 2009). There is a number of research results on the use of continuous variables that can probably be generalized (Salakhutdinov and Mnih, 2007). Using the probabilistic matrix factorization, we approach the probability mass function p (xi) using the probability density function N (xi)."}, {"heading": "3.3 Joint Modeling of the LTAI", "text": "In the LTAI, the topics and the link structures are learned simultaneously, whereby the content-related variables and the citation-related variables mutually reshape each other during the posterior inference. However, if content and citation data are modeled separately, the topics would not reflect information about the document citation structure. Therefore, documents with common links tend to exhibit similar topic distributions in the LTAI, which leads to better modelability. We develop and explain this common conclusion in Section 4. In Section 7, we illustrate the differences in the word-related predictive power of LTAI and LDA."}, {"heading": "4 Posterior Inference", "text": "We develop a hybrid inference algorithm in which the rear content-related parameters \u03b8, z and \u03b2 are approximated by inference of variation and the author-related parameters \u03c0 and \u03b7 are approximated by EM. In algorithm 1 we summarize the complete inference procedure of the LTAI."}, {"heading": "4.1 Content Parameters: Variational Update", "text": "Since the calculation of the subsequent distribution of the LTAI is not possible, we use variable conclusions to optimize variable parameters, each of which corresponds to the original content-related variables. Following the standard middle field approach, we define fully factorized variational distributions via the theme-related latent variables, placing the same family of distribution variables as the original distribution. Using the variational distributions, we have bound the log liquidity of the model as follows: L [q] c c c c c] q [c] c c c [q] q [q] q [q] q [q] q [q] q q \"q\" q \"c\" c c c c c c c c \"c c c c\" c \"c\" q \"c\" q \"q\" q \"q\" q \"c\" c \"c\" c \"c\" c \"q\" q \"q\" q [q] q [q] q [q] q \"c c\" c \"c c c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" q \"q\" q \"q\" q \"q\" q \"q\" q \"q\" q \"q\" q \"c c c c c c\" c \"c c c c c\" c c c \"c c c c\" c \"c\" c c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c c \"c\" c \"c\" c \"c c c\" c \"c\" c c \"c\" c \"c\" c c \"c\" c \"c\" c \"c\" c \"c c c\" c \"c\" c c \"c\" c \"c"}, {"heading": "4.2 Author Parameters: EM Step", "text": "In the E step, we calculate the probability that the author will contribute to the linkage between document i and j.\u03c0i. (6) In the M step, we optimize the authority parameters of all authors. Taking into account the other estimated parameters, taking into account the gradient of L with respect to \"a\" and setting it to zero leads to the following update equation: \"a\" = (1) \"CaXa\" + \"I\" \u2212 \"1\" CaXa \"(7)\" There is the amount of documents written by the author a, and \"Da\" (i) is the document written by a. Then, \"a\" is a vertical stack of \"Da | matrices\" (7) \"Da\" a vertical stack of \"Da\" i. \"(Da\" i \") is a vertical stack of\" Da. \""}, {"heading": "5 Faster Inference Using Stochastic Optimization", "text": "In order to model the current authority, the LTAI takes into account the concatenation information. If two works are linked by citation, the current authority of the authors of the cited paper increases, while the negative concatenation buffers the potential noise of irrelevant topics. This algorithmic design of the LTAI leads to a high model complexity. To solve this problem, we use the method of noisy gradient from the stochastic approximation algorithm (Robbins and Monro, 1951) to investigate negative associations for updating variation parameters and authority parameters per document. The earlier work of using subsampled negative associations to reduce computational complexity is introduced in (Raftery et al., 2012). Furthermore, we explain how stochastic variation parameters (Hoffman et al., 2013) are applied in our model to update global variation parameters per topic."}, {"heading": "5.1 Updating \u03c6 and \u03b7", "text": "This results in the temporal complexity O (DK) for each individual person. \u2212 To apply the progression method, we divide the progression degree of the expected log probability of linkage into two parts: [Log] j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"j\" j \"g\" g \"g\" g \"g\" g \"g\" g \"g\" g \"g\" g \"g\" g \"g\" g \"g\" g \"g\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"h\" h \"h\" h \"h\" s. \"h\" h \"s\" s \"s\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"h h h h\" s."}, {"heading": "5.2 Updating \u03bb", "text": "This problem is more evident in the LTAI, since updating the variation parameters using Equation 3 is slower than updating the topical authority variables per author (Hoffman et al., 2013). However, applying stochastic variation conclusions for the LTAI is straightforward after we have adjusted the intermediate topic-word-variation parameter-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-inference-rate-inference-inference-inference-rate-1-inference-inference-rate-1-inference-inference-rate-1-inference-inference-rate-1-inference-inference-rate-1-inference-inference-inference-rate-1-inference-1-inference-rate-1-1-inference-inference-rate-1-1-inference-inference-rate-1-1-inference-inference-inference-rate-1-1-inference rate-1-inference-1-inference rate-1-1-inference rate-1-inference rate-1-1-inference rate-1-inference rate-1-1-inference-1-inference-1-inference-1-rate-1-1-inference-1-1-1-inference rate-1-1-1"}, {"heading": "6 Experimental Settings", "text": "In this section, we present the four academic corporations used to adapt to the LTAI, describe comparison models and provide information on the evaluation metrics and parameter settings for the LTAI1."}, {"heading": "6.1 Datasets", "text": "We are experimenting with four academic corporations: CORA (McCallum et al., 2000), Arxiv-Physics (Gehrke et al., 2003), the Proceedings of the National Academy of Sciences (PNAS), and Citeseer (Lu and Getoor, 2003). CORA, Arxiv-Physics, and PNAS records contain only abstracts, and the positions of citations within each essay are not preserved, whereas the Citeseer record contains the citation locations. For CORA, Arxiv-Physics, and PNAS records, we lemmatize words, remove stopwords, and discard words that occur less than four times in the corpus. Table 1 describes the records in detail. Note that we obtain citation data from the entire document, not just from the abstract. Also, we only consider corpus citations, resulting in less than 13 average citations per document for all corporate code and data sets available at http: / Tacr / tacr."}, {"heading": "6.2 Comparison Models", "text": "This year, it is at an all-time high in the history of the European Union."}, {"heading": "6.3 Evaluation Metric and Parameter Settings", "text": "We use the mean reciprocal rank (MRR) (Voorhees, 1999) to measure the predictive power of LTAI and comparative models. MRR is a widely used measurement for evaluating link prediction tasks (Balog and De Rijke, 2007; Diehl et al., 2007; Radlinski et al., 2008; Huang et al., 2015). If the models output the correct answers in order of precedence, MRR is the opposite of the harmonic mean of such rankings. We specify the parameter values used for evaluations. For all datasets we use c \u2212 to 1. To predict the citation, we set c + to 10,000, 100, 1,000, 10, and to predict authorship c + to 1,000, 1,000, 10,000, 1,000 for CORA, Arxiv Physics, PNAS, and Citeseer datasets. These values are determined by an exhaustive parameter analysis."}, {"heading": "7 Evaluation", "text": "We perform the evaluation of the LTAI with three different quantitative tasks and a qualitative analysis. In the first task, we examine whether the use of citation and author information in the LTAI contributes to increasing the predictive power at the word level. In the second and third task, we measure the predictability of the LTAI in terms of the lack of a link between publication and author publication; with these two tasks, we compare the predictive power of the LTAI with other comparative models and use MRR as a benchmark. Finally, we observe the current authority values of famous researchers generated by the LTAI and examine how these values capture remarkable academic characteristics of researchers."}, {"heading": "7.1 Word-level Prediction", "text": "In the LTAI, citation and author information influence the proportions per document, as can be confirmed in Eq.3. This combined modeling of the content and linkage structure results in better performance in predicting missing words in documents compared to vanilla LDA, which only uses content data. In this task, we use a logopredictive probability, a measurement widely used in other research to measure model suitability (Teh et al., 2006; Asuncion et2Although we do not present a thorough sensitivity analysis in this paper, we confirm that the performance of our model was robust against adjusting the parameters within a factor of 2, al., 2009; Hoffman et al., 2013). For each corpus, we separate one-third of the documents as a test set, and for all documents in each test set, we use half of the words for training per document-theme proportion, and predict the probability of the word-prediction-prediction per the remaining half."}, {"heading": "7.2 Citation Prediction", "text": "In order to predict the citation relationship between publications, we first calculate the probability that the publication j will quote from p (xi \u2190 j | z, Ai, \u03c0i) of each of the documents in the test set i. Given the proportion of topics in the cited publication \u03b8i and the thematic authorities of the authors \u03b7a, we calculate which publication is more likely to quote the publication. Based on our model assumption in Section 3.2, the use of topical authority increases the performance of predicting linkage structures. In Figure 5, the LTAI provides better citation performance than other models for all datasets and with the most number of topics. As the LTAI includes the topical authority for predicting citations.By comparison, the LTAI results in a better citation performance than other models for all datasets and with the most number of topics."}, {"heading": "7.3 Author Prediction", "text": "In the case of author prediction, we randomly remove one of the authors from the test set documents while maintaining the citation structures. Similar to the citation prediction, we predict which author is more likely to write the cited publication based on the subject portions of the cited publication i and a number of citing publications J. We approach the probability that a researcher is author of the publication i from p (a | z, \u03b7a, xi \u2190 j) \u043d\u0438\u043d\u0438\u0439 J N (xi \u2190 j > i diag (\u03b7a) z-j, c \u2212 1 +). Since the mixed portion of an unknown author \u03c0i \u2190 yes cannot be determined during posterior inference, we assume that the cited publication was written by a single author to approximate the probability. In the author prediction, we select the author who maximizes the above probability. In Figure 6, the LTAI exceeds the comparison models in most cases."}, {"heading": "7.4 Qualitative Analysis", "text": "In fact, we are able to put ourselves at the forefront in the way we have done it in the past: in the way we have done it, in the way we have done it, in the way we have done it, in the way we have done it, in the way we have done it, in the way we have done it, in the way we have done it. \""}, {"heading": "8 Conclusion and Discussion", "text": "Based on the hypothesis that authors play an important role in citation, we focus specifically on their authority and develop a Bayesian model to grasp authority. Using model assumptions necessary to extract compelling and interpretable current authority values for authors, we have proposed acceleration methods based on stochastic optimization. While there is already research in the field of theme modeling that provides theme-specific indices in modeling the link structure, these do not extend to individual indices, and most previous quotation-based indices are defined for each individual, but do not include themes. On the other hand, our model combines the merits of both theme-specific and individual indices to provide academic researchers with up-to-to-date authority information. We have demonstrated with four academic datasets that joint modeling of publication and author-related variables improves theme quality when compared with Vanilla LDA."}, {"heading": "Acknowledgments", "text": "We would like to thank Jae Won Kim for his help in collecting, refining the dataset and contributing to the early version of the manuscript, anonymous reviewers, as well as TACL editor Noah Smith for detailed and thoughtful commentary, and Joon Hee Kim and other UILab members for providing helpful insights into the research supported by the Institute for Information & Communications Technology Promotion (IITP) funded by the Korean government (MSIP) (No. B0101-15-0307, Basic Software Research in Human-level Lifelong Machine Learning (Machine Learning Center))."}], "references": [{"title": "On smoothing and inference for topic models", "author": ["Arthur Asuncion", "Max Welling", "Padhraic Smyth", "Yee Whye Teh."], "venue": "UAI.", "citeRegEx": "Asuncion et al\\.,? 2009", "shortCiteRegEx": "Asuncion et al\\.", "year": 2009}, {"title": "Determining expert profiles (with an application to expert finding)", "author": ["Krisztian Balog", "Maarten De Rijke."], "venue": "IJCAI.", "citeRegEx": "Balog and Rijke.,? 2007", "shortCiteRegEx": "Balog and Rijke.", "year": 2007}, {"title": "Latent Dirichlet allocation", "author": ["David M. Blei", "Andrew Y. Ng", "Michael I. Jordan."], "venue": "JMLR, pages 993\u2013 1022.", "citeRegEx": "Blei et al\\.,? 2003", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Citationenhanced keyphrase extraction from research papers: A supervised approach", "author": ["Cornelia Caragea", "Florin Adrian Bulgarov", "Andreea Godea", "Sujatha Das Gollapalli."], "venue": "EMNLP.", "citeRegEx": "Caragea et al\\.,? 2014", "shortCiteRegEx": "Caragea et al\\.", "year": 2014}, {"title": "Co-training for topic classification of scholarly data", "author": ["Cornelia Caragea", "Florin Bulgarov", "Rada Mihalcea."], "venue": "EMNLP.", "citeRegEx": "Caragea et al\\.,? 2015", "shortCiteRegEx": "Caragea et al\\.", "year": 2015}, {"title": "Hierarchical relational models for document networks", "author": ["Jonathan Chang", "David M. Blei."], "venue": "The Annals of Applied Statistics, pages 124\u2013150.", "citeRegEx": "Chang and Blei.,? 2010", "shortCiteRegEx": "Chang and Blei.", "year": 2010}, {"title": "Scientific article summarization using citation-context and article\u2019s discourse structure", "author": ["Arman Cohan", "Nazli Goharian."], "venue": "EMNLP.", "citeRegEx": "Cohan and Goharian.,? 2015", "shortCiteRegEx": "Cohan and Goharian.", "year": 2015}, {"title": "Relationship identification for social network discovery", "author": ["Christopher P. Diehl", "Galileo Namata", "Lise Getoor."], "venue": "AAAI.", "citeRegEx": "Diehl et al\\.,? 2007", "shortCiteRegEx": "Diehl et al\\.", "year": 2007}, {"title": "Unsupervised prediction of citation influences", "author": ["Laura Dietz", "Steffen Bickel", "Tobias Scheffer."], "venue": "ICML.", "citeRegEx": "Dietz et al\\.,? 2007", "shortCiteRegEx": "Dietz et al\\.", "year": 2007}, {"title": "Will this paper increase your h-index?: Scientific impact prediction", "author": ["Yuxiao Dong", "Reid A. Johnson", "Nitesh V. Chawla."], "venue": "WSDM.", "citeRegEx": "Dong et al\\.,? 2015", "shortCiteRegEx": "Dong et al\\.", "year": 2015}, {"title": "Modeling scientific impact with topical influence regression", "author": ["James R. Foulds", "Padhraic Smyth."], "venue": "EMNLP.", "citeRegEx": "Foulds and Smyth.,? 2013", "shortCiteRegEx": "Foulds and Smyth.", "year": 2013}, {"title": "The history and meaning of the journal impact factor", "author": ["Eugene Garfield."], "venue": "JAMA, 295(1):90\u201393.", "citeRegEx": "Garfield.,? 2006", "shortCiteRegEx": "Garfield.", "year": 2006}, {"title": "Overview of the 2003 KDD Cup", "author": ["Johannes Gehrke", "Paul Ginsparg", "Jon Kleinberg."], "venue": "ACM SIGKDD Explorations Newsletter, 5(2):149\u2013151.", "citeRegEx": "Gehrke et al\\.,? 2003", "shortCiteRegEx": "Gehrke et al\\.", "year": 2003}, {"title": "Discovering canonical correlations between topical and topological information in document networks", "author": ["Yuan He", "Cheng Wang", "Changjun Jiang."], "venue": "CIKM.", "citeRegEx": "He et al\\.,? 2015", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "An index to quantify an individual\u2019s scientific research output", "author": ["Jorge E. Hirsch."], "venue": "PNAS, 102(46):16569\u201316572.", "citeRegEx": "Hirsch.,? 2005", "shortCiteRegEx": "Hirsch.", "year": 2005}, {"title": "Stochastic variational inference", "author": ["Matthew D. Hoffman", "David M. Blei", "Chong Wang", "John W. Paisley."], "venue": "JMLR, 14(1):1303\u20131347.", "citeRegEx": "Hoffman et al\\.,? 2013", "shortCiteRegEx": "Hoffman et al\\.", "year": 2013}, {"title": "Collaborative filtering for implicit feedback datasets", "author": ["Yifan Hu", "Yehuda Koren", "Chris Volinsky."], "venue": "ICDM.", "citeRegEx": "Hu et al\\.,? 2008", "shortCiteRegEx": "Hu et al\\.", "year": 2008}, {"title": "A neural probabilistic model for context based citation recommendation", "author": ["Wenyi Huang", "Zhaohui Wu", "Chen Liang", "Prasenjit Mitra", "C. Lee Giles."], "venue": "AAAI.", "citeRegEx": "Huang et al\\.,? 2015", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "Chronological scientific information recommendation via supervised dynamic topic modeling", "author": ["Zhuoren Jiang."], "venue": "WSDM.", "citeRegEx": "Jiang.,? 2015", "shortCiteRegEx": "Jiang.", "year": 2015}, {"title": "Context sensitive topic models for author influence in document networks", "author": ["Saurabh Kataria", "Prasenjit Mitra", "Cornelia Caragea", "C. Lee Giles."], "venue": "IJCAI.", "citeRegEx": "Kataria et al\\.,? 2011", "shortCiteRegEx": "Kataria et al\\.", "year": 2011}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Yehuda Koren", "Robert Bell", "Chris Volinsky."], "venue": "Computer, 42(8).", "citeRegEx": "Koren et al\\.,? 2009", "shortCiteRegEx": "Koren et al\\.", "year": 2009}, {"title": "Topic-link LDA: joint models of topic and author community", "author": ["Yan Liu", "Alexandru Niculescu-Mizil", "Wojciech Gryc."], "venue": "ICML.", "citeRegEx": "Liu et al\\.,? 2009", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "Link-based classification", "author": ["Qing Lu", "Lise Getoor."], "venue": "ICML.", "citeRegEx": "Lu and Getoor.,? 2003", "shortCiteRegEx": "Lu and Getoor.", "year": 2003}, {"title": "Automating the construction of internet portals with machine learning", "author": ["Andrew Kachites McCallum", "Kamal Nigam", "Jason Rennie", "Kristie Seymore."], "venue": "Information Retrieval, 3(2):127\u2013163.", "citeRegEx": "McCallum et al\\.,? 2000", "shortCiteRegEx": "McCallum et al\\.", "year": 2000}, {"title": "Some results on the function and quality of citations", "author": ["Michael J. Moravcsik", "Poovanalingam Murugesan."], "venue": "Social studies of science, 5(1):86\u201392.", "citeRegEx": "Moravcsik and Murugesan.,? 1975", "shortCiteRegEx": "Moravcsik and Murugesan.", "year": 1975}, {"title": "Joint latent topic models for text and citations", "author": ["Ramesh M. Nallapati", "Amr Ahmed", "Eric P. Xing", "William W Cohen."], "venue": "SIGKDD.", "citeRegEx": "Nallapati et al\\.,? 2008", "shortCiteRegEx": "Nallapati et al\\.", "year": 2008}, {"title": "Modeling citation networks using latent random offsets", "author": ["Willie Neiswanger", "Chong Wang", "Qirong Ho", "Eric P. Xing."], "venue": "UAI.", "citeRegEx": "Neiswanger et al\\.,? 2014", "shortCiteRegEx": "Neiswanger et al\\.", "year": 2014}, {"title": "Collaborative topic regression with social matrix factorization for recommendation systems", "author": ["Sanjay Purushotham", "Yan Liu", "C.-C. Jay Kuo."], "venue": "arXiv preprint arXiv:1206.4684.", "citeRegEx": "Purushotham et al\\.,? 2012", "shortCiteRegEx": "Purushotham et al\\.", "year": 2012}, {"title": "How does clickthrough data reflect retrieval quality? In CIKM", "author": ["Filip Radlinski", "Madhu Kurup", "Thorsten Joachims"], "venue": null, "citeRegEx": "Radlinski et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Radlinski et al\\.", "year": 2008}, {"title": "Fast inference for the latent space network model using a case-control approximate likelihood", "author": ["Adrian E. Raftery", "Xiaoyue Niu", "Peter D. Hoff", "Ka Yee Yeung."], "venue": "Journal of Computational and Graphical Statistics, 21(4):901\u2013919.", "citeRegEx": "Raftery et al\\.,? 2012", "shortCiteRegEx": "Raftery et al\\.", "year": 2012}, {"title": "Fast maximum margin matrix factorization for collaborative prediction", "author": ["Jasson D.M. Rennie", "Nathan Srebro."], "venue": "ICML.", "citeRegEx": "Rennie and Srebro.,? 2005", "shortCiteRegEx": "Rennie and Srebro.", "year": 2005}, {"title": "A stochastic approximation method", "author": ["Herbert Robbins", "Sutton Monro."], "venue": "The annals of mathematical statistics, pages 400\u2013407.", "citeRegEx": "Robbins and Monro.,? 1951", "shortCiteRegEx": "Robbins and Monro.", "year": 1951}, {"title": "The author-topic model for authors and documents", "author": ["Michal Rosen-Zvi", "Thomas Griffiths", "Mark Steyvers", "Padhraic Smyth."], "venue": "UAI.", "citeRegEx": "Rosen.Zvi et al\\.,? 2004", "shortCiteRegEx": "Rosen.Zvi et al\\.", "year": 2004}, {"title": "Probabilistic matrix factorization", "author": ["Ruslan Salakhutdinov", "Andriy Mnih."], "venue": "NIPS.", "citeRegEx": "Salakhutdinov and Mnih.,? 2007", "shortCiteRegEx": "Salakhutdinov and Mnih.", "year": 2007}, {"title": "A utility model of authors in the scientific community", "author": ["Yanchuan Sim", "Bryan R. Routledge", "Noah A. Smith."], "venue": "EMNLP.", "citeRegEx": "Sim et al\\.,? 2015", "shortCiteRegEx": "Sim et al\\.", "year": 2015}, {"title": "Hierarchical dirichlet processes", "author": ["Yee Whye Teh", "Michael I Jordan", "Matthew J. Beal", "David M Blei."], "venue": "Journal of the American Statistical Association.", "citeRegEx": "Teh et al\\.,? 2006", "shortCiteRegEx": "Teh et al\\.", "year": 2006}, {"title": "Automatic classification of citation function", "author": ["Simone Teufel", "Advaith Siddharthan", "Dan Tidhar."], "venue": "EMNLP.", "citeRegEx": "Teufel et al\\.,? 2006", "shortCiteRegEx": "Teufel et al\\.", "year": 2006}, {"title": "Citation author topic model in expert search", "author": ["Yuancheng Tu", "Nikhil Johri", "Dan Roth", "Julia Hockenmaier."], "venue": "COLING.", "citeRegEx": "Tu et al\\.,? 2010", "shortCiteRegEx": "Tu et al\\.", "year": 2010}, {"title": "Identifying meaningful citations", "author": ["Marco Valenzuela", "Vu Ha", "Oren Etzioni."], "venue": "Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence.", "citeRegEx": "Valenzuela et al\\.,? 2015", "shortCiteRegEx": "Valenzuela et al\\.", "year": 2015}, {"title": "The TREC-8 question answering track report", "author": ["Ellen M. Voorhees."], "venue": "TREC, volume 99, pages 77\u201382.", "citeRegEx": "Voorhees.,? 1999", "shortCiteRegEx": "Voorhees.", "year": 1999}, {"title": "Collaborative topic modeling for recommending scientific articles", "author": ["Chong Wang", "David M. Blei."], "venue": "SIGKDD.", "citeRegEx": "Wang and Blei.,? 2011", "shortCiteRegEx": "Wang and Blei.", "year": 2011}, {"title": "LDTM: A latent document type model for cumulative citation recommendation", "author": ["Jingang Wang", "Dandan Song", "Zhiwei Zhang", "Lejian Liao", "Luo Si", "Chin-Yew Lin."], "venue": "EMNLP.", "citeRegEx": "Wang et al\\.,? 2015", "shortCiteRegEx": "Wang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 14, "context": "arly impact, such as the h-index (Hirsch, 2005), the journal impact factor (Garfield, 2006), and citation count.", "startOffset": 33, "endOffset": 47}, {"referenceID": 11, "context": "arly impact, such as the h-index (Hirsch, 2005), the journal impact factor (Garfield, 2006), and citation count.", "startOffset": 75, "endOffset": 91}, {"referenceID": 2, "context": "To show the improvements over other related models, we carry out prediction tasks on word, citation and authorship using the LTAI and compare the results with those of latent Dirichlet allocation (Blei et al., 2003), relational topic model (Chang and Blei, 2010), author-link topic model, and dynamic authorcite topic model (Kataria et al.", "startOffset": 196, "endOffset": 215}, {"referenceID": 5, "context": ", 2003), relational topic model (Chang and Blei, 2010), author-link topic model, and dynamic authorcite topic model (Kataria et al.", "startOffset": 32, "endOffset": 54}, {"referenceID": 19, "context": ", 2003), relational topic model (Chang and Blei, 2010), author-link topic model, and dynamic authorcite topic model (Kataria et al., 2011), as well as simple baselines of topical h-index.", "startOffset": 116, "endOffset": 138}, {"referenceID": 4, "context": "In analyzing scientific corpora, previous research presents classifying scientific publications (Caragea et al., 2015), recommending yet unlinked citations (Huang et al.", "startOffset": 96, "endOffset": 118}, {"referenceID": 17, "context": ", 2015), recommending yet unlinked citations (Huang et al., 2015; Neiswanger et al., 2014; Wang et al., 2015; Jiang, 2015), summarizing and extracting key phrases (Cohan and Goharian, 2015; Caragea et al.", "startOffset": 45, "endOffset": 122}, {"referenceID": 26, "context": ", 2015), recommending yet unlinked citations (Huang et al., 2015; Neiswanger et al., 2014; Wang et al., 2015; Jiang, 2015), summarizing and extracting key phrases (Cohan and Goharian, 2015; Caragea et al.", "startOffset": 45, "endOffset": 122}, {"referenceID": 41, "context": ", 2015), recommending yet unlinked citations (Huang et al., 2015; Neiswanger et al., 2014; Wang et al., 2015; Jiang, 2015), summarizing and extracting key phrases (Cohan and Goharian, 2015; Caragea et al.", "startOffset": 45, "endOffset": 122}, {"referenceID": 18, "context": ", 2015), recommending yet unlinked citations (Huang et al., 2015; Neiswanger et al., 2014; Wang et al., 2015; Jiang, 2015), summarizing and extracting key phrases (Cohan and Goharian, 2015; Caragea et al.", "startOffset": 45, "endOffset": 122}, {"referenceID": 6, "context": ", 2015; Jiang, 2015), summarizing and extracting key phrases (Cohan and Goharian, 2015; Caragea et al., 2014), triggering better model fit (He et al.", "startOffset": 61, "endOffset": 109}, {"referenceID": 3, "context": ", 2015; Jiang, 2015), summarizing and extracting key phrases (Cohan and Goharian, 2015; Caragea et al., 2014), triggering better model fit (He et al.", "startOffset": 61, "endOffset": 109}, {"referenceID": 13, "context": ", 2014), triggering better model fit (He et al., 2015), incorporating authorship information to increase the content and link predictability (Sim et al.", "startOffset": 37, "endOffset": 54}, {"referenceID": 34, "context": ", 2015), incorporating authorship information to increase the content and link predictability (Sim et al., 2015), estimating a paper\u2019s potential influence on academic community (Dong et al.", "startOffset": 94, "endOffset": 112}, {"referenceID": 9, "context": ", 2015), estimating a paper\u2019s potential influence on academic community (Dong et al., 2015), and finding and classifying different functionalities of citation practices (Moravcsik and Murugesan, 1975; Teufel et al.", "startOffset": 72, "endOffset": 91}, {"referenceID": 24, "context": ", 2015), and finding and classifying different functionalities of citation practices (Moravcsik and Murugesan, 1975; Teufel et al., 2006; Valenzuela et al., 2015).", "startOffset": 85, "endOffset": 162}, {"referenceID": 36, "context": ", 2015), and finding and classifying different functionalities of citation practices (Moravcsik and Murugesan, 1975; Teufel et al., 2006; Valenzuela et al., 2015).", "startOffset": 85, "endOffset": 162}, {"referenceID": 38, "context": ", 2015), and finding and classifying different functionalities of citation practices (Moravcsik and Murugesan, 1975; Teufel et al., 2006; Valenzuela et al., 2015).", "startOffset": 85, "endOffset": 162}, {"referenceID": 8, "context": "Topic models that use text and citation network are divided into two types: (a) models that generate text given citation network (Dietz et al., 2007; Foulds and Smyth, 2013) and (b) models that generate citation network given text (Nallapati et al.", "startOffset": 129, "endOffset": 173}, {"referenceID": 10, "context": "Topic models that use text and citation network are divided into two types: (a) models that generate text given citation network (Dietz et al., 2007; Foulds and Smyth, 2013) and (b) models that generate citation network given text (Nallapati et al.", "startOffset": 129, "endOffset": 173}, {"referenceID": 25, "context": ", 2007; Foulds and Smyth, 2013) and (b) models that generate citation network given text (Nallapati et al., 2008; Liu et al., 2009; Chang and Blei, 2010).", "startOffset": 89, "endOffset": 153}, {"referenceID": 21, "context": ", 2007; Foulds and Smyth, 2013) and (b) models that generate citation network given text (Nallapati et al., 2008; Liu et al., 2009; Chang and Blei, 2010).", "startOffset": 89, "endOffset": 153}, {"referenceID": 5, "context": ", 2007; Foulds and Smyth, 2013) and (b) models that generate citation network given text (Nallapati et al., 2008; Liu et al., 2009; Chang and Blei, 2010).", "startOffset": 89, "endOffset": 153}, {"referenceID": 37, "context": "Most closely related to the LTAI are the citation author topic model (Tu et al., 2010), the authorlink topic model, and the dynamic author-cite topic model (Kataria et al.", "startOffset": 69, "endOffset": 86}, {"referenceID": 19, "context": ", 2010), the authorlink topic model, and the dynamic author-cite topic model (Kataria et al., 2011).", "startOffset": 77, "endOffset": 99}, {"referenceID": 2, "context": "To model the content of publications, we follow a standard document generative process of latent Dirichlet allocation (LDA) (Blei et al., 2003).", "startOffset": 124, "endOffset": 143}, {"referenceID": 30, "context": "There is a body of research on using continuous user and item-related variables to approximate binary variables in the field of recommender systems (Rennie and Srebro, 2005; Koren et al., 2009).", "startOffset": 148, "endOffset": 193}, {"referenceID": 20, "context": "There is a body of research on using continuous user and item-related variables to approximate binary variables in the field of recommender systems (Rennie and Srebro, 2005; Koren et al., 2009).", "startOffset": 148, "endOffset": 193}, {"referenceID": 33, "context": "Approximating binary variables using linear combination of continuous variables can be probabilistically generalized (Salakhutdinov and Mnih, 2007).", "startOffset": 117, "endOffset": 147}, {"referenceID": 5, "context": "Following relational topic model\u2019s approach (Chang and Blei, 2010), we use z\u0304i = 1 Ni \u2211 n zi,n \u2248 \u03b8i instead of topic proportion parameter \u03b8i.", "startOffset": 44, "endOffset": 66}, {"referenceID": 16, "context": "This is an implicit feedback approach that permits using negative examples (xi\u2190j = 0) of sparse observations by mitigating their importance (Hu et al., 2008; Wang and Blei, 2011; Purushotham et al., 2012).", "startOffset": 140, "endOffset": 204}, {"referenceID": 40, "context": "This is an implicit feedback approach that permits using negative examples (xi\u2190j = 0) of sparse observations by mitigating their importance (Hu et al., 2008; Wang and Blei, 2011; Purushotham et al., 2012).", "startOffset": 140, "endOffset": 204}, {"referenceID": 27, "context": "This is an implicit feedback approach that permits using negative examples (xi\u2190j = 0) of sparse observations by mitigating their importance (Hu et al., 2008; Wang and Blei, 2011; Purushotham et al., 2012).", "startOffset": 140, "endOffset": 204}, {"referenceID": 2, "context": "The update for the variational Dirichlet parameters \u03b3i and the \u03bbk is the same as the standard variational update for LDA (Blei et al., 2003).", "startOffset": 121, "endOffset": 140}, {"referenceID": 31, "context": "To remedy this issue, we adopt the noisy gradient method from the stochastic approximation algorithm (Robbins and Monro, 1951) to subsample negative links for updating per-document topic variational parameter \u03c6 and authority parameter \u03b7.", "startOffset": 101, "endOffset": 126}, {"referenceID": 29, "context": "The prior work of using subsampled negative links to reduce computational complexity is introduced in (Raftery et al., 2012).", "startOffset": 102, "endOffset": 124}, {"referenceID": 15, "context": "Also, we elucidate how stochastic variational inference (Hoffman et al., 2013) is applied in our model to update global per-topic-word variational parameter \u03bb.", "startOffset": 56, "endOffset": 78}, {"referenceID": 15, "context": "However, using the stochastic variational inference, the global parameters are updated after a small portion of local parameters are updated (Hoffman et al., 2013).", "startOffset": 141, "endOffset": 163}, {"referenceID": 31, "context": "Posterior inference is guaranteed to converge at local optimum when the learning rate satisfies the condition \u2211\u221e t=1 \u03c1t = \u221e, \u2211\u221e t=1 \u03c1 2 t < \u221e (Robbins and Monro, 1951).", "startOffset": 142, "endOffset": 167}, {"referenceID": 23, "context": "We experiment with four academic corpora: CORA (McCallum et al., 2000), Arxiv-Physics (Gehrke et al.", "startOffset": 47, "endOffset": 70}, {"referenceID": 12, "context": ", 2000), Arxiv-Physics (Gehrke et al., 2003), the Proceedings of the National Academy of Sciences (PNAS), and Citeseer (Lu and Getoor, 2003).", "startOffset": 23, "endOffset": 44}, {"referenceID": 22, "context": ", 2003), the Proceedings of the National Academy of Sciences (PNAS), and Citeseer (Lu and Getoor, 2003).", "startOffset": 82, "endOffset": 103}, {"referenceID": 2, "context": "Latent Dirichlet Allocation: LDA (Blei et al., 2003) discovers topics and represents each publication by mixture of the topics.", "startOffset": 33, "endOffset": 52}, {"referenceID": 5, "context": "Relational Topic Model: RTM (Chang and Blei, 2010) jointly models content and citation, and thus, topic proportions of a pair of publications become similar if the pair is connected by citations.", "startOffset": 28, "endOffset": 50}, {"referenceID": 19, "context": "Author-Link Topic Model: ALTM (Kataria et al., 2011) is a variation of author topic model (ATM) (Rosen-Zvi et al.", "startOffset": 30, "endOffset": 52}, {"referenceID": 32, "context": ", 2011) is a variation of author topic model (ATM) (Rosen-Zvi et al., 2004) that models both topical interests and influence of authors in scientific corpora.", "startOffset": 51, "endOffset": 75}, {"referenceID": 19, "context": "Dynamic Author-Citation Topic Model: DACTM (Kataria et al., 2011) is an extension of ALTM that requires publication corpora which preserve sentence structures.", "startOffset": 43, "endOffset": 65}, {"referenceID": 39, "context": "We use mean reciprocal rank (MRR) (Voorhees, 1999) to measure the predictive performance of the LTAI and the comparison models.", "startOffset": 34, "endOffset": 50}, {"referenceID": 7, "context": "MRR is a widely used metric for evaluating link prediction tasks (Balog and De Rijke, 2007; Diehl et al., 2007; Radlinski et al., 2008; Huang et al., 2015).", "startOffset": 65, "endOffset": 155}, {"referenceID": 28, "context": "MRR is a widely used metric for evaluating link prediction tasks (Balog and De Rijke, 2007; Diehl et al., 2007; Radlinski et al., 2008; Huang et al., 2015).", "startOffset": 65, "endOffset": 155}, {"referenceID": 17, "context": "MRR is a widely used metric for evaluating link prediction tasks (Balog and De Rijke, 2007; Diehl et al., 2007; Radlinski et al., 2008; Huang et al., 2015).", "startOffset": 65, "endOffset": 155}], "year": 2017, "abstractText": "Much of scientific progress stems from previously published findings, but searching through the vast sea of scientific publications is difficult. We often rely on metrics of scholarly authority to find the prominent authors but these authority indices do not differentiate authority based on research topics. We present Latent Topical-Authority Indexing (LTAI) for jointly modeling the topics, citations, and topical authority in a corpus of academic papers. Compared to previous models, LTAI differs in two main aspects. First, it explicitly models the generative process of the citations, rather than treating the citations as given. Second, it models each author\u2019s influence on citations of a paper based on the topics of the cited papers, as well as the citing papers. We fit LTAI to four academic corpora: CORA, Arxiv Physics, PNAS, and Citeseer. We compare the performance of LTAI against various baselines, starting with the latent Dirichlet allocation, to the more advanced models including author-link topic model and dynamic author citation topic model. The results show that LTAI achieves improved accuracy over other similar models when predicting words, citations and authors of publications.", "creator": "LaTeX with hyperref package"}}}