{"id": "1706.01427", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2017", "title": "A simple neural network module for relational reasoning", "abstract": "Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Our work shows how a deep learning architecture equipped with an RN module can implicitly discover and learn to reason about entities and their relations.", "histories": [["v1", "Mon, 5 Jun 2017 17:17:18 GMT  (1069kb,D)", "http://arxiv.org/abs/1706.01427v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["adam santoro", "david raposo", "david g t barrett", "mateusz malinowski", "razvan pascanu", "peter battaglia", "timothy lillicrap"], "accepted": true, "id": "1706.01427"}, "pdf": {"name": "1706.01427.pdf", "metadata": {"source": "CRF", "title": "A simple neural network module for relational reasoning", "authors": ["Adam Santoro", "David Raposo", "David G.T. Barrett", "Mateusz Malinowski", "Razvan Pascanu", "Peter Battaglia", "Timothy Lillicrap"], "emails": ["adamsantoro@,", "draposo@,", "barrettdavid@,", "mateuszm@,", "razp@,", "peterbattaglia@,", "countzero@google.com"], "sections": [{"heading": "1 Introduction", "text": "The ability to think about the relationships between entities and their characteristics is central to generally intelligent behavior (Figure 1) [18, 15]. Consider a child suggesting a race between the two trees in the park that are furthest apart: the paired distances between each tree in the park must be derived and compared to know where to go. Or consider a reader assembling evidence to predict the perpetrator in a murder mystery novel: each clue must be taken into account in its broader context to build a plausible narrative and solve the mysteries. Symbolic approaches to artificial intelligence are inherently relativized [32, 11]."}, {"heading": "2 Relation Networks", "text": "The design philosophy behind RNs, therefore, consists in limiting the functional form of a neural network so that it captures the central common properties of relational thinking. In other words, the ability to calculate relationships is built into the RN architecture without having to be learned, as well as the ability to think about spatial, translation-related properties that are built into CNNs, and the ability to think about sequential dependencies is in its simplest form the RN is a compositional function: RN (O) is a way in which the translation invariant properties are built into CNNs, and the ability to think about sequential dependencies is in its simplest form the RN is a recurrent neural networks.In its simplest form the RN is a composite function in which the translation is incorporated in CNNs, and the ability to think about sequential dependencies is built into recurrent neural property to recurrent neural networks.In its simplest form, the RN (O) is a way in which the RN (O) is a way in which the translation invariant properties are built in relation to CNNs, and the ability to think about sequential dependencies is in its simplest form the RN \"o.2\" o.M is a recurrent neural networks.RN (O) is a way to recurrent neural networks.RN (O).RN (O) is a composite function: RN (O) is a way in which RN (O) is oi, oi, oi, oi, oi, oi, oi, oi, oS is a way in which outputs between the individual properties of nearest properties, oS, oS, oi, oS can be a series of objects, oS, oS, oooi, oi, oS, oi, ooS, oi, oS, oi, oi, oS, oS, oS, ogabe, dependent on objects in relation to neuronal S."}, {"heading": "3 Tasks", "text": "To demonstrate the versatility of these networks, we selected tasks from a variety of areas, including visual quality assurance, text-based quality assurance, and dynamic physical systems."}, {"heading": "3.1 CLEVR", "text": "In visual QA, a model must learn to answer questions about an image (Figure 1). This is a challenging problem domain because it requires a high degree of scene understanding [1, 29]. Architecture must perform complex relational reasoning - spatial and otherwise - about the features in visual inputs, speech inputs and their conjunction. However, the majority of visual QA datasets require reasoning in the absence of fully specified word vocabularies, and perhaps more pertinently, a vast and complicated knowledge of the world that is not included in the training data. They also contain ambiguities and have strong linguistic biases that allow a model to answer these biases without thinking about visual input."}, {"heading": "3.2 Sort-of-CLEVR", "text": "To explore our hypothesis that the RN architecture is better suited for general relational thinking than more conventional neural architectures, we constructed a data set similar to CLEVR, which we call \"Sort-of-CLEVR.\" 1. This data set separates relational and non-relational questions. Sort-of-CLEVR consists of images of 2D colored shapes along with questions and answers about the images. Each image consists of a total of 6 objects, each object having a randomly chosen shape (square or circle). We used 6 colors (red, blue, green, orange, yellow, gray) to uniquely identify each object. Questions are encoded as fixed-length binary strings to reduce the difficulty of processing questions and texts in natural language, thereby eliminating any confusing difficulties in speech parsing. For each image, we generated 10 relational questions and 10 non-relational questions. Examples of relational questions: \"Which is the form of the object that removes the most relational object, the one that is the one that removes the most relational object, the one that is the one that is the most female.\""}, {"heading": "3.3 bAbI", "text": "bAbI is a purely text-based QA dataset [41]. There are 20 tasks, each corresponding to a certain type of reasoning, such as deduction, induction, or counting. Each question is linked to a number of supporting facts. For example, the facts \"Sandra took up football\" and \"Sandra went to the office\" support the question \"Where is the football?\" (Answer: \"Office\"). A model succeeds in a task when its performance exceeds 95%. Many memory-enhanced neural networks have reported impressive results about bAbI. When training all tasks together using 10K examples per task, there are storage networks 14 / 20, DNC 18 / 20, Sparse DNC 19 / 20, and EntNet 16 / 20 (the authors of EntNets report state of the art at 20 / 20; in contrast to previously reported results, however, this was not done with joint training for all tasks, where they reach 16 / 20 instead)."}, {"heading": "3.4 Dynamic physical systems", "text": "We developed a dataset of simulated physical mass-spring systems using the physics engine MuJoCo [40]. Each scene contained 10 colored spheres moving on a table surface, some of which moved independently of each other, free to collide with other spheres and barrier walls. Other randomly selected pairs of spheres were connected by invisible springs or rigid constraints, which prevented the spheres from moving independently of each other due to the force imposed by the connections. Input data consisted of state descriptions of matrices in which each ball was presented as a series in a matrix whose characteristics represented the RGB color values of each object and its spatial coordinates (x, y) over 16 sequential time steps. Introducing random linkages between spheres created an evolving physical system with a variable number of \"systems\" of connected spheres \"(referring to connections between spheres, which are connected as nodes and spheres)."}, {"heading": "4 Models", "text": "In its simplest form, RNs operate on objects, and therefore we do not explicitly operate on images or natural languages. A central contribution of this work is to demonstrate the flexibility with which relatively unstructured inputs, such as CNN or LSTM embedding, can be considered as a set of objects for an RN. Although the RN expects object representations as input, the semantics of what an object does not need to be specified is important. Our results below show that the learning process induces upstream processing, consisting of conventional neural network modules, to produce a set of useful \"objects\" from distributed representations. We used a CNN model to parse pixel inputs into a set of objects. CNN took images of size 128 x 128 and merged them through four conventional layers to k-maps of size d \u00d7 d, where k is the number of kernels in the final revolutionary layer."}, {"heading": "5 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 CLEVR from pixels", "text": "Our model achieved a state-of-the-art performance of 95.5% with CLEVR, outperforming the best model trained only on pixel images and questions at the time of data set release by 27%, and human performance in the task (see Table 1 and Figure 3). These results - especially those obtained in the comparative attribute and number categories - are evidence of our model's ability to engage in relational thinking. In fact, it is in these categories that state-of-the-art models struggle the most. Moreover, the relative simplicity of the network components used in our model suggests that the difficulty of the CLEVR task lies in its relational reasoning requirements, not in language or visual processing. Results using privileged training information A recent study reported a total performance of 96.9% on CLEVR, but uses additional monitoring signals on the functional ones used to generate the CLEVR questions."}, {"heading": "5.2 CLEVR from state descriptions", "text": "To show that the RN is robust to the form of its input, we trained our model on the version of the state description matrix of the CLEVR dataset. The model achieved an accuracy of 96.4%. This result demonstrates the universality of the RN module by demonstrating its ability to learn and judge object relationships while being agnostic about the type of input - i.e., the particular representation of the object characteristics to which it has access. Therefore, RNs are not necessarily limited to visual problems and can therefore be applied in very different contexts and to various tasks that require relational reasoning."}, {"heading": "5.3 Sort-of-CLEVR from pixels", "text": "The results so far have led us to hypothesize that the difficulty in solving CLEVR lies in its strong emphasis on relational thinking, as opposed to previous assertions that the difficulty lies in parsing. [17] However, the questions in the CLEVR dataset are not categorized on the basis of the degree to which they can be relational, making it difficult to assess our hypothesis. Therefore, we use the Sort of CLEVR dataset, which we have explicitly developed to separate relational and non-relational questions (see Section 3.2). We find that a CNN extended by one RN achieves an accuracy of over 94% for both relational and non-relational questions. However, a CNN extended by one MLP has achieved this performance only on the non-relational questions, with plateauing at 63% on the relational questions. This strongly indicates that models without a relational thought component are unable, or even completely incapable, to solve the relational problems."}, {"heading": "5.4 bAbI", "text": "Our model succeeded in 18 / 20 tasks, especially the basic induction task (2.1% overall error), which proved difficult for the Sparse DNC (54%), DNC (55.1%) and EntNet (52.1%). In addition, our model did not disastrously miss the 95% threshold by 3.1% and 11.5%, respectively, for the two tasks it failed (the \"two supporting facts\" and the \"three supporting facts\"), the 95% threshold was missed by 3.1% and 11.5%, respectively. We also found that the model we evaluated was selected based on the overall performance based on a pre-included validation set and using a single seed, meaning we did not perform multiple replications with the best hyperparameter settings (as was the case with other models of the Sparse DNC, which had performance fluctuations with a standard deviation of more than \u00b1 3 tasks passed for the best hyper parameter choice)."}, {"heading": "5.5 Dynamic physical systems", "text": "Finally, we trained our model on two tasks that require thinking about the dynamics of balls moving along a surface. In the connection inference task, our model correctly classified all connections in 93% of the sample scenes in the test set. In the count task, the RN achieved a similar performance and indicated the correct number of connected systems for 95% of the samples in the test scene. In comparison, an MLP with a comparable number of parameters for both tasks was no better than chance. In addition, using this task to learn to draw correlations to invisible motion detection data where RNs predict the connections between body joints of a running human (see additional information for experimental details and sample videos)."}, {"heading": "6 Discussion and Conclusions", "text": "This work demonstrated how the RN, a dedicated module for calculating relationships between entities, can be integrated into broader deep learning architectures to improve the performance of tasks that require rich relationship-based thinking. Our CLEVR results included a superhuman performance of 95.5% overall. Our bAbI results showed that RN module inclusion in relatively simple CNN and LSTM-based VQA architectures increased the performance of CLEVR from 68.5% to 95.5% and achieved above-average human performance. We speculated that RN module inclusion played a role in relatively simple CNN and LSTM-based VQS architectures."}, {"heading": "Acknowledgments", "text": "We would like to thank Murray Shanahan, Ari Morcos, Scott Reed, Daan Wierstra, Alex Lerchner and many others in the DeepMind team for critical feedback and discussion. Supplementary MaterialHere we provide additional details on (A) related work, (B) CLEVR from pixels, (C) CLEVR from state descriptions, (D) Sort-of-CLEVR, (E) bAbI and (F) dynamic physical system logic. For each task we provide additional information on the dataset, model architecture, training and results where necessary."}, {"heading": "A Related Work", "text": "There is the question of why, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how, of how?"}, {"heading": "B CLEVR from pixels", "text": "Our model (described in section 4 of the main text) was trained using 70,000 scenes from the CLEVR dataset and a total of 699989 questions; the images were first tried out to size 128 x 128, then pre-processed with an increase to size 136 x 136, followed by random trimming to size 128 x 128 and light random rotations between \u2212 0.05 and 0.05 wheels. We used 10 distributed workers who synchronously updated a central parameter server. Each worker learned with size 64 mini-batches using the Adam optimizer and a learning rate of 2.5 x 4. 50% failure risk was used on the penultimate layer of the RN. In our most powerful model, each convolutionary layer used 24 cores of size 3 x 3 and strip 2, batch normalization and reflected linear units. The model stopped the improvement in performance after about 1.4 million iterations, at which point the general training was completed to a model of 96.8% accuracy, we achieved the smaller VALIMs."}, {"heading": "C CLEVR from state descriptions", "text": "The model we train on the state description version of CLEVR is similar to the model trained on the pixel version of CLEVR, but without the image processing module. We used a 256-layer LSTM for question processing and text embedding of size 32. For the RN, we used a 4-layer MLP with 512 units per shift, with ReLU nonlinearities for g\u03b8. A 3-layer MLP consisting of 512, 1024 (with 2% failure rate) and 29 units with ReLU nonlinearities was used for f\u03b8. To train the model, we used 10 distributed workers who updated a central parameter server synchronously. Each worker learned with mini-lots of size 64, with the Adam optimizer and a learning rate of 1e \u2212 4."}, {"heading": "D Sort-of-CLEVR", "text": "The Sort-of-CLEVR dataset contains 10,000 images of the size 75 x 75, of which 200 were retained for validation. 20 questions per image were generated (10 relational and 10 non-relational). Non-relational questions are divided into three categories: (i) query form, e.g. \"What is the shape of the red object?\"; (ii) query the horizontal position, e.g. \"Is the red object to the left or right of the image?\"; (iii) query the vertical position, e.g. \"Is the red object on the top or bottom of the red object?.\" These questions are non-relational because they can be answered by considering the attributes (e.g. position, shape) of a single unit identified by its unique color (e.g. red). Relational questions are divided into three categories: (i) closest to, e.g. \"What is the shape of the object closest to the green object.\""}, {"heading": "E bAbI model for language understanding", "text": "In the bAbI task, each of the 20 sets of the support set was processed into an object by a 32-layer LSTM. The RN was a 4-layer LLP with 256 units per shift. f\u03c6 used a 3-layer LLP with 256, 512 and 159 units, the last layer being a linear layer that generated logits for a Softmax above the answer vocabulary. f\u03c6 used a separate LSTM with 32 units to process the question. the Softmax output was optimized with a cross-entropy loss function using the Adam optimizer with a learning rate of 2e \u2212 4."}, {"heading": "F Dynamic physical system reasoning", "text": "For the connecting task, the targets were binary vectors that dealt with the existence (or non-existence) of a connection between each Q Q pair 33 Q-Q. For a total of 10 objects, the targets were 102 length vectors. For the counting task, the targets were unit vectors (of length 10) that specify the number of systems of connected balls. It is important to note that in the first task, the monitoring signal provided by the targets explicitly informs about the relationships that need to be calculated. In the second task, the monitoring signal (the number of systems) does not provide explicit information about the type of relationships that need to be calculated. Therefore, the models that resolve the counting return must implicitly derive the relationships. Inputs to the RN were state descriptions. Each set of a state description matrix provided information about a particular object (i.e. sphere), including its coordinate position and color. Since the system was dynamic, and hence was developed over time, each series contained the following descriptions of objects for each other (i.e. sphere)."}], "references": [{"title": "Vqa: Visual question answering", "author": ["Stanislaw Antol", "Aishwarya Agrawal", "Jiasen Lu", "Margaret Mitchell", "Dhruv Batra", "C Lawrence Zitnick", "Devi Parikh"], "venue": "In ICCV,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Interaction networks for learning about objects, relations and physics", "author": ["Peter Battaglia", "Razvan Pascanu", "Matthew Lai", "Danilo Jimenez Rezende"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Semantic parsing on freebase from question-answer pairs", "author": ["Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang"], "venue": "In EMNLP,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Chains of reasoning over entities, relations, and text using recurrent neural networks", "author": ["Rajarshi Das", "Arvind Neelakantan", "David Belanger", "Andrew McCallum"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Multimodal compact bilinear pooling for visual question answering and visual grounding", "author": ["Akira Fukui", "Dong Huk Park", "Daylen Yang", "Anna Rohrbach", "Trevor Darrell", "Marcus Rohrbach"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Are you talking to a machine? dataset and methods for multilingual image question answering", "author": ["Haoyuan Gao", "Junhua Mao", "Jie Zhou", "Zhiheng Huang", "Lei Wang", "Wei Xu"], "venue": "In NIPS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Towards deep symbolic reinforcement learning", "author": ["Marta Garnelo", "Kai Arulkumaran", "Murray Shanahan"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "A game-theoretic approach to generating spatial descriptions", "author": ["Dave Golland", "Percy Liang", "Dan Klein"], "venue": "In EMNLP,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Hybrid computing using a neural network with dynamic external memory", "author": ["Alex Graves", "Greg Wayne", "Malcolm Reynolds", "Tim Harley", "Ivo Danihelka", "Agnieszka Grabska-Barwi\u0144ska", "Sergio G\u00f3mez Colmenarejo", "Edward Grefenstette", "Tiago Ramalho", "John Agapiou"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Grounding spatial relations for human-robot interaction", "author": ["Sergio Guadarrama", "Lorenzo Riano", "Dave Golland", "Daniel Gouhring", "Yangqing Jia", "Dan Klein", "Pieter Abbeel", "Trevor Darrell"], "venue": "In IROS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "The symbol grounding problem", "author": ["Stevan Harnad"], "venue": "Physica D: Nonlinear Phenomena,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1990}, {"title": "Deep convolutional networks on graph-structured data", "author": ["Mikael Henaff", "Joan Bruna", "Yann LeCun"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Tracking the world state with recurrent entity networks", "author": ["Mikael Henaff", "Jason Weston", "Arthur Szlam", "Antoine Bordes", "Yann LeCun"], "venue": "In ICLR,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "Learning to reason: End-to-end module networks for visual question answering", "author": ["Ronghang Hu", "Jacob Andreas", "Marcus Rohrbach", "Trevor Darrell", "Kate Saenko"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "Clevr: A diagnostic dataset for compositional language and elementary visual reasoning", "author": ["Justin Johnson", "Bharath Hariharan", "Laurens van der Maaten", "Li Fei-Fei", "C Lawrence Zitnick", "Ross Girshick"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2017}, {"title": "Inferring and executing programs for visual reasoning", "author": ["Justin Johnson", "Bharath Hariharan", "Laurens van der Maaten", "Judy Hoffman", "Li Fei-Fei", "C Lawrence Zitnick", "Ross Girshick"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2017}, {"title": "An analysis of visual question answering algorithms", "author": ["Kushal Kafle", "Christopher Kanan"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2017}, {"title": "The discovery of structural form", "author": ["Charles Kemp", "Joshua B Tenenbaum"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Semi-supervised classification with graph convolutional networks", "author": ["Thomas N Kipf", "Max Welling"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Jointly learning to parse and perceive: Connecting natural language to the physical world", "author": ["Jayant Krishnamurthy", "Thomas Kollar"], "venue": "TACL,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Situated dialogue and spatial organization: What, where.", "author": ["Geert-Jan M Kruijff", "Hendrik Zender", "Patric Jensfelt", "Henrik I Christensen"], "venue": "IJARS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Inducing probabilistic ccg grammars from logical form with higher-order unification", "author": ["Tom Kwiatkowski", "Luke Zettlemoyer", "Sharon Goldwater", "Mark Steedman"], "venue": "In EMNLP,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Building machines that learn and think like people", "author": ["Brenden M Lake", "Tomer D Ullman", "Joshua B Tenenbaum", "Samuel J Gershman"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "Image retrieval with structured object queries using latent ranking svm", "author": ["Tian Lan", "Weilong Yang", "Yang Wang", "Greg Mori"], "venue": "In ECCV,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Gated graph sequence neural networks", "author": ["Yujia Li", "Daniel Tarlow", "Marc Brockschmidt", "Richard Zemel"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "Learning dependency-based compositional semantics", "author": ["Percy Liang", "Michael I Jordan", "Dan Klein"], "venue": "Computational Linguistics,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "A computational analysis of the apprehension of spatial relations", "author": ["Gordon D Logan", "Daniel D Sadler"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1996}, {"title": "A multi-world approach to question answering about real-world scenes based on uncertain input", "author": ["Mateusz Malinowski", "Mario Fritz"], "venue": "In NIPS,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "A pooling approach to modelling spatial relations for image retrieval and annotation", "author": ["Mateusz Malinowski", "Mario Fritz"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2014}, {"title": "Ask your neurons: A deep learning approach to visual question answering", "author": ["Mateusz Malinowski", "Marcus Rohrbach", "Mario Fritz"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2016}, {"title": "Physical symbol systems", "author": ["Allen Newell"], "venue": "Cognitive science,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1980}, {"title": "Learning convolutional neural networks for graphs", "author": ["Mathias Niepert", "Mohamed Ahmed", "Konstantin Kutzkov"], "venue": "In ICML,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2016}, {"title": "Scaling memory-augmented neural networks with sparse reads and writes", "author": ["Jack Rae", "Jonathan J Hunt", "Ivo Danihelka", "Timothy Harley", "Andrew W Senior", "Gregory Wayne", "Alex Graves", "Tim Lillicrap"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2016}, {"title": "Discovering objects and their relations from entangled scene representations", "author": ["David Raposo", "Adam Santoro", "David Barrett", "Razvan Pascanu", "Timothy Lillicrap", "Peter Battaglia"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2017}, {"title": "Image question answering: A visual semantic embedding model and a new dataset", "author": ["Mengye Ren", "Ryan Kiros", "Richard Zemel"], "venue": "In NIPS,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "The graph neural network model", "author": ["Franco Scarselli", "Marco Gori", "Ah Chung Tsoi", "Markus Hagenbuchner", "Gabriele Monfardini"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Understanding natural language commands for robotic navigation and mobile manipulation", "author": ["Stefanie Tellex", "Thomas Kollar", "Steven Dickerson", "Matthew R Walter", "Ashis Gopal Banerjee", "Seth J Teller", "Nicholas Roy"], "venue": "In AAAI,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "Grounding spatial language for video search", "author": ["Stefanie Tellex", "Thomas Kollar", "George Shaw", "Nicholas Roy", "Deb Roy"], "venue": "In ICMI,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2010}, {"title": "Mujoco: A physics engine for model-based control", "author": ["Emanuel Todorov", "Tom Erez", "Yuval Tassa"], "venue": "In IROS,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2012}, {"title": "Towards ai-complete question answering: A set of prerequisite toy tasks", "author": ["Jason Weston", "Antoine Bordes", "Sumit Chopra", "Tomas Mikolov"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}, {"title": "Dynamic memory networks for visual and textual question answering", "author": ["Caiming Xiong", "Stephen Merity", "Richard Socher"], "venue": "In ICML,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2016}, {"title": "Ask, attend and answer: Exploring question-guided spatial attention for visual question answering", "author": ["Huijuan Xu", "Kate Saenko"], "venue": "In ECCV,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2016}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Kyunghyun Cho", "Aaron Courville", "Ruslan Salakhudinov", "Rich Zemel", "Yoshua Bengio"], "venue": "In ICML,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2015}, {"title": "Stacked attention networks for image question answering", "author": ["Zichao Yang", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Alex Smola"], "venue": null, "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2016}, {"title": "Learning to parse database queries using inductive logic programming", "author": ["John M Zelle", "Raymond J Mooney"], "venue": "In AAAI,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 1996}], "referenceMentions": [{"referenceID": 17, "context": "The ability to reason about the relations between entities and their properties is central to generally intelligent behavior (Figure 1) [18, 15].", "startOffset": 136, "endOffset": 144}, {"referenceID": 14, "context": "The ability to reason about the relations between entities and their properties is central to generally intelligent behavior (Figure 1) [18, 15].", "startOffset": 136, "endOffset": 144}, {"referenceID": 30, "context": "Symbolic approaches to artificial intelligence are inherently relational [32, 11].", "startOffset": 73, "endOffset": 81}, {"referenceID": 10, "context": "Symbolic approaches to artificial intelligence are inherently relational [32, 11].", "startOffset": 73, "endOffset": 81}, {"referenceID": 10, "context": "But symbolic approaches suffer from the symbol grounding problem and are not robust to small task and input variations [11].", "startOffset": 119, "endOffset": 123}, {"referenceID": 6, "context": "However, a number of these approaches, such as deep learning, often struggle in data-poor problems where the underlying structure is characterized by sparse but complex relations [7, 23].", "startOffset": 179, "endOffset": 186}, {"referenceID": 22, "context": "However, a number of these approaches, such as deep learning, often struggle in data-poor problems where the underlying structure is characterized by sparse but complex relations [7, 23].", "startOffset": 179, "endOffset": 186}, {"referenceID": 33, "context": "RNs are architectures whose computations focus explicitly on relational reasoning [35].", "startOffset": 82, "endOffset": 86}, {"referenceID": 35, "context": "Although several other models supporting relation-centric computation have been proposed, such as Graph Neural Networks, Gated Graph Sequence Neural Networks, and Interaction Networks, [37, 26, 2], RNs are simple, plug-and-play, and are exclusively focused on flexible relational reasoning.", "startOffset": 185, "endOffset": 196}, {"referenceID": 24, "context": "Although several other models supporting relation-centric computation have been proposed, such as Graph Neural Networks, Gated Graph Sequence Neural Networks, and Interaction Networks, [37, 26, 2], RNs are simple, plug-and-play, and are exclusively focused on flexible relational reasoning.", "startOffset": 185, "endOffset": 196}, {"referenceID": 1, "context": "Although several other models supporting relation-centric computation have been proposed, such as Graph Neural Networks, Gated Graph Sequence Neural Networks, and Interaction Networks, [37, 26, 2], RNs are simple, plug-and-play, and are exclusively focused on flexible relational reasoning.", "startOffset": 185, "endOffset": 196}, {"referenceID": 14, "context": "We applied an RN-augmented architecture to CLEVR [15], a recent visual question answering (QA) dataset on which state-of-the-art approaches have struggled due to the demand for rich relational reasoning.", "startOffset": 49, "endOffset": 53}, {"referenceID": 39, "context": "We also applied an RN-based architecture to the bAbI text-based QA suite [41] and solved 18/20 of the subtasks.", "startOffset": 73, "endOffset": 77}, {"referenceID": 1, "context": "Similar to Interaction Networks [2], to which RNs are related, RNs can take as input a list of only those pairs that should be considered, if this information is available.", "startOffset": 32, "endOffset": 35}, {"referenceID": 0, "context": "This is a challenging problem domain because it requires high-level scene understanding [1, 29].", "startOffset": 88, "endOffset": 95}, {"referenceID": 27, "context": "This is a challenging problem domain because it requires high-level scene understanding [1, 29].", "startOffset": 88, "endOffset": 95}, {"referenceID": 0, "context": "They also contain ambiguities and exhibit strong linguistic biases that allow a model to learn answering strategies that exploit those biases, without reasoning about the visual input [1, 31, 36].", "startOffset": 184, "endOffset": 195}, {"referenceID": 29, "context": "They also contain ambiguities and exhibit strong linguistic biases that allow a model to learn answering strategies that exploit those biases, without reasoning about the visual input [1, 31, 36].", "startOffset": 184, "endOffset": 195}, {"referenceID": 34, "context": "They also contain ambiguities and exhibit strong linguistic biases that allow a model to learn answering strategies that exploit those biases, without reasoning about the visual input [1, 31, 36].", "startOffset": 184, "endOffset": 195}, {"referenceID": 14, "context": "To control for these issues, and to distill the core challenges of visual QA, the CLEVR visual QA dataset was developed [15].", "startOffset": 120, "endOffset": 124}, {"referenceID": 43, "context": "Remarkably, powerful QA architectures [46] are unable to solve CLEVR, presumably because they cannot handle core relational aspects of the task.", "startOffset": 38, "endOffset": 42}, {"referenceID": 14, "context": "6% human performance) [15].", "startOffset": 22, "endOffset": 26}, {"referenceID": 39, "context": "bAbI is a pure text-based QA dataset [41].", "startOffset": 37, "endOffset": 41}, {"referenceID": 8, "context": "When training jointly on all tasks using 10K examples per task, Memory Networks pass 14/20, DNC 18/20, Sparse DNC 19/20, and EntNet 16/20 (the authors of EntNets report state-of-the-art at 20/20; however, unlike previously reported results this was not done with joint training on all tasks, where they instead achieve 16/20) [42, 9, 34, 13].", "startOffset": 326, "endOffset": 341}, {"referenceID": 32, "context": "When training jointly on all tasks using 10K examples per task, Memory Networks pass 14/20, DNC 18/20, Sparse DNC 19/20, and EntNet 16/20 (the authors of EntNets report state-of-the-art at 20/20; however, unlike previously reported results this was not done with joint training on all tasks, where they instead achieve 16/20) [42, 9, 34, 13].", "startOffset": 326, "endOffset": 341}, {"referenceID": 12, "context": "When training jointly on all tasks using 10K examples per task, Memory Networks pass 14/20, DNC 18/20, Sparse DNC 19/20, and EntNet 16/20 (the authors of EntNets report state-of-the-art at 20/20; however, unlike previously reported results this was not done with joint training on all tasks, where they instead achieve 16/20) [42, 9, 34, 13].", "startOffset": 326, "endOffset": 341}, {"referenceID": 38, "context": "We developed a dataset of simulated physical mass-spring systems using the MuJoCo physics engine [40].", "startOffset": 97, "endOffset": 101}, {"referenceID": 15, "context": "Performances of our model (RN) and previously reported models [16], measured as accuracy on the test set and broken down by question category.", "startOffset": 62, "endOffset": 66}, {"referenceID": 14, "context": "fine-tuning, very large LSTMs for language encoding, and further processing modules, such as stacked or iterative attention, or large fully connected layers (upwards of 4000 units, often) [15].", "startOffset": 188, "endOffset": 192}, {"referenceID": 15, "context": "9% on CLEVR, but uses additional supervisory signals on the functional programs used to generate the CLEVR questions [16].", "startOffset": 117, "endOffset": 121}, {"referenceID": 16, "context": "The results so far led us to hypothesize that the difficulty in solving CLEVR lies in its heavy emphasis on relational reasoning, contrary to previous claims that the difficulty lies in question parsing [17].", "startOffset": 203, "endOffset": 207}, {"referenceID": 10, "context": "Relational reasoning is implicit in many symbolic approaches [11, 32] and has been explicitly pursued using neural networks as well [4].", "startOffset": 61, "endOffset": 69}, {"referenceID": 30, "context": "Relational reasoning is implicit in many symbolic approaches [11, 32] and has been explicitly pursued using neural networks as well [4].", "startOffset": 61, "endOffset": 69}, {"referenceID": 3, "context": "Relational reasoning is implicit in many symbolic approaches [11, 32] and has been explicitly pursued using neural networks as well [4].", "startOffset": 132, "endOffset": 135}, {"referenceID": 11, "context": "There is recent work applying neural networks to graphs, which are a natural structure for formalising relations [12, 19, 33, 37, 26, 2].", "startOffset": 113, "endOffset": 136}, {"referenceID": 18, "context": "There is recent work applying neural networks to graphs, which are a natural structure for formalising relations [12, 19, 33, 37, 26, 2].", "startOffset": 113, "endOffset": 136}, {"referenceID": 31, "context": "There is recent work applying neural networks to graphs, which are a natural structure for formalising relations [12, 19, 33, 37, 26, 2].", "startOffset": 113, "endOffset": 136}, {"referenceID": 35, "context": "There is recent work applying neural networks to graphs, which are a natural structure for formalising relations [12, 19, 33, 37, 26, 2].", "startOffset": 113, "endOffset": 136}, {"referenceID": 24, "context": "There is recent work applying neural networks to graphs, which are a natural structure for formalising relations [12, 19, 33, 37, 26, 2].", "startOffset": 113, "endOffset": 136}, {"referenceID": 1, "context": "There is recent work applying neural networks to graphs, which are a natural structure for formalising relations [12, 19, 33, 37, 26, 2].", "startOffset": 113, "endOffset": 136}, {"referenceID": 7, "context": "Although grounding language in spatial percepts has a long-standing tradition, the majority of previous research has focused on either rule-based spatial representations or hand-engineered spatial features [8, 10, 20, 21, 24, 29, 38, 39].", "startOffset": 206, "endOffset": 237}, {"referenceID": 9, "context": "Although grounding language in spatial percepts has a long-standing tradition, the majority of previous research has focused on either rule-based spatial representations or hand-engineered spatial features [8, 10, 20, 21, 24, 29, 38, 39].", "startOffset": 206, "endOffset": 237}, {"referenceID": 19, "context": "Although grounding language in spatial percepts has a long-standing tradition, the majority of previous research has focused on either rule-based spatial representations or hand-engineered spatial features [8, 10, 20, 21, 24, 29, 38, 39].", "startOffset": 206, "endOffset": 237}, {"referenceID": 20, "context": "Although grounding language in spatial percepts has a long-standing tradition, the majority of previous research has focused on either rule-based spatial representations or hand-engineered spatial features [8, 10, 20, 21, 24, 29, 38, 39].", "startOffset": 206, "endOffset": 237}, {"referenceID": 23, "context": "Although grounding language in spatial percepts has a long-standing tradition, the majority of previous research has focused on either rule-based spatial representations or hand-engineered spatial features [8, 10, 20, 21, 24, 29, 38, 39].", "startOffset": 206, "endOffset": 237}, {"referenceID": 27, "context": "Although grounding language in spatial percepts has a long-standing tradition, the majority of previous research has focused on either rule-based spatial representations or hand-engineered spatial features [8, 10, 20, 21, 24, 29, 38, 39].", "startOffset": 206, "endOffset": 237}, {"referenceID": 36, "context": "Although grounding language in spatial percepts has a long-standing tradition, the majority of previous research has focused on either rule-based spatial representations or hand-engineered spatial features [8, 10, 20, 21, 24, 29, 38, 39].", "startOffset": 206, "endOffset": 237}, {"referenceID": 37, "context": "Although grounding language in spatial percepts has a long-standing tradition, the majority of previous research has focused on either rule-based spatial representations or hand-engineered spatial features [8, 10, 20, 21, 24, 29, 38, 39].", "startOffset": 206, "endOffset": 237}, {"referenceID": 26, "context": "Although there are some attempts to learn spatial relations using spatial templates [28, 30], these approaches are less versatile than ours.", "startOffset": 84, "endOffset": 92}, {"referenceID": 28, "context": "Although there are some attempts to learn spatial relations using spatial templates [28, 30], these approaches are less versatile than ours.", "startOffset": 84, "endOffset": 92}, {"referenceID": 0, "context": "Visual question answering is a recently introduced task that measures a machine understanding of the scene through questions [1, 29].", "startOffset": 125, "endOffset": 132}, {"referenceID": 27, "context": "Visual question answering is a recently introduced task that measures a machine understanding of the scene through questions [1, 29].", "startOffset": 125, "endOffset": 132}, {"referenceID": 14, "context": "Related to our work, we are mostly interested in the newly introduced CLEVR dataset [15] that distills core challenges of the task, namely relational and multi-modal reasoning.", "startOffset": 84, "endOffset": 88}, {"referenceID": 5, "context": "The majority of approaches to question answering share the same pipeline [6, 31, 36].", "startOffset": 73, "endOffset": 84}, {"referenceID": 29, "context": "The majority of approaches to question answering share the same pipeline [6, 31, 36].", "startOffset": 73, "endOffset": 84}, {"referenceID": 34, "context": "The majority of approaches to question answering share the same pipeline [6, 31, 36].", "startOffset": 73, "endOffset": 84}, {"referenceID": 4, "context": "Most successful methods also use an attention mechanism that locate important image regions [5, 44, 45, 46].", "startOffset": 92, "endOffset": 107}, {"referenceID": 41, "context": "Most successful methods also use an attention mechanism that locate important image regions [5, 44, 45, 46].", "startOffset": 92, "endOffset": 107}, {"referenceID": 42, "context": "Most successful methods also use an attention mechanism that locate important image regions [5, 44, 45, 46].", "startOffset": 92, "endOffset": 107}, {"referenceID": 43, "context": "Most successful methods also use an attention mechanism that locate important image regions [5, 44, 45, 46].", "startOffset": 92, "endOffset": 107}, {"referenceID": 13, "context": "Parallel to our work, two architectures have shown impressive results on the CLEVR dataset [14, 16].", "startOffset": 91, "endOffset": 99}, {"referenceID": 15, "context": "Parallel to our work, two architectures have shown impressive results on the CLEVR dataset [14, 16].", "startOffset": 91, "endOffset": 99}, {"referenceID": 14, "context": "The RN module, on the other hand, is conceptually simpler, can readily be combined with basic neural components such as CNNs or LSTMs, can be broadly applied to various tasks, and achieves significantly better results on CLEVR [15] than [14], and on par with strongly supervised system of [16].", "startOffset": 227, "endOffset": 231}, {"referenceID": 13, "context": "The RN module, on the other hand, is conceptually simpler, can readily be combined with basic neural components such as CNNs or LSTMs, can be broadly applied to various tasks, and achieves significantly better results on CLEVR [15] than [14], and on par with strongly supervised system of [16].", "startOffset": 237, "endOffset": 241}, {"referenceID": 15, "context": "The RN module, on the other hand, is conceptually simpler, can readily be combined with basic neural components such as CNNs or LSTMs, can be broadly applied to various tasks, and achieves significantly better results on CLEVR [15] than [14], and on par with strongly supervised system of [16].", "startOffset": 289, "endOffset": 293}, {"referenceID": 2, "context": "Answering text-based questions has long been an active research area in the NLP community [3, 22, 27, 48].", "startOffset": 90, "endOffset": 105}, {"referenceID": 21, "context": "Answering text-based questions has long been an active research area in the NLP community [3, 22, 27, 48].", "startOffset": 90, "endOffset": 105}, {"referenceID": 25, "context": "Answering text-based questions has long been an active research area in the NLP community [3, 22, 27, 48].", "startOffset": 90, "endOffset": 105}, {"referenceID": 44, "context": "Answering text-based questions has long been an active research area in the NLP community [3, 22, 27, 48].", "startOffset": 90, "endOffset": 105}, {"referenceID": 32, "context": "Recently, in addition to traditional symbolic-based question answering architectures, we observe a growing interest in neural-based approaches to text based question answering [34, 42, 43].", "startOffset": 176, "endOffset": 188}, {"referenceID": 40, "context": "Recently, in addition to traditional symbolic-based question answering architectures, we observe a growing interest in neural-based approaches to text based question answering [34, 42, 43].", "startOffset": 176, "endOffset": 188}, {"referenceID": 39, "context": "capabilities, reaching very competitive results on the bAbI dataset [41] \u2013 a dataset that test reasoning capabilities of text-based question answering models.", "startOffset": 68, "endOffset": 72}], "year": 2017, "abstractText": "Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Our work shows how a deep learning architecture equipped with an RN module can implicitly discover and learn to reason about entities and their relations.", "creator": "LaTeX with hyperref package"}}}