{"id": "1706.02869", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2017", "title": "Adaptive Consensus ADMM for Distributed Optimization", "abstract": "The alternating direction method of multipliers (ADMM) is commonly used for distributed model fitting problems, but its performance and reliability depend strongly on user-defined penalty parameters. We study distributed ADMM methods that boost performance by using different fine-tuned algorithm parameters on each worker node. We present a O(1/k) convergence rate for adaptive ADMM methods with node-specific parameters, and propose adaptive consensus ADMM (ACADMM), which automatically tunes parameters without user oversight.", "histories": [["v1", "Fri, 9 Jun 2017 08:52:37 GMT  (410kb,D)", "https://arxiv.org/abs/1706.02869v1", "ICML 2017"], ["v2", "Tue, 20 Jun 2017 05:22:11 GMT  (410kb,D)", "http://arxiv.org/abs/1706.02869v2", "ICML 2017"]], "COMMENTS": "ICML 2017", "reviews": [], "SUBJECTS": "cs.LG cs.NA cs.SY", "authors": ["zheng xu 0002", "gavin taylor", "hao li", "m\u00e1rio a t figueiredo", "xiaoming yuan", "tom goldstein"], "accepted": true, "id": "1706.02869"}, "pdf": {"name": "1706.02869.pdf", "metadata": {"source": "CRF", "title": "Adaptive Consensus ADMM for Distributed Optimization", "authors": ["Zheng Xu", "Gavin Taylor", "Hao Li", "M\u00e1rio A. T. Figueiredo", "Xiaoming Yuan", "Tom Goldstein"], "emails": ["<xuzhustc@gmail.com>."], "sections": [{"heading": "1. Introduction", "text": "The alternative method of multipliers (ADMM) is a popular tool for solving problems of form, min u > Rn, v > Rm (u) + g (v), subject to Au + Bv = b, (1) where f: Rn \u2192 R and g: Rm \u2192 R are, however, in many optimization problems in machine learning, in many other areas (Boyd et al., 2011).Consensus ADMM was first introduced in (Glowinski & Marroco, 1975) and in many optimization problems in machine learning, in many other areas (Boyd et al., 2011).Consensus ADMM al al al al al al, 2011) solves minimization problems that involve a compound goal f (v)."}, {"heading": "2. Related work", "text": "ADMM is known to have a convergence rate of aO (1 / k) under mild conditions for convex problems (He & Yuan, 2012; 2015), while a convergence rate of O (1 / k2) is possible if at least one of the functions is strongly convex or smooth (Goldfarb et al., 2013; Goldstein et al., 2014; Kadkhodaie et al., 2015; Tian & Yuan, 2016).Linear convergence rate can be achieved to the best of our knowledge with strong convergence assumptions (Davis & Yin, 2014; Nishihara et al., 2015; Giselsson & Boyd, 2016).All these results are based on constant parameters; to the best of knowledge, no convergence rate for ADMM has been imposed an adaptive penalty: (He et al., 2000; Xu et al., 2017b) exhibit convergence without offering a rate, and (Let al."}, {"heading": "3. Consensus ADMM", "text": "In the following, we will use the i subscript to name iterations calculated on the ith node, the k superscript is the iteration number, \u03bbki is the dual vector of the Lagrange multipliers, and {\u03c4ki} are iteration / worker-specific penalty parameters (contrasted with the only constant penalty parameter \"vanilla\" ADMM). Consensus methods apply ADMM (2), from which the stepsuk + 1i = arg minui fi (ui) + \u03c4ki 2 (vk \u2212 ui + \u043aki) 2 (3) vk + 1 = arg min v \u2212 g (v) + N \u0445 v \u2212 uk + 1i = arg minui fi fi fi fi fi (ui) + \u043aki + 1i = arg minui fi fi fi fi (ui) + \u043aki 2 (vk \u2212 ui)."}, {"heading": "4. Convergence analysis", "text": "We will now examine the convergence of ADMM with node-specific adaptive penalty parameters. We will provide conditions for penalty parameters that guarantee convergence, as well as a convergence rate. The question of how penalty parameters can be automatically and effectively adjusted will be discussed in Section 5."}, {"heading": "4.1. Diagonal penalty parameters for ADMM", "text": "Let T k = diag (\u03c4k1 Id,.., \u03c4 k NId) be a diagonal matrix containing non-negative penalty parameters on iteration k. Define the norm you define with u = (u1;..; uN) Using the above notation, we can rewrite the consensus ADMM steps (3) - (5) asuk + 1 = arg min u f (u) + < \u2212 Au, k > + 1 / 2 b \u2212 Au \u2212 Bvk 2Tk (8) vk + 1 = arg min v (v) + < \u2212 Bv, k > + 1 / 2 b \u2212 Auk + 1 \u2212 Bv 2Tk (9) \u03bbk + 1 \u2212 Bvk (8) vk + T k (b \u2212 Auk + 1 \u2212 Bvk + 1)."}, {"heading": "4.2. Preliminaries", "text": "variation. We use the following notation to simplify the discussions. We define the combined variables y = (u; v) q q q (note) and z = (u; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p;"}, {"heading": "4.3. Convergence criteria", "text": "We provide a convergence analysis of ADMM with an adaptive diagonal penalty matrix by (i) converging the norm of residuals to zero; (ii) the method achieves a worst-case convergence rate in the VI sense. The key idea of the evidence is to bind the adaptability of T k so that ADMM is stable enough to converge, which is presented as the following assumption. Assumption 1. The adaptability of the diagonal penalty matrix T k = diag (.., \"k\") is limited by convergence k (1), which is presented as the following assumption. \"The adaptability of the diagonal penalty matrix T k = diag (.,.,.) k) is limited by convergence (.), where (."}, {"heading": "5. Adaptive Consensus ADMM (ACADMM)", "text": "To solve the problem of automatically adjusting parameters to each node for optimal performance, we propose Adaptive Consensus ADMM (ACADMM), which defines work-specific penalty parameters by exploiting curvature information. We derive our method from the dual interpretation of ADMM - Douglas-Rachford Splitting (DRS) - using a diagonal penalty matrix. We then derive the spectral increments for consensus problems by assuming that the curvatures of the targets are diagonal matrices with different parameters at different nodes. Finally, we discuss the practical calculation of spectral increments from consensus ADMM iterates and apply our theory in Section 4 to ensure convergence."}, {"heading": "5.1. Dual interpretation of generalized ADMM", "text": "ADMM steps for the primary problem (1) are known to be equivalent to performing Douglas-Rachford splitting (DRS) for the dual problem (42) (Eckstein & Bertsekas, 1992; Xu et al., 2017a). Specifically, generalized ADMM iterations meet the DRS update formulas 0 (T k) \u2212 1 (T k) \u2212 1 (T k + 1 \u2212 p) + 1 (K) + 1 (K + K) + 4 (K) + 4 (K) + 4 (K) + 4 (K) + 4 (K) (K)."}, {"heading": "5.2. Generalized spectral stepsize rule", "text": "Xu et al. (2017a) first derived spectral penalty parameters for ADMM using DRS. Proposition 1 in (Xu et al., 2017a) has shown that the minimum remainder of DRS can be achieved by setting the scalar penalty to \u03c4k = 1 / \u221a \u03b1\u03b2, assuming that the subgradients are locally linear by presenting the generalized spectral step size rules f \u00b2 (\u03bb) = \u03b1 + \u0432 and \u0445 g \u00b2 (\u03bb) = \u03b2 \u03bb + \u03a6, (45) \u03b1, \u03b2 \u00b2 R scalar curves, and that we now present generalized spectral step size rules that can accommodate consensus problems. Proposition 1 (Generalized spectral DRS blocks) are used (43, 44) and assume that the subgradients are locally linear."}, {"heading": "5.3. Stepsize estimation for consensus problems", "text": "We now show that the generalized spectral step quantities can be derived from the ADMM formula (2) without explicitly providing the double functionality. (2) The sub-gradations of the double functionalities can be derived from the ADMM formula. (2), Auk + 1 \u2212 b), Auk + 1) and Bvk + 1 (2). (47) For the consensus problem we have A = IdN, B = \u2212 (Id;.), and b = 0, and so on (uk + 11;.)."}, {"heading": "5.4. Safeguarding and convergence", "text": "Spectral step sizes for gradient descend methods are equipped with protective strategies such as trace line search to handle inaccurate curvature estimates and guarantee convergence. To protect the proposed spectral penalty parameters, we check whether our linear gradation assumption is appropriate before updating the step sizes. We do this by testing that the correlations, i = < 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 k."}, {"heading": "6. Experiments & Applications", "text": "We are now examining the performance of ACADMM against benchmark problems and comparing it with other methods."}, {"heading": "6.1. Applications", "text": "We consider consensus formulations of the elastic mesh (Zou & Hastie, 2005) with fi and g defined as, fi (ui) = 12, g (v) = \u03c11 | v | + \u03c12 2, (55), where Di-Rni \u00b7 m is the data matrix on node i and ci is a vector of measurements. Sparse logistic regression with \"1 regulator\" can be written into the consensus form for distributed compression, fi (ui) = ni-Rni \u00b7 m = 1 log (\u2212 ci, jDTi, jui)), g (v) = v | (56), where Di-Rni \u00b7 s is the distributed compression, fi (ui) = ni-X-X = exp (\u2212 X, jui), g (v) = v-R, i-Z, i-Z, i-i, i-Z, i-Z-Z, i-Z-Z, i-Z-Z, i-Z-Z, i-i, i-Z-Z, i-Z-Z, i-Z, i-i-i, i-Z-Z, i-Z-i, i-Z-Z, i-Z-Z, i-Z-Z, i-Z-Z, i-i-i, i-i-i, i-Z, i-Z-Z, i-Z, i-Z, i-Z, i-Z, i-Z, i-Z, i-Z, i-i-Z, i-Z, i-Z, i-Z, i-i-Z, i-Z, i-i, i, i-i-i, i-i, i, i-i-i, i-i, i-i, i-i, i, i-i, i-i, i, i-i, i, i-i, i-i, i-i, i, i, i, i-i, i-i, i, i, i-i, i, i, i, i-i, i, i, i, i, i, i-i, i, i, i, i, i, i, i, i, i, i, i, i"}, {"heading": "6.2. Experimental Setup", "text": "We test the problems in Section 6.1 with synthetic and real data sets. The number of samples and characteristics is in Table 1. Synthetic1 contains samples from a normal distribution and Synthetic2 contains samples from a mixture of 10 random Gaussians. Synthetic2 is heterogeneous because the data block is sampled on each individual node by only 1 of the 10 Gaussian. We also acquire large empirical data sets from the LIBSVM website (Liu et al., 2009), as well as MNIST digital images (LeCun et al., 1998) and CIFAR10 object images (Krizhevsky & Hinton, 2009). For binary classification tasks (SVM and logreg), we equally divide the 10 category labels of MNIST and CIFAR into \"positive\" and \"negative\" parameter groups."}, {"heading": "6.3. Convergence results", "text": "These experiments are carried out with 128 cores on a Cray XC-30 supercomputer. CADMM with a standard penalty \u03c4 = 1 (Boyd et al., 2011) often converges slowly. ACADMM outperforms the other ADMM variants on all real data sets and competes with AADMM on two homogeneous synthetic datasets. ACADMM is more reliable than AADMM because estimating curvature for high-dimensional variables becomes difficult. RB is relatively stable, but sometimes has difficulty finding the exact optimal penalty, as the adjustment can stop because the difference of the residuals is not significant enough to trigger changes. RB does not change the initial penalty in several experiments, such as logistic regression to RCV1. CRB achieves comparable results with RB, suggesting that local ADMs resistance is always very helpful in practice."}, {"heading": "6.4. Robustness and sensitivity", "text": "Fig. 1a shows that the practical convergence of ADMM is sensitive to the choice of penalty parameters. ACADMM is robust in the selection of the initial penalty parameter and achieves promising results for both homogeneous and heterogeneous data, comparable to ADMM with finely tuned penalty parameters. We investigate the scalability of the method by varying the number of workers and training samples (Fig. 1b). ACADMM is relatively robust to the scaling factor. AADMM occasionally performs well when a small number of nodes is used, while ACADMM is much more stable. RB and CRB are more stable than AADMM, but cannot compete with ACADMM. Fig. 1c (below) shows the acceleration in (wall clock secs) that is achieved by increasing the number of workers. Finally, ACADMM is insensitive to the protection of hyperparameters, correlation constants and suppression parameters, although we can also improve the complexity parameters."}, {"heading": "7. Conclusion", "text": "We propose ACADMM, a fully automated algorithm for distributed optimization. Numerical experiments on various applications and data sets from the real world demonstrate the efficiency and robustness of ACADMM. We also demonstrate a convergence rate of O (1 / k) for ADMM with adaptive penalties under mild conditions. By automating the selection of algorithm parameters, adaptive methods make distributed systems more reliable and more accessible to users who lack expertise in optimization."}, {"heading": "Acknowledgements", "text": "ZX, GT, HL and TG were supported by the US Office of Naval Research under grant N00014-17-1-2078 and the US National Science Foundation (NSF) under grant CCF1535902. GT was partially supported by the DOD High Performance Computing Modernization Program. MF was partially supported by Fundac, a research and technology foundation, under grant UID / EEA / 5008 / 2013. XY was supported by the General Research Fund of the Hong Kong Research Grants Council under grant HKBU-12313516."}], "references": [{"title": "Fixing and extending some recent results on the admm algorithm", "author": ["Banert", "Sebastian", "Bot", "Radu Ioan", "Csetnek", "Ern\u00f6 Robert"], "venue": "arXiv preprint arXiv:1612.05057,", "citeRegEx": "Banert et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Banert et al\\.", "year": 2016}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["Boyd", "Stephen", "Parikh", "Neal", "Chu", "Eric", "Peleato", "Borja", "Eckstein", "Jonathan"], "venue": "Found. and Trends in Mach. Learning,", "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization", "author": ["Burer", "Samuel", "Monteiro", "Renato DC"], "venue": "Mathematical Programming,", "citeRegEx": "Burer et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Burer et al\\.", "year": 2003}, {"title": "LIBSVM: a library for support vector machines", "author": ["Chang", "Chih-Chung", "Lin", "Chih-Jen"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "Chang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2011}, {"title": "Asynchronous distributed alternating direction method of multipliers: Algorithm and convergence analysis", "author": ["Chang", "Tsung-Hui", "Hong", "Mingyi", "Liao", "Wei-Cheng", "Wang", "Xiangfeng"], "venue": "In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Chang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2016}, {"title": "Faster convergence rates of relaxed peaceman-rachford and admm under regularity assumptions", "author": ["Davis", "Damek", "Yin", "Wotao"], "venue": "arXiv preprint arXiv:1407.5210,", "citeRegEx": "Davis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Davis et al\\.", "year": 2014}, {"title": "On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators", "author": ["Eckstein", "Jonathan", "Bertsekas", "Dimitri"], "venue": "Mathematical Programming,", "citeRegEx": "Eckstein et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Eckstein et al\\.", "year": 1992}, {"title": "An explicit rate bound for over-relaxed admm", "author": ["Fran\u00e7a", "Guilherme", "Bento", "Jos\u00e9"], "venue": "In Information Theory (ISIT),", "citeRegEx": "Fran\u00e7a et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Fran\u00e7a et al\\.", "year": 2016}, {"title": "Optimal parameter selection for the alternating direction method of multipliers: quadratic problems", "author": ["Ghadimi", "Euhanna", "Teixeira", "Andr\u00e9", "Shames", "Iman", "Johansson", "Mikael"], "venue": "IEEE Trans. Autom. Control,", "citeRegEx": "Ghadimi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ghadimi et al\\.", "year": 2015}, {"title": "Linear convergence and metric selection in douglas-rachford splitting and admm", "author": ["Giselsson", "Pontus", "Boyd", "Stephen"], "venue": null, "citeRegEx": "Giselsson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Giselsson et al\\.", "year": 2016}, {"title": "Sur l\u2019approximation, par \u00e9l\u00e9ments finis d\u2019ordre un, et la r\u00e9solution, par p\u00e9nalisation-dualit\u00e9 d\u2019une classe de probl\u00e9mes de Dirichlet non lin\u00e9aires", "author": ["Glowinski", "Roland", "A. Marroco"], "venue": "ESAIM: Modlisation Mathmatique et Analyse Numrique,", "citeRegEx": "Glowinski et al\\.,? \\Q1975\\E", "shortCiteRegEx": "Glowinski et al\\.", "year": 1975}, {"title": "Fast alternating linearization methods for minimizing the sum of two convex functions", "author": ["Goldfarb", "Donald", "Ma", "Shiqian", "Scheinberg", "Katya"], "venue": "Mathematical Programming,", "citeRegEx": "Goldfarb et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Goldfarb et al\\.", "year": 2013}, {"title": "High-order methods for basis pursuit", "author": ["Goldstein", "Tom", "Setzer", "Simon"], "venue": "UCLA CAM Report,", "citeRegEx": "Goldstein et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Goldstein et al\\.", "year": 2010}, {"title": "Fast alternating direction optimization methods", "author": ["Goldstein", "Tom", "O\u2019Donoghue", "Brendan", "Setzer", "Simon", "Baraniuk", "Richard"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "Goldstein et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goldstein et al\\.", "year": 2014}, {"title": "Adaptive primal-dual splitting methods for statistical learning and image processing", "author": ["Goldstein", "Tom", "Li", "Min", "Yuan", "Xiaoming"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goldstein et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Goldstein et al\\.", "year": 2015}, {"title": "Unwrapping ADMM: efficient distributed computing via transpose reduction", "author": ["Goldstein", "Tom", "Taylor", "Gavin", "Barabin", "Kawika", "Sayre", "Kent"], "venue": "In AISTATS,", "citeRegEx": "Goldstein et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Goldstein et al\\.", "year": 2016}, {"title": "On the o(1/n) convergence rate of the douglas-rachford alternating direction method", "author": ["He", "Bingsheng", "Yuan", "Xiaoming"], "venue": "SIAM Journal on Numerical Analysis,", "citeRegEx": "He et al\\.,? \\Q2012\\E", "shortCiteRegEx": "He et al\\.", "year": 2012}, {"title": "On non-ergodic convergence rate of Douglas-Rachford alternating direction method of multipliers", "author": ["He", "Bingsheng", "Yuan", "Xiaoming"], "venue": "Numerische Mathematik,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Alternating direction method with self-adaptive penalty parameters for monotone variational inequalities", "author": ["He", "Bingsheng", "Yang", "Hai", "Wang", "Shengli"], "venue": "Jour. Optim. Theory and Appl.,", "citeRegEx": "He et al\\.,? \\Q2000\\E", "shortCiteRegEx": "He et al\\.", "year": 2000}, {"title": "Accelerated alternating direction method of multipliers", "author": ["Kadkhodaie", "Mojtaba", "Christakopoulou", "Konstantina", "Sanjabi", "Maziar", "Banerjee", "Arindam"], "venue": "In Proceedings of the 21th ACM SIGKDD,", "citeRegEx": "Kadkhodaie et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kadkhodaie et al\\.", "year": 2015}, {"title": "Learning multiple layers of features from tiny images", "author": ["Krizhevsky", "Alex", "Hinton", "Geoffrey"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2009}, {"title": "Gradient-based learning applied to document recognition", "author": ["LeCun", "Yann", "Bottou", "L\u00e9on", "Bengio", "Yoshua", "Haffner", "Patrick"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Linearized alternating direction method with adaptive penalty for low-rank representation", "author": ["Lin", "Zhouchen", "Liu", "Risheng", "Su", "Zhixun"], "venue": "In NIPS,", "citeRegEx": "Lin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2011}, {"title": "On the limited memory bfgs method for large scale optimization", "author": ["Liu", "Dong C", "Nocedal", "Jorge"], "venue": "Mathematical programming,", "citeRegEx": "Liu et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Liu et al\\.", "year": 1989}, {"title": "Large-scale sparse logistic regression", "author": ["Liu", "Jun", "Chen", "Jianhui", "Ye", "Jieping"], "venue": "In ACM SIGKDD,", "citeRegEx": "Liu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "A general analysis of the convergence of ADMM", "author": ["R. Nishihara", "L. Lessard", "B. Recht", "A. Packard", "M. Jordan"], "venue": "In ICML,", "citeRegEx": "Nishihara et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nishihara et al\\.", "year": 2015}, {"title": "Stochastic alternating direction method of multipliers", "author": ["Ouyang", "Hua", "He", "Niao", "Tran", "Long", "Gray", "Alexander G"], "venue": "ICML (1),", "citeRegEx": "Ouyang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ouyang et al\\.", "year": 2013}, {"title": "Alternating direction method of multipliers for strictly convex quadratic programs: Optimal parameter selection", "author": ["Raghunathan", "Arvind", "Di Cairano", "Stefano"], "venue": "In American Control Conf.,", "citeRegEx": "Raghunathan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Raghunathan et al\\.", "year": 2014}, {"title": "Convex Analysis", "author": ["R. Rockafellar"], "venue": null, "citeRegEx": "Rockafellar,? \\Q1970\\E", "shortCiteRegEx": "Rockafellar", "year": 1970}, {"title": "Fast ADMM algorithm for distributed optimization with adaptive penalty", "author": ["Song", "Changkyu", "Yoon", "Sejong", "Pavlovic", "Vladimir"], "venue": null, "citeRegEx": "Song et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Song et al\\.", "year": 2016}, {"title": "Training neural networks without gradients: A scalable ADMM approach", "author": ["Taylor", "Gavin", "Burmeister", "Ryan", "Xu", "Zheng", "Singh", "Bharat", "Patel", "Ankit", "Goldstein", "Tom"], "venue": null, "citeRegEx": "Taylor et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Taylor et al\\.", "year": 2016}, {"title": "Faster alternating direction method of multipliers with a worst-case o (1/n) convergence", "author": ["Tian", "Wenyi", "Yuan", "Xiaoming"], "venue": null, "citeRegEx": "Tian et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tian et al\\.", "year": 2016}, {"title": "Adaptive ADMM with spectral penalty parameter selection", "author": ["Xu", "Zheng", "Figueiredo", "Mario AT", "Goldstein", "Tom"], "venue": null, "citeRegEx": "Xu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2017}, {"title": "Adaptive relaxed ADMM: Convergence theory and practical implementation", "author": ["Xu", "Zheng", "Figueiredo", "Mario AT", "Yuan", "Xiaoming", "Studer", "Christoph", "Goldstein", "Tom"], "venue": null, "citeRegEx": "Xu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2017}, {"title": "Asynchronous distributed ADMM for consensus optimization", "author": ["Zhang", "Ruiliang", "Kwok", "James T"], "venue": "In ICML, pp", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Gradient methods with adaptive step-sizes", "author": ["Zhou", "Bin", "Gao", "Li", "Dai", "Yu-Hong"], "venue": "Computational Optimization and Applications,", "citeRegEx": "Zhou et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2006}, {"title": "Regularization and variable selection via the elastic net", "author": ["Zou", "Hui", "Hastie", "Trevor"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Zou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 1, "context": "ADMM was first introduced in (Glowinski & Marroco, 1975) and (Gabay & Mercier, 1976), and has found applications in many optimization problems in machine learning, distributed computing and many other areas (Boyd et al., 2011).", "startOffset": 207, "endOffset": 226}, {"referenceID": 1, "context": "Consensus ADMM (Boyd et al., 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al.", "startOffset": 15, "endOffset": 34}, {"referenceID": 1, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 29, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 4, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 15, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 30, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 26, "context": "In theory, ADMM converges for any constant penalty parameter (Eckstein & Bertsekas, 1992; He & Yuan, 2012; Ouyang et al., 2013).", "startOffset": 61, "endOffset": 127}, {"referenceID": 25, "context": "In practice, however, the efficiency of ADMM is highly sensitive to this parameter choice (Nishihara et al., 2015; Ghadimi et al., 2015), and can be improved via adaptive penalty selection methods (He et al.", "startOffset": 90, "endOffset": 136}, {"referenceID": 8, "context": "In practice, however, the efficiency of ADMM is highly sensitive to this parameter choice (Nishihara et al., 2015; Ghadimi et al., 2015), and can be improved via adaptive penalty selection methods (He et al.", "startOffset": 90, "endOffset": 136}, {"referenceID": 18, "context": ", 2015), and can be improved via adaptive penalty selection methods (He et al., 2000; Song et al., 2016; Xu et al., 2017a).", "startOffset": 68, "endOffset": 122}, {"referenceID": 29, "context": ", 2015), and can be improved via adaptive penalty selection methods (He et al., 2000; Song et al., 2016; Xu et al., 2017a).", "startOffset": 68, "endOffset": 122}, {"referenceID": 18, "context": "One such approach, residual balancing (RB) (He et al., 2000), adapts the penalty parameter so that the residuals (derivatives of the Lagrangian with respect to primal and dual variables) have similar magnitudes.", "startOffset": 43, "endOffset": 60}, {"referenceID": 29, "context": "Consensus residual balancing (CRB) (Song et al., 2016) extends residual balancing to consensusbased ADMM for distributed optimization by balancing the local primal and dual residuals on each node.", "startOffset": 35, "endOffset": 54}, {"referenceID": 18, "context": "Our theory is more general than the convergence guarantee in (He et al., 2000; Xu et al., 2017a) that only shows convergence when the scalar penalty parameter is adapted.", "startOffset": 61, "endOffset": 96}, {"referenceID": 11, "context": "ADMM is known to have aO(1/k) convergence rate under mild conditions for convex problems (He & Yuan, 2012; 2015), while a O(1/k) rate is possible when at least one of the functions is strongly convex or smooth (Goldfarb et al., 2013; Goldstein et al., 2014; Kadkhodaie et al., 2015; Tian & Yuan, 2016).", "startOffset": 210, "endOffset": 301}, {"referenceID": 13, "context": "ADMM is known to have aO(1/k) convergence rate under mild conditions for convex problems (He & Yuan, 2012; 2015), while a O(1/k) rate is possible when at least one of the functions is strongly convex or smooth (Goldfarb et al., 2013; Goldstein et al., 2014; Kadkhodaie et al., 2015; Tian & Yuan, 2016).", "startOffset": 210, "endOffset": 301}, {"referenceID": 19, "context": "ADMM is known to have aO(1/k) convergence rate under mild conditions for convex problems (He & Yuan, 2012; 2015), while a O(1/k) rate is possible when at least one of the functions is strongly convex or smooth (Goldfarb et al., 2013; Goldstein et al., 2014; Kadkhodaie et al., 2015; Tian & Yuan, 2016).", "startOffset": 210, "endOffset": 301}, {"referenceID": 25, "context": "Linear convergence can be achieved with strong convexity assumptions (Davis & Yin, 2014; Nishihara et al., 2015; Giselsson & Boyd, 2016).", "startOffset": 69, "endOffset": 136}, {"referenceID": 18, "context": "All of these results assume constant parameters; to the best of our knowledge, no convergence rate has been proven for ADMM with an adaptive penalty: (He et al., 2000; Xu et al., 2017b) proves convergence without providing a rate, and (Lin et al.", "startOffset": 150, "endOffset": 185}, {"referenceID": 22, "context": ", 2017b) proves convergence without providing a rate, and (Lin et al., 2011; Banert et al., 2016; Goldstein et al., 2015) prove convergence for some particular variants of ADMM (\u201clinearized\u201d or \u201cpreconditioned\u201d).", "startOffset": 58, "endOffset": 121}, {"referenceID": 0, "context": ", 2017b) proves convergence without providing a rate, and (Lin et al., 2011; Banert et al., 2016; Goldstein et al., 2015) prove convergence for some particular variants of ADMM (\u201clinearized\u201d or \u201cpreconditioned\u201d).", "startOffset": 58, "endOffset": 121}, {"referenceID": 14, "context": ", 2017b) proves convergence without providing a rate, and (Lin et al., 2011; Banert et al., 2016; Goldstein et al., 2015) prove convergence for some particular variants of ADMM (\u201clinearized\u201d or \u201cpreconditioned\u201d).", "startOffset": 58, "endOffset": 121}, {"referenceID": 8, "context": "To improve practical convergence of ADMM, fixed optimal parameters are discussed in (Raghunathan & Di Cairano, 2014; Ghadimi et al., 2015; Nishihara et al., 2015; Fran\u00e7a & Bento, 2016).", "startOffset": 84, "endOffset": 184}, {"referenceID": 25, "context": "To improve practical convergence of ADMM, fixed optimal parameters are discussed in (Raghunathan & Di Cairano, 2014; Ghadimi et al., 2015; Nishihara et al., 2015; Fran\u00e7a & Bento, 2016).", "startOffset": 84, "endOffset": 184}, {"referenceID": 29, "context": "Additionally, adaptive methods have been proposed; the most closely related work to our own is (Song et al., 2016), which extends the results of (He et al.", "startOffset": 95, "endOffset": 114}, {"referenceID": 18, "context": ", 2016), which extends the results of (He et al., 2000) to consensus problems, where communication is controlled by predefined network structure and the regularizer g(v) is absent.", "startOffset": 38, "endOffset": 55}, {"referenceID": 1, "context": "The residuals in (6) and stopping criterion in (7) are adopted from the general problem (Boyd et al., 2011) to the consensus problem.", "startOffset": 88, "endOffset": 107}, {"referenceID": 18, "context": "The observation that residuals r, d can be decomposed into \u201clocal residuals\u201d r i , d k i has been exploited to generalize the residual balancing method (He et al., 2000) for distributed consensus problems (Song et al.", "startOffset": 152, "endOffset": 169}, {"referenceID": 29, "context": ", 2000) for distributed consensus problems (Song et al., 2016).", "startOffset": 43, "endOffset": 62}, {"referenceID": 18, "context": "Our proof is inspired by the variational inequality (VI) approach in (He et al., 2000; He & Yuan, 2012; 2015).", "startOffset": 69, "endOffset": 109}, {"referenceID": 28, "context": "where \u03bb denotes the dual variable, while f\u2217, g\u2217 denote the Fenchel conjugate of f, g (Rockafellar, 1970).", "startOffset": 85, "endOffset": 104}, {"referenceID": 35, "context": "(Zhou et al., 2006) recommend using a hybrid of these two estimators, and choosing", "startOffset": 0, "endOffset": 19}, {"referenceID": 1, "context": "Application Dataset #samples \u00d7 #features 1 CADMM (Boyd et al., 2011) RB-ADMM (He et al.", "startOffset": 49, "endOffset": 68}, {"referenceID": 18, "context": ", 2011) RB-ADMM (He et al., 2000) AADMM (Xu et al.", "startOffset": 16, "endOffset": 33}, {"referenceID": 29, "context": ", 2017a) CRB-ADMM (Song et al., 2016) Proposed ACADMM", "startOffset": 18, "endOffset": 37}, {"referenceID": 15, "context": "Support Vector Machines (SVMs) minimize the distributed objective function (Goldstein et al., 2016)", "startOffset": 75, "endOffset": 99}, {"referenceID": 24, "context": "We also acquire large empirical datasets from the LIBSVM webpage (Liu et al., 2009), as well as MNIST digital images (LeCun et al.", "startOffset": 65, "endOffset": 83}, {"referenceID": 21, "context": ", 2009), as well as MNIST digital images (LeCun et al., 1998), and CIFAR10 object images (Krizhevsky & Hinton, 2009).", "startOffset": 41, "endOffset": 61}, {"referenceID": 1, "context": "Consensus ADMM (CADMM) (Boyd et al., 2011), residual balancing (RB-ADMM) (He et al.", "startOffset": 23, "endOffset": 42}, {"referenceID": 18, "context": ", 2011), residual balancing (RB-ADMM) (He et al., 2000), adaptive ADMM (AADMM) (Xu et al.", "startOffset": 38, "endOffset": 55}, {"referenceID": 29, "context": ", 2017a), and consensus residual balancing (CRB-ADMM) (Song et al., 2016) are implemented and reported for comparison.", "startOffset": 54, "endOffset": 73}, {"referenceID": 1, "context": "CADMM with default penalty \u03c4 = 1 (Boyd et al., 2011) is often slow to converge.", "startOffset": 33, "endOffset": 52}], "year": 2017, "abstractText": "The alternating direction method of multipliers (ADMM) is commonly used for distributed model fitting problems, but its performance and reliability depend strongly on userdefined penalty parameters. We study distributed ADMM methods that boost performance by using different fine-tuned algorithm parameters on each worker node. We present a O(1/k) convergence rate for adaptive ADMM methods with node-specific parameters, and propose adaptive consensus ADMM (ACADMM), which automatically tunes parameters without user oversight.", "creator": "LaTeX with hyperref package"}}}