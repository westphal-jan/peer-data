{"id": "1706.03475", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jun-2017", "title": "Confident Multiple Choice Learning", "abstract": "Ensemble methods are arguably the most trustworthy techniques for boosting the performance of machine learning models. Popular independent ensembles (IE) relying on naive averaging/voting scheme have been of typical choice for most applications involving deep neural networks, but they do not consider advanced collaboration among ensemble models. In this paper, we propose new ensemble methods specialized for deep neural networks, called confident multiple choice learning (CMCL): it is a variant of multiple choice learning (MCL) via addressing its overconfidence issue.In particular, the proposed major components of CMCL beyond the original MCL scheme are (i) new loss, i.e., confident oracle loss, (ii) new architecture, i.e., feature sharing and (iii) new training method, i.e., stochastic labeling. We demonstrate the effect of CMCL via experiments on the image classification on CIFAR and SVHN, and the foreground-background segmentation on the iCoseg. In particular, CMCL using 5 residual networks provides 14.05% and 6.60% relative reductions in the top-1 error rates from the corresponding IE scheme for the classification task on CIFAR and SVHN, respectively.", "histories": [["v1", "Mon, 12 Jun 2017 05:55:38 GMT  (1471kb,D)", "http://arxiv.org/abs/1706.03475v1", "Accepted in ICML 2017"], ["v2", "Fri, 22 Sep 2017 05:56:57 GMT  (1480kb,D)", "http://arxiv.org/abs/1706.03475v2", "Accepted in ICML 2017"]], "COMMENTS": "Accepted in ICML 2017", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["kimin lee", "changho hwang", "kyoungsoo park", "jinwoo shin"], "accepted": true, "id": "1706.03475"}, "pdf": {"name": "1706.03475.pdf", "metadata": {"source": "META", "title": "Confident Multiple Choice Learning", "authors": ["Kimin Lee", "Changho Hwang", "KyoungSoo Park", "Jinwoo Shin"], "emails": ["<jinwoos@kaist.ac.kr>."], "sections": [{"heading": "1. Introduction", "text": "Ensemble methods have played a crucial role in the machine learning community to achieve better predictive performance than what could be achieved by most constituent learning models alone. (Recently, they have been successfully applied to enhance the power of many deep neural networks, e.g. 80% by 1School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Repulic of Korea. Correspondence on: Jinwoo Shin < jinwoos @ kaist.ac.kr > Proceedings of the 34 th International Conference on Machine Learning, Sydney, PMLR 70, 2017. Copyright 2017 by author (s).top-5 best-performing teams on ILSVRC challenge 2016 (Krizhevsky et al, 2012). They are simple and worthy to apply there."}, {"heading": "2. Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Multiple Choice Learning", "text": "In this section, we describe the basic concept of multiple choice learning (MCL) (Guzman-Rivera et al., 2014; 2012). In the course of this work, we designate the sentence {1,.., n} by [n] for positive integers n. The MCL scheme is a type of ensemble learning that produces a variety of high-quality results. Formally, a training data set D = {(xi, yi) | i [N], xi-X, yi-Y}, an ensemble of M models f, i.e. (f1,., fM). For some task-specific loss functions (y, f (x)), the oracle loss via data set D is defined as: LO (D) = N block i = 1 min m = [M] (yi, fm (xi))), while the traditional independent model (IE) losses (D) = N-M = 1 m-y."}, {"heading": "2.2. Oracle Loss for Top-1 Choice", "text": "The oracle loss (1) used for MCL is useful to produce varied / plausible results, but it is often unsuitable for applications that require a single choice, i.e., top-1 errors. This is because ensembles of deep neural networks tend to be too confident in their predictions, and it is difficult to judge a better solution from their results. To explain this more precisely, we evaluate the performance of ensembles of Convolutionary Neural Networks (CNNs) for the image classification task on the CIFAR 10 dataset (Krizhevsky & Hinton, 2009). We train ensembles of 5 CNNs (two revolutionary layers followed by a fully connected layer) using MCL. We also train the models that train each model independently of other random initializations (Krizhevsky & Hinton, 2009). We train ensembles of 5 CNNs (two revolutionary layers followed by a fully connected layer) using MCL."}, {"heading": "3. Confident Multiple Choice Learning", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Confident Oracle Loss", "text": "In this section, we propose a modified oracle loss in order to alleviate the problem of the MCL described in the previous section. Suppose the m-th model outputs the predictive distribution P\u03b8m (y | x) with respect to input x, where Phenomenm denotes the model parameters. Then, we define the self-confident oracle loss as the following integer programming variant of (1): LC (D) = min vmi N \u2211 i = 1 M \u2211 m = 1 (vmi '(yi, P\u03b8m (y | xi)) + \u03b2 (1 \u2212 vmi) DKL (U (y) \u03bcm (y | xi))))) (3a) is subject to M \u2211 m = 1 vmi = 1, \u0451i, (3b) vmi, vmi (i, m (3c), where DKL denotes the Kullback-Leibler (KL) divergence, U (y) is the prediction parameter, is a parameter that can be specified as a penalty parameter for most, and the classification is a variation of the L."}, {"heading": "3.2. Stochastic Alternating Minimization for Training", "text": "To efficiently minimize self-confident oracle loss (3), we use the following procedure (Guzman-Rivera et al., 2012), which optimizes the model parameters (3a) and assignment variables (vmi), alternatively: 1. Fix (vmi) and optimize (vmi).Under specified model parameters (3a), the goal (3a) is separable in terms of assignments (vmi) and it is easy to optimize (vmi).2. Fix (vmi) and optimize (vmi).Under specified model parameters (vmi), the goal (3a) is separable in terms of model parameters (vmi), and it requires that each model be trained independently. The above scheme iteratively assigns a specific model to each model and then independently trains each model using the assigned data. Even if it monotonically reduces the target, it is still highly inefficient, as each model requires multiple assignments."}, {"heading": "3.3. Effect of Confident Oracle Loss", "text": "Similar to Section 2.2, we evaluate the performance of the proposed training scheme using 5 CNNs for image classification on the CIFAR 10 dataset. As shown in Figure 1 (b), CMCL-trained ensemble models become specialists for specific classes using the exact gradient (i.e. version 0 of the algorithm 1). For non-specialized classes, they show similar performance compared to MCL-trained models, i.e. minimizing oracle loss (1), which only takes into account specialization (see Figure 1 (a)). For non-specialized classes, the entropy members of the CMCL are not overconfident, which makes it easier to select correct output by simple tuning / averaging. We do confirm that each model tracked by CMCL not only exhibits low entropy for its specialized classes, but also has high entropy for non-specialized classes, as shown in Figure 2 (b)."}, {"heading": "4. Regularization Techniques", "text": "In this section we present advanced techniques to reduce hubris and improve performance."}, {"heading": "4.1. Feature Sharing", "text": "The primary reason why deep learning models are too self-conscious is that they do not always extract general characteristics from data. For example, let's assume that some deep models only train frogs and roses to classify them. Although there may be many types of characteristics in their images, the model could make a decision based only on some specific characteristics, such as colors. In this case, \"red\" apples can be classified as roses with high confidence. Such a problem could be more severe in CMCL (and MCL) compared to IE, as the members of CMCL specialize in specific data. To address the problem, we propose the feature ensemble approach, which encourages each model to generate meaningful abstractions from rich characteristics extracted from other models.Formally, we are looking at an ensemble of M neural networks with hidden layers x. We call the weight matrix for layer of the model 'M' m'm [hidden characteristic of W] m m m m m m m m m m."}, {"heading": "4.2. Stochastic Labeling", "text": "For greater efficiency in minimizing self-confident oracle loss, we also consider a loud, unbiased estimator of the KL divergence gradients with Monte Carlo samples from the uniform distribution. KL divergence from the predictive distribution to the uniform distribution can be described as follows: DKL (U (y), P\u03b8 (y), Log U (y), Log U (y), Log U (y), Log U (y), Log U (y), Log P\u03b8 (y | x). Therefore, the divergence of the above mentioned KL divergence in relation to the model parameter circuit, the 5\u03b8DKL (U (y), PTB (y | x), EU (y), Log PTB (y), Log PTB (y | x), Log PTB (y | x)."}, {"heading": "5. Experiments", "text": "We evaluate our algorithm for both classification and foreground-background segmentation tasks using CIFAR10 (Krizhevsky & Hinton, 2009), SVHN (Netzer et al., 2011) and iCoseg (Batra et al., 2010) datasets."}, {"heading": "5.1. Image Classification", "text": "The CIFAR-10 Dataset consists of 50,000 training sessions and 10,000 test images with 10 image classes, each image consisting of 32 x 32 RGB pixels. SVHN Dataset consists of 73,257 training sessions and 26,032 test images. 2 We process the images with global contrast normalization and ZCA whitening in the following ways (Ian J. Goodfellow & Bengio, 2013; Zagoruyko & Komodakis, 2016), which we evaluate various CNNs, e.g. VGNet (Simonyan & Zisserman, 2015), GoogLeNet et al. (Er et al., 2016). Similar to (Zagoruyko & Komodakis, 2016), we use the softmax classifiers, and train each model by minimizing the cross section."}, {"heading": "5.2. Foreground-Background Segmentation", "text": "In this section, we evaluate whether ensemble models trained with CMCL produce a high-quality segmentation of the foreground and background of an image using the iCoseg dataset. Foreground and background segmentation is formulated as a pixel error classification problem with 2 classes, i.e., 0 (background) or 1 (foreground). To address the problem, we design a fully revolutionary network (FCNs) model (Long et al., 2015) based on the decoder error architecture depicted in (Radford et al., 2016). The dataset consists of 38 groups of related images with pixel-level basic truth based on the segmentation of each image. We only use ages larger than 300 x 500 pixels. For each class, we randomly divide 80% and 20% of the data into training and test groups. We train on 75 x 125 scaled images using the bicubic interpolation Keys (2016, we define 1981, and Lee Riveret Eneg, respectively)."}, {"heading": "6. Conclusion", "text": "In this paper, we propose CMCL, a novel ensemble method of deep neural networks that provides diverse / plausible and reliable predictions of high quality. To this end, we address the problem of over-confidence in MCL and propose a new loss, architecture and training method. In our experiments, CMCL not only outperforms the well-known MCL, but also the traditional IE in terms of top-1 error rates for classification and segmentation tasks. The recent trend in the deep learning community is leading models to become larger and broader. We believe that our new ensemble approach provides a refreshing approach to the development of advanced large deep neural networks in many related applications."}, {"heading": "Acknowledgements", "text": "This work was partially supported by the ICT R & D Program of MSIP / IITP, Korea, under [2016-0-00563, Research on Adaptive Machine Learning Technology Development for Intelligent Autonomous Digital Companion], R0190-162012, [High Performance Big Data Analytics Platform Performance Acceleration Technologies Development] and by the National Research Council of Science & Technology (NST) of the Korean Government (MSIP) (No. CRC-15-05-ETRI)."}, {"heading": "A. Experimental Setups for Image Classification", "text": "In this section we describe detailed explanations of all the experiments performed in Section 5.1.Detailed CNN structure and training.The CNN we use for evaluations in Table 1 consists of two revolutionary layers followed by a fully connected layer. Convolutional layers have 128 and 256 filters respectively. Each revolutionary layer has a receptive field applied with a step of 1 pixel. Each maximum pooling layer pools 2 x 2 regions with steps of 2 pixels. Dropout has been applied to all layers in the network with the likelihood of 0.5. Similar to (Zagoruyko & Komodakis, 2016), the softmax layer pools is used, and each model is trained by the cross-entropy loss with SGD with Nesterov dynamics. The initial learning rate is set to 0.01, weight to 0.01, weight to 0.01, to 0.01, to 0.01."}, {"heading": "B. Experimental Setups for Background-Foreground Segmentation", "text": "In this section we describe detailed explanations of all the experiments described in Section 5.2. They consist of three coiled layers followed by a completely coiled layer. The coiled layers have 128, 256, and 1 filter, respectively. Each coiled layer has a 4 \u00d7 4 receptive field applied with a step of 2 pixels. To share features, the 2nd activation of FCNs is used. The Softmax classifier is used, and each model is trained by minimizing cross-entropy loss using the Adam learning rule (Kingma & Ba, 2015) with a minibatch size of 20. The initial learning rate is chosen from {0.001, 0.0005, 0.0001}, and we have used an exponentially decreasing learning rate. We train each model for a total of 300 epochs. Similar to (Guzman-Rivera et al., 2012; Lee et al., 2016) we initialize the parameters of FCNs for using the CNL method best."}], "references": [{"title": "icoseg: Interactive co-segmentation with intelligent scribble guidance", "author": ["Batra", "Dhruv", "Kowdle", "Adarsh", "Parikh", "Devi", "Luo", "Jiebo", "Chen", "Tsuhan"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Batra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Batra et al\\.", "year": 2010}, {"title": "Diverse m-best solutions in markov random fields", "author": ["Batra", "Dhruv", "Yadollahpour", "Payman", "Guzman-Rivera", "Abner", "Shakhnarovich", "Gregory"], "venue": "In European Conference on Computer Vision (ECCV),", "citeRegEx": "Batra et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Batra et al\\.", "year": 2012}, {"title": "Multi-column deep neural networks for image classification", "author": ["Ciregan", "Dan", "Meier", "Ueli", "Schmidhuber", "J\u00fcrgen"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Ciregan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ciregan et al\\.", "year": 2012}, {"title": "Discriminative reranking for natural language parsing", "author": ["Collins", "Michael", "Koo", "Terry"], "venue": "Computational Linguistics,", "citeRegEx": "Collins et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Collins et al\\.", "year": 2005}, {"title": "Predicting multiple structured visual interpretations", "author": ["Dey", "Debadeepta", "Ramakrishna", "Varun", "Hebert", "Martial", "J. Andrew Bagnell"], "venue": "In International Conference on Computer Vision (ICCV),", "citeRegEx": "Dey et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dey et al\\.", "year": 2015}, {"title": "Bayesian averaging of classifiers and the overfitting problem", "author": ["Domingos", "Pedro"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Domingos and Pedro.,? \\Q2000\\E", "shortCiteRegEx": "Domingos and Pedro.", "year": 2000}, {"title": "The pascal visual object classes (voc) challenge", "author": ["Everingham", "Mark", "Van Gool", "Luc", "Williams", "Christopher KI", "Winn", "John", "Zisserman", "Andrew"], "venue": "International journal of computer vision,", "citeRegEx": "Everingham et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Everingham et al\\.", "year": 2010}, {"title": "A short introduction to boosting", "author": ["Freund", "Yoav", "Schapire", "Robert", "N. Abe"], "venue": "Journal-Japanese Society For Artificial Intelligence,", "citeRegEx": "Freund et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1999}, {"title": "Efficiently enforcing diversity in multi-output structured prediction", "author": ["Guzman-Rivera", "Abner", "Kohli", "Pushmeet", "Batra", "Dhruv", "Rutenbar", "Rob A"], "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Guzman.Rivera et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Guzman.Rivera et al\\.", "year": 2014}, {"title": "Deep residual learning for image recognition", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "In Computer Vision and Pattern Recognition", "citeRegEx": "He et al\\.,? \\Q2016\\E", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Better k-best parsing", "author": ["Huang", "Liang", "Chiang", "David"], "venue": "In Proceedings of the Ninth International Workshop on Parsing Technology,", "citeRegEx": "Huang et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2005}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Ioffe", "Sergey", "Szegedy", "Christian"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Ioffe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe et al\\.", "year": 2015}, {"title": "Adaptive mixtures of local experts", "author": ["Jacobs", "Robert A", "Jordan", "Michael I", "Nowlan", "Steven J", "Hinton", "Geoffrey E"], "venue": "Neural computation,", "citeRegEx": "Jacobs et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Jacobs et al\\.", "year": 1991}, {"title": "Cubic convolution interpolation for digital image processing", "author": ["Keys", "Robert"], "venue": "IEEE transactions on acoustics, speech, and signal processing,", "citeRegEx": "Keys and Robert.,? \\Q1981\\E", "shortCiteRegEx": "Keys and Robert.", "year": 1981}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Kingma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2015}, {"title": "Learning multiple layers of features from tiny images", "author": ["Krizhevsky", "Alex", "Hinton", "Geoffrey"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (NIPS)", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Simple and scalable predictive uncertainty estimation using deep ensembles", "author": ["Lakshminarayanan", "Balaji", "Pritzel", "Alexander", "Blundell", "Charles"], "venue": "NIPS Workshop on Bayesian Deep Learning,", "citeRegEx": "Lakshminarayanan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lakshminarayanan et al\\.", "year": 2016}, {"title": "Why m heads are better than one: Training a diverse ensemble of deep networks", "author": ["Lee", "Stefan", "Purushwalkam", "Senthil", "Cogswell", "Michael", "Crandall", "David", "Batra", "Dhruv"], "venue": "arXiv preprint arXiv:1511.06314,", "citeRegEx": "Lee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2015}, {"title": "Network in network", "author": ["Lin", "Min", "Chen", "Qiang", "Yan", "Shuicheng"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Microsoft coco: Common objects in context", "author": ["Lin", "Tsung-Yi", "Maire", "Michael", "Belongie", "Serge", "Hays", "James", "Perona", "Pietro", "Ramanan", "Deva", "Doll\u00e1r", "Piotr", "Zitnick", "C Lawrence"], "venue": "In European Conference on Computer Vision (ECCV),", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["Long", "Jonathan", "Shelhamer", "Evan", "Darrell", "Trevor"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Long et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Long et al\\.", "year": 2015}, {"title": "Cross-stitch networks for multi-task learning", "author": ["Misra", "Ishan", "Shrivastava", "Abhinav", "Gupta", "Hebert", "Martial"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Misra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Misra et al\\.", "year": 2016}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Netzer", "Yuval", "Wang", "Tao", "Coates", "Adam", "Bissacco", "Alessandro", "Wu", "Bo", "Ng", "Andrew Y"], "venue": "NIPS Workshop on Deep Learning and Unsupervised Feature Learning,", "citeRegEx": "Netzer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Netzer et al\\.", "year": 2011}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["Nguyen", "Anh", "Yosinski", "Jason", "Clune", "Jeff"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Nguyen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "N-best maximal decoders for part models", "author": ["Park", "Dennis", "Ramanan", "Deva"], "venue": "In International Conference on Computer Vision (ICCV),", "citeRegEx": "Park et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Park et al\\.", "year": 2011}, {"title": "Regularizing neural networks by penalizing confident output distributions", "author": ["Pereyra", "Gabriel", "Tucker", "George", "Chorowski", "Jan", "Kaiser", "\u0141ukasz", "Hinton", "Geoffrey"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Pereyra et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Pereyra et al\\.", "year": 2017}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Radford", "Alec", "Metz", "Luke", "Chintala", "Soumith"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Radford et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Simonyan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2015}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Srivastava", "Nitish", "Hinton", "Geoffrey E", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}, {"title": "Going deeper with convolutions", "author": ["Szegedy", "Christian", "Liu", "Wei", "Jia", "Yangqing", "Sermanet", "Pierre", "Reed", "Scott", "Anguelov", "Dragomir", "Erhan", "Dumitru", "Vanhoucke", "Vincent", "Rabinovich", "Andrew"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Szegedy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2015}, {"title": "Regularization of neural networks using dropconnect", "author": ["Wan", "Li", "Zeiler", "Matthew D", "Zhang", "Sixin", "LeCun", "Yann", "Fergus", "Rob"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Wan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2013}, {"title": "Wide residual networks", "author": ["Zagoruyko", "Sergey", "Komodakis", "Nikos"], "venue": "In British Machine Vision Conference (BMVC),", "citeRegEx": "Zagoruyko et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zagoruyko et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 7, "context": ", Bayesian model/parameter averaging (Domingos, 2000), boosting (Freund et al., 1999) and bagging (Breiman, 1996).", "startOffset": 64, "endOffset": 85}, {"referenceID": 16, "context": "top-5 best-performing teams on ILSVRC challenge 2016 (Krizhevsky et al., 2012) employ ensemble methods.", "startOffset": 53, "endOffset": 78}, {"referenceID": 2, "context": "Despite continued efforts that apply various ensemble methods such as bagging and boosting to deep models, it has been observed that traditional independent ensembles (IE) which train models independently with random initialization achieve the best performance (Ciregan et al., 2012; Lee et al., 2015).", "startOffset": 261, "endOffset": 301}, {"referenceID": 18, "context": "Despite continued efforts that apply various ensemble methods such as bagging and boosting to deep models, it has been observed that traditional independent ensembles (IE) which train models independently with random initialization achieve the best performance (Ciregan et al., 2012; Lee et al., 2015).", "startOffset": 261, "endOffset": 301}, {"referenceID": 1, "context": "For example, (Park & Ramanan, 2011; Batra et al., 2012) proposed human-pose estimation methods which produce multiple predictions and then refine them by employing a temporal model, and (Collins & Koo, 2005) proposed a sentence parsing method which re-ranks the output of an initial system which produces a set of plausible outputs (Huang & Chiang, 2005).", "startOffset": 13, "endOffset": 55}, {"referenceID": 8, "context": "Under this motivation, MCL has been studied (Guzman-Rivera et al., 2014; 2012; Lee et al., 2016), where various applications have been demonstrated, e.", "startOffset": 44, "endOffset": 96}, {"referenceID": 6, "context": ", image classification (Krizhevsky & Hinton, 2009), semantic segmentation (Everingham et al., 2010) and image captioning (Lin et al.", "startOffset": 74, "endOffset": 99}, {"referenceID": 12, "context": "Consequently, it makes each model specialized for a certain subset of data, not for the entire one similarly as mixture-of-expert schemes (Jacobs et al., 1991).", "startOffset": 138, "endOffset": 159}, {"referenceID": 30, "context": "We apply the new ensemble model trained by the new training scheme for several convolutional neural networks (CNNs) including VGGNet (Simonyan & Zisserman, 2015), GoogLeNet (Szegedy et al., 2015), and ResNet (He et al.", "startOffset": 173, "endOffset": 195}, {"referenceID": 9, "context": ", 2015), and ResNet (He et al., 2016) for image classification on the CIFAR (Krizhevsky & Hinton, 2009) and SVHN (Netzer et al.", "startOffset": 20, "endOffset": 37}, {"referenceID": 23, "context": ", 2016) for image classification on the CIFAR (Krizhevsky & Hinton, 2009) and SVHN (Netzer et al., 2011) datasets, and fully-convolutional neural networks (FCNs) (Long et al.", "startOffset": 83, "endOffset": 104}, {"referenceID": 21, "context": ", 2011) datasets, and fully-convolutional neural networks (FCNs) (Long et al., 2015) for foreground-background segmentation on the iCoseg dataset (Batra et al.", "startOffset": 65, "endOffset": 84}, {"referenceID": 0, "context": ", 2015) for foreground-background segmentation on the iCoseg dataset (Batra et al., 2010).", "startOffset": 69, "endOffset": 89}, {"referenceID": 8, "context": "In this section, we describe the basic concept of multiple choice learning (MCL) (Guzman-Rivera et al., 2014; 2012).", "startOffset": 81, "endOffset": 115}, {"referenceID": 4, "context": ", 2012) proposed an iterative block coordinate decent algorithm and (Dey et al., 2015) reformulated this problem as a submodular optimization task in which ensemble models are trained sequentially in a boosting-like manner.", "startOffset": 68, "endOffset": 86}, {"referenceID": 31, "context": "For choosing a single output, similar to (Wan et al., 2013; Ciregan et al., 2012), one can average the output probabilities from ensemble members trained by MCL, but the corresponding top-1 classification error rate is often very high (e.", "startOffset": 41, "endOffset": 81}, {"referenceID": 2, "context": "For choosing a single output, similar to (Wan et al., 2013; Ciregan et al., 2012), one can average the output probabilities from ensemble members trained by MCL, but the corresponding top-1 classification error rate is often very high (e.", "startOffset": 41, "endOffset": 81}, {"referenceID": 24, "context": "Such issue typically occurs in deep neural networks since it is well known that they are poor at quantifying predictive uncertainties, and tend to be easily overconfident (Nguyen et al., 2015).", "startOffset": 171, "endOffset": 192}, {"referenceID": 26, "context": "We remark that although we optimize the KL divergence only for non-specialized data, one can also do it even for specialized data to regularize each model (Pereyra et al., 2017).", "startOffset": 155, "endOffset": 177}, {"referenceID": 17, "context": "In the case of IE, we follow the proposed method by (Lakshminarayanan et al., 2016): train an ensemble of 5 models with adversarial training (AT) and measure the entropy using the averaged probability, i.", "startOffset": 52, "endOffset": 83}, {"referenceID": 23, "context": "We also evaluate the quality of confidence/uncertainty level on unseen data using SVHN (Netzer et al., 2011).", "startOffset": 87, "endOffset": 108}, {"referenceID": 17, "context": "We emphasize that our method can produce confident predictions significantly better than the proposed method by (Lakshminarayanan et al., 2016), which uses the averaged probability of ensemble models trained by IE to obtain high quality uncertainty estimates (see Figure 2(c)).", "startOffset": 112, "endOffset": 143}, {"referenceID": 22, "context": "We also remark that such feature sharing strategies for better generalization have also been investigated in the literature for different purposes (Misra et al., 2016; Rusu et al., 2016).", "startOffset": 147, "endOffset": 186}, {"referenceID": 23, "context": "We evaluate our algorithm for both classification and foreground-background segmentation tasks using CIFAR10 (Krizhevsky & Hinton, 2009), SVHN (Netzer et al., 2011) and iCoseg (Batra et al.", "startOffset": 143, "endOffset": 164}, {"referenceID": 0, "context": ", 2011) and iCoseg (Batra et al., 2010) datasets.", "startOffset": 19, "endOffset": 39}, {"referenceID": 30, "context": ", VGGNet (Simonyan & Zisserman, 2015), GoogLeNet (Szegedy et al., 2015), and ResNet (He et al.", "startOffset": 49, "endOffset": 71}, {"referenceID": 9, "context": ", 2015), and ResNet (He et al., 2016).", "startOffset": 20, "endOffset": 37}, {"referenceID": 30, "context": "Specifically, we test VGGNet (Simonyan & Zisserman, 2015), GoogLeNet (Szegedy et al., 2015), and ResNet (He et al.", "startOffset": 69, "endOffset": 91}, {"referenceID": 9, "context": ", 2015), and ResNet (He et al., 2016).", "startOffset": 20, "endOffset": 37}, {"referenceID": 21, "context": "To tackle the problem, we design fully convolutional networks (FCNs) model (Long et al., 2015) based on the decoder architecture presented in (Radford et al.", "startOffset": 75, "endOffset": 94}, {"referenceID": 27, "context": ", 2015) based on the decoder architecture presented in (Radford et al., 2016).", "startOffset": 55, "endOffset": 77}], "year": 2017, "abstractText": "Ensemble methods are arguably the most trustworthy techniques for boosting the performance of machine learning models. Popular independent ensembles (IE) relying on na\u0131\u0308ve averaging/voting scheme have been of typical choice for most applications involving deep neural networks, but they do not consider advanced collaboration among ensemble models. In this paper, we propose new ensemble methods specialized for deep neural networks, called confident multiple choice learning (CMCL): it is a variant of multiple choice learning (MCL) via addressing its overconfidence issue. In particular, the proposed major components of CMCL beyond the original MCL scheme are (i) new loss, i.e., confident oracle loss, (ii) new architecture, i.e., feature sharing and (iii) new training method, i.e., stochastic labeling. We demonstrate the effect of CMCL via experiments on the image classification on CIFAR and SVHN, and the foregroundbackground segmentation on the iCoseg. In particular, CMCL using 5 residual networks provides 14.05% and 6.60% relative reductions in the top-1 error rates from the corresponding IE scheme for the classification task on CIFAR and SVHN, respectively.", "creator": "LaTeX with hyperref package"}}}