{"id": "1706.04859", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2017", "title": "Sobolev Training for Neural Networks", "abstract": "At the heart of deep learning we aim to use neural networks as function approximators - training them to produce outputs from inputs in emulation of a ground truth function or data creation process. In many cases we only have access to input-output pairs from the ground truth, however it is becoming more common to have access to derivatives of the target output with respect to the input - for example when the ground truth function is itself a neural network such as in network compression or distillation. Generally these target derivatives are not computed, or are ignored. This paper introduces Sobolev Training for neural networks, which is a method for incorporating these target derivatives in addition the to target values while training. By optimising neural networks to not only approximate the function's outputs but also the function's derivatives we encode additional information about the target function within the parameters of the neural network. Thereby we can improve the quality of our predictors, as well as the data-efficiency and generalization capabilities of our learned function approximation. We provide theoretical justifications for such an approach as well as examples of empirical evidence on three distinct domains: regression on classical optimisation datasets, distilling policies of an agent playing Atari, and on large-scale applications of synthetic gradients. In all three domains the use of Sobolev Training, employing target derivatives in addition to target values, results in models with higher accuracy and stronger generalisation.", "histories": [["v1", "Thu, 15 Jun 2017 13:25:25 GMT  (8346kb,D)", "http://arxiv.org/abs/1706.04859v1", null], ["v2", "Tue, 4 Jul 2017 12:41:55 GMT  (9199kb,D)", "http://arxiv.org/abs/1706.04859v2", null], ["v3", "Wed, 26 Jul 2017 16:18:52 GMT  (9199kb,D)", "http://arxiv.org/abs/1706.04859v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["wojciech marian czarnecki", "simon osindero", "max jaderberg", "grzegorz \\'swirszcz", "razvan pascanu"], "accepted": true, "id": "1706.04859"}, "pdf": {"name": "1706.04859.pdf", "metadata": {"source": "CRF", "title": "Sobolev Training for Neural Networks", "authors": ["Wojciech Marian Czarnecki", "Simon Osindero", "Max Jaderberg", "Grzegorz Swirszcz"], "emails": ["lejlot@google.com", "osindero@google.com", "jaderberg@google.com", "swirszcz@google.com", "razp@google.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to play by the rules that they have adopted in recent years."}, {"heading": "2 Sobolev Training", "text": "We start by introducing the idea of training with Sobolev spaces. If we learn a function f, we can access not only the output values f (xi) for training points xi, but also the values of their derivatives of the j-th order in relation to the input, Djxf (xi). In other words, instead of the typical training set consisting of pairs {(xi, f (xi)))} Ni = 1, we have access to (K + 2) tuples {(xi, f (xi), D1xf (xi),..., DKx f (xi))} Ni = 1. In this situation, the derivative information can easily flow into the formation of a neural network model of f by deriving derivatives of the neural network with those of f."}, {"heading": "3 Theory and motivation", "text": "In this section we show that neural networks with non-constant, continuous activation functions, with continuous derivatives up to order K are universal approximators in the Sobolev spaces, which show that sigmoid networks are actually able to arbitrarily approximate elements of these spaces well. Nevertheless, we often use activation functions such as ReLU, which do not yet have continuous derivatives."}, {"heading": "4 Experimental Results", "text": "We look at three areas where information on derivatives is available during the training1."}, {"heading": "4.1 Artificial Data", "text": "First, we consider the task of regression on a number of well-known low-dimensional functions used for benchmarking optimization methods.We train two hidden neural layer networks with 256 hidden units per layer with ReLU activations to go back to functional values, and check generalization capabilities by evaluating the mean square error on a hold-out test.Since the task is a standard regression, we select all losses of the Sobolev training as L2 errors and use a first-order Sobolev method (derivatives of second-order ReLU networks with a linear output layer are constant, zero).The optimization is therefore: Min."}, {"heading": "4.2 Distillation", "text": "In practice, it is often the case that there is a deviation from the expected divergence between the individual measures, for example the Kullback-Leibler divergence DKL (s) collected across states, while the policy applies multivariate functions, the direct application of Sobolev training would mean that full Jacobian matrices are compatible with the large margins of action. < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "4.3 Synthetic Gradients", "text": "Previous experiments have shown how information about the derivatives can increase approximate functional values. However, the basic idea of Sobolev formation is more diversified and can be used in both directions. So, if you ultimately take care of approximate derivatives, then additional approximate values can also help in this process. A newer technique that requires a model of the gradients is Synthetic Gradient Planning (SG). The principle behind SG is that instead of performing complete reverse propagation with the help of the chain rule, one splits a network into two (or more) parts, and partial derivatives of the loss L are activated in relation to some hidden layers."}, {"heading": "5 Discussion and Conclusion", "text": "In this paper, we introduced Sobolev Training for Neural Networks - a simple and effective method of integrating knowledge about derivatives of a target function into the training of an approximator for neural network functions. We have theoretically argued that coding both the value of a target function and its derivatives within a ReLU neural network is possible and that this leads to more efficient learning. Furthermore, we show that our proposal can be efficiently trained using stochastic approximations when encountering computer-expensive Jacobians or Hessians. In addition to toy experiments that confirm our theoretical claims, we have conducted experiments to highlight two very promising areas of application for such models: one is the distillation / compression of models; the other is the application to various meta-optimization techniques that build models of other models, dynamics (such as synthetic gradients, learning-to-learning, etc.)."}, {"heading": "1 Proofs", "text": "Theoretically, f is a C1 function on a compact set. Then, for each positive surface, there is a single hidden neural network with a ReLU (or leaky surface), the f in a compact space S1 up to an error. We will start with a definition. We will say that a function p on a specified field D is piecewise-linear if there is a finite surface D1. Let D be a compact subset R and let it be C1 (D). Then, for each face, there is a linear surface i = 1. (Note that we assume a finite surface in the definition) Lemma 1. Let D be a compact surface of R and let each face C1 (D). Then, for each face > 0, there is a piecewiselinear, continuous surface p: D \u2192 R such a surface (x)."}, {"heading": "2 Artificial Datasets", "text": "The functions used (shown in Figures 5-11): \u2022 Ackleys f (x, y) = \u2212 20 exp (\u2212 0.2 \u221a 0.5 (x2 + y2)) \u2212 exp (0.5 (cos (2\u03c0x) + cos (2\u03c0y))) + e + 20, for x, y (\u2212 5, 5] \u00b7 Beale'sf (x, y) = (1.5 \u2212 x + xy) 2 + (2.25 \u2212 x + xy2) 2 + (2.625 \u2212 x + xy3) 2, for x, y (\u2212 4.5, 4.5] \u00b7 [\u2212 4.5, 4.5] \u00b7 Beale'sf (x, y) = (x, y) 2 + (2 + 2y \u2212 7) 2 + (2x + y \u2212 5) 2, x, y (5, y, x, y, 5, y, y, y, y, y)."}, {"heading": "3 Policy Distillation", "text": "The strategies of the agents consist of: \u2022 32 8x8 cores with step velocity 4 \u2022 ReLU nonlinearity \u2022 64 4x4 cores with step velocity 2 \u2022 ReLU nonlinearity \u2022 64 3x3 cores with step velocity 1 \u2022 ReLU nonlinearity \u2022 Linear layer with 512 units \u2022 ReLU nonlinearity \u2022 Linear layer with 3 (pong), 4 (breakout) or 6 outputs (space invaders) \u2022 SoftmaxYou were trained with A3C [15] in 80e6 steps using the history of length 4, grayscale input and repetition of action 4. Observations were scaled down to 84x84 pixels. Data was collected through targeted measures to collect 100K frames (i.e. for 400K actual steps). Divided into trains and test sets, work was done at times to ensure that the test frames originated from different episodes as the training itself consists of step network (i.e. 400K with actual step velocity 8x8)."}, {"heading": "4 Synthetic Gradients", "text": "All models have been trained with multi-GPU optimization, with main sync network updates and Hogwild SG module updates."}, {"heading": "4.1 Meaning of Sobolev losses for synthetic gradients", "text": "In the environment under consideration, the true label y is used only as conditioning, but it could also be monitored for \u2202 m (h, y | \u03b8) / \u2202 y. What actual effect do these Sobolev losses have on the SG estimator? Since L is a protocol loss, it is easy to prove that these are additional penalties for matching the protocol p (h, y) to the pH value, namely: 0 x x x x m (h, y) / x y-value L (h, y) / x 2 = x log p (h, y) \u2212 l (h, y) x 2 = (log p (h | \u03b8) y \u2212 log phy) 2, where y is the index of \"1\" in the uniformly coded label vector y. Consequently, the loss monitoring ensures that the internal prediction protocol p (h | IS) for the true label y is close to the current prediction of the entire model."}, {"heading": "4.2 Cifar10", "text": "All Cifar10 experiments use a deep convolutionary network with the following structure: \u2022 64 3x3 cores with step 1 \u2022 BatchNorm and ReLU nonlinearity \u2022 64 3x3 cores with step 1 \u2022 BatchNorm and ReLU nonlinearity \u2022 128 3x3 cores with step 2 \u2022 BatchNorm and ReLU nonlinearity \u2022 128 3x3 cores with step 1 \u2022 BatchNorm and ReLU nonlinearity \u2022 256 3x3 cores with step 1 \u2022 BatchNorm and ReLU nonlinearity \u2022 256 3x3 cores with step 2 \u2022 BatchNorm and ReLU nonlinearity \u2022 128 3x3 cores with step 2 \u2022 BatchNorm and ReLLU nonlinearity."}, {"heading": "4.3 Imagenet", "text": "All ImageNet experiments use ResNet50 network with L2 regularization of 1e \u2212 4. The network is trained asynchronously, using 34 GPUs in parallel. Each worker uses a batch size of 32. The most important optimizer is Stochastic Gradient Descent with a pulse of 0.9. The learning rate is initialized to 0.1 and then dropped by an order of magnitude after 100K, 150K and finally after 175K updates.The SG module is a revolutionary network that is attached after the second ResNet block, consisting of: \u2022 64 3x3 cores with increment 1 \u2022 ReLU nonlinearity \u2022 64 3x3 cores with increment 2 \u2022 ReLU nonlinearity \u2022 Worldwide average \u2022 1000 1x1 cores \u2022 SoftmaxIt is trained with the Adam optimizer with learning speed 1e \u2212 4, no learning rate plan is applied. Updates of the synthetic gradient module are performed willy in the manipulator."}], "references": [{"title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems", "author": ["Mart\u00edn Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"], "venue": "arXiv preprint arXiv:1603.04467,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Jia Deng", "Wei Dong", "Richard Socher", "Li-Jia Li", "Kai Li", "Li Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "On learning the derivatives of an unknown mapping with multilayer feedforward networks", "author": ["A Ronald Gallant", "Halbert White"], "venue": "Neural Networks,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1992}, {"title": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "author": ["Song Han", "Huizi Mao", "William J Dally"], "venue": "arXiv preprint arXiv:1510.00149,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Distilling the knowledge in a neural network", "author": ["Geoffrey Hinton", "Oriol Vinyals", "Jeff Dean"], "venue": "arXiv preprint arXiv:1503.02531,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Approximation capabilities of multilayer feedforward networks", "author": ["Kurt Hornik"], "venue": "Neural networks,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1991}, {"title": "Estimation of non-normalized statistical models using score matching", "author": ["Aapo Hyv\u00e4rinen"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Decoupled neural interfaces using synthetic gradients", "author": ["Max Jaderberg", "Wojciech Marian Czarnecki", "Simon Osindero", "Oriol Vinyals", "Alex Graves", "Koray Kavukcuoglu"], "venue": "arXiv preprint arXiv:1608.05343,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Actor-critic algorithms", "author": ["Vijay R Konda", "John N Tsitsiklis"], "venue": "In NIPS,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "Handbook of complex variables", "author": ["Steven G Krantz"], "venue": "Springer Science & Business Media,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Neural networks for control", "author": ["W Thomas Miller", "Paul J Werbos", "Richard S Sutton"], "venue": "MIT press,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1995}, {"title": "Synthetic gradient methods with virtual forward-backward networks", "author": ["Takeru Miyato", "Daisuke Okanohara", "Shin-ichi Maeda", "Koyama Masanori"], "venue": "ICLR workshop proceedings,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "Asynchronous methods for deep reinforcement learning", "author": ["Volodymyr Mnih", "Adria Puigdomenech Badia", "Mehdi Mirza", "Alex Graves", "Timothy Lillicrap", "Tim Harley", "David Silver", "Koray Kavukcuoglu"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Playing atari with deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Alex Graves", "Ioannis Antonoglou", "Daan Wierstra", "Martin Riedmiller"], "venue": "arXiv preprint arXiv:1312.5602,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Revisiting natural gradient for deep networks", "author": ["Razvan Pascanu", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1301.3584,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Higher order contractive auto-encoder", "author": ["Salah Rifai", "Gr\u00e9goire Mesnil", "Pascal Vincent", "Xavier Muller", "Yoshua Bengio", "Yann Dauphin", "Xavier Glorot"], "venue": "Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Policy distillation", "author": ["Andrei A Rusu", "Sergio Gomez Colmenarejo", "Caglar Gulcehre", "Guillaume Desjardins", "James Kirkpatrick", "Razvan Pascanu", "Volodymyr Mnih", "Koray Kavukcuoglu", "Raia Hadsell"], "venue": "arXiv preprint arXiv:1511.06295,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Deep model compression: Distilling knowledge from noisy teachers", "author": ["Bharat Bhusan Sau", "Vineeth N Balasubramanian"], "venue": "arXiv preprint arXiv:1610.09650,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": "search. Nature,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Tangent prop-a formalism for specifying selected invariances in an adaptive network", "author": ["Patrice Simard", "Bernard Victorri", "Yann LeCun", "John S Denker"], "venue": "In NIPS,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1991}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Wavenet: A generative model for raw audio", "author": ["A\u00e4ron van den Oord", "Sander Dieleman", "Heiga Zen", "Karen Simonyan", "Oriol Vinyals", "Alex Graves", "Nal Kalchbrenner", "Andrew Senior", "Koray Kavukcuoglu"], "venue": "CoRR abs/1609.03499,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "A connection between score matching and denoising autoencoders", "author": ["Pascal Vincent"], "venue": "Neural computation,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Approximate dynamic programming for real-time control and neural modeling", "author": ["Paul J Werbos"], "venue": "Handbook of intelligent control,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1992}], "referenceMentions": [{"referenceID": 4, "context": "They are consistently proven to be powerful function approximators, able to model a wide variety of functional forms \u2013 from image recognition [6, 23], through audio synthesis [24], to human-beating policies in the ancient game of GO [21].", "startOffset": 142, "endOffset": 149}, {"referenceID": 21, "context": "They are consistently proven to be powerful function approximators, able to model a wide variety of functional forms \u2013 from image recognition [6, 23], through audio synthesis [24], to human-beating policies in the ancient game of GO [21].", "startOffset": 142, "endOffset": 149}, {"referenceID": 22, "context": "They are consistently proven to be powerful function approximators, able to model a wide variety of functional forms \u2013 from image recognition [6, 23], through audio synthesis [24], to human-beating policies in the ancient game of GO [21].", "startOffset": 175, "endOffset": 179}, {"referenceID": 19, "context": "They are consistently proven to be powerful function approximators, able to model a wide variety of functional forms \u2013 from image recognition [6, 23], through audio synthesis [24], to human-beating policies in the ancient game of GO [21].", "startOffset": 233, "endOffset": 237}, {"referenceID": 5, "context": "A common example is when the ground truth function is itself a neural network; for instance this is the case for distillation [7, 19], compressing neural networks [5], and the prediction of synthetic gradients [10].", "startOffset": 126, "endOffset": 133}, {"referenceID": 17, "context": "A common example is when the ground truth function is itself a neural network; for instance this is the case for distillation [7, 19], compressing neural networks [5], and the prediction of synthetic gradients [10].", "startOffset": 126, "endOffset": 133}, {"referenceID": 3, "context": "A common example is when the ground truth function is itself a neural network; for instance this is the case for distillation [7, 19], compressing neural networks [5], and the prediction of synthetic gradients [10].", "startOffset": 163, "endOffset": 166}, {"referenceID": 8, "context": "A common example is when the ground truth function is itself a neural network; for instance this is the case for distillation [7, 19], compressing neural networks [5], and the prediction of synthetic gradients [10].", "startOffset": 210, "endOffset": 214}, {"referenceID": 6, "context": "The approach is inspired by the work of Hornik [8] which proved the universal approximation theorems for neural networks in Sobolev spaces \u2013 metric spaces where distances between functions are defined both in terms of their differences in values and differences in values of their derivatives.", "startOffset": 47, "endOffset": 50}, {"referenceID": 16, "context": "by pushing Jacobian norm to 0 [18]), or to encode additional, hand crafted invariances to some transformations (for instance, as in Tangentprop [22]), or estimated derivatives for dynamical systems [4].", "startOffset": 30, "endOffset": 34}, {"referenceID": 20, "context": "by pushing Jacobian norm to 0 [18]), or to encode additional, hand crafted invariances to some transformations (for instance, as in Tangentprop [22]), or estimated derivatives for dynamical systems [4].", "startOffset": 144, "endOffset": 148}, {"referenceID": 2, "context": "by pushing Jacobian norm to 0 [18]), or to encode additional, hand crafted invariances to some transformations (for instance, as in Tangentprop [22]), or estimated derivatives for dynamical systems [4].", "startOffset": 198, "endOffset": 201}, {"referenceID": 24, "context": "Similar techniques have also been used in critic based Reinforcement Learning (RL), where a critic\u2019s derivatives are trained to match its target\u2019s derivatives [26, 13] using shallow, sigmoid based models.", "startOffset": 159, "endOffset": 167}, {"referenceID": 11, "context": "Similar techniques have also been used in critic based Reinforcement Learning (RL), where a critic\u2019s derivatives are trained to match its target\u2019s derivatives [26, 13] using shallow, sigmoid based models.", "startOffset": 159, "endOffset": 167}, {"referenceID": 7, "context": "Finally, Hyv\u00e4rinen proposed Score Matching Networks [9], which are based on the somewhat surprising observation that one can model unknown derivatives of the function without actual access to its values \u2013 all that is needed is a sampling based strategy and specific penalty.", "startOffset": 52, "endOffset": 55}, {"referenceID": 23, "context": "However, such an estimator has a high variance [25], thus it is not really useful when true derivatives are given.", "startOffset": 47, "endOffset": 51}, {"referenceID": 6, "context": "(2): We look formally at the implications of matching derivatives, extending previous results of Hornik [8] and showing that modern architectures are well suited for such training regimes.", "startOffset": 104, "endOffset": 107}, {"referenceID": 16, "context": "To avoid adding computational complexity to the training process, one can use an efficient, stochastic version of Sobolev Training: instead of computing a full Jacobian/Hessian, one just computes its projection onto a random vector (a direct application of a known estimation trick [18]).", "startOffset": 282, "endOffset": 286}, {"referenceID": 6, "context": "Hornik showed [8] that neural networks with non-constant, bounded, continuous activation functions, with continuous derivatives up to order K are universal approximators in the Sobolev spaces of order K, thus showing that sigmoid-networks are indeed capable of approximating elements of these spaces arbitrarily well.", "startOffset": 14, "endOffset": 17}, {"referenceID": 10, "context": "We will use a standard symbol C1(S) (or simply C1) to denote a space of functions which are continuous, differentiable, and have a continuous derivative on a space S [12].", "startOffset": 166, "endOffset": 170}, {"referenceID": 0, "context": "All experiments were performed using TensorFlow [1] and the Sonnet neural network library [2].", "startOffset": 48, "endOffset": 51}, {"referenceID": 18, "context": "This technique has many applications, such as network compression [20], ensemble merging [7], or more recently policy distillation in reinforcement learning [19].", "startOffset": 66, "endOffset": 70}, {"referenceID": 5, "context": "This technique has many applications, such as network compression [20], ensemble merging [7], or more recently policy distillation in reinforcement learning [19].", "startOffset": 89, "endOffset": 92}, {"referenceID": 17, "context": "This technique has many applications, such as network compression [20], ensemble merging [7], or more recently policy distillation in reinforcement learning [19].", "startOffset": 157, "endOffset": 161}, {"referenceID": 14, "context": "As target policies \u03c0\u2217, we use agents playing Atari games [16] that have been trained with A3C [15] on three well known games: Pong, Breakout and Space Invaders.", "startOffset": 57, "endOffset": 61}, {"referenceID": 13, "context": "As target policies \u03c0\u2217, we use agents playing Atari games [16] that have been trained with A3C [15] on three well known games: Pong, Breakout and Space Invaders.", "startOffset": 94, "endOffset": 98}, {"referenceID": 8, "context": "Noprop Direct SG [10] VFBN [14] Critic Sobolev CIFAR-10 with 3 synthetic gradient modules Top 1 (94.", "startOffset": 17, "endOffset": 21}, {"referenceID": 12, "context": "Noprop Direct SG [10] VFBN [14] Critic Sobolev CIFAR-10 with 3 synthetic gradient modules Top 1 (94.", "startOffset": 27, "endOffset": 31}, {"referenceID": 8, "context": "One recent technique, which requires a model of gradients is Synthetic Gradients (SG) [10] \u2013 a method for training complex neural networks in a decoupled, asynchronous fashion.", "startOffset": 86, "endOffset": 90}, {"referenceID": 9, "context": "This setting closely resembles what is known in reinforcement learning as critic methods [11].", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "Similarly if we do not provide supervision at the loss level, but only on the gradient component, we end up in a method that resembles VFBN [14].", "startOffset": 140, "endOffset": 144}, {"referenceID": 1, "context": "For ImageNet [3] experiments based on ResNet50 [6], we obtain qualitatively similar results.", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "For ImageNet [3] experiments based on ResNet50 [6], we obtain qualitatively similar results.", "startOffset": 47, "endOffset": 50}, {"referenceID": 15, "context": "For example curvature [17] is believed to be connected to uncertainty.", "startOffset": 22, "endOffset": 26}], "year": 2017, "abstractText": "At the heart of deep learning we aim to use neural networks as function approximators \u2013 training them to produce outputs from inputs in emulation of a ground truth function or data creation process. In many cases we only have access to input-output pairs from the ground truth, however it is becoming more common to have access to derivatives of the target output with respect to the input \u2013 for example when the ground truth function is itself a neural network such as in network compression or distillation. Generally these target derivatives are not computed, or are ignored. This paper introduces Sobolev Training for neural networks, which is a method for incorporating these target derivatives in addition the to target values while training. By optimising neural networks to not only approximate the function\u2019s outputs but also the function\u2019s derivatives we encode additional information about the target function within the parameters of the neural network. Thereby we can improve the quality of our predictors, as well as the data-efficiency and generalization capabilities of our learned function approximation. We provide theoretical justifications for such an approach as well as examples of empirical evidence on three distinct domains: regression on classical optimisation datasets, distilling policies of an agent playing Atari, and on large-scale applications of synthetic gradients. In all three domains the use of Sobolev Training, employing target derivatives in addition to target values, results in models with higher accuracy and stronger generalisation.", "creator": "LaTeX with hyperref package"}}}