{"id": "1706.05826", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jun-2017", "title": "Capacity Releasing Diffusion for Speed and Locality", "abstract": "Diffusions and related random walk procedures are of central importance in many areas of machine learning, data analysis, and applied mathematics. Because they spread mass agnostically at each step in an iterative manner, they can sometimes spread mass \"too aggressively,\" thereby failing to find the \"right\" clusters. We introduce a novel Capacity Releasing Diffusion (CRD) Process, which is both faster and stays more local than the classical spectral diffusion process. As an application, we use our CRD Process to develop an improved local algorithm for graph clustering. Our local graph clustering method can find local clusters in a model of clustering where one begins the CRD Process in a cluster whose vertices are connected better internally than externally by an $O(\\log^2 n)$ factor, where $n$ is the number of nodes in the cluster. Thus, our CRD Process is the first local graph clustering algorithm that is not subject to the well-known quadratic Cheeger barrier. Our result requires a certain smoothness condition, which we expect to be an artifact of our analysis. Our empirical evaluation demonstrates improved results, in particular for realistic social graphs where there are moderately good---but not very good---clusters.", "histories": [["v1", "Mon, 19 Jun 2017 08:18:04 GMT  (136kb,D)", "http://arxiv.org/abs/1706.05826v1", "ICML 2017"]], "COMMENTS": "ICML 2017", "reviews": [], "SUBJECTS": "cs.DS cs.AI cs.IR", "authors": ["di wang", "kimon fountoulakis", "monika henzinger", "michael w mahoney", "satish rao"], "accepted": true, "id": "1706.05826"}, "pdf": {"name": "1706.05826.pdf", "metadata": {"source": "META", "title": "Capacity Releasing Diffusion for Speed and Locality", "authors": ["Di Wang", "Kimon Fountoulakis", "Monika Henzinger", "Michael W. Mahoney", "Satish Rao"], "emails": ["<wangd@eecs.berkeley.edu>."], "sections": [{"heading": "1. Introduction", "text": "This year, it has come to the point where it can only take a few days to get a result."}, {"heading": "1.1. Capacity Releasing Diffusion (CRD)", "text": "We begin by describing the generic CRD process in Figures 1 and 2, which specifies the dynamics of mass distribution across the graph. It is important that this dynamic process is independent of a specific task to which it can be applied. Later (in Section 2), we also present a concrete CRD algorithm for the specific task of local clustering that takes advantage of the dynamics of the generic CRD process. The entire CRD process (Figure 1) repeats the generic CRD internal process (which we call a CRD step), and then doubles the mass at all vertebrae points between calls. A CRD step begins with each vertex u having a mass m (u) \u2264 2d (u), where d (u) is the degree of u, and distributes the mass so that at the end of each vertex u has a mass m (u)."}, {"heading": "1.2. Example: Classical Versus Capacity Releasing", "text": "To see the differences between the classical spectral diffusions and our CRD processes, one has to look at the graph in Figure 3. There is a \"cluster\" B consisting of k paths, each of which is connected to a common node. There is an edge from u to the rest of the graph, and we assume that the vast majority of the mass that arrives there is absorbed by its neighbors in B."}, {"heading": "1.3. Our Main Results", "text": "We provide theoretical and empirical evidence that our CRD algorithm is superior to classical diffusion methods in cluster search, in terms of noise tolerance, restoration accuracy, conductivity, and runtime. Here is the way in which we show the edges between S, S, and the volume vol (S), the sum of the degrees of wells in S. In all of these measures, we break the square barrier to classical diffusion (explained below) while presenting a local algorithm (i.e. an algorithm whose runtime depends on the volume of the cluster and not the entire graph).Our first main result (Section 2) presents a CRD algorithm and its runtime."}, {"heading": "1.4. Previous Work: Low Conductance Cuts, Diffusions, and Multicommodity Flow", "text": "The second eigenvector for G can be used to find an intersection of conductivity ideas. (Cheeger, 1969; Donath & Hoffman, 1973) Let's observe the minimal conductivity in the graph. (Donath & Hoffman, 1973) Let's observe the minimal conductivity in the graph. Cheeger already observed that random diffusion can cause diffusion. (Cheeger, 1969; Donath & Hoffman, 1973) Let's observe the minimum conductivity in the graph."}, {"heading": "2. Capacity Releasing Diffusion", "text": "In this section, we describe our algorithm, which implements a specific version of the generic CRD process. In particular, for efficiency reasons, it makes some changes and terminates the diffusion if it detects a bottleneck during the process. The algorithm iteratively calls a subroutine CRD-inner, which implements a CRD step.For efficiency reasons, CRD-inner does not necessarily perform a complete CRD step, where a complete CRD step means that each node u at termination has at most d (u) mass. Specifically, CRD-inner only makes a certain \"effort\" (matched by a parameter \u03c6) to distribute the mass, and if there is a bottleneck in the form of a cut that requires \"too much effort\" for the diffusion to pass, then CRDinner can leave excess mass on the node, i.e. m (v) > d (v) at termination, guaranteeing that a CRD does not pass through such a step."}, {"heading": "2.1. CRD Algorithm", "text": "Given a start node vs, the CRD algorithm (algorithm 1) is essentially the CRD process that starts from vs, as shown in Figure 1. The algorithm takes as input a parameter \u03c6 that is used to tune CRD-inner. Since CRDinner may be nearing a full CRD step, we remove any excess mass that remains after calling CRD-inner. Due to the excess degradation, we can discard mass as the algorithm progresses. In particular, if we start with 2d (vs) mass and double the amount after each CRD step, the amount of mass after the j-th doubling is either 2d (vs) \u00b7 2j if we never remove excess mass. If the actual mass is significantly smaller than 2d (vs) \u00b7 2j, there must be a bottleneck (K, K) during the last CRD step."}, {"heading": "2.2. CRD Inner Procedure", "text": "We will now discuss the CRD internal subroutine (algorithm 2), which aims to perform a CRD step (v > Q). Specifically, each node v has m (v) \u2264 2d (v) mass at the beginning, and CRD internal attempts to spread the mass so that each node v (v) \u2264 d (v) mass at the end. Not surprisingly, since the CRD step draws an intuition from each edge, we can consider each edge a modification of the classic push-relabel algorithm. As described in Figure 2, we maintain a label l (v) for each CRD step, and the net mass is pushed along each edge. Although the graph is undirected, we consider each edge e = {u} as two directed arcs (u, v) and (v, u), and we use m (u, v) to denote the net mass from u to v (during the current internal CRD invasion)."}, {"heading": "3. Local Graph Clustering", "text": "In this section, we provide theoretical evidence that the CRD algorithm can identify a good local cluster in a large diagram if there is one around the start node. We define a fixed conductivity, \u03c6S (B) (or internal connectivity) of a fixed B-V node is the minimum conductivity of any node within the induced subgraph on B.Informal, for a \"good\" cluster B, an inner bottleneck should have a greater conductivity than \u03c6 (B), and nodes in B should be more connected to other nodes within B than to nodes outside. We formally grasp intuition as follows. Assumption 1. \u03c31 def = illose (B) is a greater conductivity than \u03c6 (B). Assumption 2 exists as 2 (1), so that any T-B with volB (B)."}, {"heading": "4. Empirical Illustration", "text": "We compared the performance of the CRD algorithm (algorithm 1), which depends on the entire bandwidth of the volume, that is, the way we move, and the way we move. Considering that we have a start node and a teleportation probability, ACL is a local algorithm that calculates an approximate personalized PageRank vector, which is then used to identify the local structure by means of a sweep cut. FlowImp is a flow-based algorithm that takes a series of reference nodes as a starting point and calculates a cluster around the specified reference value. This is because while FlowImp needs a very good reference set to give meaningful results in our setting, it can be used as a \"clean up.\""}, {"heading": "Acknowledgements", "text": "SR and DW are supported by the National Science Foundation under the funding programmes CCF-1528174 and CCF-1535989. MM and KF would like to thank the Army Research Office and the Defense Advanced Research Projects Agency for their partial support of this work. MH was funded by the European Research Council under the Seventh Framework Programme of the European Union (FP / 20072013) / ERC Grant Agreement No. 340506."}, {"heading": "A. CRD Inner Procedure", "text": "We first fill in the missing details in the CRD internal subroutine (algorithm 3). (u > Q = 1. Q = 1. Q = 1. Q = 1. V > v (v, u) must remain unfit until the next relief of v, so we only have to check each arc from v once between the successive relays. (u) We use current (v) to track the traces of the arcs from v that we have verified since the last relay from v. (u) We always select an active vertex v with the lowest label. (u) We then know for each allowed arc (v, u) that we can move at least 1 along (v, u). (u) We always select an active vertex v with the lowest label. (u) This is crucial to keep the Q list in undecreasing order of the labels, for the efficient search for the lowest label. \""}, {"heading": "B. Local Clustering", "text": "We assume that B will meet the following conditions.Assumption 1: \"We assume that this unit is once B.\" Assumption 1: \"We assume that B will meet the following conditions.Assumption 1:\" We assume that there is a unit of B. \"Assumption 2:\" We assume that B will meet the following conditions.Assumption 1: \"We assume that we are a unit of B.\" Assumption 2: \"We assume that B is the total sum of mass in B.\" Assumption 2: \"We assume that B will be the total sum of mass in B.\" Assumption 2: \"We assume that the total sum of mass in B.\" \"We assume that the sum of mass in B.\" We assume that Mj is the total sum of mass in B. \""}, {"heading": "C. Empirical Set-up and Results", "text": "The actual IDs of the graphs in the Facebook100 Dataset are each larger than the actual metrics we used for our social networks on a given day in September 2005. The graphs are not weighted and represent \"friendships.\" The data form a subset of the Facebook100 Datasets (Traud et al., 2012). We chose these 4 graphs out of 100 due to their large sorting capability in the first column of Table A.2 in (Traud al., 2012), where the data was first introduced and analyzed. Each graph in the Facebook Datasets is shown with 6 characteristics, i.e., the second large high school, gender."}], "references": [{"title": "Non-backtracking random walks mix faster", "author": ["Alon", "Noga", "Benjamini", "Itai", "Lubetzky", "Eyal", "Sodin", "Sasha"], "venue": "Communications in Contemporary Mathematics,", "citeRegEx": "Alon et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Alon et al\\.", "year": 2007}, {"title": "An algorithm for improving graph partitions", "author": ["R. Andersen", "K. Lang"], "venue": "SODA", "citeRegEx": "Andersen and Lang,? \\Q2008\\E", "shortCiteRegEx": "Andersen and Lang", "year": 2008}, {"title": "Finding sparse cuts locally using evolving sets", "author": ["Andersen", "Reid", "Peres", "Yuval"], "venue": "STOC", "citeRegEx": "Andersen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Andersen et al\\.", "year": 2009}, {"title": "Local graph partitioning using PageRank vectors", "author": ["Andersen", "Reid", "Chung", "Fan", "Lang", "Kevin"], "venue": "FOCS", "citeRegEx": "Andersen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Andersen et al\\.", "year": 2006}, {"title": "Expander flows, geometric embeddings and graph partitioning", "author": ["Arora", "Sanjeev", "Rao", "Satish", "Vazirani", "Umesh"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Arora et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2009}, {"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["M. Belkin", "P. Niyogi"], "venue": "Neural Computation,", "citeRegEx": "Belkin and Niyogi,? \\Q2003\\E", "shortCiteRegEx": "Belkin and Niyogi", "year": 2003}, {"title": "A lower bound for the smallest eigenvalue of the Laplacian", "author": ["Cheeger", "Jeff"], "venue": "In Proceedings of the Princeton conference in honor of Professor S. Bochner,", "citeRegEx": "Cheeger and Jeff.,? \\Q1969\\E", "shortCiteRegEx": "Cheeger and Jeff.", "year": 1969}, {"title": "Lower bounds for the partitioning of graphs", "author": ["Donath", "William E", "Hoffman", "Alan J"], "venue": "IBM Journal of Research and Development,", "citeRegEx": "Donath et al\\.,? \\Q1973\\E", "shortCiteRegEx": "Donath et al\\.", "year": 1973}, {"title": "PageRank beyond the web", "author": ["D.F. Gleich"], "venue": "SIAM Review,", "citeRegEx": "Gleich,? \\Q2015\\E", "shortCiteRegEx": "Gleich", "year": 2015}, {"title": "A new approach to the maximum-flow problem", "author": ["Goldberg", "Andrew V", "Tarjan", "Robert E"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Goldberg et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 1988}, {"title": "Efficient maximum flow algorithms", "author": ["Goldberg", "Andrew V", "Tarjan", "Robert Endre"], "venue": "Commun. ACM,", "citeRegEx": "Goldberg et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2014}, {"title": "On the quality of spectral separators", "author": ["S. Guattery", "G.L. Miller"], "venue": "SIAM Journal on Matrix Analysis and Applications,", "citeRegEx": "Guattery and Miller,? \\Q1998\\E", "shortCiteRegEx": "Guattery and Miller", "year": 1998}, {"title": "Scaling personalized web search", "author": ["Jeh", "Glen", "Widom", "Jennifer"], "venue": "In Proceedings of the 12th international conference on World Wide Web,", "citeRegEx": "Jeh et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Jeh et al\\.", "year": 2003}, {"title": "Think locally, act locally: Detection of small, medium-sized, and large communities in large networks", "author": ["L.G.S. Jeub", "P. Balachandran", "M.A. Porter", "P.J. Mucha", "M.W. Mahoney"], "venue": "Physical Review E,", "citeRegEx": "Jeub et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jeub et al\\.", "year": 2015}, {"title": "An approximate maxflow min-cut theorem for uniform multicommodity flow problems with applications to approximation algorithms", "author": ["Leighton", "Tom", "Rao", "Satish"], "venue": "In FOCS,", "citeRegEx": "Leighton et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Leighton et al\\.", "year": 1988}, {"title": "Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters", "author": ["J. Leskovec", "K.J. Lang", "A. Dasgupta", "M.W. Mahoney"], "venue": "Internet Mathematics,", "citeRegEx": "Leskovec et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2009}, {"title": "A local spectral method for graphs: with applications to improving graph partitions and exploring data graphs locally", "author": ["M.W. Mahoney", "L. Orecchia", "N.K. Vishnoi"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Mahoney et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mahoney et al\\.", "year": 2012}, {"title": "On spectral clustering: Analysis and an algorithm", "author": ["A.Y. Ng", "M.I. Jordan", "Y. Weiss"], "venue": "Proceedings of the 15th Annual Conference on Advances in Neural Information Processing Systems,", "citeRegEx": "Ng et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Ng et al\\.", "year": 2001}, {"title": "Approximating the exponential, the Lanczos method and an \u00d5(m)-time spectral algorithm for balanced separator", "author": ["Orecchia", "Lorenzo", "Sachdeva", "Sushant", "Vishnoi", "Nisheeth K"], "venue": null, "citeRegEx": "Orecchia et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Orecchia et al\\.", "year": 2012}, {"title": "The pagerank citation ranking: Bringing order to the web", "author": ["Page", "Lawrence", "Brin", "Sergey", "Motwani", "Rajeev", "Winograd", "Terry"], "venue": "Technical report, Stanford InfoLab,", "citeRegEx": "Page et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Page et al\\.", "year": 1999}, {"title": "A spectral clustering approach", "author": ["S. White", "P. Smyth"], "venue": "bernetics,", "citeRegEx": "White and Smyth,? \\Q2006\\E", "shortCiteRegEx": "White and Smyth", "year": 2006}], "referenceMentions": [{"referenceID": 16, "context": ", 2015), so-called manifold learning (Belkin & Niyogi, 2003; Mahoney et al., 2012), and PageRank-based spectral", "startOffset": 37, "endOffset": 82}, {"referenceID": 19, "context": "ranking in web ranking (Page et al., 1999; Gleich, 2015).", "startOffset": 23, "endOffset": 56}, {"referenceID": 8, "context": "ranking in web ranking (Page et al., 1999; Gleich, 2015).", "startOffset": 23, "endOffset": 56}, {"referenceID": 3, "context": "Particularly relevant for our results are local/personalized versions of PageRank (Jeh & Widom, 2003) and local/distributed versions of spectral clustering (Spielman & Teng, 2004; Andersen et al., 2006; Andersen & Peres, 2009).", "startOffset": 156, "endOffset": 226}, {"referenceID": 15, "context": ", 2016); and they have been used to characterize the clustering and community structure in a wide range of social and information networks (Leskovec et al., 2009; Jeub et al., 2015).", "startOffset": 139, "endOffset": 181}, {"referenceID": 13, "context": ", 2016); and they have been used to characterize the clustering and community structure in a wide range of social and information networks (Leskovec et al., 2009; Jeub et al., 2015).", "startOffset": 139, "endOffset": 181}, {"referenceID": 15, "context": "In practice, this is seen by the extreme sensitivity of spectral methods to high-degree nodes and other structural heterogeneities in real-world graphs constructed from very noisy data (Leskovec et al., 2009; Jeub et al., 2015).", "startOffset": 185, "endOffset": 227}, {"referenceID": 13, "context": "In practice, this is seen by the extreme sensitivity of spectral methods to high-degree nodes and other structural heterogeneities in real-world graphs constructed from very noisy data (Leskovec et al., 2009; Jeub et al., 2015).", "startOffset": 185, "endOffset": 227}, {"referenceID": 13, "context": "Empirically, this is well-known to be a particular problem when there are moderately good\u2014but not very good\u2014clusters in the data, a situation that is all too common in machine learning and data analysis applications (Jeub et al., 2015).", "startOffset": 216, "endOffset": 235}, {"referenceID": 2, "context": "The relation between the generic CRD process and the CRD algorithm for local graph clustering is analogous to the relation between local random walks and a local spectral graph partitioning algorithm such as that of Andersen et al. (2006). The generic CRD inner process (Figure 2) implements a modification of the classic \u201cpush-relabel\u201d algorithm (Goldberg & Tarjan, 1988; 2014) for routing a source-sink flow.", "startOffset": 216, "endOffset": 239}, {"referenceID": 15, "context": "While idealized, such an example is not completely unrealistic (Leskovec et al., 2009; Jeub et al., 2015).", "startOffset": 63, "endOffset": 105}, {"referenceID": 13, "context": "While idealized, such an example is not completely unrealistic (Leskovec et al., 2009; Jeub et al., 2015).", "startOffset": 63, "endOffset": 105}, {"referenceID": 15, "context": "In particular, while graphs that have upward-sloping NCPs (Network Community Profiles) have good small clusters (Leskovec et al., 2009; Jeub et al., 2015), denser social networks with flat NCPs do not have any very-good conductance clusters of any size.", "startOffset": 112, "endOffset": 154}, {"referenceID": 13, "context": "In particular, while graphs that have upward-sloping NCPs (Network Community Profiles) have good small clusters (Leskovec et al., 2009; Jeub et al., 2015), denser social networks with flat NCPs do not have any very-good conductance clusters of any size.", "startOffset": 112, "endOffset": 154}, {"referenceID": 13, "context": "They do, however, often have moderately-good clusters, but these are very difficult for spectral methods to identify (Jeub et al., 2015).", "startOffset": 117, "endOffset": 136}, {"referenceID": 18, "context": ", Orecchia et al. (2012) for more details on this.", "startOffset": 2, "endOffset": 25}, {"referenceID": 0, "context": ", non-backtracking random walks (Alon et al., 2007).", "startOffset": 32, "endOffset": 51}, {"referenceID": 4, "context": "A semidefinite programming approach, which can be viewed as combining multicommodity flow and spectral methods, yields cuts of conductance O(\u03c6G \u221a log n) (Arora et al., 2009).", "startOffset": 153, "endOffset": 173}], "year": 2017, "abstractText": "Diffusions and related random walk procedures are of central importance in many areas of machine learning, data analysis, and applied mathematics. Because they spread mass agnostically at each step in an iterative manner, they can sometimes spread mass \u201ctoo aggressively,\u201d thereby failing to find the \u201cright\u201d clusters. We introduce a novel Capacity Releasing Diffusion (CRD) Process, which is both faster and stays more local than the classical spectral diffusion process. As an application, we use our CRD Process to develop an improved local algorithm for graph clustering. Our local graph clustering method can find local clusters in a model of clustering where one begins the CRD Process in a cluster whose vertices are connected better internally than externally by an O(log n) factor, where n is the number of nodes in the cluster. Thus, our CRD Process is the first local graph clustering algorithm that is not subject to the well-known quadratic Cheeger barrier. Our result requires a certain smoothness condition, which we expect to be an artifact of our analysis. Our empirical evaluation demonstrates improved results, in particular for realistic social graphs where there are moderately good\u2014but not very good\u2014clusters.", "creator": "LaTeX with hyperref package"}}}