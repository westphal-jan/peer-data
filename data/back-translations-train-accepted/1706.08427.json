{"id": "1706.08427", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jun-2017", "title": "Approximate Steepest Coordinate Descent", "abstract": "We propose a new selection rule for the coordinate selection in coordinate descent methods for huge-scale optimization. The efficiency of this novel scheme is provably better than the efficiency of uniformly random selection, and can reach the efficiency of steepest coordinate descent (SCD), enabling an acceleration of a factor of up to $n$, the number of coordinates. In many practical applications, our scheme can be implemented at no extra cost and computational efficiency very close to the faster uniform selection. Numerical experiments with Lasso and Ridge regression show promising improvements, in line with our theoretical guarantees.", "histories": [["v1", "Mon, 26 Jun 2017 15:07:02 GMT  (1061kb,D)", "http://arxiv.org/abs/1706.08427v1", "appearing at ICML 2017"]], "COMMENTS": "appearing at ICML 2017", "reviews": [], "SUBJECTS": "cs.LG math.OC", "authors": ["sebastian u stich", "anant raj", "martin jaggi"], "accepted": true, "id": "1706.08427"}, "pdf": {"name": "1706.08427.pdf", "metadata": {"source": "META", "title": "Approximate Steepest Coordinate Descent", "authors": ["Sebastian U. Stich", "Anant Raj", "Martin Jaggi"], "emails": ["<sebastian.stich@epfl.ch>."], "sections": [{"heading": "1. Introduction", "text": "This year, it has come to the point where it is able to retaliate, to retaliate."}, {"heading": "2. Steepest Coordinate Descent", "text": "In this section we present SCD and discuss its theoretical properties. The interesting functions are composite convex functions F: Rn \u2192 R of the formF (x): = f (x) + x (x) (2), where f is coordinatorily L-smooth and vice versa convex and divisible, i.e., a sequence is generated that fulfills the relation xt + 1 = xt \u2212 1L \u00b2 itf (x) eit. (3) In the UCD, the active coordinate is selected uniformly randomly from the set [n], it is then selected according to the Gauss-Southwell rule."}, {"heading": "2.1. Convergence analysis", "text": "With the top limit (1) it is easy to reach a lower limit on the upper acceleration level. (5) For UCD and SCD the expression is on the right side of the analysis (2) on the lower level (2). (5) With Cauchy Black we find the upper acceleration level (2). (6) With Cauchy Black we find the upper acceleration level (2). (6) The upper acceleration level (2). (6) The lower limit of the acceleration level (2). (6) The lower limit of the acceleration level (2). (6) The lower limit of the acceleration level (6). (8) The lower limit of the acceleration level (2). (7) The lower limit of the acceleration level (2). (6) The lower limit of the acceleration level (2)."}, {"heading": "2.2. Lower bounds", "text": "In the previous section, we made complexity estimates for the methods SCD and UCD and showed that SCD can converge faster than UCD up to a factor of dimension n. In this section, we show that this analysis is narrow. In Theorem 2.2 below, we specify a function q: Rn \u2192 R for which the one-step progress \u03c4SCD (xt) \u03c4UCD (xt) up to a constant factor for all iterates {xt} t \u2265 0 generated by SCD. With a simple technique, we can also construct functions for which the speedup is exactly the same as an arbitrary factor \u03bb [1, n]. For example, we can consider functions with a (divisible) low-dimensional structure. Fix \u2212 Integer s, n so that ns \u00b2 n define the function f: R n \u2192 R asf (x): = q (\u03b1 (x))))) (11), where lts is the projection to Rs (where the first s is from n coordinates) and q: s \u00b2 is the function that is generated."}, {"heading": "2.3. Composite Functions", "text": "The generalization of the GS rule (4) to composite problems (2) with a non-rival approach is not easy; the \"steepest\" direction does not always make sense in this constellation; consider, for example, a limited problem where this rule might not make any progress at all if stuck at the boundary. Nutini et al. (2015) discuss several generalizations of the Gauss-Southwell rule for composite functions. The GSs rule is defined in such a way that the coordinate with the most negative directional derivative is chosen (Wu & Lange, 2008). This rule is identical to (4), but requires the calculation of subgradations of the Gauss-Southwell rule. However, the length of a step may be arbitrarily small. In contrast, the GS-r rule was defined in such a way that it selects the coordinate direction that yields the longest step (Tseng & Yun, 2009). The rule that enjoys the best theoretical properties (glutini, 2015, Nvet al, is the GS-q rule)."}, {"heading": "2.4. The Complexity of the GS rule", "text": "So far we have only studied the iteration complexity of SCD, but we have ignored the fact that calculating the GS rule (4) can be as expensive as calculating the total gradient. Applying the coordinate descend methods is only justified if the complexity to calculate a direction derivative is approximately n times cheaper than calculating the complete gradient vector (cf.). According to Theorem 2.2, this reasoning also applies to SCD. A class of function with this property is given by the functions F: Rn \u2192 RF (x): = f (Ax) + n \u00b2 of the complete gradient vector calculation i (17), where A \u00b7 n is matrix, and where f: Rd \u2192 R, and i: Rn \u2192 R are convex and simple, that is the time complexity T for calculating their gradients linear."}, {"heading": "3. Algorithm", "text": "Is it possible to get the significantly improved convergence speed of SCD if one is only willing to pay the computational costs of only the much simpler UCD? In this section we give a formal definition of our proposed approximate SCD method, which we call ASCD. The basic idea of the algorithm is the following: While performing coordinate updates, ideally we would like to follow the development of all elements of the gradient efficiently, not just the one coordinate that is updated in the current step. Formal definition of the method is given in algorithm 1 for smooth objective functions. In each iteration, only one coordinate is modified according to some arbitrary update rule M. The coordinate update rule M offers two things: first, the new iterate xt + 1 and secondly, an estimate g of the it-th input of the gradient in the new iterate 3. Formally (xt + 1, g, r): = M (identical, itf (new) (new quality) is the same as the Iterate in the new one and the Iterate 18."}, {"heading": "3.1. Safe bounds for gradient evolution", "text": "It is as if a number of active coordination methods are involved, see e.g. Kim & Park (2008); Wen et al. (2012): A coordinate system j is excluded if the estimated progress in this direction (cf.) is lower than the average of the estimated progress along the coordination guidelines in E flat, [ut] 2j < 1 | It is [t] 2 i. The more active settings in E flat, [ut] 2j < 1."}, {"heading": "4. Approximate Gradient Update", "text": "In this section we argue that a large class of objective functions of machine learning, the change of course along each coordinate line (1), (1), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (3), (3), (3), (3, (3), (3), (3, (3), (3), (3), (3, (3), (3), (3), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2, (2), (2), (2), (2), (2, (2), (2), (2), (2), (2, (2), (2, (2), (2), (2), (2), (2, (2), (2), (2), (2), (2, (2), (2), (3, (2), (2), (3, (2), (2), (2), (3, (2), (2), (2), (2), (3, (3, (2), (3, (3, ("}, {"heading": "5. Extension to Composite Functions", "text": "The most important components of the ASCD are the coordinate-wise upper and lower limits of the gradient and the definition of the active group Es, which ensures that the steepest downward direction is always followed and that only bad directions are demonstrably removed from the active group. These ideas can also be generalized to the setting of composite functions (2). We already have some popular GS * update rules in the introduction to Section 2.3.Implementation of the ASCD for the GS rule is simple and we comment on the GS-r in the appendix in Sec. D.2. Here we illustrate the modification of the GS-q rule (16), which turns out to be the most advanced (the same reasoning applies to the GSL-q rule as well (Nutini et al., 2015). In Algo. 2 we show the construction - based on approximations of the smooth part f - of active group I. For this we calculate upper and lower limits, wv."}, {"heading": "6. Analysis of Competitive Ratio", "text": "In section 3 we deduce in Thm. 3.2 that the single-stage progress of ASCD lies between the limits of the onestep progress of UCD and SCD. However, we know that the efficiency of the latter two methods can vary greatly, up to a factor of n. In this section we will argue that in certain cases where SCD functions much better than UCD, ASCD will also be accelerated. To measure this effect, we can adapt ASCD to the GS-q rule [r] i [r] i: Gradient estimation of error limits r. For i [n] we define: compute u.-and l.-bounds [u] i: [g] i + [r] i: [r] i [u] i: = arg miny] i (x, y] i) minimize the model."}, {"heading": "6.1. Estimates of the competitive ratio", "text": "On the basis of this Thm. 6.1, we can now estimate the competitive ratio in various scenarios. On class (11), it holds c \u00b2 1, as we argued before. Therefore, the competitive ratio (28) depends only on T \u00b2. This quantity measures how many iterations a coordinate j / as] is on average outside the active set It. From the lower limit, we see that the competitive ratio approaches a constant for (t \u00b2 s) when T \u00b2 s reaches the active set again, when T \u00b2 5. As an approximation to the T \u00b2 instance, we estimate the quantities T \u00b2 t0 defined in Thm. 6.1. T \u00b2 t0 denotes the number of iterations it takes for the coordinate j to return to the active set, provided that it leaves the active set at iteration t0 \u2212 1. We estimate T \u00b2 t0 \u00b2 -T \u00b2, where T \u00b2 denotes the maximum number of iterations."}, {"heading": "7. Empirical Observations", "text": "It is not a question of whether or not it is a question of a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, and in which way it is about a way, in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and which it is about a way and in which it is about a way and in which it is about which it is about a way and which it is about a way and in which it is about which it is about a way and which it is about a way and which it is about a way and which it is about a way and which is about which it is about which it is about a way and which it is about which is about a way and which is about which is about which it is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which is about which"}, {"heading": "8. Concluding Remarks", "text": "We proposed ASCD, a novel active coordinate selection mechanism for CD methods. Our scheme has three favorable features: (i) its performance can reach the highest performing CD - both in theory and practice, (ii) the performance is never worse than a standard CD, (iii) in many important applications, the scheme can be implemented at no additional cost per iteration. ASCD computes the active record safely and randomly selects the active coordinate from this smaller set. It seems possible that an adaptive sampling strategy for the active record could further increase performance. At this point, we are only examining CD methods where a single coordinate is updated in each iteration. ASCD can be generalized immediately to block coordinate descend methods. However, the exact implementation in a distributed environment can be challenged. Finally, extending ASCD to stochastic gradient descend setting (not only heuristic, but with the same strong guarantees as in this essay) is an interesting direction."}, {"heading": "A. On Steepest Coordinate Descent", "text": "It is important to note that the lower limits shown in Equations (33) and (34) are almost attainable under special conditions."}, {"heading": "B. Approximate Gradient Update", "text": "In this section, we will use Lemma 4.1 (A) = 59 (A) = 61 (A) (A) (A) = 61 (A) = 61 (A) = 61 (A) (A): = 12 (A) \u2212 63 (A). In the fourth iteration, we select the coordinate to optimize it, and the update from xt + 1 to xt can be written as xt + 1 (X). Now, it is relatively easy for any other coordinate i (A) to calculate the change in the gradient of the other coordinates. We have already observed that [xt] j does not change, so the sub-gradient set of Java (axe) and Java (axe + 1) can be the same."}, {"heading": "C. Algorithm and Stability", "text": "The proof of theorem 6,1. Since we are interested in investigating the expected competitive ratio E [\u03c1t] for t \u00b2 s, we can proceed from a mixture and consider only the constant state. Let us define the number of indices in | It | which do not belong to the set [s]. Let us consider that an index j / s enters the active set. Equilibrium considerations result in the probability that an index i / s is taken from the active set (and removed from it), i.e. that an index j / s enters the active set. This results in (1 \u2212 \u03b1) the probability that an index j / s enters the group (n \u2212 s) (n \u2212 s) T \u00b2 (n \u2212 s) T \u00b2 s = 1 \u2212 \u00b2 c \u00b2 s (n \u2212 s)."}, {"heading": "D. GS rule for Composite Functions", "text": "D.1. GS-q ruleIn this section we show how ASCD can be implemented for the GS-q rule. (1) Define the modelVi coordinate mode (x, y, s): = sy + L2 (x, y) (68) The GS-q rule is defined as (cf.) Nutini et al. (2015) i = arg min i [n] min y (x, y) if (x, y) if (x))) (69) First, we show that the vectors v and w in algorithm 2 are valid upper and lower limits on the value of miny (x, y)."}, {"heading": "E. Experimental Details", "text": "We generate from the normal N (0, 1) distribution. m is fixed at 1000, but n is selected for the l2 regression with regulated smallest squares and 5000 for l1 regression. m is added to each entry (to cause a dependence between the columns), each column with a sample of N (0, 1) multiplied by ten (to induce different Lipschitz constants via coordinates), and only each entry of A non-zero with the probability of 10 log (n) n. This is exactly the same procedure discussed in (Nutini et al., 2015)."}], "references": [{"title": "Database-friendly random projections: Johnson-lindenstrauss with binary coins", "author": ["Achlioptas", "Dimitris"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Achlioptas and Dimitris.,? \\Q2003\\E", "shortCiteRegEx": "Achlioptas and Dimitris.", "year": 2003}, {"title": "Even faster accelerated coordinate descent using non-uniform sampling", "author": ["Z Allen-Zhu", "Z Qu", "P Richtarik", "Y. Yuan"], "venue": null, "citeRegEx": "Allen.Zhu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Allen.Zhu et al\\.", "year": 2016}, {"title": "Convex optimization", "author": ["Boyd", "Stephen P", "Vandenberghe", "Lieven"], "venue": null, "citeRegEx": "Boyd et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2004}, {"title": "Stochastic Dual Coordinate Ascent with Adaptive Probabilities", "author": ["Csiba", "Dominik", "Qu", "Zheng", "Richt\u00e1rik", "Peter"], "venue": "In ICML 2015 - Proceedings of the 32th International Conference on Machine Learning,", "citeRegEx": "Csiba et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Csiba et al\\.", "year": 2015}, {"title": "Siobhan\u2019s problem: The coupon collector revisited", "author": ["Dawkins", "Brian"], "venue": "The American Statistician,", "citeRegEx": "Dawkins and Brian.,? \\Q1991\\E", "shortCiteRegEx": "Dawkins and Brian.", "year": 1991}, {"title": "Nearest Neighbor based Greedy Coordinate Descent", "author": ["Dhillon", "Inderjit S", "Ravikumar", "Pradeep", "Tewari", "Ambuj"], "venue": "In NIPS 2014 - Advances in Neural Information Processing Systems", "citeRegEx": "Dhillon et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dhillon et al\\.", "year": 2011}, {"title": "Pathwise coordinate optimization", "author": ["Friedman", "Jerome", "Hastie", "Trevor", "H\u00f6fling", "Holger", "Tibshirani", "Robert"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "Friedman et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2007}, {"title": "Regularization Paths for Generalized Linear Models via Coordinate Descent", "author": ["Friedman", "Jerome", "Hastie", "Trevor", "Tibshirani", "Robert"], "venue": "Journal of Statistical Software,", "citeRegEx": "Friedman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2010}, {"title": "Penalized regressions: The bridge versus the lasso", "author": ["Fu", "Wenjiang J"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "Fu and J.,? \\Q1998\\E", "shortCiteRegEx": "Fu and J.", "year": 1998}, {"title": "A Dual Coordinate Descent Method for Large-scale Linear SVM", "author": ["Hsieh", "Cho-Jui", "Chang", "Kai-Wei", "Lin", "Chih-Jen", "Keerthi", "S Sathiya", "S. Sundararajan"], "venue": "In the 25th International Conference on Machine Learning,", "citeRegEx": "Hsieh et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hsieh et al\\.", "year": 2008}, {"title": "Nonnegative matrix factorization based on alternating nonnegativity constrained least squares and active set method", "author": ["Kim", "Hyunsoo", "Park", "Haesun"], "venue": "SIAM Journal on Matrix Analysis and Applications,", "citeRegEx": "Kim et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2008}, {"title": "Learning the parts of objects by non-negative matrix factorization", "author": ["Lee", "Daniel D", "Seung", "H Sebastian"], "venue": null, "citeRegEx": "Lee et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Lee et al\\.", "year": 1999}, {"title": "Rcv1: A new benchmark collection for text categorization research", "author": ["Lewis", "David D", "Yang", "Yiming", "Rose", "Tony G", "Li", "Fan"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Lewis et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lewis et al\\.", "year": 2004}, {"title": "On variants of the johnsonlindenstrauss lemma", "author": ["Matou\u0161ek", "Ji\u0159\u0131"], "venue": "Random Structures & Algorithms,", "citeRegEx": "Matou\u0161ek and Ji\u0159\u0131\u0301.,? \\Q2008\\E", "shortCiteRegEx": "Matou\u0161ek and Ji\u0159\u0131\u0301.", "year": 2008}, {"title": "Efficiency of coordinate descent methods on hugescale optimization problems", "author": ["Nesterov", "Yu"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nesterov and Yu.,? \\Q2012\\E", "shortCiteRegEx": "Nesterov and Yu.", "year": 2012}, {"title": "Efficiency of the accelerated coordinate descent method on structured optimization problems", "author": ["Nesterov", "Yurii", "Stich", "Sebastian U"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nesterov et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Nesterov et al\\.", "year": 2017}, {"title": "Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than Random Selection", "author": ["Nutini", "Julie", "Schmidt", "Mark W", "Laradji", "Issam H", "Friedlander", "Michael P", "Koepke", "Hoyt A"], "venue": "In ICML,", "citeRegEx": "Nutini et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nutini et al\\.", "year": 2015}, {"title": "Adaptive Sampling for Incremental Optimization Using Stochastic Gradient Descent", "author": ["Papa", "Guillaume", "Bianchi", "Pascal", "Cl\u00e9men\u00e7on", "St\u00e9phan"], "venue": "ALT 2015 - 26th International Conference on Algorithmic Learning Theory, pp", "citeRegEx": "Papa et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Papa et al\\.", "year": 2015}, {"title": "Coordinate descent with arbitrary sampling i: algorithms and complexity", "author": ["Qu", "Zheng", "Richt\u00e1rik", "Peter"], "venue": "Optimization Methods and Software,", "citeRegEx": "Qu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Qu et al\\.", "year": 2016}, {"title": "Parallel coordinate descent methods for big data optimization", "author": ["Richt\u00e1rik", "Peter", "Tak\u00e1\u010d", "Martin"], "venue": "Mathematical Programming,", "citeRegEx": "Richt\u00e1rik et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Richt\u00e1rik et al\\.", "year": 2016}, {"title": "Stochastic Methods for l1-regularized Loss Minimization", "author": ["Shalev-Shwartz", "Shai", "Tewari", "Ambuj"], "venue": "JMLR, 12:1865\u20131892,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2011}, {"title": "Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization", "author": ["Shalev-Shwartz", "Shai", "Zhang", "Tong"], "venue": "JMLR, 14:567\u2013599,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2013}, {"title": "Asymmetric LSH (ALSH) for sublinear time maximum inner product search (MIPS)", "author": ["Shrivastava", "Anshumali", "Li", "Ping"], "venue": "In NIPS 2014 - Advances in Neural Information Processing Systems", "citeRegEx": "Shrivastava et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shrivastava et al\\.", "year": 2014}, {"title": "A coordinate gradient descent method for nonsmooth separable minimization", "author": ["Tseng", "Paul", "Yun", "Sangwoon"], "venue": "Mathematical Programming,", "citeRegEx": "Tseng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Tseng et al\\.", "year": 2009}, {"title": "On the convergence of an active-set method for 1 minimization", "author": ["Wen", "Zaiwen", "Yin", "Wotao", "Zhang", "Hongchao", "Goldfarb", "Donald"], "venue": "Optimization Methods and Software,", "citeRegEx": "Wen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2012}, {"title": "Coordinate descent algorithms", "author": ["Wright", "Stephen J"], "venue": "Mathematical Programming,", "citeRegEx": "Wright and J.,? \\Q2015\\E", "shortCiteRegEx": "Wright and J.", "year": 2015}, {"title": "Coordinate descent algorithms for lasso penalized regression", "author": ["Wu", "Tong Tong", "Lange", "Kenneth"], "venue": "Ann. Appl. Stat.,", "citeRegEx": "Wu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2008}, {"title": "Stochastic optimization with importance sampling for regularized loss minimization", "author": ["Zhao", "Peilin", "Zhang", "Tong"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning,", "citeRegEx": "Zhao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 9, "context": "Due to their computational efficiency, scalability, as well as their ease of implementation, these methods are the state-of-theart for a wide selection of machine learning and signal processing applications (Fu, 1998; Hsieh et al., 2008; Wright, 2015).", "startOffset": 207, "endOffset": 251}, {"referenceID": 6, "context": "For instance in (Shalev-Shwartz & Zhang, 2013; Friedman et al., 2007; 2010; Shalev-Shwartz & Tewari, 2011) uniform sampling (UCD) is used, whereas other papers propose adaptive sampling strategies that change over time (Papa et al.", "startOffset": 16, "endOffset": 106}, {"referenceID": 17, "context": ", 2007; 2010; Shalev-Shwartz & Tewari, 2011) uniform sampling (UCD) is used, whereas other papers propose adaptive sampling strategies that change over time (Papa et al., 2015; Csiba et al., 2015; Osokin et al., 2016; Perekrestenko et al., 2017).", "startOffset": 157, "endOffset": 245}, {"referenceID": 3, "context": ", 2007; 2010; Shalev-Shwartz & Tewari, 2011) uniform sampling (UCD) is used, whereas other papers propose adaptive sampling strategies that change over time (Papa et al., 2015; Csiba et al., 2015; Osokin et al., 2016; Perekrestenko et al., 2017).", "startOffset": 157, "endOffset": 245}, {"referenceID": 16, "context": "For smooth functions this strategy yields always better progress than UCD, and the speedup can reach a factor of the dimension (Nutini et al., 2015).", "startOffset": 127, "endOffset": 148}, {"referenceID": 3, "context": ", 2015; Csiba et al., 2015; Osokin et al., 2016; Perekrestenko et al., 2017). A very simple deterministic strategy is to move along the direction corresponding to the component of the gradient with the maximal absolute value (steepest coordinate descent, SCD) (Boyd & Vandenberghe, 2004; Tseng & Yun, 2009). For smooth functions this strategy yields always better progress than UCD, and the speedup can reach a factor of the dimension (Nutini et al., 2015). However, SCD requires the computation of the whole gradient vector in each iteration which is prohibitive (except for special applications, cf. Dhillon et al. (2011); Shrivastava & Li (2014)).", "startOffset": 8, "endOffset": 624}, {"referenceID": 3, "context": ", 2015; Csiba et al., 2015; Osokin et al., 2016; Perekrestenko et al., 2017). A very simple deterministic strategy is to move along the direction corresponding to the component of the gradient with the maximal absolute value (steepest coordinate descent, SCD) (Boyd & Vandenberghe, 2004; Tseng & Yun, 2009). For smooth functions this strategy yields always better progress than UCD, and the speedup can reach a factor of the dimension (Nutini et al., 2015). However, SCD requires the computation of the whole gradient vector in each iteration which is prohibitive (except for special applications, cf. Dhillon et al. (2011); Shrivastava & Li (2014)).", "startOffset": 8, "endOffset": 649}, {"referenceID": 16, "context": "Nutini et al. (2015) present an elegant solution of this problem for \u03bc2-strongly convex functions2.", "startOffset": 0, "endOffset": 21}, {"referenceID": 16, "context": "We here extend the analysis from (Nutini et al., 2015) to smooth functions.", "startOffset": 33, "endOffset": 54}, {"referenceID": 24, "context": "Kim & Park (2008); Wen et al. (2012)).", "startOffset": 19, "endOffset": 37}, {"referenceID": 16, "context": "Here we exemplary detail the modification for the GS-q rule (16), which turns out to be the most evolved (the same reasoning also applies to the GSL-q rule from (Nutini et al., 2015)).", "startOffset": 161, "endOffset": 182}, {"referenceID": 16, "context": "For the synthetic data, we follow the same generation procedure as described in (Nutini et al., 2015), which generates very sparse data matrices.", "startOffset": 80, "endOffset": 101}, {"referenceID": 12, "context": "For real datasets, we perform the experimental evaluation on RCV1 (binary,training), which consists of 20, 242 samples, each of dimension 47, 236 (Lewis et al., 2004).", "startOffset": 146, "endOffset": 166}, {"referenceID": 16, "context": "For the l1-regularized problems, we used ASCD with the GS-s rule (the experiments in (Nutini et al., 2015) revealed almost identical performance of the different GS-\u2217 rules).", "startOffset": 85, "endOffset": 106}], "year": 2017, "abstractText": "We propose a new selection rule for the coordinate selection in coordinate descent methods for huge-scale optimization. The efficiency of this novel scheme is provably better than the efficiency of uniformly random selection, and can reach the efficiency of steepest coordinate descent (SCD), enabling an acceleration of a factor of up to n, the number of coordinates. In many practical applications, our scheme can be implemented at no extra cost and computational efficiency very close to the faster uniform selection. Numerical experiments with Lasso and Ridge regression show promising improvements, in line with our theoretical guarantees.", "creator": "LaTeX with hyperref package"}}}