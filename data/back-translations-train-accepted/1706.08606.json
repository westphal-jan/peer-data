{"id": "1706.08606", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jun-2017", "title": "Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study", "abstract": "Deep neural networks (DNNs) have advanced performance on a wide range of complex tasks, rapidly outpacing our understanding of the nature of their solutions. While past work sought to advance our understanding of these models, none has made use of the rich history of problem descriptions, theories, and experimental methods developed by cognitive psychologists to study the human mind. To explore the potential value of these tools, we chose a well-established analysis from developmental psychology that explains how children learn word labels for objects, and applied that analysis to DNNs. Using datasets of stimuli inspired by the original cognitive psychology experiments, we find that state-of-the-art one shot learning models trained on ImageNet exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color. The magnitude of this shape bias varies greatly among architecturally identical, but differently seeded models, and even fluctuates within seeds throughout training, despite nearly equivalent classification performance. These results demonstrate the capability of tools from cognitive psychology for exposing hidden computational properties of DNNs, while concurrently providing us with a computational model for human word learning.", "histories": [["v1", "Mon, 26 Jun 2017 21:31:18 GMT  (1552kb,D)", "http://arxiv.org/abs/1706.08606v1", "ICML 2017"], ["v2", "Thu, 29 Jun 2017 17:52:55 GMT  (1552kb,D)", "http://arxiv.org/abs/1706.08606v2", "ICML 2017"]], "COMMENTS": "ICML 2017", "reviews": [], "SUBJECTS": "stat.ML cs.CV cs.LG", "authors": ["samuel ritter", "david g t barrett", "adam santoro", "matt m botvinick"], "accepted": true, "id": "1706.08606"}, "pdf": {"name": "1706.08606.pdf", "metadata": {"source": "META", "title": "Cognitive Psychology for Deep Neural Networks:  A Shape Bias Case Study ", "authors": ["Samuel Ritter", "David G.T. Barrett", "Adam Santoro", "Matt M. Botvinick"], "emails": ["<ritters@google.com>,", "<barrett@google.com>."], "sections": [{"heading": "1. Introduction", "text": "Over the past half-decade, deep learning has significantly improved the performance of a variety of tasks (for a review, see LeCun et al. (2015). However, deep neural network solutions (DNN) are poorly understood, so many * equivalent papers 1DeepMind, London, UK. Correspondence to: Samuel Ritter < ritters @ google.com >, David G.T. Barrett < barrett @ google.com >.Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author (s).to think of these models as black boxes, and to question if they can be understood at all (Bornstein, 2016; Lipton, 2016). This opacity impedes both basic research that seeks to improve these models and applications of these models (Caruana et al., 2015).Recent pushes have aimed to better understand DNS functions and architectures."}, {"heading": "2. Inductive Biases, Statistical Learners and Probe Datasets", "text": "Before dealing with the particularities of form bias and one-sided word learning, we will describe our approach in the general context of inductive bias, probe datasets, and statistical learning. Suppose we have some data that we are able to understand. Our goal is to construct a model of data g (.) to optimize the functioning of a human being by measuring the gender-gender disparity (Kourou et al.), for example L as the medical history and vital metrics of a human being. Perhaps it is the case that images and history of tumors are classified as benign or malignant."}, {"heading": "3. The problem of word learning; the solution of inductive biases", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "4. One-shot word learning models and training", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. One-shot word learning task", "text": "The task of one-time word learning is to identify a novel data example x (e.g. a novel probe image) with a novel class name y (e.g. a new word) after a single example. Specifically, the one-time learning task consists of identifying the true labeling of the probe image y * from the labels of the support set {yi: i [1, k]}: y * = argmax yP (y | x, S), given a support set S = {(xi, yi): i [1, k]: y * = argmax yP (y | x, S). (1) We assume that the image labels yi are represented by a uniform coding and that P (y | x, S) is parameterized by a DNN, allowing us to use the ability of deep networks to learn powerful representations."}, {"heading": "4.2. Inception: baseline one-shot learning model", "text": "In our simplest single-line basic architecture, a probe image x (Vinyal 2016) is given the label of the closest neighbor from the support set: y = y (x, y) = arg min (xi, yi) and Sd (h (xi), h (x))) (2), where d is a distance function. Function h is parameterized by Inception - one of the most powerful ImageNet classification models (Szegedy et al., 2015a). Specifically, h provides features from the last layer (the softmax input) of a pre-trained inception classifier, which trains the inception classifier using rms-prop, as in Szegedy et al. (2015b), Section 8. With these features as input and cosine distance as distance function, the classifier achieves 87.6% accuracy in Eq.2 if it understands the single classification on the ImageNet 2016 (Vinyal)."}, {"heading": "4.3. Matching Nets model architecture and training", "text": "In fact, it is so that it is a way in which people are able to survive themselves. (...) In fact, it is so that people are able to survive themselves. (...) In fact, it is so that people are able to survive themselves. (...) It is so that people are able to survive themselves. (...) It is so that people are able to survive themselves. (...) It is as if people are able to survive themselves. (...) It is as if people are able to survive themselves. (...) It is as if people are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves."}, {"heading": "5. Data for bias discovery", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Cognitive Psychology Probe Data", "text": "The Cognitive Psychology Probe Data (CogPsyc) we use consists of 150 object images (Figure 1). The images are arranged in three rows, consisting of a probe image, a shape match image (corresponding to the probe in color but not in shape), and a color match image (corresponding to the probe in shape but not in color).The dataset contains 10 triples, each displayed on 5 different backgrounds, for a total of 50 triples.3The images were generously provided by cognitive psychologist Linda Smith. These images are photographs of stimuli previously used in form bias experiments at the Cognitive Development Lab at the University of Indiana. The potentially confusing variables of background content and object size are controlled in this dataset."}, {"heading": "5.2. Probe Data from the wild", "text": "We also compiled a real dataset consisting of 90 images of objects (30 triples) collected using Google Image Search. Here, too, the images are arranged in triples, consisting of a probe, a shape match and a colour match. For the test image, we chose images of real objects that are unlikely to appear in standard image sets such as ImageNet. In this way, our data contain the irregularity of the real world, while we also locate the properties of our models outside the image space covered in our training data. For the shape match image, we chose an object of similar shape (but with a completely different colour), and for the ColorMatch image, we chose an object of similar colour (but with a very different shape)."}, {"heading": "6. Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1. Shape bias in the Inception Baseline Model", "text": "First, we measured the shape distortion in IB: We used a pre-trained inception classifier (with 94% accuracy of the top 5) to provide characteristics for our one-shot classifier near our neighbors, and probed the model using the CogPsyc dataset. Specifically, for a given probe frame, we loaded x-s and the corresponding labels ys into memory along with the color match image xc and the corresponding label yc, as the support set S = {(xs, ys), (xc, yc)}}. We then calculated y-image with equation 2. Our model assigned either yc or ys to the sample image. To estimate the shape distortion Bs, we calculated the proportion of shape names assigned to the probe: Bs = E (y-ys), (y-ys))), (5) where E is a distortion in sample images."}, {"heading": "6.2. Shape bias in the Matching Nets Model", "text": "We then examined the MNs using a similar procedure. We used the IB trained in the previous section to provide the input functions for the MNs described in Section 4.3. Subsequently, we trained the MNs using the one-time word learning training procedure outlined in Section 4.3 in ImageNet, obtaining state-of-the-art technology as reported in (Vinyals et al., 2016). We then repeated the above analysis and found that MNs have a form of bias Bs = 0.7 using our CogPsyc dataset and a bias of Bs = 1 using the real dataset. It is interesting to note that these bias values are very similar to the IB bias values."}, {"heading": "6.3. Shape bias statistics: within models and across models", "text": "Observing a shape bias immediately raises some important questions. In particular: (1) Does this bias depend on the initial values of the parameters in our model = 48. (2) Does the size of the shape bias depend on the performance of the model? (3) When does the shape bias occur during the training - before model convergence or after? (4) How does the shape bias compare between models and within the models? To answer these questions, we extend the shape bias analysis described above to calculate the shape bias in a population of IB models and in a population of MN models with different random initialization (Fig. 2 and 5). (1) We first calculated the dependence of the shape bias on the shape of the shape bias on the initialization of IB (Fig. 2). Surprisingly, we observed a strong variability depending on the initialization of the shape bias for the shape bias at the end of the Psyc-649 bias = 0.28."}, {"heading": "7. Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1. A shape bias case study", "text": "In fact, it is the case that we will be able to set out to find a solution that is capable, that we are able, that we are able to identify."}, {"heading": "7.2. Modelling human word learning", "text": "There have been previous attempts to model human word learning in cognitive literature (Colunga & Smith, 2005; Xu & Tenenbaum, 2007; Schilling et al., 2012; Mayor & Plunkett, 2010), but none of these models is capable of learning word learning on the scale of real images at a glance. As MNs solve both the scale task and mimic typical experimental results, we propose MNs as a basis for calculating human one-off word learning (Landau et al., 1988).Another feature of our results supports this claim: In our model, shape distortion increases dramatically in training (Fig. 2a); similarly, humans show shape distortion much more strongly as adults than as children, and older children show the distortion more strongly than younger children (Landau et al., 1988).As a good cognitive model should do, our DNNs make verifiable predictions about word learning in humans that both the actual word learning and the form should predict it in the field."}, {"heading": "7.3. Cognitive Psychology for Deep Neural Networks", "text": "Our work points the way to the study of artificial cognitive psychology - the application of these techniques to better understand DNNs. For example, it would be useful to apply work from the extensive episodic memory literature (Tulving, 1985) to the recent flood of episodic memory architectures (Blundell et al., 2016; Graves et al., 2016) and apply techniques from semantic cognitive literature (Lamberts & Shanks, 2013) to newer models of concept formation (Higgins et al., 2016; Gregor et al., 2016; Raposo et al., 2017). More generally, the rich psychological literature will be increasingly useful for understanding in-depth learning agents as they learn to solve increasingly complex tasks."}, {"heading": "8. Conclusion", "text": "In this paper, we demonstrated how cognitive psychology techniques can be used to better understand DNNs. As a case study, we measured shape bias in two powerful but poorly understood DNNs - Inception and MNs. Our analysis uncovered previously unknown properties of these models. More broadly, our work is groundbreaking for future research into DNNs by leveraging the rich pool of techniques developed in cognitive psychology."}, {"heading": "Acknowledgements", "text": "We would like to thank Linda Smith and Charlotte Wozniak for providing the cognitive psychology research dataset; Charles Blundell for reviewing our work prior to submission; Oriol Vinyals, Daan Wierstra, Peter Dayan, Daniel Zoran, Ian Osband and Karen Simonyan for helpful discussions; James Besley for legal assistance and the DeepMind team for support."}], "references": [{"title": "How children learn the meanings of words. MIT press", "author": ["Bloom", "Paul"], "venue": null, "citeRegEx": "Bloom and Paul.,? \\Q2000\\E", "shortCiteRegEx": "Bloom and Paul.", "year": 2000}, {"title": "Model-free episodic control", "author": ["Blundell", "Charles", "Uria", "Benigno", "Pritzel", "Alexander", "Li", "Yazhe", "Ruderman", "Avraham", "Leibo", "Joel Z", "Rae", "Jack", "Wierstra", "Daan", "Hassabis", "Demis"], "venue": "arXiv preprint arXiv:1606.04460,", "citeRegEx": "Blundell et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Blundell et al\\.", "year": 2016}, {"title": "Is artificial intelligence permanently inscrutable? Despite new biology-like tools, some insist interpretation is impossible", "author": ["Bornstein", "Aaron"], "venue": null, "citeRegEx": "Bornstein and Aaron.,? \\Q2016\\E", "shortCiteRegEx": "Bornstein and Aaron.", "year": 2016}, {"title": "From the lexicon to expectations about kinds: a role for associative learning", "author": ["Colunga", "Eliana", "Smith", "Linda B"], "venue": "Psychological review,", "citeRegEx": "Colunga et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Colunga et al\\.", "year": 2005}, {"title": "Measuring invariances in deep networks. In Advances in neural information processing", "author": ["Goodfellow", "Ian", "Lee", "Honglak", "Le", "Quoc V", "Saxe", "Andrew", "Ng", "Andrew Y"], "venue": null, "citeRegEx": "Goodfellow et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2009}, {"title": "Towards conceptual compression", "author": ["Gregor", "Karol", "Besse", "Frederic", "Rezende", "Danilo Jimenez", "Danihelka", "Ivo", "Wierstra", "Daan"], "venue": "In Advances In Neural Information Processing Systems,", "citeRegEx": "Gregor et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2016}, {"title": "Early visual concept learning with unsupervised deep learning", "author": ["Higgins", "Irina", "Matthey", "Loic", "Glorot", "Xavier", "Pal", "Arka", "Uria", "Benigno", "Blundell", "Charles", "Mohamed", "Shakir", "Lerchner", "Alexander"], "venue": "arXiv preprint arXiv:1606.05579,", "citeRegEx": "Higgins et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Higgins et al\\.", "year": 2016}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Learning to learn using gradient descent", "author": ["Hochreiter", "Sepp", "Younger", "A Steven", "Conwell", "Peter R"], "venue": "In International Conference on Artificial Neural Networks,", "citeRegEx": "Hochreiter et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 2001}, {"title": "Visualizing and understanding recurrent networks", "author": ["Karpathy", "Andrej", "Johnson", "Justin", "Fei-Fei", "Li"], "venue": "arXiv preprint arXiv:1506.02078,", "citeRegEx": "Karpathy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Karpathy et al\\.", "year": 2015}, {"title": "Machine learning applications in cancer prognosis and prediction", "author": ["Kourou", "Konstantina", "Exarchos", "Themis P", "Konstantinos P", "Karamouzis", "Michalis V", "Fotiadis", "Dimitrios I"], "venue": "Computational and structural biotechnology journal,", "citeRegEx": "Kourou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kourou et al\\.", "year": 2015}, {"title": "Knowledge Concepts and Categories", "author": ["Lamberts", "Koen", "Shanks", "David"], "venue": null, "citeRegEx": "Lamberts et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lamberts et al\\.", "year": 2013}, {"title": "The importance of shape in early lexical learning", "author": ["Landau", "Barbara", "Smith", "Linda B", "Jones", "Susan S"], "venue": "Cognitive development,", "citeRegEx": "Landau et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Landau et al\\.", "year": 1988}, {"title": "Visualizing and understanding neural models in nlp", "author": ["Li", "Jiwei", "Chen", "Xinlei", "Hovy", "Eduard", "Jurafsky", "Dan"], "venue": "arXiv preprint arXiv:1506.01066,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "The mythos of model interpretability", "author": ["Lipton", "Zachary C"], "venue": "arXiv preprint arXiv:1606.03490,", "citeRegEx": "Lipton and C.,? \\Q2016\\E", "shortCiteRegEx": "Lipton and C.", "year": 2016}, {"title": "Cognitive basis of language learning in infants", "author": ["Macnamara", "John"], "venue": "Psychological review,", "citeRegEx": "Macnamara and John.,? \\Q1972\\E", "shortCiteRegEx": "Macnamara and John.", "year": 1972}, {"title": "A connectionist account of asymmetric category learning in early infancy", "author": ["Mareschal", "Denis", "French", "Robert M", "Quinn", "Paul C"], "venue": "Developmental psychology,", "citeRegEx": "Mareschal et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Mareschal et al\\.", "year": 2000}, {"title": "Constraints children place on word meanings", "author": ["Markman", "Ellen M"], "venue": "Cognitive Science,", "citeRegEx": "Markman and M.,? \\Q1990\\E", "shortCiteRegEx": "Markman and M.", "year": 1990}, {"title": "Children\u2019s sensitivity to constraints on word meaning: Taxonomic versus thematic relations", "author": ["Markman", "Ellen M", "Hutchinson", "Jean E"], "venue": "Cognitive psychology,", "citeRegEx": "Markman et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Markman et al\\.", "year": 1984}, {"title": "Children\u2019s use of mutual exclusivity to constrain the meanings of words", "author": ["Markman", "Ellen M", "Wachtel", "Gwyn F"], "venue": "Cognitive psychology,", "citeRegEx": "Markman et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Markman et al\\.", "year": 1988}, {"title": "Vision: A computational investigation into the human representation and processing of visual information, henry holt and co", "author": ["Marr", "David"], "venue": null, "citeRegEx": "Marr and David.,? \\Q1982\\E", "shortCiteRegEx": "Marr and David.", "year": 1982}, {"title": "A neurocomputational account of taxonomic responding and fast mapping in early word learning", "author": ["Mayor", "Julien", "Plunkett", "Kim"], "venue": "Psychological review,", "citeRegEx": "Mayor et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mayor et al\\.", "year": 2010}, {"title": "Understanding normal and impaired word reading: computational principles in quasiregular domains", "author": ["Plaut", "David C", "McClelland", "James L", "Seidenberg", "Mark S", "Patterson", "Karalyn"], "venue": "Psychological review,", "citeRegEx": "Plaut et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Plaut et al\\.", "year": 1996}, {"title": "Discovering objects and their relations from entangled scene representations", "author": ["Raposo", "David", "Santoro", "Adam", "Barrett", "David G.T", "Pascanu", "Razvan", "Lillicrap", "Timothy", "Battaglia", "Peter"], "venue": "arXiv preprint arXiv:1702.05068,", "citeRegEx": "Raposo et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Raposo et al\\.", "year": 2017}, {"title": "The human semantic potential: Spatial language and constrained connectionism", "author": ["Regier", "Terry"], "venue": null, "citeRegEx": "Regier and Terry.,? \\Q1996\\E", "shortCiteRegEx": "Regier and Terry.", "year": 1996}, {"title": "Semantic cognition: A parallel distributed processing approach", "author": ["Rogers", "Timothy T", "McClelland", "James L"], "venue": "MIT press,", "citeRegEx": "Rogers et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Rogers et al\\.", "year": 2004}, {"title": "Meta-learning with memory-augmented neural networks", "author": ["Santoro", "Adam", "Bartunov", "Sergey", "Botvinick", "Matthew", "Wierstra", "Daan", "Lillicrap", "Timothy"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "citeRegEx": "Santoro et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Santoro et al\\.", "year": 2016}, {"title": "Taking development seriously: Modeling the interactions in the emergence of different word learning biases", "author": ["Schilling", "Savannah M", "Sims", "Clare E", "Colunga", "Eliana"], "venue": "In CogSci,", "citeRegEx": "Schilling et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Schilling et al\\.", "year": 2012}, {"title": "Rethinking the inception architecture for computer vision", "author": ["Szegedy", "Christian", "Vanhoucke", "Vincent", "Ioffe", "Sergey", "Shlens", "Jonathon", "Wojna", "Zbigniew"], "venue": "arXiv preprint arXiv:1512.00567,", "citeRegEx": "Szegedy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2015}, {"title": "Matching networks for one shot learning", "author": ["Vinyals", "Oriol", "Blundell", "Charles", "Lillicrap", "Timothy", "Kavukcuoglu", "Koray", "Wierstra", "Daan"], "venue": "arXiv preprint arXiv:1606.04080,", "citeRegEx": "Vinyals et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2016}, {"title": "Word learning as bayesian inference", "author": ["Xu", "Fei", "Tenenbaum", "Joshua B"], "venue": "Psychological review,", "citeRegEx": "Xu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2007}, {"title": "Understanding neural networks through deep visualization", "author": ["Yosinski", "Jason", "Clune", "Jeff", "Nguyen", "Anh", "Fuchs", "Thomas", "Lipson", "Hod"], "venue": "arXiv preprint arXiv:1506.06579,", "citeRegEx": "Yosinski et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yosinski et al\\.", "year": 2015}, {"title": "Visualizing and understanding convolutional networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "In European Conference on Computer Vision, pp", "citeRegEx": "Zeiler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2014}, {"title": "Learning ordinal relationships for mid-level vision", "author": ["Zoran", "Daniel", "Isola", "Phillip", "Krishnan", "Dilip", "Freeman", "William T"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision, pp", "citeRegEx": "Zoran et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zoran et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 6, "context": "Recent pushes have aimed to better understand DNNs: tailor-made loss functions and architectures produce more interpretable features (Higgins et al., 2016; Raposo et al., 2017) while output-behavior analyses unveil previously opaque operations of these networks (Karpathy et al.", "startOffset": 133, "endOffset": 176}, {"referenceID": 23, "context": "Recent pushes have aimed to better understand DNNs: tailor-made loss functions and architectures produce more interpretable features (Higgins et al., 2016; Raposo et al., 2017) while output-behavior analyses unveil previously opaque operations of these networks (Karpathy et al.", "startOffset": 133, "endOffset": 176}, {"referenceID": 9, "context": ", 2017) while output-behavior analyses unveil previously opaque operations of these networks (Karpathy et al., 2015).", "startOffset": 93, "endOffset": 116}, {"referenceID": 13, "context": "Parallel to this work, neuroscience-inspired methods such as activation visualization (Li et al., 2015), ablation analysis (Zeiler & Fergus, 2014) and activation maximization (Yosinski et al.", "startOffset": 86, "endOffset": 103}, {"referenceID": 31, "context": ", 2015), ablation analysis (Zeiler & Fergus, 2014) and activation maximization (Yosinski et al., 2015) have also been applied.", "startOffset": 79, "endOffset": 102}, {"referenceID": 29, "context": "Specifically, we investigate Matching Networks (MNs) (Vinyals et al., 2016), which have state-of-the-art one-shot learning performance on ImageNet and we investigate an Inception Baseline model (Szegedy et al.", "startOffset": 53, "endOffset": 75}, {"referenceID": 12, "context": "To test the hypothesis that our DNNs discover this same \u201cshape bias\u201d, we probed our models using datasets and an experimental setup based on the original shape bias studies (Landau et al., 1988).", "startOffset": 173, "endOffset": 194}, {"referenceID": 10, "context": "Perhaps this data x is images of ImageNet objects to be classified, images and histology of tumors to be classified as benign or malignant (Kourou et al., 2015), or medical history and vital measurements to be classified according to likely pneumonia outcomes (Caruana et al.", "startOffset": 139, "endOffset": 160}, {"referenceID": 22, "context": "The use of behavioral probes to understand neural network function has been extensively applied within psychology itself, where neural networks have been employed as models of human brain function (Rumelhart et al., 1988; Plaut et al., 1996; Rogers & McClelland, 2004; Mareschal et al., 2000).", "startOffset": 197, "endOffset": 292}, {"referenceID": 16, "context": "The use of behavioral probes to understand neural network function has been extensively applied within psychology itself, where neural networks have been employed as models of human brain function (Rumelhart et al., 1988; Plaut et al., 1996; Rogers & McClelland, 2004; Mareschal et al., 2000).", "startOffset": 197, "endOffset": 292}, {"referenceID": 15, "context": ", 1996; Rogers & McClelland, 2004; Mareschal et al., 2000). To our knowledge, work applying behavioral probes to DNNs in machine learning has been quite limited; we only are aware of Zoran et al. (2015) and Goodfellow et al.", "startOffset": 35, "endOffset": 203}, {"referenceID": 4, "context": "(2015) and Goodfellow et al. (2009), who used psychophysics-like experiments to better understand image processing models.", "startOffset": 11, "endOffset": 36}, {"referenceID": 12, "context": "A variety of hypothesis-eliminating biases were then proposed including the whole object bias, by which children assume that a word refers to an entire object and not its components (Markman, 1990); the taxonomic bias, by which children assume a word refers to the basic level category an object belongs to (Markman & Hutchinson, 1984); the mutual exclusivity bias, by which children assume that a word only refers to one object category (Markman & Wachtel, 1988); the shape bias, with which we are concerned here (Landau et al., 1988); and a variety of others (Bloom, 2000).", "startOffset": 514, "endOffset": 535}, {"referenceID": 12, "context": "To address these questions, we carry out experiments analogous to those of Landau et al. (1988). This enables us to test whether the shape bias \u2013 a human interpretable feature used by children when learning language \u2013 is visible in the behavior of MNs and Inception networks.", "startOffset": 75, "endOffset": 96}, {"referenceID": 29, "context": "6% accuracy on one-shot classification on the ImageNet dataset (Vinyals et al., 2016).", "startOffset": 63, "endOffset": 85}, {"referenceID": 28, "context": "The function h is parameterised by Inception \u2013 one of the best performing ImageNet classification models (Szegedy et al., 2015a). Specifically, h returns features from the last layer (the softmax input) of a pre-trained Inception classifier, where the Inception classifier is trained using rms-prop, as described in Szegedy et al. (2015b), section 8.", "startOffset": 106, "endOffset": 339}, {"referenceID": 29, "context": "We also investigate a state-of-the-art one-shot learning architecture called Matching Nets (MN) (Vinyals et al., 2016).", "startOffset": 96, "endOffset": 118}, {"referenceID": 8, "context": "The training procedure for the one-shot learning task is critical if we want MNs to classify a probe image x\u0302 after viewing only a single example of this new image class in its support set (Hochreiter et al., 2001; Santoro et al., 2016).", "startOffset": 189, "endOffset": 236}, {"referenceID": 26, "context": "The training procedure for the one-shot learning task is critical if we want MNs to classify a probe image x\u0302 after viewing only a single example of this new image class in its support set (Hochreiter et al., 2001; Santoro et al., 2016).", "startOffset": 189, "endOffset": 236}, {"referenceID": 29, "context": "3 we trained MNs for one-shot word learning on ImageNet, achieving state-of-the-art performance, as reported in (Vinyals et al., 2016).", "startOffset": 112, "endOffset": 134}, {"referenceID": 27, "context": "There have been previous attempts to model human word learning in the cognitive science literature (Colunga & Smith, 2005; Xu & Tenenbaum, 2007; Schilling et al., 2012; Mayor & Plunkett, 2010).", "startOffset": 99, "endOffset": 192}, {"referenceID": 12, "context": "2a); similarly, humans show the shape bias much more strongly as adults than as children, and older children show the bias more strongly than younger children (Landau et al., 1988).", "startOffset": 159, "endOffset": 180}, {"referenceID": 1, "context": "For example, it would be useful to apply work from the massive literature on episodic memory (Tulving, 1985) to the recent flurry of episodic memory architectures (Blundell et al., 2016; Graves et al., 2016), and to apply techniques from the semantic cognition literature (Lamberts & Shanks, 2013) to recent models of concept formation (Higgins et al.", "startOffset": 163, "endOffset": 207}, {"referenceID": 6, "context": ", 2016), and to apply techniques from the semantic cognition literature (Lamberts & Shanks, 2013) to recent models of concept formation (Higgins et al., 2016; Gregor et al., 2016; Raposo et al., 2017).", "startOffset": 136, "endOffset": 200}, {"referenceID": 5, "context": ", 2016), and to apply techniques from the semantic cognition literature (Lamberts & Shanks, 2013) to recent models of concept formation (Higgins et al., 2016; Gregor et al., 2016; Raposo et al., 2017).", "startOffset": 136, "endOffset": 200}, {"referenceID": 23, "context": ", 2016), and to apply techniques from the semantic cognition literature (Lamberts & Shanks, 2013) to recent models of concept formation (Higgins et al., 2016; Gregor et al., 2016; Raposo et al., 2017).", "startOffset": 136, "endOffset": 200}], "year": 2017, "abstractText": "Deep neural networks (DNNs) have advanced performance on a wide range of complex tasks, rapidly outpacing our understanding of the nature of their solutions. While past work sought to advance our understanding of these models, none has made use of the rich history of problem descriptions, theories, and experimental methods developed by cognitive psychologists to study the human mind. To explore the potential value of these tools, we chose a well-established analysis from developmental psychology that explains how children learn word labels for objects, and applied that analysis to DNNs. Using datasets of stimuli inspired by the original cognitive psychology experiments, we find that state-of-the-art one shot learning models trained on ImageNet exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color. The magnitude of this shape bias varies greatly among architecturally identical, but differently seeded models, and even fluctuates within seeds throughout training, despite nearly equivalent classification performance. These results demonstrate the capability of tools from cognitive psychology for exposing hidden computational properties of DNNs, while concurrently providing us with a computational model for human word learning.", "creator": "LaTeX with hyperref package"}}}