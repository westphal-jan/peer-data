{"id": "1706.09262", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jun-2017", "title": "Hierarchical Attentive Recurrent Tracking", "abstract": "Class-agnostic object tracking is particularly difficult in cluttered environments as target specific discriminative models cannot be learned a priori. Inspired by how the human visual cortex employs spatial attention and separate \"where\" and \"what\" processing pathways to actively suppress irrelevant visual features, this work develops a hierarchical attentive recurrent model for single object tracking in videos. The first layer of attention discards the majority of background by selecting a region containing the object of interest, while the subsequent layers tune in on visual features particular to the tracked object. This framework is fully differentiable and can be trained in a purely data driven fashion by gradient methods. To improve training convergence, we augment the loss function with terms for a number of auxiliary tasks relevant for tracking. Evaluation of the proposed model is performed on two datasets of increasing difficulty: pedestrian tracking on the KTH activity recognition dataset and the KITTI object tracking dataset.", "histories": [["v1", "Wed, 28 Jun 2017 13:00:14 GMT  (7743kb,D)", "http://arxiv.org/abs/1706.09262v1", "Submitted to NIPS 2017. Code will be available atthis https URLand qualitative results are available atthis https URL"], ["v2", "Tue, 5 Sep 2017 14:35:08 GMT  (7771kb,D)", "http://arxiv.org/abs/1706.09262v2", "Published as a conference paper at NIPS 2017. Code is available atthis https URLand qualitative results are available atthis https URL"]], "COMMENTS": "Submitted to NIPS 2017. Code will be available atthis https URLand qualitative results are available atthis https URL", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.NE", "authors": ["adam r kosiorek", "alex bewley", "ingmar posner"], "accepted": true, "id": "1706.09262"}, "pdf": {"name": "1706.09262.pdf", "metadata": {"source": "CRF", "title": "Hierarchical Attentive Recurrent Tracking", "authors": ["Adam R. Kosiorek", "Alex Bewley"], "emails": ["adamk@robots.ox.ac.uk", "bewley@robots.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "2 Related Work", "text": "A number of recent studies have shown that visual content can be captured by a sequence of spatial insights or by foliation. [22, 12] Such a paradigm has the fascinating property that the computational complexity is proportional to the number of steps as opposed to the image size. Furthermore, the fovea centralis in the retina of primates is structured with maximum visual sharpness in the center and decreasing resolution in the periphery. Cheung et al. [4] shows that spatial attention is able to perform a regular sampling. Jaderberg et al. [14] introduced the spatial transformation at the center, which provides a completely differentiated resolution in the periphery."}, {"heading": "3 Hierarchical Attention", "text": "Inspired by the architecture of the human visual cortex, we structure our system around the working memory, which is responsible for storing the motion patterns and an appearance description of the tracked object. If we know both quantities, it would be possible to calculate the expected location of the object in the next step. As it is not trivial, we explicitly prefer to outsource the visual features to a separate processing stream conditioned to the expected appearance, which leads to a neglect of the features that are incompatible with our memory. We will now approach the description of the information flow in our model.Given the attention that is paid to the entered image."}, {"heading": "4 Loss", "text": "We train our system by minimizing a loss function consisting of a: Tracking Loss Term, a set of terms for auxiliary tasks and regularization terms. (D) We train our system by minimizing a loss function consisting of a: Tracking Lost Term, a set of terms for auxiliary tasks and regularization terms. (D) We are not able to limit the number of hyperparameters, we learn automatically to get better results for simpler datasets. Unlike the auxiliary tasks used by Jaderberg and al, our terms are relevant to our main goal - object tracking. (D) In order to limit the number of hyperparameters, we automatically learn the weighting of losses. The loss L (\u00b7) is given by LHART (D)."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 KTH Pedestrian Tracking", "text": "Kaho\u00fa et al. [16] performed a pedestrian tracking experiment using the KTH activity detection dataset [24] as a real case study. We replicate this experiment for comparison. We use the data preparation code provided by the authors and also use their pre-trained feature Extractor. Unlike them, we did not need to expand the Bounding Boxes by a factor of 1.5 and then scale them down for evaluation. We follow the authors and use the glitter size (h, w) = (28, 28). We copy the training sequence exactly, with the exception of the use of the RMSProp optimizer [9] with a learning rate of 3.33 x 10 \u2212 5 and a dynamics set to 0.9 instead of stochastic gradient descent with dynamics. In the original paper, an average IoU of 55.03% was measured, while the presented work achieved an average IoU value of 7.11%, reducing the relative error by a factor of almost two."}, {"heading": "5.2 Scaling to Real-World Data: KITTI", "text": "Since we have shown that footpath tracking is feasible with the proposed architecture, we will proceed to evaluate our model in a more sophisticated multi-class scenario on the KITTI dataset [8]. It consists of 21 high-resolution video sequences with multiple instances of the same class posing as potential distractors. We will split all sequences into 80 / 20 sequences for traction and test sets, respectively. Since the images in this dataset are much more diverse, we will implement V1 as the first three revolutionary layers of a modified AlexNet [1]. The original AlexNet takes inputs of size 227 x 227 and reduces them to 14 x 14 after conv3 layers. Since too low resolution would result in low tracking performance, and we did not want to shift the extracted view upwards, we decided to replace the original strip of four with one and skip one of the maximum operations to maintain spatial dimensions."}, {"heading": "6 Discussion", "text": "The experiments in the previous section show that it is possible to track real-world objects with a recurring, attentive tracker. While the tracker by Kaho\u00fa et al. [16], our approach uses additional building blocks, in particular: (i) Bounding box regression loss, (ii) loss of spatial attention, (iii) appearance attention with an additional concept of loss, and (iv) combines all of this into one unified approach. We are now discussing properties of these modulations. Spatial Attention Loss prevents gradations from occurring. Our early experiments suggest that tracking loss causes an instance of the disappearing gradient problem."}, {"heading": "7 Conclusion", "text": "Inspired by the cascaded attention mechanisms found in the human visual cortex, this work presented a neural recurring tracking architecture that is suitable for the task of tracking objects. Beyond biological inspiration, the proposed approach has a desirable computational effort and increased interpretability due to positioning maps selecting essential features for tracking. Furthermore, by introducing a series of auxiliary losses, we are able to scale difficult data from the real world, surpass previous attempts and move closer to the state of the art. Future research will address the extension of the proposed approach to multi-object tracking because, unlike many single objects, the recurring nature of the proposed tracker provides the ability to care for each object one after the other."}], "references": [{"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "Geoffrey E. Hinton"], "venue": "In NIPS, pages 1097\u20131105,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Curriculum learning", "author": ["Yoshua Bengio", "J\u00e9r\u00f4me Louradour", "Ronan Collobert", "Jason Weston"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning - ICML", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Neural Attention for Object Tracking", "author": ["Brian Cheung"], "venue": "In GPU Technology Conference,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Emergence of foveal image sampling from learning to attend", "author": ["Brian Cheung", "Eric Weiss", "Bruno Olshausen"], "venue": "in visual scenes. Arxiv,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Theoretical neuroscience : computational and mathematical modeling of neural systems", "author": ["Peter. Dayan", "L.F. Abbott"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Attend, Infer, Repeat: Fast Scene Understanding with Generative Models", "author": ["S.M. Ali Eslami", "Nicolas Heess", "Theophane Weber", "Yuval Tassa", "David Szepesvari", "Koray Kavukcuoglu", "Geoffrey E. Hinton"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Vision meets robotics: The KITTI dataset", "author": ["A. Geiger", "P. Lenz", "C. Stiller", "R. Urtasun"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Real-Time Recurrent Regression Networks for Object Tracking", "author": ["Daniel Gordon", "Ali Farhadi", "Dieter Fox"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2017}, {"title": "Hybrid computing using a neural network with dynamic external memory", "author": ["Alex Graves", "Greg Wayne", "Malcolm Reynolds", "Tim Harley", "Ivo Danihelka", "Agnieszka Grabska-Barwi\u0144ska", "Sergio G\u00f3mez Colmenarejo", "Edward Grefenstette", "Tiago Ramalho", "John Agapiou", "Adri\u00e0 Puigdom\u00e8nech Badia", "Karl Moritz Hermann", "Yori Zwols", "Georg Ostrovski", "Adam Cain", "Helen King", "Christopher Summerfield", "Phil Blunsom", "Koray Kavukcuoglu", "Demis Hassabis"], "venue": "URL http: //dx.doi.org/10.1038/nature20101http://10.0.4.14/nature20101http://www.nature", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "DRAW: A Recurrent Neural Network For Image Generation", "author": ["K Gregor", "I Danihelka", "A Graves", "D Wierstra"], "venue": "arXiv preprint arXiv:", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Learning to track at 100 FPS with deep regression networks", "author": ["David Held", "Sebastian Thrun", "Silvio Savarese"], "venue": "In European Conference on Computer Vision Workshop,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1946}, {"title": "Spatial Transformer Networks", "author": ["Max Jaderberg", "Karen Simonyan", "Andrew Zisserman", "Koray Kavukcuoglu"], "venue": "In Nips, pages 1\u201314,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Reinforcement Learning with Unsupervised Auxiliary Tasks. In arXiv:1611.05397, nov 2016", "author": ["Max Jaderberg", "Volodymyr Mnih", "Wojciech Marian Czarnecki", "Tom Schaul", "Joel Z Leibo", "David Silver", "Koray Kavukcuoglu"], "venue": "ISBN 2004012439", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "RATM: Recurrent Attentive Tracking", "author": ["Samira Ebrahimi Kaho\u00fa", "Vincent Michalski", "Roland Memisevic"], "venue": "Model. Iclr,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data", "author": ["Maximilian Karl", "Maximilian Soelch", "Justin Bayer", "Patrick van der Smagt"], "venue": "In International Conference 9  on Learning Representation,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2017}, {"title": "Mechanisms of visual attention in the human cortex", "author": ["Sabine Kastner", "Leslie G Ungerleider"], "venue": "Annual Reviews of Neuroscience,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2000}, {"title": "Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics. arXiv:1705.07115, may 2017", "author": ["Alex Kendall", "Yarin Gal", "Roberto Cipolla"], "venue": "URL http://arxiv.org/abs/1705", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2017}, {"title": "The Visual Object Tracking VOT2016 challenge results", "author": ["Matej Kristan", "Jiri Matas", "Ale\u0161 Leonardis", "Michael Felsberg", "Luk Cehovin", "Gustavo Fern\u00e1ndez", "Tom\u00e1\u0161 Voj\u00ed", "Gustav H\u00e4ger", "Georg Nebehay", "Roman Pflugfelder", "Abhinav Gupta", "Adel Bibi", "Alan Luke\u017ei\u010d", "Alvaro Garcia-Martin", "Amir Saffari", "Philip H S Torr", "Qiang Wang", "Rafael Martin-Nieto", "Rengarajan Pelapur", "Richard Bowden", "Chun Zhu", "Stefan Becker", "Stefan Duffner", "Stephen L Hicks", "Stuart Golodetz", "Sunglok Choi", "Tianfu Wu", "Thomas Mauthner", "Tony Pridmore", "Weiming Hu", "Wolfgang H\u00fcbner", "Xiaomeng Wang", "Xin Li", "Xinchu Shi", "Xu Zhao", "Xue Mei", "Yao Shizeng", "Yang Hua", "Yang Li", "Yang Lu", "Yuezun Li", "Zhaoyun Chen", "Zehua Huang", "Zhe Chen", "Zhe Zhang", "Zhenyu He", "Zhibin Hong"], "venue": "In European Conference on Computer Vision Workshop,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations", "author": ["David Krueger", "Tegan Maharaj", "J\u00e1nos Kram\u00e1r", "Mohammad Pezeshki", "Nicolas Ballas", "Nan Rosemary Ke", "Anirudh Goyal", "Yoshua Bengio", "Aaron Courville", "Chris Pal"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2017}, {"title": "Recurrent Models of Visual Attention", "author": ["Volodymyr Mnih", "Nicolas Heess", "Alex Graves", "Koray Kavukcuoglu"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking", "author": ["Guanghan Ning", "Zhi Zhang", "Chen Huang", "Zhihai He", "Xiaobo Ren", "Haohong Wang"], "venue": "arXiv preprint arXiv:1607.05781,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "Recognizing human actions: A local SVM approach", "author": ["Christian Schuldt", "Ivan Laptev", "Barbara Caputo"], "venue": "In Proceedings - International Conference on Pattern Recognition,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "Deep Networks with Internal Selective Attention through Feedback Connections", "author": ["Marijn Stollenga", "Jonathan Masci", "Faustino Gomez", "Juergen Schmidhuber"], "venue": "In arXiv preprint arXiv:", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "End-to-end representation learning for Correlation Filter based tracking", "author": ["Jack Valmadre", "Luca Bertinetto", "Jo\u00e3o F. Henriques", "Andrea Vedaldi", "Philip H.S. Torr"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2017}, {"title": "Grammar as a Foreign Language", "author": ["Oriol Vinyals", "Lukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey Hinton"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "UnitBox: An Advanced Object Detection Network", "author": ["Jiahui Yu", "Yuning Jiang", "Zhangyang Wang", "Zhimin Cao", "Thomas Huang"], "venue": "In Proceedings of the 2016 ACM on Multimedia Conference,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}], "referenceMentions": [{"referenceID": 24, "context": "Attention mechanisms have recently been explored in machine learning in a wide variety of contexts [27, 14], often providing new capabilities to machine learning algorithms [11, 12, 7].", "startOffset": 99, "endOffset": 107}, {"referenceID": 11, "context": "Attention mechanisms have recently been explored in machine learning in a wide variety of contexts [27, 14], often providing new capabilities to machine learning algorithms [11, 12, 7].", "startOffset": 99, "endOffset": 107}, {"referenceID": 8, "context": "Attention mechanisms have recently been explored in machine learning in a wide variety of contexts [27, 14], often providing new capabilities to machine learning algorithms [11, 12, 7].", "startOffset": 173, "endOffset": 184}, {"referenceID": 9, "context": "Attention mechanisms have recently been explored in machine learning in a wide variety of contexts [27, 14], often providing new capabilities to machine learning algorithms [11, 12, 7].", "startOffset": 173, "endOffset": 184}, {"referenceID": 5, "context": "Attention mechanisms have recently been explored in machine learning in a wide variety of contexts [27, 14], often providing new capabilities to machine learning algorithms [11, 12, 7].", "startOffset": 173, "endOffset": 184}, {"referenceID": 19, "context": "While they improve efficiency [22] and performance on state-of-the-art machine learning benchmarks [27], their architecture is much simpler than that of the mechanisms found in the human visual cortex [5].", "startOffset": 30, "endOffset": 34}, {"referenceID": 24, "context": "While they improve efficiency [22] and performance on state-of-the-art machine learning benchmarks [27], their architecture is much simpler than that of the mechanisms found in the human visual cortex [5].", "startOffset": 99, "endOffset": 103}, {"referenceID": 4, "context": "While they improve efficiency [22] and performance on state-of-the-art machine learning benchmarks [27], their architecture is much simpler than that of the mechanisms found in the human visual cortex [5].", "startOffset": 201, "endOffset": 204}, {"referenceID": 15, "context": "Attention has also been long studied by neuroscientists [18], who believe that it is crucial for visual perception and cognition [4], since it is inherently tied to the architecture of the visual cortex and can affect the information flow inside it.", "startOffset": 56, "endOffset": 60}, {"referenceID": 3, "context": "Attention has also been long studied by neuroscientists [18], who believe that it is crucial for visual perception and cognition [4], since it is inherently tied to the architecture of the visual cortex and can affect the information flow inside it.", "startOffset": 129, "endOffset": 132}, {"referenceID": 19, "context": "A number of recent studies have demonstrated that visual content can be captured through a sequence of spatial glimpses or foveation [22, 12].", "startOffset": 133, "endOffset": 141}, {"referenceID": 9, "context": "A number of recent studies have demonstrated that visual content can be captured through a sequence of spatial glimpses or foveation [22, 12].", "startOffset": 133, "endOffset": 141}, {"referenceID": 3, "context": "[4] show that if spatial attention is capable of zooming, a regular grid sampling is sufficient.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[14] introduced the spatial transformer network (STN) which provides a fully differentiable means of transforming feature maps, conditioned on the input itself.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[7] use the STN as a form of attention in combination with a recurrent neural network (RNN) to sequentially locate and identify objects in an image.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] use a latent variable to estimate the presence of additional objects, allowing the RNN to adapt the number of time-steps based on the input.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "Our spatial attention mechanism is based on the two dimensional Gaussian grid filters of [16] which is both fully differentiable and more biologically plausible than the STN.", "startOffset": 89, "endOffset": 93}, {"referenceID": 22, "context": "A policy with feedback connections can learn to adjust filters of a convolutional neural network (CNN), thereby adapting them to features present in the current image and improving accuracy [25].", "startOffset": 190, "endOffset": 194}, {"referenceID": 14, "context": "[17] showed that an input-dependent state transitions can be helpful for learning latent Markovian state-space system.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "In the context of single object tracking, both attention mechanisms and RNNs appear to be perfectly suited, yet their success has mostly been limited to simple monochromatic sequences with plain backgrounds [16].", "startOffset": 207, "endOffset": 211}, {"referenceID": 2, "context": "Cheung [3] applied STNs [14] as attention mechanisms for real-world object tracking, but failed due to exploding gradients potentially arising from the difficulty of the data.", "startOffset": 7, "endOffset": 10}, {"referenceID": 11, "context": "Cheung [3] applied STNs [14] as attention mechanisms for real-world object tracking, but failed due to exploding gradients potentially arising from the difficulty of the data.", "startOffset": 24, "endOffset": 28}, {"referenceID": 20, "context": "[23] achieved competitive performance by using features from an object detector as inputs to a long-short memory network (LSTM), but requires processing of the whole image at each time-step.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "Two recent state-of-the-art trackers employ convolutional Siamese networks which can be seen as an RNN unrolled over two time-steps [13, 26].", "startOffset": 132, "endOffset": 140}, {"referenceID": 23, "context": "Two recent state-of-the-art trackers employ convolutional Siamese networks which can be seen as an RNN unrolled over two time-steps [13, 26].", "startOffset": 132, "endOffset": 140}, {"referenceID": 10, "context": "Both methods explicitly process small search areas around the previous target position to produce a bounding box offset [13] or a correlation response map with the maximum corresponding to the target position [26].", "startOffset": 120, "endOffset": 124}, {"referenceID": 23, "context": "Both methods explicitly process small search areas around the previous target position to produce a bounding box offset [13] or a correlation response map with the maximum corresponding to the target position [26].", "startOffset": 209, "endOffset": 213}, {"referenceID": 7, "context": "[10] which employ an RNN based model and use explicit cropping and warping as a form of non-differentiable spatial attention.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "The work presented in this paper is closest to [16] where we share a similar spatial attention mechanism which is guided through an RNN to effectively learn a motion model that spans multiple time-steps.", "startOffset": 47, "endOffset": 51}, {"referenceID": 7, "context": "[10] only became available at the time of submitting this paper.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "This attention hierarchy, further enhanced by recurrent connections, mimics that of the human visual cortex [18].", "startOffset": 108, "endOffset": 112}, {"referenceID": 13, "context": "[16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[16], only centres and strides are estimated from the hidden state of the LSTM, while the variance depends solely on the stride.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "They are shared among later processing stages, which corresponds to the primary visual cortex in humans [5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 12, "context": "[15], ours are relevant for our main objective \u2014 object tracking.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Figure 4: Tracking results on KTH dataset [24].", "startOffset": 42, "endOffset": 46}, {"referenceID": 17, "context": "distribution (as it cannot be normalised), it is often used for evaluation [20].", "startOffset": 75, "endOffset": 79}, {"referenceID": 25, "context": "[28] and express the loss term as the negative log of IoU:", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[19] and learn the loss weighting \u03bb.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[16] performed a pedestrian tracking experiment on the KTH activity recognition dataset [24] as a real-world case-study.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[16] performed a pedestrian tracking experiment on the KTH activity recognition dataset [24] as a real-world case-study.", "startOffset": 88, "endOffset": 92}, {"referenceID": 13, "context": "[16] 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Since we demonstrated that pedestrian tracking is feasible using the proposed architecture, we proceed to evaluate our model in a more challenging multi-class scenario on the KITTI dataset [8].", "startOffset": 189, "endOffset": 192}, {"referenceID": 0, "context": "As images in this dataset are much more varied, we implement V1 as the first three convolutional layers of a modified AlexNet [1].", "startOffset": 126, "endOffset": 129}, {"referenceID": 18, "context": "We used 100 hidden units in the RNN with orthogonal initialisation and Zoneout [21] with probability set to 0.", "startOffset": 79, "endOffset": 83}, {"referenceID": 1, "context": "The system was trained via curriculum learning [2], by starting with sequences of length five and increasing sequence length every 13 epochs, with epoch length decreasing with increasing sequence length.", "startOffset": 47, "endOffset": 50}, {"referenceID": 13, "context": "[16] related works.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[16] and trained with the same hyperparameters as our framework, since both are closely related.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[16], our approach uses additional building blocks, specifically: (i) bounding-box regression loss, (ii) loss on spatial attention, (iii) appearance attention with an additional loss term, and (iv) combines all of these in a unified approach.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "Class-agnostic object tracking is particularly difficult in cluttered environments as target specific discriminative models cannot be learned a priori. Inspired by how the human visual cortex employs spatial attention and separate \u201cwhere\u201d and \u201cwhat\u201d processing pathways to actively suppress irrelevant visual features, this work develops a hierarchical attentive recurrent model for single object tracking in videos. The first layer of attention discards the majority of background by selecting a region containing the object of interest, while the subsequent layers tune in on visual features particular to the tracked object. This framework is fully differentiable and can be trained in a purely data driven fashion by gradient methods. To improve training convergence, we augment the loss function with terms for a number of auxiliary tasks relevant for tracking. Evaluation of the proposed model is performed on two datasets of increasing difficulty: pedestrian tracking on the KTH activity recognition dataset and the KITTI object tracking dataset.", "creator": "LaTeX with hyperref package"}}}