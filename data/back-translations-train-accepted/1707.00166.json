{"id": "1707.00166", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jul-2017", "title": "Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach", "abstract": "Relation extraction is a fundamental task in information extraction. Most existing methods have heavy reliance on annotations labeled by human experts, which are costly and time-consuming. To overcome this drawback, we propose a novel framework, REHession, to conduct relation extractor learning using annotations from heterogeneous information source, e.g., knowledge base and domain heuristics. These annotations, referred as heterogeneous supervision, often conflict with each other, which brings a new challenge to the original relation extraction task: how to infer the true label from noisy labels for a given instance. Identifying context information as the backbone of both relation extraction and true label discovery, we adopt embedding techniques to learn the distributed representations of context, which bridges all components with mutual enhancement in an iterative fashion. Extensive experimental results demonstrate the superiority of REHession over the state-of-the-art.", "histories": [["v1", "Sat, 1 Jul 2017 15:23:23 GMT  (553kb,D)", "http://arxiv.org/abs/1707.00166v1", "EMNLP 2017"], ["v2", "Tue, 1 Aug 2017 18:25:15 GMT  (555kb,D)", "http://arxiv.org/abs/1707.00166v2", "EMNLP 2017"]], "COMMENTS": "EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["liyuan liu", "xiang ren", "qi zhu", "shi zhi", "huan gui", "heng ji", "jiawei han 0001"], "accepted": true, "id": "1707.00166"}, "pdf": {"name": "1707.00166.pdf", "metadata": {"source": "CRF", "title": "Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach", "authors": ["Liyuan Liu", "Xiang Ren", "Qi Zhu", "Huan Gui", "Shi Zhi", "Heng Ji", "Jiawei Han"], "emails": ["hanj}@illinois.edu", "jih@rpi.edu"], "sections": [{"heading": null, "text": "Relationship extraction is a fundamental task in information extraction. Most existing methods rely heavily on annotations from human experts, which are costly and time-consuming. To overcome this disadvantage, we propose a new framework, REHESSION, to perform relationship extractor learning using annotations from heterogeneous sources of information, such as knowledge base and domain heuristics. These annotations, called heterogeneous supervision, are often contradictory, which presents a new challenge to the original task of relation extraction: how to derive true labeling from loud labels for a given example. By identifying context information as the backbone of both relationship extraction and true label discovery, we use embedding techniques to learn the distributed context representations that combine all components in an iterative way with mutual improvement."}, {"heading": "1 Introduction", "text": "In fact, most of them will be able to play by the rules they have set themselves in order to play by the rules."}, {"heading": "2 Preliminaries", "text": "In this section, we formally define relation extraction and heterogeneous monitoring. Relation extraction. For a sentence d, an entity mention is a symbolic range in d, which represents an entity, and a relation mention is a triple (e1, e2, d) consisting of an ordered entity pair (e1, e2) and d. The relation extraction task is to categorize relation mentions into a given set of relation types R, or non-target type (None), which means that the type of relation mention does not belong to R. Heterogeneous monitoring. Similar to (Ratner et al., 2016), we use naming functions as basic units to encode monitoring information and generate annotations. Since different oversight information may have different competent subsets, we require each naming function to encode the elementary oversight information."}, {"heading": "3 The REHESSION Framework", "text": "Here we present REHESSION, a novel framework for deriving true labels from automatically generated noisy labels and categorizing unlabeled instances into a series of markup types. Intuitively, annotation errors (O) occur due to incontext errors, e.g. in Fig. 1, \u03bb1 comments c1 and c2 with \"real\" labels, but for non-matching contexts \"kill\" and \"kill.\" Accordingly, we should only trust the labeling functions on matching contexts, e.g. on c3 due to its context \"was born in,\" but not on c1 and c2. On the other hand, label extraction can be considered a suitable label type for a particular context. These two matching processes are closely related and can improve each other, while context representation plays an important role in both."}, {"heading": "3.1 Modeling Relation Mention", "text": "In order to achieve a better generalization, however, we must work for a better generalization of terms with lower dimensions (102) vectors. In Fig. 2, for example, the relationship between the terms c3 and c3 is presented for the first time as a pair of terms. After learning text characteristics, we use the average generalization of characteristics to derive the vector for c3. Text-feature representation is similar to other principles of embedding learning content, we assume that text characteristics occur in the same contexts (also known as the distribution hypothesis (Harris, 1954))."}, {"heading": "3.2 True Label Discovery", "text": "Since heterogeneous monitoring generates labels in a discriminatory manner, we assume that their errors follow certain underlying principles, i.e., if a markup function describes an instance correctly / incorrectly, it would comment correctly / incorrectly on other similar instances. Since context representation captures the semantic meaning of the mention of relation types and is used to identify relation types, we also use it to identify the context and markup functions (note: c). Therefore, we assume that for each markup function p there is a competent substance called Si onRnz, which contains instances that can contain precise annotations. In Figure 1, for example, c3 is in the competent substance c of the context and labeling functions c, while c1 and c2 are the labeling functions c c c. Furthermore, the creation of annotations is not really random, and we suggest a probable model to describe the functions produced at the i-level."}, {"heading": "3.3 Modeling Relation Type", "text": "We will now discuss the model for identifying relationship types on the basis of context representation. For each mention of relationship c, its representation zc implies its relationship type, and the distribution of relationship type can be described by the soft-max function: p (ri | zc) = exp (zTc ti) \u2211 rj \u0445 R. None exp (z T c tj) (5), where ti-Rvz is the representation for relationship type ri. Furthermore, we can train the relationship extraction model with the derived appropriate designation o \u0445 c (6) as a multi-class classifier. Specifically, we will use Equation 5 to approximate the distribution type (ri | o \u0445 c0 ri 6 = o \u0445 c (6). Furthermore, we will use the KL divergence to measure the discrepancy between two distributions, and formulate model learning as maximizing JR in equation 7 (Kp 7)."}, {"heading": "3.4 Model Learning", "text": "Based on Eq.1, Eq.4, and Eq.7, we form the common optimization problem for the model parameters asmin W, v, v *, l, t, o * J = \u2212 JR \u2212 \u03bb1JE \u2212 \u03bb2JTs.t. These components would refine the context representation and improve each other. To efficiently solve the common optimization problem in Eq.8, we apply the stochastic gradient descending algorithm to update all three components iteratively, while these components would refine and improve the context representation. To efficiently apply the common optimization problem in Eq.8, we apply the stochastic gradient descending algorithm to update {W, v, v, v, v, l, t} iteratively, and oc \u00b2 is estimated by maximizing JT after calculating zc."}, {"heading": "3.5 Relation Type Inference", "text": "As shown in Table 3, the proportion of None in Cu is usually much higher than in Cl. Furthermore, unlike other relation types in R, None has no coherent semantic meaning. Similar to (Ren et al., 2016), we introduce a heuristic rule: To identify a relation mention as None if (1) our relation extractor predicts it as None, or (2) the entropy of p (. | zc) overR exceeds a predefined threshold. Entropy is calculated as H (p (. | zc)) = \u2212 \u2211 ri-R (ri | zc) log (p (ri | zc))). And the second situation means that this relation extractor mention probably does not belong to any relation types inR."}, {"heading": "4 Experiments", "text": "In this section we confirm our method empirically by comparing it with the most modern methods of relation extraction in news and Wikipedia articles."}, {"heading": "4.1 Datasets and settings", "text": "In the experiments, we are investigating two benchmark datasets from different domains: 1 NYT (Riedel et al., 2010) is a news corpus sampled from the other 294k 1989-2007 New York Times articles. It consists of 1.18M records, while 395 of 1 codes and records used in this paper can be downloaded at: https: / / github.com /.they are annotated by authors of (Hoffmann et al., 2011) and used as test data; Wiki-KBP uses 1.5M records sampled from 780k Wikipedia articles (Ling and Weld, 2012) as training corpus, while test set of the 2k sets manual annotated in KBP slot filling assessment results (Ellis et al., 2012).For both records, the training and test sets are maintained in our experiments."}, {"heading": "4.2 Compared Methods", "text": "We compare REHESSION with the following methods: FIGER (Ling and Weld, 2012) adopts multilabel learning with Perceptron algorithm; BFK (Bunescu and Mooney, 2005) uses bag-offeature kernel to train a supporting vector machine; DSL (Mintz et al., 2009) trains a multiclass logistic classifier4 on the training data; MultiR (Hoffmann et al., 2011) models training label noise by multi-instance multi-label learning; FCM (Gormley et al., 2015) performs a compositional embedding using a neural language model. CoType-RM (Ren et al., 2016) participates in participatory label loss to handle label noise and train the extractor. In addition, two different strategies for feed heterogeneous supervision are applied to these methods. The first consists of keeping all noisy labels marked as \"NL.\" Alternatively, a true label discovery method based on pastack solutions (we will blindly update from Roth and update them in 2010)."}, {"heading": "4.3 Performance Comparison", "text": "Considering the experimental setup described above, the averaged evaluation results in 10 passes of relation classification and relation extraction on two sets of data in Table 6.The comparison shows that the NL strategy performs better than the TD strategy, since the true labels derived from Investment are in fact false in many cases. On the other hand, as discussed in Section 4.4, our method introduces context awareness to real label discovery, while the derived true label guides the relation extractor in achieving the best performance. However, this observation justifies the motivation to avoid the assumption of source consistency and the effectiveness of the proposed model of real label detection. One could also see the difference between REHESSION and the comparative methods on the NYT dataset being more significant than on the WikiKBP dataset. This observation is consistent with the fact that the NYT dataset contains more conflicts than the label detection model, as opposed to the Wikel BP dataset and the intuitive BP (see table 5 and the Ralitification)."}, {"heading": "4.4 Case Study", "text": "As mentioned above, most label recognition methods use the assumption of source consistency, which means that if they trust a labeling function, they would trust it on all the notes. For example, in all four cases, investment does not refer to a true type. Our method derives true labels in a context-aware way, which means that we only trust labeling functions in matching contexts. For example, our method is born as the true label for the first two relationship mentions; after we have replaced the born with other words (selected and examined), our method no longer trusts born ones, since the modified contexts are no longer matched, then infects none as the true label detector.Effectiveness of label detection. We investigate the effectiveness of the proposed contextual true label recognition component by comparing REHESSION-TD with its variant REHESSION-TD, which uses the investment method to resolve conflicts."}, {"heading": "5 Related Work", "text": "Relation Extraction. Relation Extraction is one of the most important tasks in NLP. To alleviate dependence on annotations by human experts, weak monitoring (Bunescu and Mooney, 2007; Etzioni et al., 2004) and remote monitoring (Ren et al., 2016) have been used to automatically generate annotations based on knowledge (or seed patterns / instances).Here, we propose a more general framework to consolidate heterogeneous information and further refine the true label of loud labels, giving the re-lationary extractor the potential to detect more types of relationships in a more precise way.Word embedding has shown great potential in capturing semantic meaning (Mikolov et al., 2013), and achieved great success in a wide range of NLP tasks such as relation extraction (Zeng et al al al., 2014; Takase and Inui, 2016; Nguyen and Grishman, 2015)."}, {"heading": "6 Conclusion and Future Work", "text": "In this paper, we propose REHESSION, a framework for embedding relationships under heterogeneous supervision. It resolves conflicts based on context representation and avoids source consistency assumptions. Heterogeneous supervision allows our model to extract more relationship types, while the high-quality true labels derived from it allow our model to be more precise. Experimental evaluation fully justifies the effectiveness of the proposed framework on two real-world datasets. There are many directions for future work. One is to apply transfer learning techniques to handle the difference between label distributions of training set and test set. Another is to further integrate information such as relationship type hierarchy for fine-grained relationship extraction."}], "references": [{"title": "A review of relation extraction", "author": ["Nguyen Bach", "Sameer Badaskar."], "venue": "Literature review for Language and Statistics II .", "citeRegEx": "Bach and Badaskar.,? 2007", "shortCiteRegEx": "Bach and Badaskar.", "year": 2007}, {"title": "Knowledge-based question answering as machine translation", "author": ["Junwei Bao", "Nan Duan", "Ming Zhou", "Tiejun Zhao."], "venue": "Cell 2(6).", "citeRegEx": "Bao et al\\.,? 2014", "shortCiteRegEx": "Bao et al\\.", "year": 2014}, {"title": "Class-based n-gram models of natural language", "author": ["Peter F Brown", "Peter V Desouza", "Robert L Mercer", "Vincent J Della Pietra", "Jenifer C Lai."], "venue": "Computational linguistics 18(4):467\u2013479.", "citeRegEx": "Brown et al\\.,? 1992", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "Learning to extract relations from the web using minimal supervision", "author": ["Razvan Bunescu", "Raymond Mooney."], "venue": "ACL.", "citeRegEx": "Bunescu and Mooney.,? 2007", "shortCiteRegEx": "Bunescu and Mooney.", "year": 2007}, {"title": "Subsequence kernels for relation extraction", "author": ["Razvan Bunescu", "Raymond J Mooney."], "venue": "NIPS. pages 171\u2013178.", "citeRegEx": "Bunescu and Mooney.,? 2005", "shortCiteRegEx": "Bunescu and Mooney.", "year": 2005}, {"title": "Coupled semi-supervised learning for information extraction", "author": ["Andrew Carlson", "Justin Betteridge", "Richard C Wang", "Estevam R Hruschka Jr", "Tom M Mitchell."], "venue": "Proceedings of the third ACM international conference on Web search and data mining.", "citeRegEx": "Carlson et al\\.,? 2010", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Exploiting background knowledge for relation extraction", "author": ["Yee Seng Chan", "Dan Roth."], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics. Association for Computational Linguistics, pages 152\u2013160.", "citeRegEx": "Chan and Roth.,? 2010", "shortCiteRegEx": "Chan and Roth.", "year": 2010}, {"title": "Extraction of genedisease relations from medline using domain dictionaries and machine learning", "author": ["Hong-Woo Chun", "Yoshimasa Tsuruoka", "Jin-Dong Kim", "Rie Shiba", "Naoki Nagata", "Teruyoshi Hishiki", "Jun\u2019ichi Tsujii"], "venue": null, "citeRegEx": "Chun et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chun et al\\.", "year": 2006}, {"title": "Linguistic resources for 2013 knowledge base population evaluations", "author": ["Joe Ellis", "Xuansong Li", "Kira Griffitt", "Stephanie Strassel", "Jonathan Wright."], "venue": "TAC.", "citeRegEx": "Ellis et al\\.,? 2012", "shortCiteRegEx": "Ellis et al\\.", "year": 2012}, {"title": "Web-scale information extraction in knowitall:(preliminary results)", "author": ["Oren Etzioni", "Michael Cafarella", "Doug Downey", "Stanley Kok", "Ana-Maria Popescu", "Tal Shaked", "Stephen Soderland", "Daniel S Weld", "Alexander Yates."], "venue": "Proceedings of the", "citeRegEx": "Etzioni et al\\.,? 2004", "shortCiteRegEx": "Etzioni et al\\.", "year": 2004}, {"title": "Relex\u2014relation extraction using dependency parse trees", "author": ["Katrin Fundel", "Robert K\u00fcffner", "Ralf Zimmer."], "venue": "Bioinformatics 23(3):365\u2013371.", "citeRegEx": "Fundel et al\\.,? 2007", "shortCiteRegEx": "Fundel et al\\.", "year": 2007}, {"title": "Improved relation extraction with feature-rich compositional embedding models", "author": ["Matthew R Gormley", "Mo Yu", "Mark Dredze."], "venue": "arXiv preprint arXiv:1505.02419 .", "citeRegEx": "Gormley et al\\.,? 2015", "shortCiteRegEx": "Gormley et al\\.", "year": 2015}, {"title": "Distributional structure", "author": ["Zellig S Harris."], "venue": "Word 10(2-3):146\u2013162.", "citeRegEx": "Harris.,? 1954", "shortCiteRegEx": "Harris.", "year": 1954}, {"title": "Knowledgebased weak supervision for information extraction of overlapping relations", "author": ["Raphael Hoffmann", "Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S Weld."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computa-", "citeRegEx": "Hoffmann et al\\.,? 2011", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "Iterative learning for reliable crowdsourcing systems", "author": ["David R Karger", "Sewoong Oh", "Devavrat Shah."], "venue": "Advances in neural information processing systems. pages 1953\u20131961.", "citeRegEx": "Karger et al\\.,? 2011", "shortCiteRegEx": "Karger et al\\.", "year": 2011}, {"title": "Efficient crowdsourcing for multi-class labeling", "author": ["David R Karger", "Sewoong Oh", "Devavrat Shah."], "venue": "ACM SIGMETRICS Performance Evaluation Review 41(1):81\u201392.", "citeRegEx": "Karger et al\\.,? 2013", "shortCiteRegEx": "Karger et al\\.", "year": 2013}, {"title": "A survey on truth discovery", "author": ["Yaliang Li", "Jing Gao", "Chuishi Meng", "Qi Li", "Lu Su", "Bo Zhao", "Wei Fan", "Jiawei Han."], "venue": "SIGKDD Explor. Newsl. 17(2):1\u201316. https://doi.org/10.1145/2897350.2897352.", "citeRegEx": "Li et al\\.,? 2016", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "No noun phrase left behind: detecting and typing unlinkable entities", "author": ["Thomas Lin", "Oren Etzioni"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning", "citeRegEx": "Lin and Etzioni,? \\Q2012\\E", "shortCiteRegEx": "Lin and Etzioni", "year": 2012}, {"title": "Fine-grained entity recognition", "author": ["Xiao Ling", "Daniel S Weld."], "venue": "AAAI. Citeseer.", "citeRegEx": "Ling and Weld.,? 2012", "shortCiteRegEx": "Ling and Weld.", "year": 2012}, {"title": "The stanford corenlp natural language processing toolkit", "author": ["Christopher D Manning", "Mihai Surdeanu", "John Bauer", "Jenny Rose Finkel", "Steven Bethard", "David McClosky."], "venue": "ACL (System Demonstrations). pages 55\u201360.", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in neural information processing systems. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference", "citeRegEx": "Mintz et al\\.,? 2009", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Scalable knowledge harvesting with high precision and high recall", "author": ["Ndapandula Nakashole", "Martin Theobald", "Gerhard Weikum."], "venue": "Proceedings of the fourth ACM international conference on Web search and data mining. ACM, pages 227\u2013236.", "citeRegEx": "Nakashole et al\\.,? 2011", "shortCiteRegEx": "Nakashole et al\\.", "year": 2011}, {"title": "Patty: a taxonomy of relational patterns with semantic types", "author": ["Ndapandula Nakashole", "Gerhard Weikum", "Fabian Suchanek."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational", "citeRegEx": "Nakashole et al\\.,? 2012", "shortCiteRegEx": "Nakashole et al\\.", "year": 2012}, {"title": "Combining neural networks and log-linear models to improve relation extraction", "author": ["Thien Huu Nguyen", "Ralph Grishman."], "venue": "arXiv preprint arXiv:1511.05926 .", "citeRegEx": "Nguyen and Grishman.,? 2015", "shortCiteRegEx": "Nguyen and Grishman.", "year": 2015}, {"title": "Knowing what to believe (when you already know something)", "author": ["Jeff Pasternack", "Dan Roth."], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics. Association for Computational Linguistics, pages 877\u2013885.", "citeRegEx": "Pasternack and Roth.,? 2010", "shortCiteRegEx": "Pasternack and Roth.", "year": 2010}, {"title": "Data programming: Creating large training sets, quickly", "author": ["Alexander J Ratner", "Christopher M De Sa", "Sen Wu", "Daniel Selsam", "Christopher R\u00e9."], "venue": "Advances in Neural Information Processing Systems. pages 3567\u20133575.", "citeRegEx": "Ratner et al\\.,? 2016", "shortCiteRegEx": "Ratner et al\\.", "year": 2016}, {"title": "Clustype: Effective entity recognition and typing by relation phrase-based clustering", "author": ["Xiang Ren", "Ahmed El-Kishky", "Chi Wang", "Fangbo Tao", "Clare R Voss", "Jiawei Han."], "venue": "Proceedings of the 21th ACM SIGKDD International Conference on Knowl-", "citeRegEx": "Ren et al\\.,? 2015", "shortCiteRegEx": "Ren et al\\.", "year": 2015}, {"title": "Cotype: Joint extraction of typed entities and relations with knowledge bases", "author": ["Xiang Ren", "Zeqiu Wu", "Wenqi He", "Meng Qu", "Clare R Voss", "Heng Ji", "Tarek F Abdelzaher", "Jiawei Han."], "venue": "arXiv preprint arXiv:1610.08763 .", "citeRegEx": "Ren et al\\.,? 2016", "shortCiteRegEx": "Ren et al\\.", "year": 2016}, {"title": "Modeling relations and their mentions without labeled text", "author": ["Sebastian Riedel", "Limin Yao", "Andrew McCallum."], "venue": "Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, pages 148\u2013163.", "citeRegEx": "Riedel et al\\.,? 2010", "shortCiteRegEx": "Riedel et al\\.", "year": 2010}, {"title": "Relext: A tool for relation extraction from text in ontology extension", "author": ["Alexander Schutz", "Paul Buitelaar."], "venue": "International semantic web conference. Springer, volume 2005, pages 593\u2013606.", "citeRegEx": "Schutz and Buitelaar.,? 2005", "shortCiteRegEx": "Schutz and Buitelaar.", "year": 2005}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."], "venue": "Journal of Machine Learning Research 15(1):1929\u20131958.", "citeRegEx": "Srivastava et al\\.,? 2014", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Composing distributed representations of relational patterns", "author": ["Sho Takase", "Naoaki Okazaki Kentaro Inui."], "venue": "Proceedings of ACL.", "citeRegEx": "Takase and Inui.,? 2016", "shortCiteRegEx": "Takase and Inui.", "year": 2016}, {"title": "Learning latent vector spaces for product search", "author": ["Christophe Van Gysel", "Maarten de Rijke", "Evangelos Kanoulas."], "venue": "Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. ACM, pages 165\u2013174.", "citeRegEx": "Gysel et al\\.,? 2016a", "shortCiteRegEx": "Gysel et al\\.", "year": 2016}, {"title": "Unsupervised, efficient and semantic expertise retrieval", "author": ["Christophe Van Gysel", "Maarten de Rijke", "Marcel Worring."], "venue": "Proceedings of the 25th International Conference on World Wide Web. International World Wide Web Conferences Steering", "citeRegEx": "Gysel et al\\.,? 2016b", "shortCiteRegEx": "Gysel et al\\.", "year": 2016}, {"title": "Socratic learning: Correcting misspecified generative models using discriminative models", "author": ["Paroma Varma", "Bryan He", "Dan Iter", "Peng Xu", "Rose Yu", "Christopher De Sa", "Christopher R\u00e9."], "venue": "arXiv preprint arXiv:1610.08123 .", "citeRegEx": "Varma et al\\.,? 2016", "shortCiteRegEx": "Varma et al\\.", "year": 2016}, {"title": "Relation classification via convolutional deep neural network", "author": ["Daojian Zeng", "Kang Liu", "Siwei Lai", "Guangyou Zhou", "Jun Zhao"], "venue": "In COLING", "citeRegEx": "Zeng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeng et al\\.", "year": 2014}, {"title": "A bayesian approach to discovering truth from conflicting sources for data integration", "author": ["Bo Zhao", "Benjamin IP Rubinstein", "Jim Gemmell", "Jiawei Han."], "venue": "Proceedings of the VLDB Endowment 5(6):550\u2013561.", "citeRegEx": "Zhao et al\\.,? 2012", "shortCiteRegEx": "Zhao et al\\.", "year": 2012}, {"title": "Modeling truth existence in truth discovery", "author": ["Shi Zhi", "Bo Zhao", "Wenzhu Tong", "Jing Gao", "Dian Yu", "Heng Ji", "Jiawei Han."], "venue": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM,", "citeRegEx": "Zhi et al\\.,? 2015", "shortCiteRegEx": "Zhi et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 1, "context": "example is question answering, regarding a specific question, relation among entities can provide valuable information, which helps to seek better answers (Bao et al., 2014).", "startOffset": 155, "endOffset": 173}, {"referenceID": 10, "context": "Similarly, for medical science literature, relations like protein-protein interactions (Fundel et al., 2007) and gene disease associations (Chun et al.", "startOffset": 87, "endOffset": 108}, {"referenceID": 7, "context": ", 2007) and gene disease associations (Chun et al., 2006) can be extracted and used in knowledge base population.", "startOffset": 38, "endOffset": 57}, {"referenceID": 30, "context": "Additionally, relation extractors can be used in ontology construction (Schutz and Buitelaar, 2005).", "startOffset": 71, "endOffset": 99}, {"referenceID": 5, "context": "To alleviate such drawback, attempts have been made to build relation extractors with a small set of seed instances or human-crafted patterns (Nakashole et al., 2012, 2011; Carlson et al., 2010), based on which more patterns and instances will be iteratively generated by bootstrap learning.", "startOffset": 142, "endOffset": 194}, {"referenceID": 21, "context": "However, these methods often suffer from semantic drift (Mintz et al., 2009).", "startOffset": 56, "endOffset": 76}, {"referenceID": 21, "context": "Besides, knowledge bases like Freebase have been leveraged to automatically generate training data and provide distant supervision (Mintz et al., 2009).", "startOffset": 131, "endOffset": 151}, {"referenceID": 27, "context": "Nevertheless, for many domain-specific applications, distant supervision is either non-existent or insufficient (usually less than 25% of relation mentions are covered (Ren et al., 2015; Lin et al., 2012)).", "startOffset": 168, "endOffset": 204}, {"referenceID": 26, "context": "1, these supervisions often conflict with each other (Ratner et al., 2016).", "startOffset": 53, "endOffset": 74}, {"referenceID": 26, "context": "To address these conflicts, data programming (Ratner et al., 2016) employs a generative model, which encodes supervisions as labeling functions, and adopts the source consistency assumption: a", "startOffset": 45, "endOffset": 66}, {"referenceID": 16, "context": "This assumption is widely used in true label discovery literature (Li et al., 2016) to model reliabilities of information sources like crowdsourcing and infer the true label from noisy labels.", "startOffset": 66, "endOffset": 83}, {"referenceID": 35, "context": "In particular, a labeling function could be more reliable for a certain subset (Varma et al., 2016) (also known as its proficient subset) comparing to the rest.", "startOffset": 79, "endOffset": 99}, {"referenceID": 26, "context": "Similar to (Ratner et al., 2016), we employ labeling functions as basic units to encode supervision information and generate annotations.", "startOffset": 11, "endOffset": 32}, {"referenceID": 28, "context": "As shown in Table 2, we extract abundant lexical features (Ren et al., 2016; Mintz et al., 2009; Chan and Roth, 2010) to characterize relation mentions.", "startOffset": 58, "endOffset": 117}, {"referenceID": 21, "context": "As shown in Table 2, we extract abundant lexical features (Ren et al., 2016; Mintz et al., 2009; Chan and Roth, 2010) to characterize relation mentions.", "startOffset": 58, "endOffset": 117}, {"referenceID": 6, "context": "As shown in Table 2, we extract abundant lexical features (Ren et al., 2016; Mintz et al., 2009; Chan and Roth, 2010) to characterize relation mentions.", "startOffset": 58, "endOffset": 117}, {"referenceID": 12, "context": "Similar to other principles of embedding learning, we assume text features occurring in the same contexts tend to have similar meanings (also known as distributional hypothesis(Harris, 1954)).", "startOffset": 176, "endOffset": 190}, {"referenceID": 20, "context": "In order to perform efficient optimization, we adopt the negative sampling technique (Mikolov et al., 2013) to avoid this summation.", "startOffset": 85, "endOffset": 107}, {"referenceID": 20, "context": "(1) where P\u0302 is noise distribution used in (Mikolov et al., 2013), \u03c3 is the sigmoid function and V is number of negative samples.", "startOffset": 43, "endOffset": 65}, {"referenceID": 31, "context": "Additionally, we apply the widely used dropout techniques (Srivastava et al., 2014) to prevent overfitting and improve generalization performance.", "startOffset": 58, "endOffset": 83}, {"referenceID": 28, "context": "Similar to (Ren et al., 2016), we introduce a heuristic rule: identifying a relation mention as None when (1) our relation extractor predict it as None, or (2) the entropy of p(.", "startOffset": 11, "endOffset": 29}, {"referenceID": 29, "context": "NYT (Riedel et al., 2010) is a news corpus sampled from\u223c 294k 1989-2007 New York Times news articles.", "startOffset": 4, "endOffset": 25}, {"referenceID": 13, "context": "them are annotated by authors of (Hoffmann et al., 2011) and used as test data;", "startOffset": 33, "endOffset": 56}, {"referenceID": 18, "context": "5M sentences sampled from 780k Wikipedia articles (Ling and Weld, 2012) as training corpus, while test set consists of the 2k sentences manually annotated in 2013 KBP slot filling assessment results (Ellis et al.", "startOffset": 50, "endOffset": 71}, {"referenceID": 8, "context": "5M sentences sampled from 780k Wikipedia articles (Ling and Weld, 2012) as training corpus, while test set consists of the 2k sentences manually annotated in 2013 KBP slot filling assessment results (Ellis et al., 2012).", "startOffset": 199, "endOffset": 219}, {"referenceID": 19, "context": "As summarized in Table 2, we use a 6-word window to extract context features for each entity mention, apply the Stanford CoreNLP tool (Manning et al., 2014) to generate entity mentions and get POS tags for both datasets.", "startOffset": 134, "endOffset": 156}, {"referenceID": 2, "context": "Brown clusters(Brown et al., 1992) are derived for each corpus using public implementation2.", "startOffset": 14, "endOffset": 34}, {"referenceID": 28, "context": "For domain-specific patterns, we manually design a number of labeling functions3; for knowledge base, annotations are generated following the procedure in (Ren et al., 2016; Riedel et al., 2010).", "startOffset": 155, "endOffset": 194}, {"referenceID": 29, "context": "For domain-specific patterns, we manually design a number of labeling functions3; for knowledge base, annotations are generated following the procedure in (Ren et al., 2016; Riedel et al., 2010).", "startOffset": 155, "endOffset": 194}, {"referenceID": 18, "context": "FIGER (Ling and Weld, 2012) adopts multi-label learning with Perceptron algorithm.", "startOffset": 6, "endOffset": 27}, {"referenceID": 4, "context": "BFK (Bunescu and Mooney, 2005) applies bag-offeature kernel to train a support vector machine;", "startOffset": 4, "endOffset": 30}, {"referenceID": 21, "context": "DSL (Mintz et al., 2009) trains a multi-class logistic classifier4 on the training data;", "startOffset": 4, "endOffset": 24}, {"referenceID": 13, "context": "MultiR (Hoffmann et al., 2011) models training label noise by multi-instance multi-label learning;", "startOffset": 7, "endOffset": 30}, {"referenceID": 11, "context": "FCM (Gormley et al., 2015) performs compositional embedding by neural language model.", "startOffset": 4, "endOffset": 26}, {"referenceID": 28, "context": "CoType-RM (Ren et al., 2016) adopts partial-label loss to handle label noise and train the extractor.", "startOffset": 10, "endOffset": 28}, {"referenceID": 25, "context": "Alternatively, a true label discovery method, Investment (Pasternack and Roth, 2010), is applied to resolve conflicts, which is based on the source consistency assumption and iteratively updates inferred true labels and label functions\u2019 reliabilities.", "startOffset": 57, "endOffset": 84}, {"referenceID": 4, "context": "For relation classification task, which excludes None type from training / testing, we use the classification accuracy (Acc) for evaluation, and for relation extraction task, precision (Prec), recall (Rec) and F1 score (Bunescu and Mooney, 2005; Bach and Badaskar, 2007) are employed.", "startOffset": 219, "endOffset": 270}, {"referenceID": 0, "context": "For relation classification task, which excludes None type from training / testing, we use the classification accuracy (Acc) for evaluation, and for relation extraction task, precision (Prec), recall (Rec) and F1 score (Bunescu and Mooney, 2005; Bach and Badaskar, 2007) are employed.", "startOffset": 219, "endOffset": 270}, {"referenceID": 1, "context": "in sentence-level (Bao et al., 2014).", "startOffset": 18, "endOffset": 36}, {"referenceID": 3, "context": "To alleviate the dependency of annotations given by human experts, weak supervision (Bunescu and Mooney, 2007; Etzioni et al., 2004) and distant supervision (Ren et al.", "startOffset": 84, "endOffset": 132}, {"referenceID": 9, "context": "To alleviate the dependency of annotations given by human experts, weak supervision (Bunescu and Mooney, 2007; Etzioni et al., 2004) and distant supervision (Ren et al.", "startOffset": 84, "endOffset": 132}, {"referenceID": 28, "context": ", 2004) and distant supervision (Ren et al., 2016) have been employed to automatically generate annotations based on knowledge base (or seed patterns/instances).", "startOffset": 32, "endOffset": 50}, {"referenceID": 20, "context": "Word embedding has demonstrated great potential in capturing semantic meaning (Mikolov et al., 2013), and achieved great success in a wide range of NLP tasks like relation extraction (Zeng et al.", "startOffset": 78, "endOffset": 100}, {"referenceID": 36, "context": ", 2013), and achieved great success in a wide range of NLP tasks like relation extraction (Zeng et al., 2014; Takase and Inui, 2016; Nguyen and Grishman, 2015).", "startOffset": 90, "endOffset": 159}, {"referenceID": 32, "context": ", 2013), and achieved great success in a wide range of NLP tasks like relation extraction (Zeng et al., 2014; Takase and Inui, 2016; Nguyen and Grishman, 2015).", "startOffset": 90, "endOffset": 159}, {"referenceID": 24, "context": ", 2013), and achieved great success in a wide range of NLP tasks like relation extraction (Zeng et al., 2014; Takase and Inui, 2016; Nguyen and Grishman, 2015).", "startOffset": 90, "endOffset": 159}, {"referenceID": 16, "context": "True label discovery methods have been developed to resolve conflicts among multi-source information (Li et al., 2016; Zhao et al., 2012; Zhi et al., 2015).", "startOffset": 101, "endOffset": 155}, {"referenceID": 37, "context": "True label discovery methods have been developed to resolve conflicts among multi-source information (Li et al., 2016; Zhao et al., 2012; Zhi et al., 2015).", "startOffset": 101, "endOffset": 155}, {"referenceID": 38, "context": "True label discovery methods have been developed to resolve conflicts among multi-source information (Li et al., 2016; Zhao et al., 2012; Zhi et al., 2015).", "startOffset": 101, "endOffset": 155}, {"referenceID": 35, "context": "Besides data programming, socratic learning (Varma et al., 2016) has been developed to conduct binary classification under heterogeneous supervision.", "startOffset": 44, "endOffset": 64}], "year": 2017, "abstractText": "Relation extraction is a fundamental task in information extraction. Most existing methods have heavy reliance on annotations labeled by human experts, which are costly and time-consuming. To overcome this drawback, we propose a novel framework, REHESSION, to conduct relation extractor learning using annotations from heterogeneous information source, e.g., knowledge base and domain heuristics. These annotations, referred as heterogeneous supervision, often conflict with each other, which brings a new challenge to the original relation extraction task: how to infer the true label from noisy labels for a given instance. Identifying context information as the backbone of both relation extraction and true label discovery, we adopt embedding techniques to learn the distributed representations of context, which bridges all components with mutual enhancement in an iterative fashion. Extensive experimental results demonstrate the superiority of REHESSION over the state-of-the-art.", "creator": "LaTeX with hyperref package"}}}