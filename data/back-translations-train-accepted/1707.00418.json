{"id": "1707.00418", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jul-2017", "title": "Learning Deep Latent Spaces for Multi-Label Classification", "abstract": "Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.", "histories": [["v1", "Mon, 3 Jul 2017 06:37:01 GMT  (611kb,D)", "http://arxiv.org/abs/1707.00418v1", "published in AAAI-2017"]], "COMMENTS": "published in AAAI-2017", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chih-kuan yeh", "wei-chieh wu", "wei-jen ko", "yu-chiang frank wang"], "accepted": true, "id": "1707.00418"}, "pdf": {"name": "1707.00418.pdf", "metadata": {"source": "CRF", "title": "Learning Deep Latent Spaces for Multi-Label Classification", "authors": ["Chih-Kuan Yeh", "Wei-Chieh Wu", "Wei-Jen Ko", "Yu-Chiang Frank Wang"], "emails": ["jason6582@gmail.com,", "b01901162}@ntu.edu.tw,", "ycwang@citi.sinica.edu.tw"], "sections": [{"heading": "Introduction", "text": "In recent years, it has been shown that the different types of objects in an image are not only a real system, but also a real system that is able to identify and define itself. Thus, for example, it is necessary to distinguish the different types of objects in different categories from each other. (For example, that there is only one label that has its own designation for each individual image), that the different types of classification usually require additional efforts to identify and describe the associated data / labels in order to provide satisfactory services. (For example, that the individual labels must be divided into different categories for each individual image). (For the other, that the individual labels must be divided into different categories, it is necessary to find a simple technique and a solution that is used by users in related areas.) But in addition to the high costs, such techniques cannot be identified as regards the correlation between the labels and the individual labels for the fourth, fourth, fourth and fourth (for the second, third, third, third, fourth and fourth) and fourth time."}, {"heading": "Related Work", "text": "While binary relevance (Tsoumakas and Katakis 2006) is one of the most popular techniques of multi-label classification, the lack of sufficient ability to detect interdependencies between labels is its affair.Approaches based on classification chains have been proposed to address the above problem; while the search for probabilistic classification chains (PCC) aim to detect conditional label dependencies using the product rule of probabilities (Cheng, Hu \ufffd llermeier and Dembczynski 2010); while the search for beam beam beam (Kumar et al. 2013) and the advanced inference process (Dembczynski, Waegeman, and Hu \ufffd llermeier 2012) have broadened the ability of labels with respect to PCC, these approaches are typically compatibly expensive and cannot easily be extended to problems with a large number of label components. Multilabel embedding (another) strategy is popular."}, {"heading": "Our Proposed Method", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Canonical-Correlated Autoencoder (C2AE)", "text": "Let's call D = {(xi, yi)} Ni = {X, Y} a series of d-dimensional training instances X-IRd \u00b7 N and the associated labels Y-IRd \u00b7 N, where N and m are the number of instances and label attributes. By observing D, the goal of multi-label classification is to derive a proper learning model so that the labels y instance x-N can be predicted accordingly. Motivated by label embedding and the latest developments in deep learning, we propose a novel DNN architecture of the Canonical-Correlated Autoencode (C2AE), as illustrated in Figure 1. Our C2AE uses the Deep Canonical Correlation Analysis (DCCA) and the auto-code structures that learn a latent subspace of both feature and label domains for multi-label classification."}, {"heading": "Learning Deep Latent Spaces for Joint Feature & Label Embedding", "text": "For the sake of completeness, let us first briefly consider the ideas of CCA and DCCA (Hotelling 1936; Andrew et al. 2013; Wang et al. 2015).As a standard statistical technique for linking crossdomain data (e.g., input feature data X and their label data Y), CCA determines linear projection matrices W1 and W2 for each domain aimed at observing a subspace in which the correlation of the projected data is maximized (i.e., input feature data X and its label data Y).With the two linear projection matrices W1 and W2 for each domain, the correlation of the projected data is maximized (i.e.).Fu The version of FT1 X, W T 2, Y, W 2."}, {"heading": "Learning and Recovering Label-Correlated Outputs", "text": "For the first time in the history of the world, the world has seen the emergence of a new generation of women in the field of women's football, with the rise of women's football, the rise of women's football, the rise of women's football, the rise of women's football, the rise of men's football, the rise of women's football, the rise of women's football, the rise of women's football, the rise of women's football, the rise of women's football, the rise of women's football, the rise of men's football, the rise of women's football, the rise of men's football, the rise of women's football, the rise of men's football, the rise of women's football, the rise of men's football, the rise of women's football, the rise of men's football, the rise of men's football, the rise of women's football, the rise of men's football, the rise of women's football, the rise of men's football, the rise of women's football, the rise of women's football, the rise of men's football, the rise of men's football, the rise of women's football, the rise of men's football, the rise of women's football."}, {"heading": "Optimization", "text": "To learn the model of C2AE, we have to solve the optimization problem of (1), in which the loss concepts (Fx, Fe) and (Fe, Fd) are calculated at the latent space and in the output of C2AE. Similar to the derivation of existing DNN models, we apply the technique of gradient derivation for each loss conception to update the corresponding network parameters. As shown in Figure 1, the gradient of (Fx, Fe) updates the function of Fx ji and the coding of Fe, while that of Fe, Fd) updates both the coding of Fe and the decoding functions of Fd.To calculate the gradient conception of Fx, Fe, we reformulate the (2) with the help of lagrange multipliers."}, {"heading": "Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Datasets and Settings", "text": "To evaluate the performance of our proposed method, we consider the following datasets for experiments: iaprtc12, ESPGame, mirflickr, tmc2007, and NUS-WIDE. The first three datasets are image datasets used in (Guillaumin et al. 2009), where 1000-dimensional labeling methods (based on SIFT) are evaluated. We point out that tmc2007 is a large-format text dataset used by Mulan (Tsoumakas et al. 2011), and NUS-WIDE is a large-format image dataset typically used for image annotation tasks. The details of each dataset are listed in Table 1. for NUS-WIDE, we follow the setting of (Gong et al. 2013) by selecting the instances without positive labels and randomly selected 150,000 instances for training and remaining testing procedures."}, {"heading": "Comparisons with DNN-based Approaches", "text": "We continue to compare our C2AE with the most recent DNN-based methods for multi-label classification. In addition to a basic DNN method (as a deep version of binary relevance with the loss function of BCE (Nam et al. 2014) and BP-MLL (Zhang et al. 2016), we have (1) WARP (Gong et al. 2013), which is a CNN network with the WARP loss function, and (2) CNN-RNN (Wang et al. 2016), which is a state-of-the-art DNN that combines CNN and RNN for multi-label prediction. NUS-WIDE's large-scale image annotation datasets are used for evaluation and comparisons. As previously mentioned, for fair comparative purposes, we extract 4096-dimensional fc7 characteristics from NUS-WIDE, with NUS-WIDE characteristics pre-classified by C2DE using a network tractor as AlexNet and Hint Critical for 2012)."}, {"heading": "Performance Evaluation with Missing Labels", "text": "To conduct the experiments, we vary the error rate of the labels from 10% to 50%, while enforcing at least one positive label for each instance that needs to be preserved. Three state-of-the-art approaches are currently being considered: (1) LEML, (2) Multi-Label Learning with Missing Labels Using a Mixed Graph (ML-PGD) (Wu, Lyu and Ghanem 2015) and (3) ML-MG (i.e. Multi-Label Learning with Missing Labels Using a Mixed Graph (ML-PGD)) (Wu, Lyu and Ghanem 2015). We show the performance comparisons in Figure 4, where our C2AE performs consistently and remarkably compared to other approaches. It is worth noting that existing solutions typically learn linear regressors as predictors, requiring additional regulatory measures to handle missing labels. Our C2E conducts a consistent review of the effectiveness of the above labels to determine their effectiveness and their effectiveness."}, {"heading": "Conclusion", "text": "We suggested Canonical Correlated Autoencoder (C2AE) to solve the task of multi-label classification. By uniquely integrating DCCA and autoencoder into a unified DNN model, we are able to perform common feature and label embedding to link such cross-domain data with each other. By introducing label correlation-sensitive loss functions at the outputs of C2AE, the additional ability to exploit cross-label dependencies is further introduced into our learning model. In the experiments, we demonstrated that our C2AE not only performs favorably compared to basic and state-of-the-art methods on multiple data sets, but that our C2AE is also easily applicable for learning tasks with different number of missing labels, thus successfully verifying the effectiveness and robustness of our proposed method."}, {"heading": "Acknowledgements", "text": "This work was partially supported by the Taiwanese Ministry of Science and Technology under the auspices of MOST105-2221-E001-028-MY2."}], "references": [{"title": "J", "author": ["G. Andrew", "R. Arora", "Bilmes"], "venue": "A.; and Livescu, K.", "citeRegEx": "Andrew et al. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Lebanon", "author": ["K. Balasubramanian"], "venue": "G.", "citeRegEx": "Balasubramanian and Lebanon 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Sparse local embeddings for extreme multi-label classification", "author": ["Bhatia"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bhatia,? \\Q2015\\E", "shortCiteRegEx": "Bhatia", "year": 2015}, {"title": "J", "author": ["W. Bi", "Kwok"], "venue": "T.-Y.", "citeRegEx": "Bi and Kwok 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Lin", "author": ["Chen", "Y.-N."], "venue": "H.-T.", "citeRegEx": "Chen and Lin 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "K", "author": ["W. Cheng", "E. H\u00fcllermeier", "Dembczynski"], "venue": "J.", "citeRegEx": "Cheng. H\u00fcllermeier. and Dembczynski 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "An analysis of chaining in multi-label classification", "author": ["Waegeman Dembczynski", "K. H\u00fcllermeier 2012] Dembczynski", "W. Waegeman", "E. H\u00fcllermeier"], "venue": null, "citeRegEx": "Dembczynski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dembczynski et al\\.", "year": 2012}, {"title": "and Lin", "author": ["Ferng", "C.-S."], "venue": "H.-T.", "citeRegEx": "Ferng and Lin 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep convolutional ranking for multilabel image annotation", "author": ["Gong"], "venue": "arXiv preprint arXiv:1312.4894", "citeRegEx": "Gong,? \\Q2013\\E", "shortCiteRegEx": "Gong", "year": 2013}, {"title": "Tagprop: Discriminative metric learning in nearest neighbor models for image autoannotation", "author": ["Guillaumin"], "venue": "IEEE 12th international conference on computer vision,", "citeRegEx": "Guillaumin,? \\Q2009\\E", "shortCiteRegEx": "Guillaumin", "year": 2009}, {"title": "Multi-label prediction via compressed sensing", "author": ["Hsu"], "venue": "In NIPS,", "citeRegEx": "Hsu,? \\Q2009\\E", "shortCiteRegEx": "Hsu", "year": 2009}, {"title": "J", "author": ["Kettenring"], "venue": "R.", "citeRegEx": "Kettenring 1971", "shortCiteRegEx": null, "year": 1971}, {"title": "G", "author": ["A. Krizhevsky", "I. Sutskever", "Hinton"], "venue": "E.", "citeRegEx": "Krizhevsky. Sutskever. and Hinton 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "A", "author": ["A. Kumar", "S. Vembu", "Menon"], "venue": "K.; and Elkan, C.", "citeRegEx": "Kumar et al. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Guo", "author": ["X. Li"], "venue": "Y.", "citeRegEx": "Li and Guo 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Large-scale multi-label text classificationrevisiting neural networks", "author": ["Nam"], "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Nam,? \\Q2014\\E", "shortCiteRegEx": "Nam", "year": 2014}, {"title": "Classifier chains for multi-label classification. Machine learning 85(3):333\u2013359", "author": ["Read"], "venue": null, "citeRegEx": "Read,? \\Q2011\\E", "shortCiteRegEx": "Read", "year": 2011}, {"title": "and Lin", "author": ["F. Tai"], "venue": "H.-T.", "citeRegEx": "Tai and Lin 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "V", "author": ["L. Tang", "S. Rajan", "Narayanan"], "venue": "K.", "citeRegEx": "Tang. Rajan. and Narayanan 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "and Katakis", "author": ["G. Tsoumakas"], "venue": "I.", "citeRegEx": "Tsoumakas and Katakis 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "Mulan: A java library for multi-label learning", "author": ["Tsoumakas"], "venue": "Journal of Machine Learning Research 12(Jul):2411\u20132414", "citeRegEx": "Tsoumakas,? \\Q2011\\E", "shortCiteRegEx": "Tsoumakas", "year": 2011}, {"title": "Random k-labelsets for multilabel classification", "author": ["Katakis Tsoumakas", "G. Vlahavas 2011] Tsoumakas", "I. Katakis", "I. Vlahavas"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "Tsoumakas et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tsoumakas et al\\.", "year": 2011}, {"title": "On deep multi-view representation learning", "author": ["Wang"], "venue": "In Proc. of the 32st Int. Conf. Machine Learning", "citeRegEx": "Wang,? \\Q2015\\E", "shortCiteRegEx": "Wang", "year": 2015}, {"title": "Cnn-rnn: A unified framework for multi-label image classification", "author": ["Wang"], "venue": "arXiv preprint arXiv:1604.04573", "citeRegEx": "Wang,? \\Q2016\\E", "shortCiteRegEx": "Wang", "year": 2016}, {"title": "Cnn: Single-label to multilabel", "author": ["Wei"], "venue": "arXiv preprint arXiv:1406.5726", "citeRegEx": "Wei,? \\Q2014\\E", "shortCiteRegEx": "Wei", "year": 2014}, {"title": "Multi-label learning with missing labels", "author": ["Wu"], "venue": "In ICPR,", "citeRegEx": "Wu,? \\Q2014\\E", "shortCiteRegEx": "Wu", "year": 2014}, {"title": "Ml-mg: Multi-label learning with missing labels using a mixed graph", "author": ["Lyu Wu", "B. Ghanem 2015] Wu", "S. Lyu", "B. Ghanem"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision,", "citeRegEx": "Wu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2015}, {"title": "I", "author": ["H.-F. Yu", "P. Jain", "P. Kar", "Dhillon"], "venue": "S.", "citeRegEx": "Yu et al. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "and Schneider", "author": ["Y. Zhang"], "venue": "J.", "citeRegEx": "Zhang and Schneider 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "and Zhou", "author": ["Zhang", "M.-L."], "venue": "Z.-H.", "citeRegEx": "Zhang and Zhou 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "and Zhou", "author": ["Zhang", "M.-L."], "venue": "Z.-H.", "citeRegEx": "Zhang and Zhou 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Compressed labeling on distilled labelsets for multilabel learning. Machine Learning 88(1-2):69\u2013126", "author": ["Tao Zhou", "T. Wu 2012] Zhou", "D. Tao", "X. Wu"], "venue": null, "citeRegEx": "Zhou et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2012}], "referenceMentions": [], "year": 2017, "abstractText": "Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.", "creator": "LaTeX with hyperref package"}}}