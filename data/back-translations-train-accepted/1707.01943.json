{"id": "1707.01943", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jul-2017", "title": "A causal framework for explaining the predictions of black-box sequence-to-sequence models", "abstract": "We interpret the predictions of any black-box structured input-structured output model around a specific input-output pair. Our method returns an \"explanation\"' consisting of groups of input-output tokens that are causally related. Our method infers these dependencies by querying the model with perturbed inputs, generating a graph over tokens from the responses, and solving a partitioning problem to select the most relevant components. We focus the general approach on sequence-to-sequence problems, adopting a variational autoencoder to yield meaningful input perturbations. We test our method across several NLP sequence generation tasks.", "histories": [["v1", "Thu, 6 Jul 2017 19:36:43 GMT  (394kb,D)", "https://arxiv.org/abs/1707.01943v1", "EMNLP 2017"], ["v2", "Tue, 25 Jul 2017 16:31:23 GMT  (223kb,D)", "http://arxiv.org/abs/1707.01943v2", "12 Pages, EMNLP 2017"]], "COMMENTS": "EMNLP 2017", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["david alvarez-melis", "tommi s jaakkola"], "accepted": true, "id": "1707.01943"}, "pdf": {"name": "1707.01943.pdf", "metadata": {"source": "CRF", "title": "A causal framework for explaining the predictions of black-box sequence-to-sequence models", "authors": ["David Alvarez-Melis"], "emails": ["tommi}@csail.mit.edu"], "sections": [{"heading": null, "text": "Our method provides an \"explanation,\" consisting of groups of causally related input-output tokens. These dependencies are inferred by querying the black box model with disrupted inputs, generating a diagram of tokens from the answers, and solving a partitioning problem to select the most relevant components. We focus the general approach on sequence sequence problems by using a varying autoencoder to generate meaningful input disturbances. We test our method across multiple tasks to generate NLP sequences."}, {"heading": "1 Introduction", "text": "This year, it is only a matter of time before we reach an agreement."}, {"heading": "2 Related Work", "text": "There is a broad spectrum of work that spans various areas around the notion of \"interpretative ability,\" but this term is underdefined, so the goals, methods and formalities of these approaches are often not overlapping (Lipton, 2016). In the context of machine learning, perhaps the most visible line of work focuses on medical applications (Caruana et al., 2015), where trust can be a determining factor in whether a model is used or not. With the ever-growing success and popularity of deep learning methods for image processing, the most recent work has focused on the interpretative ability in this context and usually requires access to the activations and gradations of the method (Selvaraju et al., 2016), or directly modelling how the influence spreads (Bachet., 2015). For a broad overview of the interpretative ability in machine learning, refer to the recent study by Doshi-Velez and Kim."}, {"heading": "3 Interpreting structured prediction", "text": "This year, it has come to the point where it will be able to take the lead, at a time when it is not as far away as it was in the first one, when it is not so far away."}, {"heading": "4 Building blocks", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Perturbation Model", "text": "The first step in our approach is to obtain disturbed versions of the input: semantically similar to the original, but with potential changes in the elements and their order. This is a major challenge with any structured input. We propose to do this with a varying autoencoder (UAE) (Kingma and Welling, 2014; Rezende et al., 2014). UAEs have been successfully used with fixed dimensional inputs such as images (Rezende and Mohamed, 2015; S\u00f8nderby et al., 2016) and recently adapted to generate sentences from continuous representations (Bowman et al., 2016). The goal is to introduce the disturbance in the continuous latent representation, rather than directly on the structured input.A VAE is composed of a probabilistic encoder ENC: X \u2192 Rd and a decoder DEC: Rd \u2192 X."}, {"heading": "4.2 Causal model", "text": "The second step is to use the disrupted input-output pairs {(x > i, y > i)} Ni = 1 to derive causal dependencies between the original input and output tokens. A naive approach would take into account 2x2 contingency tables that represent the presence / absence of input / output tokens along with test statistics to assess their dependence. Instead, we include all input and output tokens simultaneously to predict the occurrence of a single output token using logistic regression. The quality of these dependency estimates depends on the frequency with which each input and output token occurs in the perturbations. Therefore, we are interested in obtaining uncertainty estimates for these predictions, which can, of course, be performed using a Bayesian approach to logistic regression. Let x (x) (x, 1} | x | be the original tokens, which will be a handy vector of the x | 1."}, {"heading": "4.3 Explanation Selection", "text": "The final step in our interpretation framework consists of selecting a series of explanations for (x, y), which so far result in a dense two-part diagram between the input and output tokens, unless this graph itself is not sufficiently interpretable. We are interested in selecting the relevant components of this dependency diagram, i.e., dividing the vertex number of G into subsets to minimize the weight of the omitted edges (i.e. the k-cut value of the partition).Graph The division is a well-studied NPcomplete problem (Garey et al., 1976). The usual setting assumes deterministic edge weights, but in our case we are interested in including the uncertainty of the dependency estimates - as a result of their finite sample estimation - in the partition problem."}, {"heading": "5 Experimental Framework", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Training and optimization", "text": "For experiments with typesetting, we train the VAE described in Section 4.1 in advance. We use symmetrical encoder decoders that consist of recurrent neural networks with a middle layer of variation. However, in our case, we use L stacked RNN on both sides and a stacked layer of variation. Formation of variation autoencoders for text is notoriously difficult. In addition to dropouts and KLD annealing (Bowman et al., 2016), we found that slow scaling of the variance sampled from the normal distribution makes the training much more stable. For the partitioning step, we compare the robust formulation described above with two classic approaches to two-part graph partitioning that do not take into account uncertainties: the co-cluster method by Dhillon (2001) and the two-part method by Kluger et al. (2003)."}, {"heading": "5.2 Recovering simple mappings", "text": "Before using our interpretation framework in real-world tasks where quantitative evaluation of explanations is difficult, we test it in a simplified framework where the \"black box\" is simple and fully known. A reasonable minimum expectation of our method is that it can derive many of these simple dependencies. To this end, we use the CMU Dictionary of word pronunciations, which is based on the ARPAbet symbol and consists of approximately 130K word-to-phoneme pairs. Phonemes are expressed as tokens of 1 to 3 characters."}, {"heading": "5.3 Machine Translation", "text": "In our second set of experiments, we evaluate our explanatory model in a relevant and popular explanation: there are three different methods of translation into English: (i) Azure's Machine Translation System, (i) a neuralism model, and (ii) a human who trains the two automatic systems, and we use the monolingual systems in the appendix. We translate the same sentences using all three methods, and explain their predictions using SOCRAT."}, {"heading": "5.4 A (mediocre) dialogue system", "text": "So far, we have used our method to explain (mostly) correct predictions of meaningful models, but we can also use it to gain insights into the workings of faulty black box systems. To test this, we are training a simple dialogue system on the OpenSubtitle corpus (Tiedemann, 2009), consisting of two two two-level film dialogs, each with 14M. As before, we are using a sequence-to-sequence model with attention, but now we are limiting the quality of the model by using only two layers, a hidden state dimension of 1000 and no hyperparameter adjustment.Input predictionWhat do you think it doesn't matter? I don't know if we may have met before? I don't think I can give you two cocktails. Table 2: \"Good\" dialog system predictions know. Which doctrine prediction doesn't matter?"}, {"heading": "5.5 Bias detection in parallel corpora", "text": "This year, the time has come for an agreement to be reached, and it will only take a few days."}, {"heading": "6 Discussion", "text": "Our model-agnostic framework for interpreting predictions with structured data can provide reasonable, conclusive, and often insightful explanations; the results of the machine translation task show how such a method provides partial insight into the inner workings of a black box system; and, finally, the results of the last two experiments also suggest potential for improving existing systems by questioning seemingly correct predictions and explaining those that are not; the method allows for several possible modifications; though we focused on sequence-to-text tasks, SOCRAT generalizes to other settings in which inputs and outputs can be expressed as attributes; and an interesting application would be to derive dependencies between text and image attributes in the picture-to-text prediction (e.g. captions)."}, {"heading": "Acknowledgments", "text": "We would like to thank the anonymous reviewers for their helpful suggestions for presentation and additional experiments and Dr. Chantal Melis for valuable feedback. DAM would like to thank for the support of a CONACYT scholarship and the cooperation between MIT and QCRI."}, {"heading": "A Formulation of graph partitioning with uncertainty", "text": "s say we want to divide U and V into K subsets, with each Ui having a cardinality in [cumin, c u max] and each Vj in [c v min, c v max]. Let us let Xuik be the binary indicator for the Ui edge, analogous to xvjk and vj. Furthermore, let us let Yij be a binary variable taking a value of 1 if ui, vj are in different corresponding subsets (i.e. the Ui edge of Vk and k 6 = k). We can express the limitations of the problem as follows: Y = K = 1 xvik = 1 xvik, k = 1 x."}, {"heading": "B Details on optimization and training", "text": "Since we are not interested in the exact value of partition costs, we can be satisfied with an approximate solution by loosening the optimum tolerance. We observed that the loosening of the absolute gap tolerance from the Gurobi requirement from 10 \u2212 12 to 10 \u2212 4 resulted in a small minimal change in the solutions and a reduction in the solution time by orders of magnitude. We added a 2-minute runtime limit for optimization, although we never reached this limit in all our experiments."}, {"heading": "C Details on the variational autoencoder", "text": "For all experiments in sections 5.3 to 5.5, we use the same variable autoencoder: a network with three-layer GRU encoder and decoder and a stacked three-layer variational autoencoder that connects the last hidden state of the encoder and the first hidden state of the decoder. We use a dimension 500 for the hidden states of the GRUs and 400 for the latent states. We train it on a 10M sentence subset of the English side of the WMT14 translation task, with KLD and Variance Annealing as described in the main text. We train for a full epoch without KLD penalty and without noise sequence (i.e. decoding directly from the middle vectormu) and begin Variance Annexation of the second epoch and KLD Annealing as described in the main text. We train for a full epoch without KLD penalty and without noise parameter sequence."}, {"heading": "D Black-box system specifications", "text": "The three systems used in the machine translation task in Section 5.3 are described below. Azures MT Service Via REST API calls Microsoft's translator text service, which is provided as part of Azure's cloud services.Neural MT System A sequence-to-sequence model with attention, which was trained with the OpenNMT library (Klein et al., 2017) on the English-German translation task set WMT15. A pre-trained model was obtained from http: / / www. opennmt.net / Models /. It has two layers, hidden state dimension 500, and was trained for 13 epochs. A person who speaks fluent English received the disrupted English sentences and asked to translate them into German in one go. No additional instructions or contexts were provided, except that in cases where the source sentence is not directly translatable, as far as possible."}], "references": [{"title": "On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation", "author": ["Sebastian Bach", "Alexander Binder", "Gr\u00e9goire Montavon", "Frederick Klauschen", "Klaus-Robert M\u00fcller", "Wojciech Samek."], "venue": "PLoS One,", "citeRegEx": "Bach et al\\.,? 2015", "shortCiteRegEx": "Bach et al\\.", "year": 2015}, {"title": "Neural Machine Translation By Jointly Learning To Align and Translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "Iclr 2015, pages 1\u201315.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings", "author": ["Tolga Bolukbasi", "Kai-Wei Chang", "James Zou", "Venkatesh Saligrama", "Adam Kalai."], "venue": "NIPS, (Nips):4349\u2014-4357.", "citeRegEx": "Bolukbasi et al\\.,? 2016", "shortCiteRegEx": "Bolukbasi et al\\.", "year": 2016}, {"title": "Generating Sentences from a Continuous Space", "author": ["Samuel R. Bowman", "Luke Vilnis", "Oriol Vinyals", "Andrew M. Dai", "Rafal Jozefowicz", "Samy Bengio."], "venue": "Iclr, pages 1\u201313.", "citeRegEx": "Bowman et al\\.,? 2016", "shortCiteRegEx": "Bowman et al\\.", "year": 2016}, {"title": "Semantics derived automatically from language corpora contain human-like biases", "author": ["Aylin Caliskan", "Joanna J Bryson", "Arvind Narayanan."], "venue": "Science (80-. )., 356(6334):183\u2013186.", "citeRegEx": "Caliskan et al\\.,? 2017", "shortCiteRegEx": "Caliskan et al\\.", "year": 2017}, {"title": "Intelligible Models for HealthCare : Predicting Pneumonia Risk and Hospital 30-day Readmission", "author": ["Rich Caruana", "Yin Lou", "Johannes Gehrke", "Paul Koch", "Marc Sturm", "Noemie Elhadad."], "venue": "Proc. 21th ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.", "citeRegEx": "Caruana et al\\.,? 2015", "shortCiteRegEx": "Caruana et al\\.", "year": 2015}, {"title": "Listen, attend and spell", "author": ["William Chan", "Navdeep Jaitly", "Quoc V. Le", "Oriol Vinyals."], "venue": "arXiv Prepr., pages 1\u201316.", "citeRegEx": "Chan et al\\.,? 2015", "shortCiteRegEx": "Chan et al\\.", "year": 2015}, {"title": "Co-clustering documents and words using Bipartite spectral graph partitioning", "author": ["Inderjit s. Dhillon."], "venue": "Proc 7th ACM SIGKDD Conf, pages 269\u2013274.", "citeRegEx": "Dhillon.,? 2001", "shortCiteRegEx": "Dhillon.", "year": 2001}, {"title": "A Roadmap for a Rigorous Science of Interpretability", "author": ["Finale Doshi-Velez", "Been Kim."], "venue": "ArXiv eprints, (Ml):1\u201312.", "citeRegEx": "Doshi.Velez and Kim.,? 2017", "shortCiteRegEx": "Doshi.Velez and Kim.", "year": 2017}, {"title": "Robust optimization of graph partitioning involving interval uncertainty", "author": ["Neng Fan", "Qipeng P. Zheng", "Panos M. Pardalos."], "venue": "Theor. Comput. Sci., volume 447, pages 53\u201361.", "citeRegEx": "Fan et al\\.,? 2012", "shortCiteRegEx": "Fan et al\\.", "year": 2012}, {"title": "Some simplified NP-complete graph problems", "author": ["M.R. Garey", "D.S. Johnson", "L. Stockmeyer."], "venue": "Theor. Comput. Sci., 1(3):237\u2013267.", "citeRegEx": "Garey et al\\.,? 1976", "shortCiteRegEx": "Garey et al\\.", "year": 1976}, {"title": "AutoEncoding Variational Bayes", "author": ["Diederik P Kingma", "Max Welling."], "venue": "Iclr, (Ml):1\u201314.", "citeRegEx": "Kingma and Welling.,? 2014", "shortCiteRegEx": "Kingma and Welling.", "year": 2014}, {"title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation", "author": ["G. Klein", "Y. Kim", "Y. Deng", "J. Senellert", "A.M. Rush."], "venue": "ArXiv e-prints.", "citeRegEx": "Klein et al\\.,? 2017", "shortCiteRegEx": "Klein et al\\.", "year": 2017}, {"title": "Spectral biclustering of microarray data: Coclustering genes and conditions", "author": ["Yuval Kluger", "Ronen Basri", "Joseph T. Chang", "Mark Gerstein"], "venue": null, "citeRegEx": "Kluger et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kluger et al\\.", "year": 2003}, {"title": "Rationalizing Neural Predictions", "author": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola."], "venue": "EMNLP 2016, Proc. 2016 Conf. Empir. Methods Nat. Lang. Process., pages 107\u2013117.", "citeRegEx": "Lei et al\\.,? 2016", "shortCiteRegEx": "Lei et al\\.", "year": 2016}, {"title": "The Mythos of Model Interpretability", "author": ["Zachary C Lipton."], "venue": "ICML Work. Hum. Interpret. Mach. Learn., (Whi).", "citeRegEx": "Lipton.,? 2016", "shortCiteRegEx": "Lipton.", "year": 2016}, {"title": "Machine Learning: A Probabilistic Perspective", "author": ["Kevin P. Murphy"], "venue": null, "citeRegEx": "Murphy.,? \\Q2012\\E", "shortCiteRegEx": "Murphy.", "year": 2012}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D J Rezende", "S Mohamed", "D Wierstra."], "venue": "Proc. 31st . . . , 32:1278\u20131286.", "citeRegEx": "Rezende et al\\.,? 2014", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Variational Inference with Normalizing Flows", "author": ["Danilo Jimenez Rezende", "Shakir Mohamed."], "venue": "Proc. 32nd Int. Conf. Mach. Learn., 37:1530\u20131538.", "citeRegEx": "Rezende and Mohamed.,? 2015", "shortCiteRegEx": "Rezende and Mohamed.", "year": 2015}, {"title": "Why Should I Trust You?\": Explaining the Predictions of Any Classifier", "author": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin."], "venue": "Proc. 22Nd ACM SIGKDD Int. Conf. Knowl. Discov. Data Min., KDD \u201916, pages 1135\u20131144, New York, NY,", "citeRegEx": "Ribeiro et al\\.,? 2016", "shortCiteRegEx": "Ribeiro et al\\.", "year": 2016}, {"title": "A Neural Attention Model for Abstractive Sentence Summarization", "author": ["Alexander M Rush", "Sumit Chopra", "Jason Weston."], "venue": "Proc. Conf. Empir. Methods Nat. Lang. Process., (September):379\u2013389.", "citeRegEx": "Rush et al\\.,? 2015", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization", "author": ["Ramprasaath R. Selvaraju", "Abhishek Das", "Ramakrishna Vedantam", "Michael Cogswell", "Devi Parikh", "Dhruv Batra."], "venue": "(Nips):1\u20135.", "citeRegEx": "Selvaraju et al\\.,? 2016", "shortCiteRegEx": "Selvaraju et al\\.", "year": 2016}, {"title": "Ladder Variational Autoencoders", "author": ["Casper Kaae S\u00f8nderby", "Tapani Raiko", "Lars Maal\u00f8e", "S\u00f8ren Kaae S\u00f8nderby", "Ole Winther."], "venue": "NIPS, (Nips).", "citeRegEx": "S\u00f8nderby et al\\.,? 2016", "shortCiteRegEx": "S\u00f8nderby et al\\.", "year": 2016}, {"title": "News from OPUS - A Collection of Multilingual Parallel Corpora with Tools and Interfaces", "author": ["J\u00f6rg Tiedemann."], "venue": "N. Nicolov, G. Bontcheva, G. Angelova, and R. Mitkov, editors, Recent Adv. Nat. Lang. Process., pages 237\u2014-248. John Benjamins,", "citeRegEx": "Tiedemann.,? 2009", "shortCiteRegEx": "Tiedemann.", "year": 2009}, {"title": "Efficient Word Alignment with Markov Chain Monte Carlo", "author": ["J\u00f6rg Tiedemann", "Robert \u00d6stling."], "venue": "Prague Bull. Math. Linguist., (106):125\u2013146.", "citeRegEx": "Tiedemann and \u00d6stling.,? 2016", "shortCiteRegEx": "Tiedemann and \u00d6stling.", "year": 2016}], "referenceMentions": [{"referenceID": 1, "context": "While such systems achieve state-of-the-art results in MT (Bahdanau et al., 2014), summarization (Rush et al.", "startOffset": 58, "endOffset": 81}, {"referenceID": 20, "context": ", 2014), summarization (Rush et al., 2015) and speech recognition (Chan et al.", "startOffset": 23, "endOffset": 42}, {"referenceID": 6, "context": ", 2015) and speech recognition (Chan et al., 2015), they remain largely uninterpretable, although attention mechanisms (Bahdanau et al.", "startOffset": 31, "endOffset": 50}, {"referenceID": 1, "context": ", 2015), they remain largely uninterpretable, although attention mechanisms (Bahdanau et al., 2014) can shed some light on how they operate.", "startOffset": 76, "endOffset": 99}, {"referenceID": 19, "context": "A slightly less obvious application concerns model improvement (Ribeiro et al., 2016) where interpretability can be used to detect biases in the methods.", "startOffset": 63, "endOffset": 85}, {"referenceID": 14, "context": "(Lei et al., 2016)).", "startOffset": 0, "endOffset": 18}, {"referenceID": 19, "context": "Following (Ribeiro et al., 2016), we turn the local behavior of the model around the given input into an interpretable representation of its operation.", "startOffset": 10, "endOffset": 32}, {"referenceID": 15, "context": "This term, however, is underdetermined, so the goals, methods and formalisms of these approaches are often non-overlapping (Lipton, 2016).", "startOffset": 123, "endOffset": 137}, {"referenceID": 5, "context": "In the context of machine learning, perhaps the most visible line of work on interpretability focuses on medical applications (Caruana et al., 2015), where trust can be a decisive factor on whether a model is used or not.", "startOffset": 126, "endOffset": 148}, {"referenceID": 21, "context": "With the ever-growing success and popularity of deep learning methods for image processing, recent work has addressed interpretability in this setting, usually requiring access to the method\u2019s activations and gradients (Selvaraju et al., 2016), or directly modeling how influence propagates (Bach et al.", "startOffset": 219, "endOffset": 243}, {"referenceID": 0, "context": ", 2016), or directly modeling how influence propagates (Bach et al., 2015).", "startOffset": 55, "endOffset": 74}, {"referenceID": 0, "context": ", 2016), or directly modeling how influence propagates (Bach et al., 2015). For a broad overview of interpretability in machine learning, we refer the reader to the recent survey by Doshi-Velez and Kim (2017).", "startOffset": 56, "endOffset": 209}, {"referenceID": 14, "context": "Most similar to this work are the approaches of Lei et al. (2016) and Ribeiro et al.", "startOffset": 48, "endOffset": 66}, {"referenceID": 14, "context": "Most similar to this work are the approaches of Lei et al. (2016) and Ribeiro et al. (2016). The former proposes a model that justifies its predictions in terms of fragments of the input.", "startOffset": 48, "endOffset": 92}, {"referenceID": 14, "context": "Most similar to this work are the approaches of Lei et al. (2016) and Ribeiro et al. (2016). The former proposes a model that justifies its predictions in terms of fragments of the input. This approach formulates explanation generation as part of the learning problem, and, as most previous work, only deals with the case where predictions are scalar or categorical. On the other hand, Ribeiro et al. (2016) propose a framework for explaining the predictions of black-box classifiers by means of locally-faithful interpretable models.", "startOffset": 48, "endOffset": 408}, {"referenceID": 19, "context": "Second, while our approach shares the locality and model-agnostic view of Ribeiro et al. (2016), generating perturbed versions of structured objects is a challenging task by itself.", "startOffset": 74, "endOffset": 96}, {"referenceID": 8, "context": "A good explanation would ideally also decompose into cognitive chunks (Doshi-Velez and Kim, 2017): basic units of explanation which are a priori bounded in size.", "startOffset": 70, "endOffset": 97}, {"referenceID": 19, "context": "Following (Ribeiro et al., 2016), we seek explanations via interpretable representations that are both i) locally faithful, in the sense that they approximate how the model behaves in the vicinity of x, and ii) model agnostic, that is, that do not require any knowledge ofF .", "startOffset": 10, "endOffset": 32}, {"referenceID": 11, "context": "We propose to do this using a variational autoencoder (VAE) (Kingma and Welling, 2014; Rezende et al., 2014).", "startOffset": 60, "endOffset": 108}, {"referenceID": 17, "context": "We propose to do this using a variational autoencoder (VAE) (Kingma and Welling, 2014; Rezende et al., 2014).", "startOffset": 60, "endOffset": 108}, {"referenceID": 18, "context": "VAEs have been successfully used with fixed dimensional inputs such as images (Rezende and Mohamed, 2015; S\u00f8nderby et al., 2016) and recently also adapted to generating sentences from continuous representations (Bowman et al.", "startOffset": 78, "endOffset": 128}, {"referenceID": 22, "context": "VAEs have been successfully used with fixed dimensional inputs such as images (Rezende and Mohamed, 2015; S\u00f8nderby et al., 2016) and recently also adapted to generating sentences from continuous representations (Bowman et al.", "startOffset": 78, "endOffset": 128}, {"referenceID": 3, "context": ", 2016) and recently also adapted to generating sentences from continuous representations (Bowman et al., 2016).", "startOffset": 90, "endOffset": 111}, {"referenceID": 16, "context": "We use a Gaussian approximation for the logarithm of the logistic function together with the prior p(\u03b8) = N (\u03b80,H 0 ) (Murphy, 2012).", "startOffset": 118, "endOffset": 132}, {"referenceID": 10, "context": "Graph partitioning is a well studied NPcomplete problem (Garey et al., 1976).", "startOffset": 56, "endOffset": 76}, {"referenceID": 9, "context": "For this, we rely on the approach of Fan et al. (2012) designed for interval estimates of edge weights.", "startOffset": 37, "endOffset": 55}, {"referenceID": 3, "context": "In addition to dropout and KLD annealing (Bowman et al., 2016), we found that slowly scaling the variance sampled from the normal distribution from 0 to 1 made training much more stable.", "startOffset": 41, "endOffset": 62}, {"referenceID": 7, "context": "For the partitioning step we compare the robust formulation described above with two classical approaches to bipartite graph partitioning which do not take uncertainty into account: the coclustering method of Dhillon (2001) and the biclustering method of Kluger et al.", "startOffset": 209, "endOffset": 224}, {"referenceID": 7, "context": "For the partitioning step we compare the robust formulation described above with two classical approaches to bipartite graph partitioning which do not take uncertainty into account: the coclustering method of Dhillon (2001) and the biclustering method of Kluger et al. (2003). For these two, we use off-the-shelf implementations,1 while we solve the MIP problem version of (2) with the optimization library gurobi.", "startOffset": 209, "endOffset": 276}, {"referenceID": 24, "context": "To provide a point of reference, we compare against a (strong) baseline that is tailored to such a task: a state-of-theart unsupervised word alignment method based on Monte Carlo inference (Tiedemann and \u00d6stling, 2016).", "startOffset": 189, "endOffset": 218}, {"referenceID": 23, "context": "To test this, we train a simple dialogue system on the OpenSubtitle corpus (Tiedemann, 2009), consisting of \u223c14M two-step movie dialogues.", "startOffset": 75, "endOffset": 92}, {"referenceID": 4, "context": "Natural language processing methods that derive semantics from large corpora have been shown to incorporate biases present in the data, such as archaic stereotypes of male/female occupations (Caliskan et al., 2017) and sexist adjective associations (Bolukbasi et al.", "startOffset": 191, "endOffset": 214}, {"referenceID": 2, "context": ", 2017) and sexist adjective associations (Bolukbasi et al., 2016).", "startOffset": 42, "endOffset": 66}, {"referenceID": 2, "context": "We choose sentences containing occupations and adjectives previously shown to exhibit gender biases in linguistic corpora (Bolukbasi et al., 2016).", "startOffset": 122, "endOffset": 146}], "year": 2017, "abstractText": "We interpret the predictions of any blackbox structured input-structured output model around a specific input-output pair. Our method returns an \u201cexplanation\u201d consisting of groups of input-output tokens that are causally related. These dependencies are inferred by querying the black-box model with perturbed inputs, generating a graph over tokens from the responses, and solving a partitioning problem to select the most relevant components. We focus the general approach on sequence-tosequence problems, adopting a variational autoencoder to yield meaningful input perturbations. We test our method across several NLP sequence generation tasks.", "creator": "LaTeX with hyperref package"}}}