{"id": "1707.04314", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jul-2017", "title": "Bayesian Optimization for Probabilistic Programs", "abstract": "We present the first general purpose framework for marginal maximum a posteriori estimation of probabilistic program variables. By using a series of code transformations, the evidence of any probabilistic program, and therefore of any graphical model, can be optimized with respect to an arbitrary subset of its sampled variables. To carry out this optimization, we develop the first Bayesian optimization package to directly exploit the source code of its target, leading to innovations in problem-independent hyperpriors, unbounded optimization, and implicit constraint satisfaction; delivering significant performance improvements over prominent existing packages. We present applications of our method to a number of tasks including engineering design and parameter optimization.", "histories": [["v1", "Thu, 13 Jul 2017 20:49:29 GMT  (7064kb,D)", "http://arxiv.org/abs/1707.04314v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.PL stat.CO", "authors": ["tom rainforth", "tuan anh le", "jan-willem van de meent", "michael a osborne", "frank wood"], "accepted": true, "id": "1707.04314"}, "pdf": {"name": "1707.04314.pdf", "metadata": {"source": "CRF", "title": "Bayesian Optimization for Probabilistic Programs\u2217", "authors": ["Tom Rainforth", "Tuan Anh Le", "Jan-Willem van de Meent", "Frank Wood"], "emails": ["TWGR@ROBOTS.OX.AC.UK", "TUANANH@ROBOTS.OX.AC.UK", "J.VANDEMEENT@NORTHEASTERN.EDU", "MOSB@ROBOTS.OX.AC.UK", "FWOOD@ROBOTS.OX.AC.UK"], "sections": [{"heading": "1. Introduction", "text": "It is also possible that probability models are presented in the form of a generative model and statements on conditioning on data (Carpenter et al., 2015; Goodman et al., 2008; Goodman and Stuhlmu \ufffd ller, 2014; Mansinghka et al., 2014; Minka et al., 2010; Wood et al., 2014). Their core philosophy is to decouple the specification and conclusion of the user model, the former leading to the user-specified program code and the latter to an inference engine capable of working on arbitrary programs. The need for users to write inference algorithms reduces the burden of developing new models and makes effective statistical methods accessible to non-experts. Although significant progress has been made on the problem of the general purpose limitation of program variables, less attention has been given to their optimization. Optimization is an essential tool for effective machine learning, which is necessary when the user requires a single estimate."}, {"heading": "2. Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Probabilistic Programming", "text": "A probabilistic program implicitly defines a distribution to random variables, while the system back-end implements universally valid inference methods. PPS such as Infer.Net (Minka et al., 2010) and Stan (Carpenter et al., 2015) may prove to be the definition of graphical models or factor diagrams. Instead, our focus will be on systems such as Church (Goodman et al., 2008), Venture (Mansinghka et al., 2014), WebPPPPPL et al (Goodman and Stuhlmu ller, 2014) that use a general programming language for model specifications. In these systems, the set of random variables is dynamically typed so that it is possible to write programs in which this set1code is available."}, {"heading": "2.2 Bayesian Optimization", "text": "Consider an arbitrary black box target function f: \u03d1 \u2192 R, which can be evaluated on the basis of an arbitrary point. (1) The basic idea of BO is to set a previous value f (Jones et al., 1998; Osborne et al., 2009), which expresses belief in the space of functions within which f could live. When the function is evaluated, the resulting information is incorporated by conditioning the observed data to give a disadvantage to the functions, which enables the estimation of the expected value and uncertainty in f (\u03b8) for all. This results in an acquisition function that assigns an expected benefit to the valuation of f in specific locations, based on the trade-off between exploration and exploitation in determining the maximum."}, {"heading": "2.3 Gaussian Processes", "text": "Informally, a Gaussian method (GP) (Rasmussen and Williams, 2006) can be thought of as a non-parametric distribution over functions fully defined by an intermediate function. \u2212 R \u2212 and covariance function k: \u03d1 \u00b7 \u03d1 \u2192 R, the latter having to be a limit (i.e. k (\u03b8, \u03b8))) (2), which by definition means that the functional evaluations performed at a finite number of sample points are distributed according to a multivariate Gaussian. Note that the inputs to \u00b5 and k do not have to be numerical and can be defined as such a GP over anything for which a kernel can be defined. \u2212 kD An important property of a GP is that it conjugates with a Gaussian probability. \u2212 K does not have to be numerical and as such a GP, and as such a GP can be defined over anything for which a kernel can be defined. \u2212 k An important property of a GP is that it is conjugated with a Gaussian probability."}, {"heading": "3. Problem Formulation", "text": "Considering a program that defines the joint density p (Y, X, \u03b8) with fixed Y, our goal is to optimize with respect to a subset of variables \u03b8 while at the same time marginalizing latent variables X\u03b8 = argmax. To provide the syntax to distinguish between \u03b8 and X, we introduce a new query macro defopt. The syntax of defopt is identical to defopt with defquery, except that it has an additional input that identifies the variables to be optimized. To enable the interference of inference and optimization required in the MAP estimation, we continue to doopt, which, analogous to optimization, results in an optimization that implements a rotten sequence of variables."}, {"heading": "4. Bayesian Program Optimization", "text": "In addition to the syntax introduced in the previous section, there are five main components to BOPP: - A program transformation, q \u2192 q-marg, which allows an estimate of the evidence p (Y, \u03b8) at a specified point. - A powerful GP-based BO implementation for active sampling effects. - A program transformation, q \u2192 q-prior, which is used for automatic and adaptive domain scaling so that a problem-free hyperprior can be placed over the GP hyperparameters. - An adaptive, non-stationary means function to support unlimited optimization. - A program transformation, q \u2192 q-acq, and an approximation of the maximum likelihood estimation method to address the implicit constraints imposed by the generative model. Together, these allow BOPP to perform an online MMAP estimation for arbitrary programs in a way that, from the user's perspective, requires a black box - the same as the existing PS target program definition and identification method."}, {"heading": "4.1 Program Transformation to Generate the Target", "text": "Calculation (7) (the definition of X = {a, b}) using a standard optimization scheme presents two problems: it is a random variable within the program, not something we control, and its probability distribution is defined only by an example (example); our boundary transformation returns a new query object, q-marg, as shown in Figure 3, that defines the same common distribution of program variables and inputs that can be found at http: / / www.github.com / probprog / deodorant / BAYESIAN OPTIMATION FOR PROBILISTIC PROGRAMS3-15 -10-15."}, {"heading": "4.2 Bayesian Optimization of the Marginal", "text": "The target function for our BO scheme is a protocol p (Y, \u03b8), the argmax f (BO) = argmax log f (\u03b8) = argmax log f (\u03b8) for all f: \u03d1 \u2192 R +. The log is recorded because GPs have unlimited support, while p (Y, \u03b8) is always positive, and because we expect variations of many orders of magnitude. Important PPS based on scanning based on inference motors, e.g. sequen al Monte Carlo (Wood et al., 2014) or th particle cascade (P ige et al., 2014), we can use these targets for the transformed program q-marg.Our BO scheme uses a GP before and a Gaussian probability. Although the rationality for the latter is predominantly computational, offering analytical post-processing, there are also theoretical results that indicate that this choice is appropriate (Be-rard et al., 2014). We use as standard 5. We use a coance function M2-3 / Mrn and a combination of a DF."}, {"heading": "4.3 Automatic and Adaptive Domain Scaling", "text": "Domain scaling by assignment to a common space is crucial for BOPP to operate in the required black box manner, as it allows universal and problem-free hyperscaling on GP hyperparameters. BOPP therefore uses affinity scaling to a [\u2212 1, 1] hypercube for both GP inputs and outputs. To initialize scaling for the input variables, we try directly from the generative model defined by the program. This is achieved by a second transformed program, q-prior, which removes all conditioning, i.e. observes statements, and reverts them. This transformation also introduces a code to stop executing the query once all \u03b8 are sampled to avoid unnecessary calculations. Since the above statements return zero, this transformation trivially preserves the generative model of the program, i.e. the probability of execution changes. The simulation from the generative model does not require a probability call or is therefore potentially more expensive."}, {"heading": "4.4 Unbounded Bayesian Optimization via Non-Stationary Mean Function Adaptation", "text": "Unlike traditional BO implementations, BOPP is not equipped with external constraints, and therefore we are developing a scheme for operating targets with potentially unlimited support. Our method takes advantage of the knowledge that the target function is a probability density, which means that the area you have to look for in practice to find the optimum is finite by defining a non-stationary previous mean function, which takes the form of a bump function that is constant within a range of interest but quickly decays outside. Specifically, we are defining this bump function in transformed space asul prior (r; re, r) = {0 if r \u2264 re log (r \u2212 re) + r \u2212 rer \u221e \u2212 re otherwise (11), where r is the radius from the origin, re the maximum radius of a point generated in the initial scaling or subsequent evaluations, and r \u043c is a parameter that is arbitrarily set to re \u221e \u2212 re, where r is the radius from the origin, re is the maximum radius of a point generated in the initial scaling or subsequent evaluations, and the follow-up function is never suggested."}, {"heading": "4.5 Optimizing the Acquisition Function", "text": "The optimization of the acquisition function for BOPP raises the problem that the query contains implicit constraints unknown to the replacement function. The problem of unknown constraints has already been addressed in literature (Gardner et al., 2014; Herna \u0301 ndez-Lobato et al., 2016), assuming that constraints take the form of a black box function that is modeled with a second replacement function and must be evaluated in a guesswork and verification strategy to determine whether a point is valid. Combined with the potentially considerable effort that such a method entails, this approach is unsuitable for equality constraints or if the target variables are potentially discreet. For example, the Dirichlet distribution in Figure 2 introduces an equality constraint on powers, namely that its components must add up to 1. Therefore, we choose an alternative approach that relies on the program being used directly to optimize the acquisition function. To do this, let us consider an additional acquisition function, see the previous acsiq-related paragraph 3."}, {"heading": "5. Experiments", "text": "We first demonstrate BOPP's ability to perform unlimited optimizations by identifying a 1D problem with a significant previous posterior mismatch as shown in Figure 4. It shows that BOPP adapts to the target and effectiveness. An important exception, therefore, is that the output mapping to the bottom of the hypercube remains potentially fixed in such a way that the low probability of new points is not taken into account. This ensures that stability is ensured by taking into account unlimited problems when the maximum match of BOPP to unlimited bimodal problems (0, 0.5) and p (Y) = Normal (5, 0.5), which exhibits a significant prior misspecification. Top plots show the regressed GP, which matches that of the mean and shading, indicates the standard definitions. Below is the corresponding acquisition function, which is away from the region of interest.The optimization of the acquisition function for BOPP presents the problem that contains the query, the limitations that are unknown to the query."}, {"heading": "5.1 Classic Optimizatio Benchmarks", "text": "Next, we compare BOPP with the well-known BO packages SMAC Hutter et al. (2011), Spearmint Snoek et al. (2012) and TPE Bergstra et al. (2011) for a number of classic benchmarks as shown in Figure 5. These results show that BOPP offers significant advantages over these systems when used only as an optimizer for both continuous and discrete optimization problems. In particular, it offers a major advantage over SMAC and TPE for continuous problems (Branin and Hartmann), as it uses a more powerful substitute, and over Spearmint for the others, as it does not require any approximations to solve discrete problems."}, {"heading": "5.2 Marginal Maximum a Posteriori Estimation Problems", "text": "We are now demonstrating the application of BOPP to a number of MMAP problems. Comparisons are more difficult here due to the lack of existing alternatives for PPS. In particular, a simple inference does not return estimates for p (Y, \u03b8) to the original 10 (defopt mvn-mixture [data mu0 kappa psi] [nu alpha] (let [n d] (shape data) query). We are considering the possible alternative of using our conditional code transformation to design a particle boundary metropolis hastings (PMMH, Andrieu et al. (2010) sampler that works similarly to BOPP, except that new subjects are selected after an MH step rather than actively sampling with BO. In these MH steps, we take into account both LMH (Wingate et al., 2011) with suggestions from the previous as well as the Random Walk MH variant (RMH) introduced in Section 4.5."}, {"heading": "5.2.1 HYPERPARAMETER OPTIMIZATION FOR GAUSSIAN MIXTURE MODEL", "text": "We begin with an illustrative case study to optimize hyperparameters in a multivariate Gaussian mixture model. We consider a Bayean formulation with a symmetrical dirichlet before the mixing weights and a Gaussian inverse wishart before the probability parameters: \u03c0 \u0445 Dir (\u03b1,.., \u03b1) (12) (\u00b5k, \u0395k). N (15) Anglican code for this model is shown in Figure 4. Anglican provides handsome objects, called random processes, to illustrate the predictive distributions for cluster assignments z and the observations yk associated with each cluster in Figure 4. Anglican provides handsome objects referred to as random processes to provide the predictive distributions for cluster assignments z and the observations yk associated with each cluster."}, {"heading": "5.2.2 EXTENDED KALMAN FILTER FOR THE PICKOVER CHAOTIC ATTRACTOR", "text": "Next, we consider the case of learning the dynamic parameters of a chaotic attractor = PP = 1, to whose response we respond. Chaotic attractors present an interesting case for tracking problems, such as, although their underlying dynamics are strictly deterministic with limited trajectories \u2212 neighbouring trajectories diverge exponentially from each other (Fujii, 2013; Ruan et al., 2003). From an empirical perspective, this is a challenging optimization problem, since the goal of being multimodal is translated, has variations on different longitudinal scales, and local minima is close to global maxims. We observe a roaring signal yt RK, t = 1, 2., T in any K-dimensional observation space, each observation has a lower dimension."}, {"heading": "5.2.3 HIDDEN MARKOV MODEL WITH UNKNOWN NUMBER OF STATES", "text": "Finally, we will consider a hidden Markov model (HMM) with an unknown number of states. This example shows how BOPP can be applied to models that conceptually have an unknown number of variables by generating all sorts of variables that may be needed, but then leaving some variables unused for some execution variables. This avoids problems with varying base metrics, so that the MAP problem is well defined and provides a function with a fixed number of inputs, as the BO scheme requires. From a BO perspective, the target function for variations in an unused variable is simply constant. HMMs are Markovian state space models with discrete latent variables. Each latent state xt {1,.,., K}, t = 1,. T is conditionally defined to xt \u2212 1 by a set of discrete transition probabilities."}, {"heading": "6. Discussion and Future Work", "text": "We have introduced a new method for MMAP estimation of probable program variables using Bayesian optimization, which provides the first unified framework for optimization and deduction of probable programs. By using a series of code transformations, our method enables optimization of any program with respect to a defined subset of its variables, while marginalizing the rest. To perform the required optimization, we introduce a new GP-based BO package that exploits the availability of the target source code to provide a number of new features, such as automatic domain scaling and constraint satisfaction.The concepts we present lead directly to a number of interest extensions, including, but not limited to, intelligent initialization of inference algorithms, adaptive suggestions, and nested optimization. Further work may take into account maximum marginal probability estimation and risk minimization. Although only minor algorithmic changes are required, these theoretical considerations require different cases."}, {"heading": "Appendix A. Program Transformations in Detail", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "Appendix B. Problem Independent Gaussian Process Hyperprior", "text": "In view of the fact that the domain scaling introduced in Section 4.3 means that both the GP input and output fluctuate between \u00b1 1, we define the problem independently of the GP hyperprior as p (\u03b1) = p (\u03c3n) p (\u03c33 / 2) p (\u03c35 / 2) \u2022 D i = 1 p (\u03c1i) p (% i), where elog (\u03c3n) \u0445 N (\u2212 5, 2) (34a) log (\u03c33 / 2) \u2022 N (\u2212 7, 0.5) (34b) log (\u03c35 / 2) \u0445 N (\u2212 0.5, 0.15) (34c) log (\u03c1i) \u0445 N (\u2212 1.5, 0.5) \u0394i (1,...., D} (34d) log (% i) \u0445 N (\u2212 1, 0.5) (34b) log (\u03c31,)."}, {"heading": "Appendix C. Full Details for House Heating Experiment", "text": "In this case study, illustrated in Figure 1, we optimize the parameters of a stochastic engineering simulation = 36 \u00b0 C. We use the Energy2D system from Xie (2012) to perform finite difference numerical simulations of the thermal equation and Navier Stokes equations in a custom geometry. In our setup, we designed a 2-dimensional representation of a house with 4 interconnected rooms using the GUI provided by Energy2D. The left side of the house receives morning sun, modelled at a constant angle of incidence of 30 \u00b0. We assume a randomly distributed solar intensity and simulate the heating of a cold house in the morning by 4 radiators, one in each of the rooms. The radiators receive a fixed budget of the total power density budget. The optimization problem is to distribute this power budget across radiators in a way that minimizes the variation of temperatures across 8 places in the household."}, {"heading": "Acknowledgements", "text": "Tuan Anh Le is supported by a Google scholarship with project code DF6700. Frank Wood is supported under DARPA PPAML by the US AFRL under the cooperation agreement FA8750-14-2-0006, Sub Award number 61160290-111668."}], "references": [{"title": "Particle Markov chain Monte Carlo methods", "author": ["Christophe Andrieu", "Arnaud Doucet", "Roman Holenstein"], "venue": "J Royal Stat. Soc.: Series B (Stat. Methodol.),", "citeRegEx": "Andrieu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2010}, {"title": "A lognormal central limit theorem for particle approximations of normalizing constants", "author": ["Jean B\u00e9rard", "Pierre Del Moral", "Arnaud Doucet"], "venue": "Electronic Journal of Probability,", "citeRegEx": "B\u00e9rard et al\\.,? \\Q2014\\E", "shortCiteRegEx": "B\u00e9rard et al\\.", "year": 2014}, {"title": "Algorithms for hyper-parameter optimization", "author": ["James S Bergstra", "R\u00e9mi Bardenet", "Yoshua Bengio", "Bal\u00e1zs K\u00e9gl"], "venue": "In NIPS,", "citeRegEx": "Bergstra et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2011}, {"title": "The convergence of a class of double-rank minimization algorithms 1. general considerations", "author": ["Charles George Broyden"], "venue": "IMA Journal of Applied Mathematics,", "citeRegEx": "Broyden.,? \\Q1970\\E", "shortCiteRegEx": "Broyden.", "year": 1970}, {"title": "Stan: a probabilistic programming language", "author": ["B Carpenter", "A Gelman", "M Hoffman", "D Lee", "B Goodrich", "M Betancourt", "M A Brubaker", "J Guo", "P Li", "A Riddell"], "venue": "Journal of Statistical Software,", "citeRegEx": "Carpenter et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Carpenter et al\\.", "year": 2015}, {"title": "Approximate Bayesian Computation (ABC) in practice", "author": ["Katalin Csill\u00e9ry", "Michael GB Blum", "Oscar E Gaggiotti", "Olivier Fran\u00e7ois"], "venue": "Trends in Ecology & Evolution,", "citeRegEx": "Csill\u00e9ry et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Csill\u00e9ry et al\\.", "year": 2010}, {"title": "An introduction to chaotic dynamical systems, volume 13046", "author": ["Robert L Devaney", "Luke Devaney"], "venue": null, "citeRegEx": "Devaney et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Devaney et al\\.", "year": 1989}, {"title": "Hybrid Monte Carlo", "author": ["Simon Duane", "Anthony D Kennedy", "Brian J Pendleton", "Duncan Roweth"], "venue": "Physics letters B,", "citeRegEx": "Duane et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Duane et al\\.", "year": 1987}, {"title": "Towards an empirical foundation for assessing Bayesian optimization of hyperparameters", "author": ["Katharina Eggensperger", "Matthias Feurer", "Frank Hutter", "James Bergstra", "Jasper Snoek", "Holger Hoos", "Kevin Leyton-Brown"], "venue": "In NIPS workshop on Bayesian Optimization in Theory and Practice,", "citeRegEx": "Eggensperger et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Eggensperger et al\\.", "year": 2013}, {"title": "Extended Kalman filter", "author": ["Keisuke Fujii"], "venue": "Refernce Manual,", "citeRegEx": "Fujii.,? \\Q2013\\E", "shortCiteRegEx": "Fujii.", "year": 2013}, {"title": "Bayesian optimization with inequality constraints", "author": ["Jacob R Gardner", "Matt J Kusner", "Zhixiang Eddie Xu", "Kilian Q Weinberger", "John Cunningham"], "venue": "In ICML,", "citeRegEx": "Gardner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gardner et al\\.", "year": 2014}, {"title": "Church: a language for generative models", "author": ["N Goodman", "V Mansinghka", "D M Roy", "K Bonawitz", "J B Tenenbaum"], "venue": "In UAI,", "citeRegEx": "Goodman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Goodman et al\\.", "year": 2008}, {"title": "The Design and Implementation of Probabilistic Programming Languages", "author": ["Noah D Goodman", "Andreas Stuhlm\u00fcller"], "venue": null, "citeRegEx": "Goodman and Stuhlm\u00fcller.,? \\Q2014\\E", "shortCiteRegEx": "Goodman and Stuhlm\u00fcller.", "year": 2014}, {"title": "Bayesian optimization for likelihood-free inference of simulatorbased statistical models", "author": ["Michael U Gutmann", "Jukka Corander"], "venue": null, "citeRegEx": "Gutmann and Corander.,? \\Q2016\\E", "shortCiteRegEx": "Gutmann and Corander.", "year": 2016}, {"title": "Predictive entropy search for efficient global optimization of black-box functions", "author": ["Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Matthew W Hoffman", "Zoubin Ghahramani"], "venue": "In NIPS,", "citeRegEx": "Hern\u00e1ndez.Lobato et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hern\u00e1ndez.Lobato et al\\.", "year": 2014}, {"title": "A general framework for constrained Bayesian optimization using information-based", "author": ["Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Michael A. Gelbart", "Ryan P. Adams", "Matthew W. Hoffman", "Zoubin Ghahramani"], "venue": "search. JMLR,", "citeRegEx": "Hern\u00e1ndez.Lobato et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hern\u00e1ndez.Lobato et al\\.", "year": 2016}, {"title": "Sequential model-based optimization for general algorithm configuration", "author": ["Frank Hutter", "Holger H Hoos", "Kevin Leyton-Brown"], "venue": "In Learn. Intell. Optim.,", "citeRegEx": "Hutter et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2011}, {"title": "Efficient global optimization of expensive black-box functions", "author": ["Donald R Jones", "Matthias Schonlau", "William J Welch"], "venue": "J Global Optim,", "citeRegEx": "Jones et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Jones et al\\.", "year": 1998}, {"title": "Venture: a higher-order probabilistic programming platform with programmable inference", "author": ["Vikash Mansinghka", "Daniel Selsam", "Yura Perov"], "venue": "arXiv preprint arXiv:1404.0099,", "citeRegEx": "Mansinghka et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mansinghka et al\\.", "year": 2014}, {"title": "Infer .NET 2.4", "author": ["T Minka", "J Winn", "J Guiver", "D Knowles"], "venue": "Microsoft Research Cambridge,", "citeRegEx": "Minka et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Minka et al\\.", "year": 2010}, {"title": "Machine learning: a probabilistic perspective", "author": ["Kevin P Murphy"], "venue": "MIT press,", "citeRegEx": "Murphy.,? \\Q2012\\E", "shortCiteRegEx": "Murphy.", "year": 2012}, {"title": "Annealed importance sampling", "author": ["Radford M Neal"], "venue": "Statistics and Computing,", "citeRegEx": "Neal.,? \\Q2001\\E", "shortCiteRegEx": "Neal.", "year": 2001}, {"title": "Gaussian processes for global optimization", "author": ["Michael A Osborne", "Roman Garnett", "Stephen J Roberts"], "venue": "In 3rd international conference on learning and intelligent optimization", "citeRegEx": "Osborne et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Osborne et al\\.", "year": 2009}, {"title": "Asynchronous anytime sequential monte carlo", "author": ["Brooks Paige", "Frank Wood", "Arnaud Doucet", "Yee Whye Teh"], "venue": "In NIPS,", "citeRegEx": "Paige et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Paige et al\\.", "year": 2014}, {"title": "The pattern book: Fractals, art, and nature", "author": ["Clifford A Pickover"], "venue": "World Scientific,", "citeRegEx": "Pickover.,? \\Q1995\\E", "shortCiteRegEx": "Pickover.", "year": 1995}, {"title": "Bayesian optimization for probabilistic programs", "author": ["Tom Rainforth", "Tuan-Anh Le", "Jan-Willem van de Meent", "Michael A Osborne", "Frank Wood"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Rainforth et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Rainforth et al\\.", "year": 2016}, {"title": "Gaussian Processes for Machine Learning", "author": ["Carl Rasmussen", "Chris Williams"], "venue": null, "citeRegEx": "Rasmussen and Williams.,? \\Q2006\\E", "shortCiteRegEx": "Rasmussen and Williams.", "year": 2006}, {"title": "A chaotic secure communication scheme with extended Kalman filter based parameter estimation", "author": ["Huawei Ruan", "Tongyan Zhai", "Edwin Engin Yaz"], "venue": "In Control Applications,", "citeRegEx": "Ruan et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Ruan et al\\.", "year": 2003}, {"title": "Unbounded Bayesian optimization via regularization", "author": ["Bobak Shahriari", "Alexandre Bouchard-C\u00f4t\u00e9", "Nando de Freitas"], "venue": "AISTATS,", "citeRegEx": "Shahriari et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shahriari et al\\.", "year": 2016}, {"title": "Taking the human out of the loop: A review of Bayesian optimization", "author": ["Bobak Shahriari", "Kevin Swersky", "Ziyu Wang", "Ryan P Adams", "Nando de Freitas"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Shahriari et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shahriari et al\\.", "year": 2016}, {"title": "Practical Bayesian optimization of machine learning algorithms", "author": ["Jasper Snoek", "Hugo Larochelle", "Ryan P Adams"], "venue": "In NIPS,", "citeRegEx": "Snoek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Scalable Bayesian optimization using deep neural networks", "author": ["Jasper Snoek", "Oren Rippel", "Kevin Swersky", "Ryan Kiros", "Nadathur Satish", "Narayanan Sundaram", "Mostofa Patwary", "Mostofa Ali", "Ryan P Adams"], "venue": "In ICML,", "citeRegEx": "Snoek et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2015}, {"title": "Probabilistic programming in Anglican", "author": ["David Tolpin", "Jan-Willem van de Meent", "Frank Wood"], "venue": "Springer International Publishing,", "citeRegEx": "Tolpin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tolpin et al\\.", "year": 2015}, {"title": "Black-box policy search with probabilistic programs", "author": ["Jan-Willem van de Meent", "Brooks Paige", "David Tolpin", "Frank Wood"], "venue": "In AISTATS,", "citeRegEx": "Meent et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Meent et al\\.", "year": 2016}, {"title": "Lightweight implementations of probabilistic programming languages via transformational compilation", "author": ["David Wingate", "Andreas Stuhlmueller", "Noah D Goodman"], "venue": "In AISTATS,", "citeRegEx": "Wingate et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wingate et al\\.", "year": 2011}, {"title": "A new approach to probabilistic programming inference", "author": ["Frank Wood", "Jan Willem van de Meent", "Vikash Mansinghka"], "venue": "In AISTATS,", "citeRegEx": "Wood et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wood et al\\.", "year": 2014}, {"title": "Interactive heat transfer simulations for everyone", "author": ["Charles Xie"], "venue": "The Physics Teacher,", "citeRegEx": "Xie.,? \\Q2012\\E", "shortCiteRegEx": "Xie.", "year": 2012}], "referenceMentions": [{"referenceID": 4, "context": "Introduction Probabilistic programming systems (PPS) allow probabilistic models to be represented in the form of a generative model and statements for conditioning on data (Carpenter et al., 2015; Goodman et al., 2008; Goodman and Stuhlm\u00fcller, 2014; Mansinghka et al., 2014; Minka et al., 2010; Wood et al., 2014).", "startOffset": 172, "endOffset": 313}, {"referenceID": 11, "context": "Introduction Probabilistic programming systems (PPS) allow probabilistic models to be represented in the form of a generative model and statements for conditioning on data (Carpenter et al., 2015; Goodman et al., 2008; Goodman and Stuhlm\u00fcller, 2014; Mansinghka et al., 2014; Minka et al., 2010; Wood et al., 2014).", "startOffset": 172, "endOffset": 313}, {"referenceID": 12, "context": "Introduction Probabilistic programming systems (PPS) allow probabilistic models to be represented in the form of a generative model and statements for conditioning on data (Carpenter et al., 2015; Goodman et al., 2008; Goodman and Stuhlm\u00fcller, 2014; Mansinghka et al., 2014; Minka et al., 2010; Wood et al., 2014).", "startOffset": 172, "endOffset": 313}, {"referenceID": 18, "context": "Introduction Probabilistic programming systems (PPS) allow probabilistic models to be represented in the form of a generative model and statements for conditioning on data (Carpenter et al., 2015; Goodman et al., 2008; Goodman and Stuhlm\u00fcller, 2014; Mansinghka et al., 2014; Minka et al., 2010; Wood et al., 2014).", "startOffset": 172, "endOffset": 313}, {"referenceID": 19, "context": "Introduction Probabilistic programming systems (PPS) allow probabilistic models to be represented in the form of a generative model and statements for conditioning on data (Carpenter et al., 2015; Goodman et al., 2008; Goodman and Stuhlm\u00fcller, 2014; Mansinghka et al., 2014; Minka et al., 2010; Wood et al., 2014).", "startOffset": 172, "endOffset": 313}, {"referenceID": 35, "context": "Introduction Probabilistic programming systems (PPS) allow probabilistic models to be represented in the form of a generative model and statements for conditioning on data (Carpenter et al., 2015; Goodman et al., 2008; Goodman and Stuhlm\u00fcller, 2014; Mansinghka et al., 2014; Minka et al., 2010; Wood et al., 2014).", "startOffset": 172, "endOffset": 313}, {"referenceID": 20, "context": "It also often forms a tractable alternative when full inference is infeasible (Murphy, 2012).", "startOffset": 78, "endOffset": 92}, {"referenceID": 35, "context": "We therefore introduce BOPP1 (Bayesian optimization for probabilistic programs) which couples existing inference algorithms from PPS, like Anglican (Wood et al., 2014), with a new Gaussian process (GP) (Rasmussen and Williams, 2006) based Bayesian optimization (BO) package (Gutmann and Corander, 2016; Jones et al.", "startOffset": 148, "endOffset": 167}, {"referenceID": 26, "context": ", 2014), with a new Gaussian process (GP) (Rasmussen and Williams, 2006) based Bayesian optimization (BO) package (Gutmann and Corander, 2016; Jones et al.", "startOffset": 42, "endOffset": 72}, {"referenceID": 13, "context": ", 2014), with a new Gaussian process (GP) (Rasmussen and Williams, 2006) based Bayesian optimization (BO) package (Gutmann and Corander, 2016; Jones et al., 1998; Osborne et al., 2009; Shahriari et al., 2016a).", "startOffset": 114, "endOffset": 209}, {"referenceID": 17, "context": ", 2014), with a new Gaussian process (GP) (Rasmussen and Williams, 2006) based Bayesian optimization (BO) package (Gutmann and Corander, 2016; Jones et al., 1998; Osborne et al., 2009; Shahriari et al., 2016a).", "startOffset": 114, "endOffset": 209}, {"referenceID": 22, "context": ", 2014), with a new Gaussian process (GP) (Rasmussen and Williams, 2006) based Bayesian optimization (BO) package (Gutmann and Corander, 2016; Jones et al., 1998; Osborne et al., 2009; Shahriari et al., 2016a).", "startOffset": 114, "endOffset": 209}, {"referenceID": 5, "context": "By expressing the utility of a particular design-environment combination using an approximate Bayesian computation (ABC) likelihood (Csill\u00e9ry et al., 2010), one can pose this as a MMAP problem, optimizing the design while marginalizing out the environmental uncertainty.", "startOffset": 132, "endOffset": 155}, {"referenceID": 36, "context": "The probabilistic program shown in Figure 2 allows us to define a prior over the uncertain weather, while conditioning on the output of a deterministic simulator (here Energy2D (Xie, 2012)-a finite element package for heat transfer) using an ABC likelihood.", "startOffset": 177, "endOffset": 188}, {"referenceID": 19, "context": "Net (Minka et al., 2010) and Stan (Carpenter et al.", "startOffset": 4, "endOffset": 24}, {"referenceID": 4, "context": ", 2010) and Stan (Carpenter et al., 2015) can be thought of as defining graphical models or factor graphs.", "startOffset": 17, "endOffset": 41}, {"referenceID": 11, "context": "Our focus will instead be on systems such as Church (Goodman et al., 2008), Venture (Mansinghka et al.", "startOffset": 52, "endOffset": 74}, {"referenceID": 18, "context": ", 2008), Venture (Mansinghka et al., 2014), WebPPL (Goodman and Stuhlm\u00fcller, 2014), and Anglican (Wood et al.", "startOffset": 17, "endOffset": 42}, {"referenceID": 12, "context": ", 2014), WebPPL (Goodman and Stuhlm\u00fcller, 2014), and Anglican (Wood et al.", "startOffset": 16, "endOffset": 47}, {"referenceID": 35, "context": ", 2014), WebPPL (Goodman and Stuhlm\u00fcller, 2014), and Anglican (Wood et al., 2014), which employ a general-purpose programming language for model specification.", "startOffset": 62, "endOffset": 81}, {"referenceID": 36, "context": "Shown are output heat maps from Energy2D (Xie, 2012) simulations at one intensity, corresponding to setting all the radiators to the same power (top left), the best result from a set of 5 randomly chosen powers used for initializing BOPP (top right), and the best setup found after 100 iterations of BOPP (bottom left).", "startOffset": 41, "endOffset": 52}, {"referenceID": 11, "context": "These models, which we refer to as queries (Goodman et al., 2008), specify a joint distribution p(Y,X) over data Y and variables X .", "startOffset": 43, "endOffset": 65}, {"referenceID": 17, "context": "BO (Jones et al., 1998; Osborne et al., 2009) aims to find the global maximum \u03b8\u2217 = argmax \u03b8\u2208\u03b8 f (\u03b8) .", "startOffset": 3, "endOffset": 45}, {"referenceID": 22, "context": "BO (Jones et al., 1998; Osborne et al., 2009) aims to find the global maximum \u03b8\u2217 = argmax \u03b8\u2208\u03b8 f (\u03b8) .", "startOffset": 3, "endOffset": 45}, {"referenceID": 2, "context": "Although alternatives such as random forests (Bergstra et al., 2011; Hutter et al., 2011) or neural networks (Snoek et al.", "startOffset": 45, "endOffset": 89}, {"referenceID": 16, "context": "Although alternatives such as random forests (Bergstra et al., 2011; Hutter et al., 2011) or neural networks (Snoek et al.", "startOffset": 45, "endOffset": 89}, {"referenceID": 31, "context": ", 2011) or neural networks (Snoek et al., 2015) exist, the most common prior used for f is a GP (Rasmussen and Williams, 2006).", "startOffset": 27, "endOffset": 47}, {"referenceID": 26, "context": ", 2015) exist, the most common prior used for f is a GP (Rasmussen and Williams, 2006).", "startOffset": 56, "endOffset": 86}, {"referenceID": 2, "context": "Although alternatives such as random forests (Bergstra et al., 2011; Hutter et al., 2011) or neural networks (Snoek et al., 2015) exist, the most common prior used for f is a GP (Rasmussen and Williams, 2006). For further information on BO we refer the reader to the recent review by Shahriari et al Shahriari et al. (2016b).", "startOffset": 46, "endOffset": 325}, {"referenceID": 26, "context": "3 Gaussian Processes Informally one can think of a Gaussian Process (GP) (Rasmussen and Williams, 2006) as being a nonparametric distribution over functions which is fully specified by a mean function \u03bc : \u03b8 \u2192 R and covariance function k : \u03b8\u00d7\u03b8\u2192 R, the latter of which must be a bounded (i.", "startOffset": 73, "endOffset": 103}, {"referenceID": 26, "context": "- Step 3 (black arrow) fits a mixture of GPs posterior Rasmussen and Williams (2006) to the scaled data (bottom centre) using a problem independent hyperprior.", "startOffset": 55, "endOffset": 85}, {"referenceID": 35, "context": "sequen al Monte Carlo (Wood et al., 2014) or th particle cascade (P ige et al.", "startOffset": 22, "endOffset": 41}, {"referenceID": 1, "context": "Though the rationale for the latter is predominantly computational, giving an analytic posterior, there are also theoretical results suggesting that this choice is appropriate (B\u00e9rard et al., 2014).", "startOffset": 176, "endOffset": 197}, {"referenceID": 30, "context": "As noted by (Snoek et al., 2012), the performance of BO using a single GP posterior is heavily influenced by the choice of these hyperparameters.", "startOffset": 12, "endOffset": 32}, {"referenceID": 7, "context": "Inference over \u03b1 is performed using Hamiltonian Monte Carlo (HMC) (Duane et al., 1987), giving an unweighted mixture of GPs.", "startOffset": 66, "endOffset": 86}, {"referenceID": 3, "context": "As we found that the performance of HMC was often poor unless a good initialization point was used, BOPP runs a small number of independent chains and allocates part of the computational budget to their initialization using a L-BFGS optimizer (Broyden, 1970).", "startOffset": 243, "endOffset": 258}, {"referenceID": 30, "context": "Secondly it is used to define the acquisition function \u03b6, for which we take the expected improvement (Snoek et al., 2012), defining \u03c3 m (\u03b8) = \u221a ki m (\u03b8, \u03b8) and \u03b3 i m (\u03b8) = \u03bcm(\u03b8)\u2212\u00fbm \u03c3i m(\u03b8) ,", "startOffset": 101, "endOffset": 121}, {"referenceID": 14, "context": "(Hern\u00e1ndez-Lobato et al., 2014), could be used instead.", "startOffset": 0, "endOffset": 31}, {"referenceID": 10, "context": "The problem of unknown constraints has been previously covered in the literature (Gardner et al., 2014; Hern\u00e1ndez-Lobato et al., 2016) by assuming that constraints take the form of a black-box function which is modeled with a second surrogate function and must be evaluated in guess-and-check strategy to establish whether a point is valid.", "startOffset": 81, "endOffset": 134}, {"referenceID": 15, "context": "The problem of unknown constraints has been previously covered in the literature (Gardner et al., 2014; Hern\u00e1ndez-Lobato et al., 2016) by assuming that constraints take the form of a black-box function which is modeled with a second surrogate function and must be evaluated in guess-and-check strategy to establish whether a point is valid.", "startOffset": 81, "endOffset": 134}, {"referenceID": 21, "context": "We obtain a maximum likelihood estimate for q-acq using a variant of annealed importance sampling (Neal, 2001) in which lightweight Metropolis Hastings (LMH) (Wingate et al.", "startOffset": 98, "endOffset": 110}, {"referenceID": 34, "context": "We obtain a maximum likelihood estimate for q-acq using a variant of annealed importance sampling (Neal, 2001) in which lightweight Metropolis Hastings (LMH) (Wingate et al., 2011) with local random-walk moves is used as the base transition kernel.", "startOffset": 158, "endOffset": 180}, {"referenceID": 8, "context": "The dashed lines shows the final mean error of SMAC (red), Spearmint (green) and TPE (black) as quoted by Eggensperger et al. (2013). The dark blue line shows the mean error for BOPP averaged over 100 runs, whilst the median and 25/75% percentiles are shown in cyan.", "startOffset": 106, "endOffset": 133}, {"referenceID": 8, "context": "The dashed lines shows the final mean error of SMAC (red), Spearmint (green) and TPE (black) as quoted by Eggensperger et al. (2013). The dark blue line shows the mean error for BOPP averaged over 100 runs, whilst the median and 25/75% percentiles are shown in cyan. Results for Spearmint on Branin and SMAC on SVM on-grid are omitted because both BOPP and the respective algorithms averaged zero error to the provided number of significant figures in Eggensperger et al. (2013).", "startOffset": 106, "endOffset": 479}, {"referenceID": 15, "context": "1 Classic Optimizatio Benchmarks Next we compare BOPP to the prominent BO packages SMAC Hutter et al. (2011), Spearmint Snoek et al.", "startOffset": 88, "endOffset": 109}, {"referenceID": 15, "context": "1 Classic Optimizatio Benchmarks Next we compare BOPP to the prominent BO packages SMAC Hutter et al. (2011), Spearmint Snoek et al. (2012) and TPE Bergstra et al.", "startOffset": 88, "endOffset": 140}, {"referenceID": 2, "context": "(2012) and TPE Bergstra et al. (2011) on a number of classical benchmarks as shown in Figure 5.", "startOffset": 15, "endOffset": 38}, {"referenceID": 34, "context": "For these MH steps we consider both LMH (Wingate et al., 2011) with proposals from the prior and the random-walk MH (RMH) variant introduced in Section 4.", "startOffset": 40, "endOffset": 62}, {"referenceID": 0, "context": "We consider the possible alternative of using our conditional code transformation to design a particle marginal Metropolis Hastings (PMMH, Andrieu et al. (2010)) sampler which operates in a similar fashion to BOPP except that new \u03b8 are chosen using a MH step instead of actively sampling with BO.", "startOffset": 139, "endOffset": 161}, {"referenceID": 9, "context": "Therefore regardless of the available precision, a trajectory cannot be indefinitely extrapolated to within a given accuracy and probabilistic methods such as the extended Kalman filter must be incorporated (Fujii, 2013; Ruan et al., 2003).", "startOffset": 207, "endOffset": 239}, {"referenceID": 27, "context": "Therefore regardless of the available precision, a trajectory cannot be indefinitely extrapolated to within a given accuracy and probabilistic methods such as the extended Kalman filter must be incorporated (Fujii, 2013; Ruan et al., 2003).", "startOffset": 207, "endOffset": 239}, {"referenceID": 6, "context": "We refer the reader to Devaney et al. (1989) for an introduction.", "startOffset": 23, "endOffset": 45}, {"referenceID": 24, "context": "xt,3 = sin (xt\u22121,1) (22c) corresponds to a Pickover attractor (Pickover, 1995) with unknown parameters \u03b8 = {\u03b2, \u03b7} which we wish to optimize.", "startOffset": 62, "endOffset": 78}, {"referenceID": 32, "context": "Anglican extends Clojure with the special forms sample and observe (Tolpin et al., 2015).", "startOffset": 67, "endOffset": 88}, {"referenceID": 36, "context": "We use the Energy2D system from Xie (2012) to perform finite-difference numerical simulation of the heat equation and Navier-Stokes equations in a user-defined geometry.", "startOffset": 32, "endOffset": 43}], "year": 2017, "abstractText": "We present the first general purpose framework for marginal maximum a posteriori estimation of probabilistic program variables. By using a series of code transformations, the evidence of any probabilistic program, and therefore of any graphical model, can be optimized with respect to an arbitrary subset of its sampled variables. To carry out this optimization, we develop the first Bayesian optimization package to directly exploit the source code of its target, leading to innovations in problem-independent hyperpriors, unbounded optimization, and implicit constraint satisfaction; delivering significant performance improvements over prominent existing packages. We present applications of our method to a number of tasks including engineering design and parameter optimization.", "creator": "LaTeX with hyperref package"}}}