{"id": "1707.06690", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jul-2017", "title": "DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning", "abstract": "We study the problem of learning to reason in large scale knowledge graphs (KGs). More specifically, we describe a novel reinforcement learning framework for learning multi-hop relational paths: we use a policy-based agent with continuous states based on knowledge graph embeddings, which reasons in a KG vector space by sampling the most promising relation to extend its path. In contrast to prior work, our approach includes a reward function that takes the accuracy, diversity, and efficiency into consideration. Experimentally, we show that our proposed method outperforms a path-ranking based algorithm and knowledge graph embedding methods on Freebase and Never-Ending Language Learning datasets.", "histories": [["v1", "Thu, 20 Jul 2017 19:39:23 GMT  (215kb,D)", "http://arxiv.org/abs/1707.06690v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["wenhan xiong", "thien hoang", "william yang wang"], "accepted": true, "id": "1707.06690"}, "pdf": {"name": "1707.06690.pdf", "metadata": {"source": "CRF", "title": "DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning", "authors": ["Wenhan Xiong", "Thien Hoang", "William Yang Wang"], "emails": ["xwhan@cs.ucsb.edu,", "william@cs.ucsb.edu,", "thienhoang@umail.ucsb.edu"], "sections": [{"heading": "1 Introduction", "text": "In recent years, the number of unemployed in Germany has multiplied, so that the number of unemployed has risen by only 0.2 percent in the first three months of this year."}, {"heading": "2 Related Work", "text": "The Path Ranking Algorithm (PRA) Method (Lao et al., 2011b) is a primary path finding approach that uses random walks with restart strategies for multi-hop reasoning. Gardner et al. (2013; 2014) propose a modification of PRA that calculates similarities in vector space. Wang and Cohen (2015) introduce a recursive random path approach to integrate background Kg and text - the method performs structural learning of logic programs and information extraction from text simultaneously. A potential bottleneck for random sequences is that supernodes that connect with large amounts of formulas create huge fan-out areas that slow down the sequences and affect accuracy. Toutanova et al. (2015) offer a revolutionary neural network solution for multi-hop reasoning. Build a path-based model on the CNN Path path path path path path lecture."}, {"heading": "3 Methodology", "text": "In this section, we describe in detail our RL-based framework for multi-hop relationship logic. The specific task of relationship logic is to find reliable predictable paths between entity pairs. We formulate the path finding problem as a sequential decision problem that can be solved with an RL agent. First, we describe the environment and the policy-based RL agent. By interacting with the environment designed around the KG, the agent learns to select the promising argumentation paths. Then, we describe the training procedures of our RL model. Then, we describe an efficient path-dependent search algorithm for the relationship logic with the paths found by the RL agent."}, {"heading": "3.1 Reinforcement Learning for Relation Reasoning", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "3.2 Training Pipeline", "text": "In practice, it is a great challenge that the overarching policy is trained with a randomized search. In practice, it is a great challenge that the relationship can be quite large. In practice, it is a great challenge that the overarching policy is connected with the overarching level of the political network. In other words, the output level of the political network often has a large dimension. Due to the complexity of the ratio chart and the large scope for action, if we train the overarching policy directly through trial and error typical of the RL algorithms, the RL model will show very poor convergence characteristics. To address this problem, we begin our training with a revised policy inspired by the imitated learning pipeline used by AlphaGo. (Silver et al, 2016) In the Go game, the player faces almost 250 possible legal steps at each step. Directly, we train the agents to select actions from the original action space."}, {"heading": "3.3 Bi-directional Path-constrained Search", "text": "For an entity pair, the thought paths learned by the RL agent can be used as logical formulas to predict the relation connection. Each formula is verified by a bidirectional search. In a typical node, an entity node can be linked to a large number of neighbors with the same relation connection. A simple example is the relation personality \u2212 1, which denotes the reversal of personality. Following this link, the entity United States can reach numerous adjacent entities. If the for algorithm 2: Bi-directional search for path verification 1 Is there a way of thinking p: r1 \u2192 r2 \u2192... rn 2 for (ei, ej) in test set D do 3 starting formula \u2190 0; end \u2190 n 4 links \u2190 5 during start < at the end do 6 leftEx descriptions, then we can get 6 leftEx results."}, {"heading": "4 Experiments", "text": "In order to evaluate the reasoning formulas found by our RL agent, we examine two common KG reasoning tasks: link prediction (predicting target subjects) and fact prediction (predicting whether an unknown fact persists or not). We compare our method with both path-based methods and embedding methods. Afterwards, we further analyze the reasoning paths found by our RL agent. These highly predictable paths confirm the effectiveness of the reward functions. Finally, we conduct an experiment to investigate the effect of the supervised learning procedure."}, {"heading": "4.1 Dataset and Settings", "text": "The triples in FB15K-237 (Toutanova et al., 2015) are sampled from FB15K (Bordes et al., 2013), removing redundant relationships. We perform the reasoning tasks on the basis of 20 relationships that have enough reasoning paths. These tasks consist of relationships from different areas such as sports, people, locations, film, etc. We also present a new NELL subset that is suitable for multihop reasoning from the 995th iteration of the NELL system. We first remove the triples with relation generalizations or haswikipediaurl. These two relationships appear more than 2M times in the NELL dataset, but they have no reasoning values. After this step, we select only the triples with the top 200 relationships. To facilitate path prediction, we add the two relationships more than 2M times in the NELL dataset, but they have no reasoning values."}, {"heading": "4.2 Baselines and Implementation Details", "text": "For path-based methods, we compare our RL model with the PRA algorithm (Lao et al., 2011a), which has been used in some argumentation methods (Gardner et al., 2013; Neelakantan et al., 2015). PRA is a data-driven algorithm that uses random walks (RW) to find paths and obtain path characteristics. For embedding-based methods, we evaluate several state-of-the-art embeddings developed to complete the knowledge base, such as TransE (Bordes et al., 2013), TransH et al. (Wang et al., 2014), TransR (Lin et al., 2015) and TransD (Ji et al., 2015).The implementation of PRA is based on the code published by (Lao et al., 2011a). We use the K negative mode to approximate negative samples and replace negative ones."}, {"heading": "4.3 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.3.1 Quantitative Results", "text": "Link Prediction This task is to classify the target units of a query unit. Table 2 shows the average precision results (MAP) on two sets of data.2The implementation we use can be found at https: / / github.com / thunlp / Fast-TransX."}, {"heading": "RL 0.311 0.493", "text": "Since path-based methods generally work better than embedding methods for this task, we do not include the other two embedding methods in this table. Instead, we save the space to show the detailed results for each reasoning task. For the general MAP shown in the last row of the table, our approach performs significantly worse both the path-based method and the embedding of methods on two sets of datasets, which confirms the strong reasoning capability of our RL model. Since the embedding methods do not use path information in the KG, they generally perform worse than our RL model or PRA in most relationships. However, if there are not enough paths between the units, our model and PRA can produce bad results. For example, our RL model finds only 4 distinct reasoning paths for the filmWrittenBy relationship, which means that there are actually not enough reasoning paths existing in the KG."}, {"heading": "4.3.2 Qualitative Analysis of Reasoning Paths", "text": "To analyze the properties of reasoning paths, we show a few reasoning paths that the agent has found in Table 5. To illustrate the effect of the efficiency reward function, we show the path length distributions in Figure 2. To interpret these paths, we take, for example, the personality relationship. The first reasoning path shows that if we know facts that contain OfBirth (x, y) and locationContainers (z, y), it is very likely that person x has nationality. These short but predictable paths indicate the effectiveness of the RL model. Another important observation is that our model uses much less reasoning paths than PRA, which indicates that our model can actually extract the most reliable reasoning paths from KG. Table 4 shows some comparisons about the number of reasoning paths. We can see that the RL agent with pre-defined reward filters is able to the position of similar or irrelevant functions."}, {"heading": "4.3.3 Effect of Supervised Learning", "text": "As mentioned in Section 3.2, one of the biggest challenges for applying RL to KG reasoning is the large margin of manoeuvre. We address this problem by applying supervised learning before the reward step. To show the effect of supervised training, we evaluate the agent's success ratio in achieving the goal within 10 steps (successive10) after different number of training episodes. For each training episode, a pair of units (Etarget, Etarget) is used in the train set to find pathways. All correct paths connecting the units receive a global reward of + 1. We then connect some true training paths. Successive10 is calculated on a reserved test set consisting of 100 entity pairs. For the NELL995 dataset, since we have 200 unique relationships, the dimension of the action space will be 400 after we have added the backward movements. This means that 400 random paths will result in very few successes."}, {"heading": "5 Conclusion and Future Work", "text": "Unlike previous random path-based models, the RL model allows us to control the properties of the paths found, and these effective paths can also be used as an alternative to PRA in many path-based reasoning methods.For two standard argumentation tasks, where the RL paths are used as argumentation formulas, our approach generally performs better than two classes of fundamentals, and for future studies we plan to explore the possibility of incorporating contradictory learning (Goodfellow et al., 2014) to give better rewards than the human-defined reward functions used in this work. Instead of designing rewards according to path characteristics, a discriminatory model can be trained to give rewards. Also, to address the problematic scenario where the KG does not have enough reasoning pathways, we are interested in applying our RL model to common reasoning pathways with texts and triptions."}], "references": [{"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Kurt Bollacker", "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor."], "venue": "Proceedings of the 2008 ACM SIGMOD international conference on Management", "citeRegEx": "Bollacker et al\\.,? 2008", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Translating embeddings for modeling multirelational data", "author": ["Antoine Bordes", "Nicolas Usunier", "Alberto GarciaDuran", "Jason Weston", "Oksana Yakhnenko."], "venue": "Advances in neural information processing systems, pages 2787\u20132795.", "citeRegEx": "Bordes et al\\.,? 2013", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "Toward an architecture for neverending language learning", "author": ["Andrew Carlson", "Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam R. Hruschka Jr.", "Tom M. Mitchell."], "venue": "AAAI.", "citeRegEx": "Carlson et al\\.,? 2010a", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Toward an architecture for neverending language learning", "author": ["Andrew Carlson", "Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam R. Hruschka Jr.", "Tom M. Mitchell."], "venue": "Proceedings of the Twenty-Fourth Conference on Artificial Intelligence", "citeRegEx": "Carlson et al\\.,? 2010b", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Chains of reasoning over entities, relations, and text using recurrent neural networks", "author": ["Rajarshi Das", "Arvind Neelakantan", "David Belanger", "Andrew McCallum."], "venue": "EACL.", "citeRegEx": "Das et al\\.,? 2017", "shortCiteRegEx": "Das et al\\.", "year": 2017}, {"title": "Improving learning", "author": ["Matt Gardner", "Partha Pratim Talukdar", "Bryan Kisiel", "Tom M Mitchell"], "venue": null, "citeRegEx": "Gardner et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gardner et al\\.", "year": 2013}, {"title": "Incorporating vector space similarity in random walk inference over knowledge bases", "author": ["Matt Gardner", "Partha Pratim Talukdar", "Jayant Krishnamurthy", "Tom Mitchell"], "venue": null, "citeRegEx": "Gardner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gardner et al\\.", "year": 2014}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio."], "venue": "Advances in Neural Information Processing Systems, pages 2672\u20132680.", "citeRegEx": "Goodfellow et al\\.,? 2014", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Traversing knowledge graphs in vector space", "author": ["Kelvin Guu", "John Miller", "Percy Liang."], "venue": "EMNLP.", "citeRegEx": "Guu et al\\.,? 2015", "shortCiteRegEx": "Guu et al\\.", "year": 2015}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared", "author": ["Geoffrey Hinton", "Li Deng", "Dong Yu", "George E Dahl", "Abdel-rahman Mohamed", "Navdeep Jaitly", "Andrew Senior", "Vincent Vanhoucke", "Patrick Nguyen", "Tara N Sainath"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Knowledge graph embedding via dynamic mapping matrix", "author": ["Guoliang Ji", "Shizhu He", "Liheng Xu", "Kang Liu", "Jun Zhao."], "venue": "ACL (1), pages 687\u2013696.", "citeRegEx": "Ji et al\\.,? 2015", "shortCiteRegEx": "Ji et al\\.", "year": 2015}, {"title": "Inferring and executing programs for visual reasoning", "author": ["Justin Johnson", "Bharath Hariharan", "Laurens van der Maaten", "Judy Hoffman", "Li Fei-Fei", "C Lawrence Zitnick", "Ross Girshick."], "venue": "arXiv preprint arXiv:1705.03633.", "citeRegEx": "Johnson et al\\.,? 2017", "shortCiteRegEx": "Johnson et al\\.", "year": 2017}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "arXiv preprint arXiv:1408.5882.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "arXiv preprint arXiv:1412.6980.", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton."], "venue": "Advances in neural information processing systems, pages 1097\u20131105.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Random walk inference and learning in a large scale knowledge base", "author": ["Ni Lao", "Tom Mitchell", "William W Cohen."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 529\u2013539. Association for Computa-", "citeRegEx": "Lao et al\\.,? 2011a", "shortCiteRegEx": "Lao et al\\.", "year": 2011}, {"title": "Random walk inference and learning in a large scale knowledge base", "author": ["Ni Lao", "Tom M. Mitchell", "William W. Cohen."], "venue": "EMNLP, pages 529\u2013 539. ACL.", "citeRegEx": "Lao et al\\.,? 2011b", "shortCiteRegEx": "Lao et al\\.", "year": 2011}, {"title": "Efficient relational learning with hidden variable detection", "author": ["Ni Lao", "Jun Zhu", "Xinwang Liu", "Yandong Liu", "William W Cohen."], "venue": "NIPS, pages 1234\u20131242.", "citeRegEx": "Lao et al\\.,? 2010", "shortCiteRegEx": "Lao et al\\.", "year": 2010}, {"title": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision", "author": ["Chen Liang", "Jonathan Berant", "Quoc Le", "Kenneth D Forbus", "Ni Lao."], "venue": "arXiv preprint arXiv:1611.00020.", "citeRegEx": "Liang et al\\.,? 2016", "shortCiteRegEx": "Liang et al\\.", "year": 2016}, {"title": "Learning entity and relation embeddings for knowledge graph completion", "author": ["Yankai Lin", "Zhiyuan Liu", "Maosong Sun", "Yang Liu", "Xuan Zhu."], "venue": "AAAI, pages 2181\u20132187.", "citeRegEx": "Lin et al\\.,? 2015", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "Playing atari with deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Alex Graves", "Ioannis Antonoglou", "Daan Wierstra", "Martin Riedmiller."], "venue": "arXiv preprint arXiv:1312.5602.", "citeRegEx": "Mnih et al\\.,? 2013", "shortCiteRegEx": "Mnih et al\\.", "year": 2013}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": null, "citeRegEx": "Mnih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "Compositional vector space models for knowledge base completion", "author": ["Arvind Neelakantan", "Benjamin Roth", "Andrew McCallum."], "venue": "arXiv preprint arXiv:1504.06662.", "citeRegEx": "Neelakantan et al\\.,? 2015", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2015}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": null, "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "Representing text for joint embedding of text and knowledge bases", "author": ["Kristina Toutanova", "Danqi Chen", "Patrick Pantel", "Hoifung Poon", "Pallavi Choudhury", "Michael Gamon."], "venue": "EMNLP, volume 15, pages 1499\u20131509. Citeseer.", "citeRegEx": "Toutanova et al\\.,? 2015", "shortCiteRegEx": "Toutanova et al\\.", "year": 2015}, {"title": "Joint information extraction and reasoning: A scalable statistical relational learning approach", "author": ["William Yang Wang", "William W Cohen."], "venue": "ACL.", "citeRegEx": "Wang and Cohen.,? 2015", "shortCiteRegEx": "Wang and Cohen.", "year": 2015}, {"title": "Knowledge graph embedding by translating on hyperplanes", "author": ["Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen."], "venue": "AAAI, pages 1112\u20131119. Citeseer.", "citeRegEx": "Wang et al\\.,? 2014", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning", "author": ["Ronald J Williams."], "venue": "Machine learning, 8(3-4):229\u2013256.", "citeRegEx": "Williams.,? 1992", "shortCiteRegEx": "Williams.", "year": 1992}, {"title": "Relation classification via convolutional deep neural network", "author": ["Daojian Zeng", "Kang Liu", "Siwei Lai", "Guangyou Zhou", "Jun Zhao"], "venue": "In COLING,", "citeRegEx": "Zeng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeng et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 14, "context": "In recent years, deep learning techniques have obtained many state-of-the-art results in various classification and recognition problems (Krizhevsky et al., 2012; Hinton et al., 2012; Kim, 2014).", "startOffset": 137, "endOffset": 194}, {"referenceID": 9, "context": "In recent years, deep learning techniques have obtained many state-of-the-art results in various classification and recognition problems (Krizhevsky et al., 2012; Hinton et al., 2012; Kim, 2014).", "startOffset": 137, "endOffset": 194}, {"referenceID": 12, "context": "In recent years, deep learning techniques have obtained many state-of-the-art results in various classification and recognition problems (Krizhevsky et al., 2012; Hinton et al., 2012; Kim, 2014).", "startOffset": 137, "endOffset": 194}, {"referenceID": 1, "context": "In contrast to PRA, we use translationbased knowledge based embedding method (Bordes et al., 2013) to encode the continuous state of our RL agent, which reasons in the vector space environment of the knowledge graph.", "startOffset": 77, "endOffset": 98}, {"referenceID": 21, "context": "To better guide the RL agent for learning relational paths, we use policy gradient training (Mnih et al., 2015) with a novel reward function that jointly encourages accuracy, diversity, and efficiency.", "startOffset": 92, "endOffset": 111}, {"referenceID": 2, "context": "Empirically, we show that our method outperforms PRA and embedding based methods on a Freebase and a Never-Ending Language Learning (Carlson et al., 2010a) dataset.", "startOffset": 132, "endOffset": 155}, {"referenceID": 16, "context": "The Path-Ranking Algorithm (PRA) method (Lao et al., 2011b) is a primary path-finding approach that uses random walk with restart strategies for multi-hop reasoning.", "startOffset": 40, "endOffset": 59}, {"referenceID": 22, "context": "Note that many of the recent KG reasoning methods (Neelakantan et al., 2015; Das et al., 2017) still rely on first learning the PRA paths, which only operates in a discrete space.", "startOffset": 50, "endOffset": 94}, {"referenceID": 4, "context": "Note that many of the recent KG reasoning methods (Neelakantan et al., 2015; Das et al., 2017) still rely on first learning the PRA paths, which only operates in a discrete space.", "startOffset": 50, "endOffset": 94}, {"referenceID": 4, "context": "Gardner et al. (2013; 2014) propose a modification to PRA that computes feature similarity in the vector space. Wang and Cohen (2015) introduce a recursive random walk approach for integrating the background KG and text\u2014the method performs structure learning of logic programs and information extraction from text at the same time.", "startOffset": 0, "endOffset": 134}, {"referenceID": 4, "context": "Gardner et al. (2013; 2014) propose a modification to PRA that computes feature similarity in the vector space. Wang and Cohen (2015) introduce a recursive random walk approach for integrating the background KG and text\u2014the method performs structure learning of logic programs and information extraction from text at the same time. A potential bottleneck for random walk inference is that supernodes connecting to large amount of formulas will create huge fan-out areas that significantly slow down the inference and affect the accuracy. Toutanova et al. (2015) provide a convolutional neural network solution to multi-hop reasoning.", "startOffset": 0, "endOffset": 562}, {"referenceID": 4, "context": "Gardner et al. (2013; 2014) propose a modification to PRA that computes feature similarity in the vector space. Wang and Cohen (2015) introduce a recursive random walk approach for integrating the background KG and text\u2014the method performs structure learning of logic programs and information extraction from text at the same time. A potential bottleneck for random walk inference is that supernodes connecting to large amount of formulas will create huge fan-out areas that significantly slow down the inference and affect the accuracy. Toutanova et al. (2015) provide a convolutional neural network solution to multi-hop reasoning. They build a CNN model based on lexicalized dependency paths, which suffers from the error propagation issue due to parse errors. Guu et al. (2015) uses KG embeddings to answer path queries.", "startOffset": 0, "endOffset": 782}, {"referenceID": 4, "context": "Gardner et al. (2013; 2014) propose a modification to PRA that computes feature similarity in the vector space. Wang and Cohen (2015) introduce a recursive random walk approach for integrating the background KG and text\u2014the method performs structure learning of logic programs and information extraction from text at the same time. A potential bottleneck for random walk inference is that supernodes connecting to large amount of formulas will create huge fan-out areas that significantly slow down the inference and affect the accuracy. Toutanova et al. (2015) provide a convolutional neural network solution to multi-hop reasoning. They build a CNN model based on lexicalized dependency paths, which suffers from the error propagation issue due to parse errors. Guu et al. (2015) uses KG embeddings to answer path queries. Zeng et al. (2014) described a CNN model for relational extraction, but it does not explicitly model the relational paths.", "startOffset": 0, "endOffset": 844}, {"referenceID": 4, "context": "Gardner et al. (2013; 2014) propose a modification to PRA that computes feature similarity in the vector space. Wang and Cohen (2015) introduce a recursive random walk approach for integrating the background KG and text\u2014the method performs structure learning of logic programs and information extraction from text at the same time. A potential bottleneck for random walk inference is that supernodes connecting to large amount of formulas will create huge fan-out areas that significantly slow down the inference and affect the accuracy. Toutanova et al. (2015) provide a convolutional neural network solution to multi-hop reasoning. They build a CNN model based on lexicalized dependency paths, which suffers from the error propagation issue due to parse errors. Guu et al. (2015) uses KG embeddings to answer path queries. Zeng et al. (2014) described a CNN model for relational extraction, but it does not explicitly model the relational paths. Neelakantan et al. (2015) propose a recurrent neural networks model for modeling relational paths in knowledge base completion (KBC), but it trains too many separate models, and therefore it does not scale.", "startOffset": 0, "endOffset": 974}, {"referenceID": 18, "context": "Neural symbolic machine (Liang et al., 2016) is a more recent work on KG reasoning, which also applies reinforcement learning but has a different flavor from our work.", "startOffset": 24, "endOffset": 44}, {"referenceID": 11, "context": "A similar framework (Johnson et al., 2017) has also been applied to visual reasoning tasks.", "startOffset": 20, "endOffset": 42}, {"referenceID": 20, "context": "Compared to Deep Q Network (DQN) (Mnih et al., 2013), policy-based RL methods turn out to be more appropriate for our knowledge graph scenario.", "startOffset": 33, "endOffset": 52}, {"referenceID": 0, "context": "Since existing practical KGs like Freebase (Bollacker et al., 2008) and NELL (Carlson et al.", "startOffset": 43, "endOffset": 67}, {"referenceID": 3, "context": ", 2008) and NELL (Carlson et al., 2010b) often have huge amounts of triples.", "startOffset": 17, "endOffset": 40}, {"referenceID": 1, "context": "To capture the semantic information of these symbols, we use translation-based embeddings such as TransE (Bordes et al., 2013) and TransH (Wang et al.", "startOffset": 105, "endOffset": 126}, {"referenceID": 26, "context": ", 2013) and TransH (Wang et al., 2014) to represent the entities and relations.", "startOffset": 19, "endOffset": 38}, {"referenceID": 23, "context": "To tackle this problem, we start our training with a supervised policy which is inspired by the imitation learning pipeline used by AlphaGo (Silver et al., 2016).", "startOffset": 140, "endOffset": 161}, {"referenceID": 27, "context": "INFORCE) (Williams, 1992):", "startOffset": 9, "endOffset": 25}, {"referenceID": 13, "context": "In practice, \u03b8 is updated using the Adam Optimizer (Kingma and Ba, 2014) with L2 regularization.", "startOffset": 51, "endOffset": 72}, {"referenceID": 24, "context": "The triples in FB15K-237 (Toutanova et al., 2015) are sampled from FB15K (Bordes et al.", "startOffset": 25, "endOffset": 49}, {"referenceID": 1, "context": ", 2015) are sampled from FB15K (Bordes et al., 2013) with redundant relations removed.", "startOffset": 31, "endOffset": 52}, {"referenceID": 15, "context": "For path based methods, we compare our RL model with the PRA (Lao et al., 2011a) algorithm, which has been used in a couple of reasoning methods (Gardner et al.", "startOffset": 61, "endOffset": 80}, {"referenceID": 5, "context": ", 2011a) algorithm, which has been used in a couple of reasoning methods (Gardner et al., 2013; Neelakantan et al., 2015).", "startOffset": 73, "endOffset": 121}, {"referenceID": 22, "context": ", 2011a) algorithm, which has been used in a couple of reasoning methods (Gardner et al., 2013; Neelakantan et al., 2015).", "startOffset": 73, "endOffset": 121}, {"referenceID": 1, "context": "For embedding based methods, we evaluate several state-of-the-art embeddings designed for knowledge base completion, such as TransE (Bordes et al., 2013), TransH (Wang et al.", "startOffset": 132, "endOffset": 153}, {"referenceID": 26, "context": ", 2013), TransH (Wang et al., 2014), TransR (Lin et al.", "startOffset": 16, "endOffset": 35}, {"referenceID": 19, "context": ", 2014), TransR (Lin et al., 2015) and TransD (Ji et al.", "startOffset": 16, "endOffset": 34}, {"referenceID": 10, "context": ", 2015) and TransD (Ji et al., 2015) .", "startOffset": 19, "endOffset": 36}, {"referenceID": 15, "context": "code released by (Lao et al., 2011a).", "startOffset": 17, "endOffset": 36}], "year": 2017, "abstractText": "We study the problem of learning to reason in large scale knowledge graphs (KGs). More specifically, we describe a novel reinforcement learning framework for learning multi-hop relational paths: we use a policy-based agent with continuous states based on knowledge graph embeddings, which reasons in a KG vector space by sampling the most promising relation to extend its path. In contrast to prior work, our approach includes a reward function that takes the accuracy, diversity, and efficiency into consideration. Experimentally, we show that our proposed method outperforms a path-ranking based algorithm and knowledge graph embedding methods on Freebase and Never-Ending Language Learning datasets.1", "creator": "LaTeX with hyperref package"}}}