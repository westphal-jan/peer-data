{"id": "1707.06971", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jul-2017", "title": "Split and Rephrase", "abstract": "We propose a new sentence simplification task (Split-and-Rephrase) where the aim is to split a complex sentence into a meaning preserving sequence of shorter sentences. Like sentence simplification, splitting-and-rephrasing has the potential of benefiting both natural language processing and societal applications. Because shorter sentences are generally better processed by NLP systems, it could be used as a preprocessing step which facilitates and improves the performance of parsers, semantic role labellers and machine translation systems. It should also be of use for people with reading disabilities because it allows the conversion of longer sentences into shorter ones. This paper makes two contributions towards this new task. First, we create and make available a benchmark consisting of 1,066,115 tuples mapping a single complex sentence to a sequence of sentences expressing the same meaning. Second, we propose five models (vanilla sequence-to-sequence to semantically-motivated models) to understand the difficulty of the proposed task.", "histories": [["v1", "Fri, 21 Jul 2017 16:47:56 GMT  (41kb,D)", "http://arxiv.org/abs/1707.06971v1", "11 pages, EMNLP 2017"]], "COMMENTS": "11 pages, EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shashi narayan", "claire gardent", "shay b cohen", "anastasia shimorina"], "accepted": true, "id": "1707.06971"}, "pdf": {"name": "1707.06971.pdf", "metadata": {"source": "CRF", "title": "Split and Rephrase", "authors": ["Shashi Narayan", "Claire Gardent", "Shay B. Cohen", "Anastasia Shimorina"], "emails": ["shashi.narayan@ed.ac.uk", "claire.gardent@loria.fr", "scohen@inf.ed.ac.uk", "anastasia.shimorina@loria.fr"], "sections": [{"heading": "1 Introduction", "text": "Several sentence transcriptions have been extensively discussed in the literature: sentence compression, multi-sentence fusion, sentence paraphrasing and sentence simplification because they transcribe an initial sentence into a shorter transcription (Knight and Marcu, 2000; Cohn and Lapata, 2008; Filippova et al., 2015; Toutanova et al., 2016). Sentence fusion consists of combining two or more sentences with overlapping information and deleting irrelevant details (McKeown et al., 2010; Filippova et al., 2010; Thadani and McKeown, 2013)."}, {"heading": "2 Related Work", "text": "Most simplification methods learn a statistical model (Zhu et al., 2010; Coster and Kauchak, 2011; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014) from the parallel age of complex sentences, that of Zhu et al. (2010) from the simple English Wikipedia2 and the traditional online loan. For the education of children and adolescents, this dataset is hardly suitable, as it consists of 108,016 complex and 114,924 simplified sentences, with an average number of simple sentences per complex sentence of 1.06. In fact, Narayan and Gardent (2014) report that only 6.1% of complex sentences are in the equivalent of English."}, {"heading": "3 The WEBSPLIT Benchmark", "text": "We derive a split-and-rephrase dataset from the WEBNLG corpus presented in Gardent et al. (2017).3.1 The WEBNLG dataset In the WEBNLG dataset, each element consists of a set of RDF triples (M) and one or more texts (Ti) that verbalize these triples. An RDF dataset (Resource Description Format) is a triple of the Subject | Object | Object form, where the subject is an URI (Uniform Resource Identifier), the property is a binary relationship, and the object is either an URI or a literal value such as a string, date, or number. In the following, we refer to the sets of triples that represent the meaning of a text as its representation (MR). Figure 1 shows three examples of WEBNLG variants with M1, M2, M3 the sets of DF-categories {7}, the subcategories {7}, and the subcategories {11}."}, {"heading": "3.2 Creating the WEBSPLIT Dataset", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "3.3 Results", "text": "By applying the above procedure to the WEBNLG data set, we create 1,100,166 pairs of the form < (MC, TC), {(M1, T1).. (Mn, Tn) >, where TC is a complex sentence and T1... Tn is a sequence of texts with semantics M1,... Mn expressing the same content MC as TC. 1,945 of these pairs were of type \"within entries\" and the rest of type \"vertical entries.\" In total, there are 1,066,115 unique < TC, T1.... Tn > pairs with 5,546 unique complex sentences. Complex sentences are associated with an average of 192.23 repetitions (min: 1, max: 76283, median: 16). The number of sentences in the repetitions varies between 2 and 7 with an average of 4.99. The vocabulary size is 3,311,5As the examples in Figure 1 show, this case is not always associated with a hayday."}, {"heading": "4 Problem Formulation", "text": "For a complex sentence C, the aim is to produce a simplified text T consisting of a sequence of texts T1... Tn in such a way that T forms a text of at least two sentences and the meaning of C in T. In this paper, we have proposed to address this problem in a monitored environment in which we aim to maximize the probability of T given C and model parameters: P (T | C; \u03b8). In order to use the different levels of information in the WEBSPLIT benchmark, we break down the problem in the following way: P (T | C; \u03b8) = \u2211 MC P (T | C; MC; \u03b8) P (MC | C; \u03b8) (1) = P (T | C; MC; \u03b8), if MC is known. (2) = \u0445 M1 \u2212 nP (T | C; MC; M1 \u2212 n; TB) \u00d7 P (M1 \u2212 n; MC; 3), where MC is located."}, {"heading": "5 Split-and-Rephrase Models", "text": "In this section, we propose five different models that aim to maximize the P / E by using different levels of information in the WEBSPLIT benchmark."}, {"heading": "5.1 A Probabilistic, Semantic-Based Approach", "text": "Narayan and Gardent (2014) describes an approach to sentence simplification that combines a probabilistic model of splitting and deletion with a phrase-based statistical machine translation (SMT) and a language model of reformulation (reordering and replacing words). Specifically, the split and delete components utilize the Discourse Representation Structure (DRS) of a complex sentence produced by Boxer (Curran et al., 2007). Based on this approach, we create a split-and-rephrase model (also known as HYBRIDSIMPL) by (i) including only splitting and SMT models (we do not learn deletion) and (ii) training the model on the WEBSPLIT corpus."}, {"heading": "5.2 A Basic Sequence-to-Sequence Approach", "text": "Sequence-to-sequence models (also referred to as encoder decoders) have been successfully applied to various sentence transcription tasks such as machine translation (Sutskever et al., 2011; Bahdanau et al., 2014), abstract summary (Rush et al., 2015), and response generation (Shang et al., 2015). First, they use a recursive neural network (RNN) to convert a source sequence into a dense, fixed vector representation (encoder), and then use another recursive network (decoder) to convert this vector into a target sequence. Our decoder also uses a three-layer encoder decoder model with LSTM (Long Short-Term Memory, (Hochreiter and Schmidhuber, 1997)) units for the split-and-phrase task."}, {"heading": "5.3 A Multi-Source Sequence-to-Sequence Approach", "text": "In this model, we learn a multi-source model that takes into account not only the input of complex sentences, but also the associated set of RDF triples available in the WEBSPLIT dataset. That is, we maximize P (T | C; MC; \u03b8) (Eqn. 2) and learn a model to rephrase C. In the face of a complex sentence C and its semantics MC, as noted by Gardent et al. (2017), the form of input could affect the syntactic structure of the corresponding text. For example, an input containing a path (X | P1 | Y) (Y | P2 | Z), equating the object of a property P1 with the subject of a property P2 might favor an association containing a subject code (\"x V1 y who V2 z\"), taking into account not only the sentence C, which needs to be reformulated, but also its semantics of RDF models."}, {"heading": "5.4 Partitioning and Generating", "text": "As the name suggests, the split-and-rephrase task can be regarded as a task consisting of two subtasks: (i) the division of a complex sentence into several shorter sentences and (ii) the reformulation of the input sentence to match the new sentence distribution. We consider an approach that explicitly models these two steps (Eqn. 3). A first model P (M1,..., Mn., Mn.) triples. Next, we create a reformulation of the C model as follows: P (T | C; MC; M1) triples the patterns associated with a complex sentence C into a fragmented set (M1,..., Mn.) of sentences MDF triples."}, {"heading": "6 Experimental Setup and Results", "text": "This section describes our experimental setup and results. We also describe the implementation details to facilitate the replication of our results."}, {"heading": "6.1 Training, Validation and Test sets", "text": "To ensure that complex sets are not visible in validation and test sets during training, we divide the 5,546 different complex sets in WEBSPLITdata into three subsets: Training Set (4,438.80%), Validation Set (554, 10%), and Test Set (554, 10%). Table 2 shows a summary of the task and size of the training corpus for each of the 5 models. For those models that directly learn to form a complex set into a meaningful sequence of at least two sets (HYBRIDSIMPL, SEQ2SEQ, and MULTISEQ2SEQ), the training set consists of 886,857 < C, T > paired with C a complex set and T, the corresponding text. In contrast, the pipeline models that partition the input first and then use RDF data (SPLIT-MULT2QSEQLIT and SPLIT-SE2QLIT < < < < < < SE2Q2Q < < < < < < < SE2Q < < < < < < < SE2Q < < < 5Q; 5Q; <"}, {"heading": "6.2 Implementation Details", "text": "For all of our neural models, we train RNNs with three-layer LSTM units, 500 hidden states, and a regularization failure with a probability of 0.8. All LSTM parameters were randomly initialized via a uniform distribution within [-0.05, 0.05]. We trained our models with stochastic gradient descent with an initial learning rate of 0.5. Each time the perplexity of the amount of validation provided increased as it was previously verified, we multiplied the current learning rate by 0.5. Since the vocabulary size of WEBSPLIT data is small, we train both encoders and decoders with full vocabulary. We initialize word embedding at the beginning and let the model access our system during the training."}, {"heading": "6.3 Results", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "7 Conclusion", "text": "We have proposed a new task for sentence simplification, which we call \"split-and-rephrase.\" For this task, we have constructed a new corpus based on readily available data used for the evaluation of NLG (Natural Language Generation). Initial experiments suggest that the ability to split is a key factor in generating fluent and meaningful phrasing, because it enables a complex generational task (the generation of a text from at least two sentences) to be reduced to a series of simpler tasks (the generation of short sentences). In future work, it would be interesting to see if and if so how sentence division can be learned without explicit semantic information in the input field. Another direction for future work concerns the exploitation of the extended WebNLG corpus. While the results presented in this paper use a version of the WebNLG corpus, which consists of 13,308 MR text pairs, 7049 clear MR16s and WebNLG optimized modules, and BLG-4.04 of the current WebNLG corpus, conclude a set of these categories."}, {"heading": "Acknowledgements", "text": "We thank Bonnie Webber and Annie Louis for early discussions on the ideas presented in the paper. We thank Rico Sennrich for the guidance on multi-source NMT models. This work benefited greatly from discussions with members of the Edinburgh NLP Group. We also thank the three anonymous reviewers for their comments on how to improve the paper. The research presented in this paper was partially supported by the H2020 SUMMA project (under funding agreement 688139) and the French National Research Agency under the WebNLG project (ANR-14CE24-0033)."}], "references": [{"title": "s occupation was a test pilot", "author": ["Alan Shepard"], "venue": "Alan Shepard was born in New Hampshire . Alan Shepard was born on Nov", "citeRegEx": "Shepard,? \\Q1923\\E", "shortCiteRegEx": "Shepard", "year": 1923}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["References Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "CoRR, abs/1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Paraphrasing with bilingual parallel corpora", "author": ["Colin Bannard", "Chris Callison-Burch."], "venue": "Proceedings of ACL.", "citeRegEx": "Bannard and Callison.Burch.,? 2005", "shortCiteRegEx": "Bannard and Callison.Burch.", "year": 2005}, {"title": "Extracting paraphrases from a parallel corpus", "author": ["Regina Barzilay", "Kathleen R McKeown."], "venue": "Proceedings of ACL.", "citeRegEx": "Barzilay and McKeown.,? 2001", "shortCiteRegEx": "Barzilay and McKeown.", "year": 2001}, {"title": "Text simplification as tree labeling", "author": ["Joachim Bingel", "Anders S\u00f8gaard."], "venue": "Proceedings of ACL.", "citeRegEx": "Bingel and S\u00f8gaard.,? 2016", "shortCiteRegEx": "Bingel and S\u00f8gaard.", "year": 2016}, {"title": "Syntactic simplification of Text", "author": ["Yvonne Margaret Canning."], "venue": "Ph.D. thesis, University of Sunderland.", "citeRegEx": "Canning.,? 2002", "shortCiteRegEx": "Canning.", "year": 2002}, {"title": "Simplifying text for language-impaired readers", "author": ["John Carroll", "Guido Minnen", "Darren Pearce", "Yvonne Canning", "Siobhan Devlin", "John Tait."], "venue": "Proceedings of EACL.", "citeRegEx": "Carroll et al\\.,? 1999", "shortCiteRegEx": "Carroll et al\\.", "year": 1999}, {"title": "Motivations and methods for text simplification", "author": ["Raman Chandrasekar", "Christine Doran", "Bangalore Srinivas."], "venue": "Proceedings of COLING.", "citeRegEx": "Chandrasekar et al\\.,? 1996", "shortCiteRegEx": "Chandrasekar et al\\.", "year": 1996}, {"title": "Automatic induction of rules for text simplification", "author": ["Raman Chandrasekar", "Bangalore Srinivas."], "venue": "Knowledge-Based Systems, 10(3):183\u2013190.", "citeRegEx": "Chandrasekar and Srinivas.,? 1997", "shortCiteRegEx": "Chandrasekar and Srinivas.", "year": 1997}, {"title": "Sentence compression beyond word deletion", "author": ["Trevor Cohn", "Mirella Lapata."], "venue": "Proceedings of COLING.", "citeRegEx": "Cohn and Lapata.,? 2008", "shortCiteRegEx": "Cohn and Lapata.", "year": 2008}, {"title": "Learning to simplify sentences using wikipedia", "author": ["William Coster", "David Kauchak."], "venue": "Proceedings of Monolingual Text-To-Text Generation.", "citeRegEx": "Coster and Kauchak.,? 2011", "shortCiteRegEx": "Coster and Kauchak.", "year": 2011}, {"title": "Linguistically motivated large-scale NLP with C&C and Boxer", "author": ["James R Curran", "Stephen Clark", "Johan Bos."], "venue": "Proceedings of ACL.", "citeRegEx": "Curran et al\\.,? 2007", "shortCiteRegEx": "Curran et al\\.", "year": 2007}, {"title": "Generic sentence fusion is an ill-defined summarization task", "author": ["Hal Daume III", "Daniel Marcu."], "venue": "Technical report, DTIC.", "citeRegEx": "III and Marcu.,? 2004", "shortCiteRegEx": "III and Marcu.", "year": 2004}, {"title": "Text simplification for children", "author": ["Jan De Belder", "Marie-Francine Moens."], "venue": "Proceedings of the SIGIR Workshop on Accessible Search Systems.", "citeRegEx": "Belder and Moens.,? 2010", "shortCiteRegEx": "Belder and Moens.", "year": 2010}, {"title": "Tree adjoining grammar and the reluctant paraphrasing of text", "author": ["Mark Dras."], "venue": "Ph.D. thesis, Macquarie University, Australia.", "citeRegEx": "Dras.,? 1999", "shortCiteRegEx": "Dras.", "year": 1999}, {"title": "Answering the question you wish they had asked: The impact of paraphrasing for question answering", "author": ["Pablo Ariel Duboue", "Jennifer Chu-Carroll."], "venue": "Proceedings of NAACL-HLT.", "citeRegEx": "Duboue and Chu.Carroll.,? 2006", "shortCiteRegEx": "Duboue and Chu.Carroll.", "year": 2006}, {"title": "Learning paraphrases to improve a questionanswering system", "author": ["Florence Duclaye", "Fran\u00e7ois Yvon", "Olivier Collin."], "venue": "Proceedings of the EACL Workshop on Natural Language Processing for Question Answering Systems.", "citeRegEx": "Duclaye et al\\.,? 2003", "shortCiteRegEx": "Duclaye et al\\.", "year": 2003}, {"title": "Multi-sentence compression: Finding shortest paths in word graphs", "author": ["Katja Filippova."], "venue": "Proceedings of COLING.", "citeRegEx": "Filippova.,? 2010", "shortCiteRegEx": "Filippova.", "year": 2010}, {"title": "Sentence compression by deletion with LSTMs", "author": ["Katja Filippova", "Enrique Alfonseca", "Carlos Colmenares", "Lukasz Kaiser", "Oriol Vinyals."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Filippova et al\\.,? 2015", "shortCiteRegEx": "Filippova et al\\.", "year": 2015}, {"title": "Dependency tree based sentence compression", "author": ["Katja Filippova", "Michael Strube."], "venue": "Proceedings of INLG.", "citeRegEx": "Filippova and Strube.,? 2008", "shortCiteRegEx": "Filippova and Strube.", "year": 2008}, {"title": "Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation", "author": ["Juri Ganitkevitch", "Chris Callison-Burch", "Courtney Napoles", "Benjamin Van Durme."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Ganitkevitch et al\\.,? 2011", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2011}, {"title": "Creating training corpora for nlg micro-planning", "author": ["Claire Gardent", "Anastasia Shimorina", "Shashi Narayan", "Laura Perez-Beltrachini."], "venue": "Proceedings of ACL.", "citeRegEx": "Gardent et al\\.,? 2017", "shortCiteRegEx": "Gardent et al\\.", "year": 2017}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation, 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Text simplification for reading assistance: A project note", "author": ["Kentaro Inui", "Atsushi Fujita", "Tetsuro Takahashi", "Ryu Iida", "Tomoya Iwakura."], "venue": "Proceedings of the workshop on Paraphrasing.", "citeRegEx": "Inui et al\\.,? 2003", "shortCiteRegEx": "Inui et al\\.", "year": 2003}, {"title": "Improvements to dependency parsing using automatic simplification of data", "author": ["Tom\u00e1\u0161 Jel\u0131\u0301nek"], "venue": "In Proceedings of LREC", "citeRegEx": "Jel\u0131\u0301nek.,? \\Q2014\\E", "shortCiteRegEx": "Jel\u0131\u0301nek.", "year": 2014}, {"title": "A theory of truth and semantic representation", "author": ["Hans Kamp."], "venue": "Formal Methods in the Study of Language, volume 1, pages 277\u2013322. Mathematisch Centrum.", "citeRegEx": "Kamp.,? 1981", "shortCiteRegEx": "Kamp.", "year": 1981}, {"title": "Statisticsbased summarization-step one: Sentence compression", "author": ["Kevin Knight", "Daniel Marcu."], "venue": "Proceedings of AAAI-IAAI.", "citeRegEx": "Knight and Marcu.,? 2000", "shortCiteRegEx": "Knight and Marcu.", "year": 2000}, {"title": "Effective approaches to attentionbased neural machine translation", "author": ["Thang Luong", "Hieu Pham", "Christopher D. Manning."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Paraphrasing revisited with neural machine translation", "author": ["Jonathan Mallinson", "Rico Sennrich", "Mirella Lapata."], "venue": "Proceedings of EACL.", "citeRegEx": "Mallinson et al\\.,? 2017", "shortCiteRegEx": "Mallinson et al\\.", "year": 2017}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky."], "venue": "Proceedings of ACL System Demonstrations.", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Analyzing and integrating dependency parsers", "author": ["Ryan McDonald", "Joakim Nivre."], "venue": "Computational Linguistics, 37(1):197\u2013230.", "citeRegEx": "McDonald and Nivre.,? 2011", "shortCiteRegEx": "McDonald and Nivre.", "year": 2011}, {"title": "Time-efficient creation of an accurate sentence fusion corpus", "author": ["Kathleen McKeown", "Sara Rosenthal", "Kapil Thadani", "Coleman Moore."], "venue": "Proceedings of NAACL-HLT.", "citeRegEx": "McKeown et al\\.,? 2010", "shortCiteRegEx": "McKeown et al\\.", "year": 2010}, {"title": "Hybrid simplification using deep semantics and machine translation", "author": ["Shashi Narayan", "Claire Gardent."], "venue": "Proceedings of ACL.", "citeRegEx": "Narayan and Gardent.,? 2014", "shortCiteRegEx": "Narayan and Gardent.", "year": 2014}, {"title": "Unsupervised sentence simplification using deep semantics", "author": ["Shashi Narayan", "Claire Gardent."], "venue": "Proceedings of INLG.", "citeRegEx": "Narayan and Gardent.,? 2016", "shortCiteRegEx": "Narayan and Gardent.", "year": 2016}, {"title": "Paraphrase generation from Latent-Variable PCFGs for semantic parsing", "author": ["Shashi Narayan", "Siva Reddy", "Shay B. Cohen."], "venue": "Proceedings of INLG.", "citeRegEx": "Narayan et al\\.,? 2016", "shortCiteRegEx": "Narayan et al\\.", "year": 2016}, {"title": "BLEU: A method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu."], "venue": "Proceedings of ACL.", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Methods for sentence compression", "author": ["Emily Pitler."], "venue": "Technical report, University of Pennsylvania.", "citeRegEx": "Pitler.,? 2010", "shortCiteRegEx": "Pitler.", "year": 2010}, {"title": "Monolingual machine translation for paraphrase generation", "author": ["Chris Quirk", "Chris Brockett", "William B Dolan."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Quirk et al\\.,? 2004", "shortCiteRegEx": "Quirk et al\\.", "year": 2004}, {"title": "Learning surface text patterns for a question answering system", "author": ["Deepak Ravichandran", "Eduard Hovy."], "venue": "Proceedings of ACL.", "citeRegEx": "Ravichandran and Hovy.,? 2002", "shortCiteRegEx": "Ravichandran and Hovy.", "year": 2002}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Alexander M. Rush", "Sumit Chopra", "Jason Weston."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Rush et al\\.,? 2015", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Neural responding machine for short-text conversation", "author": ["Lifeng Shang", "Zhengdong Lu", "Hang Li."], "venue": "CoRR, abs/1503.02364.", "citeRegEx": "Shang et al\\.,? 2015", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "An architecture for a text simplification system", "author": ["Advaith Siddharthan."], "venue": "Proceedings of Language Engineering Conference. IEEE Computer Society.", "citeRegEx": "Siddharthan.,? 2002", "shortCiteRegEx": "Siddharthan.", "year": 2002}, {"title": "Complex lexico-syntactic reformulation of sentences using typed dependency representations", "author": ["Advaith Siddharthan."], "venue": "Proceedings of INLG.", "citeRegEx": "Siddharthan.,? 2010", "shortCiteRegEx": "Siddharthan.", "year": 2010}, {"title": "Text simplification using typed dependencies: A comparison of the robustness of different generation strategies", "author": ["Advaith Siddharthan."], "venue": "Proceedings of ENLG.", "citeRegEx": "Siddharthan.,? 2011", "shortCiteRegEx": "Siddharthan.", "year": 2011}, {"title": "Hybrid text simplification using synchronous dependency grammars with hand-written and automatically harvested rules", "author": ["Advaith Siddharthan", "Angrosh Mandya."], "venue": "Proceedings of EACL.", "citeRegEx": "Siddharthan and Mandya.,? 2014", "shortCiteRegEx": "Siddharthan and Mandya.", "year": 2014}, {"title": "Syntactic simplification for improving content selection in multi-document summarization", "author": ["Advaith Siddharthan", "Ani Nenkova", "Kathleen McKeown."], "venue": "Proceedings of COLING.", "citeRegEx": "Siddharthan et al\\.,? 2004", "shortCiteRegEx": "Siddharthan et al\\.", "year": 2004}, {"title": "Generating text with recurrent neural networks", "author": ["Ilya Sutskever", "James Martens", "Geoffrey E Hinton."], "venue": "Proceedings of ICML.", "citeRegEx": "Sutskever et al\\.,? 2011", "shortCiteRegEx": "Sutskever et al\\.", "year": 2011}, {"title": "Supervised sentence fusion with single-stage inference", "author": ["Kapil Thadani", "Kathleen McKeown."], "venue": "Proceedings of IJCNLP.", "citeRegEx": "Thadani and McKeown.,? 2013", "shortCiteRegEx": "Thadani and McKeown.", "year": 2013}, {"title": "Efficient Parsing for Natural Language: A Fast Algorithm for Practical Systems", "author": ["Masaru Tomita."], "venue": "The Springer International Series in Engineering and Computer Science. Springer US.", "citeRegEx": "Tomita.,? 1985", "shortCiteRegEx": "Tomita.", "year": 1985}, {"title": "A dataset and evaluation metrics for abstractive compression of sentences and short paragraphs", "author": ["Kristina Toutanova", "Chris Brockett", "Ke M. Tran", "Saleema Amershi."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Toutanova et al\\.,? 2016", "shortCiteRegEx": "Toutanova et al\\.", "year": 2016}, {"title": "Sentence simplification for semantic role labeling", "author": ["David Vickrey", "Daphne Koller."], "venue": "Proceedings of ACL-HLT.", "citeRegEx": "Vickrey and Koller.,? 2008", "shortCiteRegEx": "Vickrey and Koller.", "year": 2008}, {"title": "Facilita: reading assistance for low-literacy readers", "author": ["Willian Massami Watanabe", "Arnaldo Candido Junior", "Vin\u0131\u0301cius Rodriguez Uz\u00eada", "Renata Pontin de Mattos Fortes", "Thiago Alexandre Salgueiro Pardo", "Sandra Maria Alu\u0131\u0301sio"], "venue": "Proceedings of ACM", "citeRegEx": "Watanabe et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Watanabe et al\\.", "year": 2009}, {"title": "Learning to simplify sentences with quasi-synchronous grammar and integer programming", "author": ["Kristian Woodsend", "Mirella Lapata."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Woodsend and Lapata.,? 2011", "shortCiteRegEx": "Woodsend and Lapata.", "year": 2011}, {"title": "Sentence simplification by monolingual machine translation", "author": ["Sander Wubben", "Antal van den Bosch", "Emiel Krahmer."], "venue": "Proceedings of ACL.", "citeRegEx": "Wubben et al\\.,? 2012", "shortCiteRegEx": "Wubben et al\\.", "year": 2012}, {"title": "Paraphrase generation as monolingual translation: Data and evaluation", "author": ["Sander Wubben", "Antal Van Den Bosch", "Emiel Krahmer."], "venue": "Proceedings of INLG.", "citeRegEx": "Wubben et al\\.,? 2010", "shortCiteRegEx": "Wubben et al\\.", "year": 2010}, {"title": "Problems in current text simplification research: New data can help", "author": ["Wei Xu", "Chris Callison-Burch", "Courtney Napoles."], "venue": "Transactions of the Association for Computational Linguistics, 3:283\u2013297.", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Optimizing statistical machine translation for text simplification", "author": ["Wei Xu", "Courtney Napoles", "Ellie Pavlick", "Quanze Chen", "Chris Callison-Burch."], "venue": "Transactions of the Association for Computational Linguistics, 4:401\u2013415.", "citeRegEx": "Xu et al\\.,? 2016", "shortCiteRegEx": "Xu et al\\.", "year": 2016}, {"title": "Sentence simplification with deep reinforcement learning", "author": ["Xingxing Zhang", "Mirella Lapata."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Zhang and Lapata.,? 2017", "shortCiteRegEx": "Zhang and Lapata.", "year": 2017}, {"title": "Pivot approach for extracting paraphrase patterns from bilingual corpora", "author": ["Shiqi Zhao", "Haifeng Wang", "Ting Liu", "Sheng Li."], "venue": "Proceedings of ACL.", "citeRegEx": "Zhao et al\\.,? 2008", "shortCiteRegEx": "Zhao et al\\.", "year": 2008}, {"title": "A monolingual tree-based translation model for sentence simplification", "author": ["Zhemin Zhu", "Delphine Bernhard", "Iryna Gurevych."], "venue": "Proceedings of COLING.", "citeRegEx": "Zhu et al\\.,? 2010", "shortCiteRegEx": "Zhu et al\\.", "year": 2010}, {"title": "Multi-source neural translation", "author": ["Barret Zoph", "Kevin Knight."], "venue": "Proceedings of NAACL-HLT.", "citeRegEx": "Zoph and Knight.,? 2016", "shortCiteRegEx": "Zoph and Knight.", "year": 2016}], "referenceMentions": [{"referenceID": 48, "context": "ing step which facilitates and improves the performance of parsers (Tomita, 1985; Chandrasekar and Srinivas, 1997; McDonald and Nivre, 2011; Jel\u0131\u0301nek, 2014), semantic role labelers (Vickrey", "startOffset": 67, "endOffset": 156}, {"referenceID": 8, "context": "ing step which facilitates and improves the performance of parsers (Tomita, 1985; Chandrasekar and Srinivas, 1997; McDonald and Nivre, 2011; Jel\u0131\u0301nek, 2014), semantic role labelers (Vickrey", "startOffset": 67, "endOffset": 156}, {"referenceID": 30, "context": "ing step which facilitates and improves the performance of parsers (Tomita, 1985; Chandrasekar and Srinivas, 1997; McDonald and Nivre, 2011; Jel\u0131\u0301nek, 2014), semantic role labelers (Vickrey", "startOffset": 67, "endOffset": 156}, {"referenceID": 24, "context": "ing step which facilitates and improves the performance of parsers (Tomita, 1985; Chandrasekar and Srinivas, 1997; McDonald and Nivre, 2011; Jel\u0131\u0301nek, 2014), semantic role labelers (Vickrey", "startOffset": 67, "endOffset": 156}, {"referenceID": 7, "context": "and Koller, 2008) and statistical machine translation (SMT) systems (Chandrasekar et al., 1996).", "startOffset": 68, "endOffset": 95}, {"referenceID": 6, "context": ", 2003) such as aphasia patients (Carroll et al., 1999), low-literacy readers (Watanabe et al.", "startOffset": 33, "endOffset": 55}, {"referenceID": 51, "context": ", 1999), low-literacy readers (Watanabe et al., 2009), language learners (Siddharthan, 2002) and children (De Belder and Moens, 2010).", "startOffset": 30, "endOffset": 53}, {"referenceID": 41, "context": ", 2009), language learners (Siddharthan, 2002) and children (De Belder and Moens, 2010).", "startOffset": 27, "endOffset": 46}, {"referenceID": 11, "context": "Our second contribution is to provide five models to understand the difficulty of the proposed Split-and-Rephrase task: (i) A basic encoderdecoder taking as input only the complex sentence; (ii) A hybrid probabilistic-SMT model taking as input a deep semantic representation (Discourse representation structures, Kamp 1981) of the complex sentence produced by Boxer (Curran et al., 2007); (iii) A multi-source encoderdecoder taking as input both the complex sentence and the corresponding set of RDF (Resource Description Format) triples; (iv,v) Two partition-andgenerate approaches which first, partition the semantics (set of RDF triples) of the complex sentence into smaller units and then generate a text", "startOffset": 366, "endOffset": 387}, {"referenceID": 59, "context": "Most simplification methods learn a statistical model (Zhu et al., 2010; Coster and Kauchak, 2011; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014) from the par-", "startOffset": 54, "endOffset": 173}, {"referenceID": 10, "context": "Most simplification methods learn a statistical model (Zhu et al., 2010; Coster and Kauchak, 2011; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014) from the par-", "startOffset": 54, "endOffset": 173}, {"referenceID": 52, "context": "Most simplification methods learn a statistical model (Zhu et al., 2010; Coster and Kauchak, 2011; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014) from the par-", "startOffset": 54, "endOffset": 173}, {"referenceID": 53, "context": "Most simplification methods learn a statistical model (Zhu et al., 2010; Coster and Kauchak, 2011; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014) from the par-", "startOffset": 54, "endOffset": 173}, {"referenceID": 32, "context": "Most simplification methods learn a statistical model (Zhu et al., 2010; Coster and Kauchak, 2011; Woodsend and Lapata, 2011; Wubben et al., 2012; Narayan and Gardent, 2014) from the par-", "startOffset": 54, "endOffset": 173}, {"referenceID": 55, "context": "allel dataset of complex-simplified sentences derived by Zhu et al. (2010) from Simple English Wikipedia2 and the traditional one3.", "startOffset": 57, "endOffset": 75}, {"referenceID": 32, "context": "Indeed, Narayan and Gardent (2014) report that only 6.", "startOffset": 8, "endOffset": 35}, {"referenceID": 32, "context": "Indeed, Narayan and Gardent (2014) report that only 6.1% of the complex sentences are in fact split in the corresponding simplification. A more detailed evaluation of the dataset by Xu et al. (2015) further shows that (i) for a large number of pairs, the", "startOffset": 8, "endOffset": 199}, {"referenceID": 55, "context": "Xu et al. (2015) therefore propose a new dataset, Newsela, which consists of 1,130 news articles each rewritten in four different ways to match 5 different levels of simplicity.", "startOffset": 0, "endOffset": 17}, {"referenceID": 38, "context": "from the new templates (Ravichandran and Hovy, 2002; Duclaye et al., 2003); systems which extract paraphrase patterns from large monolingual corpora and use them to rewrite an input text (Duboue and Chu-Carroll, 2006; Narayan et al.", "startOffset": 23, "endOffset": 74}, {"referenceID": 16, "context": "from the new templates (Ravichandran and Hovy, 2002; Duclaye et al., 2003); systems which extract paraphrase patterns from large monolingual corpora and use them to rewrite an input text (Duboue and Chu-Carroll, 2006; Narayan et al.", "startOffset": 23, "endOffset": 74}, {"referenceID": 15, "context": ", 2003); systems which extract paraphrase patterns from large monolingual corpora and use them to rewrite an input text (Duboue and Chu-Carroll, 2006; Narayan et al., 2016); statistical machine translation (SMT) based systems which learn paraphrases from monolingual parallel (Barzilay and McKeown, 2001; Zhao et al.", "startOffset": 120, "endOffset": 172}, {"referenceID": 34, "context": ", 2003); systems which extract paraphrase patterns from large monolingual corpora and use them to rewrite an input text (Duboue and Chu-Carroll, 2006; Narayan et al., 2016); statistical machine translation (SMT) based systems which learn paraphrases from monolingual parallel (Barzilay and McKeown, 2001; Zhao et al.", "startOffset": 120, "endOffset": 172}, {"referenceID": 3, "context": ", 2016); statistical machine translation (SMT) based systems which learn paraphrases from monolingual parallel (Barzilay and McKeown, 2001; Zhao et al., 2008), comparable (Quirk et al.", "startOffset": 111, "endOffset": 158}, {"referenceID": 58, "context": ", 2016); statistical machine translation (SMT) based systems which learn paraphrases from monolingual parallel (Barzilay and McKeown, 2001; Zhao et al., 2008), comparable (Quirk et al.", "startOffset": 111, "endOffset": 158}, {"referenceID": 37, "context": ", 2008), comparable (Quirk et al., 2004) or bilingual parallel (Bannard and Callison-Burch, 2005; Ganitkevitch et al.", "startOffset": 20, "endOffset": 40}, {"referenceID": 2, "context": ", 2004) or bilingual parallel (Bannard and Callison-Burch, 2005; Ganitkevitch et al., 2011) corpora; and a recent neural machine translation (NMT) based system which learns paraphrases from bilingual parallel corpora (Mallinson et al.", "startOffset": 30, "endOffset": 91}, {"referenceID": 20, "context": ", 2004) or bilingual parallel (Bannard and Callison-Burch, 2005; Ganitkevitch et al., 2011) corpora; and a recent neural machine translation (NMT) based system which learns paraphrases from bilingual parallel corpora (Mallinson et al.", "startOffset": 30, "endOffset": 91}, {"referenceID": 28, "context": ", 2011) corpora; and a recent neural machine translation (NMT) based system which learns paraphrases from bilingual parallel corpora (Mallinson et al., 2017).", "startOffset": 133, "endOffset": 157}, {"referenceID": 10, "context": "In sentence simplification approaches, rephrasing is performed either by a machine translation (Coster and Kauchak, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2016; Zhang and Lapata, 2017) or by a probabilistic model (Zhu et al.", "startOffset": 95, "endOffset": 210}, {"referenceID": 53, "context": "In sentence simplification approaches, rephrasing is performed either by a machine translation (Coster and Kauchak, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2016; Zhang and Lapata, 2017) or by a probabilistic model (Zhu et al.", "startOffset": 95, "endOffset": 210}, {"referenceID": 32, "context": "In sentence simplification approaches, rephrasing is performed either by a machine translation (Coster and Kauchak, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2016; Zhang and Lapata, 2017) or by a probabilistic model (Zhu et al.", "startOffset": 95, "endOffset": 210}, {"referenceID": 56, "context": "In sentence simplification approaches, rephrasing is performed either by a machine translation (Coster and Kauchak, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2016; Zhang and Lapata, 2017) or by a probabilistic model (Zhu et al.", "startOffset": 95, "endOffset": 210}, {"referenceID": 57, "context": "In sentence simplification approaches, rephrasing is performed either by a machine translation (Coster and Kauchak, 2011; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2016; Zhang and Lapata, 2017) or by a probabilistic model (Zhu et al.", "startOffset": 95, "endOffset": 210}, {"referenceID": 59, "context": ", 2016; Zhang and Lapata, 2017) or by a probabilistic model (Zhu et al., 2010; Woodsend and Lapata, 2011).", "startOffset": 60, "endOffset": 105}, {"referenceID": 52, "context": ", 2016; Zhang and Lapata, 2017) or by a probabilistic model (Zhu et al., 2010; Woodsend and Lapata, 2011).", "startOffset": 60, "endOffset": 105}, {"referenceID": 44, "context": "dharthan, 2010, 2011) and lexical rephrasing rules are induced from the Wikipedia simplification corpus (Siddharthan and Mandya, 2014).", "startOffset": 104, "endOffset": 134}, {"referenceID": 36, "context": "As noted by Pitler (2010) and Toutanova et al.", "startOffset": 12, "endOffset": 26}, {"referenceID": 36, "context": "As noted by Pitler (2010) and Toutanova et al. (2016) however, the ability to paraphrase is key for the development of abstractive summarisation systems since summaries written by humans often rephrase the original content using paraphrases or synonyms or alternative syntactic constructions.", "startOffset": 12, "endOffset": 54}, {"referenceID": 36, "context": "As noted by Pitler (2010) and Toutanova et al. (2016) however, the ability to paraphrase is key for the development of abstractive summarisation systems since summaries written by humans often rephrase the original content using paraphrases or synonyms or alternative syntactic constructions. Recent proposals by Rush et al. (2015) and Bingel", "startOffset": 12, "endOffset": 332}, {"referenceID": 38, "context": "Rush et al. (2015) proposed a neural model for abstractive compression and summarisation, and Bingel and S\u00f8gaard (2016) proposed a structured approach to text simplification which jointly predicts possible", "startOffset": 0, "endOffset": 19}, {"referenceID": 4, "context": "(2015) proposed a neural model for abstractive compression and summarisation, and Bingel and S\u00f8gaard (2016) proposed a structured approach to text simplification which jointly predicts possible", "startOffset": 82, "endOffset": 108}, {"referenceID": 12, "context": "However, research in that field is still hampered by the small size of datasets for the task, and the difficulty of generating one (Daume III and Marcu, 2004). Thus, the dataset of Thadani and McKeown (2013) only consists of 1,858 fusion instances of which 873 have two inputs, 569 have three and 416 have four.", "startOffset": 138, "endOffset": 208}, {"referenceID": 29, "context": "pipeline (Manning et al., 2014) to segment each", "startOffset": 9, "endOffset": 31}, {"referenceID": 11, "context": "In particular, the splitting and deletion components exploit the deep meaning representation (a Discourse Representation Structure, DRS) of a complex sentence produced by Boxer (Curran et al., 2007).", "startOffset": 177, "endOffset": 198}, {"referenceID": 39, "context": ", 2014), abstractive summarisation (Rush et al., 2015) and response generation (Shang et al.", "startOffset": 35, "endOffset": 54}, {"referenceID": 40, "context": ", 2015) and response generation (Shang et al., 2015).", "startOffset": 32, "endOffset": 52}, {"referenceID": 22, "context": "We use a three-layered encoder-decoder model with LSTM (Long Short-Term Memory, (Hochreiter and Schmidhuber, 1997)) units for the Splitand-Rephrase task.", "startOffset": 80, "endOffset": 114}, {"referenceID": 27, "context": "Our decoder also uses the local-p attention model with feed input as in (Luong et al., 2015).", "startOffset": 72, "endOffset": 92}, {"referenceID": 1, "context": "cal attention model works better than the standard global attention model of Bahdanau et al. (2014). We train this model (SEQ2SEQ) to predict, given a complex sentence, the corresponding sequence of shorter sentences.", "startOffset": 77, "endOffset": 100}, {"referenceID": 21, "context": "As noted by Gardent et al. (2017), the shape of the input may impact the syntactic structure of the corresponding text.", "startOffset": 12, "endOffset": 34}, {"referenceID": 60, "context": "The core idea comes from Zoph and Knight (2016) who show that a multi-source model trained on trilingual translation pairs ((f, g), h) outperforms sev-", "startOffset": 25, "endOffset": 48}, {"referenceID": 29, "context": "To encode MC using RNN, we first linearise MC by doing a depth-first left-right RDF tree traversal and then tokenise using the Stanford CoreNLP pipeline (Manning et al., 2014).", "startOffset": 153, "endOffset": 175}, {"referenceID": 27, "context": "Like in SEQ2SEQ, we model our decoder with the localp attention model with feed input as in (Luong et al., 2015), but now it looks at both source en-", "startOffset": 92, "endOffset": 112}, {"referenceID": 60, "context": "For a detailed explanation of multi-source encoder-decoders, we refer the reader to Zoph and Knight (2016).", "startOffset": 84, "endOffset": 107}, {"referenceID": 58, "context": "We used the system of Zoph and Knight (2016) to train both simple sequence-to-sequence and multi-source sequence-to-sequence models6, and the system of Narayan and Gardent (2014) to train our HYBRIDSIMPL model.", "startOffset": 22, "endOffset": 45}, {"referenceID": 32, "context": "We used the system of Zoph and Knight (2016) to train both simple sequence-to-sequence and multi-source sequence-to-sequence models6, and the system of Narayan and Gardent (2014) to train our HYBRIDSIMPL model.", "startOffset": 152, "endOffset": 179}, {"referenceID": 35, "context": "BLEU-4 scores (Papineni et al., 2002) based on all the rephrasings present in the Split-and-Rephrase corpus for each complex input sentence.", "startOffset": 14, "endOffset": 37}, {"referenceID": 60, "context": "The multi-source models used in machine translation have as a multi-source, two translations of the same content (Zoph and Knight, 2016).", "startOffset": 113, "endOffset": 136}], "year": 2017, "abstractText": "We propose a new sentence simplification task (Split-and-Rephrase) where the aim is to split a complex sentence into a meaning preserving sequence of shorter sentences. Like sentence simplification, splitting-and-rephrasing has the potential of benefiting both natural language processing and societal applications. Because shorter sentences are generally better processed by NLP systems, it could be used as a preprocessing step which facilitates and improves the performance of parsers, semantic role labelers and machine translation systems. It should also be of use for people with reading disabilities because it allows the conversion of longer sentences into shorter ones. This paper makes two contributions towards this new task. First, we create and make available a benchmark consisting of 1,066,115 tuples mapping a single complex sentence to a sequence of sentences expressing the same meaning.1 Second, we propose five models (vanilla sequence-to-sequence to semantically-motivated models) to understand the difficulty of the proposed task.", "creator": "LaTeX with hyperref package"}}}