{"id": "1707.07265", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jul-2017", "title": "Composing Distributed Representations of Relational Patterns", "abstract": "Learning distributed representations for relation instances is a central technique in downstream NLP applications. In order to address semantic modeling of relational patterns, this paper constructs a new dataset that provides multiple similarity ratings for every pair of relational patterns on the existing dataset. In addition, we conduct a comparative study of different encoders including additive composition, RNN, LSTM, and GRU for composing distributed representations of relational patterns. We also present Gated Additive Composition, which is an enhancement of additive composition with the gating mechanism. Experiments show that the new dataset does not only enable detailed analyses of the different encoders, but also provides a gauge to predict successes of distributed representations of relational patterns in the relation classification task.", "histories": [["v1", "Sun, 23 Jul 2017 08:12:59 GMT  (233kb,D)", "http://arxiv.org/abs/1707.07265v1", "Published as a conference paper at ACL 2016"]], "COMMENTS": "Published as a conference paper at ACL 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sho takase", "naoaki okazaki", "kentaro inui"], "accepted": true, "id": "1707.07265"}, "pdf": {"name": "1707.07265.pdf", "metadata": {"source": "CRF", "title": "Composing Distributed Representations of Relational Patterns", "authors": ["Sho Takase", "Naoaki Okazaki", "Kentaro Inui"], "emails": ["inui}@ecei.tohoku.ac.jp"], "sections": [{"heading": "1 Introduction", "text": "Knowledge of entities and their relationships (relation cases) is crucial for a wide range of NLP patterns, e.g. the query of information, the answering of questions and the recognition of textual relationships. Distributed representations for relation patterns are a central technique in downstream patterns, as a number of recent studies have shown the usefulness of distributed representations for words (Mikolov et al., 2013; Pennington et al., 2014) and sentences (Sutskever et al., 2014; Kiros et al., 2015). In particular, semantic modelling of relationships and their textual realizations (relativity patterns) is extremely important because relativization (e.g. causality) can be mentioned by various expressions (e.g. \"X cause Y,\" Y leads to Y, \"Y is associated with X."}, {"heading": "2 Data Construction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Target relation instances", "text": "We are building a new dataset on the work of Zeichner et al. (2012), which consists of relationship patterns with commented semantic inference labels; the dataset includes 5,555 pair2 extracted from Reverb (Fader et al., 2011), 2,447 pairs with inference relationships and 3,108 pairs (the rest) without one. Initially, we considered using this high-quality dataset as it is used for semantic modeling of relationship patterns. However, we found that consequential relationships have very different characteristics from those of semantic similarity. Let's say a relation pattern pair \"X is the part of Y\" and \"X is an essential part of Y,\" filled with \"X = the small intestine, Y = the digestive system\" as an instance. The pattern \"X is the part of Y\" does not bring \"X is an essential part of Y,\" but \"non-essential parts of Y are unpleasant in comparison with\" PART. \""}, {"heading": "2.2 Annotation guideline", "text": "We use instance judgments in a similar way to Zeichner et al. (2012) to ensure high consistency between the commentators. In instance-based judgments, a commentator judges a pair of relationship patterns whose variable slots are filled with the same entity pair. In other words, he or she does not judge a pair of relationship patterns with variables, \"X prevents Y\" and \"X reduces the risk of Y,\" but two instance statements, \"Cephalexin prevents the bacteria\" and \"Cephalexin reduces the risk of the bacteria\" (\"X = Cephalexin, Y = the bacteria\"). We provided the following instructions for assessing pairs of entities provided in Zeichner et al. (2012). We asked commentators to make a judgement for a pair of relationship instances by choosing a rating from 1 (dissimilar) to 7 (very similar). We provided the following instructions for assessing which are compatible with Mitchell and Jack (e.g., 2) or 2 (if the meaning of Jack is: 7 or 2)."}, {"heading": "2.3 Annotation procedure", "text": "We use a CrowdFlower3 crowdsourcing service to collect crowd-sourced similarity assessments. CrowdFlower has the mechanism to evaluate commenters \"reliability using standard gold data (gold, hereinafter), which consists of pairs of relationship patterns with assigned similarity values. Gold examples are regularly inserted into the appraisal work to allow measurement of each worker's performance4. In other words, we have randomly selected 100 pairs out of 5,555 pairs and prepared 80 gold examples that are highly consistent. Gold examples ratings have only been used to evaluate workers\" quality. In other words, we have the 3http: / / www.crowdflower.com / 4We allow \u00b1 1 differences in appraisal when measuring workers \"performance. Gold examples similarity ratings and used worker-rated data sets. In order to create a high-quality dataset, we use employee-trusted data sets (Flower's)."}, {"heading": "3 Encoder for Relational Patterns", "text": "The new dataset created in the previous section raises two new questions: What is the useful method (encoder) for calculating distributed representations of relationship patterns? Is this dataset useful for predicting the success of distributed representations of relationship patterns in real-world applications? To answer these questions, this section examines various methods for learning distributed representations of relationship patterns."}, {"heading": "3.1 Baseline methods without supervision", "text": "A naive approach would be to treat a relationship pattern as a single entity (word) and train word / pattern embedding as usual. In fact, Mikolov et al. (2013) implemented this approach as a pre-processing step, removing phrases with strong collocations from a training corpus. However, this approach could be influenced by data sparseness, which reduces the quality of distributed representations. Another simple but effective approach is the additive composition (Mitchell and Lapata, 2010), where the distributed representation of a relationship pattern is calculated from the means of embedding constituent words. Assuming that a relationship pattern consists of a sequence of T-words w1,..., wT, then we let xt-Rd use the embedding of the word wt. This approach calculates 1T-T-T = 1 xt as embedding of the relationship pattern. Muraoka et al. (2014) reported that the different composition represents a strong basis among the composition."}, {"heading": "3.2 Recurrent Neural Network", "text": "Recently, a number of studies modeled semantic compositions of phrases and sentences using (a variant of) Recurrent Neural Network (RNN) (Sutskever et al., 2014; Tang et al., 2015). For a given embedding xt at position t, the vanilla RNN (Elman, 1990) calculates the hidden state ht-Rd using the following recursive equation 5, ht = g (Wxxt + Whht \u2212 1). (1) Here are Wx and Wh d \u00b7 Dmatrices (parameters), g (.) is the elementary activation function (tanh). We set h0 = 0 at t = 1. Essentially, RNN calculates the hidden state ht based on the embedding xt at the previous position (ht \u2212 1) and the word. Using the equation 1 from t = 1 to T, we use hT as a distributed representation of the relation pattern."}, {"heading": "3.3 RNN variants", "text": "We also employ Long Short-Term Memory (LSTM ~ ~ GRs + GRs + 1x4) (Hochreiter and Schmidhuber, 1997) and Gated Recurrent Unit (GRU) (Cho et al., 2014) as encoders for relationship patterns. LSTM has been successfully applied to various NLP tasks, including word segmentation (Chen et al., 2015), dependency analysis (Dyer et al., 2015), machine translation (Sutskever et al., 2014) and sentiment analysis (Tai et al., 2015). GRU is also successful in machine translation (Cho et al., 2014) and various5We do not use a bias term in this study."}, {"heading": "3.4 Gated Additive Composition (GAC)", "text": "In addition to the gradient problem, LSTM or GRU may be suitable for relationship patterns, with the mechanism of adaptive control of gates for input words and hidden states. Consider the relationship pattern \"X have access to Y,\" the meaning of which is largely identical to that of \"X access Y.\" Since \"have\" is a slight verb in the pattern, it can be harmful to include the semantic vector of \"have\" in the distributed representation of the pattern. The same could apply to the function word \"to\" in the pattern. Therefore, the additive composition does not yet have a mechanism for ignoring the semantic vectors of these words. It is interesting to explore a method somewhere between additive composition and LSTM / GRU: additive composition with the gating mechanism \"to.\" For this reason, we present another variant of RNN in this study."}, {"heading": "3.5 Parameter estimation: Skip-gram model", "text": "To train the parameters of the encoders (RNN, LSTM, GRU, and GAC) on an unlabeled text corpus, we adapt the Skip-gram model (Mikolov et al., 2013). Formally, we refer to the occurrence of a relationship pattern p as a sub-sequence of L-words,..., s + L-1 in a corpus. We define the log liquidity of the relative pattern p as the context words, and leave Cp = (s \u2212 3, s + L,..., s + L + E) the indexes of the context words. We define the log liquidity of the relative pattern lp, according to the objective function of the skip program with negative sampling (SGNS) (Levy and Goldberg, 2014).lp = vector of the vector (h > p x)."}, {"heading": "4 Experiments", "text": "In Section 4.1 we examine the performance of distributed representations calculated by different encoders for the pattern similarity task. Section 4.2 examines the contribution of distributed representations to SemEval 2010 Task 8 and discusses the usefulness of the new dataset in predicting the success of the classification task."}, {"heading": "4.1 Relational pattern similarity", "text": "For each pair in the dataset created in section 2, we assemble the vectors of the two relationship patterns using an encoder described in section 3 and calculate the cosinal similarity of the two vectors. Repeating this process for all pairs in the dataset, we measure Spearmans \u03c1 between the similarity values calculated by the encoder and the similarity values assigned by humans."}, {"heading": "4.1.1 Training procedure", "text": "In this corpus, we have relied on word vectors and context vectors to compose vectors of relative patterns; and the skip grammar model uses the probability distribution of words lifted into the 3 / 4 potency to compose the vectors of relative patterns; and the skip grammar model uses the probability distribution of words lifted into the 3 / 4 potency (Mikolov et al., 2013).9http: / / wacky.unibo.it 10http: / www.cis.uni gramVector modules embedded in the 3 / 4 potentials."}, {"heading": "4.1.2 Results and discussions", "text": "The figure shows that GAC performs best in all dimensions. Figure 4 includes the performance of the na\u00efve approach, \"NoComp,\" which considers a relationship pattern as a single unit (word). In this approach, the vectors of the relative patterns are deduced using the Skip model. / / chainer.org / we have assigned a vector hp in Equation 5 instead of the vector composition, and the vectors of the relative patterns are degraded using the Skip-gram model. / We were not able to calculate the similarity values for 1,744 pairs because the relative patterns do not appear in ukWac."}, {"heading": "4.2 Relation classification", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1 Experimental settings", "text": "In order to investigate the usefulness of the dataset and distributed representations for another application, we are looking at the task of relation classification on the SemEval 2010 Task 8 dataset (Hendrickx et al., 2010). In other words, we are investigating whether high-quality distributed representations of relationship patterns are effective in identifying a relation type of an entity pair. The dataset consists of 10, 717 relation messages (8,000 trainings and 2,717 test instances) with their annotated relation types. The dataset defines 9 directed relationships (e.g. CAUSE-EFFECT) and 1 undirected relation OTHER. Given a pair of entity mentations, the task is to identify a relation type in 19 candidate names (2 \u00d7 9 directed + 1 undirected relationships). For example, \"given the pair of entity mentations, we are told that\" a word type is expected \"in the Burmhamm pattern.\""}, {"heading": "4.2.2 Results and discussions", "text": "The first group of the table provides basic features and improvements to the distributed representations. We can even see a significant improvement in the distributed representation of NoComp (77.3 to 79.9). In addition, the distributed representation, which showed the high performance in the pattern similarity task, was successful in this task too; GAC, which performed the highest in the pattern similarity task, also achieved the best performance (82.0) of all encoders in this task. It is noteworthy that the improvements that the different encoders made in this task roughly correspond to the performance in the pattern similarity task, implying two potential effects. First, the distributed representations of the relational patterns are useful and easily transferable to other tasks, such as knowledge-based totality. Second, pattern similarity provides a yardstick to predict the success of the distributed representations in another group."}, {"heading": "5 Related Work", "text": "They constructed the dataset containing two pairs of words with a semantic similarity that are judged by human commentators. Korkontzelos et al. (2013) provided semantic similarity datasets with pairs of two words and a single word. Although the target unit of semantic modeling is different from these earlier studies, we follow the notes and instructions of Mitchell and Lapata to build the new datasets. The task we have covered in this paper also relates to the Semantic Textual similarity (STS) task (Agirre et al al., 2012), which is the task of measuring the degree of semantic similarity between two sentences."}, {"heading": "6 Conclusion", "text": "In this work, we focused on semantic modeling of relationship patterns. We introduced the new dataset, in which people evaluate multiple similarity values for each pair of relationship patterns using the dataset of semantic inference (Zeichner et al., 2012). In addition, we investigated various encoders for the compilation of distributed representations of relationship patterns. Experimental results show that the gated additive composition (GAC), a combination of additive composition and the gating mechanism, is effective for creating distributed representations of relationship patterns. Furthermore, we demonstrated that the presented dataset is useful for predicting the success of distributed representations in the relationship classification task. We expect that several further studies will use the new dataset not only for distributed representations of relationship patterns, but also for other NLP tasks (e.g. paraphrasing)."}, {"heading": "Acknowledgments", "text": "We thank the reviewers and Jun Suzuki for valuable comments. This work was partially supported by Grant-in-Aid for JSPS Fellows Grantno. 26.5820, JSPS KAKENHI Grant Number 15H05318 and JST, CREST."}], "references": [{"title": "Semeval2012 task 6: A pilot on semantic textual similarity", "author": ["Agirre et al.2012] Eneko Agirre", "Daniel Cer", "Mona Diab", "Aitor Gonzalez-Agirre"], "venue": "In The First Joint Conference on Lexical and Computational Semantics (*SEM", "citeRegEx": "Agirre et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Agirre et al\\.", "year": 2012}, {"title": "Long short-term memory neural networks for chinese word segmentation", "author": ["Chen et al.2015] Xinchi Chen", "Xipeng Qiu", "Chenxi Zhu", "Pengfei Liu", "Xuanjing Huang"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Learning phrase representations using rnn encoder\u2013decoder for statistical machine translation", "author": ["Cho et al.2014] Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Chung et al.2014] Junyoung Chung", "\u00c7aglar G\u00fcl\u00e7ehre", "KyungHyun Cho", "Yoshua Bengio"], "venue": null, "citeRegEx": "Chung et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Classifying relations by ranking with convolutional neural networks", "author": ["Bing Xiang", "Bowen Zhou"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th In-", "citeRegEx": "Santos et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Santos et al\\.", "year": 2015}, {"title": "Transition-based dependency parsing with stack long short-term memory", "author": ["Dyer et al.2015] Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "Dyer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2015}, {"title": "Finding structure in time", "author": ["Jeffrey L Elman"], "venue": "Cognitive science,", "citeRegEx": "Elman.,? \\Q1990\\E", "shortCiteRegEx": "Elman.", "year": 1990}, {"title": "Identifying relations for open information extraction", "author": ["Fader et al.2011] Anthony Fader", "Stephen Soderland", "Oren Etzioni"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP", "citeRegEx": "Fader et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Fader et al\\.", "year": 2011}, {"title": "Ppdb: The paraphrase database", "author": ["Benjamin Van Durme", "Chris Callison-Burch"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter", "citeRegEx": "Ganitkevitch et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2013}, {"title": "Improved relation extraction with feature-rich compositional embedding models", "author": ["Mo Yu", "Mark Dredze"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP", "citeRegEx": "Gormley et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gormley et al\\.", "year": 2015}, {"title": "Relly: Inferring hypernym relationships between relational phrases", "author": ["Grycner et al.2015] Adam Grycner", "Gerhard Weikum", "Jay Pujara", "James Foulds", "Lise Getoor"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language", "citeRegEx": "Grycner et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Grycner et al\\.", "year": 2015}, {"title": "Jointly learning word representations and composition functions using predicate-argument structures", "author": ["Pontus Stenetorp", "Makoto Miwa", "Yoshimasa Tsuruoka"], "venue": "In Proceedings of the 2014 Conference", "citeRegEx": "Hashimoto et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2014}, {"title": "Task-oriented learning of word embeddings for semantic relation classification", "author": ["Pontus Stenetorp", "Makoto Miwa", "Yoshimasa Tsuruoka"], "venue": "In Proceedings of the 19th Conference on Computational Natural", "citeRegEx": "Hashimoto et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2015}, {"title": "Semeval-2010 task 8: Multi-way classification", "author": ["Su Nam Kim", "Zornitsa Kozareva", "Preslav Nakov", "Diarmuid \u00d3 S\u00e9aghdha", "Sebastian Pad\u00f3", "Marco Pennacchiotti", "Lorenza Romano", "Stan Szpakowicz"], "venue": null, "citeRegEx": "Hendrickx et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hendrickx et al\\.", "year": 2010}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Semeval-2013 task 5: Evaluating phrasal semantics", "author": ["Torsten Zesch", "Fabio Massimo Zanzotto", "Chris Biemann"], "venue": "In Second Joint Conference on Lexical and Computational Semantics (*SEM", "citeRegEx": "Korkontzelos et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Korkontzelos et al\\.", "year": 2013}, {"title": "Dirt \u2013 discovery of inference rules from text", "author": ["Lin", "Pantel2001] Dekang Lin", "Patrick Pantel"], "venue": "In Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD", "citeRegEx": "Lin et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2001}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Composition in distributional models of semantics", "author": ["Mitchell", "Lapata2010] Jeff Mitchell", "Mirella Lapata"], "venue": "Cognitive Science,", "citeRegEx": "Mitchell et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2010}, {"title": "Finding the best model among representative compositional models", "author": ["Sonse Shimaoka", "Kazeto Yamamoto", "Yotaro Watanabe", "Naoaki Okazaki", "Kentaro Inui"], "venue": "In Proceedings of the 28th Pacific Asia", "citeRegEx": "Muraoka et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Muraoka et al\\.", "year": 2014}, {"title": "Patty: A taxonomy of relational patterns with semantic types", "author": ["Gerhard Weikum", "Fabian Suchanek"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Process-", "citeRegEx": "Nakashole et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Nakashole et al\\.", "year": 2012}, {"title": "Glove: Global vectors for word representation", "author": ["Richard Socher", "Christopher Manning"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Relation extraction with matrix factorization and universal schemas", "author": ["Limin Yao", "Andrew McCallum", "Benjamin M. Marlin"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Asso-", "citeRegEx": "Riedel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2013}, {"title": "Utd: Classifying semantic relations by combining lexical and semantic resources", "author": ["Rink", "Harabagiu2010] Bryan Rink", "Sanda Harabagiu"], "venue": "In Proceedings of the 5th International Workshop on Semantic Evaluation,", "citeRegEx": "Rink et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rink et al\\.", "year": 2010}, {"title": "Parsing natural scenes and natural language with recursive neural networks", "author": ["Cliff Chiung-Yu Lin", "Andrew Y. Ng", "Christopher D. Manning"], "venue": "In Proceedings of the 28th International Conference on Machine", "citeRegEx": "Socher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Semantic compositionality through recursive matrix-vector spaces", "author": ["Brody Huval", "Christopher D. Manning", "Andrew Y. Ng"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural", "citeRegEx": "Socher et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "Parsing with compositional vector grammars", "author": ["John Bauer", "Christopher D. Manning", "Ng Andrew Y"], "venue": "In Proceedings of the 51st Annual Meeting of the Association", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Generating text with recurrent neural networks", "author": ["James Martens", "Geoffrey Hinton"], "venue": "In Proceedings of the 28th International Conference on Machine Learning (ICML", "citeRegEx": "Sutskever et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2011}, {"title": "Sequence to sequence learning with neural networks", "author": ["Oriol Vinyals", "Quoc V. Le"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Improved semantic representations from tree-structured long shortterm memory networks", "author": ["Tai et al.2015] Kai Sheng Tai", "Richard Socher", "Christopher D. Manning"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computa-", "citeRegEx": "Tai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tai et al\\.", "year": 2015}, {"title": "Modeling semantic compositionality of relational patterns", "author": ["Takase et al.2016] Sho Takase", "Naoaki Okazaki", "Kentaro Inui"], "venue": "Engineering Applications of Artificial Intelligence,", "citeRegEx": "Takase et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Takase et al\\.", "year": 2016}, {"title": "Document modeling with gated recurrent neural network for sentiment classification", "author": ["Tang et al.2015] Duyu Tang", "Bing Qin", "Ting Liu"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP", "citeRegEx": "Tang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2015}, {"title": "Representing text for joint embedding of text and knowledge bases", "author": ["Danqi Chen", "Patrick Pantel", "Hoifung Poon", "Pallavi Choudhury", "Michael Gamon"], "venue": "In Proceedings of the 2015 Conference on Empirical", "citeRegEx": "Toutanova et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2015}, {"title": "From paraphrase database to compositional paraphrase model and back. Transactions of the Association for Computational Linguistics (TACL", "author": ["Wieting et al.2015] John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": null, "citeRegEx": "Wieting et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "Semantic relation classification via convolutional neural networks with simple negative sampling", "author": ["Xu et al.2015] Kun Xu", "Yansong Feng", "Songfang Huang", "Dongyan Zhao"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Nat-", "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Semantic parsing for single-relation question answering", "author": ["Yih et al.2014] Wen-tau Yih", "Xiaodong He", "Christopher Meek"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL", "citeRegEx": "Yih et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yih et al\\.", "year": 2014}, {"title": "Crowdsourcing inference-rule evaluation", "author": ["Jonathan Berant", "Ido Dagan"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL", "citeRegEx": "Zeichner et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zeichner et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 36, "context": "tional patterns, this paper constructs a new dataset that provides multiple similarity ratings for every pair of relational patterns on the existing dataset (Zeichner et al., 2012).", "startOffset": 157, "endOffset": 180}, {"referenceID": 17, "context": "Learning distributed representations for relation instances is a central technique in downstream applications as a number of recent studies demonstrated the usefulness of distributed representations for words (Mikolov et al., 2013; Pennington et al., 2014) and sentences (Sutskever et al.", "startOffset": 209, "endOffset": 256}, {"referenceID": 21, "context": "Learning distributed representations for relation instances is a central technique in downstream applications as a number of recent studies demonstrated the usefulness of distributed representations for words (Mikolov et al., 2013; Pennington et al., 2014) and sentences (Sutskever et al.", "startOffset": 209, "endOffset": 256}, {"referenceID": 28, "context": ", 2014) and sentences (Sutskever et al., 2014; Cho et al., 2014; Kiros et al., 2015).", "startOffset": 22, "endOffset": 84}, {"referenceID": 2, "context": ", 2014) and sentences (Sutskever et al., 2014; Cho et al., 2014; Kiros et al., 2015).", "startOffset": 22, "endOffset": 84}, {"referenceID": 20, "context": ", \u201cX: smoking, Y: cancer\u201d) (Lin and Pantel, 2001; Nakashole et al., 2012).", "startOffset": 27, "endOffset": 73}, {"referenceID": 35, "context": "Nowadays, several studies adopt distributed representations computed by neural networks for semantic modeling of relational patterns (Yih et al., 2014; Takase et al., 2016).", "startOffset": 133, "endOffset": 172}, {"referenceID": 30, "context": "Nowadays, several studies adopt distributed representations computed by neural networks for semantic modeling of relational patterns (Yih et al., 2014; Takase et al., 2016).", "startOffset": 133, "endOffset": 172}, {"referenceID": 7, "context": "The dataset includes 5,555 pairs2 extracted by Reverb (Fader et al., 2011), 2,447 pairs with inference relation and 3,108 pairs (the rest) without one.", "startOffset": 54, "endOffset": 74}, {"referenceID": 35, "context": "We build a new dataset upon the work of Zeichner et al. (2012), which consists of relational patterns with semantic inference labels annotated.", "startOffset": 40, "endOffset": 63}, {"referenceID": 36, "context": "We use instance-based judgment in a similar manner to that of Zeichner et al. (2012) to secure a high inter-annotator agreement.", "startOffset": 62, "endOffset": 85}, {"referenceID": 36, "context": "We use the entity pairs provided in Zeichner et al. (2012).", "startOffset": 36, "endOffset": 59}, {"referenceID": 17, "context": "In fact, Mikolov et al. (2013) implemented this approach as a preprocessing step, mining phrasal expressions with strong collocations from a training corpus.", "startOffset": 9, "endOffset": 31}, {"referenceID": 19, "context": "Muraoka et al. (2014) reported that the additive composition is a strong baseline among various methods.", "startOffset": 0, "endOffset": 22}, {"referenceID": 28, "context": "tic compositions of phrases and sentences by using (a variant of) Recurrent Neural Network (RNN) (Sutskever et al., 2014; Tang et al., 2015).", "startOffset": 97, "endOffset": 140}, {"referenceID": 31, "context": "tic compositions of phrases and sentences by using (a variant of) Recurrent Neural Network (RNN) (Sutskever et al., 2014; Tang et al., 2015).", "startOffset": 97, "endOffset": 140}, {"referenceID": 6, "context": "For a given embedding xt at position t, the vanilla RNN (Elman, 1990) computes the hidden state ht \u2208 Rd by the following recursive equation5,", "startOffset": 56, "endOffset": 69}, {"referenceID": 2, "context": "We also employ Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) and Gated Recurrent Unit (GRU) (Cho et al., 2014) as an encoder for relational patterns.", "startOffset": 111, "endOffset": 129}, {"referenceID": 1, "context": "LSTM has been applied successfully to various NLP tasks including word segmentation (Chen et al., 2015), dependency parsing (Dyer et al.", "startOffset": 84, "endOffset": 103}, {"referenceID": 5, "context": ", 2015), dependency parsing (Dyer et al., 2015), machine translation (Sutskever et al.", "startOffset": 28, "endOffset": 47}, {"referenceID": 28, "context": ", 2015), machine translation (Sutskever et al., 2014), and sentiment analysis (Tai et al.", "startOffset": 29, "endOffset": 53}, {"referenceID": 29, "context": ", 2014), and sentiment analysis (Tai et al., 2015).", "startOffset": 32, "endOffset": 50}, {"referenceID": 2, "context": "GRU is also successful in machine translation (Cho et al., 2014) and various", "startOffset": 46, "endOffset": 64}, {"referenceID": 3, "context": "Although some researchers reported that GRU is superior to LSTM (Chung et al., 2014), we have no consensus about the superiority.", "startOffset": 64, "endOffset": 84}, {"referenceID": 17, "context": "LSTM, GRU, and GAC) on an unlabeled text corpus, we adapt the Skip-gram model (Mikolov et al., 2013).", "startOffset": 78, "endOffset": 100}, {"referenceID": 17, "context": "Equation 2 of the original paper (Mikolov et al., 2013) denotes xt (word vector) as v (input vector) and x\u0303t (context vector) as v\u2032 (output vector).", "startOffset": 33, "endOffset": 55}, {"referenceID": 17, "context": "We use the probability distribution of words raised to the 3/4 power (Mikolov et al., 2013).", "startOffset": 69, "endOffset": 91}, {"referenceID": 7, "context": "We used Reverb (Fader et al., 2011) to the ukWaC corpus to extract relational pattern can-", "startOffset": 15, "endOffset": 35}, {"referenceID": 17, "context": "The hyperparameters of the Skip-gram model are identical to those in Mikolov et al. (2013): the width of context window \u03b4 = 5, the number of negative samples K = 5, the subsampling of 10\u22125.", "startOffset": 69, "endOffset": 91}, {"referenceID": 13, "context": "To examine the usefulness of the dataset and distributed representations for a different application, we address the task of relation classification on the SemEval 2010 Task 8 dataset (Hendrickx et al., 2010).", "startOffset": 184, "endOffset": 208}, {"referenceID": 25, "context": "MV-RNN (Socher et al., 2012) embeddings, parse trees 79.", "startOffset": 7, "endOffset": 28}, {"referenceID": 9, "context": "FCM (Gormley et al., 2015) w/o fine-tuning embeddings, dependency 79.", "startOffset": 4, "endOffset": 26}, {"referenceID": 12, "context": "RelEmb (Hashimoto et al., 2015) embeddings 82.", "startOffset": 7, "endOffset": 31}, {"referenceID": 34, "context": "depLCNN (Xu et al., 2015) embeddings, dependency 81.", "startOffset": 8, "endOffset": 25}, {"referenceID": 10, "context": "7 F1 score by adding features for WordNet, named entities (NE), and dependency paths explained in Hashimoto et al. (2015). Moreover, we could obtain 84.", "startOffset": 98, "endOffset": 122}, {"referenceID": 34, "context": "If we could use the negative sampling technique proposed by Xu et al. (2015), we might improve the performance further14.", "startOffset": 60, "endOffset": 77}, {"referenceID": 8, "context": "(2015) annotated a part of PPDB (Ganitkevitch et al., 2013) to evaluate semantic modeling of paraphrases.", "startOffset": 32, "endOffset": 59}, {"referenceID": 14, "context": "Korkontzelos et al. (2013) provided a semantic similarity dataset with pairs of two words and a single word.", "startOffset": 0, "endOffset": 27}, {"referenceID": 14, "context": "Korkontzelos et al. (2013) provided a semantic similarity dataset with pairs of two words and a single word. Wieting et al. (2015) annotated a part of PPDB (Ganitkevitch et al.", "startOffset": 0, "endOffset": 131}, {"referenceID": 8, "context": "(2015) annotated a part of PPDB (Ganitkevitch et al., 2013) to evaluate semantic modeling of paraphrases. Although the target unit of semantic modeling is different from that for these previous studies, we follow the annotation guideline and instruction of Mitchell and Lapata (2010) to build the new dataset.", "startOffset": 33, "endOffset": 284}, {"referenceID": 0, "context": "The task addressed in this paper is also related to the Semantic Textual Similarity (STS) task (Agirre et al., 2012).", "startOffset": 95, "endOffset": 116}, {"referenceID": 34, "context": "However, Xu et al. (2015) omits the detail of the technique probably because of the severe page limit of short papers.", "startOffset": 9, "endOffset": 26}, {"referenceID": 19, "context": "Nakashole et al. (2012) approached the similar task by constructing a taxonomy of relational patterns.", "startOffset": 0, "endOffset": 24}, {"referenceID": 10, "context": "Grycner et al. (2015) extended Nakashole et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 10, "context": "Grycner et al. (2015) extended Nakashole et al. (2012) to generalize dimensions of the vector space (entity pairs) by incorporating hyponymy relation between entities.", "startOffset": 0, "endOffset": 55}, {"referenceID": 24, "context": "Numerous studies have been aimed at encoding distributed representations of phrases and sentences from word embeddings by using: Recursive Neural Network (Socher et al., 2011), Matrix", "startOffset": 154, "endOffset": 175}, {"referenceID": 25, "context": "Vector Recursive Neural Network (Socher et al., 2012), Recursive Neural Network with different weight matrices corresponding to syntactic categories (Socher et al.", "startOffset": 32, "endOffset": 53}, {"referenceID": 26, "context": ", 2012), Recursive Neural Network with different weight matrices corresponding to syntactic categories (Socher et al., 2013) or word types (Takase et al.", "startOffset": 103, "endOffset": 124}, {"referenceID": 30, "context": ", 2013) or word types (Takase et al., 2016), RNN (Sutskever et al.", "startOffset": 22, "endOffset": 43}, {"referenceID": 27, "context": ", 2016), RNN (Sutskever et al., 2011),", "startOffset": 13, "endOffset": 37}, {"referenceID": 28, "context": "LSTM (Sutskever et al., 2014), GRU (Cho et al.", "startOffset": 5, "endOffset": 29}, {"referenceID": 2, "context": ", 2014), GRU (Cho et al., 2014), PAS-CLBLM (Hashimoto et al.", "startOffset": 13, "endOffset": 31}, {"referenceID": 11, "context": ", 2014), PAS-CLBLM (Hashimoto et al., 2014), etc.", "startOffset": 19, "endOffset": 43}, {"referenceID": 28, "context": "As described in Section 3, we applied RNN, GRU, and LSTM to compute distributed representations of relational patterns because recent papers have demonstrated their superiority in semantic composition (Sutskever et al., 2014; Tang et al., 2015).", "startOffset": 201, "endOffset": 244}, {"referenceID": 31, "context": "As described in Section 3, we applied RNN, GRU, and LSTM to compute distributed representations of relational patterns because recent papers have demonstrated their superiority in semantic composition (Sutskever et al., 2014; Tang et al., 2015).", "startOffset": 201, "endOffset": 244}, {"referenceID": 8, "context": "Gormley et al. (2015) proposed Feature-rich Compositional Embedding Model (FCM) that can combine binary features (e.", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "dos Santos et al. (2015) addressed the task using Convolutional Neural Network (CNN).", "startOffset": 4, "endOffset": 25}, {"referenceID": 4, "context": "dos Santos et al. (2015) addressed the task using Convolutional Neural Network (CNN). Xu et al. (2015) achieved a higher performance than dos Santos et al.", "startOffset": 4, "endOffset": 103}, {"referenceID": 4, "context": "dos Santos et al. (2015) addressed the task using Convolutional Neural Network (CNN). Xu et al. (2015) achieved a higher performance than dos Santos et al. (2015) by application of CNN on de-", "startOffset": 4, "endOffset": 163}, {"referenceID": 22, "context": "To populate a knowledge base, Riedel et al. (2013) jointly learned latent feature vectors of entities, relational patterns, and relation types in the knowledge base.", "startOffset": 30, "endOffset": 51}, {"referenceID": 22, "context": "To populate a knowledge base, Riedel et al. (2013) jointly learned latent feature vectors of entities, relational patterns, and relation types in the knowledge base. Toutanova et al. (2015) adapted CNN to capture the compositional structure of a relational pattern during the joint learning.", "startOffset": 30, "endOffset": 190}, {"referenceID": 22, "context": "To populate a knowledge base, Riedel et al. (2013) jointly learned latent feature vectors of entities, relational patterns, and relation types in the knowledge base. Toutanova et al. (2015) adapted CNN to capture the compositional structure of a relational pattern during the joint learning. For open domain question answering, Yih et al. (2014) proposed the method to map an interrogative sentence on an entity and a relation type contained in a knowledge base by using CNN.", "startOffset": 30, "endOffset": 346}], "year": 2017, "abstractText": "Learning distributed representations for relation instances is a central technique in downstream NLP applications. In order to address semantic modeling of relational patterns, this paper constructs a new dataset that provides multiple similarity ratings for every pair of relational patterns on the existing dataset (Zeichner et al., 2012). In addition, we conduct a comparative study of different encoders including additive composition, RNN, LSTM, and GRU for composing distributed representations of relational patterns. We also present Gated Additive Composition, which is an enhancement of additive composition with the gating mechanism. Experiments show that the new dataset does not only enable detailed analyses of the different encoders, but also provides a gauge to predict successes of distributed representations of relational patterns in the relation classification task.", "creator": "LaTeX with hyperref package"}}}