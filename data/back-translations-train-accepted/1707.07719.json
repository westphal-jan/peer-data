{"id": "1707.07719", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jul-2017", "title": "Global Normalization of Convolutional Neural Networks for Joint Entity and Relation Classification", "abstract": "We introduce globally normalized convolutional neural networks for joint entity classification and relation extraction. In particular, we propose a way to utilize a linear-chain conditional random field output layer for predicting entity types and relations between entities at the same time. Our experiments show that global normalization outperforms a locally normalized softmax layer on a benchmark dataset.", "histories": [["v1", "Mon, 24 Jul 2017 19:39:22 GMT  (86kb,D)", "http://arxiv.org/abs/1707.07719v1", "EMNLP 2017"], ["v2", "Wed, 16 Aug 2017 06:37:55 GMT  (86kb,D)", "http://arxiv.org/abs/1707.07719v2", "EMNLP 2017"]], "COMMENTS": "EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["heike adel", "hinrich sch\u00fctze"], "accepted": true, "id": "1707.07719"}, "pdf": {"name": "1707.07719.pdf", "metadata": {"source": "CRF", "title": "Global Normalization of Convolutional Neural Networks for Joint Entity and Relation Classification", "authors": ["Heike Adel"], "emails": ["heike@cis.lmu.de"], "sections": [{"heading": "1 Introduction", "text": "Most approaches view the two tasks independently of each other or treat them as a sequential pipeline, first applying a named entity detection tool and then classifying the relationships between entity pairs. However, the named entity types and relationships are often dependent on each other. If the types of entities are known, the search space for possible relationships between them can be reduced and vice versa. This can, for example, help resolve ambiguities, as in the case of \"Mercedes,\" which can be a person, organization and place. However, it is the second argument for the relationship \"live in,\" which helps us to conclude that it is a location. Therefore, we propose a single neural network (NN) for both tasks."}, {"heading": "2 Related Work", "text": "Other studies described in more detail below use the Entity and Relationship Recognition (ERR) dataset instead (Roth and Yih, 2004, 2007), as we do in this paper. Roth and Yih (2004) develop constraints and use linear programming to normalize entity types and relationships globally. Giuliano et al. (2007) use entity type information to extract relationships, but they do not train both tasks together. Kate and Mooney (2010) train task-specific support vector machines and develop a map-pyramid parsing algorithm to model both tasks together. Miwa and Sasaki (2014) use the same datasets, but model the tasks as table-filling problems."}, {"heading": "3 Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Modeling Context and Entities", "text": "Considering an input set and two query units, our model identifies the types of units and the relationship between them; see Figure 1. The input marks are represented by word embedding, which were trained on Wikipedia with word2vec (Mikolov et al., 2013). To identify the class of a unit ek, the model uses the context to the left, the words that represent ek and the context to the right. To classify the relationship between two units ei and ej, the sentence is divided into six parts: left of ei, egg, right of ei, left of ej, ej, ej, right of ej.1 For the example sentence in Figure 1 and the entity pair (\"boss\"), the context division is: [Anderson] [, 41, was the boss of ei, right of ei, ej, ej, right of ej, ej."}, {"heading": "3.2 Global Normalization Layer", "text": "For global normalization, we use the linear chain CRF layer by Lample et al. (2016).2 It expects results for the different classes as input. Therefore, we first apply a linear layer that maps the representations hz-RHz to a vector vz of the size of the output classes N = NEC + NRE: vz = W T z hz (2) with the following sequence of scores (cf., Figure 2): d = [vEC (e1), vRE (r12), vEC (e2)] (3) with rij as relationship between ei and ej. Therefore, we propose to model the common entity and relation classification problem with the following sequence of scores (cf., Figure 2): d = [vEC (e1), vRE (e2)] (3) with rij as relationship between ei and ej."}, {"heading": "4 Experiments and Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Data and Evaluation Measure", "text": "We use the Entity and Relation Recognition (ERR) data set (Roth and Yih, 2004) 4 with the Train Test Split by Gupta et al. (2016). We adjust the parameters to a reserved part of the train. The data is labeled with entity types and relationships (see Table 1). For entity pairs without a relationship, we use the N. Statistics and model parameters of the data set are provided in the appendix. After previous work, we calculate F1 of each class for EC and RE as well as a task-by-assignment macro F1 score. We also specify the average of scores across all tasks (Avg EC + RE).32 is added based on the padded start and end tag 4http: / / cogcomp.cs.illinois.edu / page / resource view / 43."}, {"heading": "4.2 Experimental Setups", "text": "In this setup, however, the query units for our model are referred to only as entity pairs. Note that this facilitates the filling of entity pairs in our experiments. Setup 2: Fill in Table. Following Miwa and Sasaki (2014); Gupta et al. (2016), we also model the joint task of EC and RE as a table filling task. For a sentence with the length m, we create a square table. Cell (i, j) contains the relationship between word i and word j (or N for no relationship). A diagonal cell (k, k) contains the entity type of word k and RE as a table filling task. Following the previous work, we only predict classes for half of the table, i.e. for prediction (m + 1) / 2 cells."}, {"heading": "4.3 Experimental Results", "text": "Table 1 shows the results of our globally normalized model compared to the same model with locally normalized Softmax output layers (one for EC and one for RE). For Setup 1, the CRF layer yields comparable or better results than the Softmax layer. However, for Setup 2 and 3, the improvements are more obvious. We assume that the model may benefit more from global normalization in the case of table filling because it is the more difficult setup. Comparison between Setup 2 and Setup 3 shows that the entity classification suffers under ungiven entity boundaries (in Setup 3). One reason might be that the model may no longer include the token embedding of the multi-token entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity (entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity entity enti"}, {"heading": "4.4 Analysis of Entity Type Aggregation", "text": "As described in Section 4.2, we aggregate the EC results by majority decisions. Now we analyze their disagreement. For our best model, there are only 9 entities (0.12%) with disagreement in the test data. For these, the maximum, minimum and median disagreement with the majority label is 36%, 2% and 8%, respectively. Therefore, the disagreement is negligible.5We only show results of individual models, no entities. According to previous studies, we leave the entity class \"Others\" in the calculation of the EC Score.6Our results for EC in Setup 1 are also not comparable."}, {"heading": "4.5 Analysis of CRF Transition Matrix", "text": "To analyze the CRF layer, we extract which transitions have values above 0.5. Figure 4 shows that the layer has learned correct correlations between entity types and relationships."}, {"heading": "5 Conclusion and Future Work", "text": "In this paper, we presented the first study of global normalization of neural networks for a sentence classification task without transforming it into a labeling problem. We trained a Convolutionary Neural Network with a linear-chain conditional Random Field Output layer on a common entity and relation classification, and demonstrated that it performs better than a locally normalized Softmax layer. An interesting future direction is to expand the linear-chain CRF to normalize all predictions of table filling in a single model run together. We also plan to verify our results in future work on other datasets."}, {"heading": "Acknowledgments", "text": "Heike Adel is a scholarship holder of the Google European Doctoral Fellowship in Natural Language Processing and is supported by this fellowship, which was also supported by the DFG (SCHU 2246 / 4-2)."}, {"heading": "A Dataset Statistics", "text": "The N-class of Setup 2 and Setup 3 has been included in the training and development set as described in the publication. Note that the sum of the numbers of the relation labels is slightly different from the numbers mentioned in (Roth and Yih, 2004).According to their website https: / / cogcomp.cs.illinois.edu / page / resource view / 43 they have updated the corpus."}, {"heading": "B Hyperparameters", "text": "Table 4 provides the hyperparameters that we have optimized for developers (nkC: number of context filters for CNN, nkE: number of context filters for CNN that include the entities; hC: number of hidden units for creating the final context representation, hE: number of hidden units for creating the final entity representation).For all models, we use a filter width of 3 for the CNN context and a filter width of 2 for the CNN entity (tuned in previous experiments and specified for optimizing the parameters in Table 4).For training, we use gradient descent with a stack size of 10 and an initial learning rate of 0.1. When performance on developers decreases, we halve the learning rate. The model is trained with an early stop on developers, with a maximum number of 20 epochs."}], "references": [{"title": "Globally normalized transition-based neural networks", "author": ["Daniel Andor", "Chris Alberti", "David Weiss", "Aliaksei Severyn", "Alessandro Presta", "Kuzman Ganchev", "Slav Petrov", "Michael Collins."], "venue": "Proceedings of the 54th Annual Meeting of the Associa-", "citeRegEx": "Andor et al\\.,? 2016", "shortCiteRegEx": "Andor et al\\.", "year": 2016}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research, 12:2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Integrating probabilistic extraction models and data mining to discover relations and patterns in text", "author": ["Aron Culotta", "Andrew McCallum", "Jonathan Betz."], "venue": "Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,", "citeRegEx": "Culotta et al\\.,? 2006", "shortCiteRegEx": "Culotta et al\\.", "year": 2006}, {"title": "Relation extraction and the influence of automatic named-entity recognition", "author": ["Claudio Giuliano", "Alberto Lavelli", "Lorenza Romano."], "venue": "ACM Trans. Speech Lang. Process., 5(1):2:1\u20132:26.", "citeRegEx": "Giuliano et al\\.,? 2007", "shortCiteRegEx": "Giuliano et al\\.", "year": 2007}, {"title": "Table filling multi-task recurrent neural network for joint entity and relation extraction", "author": ["Pankaj Gupta", "Hinrich Sch\u00fctze", "Bernt Andrassy."], "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Techni-", "citeRegEx": "Gupta et al\\.,? 2016", "shortCiteRegEx": "Gupta et al\\.", "year": 2016}, {"title": "Joint entity and relation extraction using card-pyramid parsing", "author": ["Rohit J. Kate", "Raymond Mooney."], "venue": "Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 203\u2013212, Uppsala, Sweden. Association for Com-", "citeRegEx": "Kate and Mooney.,? 2010", "shortCiteRegEx": "Kate and Mooney.", "year": 2010}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira."], "venue": "Proceedings of the Eighteenth International Conference on Machine Learning, ICML", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Neural architectures for named entity recognition", "author": ["Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Lample et al\\.,? 2016", "shortCiteRegEx": "Lample et al\\.", "year": 2016}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "Proceedings of Workshop", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Modeling joint entity and relation extraction with table representation", "author": ["Makoto Miwa", "Yutaka Sasaki."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1858\u20131869, Doha, Qatar. Associa-", "citeRegEx": "Miwa and Sasaki.,? 2014", "shortCiteRegEx": "Miwa and Sasaki.", "year": 2014}, {"title": "Information extraction from research papers using conditional random fields", "author": ["Fuchun Peng", "Andrew McCallum."], "venue": "Information processing & management, 42(4):963\u2013979.", "citeRegEx": "Peng and McCallum.,? 2006", "shortCiteRegEx": "Peng and McCallum.", "year": 2006}, {"title": "Global inference for entity and relation identification via a linear programming formulation", "author": ["D. Roth", "W. Yih."], "venue": "Introduction to Statistical Relational Learning. MIT Press.", "citeRegEx": "Roth and Yih.,? 2007", "shortCiteRegEx": "Roth and Yih.", "year": 2007}, {"title": "A linear programming formulation for global inference in natural language tasks", "author": ["Dan Roth", "Wen-tau Yih."], "venue": "HLT-NAACL 2004 Workshop: Eighth Conference on Computational Natural Language Learning (CoNLL-2004), pages 1\u20138,", "citeRegEx": "Roth and Yih.,? 2004", "shortCiteRegEx": "Roth and Yih.", "year": 2004}, {"title": "Semimarkov conditional random fields for information extraction", "author": ["Sunita Sarawagi", "William W Cohen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Sarawagi and Cohen,? \\Q2004\\E", "shortCiteRegEx": "Sarawagi and Cohen", "year": 2004}, {"title": "An introduction to conditional random fields for relational learning", "author": ["Charles Sutton", "Andrew McCallum."], "venue": "Introduction to statistical relational learning, pages 93\u2013128.", "citeRegEx": "Sutton and McCallum.,? 2006", "shortCiteRegEx": "Sutton and McCallum.", "year": 2006}, {"title": "Combining recurrent and convolutional neural networks for relation classification", "author": ["Ngoc Thang Vu", "Heike Adel", "Pankaj Gupta", "Hinrich Sch\u00fctze."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Vu et al\\.,? 2016", "shortCiteRegEx": "Vu et al\\.", "year": 2016}, {"title": "Convolutional neural network based triangular crf for joint intent detection and slot filling", "author": ["Puyang Xu", "Ruhi Sarikaya."], "venue": "2013 IEEE Workshop on Automatic Speech Recognition and Understanding, pages 78\u201383, Olomouc, Czech Republic. IEEE.", "citeRegEx": "Xu and Sarikaya.,? 2013", "shortCiteRegEx": "Xu and Sarikaya.", "year": 2013}, {"title": "Noise mitigation for neural entity typing and relation extraction", "author": ["Yadollah Yaghoobzadeh", "Heike Adel", "Hinrich Sch\u00fctze."], "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, Valencia,", "citeRegEx": "Yaghoobzadeh et al\\.,? 2016", "shortCiteRegEx": "Yaghoobzadeh et al\\.", "year": 2016}, {"title": "Collective cross-document relation extraction without labelled data", "author": ["Limin Yao", "Sebastian Riedel", "Andrew McCallum."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1013\u20131023, Cambridge,", "citeRegEx": "Yao et al\\.,? 2010", "shortCiteRegEx": "Yao et al\\.", "year": 2010}, {"title": "2d conditional random fields for web information extraction", "author": ["Jun Zhu", "Zaiqing Nie", "Ji-Rong Wen", "Bo Zhang", "Wei-Ying Ma."], "venue": "Proceedings of the 22nd international conference on Machine learning, pages 1044\u20131051. ACM.", "citeRegEx": "Zhu et al\\.,? 2005", "shortCiteRegEx": "Zhu et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 6, "context": "conditional random field (CRF) (Lafferty et al., 2001).", "startOffset": 31, "endOffset": 54}, {"referenceID": 18, "context": ", (Yao et al., 2010; Yaghoobzadeh et al., 2016).", "startOffset": 2, "endOffset": 47}, {"referenceID": 17, "context": ", (Yao et al., 2010; Yaghoobzadeh et al., 2016).", "startOffset": 2, "endOffset": 47}, {"referenceID": 10, "context": "Roth and Yih (2004) develop constraints and use linear programming to globally normalize entity types and relations.", "startOffset": 0, "endOffset": 20}, {"referenceID": 3, "context": "Giuliano et al. (2007) use entity type information for relation extraction but do not train", "startOffset": 0, "endOffset": 23}, {"referenceID": 5, "context": "Kate and Mooney (2010) train task-specific support vector machines and develop a card-pyramid parsing algorithm to jointly model both tasks.", "startOffset": 0, "endOffset": 23}, {"referenceID": 5, "context": "Kate and Mooney (2010) train task-specific support vector machines and develop a card-pyramid parsing algorithm to jointly model both tasks. Miwa and Sasaki (2014) use the same dataset but model the tasks as a table filling problem (see Section 4.", "startOffset": 0, "endOffset": 164}, {"referenceID": 4, "context": "Recently, Gupta et al. (2016) apply recurrent neural networks to fill the table.", "startOffset": 10, "endOffset": 30}, {"referenceID": 14, "context": "Several studies propose different variants of non-neural CRF models for information extraction tasks but model them as token-labeling problems (Sutton and McCallum, 2006; Sarawagi et al., 2004; Culotta et al., 2006; Zhu et al., 2005; Peng and McCallum, 2006).", "startOffset": 143, "endOffset": 258}, {"referenceID": 2, "context": "Several studies propose different variants of non-neural CRF models for information extraction tasks but model them as token-labeling problems (Sutton and McCallum, 2006; Sarawagi et al., 2004; Culotta et al., 2006; Zhu et al., 2005; Peng and McCallum, 2006).", "startOffset": 143, "endOffset": 258}, {"referenceID": 19, "context": "Several studies propose different variants of non-neural CRF models for information extraction tasks but model them as token-labeling problems (Sutton and McCallum, 2006; Sarawagi et al., 2004; Culotta et al., 2006; Zhu et al., 2005; Peng and McCallum, 2006).", "startOffset": 143, "endOffset": 258}, {"referenceID": 10, "context": "Several studies propose different variants of non-neural CRF models for information extraction tasks but model them as token-labeling problems (Sutton and McCallum, 2006; Sarawagi et al., 2004; Culotta et al., 2006; Zhu et al., 2005; Peng and McCallum, 2006).", "startOffset": 143, "endOffset": 258}, {"referenceID": 2, "context": ", 2004; Culotta et al., 2006; Zhu et al., 2005; Peng and McCallum, 2006). In contrast, we propose a simpler linear-chain CRF model which directly connects entity and relation classes instead of assigning a label to each token of the input sequence. This is more similar to the factor graph by Yao et al. (2010) but computationally simpler.", "startOffset": 8, "endOffset": 311}, {"referenceID": 2, "context": ", 2004; Culotta et al., 2006; Zhu et al., 2005; Peng and McCallum, 2006). In contrast, we propose a simpler linear-chain CRF model which directly connects entity and relation classes instead of assigning a label to each token of the input sequence. This is more similar to the factor graph by Yao et al. (2010) but computationally simpler. Xu and Sarikaya (2013) also apply a CRF layer on top of continuous representations obtained by a CNN.", "startOffset": 8, "endOffset": 363}, {"referenceID": 8, "context": "(Mikolov et al., 2013).", "startOffset": 0, "endOffset": 22}, {"referenceID": 15, "context": "Moreover, they have proven effective for RE in previous work (Vu et al., 2016).", "startOffset": 61, "endOffset": 78}, {"referenceID": 12, "context": "The ERR dataset we use provides boundaries for entities to concentrate on the classification task (Roth and Yih, 2004).", "startOffset": 98, "endOffset": 118}, {"referenceID": 7, "context": "For global normalization, we adopt the linearchain CRF layer by Lample et al. (2016).2 It expects scores for the different classes as input.", "startOffset": 64, "endOffset": 85}, {"referenceID": 12, "context": "We use the \u201centity and relation recognition\u201d (ERR) dataset from (Roth and Yih, 2004)4 with the train-test split by Gupta et al.", "startOffset": 64, "endOffset": 84}, {"referenceID": 4, "context": "We use the \u201centity and relation recognition\u201d (ERR) dataset from (Roth and Yih, 2004)4 with the train-test split by Gupta et al. (2016). We tune", "startOffset": 115, "endOffset": 135}, {"referenceID": 5, "context": "Roth and Yih (2004, 2007); Kate and Mooney (2010) train separate models for EC and RE on the ERR dataset.", "startOffset": 27, "endOffset": 50}, {"referenceID": 8, "context": "Following Miwa and Sasaki (2014); Gupta et al.", "startOffset": 10, "endOffset": 33}, {"referenceID": 4, "context": "Following Miwa and Sasaki (2014); Gupta et al. (2016), we also model the joint task of EC and RE as a table filling task.", "startOffset": 34, "endOffset": 54}, {"referenceID": 9, "context": "Note that this setup is also used by prior work on table filling (Miwa and Sasaki, 2014; Gupta et al., 2016).", "startOffset": 65, "endOffset": 108}, {"referenceID": 4, "context": "Note that this setup is also used by prior work on table filling (Miwa and Sasaki, 2014; Gupta et al., 2016).", "startOffset": 65, "endOffset": 108}, {"referenceID": 4, "context": "Note that this setup is also used by prior work on table filling (Miwa and Sasaki, 2014; Gupta et al., 2016). For evaluation, we follow Gupta et al. (2016) and score a multi-token entity as correct if at least one of its comprising cells has been classified correctly.", "startOffset": 89, "endOffset": 156}, {"referenceID": 11, "context": "Table 2 shows our results in the context of state-of-the-art results: (Roth and Yih, 2007), (Kate and Mooney, 2010),", "startOffset": 70, "endOffset": 90}, {"referenceID": 5, "context": "Table 2 shows our results in the context of state-of-the-art results: (Roth and Yih, 2007), (Kate and Mooney, 2010),", "startOffset": 92, "endOffset": 115}, {"referenceID": 9, "context": "(Miwa and Sasaki, 2014), (Gupta et al.", "startOffset": 0, "endOffset": 23}, {"referenceID": 4, "context": "(Miwa and Sasaki, 2014), (Gupta et al., 2016).", "startOffset": 25, "endOffset": 45}, {"referenceID": 4, "context": "Our results are best comparable with (Gupta et al., 2016) since we use the same setup and traintest splits.", "startOffset": 37, "endOffset": 57}], "year": 2017, "abstractText": "We introduce globally normalized convolutional neural networks for joint entity classification and relation extraction. In particular, we propose a way to utilize a linear-chain conditional random field output layer for predicting entity types and relations between entities at the same time. Our experiments show that global normalization outperforms a locally normalized softmax layer on a benchmark dataset.", "creator": "TeX"}}}