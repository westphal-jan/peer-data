{"id": "1707.08052", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jul-2017", "title": "Challenges in Data-to-Document Generation", "abstract": "Recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records. In this work, we suggest a slightly more difficult data-to-text generation task, and investigate how effective current approaches are on this task. In particular, we introduce a new, large-scale corpus of data records paired with descriptive documents, propose a series of extractive evaluation methods for analyzing performance, and obtain baseline results using current neural generation methods. Experiments show that these models produce fluent text, but fail to convincingly approximate human-generated documents. Moreover, even templated baselines exceed the performance of these neural models on some metrics, though copy- and reconstruction-based extensions lead to noticeable improvements.", "histories": [["v1", "Tue, 25 Jul 2017 15:42:25 GMT  (42kb)", "http://arxiv.org/abs/1707.08052v1", "EMNLP 2017"]], "COMMENTS": "EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sam wiseman", "stuart m shieber", "alexander m rush"], "accepted": true, "id": "1707.08052"}, "pdf": {"name": "1707.08052.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["swiseman@seas.harvard.edu", "shieber@seas.harvard.edu", "srush@seas.harvard.edu"], "sections": [{"heading": null, "text": "ar Xiv: 170 7.08 052v 1 [cs.C L] 25 Jul 2 017icant progress on the problem of generating short descriptive texts conditioning on a small number of database records. In this paper, we propose a slightly more difficult task of data generation and examine how effective current approaches are in this task. In particular, we propose a new large-scale corpus of data sets paired with descriptive documents, propose a set of extractive evaluation methods for analyzing performance, and obtain baseline results using current methods of neural generation. Experiments show that these models produce fluent text but do not convincingly approximate human-generated documents. Furthermore, even templates baselines exceed the performance of these neural models in some metrics, although copy and reconstruction-based extensions lead to noticeable improvements."}, {"heading": "1 Introduction", "text": "In recent years, the number of those able to reform has multiplied, both in the US and in Europe."}, {"heading": "2 Data-to-Text Datasets", "text": "This year, the number of those who are able in the first half of the year in the second half of the year in the first half of the year in the second half of the year in the second half of the year in the second half of the year in the second half of the year in the second half of the year in the second half of the year in the second half of the year in the second half of the year in the second half of the year in the first half of the second half of the year in the second half of the second half of the year in the second half of the first half of the second half of the year in the second half of the second half of the year in the second half of the second half of the year, in the second half of the second half of the year in the second half of the second half of the year in the second half of the second half of the year."}, {"heading": "3 Evaluating Document Generation", "text": "We begin by discussing the evaluation of generated documents, since both the task we are introducing and the evaluation methods we are proposing are motivated by some of the shortcomings of current evaluation approaches. Text generation systems are typically evaluated using a combination of automatic metrics such as BLEU (Papineni et al., 2002) and human evaluation. BLEU may be a reasonably effective method of evaluating short-form text generation, but we found it unsatisfactory for the generation of documents. In particular, we note that it primarily rewards fluid text generation rather than generations that collect the most important information in the database or pass the information on in a particularly coherent manner. On the other hand, while human evaluation is ultimately likely to be necessary for evaluating generations (Liu et al., 2016; Wu et al., 2016), it is much less convenient than the use of automatic metrics. Furthermore, we believe that current text evaluations are more likely to rely on us to rely on automated evaluation alone, and we are still poorly able to rely on automated evaluation alone."}, {"heading": "3.1 Extractive Evaluation", "text": "To address this evaluation challenge, we start with the intuition that assessing document quality is easier than creating documents. In particular, it is much easier to automatically extract information from documents than to generate documents that accurately convey desired information. As such, simple, high-precision information extraction models can serve as a basis for assessing and better understanding the quality of automatic generations. We emphasize that such a evaluation scheme is best suited to evaluating generations (such as basketball game summaries), which are primarily intended to summarize information. While many generational problems do not fall into this category, we believe that this is an interesting category, and one should focus on it because it is suitable for this type of evaluation. To see how a simple information extraction system might work, we look at the document in Figure 1. We can first predict candidate entity (player, team, and city) and value (number and specific sequence) of text pairs, the way we predict the evaluation and then the way the pair will appear."}, {"heading": "3.2 Comparing Generations", "text": "With a sufficiently precise relation extraction system, we can begin to evaluate how well an automatic generation Y 1: T has captured the information in a number of data sets. In particular, since the predictions of an accurate information extraction system serve to align entity mentioning pairs in the text with data sets in the database, this alignment can be used both to evaluate a generation's content selection (\"what the generation says\") and content placement (\"how the generation says it\"). We will look in particular at three induced metrics: \u2022 Content selection (CS): Precision and recall of unique relationships r extracts fromy 1: T, which are also extracted from y1: T. This measures how well the generated document matches the gold document with what needs to be generated. \u2022 Relation generation (RG): Precision and number of unique relationships r extracts fromy 1: T, which also appear in s."}, {"heading": "4 Neural Data-to-Document Models", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "5 Experimental Methods", "text": "In this section, we highlight a few important details of our models and methods; the full details are in the Annex > > >. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < \"<\" > \"<\" < \"<\" < \"<\" < \"<\" < \"<\" < \"<\" < \"<\" < \"<\" < \"<\" < \"<\" < \"<\" < \"<\" &; \"<\" < \"<\"; \"<\" < \";\" < \"<\"; \"<\" < \";\" < \";\"; \"<\"; \"<\"; \";\" < \";\" < \";\"; \"<\"; \";\" < \";\"; \"<\"; \"<\"; \";\"; \"<\" < \";\" < \";\"; \"<\"; \"<\" < \";\"; \"<\"; \"<\"; \";\" < \";\"; \"<\"; \"<\" < \";\" < \";\" < \";\"; \"<\"; \"<\"; \";\" < \";\" < \";\" < \";\"; \"<\"; \";\" < \";\" < \";\"; \"<\"; \";\"; \""}, {"heading": "6 Results", "text": "We found that all models performed quite poorly in terms of SBNATION data, with the best model achieving a validation perplexity of 33.34 and a BLEU score of 1.78. This poor performance is probably due to the noisy quality of SBNATION data and the fact that many documents in the data set focus on information not included in the box and line scores. Accordingly, we focus on ROTOWIRE in what follows. The main results for the ROTOWIRE data set are presented in Table 2, which shows the performance of the models in Section 4 in terms of the metrics defined in Section 3.2, as well as in terms of perplexity and BLEU."}, {"heading": "6.1 Discussion", "text": "There are several interesting relationships in the development part of Table 2. First, we note that the template model performs very poorly on BLEU, but performs reasonably well on extractive metrics, even though all neural models achieve roughly the same perplexity. Extractive metrics provide further insights into the behavior of the models. First, we note that the extractive model achieves a precision of 92% on the y1: T gold documents. Using the JointCopy model, the generation only has a record generation (RG) of 47%, indicating that relationships are often created incorrectly. The best conditional copy system improves this to 71%, a significant improvement and potentially the cause of the improved BLEU score, but still well below gold."}, {"heading": "6.2 Human Evaluation", "text": "The first study attempted to determine whether generations that were judged more accurate by our metrics were also looked at more closely by the human rating agencies. To achieve this, the rating agencies were asked to count how many facts in each sentence were rated by records in the box or in the line, and how many were contradictory. We randomly selected 20 different games to submit to the rating agencies, and a total of 20 generated sentences per game were rated by the rating agencies. The two columns of Table 3 left contain the average numbers of supporting and contradictory facts per sentence determined by the rating agencies."}, {"heading": "6.3 Qualitative Example", "text": "Figure 2 shows a document generated by the conditional copy model, using a size 5 bar. Obviously, this particular generation has several beautiful features: it learns the colloquial style of the text beautifully, using phrases such as \"19 percent from the depth\" correctly; it is also partially correct in the use of the records; we highlight in blue when it generates text licensed by a record in the associated box and line scoring; at the same time, the generation also contains major logical errors. First, there are basic copying errors, such as flipping through the teams \"win-loss records; the system also makes obvious semantic errors; for example, it generates the phrase\" the rockets were able to catch up with the rocket. \"Finally, we see that the model hallucinates factual statements, such as\" in front of their home audience, \"which presumably corresponds to the language model, but ultimately is not supported by anything in the box or line corners."}, {"heading": "7 Related Work", "text": "In this section, we point out that the production of natural language has been studied for decades (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997), and the creation of summaries of sports games has been a topic of interest for almost as long (Robin, 1994; Tanaka-Ishii et al., 1998; Barzilay and Lapata, 2005). Historically, research has focused on the selection of content (\"what to say\") (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997; Duboue and McKeown, 2003; Barzilay and Lapata, 2005) and surface realization (\"as you say it\") (Goldberg et al., 1994; Reiter et al., 2005) with previous work using (handmade) grammars and later work using SMT-like approaches (Wong and Mooney, 2007) or generating PCFGs (Belz, 2008) or other formalities (the 2000s, 2000s and 2000s), the Sorcut and Soricang systems."}, {"heading": "8 Conclusion and Future Work", "text": "This paper examines the challenges of document-to-document neural data generation by introducing a new dataset and proposing various metrics for automatically evaluating content selection, generation, and ordering. We see that recent ideas in copying and reconstructing lead to improvements in this task, but that even between these neural models and submitted systems there is a significant gap. We hope to motivate researchers to continue focusing on generation problems that are relevant for both content selection and surface realization, but may not be clearly reflected in the perplexity of the model. Future work on this task could include approaches that process or handle the source data in a more refined manner, generation models that attempt to incorporate semantic or reference-related constraints, and approaches to conditioning facts or records that are not so explicit in the box and reference scores."}, {"heading": "Acknowledgments", "text": "We would like to thank you for your support with a Google Research Award."}, {"heading": "A. Additional Dataset Details", "text": "The ROTOWIRE data includes NBA games played between 1 / 1 / 2014 and 29 / 03 / 2017; some games have multiple summaries. The summaries have been randomly divided into training, validation and test sets consisting of 3398, 727 and 728 summaries. The SBNATION data covers NBA games played between 3 / 11 / 2006 and 26 / 03 / 2017; some games have multiple summaries. The summaries have been randomly divided into training, validation and test sets consisting of 7633, 1635 and 1635 summaries. All numbers in the box and line scores (but not the summaries) are converted into integrators; fractions corresponding to the percent are multiplied by 100 to get integrators in [0, 100]."}, {"heading": "B. Generation Model Details", "text": "We are not in a position to search for a new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new, new"}], "references": [{"title": "A simple domain-independent probabilistic approach to generation", "author": ["Gabor Angeli", "Percy Liang", "Dan Klein."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 502\u2013512. Association for Com-", "citeRegEx": "Angeli et al\\.,? 2010", "shortCiteRegEx": "Angeli et al\\.", "year": 2010}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "KyunghyunCho", "Yoshua Bengio."], "venue": "ICLR.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Collective content selection for concept-to-text generation", "author": ["Regina Barzilay", "Mirella Lapata."], "venue": "Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 331\u2013338. Association for", "citeRegEx": "Barzilay and Lapata.,? 2005", "shortCiteRegEx": "Barzilay and Lapata.", "year": 2005}, {"title": "Automatic generation of weather", "author": ["Anja Belz"], "venue": null, "citeRegEx": "Belz.,? \\Q2008\\E", "shortCiteRegEx": "Belz.", "year": 2008}, {"title": "Nltk: the natural language toolkit", "author": ["Steven Bird"], "venue": null, "citeRegEx": "Bird.,? \\Q2006\\E", "shortCiteRegEx": "Bird.", "year": 2006}, {"title": "On the properties", "author": ["danau", "Yoshua Bengio"], "venue": null, "citeRegEx": "danau and Bengio.,? \\Q2014\\E", "shortCiteRegEx": "danau and Bengio.", "year": 2014}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural Comput., 9:1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Data recombination for neural semantic parsing", "author": ["Robin Jia", "Percy Liang."], "venue": "ACL Volume 1: Long Papers.", "citeRegEx": "Jia and Liang.,? 2016", "shortCiteRegEx": "Jia and Liang.", "year": 2016}, {"title": "Speech and language processing, volume 3", "author": ["Dan Jurafsky", "James H Martin."], "venue": "Pearson London.", "citeRegEx": "Jurafsky and Martin.,? 2014", "shortCiteRegEx": "Jurafsky and Martin.", "year": 2014}, {"title": "Adversarial evaluation of dialogue models", "author": ["Anjuli Kannan", "Oriol Vinyals."], "venue": "NIPS 2016 Workshop on Adversarial Training.", "citeRegEx": "Kannan and Vinyals.,? 2016", "shortCiteRegEx": "Kannan and Vinyals.", "year": 2016}, {"title": "Generative alignment and semantic parsing for learning from ambiguous supervision", "author": ["Joohyun Kim", "Raymond J Mooney."], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 543\u2013551. Associ-", "citeRegEx": "Kim and Mooney.,? 2010", "shortCiteRegEx": "Kim and Mooney.", "year": 2010}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "EMNLP, pages 1746\u2013 1751.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Opennmt: Open-source toolkit for neural machine translation", "author": ["Guillaume Klein", "Yoon Kim", "Yuntian Deng", "Jean Senellart", "Alexander M. Rush."], "venue": "CoRR, abs/1701.02810.", "citeRegEx": "Klein et al\\.,? 2017", "shortCiteRegEx": "Klein et al\\.", "year": 2017}, {"title": "A global model for concept-to-text generation", "author": ["Ioannis Konstas", "Mirella Lapata."], "venue": "J. Artif. Intell. Res.(JAIR), 48:305\u2013346.", "citeRegEx": "Konstas and Lapata.,? 2013", "shortCiteRegEx": "Konstas and Lapata.", "year": 2013}, {"title": "Design of a knowledge-based report generator", "author": ["Karen Kukich."], "venue": "ACL, pages 145\u2013150.", "citeRegEx": "Kukich.,? 1983", "shortCiteRegEx": "Kukich.", "year": 1983}, {"title": "Neural text generation from structured data with application to the biography domain", "author": ["R\u00e9mi Lebret", "David Grangier", "Michael Auli."], "venue": "EMNLP, pages 1203\u20131213.", "citeRegEx": "Lebret et al\\.,? 2016", "shortCiteRegEx": "Lebret et al\\.", "year": 2016}, {"title": "Adversarial learning for neural dialogue generation", "author": ["Jiwei Li", "Will Monroe", "Tianlin Shi", "Alan Ritter", "Dan Jurafsky."], "venue": "CoRR, abs/1701.06547.", "citeRegEx": "Li et al\\.,? 2017", "shortCiteRegEx": "Li et al\\.", "year": 2017}, {"title": "Learning semantic correspondences with less supervision", "author": ["Percy Liang", "Michael I Jordan", "Dan Klein."], "venue": "ACL, pages 91\u201399. Association for Computational Linguistics.", "citeRegEx": "Liang et al\\.,? 2009", "shortCiteRegEx": "Liang et al\\.", "year": 2009}, {"title": "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation", "author": ["Chia-Wei Liu", "Ryan Lowe", "Iulian Serban", "Michael Noseworthy", "Laurent Charlin", "Joelle Pineau."], "venue": "EMNLP,", "citeRegEx": "Liu et al\\.,? 2016", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "A probabilistic forest-to-string model for language generation from typed lambda calculus expressions", "author": ["Wei Lu", "Hwee Tou Ng."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1611\u20131622. Asso-", "citeRegEx": "Lu and Ng.,? 2011", "shortCiteRegEx": "Lu and Ng.", "year": 2011}, {"title": "Effective approaches to attention-based neural machine translation", "author": ["Thang Luong", "Hieu Pham", "Christopher D. Manning."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, pages 1412\u2013", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Text generation - using discourse strategies and focus constraints to generate natural language text", "author": ["Kathleen McKeown."], "venue": "Studies in natural language processing. Cambridge University Press.", "citeRegEx": "McKeown.,? 1992", "shortCiteRegEx": "McKeown.", "year": 1992}, {"title": "What to talk about and how? selective generation using lstms with coarse-to-fine alignment", "author": ["Hongyuan Mei", "Mohit Bansal", "Matthew R. Walter."], "venue": "NAACL HLT, pages 720\u2013730.", "citeRegEx": "Mei et al\\.,? 2016", "shortCiteRegEx": "Mei et al\\.", "year": 2016}, {"title": "Pointer sentinel mixture models", "author": ["Stephen Merity", "Caiming Xiong", "James Bradbury", "Richard Socher."], "venue": "CoRR, abs/1609.07843.", "citeRegEx": "Merity et al\\.,? 2016", "shortCiteRegEx": "Merity et al\\.", "year": 2016}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov", "M. Karafit", "L. Burget", "J. Cernock", "S. Khudanpur."], "venue": "INTERSPEECH.", "citeRegEx": "Mikolov et al\\.,? 2010", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "ToddWard", "WeiJing Zhu."], "venue": "Proceedings of the 40th annual meeting on association for computational linguistics, pages 311\u2013318. Association for", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "You need to understand your corpora! the weathergov example", "author": ["Ehud Reiter."], "venue": "https://ehudr eiter.com/2017/05/09/weathergov/.", "citeRegEx": "Reiter.,? 2017", "shortCiteRegEx": "Reiter.", "year": 2017}, {"title": "Building applied natural language generation systems", "author": ["Ehud Reiter", "Robert Dale."], "venue": "Natural Language Engineering, 3(1):57\u201387.", "citeRegEx": "Reiter and Dale.,? 1997", "shortCiteRegEx": "Reiter and Dale.", "year": 1997}, {"title": "Choosing words in computergenerated weather forecasts", "author": ["Ehud Reiter", "Somayajulu Sripada", "Jim Hunter", "Jin Yu", "Ian Davy."], "venue": "Artificial Intelligence, 167(1-2):137\u2013169.", "citeRegEx": "Reiter et al\\.,? 2005", "shortCiteRegEx": "Reiter et al\\.", "year": 2005}, {"title": "Revision-based generation of Natural Language Summaries providing historical Background", "author": ["Jacques Robin."], "venue": "Ph.D. thesis, Citeseer.", "citeRegEx": "Robin.,? 1994", "shortCiteRegEx": "Robin.", "year": 1994}, {"title": "Classifying relations by ranking with convolutional neural networks", "author": ["C\u0131\u0301cero Nogueira dos Santos", "Bing Xiang", "Bowen Zhou"], "venue": "In ACL,", "citeRegEx": "Santos et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Santos et al\\.", "year": 2015}, {"title": "Stochastic language generation using widl-expressions and its application in machine translation and summarization", "author": ["Radu Soricut", "Daniel Marcu."], "venue": "Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual", "citeRegEx": "Soricut and Marcu.,? 2006", "shortCiteRegEx": "Soricut and Marcu.", "year": 2006}, {"title": "Generating text with recurrent neural networks", "author": ["Ilya Sutskever", "James Martens", "Geoffrey E Hinton."], "venue": "Proceedings of the 28th International", "citeRegEx": "Sutskever et al\\.,? 2011", "shortCiteRegEx": "Sutskever et al\\.", "year": 2011}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc VV Le."], "venue": "Advances in Neural Information Processing Systems (NIPS), pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Reactive content selection in the generation of real-time soccer commentary", "author": ["Kumiko Tanaka-Ishii", "K\u00f4iti Hasida", "Itsuki Noda."], "venue": "COLING-ACL, pages 1282\u20131288.", "citeRegEx": "Tanaka.Ishii et al\\.,? 1998", "shortCiteRegEx": "Tanaka.Ishii et al\\.", "year": 1998}, {"title": "Neural machine translation with reconstruction", "author": ["Zhaopeng Tu", "Yang Liu", "Lifeng Shang", "Xiaohua Liu", "Hang Li."], "venue": "AAAI, pages 3097\u20133103.", "citeRegEx": "Tu et al\\.,? 2017", "shortCiteRegEx": "Tu et al\\.", "year": 2017}, {"title": "Towards broad coverage surface realization with ccg", "author": ["Michael White", "Rajakrishnan Rajkumar", "Scott Martin."], "venue": "Proceedings of the Workshop on Using Corpora for NLG: Language Generation and Machine Translation (UCNLG+ MT), pages 267\u2013", "citeRegEx": "White et al\\.,? 2007", "shortCiteRegEx": "White et al\\.", "year": 2007}, {"title": "Generation by inverting a semantic parser that uses statistical machine translation", "author": ["Yuk Wah Wong", "Raymond J Mooney."], "venue": "HLT-NAACL, pages 172\u2013179.", "citeRegEx": "Wong and Mooney.,? 2007", "shortCiteRegEx": "Wong and Mooney.", "year": 2007}, {"title": "Reference-aware language models", "author": ["Zichao Yang", "Phil Blunsom", "Chris Dyer", "Wang Ling."], "venue": "CoRR, abs/1611.01628.", "citeRegEx": "Yang et al\\.,? 2016", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Relation classification via convolutional deep neural network", "author": ["Daojian Zeng", "Kang Liu", "Siwei Lai", "Guangyou Zhou", "Jun Zhao"], "venue": "In COLING,", "citeRegEx": "Zeng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeng et al\\.", "year": 2014}, {"title": "Weakly-supervised relation classification for information extraction", "author": ["Zhu Zhang."], "venue": "Proceedings of the thirteenth ACM international conference on Information and knowledge management, pages 581\u2013 588. ACM.", "citeRegEx": "Zhang.,? 2004", "shortCiteRegEx": "Zhang.", "year": 2004}, {"title": "Semi-supervised learning for relation extraction", "author": ["GuoDong Zhou", "JunHui Li", "LongHua Qian", "Qiaoming Zhu."], "venue": "Third International Joint Conference on Natural Language Processing, page 32.", "citeRegEx": "Zhou et al\\.,? 2008", "shortCiteRegEx": "Zhou et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 14, "context": "A classic problem in natural-language generation (NLG) (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997) involves taking structured data, such as a table, as input, and producing text that adequately and fluently describes this data as output.", "startOffset": 55, "endOffset": 107}, {"referenceID": 21, "context": "A classic problem in natural-language generation (NLG) (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997) involves taking structured data, such as a table, as input, and producing text that adequately and fluently describes this data as output.", "startOffset": 55, "endOffset": 107}, {"referenceID": 27, "context": "A classic problem in natural-language generation (NLG) (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997) involves taking structured data, such as a table, as input, and producing text that adequately and fluently describes this data as output.", "startOffset": 55, "endOffset": 107}, {"referenceID": 27, "context": "Unlike machine translation, which aims for a complete transduction of the sentence to be translated, this form of NLG is typically taken to require addressing (at least) two separate challenges: what to say, the selection of an appropriate subset of the input data to discuss, and how to say it, the surface realization of a generation (Reiter and Dale, 1997; Jurafsky and Martin, 2014).", "startOffset": 336, "endOffset": 386}, {"referenceID": 8, "context": "Unlike machine translation, which aims for a complete transduction of the sentence to be translated, this form of NLG is typically taken to require addressing (at least) two separate challenges: what to say, the selection of an appropriate subset of the input data to discuss, and how to say it, the surface realization of a generation (Reiter and Dale, 1997; Jurafsky and Martin, 2014).", "startOffset": 336, "endOffset": 386}, {"referenceID": 24, "context": "However, neural generation systems, which are typically trained end-to-end as conditional language models (Mikolov et al., 2010; Sutskever et al., 2011, 2014), blur this distinction.", "startOffset": 106, "endOffset": 158}, {"referenceID": 29, "context": "long history of NLG work that generates sports game summaries (Robin, 1994; Tanaka-Ishii et al., 1998; Barzilay and Lapata, 2005).", "startOffset": 62, "endOffset": 129}, {"referenceID": 34, "context": "long history of NLG work that generates sports game summaries (Robin, 1994; Tanaka-Ishii et al., 1998; Barzilay and Lapata, 2005).", "startOffset": 62, "endOffset": 129}, {"referenceID": 2, "context": "long history of NLG work that generates sports game summaries (Robin, 1994; Tanaka-Ishii et al., 1998; Barzilay and Lapata, 2005).", "startOffset": 62, "endOffset": 129}, {"referenceID": 17, "context": "Following the notation in Liang et al. (2009), let s = {rj} J j=1 be a set of records, where for each r\u2208 s we define r.", "startOffset": 26, "endOffset": 46}, {"referenceID": 17, "context": "Several benchmark datasets have been used in recent years for the text generation task, the most popular of these being WEATHERGOV (Liang et al., 2009) and ROBOCUP (Chen and Mooney, 2008).", "startOffset": 131, "endOffset": 151}, {"referenceID": 26, "context": "Furthermore, there is reason to believe that WEATHERGOV is at least partially machine-generated (Reiter, 2017).", "startOffset": 96, "endOffset": 110}, {"referenceID": 16, "context": "Several benchmark datasets have been used in recent years for the text generation task, the most popular of these being WEATHERGOV (Liang et al., 2009) and ROBOCUP (Chen and Mooney, 2008). Recently, neural generation systems have show strong results on these datasets, with the system of Mei et al. (2016) achieving BLEU scores in the 60s and 70s on WEATHERGOV, and BLEU scores of almost 30 even on the smaller ROBOCUP dataset.", "startOffset": 132, "endOffset": 306}, {"referenceID": 15, "context": "More recently, Lebret et al. (2016) introduced the WIKIBIO dataset, which is at least an order of magnitude larger in terms of number of tokens and record types.", "startOffset": 15, "endOffset": 36}, {"referenceID": 25, "context": "Text generation systems are typically evaluated using a combination of automatic measures, such as BLEU (Papineni et al., 2002), and human evaluation.", "startOffset": 104, "endOffset": 127}, {"referenceID": 18, "context": "While human evaluation, on the other hand, is likely ultimately necessary for evaluating generations (Liu et al., 2016; Wu et al., 2016), it is much less convenient than using automatic metrics.", "startOffset": 101, "endOffset": 136}, {"referenceID": 40, "context": "Indeed, many relation extraction systems reduce relation extraction to multi-class classification precisely in this way (Zhang, 2004; Zhou et al., 2008; Zeng et al., 2014; dos Santos et al., 2015).", "startOffset": 120, "endOffset": 196}, {"referenceID": 41, "context": "Indeed, many relation extraction systems reduce relation extraction to multi-class classification precisely in this way (Zhang, 2004; Zhou et al., 2008; Zeng et al., 2014; dos Santos et al., 2015).", "startOffset": 120, "endOffset": 196}, {"referenceID": 39, "context": "Indeed, many relation extraction systems reduce relation extraction to multi-class classification precisely in this way (Zhang, 2004; Zhou et al., 2008; Zeng et al., 2014; dos Santos et al., 2015).", "startOffset": 120, "endOffset": 196}, {"referenceID": 30, "context": "(2011) and dos Santos et al. (2015) to parameterize this probability; full details are given in the Appendix.", "startOffset": 15, "endOffset": 36}, {"referenceID": 17, "context": "Alternative approaches explicitly align the document with the table for this task (Liang et al., 2009).", "startOffset": 82, "endOffset": 102}, {"referenceID": 9, "context": "recently proposed adversarial evaluation approaches, which also advocate automatic metrics backed by classification (Bowman et al., 2016; Kannan and Vinyals, 2016; Li et al., 2017).", "startOffset": 116, "endOffset": 180}, {"referenceID": 16, "context": "recently proposed adversarial evaluation approaches, which also advocate automatic metrics backed by classification (Bowman et al., 2016; Kannan and Vinyals, 2016; Li et al., 2017).", "startOffset": 116, "endOffset": 180}, {"referenceID": 33, "context": "As a base model we utilize the now standard attentionbased encoder-decoder model (Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015).", "startOffset": 81, "endOffset": 146}, {"referenceID": 1, "context": "As a base model we utilize the now standard attentionbased encoder-decoder model (Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015).", "startOffset": 81, "endOffset": 146}, {"referenceID": 37, "context": ", 50), and then applying a 1-layer MLP (similar to Yang et al. (2016)).", "startOffset": 51, "endOffset": 70}, {"referenceID": 20, "context": "Given s\u0303, we use an LSTM decoder with attention and input-feeding, in the style of Luong et al. (2015), to compute the probability of each target word, conditioned on the previous words and on s.", "startOffset": 83, "endOffset": 103}, {"referenceID": 23, "context": "cent work involving augmenting encoder-decoder models to copy words directly from the source material on which they condition (Gu et al., 2016; G\u00fcl\u00e7ehre et al., 2016; Merity et al., 2016; Jia and Liang, 2016; Yang et al., 2016).", "startOffset": 126, "endOffset": 227}, {"referenceID": 7, "context": "cent work involving augmenting encoder-decoder models to copy words directly from the source material on which they condition (Gu et al., 2016; G\u00fcl\u00e7ehre et al., 2016; Merity et al., 2016; Jia and Liang, 2016; Yang et al., 2016).", "startOffset": 126, "endOffset": 227}, {"referenceID": 38, "context": "cent work involving augmenting encoder-decoder models to copy words directly from the source material on which they condition (Gu et al., 2016; G\u00fcl\u00e7ehre et al., 2016; Merity et al., 2016; Jia and Liang, 2016; Yang et al., 2016).", "startOffset": 126, "endOffset": 227}, {"referenceID": 38, "context": "(2016) and Yang et al. (2016) parameterize the joint distribution table over \u0177t and zt directly:", "startOffset": 11, "endOffset": 30}, {"referenceID": 38, "context": "Models with copy-decoders may be trained to minimize the negative log marginal probability, marginalizing out the latent-variable zt (Gu et al., 2016; Yang et al., 2016; Merity et al., 2016).", "startOffset": 133, "endOffset": 190}, {"referenceID": 23, "context": "Models with copy-decoders may be trained to minimize the negative log marginal probability, marginalizing out the latent-variable zt (Gu et al., 2016; Yang et al., 2016; Merity et al., 2016).", "startOffset": 133, "endOffset": 190}, {"referenceID": 35, "context": "A fully differentiable approach using the decoder hidden states has recently been successfully applied to neural machine translation by Tu et al. (2017). Unlike copying, this method is applied only at training, and attempts to learn decoder hidden states with broader coverage of the input data.", "startOffset": 136, "endOffset": 153}, {"referenceID": 24, "context": "We train the generation models using SGD and truncated BPTT (Elman, 1990; Mikolov et al., 2010), as in language modeling.", "startOffset": 60, "endOffset": 95}, {"referenceID": 20, "context": "For our ROTOWIRE models, the record encoder produces r\u0303j in R 600, and we use a 2-layer LSTM decoder with hidden states of the same size as the r\u0303j , and dot-product attention and input-feeding in the style of Luong et al. (2015). Unlike past work, we use two identically structured attention layers, one to compute the standard generation probabilities (gen or pgen), and one to produce the scores used in copy or pcopy.", "startOffset": 210, "endOffset": 230}, {"referenceID": 11, "context": "The convolutional models concatenate convolutions with kernel widths 2, 3, and 5, and 200 feature maps in the style of (Kim, 2014).", "startOffset": 119, "endOffset": 130}, {"referenceID": 12, "context": "Our encoder-decoder models are based on OpenNMT (Klein et al., 2017).", "startOffset": 48, "endOffset": 68}, {"referenceID": 14, "context": "Natural language generation has been studied for decades (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997), and generating summaries of sports games has been a topic of interest for almost as long (Robin, 1994; Tanaka-Ishii et al.", "startOffset": 57, "endOffset": 109}, {"referenceID": 21, "context": "Natural language generation has been studied for decades (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997), and generating summaries of sports games has been a topic of interest for almost as long (Robin, 1994; Tanaka-Ishii et al.", "startOffset": 57, "endOffset": 109}, {"referenceID": 27, "context": "Natural language generation has been studied for decades (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997), and generating summaries of sports games has been a topic of interest for almost as long (Robin, 1994; Tanaka-Ishii et al.", "startOffset": 57, "endOffset": 109}, {"referenceID": 29, "context": "Natural language generation has been studied for decades (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997), and generating summaries of sports games has been a topic of interest for almost as long (Robin, 1994; Tanaka-Ishii et al., 1998; Barzilay and Lapata, 2005).", "startOffset": 200, "endOffset": 267}, {"referenceID": 34, "context": "Natural language generation has been studied for decades (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997), and generating summaries of sports games has been a topic of interest for almost as long (Robin, 1994; Tanaka-Ishii et al., 1998; Barzilay and Lapata, 2005).", "startOffset": 200, "endOffset": 267}, {"referenceID": 2, "context": "Natural language generation has been studied for decades (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997), and generating summaries of sports games has been a topic of interest for almost as long (Robin, 1994; Tanaka-Ishii et al., 1998; Barzilay and Lapata, 2005).", "startOffset": 200, "endOffset": 267}, {"referenceID": 14, "context": "Historically, research has focused on both content selection (\u201cwhat to say\u201d) (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997; Duboue and McKeown, 2003; Barzilay and Lapata, 2005), and surface realization (\u201chow to say it\u201d) (Goldberg et al.", "startOffset": 77, "endOffset": 182}, {"referenceID": 21, "context": "Historically, research has focused on both content selection (\u201cwhat to say\u201d) (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997; Duboue and McKeown, 2003; Barzilay and Lapata, 2005), and surface realization (\u201chow to say it\u201d) (Goldberg et al.", "startOffset": 77, "endOffset": 182}, {"referenceID": 27, "context": "Historically, research has focused on both content selection (\u201cwhat to say\u201d) (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997; Duboue and McKeown, 2003; Barzilay and Lapata, 2005), and surface realization (\u201chow to say it\u201d) (Goldberg et al.", "startOffset": 77, "endOffset": 182}, {"referenceID": 2, "context": "Historically, research has focused on both content selection (\u201cwhat to say\u201d) (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997; Duboue and McKeown, 2003; Barzilay and Lapata, 2005), and surface realization (\u201chow to say it\u201d) (Goldberg et al.", "startOffset": 77, "endOffset": 182}, {"referenceID": 28, "context": "Historically, research has focused on both content selection (\u201cwhat to say\u201d) (Kukich, 1983; McKeown, 1992; Reiter and Dale, 1997; Duboue and McKeown, 2003; Barzilay and Lapata, 2005), and surface realization (\u201chow to say it\u201d) (Goldberg et al., 1994; Reiter et al., 2005) with earlier work using (hand-built) grammars, and later work using SMT-like approaches (Wong and Mooney, 2007) or generating from PCFGs (Belz, 2008) or other formalisms (Soricut and Marcu, 2006; White et al.", "startOffset": 226, "endOffset": 270}, {"referenceID": 37, "context": ", 2005) with earlier work using (hand-built) grammars, and later work using SMT-like approaches (Wong and Mooney, 2007) or generating from PCFGs (Belz, 2008) or other formalisms (Soricut and Marcu, 2006; White et al.", "startOffset": 96, "endOffset": 119}, {"referenceID": 3, "context": ", 2005) with earlier work using (hand-built) grammars, and later work using SMT-like approaches (Wong and Mooney, 2007) or generating from PCFGs (Belz, 2008) or other formalisms (Soricut and Marcu, 2006; White et al.", "startOffset": 145, "endOffset": 157}, {"referenceID": 31, "context": ", 2005) with earlier work using (hand-built) grammars, and later work using SMT-like approaches (Wong and Mooney, 2007) or generating from PCFGs (Belz, 2008) or other formalisms (Soricut and Marcu, 2006; White et al., 2007).", "startOffset": 178, "endOffset": 223}, {"referenceID": 36, "context": ", 2005) with earlier work using (hand-built) grammars, and later work using SMT-like approaches (Wong and Mooney, 2007) or generating from PCFGs (Belz, 2008) or other formalisms (Soricut and Marcu, 2006; White et al., 2007).", "startOffset": 178, "endOffset": 223}, {"referenceID": 17, "context": "In the late 2000s and early 2010s, a number of systems were proposed that did both (Liang et al., 2009; Angeli et al., 2010; Kim and Mooney, 2010; Lu and Ng, 2011; Konstas and Lapata, 2013).", "startOffset": 83, "endOffset": 189}, {"referenceID": 0, "context": "In the late 2000s and early 2010s, a number of systems were proposed that did both (Liang et al., 2009; Angeli et al., 2010; Kim and Mooney, 2010; Lu and Ng, 2011; Konstas and Lapata, 2013).", "startOffset": 83, "endOffset": 189}, {"referenceID": 10, "context": "In the late 2000s and early 2010s, a number of systems were proposed that did both (Liang et al., 2009; Angeli et al., 2010; Kim and Mooney, 2010; Lu and Ng, 2011; Konstas and Lapata, 2013).", "startOffset": 83, "endOffset": 189}, {"referenceID": 19, "context": "In the late 2000s and early 2010s, a number of systems were proposed that did both (Liang et al., 2009; Angeli et al., 2010; Kim and Mooney, 2010; Lu and Ng, 2011; Konstas and Lapata, 2013).", "startOffset": 83, "endOffset": 189}, {"referenceID": 13, "context": "In the late 2000s and early 2010s, a number of systems were proposed that did both (Liang et al., 2009; Angeli et al., 2010; Kim and Mooney, 2010; Lu and Ng, 2011; Konstas and Lapata, 2013).", "startOffset": 83, "endOffset": 189}, {"referenceID": 38, "context": "Within the world of neural text generation, some recent work has focused on conditioning language models on tables (Yang et al., 2016), and generating short biographies from Wikipedia Tables (Lebret et al.", "startOffset": 115, "endOffset": 134}, {"referenceID": 15, "context": ", 2016), and generating short biographies from Wikipedia Tables (Lebret et al., 2016; Chisholm et al., 2017).", "startOffset": 64, "endOffset": 108}, {"referenceID": 15, "context": ", 2016), and generating short biographies from Wikipedia Tables (Lebret et al., 2016; Chisholm et al., 2017). Mei et al. (2016) use a neural encoder-decoder approach on standard record-based generation datasets, obtaining impressive results, and motivating the need for more challenging NLG problems.", "startOffset": 65, "endOffset": 128}], "year": 2017, "abstractText": "Recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records. In this work, we suggest a slightly more difficult data-to-text generation task, and investigate how effective current approaches are on this task. In particular, we introduce a new, large-scale corpus of data records paired with descriptive documents, propose a series of extractive evaluation methods for analyzing performance, and obtain baseline results using current neural generation methods. Experiments show that these models produce fluent text, but fail to convincingly approximate humangenerated documents. Moreover, even templated baselines exceed the performance of these neural models on some metrics, though copyand reconstructionbased extensions lead to noticeable improvements.", "creator": "LaTeX with hyperref package"}}}