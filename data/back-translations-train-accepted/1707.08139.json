{"id": "1707.08139", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jul-2017", "title": "Analogs of Linguistic Structure in Deep Representations", "abstract": "We investigate the compositional structure of message vectors computed by a deep network trained on a communication game. By comparing truth-conditional representations of encoder-produced message vectors to human-produced referring expressions, we are able to identify aligned (vector, utterance) pairs with the same meaning. We then search for structured relationships among these aligned pairs to discover simple vector space transformations corresponding to negation, conjunction, and disjunction. Our results suggest that neural representations are capable of spontaneously developing a \"syntax\" with functional analogues to qualitative properties of natural language.", "histories": [["v1", "Tue, 25 Jul 2017 18:10:48 GMT  (2658kb,D)", "http://arxiv.org/abs/1707.08139v1", "In EMNLP 2017"]], "COMMENTS": "In EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL cs.NE", "authors": ["jacob", "reas", "dan klein"], "accepted": true, "id": "1707.08139"}, "pdf": {"name": "1707.08139.pdf", "metadata": {"source": "CRF", "title": "Analogs of Linguistic Structure in Deep Representations", "authors": ["Jacob Andreas", "Dan Klein"], "emails": ["jda@cs.berkeley.edu", "klein@cs.berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "In the last year, there has been a renewal of interest in the endless learning of communication strategies between pairs of agents represented by deep networks (Wagner et al., 2003). Approaches of this kind make it possible to learn decentralized strategies from scratch (Foerster et al., 2016; Sukhbaatar et al., 2016), with multiple agents coordinating via learned communication protocols. More generally, each encoder decoder model (Sutskever et al., 2014) is considered to be an implementation of an analog communication protocol, with input coding playing the role of a message in an artificial \"language\" shared by the encoder and decoder (Yu et al., 2016). Previous work has found that these protocols, under appropriate conditions, represent easy-to-interpret lexical (Dircks and Stoness, 1999; Lazaridou et al al al al al al al al al al al al al al al, 2016) and sequential structure."}, {"heading": "2 Task", "text": "We focus our evaluation on a communication game based on FitzGerald et al. (2013) (Figure 1, above). In this game, the speaker (1) observes a world with 1-20 objects labeled with attributes, and (2) a specific target group X of objects in the world. The listener observes only W, and the goal of the speaker is to communicate a representation of X that allows the listener to accurately reconstruct it. The GENX dataset collected for this purpose contains 4170 human-generated natural-language reference expressions and corresponding logical forms for 273 instances of this game. Since these human-generated expressions have all been pre-commented, we treat language and logic interchangeably and refer to both with the e symbol. We write e (W) for the expression generated by a human for a specific world W, and JeKW for the result of evaluating the logical form e against W."}, {"heading": "3 Approach", "text": "We are not interested in the raw performance of the RNN model in this task (it achieves near-perfect accuracy), but in examining what types of messages the model calculates to achieve this accuracy - and, in particular, whether these messages contain an approach inspired by formal semantics and a low structure similar to those produced by humans. But how do we assess the semantic equivalence between natural language and vector representations? Here, as in Andreas et al. (2017), we take an approach inspired by formal semantics, and represent the meaning of messages about their truth conditions (Figure 1). For each problem example W in the dataset, we have access to one or more human messages e (W), as well as the RNN coding f (W). The truth-based consideration of meaning suggests that we should judge e and f as equal if they designate the same set of objects in the world (1967, but say their expression is not sufficient)."}, {"heading": "4 Interpreting the meaning of messages", "text": "We begin with the simplest question that we can answer with this tool: How often do the messages generated by the encoder model have the same meaning as messages generated by humans for the same context? Again, our goal is not to evaluate the performance of the RNN model, but rather our ability to understand its behavior. Does it send messages with human semantics? Is it more explicit? Or does it behave in a way that cannot be distinguished by a random classifier? For each scene in the GENX test set, we calculate the model-generated message f and its tabular representation rep (f) and measure the extent to which this is consistent with representations generated by three \"theories\" of model behavior (Figure 2): (1) a random theory that accepts or rejects objects with uniform probability, (2) a literal theory that predicts membership only for objects that accurately match the original target model, and most common form (3) of the theory."}, {"heading": "5 Interpreting the structure of messages", "text": "To this end, we turn to a focused examination of three specific logical constructions used in natural language: one simple operation (negation) and two binary operations (conjunction and disjunction), all of which are used in the training data, with a variety of scopes (e.g. all green objects that are not triangles, all parts that are not in an arc).Since people often find it useful to set the target by exclusion rather than inclusion, we first assume that the RNN language might find it useful to integrate some mechanisms that respond to negation, and that messages can predictably be \"negated.\" To test this hypothesis, we first collect examples of the form (e, e, f, f \") where e\" e \"e\" e \"e\" (e) = rep \"rep\" (f), and rep \"rep\" (e \") = rep\" (f \")."}, {"heading": "6 Conclusions", "text": "Building on earlier tools for identifying neural codes with natural language strands, we have introduced a technique for exploring compositional structures in a space of vector-like representations. Our analysis of an encoder decoder model trained on a reference game identified a number of language-like properties in the model's representation space, including transformations that correspond to negation, disjunction, and conjunction. An important question that this analysis leaves open is what happens when multiple transformations are applied hierarchically, and future work could focus on extending the techniques in this paper to exploring recursive structures. We believe that our previous experiments underscore the usefulness of a denotational perspective from formal semantics in interpreting the behavior of deep models."}], "references": [{"title": "Translating neuralese", "author": ["Jacob Andreas", "Anca Dragan", "Dan Klein."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Andreas et al\\.,? 2017", "shortCiteRegEx": "Andreas et al\\.", "year": 2017}, {"title": "Question answering with subgraph embeddings", "author": ["Antoine Bordes", "Sumit Chopra", "Jason Weston."], "venue": "arXiv preprint arXiv:1406.3676 .", "citeRegEx": "Bordes et al\\.,? 2014", "shortCiteRegEx": "Bordes et al\\.", "year": 2014}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches", "author": ["Kyunghyun Cho", "Bart van Merri\u00ebnboer", "Dzmitry Bahdanau", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1409.1259 .", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Truth and meaning", "author": ["Donald Davidson."], "venue": "Synthese 17(1):304\u2013323.", "citeRegEx": "Davidson.,? 1967", "shortCiteRegEx": "Davidson.", "year": 1967}, {"title": "Effective lexicon change in the absence of population flux", "author": ["Christopher Dircks", "Scott Stoness."], "venue": "Advances in Artificial Life pages 720\u2013724.", "citeRegEx": "Dircks and Stoness.,? 1999", "shortCiteRegEx": "Dircks and Stoness.", "year": 1999}, {"title": "Learning distributions over logical forms for referring expression generation", "author": ["Nicholas FitzGerald", "Yoav Artzi", "Luke Zettlemoyer."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "FitzGerald et al\\.,? 2013", "shortCiteRegEx": "FitzGerald et al\\.", "year": 2013}, {"title": "Learning to communicate with deep multi-agent reinforcement learning", "author": ["Jakob Foerster", "Yannis M Assael", "Nando de Freitas", "Shimon Whiteson."], "venue": "Advances in Neural Information Processing Systems. pages 2137\u20132145.", "citeRegEx": "Foerster et al\\.,? 2016", "shortCiteRegEx": "Foerster et al\\.", "year": 2016}, {"title": "Towards multi-agent communicationbased language learning", "author": ["Angeliki Lazaridou", "Nghia The Pham", "Marco Baroni."], "venue": "arXiv preprint arXiv:1605.07133 .", "citeRegEx": "Lazaridou et al\\.,? 2016", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2016}, {"title": "Linguistic regularities in sparse and explicit word representations", "author": ["Omer Levy", "Yoav Goldberg", "Israel Ramat-Gan."], "venue": "pages 171\u2013180.", "citeRegEx": "Levy et al\\.,? 2014", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Emergence of grounded compositional language in multi-agent populations", "author": ["Igor Mordatch", "Pieter Abbeel."], "venue": "arXiv preprint arXiv:1703.04908 .", "citeRegEx": "Mordatch and Abbeel.,? 2017", "shortCiteRegEx": "Mordatch and Abbeel.", "year": 2017}, {"title": "Learning hierarchical structures with linear relational embedding", "author": ["Alberto Paccanaro", "Jefferey Hinton."], "venue": "Advances in Neural Information Processing Systems. Vancouver, BC, Canada, volume 14, page 857.", "citeRegEx": "Paccanaro and Hinton.,? 2002", "shortCiteRegEx": "Paccanaro and Hinton.", "year": 2002}, {"title": "Does string-based neural mt learn source syntax", "author": ["Xing Shi", "Inkit Padhi", "Kevin Knight"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Shi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shi et al\\.", "year": 2016}, {"title": "Learning multiagent communication with backpropagation", "author": ["Sainbayar Sukhbaatar", "Rob Fergus"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Sukhbaatar and Fergus,? \\Q2016\\E", "shortCiteRegEx": "Sukhbaatar and Fergus", "year": 2016}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc VV Le."], "venue": "Advances in Neural Information Processing Systems. pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Progress in the simulation of emergent communication and language", "author": ["Kyle Wagner", "James A Reggia", "Juan Uriagereka", "Gerald S Wilkinson."], "venue": "Adaptive Behavior 11(1):37\u201369.", "citeRegEx": "Wagner et al\\.,? 2003", "shortCiteRegEx": "Wagner et al\\.", "year": 2003}, {"title": "A joint speaker-listener-reinforcer model for referring expressions", "author": ["Licheng Yu", "Hao Tan", "Mohit Bansal", "Tamara L Berg."], "venue": "arXiv preprint arXiv:1612.09542 .", "citeRegEx": "Yu et al\\.,? 2016", "shortCiteRegEx": "Yu et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 14, "context": "The past year has seen a renewal of interest in endto-end learning of communication strategies between pairs of agents represented with deep networks (Wagner et al., 2003).", "startOffset": 150, "endOffset": 171}, {"referenceID": 6, "context": "Approaches of this kind make it possible to learn decentralized policies from scratch (Foerster et al., 2016; Sukhbaatar et al., 2016), with multiple agents coordinating via learned communication protocol.", "startOffset": 86, "endOffset": 134}, {"referenceID": 13, "context": "More generally, any encoder\u2013decoder model (Sutskever et al., 2014) can be viewed as implementing an analogous communication protocol, with the input encoding playing the role of a message in an artificial \u201clanguage\u201d shared by the encoder and decoder (Yu et al.", "startOffset": 42, "endOffset": 66}, {"referenceID": 15, "context": ", 2014) can be viewed as implementing an analogous communication protocol, with the input encoding playing the role of a message in an artificial \u201clanguage\u201d shared by the encoder and decoder (Yu et al., 2016).", "startOffset": 191, "endOffset": 208}, {"referenceID": 4, "context": "Earlier work has found that under suitable conditions, these protocols acquire simple interpretable lexical (Dircks and Stoness, 1999; Lazaridou et al., 2016) and sequential structure (Mordatch and Abbeel, 2017), even without natural language training data.", "startOffset": 108, "endOffset": 158}, {"referenceID": 7, "context": "Earlier work has found that under suitable conditions, these protocols acquire simple interpretable lexical (Dircks and Stoness, 1999; Lazaridou et al., 2016) and sequential structure (Mordatch and Abbeel, 2017), even without natural language training data.", "startOffset": 108, "endOffset": 158}, {"referenceID": 9, "context": ", 2016) and sequential structure (Mordatch and Abbeel, 2017), even without natural language training data.", "startOffset": 33, "endOffset": 60}, {"referenceID": 11, "context": "RNN models trained for natural language processing tasks have been found to learn representations that encode some of this compositional structure\u2014for example, sentence representations for machine translation encode explicit features for certain syntactic phenomena (Shi et al., 2016) and represent some semantic relationships translationally (Levy et al.", "startOffset": 266, "endOffset": 284}, {"referenceID": 8, "context": ", 2016) and represent some semantic relationships translationally (Levy et al., 2014).", "startOffset": 66, "endOffset": 85}, {"referenceID": 0, "context": "This is similar to the problem of \u201ctranslating\u201d RNN representations recently investigated in Andreas et al. (2017). Here we build on that approach in order to perform a detailed analysis of compositional structure in learned \u201clanguages\u201d.", "startOffset": 93, "endOffset": 115}, {"referenceID": 0, "context": "This is similar to the problem of \u201ctranslating\u201d RNN representations recently investigated in Andreas et al. (2017). Here we build on that approach in order to perform a detailed analysis of compositional structure in learned \u201clanguages\u201d. We investigate a communication game previously studied by FitzGerald et al. (2013), and make two discoveries: in a model trained without any access to language data,", "startOffset": 93, "endOffset": 321}, {"referenceID": 5, "context": "We focus our evaluation on a communication game due to FitzGerald et al. (2013) (Figure 1, top).", "startOffset": 55, "endOffset": 80}, {"referenceID": 2, "context": "The encoder is a single-layer RNN with GRU cells (Cho et al., 2014) that consumes both the input world and target labeling and outputs a 64-dimensional hidden representation.", "startOffset": 49, "endOffset": 67}, {"referenceID": 0, "context": "But how do we judge semantic equivalence between natural language and vector representations? Here, as in Andreas et al. (2017), we adopt an approach inspired by formal semantics, and represent the meaning of messages via their truth conditions (Figure 1).", "startOffset": 106, "endOffset": 128}, {"referenceID": 3, "context": "The truth-conditional account of meaning suggests that we should judge e and f to be equivalent if they designate the same set of of objects in the world (Davidson, 1967).", "startOffset": 154, "endOffset": 170}, {"referenceID": 10, "context": "Previous work has found that linear operators are powerful enough to capture many hierarchical and relational structures (Paccanaro and Hinton, 2002; Bordes et al., 2014).", "startOffset": 121, "endOffset": 170}, {"referenceID": 1, "context": "Previous work has found that linear operators are powerful enough to capture many hierarchical and relational structures (Paccanaro and Hinton, 2002; Bordes et al., 2014).", "startOffset": 121, "endOffset": 170}], "year": 2017, "abstractText": "We investigate the compositional structure of message vectors computed by a deep network trained on a communication game. By comparing truth-conditional representations of encoder-produced message vectors to human-produced referring expressions, we are able to identify aligned (vector, utterance) pairs with the same meaning. We then search for structured relationships among these aligned pairs to discover simple vector space transformations corresponding to negation, conjunction, and disjunction. Our results suggest that neural representations are capable of spontaneously developing a \u201csyntax\u201d with functional analogues to qualitative properties of natural language.1", "creator": "LaTeX with hyperref package"}}}