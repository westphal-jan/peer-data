{"id": "1707.08852", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jul-2017", "title": "Detecting and Explaining Causes From Text For a Time Series Event", "abstract": "Explaining underlying causes or effects about events is a challenging but valuable task. We define a novel problem of generating explanations of a time series event by (1) searching cause and effect relationships of the time series with textual data and (2) constructing a connecting chain between them to generate an explanation. To detect causal features from text, we propose a novel method based on the Granger causality of time series between features extracted from text such as N-grams, topics, sentiments, and their composition. The generation of the sequence of causal entities requires a commonsense causative knowledge base with efficient reasoning. To ensure good interpretability and appropriate lexical usage we combine symbolic and neural representations, using a neural reasoning algorithm trained on commonsense causal tuples to predict the next cause step. Our quantitative and human analysis show empirical evidence that our method successfully extracts meaningful causality relationships between time series with textual features and generates appropriate explanation between them.", "histories": [["v1", "Thu, 27 Jul 2017 13:14:57 GMT  (2929kb,D)", "http://arxiv.org/abs/1707.08852v1", "Accepted at EMNLP 2017"]], "COMMENTS": "Accepted at EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dongyeop kang", "varun gangal", "ang lu", "zheng chen", "eduard h hovy"], "accepted": true, "id": "1707.08852"}, "pdf": {"name": "1707.08852.pdf", "metadata": {"source": "CRF", "title": "Detecting and Explaining Causes From Text For a Time Series Event", "authors": ["Dongyeop Kang", "Varun Gangal", "Ang Lu", "Zheng Chen", "Eduard Hovy"], "emails": ["dongyeok@cs.cmu.edu", "vgangal@cs.cmu.edu", "alu1@cs.cmu.edu", "zhengc1@cs.cmu.edu", "hovy@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "This goes beyond the capabilities of modern AI. However, it is possible to collect large quantities of causally related events and, given sufficiently strong representative variability, construct cause-and-effect chains by selecting and linking individual pairs accordingly. However, our hypothesis is that chains composed of locally coherent pairs can suggest an overall causality. In this paper, we consider causality as (common sense) cause-and-effect expressions that frequently occur in online texts such as news articles or tweets. For example, \"Greenhouse gases cause global warming\" is a phrase that has an \"atomic\" relationship that can be used in a larger chain. By linking such causal facts in a sequence, the result can be considered a causal explanation between the two ends of the sequence (see Table 1 for examples). This paper makes the following contributions: \u2022 we define the problem of triggering a causal explanation of an event generation (we trigger a causal explanation of an event generation)."}, {"heading": "2 CSPIKES: Temporal Causality Detection from Textual Features", "text": "The aim of our model is to find the best set of textual characteristics F = {f1,..., fk} X, which maximizes the sum of causality relative to the characteristics on y, where X is the set of all the characteristics. Note that each characteristic is itself a time series: arg max F C (y, \u03a6 (X, y))) (1), where C (y, x) is a causality value function between y and x and \u03a6 is a linear composition function of the characteristics f. \u03a6 also needs a target time series y due to our graph-based feature selection algorithm described in the next sections. We will first introduce the basic principles of Granger causality in Section 2.1. Section 2.2 describes how to extract good source characteristics F = {f1,..., fk} from text. Section 2.3 describes the selection function C and the function for composition of characteristics."}, {"heading": "2.1 Granger Causality", "text": "The main assumption behind the Granger causality is that a cause must occur before its effect and can be used to predict the effect. Granger showed that with a target time series y (effect) and a source time series x (cause), predicting future target values yt with both past target and past source time series E (yt | y < t, x < t) is significantly stronger than predicting only past target time series E (yt | y < t) (pure auto regression) if x and y are in fact a cause-effect pair. First, we learn the parameters \u03b1 and \u03b2 to maximize the forecast expectation: E (yt | y < t, xt \u2212 l) = m \u00b2 j = 1 \u03b1jyt \u2212 j + n \u00b2 i = 1 \u03b2ixt \u2212 i (2), where i and j represent the magnitude of the delays in the past observation."}, {"heading": "2.2 Feature Extraction from Text", "text": "For example, to predict the future trend of Donald Trump's presidential polls, we need to take into account his past polling data, as well as people's reaction to his promises such as immigration, Syria, and so on. To extract such \"good\" traits from online media, we suggest three different types of traits: Fwords, Ftopic, and Fsenti. Fwords are time series of N-gram words that reflect the popularity of the word over time in online media. For each word, we include the number of elements (e.g. tweets, blogs, and messages) that contain the N-gram word, which is counted to obtain the day-by-day time series. For example, xMichael Jordan = [12, 51,..] is a time series for a bi-gram word Michael Jordan. We filter out stationary words by using simple measures to estimate how dynamically the time series of each word changes over time. Some of the simple measures include maximum Shannon number, rise, rise, and rise in time series."}, {"heading": "2.3 Temporal Causality Detection", "text": "The causality function C uses Granger causality (Granger, 1988) by equipping the two time series with a vector autoregressive model with exogenous variables (Hamilton, 1994): yt = \u03b1yt \u2212 l + \u03b2xt \u2212 l + t, where t is a white Gaussian random vector at the time t and l +. In our problem, the number of source time series x is not uniform, so the prediction in the k multivariant characters X = (f1,... fk) occurs as follows: yt = \u03b1yt \u2212 l + \u03b2 (f1, t \u2212 l +... + fk, t \u2212 l) + t (3), where \u03b1 and \u03b2 are the coefficient matrix of the target and source time series X (f1,... fk)."}, {"heading": "3 CGRAPH Construction", "text": "Formally speaking, source x and target y resulted in events that are causally related in time series, if we could find a sequence of cause-effect pairs (x 7 \u2192 e1), (e1 7 \u2192 e2), then e1 7 \u2192 e2,... 7 \u2192 et could be a good causal explanation between x and y. Sections 3 and 4 describe how to bridge the causal gap between given events (x, y) by (1) constructing a large general cause-effect graph (CGRAPH) from text, (2) linking the given events with their equivalent entities in the causal graph by using the internal paths (x 7 \u2192 e1,... et 7 \u2192 y) as causal explanations. CGRAPH is a knowledge base graph in which edges are directed and causally related between entities. In order to eliminate the less representative variability of Girju, al in 2003, Blanco, Sharp."}, {"heading": "4 Causal Reasoning", "text": "To generate a causal explanation using CGRAPH, we must traverse the graph to find the path between given source and target events. This section describes how to traverse the graph efficiently by adding an external knowledge base to entities, and how to find (or generate) suitable causal paths to suggest an explanation using symbolic and neural thought algorithms."}, {"heading": "4.1 Entity Expansion with Knowledge Base", "text": "A simple choice to traverse a graph is the traditional graph search algorithms such as Breadth-First Search (BFS). However, the graph search procedure is likely to be incomplete (little memory), since a simple string match is not enough to match an effect on all units associated with it, as it is overlooked in cases where a unit is semantically related but has a lexically different name. To address the problem of low memory and generate better explanations, we propose the use of knowledge databases to supplement our text-based causal graph with semantic knowledge from the real world. We use Freebase (Google, 2016) as an external knowledge database for this purpose. Among the 1.9 billion edges in the original freebase dump, we collect their first and second hops for each target event. While our CGRAPH is lexical, freebase units appear as identifiers (we need to combine the Knowledge KB names with Knowledge KB entries)."}, {"heading": "4.2 Symbolic Reasoning", "text": "Simple transverse algorithms such as BFS are not feasible for traversing the CGRAPH due to the large number of nodes and edges. To reduce the search space k in et 7 \u2192 {e1t + 1,... ekt + 1}, we limited our search to the depth of the paths, the word length on behalf of the company and the edge weight. Algorithm 1 Backward Causal Inference. y is target event, d is depth of the SFSS, l is delay size, BFSback is breadth-first search for a depth in the backward direction, and ig l C is the sum of Granger causality above the delay.1: S \u2190 y, d = 0 2: during (S = ekt) or (d > Dmax) 3: {e1 \u2212 d,... ek \u2212 d} \u2190 BFSback (S) 4: d = d + 1, S \u2190 5: for j causal algorithm in {1,..., k}: if C (then d \u2212 d \u2212 time)."}, {"heading": "4.3 Neural Reasoning", "text": "While symbolic inferences are quick and straightforward, the scarcity of edges can make our inferences semantically bad. To address lexical scarcity, we suggest a lexically relaxed reasoning with a neural network. \u2212 Inspired by recent success in alignment tasks such as machine translation (Bahdanau et al., 2014), our model learns the causal alignment between cause and effect for each type of relationship between them. \u2212 Instead of traversing the CGRAPH, our neural rationalist uses CGRAPH as a training resource. \u2212 The encoder, a recursive neural network such as the LSTM (Hochreiter and Schmidhuber, 1997), takes the crucial phrase, another LSTM, takes the effective phrase with its relationship to specific attention."}, {"heading": "5 Experiment", "text": "We collect social media online from tweets, news articles and blogs. Our Twitter data has one million tweets per day from 2008 to 2013, which are crawled using Twitter's Garden Hose API. News and blog records were crawled using Google's News API from 2010 to 2013. For target time series, we collect the stock prices of companies on NASDAQ and NYSE from 2001 to today for 6,200 companies. For presidential elections, we collect survey data from 6 different websites, including USA Today, Reuters, etc. Features. For N-gram word features, we select the spelling words based on their temporal dynamics (see Table 4). If a word is too frequent or the time series is too flat, the word should be filtered too broadly to be an event."}, {"heading": "5.1 Random Causality Analysis", "text": "To verify that our causality assessment function C recognizes causality over time, we perform a random analysis between target time series and randomly generated time series (see Figure 3). For Google's stock time series, we regularly shift the window size of 30 over time and generate five-day random peak time series using a SpikeM model (Matsubara et al., 2012) 4. The color of the random time series rf changes from blue to yellow depending on the degree of causality with the target C (y, rf). For example, blue is the strongest causality in target time series, while yellow is the weakest. We observe that the strong causal (blue) traits are detected immediately before (or after) the rapid rise in Google's stock price in mid-October in (a) (or (b). With the delay size of three days, we observe that the strength of the random time series gradually decreases as they grow beyond the peak event."}, {"heading": "5.2 Forecasting with Textual Features", "text": "We use time series prediction tasks to assess whether our textual characteristics adequately cause the target time series or not. Our feature on the composition of the characteristics is used to extract good causal characteristics for the forecast. We test predictions on the share price of companies (stocks) and forecast the poll value for the presidential election (polls). For share data, we collect the daily closing prices during 2013 for ten IT company5. For survey data, we select ten candidates for politician 6 during the period of the 2012 presidential election. For each of the share and survey data, the future trend of the target is determined only by the past time4Spike characteristics for modeling a time series such as peak strength, length, etc. 5 company symbols used: TSLA, MSFT, GOOGL, YHOO, FB, IBM, ORCL, AMZN, AAPL and HPO6Name of the politicians used: Santorum, Past, Bachbarek, Perry or series of targets."}, {"heading": "5.3 Generating Causality with Neural Reasoner", "text": "The common sense person must predict the next effective phrase (or previous causer pays phrase), so the model should be evaluated in terms of the generational task. We used the BLEU metric (Papineni et al., 2002) to evaluate the predicted phrases on held-up phrases in our CGRAPH. Because our CGRAPH has many edges, there can be many good paths (explanations), which may cause our prediction to be different. To evaluate this diversity in the prediction, we used the rank-based BLEU method on the k-set of predicted phrases by beam search. For example, B @ k BLEU points for generating the k-number of sentences and B @ kA the mean value of them. Table 6 shows some examples of our ray search results when k = 3. Given a causal phrase, the neural common sense person at some point predicts semantically similar phrases (e.g., against the dollar, sometimes against the other phrases)."}, {"heading": "5.4 Generating Explanation by Connecting", "text": "Unfortunately, due to the lack of quantitative measurement measures for the task, we are conducting an experiment with human annotations.Table 8 exemplifies causal chains for the rise (\u2191) and fall (\u2193) of the share price of companies that are continuously produced by two arguments: SYBM is symbolic argumentator and NEUR is neural argumentation.We also perform a human evaluation of the explanation chains produced by the two argumentators and ask people to choose more convincing explanation chains for each trait-target pair. Table 9 shows their relative preferences."}, {"heading": "6 Related Work", "text": "s ability (Acharya, 2014; Anand, 2014; Qiu et al., 2012) to predict future values of a time series using past values of their own and other time series (e.g. gene sequence, stock prices, temperature) is mainly used. (Hlava, c, kova, Schindler et al., 2007) Studies to theoretically investigate causal influences in multivariate time series based on entropy and mutual information estimates. However, none of them attempt to generate explanations of temporal causality (Hlava, c, Schindler et al.). Previous work to detect text causality uses syntactic patterns such as X verb7 \u2212 \u2192 Y, where the verb is causative (Girju, 2003; Riaz and Girju, 2013; Kozareva, 2012; Do et al, 2011, al, with additional characteristics)."}, {"heading": "7 Conclusion", "text": "This paper defines the novel task of identifying and explaining causes from texts for a time series. First, we recognize causal features from online texts. Then, we construct a large cause-and-effect graph using FrameNet semantics. By training our relationship-specific neural network on paths from this graph, our model generates causality with richer lexical variations. We could create a chain of cause-and-effect pairs as an explanation that has some appropriateness. Including aspects such as time, place, and other event properties remains a point for future work. In our subsequent work, we will collect a sequence of causal chains that have been verified by domain experts to obtain more substantiated assessments of generating explanations."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Explaining underlying causes or effects about events is a challenging but valuable task. We define a novel problem of generating explanations of a time series event by (1) searching cause and effect relationships of the time series with textual data and (2) constructing a connecting chain between them to generate an explanation. To detect causal features from text, we propose a novel method based on the Granger causality of time series between features extracted from text such as N-grams, topics, sentiments, and their composition. The generation of the sequence of causal entities requires a commonsense causative knowledge base with efficient reasoning. To ensure good interpretability and appropriate lexical usage we combine symbolic and neural representations, using a neural reasoning algorithm trained on commonsense causal tuples to predict the next cause step. Our quantitative and human analysis show empirical evidence that our method successfully extracts meaningful causality relationships between time series with textual features and generates appropriate explanation between them.", "creator": "LaTeX with hyperref package"}}}