{"id": "1707.09457", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jul-2017", "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints", "abstract": "Language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. In this work, we study data and models associated with multilabel object classification and visual semantic role labeling. We find that (a) datasets for these tasks contain significant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33% more likely to involve females than males in a training set, and a trained model further amplifies the disparity to 68% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 47.5% and 40.5% for multilabel classification and visual semantic role labeling, respectively.", "histories": [["v1", "Sat, 29 Jul 2017 03:38:32 GMT  (597kb,D)", "http://arxiv.org/abs/1707.09457v1", "11 pages, published in EMNLP 2017"]], "COMMENTS": "11 pages, published in EMNLP 2017", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.CV stat.ML", "authors": ["jieyu zhao", "tianlu wang", "mark yatskar", "vicente ordonez", "kai-wei chang"], "accepted": true, "id": "1707.09457"}, "pdf": {"name": "1707.09457.pdf", "metadata": {"source": "CRF", "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints", "authors": ["Jieyu Zhao", "Tianlu Wang", "Mark Yatskar", "Vicente Ordonez", "Kai-Wei Chang"], "emails": ["kc2wc}@virginia.edu", "my89@cs.washington.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is that we are able to assert ourselves, that we are able to adapt to the needs of the people, \"he said in an interview with the\" New York Times. \""}, {"heading": "2 Related Work", "text": "Big data technologies are known to sometimes unintentionally exacerbate discrimination based on implicit distortions in data (Podesta et al., 2014), and such problems have been demonstrated in various learning systems, including online display systems (Sweeney et al., 2013), word embedding models (Bolukbasi et al., 2016; Caliskan et al., 2017), online news (Ross and Carter, 2011), web search (Kay et al., 2015), and credit score (Hardt et al., 2016). Data collection distortions have been discussed in the context of image corpus creation (Misra et al., 2016; van Miltenburg et al.), and text corpus (Gordon and Van Durme, 2013; Van Durme, 2010). In contrast, we show that in the face of a gender-specific data corpus, structured models such as conditional random fields amplify bias activity."}, {"heading": "3 Visualizing and Quantifying Biases", "text": "Modern statistical learning approaches capture correlations between output variables in order to make coherent predictions. (However, for real-world applications, some implicit correlations are not suitable, especially if they are amplified.) In this section, we present a general framework for analyzing inherent bias that is learned and amplified by a predictive model. (Identification of bias) We consider that prediction problems have several interdependent output variables Y1, Y2,... bias that can be represented as structure y = {y1, Y2,... yK, Y. This is a common setting in NLP applications, including tagging, and parsing. For example, in the vSRL task, the output can be presented as a structured table as shown in Figure 1. Modern techniques often model the correlation between the subcomponents in y and make a common prediction about them using a structured prediction model."}, {"heading": "4 Calibration Algorithm", "text": "In this section, we will introduce the problem of collective influence on an instance that can derive the predictions from a structured prediction model. (1) The intuition behind the algorithm is to base the predictions on the distribution of training data. (2) These limitations are applied at the level of the corpus, because the calculation of gender ratios requires the prediction of all test instances. (2) As a result, a common inference is requested across the test instances. (3) The solution of such a problem with the limitations of training data is applied at the level of the corpus, because the calculation of gender ratios requires the prediction of all testinstances. (2) The advantages of this approach are: \u2022 Our algorithms are iterative, and in each iterative intervention the problem is presented with limitations."}, {"heading": "5 Experimental Setup", "text": "In this section, we present details of the two visual recognition tasks that we evaluated for bias: visual semantic role identification (vSRL) and multi-label classification (MLC), focusing on gender, the definition of G = {man, woman}, and focusing on the agent role in vSRL, as well as the occurrence of text associated with images in MLC. Problem statistics are summarized in Table 1."}, {"heading": "5.1 Visual Semantic Role Labeling", "text": "Dataset We evaluate on imSitu (Yatskar et al., 2016), where activity classes are drawn from verbs and roles in FrameNet (Baker et al., 1998) and noun categories from WordNet (Miller et al., 1990). The original dataset consists of approximately 125,000 images with 75,702 verbs for training, 25,200 for development, and 25,200 for testing. However, the dataset includes many non-human oriented activities (e.g. breeding, retrieving, and wobbling), so that we filter out these verbs, resulting in 212 verbs, leaving approximately 60,000 of the original 125,000 images in the datasets. Model We build on the baseline CRF shared with the data, which was effectively shown in comparison to an unstructured prediction task (Yatskar et al., 2016). The model decomposes the probability of a realized situation, y, the combination of activity, v, 2016 and a prediction of a prediction line, an explicit situation, a prediction line, a prediction of a prediction line, et."}, {"heading": "5.2 Multilabel Classification", "text": "Dataset We use MS-COCO (Lin et al., 2014), a general benchmark for object recognition, for multi-level object classification. The dataset contains 80 object types, but does not distinguish between man and woman. We use the five associated captions that are available for each image in this dataset to comment on the gender of people on the screens. If one of the captions mentions the word man or woman, we highlight it and remove all images that mention both genders. Finally, we filter any object category that is not strongly associated with man by removing objects that do not appear with man or woman on the screens at least 100 times, leaving a total of 66 objects.Model For this multi-level setting, we adapt a model similar to the structured CRF for vSRL. We dissect the common probability of output y consisting of all object categories, c and gender of the person, using an image | i as an image."}, {"heading": "5.3 Calibration", "text": "The derivation problems for both models are: argmax y-Yf\u03b8 (y, i) = log p (y | i; \u03b8).We use the algorithm in paragraph (4) to calibrate the predictions using the model \u03b8. Our calibration attempts to enforce gender statistics derived from the training set applicable to each recognition problem. In all experiments, we try to match the gender ratios on the test set within a span of.05 of their value on the training set. While we adjust the results on the test set, we never use the basic truth on the test set and instead assume that it should be distributed similarly to the training set."}, {"heading": "6 Bias Analysis", "text": "In this section, we will use the approaches outlined in Section 3 to quantify bias and bias amplification in the vSRL and MLC tasks."}, {"heading": "6.1 Visual Semantic Role Labeling", "text": "imSitu is gender-specific in Figure 2 (a), along the x-axis, we show the male preference of imSitu verbs. Overall, the data set tends strongly towards male agents, with 64.6% of the verbs tending to favour a male agent with an average preference of 0.707 (approximately 3: 1 male). Almost half of the verbs tend to favour a gender with a preference of at least 0.7.6. Figure 2 (a) contains several activity markers indicating problematic distortions. Thus, along the y-axis, we show the ratio of male agents (% of the total population) tending towards an invisible development tending towards a biased tendency."}, {"heading": "6.2 Multilabel Classification", "text": "MS-COCO is gender biased along the x-axis in Figure 2 (b), similar to imSitu, we analyze the bias of objects in MS-COCO toward men. MS-COCO is even more biased toward men than imSitu, with 86.6% of objects being biased toward men, but with a lower average strength of 0.65. One third of the nouns are extremely biased toward men, and 37.9% of the nouns favor men with a bias of at least 0.7. Some problematic examples include kitchen objects such as knives, forks, or spoons, which are more biased toward women. Recreational objects such as tennis rackets, snowboards, and boats tend to be more biased toward men.6In this gender binary, bias toward women is 1 \u2212 bias toward men training on MS-COCO reinforces bias in Figure 2 (b), along the y-axis, we show the ratio between men (%) unseen in both genders."}, {"heading": "6.3 Discussion", "text": "We confirmed our hypothesis that (a) both the imsitutional and MS-COCO datasets collected on the Internet are strongly gender-specific, and (b) models trained to predict these datasets reinforce existing gender bias when evaluated using developmental data. Furthermore, we showed in both datasets that the degree of distortion is related to the size of the original distortion, with strongly distorted object and verbal categories having a greater distortion. Our results show that caution should be exercised when using such uncalibrated systems, as otherwise they could not only exacerbate, but even exacerbate existing social distortions."}, {"heading": "7 Calibration Results", "text": "We test our methods for reducing bias amplification in two areas: visual semantic role labeling in the imsitu dataset (vSRL) and multi-label image classification in MS-COCO (MLC). In all areas, we derive body constraints from the training set and then batch-perform our calibration method on either the development or test set. Our results are summarized in Table 2 and Figure 3."}, {"heading": "7.1 Visual Semantic Role Labeling", "text": "Our quantitative results are summarized in the first two sections of Table 2. In the development theorem, the number of verbs whose bias exceeds the original bias by more than 5% decreases by 30.5%. Overall, we are able to reduce the bias amplification in vSRL by 52% in the development theorem (amp. bias). We evaluate the underlying detection performance using the standard measure in vSRL: top-1 semantic role accuracy, which checks how often the correct verb was predicted and how the noun value was correctly assigned to a semantic role. Our calibration method results in a negligible reduction in performance (perf.). In Figure 3 (c), we can see that the total distance to the distribution of the training set has significantly decreased by more than 39% after using RBA. Figure 3 (e) shows that RBA is capable of reducing bias over all initial training bias."}, {"heading": "7.2 Multilabel Classification", "text": "Our quantitative results on MS-COCO RBA are summarized in the last two sections of Table 2. Similar to vSRL, we were able to reduce the number of objects whose bias exceeds the original training bias by 5% (Viol.) by 40%. Amplification of bias was reduced by 31.3% in the Amp. bias. The underlying detection system was rated at the standard size: Top1 means average precision, accuracy averaged across object categories. Our calibration method results in a negligible loss of performance. Figure 3 (d) shows that we significantly reduce the gap between training bias and bias in the development set. Finally, Figure 3 (f) shows that we reduce bias amplification for all initial training bias settings. The results of the test set support our development results: We reduce bias amplification by 47.5% (Amplification)."}, {"heading": "7.3 Discussion", "text": "We have shown that RBA can significantly reduce bias amplification. Although we have not been able to remove all amplifications, we have made significant progress without affecting the underlying detection performance. RBA has been able to reduce bias amplification in both issues at all initial levels of the training bias."}, {"heading": "8 Conclusion", "text": "Structured predictive models can use correlations that allow them to make accurate predictions even with very little underlying evidence. Nevertheless, such models have the potential to exploit social bias in their training data. In this paper, we have presented a general framework for visualizing and quantifying biases in such models and proposed calibrating their predictions under two different settings. Taking gender bias as an example, our analysis shows that conditional random fields can amplify social bias from data, while our RBA approach can help to more or less reduce bias. In addition, we have presented only one method for measuring bias and are the first to propose methods for reducing this effect, but remain important opportunities for future work. While RBA can be applied to any structured prediction method, it is unclear whether different prediction methods can more or less amplify prejudices, and in addition, we have presented only one method for measuring bias and analyzing bias."}], "references": [{"title": "Vqa: Visual question answering", "author": ["Stanislaw Antol", "Aishwarya Agrawal", "Jiasen Lu", "Margaret Mitchell", "Dhruv Batra", "C Lawrence Zitnick", "Devi Parikh."], "venue": "Proceedings of the IEEE International Conference on Computer Vision, pages 2425\u20132433.", "citeRegEx": "Antol et al\\.,? 2015", "shortCiteRegEx": "Antol et al\\.", "year": 2015}, {"title": "The Berkeley framenet project", "author": ["Collin F Baker", "Charles J Fillmore", "John B Lowe."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), pages 86\u201390.", "citeRegEx": "Baker et al\\.,? 1998", "shortCiteRegEx": "Baker et al\\.", "year": 1998}, {"title": "Big data\u2019s disparate impact", "author": ["Solon Barocas", "Andrew D Selbst."], "venue": "Available at SSRN 2477899.", "citeRegEx": "Barocas and Selbst.,? 2014", "shortCiteRegEx": "Barocas and Selbst.", "year": 2014}, {"title": "Semantics derived automatically from language corpora contain human-like biases", "author": ["Aylin Caliskan", "Joanna J Bryson", "Arvind Narayanan."], "venue": "Science, 356(6334):183\u2013186.", "citeRegEx": "Caliskan et al\\.,? 2017", "shortCiteRegEx": "Caliskan et al\\.", "year": 2017}, {"title": "Tractable semi-supervised learning of complex structured prediction models", "author": ["Kai-Wei Chang", "S. Sundararajan", "S. Sathiya Keerthi."], "venue": "Proceedings of the European Conference on Machine Learning (ECML), pages 176\u2013191.", "citeRegEx": "Chang et al\\.,? 2013", "shortCiteRegEx": "Chang et al\\.", "year": 2013}, {"title": "Exact decoding of phrase-based translation models through Lagrangian relaxation", "author": ["Yin-Wen Chang", "Michael Collins."], "venue": "EMNLP, pages 26\u201337.", "citeRegEx": "Chang and Collins.,? 2011", "shortCiteRegEx": "Chang and Collins.", "year": 2011}, {"title": "Microsoft coco captions: Data collection and evaluation server", "author": ["Xinlei Chen", "Hao Fang", "Tsung-Yi Lin", "Ramakrishna Vedantam", "Saurabh Gupta", "Piotr Doll\u00e1r", "C Lawrence Zitnick."], "venue": "arXiv preprint arXiv:1504.00325.", "citeRegEx": "Chen et al\\.,? 2015", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Constrained Semisupervised Learning in the Presence of Unanticipated Classes", "author": ["Bhavana Bharat Dalvi."], "venue": "Ph.D. thesis, Google Research.", "citeRegEx": "Dalvi.,? 2015", "shortCiteRegEx": "Dalvi.", "year": 2015}, {"title": "Fairness through awareness", "author": ["Cynthia Dwork", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Richard Zemel."], "venue": "Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, pages 214\u2013226. ACM.", "citeRegEx": "Dwork et al\\.,? 2012", "shortCiteRegEx": "Dwork et al\\.", "year": 2012}, {"title": "Certifying and removing disparate impact", "author": ["Michael Feldman", "Sorelle A Friedler", "John Moeller", "Carlos Scheidegger", "Suresh Venkatasubramanian."], "venue": "Proceedings of International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "Feldman et al\\.,? 2015", "shortCiteRegEx": "Feldman et al\\.", "year": 2015}, {"title": "Reporting bias and knowledge extraction", "author": ["Jonathan Gordon", "Benjamin Van Durme."], "venue": "Automated Knowledge Base Construction (AKBC).", "citeRegEx": "Gordon and Durme.,? 2013", "shortCiteRegEx": "Gordon and Durme.", "year": 2013}, {"title": "Equality of opportunity in supervised learning", "author": ["Moritz Hardt", "Eric Price", "Nati Srebro"], "venue": "In Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Hardt et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hardt et al\\.", "year": 2016}, {"title": "Unequal representation and gender stereotypes in image search results for occupations", "author": ["Matthew Kay", "Cynthia Matuszek", "Sean A Munson."], "venue": "Human Factors in Computing Systems, pages 3819\u2013 3828. ACM.", "citeRegEx": "Kay et al\\.,? 2015", "shortCiteRegEx": "Kay et al\\.", "year": 2015}, {"title": "Combinatorial Optimization: Theory and Application", "author": ["Bernhard Korte", "Jens Vygen."], "venue": "Springer Verlag.", "citeRegEx": "Korte and Vygen.,? 2008", "shortCiteRegEx": "Korte and Vygen.", "year": 2008}, {"title": "Microsoft coco: Common objects in context", "author": ["Tsung-Yi Lin", "Michael Maire", "Serge Belongie", "James Hays", "Pietro Perona", "Deva Ramanan", "Piotr Doll\u00e1r", "C Lawrence Zitnick."], "venue": "European Conference on Computer Vision, pages 740\u2013755. Springer.", "citeRegEx": "Lin et al\\.,? 2014", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Wordnet: An on-line lexical database", "author": ["G. Miller", "R. Beckwith", "C. Fellbaum", "D. Gross", "K.J. Miller."], "venue": "International Journal of Lexicography, 3(4):235\u2013312.", "citeRegEx": "Miller et al\\.,? 1990", "shortCiteRegEx": "Miller et al\\.", "year": 1990}, {"title": "Stereotyping and bias in the flickr30k dataset", "author": ["Emiel van Miltenburg."], "venue": "MMC.", "citeRegEx": "Miltenburg.,? 2016", "shortCiteRegEx": "Miltenburg.", "year": 2016}, {"title": "Seeing through the human reporting bias: Visual classifiers from noisy humancentric labels", "author": ["Ishan Misra", "C Lawrence Zitnick", "Margaret Mitchell", "Ross Girshick."], "venue": "Conference on Computer Vision and Pattern Recognition (CVPR), pages 2930\u20132939.", "citeRegEx": "Misra et al\\.,? 2016", "shortCiteRegEx": "Misra et al\\.", "year": 2016}, {"title": "Anaphora resolution", "author": ["Ruslan Mitkov."], "venue": "Routledge.", "citeRegEx": "Mitkov.,? 2014", "shortCiteRegEx": "Mitkov.", "year": 2014}, {"title": "Dual decomposition inference for graphical models over strings", "author": ["Nanyun Peng", "Ryan Cotterell", "Jason Eisner."], "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 917\u2013927.", "citeRegEx": "Peng et al\\.,? 2015", "shortCiteRegEx": "Peng et al\\.", "year": 2015}, {"title": "Big data: Seizing opportunities and preserving values", "author": ["John Podesta", "Penny Pritzker", "Ernest J. Moniz", "John Holdren", "Jefrey Zients."], "venue": "Executive Office of the President.", "citeRegEx": "Podesta et al\\.,? 2014", "shortCiteRegEx": "Podesta et al\\.", "year": 2014}, {"title": "Women and news: A long and winding road", "author": ["Karen Ross", "Cynthia Carter."], "venue": "Media, Culture & Society, 33(8):1148\u20131165.", "citeRegEx": "Ross and Carter.,? 2011", "shortCiteRegEx": "Ross and Carter.", "year": 2011}, {"title": "A Tutorial on Dual Decomposition and Lagrangian Relaxation for Inference in Natural Language Processing", "author": ["Alexander M Rush", "Michael Collins."], "venue": "Journal of Artificial Intelligence Research, 45:305\u2013 362.", "citeRegEx": "Rush and Collins.,? 2012", "shortCiteRegEx": "Rush and Collins.", "year": 2012}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman."], "venue": "arXiv preprint arXiv:1409.1556.", "citeRegEx": "Simonyan and Zisserman.,? 2014", "shortCiteRegEx": "Simonyan and Zisserman.", "year": 2014}, {"title": "Introduction to dual decomposition for inference", "author": ["David Sontag", "Amir Globerson", "Tommi Jaakkola."], "venue": "Optimization for Machine Learning, 1:219\u2013 254.", "citeRegEx": "Sontag et al\\.,? 2011", "shortCiteRegEx": "Sontag et al\\.", "year": 2011}, {"title": "Discrimination in online ad delivery", "author": ["Latanya Sweeney."], "venue": "Queue, 11(3):10.", "citeRegEx": "Sweeney.,? 2013", "shortCiteRegEx": "Sweeney.", "year": 2013}, {"title": "Extracting implicit knowledge from text", "author": ["Benjamin D Van Durme."], "venue": "Ph.D. thesis, University of Rochester.", "citeRegEx": "Durme.,? 2010", "shortCiteRegEx": "Durme.", "year": 2010}, {"title": "Show and tell: A neural image caption generator", "author": ["Oriol Vinyals", "Alexander Toshev", "Samy Bengio", "Dumitru Erhan."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3156\u20133164.", "citeRegEx": "Vinyals et al\\.,? 2015", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Commonly uncommon: Semantic sparsity in situation recognition", "author": ["Mark Yatskar", "Vicente Ordonez", "Luke Zettlemoyer", "Ali Farhadi."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).", "citeRegEx": "Yatskar et al\\.,? 2017", "shortCiteRegEx": "Yatskar et al\\.", "year": 2017}, {"title": "Situation recognition: Visual semantic role labeling for image understanding", "author": ["Mark Yatskar", "Luke Zettlemoyer", "Ali Farhadi."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5534\u20135542.", "citeRegEx": "Yatskar et al\\.,? 2016", "shortCiteRegEx": "Yatskar et al\\.", "year": 2016}, {"title": "A survey on measuring indirect discrimination in machine learning", "author": ["Indre Zliobaite."], "venue": "arXiv preprint arXiv:1511.00148.", "citeRegEx": "Zliobaite.,? 2015", "shortCiteRegEx": "Zliobaite.", "year": 2015}], "referenceMentions": [{"referenceID": 27, "context": "Visual recognition tasks involving language, such as captioning (Vinyals et al., 2015), visual question answering (Antol et al.", "startOffset": 64, "endOffset": 86}, {"referenceID": 0, "context": ", 2015), visual question answering (Antol et al., 2015), and visual semantic role labeling (Yatskar et al.", "startOffset": 35, "endOffset": 55}, {"referenceID": 29, "context": ", 2015), and visual semantic role labeling (Yatskar et al., 2016), have emerged as avenues for expanding the diversity of information that can be recovered from images.", "startOffset": 43, "endOffset": 65}, {"referenceID": 14, "context": "For MLC, we use MS-COCO (Lin et al., 2014; Chen et al., 2015), a recognition task covering 80 object classes.", "startOffset": 24, "endOffset": 61}, {"referenceID": 6, "context": "For MLC, we use MS-COCO (Lin et al., 2014; Chen et al., 2015), a recognition task covering 80 object classes.", "startOffset": 24, "endOffset": 61}, {"referenceID": 13, "context": "We combine our calibration constraint with the original structured predictor and use Lagrangian relaxation (Korte and Vygen, 2008; Rush and Collins, 2012) to reweigh bias creating factors in the original model.", "startOffset": 107, "endOffset": 154}, {"referenceID": 22, "context": "We combine our calibration constraint with the original structured predictor and use Lagrangian relaxation (Korte and Vygen, 2008; Rush and Collins, 2012) to reweigh bias creating factors in the original model.", "startOffset": 107, "endOffset": 154}, {"referenceID": 20, "context": "It is known that big-data technologies sometimes inadvertently worsen discrimination due to implicit biases in data (Podesta et al., 2014).", "startOffset": 116, "endOffset": 138}, {"referenceID": 25, "context": "Such issues have been demonstrated in various learning systems, including online advertisement systems (Sweeney, 2013), word embedding models (Bolukbasi et al.", "startOffset": 103, "endOffset": 118}, {"referenceID": 3, "context": "Such issues have been demonstrated in various learning systems, including online advertisement systems (Sweeney, 2013), word embedding models (Bolukbasi et al., 2016; Caliskan et al., 2017), online news (Ross and Carter, 2011), web search (Kay et al.", "startOffset": 142, "endOffset": 189}, {"referenceID": 21, "context": ", 2017), online news (Ross and Carter, 2011), web search (Kay et al.", "startOffset": 21, "endOffset": 44}, {"referenceID": 12, "context": ", 2017), online news (Ross and Carter, 2011), web search (Kay et al., 2015), and credit score (Hardt et al.", "startOffset": 57, "endOffset": 75}, {"referenceID": 11, "context": ", 2015), and credit score (Hardt et al., 2016).", "startOffset": 26, "endOffset": 46}, {"referenceID": 17, "context": "Data collection biases have been discussed in the context of creating image corpus (Misra et al., 2016; van Miltenburg, 2016) and text corpus (Gordon and Van Durme, 2013; Van Durme, 2010).", "startOffset": 83, "endOffset": 125}, {"referenceID": 24, "context": ", (Sontag et al., 2011; Rush and Collins, 2012; Chang and Collins, 2011; Peng et al., 2015)) for dealing with instance-level constraints.", "startOffset": 2, "endOffset": 91}, {"referenceID": 22, "context": ", (Sontag et al., 2011; Rush and Collins, 2012; Chang and Collins, 2011; Peng et al., 2015)) for dealing with instance-level constraints.", "startOffset": 2, "endOffset": 91}, {"referenceID": 5, "context": ", (Sontag et al., 2011; Rush and Collins, 2012; Chang and Collins, 2011; Peng et al., 2015)) for dealing with instance-level constraints.", "startOffset": 2, "endOffset": 91}, {"referenceID": 19, "context": ", (Sontag et al., 2011; Rush and Collins, 2012; Chang and Collins, 2011; Peng et al., 2015)) for dealing with instance-level constraints.", "startOffset": 2, "endOffset": 91}, {"referenceID": 4, "context": "Similar techniques (Chang et al., 2013; Dalvi, 2015) have been applied in handling corpus-level constraints for semi-supervised multilabel classification.", "startOffset": 19, "endOffset": 52}, {"referenceID": 7, "context": "Similar techniques (Chang et al., 2013; Dalvi, 2015) have been applied in handling corpus-level constraints for semi-supervised multilabel classification.", "startOffset": 19, "endOffset": 52}, {"referenceID": 22, "context": "(3) using a Lagrangian relaxation technique (Rush and Collins, 2012).", "startOffset": 44, "endOffset": 68}, {"referenceID": 29, "context": "Dataset We evaluate on imSitu (Yatskar et al., 2016) where activity classes are drawn from verbs and roles in FrameNet (Baker et al.", "startOffset": 30, "endOffset": 52}, {"referenceID": 1, "context": ", 2016) where activity classes are drawn from verbs and roles in FrameNet (Baker et al., 1998) and noun categories are drawn from WordNet (Miller et al.", "startOffset": 74, "endOffset": 94}, {"referenceID": 15, "context": ", 1998) and noun categories are drawn from WordNet (Miller et al., 1990).", "startOffset": 51, "endOffset": 72}, {"referenceID": 29, "context": "Model We build on the baseline CRF released with the data, which has been shown effective compared to a non-structured prediction baseline (Yatskar et al., 2016).", "startOffset": 139, "endOffset": 161}, {"referenceID": 23, "context": "where each potential value in the CRF for subpart x, is computed using features fi from the VGG convolutional neural network (Simonyan and Zisserman, 2014) on an input image, as follows:", "startOffset": 125, "endOffset": 155}, {"referenceID": 14, "context": "Dataset We use MS-COCO (Lin et al., 2014), a common object detection benchmark, for multilabel object classification.", "startOffset": 23, "endOffset": 41}, {"referenceID": 18, "context": "Future work also includes applying bias reducing methods in other structured domains, such as pronoun reference resolution (Mitkov, 2014).", "startOffset": 123, "endOffset": 137}], "year": 2017, "abstractText": "Language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. In this work, we study data and models associated with multilabel object classification and visual semantic role labeling. We find that (a) datasets for these tasks contain significant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33% more likely to involve females than males in a training set, and a trained model further amplifies the disparity to 68% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 47.5% and 40.5% for multilabel classification and visual semantic role labeling, respectively.", "creator": "TeX"}}}