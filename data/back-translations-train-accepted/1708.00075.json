{"id": "1708.00075", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jul-2017", "title": "Efficient Regret Minimization in Non-Convex Games", "abstract": "We consider regret minimization in repeated games with non-convex loss functions. Minimizing the standard notion of regret is computationally intractable. Thus, we define a natural notion of regret which permits efficient optimization and generalizes offline guarantees for convergence to an approximate local optimum. We give gradient-based methods that achieve optimal regret, which in turn guarantee convergence to equilibrium in this framework.", "histories": [["v1", "Mon, 31 Jul 2017 21:23:29 GMT  (176kb,D)", "http://arxiv.org/abs/1708.00075v1", "Published as a conference paper at ICML 2017"]], "COMMENTS": "Published as a conference paper at ICML 2017", "reviews": [], "SUBJECTS": "cs.LG cs.GT stat.ML", "authors": ["elad hazan", "karan singh", "cyril zhang"], "accepted": true, "id": "1708.00075"}, "pdf": {"name": "1708.00075.pdf", "metadata": {"source": "CRF", "title": "Efficient Regret Minimization in Non-Convex Games", "authors": ["Elad Hazan", "Karan Singh", "Cyril Zhang"], "emails": ["ehazan@cs.princeton.edu,", "karans@cs.princeton.edu,", "cyril.zhang@princeton.edu,"], "sections": [{"heading": null, "text": "Therefore, we define a natural concept of regret that enables efficient optimisation and generalises offline guarantees of approximation to a near local optimum. We provide gradient-based methods that achieve optimum regret, which in turn guarantees approximation to the equilibrium within this framework."}, {"heading": "1 Introduction", "text": "Repeated games with non-convex utility functions serve to model many natural constellations, such as multiplayer games with risk-averse players and opposing (e.g. GAN) training. However, standard contrition minimizations and equilibrium calculations with general non-convex losses become mathematically difficult. This paper examines mathematically comprehensible notions of contrition minimizations and balances in non-convex repetitive games. Regret minimizations in games typically amount to repetitive games in which the decision maker accumulates an average loss related to the best fixed decision. This is a global term in terms of player decision making. If the loss functions are convex (or, as is often assumed, linear) to the actions of the other players, then this notion of global optimization is computerized."}, {"heading": "1.1 Related work", "text": "The field of online learning is now rich in a variety of algorithms for extremely general scenarios, see e.g. [CBL06]. For limited cost functions over a limited range, it is known that versions of the multiplicative weight method give near optimal regret limits [Cov91, Vov90, AHK12]. ehazan @ cs.princeton.edu, Department of Computer Science, Princeton University \u2020 karans @ cs.princeton.edu, Department of Computer Science, Princeton University \u2021 cyril.zhang @ princeton.edu, Department of Computer Science, Princeton Universityar Xiv: 170 8.00 075v 1 [cs.L G] 31 July 2 017Despite the enormous generality in terms of predictions, the multiplicative weight method in its various forms [Havex] is of limited use."}, {"heading": "2 Setting", "text": "We start with the setting of non-convex online optimization, which is modelled as a game between a learner and an opponent. During each iteration t, the learner is entrusted with predicting xt from K Rn, a convex decision set. At the same time, the learner selects a loss function ft: K \u2192 R; the learner then observes ft (x) (via access to a first-order oracle) and suffers a loss of ft (xt). This procedure is repeated in T rounds. The learner's performance is measured by his regret, which is defined as a function of the loss sequence f1,.., fT and the order of online decisions x1,..., xT of the learner. We discuss our choice of repentance in detail in Section 2.2.2.2.During this work, we assume that the following standard rules of regularity apply: Assumption 2.1. \u2212 We assume that for each loss function: (i) is limited:"}, {"heading": "2.1 Projected gradients and constrained non-convex optimization", "text": "In general, even if objective functions are smooth and limited, local information cannot provide information about the position of a stationary point. (This motivates us to refine our search criteria.) Consider, for example, the function outlined in Figure 1. (In this construction, it is hopeless to find this point efficiently: the number of values or gradients of this function must be exp (n) to the valley.1 We point out here that we measure the square norm of the gradient as it is compatible with convex optimization.Mathematical optimization sometimes measures the norm of the gradient without square squaring."}, {"heading": "2.2 A local regret measure", "text": "In the established framework of online convex optimization, numerous algorithms can efficiently achieve optimal regret, in the sense of convergence in terms of average loss in terms of best fixed decision retrospectively. That is, for each u-K, one can play iterated regret x1..., xT like regret i = 1 [ft (xt) \u2212 ft (u)] = o (1). Unfortunately, even in offline cases, it is too ambitious to approach a global minimizer retrospectively. In the existing literature, it is customary to guarantee state convergence toward an approximate stationary point - that is, there are some iterate xt for which it exists."}, {"heading": "2.3 Why smoothing is necessary", "text": "In this section, we show that for any online algorithm, a contradictory sequence of loss functions can force the local regret to scale with T. This demonstrates the need for a timed measure of performance in our environment and justifies our choice of larger values of window size w in the following sections. Theorem 2.7. We define K = [\u2212 1, 1]. For any online algorithm running on this sequence of functions, there is a distribution D to 0-smooth, 1-limited cost functions f1,.., fT to K, so that for any online algorithm running on this sequence of functions, E D [Rw (T)]. Evidence. We start by dividing the T rounds of the game into b T2w c. Repeated segments, each of length 2w. For the first half of the first segment (t = 1,)."}, {"heading": "3 An efficient non-convex regret minimization algorithm", "text": "Our approach as set out in Algorithm 1 is that we must perform the following steps: < (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K), (K)."}, {"heading": "4 Implications for offline and stochastic non-convex optimization", "text": "In this section, we discuss the way our online framework generalizes the offline and stochastic version of nonconvex optimization - that any algorithm that reaches a small value of Rw (T) efficiently finds a low-gradient point in these settings."}, {"heading": "4.1 Offline non-convex optimization", "text": "When optimizing offline on a fixed, non-convex function f: K \u2192 R, we show that a limit on local regret leads to convergence. Specifically, when using algorithm 1, we find a point x: K with a point x: K, \u03b7f (x), while O (1) calls to the gradient oracle, which corresponds to the best-known result for the convergence of gradient-based methods. Let f: K \u2192 R satisfy assumption 2.1. If the online algorithm A is executed on a sequence of T identical loss functions f (x), then for any 1 \u2264 w < T, Et \u00b2 D [w, T] and T \u2212 f (xt) applies."}, {"heading": "4.2 Stochastic non-convex optimization", "text": "We examine the way in which our online framework performs the stochastic non-convex optimization of a fixed function f: Rn \u2192 R, in which an algorithm has access to a noisy stochastic gradient oracle (1). We note that the reduction applies here only in the unlimited case; it becomes difficult to judge the projected gradient but not the projected gradient. In the setting, the algorithm must operate on the noisy estimates of the gradient as feedback. In particular, for each case that the opponent chooses, the learning algorithm is supplied with a stochastic gradient oracle for the preceding sections. Discussion in the preceding sections can be regarded as a specific case of this setting = 0."}, {"heading": "5 An efficient algorithm with second-order guarantees", "text": "We find that by modifying algorithm 1 to use second order information, our online algorithm can be improved to play approximate critical points of first order, which are also locally almost convex. This means that we have access to each ft by a value, a gradient, and a Hessian oracle. That is, once we have observed, we can get ft (x), and 2ft (x) for each x. Let MinEig (A) be the minimum (eigenvalue, eigenvector) for Matrix A. As the standard for second order algorithms, we must add the following additional smoothness: Assumption 5.1. ft is doubly differentiable and has an L2-Lipschitz-Lipschitz solution."}, {"heading": "6 A solution concept for non-convex games", "text": "Finally, we discuss an application of our regrets to learning in k-player T-round iterated games with smooth, non-convex payoff functions. Suppose each player has a firm decision base Ki-Rn, and a fixed payout function fi: K \u2192 R fulfills the adoption 2.1 as before. This is a natural setting that determines the risk production of the decision. This setting lends itself to the idea of a local balance to replace the stronger condition of the Nash equilibrium: a common strategy in which no player encounters a great inclination towards their utility."}, {"heading": "6.1 Experience replay for GAN training", "text": "The formation of generative adversarial networks (GANs), a popular generative model, can be seen as a symmetrical game with a non-convex payout function. In this section, we apply our smoothed local equilibrium framework to GANs and contextualize it. Indeed, in the ground-breaking setting of [GPAM + 14], there are two players: a generator that wants to mimic samples from a \"true\" distribution D to Rn, and a discriminator that wants to distinguish real samples from fake samples produced by the generator. The generator chooses some G: Rm \u2192 Rn function that maps input randomness z \u00b2 D to fake samples. The discriminator chooses a function D: Rn \u2192 [0, 1], a guess for the probability that a data point is real."}, {"heading": "7 Concluding remarks", "text": "Our definitions lead to efficient online and stochastic non-convex optimization algorithms that converge to local first and second order Optimas. We provide a game theory solution concept that we call local equilibrium, which, unlike existing solutions such as the Nash balance, is efficiently achievable in any non-convex game."}, {"heading": "Acknowledgments", "text": "We thank Naman Agarwal, Brian Bullins, Matt Weinberg and Yi Zhang for helpful discussions."}, {"heading": "A Proof of Theorem 4.4", "text": "Since each Ft is \"smooth,\" it follows that each Ft is \"smooth.\""}, {"heading": "B Proof of Theorem 5.1 (ii)", "text": "Following the technique of theorem 3.1, we have the following problem for 2 \u2264 t \u2264 T: For 2 \u2264 t \u2264 T, Ft \u2212 1 (xt) \u2212 Ft \u2212 1 (xt \u2212 1) \u2264 \u2212 \u03c4t \u00b7 \u03b432\u03b2w3.Evidence: Lemma B.1. For 2 \u2264 t \u2264 T, Ft \u2212 1 (xt) \u2212 Ft \u2212 1 (xt \u2212 1) \u2264 \u2212 \u03c4t \u00b7 \u03b432\u03b2w3.This is obtained by adding up the inequality Lemma 5.3 for all pairs of consecutive iterates of the inner loop within the same epoch and noting that each term \u03a6 (z) is at least 3w3 before the inner loop is finished. Finally, we write (understand F0 (x0): = 0): FT (xT) = T \u2211 t = 1 Ft (xt) \u2212 Ft \u2264 FT \u2212 \u2212 \u2212 1 (xt) \u2212 Twt \u2212 1 (ft \u00b7 \u00b7 1 ft \u00b7 p (xt) = 1 x (xt) (b) = 3)."}, {"heading": "C Proof of Theorem 6.2", "text": "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,"}], "references": [{"title": "Finding approximate local minima for nonconvex optimization in linear time", "author": ["Naman Agarwal", "Zeyuan Allen-Zhu", "Brian Bullins", "Elad Hazan", "Tengyu Ma"], "venue": "arXiv preprint arXiv:1611.01146,", "citeRegEx": "Agarwal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2016}, {"title": "Second order stochastic optimization for machine learning in linear time", "author": ["Naman Agarwal", "Brian Bullins", "Elad Hazan"], "venue": "arXiv preprint arXiv:1602.03943,", "citeRegEx": "Agarwal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2016}, {"title": "The multiplicative weights update method: a meta-algorithm and applications", "author": ["Sanjeev Arora", "Elad Hazan", "Satyen Kale"], "venue": "Theory of Computing,", "citeRegEx": "Arora et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2012}, {"title": "Variance reduction for faster non-convex optimization", "author": ["Zeyuan Allen-Zhu", "Elad Hazan"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "citeRegEx": "Allen.Zhu and Hazan.,? \\Q2016\\E", "shortCiteRegEx": "Allen.Zhu and Hazan.", "year": 2016}, {"title": "From external to internal regret", "author": ["A. Blum", "Y. Mansour"], "venue": "In COLT,", "citeRegEx": "Blum and Mansour.,? \\Q2005\\E", "shortCiteRegEx": "Blum and Mansour.", "year": 2005}, {"title": "Prediction, Learning, and Games", "author": ["Nicol\u00f2 Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Accelerated methods for non-convex optimization", "author": ["Yair Carmon", "John C. Duchi", "Oliver Hinder", "Aaron Sidford"], "venue": "arXiv preprint 1611.00756,", "citeRegEx": "Carmon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Carmon et al\\.", "year": 2016}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Convergence rates of sub-sampled newton methods", "author": ["Murat A Erdogdu", "Andrea Montanari"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Erdogdu and Montanari.,? \\Q2015\\E", "shortCiteRegEx": "Erdogdu and Montanari.", "year": 2015}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Yoav Freund", "Robert E. Schapire"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Freund and Schapire.,? \\Q1997\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1997}, {"title": "Stochastic first-and zeroth-order methods for nonconvex stochastic programming", "author": ["Saeed Ghadimi", "Guanghui Lan"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Ghadimi and Lan.,? \\Q2013\\E", "shortCiteRegEx": "Ghadimi and Lan.", "year": 2013}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Introduction to online convex optimization", "author": ["Elad Hazan"], "venue": "Foundations and Trends in Optimization,", "citeRegEx": "Hazan.,? \\Q2016\\E", "shortCiteRegEx": "Hazan.", "year": 2016}, {"title": "Computational equivalence of fixed points and no regret algorithms, and convergence to equilibria", "author": ["Elad Hazan", "Satyen Kale"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Hazan and Kale.,? \\Q2007\\E", "shortCiteRegEx": "Hazan and Kale.", "year": 2007}, {"title": "A simple adaptive procedure leading to correlated", "author": ["Sergiu Hart", "Andreu Mas-Colell"], "venue": "equilibrium. Econometrica,", "citeRegEx": "Hart and Mas.Colell.,? \\Q2000\\E", "shortCiteRegEx": "Hart and Mas.Colell.", "year": 2000}, {"title": "Unrolled generative adversarial networks", "author": ["Luke Metz", "Ben Poole", "David Pfau", "Jascha Sohl-Dickstein"], "venue": "arXiv preprint arXiv:1611.02163,", "citeRegEx": "Metz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Metz et al\\.", "year": 2016}, {"title": "Introductory lectures on convex optimization, volume 87", "author": ["Yurii Nesterov"], "venue": "Springer Science & Business Media,", "citeRegEx": "Nesterov.,? \\Q2004\\E", "shortCiteRegEx": "Nesterov.", "year": 2004}, {"title": "Cubic regularization of newton method and its global performance", "author": ["Yurii Nesterov", "Boris T Polyak"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov and Polyak.,? \\Q2006\\E", "shortCiteRegEx": "Nesterov and Polyak.", "year": 2006}, {"title": "Connecting generative adversarial networks and actor-critic methods", "author": ["David Pfau", "Oriol Vinyals"], "venue": "arXiv preprint arXiv:1610.01945,", "citeRegEx": "Pfau and Vinyals.,? \\Q2016\\E", "shortCiteRegEx": "Pfau and Vinyals.", "year": 2016}, {"title": "Online learning and online convex optimization", "author": ["Shai Shalev-Shwartz"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Shalev.Shwartz.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz.", "year": 2011}, {"title": "Aggregating strategies", "author": ["Volodimir G. Vovk"], "venue": "In Proceedings of the Third Annual Workshop on Computational Learning Theory, COLT", "citeRegEx": "Vovk.,? \\Q1990\\E", "shortCiteRegEx": "Vovk.", "year": 1990}], "referenceMentions": [], "year": 2017, "abstractText": "We consider regret minimization in repeated games with non-convex loss functions. Minimizing the standard notion of regret is computationally intractable. Thus, we define a natural notion of regret which permits efficient optimization and generalizes offline guarantees for convergence to an approximate local optimum. We give gradient-based methods that achieve optimal regret, which in turn guarantee convergence to equilibrium in this framework.", "creator": "LaTeX with hyperref package"}}}