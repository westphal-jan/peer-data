{"id": "1708.00088", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jul-2017", "title": "Learning Algorithms for Active Learning", "abstract": "We introduce a model that learns active learning algorithms via metalearning. For a distribution of related tasks, our model jointly learns: a data representation, an item selection heuristic, and a method for constructing prediction functions from labeled training sets. Our model uses the item selection heuristic to gather labeled training sets from which to construct prediction functions. Using the Omniglot and MovieLens datasets, we test our model in synthetic and practical settings.", "histories": [["v1", "Mon, 31 Jul 2017 22:26:54 GMT  (472kb,D)", "http://arxiv.org/abs/1708.00088v1", "Accepted for publication at ICML 2017"]], "COMMENTS": "Accepted for publication at ICML 2017", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["philip bachman", "alessandro sordoni", "adam trischler"], "accepted": true, "id": "1708.00088"}, "pdf": {"name": "1708.00088.pdf", "metadata": {"source": "META", "title": "Learning Algorithms for Active Learning", "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "emails": ["<phbachma@microsoft.com>,", "<alsordon@microsoft.com>."], "sections": [{"heading": "1. Introduction", "text": "For many people, it is only a matter of time before such a process occurs. (...) It is a matter of time before such a process occurs. (...) It is a matter of time before such a process occurs. (...) It is a matter of time before such a process occurs. (...) It is a matter of time before such a process occurs. (...) It is a matter of time before such a process occurs. (...) It is a matter of time before such a process occurs. (...) It is a matter of time before such a process occurs. (...) It is a matter of time before such a process occurs. (...) It is a matter of time before such a process occurs. \"(...) It is a matter of time before such a process occurs.\""}, {"heading": "2. Related Work", "text": "In fact, most of them are in a position to put themselves in the world in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live."}, {"heading": "3. Model Description", "text": "We now present our model, which develops algorithms for active learning. Our model earns money by trying to actively learn from tasks taken from a task distribution, and uses monitored feedback to improve its expected performance on new tasks from a similar distribution. In short, our model solves each task by adaptively selecting items for the labeled support set used by a Matching Network (Vinyals et al., 2016) to classify test elements. The complete support set from which our model selects these examples contains both labeled and unlabeled data. A summary of our model can be found in the architecture chart in Figure 1, the optimization goals in Equations 2, 3 and 5, and the pseudo code in Algorithm 1. We present a formal description of our meta learning task in Section 3.1. We describe the details of our model in Section 3.2 and our approach to parameter optimization in Section 3.3."}, {"heading": "3.1. Task Description", "text": "Our model refines its behavior based on the information it has obtained to maximize performance during the test phases that we do not encounter in training. (D) In each episode, our model interacts with a support that we apply in training. (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D. (D). (D). (D). (D. (D). (D). (D). (D. (D). (D). (D). (D). (D). (D. (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D. (D). (D). (D). (D). (D). (D). (D). (D). (D. (D). (D). (D. (D). (D). (D). (D. (D). (D). (D). (D). (D). (D). (D. (D). (D). (D). (D). (D). (D). (D. (D). (D). (D). (D). (D). (D). (D). (D). (D)."}, {"heading": "3.2. Model Architecture Details", "text": "Our model includes several modules: context-free and context-sensitive encoding, control, selection, read, fast prediction and slow prediction. We present an overview of our model in Figure 1 and Figure 1, which describe how the modules of our model perform active learning. The rest of this subsection describes the individual modules in more detail. Algorithm 1 end-to-end active learning loop (for Eq. 3) 1: # Encoding elements in S with context-sensitive encoder 2: # and encoding elements in E with context-free encoder 3: S = {(x, y)}, Su0 = {(x, \u00b7)}, Sk0 = \u2205, E = {(x, y)} 4: for t = 1.. T do 5: # select next instance 6: i \u2190 SELECT (Sut \u2212 1, Skt \u2212 1, ht \u2212 1), SELT ELECT (SELECT), ELECT (SELECT), ELECT (SELECT), ELECT (SELECT), ELECT (SELECT), ELECT (SELECT), ELECT (SELECT SELECT), ELECT (SELECT (SELECT), ELECT SELECT, ELECT (SELECT), ELECT SELECT (SELECT, ELECT SELECT, ELECT SELECT SELECT, SELECT SELECT, SELECT SELECT SELECT, SELECT SELECT, SELECT SELECT, SELECT SELECT, SELECT SELECT SELECT, SELECT SELECT SELECT SELECT, SELECT SELECT SELECT, SELECT SELECT SELECT, SELECT SELECT, SELECT SELECT SELECT SELECT SELECT, SELECT, SELECT SELECT SELECT, SELECT SELECT"}, {"heading": "3.2.1. CONTEXT-[FREE|SENSITIVE] ENCODING", "text": "The context-free encoder associates each element with an embedding, regardless of the context in which the element was presented. For our Omniglot tests, this encoder is a Convnet with two Convolutionary layers mapped by incremental embedding, followed by another Convolutionary layer and a fully connected linear layer that produces the final context-free embedding. For our MovieLens tests, this encoder is a simple look-up table mapping film id for embedding. We refer to the context-free embedding of the element xi-S as x-i and similarly define x-i for x-i-E. The context-sensitive encoder generates an embedding x-i for each element xi-i based on the context-free embedding of the element xi-j-j-S. The context-sensitive encoder for x-i-i is used in the context-free embedding of the element x-i-j-S. The context-sensitive encoder function of the 1997 is not applied to the modified encoding set of elements in our evaluation encoding."}, {"heading": "3.2.2. READING", "text": "This module concatenates the embedding x \u2032 \u2032 i and label yi for the element specified in the selection module and transforms them linearly before they are passed to the controller (Alg. 1, line 8)."}, {"heading": "3.2.3. CONTROLLER", "text": "With each step t, the controller receives an input rt from the read module that encodes the last read element-label pair. Additional inputs can benefit from task-specific information.The control module performs an LSTM update: ht = LSTM (ht \u2212 1, rt).We initialize h0 for each episode (S, E) based on the final state of the backward LSTM in the context-sensitive encoder that processed the support set S. In principle, this allows the controller to condition its behavior on the full unlabeled content of the support set (Alg. 1, line 9)."}, {"heading": "3.2.4. SELECTION", "text": "At each step, the Selection Module places a distribution of all unlabeled elements x i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i"}, {"heading": "3.2.5. FAST PREDICTION", "text": "The fast prediction module makes an attention-based prediction for each blank element xui-Sut using its cosinal similarities to the designated items xkj-Skt, which are sharpened by a non-negative matching score between x u i and the control state ht. Cosinal similarities are taken between the context-sensitive embeddings x-i and x-j of the respective items, which do not change with t and can be pre-calculated prior to the execution of the active learning guideline. Predictions from this module are therefore quick to calculate while the policy is being unrolled (Alg. 1, line 14). Cosinal similarities can be re-used in the selection module for calculating element-item similarity characteristics, thereby further amortizing their costs. For each blank xui we calculate a series of attention weights over the described xj-Sint by applying a cosmic similarity to the cosmic similarity."}, {"heading": "3.2.6. SLOW PREDICTION", "text": "The slow prediction module implements a modified matching network prediction, which takes into account the distinction between marked and unmarked items in St as well as conditions for the active learning control state (Alg. 1, line 17). Given the context-free embedding of x for some held examples x, x, E, the state ht and the required initial values, this module predicts a label by iterating the steps: 1. mk = LSTM (mk \u2212 1, x, x, \u00b2, ht) 2. x, x, \u00b2 + Wmmk 3. a, k = attend (x, Skt) 4. x, k = attRead (a, k, Skt) Here, LSTM is an LSTM update, mk is the appropriate state at step k, x, \u00b2 \u00b2 \u00b2 \u00b2 and Wmmk, the match-sensitive embedding model at step k, Wm is a verifiable matrix, k, k,.."}, {"heading": "3.3. Training the Model", "text": "For a clear review of optimization techniques for general stochastic calculation diagrams, see Schulman et al. (2015). Using the notation in Section 3.1 and following the approach of (Schulman et al., 2015), we can write the gradient of our training goal as follows:............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Omniglot", "text": "This year, it has come to the point where it will only take a few days to get a result."}, {"heading": "4.2. MovieLens", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1. SETUP", "text": "We test our model in the collaborative \"cold start\" filtering scenario using the publicly available MovieLens 20M datasets. The dataset contains approximately 20M ratings of 27K movies from 138K users. Ratings are made on a neat 10-point scale from 0.5 to 5 with intervals of 0.5. We take a close look at the dataset by selecting 4000 movies and 6000 users with the most ratings. After filtering, the dataset contains approximately 1M ratings. We randomly divide the data into 5000 training users and 1000 test users. The training set represents the users already in the system that are used to adjust the model parameters. We use the test users to evaluate our active learning approach. For each user, we randomly select 50 ratings to include them in the support set (movies that the user can query) and 10 movies and ratings for the multimodal movie set. We make sure that we multiply / multiply the Available / 1.org with our standard module."}, {"heading": "4.2.2. MOVIE EMBEDDINGS", "text": "For each film we create an embedding vector by breaking down the complete user / film rating matrix using a latent factor model (Koren, 2010).This process uses only the training set. For each user u and film m we value the true rating ru, m with a linear model r-u, m = x > u-u + bu + bm + \u03b2, where xu, xm are the user or embedding of film and bu, bm, \u03b2 the user, film or global bias respectively. We train the latent factor model by minimizing the mean square error between true rating r and predicted rating r-u. We use the trained xm as input representation for the films during our experiments."}, {"heading": "4.2.3. RESULTS", "text": "In Figure 4, we report on the results of our active model based on different baselines. The regression baseline performs a regulated linear regression on films from the support set whose ratings were observed incrementally in random order. Due to the small amount of training data, we adjust the regression parameter for each additional label by monitoring performance on a separate series of validation episodes. Gaussian process baseline selects the next film relative to the variance of the predictive posterior distribution over its rating, giving an idea of the impact of using MN-one-shot capabilities instead of standardized regression techniques. The Popular Entropy Labels, Min-Max-Cos and Entropy Sampling Baselines train our model end-to-end-end-to-end, but with the help of fixed selection guidelines. Specifically, we train our architecture-to-end selective-to-policy support by selecting the end-to-end-to-end element support module according to the active education policy."}, {"heading": "5. Conclusion", "text": "Our goal was to move away from constructed selection euristics to strategies that are learned directly from data. Our model uses marked instances from different but related tasks to learn a selection strategy for each task, while adapting its representation of the data and predictive function. We evaluated the model using \"active\" variants of one-shot learning tasks for Omniglot and showed that its policy approaches an optimistic performance estimate. In a collaborative filtering task derived from MovieLens, the model outperforms multiple baselines and shows promising applications in more realistic environments."}], "references": [{"title": "Learning to search better than your teacher", "author": ["Chang", "Kai-Wei", "Krishnamurthy", "Akshay", "Agarwal", "III Alekh", "Hal Daum\u00e9", "Langford", "John"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "Chang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2015}, {"title": "Active learning with statistical models", "author": ["Cohn", "David A", "Ghahramani", "Zoubin", "Jordan", "Michael I"], "venue": "Journal of artificial intelligence research,", "citeRegEx": "Cohn et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 1996}, {"title": "A survey of active learning in collaborative filtering recommender systems", "author": ["Elahi", "Mehdi", "Ricci", "Francesco", "Rubens", "Neil"], "venue": "Computer Science Review,", "citeRegEx": "Elahi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Elahi et al\\.", "year": 2016}, {"title": "Query by committee made real", "author": ["Gilad-Bachrach", "Ran", "Navot", "Amir", "Tishby", "Naftali"], "venue": "In Proceedings of the 18th International Conference on Neural Information Processing Systems,", "citeRegEx": "Gilad.Bachrach et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Gilad.Bachrach et al\\.", "year": 2005}, {"title": "On bootstrapping recommender systems", "author": ["Golbandi", "Nadav", "Koren", "Yehuda", "Lempel", "Ronny"], "venue": "In Proceedings of the 19th ACM International Conference on Information and Knowledge Management, CIKM", "citeRegEx": "Golbandi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Golbandi et al\\.", "year": 2010}, {"title": "Adaptive bootstrapping of recommender systems using decision trees", "author": ["Golbandi", "Nadav", "Koren", "Yehuda", "Lempel", "Ronny"], "venue": "In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, WSDM", "citeRegEx": "Golbandi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Golbandi et al\\.", "year": 2011}, {"title": "Deep speech: Scaling up end-to-end speech recognition", "author": ["Hannun", "Awni", "Case", "Carl", "Casper", "Jared", "Catanzaro", "Bryan", "Diamos", "Greg", "Elsen", "Erich", "Prenger", "Ryan", "Satheesh", "Sanjeev", "Sengupta", "Shubho", "Coates", "Adam", "Ng", "Andrew Y"], "venue": "arXiv preprint arXiv:1412.5567v2,", "citeRegEx": "Hannun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hannun et al\\.", "year": 2014}, {"title": "Personalized active learning for collaborative filtering", "author": ["Harpale", "Abhay S", "Yang", "Yiming"], "venue": "In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Harpale et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Harpale et al\\.", "year": 2008}, {"title": "Deep residual learning for image recognition", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "In Conference on Computer Vision and Pattern Recognition", "citeRegEx": "He et al\\.,? \\Q2016\\E", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Batch mode active learning and its application to medical image classification", "author": ["Hoi", "Steven CH", "Jin", "Rong", "Zhu", "Jianke", "Lyu", "Michael R"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "Hoi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hoi et al\\.", "year": 2006}, {"title": "Bayesian active learning for classification and preference learning", "author": ["Houlsby", "Neil", "Husz\u00e1r", "Ferenc", "Ghahramani", "Zoubin", "Lengyel", "M\u00e1t\u00e9"], "venue": "arXiv preprint arXiv:1112.5745,", "citeRegEx": "Houlsby et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Houlsby et al\\.", "year": 2011}, {"title": "Coldstart active learning with robust ordinal matrix factorization", "author": ["Houlsby", "Neil", "Hernandez", "Jose", "Ghahramani", "Zoubin"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "Houlsby et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Houlsby et al\\.", "year": 2014}, {"title": "Efficient thompson sampling for online matrix-factorization recommendation", "author": ["Kawale", "Jaya", "Bui", "Hung H", "Kveton", "Branislav", "Tran-Thanh", "Long", "Chawla", "Sanjay"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "Kawale et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kawale et al\\.", "year": 2015}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik P", "Ba", "Jimmy"], "venue": "[cs.LG],", "citeRegEx": "Kingma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2015}, {"title": "Siamese neural networks for one-shot image recognition", "author": ["Koch", "Gregory"], "venue": "PhD thesis, University of Toronto,", "citeRegEx": "Koch and Gregory.,? \\Q2015\\E", "shortCiteRegEx": "Koch and Gregory.", "year": 2015}, {"title": "Factor in the neighbors: Scalable and accurate collaborative filtering", "author": ["Koren", "Yehuda"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD),", "citeRegEx": "Koren and Yehuda.,? \\Q2010\\E", "shortCiteRegEx": "Koren and Yehuda.", "year": 2010}, {"title": "Imagenet classification with deep neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["Lake", "Brenden M", "Salakhutdinov", "Ruslan", "Tenenbaum", "Joshua B"], "venue": null, "citeRegEx": "Lake et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2015}, {"title": "A sequential algorithm for training text classifiers", "author": ["Lewis", "David D", "Gale", "William A"], "venue": "In Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Lewis et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Lewis et al\\.", "year": 1994}, {"title": "Facing the cold start problem in recommender systems", "author": ["Lika", "Blerina", "Kolomvatsos", "Kostas", "Hadjiefthymiades", "Stathes"], "venue": "Expert Systems with Applications,", "citeRegEx": "Lika et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lika et al\\.", "year": 2014}, {"title": "Rectifier nonlinearities improve neural network acoustic models", "author": ["Maas", "Andrew L", "Hannun", "Awni Y", "Ng", "Andrew Y"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "Maas et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Maas et al\\.", "year": 2013}, {"title": "Getting to know you: learning new user preferences in recommender systems", "author": ["Rashid", "Al Mamunur", "Albert", "Istvan", "Cosley", "Dan", "Lam", "Shyong K", "McNee", "Sean M", "Konstan", "Joseph A", "Riedl", "John"], "venue": "In Proceedings of the 7th international conference on Intelligent user interfaces,", "citeRegEx": "Rashid et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Rashid et al\\.", "year": 2002}, {"title": "Learning preferences of new users in recommender systems: an information theoretic approach", "author": ["Rashid", "Al Mamunur", "Karypis", "George", "Riedl", "John"], "venue": "ACM SIGKDD Explorations Newsletter,", "citeRegEx": "Rashid et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rashid et al\\.", "year": 2008}, {"title": "Reinforcement and imitation learning via interactive no-regret learning", "author": ["Ross", "St\u00e9phane", "Bagnell", "J. Andrew"], "venue": "[cs.LG],", "citeRegEx": "Ross et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2014}, {"title": "Weight normalization: A simple reparameterization to accelerate training of deep neural networks", "author": ["Salimans", "Tim", "Kingma", "Diederik P"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "Salimans et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2016}, {"title": "One-shot learning with memoryaugmented neural networks", "author": ["Santoro", "Adam", "Bartunov", "Sergey", "Botvinick", "Matthew", "Wierstra", "Daan", "Lillicrap", "Timothy"], "venue": "arXiv preprint arXiv:1605.06065,", "citeRegEx": "Santoro et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Santoro et al\\.", "year": 2016}, {"title": "Learning with kernels: support vector machines, regularization, optimization, and beyond", "author": ["Sch\u00f6lkopf", "Bernhard", "Smola", "Alexander J"], "venue": null, "citeRegEx": "Sch\u00f6lkopf et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Sch\u00f6lkopf et al\\.", "year": 2002}, {"title": "Gradient estimation using stochastic computation graphs", "author": ["Schulman", "John", "Heess", "Nicolas", "Weber", "Theophane", "Abbeel", "Pieter"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Schulman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schulman et al\\.", "year": 2015}, {"title": "High-dimensional continuous control using generalized advantage estimation", "author": ["Schulman", "John", "Moritz", "Philipp", "Levine", "Sergey", "Jordan", "Michael I", "Abbeel", "Pieter"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Schulman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Schulman et al\\.", "year": 2016}, {"title": "Bidirectional recurrent neural networks", "author": ["M. Schuster", "K.K. Paliwal"], "venue": "Transactions on Signal Processing,", "citeRegEx": "Schuster and Paliwal,? \\Q1997\\E", "shortCiteRegEx": "Schuster and Paliwal", "year": 1997}, {"title": "Active learning literature survey", "author": ["Settles", "Burr"], "venue": "University of Wisconsin, Madison,", "citeRegEx": "Settles and Burr.,? \\Q2010\\E", "shortCiteRegEx": "Settles and Burr.", "year": 2010}, {"title": "Learning multiple-question decision trees for cold-start recommendation", "author": ["Sun", "Mingxuan", "Li", "Fuxin", "Lee", "Joonseok", "Zhou", "Ke", "Lebanon", "Guy", "Zha", "Hongyuan"], "venue": "In Proceedings of the Sixth ACM International Conference on Web Search and Data Mining, WSDM \u201913,", "citeRegEx": "Sun et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2013}, {"title": "Learning multiple-question decision trees for cold-start recommendation", "author": ["Sun", "Mingxuan", "Li", "Fuxin", "Lee", "Joonseok", "Zhou", "Ke", "Lebanon", "Guy", "Zha", "Hongyuan"], "venue": "In Proceedings of the sixth ACM international conference on Web search and data mining,", "citeRegEx": "Sun et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2013}, {"title": "Deeply aggrevated: Differentiable imitation learning for sequential prediction", "author": ["Sun", "Wen", "Venkatraman", "Arun", "Gordon", "Geoffrey J", "Boots", "Byron", "Bagnell", "J Andrew"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "Sun et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2017}, {"title": "Support vector machine active learning for image retrieval", "author": ["Tong", "Simon", "Chang", "Edward"], "venue": "In Proceedings of the ninth ACM international conference on Multimedia,", "citeRegEx": "Tong et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Tong et al\\.", "year": 2001}, {"title": "Matching networks for one shot learning", "author": ["Vinyals", "Oriol", "Blundell", "Charles", "Lillicrap", "Tim", "Wierstra", "Daan"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Vinyals et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2016}, {"title": "Active one-shot learning", "author": ["Woodward", "Mark", "Finn", "Chelsea"], "venue": "In NIPS Workshop,", "citeRegEx": "Woodward et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Woodward et al\\.", "year": 2016}, {"title": "Query-efficient imitation learning for end-to-end autonomous driving", "author": ["Zhang", "Jiakai", "Cho", "Kyunghyun"], "venue": "American Association for Artificial Intelligence (AAAI),", "citeRegEx": "Zhang et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2017}, {"title": "Using anytime algorithms in intelligent systems", "author": ["Zilberstein", "Shlomo"], "venue": "AI magazine,", "citeRegEx": "Zilberstein and Shlomo.,? \\Q1996\\E", "shortCiteRegEx": "Zilberstein and Shlomo.", "year": 1996}], "referenceMentions": [{"referenceID": 1, "context": "Active learning is motivated by the observation that a model may perform better while training on less labeled data if it can choose the data on which it trains (Cohn et al., 1996).", "startOffset": 161, "endOffset": 180}, {"referenceID": 12, "context": "For example, preference information for a new user in a movie recommender system may be scarce, and recommendations for the new user could be improved by carefully selecting several movies for her to rate (Sun et al., 2013b; Houlsby et al., 2014; Aggarwal, 2016).", "startOffset": 205, "endOffset": 262}, {"referenceID": 10, "context": "Likewise, collecting labels for a medical imaging task may be costly because it requires a specialist (Hoi et al., 2006), and the cost could be reduced by carefully selecting which images to label.", "startOffset": 102, "endOffset": 120}, {"referenceID": 11, "context": "proposed in the active learning literature, such as choosing the instance whose label the model is most uncertain about, or the instance whose label is expected to maximally reduce the model\u2019s uncertainty about other instances (GiladBachrach et al., 2005; Settles, 2010; Houlsby et al., 2011).", "startOffset": 227, "endOffset": 292}, {"referenceID": 4, "context": "In recommendation systems, for example, ratings data for existing users can inform a strategy that efficiently elicits preferences for new users who lack prior rating data, thus bootstrapping the system quickly out of the cold-start setting (Golbandi et al., 2010; 2011; Sun et al., 2013a; Kawale et al., 2015).", "startOffset": 241, "endOffset": 310}, {"referenceID": 13, "context": "In recommendation systems, for example, ratings data for existing users can inform a strategy that efficiently elicits preferences for new users who lack prior rating data, thus bootstrapping the system quickly out of the cold-start setting (Golbandi et al., 2010; 2011; Sun et al., 2013a; Kawale et al., 2015).", "startOffset": 241, "endOffset": 310}, {"referenceID": 17, "context": ", computer vision, speech recognition, and machine translation (Krizhevsky et al., 2012; Hannun et al., 2014; He et al., 2016; Wu et al., 2016).", "startOffset": 63, "endOffset": 143}, {"referenceID": 6, "context": ", computer vision, speech recognition, and machine translation (Krizhevsky et al., 2012; Hannun et al., 2014; He et al., 2016; Wu et al., 2016).", "startOffset": 63, "endOffset": 143}, {"referenceID": 8, "context": ", computer vision, speech recognition, and machine translation (Krizhevsky et al., 2012; Hannun et al., 2014; He et al., 2016; Wu et al., 2016).", "startOffset": 63, "endOffset": 143}, {"referenceID": 36, "context": "We base our model on the Matching Networks (MN) introduced by Vinyals et al. (2016). We extend the MN\u2019s one-shot learning ability to settings where labels are not available a priori.", "startOffset": 62, "endOffset": 84}, {"referenceID": 18, "context": "We evaluate the model on \u201cactive\u201d variants of existing oneshot learning tasks for Omniglot (Lake et al., 2015; Vinyals et al., 2016; Santoro et al., 2016), and show that it can learn efficient label querying strategies.", "startOffset": 91, "endOffset": 154}, {"referenceID": 36, "context": "We evaluate the model on \u201cactive\u201d variants of existing oneshot learning tasks for Omniglot (Lake et al., 2015; Vinyals et al., 2016; Santoro et al., 2016), and show that it can learn efficient label querying strategies.", "startOffset": 91, "endOffset": 154}, {"referenceID": 26, "context": "We evaluate the model on \u201cactive\u201d variants of existing oneshot learning tasks for Omniglot (Lake et al., 2015; Vinyals et al., 2016; Santoro et al., 2016), and show that it can learn efficient label querying strategies.", "startOffset": 91, "endOffset": 154}, {"referenceID": 3, "context": "For instance, Lewis & Gale (1994) and Tong & Chang (2001) developed policies based on the confidence of the classifier, while Gilad-Bachrach et al. (2005) used the disagreement of a committee of classifiers.", "startOffset": 126, "endOffset": 155}, {"referenceID": 3, "context": "For instance, Lewis & Gale (1994) and Tong & Chang (2001) developed policies based on the confidence of the classifier, while Gilad-Bachrach et al. (2005) used the disagreement of a committee of classifiers. Houlsby et al. (2011) presented an approach based on Bayesian information theory, in which examples are selected in order to maximally reduce the entropy of the posterior distribution over classifier parameters.", "startOffset": 126, "endOffset": 230}, {"referenceID": 26, "context": "Building on the memory-augmented neural network (MANN) (Santoro et al., 2016), the authors developed a stream-based active learner.", "startOffset": 55, "endOffset": 77}, {"referenceID": 10, "context": "in medical imaging (Hoi et al., 2006)).", "startOffset": 19, "endOffset": 37}, {"referenceID": 26, "context": "learning the appearance of a class from just a single example of that class (Santoro et al., 2016; Koch, 2015).", "startOffset": 76, "endOffset": 110}, {"referenceID": 34, "context": "Our model builds on the matching-networks (MN) architecture presented by Vinyals et al. (2016), which enables \u201cone-shot\u201d learning, i.", "startOffset": 73, "endOffset": 95}, {"referenceID": 25, "context": "learning the appearance of a class from just a single example of that class (Santoro et al., 2016; Koch, 2015). Vinyals et al. (2016) assume that at least one example per class exists in the labeled support set available to the model.", "startOffset": 77, "endOffset": 134}, {"referenceID": 25, "context": "learning the appearance of a class from just a single example of that class (Santoro et al., 2016; Koch, 2015). Vinyals et al. (2016) assume that at least one example per class exists in the labeled support set available to the model. Confronted with the harder task of composing a labeled support set from a larger pool of unlabeled examples, we show that the active learning policy learnt by our model obtains, in some cases, an equally effective support set. As in the recent one-shot learning work of Santoro et al. (2016) and Vinyals et al.", "startOffset": 77, "endOffset": 527}, {"referenceID": 25, "context": "learning the appearance of a class from just a single example of that class (Santoro et al., 2016; Koch, 2015). Vinyals et al. (2016) assume that at least one example per class exists in the labeled support set available to the model. Confronted with the harder task of composing a labeled support set from a larger pool of unlabeled examples, we show that the active learning policy learnt by our model obtains, in some cases, an equally effective support set. As in the recent one-shot learning work of Santoro et al. (2016) and Vinyals et al. (2016), and the active learning work of Woodward & Finn (2016), we evaluate our model on the Omniglot dataset.", "startOffset": 77, "endOffset": 553}, {"referenceID": 25, "context": "learning the appearance of a class from just a single example of that class (Santoro et al., 2016; Koch, 2015). Vinyals et al. (2016) assume that at least one example per class exists in the labeled support set available to the model. Confronted with the harder task of composing a labeled support set from a larger pool of unlabeled examples, we show that the active learning policy learnt by our model obtains, in some cases, an equally effective support set. As in the recent one-shot learning work of Santoro et al. (2016) and Vinyals et al. (2016), and the active learning work of Woodward & Finn (2016), we evaluate our model on the Omniglot dataset.", "startOffset": 77, "endOffset": 609}, {"referenceID": 18, "context": "This dataset was developed for the foundational one-shot learning work of Lake et al. (2015), which focused on probabilistic program induction.", "startOffset": 74, "endOffset": 93}, {"referenceID": 20, "context": "The cold-start problem is ubiquitous in recommendation systems (Aggarwal, 2016; Lika et al., 2014; Harpale & Yang, 2008; Sun et al., 2013b; Elahi et al., 2016).", "startOffset": 63, "endOffset": 159}, {"referenceID": 2, "context": "The cold-start problem is ubiquitous in recommendation systems (Aggarwal, 2016; Lika et al., 2014; Harpale & Yang, 2008; Sun et al., 2013b; Elahi et al., 2016).", "startOffset": 63, "endOffset": 159}, {"referenceID": 23, "context": "In model-free strategies (Rashid et al., 2008), items are selected according to general empirical statistics such as popularity or informativeness.", "startOffset": 25, "endOffset": 46}, {"referenceID": 12, "context": "Proposals for learning an adaptive selection strategy have been made in the form of Bayesian methods that learn the parameters of a user model (Houlsby et al., 2014; Harpale & Yang, 2008), and in the form of decision-trees learned from existing ratings (Sun et al.", "startOffset": 143, "endOffset": 187}, {"referenceID": 2, "context": ", 2013b; Elahi et al., 2016). Instead of bootstrapping from a cold-start by randomly selecting items for a user to rate, an active learner asks for particular items to help learn a strong user model more quickly. In model-free strategies (Rashid et al., 2008), items are selected according to general empirical statistics such as popularity or informativeness. These approaches are computationally cheap, but lack the benefits of adaptation and personalization. Proposals for learning an adaptive selection strategy have been made in the form of Bayesian methods that learn the parameters of a user model (Houlsby et al., 2014; Harpale & Yang, 2008), and in the form of decision-trees learned from existing ratings (Sun et al., 2013b). An extensive review can be found in Elahi et al. (2016). Intuitively, our model learns a compact, parametric representation of a decision tree end-toend, by directly maximizing task performance.", "startOffset": 9, "endOffset": 792}, {"referenceID": 0, "context": "Related approaches have been explored in previous work on imitation learning and learning to search (Ross & Bagnell, 2014; Chang et al., 2015).", "startOffset": 100, "endOffset": 142}, {"referenceID": 34, "context": "These methods, which focus the cost of sampling from the oracle policy on states visited by the model policy, have recently been adopted by researchers working with deep networks for representation learning (Zhang & Cho, 2017; Sun et al., 2017).", "startOffset": 207, "endOffset": 244}, {"referenceID": 36, "context": "Succinctly, our model solves each task by adaptively selecting items for the labeled support set used by a Matching Network (Vinyals et al., 2016) to classify test items.", "startOffset": 124, "endOffset": 146}, {"referenceID": 36, "context": "Our model uses a modified form of the encoder from Matching Networks (Vinyals et al., 2016).", "startOffset": 69, "endOffset": 91}, {"referenceID": 36, "context": "For details of the attend and attRead functions, refer to Vinyals et al. (2016). As a final prediction, this module returns the label attention result \u1ef9K from the Kth (final) step of iterative matching.", "startOffset": 58, "endOffset": 80}, {"referenceID": 28, "context": "For a clear review of optimization techniques for general stochastic computation graphs, see Schulman et al. (2015).", "startOffset": 93, "endOffset": 116}, {"referenceID": 28, "context": "1 and following the approach of (Schulman et al., 2015), we can write the gradient of our training objective as follows:", "startOffset": 32, "endOffset": 55}, {"referenceID": 29, "context": "Rather than using the gradients in Equation 5 directly, we optimize the model parameters using Generalized Advantage Estimation (Schulman et al., 2016), which provides an actor-critic approach for approximately optimizing the policy gradients in Equation 5.", "startOffset": 128, "endOffset": 151}, {"referenceID": 29, "context": "For more details on how Generalized Advantage Estimation helps reach a favourable bias-variance trade-off in policy gradient estimation, see the source paper (Schulman et al., 2016).", "startOffset": 158, "endOffset": 181}, {"referenceID": 18, "context": "We run our first experiments on the Omniglot dataset (Lake et al., 2015) consisting of 1623 characters from 50 different alphabets, each hand-written by 20 different people.", "startOffset": 53, "endOffset": 72}, {"referenceID": 18, "context": "We run our first experiments on the Omniglot dataset (Lake et al., 2015) consisting of 1623 characters from 50 different alphabets, each hand-written by 20 different people. Following Vinyals et al. (2016), we divide the dataset into 1200 characters for training and keep the rest for testing.", "startOffset": 54, "endOffset": 206}, {"referenceID": 21, "context": "All convolutional layers use the leaky ReLU nonlinearity (Maas et al., 2013).", "startOffset": 57, "endOffset": 76}, {"referenceID": 36, "context": "When designing the architecture, we followed the simple approach of minimizing changes to the original Matching Network from Vinyals et al. (2016). We now provide ablation test results for several parts of our model.", "startOffset": 125, "endOffset": 147}, {"referenceID": 2, "context": "Although it is simplistic, the policy achieves competitive performance for bootstrapping a system from a cold-start setting (Elahi et al., 2016).", "startOffset": 124, "endOffset": 144}, {"referenceID": 21, "context": "The Popular-Entropy policy, adapted from the cold-start work of Rashid et al. (2002), scores each item in the support set a priori, according to the logarithm of its popularity multiplied by the entropy of the item\u2019s ratings measured across users.", "startOffset": 64, "endOffset": 85}, {"referenceID": 2, "context": "The Min-Max-Cos heuristic is designed to not select items similar to those it has already seen, but selecting similar items can be beneficial in personalized settings (Elahi et al., 2016).", "startOffset": 167, "endOffset": 187}], "year": 2017, "abstractText": "We introduce a model that learns active learning algorithms via metalearning. For a distribution of related tasks, our model jointly learns: a data representation, an item selection heuristic, and a method for constructing prediction functions from labeled training sets. Our model uses the item selection heuristic to gather labeled training sets from which to construct prediction functions. Using the Omniglot and MovieLens datasets, we test our model in synthetic and practical settings.", "creator": "LaTeX with hyperref package"}}}