{"id": "1708.00391", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Aug-2017", "title": "A Continuously Growing Dataset of Sentential Paraphrases", "abstract": "A major challenge in paraphrase research is the lack of parallel corpora. In this paper, we present a new method to collect large-scale sentential paraphrases from Twitter by linking tweets through shared URLs. The main advantage of our method is its simplicity, as it gets rid of the classifier or human in the loop needed to select data before annotation and subsequent application of paraphrase identification algorithms in the previous work. We present the largest human-labeled paraphrase corpus to date of 51,524 sentence pairs and the first cross-domain benchmarking for automatic paraphrase identification. In addition, we show that more than 30,000 new sentential paraphrases can be easily and continuously captured every month at ~70% precision, and demonstrate their utility for downstream NLP tasks through phrasal paraphrase extraction. We make our code and data freely available.", "histories": [["v1", "Tue, 1 Aug 2017 15:41:51 GMT  (808kb,D)", "http://arxiv.org/abs/1708.00391v1", "11 pages, accepted to EMNLP 2017"]], "COMMENTS": "11 pages, accepted to EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["wuwei lan", "siyu qiu", "hua he", "wei xu"], "accepted": true, "id": "1708.00391"}, "pdf": {"name": "1708.00391.pdf", "metadata": {"source": "CRF", "title": "A Continuously Growing Dataset of Sentential Paraphrases", "authors": ["Wuwei Lan", "Siyu Qiu", "Hua He", "Wei Xu"], "emails": ["xu.1265}@osu.edu", "siqiu@seas.upenn.edu", "huah@umd.edu"], "sections": [{"heading": "1 Introduction", "text": "It is a fundamental semantic relationship in human language, as formalized in the Meaning-Text linguistic theory, which defines meaning as \"invariant of paraphrases\" (Milic \u0301 evic \u0301, 2006). Researchers have shown that the use of paraphrases in a wide range of applications (Madnani and Dorr, 2010), including answering questions (Fader et al., 2013), semantic paraphrases (Berant and Liang, 2014), information extraction (Sekine, 2006; Zhang et al., 1The code and data can be used by the first and last author of the websites.2015), machine translation (Mehdizadeh Seraj et al., 2015), textual enhancement (Dagan et al., 2006; Bjerva et al., 2014; Izadinia et al., 2015; Li sequi al."}, {"heading": "2 Existing Paraphrase Corpora and Their Limitations", "text": "To date, there are only two publicly available corpora of both sentence paraphrases and non-sentence pairs, which are automatically composed of 72 sentences: MSR Paraphrase Corpus [MSRP] (Dolan et al., 2004; Dolan and Brockett, 2005) This corpus contains 5,801 sentence pairs of news articles, of which 4,076 were used for training purposes and the remaining 1,725 for testing purposes. It was created from clustered news articles by using an SVM classifier (using3Another 12 name variations are omitted from the paper due to their offensive nature. Features such as string similarity and WordNet synonyms are included) to collect probable paraphrases, which are then commented by humans on semantic equivalence. The MSRP corpus exhibits a known deficiency, which is biased toward over-identification (Das and Smith, 2009), because \"the purpose of assessing both the potential effectiveness of the sentence pairs and the actual number of the sentence pairs was relatively small.\""}, {"heading": "3 Constructing the Twitter URL Paraphrase Corpus", "text": "We demonstrate the effectiveness of tracking URLs in Twitter. This method does not rely on automated message clusters as in MSRP or theme recognition as in PIT2015, but continues to collect good candidate pairs in large quantities."}, {"heading": "3.1 Data Source: News Tweets vs. Streaming", "text": "We extracted the embedded URL in each tweet and used the Twitters Search API to retrieve all tweets that contain the same URL. Some tweets use abbreviated URLs that we resolve as full URLs. We tracked 22 English news accounts on Twitter to create the paraphrase in this post (see examples in Table 3). We will expand the corpus to other languages and domains in the future. As shown in Table 5, almost all tweets posted by news agencies have embedded URLs. About 51.17% of the posts contain two URLs, one of which usually refers to a news article and the other to media such as a photo or video. Although nearly half of the tweets in Twitter Streaming Data4 contain at least one URL, most of them are very difficult to read (see examples in Table 4)."}, {"heading": "3.2 Filtering of Retweets", "text": "Retweeting is an important feature in Twitter. There are two types: automatic and manual retweets. An automatic retweet is done by clicking on the retweet button on Twitter and is easy to remove using the Twitter API. A manual retweet occurs when the user creates a new tweet by copying and pasting the original tweet and possibly adding some extras, such as hashtags, usernames or comments. It is crucial to remove these redundant tweets with minor deviations that otherwise represent a significant portion of the data (Table 6). We pre-edited the tweets with a tokenizer5 (Gimpel et al., 2011) and an internal sentence splitter. We then filtered out manual retweets using a set of rules and checked whether one tweet was a partial sequence of the other or whether it differed only in punctuation or the content of the \"Tweet: Title\" or \"tweet: Description.\""}, {"heading": "3.3 Gold Standard Corpus", "text": "We showed the commentators an original sentence and asked them to select sentences with the same meaning from 10 candidate sentences. We recruited 6 commentators for each question and paid $0.03 to each worker. 6 On average, each question took about 53 seconds to process. For each sentence pair, we aggregated the paraphrase and non-paraphrase labels using the majority decision. We constructed the largest gold standard paraphrase corpus to date, with 42,200 tweets to 4,272 different URLs commented on in the training set, and 9,324 tweets to 915 different URLs in the test set. Training data was collected between 10 / 10 / 2016 and 22 / 11 / 2016, and the test data between 1 / 09 / 2017 and 19 / 01 / 2017 were evaluated by the experts."}, {"heading": "3.4 Continuous Harvesting of Sentential Paraphrases", "text": "Because our method is directly applicable to raw tweets, it can continuously extract sentence paraphrases from Twitter. In Section 4, we show that this approach can produce a standard silver paraphrase corpus with an accuracy of about 70%, growing by more than 30,000 new sentence paraphrases per month. Section 5 presents experiments demonstrating the utility of these automatically identified sentence paraphrases.6Low prices help keep spammers out of this easy-to-do task."}, {"heading": "4 Comparison of Paraphrase Corpora", "text": "Although paraphrasing is widely researched, supportive analyses and experiments have often only been carried out on a single dataset. In this section we present a comparative analysis of our newly constructed gold standard corpus with two existing corpus by 1) examining the cases of paraphrase phenomena one at a time and 2) comparing a series of automatic approaches to paraphrase identification."}, {"heading": "4.1 Paraphrase Phenomena", "text": "To show the differences between these three sets of data, we sampled 100 sentence paraphrases from each training set and counted the occurrence of each phenomenon in the following categories: elaboration (pairs of texts may differ in total information content, such as Trump's ex-wife Ivana and Ivana Trump), phrasal (phrase changes, such as takeover and replacement), spelling (spelling variants such as Trump and trump), synonym (as said and narrated), anaphora (a complete noun sentence in a sentence that corresponds to its counterpart, such as @ MarkKirk and Kirk), and reordering (when a word, phrase, or entire sentence is reordered or even logically reordered, as Matthew Fishbein surveyed and interviewed by Matthew Fishbein). We report on the average number of occurrences of each paraphrase type per sentence pair in Table 7. Since sentences tend to be longer in SRP news 2015, most SYM numbers are likely to be shortened."}, {"heading": "4.2 Automatic Paraphrase Identification", "text": "We provide a benchmark for paraphrase identification to better understand different models, as well as the properties of our new corpus compared to existing ones. We focus on the binary classification of paraphrase / non-paraphrase and report on the maximum formula 1 measurement of any point on the precision recall curve."}, {"heading": "4.2.1 Models", "text": "It is a play on words that spreads in the manner in which it has been experienced in the past: in the way in which people are able to understand the world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in the past, in the past, in the way, in which they, in which they live, in which they"}, {"heading": "4.2.2 Model Performance and Dataset Difference", "text": "The results for three benchmark paraphrase corpora are given in Tables 8, 9 and 10. The random baseline reflects that almost 80% of the sentient pairs are paraphrases in the MSPR corpus. This is atypical in the real text data and can lead to false positive predictions. Both the processing distance and the LR models use surface word properties. In particular, the LR model, which uses lemmatization and intersecting features, achieves a very competitive performance on all datasets. Figure 1 shows a closer look at ngram differences between datasets measured by the PINC metric (Chen and Dolan, 2011), which is the opposite of BLEU (Papineni et al., 2002). MSRP consists of paraphrases with more ngram overlaps (lower PINC values), while PIT-2015 contains shorter and lexically different sentences."}, {"heading": "5 Extracting Phrasal Paraphrases", "text": "We can use paraphrase identification models trained on our gold standard corpus to identify unmarked Twitter data and continuously harvest sentence paraphrases in large quantities. We used the open LEX OrMF model and obtained 114,025 sentence paraphrases (system predicted probability \u2265 0.5 and average precision = 69.08%) from raw 1% free Twitter data between 10 / 10 / 2016 and 10 / 1 / 2017. To demonstrate the benefits, we show that we can extract current lexical and phratical paraphrases from this data."}, {"heading": "5.1 Phrase Extraction and Ranking", "text": "One of the most successful ideas for obtaining lexical and phrase-like paraphrases in large quantities is the use of four pairs of phrases \u2022 by word matching, then ranking for better quality. This approach was proposed by Bannard (Bannard and Callison-Burch, 2005) and previously applied to bilingual parallel data to create PPDB (Ganitkevitch et al., 2013; Pavlick et al., 2015). There were few previous papers where monolingual parallel data was used to learn paraphrases as they are not as naturally available as bittexts. We also used the GIZA + word matching tool in Moses's machine translation toolbox (Koehn et al., 2007) and extracted 245,686 phrase matching. Some examples are in Table 2. We also examined two monitored monolingual paraphrases: Jacana angleicher p. (Yao et al., 2013) and Md Sultan."}, {"heading": "5.2 Paraphrase Quality Evaluation", "text": "We compared the quality of the paraphrases extracted by our method with the closest previous work (BUCC-2013) (Xu et al., 2013), in which a similar phrase table was created using Moses from monolingual parallel tweets containing the same entity and calendar date. We sampled 500 pairs of phrases from each phrase table and collected human judgments on a 5-point Likert scale as described in Callison-Burch (Callison-Burch, 2008). Table 11 shows the evaluation results. We focused on the highest-quality paraphrases rated at 5 (\"the whole meaning of the original phrase remains intact and nothing is added\") and their presence among all extracted paraphrases sorted by league tables. We were also interested in how these phrase paraphrases are compared to those in PDB (PDB data)."}, {"heading": "6 Related Work", "text": "Sentential Paraphrase Data Researchers have found several data sources from which to collect sentential paraphrases: multiple news agencies reporting the same event (MSRP) (Dolan et al., 2004; Dolan and Brockett, 2005), multiple translated versions of a foreign novel (Barzilay and Elhadad, 2003; Barzilay and Lee, 2003) or other texts (Cohn et al., 2008), multiple definitions of the same concept (Hashimoto et al., 2011), descriptions of the same video clip from multiple workers (Chen and Dolan, 2011) or rephrased sentences (Burrows et al., 2013; Toutanova et al., 2016). However, all these data collection methods are unable to obtain sentential paraphrases on a large scale (i.e. limited number of news agencies or books with multiple translated versions), and / or missing significant negatives."}, {"heading": "7 Conclusion and Future Work", "text": "In this article, we show how a simple method can effectively and continuously collect large-scale paraphrases of Twitter. We have rigorously evaluated our data using automatic classification models and various measurements. We will share our new data set with the research community, which includes 51,524 manually labeled sentence pairs and a monthly growth of 30,000 automatically labeled sentence paraphrases. Future work could include expanding to many different languages on social media and developing language-independent automatic paraphrase identification models."}, {"heading": "Acknowledgments", "text": "We thank Chris Callison-Burch, Weiwei Guo and Mike White for valuable conversations and the anonymous critics for helpful feedback."}], "references": [{"title": "Semeval-2015 task 2: Semantic textual similarity, english, spanish and pilot on", "author": ["Eneko Agirre", "Carmen Banea", "Claire Cardie", "Daniel Cer", "Mona Diab", "Aitor Gonzalez-Agirre", "Weiwei Guo", "Inigo Lopez-Gazpio", "Montse Maritxalar", "Rada Mihalcea"], "venue": null, "citeRegEx": "Agirre et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Agirre et al\\.", "year": 2015}, {"title": "Leveraging paraphrase labels to extract synonyms from twitter", "author": ["Maria Antoniak", "Eric Bell", "Fei Xia."], "venue": "Proceedings of the 28th Florida Artificial Intelligence Research Society Conference (FLAIRS).", "citeRegEx": "Antoniak et al\\.,? 2015", "shortCiteRegEx": "Antoniak et al\\.", "year": 2015}, {"title": "Inter-coder agreement for computational linguistics", "author": ["Ron Artstein", "Massimo Poesio."], "venue": "Computational Linguistics 34(4):555\u2013596.", "citeRegEx": "Artstein and Poesio.,? 2008", "shortCiteRegEx": "Artstein and Poesio.", "year": 2008}, {"title": "Everyone\u2019s an influencer: quantifying influence on twitter", "author": ["Eytan Bakshy", "Jake M Hofman", "Winter A Mason", "Duncan J Watts."], "venue": "Proceedings of the fourth ACM international conference on Web search and data mining (WSDM).", "citeRegEx": "Bakshy et al\\.,? 2011", "shortCiteRegEx": "Bakshy et al\\.", "year": 2011}, {"title": "Paraphrasing with bilingual parallel corpora", "author": ["Colin Bannard", "Chris Callison-Burch."], "venue": "Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL).", "citeRegEx": "Bannard and Callison.Burch.,? 2005", "shortCiteRegEx": "Bannard and Callison.Burch.", "year": 2005}, {"title": "Sentence alignment for monolingual comparable corpora", "author": ["Regina Barzilay", "Noemie Elhadad."], "venue": "Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Barzilay and Elhadad.,? 2003", "shortCiteRegEx": "Barzilay and Elhadad.", "year": 2003}, {"title": "Learning to paraphrase: an unsupervised approach using multiple-sequence alignment", "author": ["Regina Barzilay", "Lillian Lee."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on", "citeRegEx": "Barzilay and Lee.,? 2003", "shortCiteRegEx": "Barzilay and Lee.", "year": 2003}, {"title": "Semantic parsing via paraphrasing", "author": ["Jonathan Berant", "Percy Liang."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Berant and Liang.,? 2014", "shortCiteRegEx": "Berant and Liang.", "year": 2014}, {"title": "What is a paraphrase? Computational Linguistics 39(3)", "author": ["Rahul Bhagat", "Eduard Hovy"], "venue": null, "citeRegEx": "Bhagat and Hovy.,? \\Q2013\\E", "shortCiteRegEx": "Bhagat and Hovy.", "year": 2013}, {"title": "The meaning factory: Formal semantics for recognizing textual entailment and determining semantic similarity", "author": ["Johannes Bjerva", "Johan Bos", "Rob van der Goot", "Malvina Nissim."], "venue": "SemEval 2014 page 642.", "citeRegEx": "Bjerva et al\\.,? 2014", "shortCiteRegEx": "Bjerva et al\\.", "year": 2014}, {"title": "Large-scale information extraction from textual definitions through deep syntactic and semantic analysis", "author": ["Claudio Delli Bovi", "Luca Telesca", "Roberto Navigli."], "venue": "Transactions of the Association for Computational Linguistics (TACL) pages 529\u2013543.", "citeRegEx": "Bovi et al\\.,? 2015", "shortCiteRegEx": "Bovi et al\\.", "year": 2015}, {"title": "Paraphrase acquisition via crowdsourcing and machine learning", "author": ["Steven Burrows", "Martin Potthast", "Benno Stein."], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST) 4(3):43.", "citeRegEx": "Burrows et al\\.,? 2013", "shortCiteRegEx": "Burrows et al\\.", "year": 2013}, {"title": "Syntactic constraints on paraphrases extracted from parallel corpora", "author": ["Chris Callison-Burch."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Callison.Burch.,? 2008", "shortCiteRegEx": "Callison.Burch.", "year": 2008}, {"title": "Collecting highly parallel data for paraphrase evaluation", "author": ["David L. Chen", "William B. Dolan."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Chen and Dolan.,? 2011", "shortCiteRegEx": "Chen and Dolan.", "year": 2011}, {"title": "Constructing corpora for the development and evaluation of paraphrase systems", "author": ["Trevor Cohn", "Chris Callison-Burch", "Mirella Lapata."], "venue": "Computational Linguistics 34(4):597\u2013614.", "citeRegEx": "Cohn et al\\.,? 2008", "shortCiteRegEx": "Cohn et al\\.", "year": 2008}, {"title": "The PASCAL recognising textual entailment challenge", "author": ["Ido Dagan", "Oren Glickman", "Bernardo Magnini."], "venue": "Proceedings of the First international conference on Machine Learning Challenges: Evaluating Predictive Uncertainty Visual", "citeRegEx": "Dagan et al\\.,? 2006", "shortCiteRegEx": "Dagan et al\\.", "year": 2006}, {"title": "Paraphrase identification as probabilistic quasi-synchronous recognition", "author": ["Dipanjan Das", "Noah A Smith."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Lan-", "citeRegEx": "Das and Smith.,? 2009", "shortCiteRegEx": "Das and Smith.", "year": 2009}, {"title": "Automatically constructing a corpus of sentential paraphrases", "author": ["William B Dolan", "Chris Brockett."], "venue": "Proceedings of the Third International Workshop on Paraphrasing (IWP).", "citeRegEx": "Dolan and Brockett.,? 2005", "shortCiteRegEx": "Dolan and Brockett.", "year": 2005}, {"title": "Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources", "author": ["William B. Dolan", "Chris Quirk", "Chris Brockett."], "venue": "Proceedings of the 20th International Conference on Computational Linguistics (COL-", "citeRegEx": "Dolan et al\\.,? 2004", "shortCiteRegEx": "Dolan et al\\.", "year": 2004}, {"title": "Paraphrase-driven learning for open question answering", "author": ["Anthony Fader", "Luke S Zettlemoyer", "Oren Etzioni."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Fader et al\\.,? 2013", "shortCiteRegEx": "Fader et al\\.", "year": 2013}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Manaal Faruqui", "Jesse Dodge", "Sujay K Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A Smith."], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Faruqui et al\\.,? 2015", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "PPDB: The paraphrase database", "author": ["Juri Ganitkevitch", "Benjamin Van Durme", "Chris Callison-Burch."], "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language", "citeRegEx": "Ganitkevitch et al\\.,? 2013", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2013}, {"title": "Part-of-speech tagging for twitter: Annotation, features, and experiments", "author": ["Kevin Gimpel", "Nathan Schneider", "Brendan O\u2019Connor", "Dipanjan Das", "Daniel Mills", "Jacob Eisenstein", "Michael Heilman", "Dani Yogatama", "Jeffrey Flanigan", "Noah A Smith"], "venue": null, "citeRegEx": "Gimpel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gimpel et al\\.", "year": 2011}, {"title": "POLY: Mining relational paraphrases from multilingual sentences", "author": ["Adam Grycner", "Saarland Informatics Campus", "Gerhard Weikum."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Grycner et al\\.,? 2016", "shortCiteRegEx": "Grycner et al\\.", "year": 2016}, {"title": "Modeling sentences in the latent space", "author": ["Weiwei Guo", "Mona Diab."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Guo and Diab.,? 2012", "shortCiteRegEx": "Guo and Diab.", "year": 2012}, {"title": "Fast tweet retrieval with compact binary codes", "author": ["Weiwei Guo", "Wei Liu", "Mona Diab."], "venue": "Proceedings of the 30th International Conference on Computational Linguistics (COLING).", "citeRegEx": "Guo et al\\.,? 2014", "shortCiteRegEx": "Guo et al\\.", "year": 2014}, {"title": "Extracting paraphrases from definition sentences on the web", "author": ["Chikara Hashimoto", "Kentaro Torisawa", "Stijn De Saeger", "Jun\u2019ichi Kazama", "Sadao Kurohashi"], "venue": "In Proceedings of the 49th Annual Meeting of the Association", "citeRegEx": "Hashimoto et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2011}, {"title": "Pairwise word interaction modeling with deep neural networks for semantic similarity measurement", "author": ["Hua He", "Jimmy Lin."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-", "citeRegEx": "He and Lin.,? 2016", "shortCiteRegEx": "He and Lin.", "year": 2016}, {"title": "KenLM: Faster and smaller language model queries", "author": ["Kenneth Heafield."], "venue": "Proceedings of the Sixth Workshop on Statistical Machine Translation (WMT).", "citeRegEx": "Heafield.,? 2011", "shortCiteRegEx": "Heafield.", "year": 2011}, {"title": "Segment-phrase table for semantic segmentation, visual entailment and paraphrasing", "author": ["Hamid Izadinia", "Fereshteh Sadeghi", "Santosh K Divvala", "Hannaneh Hajishirzi", "Yejin Choi", "Ali Farhadi."], "venue": "Proceedings of the IEEE International Confer-", "citeRegEx": "Izadinia et al\\.,? 2015", "shortCiteRegEx": "Izadinia et al\\.", "year": 2015}, {"title": "The distribution of the flora in the alpine zone", "author": ["P. Jaccard."], "venue": "New Phytologist 11(2):37\u201350.", "citeRegEx": "Jaccard.,? 1912", "shortCiteRegEx": "Jaccard.", "year": 1912}, {"title": "Discriminative improvements to distributional sentence similarity", "author": ["Yangfeng Ji", "Jacob Eisenstein."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Ji and Eisenstein.,? 2013", "shortCiteRegEx": "Ji and Eisenstein.", "year": 2013}, {"title": "Moses: Open source toolkit for statistical machine translation", "author": ["Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens"], "venue": null, "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "Exploiting sentence similarities for better alignments", "author": ["Tao Li", "Vivek Srikumar."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Li and Srikumar.,? 2016", "shortCiteRegEx": "Li and Srikumar.", "year": 2016}, {"title": "DIRT \u2013 Discovery of inference rules from text", "author": ["Dekang Lin", "Patrick Pantel."], "venue": "Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD).", "citeRegEx": "Lin and Pantel.,? 2001", "shortCiteRegEx": "Lin and Pantel.", "year": 2001}, {"title": "Generating phrasal and sentential paraphrases: A survey of datadriven methods", "author": ["Nitin Madnani", "Bonnie J. Dorr."], "venue": "Computational Linguistics 36(3).", "citeRegEx": "Madnani and Dorr.,? 2010", "shortCiteRegEx": "Madnani and Dorr.", "year": 2010}, {"title": "Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual", "author": ["Marco Marelli", "Luisa Bentivogli", "Marco Baroni", "Raffaella Bernardi", "Stefano Menini", "Roberto Zamparelli"], "venue": null, "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Improving statistical machine translation with a multilingual paraphrase database", "author": ["Ramtin Mehdizadeh Seraj", "Maryam Siahbani", "Anoop Sarkar."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Seraj et al\\.,? 2015", "shortCiteRegEx": "Seraj et al\\.", "year": 2015}, {"title": "A short guide to the meaning-text linguistic theory", "author": ["Jasmina Mili\u0107evi\u0107."], "venue": "Journal of Koralex 8:187\u2013233.", "citeRegEx": "Mili\u0107evi\u0107.,? 2006", "shortCiteRegEx": "Mili\u0107evi\u0107.", "year": 2006}, {"title": "PATTY: a taxonomy of relational patterns with semantic types", "author": ["Ndapandula Nakashole", "Gerhard Weikum", "Fabian Suchanek."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Nakashole et al\\.,? 2012", "shortCiteRegEx": "Nakashole et al\\.", "year": 2012}, {"title": "BLEU: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu."], "venue": "Proceedings of 40th Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "PPDB 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification", "author": ["Ellie Pavlick", "Pushpendre Rastogi", "Juri Ganitkevich"], "venue": "In Proceedings of the 53rd Annual", "citeRegEx": "Pavlick et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pavlick et al\\.", "year": 2015}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "On-demand information extraction", "author": ["Satoshi Sekine."], "venue": "Proceedings of the 22nd International Conference on Computational Linguistics (COLING).", "citeRegEx": "Sekine.,? 2006", "shortCiteRegEx": "Sekine.", "year": 2006}, {"title": "Back to basics for monolingual alignment: Exploiting word similarity and contextual evidence", "author": ["Md Arafat Sultan", "Steven Bethard", "Tamara Sumner."], "venue": "Transactions of the Association for Computational Linguistics (TACL) 2:219\u2013230.", "citeRegEx": "Sultan et al\\.,? 2014", "shortCiteRegEx": "Sultan et al\\.", "year": 2014}, {"title": "A dataset and evaluation metrics for abstractive compression of sentences and short paragraphs", "author": ["Kristina Toutanova", "Chris Brockett", "Ke M. Tran", "Saleema Amershi."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language", "citeRegEx": "Toutanova et al\\.,? 2016", "shortCiteRegEx": "Toutanova et al\\.", "year": 2016}, {"title": "A semiautomatic method for efficient detection of stories on social media", "author": ["Soroush Vosoughi", "Deb Roy."], "venue": "Tenth International AAAI Conference on Web and Social Media (ICWSM).", "citeRegEx": "Vosoughi and Roy.,? 2016", "shortCiteRegEx": "Vosoughi and Roy.", "year": 2016}, {"title": "Paraphrasing 4 microblog normalization", "author": ["Ling Wang", "Chris Dyer", "Alan W. Black", "Isabel Trancoso."], "venue": "Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP).", "citeRegEx": "Wang et al\\.,? 2013", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "From paraphrase database to compositional paraphrase model and back", "author": ["J. Wieting", "M. Bansal", "K. Gimpel", "K. Livescu", "D. Roth."], "venue": "Transactions of the Association for Computational Linguistics (TACL) 3:345\u2013358.", "citeRegEx": "Wieting et al\\.,? 2015", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "SemEval-2015 Task 1: Paraphrase and semantic similarity in Twitter (PIT)", "author": ["Wei Xu", "Chris Callison-Burch", "William B. Dolan."], "venue": "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval).", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Extracting lexically divergent paraphrases from Twitter", "author": ["Wei Xu", "Alan Ritter", "Chris Callison-Burch", "William B. Dolan", "Yangfeng Ji."], "venue": "Transactions of the Association for Computational Linguistics (TACL) 2:435\u2013448.", "citeRegEx": "Xu et al\\.,? 2014", "shortCiteRegEx": "Xu et al\\.", "year": 2014}, {"title": "Gathering and generating paraphrases from twitter with application to normalization", "author": ["Wei Xu", "Alan Ritter", "Ralph Grishman."], "venue": "Proceedings of the Sixth Workshop on Building and Using Comparable Corpora (BUCC).", "citeRegEx": "Xu et al\\.,? 2013", "shortCiteRegEx": "Xu et al\\.", "year": 2013}, {"title": "A lightweight and high performance monolingual word aligner", "author": ["Xuchen Yao", "Benjamin Van Durme", "Chris CallisonBurch", "Peter Clark."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Yao et al\\.,? 2013", "shortCiteRegEx": "Yao et al\\.", "year": 2013}, {"title": "Linguistic redundancy in Twitter", "author": ["Fabio Massimo Zanzotto", "Marco Pennacchiotti", "Kostas Tsioutsiouliklis."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Zanzotto et al\\.,? 2011", "shortCiteRegEx": "Zanzotto et al\\.", "year": 2011}, {"title": "Exploiting parallel news streams for unsupervised event extraction", "author": ["Congle Zhang", "Stephen Soderland", "Daniel S Weld."], "venue": "Transactions of the Association for Computational Linguistics (TACL) 3:117\u2013 129.", "citeRegEx": "Zhang et al\\.,? 2015", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "A paraphrase is a restatement of meaning using different expressions (Bhagat and Hovy, 2013).", "startOffset": 69, "endOffset": 92}, {"referenceID": 38, "context": "It is a fundamental semantic relation in human language, as formalized in the Meaning-Text linguistic theory which defines meaning as \u2018invariant of paraphrases\u2019 (Mili\u0107evi\u0107, 2006).", "startOffset": 161, "endOffset": 178}, {"referenceID": 35, "context": "Researchers have shown benefits of using paraphrases in a wide range of applications (Madnani and Dorr, 2010), including question answering (Fader et al.", "startOffset": 85, "endOffset": 109}, {"referenceID": 19, "context": "Researchers have shown benefits of using paraphrases in a wide range of applications (Madnani and Dorr, 2010), including question answering (Fader et al., 2013), semantic parsing (Berant and Liang, 2014), information extraction (Sekine, 2006; Zhang et al.", "startOffset": 140, "endOffset": 160}, {"referenceID": 7, "context": ", 2013), semantic parsing (Berant and Liang, 2014), information extraction (Sekine, 2006; Zhang et al.", "startOffset": 26, "endOffset": 50}, {"referenceID": 15, "context": ", 2015), textual entailment (Dagan et al., 2006; Bjerva et al., 2014; Marelli et al., 2014; Izadinia et al., 2015), vector semantics (Faruqui et al.", "startOffset": 28, "endOffset": 114}, {"referenceID": 9, "context": ", 2015), textual entailment (Dagan et al., 2006; Bjerva et al., 2014; Marelli et al., 2014; Izadinia et al., 2015), vector semantics (Faruqui et al.", "startOffset": 28, "endOffset": 114}, {"referenceID": 36, "context": ", 2015), textual entailment (Dagan et al., 2006; Bjerva et al., 2014; Marelli et al., 2014; Izadinia et al., 2015), vector semantics (Faruqui et al.", "startOffset": 28, "endOffset": 114}, {"referenceID": 29, "context": ", 2015), textual entailment (Dagan et al., 2006; Bjerva et al., 2014; Marelli et al., 2014; Izadinia et al., 2015), vector semantics (Faruqui et al.", "startOffset": 28, "endOffset": 114}, {"referenceID": 0, "context": ", 2015), and semantic textual similarity (Agirre et al., 2015; Li and Srikumar, 2016).", "startOffset": 41, "endOffset": 85}, {"referenceID": 33, "context": ", 2015), and semantic textual similarity (Agirre et al., 2015; Li and Srikumar, 2016).", "startOffset": 41, "endOffset": 85}, {"referenceID": 46, "context": "Studying paraphrases in Twitter can also help track unfolding events (Vosoughi and Roy, 2016) or the spread of information (Bakshy et al.", "startOffset": 69, "endOffset": 93}, {"referenceID": 17, "context": "derived from clustered news articles (Dolan and Brockett, 2005) and the PIT-2015 corpus from Twitter trending topics (Xu et al.", "startOffset": 37, "endOffset": 63}, {"referenceID": 18, "context": "MSR Paraphrase Corpus [MSRP] (Dolan et al., 2004; Dolan and Brockett, 2005) This corpus contains 5,801 pairs of sentences from news articles, with 4,076 for training and the remaining 1,725 for testing.", "startOffset": 29, "endOffset": 75}, {"referenceID": 17, "context": "MSR Paraphrase Corpus [MSRP] (Dolan et al., 2004; Dolan and Brockett, 2005) This corpus contains 5,801 pairs of sentences from news articles, with 4,076 for training and the remaining 1,725 for testing.", "startOffset": 29, "endOffset": 75}, {"referenceID": 16, "context": "The MSRP corpus has a known deficiency skewed toward over-identification (Das and Smith, 2009), because the \u201cpurpose was not to evaluate the po-", "startOffset": 73, "endOffset": 94}, {"referenceID": 17, "context": "tential effectiveness of the classifier itself, but to identify a reasonably large set of both positive and plausible \u2018near-miss\u2019 negative examples\u201d (Dolan and Brockett, 2005).", "startOffset": 149, "endOffset": 175}, {"referenceID": 22, "context": "We preprocessed the tweets using a tokenizer5 (Gimpel et al., 2011) and an in-house sen-", "startOffset": 46, "endOffset": 67}, {"referenceID": 13, "context": "ric, to measure ngram-based dissimilarity (Chen and Dolan, 2011), and Jaccard metric to measure token-based string similarity (Jaccard, 1912).", "startOffset": 42, "endOffset": 64}, {"referenceID": 30, "context": "ric, to measure ngram-based dissimilarity (Chen and Dolan, 2011), and Jaccard metric to measure token-based string similarity (Jaccard, 1912).", "startOffset": 126, "endOffset": 141}, {"referenceID": 2, "context": "Quality Control We evaluated the annotation quality of each worker using Cohen\u2019s kappa agreement (Artstein and Poesio, 2008) against the majority vote of other workers.", "startOffset": 97, "endOffset": 124}, {"referenceID": 42, "context": "GloVe (Pennington et al., 2014) This is a word representation model trained on aggregated global word-word co-occurrence statistics from a corpus.", "startOffset": 6, "endOffset": 31}, {"referenceID": 16, "context": "LR The logistic regression (LR) model incorporates 18 features based on 1-3 gram overlaps between two sentences (s1 and s2) (Das and Smith, 2009).", "startOffset": 124, "endOffset": 145}, {"referenceID": 24, "context": "WMF/OrMF Weighted Matrix Factorization (WMF) (Guo and Diab, 2012) is an unsupervised latent space model.", "startOffset": 45, "endOffset": 65}, {"referenceID": 25, "context": "Orthogonal Matrix Factorization (OrMF) (Guo et al., 2014) is the extension of WMF, with an additional objective to obtain nearly orthogonal dimensions in matrix factorization to discount redundant information.", "startOffset": 39, "endOffset": 57}, {"referenceID": 50, "context": "LEX-WMF/LEX-OrMF This is an opensourced adaptation (Xu et al., 2014) of LEXDISCRIM (Ji and Eisenstein, 2013) that have shown comparable performance.", "startOffset": 51, "endOffset": 68}, {"referenceID": 31, "context": ", 2014) of LEXDISCRIM (Ji and Eisenstein, 2013) that have shown comparable performance.", "startOffset": 22, "endOffset": 47}, {"referenceID": 50, "context": "MultiP MultiP (Xu et al., 2014) is a multiinstance learning model suited for short messages on Twitter.", "startOffset": 14, "endOffset": 31}, {"referenceID": 50, "context": "This model achieved the best performance in the PIT2015 (Xu et al., 2014) dataset.", "startOffset": 56, "endOffset": 73}, {"referenceID": 13, "context": "Figure 1 shows a closer look at ngram differences across datasets measured by the PINC metric (Chen and Dolan, 2011), which", "startOffset": 94, "endOffset": 116}, {"referenceID": 40, "context": "is the opposite of BLEU (Papineni et al., 2002).", "startOffset": 24, "endOffset": 47}, {"referenceID": 4, "context": "This approach was proposed by Bannard (Bannard and Callison-Burch, 2005) and previously applied to bilingual parallel data to create PPDB (Ganitkevitch et al.", "startOffset": 38, "endOffset": 72}, {"referenceID": 21, "context": "This approach was proposed by Bannard (Bannard and Callison-Burch, 2005) and previously applied to bilingual parallel data to create PPDB (Ganitkevitch et al., 2013; Pavlick et al., 2015).", "startOffset": 138, "endOffset": 187}, {"referenceID": 41, "context": "This approach was proposed by Bannard (Bannard and Callison-Burch, 2005) and previously applied to bilingual parallel data to create PPDB (Ganitkevitch et al., 2013; Pavlick et al., 2015).", "startOffset": 138, "endOffset": 187}, {"referenceID": 32, "context": "We used the GIZA++ word aligner in the Moses machine translation toolkit (Koehn et al., 2007) and extracted 245,686 phrasal paraphrases.", "startOffset": 73, "endOffset": 93}, {"referenceID": 52, "context": "cana aligner (Yao et al., 2013) and Md Sultan\u2019s aligner (Sultan et al.", "startOffset": 13, "endOffset": 31}, {"referenceID": 44, "context": ", 2013) and Md Sultan\u2019s aligner (Sultan et al., 2014).", "startOffset": 32, "endOffset": 53}, {"referenceID": 28, "context": "p if w\u22122w\u22121pw1w2 is a likely sequence according to a language model (Heafield, 2011) trained on Twitter data.", "startOffset": 68, "endOffset": 84}, {"referenceID": 42, "context": "\u2022 Glove Score We used Glove (Pennington et al., 2014) pretrained 100-dimensional Twitter word vectors and cosine similarity.", "startOffset": 28, "endOffset": 53}, {"referenceID": 51, "context": "We compared the quality of paraphrases extracted by our method with the closest previous work (BUCC-2013) (Xu et al., 2013), in which a similar phrase table was created using Moses from monolingual parallel tweets that contain the same named entity and calendar date.", "startOffset": 106, "endOffset": 123}, {"referenceID": 12, "context": "sampled 500 phrase pairs from each phrase table and collected human judgements on a 5point Likert scale, as described in Callison-Burch (Callison-Burch, 2008).", "startOffset": 136, "endOffset": 158}, {"referenceID": 18, "context": "Sentential Paraphrase Data Researchers have found several data sources from which to collect sentential paraphrases: multiple news agencies reporting the same event (MSRP) (Dolan et al., 2004; Dolan and Brockett, 2005), multiple transPPDB URL GIZA++ Jacana Sultan Sample Size 50% 50% 16.", "startOffset": 172, "endOffset": 218}, {"referenceID": 17, "context": "Sentential Paraphrase Data Researchers have found several data sources from which to collect sentential paraphrases: multiple news agencies reporting the same event (MSRP) (Dolan et al., 2004; Dolan and Brockett, 2005), multiple transPPDB URL GIZA++ Jacana Sultan Sample Size 50% 50% 16.", "startOffset": 172, "endOffset": 218}, {"referenceID": 21, "context": "outputs) and the PPDB (Ganitkevitch et al., 2013).", "startOffset": 22, "endOffset": 49}, {"referenceID": 5, "context": "lated versions of a foreign novel (Barzilay and Elhadad, 2003; Barzilay and Lee, 2003) or other texts (Cohn et al.", "startOffset": 34, "endOffset": 86}, {"referenceID": 6, "context": "lated versions of a foreign novel (Barzilay and Elhadad, 2003; Barzilay and Lee, 2003) or other texts (Cohn et al.", "startOffset": 34, "endOffset": 86}, {"referenceID": 14, "context": "lated versions of a foreign novel (Barzilay and Elhadad, 2003; Barzilay and Lee, 2003) or other texts (Cohn et al., 2008), multiple definitions of the same concept (Hashimoto et al.", "startOffset": 102, "endOffset": 121}, {"referenceID": 26, "context": ", 2008), multiple definitions of the same concept (Hashimoto et al., 2011), descriptions of the same video clip from multiple", "startOffset": 50, "endOffset": 74}, {"referenceID": 13, "context": "workers (Chen and Dolan, 2011) or rephrased sentences (Burrows et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 11, "context": "workers (Chen and Dolan, 2011) or rephrased sentences (Burrows et al., 2013; Toutanova et al., 2016).", "startOffset": 54, "endOffset": 100}, {"referenceID": 45, "context": "workers (Chen and Dolan, 2011) or rephrased sentences (Burrows et al., 2013; Toutanova et al., 2016).", "startOffset": 54, "endOffset": 100}, {"referenceID": 34, "context": "Non-sentential Paraphrase Data There are other phrasal and syntactic paraphrase data, such as DIRT (Lin and Pantel, 2001), POLY (Grycner", "startOffset": 99, "endOffset": 121}, {"referenceID": 39, "context": ", 2016), PATTY (Nakashole et al., 2012), DEFIE (Bovi et al.", "startOffset": 15, "endOffset": 39}, {"referenceID": 10, "context": ", 2012), DEFIE (Bovi et al., 2015), and PPDB (Ganitkevitch et al.", "startOffset": 15, "endOffset": 34}, {"referenceID": 21, "context": ", 2015), and PPDB (Ganitkevitch et al., 2013; Pavlick et al., 2015).", "startOffset": 18, "endOffset": 67}, {"referenceID": 41, "context": ", 2015), and PPDB (Ganitkevitch et al., 2013; Pavlick et al., 2015).", "startOffset": 18, "endOffset": 67}, {"referenceID": 51, "context": "pervised approaches (Xu et al., 2013; Wang et al., 2013) or small datasets (Zanzotto et al.", "startOffset": 20, "endOffset": 56}, {"referenceID": 47, "context": "pervised approaches (Xu et al., 2013; Wang et al., 2013) or small datasets (Zanzotto et al.", "startOffset": 20, "endOffset": 56}, {"referenceID": 53, "context": ", 2013) or small datasets (Zanzotto et al., 2011; Antoniak et al., 2015).", "startOffset": 26, "endOffset": 72}, {"referenceID": 1, "context": ", 2013) or small datasets (Zanzotto et al., 2011; Antoniak et al., 2015).", "startOffset": 26, "endOffset": 72}], "year": 2017, "abstractText": "A major challenge in paraphrase research is the lack of parallel corpora. In this paper, we present a new method to collect large-scale sentential paraphrases from Twitter by linking tweets through shared URLs. The main advantage of our method is its simplicity, as it gets rid of the classifier or human in the loop needed to select data before annotation and subsequent application of paraphrase identification algorithms in the previous work. We present the largest human-labeled paraphrase corpus to date of 51,524 sentence pairs and the first cross-domain benchmarking for automatic paraphrase identification. In addition, we show that more than 30,000 new sentential paraphrases can be easily and continuously captured every month at \u223c70% precision, and demonstrate their utility for downstream NLP tasks through phrasal paraphrase extraction. We make our code and data freely available.1", "creator": "TeX"}}}