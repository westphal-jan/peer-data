{"id": "1708.00524", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Aug-2017", "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm", "abstract": "NLP tasks are often limited by scarcity of manually annotated data. In social media sentiment analysis and related tasks, researchers have therefore used binarized emoticons and specific hashtags as forms of distant supervision. Our paper shows that by extending the distant supervision to a more diverse set of noisy labels, the models can learn richer representations. Through emoji prediction on a dataset of 1246 million tweets containing one of 64 common emojis we obtain state-of-the-art performance on 8 benchmark datasets within sentiment, emotion and sarcasm detection using a single pretrained model. Our analyses confirm that the diversity of our emotional labels yield a performance improvement over previous distant supervision approaches.", "histories": [["v1", "Tue, 1 Aug 2017 21:28:42 GMT  (1811kb,D)", "http://arxiv.org/abs/1708.00524v1", "Accepted at EMNLP 2017. Please include EMNLP in any citations. Minor changes from the submitted camera-ready version. 9 pages + references and supplementary material"], ["v2", "Sat, 7 Oct 2017 19:21:48 GMT  (1811kb,D)", "http://arxiv.org/abs/1708.00524v2", "Accepted at EMNLP 2017. Please include EMNLP in any citations. Minor changes from the EMNLP camera-ready version. 9 pages + references and supplementary material"]], "COMMENTS": "Accepted at EMNLP 2017. Please include EMNLP in any citations. Minor changes from the submitted camera-ready version. 9 pages + references and supplementary material", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["bjarke felbo", "alan mislove", "anders s\u00f8gaard", "iyad rahwan", "sune lehmann"], "accepted": true, "id": "1708.00524"}, "pdf": {"name": "1708.00524.pdf", "metadata": {"source": "CRF", "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm", "authors": ["Bjarke Felbo", "Alan Mislove", "Anders S\u00f8gaard", "Iyad Rahwan", "Sune Lehmann"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "2 Related work", "text": "The use of emotional expressions as loud captions in text to counteract the lack of captions is not a new idea (Read, 2005; Go et al., 2009). Originally, binary emoticons were used as loud captions, but later hashtags and emojis were also used. However, to our knowledge, previous research has always manually determined which emotional category each emotional expression belongs to. Prior to the work, theories of emotions such as Ekman's six basic emotions and Plutchik's eight basic emotions were used (Mohammad, 2012; Suttles and Ide, 2013).Such manual categorization requires an understanding of the emotional content of each expression, which is difficult and time-consuming for complex combinations of emotional content. In addition, any manual selection and categorization is prone to misinterpretation and can omit important details regarding usage. In contrast, our approach does not require prior knowledge of the corpus and can capture the diverse use of 64 types of emojis."}, {"heading": "3 Method", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Pretraining", "text": "In many cases, emojis serve as a proxy for the emotional content of a text. Therefore, using the classification task to predict which emojis were originally part of a text can improve performance in the target task (see section 5.3 for an analysis of why our pretraining helps). Social media contains large amounts of short texts with emojis that can be used as loud captions for pretraining datasets. Here, we use data from Twitter from January 1, 2013 to June 1, 2017, but all datasets with emoji events could be used. Only English tweets without URLs are used for the pretraining datasets. Our hypothesis is that the content derived from the URL is likely to be important in understanding the emotional content of the text in the tweet. Therefore, we expect emojis associated with these tweets to be noisier labels than for tweets without URLs, and the tweets to be shortened with URLs."}, {"heading": "3.2 Model", "text": "With the millions of emoji events available, we can train highly expressive classifiers with limited risk of overfitting. We use a variant of the Long Short-Term Memory (LSTM) model, which has been successful in many NLP tasks (Hochreiter and Schmidhuber, 1997; Sutskever et al., 2014). Our DeepMoji model uses an embedding layer of 256 dimensions to project each word into a vector space. A hyperbolic tangent activation function is used to limit each embedding dimension within [\u2212 1, 1]. To capture the details available at github.com / bfelbo / deepmojitext, we use two bidirectional LSTM layers, each with 1024 hidden units in each direction."}, {"heading": "3.3 Transfer learning", "text": "Our pre-built model can be tailored to the target task in multiple ways, with some approaches \"freezing\" by disabling parameter updates to prevent overload. A common approach is to use the network as a feature extractor (Donahue et al., 2014), where all layers in the model are frozen when fine-tuning to the target task except the last layer (hereinafter referred to as the \"last\" approach). Alternatively, another common approach is to use the pre-built model as an initialization (Erhan et al., 2010), where the full model is thawed (hereinafter referred to as the \"full\"). We propose a new easy transfer learning approach that thaws and refines a single layer sequentially, which increases the accuracy of the target task at the expense of additional computing power."}, {"heading": "233.7 82.2 79.5 78.1 60.8 54.7 54.6 51.7 50.5 44.0 39.5 39.1 34.8 34.4 32.1 28.1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "24.8 23.4 21.6 21.0 20.5 20.3 19.9 19.6 18.9 17.5 17.0 16.9 16.1 15.3 15.2 15.0", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "14.9 14.3 14.2 14.2 12.9 12.4 12.0 12.0 11.7 11.7 11.3 11.2 11.1 11.0 11.0 10.8", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10.2 9.6 9.5 9.3 9.2 8.9 8.7 8.6 8.1 6.3 6.0 5.7 5.6 5.5 5.4 5.1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Emoji prediction", "text": "We use a raw dataset of 56.6 billion tweets, which is then filtered to 1.2 billion relevant tweets (see paragraph 3.1 for details). In the pretraining dataset, a copy of a single tweet is stored once for each individual tweet, resulting in a dataset of 1.6 billion tweets. Table 2 shows the distribution of tweets across different emoji types. A validation set and a test set of 640K tweets (10K for each emoji type) are used to evaluate performance in the pretraining task, and the remaining tweets are used for training, which is done by upsampling. The performance of the DeepMoji model is evaluated on the pretraining task with the results shown in Table 3. Both the top 1 and top 5 accuracy are used for evaluation, as the emoji labels with multiple emojis are potentially correct for each set."}, {"heading": "4.2 Benchmarking", "text": "In fact, the fact is that most of the people who have opted for the EU over the last ten years have opted for a different EU than for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another EU, for another world, for another world, for another world, for another world, for another world, for another world, for another EU, for another EU, for another EU, for another EU, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another us, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for another world, for one world in, for one world, for one world, for one world in, for one world, for one world, for one world, for one world in, for one world, for one world, for one world, for one world, for one world, for one world, for one world in, for one world, for one world, for one world, for one world, for one world in, for one world, for one world, for one world, for one world, for one world, for one world, for all, for one world, for one world, for one world, for one world, for"}, {"heading": "5 Model Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Importance of emoji diversity", "text": "One of the main differences between this work and previous work that used remote supervision is the variety of emotional emoticons used (see \u00a7 2). Thus, both Deriu et al. (2016) and Tang et al. (2014) used only positive and negative emoticons as vocal labels. Other examples of previous work have used slightly more nuanced sets of loud labels (see \u00a7 2), but to our knowledge our group of loud labels is the most diverse so far. To analyze the effect of using a diverse emoji set, we create a subset of our pretraining data that contains tweets with one of 8 emojis that resemble positive / negative emoticons similar to those of Tang et al. (2014) and Hu et al. (2013) emoticons and the corresponding emojis that contain tweets that contain one of 8 emojis that resemble positive / negative emojis models that are similar to Mois models."}, {"heading": "5.2 Model architecture", "text": "Our DeepMoji model architecture according to \u00a7 3.2 uses an attention mechanism and skipconnections to simplify the transfer of the learned representation to new areas and tasks. Here, we compare the DeepMoji model architecture with that of a standard 2-layer LSTM, both compared to the \"last\" transfer learning approach. We use the same regulation and training parameters. As shown in Table 6, the DeepMoji model architecture is better across all benchmark data sets than a standard 2-layer LSTM. Both architectures have proven equally effective in the pre-training task, suggesting that the DeepMoji model architecture is better for transfer learning, but not necessarily better for a single supervised classification task with abundant data. A reasonable guess is that the improved transfer learning performance is due to two factors: a) the attention mechanism with skipconnections provides easy access to learned low-level information, which makes it easy for each task to use a new time-step for each one."}, {"heading": "5.3 Analyzing the effect of pretraining", "text": "In this section, we will experimentally break down the benefits of pretraining into 2 effects: word coverage and phrase coverage. These two effects help regulate the model by preventing overuse (see the additional details for a visualization of the effect of this regulation).There are numerous ways to express a particular feeling, emotion, or sarcastic commentary. Consequently, the test sentence may contain specific language usage that is not present in the training set. Pretraining helps the target task models to provide low support by previously observing similar use in the pretraining datasets. We will first examine this effect by measuring the improvement in word coverage in the test set, while defining the use of word coverage as a percentage of words in the test datasets."}, {"heading": "5.4 Comparing with human-level agreement", "text": "To understand how well our DeepMoji classifier performs in comparison to humans, we created a new set of random tweets that were commented on on on a sentiment basis. Each tweet was commented on by at least 10 English-speaking Amazon Mechanical Turkers (MTurks) living in the US. Tweets were rated on a scale of 1 to 9 with the \"Do not know\" option, and guidelines for evaluating the tweets were provided to human evaluators. Tweets were selected to include only English text, no mentions, and no URLs that allow them to be rated without additional contextual information. Tweets where more than half of the evaluators chose \"Do not know\" were removed (98 tweets). For each tweet, we randomly select an MTurk rating to achieve the \"human rating,\" and the average across the remaining nine MTurk ratings is averaged to form the basic truth. \"Thus, the overall tweet is chosen as a\" Sensible \"rating."}, {"heading": "6 Conclusion", "text": "We have shown how the millions of texts on social media can be used with emojis for training models to enable them to learn how to display emotional content in texts. By comparing them to an identical model that is pre-trained on a subset of emojis, we find that the diversity of our emoji set is important for the performance of our methodology. We are publishing our pre-trained DeepMoji model in the hope that other researchers will use it well for various emotion-related NLP assignment4."}, {"heading": "Acknowledgments", "text": "The authors would like to thank Janys Analytics for generously allowing us to use their dataset of human-rated tweets and associated code for analysis, Max Lever, who helped design the online demo, and Han Thi Nguyen, who helped to program the software provided alongside the pre-trained model."}, {"heading": "A Supplemental Material", "text": "A.1 Preprocessing Emotion DatasetsIn the Olympic Games dataset by Sintsova et al. each tweet can be assigned multiple emotion out of 20 possible emotion, making evaluation difficult. To counteract this difficulty, we have decided to convert the labels into 4 classes of low / high value and low / high arousal, with \"Low\" = 1, \"Medium\" = 2 and \"High\" = 3.We also rate on the ISEAR database (Wallbott and Scherer, 1986), which was created over many years by a large group of psychologists who interviewed the respondents in 37 countries, with \"Low\" = 1, \"Medium\" = 2 and \"High\" = 3.We also rate the labels positively on the ISEAR database (Wallbott and Scherer, 1986).Each observation in the Dataset ji is a self-reported experience model that is assigned to 1 out of 7 possible emotions, which makes for an interesting benchmark dataset.2 Precise training quickly demonstrates a learning chain for this example of the regression.4"}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "3rd International Conference on Learning Representations (ICLR).", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Deep learning of representations for unsupervised and transfer learning", "author": ["Yoshua Bengio"], "venue": "29th International Conference on Machine learning (ICML) \u2013 Workshop on Unsupervised and Transfer Learning, volume 27, pages 17\u201336.", "citeRegEx": "Bengio,? 2012", "shortCiteRegEx": "Bengio", "year": 2012}, {"title": "Emotion analysis as a regression problem - dimensional models and their implications on emotion representation and metrical evaluation", "author": ["Sven Buechel", "Udo Hahn."], "venue": "22nd European Conference on Artificial Intelligence (ECAI).", "citeRegEx": "Buechel and Hahn.,? 2016", "shortCiteRegEx": "Buechel and Hahn.", "year": 2016}, {"title": "Keras", "author": ["Fran\u00e7ois Chollet"], "venue": "https:// github.com/fchollet/keras.", "citeRegEx": "Chollet,? 2015", "shortCiteRegEx": "Chollet", "year": 2015}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Ronan Collobert", "Jason Weston."], "venue": "25th International Conference on Machine learning (ICML), pages 160\u2013167.", "citeRegEx": "Collobert and Weston.,? 2008", "shortCiteRegEx": "Collobert and Weston.", "year": 2008}, {"title": "Swisscheese at semeval-2016 task 4: Sentiment classification using an ensemble of convolutional neural networks with distant supervision", "author": ["Jan Deriu", "Maurice Gonzenbach", "Fatih Uzdilli", "Aurelien Lucchi", "Valeria De Luca", "Martin Jaggi"], "venue": null, "citeRegEx": "Deriu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Deriu et al\\.", "year": 2016}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["Jeff Donahue", "Yangqing Jia", "Oriol Vinyals", "Judy Hoffman", "Ning Zhang", "Eric Tzeng", "Trevor Darrell."], "venue": "31th International Conference on Machine Learning (ICML),", "citeRegEx": "Donahue et al\\.,? 2014", "shortCiteRegEx": "Donahue et al\\.", "year": 2014}, {"title": "emoji2vec: Learning emoji representations from their description", "author": ["Ben Eisner", "Tim Rockt\u00e4schel", "Isabelle Augenstein", "Matko Bo\u0161njak", "Sebastian Riedel."], "venue": "4th International Workshop on Natural Language Processing for Social Media (So-", "citeRegEx": "Eisner et al\\.,? 2016", "shortCiteRegEx": "Eisner et al\\.", "year": 2016}, {"title": "Why does unsupervised pre-training help deep learning", "author": ["Dumitru Erhan", "Yoshua Bengio", "Aaron Courville", "Pierre-Antoine Manzagol", "Pascal Vincent", "Samy Bengio"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Erhan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Erhan et al\\.", "year": 2010}, {"title": "A theoretically grounded application of dropout in recurrent neural networks", "author": ["Yarin Gal", "Zoubin Ghahramani."], "venue": "30th Conference on Neural Information Processing Systems (NIPS), pages 1019\u2013 1027.", "citeRegEx": "Gal and Ghahramani.,? 2016", "shortCiteRegEx": "Gal and Ghahramani.", "year": 2016}, {"title": "Twitter sentiment classification using distant supervision", "author": ["Alec Go", "Richa Bhayani", "Lei Huang."], "venue": "CS224N Project Report, Stanford, 1(12).", "citeRegEx": "Go et al\\.,? 2009", "shortCiteRegEx": "Go et al\\.", "year": 2009}, {"title": "Generating sequences with recurrent neural networks", "author": ["Alex Graves."], "venue": "arXiv preprint arXiv:1308.0850.", "citeRegEx": "Graves.,? 2013", "shortCiteRegEx": "Graves.", "year": 2013}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural Computation, 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Unsupervised sentiment analysis with emotional signals", "author": ["Xia Hu", "Jiliang Tang", "Huiji Gao", "Huan Liu."], "venue": "Proceedings of the 22nd international conference on World Wide Web (WWW), pages 607\u2013618. ACM.", "citeRegEx": "Hu et al\\.,? 2013", "shortCiteRegEx": "Hu et al\\.", "year": 2013}, {"title": "Are word embedding-based features useful for sarcasm detection", "author": ["Aditya Joshi", "Vaibhav Tripathi", "Kevin Patel", "Pushpak Bhattacharyya", "Mark Carman"], "venue": "In Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Joshi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "Bag of tricks for efficient text classification", "author": ["Armand Joulin", "Edouard Grave", "Piotr Bojanowski", "Tomas Mikolov."], "venue": "arXiv preprint arXiv:1607.01759.", "citeRegEx": "Joulin et al\\.,? 2016", "shortCiteRegEx": "Joulin et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "3rd International Conference on Learning Representations (ICLR).", "citeRegEx": "Kingma and Ba.,? 2015", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "The (un)predictability of emotional hashtags in twitter", "author": ["FA Kunneman", "CC Liebrecht", "APJ van den Bosch."], "venue": "52th Annual Meeting of the Association for Computational Linguistics (ACL). Association for Computational Linguistics.", "citeRegEx": "Kunneman et al\\.,? 2014", "shortCiteRegEx": "Kunneman et al\\.", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "27th Conference on Neural Information Processing Systems (NIPS), pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "emotional tweets", "author": ["Saif Mohammad."], "venue": "The First Joint Conference on Lexical and Computational Semantics (*SEM), pages 246\u2013255. Association for Computational Linguistics.", "citeRegEx": "Mohammad.,? 2012", "shortCiteRegEx": "Mohammad.", "year": 2012}, {"title": "Semeval2016 task 4: Sentiment analysis in twitter", "author": ["Preslav Nakov", "Alan Ritter", "Sara Rosenthal", "Fabrizio Sebastiani", "Veselin Stoyanov."], "venue": "10th International Workshop on Semantic Evaluation (SemEval), pages 1\u201318.", "citeRegEx": "Nakov et al\\.,? 2016", "shortCiteRegEx": "Nakov et al\\.", "year": 2016}, {"title": "Creating and characterizing a diverse corpus of sarcasm in dialogue", "author": ["Shereen Oraby", "Vrindavan Harrison", "Lena Reed", "Ernesto Hernandez", "Ellen Riloff", "Marilyn Walker."], "venue": "17th Annual Meeting of the Special Interest Group on Discourse and", "citeRegEx": "Oraby et al\\.,? 2016", "shortCiteRegEx": "Oraby et al\\.", "year": 2016}, {"title": "Learning to generate reviews and discovering sentiment", "author": ["Alec Radford", "Rafal Jozefowicz", "Ilya Sutskever."], "venue": "arXiv preprint arXiv:1704.01444.", "citeRegEx": "Radford et al\\.,? 2017", "shortCiteRegEx": "Radford et al\\.", "year": 2017}, {"title": "Using emoticons to reduce dependency in machine learning techniques for sentiment classification", "author": ["Jonathon Read."], "venue": "ACL student research workshop, pages 43\u201348. Association for Computational Linguistics.", "citeRegEx": "Read.,? 2005", "shortCiteRegEx": "Read.", "year": 2005}, {"title": "Evaluation datasets for twitter sentiment analysis: a survey and a new dataset, the stsgold", "author": ["Hassan Saif", "Miriam Fernandez", "Yulan He", "Harith Alani."], "venue": "Workshop: Emotion and Sentiment in Social and Expressive Media: approaches and per-", "citeRegEx": "Saif et al\\.,? 2013", "shortCiteRegEx": "Saif et al\\.", "year": 2013}, {"title": "Fine-grained emotion recognition in olympic tweets based on human computation", "author": ["Valentina Sintsova", "Claudiu-Cristian Musat", "Pearl Pu."], "venue": "4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis", "citeRegEx": "Sintsova et al\\.,? 2013", "shortCiteRegEx": "Sintsova et al\\.", "year": 2013}, {"title": "Overtraining, regularization and searching for a minimum, with application to neural networks", "author": ["Jonas Sj\u00f6berg", "Lennart Ljung."], "venue": "International Journal of Control, 62(6):1391\u20131407.", "citeRegEx": "Sj\u00f6berg and Ljung.,? 1995", "shortCiteRegEx": "Sj\u00f6berg and Ljung.", "year": 1995}, {"title": "Depechemood: A lexicon for emotion analysis from crowd-annotated news", "author": ["Jacopo Staiano", "Marco Guerini."], "venue": "52th Annual Meeting of the Association for Computational Linguistics (ACL). Association for Computational Linguistics.", "citeRegEx": "Staiano and Guerini.,? 2014", "shortCiteRegEx": "Staiano and Guerini.", "year": 2014}, {"title": "Semeval2007 task 14: Affective text", "author": ["Carlo Strapparava", "Rada Mihalcea."], "venue": "4th International Workshop on Semantic Evaluations (SemEval), pages 70\u201374. Association for Computational Linguistics.", "citeRegEx": "Strapparava and Mihalcea.,? 2007", "shortCiteRegEx": "Strapparava and Mihalcea.", "year": 2007}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "28th Conference on Neural Information Processing Systems (NIPS), pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Distant supervision for emotion classification with discrete binary values", "author": ["Jared Suttles", "Nancy Ide."], "venue": "International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), pages 121\u2013136. Springer.", "citeRegEx": "Suttles and Ide.,? 2013", "shortCiteRegEx": "Suttles and Ide.", "year": 2013}, {"title": "Learning sentimentspecific word embedding for twitter sentiment classification", "author": ["Duyu Tang", "Furu Wei", "Nan Yang", "Ming Zhou", "Ting Liu", "Bing Qin."], "venue": "52th Annual Meeting of the Association for Computational Linguistics (ACL), pages", "citeRegEx": "Tang et al\\.,? 2014", "shortCiteRegEx": "Tang et al\\.", "year": 2014}, {"title": "Theano: A Python framework for fast computation of mathematical expressions", "author": ["Theano Development Team."], "venue": "arXiv e-prints, abs/1605.02688.", "citeRegEx": "Team.,? 2016", "shortCiteRegEx": "Team.", "year": 2016}, {"title": "Sentiment strength detection for the social web", "author": ["Mike Thelwall", "Kevan Buckley", "Georgios Paltoglou."], "venue": "Journal of the American Society for Information Science and Technology (JASIST), 63(1):163\u2013173.", "citeRegEx": "Thelwall et al\\.,? 2012", "shortCiteRegEx": "Thelwall et al\\.", "year": 2012}, {"title": "Sentiment strength detection in short informal text", "author": ["Mike Thelwall", "Kevan Buckley", "Georgios Paltoglou", "Di Cai", "Arvid Kappas."], "venue": "Journal of the American Society for Information Science and Technology, 61(12):2544\u20132558.", "citeRegEx": "Thelwall et al\\.,? 2010", "shortCiteRegEx": "Thelwall et al\\.", "year": 2010}, {"title": "A corpus for research on deliberation and debate", "author": ["Marilyn A Walker", "Jean E Fox Tree", "Pranav Anand", "Rob Abbott", "Joseph King."], "venue": "International Conference on Language Resources and Evaluation (LREC), pages 812\u2013817.", "citeRegEx": "Walker et al\\.,? 2012", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "How universal and specific is emotional experience? evidence from 27 countries on five continents", "author": ["Harald G Wallbott", "Klaus R Scherer."], "venue": "International Social Science Council, 25(4):763\u2013795.", "citeRegEx": "Wallbott and Scherer.,? 1986", "shortCiteRegEx": "Wallbott and Scherer.", "year": 1986}, {"title": "A survey on the role of negation in sentiment analysis", "author": ["Michael Wiegand", "Alexandra Balahur", "Benjamin Roth", "Dietrich Klakow", "Andr\u00e9s Montoyo."], "venue": "Workshop on Negation and Speculation in Natural Language Processing (NeSp-NLP), pages 60\u201368.", "citeRegEx": "Wiegand et al\\.,? 2010", "shortCiteRegEx": "Wiegand et al\\.", "year": 2010}, {"title": "The positive emoticons", "author": ["Hu"], "venue": null, "citeRegEx": "Hu,? \\Q2013\\E", "shortCiteRegEx": "Hu", "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "For instance, the state-of-the-art approaches within sentiment analysis of social media data use positive/negative emoticons for training their models (Deriu et al., 2016; Tang et al., 2014).", "startOffset": 151, "endOffset": 190}, {"referenceID": 31, "context": "For instance, the state-of-the-art approaches within sentiment analysis of social media data use positive/negative emoticons for training their models (Deriu et al., 2016; Tang et al., 2014).", "startOffset": 151, "endOffset": 190}, {"referenceID": 19, "context": "Similarly, hashtags such as #anger, #joy, #happytweet, #ugh, #yuck and #fml have in previous research been mapped into emotional categories for emotion analysis (Mohammad, 2012).", "startOffset": 161, "endOffset": 177}, {"referenceID": 17, "context": "Kunneman et al. (2014) discuss a similar duality in the use of emotional hashtags such as #nice and #lame.", "startOffset": 0, "endOffset": 23}, {"referenceID": 23, "context": "Using emotional expressions as noisy labels in text to counter scarcity of labels is not a new idea (Read, 2005; Go et al., 2009).", "startOffset": 100, "endOffset": 129}, {"referenceID": 10, "context": "Using emotional expressions as noisy labels in text to counter scarcity of labels is not a new idea (Read, 2005; Go et al., 2009).", "startOffset": 100, "endOffset": 129}, {"referenceID": 19, "context": "Prior work has used theories of emotion such as Ekman\u2019s six basic emotions and Plutchik\u2019s eight basic emotions (Mohammad, 2012; Suttles and Ide, 2013).", "startOffset": 111, "endOffset": 150}, {"referenceID": 30, "context": "Prior work has used theories of emotion such as Ekman\u2019s six basic emotions and Plutchik\u2019s eight basic emotions (Mohammad, 2012; Suttles and Ide, 2013).", "startOffset": 111, "endOffset": 150}, {"referenceID": 7, "context": "Another way of automatically interpreting the emotional content of an emoji is to learn emoji embeddings from the words describing the emojisemantics in official emoji tables (Eisner et al., 2016).", "startOffset": 175, "endOffset": 196}, {"referenceID": 4, "context": "training on multiple datasets has shown promising results (Collobert and Weston, 2008).", "startOffset": 58, "endOffset": 86}, {"referenceID": 12, "context": "We use a variant of the Long Short-Term Memory (LSTM) model that has been successful at many NLP tasks (Hochreiter and Schmidhuber, 1997; Sutskever et al., 2014).", "startOffset": 103, "endOffset": 161}, {"referenceID": 29, "context": "We use a variant of the Long Short-Term Memory (LSTM) model that has been successful at many NLP tasks (Hochreiter and Schmidhuber, 1997; Sutskever et al., 2014).", "startOffset": 103, "endOffset": 161}, {"referenceID": 0, "context": "We use a simple approach inspired by (Bahdanau et al., 2014; Yang et al., 2016) with a single parameter pr.", "startOffset": 37, "endOffset": 79}, {"referenceID": 6, "context": "to use the network as a feature extractor (Donahue et al., 2014), where all layers in the model are frozen when fine-tuning on the target task except the last layer (hereafter referred to as the \u2018last\u2019 approach).", "startOffset": 42, "endOffset": 64}, {"referenceID": 8, "context": "Alternatively, another common approach is to use the pretrained model as an initialization (Erhan et al., 2010), where the full model is unfrozen (hereafter referred to as \u2018full\u2019).", "startOffset": 91, "endOffset": 111}, {"referenceID": 8, "context": "The sequential fine-tuning seems to have a regularizing effect similar to what has been examined with layer-wise training in the context of unsupervised learning (Erhan et al., 2010).", "startOffset": 162, "endOffset": 182}, {"referenceID": 26, "context": "Each time the model converges as measured on the validation set, the weights are reloaded to the best setting, thereby preventing overfitting in a similar manner to early stopping (Sj\u00f6berg and Ljung, 1995).", "startOffset": 180, "endOffset": 205}, {"referenceID": 15, "context": "For comparison we also train a version of our DeepMoji model with smaller LSTM layers and a bag-of-words classifier, fastText, that has recently shown competitive results (Joulin et al., 2016).", "startOffset": 171, "endOffset": 192}, {"referenceID": 27, "context": "Many recent papers proposing new methods for emotion analysis such as (Staiano and Guerini, 2014) only evaluate performance on a single benchmark dataset, SemEval 2007 Task 14, that contains 1250 observations.", "startOffset": 70, "endOffset": 97}, {"referenceID": 2, "context": "Recently, criticism has been raised concerning the use of correlation with continuous ratings as a measure (Buechel and Hahn, 2016), making only the somewhat limited binary evaluation possible.", "startOffset": 107, "endOffset": 131}, {"referenceID": 36, "context": "that we convert to a single-label classification task and a dataset of self-reported emotional experiences created by a large group of psychologists (Wallbott and Scherer, 1986).", "startOffset": 149, "endOffset": 177}, {"referenceID": 2, "context": "As these two datasets do not have prior evaluations, we evaluate against a state-of-the-art approach, which is based on a valence-arousal-dominance framework (Buechel and Hahn, 2016).", "startOffset": 158, "endOffset": 182}, {"referenceID": 34, "context": "Two of the datasets are from SentiStrength (Thelwall et al., 2010), SS-Twitter and SS-Youtube, and follow the relabeling described in (Saif et al.", "startOffset": 43, "endOffset": 66}, {"referenceID": 24, "context": ", 2010), SS-Twitter and SS-Youtube, and follow the relabeling described in (Saif et al., 2013) to make the labels binary.", "startOffset": 75, "endOffset": 94}, {"referenceID": 20, "context": "The third dataset is from SemEval 2016 Task4A (Nakov et al., 2016).", "startOffset": 46, "endOffset": 66}, {"referenceID": 15, "context": "observation that even bag-ofwords classifiers and unsupervised approaches can obtain a high accuracy (Joulin et al., 2016; Radford et al., 2017).", "startOffset": 101, "endOffset": 144}, {"referenceID": 22, "context": "observation that even bag-ofwords classifiers and unsupervised approaches can obtain a high accuracy (Joulin et al., 2016; Radford et al., 2017).", "startOffset": 101, "endOffset": 144}, {"referenceID": 5, "context": "The current state of the art for sentiment analysis on social media (and winner of SemEval 2016 Task 4A) uses an ensemble of convolutional neural networks that are pretrained on a private dataset of tweets with emoticons, making it difficult to replicate (Deriu et al., 2016).", "startOffset": 255, "endOffset": 275}, {"referenceID": 31, "context": "We also implemented the SentimentSpecific Word Embedding (SSWE) using the embeddings available on the authors\u2019 website (Tang et al., 2014), but found that it performed worse", "startOffset": 119, "endOffset": 138}, {"referenceID": 5, "context": "The current state of the art for sentiment analysis on social media (and winner of SemEval 2016 Task 4A) uses an ensemble of convolutional neural networks that are pretrained on a private dataset of tweets with emoticons, making it difficult to replicate (Deriu et al., 2016). Instead we pretrain a model with the hyperparameters of the largest model in their ensemble on the positive/negative emoticon dataset from Go et al. (2009). Using this pretraining as an initialization we finetune the model on the target tasks using early stopping on a validation set to determine the amount of training.", "startOffset": 256, "endOffset": 433}, {"referenceID": 28, "context": "SE0714 (Strapparava and Mihalcea, 2007) Emotion Headlines 3 250 1000 Olympic (Sintsova et al.", "startOffset": 7, "endOffset": 39}, {"referenceID": 25, "context": "SE0714 (Strapparava and Mihalcea, 2007) Emotion Headlines 3 250 1000 Olympic (Sintsova et al., 2013) Emotion Tweets 4 250 709 PsychExp (Wallbott and Scherer, 1986) Emotion Experiences 7 1000 6480", "startOffset": 77, "endOffset": 100}, {"referenceID": 36, "context": ", 2013) Emotion Tweets 4 250 709 PsychExp (Wallbott and Scherer, 1986) Emotion Experiences 7 1000 6480", "startOffset": 42, "endOffset": 70}, {"referenceID": 33, "context": "SS-Twitter (Thelwall et al., 2012) Sentiment Tweets 2 1000 1113 SS-Youtube (Thelwall et al.", "startOffset": 11, "endOffset": 34}, {"referenceID": 33, "context": ", 2012) Sentiment Tweets 2 1000 1113 SS-Youtube (Thelwall et al., 2012) Sentiment Video Comments 2 1000 1142 SE1604 (Nakov et al.", "startOffset": 48, "endOffset": 71}, {"referenceID": 20, "context": ", 2012) Sentiment Video Comments 2 1000 1142 SE1604 (Nakov et al., 2016) Sentiment Tweets 3 7155 31986", "startOffset": 52, "endOffset": 72}, {"referenceID": 35, "context": "SCv1 (Walker et al., 2012) Sarcasm Debate Forums 2 1000 995 SCv2-GEN (Oraby et al.", "startOffset": 5, "endOffset": 26}, {"referenceID": 21, "context": ", 2012) Sarcasm Debate Forums 2 1000 995 SCv2-GEN (Oraby et al., 2016) Sarcasm Debate Forums 2 1000 2260", "startOffset": 50, "endOffset": 70}, {"referenceID": 35, "context": "For sarcasm detection we use the sarcasm dataset version 1 and 2 from the Internet Argument Corpus (Walker et al., 2012).", "startOffset": 99, "endOffset": 120}, {"referenceID": 18, "context": "GoogleNews word2vec embeddings (Mikolov et al., 2013) are used for computing the embedding-based features.", "startOffset": 31, "endOffset": 53}, {"referenceID": 19, "context": "Oraby et al. (2016) are not directly comparable as only a subset of the data is available online.", "startOffset": 0, "endOffset": 20}, {"referenceID": 14, "context": "3 A state-of-the-art baseline is found by modeling the embedding-based features from Joshi et al. (2016) alongside unigrams, bigrams and trigrams with an SVM.", "startOffset": 85, "endOffset": 105}, {"referenceID": 16, "context": "For training we use the Adam optimizer (Kingma and Ba, 2015) with gradient clipping of the norm to 1.", "startOffset": 39, "endOffset": 60}, {"referenceID": 9, "context": "(Gal and Ghahramani, 2016) we do not drop out entire words in the input as some of our datasets contain observations with so few words that it could change the meaning of the text.", "startOffset": 0, "endOffset": 26}, {"referenceID": 21, "context": "the board posts from the Internet Argument Corpus version 1 (Oraby et al., 2016) has an average of 66 tokens with some observations being much longer.", "startOffset": 60, "endOffset": 80}, {"referenceID": 5, "context": "For instance, both Deriu et al. (2016) and Tang et al.", "startOffset": 19, "endOffset": 39}, {"referenceID": 5, "context": "For instance, both Deriu et al. (2016) and Tang et al. (2014) only used positive and negative emoticons as noisy labels.", "startOffset": 19, "endOffset": 62}, {"referenceID": 5, "context": "For instance, both Deriu et al. (2016) and Tang et al. (2014) only used positive and negative emoticons as noisy labels. Other instances of previous work have used slightly more nuanced sets of noisy labels (see \u00a72), but to our knowledge our set of noisy labels is the most diverse yet. To analyze the effect of using a diverse emoji set we create a subset of our pretraining data containing tweets with one of 8 emojis that are similar to the positive/negative emoticons used by Tang et al. (2014) and Hu et al.", "startOffset": 19, "endOffset": 499}, {"referenceID": 5, "context": "For instance, both Deriu et al. (2016) and Tang et al. (2014) only used positive and negative emoticons as noisy labels. Other instances of previous work have used slightly more nuanced sets of noisy labels (see \u00a72), but to our knowledge our set of noisy labels is the most diverse yet. To analyze the effect of using a diverse emoji set we create a subset of our pretraining data containing tweets with one of 8 emojis that are similar to the positive/negative emoticons used by Tang et al. (2014) and Hu et al. (2013) (the set of emoticons and corresponding emojis are available in the supplemental material).", "startOffset": 19, "endOffset": 520}, {"referenceID": 11, "context": "level features for any time step, making it easy to use this information if needed for a new task b) the improved gradient-flow from the output layer to the early layers in the network due to skipconnections (Graves, 2013) is important when adjusting parameters in early layers as part of transfer learning to small datasets.", "startOffset": 208, "endOffset": 222}, {"referenceID": 37, "context": "One concept that the LSTM layers likely learn is negation, which is known to be important for sentiment analysis (Wiegand et al., 2010).", "startOffset": 113, "endOffset": 135}], "year": 2017, "abstractText": "NLP tasks are often limited by scarcity of manually annotated data. In social media sentiment analysis and related tasks, researchers have therefore used binarized emoticons and specific hashtags as forms of distant supervision. Our paper shows that by extending the distant supervision to a more diverse set of noisy labels, the models can learn richer representations. Through emoji prediction on a dataset of 1246 million tweets containing one of 64 common emojis we obtain state-of-theart performance on 8 benchmark datasets within sentiment, emotion and sarcasm detection using a single pretrained model. Our analyses confirm that the diversity of our emotional labels yield a performance improvement over previous distant supervision approaches.", "creator": "LaTeX with hyperref package"}}}