{"id": "1708.00805", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Aug-2017", "title": "Variational Generative Stochastic Networks with Collaborative Shaping", "abstract": "We develop an approach to training generative models based on unrolling a variational auto-encoder into a Markov chain, and shaping the chain's trajectories using a technique inspired by recent work in Approximate Bayesian computation. We show that the global minimizer of the resulting objective is achieved when the generative model reproduces the target distribution. To allow finer control over the behavior of the models, we add a regularization term inspired by techniques used for regularizing certain types of policy search in reinforcement learning. We present empirical results on the MNIST and TFD datasets which show that our approach offers state-of-the-art performance, both quantitatively and from a qualitative point of view.", "histories": [["v1", "Wed, 2 Aug 2017 15:55:40 GMT  (4588kb,D)", "http://arxiv.org/abs/1708.00805v1", "Old paper, from ICML 2015"]], "COMMENTS": "Old paper, from ICML 2015", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["philip bachman", "doina precup"], "accepted": true, "id": "1708.00805"}, "pdf": {"name": "1708.00805.pdf", "metadata": {"source": "META", "title": "Variational Generative Stochastic Networks with Collaborative Shaping", "authors": ["Philip Bachman", "Doina Precup"], "emails": ["PHIL.BACHMAN@GMAIL.COM", "DPRECUP@CS.MCGILL.CA"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of us are able to play by the rules that they have imposed on themselves and are able to play by the rules that they have imposed on themselves."}, {"heading": "2. Background", "text": "This section summarizes previous work on the denocialization of auto-encoders and generative stochastic networks that form the basis of our model."}, {"heading": "2.1. Generalized Denoising Auto-encoders", "text": "In the Generalized Denoising Auto-encoder (DAE) framework (Bengio et al., 2013), a reconstruction distribution package (x-x-x) is formed to correspond implicitly to the conditional distribution P (x-x-x) in an infinite set of pairs {(x1, x-1),..., (xn, x-n) by extracting each xi-X from the target distribution D and then generating each x-i-X by applying a stochastic corruption process q\u03c6 (x-x) to xi. Given the fact that q\u03c6 and p\u03b8, where the two distribution parameters point to each other, one can construct a Markov chain via x-X by iteratively stamping a point xt from the PV (xt | x-1) and then forming a point x-t from the quantity (x-t-x-x), the chain is initialized with t = 0 by becoming x0 directly from the quantification of the transitional operator and the quantification of the Txt (x)."}, {"heading": "2.2. Training with Walkback", "text": "A method called \"walkback training\" was proposed for Generalized DAEs in (Bengio et al., 2013) and again used for GSNs in (Bengio et al., 2014). The motivation for walkback training was to alleviate difficulties that occur in practical, finite data settings in which many values for the latent variables z | Z, which were rarely (if at all) visited during training, would arise during sampling from the resulting Markov chain. the difficulties stem primarily from the desire to induce the corruption process q\u03c6 to a conditional distribution P (x | z), which is roughly unimodal via x givenAlgorithm 1 walkback for a general GSN input: data sample x, Corruptor q\u03c6, Reconstructor Pledge to cause the corruption process q\u03c6 to have an empty training pair list Pxz = {} Set z for any initial vector in Z. i = 1 to kz-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-z-to-z-z-z-z-z-z-z-z model."}, {"heading": "3. Simple Generative Stochastic Networks", "text": "We define a \"Simple GSN\" as any GSN in which the corruption process allows a consistent distribution.The structure of a simple GSN is therefore based on an iteratively controlled process that starts from a walkback process that can also generate outputs in another room from their inputs. Indeed, the simple GSN model is quite general and covers all GSNs that are trained with a walkback procedure. We now issue versions of the theorems (Bengio et al., 2013) modified for Simple GSNs that show that training with enough data and with sufficiently powerful functional approximators produces a Markov chain whose asymp-totic distribution exists."}, {"heading": "4. Variational Simple GSNs", "text": "We are developing a simple GSN that can efficiently generate \"locally coherent\" wanderings along the multiple boundaries described by target distribution by replacing the two competing terms in existing examples of generalized DAEs and GSNs with variable auto encoders (Kingma & Welling, 2014), while reinterpreting the two competing terms in variable free energy F (see Eq. 2) to represent an explicit trade-off between the different auto encoders (z | x) and the ease of modeling p.z (x)."}, {"heading": "5. Collaborative Generative Networks", "text": "In this section, we take a step back and present a general method of designing distribution, characterized by a generative approach. (...) The general approach to estimating the parameters of the \"Method of Moments\" is based on the \"Method of Moments,\" which learns the parameters of the \"Moments of Moments,\" which match some of the statistical moments of G and D. (...) The empirical sample from D, and more recent approaches, are based on minimizing the ability of some classical models to distinguish between G and D. (...) Motivated by the recent empirical success of this approach."}, {"heading": "6. Generating Random Walks on Manifolds", "text": "We now combine the variational Simple GSNs from Sec. 4 with the collaborative mechanism from Sec. 5. Our goal is to train the Markov chain directly by executing the variational Simple GSN in order to generate locally connected migrations along the multiplicity of the target distributionD, and to have the asymptotic distribution of the chain approximately D. The collaborative mechanism described in Sec. 5 pairs a generator g\u03b8 with a guidance function f\u0443. For the generator, we propose the use of a variational Simple GSN, which we unroll into a Markov chain by initializing x0 \u0445 D with a sample and then repeatedly {x1,..., xt,..., xn} by scanning zt-q\u03c6 (z | xt) xt + 1-p\u0442 (x | zt). In other words, we grind a variable auto-encoder by translating its output back into its sequential function, which is shown in the grid-2 fusions."}, {"heading": "7. Experiments", "text": "We have selected this datasetsto to allow a direct comparison with (Bengio et al., 2014) and (Goodfellow et al., 2014). Our first tests with MNIST data investigated the benefits of training using the unrolled collaborative mechanisms in the mapping. We have a Gaussian with identity covariance for the previous distribution p. (x) We have produced two vectors in R64, one representing the mean of a Gaussian distribution over Z and the other representing the elementary log variances of the distribution. Given these q2 / p models (z | x) it was easy to analytically compile, and its gradients in terms of distribution."}, {"heading": "8. Discussion", "text": "We presented an approach to learning generative models that belong to a simple subset of GSNs, using varying auto-encoders as building blocks. We created Markov chains by looping the output of these auto-encoders back into the input, and trained them to generate random walks along a target multiplicity, based on feedback from a leadership function trained to distinguish between samples sent out from the chain and samples drawn from the data multiplicity. An important conceptual contribution of our approach is that we execute the generative process as a unrolled Markov chain according to its natural dynamics, i.e. in the same way that we want to execute it \"in the wild,\" and then correct differences between exhibited and desired behavior by providing direct feedback about its size and location (rather than trying to force the behavior during the creation process in any way), and that the approach is part of the experiment."}, {"heading": "Acknowledgements", "text": "The funding for this work was provided by NSERC, and the authors would also like to thank the anonymous reviewers for their helpful feedback."}], "references": [{"title": "Generalized denoising auto-encoders as generative models", "author": ["Bengio", "Yoshua", "Yao", "Li", "Alain", "Guillaume", "Vincent", "Pascal"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "A cpu and gpu math expression compiler", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. Warde-Farley", "Bengio", "Y. Theano"], "venue": "In Python for Scientific Computing Conference (SciPy),", "citeRegEx": "Bergstra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "Quickly generating representative samples from an rbmderived process", "author": ["Breuleux", "Olivier", "Bengio", "Yoshua", "Vincent", "Pascal"], "venue": "Neural Computation,", "citeRegEx": "Breuleux et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Breuleux et al\\.", "year": 2011}, {"title": "Generative adversarial nets", "author": ["Goodfellow", "Ian J", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Classifier abc", "author": ["Gutmann", "Michael U", "Dutta", "Ritabrata", "Kaski", "Samuel", "Corander", "Jukka"], "venue": "In MCMSki IV (posters),", "citeRegEx": "Gutmann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gutmann et al\\.", "year": 2014}, {"title": "Likelihood-free inference via classification", "author": ["Gutmann", "Michael U", "Dutta", "Ritabrata", "Kaski", "Samuel", "Corander", "Jukka"], "venue": "In arXiv:1407.4981v1 [stat.CO],", "citeRegEx": "Gutmann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gutmann et al\\.", "year": 2014}, {"title": "Elements of Statistical Learning II", "author": ["Hastie", "Trevor", "Friedman", "Jerome", "Tibshirani", "Robert"], "venue": null, "citeRegEx": "Hastie et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hastie et al\\.", "year": 2008}, {"title": "Auto-encoding variational bayes", "author": ["Kingma", "Diederik P", "Welling", "Max"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Neural variational inference and learning", "author": ["Mnih", "Andriy", "Gregor", "Karol"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Mnih et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2014}, {"title": "Relative entropy policy search", "author": ["Peters", "Jan", "Mulling", "Karen", "Altun", "Yasemin"], "venue": "In AAAI,", "citeRegEx": "Peters et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Peters et al\\.", "year": 2010}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Rezende", "Danilo", "Mohamed", "Shakir", "Wierstra", "Daan"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Efficient computation of optimal action", "author": ["Todorov", "Emanuel"], "venue": "Proceedings of the National Academy of Science (PNAS),", "citeRegEx": "Todorov and Emanuel.,? \\Q2009\\E", "shortCiteRegEx": "Todorov and Emanuel.", "year": 2009}, {"title": "Regularization and variable selection via the elastic net", "author": ["Zou", "Hui", "Hastie", "Trevor"], "venue": "Journal of the Royal Statistical Society, B.,", "citeRegEx": "Zou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "We show that any model trained with the walkback procedure (Bengio et al., 2013) is encompassed by our approach.", "startOffset": 59, "endOffset": 80}, {"referenceID": 10, "context": "(Kingma & Welling, 2014; Rezende et al., 2014; Mnih & Gregor, 2014), and build our approach starting from variational auto-encoders.", "startOffset": 0, "endOffset": 67}, {"referenceID": 3, "context": "We partner a generative model with a function approximator that estimates the log-density ratio between the model-generated distribution and the target distribution, in what can be seen as a collaborative alternative to the adversarial approaches in (Gutmann et al., 2014a;b; Goodfellow et al., 2014).", "startOffset": 250, "endOffset": 300}, {"referenceID": 9, "context": "To control the model complexity, we introduce a regularization term close in spirit to reinforcement learning methods such as relative entropy policy search (Peters et al., 2010) and other approaches which depend on a notion of \u201cnatural system dynamics\u201d, e.", "startOffset": 157, "endOffset": 178}, {"referenceID": 3, "context": ", 2014) and the adversarial networks in (Goodfellow et al., 2014) in terms of test-set log-likelihood and qualitative behavior.", "startOffset": 40, "endOffset": 65}, {"referenceID": 0, "context": "In the Generalized Denoising Auto-encoder (DAE) framework (Bengio et al., 2013), one trains a reconstruc-", "startOffset": 58, "endOffset": 79}, {"referenceID": 0, "context": "Given a few small assumptions on the forms of q\u03c6 and p\u03b8, and the larger assumption that p\u03b8(x|x\u0303) provides a consistent estimator of P(x|x\u0303) as the number of training samples x \u223c D goes to infinity, it was shown in (Bengio et al., 2013) that the Markov chain constructed from the iterative process described above will be ergodic and have a stationary distribution \u03c0\u03b8 which matches D (i.", "startOffset": 214, "endOffset": 235}, {"referenceID": 0, "context": "All of the discussion in (Bengio et al., 2013) assumed that both xi and x\u0303i for each training pair (xi, x\u0303i) were from the same space X , although this was not required for their proofs.", "startOffset": 25, "endOffset": 46}, {"referenceID": 0, "context": "A method called walkback training was proposed for Generalized DAEs in (Bengio et al., 2013) and used again for GSNs in (Bengio et al.", "startOffset": 71, "endOffset": 92}, {"referenceID": 0, "context": "We now give versions of the theorems from (Bengio et al., 2013) modified for Simple GSNs, which show that training with enough data and with sufficiently powerful function approximators p\u03b8/q\u03c6 produces a Markov chain whose asymp-", "startOffset": 42, "endOffset": 63}, {"referenceID": 0, "context": "The proof is a direct translation of the proof for Theorem 1 in (Bengio et al., 2013), but with zs replacing x\u0303s.", "startOffset": 64, "endOffset": 85}, {"referenceID": 9, "context": "Though not explicitly stated in the existing work on GSNs, it seems that balancing between maximizing dispersion of the corruption process and the ease of modeling the reconstruction distribution p\u03b8 plays a role for GSNs analogous to balancing between minimizing the KL divergence KL(q\u03c6(z|x)||p(z)) and maximizing the expected conditional log-likelihood Ez\u223cq\u03c6(z|x) log p\u03b8(x|z) when training a generative model p\u03b8(x) with variational methods, or balancing between following the \u201cnatural dynamics\u201d of the system and optimizing reward in policy search (Peters et al., 2010; Todorov, 2009).", "startOffset": 549, "endOffset": 585}, {"referenceID": 10, "context": "We do this by replacing the denoising auto-encoders in existing examples of Generalized DAEs and GSNs with variational auto-encoders (Kingma & Welling, 2014; Rezende et al., 2014), while reinterpreting the two competing terms in the variational free-energy F (see Eq.", "startOffset": 133, "endOffset": 179}, {"referenceID": 0, "context": "4 in (Bengio et al., 2013):", "startOffset": 5, "endOffset": 26}, {"referenceID": 3, "context": "Examples of Approximate Bayesian Computation include spectral methods based on the \u201cmethod of moments\u201d, which learn the parameters of g\u03b8 so as to match some of the statistical moments of G to the corresponding moments observed in an empirical sample from D, and more recent approaches based on minimizing the ability of some classifier to distinguish between G and D (Gutmann et al., 2014a;b; Goodfellow et al., 2014).", "startOffset": 367, "endOffset": 417}, {"referenceID": 3, "context": "Motivated by the recent empirical success of this latter approach in training deep generative models (Goodfellow et al., 2014), we develop a related approach which offers improved stability and a simpler proof of correctness.", "startOffset": 101, "endOffset": 126}, {"referenceID": 3, "context": "Our method can be interpreted as a collaboration between g\u03b8 and f\u03c8 , in contrast with the adversarial approach presented in (Goodfellow et al., 2014).", "startOffset": 124, "endOffset": 149}, {"referenceID": 6, "context": "f\u03c8 if and only if \u2200x, f\u03c8(x) = log D(x) G(x) (Hastie et al., 2008).", "startOffset": 44, "endOffset": 65}, {"referenceID": 3, "context": "The key characteristic that distinguishes our objective from (Goodfellow et al., 2014) is that, given a fixed guide function f\u03c8 , our objective for the generator g\u03b8 pushes the mass in over-dense regions of G towards zero-contours of f\u03b8 while leaving the mass in under-dense regions unmoved.", "startOffset": 61, "endOffset": 86}, {"referenceID": 3, "context": "In contrast, the adversarial objective in (Goodfellow et al., 2014) drives all mass emitted by g\u03b8 towards local maxima of f\u03c8 .", "startOffset": 42, "endOffset": 67}, {"referenceID": 3, "context": "moment matching terms for matching the mean and covariance of x \u223c G with those of x \u223c D can be included to help avoid the occasional empirical \u201ccollapses\u201d of G that were described in (Goodfellow et al., 2014).", "startOffset": 183, "endOffset": 208}, {"referenceID": 3, "context": ", 2014) and (Goodfellow et al., 2014).", "startOffset": 12, "endOffset": 37}, {"referenceID": 10, "context": "\u03c6 using the techniques in (Kingma & Welling, 2014; Rezende et al., 2014).", "startOffset": 26, "endOffset": 72}, {"referenceID": 1, "context": "We implemented our models in Python using the THEANO library (Bergstra et al., 2010).", "startOffset": 61, "endOffset": 84}, {"referenceID": 2, "context": "on the validation set log-likelihood provided by the Gaussian Parzen density estimator described in (Breuleux et al., 2011) and the", "startOffset": 100, "endOffset": 123}, {"referenceID": 2, "context": "We found that the ORK model with strong regularization on KL(q\u03c6(z|x)||p\u2217(z)) was able to significantly out-perform the VAR model according to the Gaussian Parzen density estimator (GPDE) test described in (Breuleux et al., 2011)1.", "startOffset": 205, "endOffset": 228}, {"referenceID": 3, "context": ", 2014) and the 225 in (Goodfellow et al., 2014).", "startOffset": 23, "endOffset": 48}, {"referenceID": 3, "context": "1], as in (Bengio et al., 2014; Goodfellow et al., 2014).", "startOffset": 10, "endOffset": 56}, {"referenceID": 3, "context": "For comparison, best previous results on the GPDE bound for this dataset are 2050 (Goodfellow et al., 2014) and 2110 (Bengio et al.", "startOffset": 82, "endOffset": 107}, {"referenceID": 0, "context": ", 2014) and 2110 (Bengio et al., 2013).", "startOffset": 17, "endOffset": 38}], "year": 2017, "abstractText": "We develop an approach to training generative models based on unrolling a variational autoencoder into a Markov chain, and shaping the chain\u2019s trajectories using a technique inspired by recent work in Approximate Bayesian computation. We show that the global minimizer of the resulting objective is achieved when the generative model reproduces the target distribution. To allow finer control over the behavior of the models, we add a regularization term inspired by techniques used for regularizing certain types of policy search in reinforcement learning. We present empirical results on the MNIST and TFD datasets which show that our approach offers state-of-the-art performance, both quantitatively and from a qualitative point of view.", "creator": "LaTeX with hyperref package"}}}