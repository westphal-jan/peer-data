{"id": "1708.03492", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Aug-2017", "title": "Break it Down for Me: A Study in Automated Lyric Annotation", "abstract": "Comprehending lyrics, as found in songs and poems, can pose a challenge to human and machine readers alike. This motivates the need for systems that can understand the ambiguity and jargon found in such creative texts, and provide commentary to aid readers in reaching the correct interpretation. We introduce the task of automated lyric annotation (ALA). Like text simplification, a goal of ALA is to rephrase the original text in a more easily understandable manner. However, in ALA the system must often include additional information to clarify niche terminology and abstract concepts. To stimulate research on this task, we release a large collection of crowdsourced annotations for song lyrics. We analyze the performance of translation and retrieval models on this task, measuring performance with both automated and human evaluation. We find that each model captures a unique type of information important to the task.", "histories": [["v1", "Fri, 11 Aug 2017 09:58:39 GMT  (133kb,D)", "http://arxiv.org/abs/1708.03492v1", "To appear in Proceedings of EMNLP 2017"]], "COMMENTS": "To appear in Proceedings of EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lucas sterckx", "jason naradowsky", "bill byrne", "thomas demeester", "chris develder"], "accepted": true, "id": "1708.03492"}, "pdf": {"name": "1708.03492.pdf", "metadata": {"source": "CRF", "title": "Break it Down for Me: A Study in Automated Lyric Annotation", "authors": ["Lucas Sterckx", "Jason Naradowsky", "Bill Byrne", "Thomas Demeester", "Chris Develder"], "emails": ["firstname.lastname@ugent.be", "jrn39@cam.ac.uk", "wjb31@cam.ac.uk"], "sections": [{"heading": null, "text": "Like simplifying texts, ALA's goal is to make the original text easier to understand. However, in ALA, the system often needs to contain additional information to clarify niche terminology and abstract concepts. To stimulate research on this task, we publish a large collection of crowd-sourced annotations for song lyrics. We analyze the performance of translation and retrieval models for this task and measure performance with both automated and human evaluation. We find that each model captures a unique type of information that is important for the task."}, {"heading": "1 Introduction", "text": "Lyrics and poetry often use ambiguity, symbolism, irony, and other stylistic elements to elicit emotional responses, which sometimes make it difficult to interpret obscure texts, especially for readers or listeners unfamiliar with the genre. To address this problem, several online poetry databases have been created where users can explain, contextualize, or discuss texts. Examples are MetroLyrics1 and Genius.com. We refer to such 1http: / / www.metrolyrics.com 2http: / genius.com comments as lyrical annotations (Figure 1). In this work, we introduce the task of automated lyrical annotation (ALA). Compared with many traditional NLP systems trained on message wire or similar text, an automated system is able to explain abstract language, or find alternative text expressions for slang (and other unknown terms)."}, {"heading": "2 The Genius ALA Dataset", "text": "We collect a dataset of crowdsourced annotations generated by users of the Genius Online Text Database. Users can navigate to a particular verse or line, view existing annotations for the target text, or provide their own annotations for a particular song. Discussions between users are designed to improve the quality of annotations, as is the case with other shared online databases such as Wikipedia. This process is gamified: users collect IQ points for creating high-quality annotations. We collect 736,423 song texts for a total of 1,404,107 annotation pairs from all Genius subsections (rap, poetry, news, etc.). We limit the initial publication of annotation data to only English and filter out non-English annotations using a pre-trained language identifier. We also remove annotations that are solely links to external resources, and provide no useful annotations reduced to 3,720 data sets."}, {"heading": "2.1 Context Independent Annotation", "text": "For example, while we are able to generate large amounts of parallel text from Genius, users work without a single, predefined and common global goal other than maximizing their own IQ points. Therefore, there is no motivation to provide annotations to a song in its entirety or independently of previous annotations. Therefore, we distinguish between two types of annotations: context-sensitive (CI) annotations are independent of their surrounding context and can be interpreted without it, for example to explain certain metaphors or images or provide narratives while normalizing colloquial language. In contrast, context-sensitive (CS) annotations provide a broader context beyond the lyrical extract, e.g. background information about the artist. To estimate the contribution of both types to the dataset, we stamp 2,000 lyrical annotations and designate them either as CI or CS."}, {"heading": "3 Baselines", "text": "We are experimenting with three basic models that are used to simplify texts and generate paraphrases. \u2022 Statistical Machine Translation (SMT): One approach is to treat the task as a translation task and use established methods of statistical machine translation (SMT) to produce it (Quirk et al., 2004). We train a standard, phrase-based SMT model to translate texts into annotations, using GIZA + + (Josef Och et al., 2003) for text alignment and Moses (Koehn et al., 2007) for phrase alignment, training and decoding. \u2022 Seq2Seq: Sequence-to-Sequence models (Sutskever et al., 2014) offer an alternative to SMT systems and have been successfully applied to a variety of tasks, including machine translation."}, {"heading": "4 Evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Data", "text": "We evaluate automatic annotations based on a selection of 354 CI annotations and divide the rest of the annotations into 2,000 instances for development and the full remainder for training. It is important to note that the annotations for training and development include both CI and CS annotations. Annotations often include multiple sentences or even paragraphs for a single excerpt of text (which does not include endnotes), while machine translation models at the sentence level require synchronized corpora to perform well (Xu et al., 2016). Therefore, we transform training data by including each sentence from the annotations as a single training instance with the same lyric, resulting in a total of 1,813,350 sentence pairs. We use this collection of sentence pairs (which are reported as sentences in the results) to train the SMT model. Seq2Seq models are trained based on sentence pairs and full annotations, which have no effect on the performance of adjustment between the length and adjustment of the lycosm."}, {"heading": "4.2 Measures", "text": "For automated evaluation, we use measures commonly used to evaluate translation systems (BLEU, METEOR), paraphrase generation (iBLEU) and text simplification (SARI). BLEU (Papineni et al., 2002) uses a modified form of precision to compare generated annotations with references from Genius. METEOR (Denkowski and Lavie, 2011) is based on the harmonious mean of precision and memory and includes, along with the exact word comparison, stem and synonym. iBLEU (Sun and Zhou, 2012) is an extension of the BLEU metric to measure the diversity and appropriateness of annotations, iBLEU = 0.9 \u00d7 BLEU (annotation, reference) \u2212 0.1 \u00d7 BLEU (annotation, lyric). SARI (Xu et al., 2016) measures the precision and memory of words that are added separately, preserved, or erased, and tharic, and tharic."}, {"heading": "4.3 Hyperparameters and Optimization", "text": "Here we describe the implementation and some of the optimizations used to train the models.4https: / / www.crowdflower.com / For Seq2Seq models, we use OpenNMT (Klein et al., 2017) and optimize the perplexity of the development set. The vocabulary for both lyrics and annotations is reduced to the 50,000 most common tokens and is embedded in a 500-dimensional space. We use two layers of stacked bidirectional LSTMs with hidden states of 1024 dimensions. We regulate using drop-out (keep the probability at 0.7) and train with stochastic gradient descent with stacks of 64 samples for 13 epochs. The decoder of the SMT model is matched to optimal BLEU values on the development set by training minimal error rates (Bertoldi et al., 2009)."}, {"heading": "5 Results", "text": "To measure employee match, we calculate the Kappa Statistics (Fleiss, 1971). Kappa statistics for fluctuation and information are 0.05 and 0.07, respectively, indicating a low match. Assessing lyrical notes was difficult for CrowdFlower staff, as was evident from their assessment of the task. To evaluate in future work, we recommend hiring specialists familiar with the Genius platform and lyrics. Table 3 shows examples of song texts with Genius annotations and those generated by baseline models. One noteworthy observation is that translation models learn to assume the role of the narrator, as is common in CI annotations, and recognize the slang language while simplifying it to more standard English."}, {"heading": "6 Related Work", "text": "Work on modelling social annotations has focused mainly on the use of theme models (Iwata et al., 2009; Das et al., 2014) where annotations are based on themes. They can be used as a pre-processing step in machine learning tasks such as text classification and image recognition, but do not generate language as required in our ALA task. Text simplification and paraphrase generation have been extensively studied. Recent work has highlighted the need for large collections of text (Xu et al., 2015) and more appropriate evaluation standards (Xu et al., 2016; Galley et al., 2015), showing that informal language in particular, with its high degree of lexical variation, such as that is used in social media or texts, poses serious challenges (Xu et al., 2013). Text generation for artistic purposes (Xu et al., 2016; Galley et al., 2015), in particular, showed that particularly informational language with its high level of xicity is used in text, such as Xu."}, {"heading": "7 Conclusion and Future Work", "text": "As a first study, we investigated the automatic generation of context-independent annotations as machine translation and information gathering. Our basic system tests suggest that our body is suited to train machine translation systems.Standard SMT models are capable of reformulating and simplifying song lyrics, but tend to adhere closely to the structure of the song text. Seq2Seq models showed the potential to generate more fluid and informative text that is not dissimilar to the lyric.A large proportion of the annotations are strongly based on context and background knowledge (CS), one of their most appealing aspects. For future work, we propose to introduce structured and unstructured external knowledge (Ahn et al., 2016) and explicitly model references (Yang et al., 2016)."}, {"heading": "Acknowledgments", "text": "The authors thank the anonymous reviewers for their helpful comments. This work was supported by the Research Foundation - Flanders (FWO) and the U.K. Engineering and Physical Sciences Research Council (EPSRC grant EP / L027623 / 1)."}], "references": [{"title": "A Neural Knowledge Language Model", "author": ["S. Ahn", "H. Choi", "T. P\u00e4rnamaa", "Y. Bengio."], "venue": "ArXiv e-prints https://arxiv.org/abs/1608.00318.", "citeRegEx": "Ahn et al\\.,? 2016", "shortCiteRegEx": "Ahn et al\\.", "year": 2016}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "CoRR abs/1409.0473. http://arxiv.org/abs/1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Markov constraints for generating lyrics with style", "author": ["Gabriele Barbieri", "Fran\u00e7ois Pachet", "Pierre Roy", "Mirko Degli Esposti."], "venue": "ECAI 2012 - 20th European Conference on Artificial Intelligence. Including Prestigious Applications of Arti-", "citeRegEx": "Barbieri et al\\.,? 2012", "shortCiteRegEx": "Barbieri et al\\.", "year": 2012}, {"title": "Improved minimum error rate training in moses", "author": ["Nicola Bertoldi", "Barry Haddow", "Jean-Baptiste Fouet."], "venue": "Prague Bull. Math. Linguistics 91:7\u201316. http://ufal.mff.cuni.cz/pbml/91/art-bertoldi.pdf.", "citeRegEx": "Bertoldi et al\\.,? 2009", "shortCiteRegEx": "Bertoldi et al\\.", "year": 2009}, {"title": "Going beyond corr-lda for detecting specific comments on news & blogs", "author": ["Mrinal Kanti Das", "Trapit Bansal", "Chiranjib Bhattacharyya."], "venue": "Seventh ACM International Conference on Web Search and Data Mining, WSDM 2014, New York,", "citeRegEx": "Das et al\\.,? 2014", "shortCiteRegEx": "Das et al\\.", "year": 2014}, {"title": "Proceedings of the sixth workshop on statistical machine translation pages 85\u201391", "author": ["Michael Denkowski", "Alon Lavie."], "venue": "http://aclweb.org/anthology/W11-2107.", "citeRegEx": "Denkowski and Lavie.,? 2011", "shortCiteRegEx": "Denkowski and Lavie.", "year": 2011}, {"title": "Measuring nominal scale agreement among many raters", "author": ["Joseph L Fleiss."], "venue": "Psychological bulletin 76(5):378.", "citeRegEx": "Fleiss.,? 1971", "shortCiteRegEx": "Fleiss.", "year": 1971}, {"title": "deltableu: A discriminative metric for generation tasks with intrinsically diverse targets", "author": ["Michel Galley", "Chris Brockett", "Alessandro Sordoni", "Yangfeng Ji", "Michael Auli", "Chris Quirk", "Margaret Mitchell", "Jianfeng Gao", "Bill Dolan."], "venue": "Proceed-", "citeRegEx": "Galley et al\\.,? 2015", "shortCiteRegEx": "Galley et al\\.", "year": 2015}, {"title": "Modeling social annotation data with content relevance using a topic model", "author": ["Tomoharu Iwata", "Takeshi Yamada", "Naonori Ueda."], "venue": "Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural", "citeRegEx": "Iwata et al\\.,? 2009", "shortCiteRegEx": "Iwata et al\\.", "year": 2009}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Franz Josef Och", "Hermann Ney."], "venue": "Computational Linguistics, Volume 29, Number 1, March 2003 http://aclweb.org/anthology/J03-1002.", "citeRegEx": "Och and Ney.,? 2003", "shortCiteRegEx": "Och and Ney.", "year": 2003}, {"title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation", "author": ["G. Klein", "Y. Kim", "Y. Deng", "J. Senellart", "A.M. Rush."], "venue": "ArXiv e-prints https://arxiv.org/abs/1701.02810.", "citeRegEx": "Klein et al\\.,? 2017", "shortCiteRegEx": "Klein et al\\.", "year": 2017}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu."], "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Note on regression and inheritance in the case of two parents", "author": ["Karl Pearson."], "venue": "Proceedings of the Royal Society of London 58:240\u2013242.", "citeRegEx": "Pearson.,? 1895", "shortCiteRegEx": "Pearson.", "year": 1895}, {"title": "Ghostwriter: Using an lstm for automatic rap lyric generation", "author": ["Peter Potash", "Alexey Romanov", "Anna Rumshisky."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association", "citeRegEx": "Potash et al\\.,? 2015", "shortCiteRegEx": "Potash et al\\.", "year": 2015}, {"title": "Proceedings of the 2004 conference on empirical methods in natural language processing", "author": ["Chris Quirk", "Chris Brockett", "William Dolan."], "venue": "http://aclweb.org/anthology/W04-3219.", "citeRegEx": "Quirk et al\\.,? 2004", "shortCiteRegEx": "Quirk et al\\.", "year": 2004}, {"title": "Metaphor corpus annotated for source - target domain mappings", "author": ["Ekaterina Shutova", "Simone Teufel."], "venue": "Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC\u201910). European Languages Resources Asso-", "citeRegEx": "Shutova and Teufel.,? 2010", "shortCiteRegEx": "Shutova and Teufel.", "year": 2010}, {"title": "Joint learning of a dual smt system for paraphrase generation", "author": ["Hong Sun", "Ming Zhou."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguis-", "citeRegEx": "Sun and Zhou.,? 2012", "shortCiteRegEx": "Sun and Zhou.", "year": 2012}, {"title": "Sequence to sequence learning with neural", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V. Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Learning to freestyle: Hip hop challenge-response induction via transduction rule segmentation", "author": ["Dekai Wu", "Karteek Addanki", "Markus Saers", "Meriem Beloucif."], "venue": "Proceedings of the 2013 Conference on Empirical Meth-", "citeRegEx": "Wu et al\\.,? 2013", "shortCiteRegEx": "Wu et al\\.", "year": 2013}, {"title": "Problems in current text simplification research: New data can help", "author": ["Wei Xu", "Chris Callison-Burch", "Courtney Napoles."], "venue": "Transactions of the Association of Computational Linguistics 3:283\u2013297. http://aclweb.org/anthology/Q15-1021.", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Optimizing statistical machine translation for text simplification", "author": ["Chen", "Chris Callison-Burch."], "venue": "Transactions of the Association of Computational Linguistics 4:401\u2013415. http://aclweb.org/anthology/Q16-1029.", "citeRegEx": "Chen and Callison.Burch.,? 2016", "shortCiteRegEx": "Chen and Callison.Burch.", "year": 2016}, {"title": "Proceedings of the sixth workshop on building and using comparable corpora", "author": ["Wei Xu", "Alan Ritter", "Ralph Grishman."], "venue": "Association for Computational Linguistics, pages 121\u2013128. http://aclweb.org/anthology/W13-2515.", "citeRegEx": "Xu et al\\.,? 2013", "shortCiteRegEx": "Xu et al\\.", "year": 2013}, {"title": "Reference-Aware Language Models", "author": ["Z. Yang", "P. Blunsom", "C. Dyer", "W. Ling."], "venue": "ArXiv e-prints https://arxiv.org/abs/1611.01628.", "citeRegEx": "Yang et al\\.,? 2016", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Chinese poetry generation with recurrent neural networks", "author": ["Xingxing Zhang", "Mirella Lapata."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for", "citeRegEx": "Zhang and Lapata.,? 2014", "shortCiteRegEx": "Zhang and Lapata.", "year": 2014}], "referenceMentions": [{"referenceID": 14, "context": "One approach is to treat the task as one of translation, and to use established statistical machine translation (SMT) methods (Quirk et al., 2004) to produce them.", "startOffset": 126, "endOffset": 146}, {"referenceID": 17, "context": "\u2022 Seq2Seq: Sequence-to-sequence models (Sutskever et al., 2014) offer an alternative to SMT systems, and have been applied successfully to a variety of tasks including machine translation.", "startOffset": 39, "endOffset": 63}, {"referenceID": 1, "context": "We utilize Seq2Seq with attention (Bahdanau et al., 2014), which allows the model to", "startOffset": 34, "endOffset": 57}, {"referenceID": 11, "context": "BLEU (Papineni et al., 2002) uses a modified form of precision to compare generated annotations against references from Genius.", "startOffset": 5, "endOffset": 28}, {"referenceID": 5, "context": "METEOR (Denkowski and Lavie, 2011) is based on the harmonic mean of precision and recall and,", "startOffset": 7, "endOffset": 34}, {"referenceID": 16, "context": "iBLEU (Sun and Zhou, 2012) is an extension of the BLEU metric to measure diversity as well as adequacy of the annotation, iBLEU = 0.", "startOffset": 6, "endOffset": 26}, {"referenceID": 10, "context": "For Seq2Seq models, we use OpenNMT (Klein et al., 2017) and optimize for perplexity on the development set.", "startOffset": 35, "endOffset": 55}, {"referenceID": 3, "context": "The decoder of the SMT model is tuned for optimal BLEU scores on the development set using minimum error rate training (Bertoldi et al., 2009).", "startOffset": 119, "endOffset": 142}, {"referenceID": 6, "context": "To measure agreement between collaborators, we compute the kappa statistic (Fleiss, 1971).", "startOffset": 75, "endOffset": 89}, {"referenceID": 12, "context": "Out of the unsupervised metrics, METEOR obtained the highest Pearson correlation (Pearson, 1895) with human ratings for Information with a coefficient of 0.", "startOffset": 81, "endOffset": 96}, {"referenceID": 8, "context": "Work on modeling of social annotations has mainly focused on the use of topic models (Iwata et al., 2009; Das et al., 2014) in which annotations are assumed to originate from topics.", "startOffset": 85, "endOffset": 123}, {"referenceID": 4, "context": "Work on modeling of social annotations has mainly focused on the use of topic models (Iwata et al., 2009; Das et al., 2014) in which annotations are assumed to originate from topics.", "startOffset": 85, "endOffset": 123}, {"referenceID": 19, "context": "Recent work has highlighted the need for large text collections (Xu et al., 2015) as well as more appropriate evaluation measures (Xu et al.", "startOffset": 64, "endOffset": 81}, {"referenceID": 7, "context": ", 2015) as well as more appropriate evaluation measures (Xu et al., 2016; Galley et al., 2015).", "startOffset": 56, "endOffset": 94}, {"referenceID": 21, "context": ", as used in social media or lyrics, poses serious challenges (Xu et al., 2013).", "startOffset": 62, "endOffset": 79}, {"referenceID": 2, "context": "Text generation for artistic purposes, such as poetry and lyrics, has been explored most commonly using templates and constraints (Barbieri et al., 2012).", "startOffset": 130, "endOffset": 153}, {"referenceID": 2, "context": "Text generation for artistic purposes, such as poetry and lyrics, has been explored most commonly using templates and constraints (Barbieri et al., 2012). In regard to rap lyrics, Wu et al. (2013) present a system for rap lyric generation that produces a single line of lyrics that is meant to be a response to a single line of input.", "startOffset": 131, "endOffset": 197}, {"referenceID": 2, "context": "Text generation for artistic purposes, such as poetry and lyrics, has been explored most commonly using templates and constraints (Barbieri et al., 2012). In regard to rap lyrics, Wu et al. (2013) present a system for rap lyric generation that produces a single line of lyrics that is meant to be a response to a single line of input. Most recent work is that of Zhang et al. (2014) and Potash et al.", "startOffset": 131, "endOffset": 383}, {"referenceID": 2, "context": "Text generation for artistic purposes, such as poetry and lyrics, has been explored most commonly using templates and constraints (Barbieri et al., 2012). In regard to rap lyrics, Wu et al. (2013) present a system for rap lyric generation that produces a single line of lyrics that is meant to be a response to a single line of input. Most recent work is that of Zhang et al. (2014) and Potash et al. (2015), who show the effectiveness of RNNs for the generation of poetry and lyrics.", "startOffset": 131, "endOffset": 408}, {"referenceID": 15, "context": "tional modeling of metaphors (Shutova and Teufel, 2010).", "startOffset": 29, "endOffset": 55}, {"referenceID": 0, "context": "As future work we suggest injection of structured and unstructured external knowledge (Ahn et al., 2016) and explicit modeling of references (Yang et al.", "startOffset": 86, "endOffset": 104}, {"referenceID": 22, "context": ", 2016) and explicit modeling of references (Yang et al., 2016).", "startOffset": 44, "endOffset": 63}], "year": 2017, "abstractText": "Comprehending lyrics, as found in songs and poems, can pose a challenge to human and machine readers alike. This motivates the need for systems that can understand the ambiguity and jargon found in such creative texts, and provide commentary to aid readers in reaching the correct interpretation. We introduce the task of automated lyric annotation (ALA). Like text simplification, a goal of ALA is to rephrase the original text in a more easily understandable manner. However, in ALA the system must often include additional information to clarify niche terminology and abstract concepts. To stimulate research on this task, we release a large collection of crowdsourced annotations for song lyrics. We analyze the performance of translation and retrieval models on this task, measuring performance with both automated and human evaluation. We find that each model captures a unique type of information important to the task.", "creator": "TeX"}}}