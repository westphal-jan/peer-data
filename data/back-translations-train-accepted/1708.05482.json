{"id": "1708.05482", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Aug-2017", "title": "A Question Answering Approach to Emotion Cause Extraction", "abstract": "Emotion cause extraction aims to identify the reasons behind a certain emotion expressed in text. It is a much more difficult task compared to emotion classification. Inspired by recent advances in using deep memory networks for question answering (QA), we propose a new approach which considers emotion cause identification as a reading comprehension task in QA. Inspired by convolutional neural networks, we propose a new mechanism to store relevant context in different memory slots to model context information. Our proposed approach can extract both word level sequence features and lexical features. Performance evaluation shows that our method achieves the state-of-the-art performance on a recently released emotion cause dataset, outperforming a number of competitive baselines by at least 3.01% in F-measure.", "histories": [["v1", "Fri, 18 Aug 2017 02:07:36 GMT  (363kb,D)", "http://arxiv.org/abs/1708.05482v1", "Accepted by EMNLP 2017"], ["v2", "Sun, 24 Sep 2017 01:43:43 GMT  (1081kb,D)", "http://arxiv.org/abs/1708.05482v2", "Accepted by EMNLP 2017"]], "COMMENTS": "Accepted by EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lin gui", "jiannan hu", "yulan he", "ruifeng xu", "qin lu", "jiachen du"], "accepted": true, "id": "1708.05482"}, "pdf": {"name": "1708.05482.pdf", "metadata": {"source": "CRF", "title": "A Question Answering Approach to Emotion Cause Extraction", "authors": ["Lin Gui", "Jiannan Hu", "Yulan He", "Ruifeng Xua", "Qin Lu", "Jiachen Du"], "emails": ["guilin.nlp@gmail.com,", "hujiannan0526@gmail.com,", "y.he9@aston.ac.uk,", "xuruifeng@hit.edu.cn,", "csluqin@comp.polyu.edu.hk,", "dujiachen@stmail.hitsz.edu.cn", "xuruifeng@hit.edu.cn"], "sections": [{"heading": "1 Introduction", "text": "The fact is that we will be able to find a solution that will enable us to find a solution that will enable us to find a solution and that will enable us to find a solution that will enable us to find a solution that will enable us to find a solution that will enable us to find a solution that will enable us to find a solution that is capable of finding a solution."}, {"heading": "2 Related Work", "text": "Identifying emotion categories in the text is one of the most important tasks in NLP (Liu, 2015). Going one step further, emotion cause extraction can reveal important information about what causes a particular emotion and why there is emotion change. In this section, we present related work on emotion analysis, including emotion cause extraction. In emotion analysis, however, we must first determine the taxonomy of emotions. Researchers have proposed a list of primary emotions (Plutchik, 1980; Ekman, 1984; Turner, 2000). In this study, we use Ekman's emotion classification scheme (Ekman, 1984), which identifies six primary emotions, namely happiness, fear, anger, disgust and surprise, known as the \"Big6\" scheme in the W3C Emotion Markup Language. This emotion classification scheme is consistent with most previous work in Chinese emotion analysis.Existing work in emotion analysis largely focuses on emotion classification (et al)."}, {"heading": "3 Our Approach", "text": "In this section we will first define our task. Then we will give a brief introduction to the memory network, including its basic learning structure of memory networks and deep architecture. Finally, we will introduce our modified deep memory network for the extraction of emotions."}, {"heading": "3.1 Task Definition", "text": "In this task, a particular document, which is a passage about an emotional event, contains an emotional word E and the cause of the event. It is manually segmented at the sentence level. For each sentence c = {w1, w2,... wk}, which consists of k-words, the goal is to find out which sentence contains the emotional cause. For data representation, we can map each word into a low-dimensional embedding space, also known as a word vector (Mikolov et al., 2013). All word vectors are stacked in a word that embeds the matrix L, Rd, and V. For example, the sentence \"I lost my phone yesterday, I feel so sad now.\" The first sentence consists of two clauses. The first sentence contains the cause of emotion, while the second sentence enlarges the vocabulary. In the second sentence, the complex methods of emotionality we cannot trigger in the emotional ability."}, {"heading": "3.2 Memory Network", "text": "Since there is a clause c = {w1, w2,..., wk} and an emotion word, we first get the representation of the emotion word in an embedding space designated E. However, for the clause, we let the embedding of the representations of the words be designated e1, e2,..., ek. Here, both ei and E are defined in Rd. Then we use the inner product to evaluate the correlation between each word i in a sentence and the emotion word designated as mi: mi = ei \u00b7 E. (1) We then normalize the value from mi to [0, 1] using a Softmax function designated by: \u03b1i = exp (mi).k j = 1 exp (mj), (2) where k is the length of the clause."}, {"heading": "3.3 Convolutional Multiple-Slot Deep Memory Network", "text": "It is often the case that the meaning of a word wi is determined by its context, such as the previous word and the following word. Denials and emotional transitions are also context sensitive. However, the storage network described in Section 3.2 has only one disk space of the size d \u00b7 k to represent a clause where d is the dimension of a word and k is the length of a clause. It means that when the storage network models a clause, it only looks at each word separately. To capture context information for clauses, we propose a new architecture that contains more disk space to model the context with a revolutionary operation. The basic architecture of the Convolutionary Multiple-Slot Memory Network (short: ConvMS-Memory Network) is shown in Figure 4.Consider the text length is usually briefly used in the dataset that we use for the emotion cause extraction, we set the convolutionary size of the kernel to 3."}, {"heading": "4 Experiments and Evaluation", "text": "We first present the experimental settings and then report on the results in this section."}, {"heading": "4.1 Experimental Setup and Dataset", "text": "We are conducting experiments with a simplified Chinese emotion corpus (Gui et al., 2016), the only publicly available data set for this task to the best of our knowledge and belief. The corpus contains 2,105 documents from the SINA City News \u2020. Each document has only one emotion corpus word and one or more emotion causes. The documents are manually segmented into clauses. The main task is to find out which clause contains the emotion corpus warning. Details of the corpus are in Table 1. The metrics we used in the evaluation follow Lee et al. Available at: http: / / hlt.hitsz.edu.cn /? Page id = 694 \u2020 http: / / news.sina.com.cn / society / (2010). It is generally accepted that we can compare our results with others. If a proposed emotion causation clause covers the commented answer, the word sequence is considered correct. The measurement correctness, the callback precision and the causes are the P."}, {"heading": "4.2 Evaluation and Comparison", "text": "We compare ourselves to the following basic methods: \u2022 RB (Rule based method): The rules-based method has been used in the past (Lee et al., 2010). \u2022 CB (Common Sense based method): This is the knowledge-based method we have proposed (Russo et al., 2011). We use the Chinese Emotion Cognition Lexicon (Xu et al., 2013) as a common sense knowledge base. The lexicon contains more than 5000 types of emotion stimulation and their corresponding words of reflection. \u2022 Machine Learning Methodology, which starts from rules-based characteristics and facts from a sound knowledge base."}, {"heading": "4.3 More Insights into the ConvMS-Memnet", "text": "To gain better insight into our proposed ConvMSMemnet, we are conducting further experiments to understand the impact on performance by: 1) pre-trained or randomly initialized word embedding; 2) multiple hops; 3) attention visualizations; 4) additional training periods."}, {"heading": "4.3.1 Pre-trained Word Embeddings", "text": "In our ConvMS memnet, we use pre-trained word embedding as input; embedding maps each word into a low-dimensional real-value vector as representation; words with similar meanings should have similar representations; it allows our model to deal more effectively with synonyms; the question is, \"Can we train the network without pre-trained word embedding?\" Wine word vectors randomly and use an embedding matrix to update the word vectors simultaneously in network training. Comparison results are shown in Table 3. It can be observed that pre-trained word embedding yields 2.59% higher F dimensions than random initialization. This is partly due to the limited size of our training data. Therefore, using word embedding trained from other, much larger corpus yields better results."}, {"heading": "4.3.2 Multiple Hops", "text": "It is widely accepted that mathematical models using a deep multi-layered architecture are better able to learn data representations with multiple levels of abstraction. In this section, we evaluate the performance of several hops in this task. We set the number of hops from 1 to 9, with 1 representing the simplest single-layer network shown in Figure 4. The more hops are stacked, the more complicated the model. The results are in Table 4. The single-layer network has achieved a competitive performance. As the number of hops increases, performance improves. However, if the number of hops is greater than 3, performance decreases as a result of the overhaul. As the data set for this task is small, more parameters lead to overhauls."}, {"heading": "4.3.3 Word-Level Attention Weights", "text": "The question is whether the model really focuses on the words that cause the emotion. In this example, the cause of the \"touched\" emotion is \"persistence.\" In Table 5, we show the distribution of attention weights at the word level in different phases of memory network training. We can find that in the first two phases, the highest attention weights are centered on the word \"more.\" However, from the third jump, the highest attention weight moves on the word \"persistence.\" This shows that our model is effective in identifying the most important key word in relation to the emotion cause."}, {"heading": "4.3.4 Training Epochs", "text": "In our model, the training periods are set to 20. In this section, we examine the examination error on the basis of a case study. Due to the limited length of the page, we select only one example from the corpus. The following text contains four paragraphs: paragraph 3 45%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%, paragraph 3%."}, {"heading": "4.4 Limitations", "text": "We have shown a simple example in Section 4.3.4, which consists of only four clauses, on the basis of which our model can identify the clause that correctly contains the cause of emotions. We note that for some complex passages of text that contain dependency relationships, negations or transitions of emotions, it can be difficult to find the right clause that contains the causes of emotions. It is a difficult task to correctly model the discourse relationships between clauses. In the future, we will examine different network architectures taking into account different discourse relationships, possibly by transferring larger commented data available for other tasks. Another shortcoming of our model is that the answer generated from our model is simply \"yes\" or \"no.\" However, the main reason for this is that the size of the annotated corpus is too small to train a model that can provide natural answers in full sentences. Ideally, we would like to develop a model that allows the cause of a text-expressed data to be directly applied to the automated task, however, since it is also expensive for systems to perform the automated task."}, {"heading": "5 Conclusions", "text": "The key feature of this approach is the use of contextual information in the learning process that is ignored in the original storage network. Our new storage network architecture is capable of storing contextual information in different storage locations to capture it in the correct order through revolutionary operation. Our model achieves the most advanced performance on a dataset for identifying emotional causes compared to a number of competing baselines. In the future, we will explore effective ways to model discourse relationships between clauses and develop a QA system that can output the cause of emotions directly as answers."}, {"heading": "Acknowledgments", "text": "This work was supported by the National Natural Science Foundation of China 61370165, U1636103, 61632011, 61528302, National 863 Program of China 2015AA015405, Shenzhen Foundational Research Funding JCYJ20150625142543470, JCYJ20170307150024907 and Guangdong Provincial Engineering Technology Research Center for Data Science 2016KF09."}], "references": [{"title": "Emotinet: A knowledge base for emotion detection in text built on the appraisal theories", "author": ["Alexandra Balahur", "Jes\u00fas M. Hermida", "Andr\u00e9s Montoyo", "Rafael Mu\u00f1oz."], "venue": "Proceedings of International Conference on Applications of Natural Language to", "citeRegEx": "Balahur et al\\.,? 2011", "shortCiteRegEx": "Balahur et al\\.", "year": 2011}, {"title": "Detecting implicit emotion expressions from text using ontological resources and lexical learning", "author": ["Alexandra Balahur", "Jes\u00fas M. Hermida", "Hristo Tanev."], "venue": "Theory and Applications of Natural Language Processing, pages 235\u2013255.", "citeRegEx": "Balahur et al\\.,? 2013", "shortCiteRegEx": "Balahur et al\\.", "year": 2013}, {"title": "Joint emotion analysis via multi-task gaussian processes", "author": ["Daniel Beck", "Trevor Cohn", "Lucia Specia."], "venue": "EMNLP, pages 1798\u20131803.", "citeRegEx": "Beck et al\\.,? 2014", "shortCiteRegEx": "Beck et al\\.", "year": 2014}, {"title": "Linguistic template extraction for recognizing reader-emotion and emotional resonance writing assistance", "author": ["Yung-Chun Chang", "Cen-Chieh Chen", "Yu-Lun Hsieh", "WL Hsu."], "venue": "ACL, pages 775\u2013780.", "citeRegEx": "Chang et al\\.,? 2015", "shortCiteRegEx": "Chang et al\\.", "year": 2015}, {"title": "A computer-assistance learning system for emotional wording", "author": ["Wei Fan Chen", "Mei Hua Chen", "Ming Lung Chen", "Lun Wei Ku."], "venue": "IEEE Transactions on Knowledge and Data Engineering, 28(5):1\u20131.", "citeRegEx": "Chen et al\\.,? 2016", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Emotion cause detection with linguistic constructions", "author": ["Ying Chen", "Sophia Yat Mei Lee", "Shoushan Li", "Chu-Ren Huang."], "venue": "COLING, pages 179\u2013187.", "citeRegEx": "Chen et al\\.,? 2010", "shortCiteRegEx": "Chen et al\\.", "year": 2010}, {"title": "Finding emotion holder from bengali blog texts\u2014an unsupervised syntactic approach", "author": ["Dipankar Das", "Sivaji Bandyopadhyay."], "venue": "Proceedings of Pacific Asia Conference on Language, Information and Computation, pages 621\u2013628.", "citeRegEx": "Das and Bandyopadhyay.,? 2010", "shortCiteRegEx": "Das and Bandyopadhyay.", "year": 2010}, {"title": "Expression and the nature of emotion", "author": ["Paul Ekman."], "venue": "Approaches to Emotion, 3:19\u2013344.", "citeRegEx": "Ekman.,? 1984", "shortCiteRegEx": "Ekman.", "year": 1984}, {"title": "A rulebased approach to emotion cause detection for chinese micro-blogs", "author": ["Kai Gao", "Hua Xu", "Jiushuo Wang."], "venue": "Expert Systems with Applications, 42(9):4517\u20134528.", "citeRegEx": "Gao et al\\.,? 2015", "shortCiteRegEx": "Gao et al\\.", "year": 2015}, {"title": "Joint learning on sentiment and emotion classification", "author": ["Wei Gao", "Shoushan Li", "Sophia Yat Mei Lee", "Guodong Zhou", "Chu-Ren Huang."], "venue": "CIKM, pages 1505\u20131508. ACM.", "citeRegEx": "Gao et al\\.,? 2013", "shortCiteRegEx": "Gao et al\\.", "year": 2013}, {"title": "Detecting emotion stimuli in emotion-bearing sentences", "author": ["Diman Ghazi", "Diana Inkpen", "Stan Szpakowicz."], "venue": "Computational Linguistics and Intelligent Text Processing, pages 152\u2013165. Springer.", "citeRegEx": "Ghazi et al\\.,? 2015", "shortCiteRegEx": "Ghazi et al\\.", "year": 2015}, {"title": "Event-driven emotion cause extraction with corpus construction", "author": ["Lin Gui", "Dongyin Wu", "Ruifeng Xu", "Qin Lu", "Yu Zhou."], "venue": "EMNLP, pages 1639\u20131649.", "citeRegEx": "Gui et al\\.,? 2016", "shortCiteRegEx": "Gui et al\\.", "year": 2016}, {"title": "Emotion cause detection with linguistic construction in chinese weibo text", "author": ["Lin Gui", "Li Yuan", "Ruifeng Xu", "Bin Liu", "Qin Lu", "Yu Zhou."], "venue": "Natural Language Processing and Chinese Computing, pages 457\u2013464. Springer.", "citeRegEx": "Gui et al\\.,? 2014", "shortCiteRegEx": "Gui et al\\.", "year": 2014}, {"title": "Predicting and eliciting addressee\u2019s emotion in online dialogue", "author": ["Takayuki Hasegawa", "Nobuhiro Kaji", "Naoki Yoshinaga", "Masashi Toyoda."], "venue": "ACL, pages 964\u2013972.", "citeRegEx": "Hasegawa et al\\.,? 2013", "shortCiteRegEx": "Hasegawa et al\\.", "year": 2013}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "EMNLP, pages 1746\u2013 1751.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "A text-driven rule-based system for emotion cause detection", "author": ["Sophia Yat Mei Lee", "Ying Chen", "Chu-Ren Huang."], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages", "citeRegEx": "Lee et al\\.,? 2010", "shortCiteRegEx": "Lee et al\\.", "year": 2010}, {"title": "Sentence-level emotion classification with label and context dependence", "author": ["Shoushan Li", "Lei Huang", "Rong Wang", "Guodong Zhou."], "venue": "ACL, pages 1045\u20131053.", "citeRegEx": "Li et al\\.,? 2013", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Text-based emotion classification using emotion cause extraction", "author": ["Weiyuan Li", "Hua Xu."], "venue": "Expert Systems with Applications, 41(4):1742\u20131749.", "citeRegEx": "Li and Xu.,? 2014", "shortCiteRegEx": "Li and Xu.", "year": 2014}, {"title": "Sentiment analysis: Mining opinions, sentiments, and emotions", "author": ["Bing Liu."], "venue": "Cambridge University Press.", "citeRegEx": "Liu.,? 2015", "shortCiteRegEx": "Liu.", "year": 2015}, {"title": "Joint modeling of news reader\u2019s and comment writer\u2019s emotions", "author": ["Huanhuan Liu", "Shoushan Li", "Guodong Zhou", "Chu-Ren Huang", "Peifeng Li."], "venue": "ACL, pages 511\u2013515.", "citeRegEx": "Liu et al\\.,? 2013", "shortCiteRegEx": "Liu et al\\.", "year": 2013}, {"title": "Jeam: A novel model for cross-domain sentiment classification based on emotion analysis", "author": ["Kun-Hu Luo", "Zhi-Hong Deng", "Liang-Chen Wei", "Hongliang Yu."], "venue": "EMNLP, pages 2503\u20132508.", "citeRegEx": "Luo et al\\.,? 2015", "shortCiteRegEx": "Luo et al\\.", "year": 2015}, {"title": "Effective approaches to attention-based neural machine translation", "author": ["Thang Luong", "Hieu Pham", "Christopher D. Manning."], "venue": "EMNLP, pages 1412\u20131421.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Alexander M. Rush", "Sumit Chopra", "Jason Weston."], "venue": "EMNLP, pages 379\u2013389.", "citeRegEx": "Rush et al\\.,? 2015", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "NIPS, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Crowdsourcing a word\u2013emotion association lexicon", "author": ["Saif M Mohammad", "Peter D Turney."], "venue": "Computational Intelligence, 29(3):436\u2013465.", "citeRegEx": "Mohammad and Turney.,? 2013", "shortCiteRegEx": "Mohammad and Turney.", "year": 2013}, {"title": "Probabilistic sense sentiment similarity through hidden emotions", "author": ["Mitra Mohtarami", "Man Lan", "Chew Lim Tan."], "venue": "ACL, pages 983\u2013992.", "citeRegEx": "Mohtarami et al\\.,? 2013", "shortCiteRegEx": "Mohtarami et al\\.", "year": 2013}, {"title": "Exploiting community emotion for microblog event detection", "author": ["Gaoyan Ou", "Wei Chen", "Tengjiao Wang", "Zhongyu Wei", "Binyang Li", "Dongqing Yang", "Kam-Fai Wong."], "venue": "EMNLP, pages 1159\u20131168.", "citeRegEx": "Ou et al\\.,? 2014", "shortCiteRegEx": "Ou et al\\.", "year": 2014}, {"title": "Emotion: A psychoevolutionary synthesis", "author": ["Robert Plutchik"], "venue": null, "citeRegEx": "Plutchik.,? \\Q1980\\E", "shortCiteRegEx": "Plutchik.", "year": 1980}, {"title": "Learning emotion indicators from tweets: Hashtags, hashtag patterns, and phrases", "author": ["Ashequl Qadir", "Ellen Riloff."], "venue": "EMNLP, pages 1203\u20131209.", "citeRegEx": "Qadir and Riloff.,? 2014", "shortCiteRegEx": "Qadir and Riloff.", "year": 2014}, {"title": "Construction of a blog emotion corpus for chinese emotional expression analysis", "author": ["Changqin Quan", "Fuji Ren."], "venue": "EMNLP, pages 1446\u20131454.", "citeRegEx": "Quan and Ren.,? 2009", "shortCiteRegEx": "Quan and Ren.", "year": 2009}, {"title": "Emocause: an easy-adaptable approach to emotion cause contexts", "author": ["Irene Russo", "Tommaso Caselli", "Francesco Rubino", "Ester Boldrini", "Patricio Mart\u0131\u0301nez-Barco"], "venue": "In Proceedings of the 2nd Workshop on Computational Approaches", "citeRegEx": "Russo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Russo et al\\.", "year": 2011}, {"title": "Depechemood: a lexicon for emotion analysis from crowd-annotated news", "author": ["Jacopo Staiano", "Marco Guerini."], "venue": "arXiv preprint arXiv:1405.1605.", "citeRegEx": "Staiano and Guerini.,? 2014", "shortCiteRegEx": "Staiano and Guerini.", "year": 2014}, {"title": "End-to-end memory networks", "author": ["Sainbayar Sukhbaatar", "Arthur Szlam", "Jason Weston."], "venue": "NIPS, pages 2431\u20132439.", "citeRegEx": "Sukhbaatar et al\\.,? 2015", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Aspect level sentiment classification with deep memory network", "author": ["Duyu Tang", "Bing Qin", "Ting Liu."], "venue": "EMNLP, pages 214\u2013225.", "citeRegEx": "Tang et al\\.,? 2016", "shortCiteRegEx": "Tang et al\\.", "year": 2016}, {"title": "On the origins of human emotions: A sociological inquiry into the evolution of human affect", "author": ["Jonathan H Turner."], "venue": "Stanford University Press Stanford, CA.", "citeRegEx": "Turner.,? 2000", "shortCiteRegEx": "Turner.", "year": 2000}, {"title": "Memory networks", "author": ["Jason Weston", "Sumit Chopra", "Antoine Bordes."], "venue": "arXiv preprint arXiv:1410.3916.", "citeRegEx": "Weston et al\\.,? 2014", "shortCiteRegEx": "Weston et al\\.", "year": 2014}, {"title": "Coarse-to-fine sentence-level emotion classification based on the intra-sentence features and sentential context", "author": ["Jun Xu", "Ruifeng Xu", "Qin Lu", "Xiaolong Wang."], "venue": "CIKM, pages 2455\u20132458. ACM.", "citeRegEx": "Xu et al\\.,? 2012", "shortCiteRegEx": "Xu et al\\.", "year": 2012}, {"title": "A new emotion dictionary based on the distinguish of emotion expression and emotion cognition", "author": ["Ruifeng Xu", "Chengtian Zou", "Yanzhen Zheng", "Xu Jun", "Lin Gui", "Bin Liu", "Xiaolong Wang."], "venue": "Journal of Chinese Information Processing, 27(6):82\u201390.", "citeRegEx": "Xu et al\\.,? 2013", "shortCiteRegEx": "Xu et al\\.", "year": 2013}, {"title": "A topic model for building fine-grained domainspecific emotion lexicon", "author": ["Min Yang", "Dingju Zhu", "Kam-Pui Chow."], "venue": "ACL(2), pages 421\u2013 426.", "citeRegEx": "Yang et al\\.,? 2014", "shortCiteRegEx": "Yang et al\\.", "year": 2014}, {"title": "Emotion distribution learning from texts", "author": ["Deyu Zhou", "Xuan Zhang", "Yin Zhou", "Quan Zhao", "Xin Geng."], "venue": "EMNLP, pages 638\u2013647.", "citeRegEx": "Zhou et al\\.,? 2016", "shortCiteRegEx": "Zhou et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 9, "context": "In recent years, studies in emotion analysis largely focus on emotion classification including detection of writers\u2019 emotions (Gao et al., 2013) as well as readers\u2019 emotions (Chang et al.", "startOffset": 126, "endOffset": 144}, {"referenceID": 3, "context": ", 2013) as well as readers\u2019 emotions (Chang et al., 2015).", "startOffset": 37, "endOffset": 57}, {"referenceID": 4, "context": "There are also some information extraction tasks defined in emotion analysis (Chen et al., 2016; Balahur et al., 2011), such as extracting the feeler of an emotion (Das and Bandyopadhyay, 2010).", "startOffset": 77, "endOffset": 118}, {"referenceID": 0, "context": "There are also some information extraction tasks defined in emotion analysis (Chen et al., 2016; Balahur et al., 2011), such as extracting the feeler of an emotion (Das and Bandyopadhyay, 2010).", "startOffset": 77, "endOffset": 118}, {"referenceID": 6, "context": ", 2011), such as extracting the feeler of an emotion (Das and Bandyopadhyay, 2010).", "startOffset": 53, "endOffset": 82}, {"referenceID": 14, "context": "In this paper, we propose a new deep memory network architecture to model the context of each word simultaneously by multiple memory slots which capture sequential information using convolutional operations (Kim, 2014), and achieves the state-of-the-art performance compared to existing methods which use manual rules, common sense knowledge bases or other machine learning models.", "startOffset": 207, "endOffset": 218}, {"referenceID": 18, "context": "Identifying emotion categories in text is one of the key tasks in NLP (Liu, 2015).", "startOffset": 70, "endOffset": 81}, {"referenceID": 27, "context": "Researchers have proposed a list of primary emotions (Plutchik, 1980; Ekman, 1984; Turner, 2000).", "startOffset": 53, "endOffset": 96}, {"referenceID": 7, "context": "Researchers have proposed a list of primary emotions (Plutchik, 1980; Ekman, 1984; Turner, 2000).", "startOffset": 53, "endOffset": 96}, {"referenceID": 34, "context": "Researchers have proposed a list of primary emotions (Plutchik, 1980; Ekman, 1984; Turner, 2000).", "startOffset": 53, "endOffset": 96}, {"referenceID": 7, "context": "In this study, we adopt Ekman\u2019s emotion classification scheme (Ekman, 1984), which identifies six primary emotions, namely happiness, sadness, fear, anger, disgust and surprise, known as the \u201cBig6\u201d scheme in the W3C Emotion Markup Language.", "startOffset": 62, "endOffset": 75}, {"referenceID": 16, "context": "Existing work in emotion analysis mostly focuses on emotion classification (Li et al., 2013; Zhou et al., 2016) and emotion information extraction (Balahur et al.", "startOffset": 75, "endOffset": 111}, {"referenceID": 39, "context": "Existing work in emotion analysis mostly focuses on emotion classification (Li et al., 2013; Zhou et al., 2016) and emotion information extraction (Balahur et al.", "startOffset": 75, "endOffset": 111}, {"referenceID": 1, "context": ", 2016) and emotion information extraction (Balahur et al., 2013).", "startOffset": 43, "endOffset": 65}, {"referenceID": 20, "context": "There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al.", "startOffset": 70, "endOffset": 112}, {"referenceID": 25, "context": "There are other studies which focused on joint learning of sentiments (Luo et al., 2015; Mohtarami et al., 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al.", "startOffset": 70, "endOffset": 112}, {"referenceID": 29, "context": ", 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al.", "startOffset": 39, "endOffset": 141}, {"referenceID": 19, "context": ", 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al.", "startOffset": 39, "endOffset": 141}, {"referenceID": 13, "context": ", 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al.", "startOffset": 39, "endOffset": 141}, {"referenceID": 28, "context": ", 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al.", "startOffset": 39, "endOffset": 141}, {"referenceID": 26, "context": ", 2013) or emotions in tweets or blogs (Quan and Ren, 2009; Liu et al., 2013; Hasegawa et al., 2013; Qadir and Riloff, 2014; Ou et al., 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al.", "startOffset": 39, "endOffset": 141}, {"referenceID": 24, "context": ", 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014).", "startOffset": 42, "endOffset": 115}, {"referenceID": 38, "context": ", 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014).", "startOffset": 42, "endOffset": 115}, {"referenceID": 31, "context": ", 2014), and emotion lexicon construction (Mohammad and Turney, 2013; Yang et al., 2014; Staiano and Guerini, 2014).", "startOffset": 42, "endOffset": 115}, {"referenceID": 0, "context": ", 2016) and emotion information extraction (Balahur et al., 2013). Xu et al. (2012) used a coarse to fine method to classify emotions in Chinese blogs.", "startOffset": 44, "endOffset": 84}, {"referenceID": 0, "context": ", 2016) and emotion information extraction (Balahur et al., 2013). Xu et al. (2012) used a coarse to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier.", "startOffset": 44, "endOffset": 170}, {"referenceID": 0, "context": ", 2016) and emotion information extraction (Balahur et al., 2013). Xu et al. (2012) used a coarse to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification.", "startOffset": 44, "endOffset": 273}, {"referenceID": 0, "context": ", 2016) and emotion information extraction (Balahur et al., 2013). Xu et al. (2012) used a coarse to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader\u2019s emotions.", "startOffset": 44, "endOffset": 373}, {"referenceID": 0, "context": ", 2016) and emotion information extraction (Balahur et al., 2013). Xu et al. (2012) used a coarse to fine method to classify emotions in Chinese blogs. Gao et al. (2013) proposed a joint model to co-train a polarity classifier and an emotion classifier. Beck et al. (2014) proposed a Multi-task Gaussian-process based method for emotion classification. Chang et al. (2015) used linguistic templates to predict reader\u2019s emotions. Das and Bandyopadhyay (2010) used an unsupervised method to extract emotion feelers from Bengali blogs.", "startOffset": 44, "endOffset": 458}, {"referenceID": 12, "context": "Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) extended the rule based method to informal text in Weibo text (Chinese tweets).", "startOffset": 13, "endOffset": 66}, {"referenceID": 17, "context": "Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) extended the rule based method to informal text in Weibo text (Chinese tweets).", "startOffset": 13, "endOffset": 66}, {"referenceID": 8, "context": "Some studies (Gui et al., 2014; Li and Xu, 2014; Gao et al., 2015) extended the rule based method to informal text in Weibo text (Chinese tweets).", "startOffset": 13, "endOffset": 66}, {"referenceID": 4, "context": "Based on this corpus, Chen et al. (2010) proposed a rule based method to detect emotion causes based on manually define linguistic rules.", "startOffset": 22, "endOffset": 41}, {"referenceID": 27, "context": "Other than rule based methods, Russo et al. (2011) proposed a crowdsourcing method to construct a common-sense knowledge base which is related to emotion causes.", "startOffset": 31, "endOffset": 51}, {"referenceID": 10, "context": "Ghazi et al. (2015) used Conditional Random Fields (CRFs) to extract emotion causes.", "startOffset": 0, "endOffset": 20}, {"referenceID": 10, "context": "Ghazi et al. (2015) used Conditional Random Fields (CRFs) to extract emotion causes. However, it requires emotion cause and emotion keywords to be in the same sentence. More recently, Gui et al. (2016) proposed a multi-kernel based method to extract emotion causes through", "startOffset": 0, "endOffset": 202}, {"referenceID": 35, "context": "In our work, we choose the memory network, which is designed to model the relation between a story and a query for QA systems (Weston et al., 2014; Sukhbaatar et al., 2015).", "startOffset": 126, "endOffset": 172}, {"referenceID": 32, "context": "In our work, we choose the memory network, which is designed to model the relation between a story and a query for QA systems (Weston et al., 2014; Sukhbaatar et al., 2015).", "startOffset": 126, "endOffset": 172}, {"referenceID": 21, "context": "Apart from its application in QA, memory network has also achieved great successes in other NLP tasks, such as machine translation (Luong et al., 2015), sentiment analysis (Tang et al.", "startOffset": 131, "endOffset": 151}, {"referenceID": 33, "context": ", 2015), sentiment analysis (Tang et al., 2016) or summarization (M.", "startOffset": 28, "endOffset": 47}, {"referenceID": 11, "context": "The formal definition of emotion cause extraction is given in (Gui et al., 2016).", "startOffset": 62, "endOffset": 80}, {"referenceID": 23, "context": "a word vector (Mikolov et al., 2013).", "startOffset": 14, "endOffset": 36}, {"referenceID": 11, "context": "As the distance between a clause and an emotion words is a very important feature according to (Gui et al., 2016), we simply add this distance into the softmax function as an additional feature in our work.", "startOffset": 95, "endOffset": 113}, {"referenceID": 11, "context": "We conduct experiments on a simplified Chinese emotion cause corpus (Gui et al., 2016)\u2217, the only publicly available dataset on this task to the best of our knowledge.", "startOffset": 68, "endOffset": 86}, {"referenceID": 15, "context": "\u2022 RB (Rule based method): The rule based method proposed in (Lee et al., 2010).", "startOffset": 60, "endOffset": 78}, {"referenceID": 30, "context": "\u2022 CB (Common-sense based method): This is the knowledge based method proposed by (Russo et al., 2011).", "startOffset": 81, "endOffset": 101}, {"referenceID": 37, "context": "We use the Chinese Emotion Cognition Lexicon (Xu et al., 2013) as the common-sense knowledge base.", "startOffset": 45, "endOffset": 62}, {"referenceID": 5, "context": "\u2022 RB+CB+ML (Machine learning method trained from rule-based features and facts from a common-sense knowledge base): This methods was previously proposed for emotion cause classification in (Chen et al., 2010).", "startOffset": 189, "endOffset": 208}, {"referenceID": 15, "context": "We train a SVM using features extracted from the rules defined in (Lee et al., 2010) and the Chinese Emotion Cognition Lexicon (Xu et al.", "startOffset": 66, "endOffset": 84}, {"referenceID": 37, "context": ", 2010) and the Chinese Emotion Cognition Lexicon (Xu et al., 2013).", "startOffset": 50, "endOffset": 67}, {"referenceID": 17, "context": "It is a baseline previously used in (Li and Xu, 2014; Gui et al., 2016)", "startOffset": 36, "endOffset": 71}, {"referenceID": 11, "context": "It is a baseline previously used in (Li and Xu, 2014; Gui et al., 2016)", "startOffset": 36, "endOffset": 71}, {"referenceID": 23, "context": "\u2022 Word2vec: This is a SVM classifier using word representations learned by Word2vec (Mikolov et al., 2013) as features.", "startOffset": 84, "endOffset": 106}, {"referenceID": 11, "context": "\u2022 Multi-kernel: This is the state-of-the-art method using the multi-kernel method (Gui et al., 2016) to identify the emotion cause.", "startOffset": 82, "endOffset": 100}, {"referenceID": 14, "context": "\u2022 CNN: The convolutional neural network for sentence classification (Kim, 2014).", "startOffset": 68, "endOffset": 79}, {"referenceID": 11, "context": "The multi-kernel method (Gui et al., 2016) is the best performer among the baselines because it considers context information in a structured way.", "startOffset": 24, "endOffset": 42}], "year": 2017, "abstractText": "Emotion cause extraction aims to identify the reasons behind a certain emotion expressed in text. It is a much more difficult task compared to emotion classification. Inspired by recent advances in using deep memory networks for question answering (QA), we propose a new approach which considers emotion cause identification as a reading comprehension task in QA. Inspired by convolutional neural networks, we propose a new mechanism to store relevant context in different memory slots to model context information. Our proposed approach can extract both word level sequence features and lexical features. Performance evaluation shows that our method achieves the state-of-the-art performance on a recently released emotion cause dataset, outperforming a number of competitive baselines by at least 3.01% in F-measure.", "creator": "LaTeX with hyperref package"}}}