{"id": "1708.06075", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Aug-2017", "title": "Scientific Information Extraction with Semi-supervised Neural Tagging", "abstract": "This paper addresses the problem of extracting keyphrases from scientific articles and categorizing them as corresponding to a task, process, or material. We cast the problem as sequence tagging and introduce semi-supervised methods to a neural tagging model, which builds on recent advances in named entity recognition. Since annotated training data is scarce in this domain, we introduce a graph-based semi-supervised algorithm together with a data selection scheme to leverage unannotated articles. Both inductive and transductive semi-supervised learning strategies outperform state-of-the-art information extraction performance on the 2017 SemEval Task 10 ScienceIE task.", "histories": [["v1", "Mon, 21 Aug 2017 03:33:58 GMT  (1762kb,D)", "http://arxiv.org/abs/1708.06075v1", "accepted by EMNLP 2017"]], "COMMENTS": "accepted by EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yi luan", "mari ostendorf", "hannaneh hajishirzi"], "accepted": true, "id": "1708.06075"}, "pdf": {"name": "1708.06075.pdf", "metadata": {"source": "CRF", "title": "Scientific Information Extraction with Semi-supervised Neural Tagging", "authors": ["Yi Luan", "Mari Ostendorf", "Hannaneh Hajishirzi"], "emails": ["hannaneh}@uw.edu"], "sections": [{"heading": "1 Introduction", "text": "This year it is more than ever before."}, {"heading": "2 Related Work", "text": "There has been a growing interest in research on automatic methods to help researchers search and extract useful information from scientific literature. Previous research has focused on citation feelings (Athar and Devil, 2012b, a), citation networks (Kas, 2011; Gabor et al., 2016; Do et al., 2013; Jaidka et al., 2014), summary (Abu-Jbara and Radev, 2011) and some research community analyses (Vogel and Jurafsky, 2012; Anderson et al., 2012; Levow et al., 2014), summary (Levow et al.), data resource summary, previous work on information extraction (IE) for scientific literature is very limited. Gupta and Manning (2011) initially proposed a task to define scientific terms for 474 abstracts from the ACL group."}, {"heading": "3 Problem Definition and Data", "text": "The purpose of this work is to extract phrases that can answer questions researchers normally face when reading a paper: What TASK addressed the paper? What PROCESS or method did the paper use or compare? What MATERIALS does the paper used in experiments have? While these basic concepts are important in a variety of scientific disciplines, the terms used in certain disciplines can be substantially different. For example, MATERIALS in computer science could be a text corpus while they are physical materials in physics or materials science. Data we use to label the task 10 ScienceIE datasets. Fig. 1 provides examples that illustrate the variation in domains, but also show that there are common terms like \"the task of,\" \"\" use, \"\" technique, \"etc. A challenge with this dataset is that the size of the training data is very small."}, {"heading": "4 Neural Architecture Model", "text": "We introduce an end-to-end model for categorizing scientific keyphrases, based on a neural entity recognition model (Lample et al., 2016) and adding functional embedding."}, {"heading": "4.1 Model", "text": "We develop a three-layer hierarchical neural model to highlight the tokens of the documents (details of tokenization are in Sec. 6). (1) The token representation layer links three components together. (2) The token LSTM layer uses a bidirectional LSTM layer to integrate contextual cues from surrounding tokens to derive intermediate token embeddings. (3) The CRF tagging layer tagging decisions together with a CRF objective function to embedding dependencies between characters."}, {"heading": "5 Semi-supervised Learning", "text": "We develop a semi-monitored algorithm that extends self-training by estimating the labels of unmarked data and then using them for retraining. Specifically, we use a graph-based algorithm to estimate the posterior probabilities of unmarked data and develop a new CRF training to take into account the uncertainty of the estimated labels while optimizing the objective function."}, {"heading": "5.1 Graph-based Posterior Estimates", "text": "First, a diagram of symbols based on their semantic similarity is used, which is then used as an additional feature of the neural network. (The totality of the graph is equal to the number of tokens in both labeled records Vl and unlabeled records Vu.) The tokens are modeled with a concatenation of pre-trained word beds (with dimensions d) of 5 grams centered by the current tokens, the word embedding the narrowest verb, and a set of discrete features of 5 grams. (with dimensions d) of 4 grams centered by the current tokens, the word embedding the narrowest verb, and a set of discrete features that include a portion of the word beds. (with dimensions d) of 4 grams."}, {"heading": "5.2 CRF training with Uncertain Labels", "text": "A standard approach to self-training is to make hard choices about labeling symbols based on estimated q values and to retrain the model. However, the estimated rear values of our task are silent due to the difficulty and variety of the ScienceIE task. Instead, we expand the CRF training to take advantage of the confidence of estimated rear values. A similar idea has already been used in treating partially labeled data (Kim et al., 2015).Specifically, we look at a set of x that we define as a limited grid Y value (x), with the permitted label types Y (xt) = {yt} at each position when p (yt}, p (yt | x) > empirical label types that we define as boundaries."}, {"heading": "6 Experimental Setup", "text": "Data SemEval ScienceIE (SE) corpus consists of 500 journal articles; one paragraph of each article is initially randomly selected and commented on; the complete unlabeled articles and their metadata are provided along with the labeled data; the training data consists of 350 documents; 50 are stored for development and 100 for testing; the 500 articles come from 82 different journals spread evenly across three areas; we also use two external resources for pretraining word embedding: i) WIKI, as for Wikipedia articles, in particular a full Wikipedia dump from 2012 with 46M words; and ii) ACM, a collection of CS papers containing 108M words.Comparisons We compare our system with two late matching baselines and the task."}, {"heading": "7 Experimental Results", "text": "We evaluate our NN-CRF model in both supervised and semi-supervised environments. We also perform ablations and try different variants to best understand our model."}, {"heading": "7.1 Best Case System Performance", "text": "Table 1 shows the results of our neural sequence tagging model NN-CRF in both supervised and semi-supervised learning (ULM and graph-based) and compares them with baseline and state of the art (best SemEval system (Augenstein et al., 2017)). Augenstein and S\u00f8gaard (2017) use a multi-task learning strategy to improve the performance of the supervised keyphrase classification, but they report only on the evolution of the results of SemEval Task 10, we include their result here as well and refer to it as MULTITASK. We report results for both Span Identification (SemEval SubTask A) and Span Classification in TASK, PROCESS and MATERIAL (SemEval Subtask B). 5The results show that our neural sequence tagging models significantly exceed the state of the art and both baselines."}, {"heading": "7.2 Supervised Learning", "text": "The Impact of Neural Model Components Table 2 provides the results of an ablation study on the development environment showing the impact of various components of our NN-CRF on the IE scientific task. In the basic model, the word embeddings of word2vec, which is trained on the 350 full journal articles in the SE training set along with Wikipedia and ScienceIE data, are initialized. The feature layer, character layer and bi-LSTM word layers all improve performance. In addition, we observe a big improvement (20.6% relative) in the IE scientific task by adding the CRF layer. Initialization Table 3 reports on our NN-CRF performance when deployed on different do-5The evaluation script is provided by the challenge, with a modification to report 3 decimal precision results.6Best semester numbers from https: / / scienceS layer."}, {"heading": "7.3 Semi-Supervision Learning", "text": "Table 4 reports on the results of the semi-monitored learning algorithms in different settings. In particular, we include the graph-based methods for calculating posterior and CRF training (ULM vs. Hard Decision). The table shows that the inclusion of graph-based methods for calculating posterior and ULM for CRF training outperforms their counterparts. To calculate the posterior, we examine two different strategies of the graph-based methods: i) GRAPHINTERP, which interpolates the smoothed posterior values from label propagation with CRF marginals; for the inductive setting, GRAPHINTERP uses only uncommented data from the dev set and uses the best model for decoding at test times. For the transductive setting, GRAPHINTERP uses the annoyed data from the test set to also create the graph and adjust the parameters on the dev segment. ii) GRAPHINTERP uses the smoothed label."}, {"heading": "7.4 Category and Span Analysis", "text": "Table 5 describes the performance of our method in the three categories at the margin and token level. We observe significant improvements in the use of ULM + GRAPHINTERP and ULM + GRAPHFEAT over the best SemEval and our best monitored system across all three categories at both the token and chip levels. We also observe that system performance in the TASK classification is much lower than in the PROCESS and MATERIAL domains, in part because TASK occurs much less frequently than the other types. In addition, TASK keyphrases often contain verb phrases, while the other two domains mainly consist of noun phrases. An analysis of confusion patterns shows that the most common confusion between PROCESS and MATERIAL exists. However, we observe that ULM + GRAPHFEAT * can significantly reduce confusion, with 3.5% relative improvement of PHCULS and 3.6% relative improvement of GROCESS + GRAFEAT."}, {"heading": "7.5 Error Analysis", "text": "As described in the previous section, TASK is the most difficult type to identify with our system. Series 1 shows a failure to recognize the verbal phrase that follows \"to\" as part of TASK, but to recognize \"enantiopure products\" as MATERIAL. The system prefers to predict PROCESS or MATERIAL because these classes have more samples than TASK. Series 2 illustrates the problem of identifying generic terms as key terms based on similar associations such as \"receptors\" and \"drug effect.\" A third common error is the erroneous labeling of adjectives such as \"adjacent\" in Series 3, which leads to voltage errors. Another common cause of error is an insufficient context: in the last example, a larger context is required to determine whether \"SWE\" is a PROCESS or MATERIAL."}, {"heading": "8 Conclusion", "text": "This paper presents the task of scientific information extraction as a sequence marker problem, and introduces a hierarchical LSTM-CRF Neural Marker Model for this task, building on the recent results of NER. We have implemented a semi-monitored learning algorithm that includes graph-based marker propagation and confidence-based data selection. We show that the introduction of semi-supervision significantly outperforms the performance of the monitored LSTM-CRF marker model. We have also performed a detailed analysis of the system and pointed out common errors. In our experiments, we find that the inclusion of indomain data only for semi-supervised learning performs slightly better than the use of transverse domain data, so reducing the amount of in-domain data is detrimental to performance."}, {"heading": "9 Acknowledgments", "text": "This research was supported by the NSF (IIS 1616112), the Allen Institute for AI (66-9175), the Allen Distinguished Investigator Award and gifts from Google, Samsung and Bloomberg. We thank the anonymous critics for their helpful comments."}], "references": [{"title": "Coherent citation-based summarization of scientific papers", "author": ["Amjad Abu-Jbara", "Dragomir Radev."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1. Association", "citeRegEx": "Abu.Jbara and Radev.,? 2011", "shortCiteRegEx": "Abu.Jbara and Radev.", "year": 2011}, {"title": "Graphbased semi-supervised conditional random fields for spoken language understanding using unaligned data", "author": ["Mohammad Aliannejadi", "Masoud Kiaeeha", "Shahram Khadivi", "Saeed Shiry Ghidary."], "venue": "Australasian Language Technology Associ-", "citeRegEx": "Aliannejadi et al\\.,? 2014", "shortCiteRegEx": "Aliannejadi et al\\.", "year": 2014}, {"title": "Towards a computational history of the ACL", "author": ["Ashton Anderson", "Dan McFarland", "Dan Jurafsky"], "venue": null, "citeRegEx": "Anderson et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Anderson et al\\.", "year": 2012}, {"title": "Contextenhanced citation sentiment detection", "author": ["Awais Athar", "Simone Teufel."], "venue": "Proceedings of the 2012 conference of the North American chapter of the Association for Computational Linguistics: Human language technologies. Associa-", "citeRegEx": "Athar and Teufel.,? 2012a", "shortCiteRegEx": "Athar and Teufel.", "year": 2012}, {"title": "Detection of implicit citations for sentiment detection", "author": ["Awais Athar", "Simone Teufel."], "venue": "Proceedings of the Workshop on Detecting Structure in Scholarly Discourse. Association for Computational Linguistics, pages 18\u201326.", "citeRegEx": "Athar and Teufel.,? 2012b", "shortCiteRegEx": "Athar and Teufel.", "year": 2012}, {"title": "Semeval 2017 task 10: ScienceIE - extracting keyphrases and relations from scientific publications", "author": ["Isabelle Augenstein", "Mrinal Das", "Sebastian Riedel", "Lakshmi Vikraman", "Andrew McCallum."], "venue": "Proceedings of SemEval .", "citeRegEx": "Augenstein et al\\.,? 2017", "shortCiteRegEx": "Augenstein et al\\.", "year": 2017}, {"title": "Multitask learning of keyphrase boundary classification", "author": ["Isabelle Augenstein", "Anders S\u00f8gaard."], "venue": "arXiv preprint arXiv:1704.00514.", "citeRegEx": "Augenstein and S\u00f8gaard.,? 2017", "shortCiteRegEx": "Augenstein and S\u00f8gaard.", "year": 2017}, {"title": "Improved transition-based parsing by modeling characters instead of words with LSTMs", "author": ["Miguel Ballesteros", "Chris Dyer", "Noah A Smith."], "venue": "EMNLP.", "citeRegEx": "Ballesteros et al\\.,? 2015", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2015}, {"title": "The ACL anthology reference corpus: A reference dataset for bibliographic research", "author": ["Steven Bird", "Robert Dale", "Bonnie J Dorr", "Bryan R Gibson", "Mark Thomas Joseph", "Min-Yen Kan", "Dongwon Lee", "Brett Powley", "Dragomir R Radev", "Yee Fan Tan"], "venue": null, "citeRegEx": "Bird et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bird et al\\.", "year": 2008}, {"title": "Named entity recognition with bidirectional lstm-cnns", "author": ["Jason PC Chiu", "Eric Nichols."], "venue": "TACL.", "citeRegEx": "Chiu and Nichols.,? 2016", "shortCiteRegEx": "Chiu and Nichols.", "year": 2016}, {"title": "Unsupervised models for named entity classification", "author": ["Michael Collins", "Yoram Singer."], "venue": "Proceedings of the joint SIGDAT conference on empirical methods in natural language processing and very large corpora. Citeseer, pages 100\u2013110.", "citeRegEx": "Collins and Singer.,? 1999", "shortCiteRegEx": "Collins and Singer.", "year": 1999}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research 12(Aug):2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Semi-supervised sequence learning", "author": ["Andrew M Dai", "Quoc V Le."], "venue": "Advances in Neural Information Processing Systems. pages 3079\u20133087.", "citeRegEx": "Dai and Le.,? 2015", "shortCiteRegEx": "Dai and Le.", "year": 2015}, {"title": "Extracting and matching authors and affiliations in scholarly documents", "author": ["Huy Hoang Nhat Do", "Muthu Kumar Chandrasekaran", "Philip S Cho", "Min Yen Kan."], "venue": "Proceedings of the 13th ACM/IEEECS joint conference on Digital libraries. ACM,", "citeRegEx": "Do et al\\.,? 2013", "shortCiteRegEx": "Do et al\\.", "year": 2013}, {"title": "Semantic annotation of the ACL anthology corpus for the automatic analysis of scientific literature", "author": ["Kata Gabor", "Haifa Zargayouna", "Davide Buscaldi", "Isabelle Tellier", "Thierry Charnois."], "venue": "Proceedings of the Tenth International Conference on", "citeRegEx": "Gabor et al\\.,? 2016", "shortCiteRegEx": "Gabor et al\\.", "year": 2016}, {"title": "Analyzing the dynamics of research by extracting key aspects of scientific papers", "author": ["Sonal Gupta", "Christopher D Manning."], "venue": "IJCNLP. pages 1\u20139.", "citeRegEx": "Gupta and Manning.,? 2011", "shortCiteRegEx": "Gupta and Manning.", "year": 2011}, {"title": "Driver prediction to improve interaction with in-vehicle hmi", "author": ["Bret Harsham", "Shinji Watanabe", "Alan Esenther", "John Hershey", "Jonathan Le Roux", "Yi Luan", "Daniel Nikovski", "Vamsi Potluru."], "venue": "Proc. Workshop on Digital Signal Processing for In-", "citeRegEx": "Harsham et al\\.,? 2015", "shortCiteRegEx": "Harsham et al\\.", "year": 2015}, {"title": "Bidirectional LSTM-CRF models for sequence tagging", "author": ["Zhiheng Huang", "Wei Xu", "Kai Yu."], "venue": "arXiv preprint arXiv:1508.01991.", "citeRegEx": "Huang et al\\.,? 2015", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "The computational linguistics summarization pilot", "author": ["Kokil Jaidka", "Muthu Kumar Chandrasekaran", "Beatriz Fisas Elizalde", "Rahul Jha", "Christopher Jones", "Min-Yen Kan", "Ankur Khanna", "Diego Molla-Aliod", "Dragomir R Radev", "Francesco Ronzano"], "venue": null, "citeRegEx": "Jaidka et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jaidka et al\\.", "year": 2014}, {"title": "Structures and statistics of citation networks", "author": ["Miray Kas."], "venue": "Technical report, DTIC Document.", "citeRegEx": "Kas.,? 2011", "shortCiteRegEx": "Kas.", "year": 2011}, {"title": "Weakly supervised slot tagging with partially labeled sequences from web search click logs", "author": ["Young-Bum Kim", "Minwoo Jeong", "Karl Stratos", "Ruhi Sarikaya."], "venue": "HLT-NAACL. pages 84\u201392.", "citeRegEx": "Kim et al\\.,? 2015", "shortCiteRegEx": "Kim et al\\.", "year": 2015}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John Lafferty", "Andrew McCallum", "Fernando Pereira"], "venue": "In Proceedings of the eighteenth international conference on machine learning, ICML", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Neural architectures for named entity recognition", "author": ["Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer."], "venue": "NAACL.", "citeRegEx": "Lample et al\\.,? 2016", "shortCiteRegEx": "Lample et al\\.", "year": 2016}, {"title": "Recognition of stance strength and polarity in spontaneous speech", "author": ["Gina-Anne Levow", "Valerie Freeman", "Alena Hrynkevich", "Mari Ostendorf", "Richard Wright", "Julian Chan", "Yi Luan", "Trang Tran."], "venue": "Spoken Language Technology Workshop (SLT),", "citeRegEx": "Levow et al\\.,? 2014", "shortCiteRegEx": "Levow et al\\.", "year": 2014}, {"title": "Dependencybased word embeddings", "author": ["Omer Levy", "Yoav Goldberg."], "venue": "ACL. pages 302\u2013308.", "citeRegEx": "Levy and Goldberg.,? 2014", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "Graph-based semi-supervised learning for phone and segment classification", "author": ["Yuzong Liu", "Katrin Kirchhoff."], "venue": "Proceedings of Annual Conference of the International Speech Communication Association (Interspeech).", "citeRegEx": "Liu and Kirchhoff.,? 2013", "shortCiteRegEx": "Liu and Kirchhoff.", "year": 2013}, {"title": "Graph-based semi-supervised acoustic modeling in DNN-based speech recognition", "author": ["Yuzong Liu", "Katrin Kirchhoff."], "venue": "IEEE SLT .", "citeRegEx": "Liu and Kirchhoff.,? 2014", "shortCiteRegEx": "Liu and Kirchhoff.", "year": 2014}, {"title": "Acoustic modeling with neural graph embeddings", "author": ["Yuzong Liu", "Katrin Kirchhoff."], "venue": "IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU).", "citeRegEx": "Liu and Kirchhoff.,? 2015", "shortCiteRegEx": "Liu and Kirchhoff.", "year": 2015}, {"title": "Graph-based semisupervised learning for acoustic modeling in automatic speech recognition", "author": ["Yuzong Liu", "Katrin Kirchhoff."], "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing 24(11):1946\u20131956.", "citeRegEx": "Liu and Kirchhoff.,? 2016a", "shortCiteRegEx": "Liu and Kirchhoff.", "year": 2016}, {"title": "Novel frontend features based on neural graph embeddings for DNN-HMM and LSTM-CTC acoustic modeling", "author": ["Yuzong Liu", "Katrin Kirchhoff."], "venue": "Proceedings of Annual Conference of the International Speech Communication Association (Inter-", "citeRegEx": "Liu and Kirchhoff.,? 2016b", "shortCiteRegEx": "Liu and Kirchhoff.", "year": 2016}, {"title": "Multiplicative representations for unsupervised semantic role induction", "author": ["Yi Luan", "Yangfeng Ji", "Hannaneh Hajishirzi", "Boyang Li."], "venue": "The 54th Annual Meeting of the Association for Computational Linguistics. page 118.", "citeRegEx": "Luan et al\\.,? 2016a", "shortCiteRegEx": "Luan et al\\.", "year": 2016}, {"title": "Lstm based conversation models", "author": ["Yi Luan", "Yangfeng Ji", "Mari Ostendorf."], "venue": "arXiv preprint arXiv:1603.09457.", "citeRegEx": "Luan et al\\.,? 2016b", "shortCiteRegEx": "Luan et al\\.", "year": 2016}, {"title": "Semisupervised noise dictionary adaptation for exemplarbased noise robust speech recognition", "author": ["Yi Luan", "Daisuke Saito", "Yosuke Kashiwagi", "Nobuaki Minematsu", "Keikichi Hirose."], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE", "citeRegEx": "Luan et al\\.,? 2014a", "shortCiteRegEx": "Luan et al\\.", "year": 2014}, {"title": "Performance improvement of automatic pronunciation assessment in a noisy classroom", "author": ["Yi Luan", "Masayuki Suzuki", "Yutaka Yamauchi", "Nobuaki Minematsu", "Shuhei Kato", "Keikichi Hirose."], "venue": "Spoken Language Technology Workshop (SLT), 2012", "citeRegEx": "Luan et al\\.,? 2012", "shortCiteRegEx": "Luan et al\\.", "year": 2012}, {"title": "Efficient learning for spoken language understanding tasks with word embedding based pre-training", "author": ["Yi Luan", "Shinji Watanabe", "Bret Harsham."], "venue": "INTERSPEECH. Citeseer, pages 1398\u20131402.", "citeRegEx": "Luan et al\\.,? 2015", "shortCiteRegEx": "Luan et al\\.", "year": 2015}, {"title": "Relating automatic vowel space estimates to talker intelligibility", "author": ["Yi Luan", "Richard Wright", "Mari Ostendorf", "GinaAnne Levow."], "venue": "Fifteenth Annual Conference of the International Speech Communication Association.", "citeRegEx": "Luan et al\\.,? 2014b", "shortCiteRegEx": "Luan et al\\.", "year": 2014}, {"title": "End-to-end sequence labeling via bi-directional LSTM-CNNsCRF", "author": ["Xuezhe Ma", "Eduard Hovy."], "venue": "ACL.", "citeRegEx": "Ma and Hovy.,? 2016", "shortCiteRegEx": "Ma and Hovy.", "year": 2016}, {"title": "The stanford CoreNLP natural language processing toolkit", "author": ["Christopher D Manning", "Mihai Surdeanu", "John Bauer", "Jenny Rose Finkel", "Steven Bethard", "David McClosky."], "venue": "ACL (System Demonstrations). pages 55\u201360.", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Named entity recognition for chinese social media with jointly trained embeddings", "author": ["Nanyun Peng", "Mark Dredze."], "venue": "EMNLP. pages 548\u2013554.", "citeRegEx": "Peng and Dredze.,? 2015", "shortCiteRegEx": "Peng and Dredze.", "year": 2015}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP. volume 14, pages 1532\u2013 1543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "The acl rd-tec 2.0: A language resource for evaluating term extraction and entity recognition methods", "author": ["Behrang QasemiZadeh", "Anne-Kathrin Schumann"], "venue": null, "citeRegEx": "QasemiZadeh and Schumann.,? \\Q2012\\E", "shortCiteRegEx": "QasemiZadeh and Schumann.", "year": 2012}, {"title": "Discovering factions in the computational linguistics community", "author": ["Yanchuan Sim", "Noah A Smith", "David A Smith."], "venue": "Proceedings of the ACL2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Lin-", "citeRegEx": "Sim et al\\.,? 2012", "shortCiteRegEx": "Sim et al\\.", "year": 2012}, {"title": "Semi-supervised learning with measure propagation", "author": ["Amarnag Subramanya", "Jeff Bilmes."], "venue": "Journal of Machine Learning Research 12(Nov):3311\u20133370.", "citeRegEx": "Subramanya and Bilmes.,? 2011", "shortCiteRegEx": "Subramanya and Bilmes.", "year": 2011}, {"title": "Efficient graph-based semisupervised learning of structured tagging models", "author": ["Amarnag Subramanya", "Slav Petrov", "Fernando Pereira."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. Associa-", "citeRegEx": "Subramanya et al\\.,? 2010", "shortCiteRegEx": "Subramanya et al\\.", "year": 2010}, {"title": "Concept-based analysis of scientific literature", "author": ["Chen-Tse Tsai", "Gourab Kundu", "Dan Roth."], "venue": "Proceedings of the 22nd ACM international conference on Conference on information & knowledge management. ACM, pages 1733\u20131738.", "citeRegEx": "Tsai et al\\.,? 2013", "shortCiteRegEx": "Tsai et al\\.", "year": 2013}, {"title": "He said, she said: Gender in the ACL anthology", "author": ["Adam Vogel", "Dan Jurafsky."], "venue": "Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Linguistics, pages 33\u201341.", "citeRegEx": "Vogel and Jurafsky.,? 2012", "shortCiteRegEx": "Vogel and Jurafsky.", "year": 2012}], "referenceMentions": [{"referenceID": 15, "context": "Previous research has focused on unsupervised approaches such as bootstrapping (Gupta and Manning, 2011; Tsai et al., 2013), where hand-designed templates are used to extract scientific keyphrases, and more templates are added through bootstrapping.", "startOffset": 79, "endOffset": 123}, {"referenceID": 45, "context": "Previous research has focused on unsupervised approaches such as bootstrapping (Gupta and Manning, 2011; Tsai et al., 2013), where hand-designed templates are used to extract scientific keyphrases, and more templates are added through bootstrapping.", "startOffset": 79, "endOffset": 123}, {"referenceID": 5, "context": "Very recently a new challenge on Scientific Information Extraction (ScienceIE) (Augenstein et al., 2017)1 provides a dataset consisting of 500", "startOffset": 79, "endOffset": 104}, {"referenceID": 19, "context": "Past research has addressed citation sentiment (Athar and Teufel, 2012b,a), citation networks (Kas, 2011; Gabor et al., 2016; Sim et al., 2012; Do et al., 2013; Jaidka et al., 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al.", "startOffset": 94, "endOffset": 181}, {"referenceID": 14, "context": "Past research has addressed citation sentiment (Athar and Teufel, 2012b,a), citation networks (Kas, 2011; Gabor et al., 2016; Sim et al., 2012; Do et al., 2013; Jaidka et al., 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al.", "startOffset": 94, "endOffset": 181}, {"referenceID": 42, "context": "Past research has addressed citation sentiment (Athar and Teufel, 2012b,a), citation networks (Kas, 2011; Gabor et al., 2016; Sim et al., 2012; Do et al., 2013; Jaidka et al., 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al.", "startOffset": 94, "endOffset": 181}, {"referenceID": 13, "context": "Past research has addressed citation sentiment (Athar and Teufel, 2012b,a), citation networks (Kas, 2011; Gabor et al., 2016; Sim et al., 2012; Do et al., 2013; Jaidka et al., 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al.", "startOffset": 94, "endOffset": 181}, {"referenceID": 18, "context": "Past research has addressed citation sentiment (Athar and Teufel, 2012b,a), citation networks (Kas, 2011; Gabor et al., 2016; Sim et al., 2012; Do et al., 2013; Jaidka et al., 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al.", "startOffset": 94, "endOffset": 181}, {"referenceID": 0, "context": ", 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al.", "startOffset": 23, "endOffset": 50}, {"referenceID": 46, "context": ", 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al., 2012; Luan et al., 2012, 2014b; Levow et al., 2014).", "startOffset": 91, "endOffset": 186}, {"referenceID": 2, "context": ", 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al., 2012; Luan et al., 2012, 2014b; Levow et al., 2014).", "startOffset": 91, "endOffset": 186}, {"referenceID": 23, "context": ", 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al., 2012; Luan et al., 2012, 2014b; Levow et al., 2014).", "startOffset": 91, "endOffset": 186}, {"referenceID": 8, "context": "Gupta and Manning (2011) first proposed a task that defines scientific terms for 474 abstracts from the ACL anthologhy (Bird et al., 2008) into three aspects: domain, technique and focus and apply templatebased bootstrapping to tackle the problem.", "startOffset": 119, "endOffset": 138}, {"referenceID": 10, "context": "(2013) improve the performance by introducing hand-designed features from NER (Collins and Singer, 1999) to the bootstrapping framework.", "startOffset": 78, "endOffset": 104}, {"referenceID": 0, "context": ", 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al., 2012; Luan et al., 2012, 2014b; Levow et al., 2014). However, due to scarce hand-annotated data resources, previous work on information extraction (IE) for scientific literature is very limited. Gupta and Manning (2011) first proposed a task that defines scientific terms for 474 abstracts from the ACL anthologhy (Bird et al.", "startOffset": 24, "endOffset": 355}, {"referenceID": 0, "context": ", 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al., 2012; Luan et al., 2012, 2014b; Levow et al., 2014). However, due to scarce hand-annotated data resources, previous work on information extraction (IE) for scientific literature is very limited. Gupta and Manning (2011) first proposed a task that defines scientific terms for 474 abstracts from the ACL anthologhy (Bird et al., 2008) into three aspects: domain, technique and focus and apply templatebased bootstrapping to tackle the problem. Based on this study, Tsai et al. (2013) improve the performance by introducing hand-designed features from NER (Collins and Singer, 1999) to the bootstrapping framework.", "startOffset": 24, "endOffset": 618}, {"referenceID": 0, "context": ", 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al., 2012; Luan et al., 2012, 2014b; Levow et al., 2014). However, due to scarce hand-annotated data resources, previous work on information extraction (IE) for scientific literature is very limited. Gupta and Manning (2011) first proposed a task that defines scientific terms for 474 abstracts from the ACL anthologhy (Bird et al., 2008) into three aspects: domain, technique and focus and apply templatebased bootstrapping to tackle the problem. Based on this study, Tsai et al. (2013) improve the performance by introducing hand-designed features from NER (Collins and Singer, 1999) to the bootstrapping framework. QasemiZadeh and Schumann (2012) compile a dataset of scientific terms into 7 fine-grained categories for 171 abstracts of ACL anothology.", "startOffset": 24, "endOffset": 780}, {"referenceID": 0, "context": ", 2014), summarization (Abu-Jbara and Radev, 2011) and some analysis of research community (Vogel and Jurafsky, 2012; Anderson et al., 2012; Luan et al., 2012, 2014b; Levow et al., 2014). However, due to scarce hand-annotated data resources, previous work on information extraction (IE) for scientific literature is very limited. Gupta and Manning (2011) first proposed a task that defines scientific terms for 474 abstracts from the ACL anthologhy (Bird et al., 2008) into three aspects: domain, technique and focus and apply templatebased bootstrapping to tackle the problem. Based on this study, Tsai et al. (2013) improve the performance by introducing hand-designed features from NER (Collins and Singer, 1999) to the bootstrapping framework. QasemiZadeh and Schumann (2012) compile a dataset of scientific terms into 7 fine-grained categories for 171 abstracts of ACL anothology. Similar to our work, very recently Augenstein and S\u00f8gaard (2017) also evaluated on ScienceIE dataset, but use multi-task learning to improve the performance of a supervised neural approach.", "startOffset": 24, "endOffset": 951}, {"referenceID": 11, "context": "For example, Collobert et al. (2011) use a CNN over", "startOffset": 13, "endOffset": 37}, {"referenceID": 17, "context": "Huang et al. (2015) use hand-crafted features with LSTMs to improve performance.", "startOffset": 0, "endOffset": 20}, {"referenceID": 38, "context": ", 2015) or initializing the model with pre-trained word embeddings (Mikolov et al., 2013; Pennington et al., 2014; Levy and Goldberg, 2014; Luan et al., 2016b, 2015, 2016a).", "startOffset": 67, "endOffset": 172}, {"referenceID": 40, "context": ", 2015) or initializing the model with pre-trained word embeddings (Mikolov et al., 2013; Pennington et al., 2014; Levy and Goldberg, 2014; Luan et al., 2016b, 2015, 2016a).", "startOffset": 67, "endOffset": 172}, {"referenceID": 24, "context": ", 2015) or initializing the model with pre-trained word embeddings (Mikolov et al., 2013; Pennington et al., 2014; Levy and Goldberg, 2014; Luan et al., 2016b, 2015, 2016a).", "startOffset": 67, "endOffset": 172}, {"referenceID": 20, "context": "powerful methods including graph-based semisupervision (Subramanya and Bilmes, 2011; Liu and Kirchhoff, 2013, 2015, 2016a,b) and a method for leveraging partially labeled data (Kim et al., 2015).", "startOffset": 176, "endOffset": 194}, {"referenceID": 22, "context": "We introduce an end-to-end model to categorize scientific keyphrases, building on a neural named entity recognition model (Lample et al., 2016) and adding a feature-based embedding.", "startOffset": 122, "endOffset": 143}, {"referenceID": 21, "context": "Therefore, instead of making independent tagging decisions for each output, we model them jointly using conditional random field (Lafferty et al., 2001).", "startOffset": 129, "endOffset": 152}, {"referenceID": 26, "context": "Label Propagation We use prior-regularized measure propagation (Liu and Kirchhoff, 2014; Subramanya and Bilmes, 2011) to propagate labels from the annotated data to their neighbors in the graph.", "startOffset": 63, "endOffset": 117}, {"referenceID": 43, "context": "Label Propagation We use prior-regularized measure propagation (Liu and Kirchhoff, 2014; Subramanya and Bilmes, 2011) to propagate labels from the annotated data to their neighbors in the graph.", "startOffset": 63, "endOffset": 117}, {"referenceID": 44, "context": "The first strategy (called GRAPHINTERP) is the commonly used approach (Subramanya et al., 2010; Aliannejadi et al., 2014) that interpolates the smoothed posterior {q} with CRF marginals p:", "startOffset": 70, "endOffset": 121}, {"referenceID": 1, "context": "The first strategy (called GRAPHINTERP) is the commonly used approach (Subramanya et al., 2010; Aliannejadi et al., 2014) that interpolates the smoothed posterior {q} with CRF marginals p:", "startOffset": 70, "endOffset": 121}, {"referenceID": 20, "context": "A similar idea has been previously used in treating partially labeled data (Kim et al., 2015).", "startOffset": 75, "endOffset": 93}, {"referenceID": 15, "context": "The first baseline (Gupta and Manning, 2011) is an unsupervised method to extract keyphrases by initially using seed patterns in a dependency tree, and then adding to seed patterns through bootstrap-", "startOffset": 19, "endOffset": 44}, {"referenceID": 45, "context": "The second baseline (Tsai et al., 2013) improves the work of Gupta and Manning (2011) by adding Named Entity Features and use different set of seed patterns.", "startOffset": 20, "endOffset": 39}, {"referenceID": 15, "context": ", 2013) improves the work of Gupta and Manning (2011) by adding Named Entity Features and use different set of seed patterns.", "startOffset": 29, "endOffset": 54}, {"referenceID": 37, "context": "We use Stanford CoreNLP (Manning et al., 2014) tokenizer to tokenize words.", "startOffset": 24, "endOffset": 46}, {"referenceID": 5, "context": "Table 1 reports the results of our neural sequence tagging model NN-CRF in both supervised and semi-supervised learning (ULM and graph-based), and compares them with the baselines and the state-of-the-art (best SemEval System (Augenstein et al., 2017)).", "startOffset": 226, "endOffset": 251}], "year": 2017, "abstractText": "This paper addresses the problem of extracting keyphrases from scientific articles and categorizing them as corresponding to a task, process, or material. We cast the problem as sequence tagging and introduce semi-supervised methods to a neural tagging model, which builds on recent advances in named entity recognition. Since annotated training data is scarce in this domain, we introduce a graph-based semi-supervised algorithm together with a data selection scheme to leverage unannotated articles. Both inductive and transductive semi-supervised learning strategies outperform state-of-the-art information extraction performance on the 2017 SemEval Task 10 ScienceIE task.", "creator": "LaTeX with hyperref package"}}}