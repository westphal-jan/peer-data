{"id": "1708.08484", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Aug-2017", "title": "Joint Syntacto-Discourse Parsing and the Syntacto-Discourse Treebank", "abstract": "Discourse parsing has long been treated as a stand-alone problem independent from constituency or dependency parsing. Most attempts at this problem are pipelined rather than end-to-end, sophisticated, and not self-contained: they assume gold-standard text segmentations (Elementary Discourse Units), and use external parsers for syntactic features. In this paper we propose the first end-to-end discourse parser that jointly parses in both syntax and discourse levels, as well as the first syntacto-discourse treebank by integrating the Penn Treebank with the RST Treebank. Built upon our recent span-based constituency parser, this joint syntacto-discourse parser requires no preprocessing whatsoever (such as segmentation or feature extraction), achieves the state-of-the-art end-to-end discourse parsing accuracy.", "histories": [["v1", "Mon, 28 Aug 2017 18:57:50 GMT  (60kb,D)", "http://arxiv.org/abs/1708.08484v1", "Accepted at EMNLP 2017"]], "COMMENTS": "Accepted at EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kai zhao", "liang huang 0001"], "accepted": true, "id": "1708.08484"}, "pdf": {"name": "1708.08484.pdf", "metadata": {"source": "CRF", "title": "Joint Syntacto-Discourse Parsing and the Syntacto-Discourse Treebank", "authors": ["Kai Zhao", "Liang Huang"], "emails": ["liang.huang.sh}@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "Distinguishing the semantic relationships between segments in a document can be useful for many high-level NLP tasks, such as summary (Louis et al., 2010; Yoshida et al., 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al., 2009; Bhatia et al., 2015), questioning (Ferrucci et al., 2010; Jansen et al., 2014), and evaluation of text quality (Tetreault et al., 2013; Li and Jurafsky, 2016).There has been a variety of research on discourse sparing (Marcu, 2000a; Soricut and Marcu al., 2003; Pardo and Nunes, 2008; Hernault et al., We assume that the source code and common trust bank are available at https: / / github.com / josydipa."}, {"heading": "2 Combined Representation & Treebank", "text": "We first briefly examine the discourse structures in Rhetorical Structure Theory (Mann and Thompson, 1988) and then discuss how discourse and constituency trees can be standardized, leading to our syntakto-discourse tree bank PTB-RST."}, {"heading": "2.1 Review: RST Discourse Structures", "text": "In an RST discourse tree, there are two types of branching: most internal tree nodes are ebinal branching, with a nuclear child containing the semantic core meaning of the current node, and a satellite child semantically containing the nucleus. Like dependency labels, there is a relationship between each satellite nuclear pair, such as \"background\" or \"purpose.\" Figure 1 (a) shows an example of an RST tree. There are also non-binary branched internal nodes whose children are conjunctions, such as a \"list\" of semantically similar EDUs (which are all nucleus nodes); see Figure 2 (a) for an example."}, {"heading": "2.2 Syntacto-Discourse Representation", "text": "It is generally accepted that lower-level lexical and syntactical information can significantly contribute to determining both the boundaries of TB (i.e., discourse segmentation) (Bach et al., 2012) and the semantic relationships between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015). While these earlier approaches rely on pre-formed tools to provide both EDU segmentation and intra-EDU syntactic parse trees, we instead propose to directly determine lower-level segmentation, the syntactic parses, and the highest-level discourses are parsed with a single common parser. This parser is trained on the combined trees of constituencies and discourse structures."}, {"heading": "2.3 Joint PTB-RST Treebank", "text": "With the conversion strategy described above, we build the first synactive discourse tree trunk common to Penn Treebank and RST Treebank. This PTB-RST tree trunk is released as a tool for generating the common trees based on Penn Treebank and RST Treebank data. When aligning between the RST trees and the PTB trees, we only keep the common parts of the two trees. We follow the standard training / test split of the RST trunk. In the training set, there are 347 common trees with a total of 17,837 tokens, and the discourse lengths range from 30 to 2,199 tokens. In the test set, there are 38 common trees with a total of 4,819 tokens, and the lengths vary from 45 to 2,607. Figure 3 shows the distribution of the discourse lengths over the entire dataset, which averages about twice the length of the PTB set, but the longest are about 10x the lengths in the trunk."}, {"heading": "3 Joint Syntacto-Discourse Parsing", "text": "Given the combined syntakto-discourse tree base, we now propose a common parser that can perform end-to-end discourse segmentation and analysis."}, {"heading": "3.1 Extending Span-based Parsing", "text": "As mentioned above, the input sequences are much longer than the PTB analysis, so we choose linear time analysis by adapting a popular, greedy constituency parser, the span-based constituency parser of Cross and Huang (2016).As in span-based parsing, we maintain a stack of span at each step. Note that in conventional incremental parsing the stack subdivisions 1111Comb <... iSome text and the symbol or scaled1j >: (c, t) <... iSome text and the symbol or the scaled1k: some text and the symbol or the scaled1k: (c + sccomb (i, k, j), t), labelX < iSome text and the symbol or scaled1k: (c, t) < (c, t) < (ialm) < iSome text and the symbol or scaledm: (c, t) < <"}, {"heading": "3.2 Recurrent Neural Models and Training", "text": "The scoring functions in the deductive system (Figure 4) are calculated using an underlying neural model similar to the bidirectional LSTM model in Cross and Huang (2016), which is evaluated using interface characteristics. Again, it is important to note that the characteristics do not present any discourse or syntactic tree structures.During the decoding period, a document is first passed into a two-layer bidirectional LSTM model, then the output is linked to each text position of the two layers of the bidirectional LSTMs as position characteristics.The spans in each parsing step can be displayed as feature vectors at the boundaries.The tension characteristics are then passed into fully connected networks with Softmax to calculate the likelihood of performing the corresponding action or marking the corresponding label.We use the \"Training with Exploration\" strategy (Goldberg and Nivre, 2013) and the dynamic ocellum mechanism that can be correctly described in Huang (2016)."}, {"heading": "4 Empirical Results", "text": "We use the tree base described in section 2 for empirical evaluation. We randomly select 30 documents from the training set as a development set.We adjust the hyperparameters of the neural model to the amount of development. For most hyperparameters, which we balance with the same values proposed by Cross and Huang (2016).To alleviate the overfit problem for training on the relatively small RST tree base, we use a drop-out of 0.5.A certain hyperparameter is that we use a value \u03b2 to follow the chances between training after exploration (i.e., the best action chosen by the neural model) and the correct path provided by the dynamic oracle. We find that \u03b2 = 0.8, i.e., after the dynamic oracle with a 0.8 chance, achieves the best performance. One explanation for this high probability of following the oracle is that our combined trees are significantly larger than the choice parameters."}, {"heading": "5 Conclusion", "text": "We have introduced a neural incremental parser that can be analyzed at both constituency and discourse levels. To the best of our knowledge, this is the first end-to-end parser for discourse-sparing tasks. Our parser achieves the most advanced performance in end-to-end parsing and, unlike previous approaches, requires little pre-processing."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for helpful comments and Mingbo Ma, James Cross and Dezhong Deng for suggestions. This work is partially supported by NSF IIS-1656051, DARPA N66001-17-2-4030 (XAI), a Google Faculty Research Award and HP."}], "references": [{"title": "A reranking model for discourse segmentation using subtree features", "author": ["Ngo Xuan Bach", "Nguyen Le Minh", "Akira Shimazu."], "venue": "Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 160\u2013168. Asso-", "citeRegEx": "Bach et al\\.,? 2012", "shortCiteRegEx": "Bach et al\\.", "year": 2012}, {"title": "Better document-level sentiment analysis from rst discourse parsing", "author": ["Parminder Bhatia", "Yangfeng Ji", "Jacob Eisenstein."], "venue": "arXiv preprint arXiv:1509.01599.", "citeRegEx": "Bhatia et al\\.,? 2015", "shortCiteRegEx": "Bhatia et al\\.", "year": 2015}, {"title": "Incremental parsing with minimal features using bi-directional lstm", "author": ["James Cross", "Liang Huang."], "venue": "arXiv preprint arXiv:1606.06406.", "citeRegEx": "Cross and Huang.,? 2016", "shortCiteRegEx": "Cross and Huang.", "year": 2016}, {"title": "A symbolic approach for automatic detection of nuclearity and rhetorical relations among intra-sentence discourse segments in spanish", "author": ["Iria da Cunha", "Eric SanJuan", "Juan-Manuel TorresMoreno", "M Teresa Cabr\u00e9", "Gerardo Sierra."], "venue": "In-", "citeRegEx": "Cunha et al\\.,? 2012", "shortCiteRegEx": "Cunha et al\\.", "year": 2012}, {"title": "A lineartime bottom-up discourse parser with constraints and post-editing", "author": ["Vanessa Wei Feng", "Graeme Hirst."], "venue": "ACL (1), pages 511\u2013521.", "citeRegEx": "Feng and Hirst.,? 2014", "shortCiteRegEx": "Feng and Hirst.", "year": 2014}, {"title": "Building watson: An overview of the deepqa project", "author": ["David Ferrucci", "Eric Brown", "Jennifer Chu-Carroll", "James Fan", "David Gondek", "Aditya A Kalyanpur", "Adam Lally", "J William Murdock", "Eric Nyberg", "John Prager"], "venue": "AI magazine,", "citeRegEx": "Ferrucci et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ferrucci et al\\.", "year": 2010}, {"title": "Training deterministic parsers with non-deterministic oracles", "author": ["Yoav Goldberg", "Joakim Nivre."], "venue": "Transactions of the association for Computational Linguistics, 1:403\u2013414.", "citeRegEx": "Goldberg and Nivre.,? 2013", "shortCiteRegEx": "Goldberg and Nivre.", "year": 2013}, {"title": "Fast rhetorical structure theory discourse parsing", "author": ["Michael Heilman", "Kenji Sagae."], "venue": "arXiv preprint arXiv:1505.02425.", "citeRegEx": "Heilman and Sagae.,? 2015", "shortCiteRegEx": "Heilman and Sagae.", "year": 2015}, {"title": "Hilda: a discourse parser using support vector machine classification", "author": ["Hugo Hernault", "Helmut Prendinger", "David A DuVerle", "Mitsuru Ishizuka", "Tim Paek."], "venue": "Dialogue and Discourse, 1(3):1\u201333.", "citeRegEx": "Hernault et al\\.,? 2010", "shortCiteRegEx": "Hernault et al\\.", "year": 2010}, {"title": "Discourse complements lexical semantics for nonfactoid answer reranking", "author": ["Peter Jansen", "Mihai Surdeanu", "Peter Clark."], "venue": "ACL (1), pages 977\u2013 986.", "citeRegEx": "Jansen et al\\.,? 2014", "shortCiteRegEx": "Jansen et al\\.", "year": 2014}, {"title": "Representation learning for text-level discourse parsing", "author": ["Yangfeng Ji", "Jacob Eisenstein."], "venue": "ACL (1), pages 13\u201324.", "citeRegEx": "Ji and Eisenstein.,? 2014", "shortCiteRegEx": "Ji and Eisenstein.", "year": 2014}, {"title": "Discriminative reranking of discourse parses using tree kernels", "author": ["Shafiq Joty", "Alessandro Moschitti."], "venue": "a) A, 4(5):6.", "citeRegEx": "Joty and Moschitti.,? 2014", "shortCiteRegEx": "Joty and Moschitti.", "year": 2014}, {"title": "Combining intra-and multisentential rhetorical parsing for document-level discourse analysis", "author": ["Shafiq R Joty", "Giuseppe Carenini", "Raymond T Ng", "Yashar Mehdad."], "venue": "ACL (1), pages 486\u2013496.", "citeRegEx": "Joty et al\\.,? 2013", "shortCiteRegEx": "Joty et al\\.", "year": 2013}, {"title": "Neural net models for open-domain discourse coherence", "author": ["Jiwei Li", "Dan Jurafsky."], "venue": "arXiv preprint arXiv:1606.01545.", "citeRegEx": "Li and Jurafsky.,? 2016", "shortCiteRegEx": "Li and Jurafsky.", "year": 2016}, {"title": "Recursive deep models for discourse parsing", "author": ["Jiwei Li", "Rumeng Li", "Eduard H Hovy."], "venue": "EMNLP, pages 2061\u20132069.", "citeRegEx": "Li et al\\.,? 2014a", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Text-level discourse dependency parsing", "author": ["Sujian Li", "Liang Wang", "Ziqiang Cao", "Wenjie Li."], "venue": "ACL (1), pages 25\u201335.", "citeRegEx": "Li et al\\.,? 2014b", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Discourse indicators for content selection in summarization", "author": ["Annie Louis", "Aravind Joshi", "Ani Nenkova."], "venue": "Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 147\u2013156. Association for Computa-", "citeRegEx": "Louis et al\\.,? 2010", "shortCiteRegEx": "Louis et al\\.", "year": 2010}, {"title": "Rhetorical structure theory: Toward a functional theory of text organization", "author": ["William C Mann", "Sandra A Thompson."], "venue": "Text-Interdisciplinary Journal for the Study of Discourse, 8(3):243\u2013281.", "citeRegEx": "Mann and Thompson.,? 1988", "shortCiteRegEx": "Mann and Thompson.", "year": 1988}, {"title": "The rhetorical parsing of unrestricted texts: A surface-based approach", "author": ["Daniel Marcu."], "venue": "Computational linguistics, 26(3):395\u2013448.", "citeRegEx": "Marcu.,? 2000a", "shortCiteRegEx": "Marcu.", "year": 2000}, {"title": "The theory and practice of discourse parsing and summarization", "author": ["Daniel Marcu."], "venue": "MIT press.", "citeRegEx": "Marcu.,? 2000b", "shortCiteRegEx": "Marcu.", "year": 2000}, {"title": "Building a large annotated corpus of english: The penn treebank", "author": ["Mitchell P Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini."], "venue": "Computational linguistics, 19(2):313\u2013330.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "On the development and evaluation of a brazilian portuguese discourse parser", "author": ["Thiago Alexandre Salgueiro Pardo", "Maria das Gra\u00e7as Volpe Nunes."], "venue": "Revista de Inform\u00e1tica Te\u00f3rica e Aplicada, 15(2):43\u201364.", "citeRegEx": "Pardo and Nunes.,? 2008", "shortCiteRegEx": "Pardo and Nunes.", "year": 2008}, {"title": "Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification", "author": ["Swapna Somasundaran", "Galileo Namata", "Janyce Wiebe", "Lise Getoor."], "venue": "Proceedings of the 2009 Conference on Empirical", "citeRegEx": "Somasundaran et al\\.,? 2009", "shortCiteRegEx": "Somasundaran et al\\.", "year": 2009}, {"title": "Sentence level discourse parsing using syntactic and lexical information", "author": ["Radu Soricut", "Daniel Marcu."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language", "citeRegEx": "Soricut and Marcu.,? 2003", "shortCiteRegEx": "Soricut and Marcu.", "year": 2003}, {"title": "Holistic discourse coherence annotation for noisy essay writing", "author": ["ETS Tetreault"], "venue": null, "citeRegEx": "Tetreault,? \\Q2013\\E", "shortCiteRegEx": "Tetreault", "year": 2013}, {"title": "Not all words are created equal: Extracting semantic orientation as a function of adjective relevance", "author": ["Kimberly Voll", "Maite Taboada."], "venue": "Australasian Joint Conference on Artificial Intelligence, pages 337\u2013346. Springer.", "citeRegEx": "Voll and Taboada.,? 2007", "shortCiteRegEx": "Voll and Taboada.", "year": 2007}, {"title": "A two-stage parsing method for text-level discourse analysis", "author": ["Yizhong Wang", "Sujian Li", "Houfeng Wang."], "venue": "Proceedings of ACL.", "citeRegEx": "Wang et al\\.,? 2017", "shortCiteRegEx": "Wang et al\\.", "year": 2017}, {"title": "Dependency-based discourse parser for single-document summarization", "author": ["Yasuhisa Yoshida", "Jun Suzuki", "Tsutomu Hirao", "Masaaki Nagata."], "venue": "EMNLP, pages 1834\u20131839. Citeseer.", "citeRegEx": "Yoshida et al\\.,? 2014", "shortCiteRegEx": "Yoshida et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 16, "context": "Distinguishing the semantic relations between segments in a document can be greatly beneficial to many high-level NLP tasks, such as summarization (Louis et al., 2010; Yoshida et al., 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al.", "startOffset": 147, "endOffset": 189}, {"referenceID": 27, "context": "Distinguishing the semantic relations between segments in a document can be greatly beneficial to many high-level NLP tasks, such as summarization (Louis et al., 2010; Yoshida et al., 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al.", "startOffset": 147, "endOffset": 189}, {"referenceID": 25, "context": ", 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al., 2009; Bhatia et al., 2015), question answering (Ferrucci et al.", "startOffset": 28, "endOffset": 100}, {"referenceID": 22, "context": ", 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al., 2009; Bhatia et al., 2015), question answering (Ferrucci et al.", "startOffset": 28, "endOffset": 100}, {"referenceID": 1, "context": ", 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al., 2009; Bhatia et al., 2015), question answering (Ferrucci et al.", "startOffset": 28, "endOffset": 100}, {"referenceID": 5, "context": ", 2015), question answering (Ferrucci et al., 2010; Jansen et al., 2014), and textual quality evaluation (Tetreault et al.", "startOffset": 28, "endOffset": 72}, {"referenceID": 9, "context": ", 2015), question answering (Ferrucci et al., 2010; Jansen et al., 2014), and textual quality evaluation (Tetreault et al.", "startOffset": 28, "endOffset": 72}, {"referenceID": 13, "context": ", 2014), and textual quality evaluation (Tetreault et al., 2013; Li and Jurafsky, 2016).", "startOffset": 40, "endOffset": 87}, {"referenceID": 18, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 23, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 21, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 12, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 11, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 4, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 10, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 7, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 26, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 1, "context": ", 2009; Bhatia et al., 2015), question answering (Ferrucci et al., 2010; Jansen et al., 2014), and textual quality evaluation (Tetreault et al., 2013; Li and Jurafsky, 2016). There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017). But most of them suffer from the following limitations: 1. pipelined rather than end-to-end: they assume pre-segmented discourse, and worse yet, use gold-standard segmentations, except Hernault et al. (2010);", "startOffset": 8, "endOffset": 851}, {"referenceID": 2, "context": "Our algorithm builds up on the span-based parser (Cross and Huang, 2016); it employs the strong generalization power of bi-directional LSTMs, and parses efficiently and robustly with an extremely simple span-based feature set that does not use any tree structure information.", "startOffset": 49, "endOffset": 72}, {"referenceID": 20, "context": "Using this representation, we build and release a joint treebank based on the Penn Treebank (Marcus et al., 1993) and RST Treebank (Marcu, 2000a,b) (Section 2).", "startOffset": 92, "endOffset": 113}, {"referenceID": 19, "context": "(a) A discourse tree with 3 EDUs (\u2022: nucleas; \u25e6: satellite) in the RST treebank (Marcu, 2000b)", "startOffset": 80, "endOffset": 94}, {"referenceID": 2, "context": "Even though it simultaneously performs constituency parsing, our parser does not use any explicit syntactic feature, nor does it need any binarization of discourse trees, thanks to the powerful span-based framework of Cross and Huang (2016) (Section 3).", "startOffset": 218, "endOffset": 241}, {"referenceID": 17, "context": "We first briefly review the discourse structures in Rhetorical Structure Theory (Mann and Thompson, 1988), and then discuss how to unify discourse and constituency trees, which gives rise to our syntacto-discourse treebank PTB-RST.", "startOffset": 80, "endOffset": 105}, {"referenceID": 0, "context": ", discourse segmentation) (Bach et al., 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al.", "startOffset": 26, "endOffset": 45}, {"referenceID": 23, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 8, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 11, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 4, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 10, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 14, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 7, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 20, "context": "to those constituency trees in the Penn Treebank (Marcus et al., 1993).", "startOffset": 49, "endOffset": 70}, {"referenceID": 19, "context": "Given that the sentences in the RST Treebank (Marcu, 2000b) is a subset of that of PTB, we can always find the corresponding constituency subtrees for each EDU leaf node.", "startOffset": 45, "endOffset": 59}, {"referenceID": 2, "context": "1 Extending Span-based Parsing As mentioned above, the input sequences are substantially longer than PTB parsing, so we choose linear-time parsing, by adapting a popular greedy constituency parser, the span-based constituency parser of Cross and Huang (2016). As in span-based parsing, at each step, we maintain a a stack of spans.", "startOffset": 236, "endOffset": 259}, {"referenceID": 2, "context": "Please refer Cross and Huang (2016) for details.", "startOffset": 13, "endOffset": 36}, {"referenceID": 2, "context": "But different from Cross and Huang (2016), after a structural action, we choose to keep the last branching point k, i.", "startOffset": 19, "endOffset": 42}, {"referenceID": 2, "context": "1 j) to determine the parity of the step and thus no longer need to carry the step z in the state as in Cross and Huang (2016).", "startOffset": 104, "endOffset": 127}, {"referenceID": 6, "context": "We use the \u201ctraining with exploration\u201d strategy (Goldberg and Nivre, 2013) and the dynamic oracle mechanism described in Cross and Huang (2016) to make sure the model can handle unseen parsing configurations properly.", "startOffset": 48, "endOffset": 74}, {"referenceID": 2, "context": "2 Recurrent Neural Models and Training The scoring functions in the deductive system (Figure 4) are calculated by an underlying neural model, which is similar to the bi-directional LSTM model in Cross and Huang (2016) that evaluates based on span boundary features.", "startOffset": 195, "endOffset": 218}, {"referenceID": 2, "context": "2 Recurrent Neural Models and Training The scoring functions in the deductive system (Figure 4) are calculated by an underlying neural model, which is similar to the bi-directional LSTM model in Cross and Huang (2016) that evaluates based on span boundary features. Again, it is important to note that no discourse or syntactic tree structures are represented in the features. During the decoding time, a document is firstl passed into a two-layer bi-directional LSTM model, then the outputs at each text position of the two layers of the bi-directional LSTMs are concatenated as the positional features. The spans at each parsing step can be represented as the feature vectors at the boundaries. The span features are then passed into fully connected networks with softmax to calculate the likelihood of performing the corresponding action or marking the corresponding label. We use the \u201ctraining with exploration\u201d strategy (Goldberg and Nivre, 2013) and the dynamic oracle mechanism described in Cross and Huang (2016) to make sure the model can handle unseen parsing configurations properly.", "startOffset": 195, "endOffset": 1021}, {"referenceID": 2, "context": "For most of the hyperparameters we settle with the same values suggested by Cross and Huang (2016). To alleviate the overfitting problem for training on the relative small RST Treebank, we use a dropout of 0.", "startOffset": 76, "endOffset": 99}, {"referenceID": 0, "context": "segmentation structure +nuclearity +relation Bach et al. (2012) segmentation only Stanford 95.", "startOffset": 45, "endOffset": 64}, {"referenceID": 0, "context": "segmentation structure +nuclearity +relation Bach et al. (2012) segmentation only Stanford 95.1 Hernault et al. (2010) end-to-end pipeline Penn Treebank 94.", "startOffset": 45, "endOffset": 119}, {"referenceID": 10, "context": "syntactic feats structure +nuclearity +relation human annotation (Ji and Eisenstein, 2014) 88.", "startOffset": 65, "endOffset": 90}, {"referenceID": 6, "context": "sparse Hernault et al. (2010) Penn Treebank 83.", "startOffset": 7, "endOffset": 30}, {"referenceID": 6, "context": "sparse Hernault et al. (2010) Penn Treebank 83.0 68.4 54.8 Joty et al. (2013) Charniak (retrained) 82.", "startOffset": 7, "endOffset": 78}, {"referenceID": 6, "context": "sparse Hernault et al. (2010) Penn Treebank 83.0 68.4 54.8 Joty et al. (2013) Charniak (retrained) 82.7 68.4 55.7 Joty and Moschitti (2014) Charniak (retrained) 57.", "startOffset": 7, "endOffset": 140}, {"referenceID": 4, "context": "3 Feng and Hirst (2014) Stanford 85.", "startOffset": 2, "endOffset": 24}, {"referenceID": 4, "context": "3 Feng and Hirst (2014) Stanford 85.7 71.0 58.2 Heilman and Sagae (2015) ZPar (retraied) 83.", "startOffset": 2, "endOffset": 73}, {"referenceID": 4, "context": "3 Feng and Hirst (2014) Stanford 85.7 71.0 58.2 Heilman and Sagae (2015) ZPar (retraied) 83.5 68.1 55.1 Wang et al. (2017) Stanford 86.", "startOffset": 2, "endOffset": 123}, {"referenceID": 13, "context": "neural Li et al. (2014a) Stanford 82.", "startOffset": 7, "endOffset": 25}, {"referenceID": 10, "context": "6 Ji and Eisenstein (2014) MALT 80.", "startOffset": 2, "endOffset": 27}, {"referenceID": 4, "context": "Note that most of these parsers do not handle multi-branching discourse nodes and are trained and evaluated on binarized discourse trees (Feng and Hirst, 2014; Li et al., 2014a,b; Ji and Eisenstein, 2014; Heilman and Sagae, 2015), so their performances are actually not directly comparable to the results we reported.", "startOffset": 137, "endOffset": 229}, {"referenceID": 10, "context": "Note that most of these parsers do not handle multi-branching discourse nodes and are trained and evaluated on binarized discourse trees (Feng and Hirst, 2014; Li et al., 2014a,b; Ji and Eisenstein, 2014; Heilman and Sagae, 2015), so their performances are actually not directly comparable to the results we reported.", "startOffset": 137, "endOffset": 229}, {"referenceID": 7, "context": "Note that most of these parsers do not handle multi-branching discourse nodes and are trained and evaluated on binarized discourse trees (Feng and Hirst, 2014; Li et al., 2014a,b; Ji and Eisenstein, 2014; Heilman and Sagae, 2015), so their performances are actually not directly comparable to the results we reported.", "startOffset": 137, "endOffset": 229}, {"referenceID": 1, "context": "Note that in constituency level, the accuracy is not directly comparable with the accuracy reported in Cross and Huang (2016), since: a) our parser is trained on a much smaller dataset (RST Treebank is about 1/6 of Penn Treebank); b) the parser is trained to optimize the discourse-level accuracy.", "startOffset": 103, "endOffset": 126}, {"referenceID": 0, "context": "Table 2 shows that, in the perspective of endto-end discourse parsing, our parser first outperforms the state-of-the-art segmentator of Bach et al. (2012), and furthermore, in end-to-end parsing, the superiority of our parser is more pronounced comparing to the previously best parser of Hernault et al.", "startOffset": 136, "endOffset": 155}, {"referenceID": 0, "context": "Table 2 shows that, in the perspective of endto-end discourse parsing, our parser first outperforms the state-of-the-art segmentator of Bach et al. (2012), and furthermore, in end-to-end parsing, the superiority of our parser is more pronounced comparing to the previously best parser of Hernault et al. (2010). On the other hand, the majority of the conventional discourse parsers are not end-to-end: they rely on gold EDU segmentations and pre-trained tools like Stanford parsers to generate features.", "startOffset": 136, "endOffset": 311}], "year": 2017, "abstractText": "Discourse parsing has long been treated as a stand-alone problem independent from constituency or dependency parsing. Most attempts at this problem are pipelined rather than end-to-end, sophisticated, and not self-contained: they assume goldstandard text segmentations (Elementary Discourse Units), and use external parsers for syntactic features. In this paper we propose the first end-to-end discourse parser that jointly parses in both syntax and discourse levels, as well as the first syntacto-discourse treebank by integrating the Penn Treebank with the RST Treebank. Built upon our recent span-based constituency parser, this joint syntactodiscourse parser requires no preprocessing whatsoever (such as segmentation or feature extraction), achieves the state-of-theart end-to-end discourse parsing accuracy.", "creator": "LaTeX with hyperref package"}}}