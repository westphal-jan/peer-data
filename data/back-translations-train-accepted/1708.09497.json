{"id": "1708.09497", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Aug-2017", "title": "Unsupervised Induction of Contingent Event Pairs from Film Scenes", "abstract": "Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning. Researchers in NLP have tackled modeling such expectations from a range of perspectives, including treating it as the inference of the contingent discourse relation, or as a type of common-sense causal reasoning. Our approach is to model likelihood between events by drawing on several of these lines of previous work. We implement and evaluate different unsupervised methods for learning event pairs that are likely to be contingent on one another. We refine event pairs that we learn from a corpus of film scene descriptions utilizing web search counts, and evaluate our results by collecting human judgments of contingency. Our results indicate that the use of web search counts increases the average accuracy of our best method to 85.64% over a baseline of 50%, as compared to an average accuracy of 75.15% without web search.", "histories": [["v1", "Wed, 30 Aug 2017 23:02:06 GMT  (983kb,D)", "http://arxiv.org/abs/1708.09497v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhichao hu", "elahe rahimtoroghi", "larissa munishkina", "reid swanson", "marilyn a walker"], "accepted": true, "id": "1708.09497"}, "pdf": {"name": "1708.09497.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Induction of Contingent Event Pairs from Film Scenes", "authors": ["Zhichao Hu", "Elahe Rahimtoroghi", "Larissa Munishkina", "Reid Swanson", "Marilyn A. Walker"], "emails": ["maw}@soe.ucsc.edu"], "sections": [{"heading": null, "text": "Human engagement with narratives is partly based on thinking about discourse relationships between narrative events and the resulting expectations of what is likely to happen next. Researchers at NLP have tackled modeling such expectations from a range of perspectives, including their treatment as a conclusion from the CONTINGENT discourse relationship or as a kind of common sense causal reasoning. Our approach is to model the probability between events by using several of these lines from previous work. We implement and evaluate various unguarded methods for learning pairs of events that are likely to be causal to each other. We refine event pairs we learn from a corpus of movie scene descriptions by using web search numbers, and evaluate our results by collecting human judgments of contingency. Our results suggest that the average accuracy of our best method increases from 5.864% to an average of 715% with no basis line of accuracy, using web search numbers."}, {"heading": "1 Introduction", "text": "So we have discourse relationships, which are one of the primary means of structuring narratives in genres as diverse as weblogs, search queries, stories, film scripts, and news articles (Chambers and Jurafsky, 2009; Manshadi et al., 2008; Gordon et al., 2011; Beamer and Girju, 2009; Do et al., 2011).Recent work in NLP has tackled the inference of relationships between events from a wide range of perspectives: (1) as inference to discourse relationships (e.g. the Penn Discourse Treebank (PDTB) CONTINGENT relationship and its specializations. (2) as a kind of common sense part of reason; (3) as inference to discourse relationships of discourse relationships (e.g. the Penn Discourse Treebank (PDTB) CONTINGENT relationship and its specializations."}, {"heading": "2 Experimental Method", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2.1 Text Processing", "text": "We first separate our screen games into two sets of documents, one for the action genre and one for the romance genre. As we are interested in the event descriptions that are part of the scene descriptions, we extract the dialogue from each script. Then, we comment on the movie scene files using Stanford's CoreNLP pipeline. Notes include tokenization, lemmatization, entity recognition, analysis, and co-referencing resolution. We extract the events by keeping all tokens whose POS tags start with VB. We then use dependency analysis to find the subject and object of each verb (if any), taking only nsubj, agent, dobj, iobj, nsubjpass into account. We retain the original tokens of the subject and object for further processing."}, {"heading": "2.2 Compute Event Representations", "text": "Considering the results of the previous step, we start generalizing the subject and the object stored at each event by replacing tokens with named units if there are named units. Otherwise, we generalize the subjects and objects using their terms. For example, the person UNLOCK door, as shown in Table 1. We then integrate all subjects and objects in all movie scene files and keep a record of the frequency of each subject and object. For example, [Person (115), Organization (14), Door (3)] UNLOCK [Door (127), Person (5), Bar (2). The most common subjects and objects are selected as representative arguments for the event. Then, we count the frequency of each event in all movie scene files.Within each movie scene, we count adjacent events as potential CONTINGENT pairs of events. Two pairs of events are defined as equal if they have the same sequence."}, {"heading": "2.3 Calculate Contingency Measures", "text": "We calculate four different metrics of CONTINGENCY based on previous work with the results of Steps 1 and 2 (Sec. 2,1 and Sec. 2,2). These metrics are only relevant if the actual and actual events occur in any form or form (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Riaz and Girju, 2010; Do et al., 2011). Faced with a series of events (a verb and its collected subjects and objects), we calculate the PMI using the standard definition: pmi (e1, e2) P (e1) P (e2), in which e1 and e2 events (e2) are two events."}, {"heading": "2.4 Web Search Refinement", "text": "We then define search patterns that are based on the PCEP / REP pairs that we learned from the movie corpus, less dependent on the general search patterns. We do not recall that REP stands for random events and that PCEP stands for predicted random events. Our hypothesis is that the use of movie corpus within a particular browser genre to do the initial estimates of browser randomness, genre characteristics such as similar events and narratives of browser browser scenes in browser browser browser browser chronological order. However, the movie corpus is nec-necessarily small browser browser browser corpus, and we can expand the evidence of a certain random browser relationship by defining certain browser corpus patterns and collecting web browser counts. PCEPs should often be used in web searches and REPs, should be infrequent. Our web refinement procedure is: \u2022 For each event pair that create a Google search element, such as 1 general search cognitive search, we will describe in more detail in the browser browser search cognition procedure."}, {"heading": "3 Evaluation and Results", "text": "While other papers use a number of methods to evaluate accuracy, to our knowledge our work is the first to use human judgement from Mechanical Turk to evaluate the accuracy of the learned contingent event pairs. We first describe the evaluation setup in paragraph 3.1 and then report on the results in paragraph 3.2."}, {"heading": "3.1 Mechanical Turk Contingent Pair Evaluations", "text": "We used three different types of HITs (Human Intelligence Tasks) on Mechanical Turk for our evaluation. Two of the HITS are in Fig. 2 and Fig. 3 The differences in the different types of HITS include: (1) whether the arguments of the events in HIT were given, as in Fig. 2 and (2): whether the Turks were told that the sequence of events is important, as in Fig. 3) We initially thought that providing the arguments to the events as in Fig. 2 would help about which was more likely. We tested this hypothesis only in the action genre for the Causal Potential Measures."}, {"heading": "3.2 Results", "text": "We report our results in terms of overall accuracy. Since the Turk mechanical task is a chooseone question and not a binary classification, Precision = Recall in our experimental results: True Positive = Number of correct answers True Negative = Number of correct answers False Positive = Number of wrong answers False Positive = Number of wrong answers Precision = True PositiveTrue Positive + False PositiveRecall = True Positive + False Negative The accuracy of all methods are shown in Table 2. The results of using event arguments (person white person) in the Mechanical Turk evaluation task (i.e. Fig. 2) is given in rows 1 and 2 of Table 2. Accuracy for rows 1 and 2 are significantly lower than when the PCEPs are tested without arguments."}, {"heading": "4 Discussion and Future Work", "text": "We induced pairs of events using several methods from previous work with similar objectives but very different problem formulations and evaluation methods. We used a verb-rich film scene in which the events are normally told in chronological order. We used the method to evaluate the learned pairs of CONTINGENT events using human perceptions. In the first phase of drawing on previous measures of distributional relationships, which we used in the overall average accuracy of about 70%, over a 50% baseline, we then achieved a novel method of defining narrative patterns using the Google Search API, and used web numbers to further refine our estimates of the contingency of learned event pairs. This increased the overall average accuracy to about 77%, which is 27% above the baseline. Our results suggest that the use of web search increases the average accuracy of our causal-based method to 5.764% from an average of 864%."}, {"heading": "Acknowledgments", "text": "We thank Yan Li for setting up automatic searches and the members of the NLDS for their discussions and suggestions, especially Stephanie Lukin, Rob Abbort and Grace Lin."}], "references": [{"title": "Using a bigram event model to predict causal potential", "author": ["B. Beamer", "R. Girju."], "venue": "Computational Linguistics and Intelligent Text Processing, p. 430\u2013 441. Springer.", "citeRegEx": "Beamer and Girju.,? 2009", "shortCiteRegEx": "Beamer and Girju.", "year": 2009}, {"title": "Fast, cheap, and creative: evaluating translation quality using amazon\u2019s mechanical turk", "author": ["C. Callison-Burch."], "venue": "Proc. of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 Volume 1, p. 286\u2013295. Association for Computational", "citeRegEx": "Callison.Burch.,? 2009", "shortCiteRegEx": "Callison.Burch.", "year": 2009}, {"title": "Unsupervised learning of narrative event chains", "author": ["N. Chambers", "D. Jurafsky."], "venue": "Proc. of ACL-08: HLT, p. 789\u2013797.", "citeRegEx": "Chambers and Jurafsky.,? 2008", "shortCiteRegEx": "Chambers and Jurafsky.", "year": 2008}, {"title": "Unsupervised learning of narrative schemas and their participants", "author": ["N. Chambers", "D. Jurafsky."], "venue": "Proc. of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:", "citeRegEx": "Chambers and Jurafsky.,? 2009", "shortCiteRegEx": "Chambers and Jurafsky.", "year": 2009}, {"title": "Towards the unsupervised acquisition of discourse relations", "author": ["C. Chiarcos."], "venue": "Proc. of the 50th Annual", "citeRegEx": "Chiarcos.,? 2012", "shortCiteRegEx": "Chiarcos.", "year": 2012}, {"title": "Maximum likelihood estimation of observer error-rates using the EM algorithm", "author": ["A.P. Dawid", "A.M. Skene."], "venue": "Journal of the Royal Statistical Society. Series C (Applied Statistics), 28(1):20\u201328, January. ArticleType: research-article / Full publication date: 1979", "citeRegEx": "Dawid and Skene.,? 1979", "shortCiteRegEx": "Dawid and Skene.", "year": 1979}, {"title": "Minimally supervised event causality identification", "author": ["Q.X. Do", "Y.S. Chan", "D. Roth."], "venue": "Proc. of the Conference on Empirical Methods in Natural Language Processing, p. 294\u2013303. Association for Computational Linguistics.", "citeRegEx": "Do et al\\.,? 2011", "shortCiteRegEx": "Do et al\\.", "year": 2011}, {"title": "Experiencing narrative worlds: On the psychological activities of reading", "author": ["R.J. Gerrig."], "venue": "Yale Univ Pr.", "citeRegEx": "Gerrig.,? 1993", "shortCiteRegEx": "Gerrig.", "year": 1993}, {"title": "Identifying personal stories in millions of weblog entries", "author": ["A. Gordon", "R. Swanson."], "venue": "Third International Conference on Weblogs and Social Media, Data Challenge Workshop.", "citeRegEx": "Gordon and Swanson.,? 2009", "shortCiteRegEx": "Gordon and Swanson.", "year": 2009}, {"title": "Commonsense causal reasoning using millions of personal stories", "author": ["A. Gordon", "Cosmin Bejan", "Kenji Sagae."], "venue": "Twenty-Fifth Conference on Artificial Intelligence (AAAI-11).", "citeRegEx": "Gordon et al\\.,? 2011", "shortCiteRegEx": "Gordon et al\\.", "year": 2011}, {"title": "Automatically producing plot unit representations for narrative text", "author": ["A. Goyal", "E. Riloff", "H. Daum\u00e9 III."], "venue": "Proc. of the 2010 Conference on Empirical Methods in Natural Language Processing, p. 77\u201386. Association for Computational Linguistics.", "citeRegEx": "Goyal et al\\.,? 2010", "shortCiteRegEx": "Goyal et al\\.", "year": 2010}, {"title": "Constructing inferences during narrative text comprehension", "author": ["A.C. Graesser", "M. Singer", "T. Trabasso."], "venue": "Psychological review, 101(3):371.", "citeRegEx": "Graesser et al\\.,? 1994", "shortCiteRegEx": "Graesser et al\\.", "year": 1994}, {"title": "Iterative learning for reliable crowdsourcing systems", "author": ["D.R. Karger", "S. Oh", "D. Shah."], "venue": "John Shawe-Taylor, Richard S. Zemel, Peter L. Bartlett, Fernando C. N. Pereira, and Kilian Q. Weinberger, editors, NIPS, p. 1953\u20131961.", "citeRegEx": "Karger et al\\.,? 2011", "shortCiteRegEx": "Karger et al\\.", "year": 2011}, {"title": "Narrative analysis: Oral versions of personal experience", "author": ["W. Labov", "J. Waletzky"], "venue": null, "citeRegEx": "Labov and Waletzky.,? \\Q1997\\E", "shortCiteRegEx": "Labov and Waletzky.", "year": 1997}, {"title": "Plot units and narrative summarization", "author": ["W.G. Lehnert."], "venue": "Cognitive Science, 5(4):293\u2013331.", "citeRegEx": "Lehnert.,? 1981", "shortCiteRegEx": "Lehnert.", "year": 1981}, {"title": "A pdtb-styled end-to-end discourse parser", "author": ["Z. Lin", "M.-Y. Kan", "H. T Ng."], "venue": "Proc. of the Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Lin et al\\.,? 2010", "shortCiteRegEx": "Lin et al\\.", "year": 2010}, {"title": "Variational inference for crowdsourcing", "author": ["Q. Liu", "J. Peng", "A. Ihler."], "venue": "Advances in Neural Information Processing Systems 25, p. 701\u2013709.", "citeRegEx": "Liu et al\\.,? 2012", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Using entity features to classify implicit relations", "author": ["A. Louis", "A. Joshi", "R. Prasad", "A. Nenkova."], "venue": "Proc. of the 11th Annual SIGdial Meeting on Discourse and Dialogue, Tokyo, Japan.", "citeRegEx": "Louis et al\\.,? 2010", "shortCiteRegEx": "Louis et al\\.", "year": 2010}, {"title": "Learning a probabilistic model of event sequences from internet weblog stories", "author": ["M. Manshadi", "R. Swanson", "A. S Gordon."], "venue": "Proc. of the 21st FLAIRS Conference.", "citeRegEx": "Manshadi et al\\.,? 2008", "shortCiteRegEx": "Manshadi et al\\.", "year": 2008}, {"title": "Automatic sense prediction for implicit discourse relations in text", "author": ["E. Pitler", "A. Louis", "A. Nenkova."], "venue": "Proc. of the 47th Meeting of the Association for Computational Linguistics.", "citeRegEx": "Pitler et al\\.,? 2009", "shortCiteRegEx": "Pitler et al\\.", "year": 2009}, {"title": "The penn discourse treebank 2.0", "author": ["R. Prasad", "N. Dinesh", "A. Lee", "E. Miltsakaki", "L. Robaldo", "A. Joshi", "B. Webber"], "venue": "In Proc. of the 6th International Conference on Language Resources and Evaluation (LREC", "citeRegEx": "Prasad et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Prasad et al\\.", "year": 2008}, {"title": "The Penn Discourse TreeBank 2.0", "author": ["R. Prasad", "N. Dinesh", "A. Lee", "E. Miltsakaki", "L. Robaldo", "A. Joshi", "B. Webber"], "venue": "In Proc. of 6th International Conference on Language Resources and Evaluation (LREC", "citeRegEx": "Prasad et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Prasad et al\\.", "year": 2008}, {"title": "Another look at causality: Discovering scenario-specific contingency relationships with no supervision", "author": ["M. Riaz", "R. Girju."], "venue": "Semantic Computing (ICSC), 2010 IEEE Fourth International Conference on, p. 361\u2013368. IEEE.", "citeRegEx": "Riaz and Girju.,? 2010", "shortCiteRegEx": "Riaz and Girju.", "year": 2010}, {"title": "Scripts Plans Goals", "author": ["R. Schank", "R. Abelson."], "venue": "Lea.", "citeRegEx": "Schank and Abelson.,? 1977", "shortCiteRegEx": "Schank and Abelson.", "year": 1977}, {"title": "Cheap and fast\u2014but is it good?: evaluating non-expert annotations for natural language tasks", "author": ["R. Snow", "B. O\u2019Connor", "D. Jurafsky", "A.Y. Ng"], "venue": "In Proc. of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Snow et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Snow et al\\.", "year": 2008}, {"title": "Say anything: Using textual case-based reasoning to enable opendomain interactive storytelling", "author": ["R. Swanson", "A.S. Gordon."], "venue": "ACM Transactions on Interactive Intelligent Systems (TiiS), 2(3):16.", "citeRegEx": "Swanson and Gordon.,? 2012", "shortCiteRegEx": "Swanson and Gordon.", "year": 2012}, {"title": "An annotated corpus of film dialogue for learning and characterizing character style", "author": ["M.A. Walker", "G. Lin", "J. Sawyer."], "venue": "Language Resources and Evaluation Conference, LREC2012.", "citeRegEx": "Walker et al\\.,? 2012b", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "The multidimensional wisdom of crowds", "author": ["P. Welinder", "S. Branson", "S. Belongie", "P. Perona."], "venue": "Advances in Neural Information Processing Systems 23, p. 2424\u20132432.", "citeRegEx": "Welinder et al\\.,? 2010", "shortCiteRegEx": "Welinder et al\\.", "year": 2010}, {"title": "Predicting discourse connectives for implicit discourse relation recognition", "author": ["Z.-M. Zhou", "Y. Xu", "Z.Y. Niu", "M. Lan", "J. Su", "C.L. Tan"], "venue": "Coling 2010: Posters,", "citeRegEx": "Zhou et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 7, "context": "Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning (Gerrig, 1993; Graesser et al., 1994; Lehnert, 1981; Goyal et al., 2010).", "startOffset": 205, "endOffset": 277}, {"referenceID": 11, "context": "Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning (Gerrig, 1993; Graesser et al., 1994; Lehnert, 1981; Goyal et al., 2010).", "startOffset": 205, "endOffset": 277}, {"referenceID": 14, "context": "Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning (Gerrig, 1993; Graesser et al., 1994; Lehnert, 1981; Goyal et al., 2010).", "startOffset": 205, "endOffset": 277}, {"referenceID": 10, "context": "Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning (Gerrig, 1993; Graesser et al., 1994; Lehnert, 1981; Goyal et al., 2010).", "startOffset": 205, "endOffset": 277}, {"referenceID": 3, "context": "Thus discourse relations are one of the primary means to structure narrative in genres as diverse as weblogs, search queries, stories, film scripts and news articles (Chambers and Jurafsky, 2009; Manshadi et al., 2008; Gordon and Swanson, 2009; Gordon et al., 2011; Beamer and Girju, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 166, "endOffset": 328}, {"referenceID": 18, "context": "Thus discourse relations are one of the primary means to structure narrative in genres as diverse as weblogs, search queries, stories, film scripts and news articles (Chambers and Jurafsky, 2009; Manshadi et al., 2008; Gordon and Swanson, 2009; Gordon et al., 2011; Beamer and Girju, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 166, "endOffset": 328}, {"referenceID": 8, "context": "Thus discourse relations are one of the primary means to structure narrative in genres as diverse as weblogs, search queries, stories, film scripts and news articles (Chambers and Jurafsky, 2009; Manshadi et al., 2008; Gordon and Swanson, 2009; Gordon et al., 2011; Beamer and Girju, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 166, "endOffset": 328}, {"referenceID": 9, "context": "Thus discourse relations are one of the primary means to structure narrative in genres as diverse as weblogs, search queries, stories, film scripts and news articles (Chambers and Jurafsky, 2009; Manshadi et al., 2008; Gordon and Swanson, 2009; Gordon et al., 2011; Beamer and Girju, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 166, "endOffset": 328}, {"referenceID": 0, "context": "Thus discourse relations are one of the primary means to structure narrative in genres as diverse as weblogs, search queries, stories, film scripts and news articles (Chambers and Jurafsky, 2009; Manshadi et al., 2008; Gordon and Swanson, 2009; Gordon et al., 2011; Beamer and Girju, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 166, "endOffset": 328}, {"referenceID": 22, "context": "Thus discourse relations are one of the primary means to structure narrative in genres as diverse as weblogs, search queries, stories, film scripts and news articles (Chambers and Jurafsky, 2009; Manshadi et al., 2008; Gordon and Swanson, 2009; Gordon et al., 2011; Beamer and Girju, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 166, "endOffset": 328}, {"referenceID": 6, "context": "Thus discourse relations are one of the primary means to structure narrative in genres as diverse as weblogs, search queries, stories, film scripts and news articles (Chambers and Jurafsky, 2009; Manshadi et al., 2008; Gordon and Swanson, 2009; Gordon et al., 2011; Beamer and Girju, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 166, "endOffset": 328}, {"referenceID": 15, "context": "We model this likelihood between events by drawing on the PTDB\u2019s general definition of the CONTINGENT relation, which encapsulates relations elsewhere called CAUSE, CONDITION and ENABLEMENT (Prasad et al., 2008a; Lin et al., 2010; Pitler et al., 2009; Louis et al., 2010).", "startOffset": 190, "endOffset": 271}, {"referenceID": 19, "context": "We model this likelihood between events by drawing on the PTDB\u2019s general definition of the CONTINGENT relation, which encapsulates relations elsewhere called CAUSE, CONDITION and ENABLEMENT (Prasad et al., 2008a; Lin et al., 2010; Pitler et al., 2009; Louis et al., 2010).", "startOffset": 190, "endOffset": 271}, {"referenceID": 17, "context": "We model this likelihood between events by drawing on the PTDB\u2019s general definition of the CONTINGENT relation, which encapsulates relations elsewhere called CAUSE, CONDITION and ENABLEMENT (Prasad et al., 2008a; Lin et al., 2010; Pitler et al., 2009; Louis et al., 2010).", "startOffset": 190, "endOffset": 271}, {"referenceID": 0, "context": "Screenplay scene descriptions are one type of narrative that tend to be told in temporal order (Beamer and Girju, 2009; Gordon and Swanson, 2009), which makes them a good resource for learning about contingencies between events.", "startOffset": 95, "endOffset": 145}, {"referenceID": 8, "context": "Screenplay scene descriptions are one type of narrative that tend to be told in temporal order (Beamer and Girju, 2009; Gordon and Swanson, 2009), which makes them a good resource for learning about contingencies between events.", "startOffset": 95, "endOffset": 145}, {"referenceID": 26, "context": "Our method uses a combination of estimating the likelihood of a CONTINGENT relation between events in a corpus of film scenes (Walker et al., 2012b), with estimates then revised through web search.", "startOffset": 126, "endOffset": 148}, {"referenceID": 26, "context": "Our experiments are based on two subsets of 862 film screen plays collected from the IMSDb website using its ontology of film genres (Walker et al., 2012b): a set of action movies of 115 screenplays totalling 748 MB, and a set of romance movies of 71 screenplays totalling 390 MB.", "startOffset": 133, "endOffset": 155}, {"referenceID": 6, "context": "Other related work has made use of discourse connectives or discourse taggers (implicit discourse relations) to provide additional evidence of CONTINGENCY (Do et al., 2011; Gordon et al., 2011; Chiarcos, 2012; Pitler et al., 2009; Lin et al., 2010), but we do not because the results have been mixed.", "startOffset": 155, "endOffset": 248}, {"referenceID": 9, "context": "Other related work has made use of discourse connectives or discourse taggers (implicit discourse relations) to provide additional evidence of CONTINGENCY (Do et al., 2011; Gordon et al., 2011; Chiarcos, 2012; Pitler et al., 2009; Lin et al., 2010), but we do not because the results have been mixed.", "startOffset": 155, "endOffset": 248}, {"referenceID": 4, "context": "Other related work has made use of discourse connectives or discourse taggers (implicit discourse relations) to provide additional evidence of CONTINGENCY (Do et al., 2011; Gordon et al., 2011; Chiarcos, 2012; Pitler et al., 2009; Lin et al., 2010), but we do not because the results have been mixed.", "startOffset": 155, "endOffset": 248}, {"referenceID": 19, "context": "Other related work has made use of discourse connectives or discourse taggers (implicit discourse relations) to provide additional evidence of CONTINGENCY (Do et al., 2011; Gordon et al., 2011; Chiarcos, 2012; Pitler et al., 2009; Lin et al., 2010), but we do not because the results have been mixed.", "startOffset": 155, "endOffset": 248}, {"referenceID": 15, "context": "Other related work has made use of discourse connectives or discourse taggers (implicit discourse relations) to provide additional evidence of CONTINGENCY (Do et al., 2011; Gordon et al., 2011; Chiarcos, 2012; Pitler et al., 2009; Lin et al., 2010), but we do not because the results have been mixed.", "startOffset": 155, "endOffset": 248}, {"referenceID": 2, "context": "We do not believe word ambiguities to be a primary concern, and previous work also defines events to be the same if they have the same surface verb, in some cases with a restriction that the dependency relations should also be the same (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Do et al., 2011; Riaz and Girju, 2010; Manshadi et al., 2008).", "startOffset": 236, "endOffset": 356}, {"referenceID": 3, "context": "We do not believe word ambiguities to be a primary concern, and previous work also defines events to be the same if they have the same surface verb, in some cases with a restriction that the dependency relations should also be the same (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Do et al., 2011; Riaz and Girju, 2010; Manshadi et al., 2008).", "startOffset": 236, "endOffset": 356}, {"referenceID": 6, "context": "We do not believe word ambiguities to be a primary concern, and previous work also defines events to be the same if they have the same surface verb, in some cases with a restriction that the dependency relations should also be the same (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Do et al., 2011; Riaz and Girju, 2010; Manshadi et al., 2008).", "startOffset": 236, "endOffset": 356}, {"referenceID": 22, "context": "We do not believe word ambiguities to be a primary concern, and previous work also defines events to be the same if they have the same surface verb, in some cases with a restriction that the dependency relations should also be the same (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Do et al., 2011; Riaz and Girju, 2010; Manshadi et al., 2008).", "startOffset": 236, "endOffset": 356}, {"referenceID": 18, "context": "We do not believe word ambiguities to be a primary concern, and previous work also defines events to be the same if they have the same surface verb, in some cases with a restriction that the dependency relations should also be the same (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Do et al., 2011; Riaz and Girju, 2010; Manshadi et al., 2008).", "startOffset": 236, "endOffset": 356}, {"referenceID": 2, "context": "The majority of related work uses pointwise mutual information (PMI) in some form or another (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 93, "endOffset": 190}, {"referenceID": 3, "context": "The majority of related work uses pointwise mutual information (PMI) in some form or another (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 93, "endOffset": 190}, {"referenceID": 22, "context": "The majority of related work uses pointwise mutual information (PMI) in some form or another (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 93, "endOffset": 190}, {"referenceID": 6, "context": "The majority of related work uses pointwise mutual information (PMI) in some form or another (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009; Riaz and Girju, 2010; Do et al., 2011).", "startOffset": 93, "endOffset": 190}, {"referenceID": 18, "context": "Our third method models event sequences using statistical language models (Manshadi et al., 2008).", "startOffset": 74, "endOffset": 97}, {"referenceID": 3, "context": "This method is roughly based on previous work using chains of discourse entities to induce narrative schemas (Chambers and Jurafsky, 2009).", "startOffset": 109, "endOffset": 138}, {"referenceID": 25, "context": "(Swanson and Gordon, 2012; Beamer and Girju, 2009; Labov and Waletzky, 1997).", "startOffset": 0, "endOffset": 76}, {"referenceID": 0, "context": "(Swanson and Gordon, 2012; Beamer and Girju, 2009; Labov and Waletzky, 1997).", "startOffset": 0, "endOffset": 76}, {"referenceID": 13, "context": "(Swanson and Gordon, 2012; Beamer and Girju, 2009; Labov and Waletzky, 1997).", "startOffset": 0, "endOffset": 76}, {"referenceID": 25, "context": "We decided to use third person rather than first person patterns, because first person patterns are only one type of narrative (Swanson and Gordon, 2012).", "startOffset": 127, "endOffset": 153}, {"referenceID": 24, "context": "Previous work has shown that for many common NLP tasks, 7 Turkers\u2019 average score can match expert annotations (Snow et al., 2008), however we use 15 Turkers because we had no gold-standard data and because we were not sure how difficult the task is.", "startOffset": 110, "endOffset": 129}, {"referenceID": 1, "context": "In the future we plan to test other solutions to measuring annotator reliability as proposed in related work (Callison-Burch, 2009; Snow et al., 2008; Karger et al., 2011; Dawid and Skene, 1979; Welinder et al., 2010; Liu et al., 2012).", "startOffset": 109, "endOffset": 235}, {"referenceID": 24, "context": "In the future we plan to test other solutions to measuring annotator reliability as proposed in related work (Callison-Burch, 2009; Snow et al., 2008; Karger et al., 2011; Dawid and Skene, 1979; Welinder et al., 2010; Liu et al., 2012).", "startOffset": 109, "endOffset": 235}, {"referenceID": 12, "context": "In the future we plan to test other solutions to measuring annotator reliability as proposed in related work (Callison-Burch, 2009; Snow et al., 2008; Karger et al., 2011; Dawid and Skene, 1979; Welinder et al., 2010; Liu et al., 2012).", "startOffset": 109, "endOffset": 235}, {"referenceID": 5, "context": "In the future we plan to test other solutions to measuring annotator reliability as proposed in related work (Callison-Burch, 2009; Snow et al., 2008; Karger et al., 2011; Dawid and Skene, 1979; Welinder et al., 2010; Liu et al., 2012).", "startOffset": 109, "endOffset": 235}, {"referenceID": 27, "context": "In the future we plan to test other solutions to measuring annotator reliability as proposed in related work (Callison-Burch, 2009; Snow et al., 2008; Karger et al., 2011; Dawid and Skene, 1979; Welinder et al., 2010; Liu et al., 2012).", "startOffset": 109, "endOffset": 235}, {"referenceID": 16, "context": "In the future we plan to test other solutions to measuring annotator reliability as proposed in related work (Callison-Burch, 2009; Snow et al., 2008; Karger et al., 2011; Dawid and Skene, 1979; Welinder et al., 2010; Liu et al., 2012).", "startOffset": 109, "endOffset": 235}, {"referenceID": 0, "context": "They evaluate the pairs by asking two trained human annotators to label whether occurrences of those pairs in their corpus are causally related (Beamer and Girju, 2009; Riaz and Girju, 2010).", "startOffset": 144, "endOffset": 190}, {"referenceID": 22, "context": "They evaluate the pairs by asking two trained human annotators to label whether occurrences of those pairs in their corpus are causally related (Beamer and Girju, 2009; Riaz and Girju, 2010).", "startOffset": 144, "endOffset": 190}, {"referenceID": 9, "context": "Work on commonsense causal reasoning aims to learn causal relations beween pairs of events using a range of methods applied to a large corpus of weblog narratives (Gordon et al., 2011; Gordon and Swanson, 2009; Manshadi et al., 2008).", "startOffset": 163, "endOffset": 233}, {"referenceID": 8, "context": "Work on commonsense causal reasoning aims to learn causal relations beween pairs of events using a range of methods applied to a large corpus of weblog narratives (Gordon et al., 2011; Gordon and Swanson, 2009; Manshadi et al., 2008).", "startOffset": 163, "endOffset": 233}, {"referenceID": 18, "context": "Work on commonsense causal reasoning aims to learn causal relations beween pairs of events using a range of methods applied to a large corpus of weblog narratives (Gordon et al., 2011; Gordon and Swanson, 2009; Manshadi et al., 2008).", "startOffset": 163, "endOffset": 233}, {"referenceID": 18, "context": "One form of evaluation aimed to predict the last event in a sequence (Manshadi et al., 2008), while more recent work uses the learned pairs to improve performance on the COPA SEMEVAL task (Gordon et al.", "startOffset": 69, "endOffset": 92}, {"referenceID": 9, "context": ", 2008), while more recent work uses the learned pairs to improve performance on the COPA SEMEVAL task (Gordon et al., 2011).", "startOffset": 103, "endOffset": 124}, {"referenceID": 2, "context": "Related work on SCRIPT LEARNING induces likely sequences of temporally ordered events in news, rather than CONTINGENCY or CAUSALITY (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009).", "startOffset": 132, "endOffset": 190}, {"referenceID": 3, "context": "Related work on SCRIPT LEARNING induces likely sequences of temporally ordered events in news, rather than CONTINGENCY or CAUSALITY (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009).", "startOffset": 132, "endOffset": 190}], "year": 2017, "abstractText": "Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning. Researchers in NLP have tackled modeling such expectations from a range of perspectives, including treating it as the inference of the CONTINGENT discourse relation, or as a type of common-sense causal reasoning. Our approach is to model likelihood between events by drawing on several of these lines of previous work. We implement and evaluate different unsupervised methods for learning event pairs that are likely to be CONTINGENT on one another. We refine event pairs that we learn from a corpus of film scene descriptions utilizing web search counts, and evaluate our results by collecting human judgments of contingency. Our results indicate that the use of web search counts increases the average accuracy of our best method to 85.64% over a baseline of 50%, as compared to an average accuracy of 75.15% without web search.", "creator": "TeX"}}}