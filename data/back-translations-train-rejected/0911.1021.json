{"id": "0911.1021", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2009", "title": "Examples as Interaction: On Humans Teaching a Computer to Play a Game", "abstract": "This paper reviews an experiment in human-computer interaction, where interaction takes place when humans attempt to teach a computer to play a strategy board game. We show that while individually learned models can be shown to improve the playing performance of the computer, their straightforward composition results in diluting what was earlier learned. This observation suggests that interaction cannot be easily distributed when one hopes to harness multiple human experts to develop a quality computer player. This is related to similar approaches in robot task learning and to classic approaches to human learning and reinforces the need to develop tools that facilitate the mix of human-based tuition and computer self-learning.", "histories": [["v1", "Thu, 5 Nov 2009 12:58:46 GMT  (193kb)", "http://arxiv.org/abs/0911.1021v1", "15 pages, 1 figure, 13 tables, submitted to a journal"]], "COMMENTS": "15 pages, 1 figure, 13 tables, submitted to a journal", "reviews": [], "SUBJECTS": "cs.AI cs.GT", "authors": ["dimitris kalles", "ilias fykouras"], "accepted": false, "id": "0911.1021"}, "pdf": {"name": "0911.1021.pdf", "metadata": {"source": "CRF", "title": "EXAMPLES AS INTERACTION: ON HUMANS TEACHING A COMPUTER TO PLAY A GAME", "authors": ["DIMITRIS KALLES"], "emails": ["kalles@eap.gr", "fykouras@sch.gr"], "sections": [{"heading": null, "text": "1 EXAMPLES AS INTERACTION: ON HUMANS TEACHING A COMPUTER TO PLAY A GAMEDIMITRIS KALLESHellenic Open University, Tsamadou 13-15, Patras, 26222, Greecekalles @ eap.grILIAS FYKOURASHellenic Open University, Tsamadou 13-15, Patras, 26222, Greecefykouras @ sch.grReceived (Day Month Year) Revised (Day Month Year) Accepted (Day Month Year) This paper examines an experiment in human-computer interaction in which humans try to teach a computer to play a strategy game. We show that while individually learned models can improve the performance of the computer, their simple composition leads to a dilution of what was learned previously. This observation suggests that interaction cannot be so easily distributed if one hopes to use several human experts to develop lessons."}, {"heading": "1. Introduction", "text": "This year, the time has come for us to look for a solution that is capable of finding a solution that will enable us, that will enable us, to find a solution that will meet the needs of the people."}, {"heading": "2. A brief review of related work", "text": "In fact, it is such that most of them are able to survive themselves without there being a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process of the process, the process, the process, the process, the process, the process, the process of the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the process, the"}, {"heading": "3. A brief background on a strategy game workbench", "text": "In fact, it is as if it were a way of turning people away from the real world, which is what it is, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is what it is about, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is about money, which is what is about money, which is about money, which is about which is what is about money, which is about which is what is about money, which is about which is about money, which is about which is about, which is about which is about money, which is about which is about, which is about which is about which is about money, which is about which is about money, which is about which is about which is about money, which is about which is about money, which is about which is about which is about money, which is about which is about which is about money, which is about which is about which is about money, which is about which is about money, which is about money, which is about which is about which is about money, which is about which is about money, which is about which is about which is about money, which is about which is about money, which is about money, which is about which is about money, which is about which is about money, which is about money, which is about which is about money, which is about which is about money, which is about money, which is about which is about which is about which is about money, which is about which is about money, which is about which is about money, which is about money, which is about"}, {"heading": "4. Experimentation and analysis", "text": "In the first phase, we collect data based on HC40; this is the phase in which people do their best to teach a computer within a limited number of games (40); in the second phase, the learned strategies are paired in the different types of selection tournaments to gain insight into whether an individual player has clearly attained good training; and to investigate whether the composition of the players can deliver a better player simply by themselves. Data collection through human-vs-computer experiments This session took place in a high school environment, where one of the authors serves as a teacher to play RLGame for 40 consecutive games. Neural networks were initialized before the first game and were updated throughout the period."}, {"heading": "5. On the validity and the implication of the results", "text": "This year, the time has come for us to be able to try to find a solution that is capable, in which we have to try to find a solution, in order to find a solution."}, {"heading": "6. Conclusions and future directions", "text": "In this paper, we have explored experimental approaches to the development of computer players based on the input of examples played by humans and then developed through computer self-play. We have used two groups of players, one consisting of high school students and one consisting of their tutors, for different disciplines. Both groups have shown that while each individual is able to present a specific game tactic that can be used as the basis for an improved automatic game, attempting to merge such behaviors in a simple way does not lead to an improved automatic game. First, this seems to suggest that we need to rethink how to use such synthetic approaches to play; it looks like a composition that exploits parallels, as intuition would have us believe. Interactive evolution is a promising direction. In such a course, one would move from concentrated human training to autonomous crawling between promising alternatives."}, {"heading": "Acknowledgments", "text": "This paper has not been published elsewhere and has not been submitted for publication elsewhere. It shares some setting-the-context paragraphs with some referenced essays by the same author with which it is neither identical nor similiar. Code and data are available on request for academic purposes."}], "references": [{"title": "Programming a computer for playing chess", "author": ["C. Shannon"], "venue": "Philosophical Magazine", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1950}, {"title": "Some Studies in Machine Learning Using the Game of Checkers", "author": ["A. Samuel"], "venue": "IBM Journal of Research and Development", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1959}, {"title": "Behind Deep Blue: Building the Computer that Defeated the World Chess Champion", "author": ["Hsu", "F-H"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Solving Checkers", "author": ["J. Schaeffer", "Y. Bjoernsson", "N. Burch", "A. Kishimoto", "M. Mueller", "R. Lake", "P. Lu", "S. Sutphen"], "venue": "Proceedings of the International Joint Conference on Artificial Intelligence", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Teachable Robots: Understanding Human Teaching Behavior to Build more Effective Robot Learners", "author": ["A.L. Thomaz", "C. Breazeal"], "venue": "Artificial Intelligence", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Collaborative Interface Agents", "author": ["Y. Lashkari", "M. Metral", "P. Maes"], "venue": "Proceedings of the National Conference on Artificial Intelligence, Seattle, WA,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1994}, {"title": "Extracting Knowledge about Users\u2019 Activities from Raw Workstation Contents", "author": ["T.M. Mitchell", "S. Wang", "Y. Huang"], "venue": "Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Active learning with statistical models", "author": ["D. Cohn", "Z. Ghahramani", "M. Jordan"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1996}, {"title": "Natural methods for robot task learning: Instructive demonstrations, generalization and practice", "author": ["M.J.M.N. Nicolescu"], "venue": "Proceedings of 2 International Conference on Autonomous Agents and Multi-Agent", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Toward an Ideal Trainer", "author": ["S.L. Epstein"], "venue": "Machine Learning", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1994}, {"title": "Opponent Modelling and Commercial Games", "author": ["H.J. van den Herik", "P.H.M.H.H.L.M. Donkersa"], "venue": "Spronck", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Game Theoretic and Machine Learning Techniques for Balancing Games. M.Sc. Thesis, University of Saskatchewan, Canada.  Learning to Play Games by Observing Humans", "author": ["E. Long"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Learning and Applying Competitive Strategies", "author": ["S.L.E. Lock"], "venue": "Proceedings of AAAI-04", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Interactive Verification of Game Design and Playing Strategies", "author": ["D. Kalles", "E. Ntoutsi"], "venue": "Proceedings of IEEE International Conference on Tools with Artificial", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "Measuring Expert Impact on Learning how to Play a Board Game", "author": ["D. Kalles"], "venue": "IFIP Conference on Artificial Intelligence Applications and Innovations,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Player co-modelling in a strategy board game: discovering how to play fast", "author": ["D. Kalles"], "venue": "Cybernetics and Systems", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "On Verifying Game Design and Playing Strategies using Reinforcement Learning", "author": ["D. Kalles", "P. Kanellopoulos"], "venue": "Proceedings of ACM Symposium on Applied Computing, special track on Artificial Intelligence and Computation", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2001}, {"title": "Learning to Predict by the Methods of Temporal Differences", "author": ["R. Sutton"], "venue": "Machine Learning", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1988}, {"title": "Reinforcement Learning - An Introduction", "author": ["R. Sutton", "A. Barto"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1998}, {"title": "Temporal Difference Learning and TD-Gammon", "author": ["G. Tesauro"], "venue": "Communications of the ACM", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1995}, {"title": "Markov Games as a Framework for Multi-Agent Reinforcement Learning", "author": ["M.L. Littman"], "venue": "Proceedings of 11 International Conference on Machine", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1994}, {"title": "The Complexity of Stochastic Games", "author": ["A. Condon"], "venue": "Information and Computation", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1992}, {"title": "A Minimax Tutor for Learning to Play a Board Game,", "author": ["D. Kalles", "D. Kanellopoulos"], "venue": "Proceedings of the AI in Games Workshop,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "Apprenticeship Learning for Helicopter Control", "author": ["A. Coates", "A.Y.P. Abbeel"], "venue": "Communications of the ACM", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "Provably Secure Competitive Routing against Proactive Byzantine Adversaries via Reinforcement Learning", "author": ["B. Awerbuch", "D. Holmer", "H. Rubens"], "venue": "Technical Report 5/16/2003,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2003}], "referenceMentions": [], "year": 2009, "abstractText": "This paper reviews an experiment in human-computer interaction, where interaction takes place when humans attempt to teach a computer to play a strategy board game. We show that while individually learned models can be shown to improve the playing performance of the computer, their straightforward composition results in diluting what was earlier learned. This observation suggests that interaction cannot be easily distributed when one hopes to harness multiple human experts to develop a quality computer player. This is related to similar approaches in robot task learning and to classic approaches to human learning and reinforces the need to develop tools that facilitate the mix of human-based tuition and computer self-learning.", "creator": "PScript5.dll Version 5.2.2"}}}