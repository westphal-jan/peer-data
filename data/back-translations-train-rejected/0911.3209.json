{"id": "0911.3209", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Nov-2009", "title": "Apply Ant Colony Algorithm to Search All Extreme Points of Function", "abstract": "To find all extreme points of multimodal functions is called extremum problem, which is a well known difficult issue in optimization fields. Applying ant colony optimization (ACO) to solve this problem is rarely reported. The method of applying ACO to solve extremum problem is explored in this paper. Experiment shows that the solution error of the method presented in this paper is less than 10^-8. keywords: Extremum Problem; Ant Colony Optimization (ACO)", "histories": [["v1", "Tue, 17 Nov 2009 03:34:19 GMT  (704kb)", "http://arxiv.org/abs/0911.3209v1", "23 pages, 7 figures"]], "COMMENTS": "23 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["chao-yang pang", "hui liu", "xia li", "yun-fei wang", "ben-qiong hu"], "accepted": false, "id": "0911.3209"}, "pdf": {"name": "0911.3209.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Chao-Yang Pang", "Yun-Fei Wang"], "emails": ["cypang@live.com;", "cypang@sicnu.edu.cn"], "sections": [{"heading": null, "text": "The application of ant colony optimization (ACO) to solve this problem is rarely reported, and the method of using ACO to solve the Extremum problem is explained in this essay. Experiment shows that the solution error of the method presented in this essay is less than 10 \u2212 8.Keywords: Extremum Problem; Ant Colony Optimization (ACO) \u0445 Electronic Address: cypang @ live.com; Electronic Address: cypang @ sicnu.edu.cnI. INTRODUCTION"}, {"heading": "A. Extremum Problem", "text": "This year is the highest in the history of the country."}, {"heading": "C. Framework of ACO", "text": "In what order should he visit them to minimize the distance traveled? The typical application of ACO is to solve TSP, and its basic idea is described as follows: When an ant passes an edge, it releases pheromone at that edge. And the pheromone causes other ants to traverse that edge. Finally, all ants choose a unique route, and this route is the shortest possible. The framework of ACO is introduced as follows: Step 1 (Initialization): Posit M ants in different M cities at random; Pre-assign maximum iteration number tmax; Let t = 0, where t denotes the t \u2212 th iteration level; Initial height of pheromones of each edge.Step2 While (< Pre-assign maximum iteration number tmax; Let t = 0, where t denotes the iteration level of a city."}, {"heading": "II. APPLY ACO TO SEARCH ALL EXTREME POINTS OF FUNCTION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Basic Idea", "text": "Suppose the function is f (x), x is a real number and it belongs to a closed interval [a, b]. The purpose of this paper is to extract all the extreme points so that the corresponding value is locally minimal. The basic idea of this paper is roughly described as follows: Divide the interval [a, b] into many small intervals of the same size. Suppose these small intervals are {I1, I2, \u00b7, In} and the center of the interval Ii is denoted by xi. Suppose the neighboring interval Ii is Ii + 1 (or Ii \u2212 1) and an ant is placed in the center of each small interval. If f (xi) > f (xi + 1), the ant may move in the interval Ii + 1 into the interval Ii + 1, only the preference is a virtual edge between Ii and Ii + 1. And let us assume that the virtual Ii is (Ii)."}, {"heading": "B. Partition of Interval and Initialization", "text": "Suppose the interval [a, b] is divided into n small intervals of the same size, denoted by {I1, I2, \u00b7 \u00b7 \u00b7, In}, where n is a pre-assigned number. Then, each interval has size\u03b4 = b \u2212 anIi = [a + (i \u2212 1) \u03b4, a + i\u03b4] The i \u2212 th interval Ii has a center xi.xi = a + (i \u2212 12) \u03b4Suppose t stands for the t \u2212 th iteration step of ACO and it is initialized as zero (i.e. t = 0). Let us place n ants at the centers of n intervals, and each interval has only one ant. Suppose that these ants are denoted by a1, a2, \u00b7 an, and ant ai is associated with the i \u2212 th interval Iperci. Each ant becomes an initial pheromone in its associated interval Ii.e., a constant (0)."}, {"heading": "C. Rule of Ant Moving", "text": "For example, take the one-dimensional function Neighbor (Ii) = {Ii + 1}, i = 1 {Ii \u2212 1, Ii + 1}, i = 2 \u00b7 \u00b7 \u00b7 n \u2212 1 {Ii \u2212 1}, i = nAs discussed in Section A, the ant that remains in interval Ii moves into the neighboring interval indicated by Ij, just as there is a virtual edge e (Ii, Ij). The weight of the virtual edge is | f (xi) \u2212 f (xj) |. Then the heuristic factor Ii = | f (xi) \u2212 f (xj) | Interval Ii contains anthrax. If f (xi) > f (xj) anthrax is allowed to move into the neighboring interval Ij. Otherwise it is forbidden to move."}, {"heading": "D. The Rule of Pheromone Updating", "text": "Suppose the ant stays in the interval Ii and moves to the neighboring interval Ij. After moving to Ij, it releases pheromone, where C1 is a positive constant. The greater the pheromone amount, the higher the amount of pheromone released, the more likely it is that other ants will be attracted to interval Ij. Not only the ant ak comes to Ij and releases pheromone, but also other ants that move in interval Ij and release pheromone. Suppose that there are q ants that move during the t \u2212 th iteration step to interval Ij, which is denoted by aj1, aj2, \u00b7 \u00b7 \u00b7 ajq."}, {"heading": "E. Keeping Only the Intervals Containing Ants to Cut Down Search Range", "text": "After several iterations, the distribution of ants has the characteristic that all ants stay in the intervals that have smaller functional values and other intervals do not contain ants. That is, extreme points are included in the intervals that ants contain. Then, hold the intervals with ants and delete other intervals to refresh the search area. Thus, the updated search area became smaller. Subdividing the updated search area into smaller intervals leads to a much smaller search area at the next iteration step. If the intervals become sufficiently small, all ants stay around extreme points, the centers of the intervals are their approximate values. Figure 2 shows the distribution characteristic of ants. In addition, ACO is known to run slowly, which is the bottleneck in application. And it bypasses this bottleneck that only keeps the intervals ants have to reduce the search area."}, {"heading": "F. Method of Searching All ExtremePoints", "text": "Step 1 (Initialization): Divide the domain [a, b] into many small intervals and insert an ant at each interval; perform a different initialization; the detail is shown in Section B. Suppose \u03b4 is the length of the interval and \u03b5 is a stop threshold.Step 2 While (\u03b4 > \u03b5) {Step 2.1: All ants move into new intervals according to the rule shown in Section C Step 2.2: Update the pheromone according to the rule shown in Section D. Step 2.3: Update the search area according to Section E and divide it into smaller intervals (Suppose the number of these intervals is nale n1).Calculate the size of the interval and set it to \u03b4.} Step 3 Extract all intervals Intervals Intervals Intervals containing ants, the centers of the intervals are the approximate imitations of extreme point components.If each interval is multidimensional, each of the intervals is smaller, the combination is vector."}, {"heading": "G. An Example", "text": "To make the above method easy to understand, a simple example is given as follows: Suppose the domain of the one-dimensional function is divided into 3 intervals I1, I2, I3, whose associated center is x1, x2, and x3, respectively. Initially, the ant a1, a2, and a3 are set to x1, x2, and x3, respectively. Check the first ant: If f (x1) > f (x2), the ant a1 will move in interval I2. Otherwise, do nothing. Check the second ant: If its interval is so unique (e.g. I3) that f (x2) > f (x3), the ant a2 will move in interval I3. If f (x2) is smaller than f (x2) and the ant a2 is smaller than f (x3), it is uncertain that the ant a2 will move in I1 or I3, and the ant will pick the interval after the 3rd interval."}, {"heading": "III. EXPERIMENT", "text": "In this section, several functions are tested. Parameters are listed below: const = 10, \u03b1 = 1, \u03b2 = 1, C1 = 1, \u03c1 = 0.3, \u03b5 = 0.0001 Two performances are taken into account, the errors (ratio of inaccuracy) r and runtime.Error r is defined as (x \u2032 0) its ap-proximation is calculated by the method presented in this paper. \u2212 In addition, the hardware condition is: Notebook DELL D520, CPU 1.66 GHZ.A. instance 1 (see Table 1 and Fig.3): f1 x x = sin 6 (5.1), x2) is the limit."}, {"heading": "IV. CONCLUSION", "text": "It is rarely reported that the application of ant colony optimization (ACO) to solve the problem is referred to as the Extremum problem, and the motivation of this paper is to explore the ACO application method to solve the problem. In this paper, the following method is presented: Divide the functional area into many intervals and add an ant at each interval. And then design the rule so that each ant moves into the interval that contains an extreme point nearby. Finally, all ants stay around extreme points. The method presented in this paper has the following three advantages: 1. The solving accuracy is high. Experiment shows that the solving error is less than 10 \u2212 8. 2. The calculated solution is stable (robust). Ants only show the interval that contains extreme points, not the exact position of the extreme point. It is easy for ants to find an interval, although the function of a specific point in the ACO section is fast (some 2.5 but slow in the final interval)."}, {"heading": "Acknowledgments", "text": "The authors appreciate the discussion by the members of the Gene Computation Group, J. Gang, X. Li, C.-B. Wang, W. Hu, S.-P. Wang, Q. Yang, J.-L. Zhou, P. Shuai, L.-J. Ye. The authors appreciate the help of Prof. J. Zhang, Z.-Lin Pu, X.-P. Wang, J. Zhou, and Q. Li. [1] Min-qiang Li, Ji-song Kou, \"Coordinate multi-population genetic algorithms for multimodalfunction optimization,\" Acta Automatica Sinica, 2002,28 (04): 497-504."}, {"heading": "66, 1997.", "text": "[14] M. Manfrin, M. Birattari, T. Stu tzle, and M. Dorigo, \"Parallel ant colony optimization for thetraveling salesman problem,\" In M. Dorigo, L. M. Gambardella, M. Birattari, A. Martinoli, R.Poli, and T. Stu tzle (Eds.) Ant Colony Optimization and Swarm Intelligence, 5th InternationalWorkshop, ANTS 2006, LNCS 4150 pp. 224-234. Springer, Berlin, Germany. Conference herodin Br\u00fcssel, Belgium. September 4-7, 2006. [15] L. M. Gambardella, D. Taillard, and M. Dorigo, \"Ant colonies for the quadratic assignmentproblem,\" Journal of the Operational Research Society, 50 (2): 167-176, 1999. [16] L. M. Gambarbardella and M. Dorigo, \"Trenigo learning approach to the travelingproblem.\""}, {"heading": "409-433 , 2008.", "text": "[25] Walter J. Gutjahr, \"First steps to the runtime complexity analysis of ant colony technology optimization,\" Computers and Operations Research 35 (no. 9), pp. 2711-2727, 2008. [26] Chao-Yang Pang, Wei Hu, Xia Li, and Ben-Qiong Hu, \"Applying local clustering methodto improve the running speed of Ant Colony Optimization,\" arXiv: 0907.1012v2 [cs.NE] 7 Jul2009. [on line] http: / / arxiv.org / abs / 0907.1012 [27] Chao-Yang Pang, Wei Hu, Xia Li, and Ben-Qiong Hu, \"Applying local clus-tering method to improve the running speed of Ant Colony Optimigorithony Y,\" arxiv.org / abs / 0907.1012, \"Chao-Yang Yang Yang Pang.\""}, {"heading": "V. APPENDIX", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Appendix I", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1. Instance 4:", "text": "f4 (x) = (x + 1) (x + 2) (x + 3) (x + 4) (x + 5) + 5 x [\u2212 5, 0] The additional parameters are n = 30 and n1 = 10."}, {"heading": "2. Instance 5:", "text": "f5 (x) = (x + 2) cos (9x) + sin (7x) x [0, 4] The additional parameters are n = 95 and n1 = 10B. Appendix II.f2 (x) = 5e \u2212 0.5x sin (30x) + e0.2x sin (20x) + 6, x \u0441 [0, 8] The additional parameters are n = 480 and n1 = 10."}, {"heading": "C. Appendix III.", "text": "f3 (x1, x2) = x 2 1 + x 2 \u2212 cos (18x1) \u2212 cos (18x2), x1, x2 [\u2212 1, 1] The interval [\u2212 1, 1] [\u2212 1, 1] is initially divided into n = 40 x 40 intervals."}], "references": [{"title": "Coordinate multi-population genetic algorithms for multimodal function optimization", "author": ["Min-qiang Li", "Ji-song Kou"], "venue": "Acta Automatica Sinica, 2002,28(04):497-504.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "The simulated annealing algorithm for multi-modal function problem", "author": ["Qing-yun Tao", "Hui-yun Quan"], "venue": "Computer Engineering and Applications, 2006,(14):63-64,92.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Effective optimization algorithm for multimodal functions", "author": ["Li Li", "Hong-qi Li", "Shao-long Xie"], "venue": "Application Research of Computers, 2008,25(10):4792, 5792,6792.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Application-oriented fast optimizer for multi-peak searchin", "author": ["Jiang Wu", "Han-ying Hu", "Ying Wu"], "venue": "Application Research of Computers 2008,25(12):3617-3620. 15", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "New algorithm for multimodal function optimization based on immune algorithm and Hopfield neural network", "author": ["Rui-ying Zhou", "Jun-hua Gu", "Na-na Li", "Qing Tan"], "venue": "Computer Applications, 2007,27(7):1751-1753,1756.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Positive feedback as a search strategy", "author": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "venue": "Technical Report 91-016,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1991}, {"title": "Distributed Optimization by Ant Colonies", "author": ["A. Colorni", "M. Dorigo", "V. Maniezzo"], "venue": "F. J.Varela and P. Bourgine, editors, Towards a Practice of Autonomous Systems: Proceedings of the First European Conference on Artificial Life, pages 134-142. MIT Press, Cambridge, MA,1992.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1992}, {"title": "Optimization Learning and Natural Algorithms", "author": ["M. Dorigo"], "venue": "PhD thesis, Dipartimento di Elettronica, Politecnico di Milano, Milan, Italy, 1992.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1992}, {"title": "THE Ant System: Optimization by a colony of cooperating agents", "author": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "venue": "IEEE Transactions on Systems, Man, and, Cybernetics Part B: Cybernetics. 26(1): 29-41.1996.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1996}, {"title": "HANDBOOKS IN OPER- ATIONS RESEARCH AND MANAGEMENT SCIENCE, 7: NETWORK MODELS", "author": ["M.O. Ball", "T.L. Magnanti", "C.L. Monma", "G.L. Nemhauser"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1995}, {"title": "Nemhauser,HANDBOOKS IN OPERA- TIONS RESEARCH AND MANAGEMENT SCIENCE, 8: NETWORK ROUTING", "author": ["M.O. Ball", "T.L. Magnanti", "C.L. Monma", "G.L"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1995}, {"title": "Pareto ant colony optimization with IP preprocessing in multiobjective project portfolio selection", "author": ["K. Doerner", "Walter J. Gutjahr", "R.F. Hartl", "C. Strauss", "C. Stummer"], "venue": "European Journal of Operational Research 171, pp. 830-841 ,2006.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Ant Colony System: A cooperative learning approach to the traveling salesman problem", "author": ["M. Dorigo", "L.M. Gambardella"], "venue": "IEEE Transactions on Evolutionary Computation, 1(1):53- 66, 1997.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1997}, {"title": "Parallel ant colony optimization for the traveling salesman problem", "author": ["M. Manfrin", "M. Birattari", "T. St\u0171tzle", "M. Dorigo"], "venue": "M. Dorigo, L. M. Gambardella, M. Birattari, A. Martinoli, R. Poli, and T. St\u0171tzle (Eds.) Ant Colony Optimization and Swarm Intelligence, 5th International Workshop, ANTS 2006, LNCS 4150 pp. 224-234. Springer, Berlin, Germany. Conference held in Brussels, Belgium. September 4-7, 2006. 16", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Ant colonies for the quadratic assignment problem", "author": ["L.M. Gambardella", "D. Taillard", "M. Dorigo"], "venue": "Journal of the Operational Research Society, 50(2):167-176, 1999.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1999}, {"title": "Ant-Q: A reinforcement learning approach to the traveling salesman problem", "author": ["L.M. Gambardella", "M. Dorigo"], "venue": "A. Prieditis and S. Russell, editors, Machine Learning: Proceedings of the Twelfth International Conference on Machine Learning, pages 252-260. Morgan Kaufmann Publishers, San Francisco, CA, 1995.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1995}, {"title": "Applying the ant system to the vehicle routing problem", "author": ["B. Bullnheimer", "R.F. Hartl", "C. Strauss"], "venue": "IN I. H. Osman, S. Vo, S. Martello and C. Roucairol, editors, Meta- Heuristics:Advances and Trends in Local Search Paradigms for Optimization, pages 109-120. KluwerAcademics, 1998.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}, {"title": "An ant systemfor bus driver scheduling", "author": ["P. Forsyth", "A. Wren"], "venue": "Technical Report 97.25, University of Leeds , School of Computer Studies , July 1997. Presented at the 7th International Workshop on Computer - Aided Scheduling of Public Transport , Boston , July 1997.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "Data mining with an ant colony optimization algorithm", "author": ["Rafael S. Parpinelli", "Heitor S. Lopes"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 6, no. 4, pp. 321-332, 2002.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2002}, {"title": "On the invariance of ant colony optimization", "author": ["M. Birattari", "P. Pellegrini", "M. Dorigo"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 11, no. 6, pp. 732-742, 2007.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "A graph-based ant system and its convergence", "author": ["W.J. Gutijahr"], "venue": "Future Generation Computer Systems 16 , 873-888, 2000.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2000}, {"title": "A Short Convergence Proof for a Class of ACO Algorithms", "author": ["T. St  .. uezle", "M. Dorigo"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "Experiment study of entropy convergence of ant colony optimization", "author": ["Chao-Yang Pang", "Chong-Bao Wang", "Ben-Qiong Hu"], "venue": "arXiv:0905.1751v4 [cs.NE] 25 Oct 2009. [on line] http://arxiv.org/abs/0905.1751", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Runtime analysis of ant colony optimization with best-so-far reinforcement", "author": ["Walter J. Gutjahr", "Giovanni Sebastiani"], "venue": "Methodology and Computing in Applied Probability 10, pp. 409-433 , 2008.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "First steps to the runtime complexity analysis of ant colony optimization", "author": ["Walter J. Gutjahr"], "venue": "Computers and Operations Research 35 (no. 9), pp. 2711-2727 ,2008.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Applying local clustering method to improve the running speed of Ant Colony Optimization", "author": ["Chao-Yang Pang", "Wei Hu", "Xia Li", "Ben-Qiong Hu"], "venue": "arXiv:0907.1012v2 [cs.NE] 7 Jul 17  2009. [on line] http://arxiv.org/abs/0907.1012", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Applying local clustering method to improve the running speed of Ant Colony Optimization", "author": ["Chao-Yang Pang", "Wei Hu", "Xia Li", "Ben-Qiong Hu"], "venue": "[on line]http://arxiv.org/pdf/0907.1012", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1012}, {"title": "The ant colony metaphor for searching continuous spaces", "author": ["G.A. Bilchev", "I.C. Parmee"], "venue": "Lecture Notes in Computer Science, 993:25 \u030339, 1995.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1995}, {"title": "Multi-Colony Ant Algorithm for Continuous Multi-Reservoir Operation Optimization Problem", "author": ["M.R. Jalali", "A. Afshar", "M.A. Mari\u0148o"], "venue": "Water Resour Manage 21:1429\u20131447,2007.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "Cooperative distributed search: the ant\u2019s way", "author": ["M Wodrich", "G Bilche"], "venue": "Control Cybern (3):413\u2013446,1997.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1997}, {"title": "Ant colony approach to continuous function optimization", "author": ["M Mathur", "SB Karale", "S Priye", "VK Jyaraman", "BD Kulkarni"], "venue": "Ind Eng Chem Res 39:3814\u20133822, 2000.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2000}, {"title": "Semi-continuous ACO algorithms (technical report)", "author": ["M.R. Jalali", "A. Afshar"], "venue": "Hydroinformatics Center,Civil Engineering Department, Iran University of Science and Technology, Tehran, Iran,2005b.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "P.-Siarry,\u201cA new ant colony algorithm using the hierarchical concept aimed at optimization of multiminima continuous functions,", "author": ["J. Dreo"], "venue": "Proceedings of the 3rd international workshop on ant algorithms (ANTS 2002),", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "To solve the extremum problem, many methods of optimization are applied, such as genetic algorithm (GA) [1], simulated annealing (SA) [2], particle swarm optimization algorithm (PSO) [3, 4], immune algorithm ( IA) [5], and so on.", "startOffset": 104, "endOffset": 107}, {"referenceID": 1, "context": "To solve the extremum problem, many methods of optimization are applied, such as genetic algorithm (GA) [1], simulated annealing (SA) [2], particle swarm optimization algorithm (PSO) [3, 4], immune algorithm ( IA) [5], and so on.", "startOffset": 134, "endOffset": 137}, {"referenceID": 2, "context": "To solve the extremum problem, many methods of optimization are applied, such as genetic algorithm (GA) [1], simulated annealing (SA) [2], particle swarm optimization algorithm (PSO) [3, 4], immune algorithm ( IA) [5], and so on.", "startOffset": 183, "endOffset": 189}, {"referenceID": 3, "context": "To solve the extremum problem, many methods of optimization are applied, such as genetic algorithm (GA) [1], simulated annealing (SA) [2], particle swarm optimization algorithm (PSO) [3, 4], immune algorithm ( IA) [5], and so on.", "startOffset": 183, "endOffset": 189}, {"referenceID": 4, "context": "To solve the extremum problem, many methods of optimization are applied, such as genetic algorithm (GA) [1], simulated annealing (SA) [2], particle swarm optimization algorithm (PSO) [3, 4], immune algorithm ( IA) [5], and so on.", "startOffset": 214, "endOffset": 217}, {"referenceID": 5, "context": "Ant Colony Optimization (ACO) was first proposed by Dorigo (1991) [6, 7, 8].", "startOffset": 66, "endOffset": 75}, {"referenceID": 6, "context": "Ant Colony Optimization (ACO) was first proposed by Dorigo (1991) [6, 7, 8].", "startOffset": 66, "endOffset": 75}, {"referenceID": 7, "context": "Ant Colony Optimization (ACO) was first proposed by Dorigo (1991) [6, 7, 8].", "startOffset": 66, "endOffset": 75}, {"referenceID": 8, "context": "ACO imitates this feature and it becomes an effective algorithm for the optimization problems [9].", "startOffset": 94, "endOffset": 97}, {"referenceID": 9, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 77, "endOffset": 89}, {"referenceID": 10, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 77, "endOffset": 89}, {"referenceID": 11, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 77, "endOffset": 89}, {"referenceID": 12, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 132, "endOffset": 140}, {"referenceID": 13, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 132, "endOffset": 140}, {"referenceID": 14, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 176, "endOffset": 180}, {"referenceID": 15, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 215, "endOffset": 219}, {"referenceID": 16, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 250, "endOffset": 258}, {"referenceID": 17, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 250, "endOffset": 258}, {"referenceID": 18, "context": "It has been successfully applied to many combinatorial optimization problems [10, 11, 12], such as Traveling Salesman Problem (TSP) [13, 14], Quadratic Assignment Problem(QAP) [15], Job-shop Scheduling Problem(JSP) [16], Vehicle Routing Problem(VRP) [17, 18], Data Mining(DM) [19] and so on.", "startOffset": 276, "endOffset": 280}, {"referenceID": 19, "context": "Birattari proves the invariance of ACO and introduced three new ACO algorithms [20].", "startOffset": 79, "endOffset": 83}, {"referenceID": 20, "context": "Gutjahr studied the convergence of ACO firstly in 2000 [21].", "startOffset": 55, "endOffset": 59}, {"referenceID": 21, "context": "Dorigo proved the existence of the ACO convergence under two conditions, one is to only update the pheromone of the shortest route generated at each iteration step, the other is that the pheromone on all routes has lower bound [22].", "startOffset": 227, "endOffset": 231}, {"referenceID": 22, "context": "found a potential new view point to study ACO convergence under general condition, that is entropy convergence in 2009 [23].", "startOffset": 119, "endOffset": 123}, {"referenceID": 22, "context": "[23], the following conclusion is get: ACO may not converges to the optimal solution in practice, but its entropy is convergent.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "Gutjahr presented some theoretical results about ACO runtime [24, 25].", "startOffset": 61, "endOffset": 69}, {"referenceID": 24, "context": "Gutjahr presented some theoretical results about ACO runtime [24, 25].", "startOffset": 61, "endOffset": 69}, {"referenceID": 25, "context": "do the following attempt [26].", "startOffset": 25, "endOffset": 29}, {"referenceID": 27, "context": "The first method for continuous-space optimization problems, called Continuous ACO (CACO), was proposed by Bilchev and Parmee (1995)[29], and later it was used by some others [30, 31, 32, 33].", "startOffset": 132, "endOffset": 136}, {"referenceID": 28, "context": "The first method for continuous-space optimization problems, called Continuous ACO (CACO), was proposed by Bilchev and Parmee (1995)[29], and later it was used by some others [30, 31, 32, 33].", "startOffset": 175, "endOffset": 191}, {"referenceID": 29, "context": "The first method for continuous-space optimization problems, called Continuous ACO (CACO), was proposed by Bilchev and Parmee (1995)[29], and later it was used by some others [30, 31, 32, 33].", "startOffset": 175, "endOffset": 191}, {"referenceID": 30, "context": "The first method for continuous-space optimization problems, called Continuous ACO (CACO), was proposed by Bilchev and Parmee (1995)[29], and later it was used by some others [30, 31, 32, 33].", "startOffset": 175, "endOffset": 191}, {"referenceID": 31, "context": "The first method for continuous-space optimization problems, called Continuous ACO (CACO), was proposed by Bilchev and Parmee (1995)[29], and later it was used by some others [30, 31, 32, 33].", "startOffset": 175, "endOffset": 191}, {"referenceID": 32, "context": "Other methods include that, in 2002, Continuous Interacting Ant Colony (CIAC) was proposed by Dreo and Siarry [34], and in 2003, an adaptive ant colony system algorithm for continuous-space optimization problems was proposed by Li Yan-jun [35], and so on.", "startOffset": 110, "endOffset": 114}, {"referenceID": 0, "context": "5), x \u2208 [0, 1] In the experiment, additional parameter is n = 20 and n1 = 10.", "startOffset": 8, "endOffset": 14}, {"referenceID": 7, "context": "5x sin(30x) + e sin(20x) + 6, x \u2208 [0, 8] Instance 2 is a typical test function, which include many extreme points and any small change of argument x will result in big change.", "startOffset": 34, "endOffset": 40}, {"referenceID": 0, "context": "[1] Min-qiang Li, Ji-song Kou, \u201cCoordinate multi-population genetic algorithms for multimodal function optimization,\u201d Acta Automatica Sinica, 2002,28(04):497-504.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Qing-yun Tao, Hui-yun Quan, \u201cThe simulated annealing algorithm for multi-modal function problem,\u201d Computer Engineering and Applications, 2006,(14):63-64,92.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Li Li, Hong-qi Li, Shao-long Xie, \u201c Effective optimization algorithm for multimodal functions,\u201d Application Research of Computers, 2008,25(10):4792, 5792,6792.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Jiang Wu, Han-ying Hu, Ying Wu, \u201cApplication-oriented fast optimizer for multi-peak searchin,\u201d Application Research of Computers 2008,25(12):3617-3620.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Rui-ying Zhou, Jun-hua Gu, Na-na Li, Qing Tan, \u201cNew algorithm for multimodal function optimization based on immune algorithm and Hopfield neural network,\u201d Computer Applications, 2007,27(7):1751-1753,1756.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] B.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] Rafael S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] W.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] Chao-Yang Pang, Chong-Bao Wang and Ben-Qiong Hu, \u201cExperiment study of entropy convergence of ant colony optimization,\u201d arXiv:0905.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "1751 [24] Walter J.", "startOffset": 5, "endOffset": 9}, {"referenceID": 24, "context": "[25] Walter J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] Chao-Yang Pang, Wei Hu, Xia Li, and Ben-Qiong Hu, \u201cApplying local clustering method to improve the running speed of Ant Colony Optimization,\u201d arXiv:0907.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "1012 [27] Chao-Yang Pang, Wei Hu, Xia Li, and Ben-Qiong Hu, \u201cApplying local clustering method to improve the running speed of Ant Colony Optimization,\u201d [on line]http://arxiv.", "startOffset": 5, "endOffset": 9}, {"referenceID": 27, "context": "1751 [29] G.", "startOffset": 5, "endOffset": 9}, {"referenceID": 28, "context": "[30] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[31] Wodrich M, Bilche G, \u201cCooperative distributed search: the ant\u2019s way,\u201d Control Cybern (3):413\u2013446,1997.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[32] Mathur M, Karale SB, Priye S, Jyaraman VK, Kulkarni BD, \u201cAnt colony approach to continuous function optimization,\u201d Ind Eng Chem Res 39:3814\u20133822, 2000.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[33] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[34] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "f5(x) = (x+ 2) cos(9x) + sin(7x) x \u2208 [0, 4] The additional parameters are n = 95 and n1 = 10 Table 3.", "startOffset": 37, "endOffset": 43}, {"referenceID": 7, "context": "5x sin(30x) + e sin(20x) + 6, x \u2208 [0, 8] The additional parameters are n = 480 and n1 = 10.", "startOffset": 34, "endOffset": 40}], "year": 2009, "abstractText": "Ben-Qiong Hu College of Information Management, Chengdu University of Technology, 610059, China Abstract To find all extreme points of multimodal functions is called extremum problem, which is a well known difficult issue in optimization fields. Applying ant colony optimization (ACO) to solve this problem is rarely reported. The method of applying ACO to solve extremum problem is explored in this paper. Experiment shows that the solution error of the method presented in this paper is less than 10\u22128.", "creator": "LaTeX with hyperref package"}}}