{"id": "0911.5708", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2009", "title": "Learning in a Large Function Space: Privacy-Preserving Mechanisms for SVM Learning", "abstract": "Several recent studies in privacy-preserving learning have considered the trade-off between utility or risk and the level of differential privacy guaranteed by mechanisms for statistical query processing. In this paper we study this trade-off in private Support Vector Machine (SVM) learning. We present two efficient mechanisms, one for the case of finite-dimensional feature mappings and one for potentially infinite-dimensional feature mappings with translation-invariant kernels. For the case of translation-invariant kernels, the proposed mechanism minimizes regularized empirical risk in a random Reproducing Kernel Hilbert Space whose kernel uniformly approximates the desired kernel with high probability. This technique, borrowed from large-scale learning, allows the mechanism to respond with a finite encoding of the classifier, even when the function class is of infinite VC dimension. Differential privacy is established using a proof technique from algorithmic stability. Utility--the mechanism's response function is pointwise epsilon-close to non-private SVM with probability 1-delta--is proven by appealing to the smoothness of regularized empirical risk minimization with respect to small perturbations to the feature mapping. We conclude with a lower bound on the optimal differential privacy of the SVM. This negative result states that for any delta, no mechanism can be simultaneously (epsilon,delta)-useful and beta-differentially private for small epsilon and small beta.", "histories": [["v1", "Mon, 30 Nov 2009 20:34:45 GMT  (142kb,DS)", "http://arxiv.org/abs/0911.5708v1", "21 pages, 1 figure"]], "COMMENTS": "21 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.LG cs.CR cs.DB", "authors": ["benjamin i p rubinstein", "peter l bartlett", "ling huang", "nina taft"], "accepted": false, "id": "0911.5708"}, "pdf": {"name": "0911.5708.pdf", "metadata": {"source": "CRF", "title": "LEARNING IN A LARGE FUNCTION SPACE: PRIVACY-PRESERVING MECHANISMS FOR SVM LEARNING", "authors": ["Benjamin I. P. Rubinstein", "Peter L. Bartlett", "Ling Huang", "Nina Taft"], "emails": [], "sections": [{"heading": "1. Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2. Background & Definitions", "text": "It is the only information that we are able to familiarize ourselves with accessing a database that is content with accessing a database. (D) It is the only information that we provide with access to a database. (D) It is the only information that we provide with access to a database. (D) It is the only information that we provide with access to a database. (D) It is the only information that we provide with access to a database. (D) It is the only information that we provide with access to a database. (D) It is the only information that we provide with access to a database. (D) We adopt the following strong notion of privacy. (D) It is the only response from M to D. (D) We assume that M offers a randomized privacy. (D)"}, {"heading": "3. Mechanism for Finite Feature Maps", "text": "As the first step towards private SVM learning processes, we begin with the consideration of the simple case of nite F - dimensional approaches in practice. (D) D (D) S (D) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S) S (S) S (S) S (S) S (S) S S (S) S S S (S) S S S (S) S S S (S) S S (S) S S (S) S S (S) S (S) S S (S) S (S) S (S) S S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S (S) S (S) S (S (S) S (S) S (S) S (S (S) S (S (S) S (S) S (S (S) S (S (S) S (S (S) S (S) S (S (S) S (S) S (S) S (S) S (S (S) S (S) S (S) S (S) S (S) S (S (S (S) S (S) S) S (S (S) S (S (S) S) S (S) S (S) S (S (S) S (S (S) S (S) S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S (S (S) S (S) S (S) S ("}, {"heading": "4. Mechanism for Translation-Invariant Kernels", "text": "Let us now consider the problem of private learning in a RKHS H, which was triggered by a nite dimensional function."}, {"heading": "5. Hinge-Loss and an Upper Bound on Optimal Differential Privacy", "text": "We start with \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \""}, {"heading": "7. Conclusion & Open Problems", "text": "We have presented a pair of new mechanisms for private SVM learning. In each case, we have established a quantitative privacy via the algorithmic stability of regulated empirical risk minimization. In order to achieve a benefit among nite-dimensional feature mappings, we perform regulated ERM in a random reproducing kernel Hilbert Space, the core of which approaches the target RKHS kernel. This trick, borrowed from large-scale learning, allows the mechanism to react privately with a nite representation of a maximum hyperplane class. Subsequently, we found that the high probability of striking similarity between the resulting function and the SVM class is due to a new smooth result of regulated ERM with respect to disturbances in the RKHS. The limits of the potential privacy and benefit combine with the upper limit of the optimal dierential privacy of SVM learning for hinge-probability, these quantity losses are as large as the hinge number of privacy they are."}, {"heading": "Acknowledgments", "text": "We thank Ali Rahimi for the helpful discussions in connection with this research and thank him for the support of NSF through the grant DMS-0707060 and the support of Siebel Scholars Foundation."}, {"heading": "Appendix A. Proofs for Subdifferentiable Loss Functions", "text": "The most important results are related to the non-diversified loss functions, so that they are available for the non-diversified loss functions. (D) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S S (S) S (S) S S (S) S (S) S (S) S (S) S (S) S S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S (S) S (S) S (S (S) S (S) S (S (S) S (S (S) S (S) S (S (S) S (S) S (S (S (S) S (S) S (S (S) S (S) S (S (S) S (S) S (S (S (S) S (S (S) S (S) S (S (S) S (S (S) S) S (S (S) S (S (S) S) S (S) S (S (S) S (S) S (S) S) S (S (S) S (S) S (S (S) S (S) S (S) S) S (S (S) S) S (S (S) S) S (S (S) S (S) S (S (S) S (S (S) S) S"}], "references": [{"title": "Privacy, accuracy, and consistency too: a holistic solution to contingency table release", "author": ["Boaz Barak", "Kamalika Chaudhuri", "Cynthia Dwork", "Satyen Kale", "Frank McSherry", "Kunal Talwar"], "venue": "Proceedings of the Twenty-Sixth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,", "citeRegEx": "Barak et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Barak et al\\.", "year": 2007}, {"title": "Pattern Recognition and Machine Learning", "author": ["Christopher M. Bishop"], "venue": null, "citeRegEx": "Bishop.,? \\Q2006\\E", "shortCiteRegEx": "Bishop.", "year": 2006}, {"title": "Practical privacy: the SuLQ framework", "author": ["Avrim Blum", "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim"], "venue": "Proceedings of the Twenty-Fourth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,", "citeRegEx": "Blum et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2005}, {"title": "A learning theory approach to non-interactive database privacy", "author": ["Avrim Blum", "Katrina Ligett", "Aaron Roth"], "venue": "Proceedings of the 40th Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Blum et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2008}, {"title": "A tutorial on support vector machines for pattern recognition", "author": ["Christopher J.C. Burges"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "Burges.,? \\Q1998\\E", "shortCiteRegEx": "Burges.", "year": 1998}, {"title": "Privacy-preserving logistic regression", "author": ["Kamalika Chaudhuri", "Claire Monteleoni"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Chaudhuri and Monteleoni.,? \\Q2009\\E", "shortCiteRegEx": "Chaudhuri and Monteleoni.", "year": 2009}, {"title": "An Introduction to Support Vector Machines", "author": ["Nello Cristianini", "John Shawe-Taylor"], "venue": null, "citeRegEx": "Cristianini and Shawe.Taylor.,? \\Q2000\\E", "shortCiteRegEx": "Cristianini and Shawe.Taylor.", "year": 2000}, {"title": "Distribution-free performance bounds for potential function rules", "author": ["Luc P. Devroye", "T.J. Wagner"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Devroye and Wagner.,? \\Q1979\\E", "shortCiteRegEx": "Devroye and Wagner.", "year": 1979}, {"title": "Revealing information while preserving privacy", "author": ["Irit Dinur", "Kobbi Nissim"], "venue": "Proceedings of the Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,", "citeRegEx": "Dinur and Nissim.,? \\Q2003\\E", "shortCiteRegEx": "Dinur and Nissim.", "year": 2003}, {"title": "Di erential privacy and robust statistics", "author": ["Cynthia Dwork", "Jing Lei"], "venue": "Proceedings of the 41st Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Dwork and Lei.,? \\Q2009\\E", "shortCiteRegEx": "Dwork and Lei.", "year": 2009}, {"title": "New e cient attacks on statistical disclosure control mechanisms", "author": ["Cynthia Dwork", "Sergey Yekhanin"], "venue": "In CRYPTO 2008: Proceedings of the 28th Annual conference on Cryptology,", "citeRegEx": "Dwork and Yekhanin.,? \\Q2008\\E", "shortCiteRegEx": "Dwork and Yekhanin.", "year": 2008}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "In 3rd Theory of Cryptography Conference (TCC", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "The price of privacy and the limits of LP decoding", "author": ["Cynthia Dwork", "Frank McSherry", "Kunal Talwar"], "venue": "Proceedings of the Thirty-Ninth Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Dwork et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2007}, {"title": "On the complexity of di erentially private data release: e cient algorithms and hardness results", "author": ["Cynthia Dwork", "Moni Naor", "Omer Reingold", "Guy N. Rothblum", "Salil Vadhan"], "venue": "Proceedings of the 41st Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Dwork et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2009}, {"title": "What can we learn privately", "author": ["Shiva Prasad Kasiviswanathan", "Homin K. Lee", "Kobbi Nissim", "Sofya Raskhodnikova", "Adam Smith"], "venue": "Proceedings of the 2008 49th Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "Kasiviswanathan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kasiviswanathan et al\\.", "year": 2008}, {"title": "Algorithmic stability and sanity-check bounds for leave-one-out crossvalidation", "author": ["Michael Kearns", "Dana Ron"], "venue": "Neural Computation,", "citeRegEx": "Kearns and Ron.,? \\Q1999\\E", "shortCiteRegEx": "Kearns and Ron.", "year": 1999}, {"title": "Some results on Tchebyche an spline functions", "author": ["George Kimeldorf", "Grace Wahba"], "venue": "Journal of Mathematical Analysis and Applications,", "citeRegEx": "Kimeldorf and Wahba.,? \\Q1971\\E", "shortCiteRegEx": "Kimeldorf and Wahba.", "year": 1971}, {"title": "Almost-everywhere algorithmic stability and generalization error", "author": ["Samuel Kutin", "Partha Niyogi"], "venue": "Technical report TR-2002-03,", "citeRegEx": "Kutin and Niyogi.,? \\Q2002\\E", "shortCiteRegEx": "Kutin and Niyogi.", "year": 2002}, {"title": "Mechanism design via di erential privacy", "author": ["Frank McSherry", "Kunal Talwar"], "venue": "Data Mining,", "citeRegEx": "McSherry and Talwar.,? \\Q2009\\E", "shortCiteRegEx": "McSherry and Talwar.", "year": 2009}, {"title": "Random features for large-scale kernel machines", "author": ["Ali Rahimi", "Benjamin Recht"], "venue": "IEEE Symposium on Foundations of Computer Science, pages", "citeRegEx": "Rahimi and Recht.,? \\Q2007\\E", "shortCiteRegEx": "Rahimi and Recht.", "year": 2007}], "referenceMentions": [{"referenceID": 8, "context": "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).", "startOffset": 159, "endOffset": 304}, {"referenceID": 0, "context": "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).", "startOffset": 159, "endOffset": 304}, {"referenceID": 12, "context": "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).", "startOffset": 159, "endOffset": 304}, {"referenceID": 3, "context": "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).", "startOffset": 159, "endOffset": 304}, {"referenceID": 5, "context": "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).", "startOffset": 159, "endOffset": 304}, {"referenceID": 14, "context": "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008).", "startOffset": 159, "endOffset": 304}, {"referenceID": 0, "context": "It has been of key interest to the statistical database community to understand when the goals of utility and privacy can be e ciently achieved simultaneously (Dinur and Nissim, 2003; Barak et al., 2007; Dwork et al., 2007; Blum et al., 2008; Chaudhuri and Monteleoni, 2009; Kasiviswanathan et al., 2008). In this paper we consider the practical goal of private regularized empirical risk minimization (ERM) in Reproducing Kernel Hilbert Spaces for the special case of the Support Vector Machine (SVM). We adopt the strong notion of di erential privacy as formalized by Dwork (2006). Our e cient new mechanisms are shown to parametrize functions that are close to non-private SVM under the L\u221e-norm, with high probability.", "startOffset": 184, "endOffset": 583}, {"referenceID": 2, "context": "Early work on private interactive mechanisms focused on approximating real- and vector-valued statistics (e.g., Dinur and Nissim, 2003; Blum et al., 2005; Dwork et al., 2006; Dwork, 2006; Barak et al., 2007).", "startOffset": 105, "endOffset": 207}, {"referenceID": 11, "context": "Early work on private interactive mechanisms focused on approximating real- and vector-valued statistics (e.g., Dinur and Nissim, 2003; Blum et al., 2005; Dwork et al., 2006; Dwork, 2006; Barak et al., 2007).", "startOffset": 105, "endOffset": 207}, {"referenceID": 0, "context": "Early work on private interactive mechanisms focused on approximating real- and vector-valued statistics (e.g., Dinur and Nissim, 2003; Blum et al., 2005; Dwork et al., 2006; Dwork, 2006; Barak et al., 2007).", "startOffset": 105, "endOffset": 207}, {"referenceID": 0, "context": ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design.", "startOffset": 21, "endOffset": 69}, {"referenceID": 0, "context": ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design. More related to our work are the private mechanisms for regularized logistic regression proposed and analyzed by Chaudhuri and Monteleoni (2009). There the mechanism's range space parametrizes the VC-dimension d + 1 class of linear hyperplanes in R.", "startOffset": 21, "endOffset": 391}, {"referenceID": 0, "context": ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design. More related to our work are the private mechanisms for regularized logistic regression proposed and analyzed by Chaudhuri and Monteleoni (2009). There the mechanism's range space parametrizes the VC-dimension d + 1 class of linear hyperplanes in R. Kasiviswanathan et al. (2008) showed that discretized concept classes can be PAC learned or agnostically learned privately, albeit via an ine cient mechanism.", "startOffset": 21, "endOffset": 526}, {"referenceID": 0, "context": ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design. More related to our work are the private mechanisms for regularized logistic regression proposed and analyzed by Chaudhuri and Monteleoni (2009). There the mechanism's range space parametrizes the VC-dimension d + 1 class of linear hyperplanes in R. Kasiviswanathan et al. (2008) showed that discretized concept classes can be PAC learned or agnostically learned privately, albeit via an ine cient mechanism. Blum et al. (2008) showed that non-interactive mechanisms can privately release anonymized data such that utility is guaranteed over classes of predicate queries with polynomial VC dimension, when the domain is discretized.", "startOffset": 21, "endOffset": 674}, {"referenceID": 0, "context": ", 2006; Dwork, 2006; Barak et al., 2007). McSherry and Talwar (2007) rst considered private mechanisms with range spaces parametrizing sets more general than real-valued vectors, and used such di erentially private mappings for mechanism design. More related to our work are the private mechanisms for regularized logistic regression proposed and analyzed by Chaudhuri and Monteleoni (2009). There the mechanism's range space parametrizes the VC-dimension d + 1 class of linear hyperplanes in R. Kasiviswanathan et al. (2008) showed that discretized concept classes can be PAC learned or agnostically learned privately, albeit via an ine cient mechanism. Blum et al. (2008) showed that non-interactive mechanisms can privately release anonymized data such that utility is guaranteed over classes of predicate queries with polynomial VC dimension, when the domain is discretized. Dwork et al. (2009) more recently characterized when utility and privacy can be achieved by e cient non-interactive mechanisms.", "startOffset": 21, "endOffset": 899}, {"referenceID": 0, "context": "2005 and Barak et al. 2007 respectively, as examples) and learning algorithms (e.g., interval queries and half-spaces as explored by Blum et al. 2008), or on constructing learning algorithms that can be decomposed into subset-sum operations (e.g., perceptron, k-NN, ID3 as described by Blum et al. 2005, and various recommender systems due to the work of McSherry and Mironov 2009). By contrast, we consider the practical goal of SVM learning, which does not decompose into subsetsums. It is also notable that our mechanisms run in polynomial time. The most related work to our own in this regard is due to Chaudhuri and Monteleoni (2009), although their results hold only for di erentiable loss, and nite feature mappings.", "startOffset": 9, "endOffset": 639}, {"referenceID": 8, "context": "A sequence of prior negative results have shown that any mechanism providing overly accurate responses cannot be private (Dinur and Nissim, 2003; Dwork et al., 2007; Dwork and Yekhanin, 2008).", "startOffset": 121, "endOffset": 191}, {"referenceID": 12, "context": "A sequence of prior negative results have shown that any mechanism providing overly accurate responses cannot be private (Dinur and Nissim, 2003; Dwork et al., 2007; Dwork and Yekhanin, 2008).", "startOffset": 121, "endOffset": 191}, {"referenceID": 10, "context": "A sequence of prior negative results have shown that any mechanism providing overly accurate responses cannot be private (Dinur and Nissim, 2003; Dwork et al., 2007; Dwork and Yekhanin, 2008).", "startOffset": 121, "endOffset": 191}, {"referenceID": 0, "context": "Barak et al. (2007) presented a mechanism for releasing contingency tables that guarantees di erential privacy and also guarantees a notion of accuracy: with high probability all marginals from the released table are close in L1-norm to the true table's marginals.", "startOffset": 0, "endOffset": 20}, {"referenceID": 0, "context": "Barak et al. (2007) presented a mechanism for releasing contingency tables that guarantees di erential privacy and also guarantees a notion of accuracy: with high probability all marginals from the released table are close in L1-norm to the true table's marginals. As mentioned above, Blum et al. (2008) developed a private non-interactive mechanism that releases anonymized data such that all predicate queries in a VC-class take on similar values on the anonymized data and original data.", "startOffset": 0, "endOffset": 304}, {"referenceID": 0, "context": "Barak et al. (2007) presented a mechanism for releasing contingency tables that guarantees di erential privacy and also guarantees a notion of accuracy: with high probability all marginals from the released table are close in L1-norm to the true table's marginals. As mentioned above, Blum et al. (2008) developed a private non-interactive mechanism that releases anonymized data such that all predicate queries in a VC-class take on similar values on the anonymized data and original data. In the work of Kasiviswanathan et al. (2008), utility corresponds to PAC learning: with high probability the response and target concepts are close, averaged over the underlying measure.", "startOffset": 0, "endOffset": 536}, {"referenceID": 0, "context": "Barak et al. (2007) presented a mechanism for releasing contingency tables that guarantees di erential privacy and also guarantees a notion of accuracy: with high probability all marginals from the released table are close in L1-norm to the true table's marginals. As mentioned above, Blum et al. (2008) developed a private non-interactive mechanism that releases anonymized data such that all predicate queries in a VC-class take on similar values on the anonymized data and original data. In the work of Kasiviswanathan et al. (2008), utility corresponds to PAC learning: with high probability the response and target concepts are close, averaged over the underlying measure. A sequence of prior negative results have shown that any mechanism providing overly accurate responses cannot be private (Dinur and Nissim, 2003; Dwork et al., 2007; Dwork and Yekhanin, 2008). Dinur and Nissim (2003) showed that if noise of rate only o( \u221a n) is added to subset sum queries on a database of bits then an adversary can reconstruct a 1\u2212 o(1) fraction of the database.", "startOffset": 0, "endOffset": 895}, {"referenceID": 12, "context": "This result was more recently extended to allow for mechanisms that answer a small fraction of queries arbitrarily (Dwork et al., 2007).", "startOffset": 115, "endOffset": 135}, {"referenceID": 13, "context": "In passing Kasiviswanathan et al. (2008) note the similarity between notions of algorithmic stability and di erential privacy, however do not exploit this.", "startOffset": 11, "endOffset": 41}, {"referenceID": 9, "context": "The connection between algorithmic stability and di erential privacy is qualitatively similar to the recent work of Dwork and Lei (2009) who demonstrated that robust estimators can serve as the basis for private mechanisms, by exploiting the limited in uence of outliers on such estimators.", "startOffset": 116, "endOffset": 137}, {"referenceID": 2, "context": "2Note that we have chosen to overload the term ( , \u03b4)-usefulness introduced by Blum et al. (2008) for non-interactive mechanisms that release anonymized data.", "startOffset": 79, "endOffset": 98}, {"referenceID": 16, "context": "The Representer Theorem (Kimeldorf and Wahba, 1971) states that the minimizing f = arg minf\u2208H 12\u2016f\u2016 2 H + C n \u2211n i=1 `(yi, f(xi)) lies in the span of the functions k(\u00b7,xi) \u2208 H.", "startOffset": 24, "endOffset": 51}, {"referenceID": 4, "context": ", (Burges, 1998; Cristianini and Shawe-Taylor, 2000; Sch\u00f6lkopf and Smola, 2001; Bishop, 2006).", "startOffset": 2, "endOffset": 93}, {"referenceID": 6, "context": ", (Burges, 1998; Cristianini and Shawe-Taylor, 2000; Sch\u00f6lkopf and Smola, 2001; Bishop, 2006).", "startOffset": 2, "endOffset": 93}, {"referenceID": 1, "context": ", (Burges, 1998; Cristianini and Shawe-Taylor, 2000; Sch\u00f6lkopf and Smola, 2001; Bishop, 2006).", "startOffset": 2, "endOffset": 93}, {"referenceID": 7, "context": "Several notions of stability are known to lead to good generalization error bounds (Devroye and Wagner, 1979; Kearns and Ron, 1999; Bousquet and Elissee , 2002; Kutin and Niyogi, 2002), sometimes in cases where class capacity-based approaches such as VC theory do not apply.", "startOffset": 83, "endOffset": 184}, {"referenceID": 15, "context": "Several notions of stability are known to lead to good generalization error bounds (Devroye and Wagner, 1979; Kearns and Ron, 1999; Bousquet and Elissee , 2002; Kutin and Niyogi, 2002), sometimes in cases where class capacity-based approaches such as VC theory do not apply.", "startOffset": 83, "endOffset": 184}, {"referenceID": 17, "context": "Several notions of stability are known to lead to good generalization error bounds (Devroye and Wagner, 1979; Kearns and Ron, 1999; Bousquet and Elissee , 2002; Kutin and Niyogi, 2002), sometimes in cases where class capacity-based approaches such as VC theory do not apply.", "startOffset": 83, "endOffset": 184}, {"referenceID": 11, "context": "With the weight vector's sensitivity in hand, di erential privacy follows immediately from the proof technique established by Dwork et al. (2006).", "startOffset": 126, "endOffset": 146}, {"referenceID": 16, "context": "It is natural to look to the SVM's dual solution as a starting point: the Representer Theorem (Kimeldorf and Wahba, 1971) states that the optimizing f \u2208 H must be in the span of the data a nite-dimensional subspace.", "startOffset": 94, "endOffset": 121}, {"referenceID": 16, "context": "It is natural to look to the SVM's dual solution as a starting point: the Representer Theorem (Kimeldorf and Wahba, 1971) states that the optimizing f \u2208 H must be in the span of the data a nite-dimensional subspace. While the coordinates in this subspace the \u03b1 i dual variables could be perturbed in the usual way to guarantee di erential privacy, the subspace's basis the data are also needed to parametrize f. To side-step this apparent stumbling block, we take another approach by approximating H with a random RKHS \u0124 induced by a random nite-dimensional map \u03c6\u0302. This then allows us to respond with a nite primal parametrization. Algorithm 3 summarizes the PrivateSVM mechanism. As noted recently by Rahimi and Recht (2008), the Fourier transform p of the g function of a continuous positive-de nite translation-invariant kernel is a non-negative measure (Rudin, 1994).", "startOffset": 95, "endOffset": 727}, {"referenceID": 4, "context": "Algorithm 3 takes O(d\u0302) time to compute each entry of the kernel matrix, or a total time of O(d\u0302n) on top of running dual SVM in the random feature space which is worst-case O(ns) for the analytic solution (where ns \u2264 n is the number of support vectors), and faster using numerical methods such as chunking (Burges, 1998).", "startOffset": 307, "endOffset": 321}, {"referenceID": 18, "context": "Rahimi and Recht (2008) applied this approximation to large-scale learning (situations where n is large).", "startOffset": 0, "endOffset": 24}, {"referenceID": 19, "context": "We now recall the result due to Rahimi and Recht (2008) that establishes the non-asymptotic uniform convergence of the kernel functions required by the previous Lemma (i.", "startOffset": 32, "endOffset": 56}], "year": 2009, "abstractText": "Several recent studies in privacy-preserving learning have considered the trade-o between utility or risk and the level of di erential privacy guaranteed by mechanisms for statistical query processing. In this paper we study this trade-o in private Support Vector Machine (SVM) learning. We present two e cient mechanisms, one for the case of nite-dimensional feature mappings and one for potentially in nite-dimensional feature mappings with translation-invariant kernels. For the case of translation-invariant kernels, the proposed mechanism minimizes regularized empirical risk in a random Reproducing Kernel Hilbert Space whose kernel uniformly approximates the desired kernel with high probability. This technique, borrowed from large-scale learning, allows the mechanism to respond with a nite encoding of the classi er, even when the function class is of in nite VC dimension. Di erential privacy is established using a proof technique from algorithmic stability. Utility the mechanism's response function is pointwise -close to non-private SVM with probability 1\u2212 \u03b4 is proven by appealing to the smoothness of regularized empirical risk minimization with respect to small perturbations to the feature mapping. We conclude with a lower bound on the optimal di erential privacy of the SVM. This negative result states that for any \u03b4, no mechanism can be simultaneously ( , \u03b4)-useful and \u03b2-di erentially private for small and small \u03b2.", "creator": "LaTeX with hyperref package"}}}