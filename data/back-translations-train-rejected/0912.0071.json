{"id": "0912.0071", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2009", "title": "Differentially Private Empirical Risk Minimization", "abstract": "This paper addresses the problem of practical privacy-preserving machine learning: how to detect patterns in massive, real-world databases of sensitive personal information, while maintaining the privacy of individuals. Chaudhuri and Monteleoni (2008) recently provided privacy-preserving techniques for learning linear separators via regularized logistic regression. With the goal of handling large databases that may not be linearly separable, we provide privacy-preserving support vector machine algorithms.", "histories": [["v1", "Tue, 1 Dec 2009 04:35:44 GMT  (47kb)", "http://arxiv.org/abs/0912.0071v1", "Submitted to AISTATS 2010"], ["v2", "Mon, 22 Feb 2010 19:33:44 GMT  (41kb)", "http://arxiv.org/abs/0912.0071v2", "Under review"], ["v3", "Tue, 23 Feb 2010 05:26:22 GMT  (75kb)", "http://arxiv.org/abs/0912.0071v3", "Under review"], ["v4", "Wed, 2 Jun 2010 23:16:36 GMT  (217kb)", "http://arxiv.org/abs/0912.0071v4", "40 pages, 7 figures, under review"], ["v5", "Wed, 16 Feb 2011 22:35:55 GMT  (218kb)", "http://arxiv.org/abs/0912.0071v5", "40 pages, 7 figures, accepted to the Journal of Machine Learning Research"]], "COMMENTS": "Submitted to AISTATS 2010", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CR cs.DB", "authors": ["kamalika chaudhuri", "claire monteleoni", "anand d sarwate"], "accepted": false, "id": "0912.0071"}, "pdf": {"name": "0912.0071.pdf", "metadata": {"source": "CRF", "title": "Differentially Private Support Vector Machines", "authors": ["Anand Sarwate"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 091 2.00 71v1 [cs.LG] This paper addresses the problem of practical, privacy-preserving machine learning: how to recognize patterns in massive, real databases of sensitive personal information while preserving the privacy of the individual. Chaudhuri and Monteleoni (2008) have recently provided privacy-preserving techniques for learning linear separators using regulated logistic regression, with the goal of addressing large databases that may not be linearly separable. We provide privacy-preserving vector machine algorithms to address general challenges left open by previous work, such as releasing a core classifier without releasing the training data, and adjusting algorithm parameters in a privacy-preserving manner. We provide general, efficient algorithms for linear and nonlinear kernel SVMs that guarantee a distinct privacy, a very strong privacy definition based on data protection in 2006."}, {"heading": "1 Introduction", "text": "It is about the question of how the private sphere of people is organised, about the question of how the private sphere of people is organised, and about the question of how it could come to this, that the people who live in the world, live in the world, live in the world, live in the world in which they live, live in the world in which they live, live in the world in which they live, live in the world in which they live, live in the world in which they live, live in the world in which they live, live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which"}, {"heading": "1.1 Related work", "text": "There is a significant amount of literature on privacy [Agrawal and Srikant, 2000, Evfimievski et al., 2003, Sweeney, 2002, Machanavajjhala et al., 2006] that works with data protection models other than differentiated privacy, but many of the models used in this work are vulnerable to attack if the adversary has a reasonable level of prior knowledge. [Ganta et al., 2008] they look at the issue of privacy by sharing private data, and offer a solution that uses random cores."}, {"heading": "2 Problem statement", "text": "In this paper, we are interested in supporting vector machines (SVMs) that construct a class of algorithms that perform a classification based on examples. (SVMs) In this paper, we are developing algorithms that perform a classification. (SVMs) In this paper, we are interested in supporting vector machines (SVMs) that form a class of algorithms. (SVMs) In this paper, we are interested in supporting vector machines (SVMs) that form a class of algorithms that form a classification. (K) In this paper, we are interested in supporting vector machines (SVMs) that form a class of algorithms that perform a classification. (K). (K) In this paper, we are interested in supporting vector machines (SVMs) that form a class of algorithms that perform a classification. (K)"}, {"heading": "3 Linear support vector machines", "text": "The simplest case of a support vector machine classifier is a linear SVM method in which the classifier f (x) is the inner product of the data point x with a fixed vector f. In this setting, the damage f (1) becomes the Euclidean norm f (2). Previous work has shown that an efficient way to ensure privacy in logistical regression is to solve a disturbed objective function [Chaudhuri and Monteleoni, 2008]. We show how to provide a data-preserving SVM through a similar approach; to guarantee a differentiated privacy, we minimize the following objective function: Jpriv (f) = 1nn (f T x (i)), y (i) + 2 (f), 22 + 1 (n) b), the privacy f (f), (5), where b) privacy is to be protected."}, {"heading": "3.1 Privacy guarantees", "text": "Theorem 1: In view of the data {(x (i), y (i)): i [n]}, the output fpriv of algorithm 1 contains a p-differential privacy. We use the Huber loss instead of the hinge loss, because the proof for theorem 1 depends on the differentiability of the loss function. To see why a differential loss function is important for our algorithm, let us assume that (t, y) = (1 \u2212 ty) + and consider the case in which d = 1. We attach two databases D and D \u00b2, each with only one entry. That is, let us suppose D = (+ 1, 1) and D \u00b2 has (\u2212 1, 1), and let us assume that f \u00b2 = 1 was given by the algorithm. Then, in database D, we have the Jpriv (f) = (1 \u2212 f), which is the same for us."}, {"heading": "3.2 Generalization bounds", "text": "To provide learning guarantees, we assume that the data {x (i), y (i))} from independent and identically distributed samples of a distribution P (X, Y).Lemma 1. Given a regulated SVM with regularization parameters, be f0 the classifier, minimize J in (1) and minimize fpriv the classifier, minimize Jpriv in (5).The proof is identical to Lemma 4 in [Chaudhuri and Monteleoni, 2008]. 6Theorem 2. Leave f a classifier with expected loss L (f) and norm. \u2212 The proof is identical to Lemma 4 in [Chaudhuri and Monteleoni, 2008]."}, {"heading": "4 Nonlinear kernels", "text": "In this section, we show how to use SVMs to generate nonlinear decision limits for classification in a way that preserves privacy, which is typically found by using a nonlinear core function k (x, x \u2032), which is associated with a reproducing Hilbert space (RKHS) in which the classifier resides. Representative's theorem [Kimeldorf and Wahba, 1970] shows that the regulated empirical risk in (1) is minimized by a function f (x) given by a linear combination of core functions centered at the data points: f * (x) = n \u00b2 i = 1aik (x (i), x). (11) This elegant result is appealing from a theoretical point of view. To use it in practice, release the values ai that correspond to the f that minimizes empirical risk, along with the data points x (i)."}, {"heading": "4.1 The algorithm", "text": "s kernel k (x, x) = exp (\u2212 ig, x \u2212 x \u00b2 22), but we can approximate many different nuclei of interest [Rahimi7and Recht, 2008b]. For j [D] we draw an example character in Rd \u00b7 R according to the distribution given by N (0, 2\u03b3Id) \u00b7 Uniform [\u2212 \u03c0, \u03c0] p. Then we assign each vector x (i) to a vector v (i)."}, {"heading": "4.2 Privacy guarantees", "text": "Since the workhorse of algorithm 2 is algorithm 1 and the points {\u03b8j: j [D]} are independent of the data, the privacy guarantees for algorithm 2 result trivially from theorem 1.Theorem 3. Given the data {(x (i), y (i): i = 1, 2,..., n} with (x (i), y (i) and \u0435x (i) \u0432 \u2264 1, the outputs (fpriv, {\u03b8j: j [D]}) of algorithm 2 guarantee p-differential privacy."}, {"heading": "4.3 Generalization bounds", "text": "In this section, we show limits on the generalization power of the classifier generated by algorithm 2. (We compare this generalization power with any classifier whose \"norm\" is limited in a certain sense. (This means that as long as n is greater than a certain amount, we then L (fpriv) \u2212 L (f) \u2212 L (f) (f).Our first generalization result is the simplest, since it assumes a strong condition that gives simple guarantees for the predictions. (F) We want our privatized classifier to be competitive against a classifier who uses f) such a procedure. (F) The first generalization result is the simplest, since there are simple guarantees for the predictions. (F) We want our privatized classifier to be competitive against a classifier who uses f) such a procedure. (F) The first generalization result is the simplest, given that it is a strong generalization result."}, {"heading": "5 Privacy-preserving tuning", "text": "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *"}, {"heading": "6 Experiments", "text": "In fact, we are in a position to go in search of a solution that will enable us to go in search of a solution that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to, that will enable us to."}, {"heading": "7 Proofs", "text": "This section contains supplementary material and the evidence for our main findings. We assume that the core function is limited and that we can write it as a whole across a room."}], "references": [{"title": "Privacy-preserving data mining", "author": ["Agrawal", "Srikant", "R. 2000] Agrawal", "R. Srikant"], "venue": "SIGMOD Rec.,", "citeRegEx": "Agrawal et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 2000}, {"title": "Privacy, accuracy, and consistency too: a holistic solution to contingency table release", "author": ["Barak et al", "B. 2007] Barak", "K. Chaudhuri", "C. Dwork", "S. Kale", "F. McSherry", "K. Talwar"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "A learning theory approach to non-interactive database privacy", "author": ["A. Blum", "K. Ligett", "A. Roth"], "venue": null, "citeRegEx": "Blum et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2008}, {"title": "Privacy-preserving logistic regression", "author": ["Chaudhuri", "Monteleoni", "K. 2008] Chaudhuri", "C. Monteleoni"], "venue": "In Twenty-Second Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Chaudhuri et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2008}, {"title": "Differential privacy and robust statistics", "author": ["Dwork", "Lei", "C. 2009] Dwork", "J. Lei"], "venue": null, "citeRegEx": "Dwork et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2009}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Dwork et al", "C. 2006] Dwork", "F. McSherry", "K. Nissim", "A. Smith"], "venue": "In 3rd IACR Theory of Cryptography Conference,,", "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "Limiting privacy breaches in privacy preserving data mining", "author": ["Evfimievski et al", "A. 2003] Evfimievski", "J. Gehrke", "R. Srikant"], "venue": "In PODS,", "citeRegEx": "al. et al\\.,? \\Q2003\\E", "shortCiteRegEx": "al. et al\\.", "year": 2003}, {"title": "Composition attacks and auxiliary information in data privacy", "author": ["Ganta et al", "S.R. 2008] Ganta", "S.P. Kasiviswanathan", "A. Smith"], "venue": "In KDD,", "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "The UCI KDD Archive", "author": ["Hettich", "Bay", "S. 1999] Hettich", "S. Bay"], "venue": null, "citeRegEx": "Hettich et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Hettich et al\\.", "year": 1999}, {"title": "What can we learn privately", "author": ["Kasiviswanathan et al", "S.A. 2008] Kasiviswanathan", "H.K. Lee", "K. Nissim", "S. Raskhodnikova", "A. Smith"], "venue": "In Proc. of Foundations of Computer Science", "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "A correspondence between Bayesian estimation on stochastic processes and smoothing by splines", "author": ["Kimeldorf", "Wahba", "G. 1970] Kimeldorf", "G. Wahba"], "venue": "Annals of Mathematical Statistics,", "citeRegEx": "Kimeldorf et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Kimeldorf et al\\.", "year": 1970}, {"title": "Cryptographically private support vector machines", "author": ["Laur et al", "S. 2006] Laur", "H. Lipmaa", "T. Mielik\u00e4inen"], "venue": "In KDD,", "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "l-diversity: Privacy beyond k-anonymity", "author": ["Machanavajjhala et al", "A. 2006] Machanavajjhala", "J. Gehrke", "D. Kifer", "M. Venkitasubramaniam"], "venue": "In Proc. of ICDE", "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "Privacy: Theory meets practice on the map", "author": ["Machanavajjhala et al", "A. 2008] Machanavajjhala", "D. Kifer", "J.M. Abowd", "J. Gehrke", "L. Vilhuber"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "Privacy-preserving classification of vertically partitioned data via random kernels", "author": ["Mangasarian et al", "O.L. 2008] Mangasarian", "E.W. Wild", "G. Fung"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "Mechanism design via differential privacy", "author": ["McSherry", "Talwar", "F. 2007] McSherry", "K. Talwar"], "venue": "In FOCS,", "citeRegEx": "McSherry et al\\.,? \\Q2007\\E", "shortCiteRegEx": "McSherry et al\\.", "year": 2007}, {"title": "Smooth sensitivity and sampling in private data analysis", "author": ["Nissim et al", "K. 2007] Nissim", "S. Raskhodnikova", "A. Smith"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "Random features for large-scale kernel machines", "author": ["Rahimi", "Recht", "A. 2007] Rahimi", "B. Recht"], "venue": null, "citeRegEx": "Rahimi et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Rahimi et al\\.", "year": 2007}, {"title": "Uniform approximation of functions with random bases", "author": ["Rahimi", "Recht", "A. 2008a] Rahimi", "B. Recht"], "venue": "In Proceedings of the 46th Allerton Conference on Communication,", "citeRegEx": "Rahimi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rahimi et al\\.", "year": 2008}, {"title": "Weighted sums of random kitchen sinks : Replacing minimization with randomization in learning", "author": ["Rahimi", "Recht", "A. 2008b] Rahimi", "B. Recht"], "venue": null, "citeRegEx": "Rahimi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rahimi et al\\.", "year": 2008}, {"title": "SVM optimization : Inverse dependence on training set size", "author": ["Shalev-Shwartz", "Srebro", "S. 2008] Shalev-Shwartz", "N. Srebro"], "venue": null, "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2008}, {"title": "Fast rates for regularized objectives", "author": ["Sridharan et al", "K. 2008] Sridharan", "N. Srebro", "S. Shalev-Shwartz"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "Privacy-preserving support vector machine classification", "author": ["Zhan", "Matwin", "J.Z. 2007] Zhan", "S. Matwin"], "venue": "IJIIDS,", "citeRegEx": "Zhan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zhan et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 4, "context": "We provide general, efficient algorithms for linear and nonlinear kernel SVMs, which guarantee \u01eb-differential privacy, a very strong privacy definition due to Dwork et al. (2006). We also provide learning generalization guarantees.", "startOffset": 159, "endOffset": 179}], "year": 2017, "abstractText": "This paper addresses the problem of practical privacy-preserving machine learning: how to detect patterns in massive, real-world databases of sensitive personal information, while maintaining the privacy of individuals. Chaudhuri and Monteleoni (2008) recently provided privacy-preserving techniques for learning linear separators via regularized logistic regression. With the goal of handling large databases that may not be linearly separable, we provide privacy-preserving support vector machine algorithms. We address general challenges left open by past work, such as how to release a kernel classifier without releasing any of the training data, and how to tune algorithm parameters in a privacy-preserving manner. We provide general, efficient algorithms for linear and nonlinear kernel SVMs, which guarantee \u01eb-differential privacy, a very strong privacy definition due to Dwork et al. (2006). We also provide learning generalization guarantees. Empirical evaluations reveal promising performance on real and simulated data sets.", "creator": "LaTeX with hyperref package"}}}