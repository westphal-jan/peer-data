{"id": "1001.0830", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jan-2010", "title": "K-tree: Large Scale Document Clustering", "abstract": "We introduce K-tree in an information retrieval context. It is an efficient approximation of the k-means clustering algorithm. Unlike k-means it forms a hierarchy of clusters. It has been extended to address issues with sparse representations. We compare performance and quality to CLUTO using document collections. The K-tree has a low time complexity that is suitable for large document collections. This tree structure allows for efficient disk based implementations where space requirements exceed that of main memory.", "histories": [["v1", "Wed, 6 Jan 2010 07:43:31 GMT  (32kb)", "http://arxiv.org/abs/1001.0830v1", "2 pages, SIGIR 2009"]], "COMMENTS": "2 pages, SIGIR 2009", "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.DS", "authors": ["christopher m de vries", "shlomo geva"], "accepted": false, "id": "1001.0830"}, "pdf": {"name": "1001.0830.pdf", "metadata": {"source": "CRF", "title": "K-tree: Large Scale Document Clustering", "authors": ["Christopher M De Vries", "Shlomo Geva"], "emails": ["chris@de-vries.id.au", "s.geva@qut.edu.au"], "sections": [{"heading": null, "text": "ar Xiv: 100 1,08 30v1 [cs.IR] 6 Jan 201 0"}, {"heading": "Categories and Subject Descriptors", "text": "H.3.3 [Storage and Retrieval of Information]: Search and Retrieval of Information - Clustering"}, {"heading": "General Terms", "text": "Algorithms, Performance"}, {"heading": "Keywords", "text": "Document Clustering, K-tree, B-tree, search tree, k-medium"}, {"heading": "1. K-TREE", "text": "There are two types of nodes. Leaf nodes are 1 to m vectors. Internal nodes are 1 to m (vector, child node) pairs. The next neighbor search tree is built bottom-up by splitting full nodes with k-means. Once the tree grows in depth, it forms a hierarchy of \"clusters\" until the top level is reached. The top level contains cluster centers and pointers to the leaves that insert vectors into the tree. For more information see Geva [3] and the K-tree project page. The algorithm shares many similarities with BIRCH [7], as both are inspired by the B + tree data structure."}, {"heading": "2. MEDOID K-TREE", "text": "Inspired by the kmedoids algorithm [5], we propose an extension of K-tree, where all cluster centers are document examples. Sample documents are selected by selecting the closest documents to the cluster centers generated by k-means clustering. Internal nodes now contain references to document vectors. This reduces memory consumption by not allocating new memory to cluster centers. Runtime performance is increased because all vectors are sparse. Compensation for this increased performance is a decline in cluster quality. This is expected because we throw away information. Cluster centers in the tree are no longer weighted and are not updated when inserted."}, {"heading": "3. EXPERIMENTAL SETUP", "text": "In all cases, the K-tree order was adjusted to change the number of clusters at the leaf level. CLUTO was then guided to match the number of clusters produced, and all algorithms were executed in a single three.The INEX 2008 XML Mining Corpus and a selection of the RCV1 corpus used by [6] were grouped together, with the INEX collection consisting of 114,366 Wikipedia documents with 15 labels, and the subset of the RCV1 corpus consisting of 193,844 documents with 103 industry labels, both of which were confined to the most important terms."}, {"heading": "4. EXPERIMENTAL RESULTS", "text": "CLUTO k \u2212 means CLUTO repeat bisecting k \u2212 means K \u2212 tree medoid K \u2212 tree hybrid sampled K \u2212 tree0 2000 4000 6000 8000 10000 12000 0.40.450.50.550.650.750.80.850.9number of clusterspu rity0 2000 4000 6000 10000 12000 00.511.522.53number of clustersen trop y0 2000 4000 6000 8000 10000 12000 05001000150020003000number of clustersru n \u2212 tim ein sec ondsFigure 1: INEX 20080 1000 2000 3000 4000 5000 7000 9000 11000 120000000000.20.250.450.450.50.50.550.60.65number of clusterspu rity0 2000 4000 10000 12000 1.522.533.555.5number of clustersen trop y0 2000 4000 6000 10000 150.200.2000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"}, {"heading": "5. APPLICATIONS IN INFORMATION RETRIEVAL", "text": "The performance increase of K-tree is most pronounced when many small clusters are needed, and many practical applications require it. For example, many clusters are useful when selecting collections when it comes to distributing a collection across many machines. When using clusters to find links, a large number of small clusters are useful. A small number of highly semantically related documents are candidates for linking. Due to the dynamic nature of the algorithm, clusters can be created step by step without having to process all documents at once, which also allows easy updates when new documents arrive. The tree structure can be used for interactive collection explorations, and the user can scroll and generalize from any point in the tree, or specialize in what he is looking at by traversing the tree up or down."}, {"heading": "6. REFERENCES", "text": "[1] K-tree project page, http: / / ktree.sourceforge.net. 2009. [2] Ludovic Denoyer and Patrick Gallinari. The Wikipedia XML Corpus. SIGIR Forum, 2006. [3] S. Geva. K-tree: a height balanced tree structured vector quantizer. Neural Networks for Signal Processing X, 2000. Proceedings of the 2000 IEEE SignalProcessing Society Workshop, 1: 271-280 vol.1, 2000. [4] G. Karypis. CLUTO-A Clustering Toolkit. 2002. [5] L. Kaufman, P. Rousseeuw, Delft (Netherlands). Dept. of Mathematics Technische Hogeschool, and Informatics. Clustering by medoids. Technical report, Technische Hogeschool, Delft (Netherlands). [Dept. of Mathematics and Informatics."}], "references": [{"title": "The Wikipedia XML Corpus", "author": ["Ludovic Denoyer", "Patrick Gallinari"], "venue": "SIGIR Forum,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "K-tree: a height balanced tree structured vector quantizer", "author": ["S. Geva"], "venue": "Neural Networks for Signal Processing X,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "CLUTO-A Clustering Toolkit", "author": ["G. Karypis"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2002}, {"title": "Delft(Netherlands). Dept. of Mathematics Technische Hogeschool, and Informatics. Clustering by means of medoids", "author": ["L. Kaufman", "P. Rousseeuw"], "venue": "Technical report, Technische Hogeschool, Delft(Netherlands). Dept. of Mathematics and Informatics.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1987}, {"title": "BIRCH: A New Data Clustering Algorithm and Its Applications", "author": ["T. Zhang", "R. Ramakrishnan", "M. Livny"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1997}], "referenceMentions": [{"referenceID": 1, "context": "For more information see Geva [3] and the K-tree Project Page [1].", "startOffset": 30, "endOffset": 33}, {"referenceID": 4, "context": "The algorithm shares many similarities with BIRCH [7] as both are inspired by the B-tree data structure.", "startOffset": 50, "endOffset": 53}, {"referenceID": 0, "context": "We will highlight the issue using the INEX 2008 XML Mining collection [2].", "startOffset": 70, "endOffset": 73}, {"referenceID": 3, "context": "This is inspired by the kmedoids algorithm [5].", "startOffset": 43, "endOffset": 46}, {"referenceID": 2, "context": "Performance and quality is compared between CLUTO [4] and K-tree.", "startOffset": 50, "endOffset": 53}], "year": 2010, "abstractText": "We introduce K-tree in an information retrieval context. It is an efficient approximation of the k-means clustering algorithm. Unlike k-means it forms a hierarchy of clusters. It has been extended to address issues with sparse representations. We compare performance and quality to CLUTO using document collections. The K-tree has a low time complexity that is suitable for large document collections. This tree structure allows for efficient disk based implementations where space requirements exceed that of main memory.", "creator": "LaTeX with hyperref package"}}}