{"id": "1001.2605", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2010", "title": "An Explicit Nonlinear Mapping for Manifold Learning", "abstract": "Manifold learning is a hot research topic in the field of computer science and has many applications in the real world. A main drawback of manifold learning methods is, however, that there is no explicit mappings from the input data manifold to the output embedding. This prohibits the application of manifold learning methods in many practical problems such as classification and target detection. Previously, in order to provide explicit mappings for manifold learning methods, many methods have been proposed to get an approximate explicit representation mapping with the assumption that there exists a linear projection between the high-dimensional data samples and their low-dimensional embedding. However, this linearity assumption may be too restrictive. In this paper, an explicit nonlinear mapping is proposed for manifold learning, based on the assumption that there exists a polynomial mapping between the high-dimensional data samples and their low-dimensional representations. As far as we know, this is the first time that an explicit nonlinear mapping for manifold learning is given. In particular, we apply this to the method of Locally Linear Embedding (LLE) and derive an explicit nonlinear manifold learning algorithm, named Neighborhood Preserving Polynomial Embedding (NPPE). Experimental results on both synthetic and real-world data show that the proposed mapping is much more effective in preserving the local neighborhood information and the nonlinear geometry of the high-dimensional data samples than previous work.", "histories": [["v1", "Fri, 15 Jan 2010 03:03:24 GMT  (1416kb)", "http://arxiv.org/abs/1001.2605v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["hong qiao", "peng zhang", "di wang", "bo zhang"], "accepted": false, "id": "1001.2605"}, "pdf": {"name": "1001.2605.pdf", "metadata": {"source": "CRF", "title": "An Explicit Nonlinear Mapping for Manifold Learning", "authors": ["Hong Qiao", "Bo Zhang"], "emails": ["hong.qiao@ia.ac.cn", "wangdi}@amss.ac.cn", "b.zhang@amt.ac.cn"], "sections": [{"heading": null, "text": "ar Xiv: 100 1.26 05v1 [cs.CV] 1 5Ja n20 10Index Terms - Diverse learning, nonlinear dimension reduction, machine learning, data mining."}, {"heading": "1 INTRODUCTION", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2 RELATED WORKS", "text": "In this section, we briefly discuss existing multiple learning algorithms, including those based on linear projections and nonlinear extensions from the scholarly multiplicity sample. To simplify the presentation, the most important notations used in this essay are summarized in Table 1. In this essay, all data samples are presented in the form of column vectors, matrices are expressed in normal uppercase letters, and data vectors are represented in lowercase letters."}, {"heading": "2.1 Manifold Learning Methods", "text": "As local approaches, Locally Linear Embedding (LLE) [2], [3] preserves local reconstruction weights. Locally Multidimensional Scaling (LMDS) [9] preserves local pairwise Euclidean distances between data samples. Maximum Variance Unfolding (MVU) [10] also preserves pairwise Euclidean distances in each local neighborhood, while maximizing the variance of low-dimensional representations. Local Tangent Space3 Alignment (LTSA) [11] preserves the local tangential structure. Diffusion maps [14] preserve local pairwise diffusion distances from high-dimensional samples to low-dimensional representations. Laplacian Eigenmap (LE) [12] preserves local dependency relationships."}, {"heading": "2.2 Linear Projections for Manifold Learning", "text": "Various learning algorithms based on linear projections assume that there is a linear projection that maps the high-dimensional samples into a low-dimensional space, i.e. yi = U Txi, where U-R is n \u00b7 m, (1) where xi is a high-dimensional sample and yi is its low-dimensional representation. Indicated by ui the i-th column of U. Then, from a geometric point of view, the data samples in Rn are projected into an anm-dimensional linear subspace spanned by {ui} n i = 1. The low-dimensional representation yi is the coordinate of xi in R m in relation to the base {ui} n i = 1."}, {"heading": "2.2.1 LPP", "text": "The LE method aims to train a series of low-dimensional representations Y, which can best maintain the adhesion relationship between high-dimensional inputs X. If xi and xj are \"close\" to each other, then yi and yj should be too. This property is achieved by solving the following limited optimization problem Y: Ni, j = 1 Wij-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi-Yi (2)."}, {"heading": "2.2.2 NPP and NPE", "text": "Linear projection for local linear embedding (LLE) is provided independently by Neighborhood Preserving Embedding (NPE) [26] and Neighborhood Preserving Projections (NPP) [27]. Similar to LPP, NPE and NPP apply linear projection assumptions (1) to LLE's training process and reformulate the optimization problem in LLE to calculate the linear projection matrix. During LLE's training process, a series of linear reconstruction weights {Wij} N i, j = 1 is first calculated, with convex optimization problems i = 1Wijxj \u00b2 2 2s. t Wij = 0 if j 6% N \u00b2 j (i) N \u00b2 j = 1Wij = 1, where N (i) is the index set for the k nearest neighbors of xi. Then LLE aims to preserve the problem of Wij \u00b2 n \u00b2 n \u00b2."}, {"heading": "2.2.3 OLPP and ONPP", "text": "Orthogonal Locality Preserving Projections (OLPP) [28] and Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30] are the same as LPP and NPE (or NPP), except that the linear projection matrix provided by LPP and NPE (or NPP) is limited to its orthogonality, which is achieved by replacing the constraints (5) and (9) with UTU = Im. Then, the optimization problems in OLPP and ONPP: UOLPP = argmin UTU = ImTr (10) ONPP: UONPP = argmin UTU = ImTr (UTXMXTU). (11) In contrast to the cases of LPP and NPE (or NPP), these two optimization problems lead to eigenvalue problems that are numerically much easier to solve than a generalized eigenvalue."}, {"heading": "2.3 Out-of-Sample Nonlinear Extensions for Manifold Learning", "text": "These methods are based on core functions and extrapolation techniques. Bengio et al. [32], [36] proposed a unified framework for extending LLE, ISOMAP, and LE, in which these methods are considered as learning characteristics of operators defined from data-dependent cores. Bengio et al. [32], [36] proposed a unified framework for extending LLE, ISOMAP, and LE, in which these methods are considered as learning characteristics of operators defined from data-dependent cores. Data-dependent cores are implicitly defined by LLE, ISOMAP LE, and are used along with the Nystro-m formula [38] to extrapolate the matrix."}, {"heading": "3 EXPLICIT NONLINEAR MAPPINGS FOR MANIFOLD LEARNING", "text": "In this section, we present an explicit nonlinear mapping for multiple learning, based on the assumption that there is a polynomial mapping between the high-dimensional data samples and their low-dimensional representations. (...) We assume that there is a polynomial mapping that maps X to Y, that is, the k-th component yi is a polynomial of degree p in relation to xi in the following way: yki = 1, l2, ln. (...) There is a polynomial of degree p in relation to xi, (12) where l1, ln. (.) The superscript stands for n-pvlk (x2i) l2 (xni) ln."}, {"heading": "4 NEIGHBORHOOD PRESERVING POLYNOMIAL EMBEDDING", "text": "In this section we propose a new, diverse learning algorithm with an explicit nonlinear mapping called Neighborhood Preserving Polynomial Embedding (NPPE), which is achieved by defining the weights Wij, i, j = 1, 2,.., N similar to the LLE method and combining them with the explicit nonlinear mapping as in the previous section 3."}, {"heading": "4.1 NPPE", "text": "Consider a dataset {x1, x2,., xN} from the high-dimensional space Rn. NPPE begins by searching for a set of linear reconstruction weights that can best reconstruct any data point xi by its k-nearest neighbors (k-NNNs). This step is identical to that of LLE [2], [3]. The weights Rij, i, j = 1,.., N, which are only defined if xj belongs to the k-NNNNs of xi, are calculated by solving the following optimization problems."}, {"heading": "4.2 Computational Complexity and Simplified NPPE", "text": "The calculation of XpWX T p and XpDX T p requires O (kN 2-p i = 1 n i) and O (N2-p = 1 n i) operations, respectively, since there are only k-unequal entries in each column of W and D. The calculation complexity of the final egg decomposition is O (m (p i = 1 ni) 3), which is the most time-consuming step. In the process of locating new samples with NPPE, the calculation complexity of X (new) p takesO (p = 2 ni) operations is generated and the calculation of ynew takes O (m (p = 1 ni) 2) operations."}, {"heading": "4.3 Discussion", "text": "In this subsection we briefly explain why NPPE or SNPPE perform better than their linear counterparts for nonlinear distributed datasets. Let us let f = (f1, f2, \u00b7 \u00b7, fm) be a nonlinear map from a manifold M-Rn to Rm, so that yki = f k (xi), where fk is differentiable at least pth order. For simplicity and without loss of universality we can assume that 0% M and that f (0) = 0. Then the Taylor expansion of fk (x) at zero will be differentiated by fk (x) = (\u03c6fk (0) Tx + 12 xTHfk (0) x + o (\u0445fk x 2), (31) where Fk and Hfk are the gradient and Hessian of fk (x) at zero. From (31) we can see that the linear methods only use the linear approximation provided by the first order, while non-approximating the zero."}, {"heading": "5 EXPERIMENTAL TESTS", "text": "In this section, experiments with both synthetic and real data sets will be performed to demonstrate the validity and effectiveness of the proposed NPPE algorithm. In Section 5.1, NPPE will be tested for the recovery of geometric structures of surfaces embedded in R3. In Section 5.2, NPPE will be applied to the localization of new incoming data samples in the learned low-dimensional space. In Section 5.3, NPPE will be used to extract intrinsic degrees of freedom based on two image diversity. In the experiments, the simplified version of NPPE will be implemented and compared with NPP [27] and ONPP [30] (which compares the linear and orthogonal linear projection mapping to the training method for LLE and / or), as well as the kernextrapolation method (KE) proposed in [33]. There are two parameters in the NPPE algorithm, the number of the nearest polynop and the number of samples should be as high as the P1 in this section."}, {"heading": "5.1 Learning Surfaces in R3 with NPPE", "text": "In the first experiment, NPPE, NPP, ONPP and LLE are applied to the task of unfolding surfaces embedded in R3. The surfaces are the SwissRoll, SwissHole and Gaussian, all of which are generated by the Matlab demo at http: / / www.math.umn.edu / \u0445 wittman / mani /. On each manifold, 1000 data samples are randomly generated for training, the number of closest neighbours is k = 10 and the polynomial degree p = 2. The experimental results are shown in Fig. 1. In each partial figure, Z = [z1 z2 \u00b7 zN] stands for the generation of data, so xi = \u03c6 (zi), which is the non-linear mapping that embeds Z in R3. Fig. 1 shows that NPPE outperforms all three methods, even the LLE method itself."}, {"heading": "5.2 Locating New Data Samples with NPPE", "text": "In the second experiment, we use NPPE, NPP, ONPP and KE to locate new incoming samples in the learned low-dimensional space. Initially, 2000 data samples are generated, which are evenly distributed on the SwissRoll distributor. Then, 1000 samples are randomly selected as training data to learn the imaging relationship of R3 to R2 by NPPE, NPP, ONPP and KE. The learned images are used to provide the low-dimensional representations for the remaining 1000 samples. The time cost of calculating the low-dimensional representations of the test samples is also recorded. Experimental results are shown in Fig. 2. It can be seen that NPPE not only delivers the best locating result, but also has a much lower time cost than KE. NPP and ONPP are faster to calculate, but do not give the correct embedding result of the test samples. The same experiment is performed on randomly selected data samples from ONig. The other methods are calculated in Figure 3. We also exceed the PPE for the other three."}, {"heading": "5.3 Learning Image Manifolds with NPPE", "text": "In the last experiment, NPPE is used to extract intrinsic degrees of freedom based on two image multiplicities, the NPPE [2] and the USPS-0.The NPPE consists of 1965 facial images of the same person with a resolution of 28 x 20, and the two degrees of freedom underlying the facial images are rotation of the head and facial motions. We randomly select 1500 samples as training data and 400 samples as test data. The number of closest neighbors is set to 15. Experimental results are shown in Fig. 5. Training and test results are shown in the left or right column, in Fig. 5. 100 training samples and 40 test samples are randomly selected and attached to the learned embedding. It can be seen that NPPE and NPP have successfully recovered the underlying structure of the facial image, while the result given by KE is not satisfactory."}, {"heading": "6 CONCLUSION", "text": "Based on the assumption that there is a polynomial mapping of the high-dimensional input samples to their low-dimensional representations, applying this assumption to a generic model of multiple learning results in explicit polynomial mapping. Furthermore, the NPPE algorithm is a nonlinear method for reducing dimensionality with an explicit nonlinear mapping that tends to obtain not only the locality but also the nonlinear geometry of the high-dimensional data samples. NPPE can provide convincing embedding results and locate new incoming data samples easily and quickly simultaneously in reduced low-dimensional space. Experimental tests on both synthetic and real data have confirmed the effectiveness of the proposed NPPE algorithm."}], "references": [{"title": "The manifold ways of perception,", "author": ["H.S. Seung", "D.D. Lee"], "venue": "Science, vol. 290,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Nonlinear dimensionality reduction by locally linear embedding,", "author": ["S.T. Roweis", "L.K. Saul"], "venue": "Science, vol. 290,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2000}, {"title": "Think globally, fit locally: unsupervised learning of low dimensional manifold,", "author": ["L.K. Saul", "S.T. Roweis"], "venue": "J. Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "A global geometric framework for nonlinear dimensionality reduction,", "author": ["J.B. Tenenbaum", "V. de Silva", "J.C. Langford"], "venue": "Science, vol. 290,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "Global versus local methods in nonlinear dimensionality reduction,", "author": ["V. de Silva", "J. Tenenbaum"], "venue": "Proc. Advances in Neural Information Processing Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Eigenfaces for recognition,", "author": ["M. Turk", "A. Pentland"], "venue": "J. Cognitive Neuroscience,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1991}, {"title": "Multidimensional Scaling", "author": ["T. Cox", "M. Cox"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1994}, {"title": "Alignment of overlapping locally scaled patches for multidimensional scaling and dimensionality reduction,", "author": ["L. Yang"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Unsupervised learning of image manifolds by semidefinite programming,", "author": ["K.Q. Weinberger", "L.K. Saul"], "venue": "Int. J. Comput. Vision,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Principal manifolds and nonlinear dimension reduction via local tangent space alignment,", "author": ["Z. Zhang", "H. Zha"], "venue": "SIAM J. Sci. Comput.,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Laplacian eigenmaps for dimensionality reduction and data representation,", "author": ["M. Belkin", "P. Niyogi"], "venue": "Neural Comput.", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Riemannian manifold learning,", "author": ["T. Lin", "H. Zha"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Hessian eigenmaps: new locally linear embedding techniques for high-dimensional data,", "author": ["D. Donoho", "C. Grimes"], "venue": "Proc. Nat. Acad. Sci.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "Learning and matching of dynamics shape manifolds for human action recognition,", "author": ["L. Wang", "D. Suter"], "venue": "IEEE Trans. Image Process.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Enhancing human face detection by resampling examples through manifolds,", "author": ["J. Chen", "R. Wang", "S. Yan", "S. Shan", "X. Chen", "W. Gao"], "venue": "IEEE Trans. Syst. Man Cybern. Part A,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Fusina, \u201cExploiting manifold geometry in hyperspectral imagery,", "author": ["C.M. Bachmann", "T.L. Ainsworth", "R.A"], "venue": "IEEE Trans. Geosci. Remote Sensing,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Nonlinear manifold learning for dynamic shape and dynamic appearance,", "author": ["A. Elgammal", "C.S. Lee"], "venue": "Comput. Vis. Image Underst.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Learning object intrinsic structure for robust visual tracking,", "author": ["Q. Wang", "G. Xu", "H. Ai"], "venue": "in Proc. IEEE Int. Conf. Comput. Vis. Pattern Recog.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "Learning an intrinsic variable preserving manifold for dynamic visual tracking", "author": ["H. Qiao", "P. Zhang", "B. Zhang", "S. Zheng"], "venue": "IEEE. Trans. Syst. Man. Cybern. Part B, in press,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Tracking feature extraction based on manifold learning framework", "author": ["H. Qiao", "P. Zhang", "B. Zhang", "S. Zheng"], "venue": "J. Exp. Theor. Artif. Intell., in press,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Locality preserving projections", "author": ["X. He", "P. Niyogi"], "venue": "in Proc. Advances Neural Inf. Process. Syst.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Face recognition using Laplacianfaces,", "author": ["X. He", "S. Yan", "Y. Hu", "P. Niyogi", "H.J. Zhang"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Neighborhood preserving embedding,", "author": ["X. He", "D. Cai", "S. Yan", "H.J. Zhang"], "venue": "in: Proc. IEEE Int. Conf. Comput. Vis.,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "Neighborhood preserving projections (NPP): A novel linear dimension reduction method", "author": ["Y. Pang", "L. Zhang", "Z. Liu", "N. Yu", "H. Li"], "venue": "in Proc. ICIC", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2005}, {"title": "Orthogonal neighborhood preserving projections", "author": ["E. Kokiopoulou", "Y. Saad"], "venue": "Proc. Fifth IEEE Int\u2019l Conf. Data Mining,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2005}, {"title": "Orthogonal neighborhood preserving projections: A projection-based dimensionality reduction technique", "author": ["E. Kokiopoulou", "Y. Saad"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Graph embedding and extensions: a general framework for dimensionality reduction,", "author": ["S. Yan", "D. Xu", "B.Y. Zhang", "H.J. Zhang", "Q. Yang", "S. Lin"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 29,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2007}, {"title": "Out-of-sample extions for LLE, Isomap, MDS, Eigenmaps and spectral clustering,", "author": ["Y. Bengio", "J.F. Paiement", "P. Vincent", "O. Delalleau", "N.L. Roux", "M. Ouimet"], "venue": "in Proc. Advances Neural Inf. Process. Syst.,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2003}, {"title": "Manifold regularization: a geometric framework for learning from labelled and unlabelled examples,", "author": ["M. Belkin", "P. Niyogi", "V. Sindhwani"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2006}, {"title": "Out-of-sample extrapolation of learned manifolds", "author": ["T. Chin", "D. Suter"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Incremental nonlinear dimensionality reduction by manifold learning", "author": ["M. Law", "A. Jain"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}, {"title": "The Numerical Treatment of Intergral Equations", "author": ["C. Baker"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1977}], "referenceMentions": [{"referenceID": 0, "context": "1 INTRODUCTION MANIFOLD learning has drawn great interests since it was first proposed in 2000 ( [1], [2], [4]) as a promising nonlinear dimensionality reduction (NDR) method for high-dimensional data manifolds.", "startOffset": 97, "endOffset": 100}, {"referenceID": 1, "context": "1 INTRODUCTION MANIFOLD learning has drawn great interests since it was first proposed in 2000 ( [1], [2], [4]) as a promising nonlinear dimensionality reduction (NDR) method for high-dimensional data manifolds.", "startOffset": 102, "endOffset": 105}, {"referenceID": 3, "context": "1 INTRODUCTION MANIFOLD learning has drawn great interests since it was first proposed in 2000 ( [1], [2], [4]) as a promising nonlinear dimensionality reduction (NDR) method for high-dimensional data manifolds.", "startOffset": 107, "endOffset": 110}, {"referenceID": 1, "context": "In recent years, various manifold learning algorithms have been proposed, such as locally linear embedding (LLE) [2], [3], ISOMAP [4], [5], Laplacian eigenmap (LE) [12], diffusion maps (DM) [14], local tangent space alignment (LTSA) [11], and Riemannian manifold learning [13].", "startOffset": 113, "endOffset": 116}, {"referenceID": 2, "context": "In recent years, various manifold learning algorithms have been proposed, such as locally linear embedding (LLE) [2], [3], ISOMAP [4], [5], Laplacian eigenmap (LE) [12], diffusion maps (DM) [14], local tangent space alignment (LTSA) [11], and Riemannian manifold learning [13].", "startOffset": 118, "endOffset": 121}, {"referenceID": 3, "context": "In recent years, various manifold learning algorithms have been proposed, such as locally linear embedding (LLE) [2], [3], ISOMAP [4], [5], Laplacian eigenmap (LE) [12], diffusion maps (DM) [14], local tangent space alignment (LTSA) [11], and Riemannian manifold learning [13].", "startOffset": 130, "endOffset": 133}, {"referenceID": 4, "context": "In recent years, various manifold learning algorithms have been proposed, such as locally linear embedding (LLE) [2], [3], ISOMAP [4], [5], Laplacian eigenmap (LE) [12], diffusion maps (DM) [14], local tangent space alignment (LTSA) [11], and Riemannian manifold learning [13].", "startOffset": 135, "endOffset": 138}, {"referenceID": 10, "context": "In recent years, various manifold learning algorithms have been proposed, such as locally linear embedding (LLE) [2], [3], ISOMAP [4], [5], Laplacian eigenmap (LE) [12], diffusion maps (DM) [14], local tangent space alignment (LTSA) [11], and Riemannian manifold learning [13].", "startOffset": 164, "endOffset": 168}, {"referenceID": 9, "context": "In recent years, various manifold learning algorithms have been proposed, such as locally linear embedding (LLE) [2], [3], ISOMAP [4], [5], Laplacian eigenmap (LE) [12], diffusion maps (DM) [14], local tangent space alignment (LTSA) [11], and Riemannian manifold learning [13].", "startOffset": 233, "endOffset": 237}, {"referenceID": 11, "context": "In recent years, various manifold learning algorithms have been proposed, such as locally linear embedding (LLE) [2], [3], ISOMAP [4], [5], Laplacian eigenmap (LE) [12], diffusion maps (DM) [14], local tangent space alignment (LTSA) [11], and Riemannian manifold learning [13].", "startOffset": 272, "endOffset": 276}, {"referenceID": 13, "context": "Meanwhile, manifold learning also has many important applications in real-world problems, such as human motion detection [17], human face recognition [18], classification and compressed expression of hyper-spectral imageries [19], dynamic shape and appearance classification [20], and visual tracking [21]\u2013[23].", "startOffset": 121, "endOffset": 125}, {"referenceID": 14, "context": "Meanwhile, manifold learning also has many important applications in real-world problems, such as human motion detection [17], human face recognition [18], classification and compressed expression of hyper-spectral imageries [19], dynamic shape and appearance classification [20], and visual tracking [21]\u2013[23].", "startOffset": 150, "endOffset": 154}, {"referenceID": 15, "context": "Meanwhile, manifold learning also has many important applications in real-world problems, such as human motion detection [17], human face recognition [18], classification and compressed expression of hyper-spectral imageries [19], dynamic shape and appearance classification [20], and visual tracking [21]\u2013[23].", "startOffset": 225, "endOffset": 229}, {"referenceID": 16, "context": "Meanwhile, manifold learning also has many important applications in real-world problems, such as human motion detection [17], human face recognition [18], classification and compressed expression of hyper-spectral imageries [19], dynamic shape and appearance classification [20], and visual tracking [21]\u2013[23].", "startOffset": 275, "endOffset": 279}, {"referenceID": 17, "context": "Meanwhile, manifold learning also has many important applications in real-world problems, such as human motion detection [17], human face recognition [18], classification and compressed expression of hyper-spectral imageries [19], dynamic shape and appearance classification [20], and visual tracking [21]\u2013[23].", "startOffset": 301, "endOffset": 305}, {"referenceID": 19, "context": "Meanwhile, manifold learning also has many important applications in real-world problems, such as human motion detection [17], human face recognition [18], classification and compressed expression of hyper-spectral imageries [19], dynamic shape and appearance classification [20], and visual tracking [21]\u2013[23].", "startOffset": 306, "endOffset": 310}, {"referenceID": 20, "context": "input data samples and their low-dimensional representations, such as Locality Preserving Projections (LPP) [24], [25], Neighborhood Preserving Embedding (NPE) [26], Neighborhood Preserving Projections (NPP) [27], Orthogonal Locality Preserving Projections (OLPP) [28], Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30], and Graph Embedding [31].", "startOffset": 108, "endOffset": 112}, {"referenceID": 21, "context": "input data samples and their low-dimensional representations, such as Locality Preserving Projections (LPP) [24], [25], Neighborhood Preserving Embedding (NPE) [26], Neighborhood Preserving Projections (NPP) [27], Orthogonal Locality Preserving Projections (OLPP) [28], Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30], and Graph Embedding [31].", "startOffset": 114, "endOffset": 118}, {"referenceID": 22, "context": "input data samples and their low-dimensional representations, such as Locality Preserving Projections (LPP) [24], [25], Neighborhood Preserving Embedding (NPE) [26], Neighborhood Preserving Projections (NPP) [27], Orthogonal Locality Preserving Projections (OLPP) [28], Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30], and Graph Embedding [31].", "startOffset": 160, "endOffset": 164}, {"referenceID": 23, "context": "input data samples and their low-dimensional representations, such as Locality Preserving Projections (LPP) [24], [25], Neighborhood Preserving Embedding (NPE) [26], Neighborhood Preserving Projections (NPP) [27], Orthogonal Locality Preserving Projections (OLPP) [28], Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30], and Graph Embedding [31].", "startOffset": 208, "endOffset": 212}, {"referenceID": 24, "context": "input data samples and their low-dimensional representations, such as Locality Preserving Projections (LPP) [24], [25], Neighborhood Preserving Embedding (NPE) [26], Neighborhood Preserving Projections (NPP) [27], Orthogonal Locality Preserving Projections (OLPP) [28], Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30], and Graph Embedding [31].", "startOffset": 324, "endOffset": 328}, {"referenceID": 25, "context": "input data samples and their low-dimensional representations, such as Locality Preserving Projections (LPP) [24], [25], Neighborhood Preserving Embedding (NPE) [26], Neighborhood Preserving Projections (NPP) [27], Orthogonal Locality Preserving Projections (OLPP) [28], Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30], and Graph Embedding [31].", "startOffset": 330, "endOffset": 334}, {"referenceID": 26, "context": "input data samples and their low-dimensional representations, such as Locality Preserving Projections (LPP) [24], [25], Neighborhood Preserving Embedding (NPE) [26], Neighborhood Preserving Projections (NPP) [27], Orthogonal Locality Preserving Projections (OLPP) [28], Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30], and Graph Embedding [31].", "startOffset": 356, "endOffset": 360}, {"referenceID": 27, "context": "[32]\u2013[35]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[32]\u2013[35]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 3, "context": "This is different from the traditional manifold learning methods such as like LLE, LE, and ISOMAP [4] in which the mapping is implicit and it is not clear how new data samples can be embedded in the low-dimensional space.", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "As local approaches, Locally Linear Embedding (LLE) [2], [3] preserves local reconstruction weights.", "startOffset": 52, "endOffset": 55}, {"referenceID": 2, "context": "As local approaches, Locally Linear Embedding (LLE) [2], [3] preserves local reconstruction weights.", "startOffset": 57, "endOffset": 60}, {"referenceID": 7, "context": "Locally Multidimensional Scaling (LMDS) [9] preserves local pairwise Euclidean distances among data samples.", "startOffset": 40, "endOffset": 43}, {"referenceID": 8, "context": "Maximum Variance Unfolding (MVU) [10] also preserves pairwise Euclidean distances in each local neighborhood, but it maximizes the variance of the low-dimensional representations at the same time.", "startOffset": 33, "endOffset": 37}, {"referenceID": 9, "context": "Alignment (LTSA) [11] keeps the local tangent structure.", "startOffset": 17, "endOffset": 21}, {"referenceID": 10, "context": "Laplacian Eigenmap (LE) [12] preserves the local adjacency relationship.", "startOffset": 24, "endOffset": 28}, {"referenceID": 3, "context": "As global approaches, Isometric Feature Mapping (ISOMAP) [4], [5] preserves the pairwise geodesic distances among the high-dimensional data samples and their low-dimensional representations.", "startOffset": 57, "endOffset": 60}, {"referenceID": 4, "context": "As global approaches, Isometric Feature Mapping (ISOMAP) [4], [5] preserves the pairwise geodesic distances among the high-dimensional data samples and their low-dimensional representations.", "startOffset": 62, "endOffset": 65}, {"referenceID": 12, "context": "Hessian Eigenmaps (HLLE) [15] extends ISOMAP to more general cases where the set of intrinsic degrees of freedom may be non-convex.", "startOffset": 25, "endOffset": 29}, {"referenceID": 11, "context": "In Riemannian Manifold Learning (RML) [13], the coordinates of data samples in the tangential space are preserved to be their low-dimensional representations.", "startOffset": 38, "endOffset": 42}, {"referenceID": 20, "context": "1 LPP Locality Preserving Projections (LPP) [24], [25] provides a linear mapping for Laplacian Eigenmaps (LE), by applying (1) into the training procedure of LE.", "startOffset": 44, "endOffset": 48}, {"referenceID": 21, "context": "1 LPP Locality Preserving Projections (LPP) [24], [25] provides a linear mapping for Laplacian Eigenmaps (LE), by applying (1) into the training procedure of LE.", "startOffset": 50, "endOffset": 54}, {"referenceID": 22, "context": "2 NPP and NPE The linear projection mapping for Locally Linear Embedding (LLE) is independently provided by Neighborhood Preserving Embedding (NPE) [26] and Neighborhood Preserving Projections (NPP) [27].", "startOffset": 148, "endOffset": 152}, {"referenceID": 23, "context": "2 NPP and NPE The linear projection mapping for Locally Linear Embedding (LLE) is independently provided by Neighborhood Preserving Embedding (NPE) [26] and Neighborhood Preserving Projections (NPP) [27].", "startOffset": 199, "endOffset": 203}, {"referenceID": 24, "context": "3 OLPP and ONPP Orthogonal Locality Preserving Projections (OLPP) [28] and Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30] are the same as LPP and NPE (or NPP), respectively, except that the linear projection matrix provided by LPP and NPE (or NPP) is restricted to be orthogonal.", "startOffset": 129, "endOffset": 133}, {"referenceID": 25, "context": "3 OLPP and ONPP Orthogonal Locality Preserving Projections (OLPP) [28] and Orthogonal Neighborhood Preserving Projections (ONPP) [29], [30] are the same as LPP and NPE (or NPP), respectively, except that the linear projection matrix provided by LPP and NPE (or NPP) is restricted to be orthogonal.", "startOffset": 135, "endOffset": 139}, {"referenceID": 24, "context": "The reader is referred to [28] and [29], [30] for details of these two algorithms.", "startOffset": 35, "endOffset": 39}, {"referenceID": 25, "context": "The reader is referred to [28] and [29], [30] for details of these two algorithms.", "startOffset": 41, "endOffset": 45}, {"referenceID": 27, "context": "[32], [36] proposed a unified framework for extending LLE, ISOMAP and LE, in which these methods are seen as learning eigenfunctions of operators defined from data-dependent kernels.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "The data-dependent kernels are implicitly defined by LLE, ISOMAP LE and are used together with the Nystr\u00f6m formula [38] to extrapolate the embedding of a manifold learned from finite training samples to new coming samples for LLE, ISOMAP and LE (see [32], [36]).", "startOffset": 115, "endOffset": 119}, {"referenceID": 27, "context": "The data-dependent kernels are implicitly defined by LLE, ISOMAP LE and are used together with the Nystr\u00f6m formula [38] to extrapolate the embedding of a manifold learned from finite training samples to new coming samples for LLE, ISOMAP and LE (see [32], [36]).", "startOffset": 250, "endOffset": 254}, {"referenceID": 29, "context": "Chin and Suter [35] investigated the equivalence between MVU and Kernel Principal Component Analysis (KPCA) [39], by which extending MVU to new samples is reduced to extending a kernel matrix.", "startOffset": 15, "endOffset": 19}, {"referenceID": 29, "context": "In their work [35], the kernel matrix is generated from an unknown kernel eigenfunction which is approximated using Gaussian basis functions.", "startOffset": 14, "endOffset": 18}, {"referenceID": 26, "context": "Recently, it was proved in [31] that most manifold learning methods, including LLE, LE, and ISOMAP, can be cast into the framework of spectral embedding.", "startOffset": 27, "endOffset": 31}, {"referenceID": 1, "context": "This step is identical with that of LLE [2], [3].", "startOffset": 40, "endOffset": 43}, {"referenceID": 2, "context": "This step is identical with that of LLE [2], [3].", "startOffset": 45, "endOffset": 48}, {"referenceID": 23, "context": "In the experiments, the simplified version of NPPE is implemented and compared with NPP [27] and ONPP [30] (which apply the linear and orthogonal linear projection mapping to the training procedure for LLE, respectively) as well as the kernel extrapolation (KE) method proposed in [33].", "startOffset": 88, "endOffset": 92}, {"referenceID": 25, "context": "In the experiments, the simplified version of NPPE is implemented and compared with NPP [27] and ONPP [30] (which apply the linear and orthogonal linear projection mapping to the training procedure for LLE, respectively) as well as the kernel extrapolation (KE) method proposed in [33].", "startOffset": 102, "endOffset": 106}, {"referenceID": 3, "context": "Furthermore, in order to estimate the similarity between the learned low-dimensional representations and the generating data, the residual variance [4] \u03c1(Y, Z) = 1\u2212R(Y, Z) is computed, where R is the standard linear correlation coefficient taken over all entries of Y and Z .", "startOffset": 148, "endOffset": 151}], "year": 2010, "abstractText": "Manifold learning is a hot research topic in the field of computer science and has many applications in the real world. A main drawback of manifold learning methods is, however, that there is no explicit mappings from the input data manifold to the output embedding. This prohibits the application of manifold learning methods in many practical problems such as classification and target detection. Previously, in order to provide explicit mappings for manifold learning methods, many methods have been proposed to get an approximate explicit representation mapping with the assumption that there exists a linear projection between the high-dimensional data samples and their low-dimensional embedding. However, this linearity assumption may be too restrictive. In this paper, an explicit nonlinear mapping is proposed for manifold learning, based on the assumption that there exists a polynomial mapping between the highdimensional data samples and their low-dimensional representations. As far as we know, this is the first time that an explicit nonlinear mapping for manifold learning is given. In particular, we apply this to the method of Locally Linear Embedding (LLE) and derive an explicit nonlinear manifold learning algorithm, named Neighborhood Preserving Polynomial Embedding (NPPE). Experimental results on both synthetic and real-world data show that the proposed mapping is much more effective in preserving the local neighborhood information and the nonlinear geometry of the high-dimensional data samples than previous work.", "creator": "LaTeX with hyperref package"}}}