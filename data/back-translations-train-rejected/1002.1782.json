{"id": "1002.1782", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Feb-2010", "title": "Online Distributed Sensor Selection", "abstract": "A key problem in sensor networks is to decide which sensors to query when, in order to obtain the most useful information (e.g., for performing accurate prediction), subject to constraints (e.g., on power and bandwidth). In many applications the utility function is not known a priori, must be learned from data, and can even change over time. Furthermore for large sensor networks solving a centralized optimization problem to select sensors is not feasible, and thus we seek a fully distributed solution. In this paper, we present Distributed Online Greedy (DOG), an efficient, distributed algorithm for repeatedly selecting sensors online, only receiving feedback about the utility of the selected sensors. We prove very strong theoretical no-regret guarantees that apply whenever the (unknown) utility function satisfies a natural diminishing returns property called submodularity. Our algorithm has extremely low communication requirements, and scales well to large sensor deployments. We extend DOG to allow observation-dependent sensor selection. We empirically demonstrate the effectiveness of our algorithm on several real-world sensing tasks.", "histories": [["v1", "Tue, 9 Feb 2010 07:32:59 GMT  (164kb,D)", "https://arxiv.org/abs/1002.1782v1", null], ["v2", "Wed, 10 Feb 2010 02:34:38 GMT  (166kb,D)", "http://arxiv.org/abs/1002.1782v2", null], ["v3", "Thu, 13 May 2010 03:32:05 GMT  (169kb,D)", "http://arxiv.org/abs/1002.1782v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["daniel golovin", "matthew faulkner", "andreas krause"], "accepted": false, "id": "1002.1782"}, "pdf": {"name": "1002.1782.pdf", "metadata": {"source": "CRF", "title": "Online Distributed Sensor Selection", "authors": ["Daniel Golovin", "Matthew Faulkner", "Andreas Krause"], "emails": [], "sections": [{"heading": null, "text": "Categories and Topics C.2.1 [Computer Communication Networks]: Network Architecture and Design; G.3 [Probability and Statistics]: Experimental Design; I.2.6 [AI]: Learning General Term Algorithms, ScalesKeywords Sensor Networks, Approximation Algorithms, Distributed Multi-Arm Bandit Algorithms, Submodular Optimization"}, {"heading": "1. INTRODUCTION", "text": "A key challenge in providing sensor networks for real-world applications such as environmental monitoring [19], building automation [25] and others is to decide when to activate the sensors in order to obtain the most useful information from the network (e.g., accurate predictions in unobserved locations) and to minimize power consumption. This sensor selection problem has already received considerable attention [1, 32, 10] and algorithms with performance guarantees have been developed [1, 16]. However, many of the existing approaches make simplistic assumptions. Many approaches assume that the sensors can perfectly observe a particular sensor region, and nothing outside the region [1]. This assumption does not allow us to model settings in which multiple noise sensors can help each other. There are also approaches that base their idea of usability on more detailed models such as improving predictive accuracy."}, {"heading": "2. THE SENSOR SELECTION PROBLEM", "text": "Suppose a network of sensors has been used in a number of locations to monitor a phenomenon (e.g., the temperature in a building). Communication bandwidth or battery power limitations typically require us to select a subset A of these sensors for activation, according to a power function, and the activated sensors then send their data to a server (base station). First, we review the traditional offline setting, where the power function is pre-specified, and illustrate how submodularity allows us to achieve demonstrably near-optimal selections, and then we turn to the more sophisticated setting, where the power function needs to be learned from the data online."}, {"heading": "2.1 The Offline Sensor Selection Problem", "text": "A standard selection algorithm enables predictions at unobserved locations, e.g. by predicting XA = xA, which maximizes a known query quality objective function f (A) (A), subject to some limitations, e.g. the number of sensors activated. A possible choice for query quality is based on predictive accuracy (we will discuss other possible decisions later). In many applications, measurements are correlated across space, which allows us to make predictions at the unobserved locations. Here, XV = [X1] is the random vector across all measurements. If some measurements XA = xA at a subset of locations, which allows the conditional distribution P (XV\\ A), predictions at the unobserved locations."}, {"heading": "2.2 The Online Sensor Selection Problem", "text": "We assume that we intend to monitor the environment for a number of time steps (rounds). In each round t, a series of sensors is selected, and these sensors transmit their measurements to a server (base station). The server then determines a sampling quality ft (St), which quantifies the usefulness obtained from the resulting analysis. For example, if our goal is a spatial prediction, the server would build a model based on the previously collected sensor data, select a random sensor, make predictions for the variable Xs, and then compare the predictiveness \u00b5s with the sensor measurement xs. The error ft = \u03c32s \u2212 xs) 2 is an unbiased estimate of the reduction in EMSE. In the following analysis, we only assume that the objective functions ft ft are limited (w.l.above), values in [0, 1], monotonous, one, and some that we have."}, {"heading": "3. CENTRALIZED ALGORITHM FOR ONLINE SENSOR SELECTION", "text": "Before developing the distributed algorithm for online sensor selection, we will first review a centralized algorithm that is guaranteed to achieve no (1 \u2212 1 / e) remorse. In paragraph 4, we will show how this centralized algorithm can be implemented efficiently and in a distributed manner, starting with the greedy algorithm for a known submodular function mentioned in paragraph 2.1 and adapting it to the online setting. To do this, an online algorithm for selecting a single sensor as a subroutine is required, and we will review such an algorithm in paragraph 3.1, before discussing the centralized algorithm for selecting multiple sensors in paragraph 3.2."}, {"heading": "3.1 Centralized Online Single Sensor Selection", "text": "Let's first consider the case in which k = 1, i.e. we want to select a sensor in each round. In this case, the EXP3 algorithm [2] is a centralized solution for selecting a single sensor without regret. EXP3 works as follows: It is parameterized by a learning rate \u03b7 and an exploration probability \u03b3. It maintains a series of weights, one for each arm (sensor) s, initialized to 1. In each round t he selects each arm s with probability styps = (1 \u2212 \u03b3) ws \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \""}, {"heading": "3.2 Centralized Selection of Multiple Sensors", "text": "In principle, we could interpret the sensor selection problem as an armed bandit problem, and we could apply existing no-contrition algorithms such as EXP3. Unfortunately, this approach is not scalable, since the number of arms exponentially grows with k. But, unlike the traditional, multi-armed bandit problems in which the arms are independent of each other, the functioning of the system is submodular and therefore correlates it with different sets. It shows how this submodularity can be exploited, and develops a no- (1) - (1) - (2) - (2) - (2) - (2) - (2) - - (3) - (3) - (3) - (3) - (4) - (4) - (4) - (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) - (4) - (4) - (4) (4) (4) (4) (4) (4) (4) (4) (4) - (4) - (4) - (4) - (3) - (3) - (3) - (3) - (3) - (3) - (3) - (3) - (4) - (4) - (4) - (4) - (4 - (4) - (4) - (4) - (4) - (4) - (4) - (4) - (4) - (4) - (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (4) (5) (5) (5) (5 (5) (5) (5) (5) (5) (5) (5 (5) (5) (5) (5) (5) (5) (5) (5) (5 (5) (5) (5) (5) (5) (5) (5) (5) (5) (5) (5) (5) (5"}, {"heading": "4. DISTRIBUTED ALGORITHM FOR ONLINE SENSOR SELECTION", "text": "We will now develop DOG, an efficient algorithm for distributed on-line sensor selection. For the moment, we are assuming the following assumptions: 1. Each sensor can calculate its contribution to the benefit ft (S) -ft (S) -ft (S), with S being a subset of already selected sensors.2. Each sensor can transmit to all other sensors.3. The sensors have calibrated clocks and unique, linear identifications. These assumptions are reasonable in many applications: (1) In target detection, for example, the lens function ft (S) counts the number of targets detected by the sensors. Once previously selected sensors have emitted what targets they have detected, the new sensor can determine how many additional targets have been detected. Likewise, in statistical estimation, a sensor (or a small number of sensors) can randomly activate the number of sensors and spread their value.After Sensors S have been selected and their measurements announced, we can first determine the relatively new (or small) assumptions for the number of sensors (1)."}, {"heading": "4.1 Distributed Selection of a Single Sensor", "text": "The key challenge in the development of a global network is to find a way to filter exactly one element out of the distribution phase. (1) We note that among the different types of communication, one element has to be selected from the distribution phase. (1) On the other hand, our algorithm, which enables arbitrary distribution by individually deciding which sensors exist, also has two other advantages: (1) it is a modification of the activation probabilities based on local observations as we discuss them, and (2) because it does not rely on a global state of the network, there may be a change in local observations. (2)"}, {"heading": "4.2 The Distributed Online Greedy Algorithm", "text": "We now use our only sensor selection algorithm, the Distributed Online Greedy Algorithm (DOG). It is based on the distributed implementation of EXP3 using the PMS protocol. Suppose we want to select k-sensors in each round. Each sensor v maintains k-weights wv, 1,.., wv, k and normalizing constants Zv, 1,..., Zv, k. The algorithm runs in k-steps, synchronized using the common clock. In stage i, a single sensor is selected using the PMS protocol based on the distribution (1 \u2212 3) wv, i / Zv, i + \u03b3 / n. Suppose sensors S = {v1,., vi \u2212 1} were selected in stages 1 to i \u2212 1."}, {"heading": "5. THE STAR NETWORK MODEL", "text": "In some applications, the assumption that sensors can send messages to all sensors may be unrealistic. In this section, we analyze LAZYDOG, a variant of our DOG algorithm that replaces the above assumptions by the assumption that a dedicated Base Unit 4 is available that calculates supplies and can send untransmitted messages to individual sensors. We assume the following assumptions: 4Although the existence of such a Base Unit means that the protocol is not fully distributed, it is realistic in Sensor Network Applications where the sensor data must be collected somewhere for analysis. 1. Each sensor stores its probability mass pv with it and can only send messages to the Base Unit and receive messages."}, {"heading": "5.1 Lazy renormalization & Distributed EXP3", "text": "EXP3 (and all MABs with no-regret guarantees against arbitrary reward functions) must maintain a distribution of actions (= v) and update this distribution in response to environmental feedback. In EXP3, each sensor v requires only wv (t) and a normalizer Z (t). In the star network model (or more generally in multi-hop models), standard flutecho-aggregation techniques can be used to calculate and distribute the new normalizer, although at high communication costs. We show that a lazy renormalization scheme can significantly reduce the amount of communication required by a distributed bandit algorithm without changing its boundaries. Thus, our lazy scheme is complementary to standard aggregation techniques. Our lazy renormalization scheme for EXP3 works as follows."}, {"heading": "5.2 LazyDOG", "text": "Once we have the distributed EXP3 variant described above, we can use it for the bandit subroutines in the OGUNIT algorithm (cf. Par. 3,2). We call the result the LAZYDOG algorithm, which allows activation due to its use of the rotten renormalization. The rotten distributed EXP3 random sensors from the same distribution as the regularly distributed EXP3, therefore LAZYDOG has exactly the same performance guarantees with regard to the activation of T (St) as DOG. It works in the communication model of the star network and requires few messages or sensor activations. Episode 5 immediately implies the following result.COROLLARY 6 \u2212 The number of sensors that activate each round in LAZYDOG is at most k + O (k) in expectation and O (k log n) with high probability, the number of messages is at most twice as the number of sensors in DOK level and YOK level and we do not activate the number of LAK \u2212 YOK, the number of sensors in expectation is maximum (LAK)."}, {"heading": "6. OBSERVATION-DEPENDENT SAMPLING", "text": "Theorem 3 states that DOG is almost guaranteed to focus almost as much as the offline greedy algorithm on an instance with objective function as we can do. (In many application areas, however, we would also like to fall back on \"atypical\" objective functions. (For example, in an eruption application such as we discuss in Sec. 7, we would like to get very good data on significant events, even if the nearest sensors typically contribute very little to objective functionality.) Suppose that we run only a single MAB instance to select a single sensor in each round. (If we have access to a black box for evaluating round t, then we can work well on atypical rounds at the cost of additional communication by recording each sensor reading in their environment and estimating its payout. ({v})"}, {"heading": "7. EXPERIMENTS", "text": "In this section we evaluate our DOG algorithm on the basis of several real perception problems."}, {"heading": "7.1 Data sets", "text": "In our first dataset, we analyze temperature measurements from the network of 46 sensors we provide at Berkeley. Our training data is based on samples collected at 30-second intervals on three consecutive days (starting on February 28, 2004). Our second data consists of precipitation data collected in the states of Washington and Oregon between 1949 and 1994. In total, 167 regions with the same area, about 50 km apart, are compared with daily rainfall amounts. To ensure that the data can be reasonably modeled, we have described pre-processing as described in the US."}, {"heading": "7.2 Convergence experiments", "text": "In our first set of experiments, we analyzed the convergence of our DOG algorithm. For both the temperature [T] and precipitation data [R], we first run the offline greedy algorithm with the fEMSE objective function to select k = 5 sensors. We compare its performance with the DOG algorithm, in which we return the same objective function in each round. We use an exploration probability \u03b3 = 0.01 and a learning rate inversely proportional to the maximum achievable reward fEMSE (V). Figure 4 (a) presents the results for the temperature dataset. Note that the algorithm obtains 95% of the performance of the offline algorithm even after only a small number of rounds (0.01). After approximately 13,000 iterations, the algorithm receives 99% of the offline performance, which is the best to be expected with an exploration probability of.01. Figure 4 shows the probability that the impact data is increased by 50% after this experiment."}, {"heading": "7.3 Observation dependent activation", "text": "We evaluate our OD-DOG algorithm experimentally with observation-specific sensor activations, selecting different values for the activation cost, which we vary as multiples of the total achievable reward; the activation cost allows us to smoothly compare the average number of sensors that activate each turn with the average reward received; the resulting activation strategies are used to select a subset of the size k = 10 from a collection of 12,527 sensors; Fig. 4 (c) shows convergence rates using the OD-DOG algorithm using a fixed lens function that takes into account all contamination events; Fig. 4 (d) shows convergence rates under a varying lens function that selects a different contamination event in each turn; at low activation costs, the performance quickly approaches or exceeds the performance of the offline solution; even among the lowest activation costs in our experiments, the average number of additional DOG activations per OD activation level may exceed 5."}, {"heading": "8. RELATED WORK", "text": "The problem of deciding when to selectively turn on sensors in sensor networks to save power was first discussed by [26] and [32]. Many approaches to optimize sensor placement and selection assume that sensors have a fixed region [15, 14, 3], which are usually convex or even circular. Furthermore, it is assumed that everything within a region can be perfectly observed and everything outside cannot be measured by the sensors. For complex applications such as environmental monitoring, these assumptions are unrealistic and direct optimization of predictive accuracy is desired. The problem of selecting observations to monitor spatial phenomena has been extensively investigated in geostatistics [8], and more generally (Bayesian) experimental design [6]. Several approaches have been proposed to activate sensors to minimize uncertainty [32] or prediction errors [10]."}, {"heading": "9. CONCLUSIONS", "text": "We have developed an efficient distributed online greedy algorithm DOG and proved that it suffers no (1 \u2212 1 / e) regrets, essentially the best possible performance that can be achieved unless P = NP. Our algorithm is fully distributed and requires only a small number of messages that are highly likely to be exchanged in each round. We analyze our algorithm in both the broadcast model and the star network model, where a separate base station is responsible for calculating the usability of selected sensor sets. Our LAZYDOG algorithm for the latter model uses lazy renormalization suggestions to reduce the number of messages it requires from N to O (k log n)."}, {"heading": "10. REFERENCES", "text": "[1] Z. Abrams, A. Goel, and S. Plotkin. Set k-cover algorithms for energy efficient monitoring in wireless sensor networks. In IPSN, pages 424-432, 2004. [2] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed bandit problem. SIAM Journal on Computing, 32 (1): 48-77, 2002. [3] X. Bai, S. Kumar, Z. Yun, D. Xuan, and T. H. Lai. Deploying wireless sensors to achieve both coverage and connectivity. In ACM MobiHoc, 2006. [4] A. Blum, M. Hajiaghayi, K. Ligett, and A. Roth. Regret minimization and the price of total anarchy. In STOC, pages 373-382, 2008. [5] J. Burke, D. Estrin, M. Hansen, N. Ramanathan, S., S. Redley."}, {"heading": "A. RESULTS IN THE BROADCAST MODEL", "text": "PROOF OF THEOREM 2. To prove the limits of regret, note that on each lap, the distribution via sensor selection is exactly the same in the EXP3 variant (which uses the distributed multinomial scanning scheme and repeatedly activates the protocol to always select one sensor in each lap) The total number of scans is then | S | + 2; using their calibrated clocks, each sensor (re) samples is (essentially) Xv \u2212 Poisson and activated when Xv activates a series of sensors that are activated in that round. The total number of scans is then | S | + 2; using their calibrated clocks, each sensor (re) Xv \u2212 Poisson (re) is scanned and activated when Xv is activated a certain scanning element. If no sensors are activated before a certain time period, the default behavior is to activate the scanning element."}, {"heading": "B. RESULTS IN THE STAR NETWORK MODEL", "text": "In this section we will prove that lazy renormalization samples from a proper scale distribution (1 \u2212 e \u2212 \u03b1) pv where pv is the input distribution. We will then communicate via lazy renormalization scheme of Sec. 5.1, described in pseudocode in Fig. 2, samples v with probability (1 \u2212 e \u2212 \u03b1) pv, where pv = \u03c1 (t), Z (t) is the desired renormalization scheme of v.PROOF. renormalization selects each sensor v with probability (1 \u2212 e) pv, where pv = \u03c1 (t)), where pv = \u03c1 (t) is the desired probability for v.PROOF. Lazy renormalization each sensor v with probability (1 \u2212 e \u2212 e) pv, because of the way the random bits rv are shared in order to implement a coupled distribution for sensor activation and selection."}, {"heading": "1. INTRODUCTION", "text": "A key challenge in providing sensor networks for real-world applications such as environmental monitoring [?], building automation [?], and others is deciding when to activate the sensors in order to get the most useful information from the network (e.g., accurate predictions in unobserved locations) and minimize power consumption. This sensor selection problem has received considerable attention [?,??] and algorithms with performance guarantees have been developed [?,?]. However, many of the existing approaches make simplistic assumptions. Many approaches assume that the sensors can observe a particular sensor region perfectly, and nothing outside the region [?]. This assumption does not allow us to model settings where multiple noisy sensors can help each other. There are also approaches that base their idea of usability on more detailed models, such as improving predictive accuracy w.r.t. some statistical models [?] or detection performance."}, {"heading": "2. THE SENSOR SELECTION PROBLEM", "text": "Suppose a network of sensors has been used in a number of locations to monitor a phenomenon (e.g., the temperature in a building). Communication bandwidth or battery power limitations typically require us to select a subset A of these sensors for activation, according to a power function, and the activated sensors then send their data to a server (base station). First, we review the traditional offline setting, where the power function is pre-specified, and illustrate how submodularity allows us to achieve demonstrably near-optimal selections, and then we turn to the more sophisticated setting, where the power function needs to be learned from the data online."}, {"heading": "2.1 The Offline Sensor Selection Problem", "text": "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"}, {"heading": "2.2 The Online Sensor Selection Problem", "text": "We now consider the more difficult problem where the objective function is not specified in advance and needs to be learned during the monitoring task. We assume that we intend to monitor the environment for a number of time steps (rounds). In each round t, a series of sensors is selected that transmit their measurements to a server (Base Unit). The server then determines a sampling quality ft (St) that quantifies the usefulness obtained from the resulting analysis. For example, if our goal is a spatial prediction, the server would build a model based on the previously collected sensor data, select a random sensor, make predictions for the variable Xs, and then compare the predictive power \u00b5s with the sensor reading xs. The error = St 2s \u2212 xs) 2 is an unbiased estimate of the reduction in EMSE. In the following analysis, we only assume that the objective functions ft are limited (l.1,.o., we take some values) in EMSE."}, {"heading": "3. CENTRALIZED ALGORITHM FOR ONLINE SENSOR SELECTION", "text": "Before developing the distributed algorithm for online sensor selection, we will first review a centralized algorithm that is guaranteed to achieve no (1 \u2212 1 / e) remorse. In paragraph 4, we will show how this centralized algorithm can be implemented efficiently and in a distributed manner, starting with the greedy algorithm for a known submodular function mentioned in paragraph 2.1 and adapting it to the online setting. To do this, an online algorithm for selecting a single sensor as a subroutine is required, and we will review such an algorithm in paragraph 3.1, before discussing the centralized algorithm for selecting multiple sensors in paragraph 3.2."}, {"heading": "3.1 Centralized Online Single Sensor Selection", "text": "First, let's consider the case where k = 1, i.e. we want to select a sensor in each round. In this case, the EXP3 algorithm [?] is a centralized solution for selecting a single sensor without regrets. EXP3 works as follows: It is parameterized by a learning rate \u03b7 and an exploration probability \u03b3. It receives a series of 2Formally, no-regret means if RT is the total regret for the first rounds of T, Lim-supT \u2192 RT / T \u2264 0, weights, one for each arm (sensor) s, initialized on 1. At each round t, it selects each arm s with probabilities, if RT is the total regret for the first rounds of T, no-regret means that it lim supT \u2192 RT / T \u2264 0, weights, one for each arm (sensor) s, initialized on 1."}, {"heading": "3.2 Centralized Selection of Multiple Sensors", "text": "In principle, we could interpret the sensor selection problem as a (n) -armed bandit problem and apply existing no-contrition algorithms such as EXP3. Unfortunately, this approach is not scalable, as the number of arms exponentially grows with k. But, unlike traditional multi-armed bandit problems, where the arms are assumed to be independent payouts, the utility is more submodular, and thus the payouts are correlated."}, {"heading": "4. DISTRIBUTED ALGORITHM FOR ONLINE SENSOR SELECTION", "text": "We will now develop DOG, an efficient algorithm for distributed on-line sensor selection. For the moment, we are assuming the following assumptions: 1. Each sensor can calculate its contribution to the benefit ft (S) -ft (S) -ft (S), with S being a subset of already selected sensors.2. Each sensor can transmit to all other sensors.3. The sensors have calibrated clocks and unique, linear identifications. These assumptions are reasonable in many applications: (1) In target detection, for example, the lens function ft (S) counts the number of targets detected by the sensors. Once previously selected sensors have emitted what targets they have detected, the new sensor can determine how many additional targets have been detected. Likewise, in statistical estimation, a sensor (or a small number of sensors) can randomly activate the number of sensors and spread their value.After Sensors S have been selected and their measurements announced, we can first determine the relatively new (or small) assumptions for the number of sensors (1)."}, {"heading": "4.1 Distributed Selection of a Single Sensor", "text": "The key challenge in the development of a global network is to find a way to filter out exactly one element from a probability distribution based on a particular distribution. (1) We point out that we need to select one element from the universal distribution to enable a uniform distribution. (2) Our algorithms, which assume an arbitrary distribution by allowing sensors to decide individually, also have two other advantages: (1) it is amenable to the modification of activation probabilities at the local level as we discuss them, and (2) because it is not based on a global state of the network, there may be a change in local observations. (2)"}, {"heading": "4.2 The Distributed Online Greedy Algorithm", "text": "We now use our only sensor selection algorithm, the Distributed Online Greedy Algorithm (DOG). It is based on the distributed implementation of EXP3 using the PMS protocol. Suppose we want to select k sensors in each round. Each sensor v maintains k weights wv, 1,.., wv, k and normalizing constants Zv, 1,..., Zv, k. The algorithm runs in k stages, synchronized using the common clock. In stage i, a single sensor is selected using the PMS protocol applied to the distribution (1 \u2212 \u03b3) wv, i / Zv, i + \u03b3 / n. Suppose sensors S = {v1,., vi \u2212 1} were selected in stages 1 to i \u2212 1. The sensor v in stage i \u2212 1 then calculates its local rewards."}, {"heading": "5. THE STAR NETWORK MODEL", "text": "In some applications, the assumption that sensors can send messages to all sensors may be unrealistic. In this section, we will analyze LAZYDOG, a variant of our DOG algorithm, which replaces the above assumptions by the assumption that a dedicated Base Unit 4 is available, which calculates power supplies and can send untransmitted messages to individual sensors. 4Although the existence of such a Base Unit means that the protocol is not fully distributed, it is realistic in sensor network applications where the sensor data must be collected somewhere for analysis. We assume the following assumptions: 1. Each sensor stores its probability mass pv with it and can only send messages to the Base Unit and receive messages. 2. The Base Unit is able to forward the basic data to the Base Unit after receiving messages from a number of sensors."}, {"heading": "5.1 Lazy renormalization & Distributed EXP3", "text": "EXP3 (and all MABs with no remorse guarantees against arbitrary reward functions) must maintain a distribution of actions (= v) and update this distribution in response to feedback about the environment. In EXP3, each sensor v requires only wv (t) and a normalizer Z (t). In the star network model (or more generally in multi-hop models), standard flood six aggregation techniques can be used to calculate and distribute the new normalizer, although at high communication costs. We show that a lazy renormalization scheme can significantly reduce the amount of communication required by a distributed bandit algorithm without changing its boundaries. Thus, our lazy scheme is complementary to standard aggregation techniques. Our lazy renormalization scheme for EXP3 works as follows."}, {"heading": "5.2 LazyDOG", "text": "Once we have the distributed EXP3 variant described above, we can use it for the bandit subroutines in the OGUNIT algorithm (see paragraph 3,2). We call the result the LAZYDOG algorithm, which allows activation due to its use of the rotten renormalization. The rotten distributed EXP3 random sensors from the same distribution as the regularly distributed EXP3, therefore LAZYDOG has exactly the same performance guarantees with regard to the activation t (St) as DOG. It functions in the communication model of the star network and requires few messages or sensor activations. Episode 5 immediately implies the following result.COROLLARY 6 \u2212 The number of sensors that activate each round in LAZYDOG is at most k + O (k) in expectation andO (k log n) with high probability, the number of messages is at most twice the number of sensors in DOK level."}, {"heading": "6. OBSERVATION-DEPENDENT SAMPLING", "text": "Theorem 3 states that DOG is guaranteed to be almost as good as the offline greedy algorithm can be used to select an instance with objective function as we can do. (=) So the reward of the DOG is nearly optimal in many areas of application, even if the nearest sensors typically contribute very little to the objective function. Suppose we run only a single MAB instance to select a single sensor in each round. (If we have access to a black box for evaluating round t, then we can work well on atypical rounds at the cost of additional communication by recording each local reading of their environment and estimating their payout ({v})."}, {"heading": "7. EXPERIMENTS", "text": "In this section we evaluate our DOG algorithm on several real sensation problems."}, {"heading": "7.2 Convergence experiments", "text": "In our first set of experiments, we analyzed the convergence of our DOG algorithm. For both the temperature [T] and precipitation data [R], we first perform the offline greedy algorithm with the fEMSE objective function to select k = 5 sensors. We compare its performance with the DOG algorithm, in which we return the same objective function in each round. We use an exploration probability \u03b3 = 0.01 and a learning rate inversely proportional to the maximum achievable reward fEMSE (V). Figure 4 (a) presents the results of the temperature data set. Note that the algorithm obtains 95% of the performance of the offline algorithm even after only a small number of laps (0.01). After approximately 13,000 iterations, the algorithm receives 99% of the offline performance, which is the best to be expected with an exploration probability of.01. Figure 4 shows the probability that the impact data is increased by 100% after this experiment is completed."}, {"heading": "7.3 Observation dependent activation", "text": "We evaluate our OD-DOG algorithm experimentally with observation-specific sensor activations, selecting different values for the activation cost, which we vary as multiples of the total achievable reward; the activation cost allows us to smoothly compare the average number of sensors that activate each turn with the average reward received; the resulting activation strategies are used to select a subset of the size k = 10 from a collection of 12,527 sensors; Fig. 4 (c) shows convergence rates using the OD-DOG algorithm using a fixed lens function that takes into account all contamination events; Fig. 4 (d) shows convergence rates under a varying lens function that selects a different contamination event in each turn; at low activation costs, the performance quickly approaches or exceeds the performance of the offline solution; even among the lowest activation costs in our experiments, the average number of additional DOG activations per OD activation level may exceed 5."}, {"heading": "8. RELATED WORK", "text": "The problem of deciding when sensors in sensor networks are selectively switched on to save power was first discussed by [?] and [?]. Many approaches to optimizing sensor placement and selection assume that sensors have a fixed region [?,?,?,?], which is usually convex or even circular. Furthermore, it is assumed that everything within a region can be perfectly observed and everything outside cannot be measured by the sensors. For complex applications such as environmental monitoring, these assumptions are unrealistic, and direct optimization of predictive accuracy is desired. The problem of selecting observations to monitor spatial phenomena has been extensively studied in geostatistics [?] and more generally (Bayesian) experimental design [?]. Several approaches have been proposed to activate sensors to minimize uncertainty [?] or prediction errors [?]. However, these approaches have no performance guarantees."}, {"heading": "9. CONCLUSIONS", "text": "We have developed an efficient distributed online greedy algorithm DOG and proved that it suffers no (1 \u2212 1 / e) regrets, essentially the best possible performance that can be achieved unless P = NP. Our algorithm is fully distributed and requires only a small number of messages that are highly likely to be exchanged in each round. We analyze our algorithm in both the broadcast model and the star network model, where a separate base station is responsible for calculating the usability of selected sensor sets. Our LAZYDOG algorithm for the latter model uses lazy renormalization suggestions to reduce the number of messages required from N to O (k log n) and the server memory required from N to O (k + log n). Our LAZYDOG algorithm for the latter model uses lazy renormalization to reduce the number of messages required from N to O (k log n)."}, {"heading": "A. RESULTS IN THE BROADCAST MODEL", "text": "PROOF OF THEOREM 2: To prove the limits of regret, note that in each lap, the distribution via the sensor selection in the variant of EXP3 (which uses the distributed multinomial scanning scheme and repeatedly activates the protocol to always select one sensor in each lap) is exactly the same as the original EXP3. The total number of transmissions is then | S | + 2; using their calibrated clocks, each sensor (re) becomes invariable. \u2212 Next, we tie the number of transmissions. Attach one lap, and have a series of sensors activate in that lap. The total number of transmissions is then | S | + 2; using their calibrated clocks, each sensor pisson (re) samples is activated and activated Xv \u2212 Poisson (\u03b1pv) samples when Xv \u2265 1. If no sensors are activated before a certain time period has elapsed, the standard behavior is to repeat the sampling."}, {"heading": "B. RESULTS IN THE STAR NETWORK MODEL", "text": "In this section we will prove that lazy renormalization samples from a proper scale distribution (1 \u2212 e \u2212 \u03b1) pv where pv is the input distribution. We will then demonstrate the communication via lazy renormalization scheme of Sec. 5.1, described in pseudocode in Fig. 2, samples v with probability enumeratbelow, and then show how these bounds apply to EXP3.PROPOSITION 9, Z (t) is the desired renormalization scheme of v.PROOF. renormalization selects each sensor v with probability (1 \u2212 e) pv, where pv = \u03c1 bits are shared in order to implement a coupled distribution for sensor activation and selection. Lazy renormalization each sensor v with probability (1 \u2212 e \u2212 e) pv, because of the way the random bits rv are shared in order to implement a coupled distribution for sensor activation and selection."}], "references": [], "referenceMentions": [], "year": 2010, "abstractText": "A key problem in sensor networks is to decide which sensors<lb>to query when, in order to obtain the most useful information<lb>(e.g., for performing accurate prediction), subject to con-<lb>straints (e.g., on power and bandwidth). In many applications<lb>the utility function is not known a priori, must be learned<lb>from data, and can even change over time. Furthermore for<lb>large sensor networks solving a centralized optimization prob-<lb>lem to select sensors is not feasible, and thus we seek a fully<lb>distributed solution. In this paper, we present Distributed<lb>Online Greedy (DOG), an efficient, distributed algorithm for<lb>repeatedly selecting sensors online, only receiving feedback<lb>about the utility of the selected sensors. We prove very strong theoretical no-regret guarantees that apply whenever the (un-<lb>known) utility function satisfies a natural diminishing returns<lb>property called submodularity. Our algorithm has extremely<lb>low communication requirements, and scales well to large sensor deployments. We extend DOG to allow observation-<lb>dependent sensor selection. We empirically demonstrate the<lb>effectiveness of our algorithm on several real-world sensing<lb>tasks.", "creator": "TeX"}}}