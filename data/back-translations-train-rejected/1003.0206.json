{"id": "1003.0206", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2010", "title": "Why has (reasonably accurate) Automatic Speech Recognition been so hard to achieve?", "abstract": "Hidden Markov models (HMMs) have been successfully applied to automatic speech recognition for more than 35 years in spite of the fact that a key HMM assumption -- the statistical independence of frames -- is obviously violated by speech data. In fact, this data/model mismatch has inspired many attempts to modify or replace HMMs with alternative models that are better able to take into account the statistical dependence of frames. However it is fair to say that in 2010 the HMM is the consensus model of choice for speech recognition and that HMMs are at the heart of both commercially available products and contemporary research systems. In this paper we present a preliminary exploration aimed at understanding how speech data depart from HMMs and what effect this departure has on the accuracy of HMM-based speech recognition. Our analysis uses standard diagnostic tools from the field of statistics -- hypothesis testing, simulation and resampling -- which are rarely used in the field of speech recognition. Our main result, obtained by novel manipulations of real and resampled data, demonstrates that real data have statistical dependency and that this dependency is responsible for significant numbers of recognition errors. We also demonstrate, using simulation and resampling, that if we `remove' the statistical dependency from data, then the resulting recognition error rates become negligible. Taken together, these results suggest that a better understanding of the structure of the statistical dependency in speech data is a crucial first step towards improving HMM-based speech recognition.", "histories": [["v1", "Sun, 28 Feb 2010 19:00:12 GMT  (82kb,D)", "http://arxiv.org/abs/1003.0206v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["steven wegmann", "larry gillick"], "accepted": false, "id": "1003.0206"}, "pdf": {"name": "1003.0206.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Steven Wegmann"], "emails": [], "sections": [{"heading": null, "text": "Why is (reasonably accurate) automatic speech recognition so difficult to achieve? Steven Wegmann & Larry Gillick Nuance CommunicationsMobile Research"}, {"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "1.1 Outline", "text": "In Section 3, we describe experiments that show that MMI can compensate for simple miscalculations of acoustic values. In Section 4.1, we describe our initial simulation and resampling experiments. In these experiments, we generate pseudo-statements that follow the model of the HMM generation but violate the normal diagonal output assumption in a controlled manner. In Section 5, we describe our experiments that examine the type of statistical dependence on real data and its effects on recognition performance."}, {"heading": "1.2 Acknowledgments", "text": "We would like to thank Don McAllaster for not only providing us with the simulation software we used in the early stages of this research, but also providing us with helpful feedback on this work. We would also like to thank our colleagues Orith Toledo-Ronen, Jim Wu and George Zavaliagkos for useful discussions about this research. Finally, we would like to thank Nuance Communications for supporting this research."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 HMM Notation", "text": "We start with a fairly general definition of an HMM. Let X1, X2,. Xn is a sequence of observed d-dimensional acoustic vectors following P (n) and the parameter number. \"3 A probability function for X1, X2,., Xn, f\u03b8.,\" is a hidden Markov model if the following three assumptions apply: (a) (Hidden chain) We are given, but not observe, a finite stationary Markov chain S1, S2,.,.,.,.,.,.,.,.,.,.,.,.,,.,.,,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,...,.,.,.,.,.,.,.,.,.,.,...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "2.2 Experimental preliminaries", "text": "This year, it has come to the point where you have to go in search of a new concept in order to go in search of a new concept. \"We've done it,\" he says, \"but we're not there yet to go in search of a new concept.\" Unless you've gone in search of a new concept. \"We've developed a new concept,\" he says, \"but we're not there yet to go in search of a new concept.\""}, {"heading": "2.3 Simulating a pseudo utterance from an HMM", "text": "The classical reference for this material is [1], Chapter 26. Here is a general description of how to create a parallel version of a corpus by simulating from an HMM. We leave the actual simulation details in (short) limbo. The inputs are the model, a dictionary, the transcript and the real utterance. We use the model, the transcript, the dictionary and the forced alignment to select the pronunciation (we discard the time information) and the interword silence (sp or sil). We use an alignment to ensure that the real and pseudo-utterance share the underlying trilingual sequence, but a perfectly reasonable alternative is to make random selections among the pronunciations and sweat types. 6 This results in a trilingual sequence for utterance, e.g., sil a + b + c-b-c-c-sil."}, {"heading": "2.4 Resampling from a corpus", "text": "In this section, we briefly describe how resampling differs from simulation in the context of an HMM. Readers should consult [6] for more details. We will use resampling to generate frames from the initial distributions. At the center of the resampling method is a collection of labeled urns that contain frames. If we need a frame from a state, we select a single frame (with replacement) from the corresponding frame. How do we fill the urns with frames? We start with a collection of statements that have state orientations that use either (a) forced orientation or (b) forward direction from the corresponding frame. We go through all frames in the collection by placing each frame in its corresponding urn with a count in case (a) and a fraction number that comes from the HMM."}, {"heading": "3 Experiments involving MMI and score scales", "text": "In this section, we begin with a more detailed description of the anomalous results of the LM scale outlined in the introduction. We then show that the MMI machines can compensate for simple artificial scales that we introduce into pseudo-data."}, {"heading": "3.1 An anomaly", "text": "We generated pseudo-test and training data by simulation from the model. When we performed detection on the pseudo-test data scale with the LM scale of 16, the WHO was 2.0%, which seemed relatively low at the time. We created grids on the pseudo-training data, again with the LM scale of 16, and ran 100 passes of the extended Tree Welch. To our surprise, the WHO steadily decreased during the passes of the extended Tree Welch: from 2.0% at the mle, it dropped to 1.3% after 10 passes, and ended at 0.7% after 100 passes. How could a different choice of parameters lead to better classification performance? 10Of course, the problem was that we used the LM scale of 16. This choice is what we have routinely used for WSJ experiments, but it is the wrong choice if the data matches the model."}, {"heading": "3.2 Is MMI compensating for differences in score scales?", "text": "The results of the previous section are very intriguing: we inadvertently introduced an additional scale (1 / 16), which was applied uniformly to the acoustics, and one possibility we had to eliminate was that there was an error in our code. In response, we have maximum probability that these models were indistinguishable from the models we were able to simulate the pseudo-training data."}, {"heading": "4 Initial experiments with simulated and re-", "text": "In this section, we begin by describing our first experiments with simulated test and training data. At the time, these results were both surprising and discouraging; they only made sense when we turned to experiments with newly collected data. These experiments all aim to understand the extent to which real data differs from the diagonal normal output assumption and what effect this has on detection performance. In this section, we will show that real data differs significantly from the shape of our output distributions, but that this deviation does not appear to be a major cause of error."}, {"heading": "4.1 Simulation experiments", "text": "We would then run the MMI machinery to see if and how it compensates for the known mismatch. There are two obvious model assumptions we start with, both of which incorporate the diagonal normal output assumption, namely our use of diagonal rather than complete covariance and our use of normal distribution. Our use of unimodal models should make it easier to see any effects. As a starting point, we have created pseudo-test data by simulating and detecting from this model: the WHO is 0.2% (16 errors). One conclusion we can draw directly from this result is that there is virtually no overlap in the 1,500 output distributions we use, as we would have seen a higher error rate if there were significant overlaps. We find this to be very surprising! The first experiment tests whether MMI compensates for the diagonal variance assumption, as real data clearly contravenes these assumptions."}, {"heading": "4.2 The predicted versus observed distribution of acous-", "text": "We were so surprised by the latest results that we began to wonder if some of our assumptions about the data were correct. (In particular: How far do the data differ from the unimodal normal production distributions?) The first statement is obvious, while the second follows from the results we draw from the corresponding acoustic models themselves. First, we introduce a bit of notation. We use j to index our 1500 states whose diagonal normal production distributions have 39-dimensional means. We will use i to index the 39 dimensions, and denote the ith component of the 39-dimensional vector of \u00b5j, i."}, {"heading": "4.3 Resampling experiments", "text": "This year is the highest in the history of the country."}, {"heading": "5 Controlling for statistical dependence", "text": "All simulation and resampling experiments in Section 4 generate pseudo-statements that meet the underlying Markov assumption in our model, or to put it another way: These pseudo-statements respect the HMM generation model. In this section, we describe a series of new experiments that generate pseudo-statements that violate this generational model. Finally, we not only see significant word error rates in these pseudo-statements, but also show that statistical dependence is a major cause of detection errors in real data. We also investigate the source of dependence by analyzing the correlation structure in the results broadcast by the models. Finally, we present two variants of the main experiment, which in the first case investigates how much of the dependence we observe is due to the correlation built into our feature set, and in the second case, it presents preliminary results using speaker-dependent resampling data."}, {"heading": "5.1 The main experiment", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "5.2 Variant 1: cepstral features", "text": "The 39-dimensional characteristics we use consist of 13 ceptral characteristics plus their first and second differences. The inclusion of the differences guarantees that adjacent frames are correlated to some degree. How much of the time dependence we observed in Section 5.1 is due to this? To answer this question, we repeat the experiments only with the 13-dimensional characteristics. To generate these data, we simply extract the 13-dimensional subspaces from the models and the characteristics. Table 4 compares the results to pseudo-data generated from the model using simulation using 39 or 13-dimensional characteristics. Since the error rates are so low, ranging from a minimum of 0.2% to a maximum of 1.4%, we show the number of errors on these test sets in Table 4 instead of WHO. The small number of errors in the simulation results implies that there is surprisingly little overlap in the models in 39 or 13 dimensions."}, {"heading": "5.3 Variant 2: speaker dependent resampling", "text": "This year, it will be able to fix and fix the mentioned bugs."}, {"heading": "6 Discussion", "text": "In fact, it is as if most of us are able to surpass ourselves by putting ourselves at the centre. (...) It is not as if they step into the role of the individual. (...) It is not as if they slip into the role of the individual. (...) It is not as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual. (...) It is as if they slip into the role of the individual."}], "references": [{"title": "Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables", "author": ["M. Abramowitz", "I.A. Stegun", "eds"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1972}, {"title": "The DRAGON system \u2013 an overview", "author": ["J.K. Baker"], "venue": "IEEE Transactions on Acoustics, Speech, and Signal Processing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1975}, {"title": "Buried Markov models: a graphical-modeling approach to automatic speech recognition", "author": ["J.A. Bilmes"], "venue": "Computer Speech and Language,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Advances in speech transcription at IBM under the DARPA EARS program", "author": ["S. Chen", "B. Kingsbury", "L. Mangu", "D. Povey", "G. Saon", "H. Soltau", "G. Zweig"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Bootstrap methods: another look at the jackknife", "author": ["B. Efron"], "venue": "The Annals of Statistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1979}, {"title": "The Jackknife, the Bootstrap and Other Resampling Plans", "author": ["B. Efron"], "venue": "SIAM CBMS-NSF Monographs,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1982}, {"title": "Continuous speech recognition by statistical methods", "author": ["F. Jelinek"], "venue": "IEEE Proceedings,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1976}, {"title": "Large-Vocabulary Speaker-Independent Continuous Speech Recognition: the Sphinx System", "author": ["Lee", "K.-F"], "venue": "Ph. D. Thesis,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1988}, {"title": "Speech recognition by machines and humans", "author": ["R. Lippmann"], "venue": "Speech Communication,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Studies with fabricated Switchboard data: exploring sources of model-data mismatch", "author": ["D. McAllaster", "L. Gillick", "F. Scattone", "M. Newman"], "venue": "Proceedings of DARPA Broadcast News Transcription and Understanding Workshop,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Pushing the envelope - aside : beyond the spectral envelope as the fundamental representation for speech recognition", "author": ["N. Morgan", "Q. Zhu", "A. Stolcke", "K. Sonmez", "S. Sivadas", "T. Shinozaki", "M. Ostendorf", "P. Jain", "H. Hermansky", "D. Ellis", "G. Doddington", "B. Chen", "O. Cretin", "H. Bourlard", "M. Athineos"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "From HMM\u2019s to segment models: a unified view of stochastic modeling for speech recognition", "author": ["M. Ostendorf", "V. Digalakis", "O.A. Kimball"], "venue": "IEEE Transactions on Speech and Audio Processing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1996}, {"title": "Discriminative Training for Large Vocabulary Speech Recognition, Ph", "author": ["D. Povey"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Large vocabulary continuous speech recognition using HTK", "author": ["P.C. Woodland", "J.J. Odell", "V. Valtchev", "S.J. Young"], "venue": "Proceedings of ICASSP-94,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1994}, {"title": "Large scale discriminative training of hidden Markov models for speech recognition", "author": ["P.C. Woodland", "D. Povey"], "venue": "Computer Speech and Language,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}, {"title": "Acoustic segmentation and phonetic classification in the SUMMIT system", "author": ["V. Zue", "J. Glass", "M. Philips", "S Seneff"], "venue": "Proceedings of ICASSP-89,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1989}], "referenceMentions": [{"referenceID": 1, "context": "It has now been over 35 years since hidden Markov Models were first applied to the problem of speech recognition ([2], [7]).", "startOffset": 114, "endOffset": 117}, {"referenceID": 6, "context": "It has now been over 35 years since hidden Markov Models were first applied to the problem of speech recognition ([2], [7]).", "startOffset": 119, "endOffset": 122}, {"referenceID": 7, "context": "Perhaps a key turning point in this regard was Kai-Fu Lee\u2019s thesis work [8], in which he clearly explained how to train an HMM-based system and then successfully applied a series of variations on the HMM theme to the Resource Management task, which was defined by DARPA and where the results were publicly evaluated by NIST.", "startOffset": 72, "endOffset": 75}, {"referenceID": 15, "context": "One thinks of segmental models of various sorts ([17], [12]), and more recently, of the use of graphical models ([3]).", "startOffset": 49, "endOffset": 53}, {"referenceID": 11, "context": "One thinks of segmental models of various sorts ([17], [12]), and more recently, of the use of graphical models ([3]).", "startOffset": 55, "endOffset": 59}, {"referenceID": 2, "context": "One thinks of segmental models of various sorts ([17], [12]), and more recently, of the use of graphical models ([3]).", "startOffset": 113, "endOffset": 116}, {"referenceID": 3, "context": "conversational material found in Switchboard or Fisher data) are still very high (around 15% [4]), compared to what is achievable by", "startOffset": 93, "endOffset": 96}, {"referenceID": 9, "context": "But how false are they? Is their falsity actually crippling the results we are obtaining? Around 10 years ago, we and some of our colleagues at Dragon Systems ([10]) undertook a series of studies of speech recognition based on the use of", "startOffset": 160, "endOffset": 164}, {"referenceID": 8, "context": "See the still excellent survey article [9].", "startOffset": 39, "endOffset": 42}, {"referenceID": 10, "context": ", [11]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": "Back in the late 1970s Bradley Efron, a statistician at Stanford, proposed a general approach called Bootstrapping [5], [6] as a method for deriving the properties of statistical algorithms without the necessity of making specific parametric assumptions.", "startOffset": 115, "endOffset": 118}, {"referenceID": 5, "context": "Back in the late 1970s Bradley Efron, a statistician at Stanford, proposed a general approach called Bootstrapping [5], [6] as a method for deriving the properties of statistical algorithms without the necessity of making specific parametric assumptions.", "startOffset": 120, "endOffset": 123}, {"referenceID": 13, "context": "odd in [14].", "startOffset": 7, "endOffset": 11}, {"referenceID": 12, "context": "When we refer to MMI training, we mean lattice-based extended BaumWelch as described in [13] or [15].", "startOffset": 88, "endOffset": 92}, {"referenceID": 14, "context": "When we refer to MMI training, we mean lattice-based extended BaumWelch as described in [13] or [15].", "startOffset": 96, "endOffset": 100}, {"referenceID": 0, "context": "The classic reference for this material is [1], chapter 26.", "startOffset": 43, "endOffset": 46}, {"referenceID": 0, "context": "Let F be a continuous, invertible, cumulative distribution function and let the continuous random variable U have uniform distribution on [0, 1].", "startOffset": 138, "endOffset": 144}, {"referenceID": 0, "context": "1 to generate data having distribution F , first we use a random number generator to choose u \u2208 [0, 1], then we find the unique x satisfying F (x) = u.", "startOffset": 96, "endOffset": 102}, {"referenceID": 0, "context": "We use a random number generator d times to create the d-dimensional vector u with each component ui \u2208 [0, 1] and use this to create a d-dimensional vector y by the rule yi = \u03a6 (ui) for i \u2264 i \u2264 d.", "startOffset": 103, "endOffset": 109}, {"referenceID": 0, "context": "Then the {Aj}j=1 form a partition of [0, 1], which means that \u222aj=1Aj = [0, 1] and \u2229j=1Aj = \u2205.", "startOffset": 37, "endOffset": 43}, {"referenceID": 0, "context": "Then the {Aj}j=1 form a partition of [0, 1], which means that \u222aj=1Aj = [0, 1] and \u2229j=1Aj = \u2205.", "startOffset": 71, "endOffset": 77}, {"referenceID": 0, "context": "We use this partition to define a function h : [0, 1] \u2192 {1, 2, .", "startOffset": 47, "endOffset": 53}, {"referenceID": 0, "context": ", n} in the following way: given u \u2208 [0, 1] there is a unique j with u \u2208 Aj and we set h(u) = j.", "startOffset": 37, "endOffset": 43}, {"referenceID": 0, "context": "Finally, if the continuous random variable U has uniform distribution on [0, 1], then we define a discrete random variable X on a set of values {xi}i=1 by X = h(U).", "startOffset": 73, "endOffset": 79}, {"referenceID": 0, "context": "The function h is given in terms of u \u2208 [0, 1] by", "startOffset": 40, "endOffset": 46}, {"referenceID": 0, "context": "Since U has uniform distribution over [0, 1], it follows that the probability distribution of the random variable X = h(U) is given by", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "To simulate the random variable X we first use a random number generator to choose u \u2208 [0, 1].", "startOffset": 87, "endOffset": 93}, {"referenceID": 0, "context": "5 shows that this is equivalent to repeatedly running a random number generator, which takes values in [0, 1], to create a sequence u1, u2, .", "startOffset": 103, "endOffset": 109}, {"referenceID": 5, "context": "The reader should consult [6] for more details.", "startOffset": 26, "endOffset": 29}], "year": 2010, "abstractText": "It has now been over 35 years since hidden Markov Models were first applied to the problem of speech recognition ([2], [7]). Moreover, it has now been over 20 years since the speech recognition community seemed to collectively adopt the HMM paradigm as the most useful general approach to the fundamental problem of modeling speech. Perhaps a key turning point in this regard was Kai-Fu Lee\u2019s thesis work [8], in which he clearly explained how to train an HMM-based system and then successfully applied a series of variations on the HMM theme to the Resource Management task, which was defined by DARPA and where the results were publicly evaluated by NIST. This is not to say that there have not been critiques of the HMM as a model of speech, nor that there have not been alternatives proposed and even explored at some length. One thinks of segmental models of various sorts ([17], [12]), and more recently, of the use of graphical models ([3]). Nonetheless, we think it is fair to say that it is still true in 2010 that the HMM remains the consensus model of choice for speech recognition, and that it lies at the heart of both commercially available products and contemporary research systems. However, in spite of the great success of the HMM paradigm, all is not well in the Land of Speech Recognition. Machine error rates on natural speech (e.g. conversational material found in Switchboard or Fisher data) are still very high (around 15% [4]), compared to what is achievable by", "creator": "LaTeX with hyperref package"}}}