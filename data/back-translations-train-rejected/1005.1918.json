{"id": "1005.1918", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2010", "title": "Prediction with Expert Advice under Discounted Loss", "abstract": "We study prediction with expert advice in the setting where the losses are accumulated with some discounting---the impact of old losses may gradually vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm for Regression to this case, propose a suitable new variant of exponential weights algorithm, and prove respective loss bounds.", "histories": [["v1", "Tue, 11 May 2010 19:27:35 GMT  (20kb)", "https://arxiv.org/abs/1005.1918v1", "22 pages; draft version"], ["v2", "Fri, 4 Jun 2010 19:13:37 GMT  (24kb)", "http://arxiv.org/abs/1005.1918v2", "26 pages; expanded (2 remarks -&gt; theorems), some misprints corrected"]], "COMMENTS": "22 pages; draft version", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alexey chernov", "fedor zhdanov"], "accepted": false, "id": "1005.1918"}, "pdf": {"name": "1005.1918.pdf", "metadata": {"source": "CRF", "title": "Prediction with Expert Advice under Discounted Loss", "authors": ["Alexey Chernov", "Fedor Zhdanov"], "emails": ["chernov@cs.rhul.ac.uk", "fedor@cs.rhul.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 100 5.19 18v2 [cs.LG] 4 JWe study predictions with expert advice in the environment where losses are accumulated at a certain discount and the effects of old losses can gradually disappear. We generalize the Aggregating Algorithm and the Aggregating Algorithm for Regression, propose a new variant of the exponentially weighted average algorithm and prove limits of cumulative discounted loss."}, {"heading": "1 Introduction", "text": "The quality of each prediction (the discrepancy between the prediction and the actual outcome) is evaluated by a real number called a loss. Losses are calculated within the standard prediction framework with expert recommendations (see Monograph [2] for a comprehensive review. In this paper, we consider a generalization where older losses can be depreciated; in other words, we use discounted cumulative losses. Predictions are made by experts and learners in accordance with Protocol 1. InProtocol 1. Prediction with expert recommendations in accordance with general discountingL0: = 0. Predictions 0: = 0."}, {"heading": "2 Linear Bounds for Learner\u2019s Loss", "text": "In this section, we assume that the group of experts is limited, namely for all experts k, where c \u2265 1 and \u03b7 > 0 are constants. Limits of this kind have been reached in [19]. To recall: such a limit applies to certain c and \u03b7, if and only if the game has the following property: \"[0, 1] so that this property applies to any arbitrary finite game.\" (This also applies to all other games). \"(It turns out that this property is not sufficient for each game.\" (It turns out that this property is sufficient for the game.) \"Theorem\" 1. Assumption that the game (this game) is not sufficient. \"(Theorem) 1. Assumption that the game (this game) is not sufficient.\" (1) \"We assume that the game (this game) is sufficient.\""}, {"heading": "2.1 Learner\u2019s Strategy", "text": "To prove theorem 1, we will use the AA with a minor modification. Algorithm 1: Aggregation Algorithm1: Initialization weights of experts wk0: = 1 / K, k = 1,.., K. 2: for t = 1, 2,.. do 3: Get Experts's predictions g1, k = 1,.., K. 4: Calculate gt (p) = 0: Update of weights w: = K = 1 w k \u2212 1e \u2212 n (p,.), for all., for all. 5: Output g.t: =."}, {"heading": "2.2 Proof of the Bound", "text": "\u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2"}, {"heading": "3 Learner\u2019s Loss in Bounded Convex Games", "text": "The linear limits of the form (4) are perfect if c = 1. For many games (for example, the game with absolute loss), condition (3) does not apply to c = 1 (with any \u03b7 > 0), and one cannot reach a limit of the form Lt \u2264 Lkt + O (1). However, since the losses of the experts can increase as T in the worst case, any limit with c > 1 only guarantees that the loss of the learner can exceed the loss of an expert in mostO (T). However, for a large class of interesting games (including the absolute loss game), guarantees of the form LT \u2264 LkT + O (\u221a T) can be obtained in the undiscounted case. In this section, we prove an analogous result for the discounted setting. A game (e.g. a game) is not empty if it is empty and not empty. The game is not designated as empty if it is not empty."}, {"heading": "3.1 Learner\u2019s Strategy for Theorem 2", "text": "The pseudo-code of the learner's strategy is given as algorithm 3. It contains a constant a > 0 = 1 = 1, which we will select later in the study. The algorithm is not fully specified, since lines 6-7 of algorithm 3 allow an arbitrary choice that fulfils the inequality. The algorithm can be completed with the help of a substitution function as in algorithm 2, replacing lines 6-8. (However, the current form of algorithm 3 emphasizes the similarity to algorithm 5, which is described later. (subsection 3.3), but actually inspires our analyses."}, {"heading": "3.2 Proof of Theorem 2", "text": "Analog to the case of AAD, we want to show that Algorithm 3 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s s s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s s \u00b2 s s s s s s \u00b2 s \u00b2 s s s s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s s s s s \u00b2 s s \u00b2 s s s s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s s s s \u00b2 s \u00b2 s s s s s s \u00b2 s s s s s s \u00b2 s s s s s \u00b2 s \u00b2 s \u00b2 s s s s s s s \u00b2 s s s s s s"}, {"heading": "3.3 A Bound with respect to \u01eb-Best Expert", "text": "Algorithm 3 is derived from the \"Fake Defensive Forecasting\" (FDF) algorithm of [5, Theorem 9]. This algorithm is based on the ideas of defensive prediction [4], in particular [5], the ideas of [2, Theorem 2.2] and [13]. In this subsection we will consider a direct extension of the FDF algorithm from [5, Theorem 9] to the discounted case [5]. Algorithm 5 becomes the FDF algorithm if it contains the 5 Fake Defensive Forecasting Algorithm with Discounting1: Initialize cumulative losses L0 = 0, Lk0 = 0, K. Set \u03b21 = 0."}, {"heading": "4 Regression with Discounted Loss", "text": "In this section we consider a regression task where the learner must predict \"labels\" yt-R for input examples xt-X-Rn. Predictions are made according to protocol 2. This task can be embedded in the prediction with ExpertProtocol 2 Competitive online regressionfor t = 1, 2,... do Reality announces xt-X. The learner announces yt-t. end foradvice when the learner competes with all functions x-y from a large class that serves as a pool of (imaginary) experts."}, {"heading": "4.1 The Framework and Linear Functions as Experts", "text": "Let the input range be X Rn, the set of predictions is 1 = \u03b22 = \u03b22, and the set of results is 1 = [Y1, Y2]. In this section we will consider the square loss \u03bbsq (\u03b3, y) = (\u03b3 \u2212 y) 2. Let us take a distribution over the experts P (d). It is known from [19] that (3) applies to the square loss with c = 1, \u03b7 = 2 (Y2 \u2212 Y1) 2: n x x at step. It is known that (3) does not apply to the square loss with c = 2 (Y2 \u2212 Y1) T. (20) Denote by the matrix of quantity T \u00b7 n consists of the rows of the input vectors."}, {"heading": "4.2 Functions from an RKHS as Experts", "text": "In this section we apply the kernel trick to the linear method to compete with broader groups of experts. (Each expert f = 2) predicts f (xt). (Here F is a reproducing kernel Hilbert (RKHS) with a positive definitive kernel k = \u03b2\u03b2\u03b22 (\u03b22). (Each kernel defines a unique RKHS. (Each kernel defines a unique RKHS.) We use the notation KT = \u2264 (xi, xj)} i, j = \u03b21, T for the kernel matrix for the input vectors in step T. Similarly to [7] we prove the following upper limit for the discounted square loss of learner.Theorem 5. For a > 0, there is a strategy for learners in Protocol 2b, for each positive integer T and each predictor f (F, T = 1\u03b2t \u03b22)."}, {"heading": "4.3 Proofs of Theorems 4 and 5", "text": "Let's start with several technical lemmas from linear algebra. The proofs for some of these lemmas are moved to Appendix A.1. Lemma 2. \u00b7 Let A have a symmetric positive definitive matrix of size n \u00b7 n. Let the proofs for some of these lemmas be moved to Appendix A.1. Lemma 2. \u00b7 Let A have a symmetric positive definitive matrix of size n \u00b7 n. Let the proofs for this problem be found in [9, theorem 15.12.1]. \u2212 Lemma 3. Let A have a symmetric positive definitive matrix of size n \u00b7 n. Let b, z, Rn and F (A, b, z) = positive Rn Q (BC). The proof for this problem can be found in [9, theorem 15.12.1]. \u2212 Lemma 3. Let A have a symmetric positive definitive matrix of size n."}, {"heading": "4.3.1 Proof of Theorem 4.", "text": "We take the Gaussian initial distribution over the experts with a parameter a > 0: P0 (d\u03b8) = (a\u03b7\u03c0) n / 2e \u2212 a\u03b7 \u0432 2 d\u0445.and use \"Algorithm 2 with an infinite number of experts.\" If we repeat the derivatives from Section 2.2, we obtain the following analogy of (7): (a\u03b7\u03c0) n / 2 \u00b2 e \u00b2 e \u00b2 (\u2211 T = 1 \u03b2t \u03b2T (\u03b3t \u2212 yt) 2 \u2212 2 \u2212 4 T = 1 \u03b2t \u03b2T (\u03b8 \u00b2 xt \u2212 yt) 2) 2) 2) e \u2212 a\u03b7 \u00b2 2 d\u03b8 \u2264 1. The simple equation T \u00b2 t = 1\u03b2t \u03b2T (\u03b8 \u00b2 xt \u2212 yt) 2 + a \u00b2 2 = ta \u00b2 2 (aI + X \u2032 WTX \u00b2 WTX). \u2212 2 T \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 and T = s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s)."}, {"heading": "4.3.2 Proof of Theorem 5.", "text": "We have to prove that for each T and each sequence (x1, y1,.., xT, yT) the guarantee (24) is fulfilled. Fix T and (x1, y1,..., xT, yT). Let us fix an isomorphism between the linear range of kx1,.., kxT for the Riesz representation theorem and RT, where T is the dimension of the linear range of kx1,.., kxT. Let us leave the x-range of kx1,.., x-T-RT-T the images of kx1,... \u2212, kxT-T each under this isomorphy. We then have k (\u00b7, xi) = < x-i > for each x-range. Let us apply the strategy of theorem 4 to x-T."}, {"heading": "4.4 Regression Algorithms", "text": "In this section we explicitly derive the prediction strategies for learners used in theorems 4 and 5."}, {"heading": "4.4.1 Strategy for Theorem 4.", "text": "In [22] Vovk proposes the following substitution function for the square loss: \u03b2T = Y2 + Y1 2 \u2212 gT (Y2) \u2212 gT (Y1) 2 (Y2 \u2212 Y1). (30) It allows us to calculate gT with unnormalized weights: gT (y) = \u2212 1\u03b7 (ln). (Here we use expansion (29), whereas AT = aI + T \u2212 1 + yxT) + (T \u2212 1 t = 1 \u03b2t \u03b2Ty2t + y 2)). (D) for any y operations (Y1, Y2] (here we use expansion (29). \u2212 The direct calculation of gT \u2212 1\u03b2t \u03b2T xtx \u2032 t + xTx T \u2032 T = aI + X \u2032 WTX \u2032 YY, and bT \u2212 T \u2212 1 = 1 \u03b2t \u03b2t \u03b2Tytxt."}, {"heading": "4.4.2 Strategy for Theorem 5.", "text": "We use the following notation. LetkT is the last column of the matrix KT, kT = {k (xi, xT)} Ti = 1, YT is the column vector of the results YT = (y1,.., yT). \"(32) When we write Z = (V; Y) or Z = (V; Y), we mean that the column vector Z is achieved by concatenating two column vectors V, Y vertically or V \u2032, Y \u2032 horizontally. As can be seen from the proof for Theorem 5, we must prove that the strategy for this theorem is the same as the strategy for Theorem 4 in the case where the kernel is the scalar product \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 31), the predictions (31) can be presented as T = (YT = (YT) and YT xT (xT)."}, {"heading": "Acknowledgements", "text": "We thank Yura Kalnishkan and Volodya Vovk for numerous enlightening discussions. This work was supported by the EPSRC (grant EP / F002998 / 1)."}, {"heading": "A Appendix", "text": "For T = 1, inequality is trivial. Let's assume that for T \u2212 1 \u00b0 C (1 \u00b0 C) + 1 \u00b0 C (2 \u00b0 C) + 1 \u00b0 C (2 \u00b0 C) + 2 \u00b0 C (2 \u00b0 C) + 2 \u00b0 C (2 \u00b0 C) + 2 \u00b0 C (2 \u00b0 C). The first inequality is due to the assumption of production, and the second inequality holds since \u03b2T \u2212 1 \u00b0 C (2 \u00b0 C), the last inequality is 2 \u00b0 C (2 \u00b0 C), the last inequality is 2 \u00b0 C (2 \u00b0 C), the last inequality is 2 \u00b0 C (2 \u00b0 C), the last inequality is 2 \u00b0 C (2 \u00b0 C)."}], "references": [{"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "A parameter-free hedging algorithm", "author": ["K. Chaudhuri", "Y. Freund", "D. Hsu"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Supermartingales in prediction with expert advice", "author": ["A. Chernov", "Y. Kalnishkan", "F. Zhdanov", "V. Vovk"], "venue": "Theoretical Computer Science,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Prediction with Advice of Unknown Number of Experts Technical report, arXiv:1006.0475 [cs.LG], arXiv.org e-Print archive", "author": ["A. Chernov", "V. Vovk"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "A new hedging algorithm and its application to inferring latent random variables. Technical report, arXiv:0806.4802v1 [cs.GT], arXiv.org e-Print archive", "author": ["Y. Freund", "D. Hsu"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "On-line prediction with kernels and the complexity approximation principle", "author": ["A. Gammerman", "Y. Kalnishkan", "V. Vovk"], "venue": "Uncertainty in Artificial Intelligence, Proc. of 20th Conf., pp", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Exponential smoothing: The state of the art \u2013 part II", "author": ["E.S. Gardner"], "venue": "International Journal of Forecasting 22,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Matrix algebra from a statistician\u2019s perspective", "author": ["D.A. Harville"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Sequential prediction of individual sequences under general loss functions", "author": ["D. Haussler", "J. Kivinen", "M. Warmuth"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Tracking the best expert", "author": ["M. Herbster", "M.K. Warmuth"], "venue": "Machine Learning 32,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1998}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["W. Hoeffding"], "venue": "Journal of the American Statistical Association 58,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1963}, {"title": "The weak aggregating algorithm and weak mixability", "author": ["Y. Kalnishkan", "M. Vyugin"], "venue": "Technical report, CLRC-TR-03-01,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "The weak aggregating algorithm and weak mixability", "author": ["Y. Kalnishkan", "M. Vyugin"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Uniform tests of randomness", "author": ["L. Levin"], "venue": "Soviet Mathematics Doklady 17,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1976}, {"title": "Optimal properties of exponentially weighted forecasts", "author": ["J.F. Muth"], "venue": "Journal of the American Statistical Association", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1960}, {"title": "Learning with kernels: Support Vector Machines, regularization, optimization, and beyond", "author": ["B. Sch\u00f6lkopf", "A.J. Smola"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "Reinforcement learning: An introduction", "author": ["R. Sutton", "A. Barto"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1998}, {"title": "Aggregating strategies", "author": ["V. Vovk"], "venue": "Proceedings of the Third Annual Workshop on Computational Learning Theory. pp", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1990}, {"title": "A Game of Prediction with Expert Advice", "author": ["V. Vovk"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}, {"title": "Derandomizing stochastic prediction strategies", "author": ["V. Vovk"], "venue": "Machine Learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1999}, {"title": "Competitive on-line statistics", "author": ["V. Vovk"], "venue": "Int. Stat. Review 69,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2001}, {"title": "On-line regression competitive with reproducing kernel Hilbert spaces. Technical report, arXiv:cs/0511058 [cs.LG], arXiv.org e-Print archive", "author": ["V. Vovk"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "Hoeffding\u2019s inequality in game-theoretic probability. Technical Report, arXiv:0708.2502 [math.PR], arXiv.org e-Print archive", "author": ["V. Vovk"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "In the standard framework for prediction with expert advice (see the monograph [2] for a comprehensive review), the losses from all steps are just summed.", "startOffset": 79, "endOffset": 82}, {"referenceID": 17, "context": "The standard protocol of prediction with expert advice (as described in [19, 20]) is a special case of Protocol 1 where Accountant always announces \u03b1t = 1, t = 0, 1, 2, .", "startOffset": 72, "endOffset": 80}, {"referenceID": 18, "context": "The standard protocol of prediction with expert advice (as described in [19, 20]) is a special case of Protocol 1 where Accountant always announces \u03b1t = 1, t = 0, 1, 2, .", "startOffset": 72, "endOffset": 80}, {"referenceID": 14, "context": ", [16]), time series analysis (see, e.", "startOffset": 2, "endOffset": 6}, {"referenceID": 6, "context": ", [8]), reinforcement learning [18], and other applications.", "startOffset": 2, "endOffset": 5}, {"referenceID": 16, "context": ", [8]), reinforcement learning [18], and other applications.", "startOffset": 31, "endOffset": 35}, {"referenceID": 4, "context": "In the context of prediction with expert advice, Freund and Hsu [6] noted that the discounted loss provides an alternative to \u201ctracking the best expert\u201d framework [11].", "startOffset": 64, "endOffset": 67}, {"referenceID": 9, "context": "In the context of prediction with expert advice, Freund and Hsu [6] noted that the discounted loss provides an alternative to \u201ctracking the best expert\u201d framework [11].", "startOffset": 163, "endOffset": 167}, {"referenceID": 0, "context": "8 in [2] gives a guarantee only at one moment T chosen in advance.", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "Under this discounting, NormalHedge algorithm is analysed in [6]; we briefly compare the obtained bounds in Section 3.", "startOffset": 61, "endOffset": 64}, {"referenceID": 18, "context": "In Section 2, we propose a generalization of the Aggregating Algorithm [20] and prove the same bound as in [20] but for the discounted loss.", "startOffset": 71, "endOffset": 75}, {"referenceID": 18, "context": "In Section 2, we propose a generalization of the Aggregating Algorithm [20] and prove the same bound as in [20] but for the discounted loss.", "startOffset": 107, "endOffset": 111}, {"referenceID": 12, "context": "In Section 3, we consider convex loss functions and propose an algorithm similar to the Weak Aggregating Algotihm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, \u00a7 2.", "startOffset": 114, "endOffset": 118}, {"referenceID": 20, "context": "In Section 4, we consider the use of prediction with expert advice for the regression problem and adapt the Aggregating Algorithm for Regression [22] (applied to spaces of linear functions and to reproducing kernel Hilbert spaces) to the discounted square loss.", "startOffset": 145, "endOffset": 149}, {"referenceID": 2, "context": "All our algorithms are inspired by the methodology of defensive forecasting [4].", "startOffset": 76, "endOffset": 79}, {"referenceID": 17, "context": "Bounds of this kind were obtained in [19].", "startOffset": 37, "endOffset": 41}, {"referenceID": 17, "context": "For the standard undiscounted case (Accountant announces \u03b1t = 1 at each step t), this theorem was proved by Vovk in [19] with the help of the Aggregating Algorithm (AA) as Learner\u2019s strategy.", "startOffset": 116, "endOffset": 120}, {"referenceID": 8, "context": "It is known ([10, 20]) that this bound is asymptotically optimal for large pools of Experts (for games satisfying some assumptions): if the game does not satisfy (3) for some c \u2265 1 and \u03b7 > 0, then, for sufficiently large K, there is a strategy for Experts and Reality (recall that Accountant always says \u03b1t = 1) such that Learner cannot secure (4).", "startOffset": 13, "endOffset": 21}, {"referenceID": 18, "context": "It is known ([10, 20]) that this bound is asymptotically optimal for large pools of Experts (for games satisfying some assumptions): if the game does not satisfy (3) for some c \u2265 1 and \u03b7 > 0, then, for sufficiently large K, there is a strategy for Experts and Reality (recall that Accountant always says \u03b1t = 1) such that Learner cannot secure (4).", "startOffset": 13, "endOffset": 21}, {"referenceID": 19, "context": "For the special case of c = 1, bound (4) is tight for any fixedK as well [21].", "startOffset": 73, "endOffset": 77}, {"referenceID": 20, "context": "Then the algorithm and its analysis remain valid (if we impose natural integrability conditions on Experts\u2019 predictions \u03b3 t ; see [22] for more detailed discussion)\u2014this will be used in Section 4.", "startOffset": 130, "endOffset": 134}, {"referenceID": 4, "context": "A similar bound (with worse constants) is obtained in [6] for NormalHedge: LT \u2264 LT + \u221a", "startOffset": 54, "endOffset": 57}, {"referenceID": 1, "context": "The NormalHedge algorithm has an important advantage: it can guarantee the last bound without knowledge of the number of experts K (see [3] for a precise definition).", "startOffset": 136, "endOffset": 139}, {"referenceID": 12, "context": "Let us explain the relation of Algorithm 3 to the Weak Aggregating Algorithm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, \u00a7 2.", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "In this case, Algorithm 4 is just the Weak Aggregating Algorithm as described in [14].", "startOffset": 81, "endOffset": 85}, {"referenceID": 2, "context": "That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13].", "startOffset": 62, "endOffset": 65}, {"referenceID": 22, "context": "That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13].", "startOffset": 109, "endOffset": 113}, {"referenceID": 11, "context": "That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13].", "startOffset": 195, "endOffset": 199}, {"referenceID": 3, "context": "However, our analysis in Theorem 2 is completely different from [5], following the lines of [2, Theorem 2.", "startOffset": 64, "endOffset": 67}, {"referenceID": 11, "context": "2] and [13].", "startOffset": 7, "endOffset": 11}, {"referenceID": 1, "context": "However, this bound can be stated as a bound for \u01eb-quantile regret introduced in [3].", "startOffset": 81, "endOffset": 84}, {"referenceID": 3, "context": "of \u01eb, and in this sense the algorithm works for the unknown number of Experts (see [5] for a more detailed discussion).", "startOffset": 83, "endOffset": 86}, {"referenceID": 3, "context": "We do not do this here, but refer to [5]; the proof is literally the same as in [5, Theorem 9] and is based on the supermartingale property of ft.", "startOffset": 37, "endOffset": 40}, {"referenceID": 17, "context": "It is known from [19] that (3) holds for the square loss with c = 1, \u03b7 = 2 (Y2\u2212Y1) : \u2203\u03b3 \u2208 \u0393 \u2200y \u2208 \u03a9 = [Y1, Y2] (\u03b3 \u2212 y) \u2264 \u2212 1 \u03b7 ln (\u222b", "startOffset": 17, "endOffset": 21}, {"referenceID": 20, "context": "In a manner similar to [22], we prove the following upper bound for Learner\u2019s loss.", "startOffset": 23, "endOffset": 27}, {"referenceID": 15, "context": "For the definition of RKHS and its connection to kernels see [17].", "startOffset": 61, "endOffset": 65}, {"referenceID": 5, "context": "In a manner similar to [7], we prove the following upper bound on the discounted square loss of Learner.", "startOffset": 23, "endOffset": 26}, {"referenceID": 20, "context": "The previous three lemmas were implicitly used in [22] to derive a bound on the cumulative undiscounted square loss of the algorithm competing with linear experts.", "startOffset": 50, "endOffset": 54}, {"referenceID": 15, "context": "2 in [17]) the minimum of \u2211T t=1 \u03b2t \u03b2T (f(xt)\u2212yt)+a\u2016f\u2016 over all f \u2208 F is achieved on one of the linear combinations from the bound obtained above.", "startOffset": 5, "endOffset": 9}, {"referenceID": 20, "context": "In [22] Vovk suggests for the square loss the following substitution function satisfying (5): \u03b3T = Y2 + Y1 2 \u2212 gT (Y2)\u2212 gT (Y1) 2(Y2 \u2212 Y1) .", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "1 in [9]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "2 An Alternative Derivation of Regression Algorithms Using Defensive Forecasting In this section we derive the upper bound and the algorithms using a different technique, the defensive forecasting [4].", "startOffset": 197, "endOffset": 200}, {"referenceID": 10, "context": "Applying Hoeffding\u2019s inequality (see [12]) to the random variableX that is equal to 1 with probability p and to 0 with probability (1\u2212 p), we obtain pe + (1\u2212 p)e \u2264 eh2/8 for any h \u2208 R.", "startOffset": 37, "endOffset": 41}, {"referenceID": 13, "context": "The following lemma states the most important for us property of the sequences having the defensive property originally proven in [15].", "startOffset": 130, "endOffset": 134}], "year": 2010, "abstractText": "We study prediction with expert advice in the setting where the losses are accumulated with some discounting and the impact of old losses can gradually vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm for Regression, propose a new variant of exponentially weighted average algorithm, and prove bounds on the cumulative discounted loss.", "creator": "LaTeX with hyperref package"}}}