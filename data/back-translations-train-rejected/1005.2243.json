{"id": "1005.2243", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2010", "title": "Robustness and Generalization", "abstract": "We derive generalization bounds for learning algorithms based on their robustness: the property that if a testing sample is \"similar\" to a training sample, then the testing error is close to the training error. This provides a novel approach, different from the complexity or stability arguments, to study generalization of learning algorithms. We further show that a weak notion of robustness is both sufficient and necessary for generalizability, which implies that robustness is a fundamental property for learning algorithms to work.", "histories": [["v1", "Thu, 13 May 2010 01:59:57 GMT  (90kb)", "http://arxiv.org/abs/1005.2243v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["huan xu", "shie mannor"], "accepted": false, "id": "1005.2243"}, "pdf": {"name": "1005.2243.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Huan Xu", "Shie Mannor"], "emails": ["huan.xu@mail.utexas.edu", "shie@technion.ee.ac.il"], "sections": [{"heading": null, "text": "ar Xiv: 100 5.22 43v1 [cs.LG] 1 3We derive generalization limits for learning algorithms based on their robustness: the property that if a test sample is \"similar\" to a training sample, the test error is close to the training error. This offers a new approach, unlike complexity or stability arguments, to investigate the generalization of learning algorithms. We also show that a weak notion of robustness is both sufficient and necessary for generalization, implying that robustness is a fundamental property for functioning learning algorithms."}, {"heading": "1. Introduction", "text": "The most important questions and answers to the question of how this could have happened and how it could have happened and how it could have happened are indeed very different, especially when the number of training problems is low. (...) There are several approaches to limiting the deviation from the empirical measurement. (...) There are ways to close the gap between the expected risks and the empirical risks. (...) Examples of the complexity of the measures are the VapnikChervonenkis (VapnikChervonenkis, 1974, 1991). (...) Evgeniou et al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al. (...) Examples of complexity are the VapnikChervonenkis (VapnikChervonenkis, 1991, 1991). (...)"}, {"heading": "1.1 Preliminaries", "text": "We consider the following general learning model: a series of training samples are given, and the goal is to select a hypothesis from a hypothesis set (unless otherwise stated, the size of the training set is set as n. Therefore, we drop the dependence on parameters on the number of training samples, while it should be understood that the parameters may vary with the number of training samples. We use Z and H to indicate the amount from which each sample is drawn, and set the hypotheses accordingly. Throughout the paper, we use s to denote the training sample set, which consists of n training samples (s1, \u00b7, sn). A learning algorithm A is therefore a mapping of Zn to H. We use T to represent the learned hypothesis (given training sets). For each hypothesis h-H and a point z-Z, a training set consists of n, with an associated loss l (h, z) we continue to ignore the measurability of the question h and z."}, {"heading": "2. Robustness of Learning Algorithms", "text": "Prior to the provision of a precise definition of what we understand to be the \"robustness\" of an algorithm, we provide a number of motivating examples which share a common characteristic: If a test sample is located close to a training sample, the test error is also nearby, a property which we will formalize later as \"robustness.\" \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "3. Generalization of Robust Algorithms", "text": "In this section, we examine the generalization property of robust algorithms. In particular, in the following subsections, we deduce PAC limits for robust algorithms under three different conditions: (1) The ubiquitous learning setup in which the samples are i.i.d. and the goal of learning is to minimize expected losses. (2) The learning goal is to minimize quantitative loss. (3) The samples are generated according to a (Doeblin) Markovian chain. In fact, the fact that we can provide results in (2) and (3) indicates the fundamental nature of robustness as a property of learning algorithms."}, {"heading": "3.1 IID samples and expected loss", "text": "Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-Sample-"}, {"heading": "3.2 Quantile Loss", "text": "In this section, we will consider some less extensively studied loss functions, namely the quantil value and truncated expectation (\u03b2 \u03b2 for precise definitions), which are of interest because they are less sensitive to the presence of outliers than the average standard loss (Huber, 1981). Definition 6 For a non-negative random variable X, the \u03b2 quantil value isQ\u03b2 (X), inf {c \u00b2 R: Pr (X \u2264 c) \u2265 \u03b2} follows. The \u03b2 truncated mean isT\u03b2 (X), E [X \u00b7 1 (X < Q\u03b2 (X)]]], if Pr [X = Q\u03b2 (X)] = 0; E [X \u00b7 1 (X < Q\u03b2 (X) and p) = 0.0."}, {"heading": "3.3 Markovian samples", "text": "It is known that this corresponds to the class of the Doeblin chains (Meyn and Tweedie, 1993)."}, {"heading": "4. Pseudo Robustness", "text": "In this section, we propose a relaxed definition of robustness that takes into account the case in which equation (2) applies to most training points, as opposed to definition 6, in equation (2) applies to all training places. Note that the size of the training places is such that the number of training places is such that the number of training places is such that the number of training places is so high, the number of training places is so high, the number of training places is so high, the number of training places is so high, the number of training places is so high, the number of training places is so high, the number of training places is so low, the number of training places is so low, the number of training places is so low that the number of training places is such that the number of training places is so low that the number of training places is so low that the number of training places is such that the number of training places is so low."}, {"heading": "5. Examples of Robust Algorithms", "text": "In this section we provide some examples of robust algorithms. The evidence of the examples can be found in Appendix. Our first example is the Majority Voting (MV) classification (cf Section 6.3 of Devroye et al., 1996), which splits the entrance space X and each partition according to a majority decision of it.Example 3 (Majority Voting) Let Y = {\u2212 1, + 1}. Partition X to C1, \u00b7 \u00b7 \u00b7 CK, and use C (x) to name the sentence to which x belongs. A new sample xa is called \"As\" (xa), {1 if it is \"C (xa).si\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" \"i\" i \"i\" \"i\" i \"\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \".\" i \"i\" i \".\" i \"i\" i \".\" i \"i\" i \".\" i \"i\" i \".\" i \"i\". \".\" i \"i\". \"i\". \".\""}, {"heading": "6. Necessity of Robustness", "text": "So far we have dealt with the question of whether and to what extent a generalization of learning processes can occur at all. (...) We are now engaged (...) in a generalization of learning processes (...). (...) We have (...) a generalization of learning processes (...). (...) We have (...) a generalization of learning processes (...). We have (...) a generalization of learning processes (...). We show in this section that the generalization of learning processes is an essential characteristic of successful learning. (...) In particular, a (weaker) idea of learning processes (...) a generalization of learning processes (...) a generalization of learning processes (...). In this section, we show that the generalization of learning processes is an essential characteristic of successful learning. (...) In particular, a (weaker) idea of learning processes, (...) a generalization of learning processes, (...) a generalization of learning processes, (...) a (...) generalization of learning processes, (...) a (...) generalization of learning processes, (...) a (...) generalization of learning process, (...)"}, {"heading": "7. Discussion", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "Appendix A. Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1 Proof of Theorem 13", "text": "We observe the following properties of the quantitative value and the truncated mean values: 1. If X is supported on the basis of quantitative value and quantitative value = quantitative value and quantitative value, this means: 1. Q = quantitative value and quantitative value (quantitative value and quantitative value), 2. Q = quantitative value (quantitative value and quantitative value), 3. Q = quantitative value (quantitative value), 4. Q = quantitative value (quantitative value), 4. Si (quantitative value), 5. Si (quantitative value), 6. Si (quantitative value), 6. Si (quantitative value), 6. Si (quantitative value), 6. Si (quantitative value), 6. Si (quantitative value), 7. Si (quantitative value), 6. Si (quantitative value)."}, {"heading": "A.2 Proof of Example 3", "text": "We can divide Z as follows: {\u2212 1} \u00b7 C1, \u00b7 \u00b7 \u00b7, {\u2212 1} \u00b7 CK, {+ 1} \u00b7 C1, \u00b7 \u00b7, {+ 1} \u00b7 CK. If we look at za, zb belonging to a group, then za | y = zb | y and i so that za | x, zb | x Ci, which by the definition of the majority voting algorithm means As (za | x) = As (zb | x). Therefore, we have (As, za) = f (za | y, As (za | x) = f (zb | y, As (zb | x)) = l (As, zb).Therefore, MV (2K, 0) is -robust."}, {"heading": "A.3 Proof of Example 5", "text": "The existence of fH (\u03b3) stems from the compactness of X and the continuity of k (\u00b7, \u00b7). In order to prove the robustness of SVM, we must specify the predetermined training data (due to the optimality of w). To avoid a tangle of notations, we must leave yi = si | y and xi = si | x. Thus, we (due to the optimality of w \u00b2, d \u00b2) c \u00b2 w 2H + 1nn \u00b2 i = 1 [1 \u2212 yi (< w example (xi) > + d \u00b2)] + c \u00b2 0 \u00b2 2H + 1nn \u00b2 i = 1 [1 \u2212 yi (< 0 \u2212 xi) > + 0) + 1, which implies that the definition w \u00b2 H \u00b2 1 / c \u00b2, c1 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7, cN (xi) > + c \u00b2 0 \u00b2 2H + 1nn \u00b2 i = 1 [1 \u2212 yi (< 0 \u2212 xi) > + 1) + 1, + 1, which implies that the definition w \u00b2 H \u00b2 p \u00b2 1 / c \u00b2 p \u00b2 p, p \u00b2 p, p \u00b2 p, p \u00b2 p, p \u00b2 p, p \u00b2 p, p \u00b2 p, p \u00b2 p, p, p \u00b2 p, p \u00b2 p, p \u00b2 p, p \u00b2 p, p, p \u00b2 p, p \u00b2 p, p \u00b2 p, p, p \u00b2 p, p \u00b2 p, p, p \u00b2 p, p \u00b2 p, p, p \u00b2 p, p, p \u00b2 p, p, p \u00b2 p, p, p, p \u00b2 p, p, p, p \u00b2 p, p, p, p, p \u00b2 p, p, p, p, p \u00b2 p, p, p, p, p, p \u00b2 p, p, p, p, p \u00b2 p, p, p, p, p \u00b2 p, p, p, p, p \u00b2 p, p, p, p, p, p \u00b2 p, p, p, p, p \u00b2."}, {"heading": "A.4 Proof of Example 6", "text": "Suffice it to point out the following problem, which states that the loss of the lasso solution Liptschitz (s) is continuous. Lemma 21 If w \u00b2 (s) is the solution of the training set given by Lasso, then | l (w \u00b2 (s), za) \u2212 l (w \u00b2 (s), zb (1ncn \u00b2 (s), then we let yi = si \u00b2 (s), xi = si | x for i = 1, \u00b7 \u00b7, n. Similarly, we let ya (b) = za (b) | y and xa (b) = za (b) | x. Since w \u00b2 (s) is the solution of Lasso, we let 1 nn \u00b2 s \u00b2 i = 1 (yi \u2212 x \u00b2 i) w \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s (s) 2 + c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s (s) is the solution of Lasso, we let 1 nn \u00b2 s \u00b2 s \u00b2 i = 1 nn \u00b2, x i) w \u00b2 s \u00b2 s \u00b2 s \u00b2 s (s) w) s \u00b2 s \u00b2 s \u00b2 s (s) s (s) s (s) s (s) s) s \u00b2 s (s) s (s) s (s) s) s (s) s (s) s (s) s (s) s) s (s) s (s) s (s) s (s) are the solution of Lasso) s (s) s (s) s (s) s) s (s) s (s) s (s) s) s (s) s (s) s (s) s) s (s) s) s (s) s (s) s (s) s (s) s) s (s) s (s) s (s) s) s (s) s (s) s (s) s) s (s) s (s) s) s (s) s (s) s) s (s) s) s) s) s (s) s (s) s (s) s) s) s) s (s (s) s) s (s) s (s) s) s) s"}, {"heading": "A.5 Proof of Example 7", "text": "To see why the example is correct, it is sufficient to point out the following leak, which states that the mentioned neural network Lipschitz is continuous. To simplify it, we write the prediction x \u2212 x \u2212 x \u2212 x \u2212 x for all v, i, then the following applies: | l (As, z) \u2212 l (As, z, z) | \u2264 (1 + \u03b1 d\u03b2d), z \u2212 z and x \u2212 v for all v, i, i, then the following applies: x (As, z) \u2212 l (As, z)."}, {"heading": "A.6 Proof of Example 8", "text": "We show that the loss of PCA Lipschitz is continuous, and then apply Theorem 14. Let (w-1 (s), \u00b7 \u00b7, w-d (s)) be the solution of PCA that is trained to s. Thus, we have | l (w-1 (s), \u00b7 \u00b7, w-d (s), za) \u2212 l (w-1 (s), \u00b7 \u00b7, w-d (s), zb) | = 1 (w-k (s) za) 2 \u2212 d-k = 1 (w-k (s) za) 2 \u2212 d-k = 1 (w-k) zb) 2 (w-k) zb) 2 (w-k-k (s) za + w-k (s) za + w-k (s) zb \u2212 zb-2, where the last inequality applies because w-k (s) za + w-k (s) za + w-k (s) za + w-k (s) zb (s) zb-2, where the last inequality applies."}, {"heading": "A.7 Proof of Example 9", "text": "Thus, Z can be divided into 2N (\u03b3 / 2, X, \u03c1) subsets (Ci) so that ifz1, z2, Ci; = \u21d2 y1 = y2; & \u03c1 (x1, x2) \u2264 \u03b3.This means that: z1, z1, z2, Ci; = \u21d2 y1 = y2; As (x1) = As (x2); = \u21d2 l (As, z1) = l (As, z2).By definition, A (2N (\u03b3 / 2, X), 0, n) is pseudorust."}], "references": [{"title": "Scale-sensitive dimension, uniform convergence, and learnability", "author": ["N. Alon", "S. Ben-David", "N. Cesa-Bianchi", "D. Haussler"], "venue": "Journal of the ACM,", "citeRegEx": "Alon et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Alon et al\\.", "year": 1997}, {"title": "The sample complexity of pattern classification with neural networks: The size of the weight is more important than the size of the network", "author": ["P.L. Bartlett"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Bartlett.,? \\Q1998\\E", "shortCiteRegEx": "Bartlett.", "year": 1998}, {"title": "Rademacher and Gaussian complexities: Risk bounds and structural results", "author": ["P.L. Bartlett", "S. Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bartlett and Mendelson.,? \\Q2002\\E", "shortCiteRegEx": "Bartlett and Mendelson.", "year": 2002}, {"title": "Local Rademacher complexities", "author": ["P.L. Bartlett", "O. Bousquet", "S. Mendelson"], "venue": "The Annals of Statistics,", "citeRegEx": "Bartlett et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2005}, {"title": "Robust convex optimization", "author": ["A. Ben-tal", "A. Nemirovski"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Ben.tal and Nemirovski.,? \\Q1998\\E", "shortCiteRegEx": "Ben.tal and Nemirovski.", "year": 1998}, {"title": "The price of robustness", "author": ["D. Bertsimas", "M. Sim"], "venue": "Operations Research,", "citeRegEx": "Bertsimas and Sim.,? \\Q1999\\E", "shortCiteRegEx": "Bertsimas and Sim.", "year": 1999}, {"title": "Support vector networks", "author": ["Cortes", "V.N. Vapnik"], "venue": "Machine Learning,", "citeRegEx": "Cortes and Vapnik.,? \\Q2002\\E", "shortCiteRegEx": "Cortes and Vapnik.", "year": 2002}, {"title": "Markov Chains and Stochastic Stability", "author": ["S.P. Meyn", "R.L. Tweedie"], "venue": null, "citeRegEx": "1989", "shortCiteRegEx": "1989", "year": 1993}, {"title": "Learning with Kernels", "author": ["B. Sch\u00f6lkopf", "A.J. Smola"], "venue": null, "citeRegEx": "Sch\u00f6lkopf and Smola.,? \\Q2002\\E", "shortCiteRegEx": "Sch\u00f6lkopf and Smola.", "year": 2002}, {"title": "Learnability and stability in the general learning setting", "author": ["S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan"], "venue": "In Proceedings of 22nd Annual Conference of Learning Theory,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2009}, {"title": "Second order cone programming approaches for handling missing and uncertain data", "author": ["P.K. Shivaswamy", "C. Bhattacharyya", "A.J. Smola"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Shivaswamy et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Shivaswamy et al\\.", "year": 2006}, {"title": "Regression shrinkage and selection via the Lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society, Series B,", "citeRegEx": "Tibshirani.,? \\Q1996\\E", "shortCiteRegEx": "Tibshirani.", "year": 1996}, {"title": "Weak Convergence and Empirical Processes", "author": ["A.W. van der Vaart", "J.A. Wellner"], "venue": null, "citeRegEx": "Vaart and Wellner.,? \\Q2000\\E", "shortCiteRegEx": "Vaart and Wellner.", "year": 2000}, {"title": "The necessary and sufficient conditions for consistency in the empirical risk minimization method", "author": ["V.N. Vapnik", "A. Chervonenkis"], "venue": "Pattern Recognition and Image Analysis,", "citeRegEx": "Vapnik and Chervonenkis.,? \\Q1991\\E", "shortCiteRegEx": "Vapnik and Chervonenkis.", "year": 1991}, {"title": "Robust regression and Lasso", "author": ["H. Xu", "C. Caramanis", "S. Mannor"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Xu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2009}, {"title": "Robustness and regularization of support vector machines", "author": ["H. Xu", "C. Caramanis", "S. Mannor"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Xu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 1, "context": ", 2000), the fat-shattering dimension (e.g., Alon et al., 1997; Bartlett, 1998), and the Rademacher complexity (Bartlett and Mendelson, 2002; Bartlett et al.", "startOffset": 38, "endOffset": 79}, {"referenceID": 2, "context": ", 1997; Bartlett, 1998), and the Rademacher complexity (Bartlett and Mendelson, 2002; Bartlett et al., 2005).", "startOffset": 55, "endOffset": 108}, {"referenceID": 3, "context": ", 1997; Bartlett, 1998), and the Rademacher complexity (Bartlett and Mendelson, 2002; Bartlett et al., 2005).", "startOffset": 55, "endOffset": 108}, {"referenceID": 0, "context": ", Alon et al., 1997; Bartlett, 1998), and the Rademacher complexity (Bartlett and Mendelson, 2002; Bartlett et al., 2005). Another well-known approach is based on stability. An algorithm is stable if its output remains \u201csimilar\u201d for different sets of training samples that are identical up to removal or change of a single sample. The first results that relate stability to generalizability track back to Devroye and Wagner (1979a) and Devroye and Wagner (1979b).", "startOffset": 2, "endOffset": 432}, {"referenceID": 0, "context": ", Alon et al., 1997; Bartlett, 1998), and the Rademacher complexity (Bartlett and Mendelson, 2002; Bartlett et al., 2005). Another well-known approach is based on stability. An algorithm is stable if its output remains \u201csimilar\u201d for different sets of training samples that are identical up to removal or change of a single sample. The first results that relate stability to generalizability track back to Devroye and Wagner (1979a) and Devroye and Wagner (1979b). Later, McDiarmid\u2019s (McDiarmid, 1989), concentration inequalities facilitated new bounds on generalization error (e.", "startOffset": 2, "endOffset": 463}, {"referenceID": 4, "context": "This notion of robustness is rooted in robust optimization (Ben-tal and Nemirovski, 1998; Ben-Tal and Nemirovski, 1999; Bertsimas and Sim, 2004) where a decision maker aims to find a solution x that minimizes a (parameterized) cost function f(x, \u03be) with the knowledge that the unknown true parameter \u03be may deviate from the observed parameter \u03be\u0302.", "startOffset": 59, "endOffset": 144}, {"referenceID": 10, "context": "Robust optimization was introduced in machine learning tasks to handle exogenous noise (e.g., Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Globerson and Roweis, 2006), i.", "startOffset": 87, "endOffset": 174}, {"referenceID": 13, "context": "While it is known having a finite VC-dimension (Vapnik and Chervonenkis, 1991) or equivalently being CVEEEloo stable (Mukherjee et al.", "startOffset": 47, "endOffset": 78}, {"referenceID": 9, "context": "Recently, Shalev-Shwartz et al. (2009) proposed a weaker notion of stability that is necessary and sufficient for a learning algorithm to be consistent and generalizing, provided that the problem itself is learnable.", "startOffset": 10, "endOffset": 39}, {"referenceID": 9, "context": "Recently, Shalev-Shwartz et al. (2009) proposed a weaker notion of stability that is necessary and sufficient for a learning algorithm to be consistent and generalizing, provided that the problem itself is learnable. However, learnability requires that the convergence rate is uniform with respect to all distributions, and is hence a fairly strong assumption. In particular, the standard supervised learning setup where the hypothesis set is the set of measurable functions is not learnable since no algorithm can achieve a uniform convergence rate (cf Devroye et al., 1996). Indeed, as the authors of Shalev-Shwartz et al. (2009) stated, for supervised learning problem learnability is equivalent to the generalizability of ERM, and hence reduce to the aforementioned results on ERM algorithms.", "startOffset": 10, "endOffset": 632}, {"referenceID": 12, "context": "We recall the following standard notion of covering number from van der Vaart and Wellner (2000). Definition 1 (cf.", "startOffset": 72, "endOffset": 97}, {"referenceID": 12, "context": "We recall the following standard notion of covering number from van der Vaart and Wellner (2000). Definition 1 (cf. van der Vaart and Wellner (2000)) For a metric space S, \u03c1 and T \u2282 S we say that T\u0302 \u2282 S is an \u01eb-cover of T , if \u2200t \u2208 T , \u2203t\u0302 \u2208 T\u0302 such that \u03c1(t, t\u0302) \u2264 \u01eb.", "startOffset": 72, "endOffset": 149}, {"referenceID": 8, "context": "Consider the standard SVM formulation (Cortes and Vapnik, 1995; Sch\u00f6lkopf and Smola, 2002) Minimize:w,d c\u2016w\u2016 2 H + 1 n n \u2211", "startOffset": 38, "endOffset": 90}, {"referenceID": 11, "context": "Lasso (Tibshirani, 1996), which is the following regression formulation: min w : 1 n n \u2211", "startOffset": 6, "endOffset": 24}, {"referenceID": 1, "context": "This indeed agrees with Bartlett (1998), where the author showed (using a different approach based on fat-shattering dimension) that for neural networks, the weight plays a more important role than the number of hidden units.", "startOffset": 24, "endOffset": 40}], "year": 2010, "abstractText": "We derive generalization bounds for learning algorithms based on their robustness: the property that if a testing sample is \u201csimilar\u201d to a training sample, then the testing error is close to the training error. This provides a novel approach, different from the complexity or stability arguments, to study generalization of learning algorithms. We further show that a weak notion of robustness is both sufficient and necessary for generalizability, which implies that robustness is a fundamental property for learning algorithms to work.", "creator": "LaTeX with hyperref package"}}}