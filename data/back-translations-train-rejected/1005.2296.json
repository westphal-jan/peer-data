{"id": "1005.2296", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2010", "title": "Online Learning of Noisy Data with Kernels", "abstract": "We study online learning when individual instances are corrupted by random noise. We assume the noise distribution is unknown, and may change over time with no restriction other than having zero mean and bounded variance. Our technique relies on a family of unbiased estimators for non-linear functions, which may be of independent interest. We show that a variant of online gradient descent can learn functions in any dot-product (e.g., polynomial) or Gaussian kernel space with any analytic convex loss function. Our variant uses randomized estimates that need to query a random number of noisy copies of each instance, where with high probability this number is upper bounded by a constant. Allowing such multiple queries cannot be avoided: Indeed, we show that online learning is in general impossible when only one noisy copy of each instance can be accessed.", "histories": [["v1", "Thu, 13 May 2010 10:56:01 GMT  (46kb,D)", "https://arxiv.org/abs/1005.2296v1", "This is a full version of the paper appearing in the 23rd International Conference on Learning Theory (COLT 2010)."], ["v2", "Thu, 20 May 2010 12:43:57 GMT  (46kb,D)", "http://arxiv.org/abs/1005.2296v2", "This is a full version of the paper appearing in the 23rd International Conference on Learning Theory (COLT 2010)"]], "COMMENTS": "This is a full version of the paper appearing in the 23rd International Conference on Learning Theory (COLT 2010).", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["nicol\\`o cesa-bianchi", "shai shalev-shwartz", "ohad shamir"], "accepted": false, "id": "1005.2296"}, "pdf": {"name": "1005.2296.pdf", "metadata": {"source": "CRF", "title": "Online Learning of Noisy Data with Kernels", "authors": ["Nicol\u00f2 Cesa-Bianchi", "Shai Shalev Shwartz"], "emails": ["cesa-bianchi@dsi.unimi.it", "shais@cs.huji.ac.il", "ohadsh@cs.huji.ac.il"], "sections": [{"heading": "1 Introduction", "text": "In many cases, we are dealing with errors that can be attributed to several reasons. In this paper, we examine the extent to which a learning algorithm has good predictive power when confronted with an unclear prediction."}, {"heading": "1.1 Related Work", "text": "In the literature on machine learning, the problem of learning from loud examples and especially from loud training instances has traditionally received a lot of attention - see, for example, the most recent survey [11]. On the other hand, there are comparatively few theoretically based studies on this topic. Two of them focus on models that differ significantly from the one studied here: random attribute noise in PAC-Boolean learning [3, 8] and malicious noise [9, 5]. In the first case, learning is limited to classes of Boolean functions, and the noise must be independent of any Boolean coordinate. In the second case, an opponent may arbitrarily disrupt a small fraction of the training examples, making learning impossible in a strong informative sense, unless this disturbed fraction is very small (in the order of desired accuracy for the predictor)."}, {"heading": "2 Setting", "text": "In fact, it is such that most of us are able to move to another world, in which they are able, in which they are able, in which they are able, in which they are able, in which they live to stay, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live that they live, that they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they"}, {"heading": "3 Techniques", "text": "Our results are based on two key ideas: the use of online gradient descend algorithms and the construction of unbiased gradient estimators in the core setting. The latter is based on a general method of creating unbiased estimates for nonlinear functions that may be of independent interest."}, {"heading": "3.1 Online Gradient Descent", "text": "There are a number of reasons why we should not be able to find a solution that we can deal with. (...) There are a number of reasons why we are not able to find a solution. (...) There are many reasons why we are not able to find a solution. (...) There are many reasons why we are not able to find a solution. (...) There are many reasons why we are not able to find a solution. (...) There are many reasons why we are not able to find a solution. \"(...) There are many reasons why we are not able to find a solution.\""}, {"heading": "3.2 Unbiased Estimators for Non-Linear Functions", "text": "Suppose we have access to independent copies of a real random variable X, with expectation E [X], and some real function Q, and we want to construct an unbiased estimate of f (E [X]). If f is a linear function, then this is simple: just example x of X and return f (x). By linearity, E [f (X)] = f (E [X])) and we are done. The problem becomes less trivial if f is a generic, nonlinear function, since normally E [f (X)] 6 = f (X]) is decisive. In fact, if X takes an infinite number of values and f is not a polynomial function, one can prove that no unbiased estimator can exist (see [13], Proposition 8 and its evidence). Nevertheless, we show how to construct an unbiased estimator of f (E] in many cases, including cases covered by impossibility."}, {"heading": "3.3 Unbiasing Noise in the RKHS", "text": "The third component of our approach involves the unbiased estimation of two-dimensional elements if we only have unbiased copies of two-dimensional elements. Again, we have a non-trivial problem, since the mapping of features is usually highly non-linear, so the event N = 0 should have zero probability, since it amounts to \"skipping\" the sample as a whole. However, the setting P (N = 0) = 0 only seems to improve the boundary set in this paper in a smaller order, while the analysis in the paper is more complicated. To address this problem, we construct an explicit mapping of these features, which must be tailored to the core we want to use. To give a very simple example, let us assume that we use the homogeneous two-dimensional mapping."}, {"heading": "4 Main Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Algorithm", "text": "We present our algorithmic approach in a modular form. We start by introducing the most important algorithms that contain several subdivisions, then we prove our two main results, which limit the regrets of the algorithm, the number of queries to the oracle, and runtime for two types of kernels: most of the results can also be extended to other kernel types (including explicit pseudo-codes). In this section, we describe only one subroutine based on the techniques discussed in Sec. The other subdivisions require a more detailed and technical discussion, and therefore their implementation is described as part of the proofs."}, {"heading": "4.2 Loss Function Examples", "text": "Theorems 1 and 2 both deal with generic loss functions \"whose derivative may be written rather than > > reader.\" < < < < < < < < < < < < < < < < < < < < < < < < p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, u, u, u, u, u, u, u, u, u, u, u, u, u, u, u, u, u, u, u, u, u, u, u, p, p, p, p, p, p, p, p, p, p, p, p, u, u, u, u, u, u."}, {"heading": "4.3 One Noisy Copy is Not Enough", "text": "Previous results have raised the question of whether it is really necessary to question the same instance more than once. < < / p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p"}, {"heading": "5 Proofs", "text": "Due to the lack of space, some of the documents are listed in the annex."}, {"heading": "5.1 Preliminary Result", "text": "In order to prove Thm. 1 and Thm. 2, we need a theorem that essentially states that if all subroutines in Algorithm 1 behave as they should, an O (\u221a T) repentance limit can be reached. This is explained in the following theorem, which is an adaptation of a standard result of convex online optimization (see e.g. [17]). The proof for this is in Appendix D. Theorem 4. Suppose the following conditions apply with respect to Algorithm 1: 1. For all t, HQ (xt) and G (t) are independent of each other (as random variables caused by the therandominity of Algorithm 1) and independent of any HQ (xi) and G (i for i < t)."}, {"heading": "2. For all t, E[\u03a8\u0303(xt)] = \u03a8(xt), and there exists a constant B\u03a8\u0303 > 0 such that E[\u2016\u03a8\u0303(xt)\u20162] \u2264 B\u03a8\u0303.", "text": "3. For all t, E [g] = yt '\"(yt < wt, \u0441 (xt) >), and there is a constant Bg > 0, so that E [g] \u2264 Bg.\" 4. For each instance pair x, x, \"Prod (HB (x), HB (x)) = < HB (x), HB (x) >. Then, if algorithm 1 is executed with B =\" Bw Bg, \"the following inequality holds E [T = 1\" (yt < wt, HB (xt) >) \u2212 min w: \"w\" 2 \u2264 Bw T = 1 \"(yt < w, HB (xt) >)."}, {"heading": "5.2 Proof of Thm. 1", "text": "In this subsection, we present the proof for Thm. First, we show how to implement the subroutines of algorithm 1 and check the relevant results for their behavior, then we show that for k (\u00b7 \u00b7 \u00b7) = Q (< x, x \">) n, which must be a valid kernel, it is necessary that Q (< x, x\" >) n, as Taylor expansion attribute n = 0 \u03b2n (< x, x \">) n, where \u03b2n properties 0 (see theorem 4.19 in [14]) n, can be written, making these types of kernel amable among our techniques. We start with the construction of an explicit attribute n = 0 \u03b2n (< x\" >) n corresponding to the RKHS generated by our kernel. For each x, x \"n, we have thatk (x, x\")."}, {"heading": "5.3 Proof Sketch of Thm. 3", "text": "To prove the theorem, we use a more general result that leads to not disappearing regret, and then show that the result applies under the assumptions of Thm. 3. Proof of the result is given in Appendix F. Theorem 5. Let W be a compact convex subset of Rd and choose any learning algorithm that selects hypotheses of W and allows access to a single loud copy of the instance in each turn t. If there is a distribution over a compact subset of Rd, such a thatargmin w \"WE [\" (< w, x >, 1) and argmin w \"W\" (< w, E [x] >, 1) (3) must exist a strategy for the opponent so that the sequence w1, w2, \u00b7 \u00b7 \u00b7 \u00b7 W of the predictive results is."}, {"heading": "6 Future Work", "text": "There are several interesting lines of research that are worth pursuing in the noisy learning framework presented here. For example, eliminating the impartiality that could lead to the development of estimators that are applicable to more types of loss functions for which there may not even be impartial estimators. It would also be interesting to show how additional information on sound distribution can be used to design improved estimates, possibly in conjunction with specific losses or cores. Another open question is whether our lower limit (Thm. 3) can be improved when non-linear cores are used."}, {"heading": "A Alternative Notions of Regret", "text": "In the online setting, one can consider other terms of regret than \"1.\" One choice is \"T\" = \"1\" (< wt, \u0442 (x) >, yt) \u2212 min w \"W\" = \"1\" (< w \"(x) >, yt), but this is too easy since it is reduced to traditional online learning in terms of examples that happen to be loud. (5) This type of regret may be relevant to the actual prediction of\" t \"= 1\" (< wt \"(x) >, yt) \u2212 min w\" W \"(< wt\" (xt) >, yt)."}, {"heading": "B Proof of Thm. 2", "text": "The analysis in this subsection is similar to that in subsection 5.2, which focuses on Gaussian nuclei."}, {"heading": "C Proof of Examples 3 and 4", "text": "Examples 3 and 4 use the Erf (a) error function to construct smooth approximations of hinge loss and absolute loss (see Fig. 1). The Erf (a) error function is useful for our purposes as it is analytical throughout R and smoothly interpolates between \u2212 1 for a 0 and 1 for a 0. To approximate absolute loss (see Fig. 1), we use the Erf (sa) antiderivative, which is piecewise linear, such as the hinge loss' (a) = max {0, 1 \u2212 a} and the absolute loss' (a) (a) = | a. To approximate absolute loss, we use the Erf (sa) antiderivative, which represents a smooth upper limit to absolute loss, narrowing as s increases. It can be verified that the antiderivative (fixed with the constant free parameter) is such that the function has the desired behavior of Erf (a)."}, {"heading": "D Proof of Thm. 4", "text": "Our algorithm corresponds to Zinkevich's algorithm [17] in a finite horizon setting in which we assume the order of examples in which g-value (x1),..., g-value (xT), the cost function is linear, and the learning rate is round t = 1 < wt, g-value (xt) > \u2212 T-value (xt) > < w, g-value (xt) > T-value (t) > Bw-value (xt) = 1 < wt, g-value (xt) (xt) > t-value (lt; ww, g-value (t) < ww, g-value (xt) > Bw-value (t) [t-value) [t-value) [t-value) < ww-value (lt; wp-value) [p-value (ltd) [p-value] [t-p-value; p-p-value; p-p-value; p-p-value; p-wxt-value) p < p-w-value; p-w-w-w-value; p-w-w-t; p-t-value [t-p-value] p-p-value [t-p-value] p-p-p-value; p-p-p-p-p-wt-value [p-value] p-p-p-value; p-wt-p-p-p-p-value) p-wt; p-wt-p-p-wt-value [p-wt-value [p-value] p-p-p-wt; p-p-p-p-value [p-wt) p-p-p-wt-wt-value [wt; p-wt-p-wt-value [wt-value] p-p-p-p-wt; p-p-value [wt) p-p-wt-wt-value [wt-wt-value [wt)"}, {"heading": "E Proof of Theorem 3", "text": "To prove the result, we simply have to show that the first group above (3w, 1) + \"(\u2212 w, 1) +\" (\u2212 w, 1) + \"(\u2212 w, 1) +\" (\u2212 w, 1) + \"(\u2212 w, 1) +\" (\u2212 w, 1) + \"(\u2212 w, 1). To prove the result, we simply have to show that the first group above is a subset of\" [w, 1) + \"(\u2212 w, 1) +\" (\u2212 w, 1) that does not depend on \"Bw\" (w, 1). We do a case-by-case analysis depending on how \"(\u00b7 1) looks like. (\u00b7 1) Monotonically increases in R. Impossible by assuming (2).2\" (\u00b7, 1) monotonically decreases in R."}, {"heading": "F Proof of Thm. 5", "text": "(1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1. (1). (1). (1). (1). (1). (1). (1.). (1.). (1.). (1.). (1.). (1.).). (1.). (1.).). (1.). (1.). (1.).). (1.).). (1.).). (1.).). (1.).). (1.).). (1.).). (1.).).). (1.).). (1.). (1.).). (1.).). (1.).). (1.).).). (1.).). (1.).). (1.). (1.).).). (1.). (1.). (1.).). (1.).). (1.).). (1.).). (1.).). (1.).). (1.).). (1.).). (1.).).).)."}], "references": [], "referenceMentions": [], "year": 2010, "abstractText": "We study online learning when individual instances are corrupted by adversarially chosen<lb>random noise. We assume the noise distribution is unknown, and may change over time<lb>with no restriction other than having zero mean and bounded variance. Our technique relies<lb>on a family of unbiased estimators for non-linear functions, which may be of independent<lb>interest. We show that a variant of online gradient descent can learn functions in any dot-<lb>product (e.g., polynomial) or Gaussian kernel space with any analytic convex loss function.<lb>Our variant uses randomized estimates that need to query a random number of noisy copies<lb>of each instance, where with high probability this number is upper bounded by a constant.<lb>Allowing such multiple queries cannot be avoided: Indeed, we show that online learning is<lb>in general impossible when only one noisy copy of each instance can be accessed.", "creator": "LaTeX with hyperref package"}}}