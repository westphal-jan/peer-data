{"id": "1005.3566", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-May-2010", "title": "Evolution with Drifting Targets", "abstract": "We consider the question of the stability of evolutionary algorithms to gradual changes, or drift, in the target concept. We define an algorithm to be resistant to drift if, for some inverse polynomial drift rate in the target function, it converges to accuracy 1 -- \\epsilon , with polynomial resources, and then stays within that accuracy indefinitely, except with probability \\epsilon , at any one time. We show that every evolution algorithm, in the sense of Valiant (2007; 2009), can be converted using the Correlational Query technique of Feldman (2008), into such a drift resistant algorithm. For certain evolutionary algorithms, such as for Boolean conjunctions, we give bounds on the rates of drift that they can resist. We develop some new evolution algorithms that are resistant to significant drift. In particular, we give an algorithm for evolving linear separators over the spherically symmetric distribution that is resistant to a drift rate of O(\\epsilon /n), and another algorithm over the more general product normal distributions that resists a smaller drift rate.", "histories": [["v1", "Wed, 19 May 2010 22:58:53 GMT  (160kb,S)", "http://arxiv.org/abs/1005.3566v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["varun kanade", "leslie g valiant", "jennifer wortman vaughan"], "accepted": false, "id": "1005.3566"}, "pdf": {"name": "1005.3566.pdf", "metadata": {"source": "CRF", "title": "Evolution with Drifting Targets", "authors": ["Varun Kanade", "Leslie G. Valiant", "Jennifer Wortman Vaughan"], "emails": ["vkanade@fas.harvard.edu", "valiant@seas.harvard.edu", "jenn@seas.harvard.edu"], "sections": [{"heading": null, "text": "ar Xiv: 100 5.35 66v1 [cs.LG] 1 9M ay2 01The above translation result can also be interpreted as one about the robustness of the concept of evolutionary capacity even under definition changes. As a second result in this direction, we show that any evolutionary algorithm can be transformed into a quasi-monotonous one that can develop from any starting point without performance ever falling significantly below that of the starting point. This makes it possible to remove the somewhat unnatural feature of arbitrary performance degradation from several known robustness translations."}, {"heading": "1 Overview", "text": "The evolutionary models introduced by Valiant [19] were designed to provide a quantitative theory for the study of mechanisms that can develop in populations of realistic size, in an appropriate number of generations through the Darwinian process of variation and selection. It is then essentially modeled as a limited form of learning examples in which the learner observes only the empirical performance of a set of functions that are feasible variants of the current function. The performance of a function is defined as its correlation with the ideal function that, for any circumstance, specifies the behavior that is most advantageous in the current environment for the developing entities. The evolutionary process consists of repeated applications of random variation followed by a selection step."}, {"heading": "2 The Computational Model of Evolution", "text": "In this section we will give an overview of the original computer model of evolution (Valiant [19], where more details can be found), many of which will be familiar to readers familiar with the PAC model of learning [18]."}, {"heading": "2.1 Basic Definitions", "text": "A representation class R over X consists of a series of (possibly randomized) functions from X to {\u2212 1, 1} that are described in a particular language. In this work, however, we consider C as the class of functions from which the ideal target f is selected, and R as a class of representations from which the evolutionary algorithm considers an r to approximately f. We consider only classes of representations that can be evaluated efficiently, i.e. classes R such that for each r, f and each x x, x, r (x) a class of representations of the size of x. We associate a complexity parameter n with X, C, andR. This parameter specifies the number of dimensions of each element in the domain. For example, we could define Xn as {\u2212 1, 1} n to be the class of a variation over the boy constellation."}, {"heading": "2.2 Model of Variation and Selection", "text": "An evolutionary algorithm E determines in each round i which set of mutations of the algorithm is required for the current hypothesis ri \u2212 1, as a candidate for ri, and how the selection should be made. E = (R, Neigh, \u00b5, t, s) is specified by the following set of components: \u2022 The representation class R = {Rn} n = 1 specifies the space of representations via X from which the algorithm can select functions r to approximate the target f. \u2022 The (possibly randomized) function Neigh (r, i) specifies for each r-series of representations r \u00b2 n the number of representations r \u00b2 n into which the representations r can be randomly mutated."}, {"heading": "2.3 Putting It All Together", "text": "A concept class C should be evolvable by the algorithm E via the distribution D, if for each target f-C, starting with each r0-R, the sequence of mutations defined by E converges in polynomial time to a representation r, whose performance in relation to f is close to 1, formalized as follows. Definition 1 (Evolvability [19]) For a concept class C, the distribution D, and the evolutionary algorithm E = (R, Neigh, \u00b5, t, s), let us say that C via D is evolvable by E, if there is a polynomial g (n, 1 / E), so that for each n-N, f-Cn, r0-Rn, and each n-evolution at least 1-0 a sequence r0, r1, r2, \u00b7 \u00b7 is generated by making ri = M (f, D, E, ri \u2212 1) evolvable for all i."}, {"heading": "2.4 Alternative Models", "text": "Various alternative formulations of the basic model of evolution described here have been studied, many of which have proved to be equivalent to the basic model in the sense that any concept developed in the basic model can be developed in the alternative model, and vice versa. At this point, we will briefly discuss some of the variations considered. Perff (r, D) is defined in the sense of 0 / 1 loss. Alternative performance measures based on square loss or other loss functions have been studied in the context of evolution [10, 11, 17]. However, these alternative measures are identical to the original if f and r (possibly randomized) are binary functions, as we have assumed. (If the model is extended to allow for a real-rated function output, the ability to evolve with a power measure based on a non-linear loss function is strictly more powerful than the evolutionary capacity with the standard correlation-based power measure [10]."}, {"heading": "3 Notions of Monotonicity", "text": "The concept of monotonicity, redefined here in Definition 2, requires that, with a high probability, the performance of the present representation does not fall within the performance of the initial representation r0. (Definition 2 (Monotonic Evolution) An evolutionary algorithm E monotonically develops a class C over a distribution D if E develops C over D and with probability at least 1 \u2212 for all i \u2264 g (n, 1 / 2), Perff (ri, D), Perff (r0, D), where g (n, 1 / 3) and r0, \u00b7 are as in Definition 1.If explicit initialization of the starting representation r0 is prohibited, this is equivalent to the requirement that Perff (ri, D), Perff (ri \u2212 1, D) for all other classes."}, {"heading": "4 Resistance to Drift", "text": "There are many ways to formalize the idea of drift resistance. Our formalization is closely related to ideas from work on tracking technology. [16] In both models, an input point is drawn from a fixed but unknown distribution mode. [17] It is assumed that the error from fi \u2212 1 to D is less than a fixed value. [16] In both models, a simple algorithm that is a concept for (approximately) minimizing an average error from O \u2212 1 to D is defined as a fixed value. [17] It is shown that a simple algorithm that chooses an (approximate) distribution method is an (approximate) error of O (approximate) d, where d is the VC dimension of C.3 Moregeneral models of drift also proposed."}, {"heading": "5 Robustness Results", "text": "Feldman [9] proved that the original model of evolutionary ability equals a limitation of the statistical query model of learning [15], known as learning by correlational statistical queries (CSQ). [5] We expand Feldman's analysis to show that CSQ learning equals both the ability to evolve with drifting goals and the quasi-monotonous ability to evolve, and therefore the notion of evolutionary ability is robust against these changes in definition. We will begin with a brief review of the CSQ model."}, {"heading": "5.1 Learning from Correlational Statistical Queries", "text": "Like the PAC model, the goal of an SQ learner is to build a hypothesis that approximates the behavior of a target function f with respect to a fixed but unknown distribution D. Unlike the PAC model, the learner does not gain direct access to labeled examples < x, f (x) >, but instead gains access to a statistical query oracle. The learner submits queries of the form (CSgorithm) to the oracle, where the student either gains direct access to labeled examples < x, f (x) > query is a query function and will instead gain access to a static query oracle. The oracle responds to each query with a value v, such that the query is of any value v."}, {"heading": "5.2 Overview of the Reduction", "text": "The construction we present uses Feldman's simulation [9] repeatedly. Fix a concept class C and a distribution D so that C can be learned in the CSQ model via D. As mentioned above, this implies that there is a CSQ > algorithm A for learning C via D. Let Feldman be the class of hypotheses from which the output of A is selected. In the analysis that follows, we limit our attention to the case in which A is deterministic. However, extending our analysis to randomized algorithms is straightforward with Feldman's ideas (see Lemma 4.7 in his paper [9]). First, we present a high-level sketch of our simulation in the case in which we will use randomized Boolean functions."}, {"heading": "5.3 Construction of the Evolutionary Algorithm", "text": "We describe the construction of our evolutionary algorithm E: Let's answer (n, 1 / 2) to the question (n, 1 / 2) to the question (n, 1 / 2) to the question (n, 1 / 2) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n, 1) to the question (n) to the question (n) to the question (n) to the question (n)."}, {"heading": "5.5 Restarting the Simulation", "text": "We will now discuss how to restart Feldman's simulation once it is complete. Suppose we are in a representation of the form r\u0442 [h, z] in which we either use the current target function f. [hz] is the hypothesis output by A with the help of query responses in z, we are sure that (with a high probability) Perff (hz, D) \u2265 1 \u2212 0 \u2212 / 4. At this point we want the algorithm to choose a new representation where the empty string is. The intuition behind this step is as follows: [hz, D] is guaranteed to be high (and will remain high for many generations) because much of the weight is on the hz term. Thus, we can use the second term to restart the learning process. After further time steps, we have the case that the performance of hz is no longer as high as in terms of the new goal."}, {"heading": "5.6 Equivalence to Evolvability with Drifting Targets", "text": "If we combine these results, we prove the equivalence between the ability to evolve and the ability to evolve with the theory of evolution. (...) We assume that the theory of evolution (and thus every class that is evolutionary) can be developed with the theory of evolution (and thus every class that is evolutionary). (...) If the theory of evolution of the theory of evolution of the theory of evolution of evolution of evolution theory can be developed, then the theory of evolution of evolution of evolution theory can be developed with the theory of evolution. (...) We make the theory of evolution of the theory of evolution of the theory of evolution with the theory of evolution. (...) We make the theory of evolution of the theory of evolution (...) of the theory of evolution."}, {"heading": "5.7 Equivalence to Quasi-Monotonic Evolution", "text": "Finally, we show that all developable classes are also quasi-monotonous. In the proof of Theorem 13, we have shown that for all g = 2q + K + 1, there is a high probability of satisfying Perff (r, D) \u2265 1 \u2212 and quasi-monotonicity trivially. Therefore, we only need to show quasi-monotonicity for the first g steps. We will use the same construction as in Section 5.3, with modifications. However, this assumes that the representation knows that the trick of bringing performance back to zero would violate quasi-monotonicity. To make the representation class independent of a more complex construction, a more complex construction is required. Details can be found in the appendix. Theorem 14 If C is developable via the distribution D, then C is quasi-monotonous via D with drifting objectives."}, {"heading": "6 Evolving Hyperplanes with Drifting Targets", "text": "In this section we present two alternative algorithms for developing n-dimensional hyperplanes with drifting targets: the first algorithm, which generates the neighbors of a hyperplane by rotating them in one of 2 (n \u2212 1) directions, tolerates a drift in the order of p / n, but only via spherically symmetrical distributions; the second algorithm, which generates the neighbors of a hyperplane by shifting individual components of its normal vector, tolerates a minor drift, but works when the distribution is an unknown product normal distribution. To our knowledge, these are the first positive results on evolving hyperplanes in the mathematical model of evolution. Formally, Cn is considered a class of all n-dimensional homogeneous linear separators.4 For notational reasons, we refer to each linear separator in Cn through the n-dimensional unit of longitude 4A homogeneous linear divider."}, {"heading": "6.1 An Evolution Algorithm Based on Rotations", "text": "For the rotation-based algorithm, we define the neighborhood function of r & # 246; Rn as follows: & # 8222; This orthonormal base can be chosen arbitrarily (and potentially randomly) as long as u1 = r & # 8220;. & # 8220; & # 8220; This orthonormal base can be chosen arbitrarily (and potentially randomly) as long as u1 = r & # 8220;. (& # 8220;) In other words: Each r & # 8222; Neigh (r & # 8220;) is achieved by rotating r & # 8222; n & # 8220; in any direction. & # 8220; The size of this neighboring group is clearly 2n & # 82- & # 8220; 1. & # 8220; We get the following theorem & # 8222;. & # 8220; Let C be the class of homogeneous linear separators, R the class of homogeneous separators are represented."}, {"heading": "6.2 A Component-Wise Evolution Algorithm", "text": "We must now describe the alternative algorithms for developing homogeneous linear separators that we are able to achieve the values described in the previous section. (We are not able to achieve the goals described in the previous section.) However, these algorithms apply if the alternative algorithms are based on the following observations. (First, if there are some i for which ri and fi have different characters and which are not too close to 0, we can achieve a new representation with a non-trivial performance enhancement by reversing the character of ri.) If there is no advantageous character for which ri and fi are not too close to fi, we can obtain a new representation with a significant performance enhancement by adjusting ri and renormalizing."}, {"heading": "7 Evolving Conjunctions with Drifting Targets", "text": "We now show that conjunctions with drifting objectives over the even distribution with a drift of O (2), independent of n. We begin by examining monotonous conjunctions and prove that the neighbourhood function defined by Valiant [19] is a strictly beneficial neighbourhood function with b (n, 1 / 2) = 2 / 9. Our evidence uses techniques similar to those presented in the simplified analysis of the Valiant algorithm presented by Diochnos and Tura'n [8]. Building on ideas by Jacobson [14], we extend this result to show that general conjunctions can be developed with the same drift rate."}, {"heading": "7.1 Monotone Conjunctions", "text": "We represent monotonous conjunctions with a representation class R, in which each r-r case is a subset of {1, \u00b7 \u00b7, n}, so this dependency is easy to remove (e.g. by using valiant's technique of allowing an initial phase in which the length of the representation decreases until it is below log2 (3 / 3), but simplifies the representation).The neighborhood of a representation r consists of a series of conjunctions formed by adding a variable to r, where a variable in r is not replaced by a variable in r, plus the representation r itself. Formally, we define the following three groups of conjunctions: N + (r) = {r-j}, N \u2212 r-r-class."}, {"heading": "7.2 General Conjunctions", "text": "Jacobson [14] proposed an extension of the above algorithm that applies to general conjunctions. However, the key innovation in his algorithm is the addition of a fourth sentence N \"(r) to the neighborhood or r, where each r\" N \"(r) by negating a subset of the literals in r. We show here that the drift rate of its construction can be analyzed in a similar way to the monotonous case. We represent general conjunctions using a representation class R in which each r\" r \"contains a subset of {1, \u00b7, n.\" {\u2212 1, \u00b7, \u2212 n} in such a way that the inclination | r \"log2 (3 / B) is the conjunction of the literals xj for all positive j\" r \"and negated literals x \u2212 j for all negative j\" r, \"and we restrict the R\" so that it is never the case that both j \"r\" and \u2212 j \"r\" r \"r.\" The dependence of this representation class of letters can be removed as before."}, {"heading": "A Additional Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1 Accuracy of the Empirical Performance", "text": "In order to prove Lemma 5 and Theorem 8, it is necessary to examine how close the empirical performance of a representation r is to the actual performance of representation.The following simple problem shows that as long as the sample size s (n, 1 / 2) is sufficiently large, the empirical performance of each representation is highly likely to come close to the actual performance. Lemma 19 Consider any r-R and f-C and fix any Z > 0 and \u03b4 > 0. Let N be an upper limit for the size of the Neigh neighborhood (r, 1 / 2).For each r \"Neigh (r, 2), v (r) should be the empirical performance of r\" in relation to a sample of the size s \u00b2 ln (2N / 3) / Z2."}, {"heading": "A.2 Proof of Lemma 5", "text": "Suppose that Neigh is a strictly favorable neighborhood function for C, D, and R with a high probability."}, {"heading": "A.3 Proof of Theorem 8", "text": "Suppose that Neigh is a strictly beneficial neighborhood function for C, D, and R with benefits. (...) Suppose that Neigh is a strictly beneficial neighborhood function for C, D, and R with benefits. (...) Suppose that Neigh is a strictly beneficial neighborhood function. (...) Suppose that Neigh is a strictly beneficial neighborhood function. (...) Suppose that Neigh is a strictly beneficial neighborhood function. (...) Suppose that Neigh is a strictly beneficial neighborhood function. (...) Suppose that Neigh is a strictly beneficial neighborhood function. (...) Suppose that Neigh is a strictly beneficial neighborhood function. (...) Suppose that Neigh is a strictly beneficial neighborhood function. (...) Let us assume that Neigh is a strictly beneficial neighborhood function. (...) Suppose that Neigh is a strictly beneficial neighborhood function."}, {"heading": "A.4 Proof of Lemma 10", "text": "In each case and any arbitrary function in the same order: X [1, 1], E [??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????"}, {"heading": "A.5 Proof of Lemma 11", "text": "Assuming that the LPE does not occur at any time, after q time steps, if rq = rq [h, z], then | z | = q, since we add a bit at each step. We consider the possible mutations of ri. Note that rq [h, z i0] is always neutral for all i. The cases we have to consider are (a) rq [h, z i1] as the next representation, which means that zi + 1 = 0 and (c) rzi [h, z i1] is chosen as the next representation, which implies that zi + 1 = 1, (b) rq [h, z i1] is considered the next representation, and (c) rzi [h, z i1] is neutral as the next representation, which implies that either rq [h, z i1] or rzi [h, z i0] is valid as the answer."}, {"heading": "A.6 Proof of Lemma 12", "text": "Suppose that the LPE does not occur at any point in time, wj + 1 is always a neutral mutation for wj, and mutations of the form wj \u2192 wj will not occur. Also, in K \u2212 k rounds we will reach wK (if we have not already gone to r.hz [hz,]) and therefore move on to r.hz [0,] in the next round, which means that the number of steps will not exceed K \u2212 k + 1. Now let us assume that if at any given time Perffi (ri, D) < Perffi (r.hz,], D), then Perffi \u2212 1 (r.hz,), Perffi \u2212 1 (r.hz,), Perffi \u2212 1 (re \u2212 1, D), Perffi \u2212 1 (r.hz,), D \u2212 r.hz (r.hz,), D \u2212 ffi \u2212 1 (r.hz), and vice versa."}, {"heading": "A.7 Proof Sketch for Theorem 14", "text": "We will apply some details here, because the arguments are very similar; in fact, the argument that this algorithm is resistant to drift is almost identical. To begin with, let's leave the representation category in the following section. We will use the same construction defined in Section 5.3, with only a small modification. For the representations in Vladivostok, let's say w0 = r.2 with the same representation category, and in the neighborhood of wk we will also add r.3, with only a small modification. For the representations in Vladivostok, let's say: w0 = r.2 with the same representation category, and in the neighborhood of wk we will add the r.2 further construction, which is in addition to the existing r.2, [hz], r.2 with the representation in Vladivostok, let's say: w0 = r.2 with the same representation category, and wk + 1."}, {"heading": "A.7.1 Removing the Need to Know \u01eb", "text": "In Section A.7, we have shown that any CSQ algorithm can be transformed into an evolutionary algorithm that is drift-resistant and quasi-monotonous, provided that we are allowed to fix and encode it in representation. We assume that the parameter provided to the algorithm has a power of 2. If this were not the case, we could simply run the algorithm with other values, with the definition of the ability to evolve allowing the neighborhood to depend on other values, but not on the incipient representation. Moreover, we assume that the parameter provided to the algorithm has a power of 2. If this were not the case, we could simply run the algorithm with other values. \""}, {"heading": "A.8 Proof of Theorem 15", "text": "We show that Neigh is a strictly favorable neighborhood function for C, D, and R with b (n, 1 / 2) = 1 (2). The theory is then a direct consequence of the theory. The analysis relies heavily on a few useful trigonometric facts. First, it is known (see for example, Dasgupta [6]) that under each spherically symmetrical distribution D (for example, the even distribution across a sphere), errD (u, v) = arccos (u \u00b7 v) / \u03c0, where arccos (u \u00b7 v) is the angle between u and v. We will apply this fact repeatedly. We also make use of the following inequalities from Dasgupta et al. [7] For all other areas where the arccos (0, 2 / 2), is the arccos (both), the arccos (u \u00b7 v), where arccos (u \u00b7 v) is the angle between u and v."}, {"heading": "A.9 Proof of Theorem 16", "text": "We begin by analyzing the simpler case in which D = = = = = = = = = = = = = \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "Product Normal Distributions", "text": "We are very pleased to announce that we have been able to offer our customers a wide range of products and services for the benefit of our customers. We are pleased to announce that we have been able to offer our customers a wide range of products and services for the benefit of our customers. We are pleased to announce that we have been able to offer our customers a wide range of products and services for the benefit of our customers. We are pleased to announce that we have been able to offer our customers a wide range of products and services for the benefit of our customers. We are pleased to announce that we have been able to offer our customers a wide range of products and services for the benefit of our customers."}, {"heading": "A.10 Proof of Theorem 17", "text": "\u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2"}, {"heading": "A.11 Proof of Theorem 18", "text": "We show that Neigh is a strictly favorable neighboring function for C, D, and R with utility polynomial b (n, 1 / 2). \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 The theorem is then a direct consequence of Theorem 8. Consider an arbitrary case for R and f for Cn. As with the proof for Theorem 17, we begin by looking at the case in which the target is \"long,\" i.e. the performance of r in relation to f is already good enough. If r does not contain a literal negation of a letter in f, then Perff (r, D) > 1 \u2212 21 \u2212 | r | 1 \u2212 applies as before, and the performance of r in relation to f is already good enough."}], "references": [], "referenceMentions": [], "year": 2010, "abstractText": "We consider the question of the stability of evolutionary algorithms to gradual changes,<lb>or drift, in the target concept. We define an algorithm to be resistant to drift if, for<lb>some inverse polynomial drift rate in the target function, it converges to accuracy 1 \u2212 \u01eb<lb>with polynomial resources, and then stays within that accuracy indefinitely, except with<lb>probability \u01eb at any one time. We show that every evolution algorithm, in the sense of<lb>Valiant [19], can be converted using the Correlational Query technique of Feldman [9], into<lb>such a drift resistant algorithm. For certain evolutionary algorithms, such as for Boolean<lb>conjunctions, we give bounds on the rates of drift that they can resist. We develop some<lb>new evolution algorithms that are resistant to significant drift. In particular, we give an<lb>algorithm for evolving linear separators over the spherically symmetric distribution that is<lb>resistant to a drift rate of O(\u01eb/n), and another algorithm over the more general product<lb>normal distributions that resists a smaller drift rate. The above translation result can be also interpreted as one on the robustness of the notion of<lb>evolvability itself under changes of definition. As a second result in that direction we show<lb>that every evolution algorithm can be converted to a quasi-monotonic one that can evolve<lb>from any starting point without the performance ever dipping significantly below that of<lb>the starting point. This permits the somewhat unnatural feature of arbitrary performance<lb>degradations to be removed from several known robustness translations.", "creator": "LaTeX with hyperref package"}}}