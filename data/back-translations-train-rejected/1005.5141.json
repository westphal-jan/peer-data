{"id": "1005.5141", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-May-2010", "title": "On Recursive Edit Distance Kernels with Application to Time Series Classification", "abstract": "This paper proposes some extensions to the work on kernels dedicated to string alignment (biological sequence alignment) based on the summing up of scores obtained by local alignments with gaps. The extensions we propose allow to construct, from classical time warp distances, what we called summative time warp kernels that are positive definite if some simple sufficient conditions are satisfied. Furthermore, from the same formalism, we derive a time warp inner product that extend the usual euclidean inner product, providing the capability to handle discrete sequences or time series of variable lengths in an Hilbert space. The classification experiment we conducted, using either first near neighbor classifier or Support Vector Machine classifier leads to conclude that the positive definite elastic kernels we propose outperform the distance substituting kernels for the classical elastic distances we tested. In a similar way, the kernel based on the distance induced by the time warp inner product outperforms significantly on the considered task the kernel based on the euclidean distance.", "histories": [["v1", "Thu, 27 May 2010 18:11:15 GMT  (36kb)", "http://arxiv.org/abs/1005.5141v1", "15 pages"], ["v2", "Mon, 12 Jul 2010 12:45:28 GMT  (36kb)", "http://arxiv.org/abs/1005.5141v2", "15 pages"], ["v3", "Tue, 7 Dec 2010 11:02:10 GMT  (37kb)", "http://arxiv.org/abs/1005.5141v3", "15 pages"], ["v4", "Mon, 3 Jan 2011 10:32:07 GMT  (124kb)", "http://arxiv.org/abs/1005.5141v4", "15 pages"], ["v5", "Wed, 6 Feb 2013 16:32:52 GMT  (122kb)", "http://arxiv.org/abs/1005.5141v5", "20 pages"], ["v6", "Mon, 27 May 2013 08:58:31 GMT  (173kb,D)", "http://arxiv.org/abs/1005.5141v6", "20 pages"], ["v7", "Tue, 30 Jul 2013 09:21:26 GMT  (110kb)", "http://arxiv.org/abs/1005.5141v7", "14 pages"], ["v8", "Thu, 1 Aug 2013 14:41:48 GMT  (110kb)", "http://arxiv.org/abs/1005.5141v8", "14 pages"], ["v9", "Mon, 25 Nov 2013 20:31:46 GMT  (110kb)", "http://arxiv.org/abs/1005.5141v9", "14 pages"], ["v10", "Wed, 27 Nov 2013 07:57:25 GMT  (110kb)", "http://arxiv.org/abs/1005.5141v10", "14 pages"], ["v11", "Thu, 5 Dec 2013 14:04:32 GMT  (106kb)", "http://arxiv.org/abs/1005.5141v11", "14 pages"], ["v12", "Mon, 26 May 2014 06:17:30 GMT  (107kb)", "http://arxiv.org/abs/1005.5141v12", "14 pages"]], "COMMENTS": "15 pages", "reviews": [], "SUBJECTS": "cs.LG cs.IR", "authors": ["pierre-fran\\c{c}ois marteau", "sylvie gibet"], "accepted": false, "id": "1005.5141"}, "pdf": {"name": "1005.5141.pdf", "metadata": {"source": "CRF", "title": "Constructing Positive Definite Elastic Kernels with Application to Time Series Classification", "authors": ["Pierre-Fran\u00e7ois Marteau"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 100 5.51 41v1 [cs.LG] 2 7M ay2 010 DRAFT PAPER IN SUBMISSION 1Index Terms - Elastic Distance, Time Warp Core, Time Warp Inner Product, Definitness, Time Series Classification, SVM."}, {"heading": "1 INTRODUCTION", "text": "In fact, most of us are able to play by the rules we have set ourselves in order to make them a reality."}, {"heading": "2 RELATED WORKS", "text": "In fact, most of them are able to determine for themselves what they want to do and what they want to do."}, {"heading": "3 NOTATIONS AND MATHEMATICAL BACKGROUNDS", "text": "To ensure that this paper is self-satisfied, we give, without much detail, commonly used definitions for metric or quasi-metric, inner products, cores and definitions, sequence sets and classic elastic dimensions."}, {"heading": "3.1 Premetric, pseudometric and metric", "text": "Definition 3.1: A premetry on a set of U is a function \u03b4: U \u00b7 U \u2192 R that fulfills the following axioms: For all (x, y) \u2022 U \u00b7 U, 1) \u03b4 (x, y) \u2265 0 (nonnegativity) 2) \u03b4 (x, x) = 0 (zero if identical) Definition 3.2: A pseudometry on a set of U is a function \u03b4: U \u00b7 U \u2192 R that fulfills the following axioms: For all (x, y) \u0445 U \u00b7 U, 1) \u03b4 (x, y) \u2265 0 (nonnegativity) 2) \u03b4 (x, x) = 0 (zero if identical) 3) \u03b4 (x, y) = \u03b4 (y, x) (symmetry) 4) \u043c (x, z) \u2264 d (x, y) + d (y, z). (subadditivity / triangle uniformity) Definition 3.3: A metric, also referred to as a distance, on a set U is a second when it is defined as pseudomry, and only for all (x)."}, {"heading": "3.2 Inner Product", "text": "Following, the field of scalars called F is either the field of real numbers R or the field of complex numbers C. Definition 3.4: An inner product space is a vector space V above the field F along with an inner product, i.e. with a map < \u00b7, \u00b7 >: V \u00b7 V \u2192 F containing the following three axioms for all vectors x, y, z \u00b2 V and all scalars a \u00b2 F: 1) Conjugate symmetry: < x, y > = < y, x >. 2) Linearity in the first argument: < ax, y > = a < x, y >. < x + y, z > = < x, z > <.3) Positive definition: < x, x > \u2265 0 with equality only for x = 0."}, {"heading": "3.3 Kernel and definiteness", "text": "Definition 3,5: A kernel on a non-empty set U refers to a complex (or real) symmetric function (x, y): U \u00b7 U \u2192 C (or R). Definition 3,6: Let U be a non-empty set. A function: U \u00b7 U \u2192 C is called a positive (or negative) definite core if and only if it is Hermitian (i.e. if it is a positive (x, y) = definite (y, x), where the upper limit is the conjugate number) for all x and y, j = 1 positive (i.e. negative) positive (xi, xj). Definition 0 (i.e.) n i, j = 1 cic (xi, xj) \u2264 (xi, xj) \u2264 0), for all n in N, {x1, x2, xn \u00b2 negative elements and {c1, c2,... xx.Definition 3,7: Let U be a non-empty set."}, {"heading": "3.4 Sequence set", "text": "Definition 3.9: Let U be the set of finite sequences (symbolic sequences or time series): U = {Ap1 | p \u00b2 N}. Ap1 is a sequence with a discrete index that varies between 1 and p. We note that the empty sequence (with zero length) and according to convention A01 = \"is such that A is a member of group U. | A | denotes the length of sequence A. Let us remember that a\" i \"S\" T, where S includes the multidimensional space variables (either symbolic or numerical) and T \"R\" includes the time stamp variable, \"so that we can write an\" i \"(ai, tai) where ai\" S \"and tai\" T, \"with the condition that tai > taj\" i. \""}, {"heading": "3.5 General Edit/Elastic distance on a sequence set", "text": "Definition 3.11: An editing operation is a pair (a, b \"s) 6 = (\" q \") of sequence elements written a\" \u2192 b. \"Sequence B results from the application of editing operation a\" b \"in sequence A, written A\" B about a \"\u2192 b,\" when A \"a\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s"}, {"heading": "3.5.1 Levenshtein distance", "text": "The Levenshtein spacing \u03b4lev (x, y) was defined for string matching. At this input distance, the delete and insert operations incur uniform costs, i.e., the delete and insert operations incur uniform costs, i.e., the delete and insert operations incur uniform costs, i.e., the delete and insert operations incur uniform costs, i.e., the delete and insert operations incur uniform costs, i.e., the delete and insert operations incur no costs if a \u2032 p = b \u2032 p or 1 otherwise."}, {"heading": "3.5.2 Dynamic time warping", "text": "The DTW similarity measurement \u03b4dtw [23] [17] is defined according to the previous notations as: \u03b4dtw (A p 1, B q 1) = dLP (ap, bq) + Min\u03b4dtw (A p \u2212 1, B q 1) \u03b4dtw (A p \u2212 1, B q \u2212 1) \u03b4dtw (A p 1, B q \u2212 1) (2), where dLP (ap, bq) is the Lp standard in R k, and therefore for the DTW, and the cost of each processing operation includes vectors a and b in S instead of vectors a and b \u00b2 q) = and b \u00b2 in S \u00b7 v \u2212 q) = dLP (ap, bq). It can be noted that the timestamp values are not used, so the cost of each processing operation includes vectors a and b in S instead of vectors a and b \u00b2 in S and b \u00b2 p \u00b2 p \u00b2 p \u00b2 p p p p p p p p p p p p p. One of the most important limitations of p v \u2212 is that it is not consistent with triangular inequality."}, {"heading": "3.5.4 Time warp edit distance", "text": "Time Warp Edit Distance (TWED) [12], [13] is similarly defined as the edit distance defined for string [11] [24]. The similarity between any two time series of finite length A and B, or p and q, is defined as: \u03b4twed (A p 1, B q 1) = Minutes twed (A p \u2212 1, B q 1) + \u0442twed (a \u2032 p \u00b2 B) deleteA \u03b4twed (A p \u2212 1, B q \u2212 1 1) + \u0445 (a \u2032 p \u2192 b \u00b2 q) match \u0441twed (A p 1, B q \u2212 1) + \u0441twed (A \u00b2 q) deleteB (4) withched (a \u2032 p \u00b2) = d (a \u2032 p, a \u2032 p \u2212 1) + \u03bb (a \u2032 p \u00b2 b \u00b2 q) + \u03bb (a \u2032 p \u00b2 q) = p \u00b2 q) = negative (a \u2032 p \u00b2 q) = d (a \u2032 p \u00b2 q), b \u00b2 (the constant is b \u00b2) and b \u00b2 (b)."}, {"heading": "4 UNDEFINITENESS OF ELASTIC DISTANCE KERNELS", "text": "The Levenshtein spacing kernel \u0438 (x, y) = \u03b4lev (x, y) is known not to be defined. (We report under the first known counterexample, which was produced by [6]. Consider the subset of sequences V = {abc, bad, dab, adc, bcd}, which leads to the following eigenspectrum. (1, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 3, \u2212 3) and consider the coefficient vectors C and D in R5 such that C = [1, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 3, that the properties C = [1, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, 5, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, \u2212 2, 5, \u2212 2, \u2212 2, \u2212 2, 5, \u2212 2, \u2212 2, \u2212 2, \u2212 2, 5, \u2212 2, 5, \u2212 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,"}, {"heading": "5 CONSTRUCTING POSITIVE DEFINITE KERNELS FROM ELASTIC DISTANCE", "text": "The simple idea that leads to the construction of positive defined cores from a given elastic distance defined on U is to replace the min or max operator with a recursive equation that defines the elastic distance by a \u2211 operator. Instead of maintaining one of the best alignment paths, the new kernel summarizes all sub-sequence alignments with an optimizable weighting factor, which has been successfully done for the symbolic distance of Smith and Waterman, also known as indefinite [16], and we propose some generalizations and extensions of this result in the following subsections."}, {"heading": "5.1 Summative Time Warped Kernels", "text": "K-definition 5.1: A function < >: U-U-Q-Q function is designated as summative time warp kernel (STWK) if a function f: R-R-R function exists for any sequence pairs Ap1, B-Q-1 so that the following recursive equation is fulfilled < Ap1; B-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-1-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q-Q"}, {"heading": "5.2 Some instances of additive and multiplicative STWK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2.1 Additive STWK", "text": "Definition 5,4: < Ap1, B > twip = 1 > twip = 1 3 \u00b7 \u2211 < Ap \u2212 11, B q \u2212 1 > delete twip < Ap \u2212 11, B q \u2212 1 > twip + e \u2212 \u03bd.d (tap, tbq) (ap \u00b7 bq) match < Ap1, B \u2212 1 > twip insertwhere d is a distance and a stiffness parameter. We propose for this addition SWTK.Proposition 5,5: Definiteness of the additive STWK <.,. twip that the property of an inner product: i) <. > twip is positive definite.ii) In addition <. > twip is an internal product on (U, ltc ltc) that we call a Time Warp Inner Product (TWIP), where both in definition 5,2.1 and m 5,6, i."}, {"heading": "5.2.2 Multiplicative exponentiated STWK", "text": "Definition 5,7: < Ap1, B q 1 > me = 1 3 \u00b7 \u2211 < Ap \u2212 11, B q 1 > me.e \u2212 \u03bd \"(a\" p \"p\") delete < Ap \u2212 11, B \"1\" me. \"e\" (a \"p\" b \"q) match < Ap1, B\" q \"1\" me. \"e\" (b \"q) insert (10), which is a stiffness parameter that weights the contribution of local elementary costs. The larger the approach, the more selective the core is with respect to the optimal paths. At the limit, when the cost of the optimal paths is summed up by the core. Note that, as is generally the case, several optimal paths that lead to the same global costs exist, lim \u00b2 \u00b2 \u00b2 + 1 / 4\" kernel \"\u00b7 log (< A, B\" q > me) do not match the element position."}, {"heading": "6 CLASSIFICATION EXPERIMENTS", "text": "Empirically, we evaluate the effectiveness of some STWK in comparison to Gaussian Radial Base Function (RBF) kernels or elastic distance substitution kernels [7] using some classification tasks on a series of time series from very different application fields. The classification task we considered consists of mapping one of the possible categories to an unknown time series for the 20 data sets available in the UCR repository [10]. Since the time for these data sets is not explicitly specified, we used the index value of the samples as a time stamp for the entire experiment. For each data set, a training subset (TRAIN) is defined, as well as an independent test subset (TEST). We use the training sets to train two types of classifiers: \u2022 the first is a first near neighborhood (1-NN) classification unit: first, we select a training subgroup (TRAIN), we select a training parameter from a minimum test subset (we select a time series that contains an unknown time series for a RAIN) subset (we select a class that contains an unknown time series for a RAN)."}, {"heading": "6.1 Additive STWK", "text": "We tested the additive STWK based on the Time Warp Inner Product < Ap1, B q 1 > twip (Eq.10). Strictly speaking, we used the Time Warp Distance induced by < Ap1, B q 1 > twip, essentially \u03b4twip (A p 1, B q 1) = (< A p 1 \u2212 Bq1, Ap1 \u2212 Bq1 > twip) 1 / 2."}, {"heading": "6.1.1 Meta parameters", "text": "\u03b4twip is characterized by the meta parameter \u03bd (the stiffness parameter), which is optimized for each data set on the train data by minimizing the error rate in classifying a first classifier near neighbors. For this kernel, \u03bd was selected in {100, 10, 1,.1,.01,..., 1e \u2212 5}. To investigate the potential advantages of TWIP over the Euclidean internal product, we also tested the Euclidean distance \u03b4ed, which is the limit when \u03bd \u2192 \u221e of \u03b4twip. The cores exploited by the SVM classifiers are the Gaussian cores STWKtwid (A, B) = e\u00e4t twid (A, B) 2 / (2 \u00b7 \u03c32) and Ked (A, B) = e \u0441ed (A, B) 2 / (2 \u00b7 \u03c32) and the meta parameters C are expressed in the discrete values {2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \u2212, 2, 2, 2, 210, and \u2212, 2, 2, 2, 210, and \u2212, and \u2212 210 (A, B), 2, 2, 2, 2, 210, and \u2212, and \u2212."}, {"heading": "6.2 Multiplicative STWK", "text": "We tested the multiplicative exposed STWW, based on the grading errors for \u2022 the first adjacent grading criteria based on the grading criteria STWKerp, STWKdtw, STWKtwed. Our experiment compares grading errors for \u2022 the first grading criteria based on the grading criteria for close neighbors based on the grading criteria STWKerp, \u03b4dtw, STWKtwed and STWKtwed. \u2022 The SVM grading criteria use Gaussian distance substitution criteria based on the same distances and the corresponding STWKtwed, e.g. SVM insperp, SVM STWKerp, SVM inspdtw, SVM STWKdtw, SVM insptwed, SVM insptwed, SVM insptwed, SVM STWKtwed, SVM STWKtwed and STWKtwed. For exposure criteria, we used the STWWW1 and STWtwed for the NorWWWtwed."}, {"heading": "6.2.1 Meta parameters", "text": "For this kernel, g is selected in {\u2212 3, \u2212 2,99, \u2212 2,98, \u00b7 \u00b7, 2,98, 2,99, 3}. This optimized value is also used for comparison in the STWKme (ERP) kernel. For this kernel, the meta parameters \u03bb and \u03bd are optimized for each data set in the traction data by minimizing the classification error rate of a first classifier nearby. In our experiment, the stiffness value (\u03bd) from {10 \u2212 5, 10 \u2212 4, 10 \u2212 3, 10 \u2212 2, 10 \u2212 1, 1} and the STernS value from {0,.25,.5, Kk5 \u2212 are metametrized."}, {"heading": "6.3 Discussion", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.3.1 Additive STWK experiment analysis", "text": "Table 3 shows the classification error rates achieved for the methods tested, e.g. the first classifier near the Euclidean distance and the distance induced by the time-warp internal product (1-NN ED and 1-NN \u03b4twip), the Gaussian RBF kernel SVM based on the Euclidean distance and the distance induced by the time-warp internal product (SVM Ked and SVM STWKtwip). This experiment shows that the time-warp internal product is significantly more effective for the tasks considered compared to the edit distance measure, as it has on average the lowest error rates for the test data for both the 1-NN and the SVM classifiers, as shown in Table 3 and Figures 1 and 2. The stiffness parameter in \u03b4twip appears to play an important role in these classification tasks, and this for a large majority of the data sets."}, {"heading": "6.3.2 Multiplicative STWK experiment analysis", "text": "Tables 4 and 5 show the classification error rates obtained for the methods tested, e.g. the first adjacent classifier based on the same distances, the Gaussian SVM RBF kernel (SVM kernel, SVM kernel STWKerp, SVM kernel STWKdtw and SVM kernel STWKtwed) and the Euclidean spacing and Gaussian SVM RBF kernel based on the STWK cores (SVM STWKdtw and SVM STWKtwed). In this experiment we show that the SVM classifiers clearly outperform the 1-NN classifiers, but the interesting results in Tables 4 and 5 and Figures 3, 4 and 5 show that SVM STWKerp and SVM STWKtww kerp perform slightly better than SVM kerp and SVM classifiers."}, {"heading": "7 CONCLUSION", "text": "After the work on folding cores [9] and local alignment cores defined for the processing of strings around the Smith and Waterman algorithms [20], we propose additive and multiplicative STWK cores (STWK) applicable to the processing of strings and time series. We provide some simple, sufficient conditions to form positively defined STWK distances. Our generalization leads us to additive and multiplicative STWK cores. For the well-known dynamic time distortion measure, we show that the sufficient conditions are essentially fulfilled by very classical elastic distances defined by a recursive equation, in particular the case of the machining distance, the known dynamic time distortion, and for some variants such as the machining distance with real penalty and the time distortion of the distance, which are these last two metrics, as well as the symbolic machining distance."}, {"heading": "APPENDIX A", "text": "In this sense, we consider the established Vr = [V] so that Max (Ak, Al) 2 (A) 2 (A) 2 (A) 4 (A) 4 (A) 4 (A) 4 (A) 4 (A) 4 (A) 4 (A) 4 (A) 4 (A) 4 (A) 4 (A) 4 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A) 5 (A (A) 5 (A) 5 (A) 5 (A (A) 5 (A) 5 (A) 5 (5 (A) 5 (A) 5 (A) 5 (5 (A) 5 (A) 5 (A (A) 5 (A) 5 (A) 5 (5 (A) 5 (A) 5 (A) 5 (5 (A) 5 (A) 5 (A) 5 (5 (A) 5 (A) 5 (A) 5 (5 (A) 5 (A) 5 (5 (A) 5 (5 (A) 5 (A) 5"}, {"heading": "ACKNOWLEDGMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "A basic local alignment serach tool", "author": ["S. Altschul", "W. Gish", "W. Miller", "E. Myers", "D. Lipman"], "venue": "Journal of Molecular Biology, 215:403\u2013 410", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1990}, {"title": "Dynamic Programming", "author": ["R. Bellman"], "venue": "Princeton Univ Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1957}, {"title": "Harmonic Analysis on Semigroups: Theory of Positive Definite and Related Functions, volume 100 of Graduate Texts in Mathematics", "author": ["Christian Berg", "Jens Peter Reus Christensen", "Paul Ressel"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1984}, {"title": "A training algorithm for optimal margin classifiers", "author": ["Bernhard E. Boser", "Isabelle Guyon", "Vladimir Vapnik"], "venue": "In COLT,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1992}, {"title": "On the marriage of lp-norm and edit distance", "author": ["L. Chen", "R. Ng"], "venue": "Proceedings of the 30th International Conference on Very Large Data Bases, pages 792\u2013801", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "Positive Definite Rational Kernels", "author": ["Corinna Cortes", "Patrick Haffner", "Mehryar Mohri"], "venue": "In Proceedings of COLT\u201903,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Learning with distance substitution kernels", "author": ["B. Haasdonk", "C. Bahlmann"], "venue": "DAGM-Symposium, pages 220\u2013227", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Feature space interpretation of svms with indefinite kernels", "author": ["Bernard Haasdonk"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "Convolution kernels on discrete structures", "author": ["D. Haussler"], "venue": "Technical report, University of California, Santa Cruz", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "L", "author": ["E.J. Keogh", "X. Xi"], "venue": "Wei, and C.A. Ratanamahatana. The ucr time series classification-clustering datasets", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Binary codes capable of correcting deletions", "author": ["V.I. Levenshtein"], "venue": "insertions, and reversals. Doklady Akademii Nauk SSSR, 163(4):845- 848, 1965 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1966}, {"title": "Time warp edit distance", "author": ["P.F. Marteau"], "venue": "Technical report, VALORIA, Universite de Bretagne Sud", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Time warp edit distance with stiffness adjustment for time series matching", "author": ["P.F. Marteau"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., 31(2):306\u2013318", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Rapid and sensitive sequence comparisons with fasp and fasta", "author": ["W. Pearson"], "venue": "Methods Enzymol, 183:63\u201398", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1990}, {"title": "Making time-series classification more accurate using learned constraints", "author": ["C.A. Ratanamahatana", "E.J. Keogh"], "venue": "Proceedings of the Fourth SIAM International Conference on Data Mining (SDM\u201904), pages 11\u201322", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Protein homology detection using string alignment kernels", "author": ["H. Saigo", "J.P. Vert", "N. Ueda", "T. Akutsu"], "venue": "Bioinformatics, 20:1682\u2013 1689", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "A dynamic programming approach to continuous speech recognition", "author": ["H. Sakoe", "S. Chiba"], "venue": "Proceedings of the 7th International Congress of Acoustic, pages 65\u201368", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1971}, {"title": "Metric spaces and positive definite functions", "author": ["I.J. Schoenberg"], "venue": "Transactions of the American Mathematical Society,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1938}, {"title": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond", "author": ["Bernhard Scholkopf", "Alexander J. Smola"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2001}, {"title": "Identification of common molecular subsequences", "author": ["T. Smith", "Waterman M"], "venue": "Journal of Molecular Biology,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1981}, {"title": "Statistical Learning Theory", "author": ["Vladimir Vapnik"], "venue": "Wiley-Interscience, ISBN 0-471-03003-1,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1989}, {"title": "Automatic recognition of 200 words", "author": ["V.M. Velichko", "N.G. Zagoruyko"], "venue": "International Journal of Man-Machine Studies, 2:223\u2013234", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1970}, {"title": "The string-to-string correction problem", "author": ["R.A. Wagner", "M.J. Fischer"], "venue": "Journal of the ACM (JACM), 21:168\u2013173", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1973}, {"title": "Distances and (indefinite) kernels for sets of objects", "author": ["Adam Woznica", "Alexandros Kalousis", "Melanie Hilario"], "venue": "Data Mining, IEEE International Conference on,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "Learning with non-metric proximity matrices", "author": ["Gang Wu", "Edward Y. Chang", "Zhihua Zhang"], "venue": "Proceedings of the 13th annual ACM international conference on Multimedia,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}], "referenceMentions": [{"referenceID": 1, "context": "From the original dynamic programming [2] implementation of the symbolic edit distance [11] by Wagner and Fisher [24], the Smith and Waterman (SW) algorithm [20] has been designed to evaluate the similarity between two symbolic sequences by means of a local gap alignment.", "startOffset": 38, "endOffset": 41}, {"referenceID": 10, "context": "From the original dynamic programming [2] implementation of the symbolic edit distance [11] by Wagner and Fisher [24], the Smith and Waterman (SW) algorithm [20] has been designed to evaluate the similarity between two symbolic sequences by means of a local gap alignment.", "startOffset": 87, "endOffset": 91}, {"referenceID": 22, "context": "From the original dynamic programming [2] implementation of the symbolic edit distance [11] by Wagner and Fisher [24], the Smith and Waterman (SW) algorithm [20] has been designed to evaluate the similarity between two symbolic sequences by means of a local gap alignment.", "startOffset": 113, "endOffset": 117}, {"referenceID": 19, "context": "From the original dynamic programming [2] implementation of the symbolic edit distance [11] by Wagner and Fisher [24], the Smith and Waterman (SW) algorithm [20] has been designed to evaluate the similarity between two symbolic sequences by means of a local gap alignment.", "startOffset": 157, "endOffset": 161}, {"referenceID": 0, "context": "More efficient local heuristics have been since proposed to meet the massive symbolic data challenge, such as BLAST [1] or FASTA [14].", "startOffset": 116, "endOffset": 119}, {"referenceID": 13, "context": "More efficient local heuristics have been since proposed to meet the massive symbolic data challenge, such as BLAST [1] or FASTA [14].", "startOffset": 129, "endOffset": 133}, {"referenceID": 21, "context": "Similarly, dynamic time warping measures have been developed to evaluate similarity between numeric time series or time stamped data [23], [17], and more recently [5], [13] propose elastic metrics dedicated to such numeric data.", "startOffset": 133, "endOffset": 137}, {"referenceID": 16, "context": "Similarly, dynamic time warping measures have been developed to evaluate similarity between numeric time series or time stamped data [23], [17], and more recently [5], [13] propose elastic metrics dedicated to such numeric data.", "startOffset": 139, "endOffset": 143}, {"referenceID": 4, "context": "Similarly, dynamic time warping measures have been developed to evaluate similarity between numeric time series or time stamped data [23], [17], and more recently [5], [13] propose elastic metrics dedicated to such numeric data.", "startOffset": 163, "endOffset": 166}, {"referenceID": 12, "context": "Similarly, dynamic time warping measures have been developed to evaluate similarity between numeric time series or time stamped data [23], [17], and more recently [5], [13] propose elastic metrics dedicated to such numeric data.", "startOffset": 168, "endOffset": 172}, {"referenceID": 20, "context": "SVM or vast margin classifiers [21], [4], [19] are a set of supervised algorithms that learn from positive and negative examples how to solve discrimination or regression problems.", "startOffset": 31, "endOffset": 35}, {"referenceID": 3, "context": "SVM or vast margin classifiers [21], [4], [19] are a set of supervised algorithms that learn from positive and negative examples how to solve discrimination or regression problems.", "startOffset": 37, "endOffset": 40}, {"referenceID": 18, "context": "SVM or vast margin classifiers [21], [4], [19] are a set of supervised algorithms that learn from positive and negative examples how to solve discrimination or regression problems.", "startOffset": 42, "endOffset": 46}, {"referenceID": 23, "context": "The sub-optimality of the non convex optimization process is possibly one of the causes leading to these un-guaranteed performances [25], [7].", "startOffset": 132, "endOffset": 136}, {"referenceID": 6, "context": "The sub-optimality of the non convex optimization process is possibly one of the causes leading to these un-guaranteed performances [25], [7].", "startOffset": 138, "endOffset": 141}, {"referenceID": 24, "context": "Among others, some approaches apply direct spectral transformations to indefinite kernels: the methods [26] consist in flipping the negative eigenvalues or shifting the eigenvalues using the minimal shift value required to make the spectrum of eigenvalues positive and reconstructing the kernel with the original eigenvectors in order to produce a positive semidefinite kernel.", "startOffset": 103, "endOffset": 107}, {"referenceID": 7, "context": "Some theoretical highlights have been provided through approaches that consist in embedding the data into a pseudo-Euclidean (pE) space and formulating the classification problem with an indefinite kernel as that of minimizing the distance between convex hulls formed from the two categories of data embedded in the pE space [8].", "startOffset": 325, "endOffset": 328}, {"referenceID": 8, "context": "Our approach is founded on the work of Haussler (199) on convolution kernels [9] defined on set of discrete structures such as strings, trees or graphs.", "startOffset": 77, "endOffset": 80}, {"referenceID": 15, "context": "Following the work of Haussler (1999), Saigo and al [16] define, from the smith and waterman algorithm [20], a kernel to detect local alignment between strings by convolving simpler kernels.", "startOffset": 52, "endOffset": 56}, {"referenceID": 19, "context": "Following the work of Haussler (1999), Saigo and al [16] define, from the smith and waterman algorithm [20], a kernel to detect local alignment between strings by convolving simpler kernels.", "startOffset": 103, "endOffset": 107}, {"referenceID": 21, "context": "2 Dynamic time warping The DTW similarity measure \u03b4dtw [23][17] is defined according to the previous notations as:", "startOffset": 55, "endOffset": 59}, {"referenceID": 16, "context": "2 Dynamic time warping The DTW similarity measure \u03b4dtw [23][17] is defined according to the previous notations as:", "startOffset": 59, "endOffset": 63}, {"referenceID": 4, "context": "One of the main restrictions of \u03b4dtw is that it does not comply with the triangle inequality as shown in [5].", "startOffset": 105, "endOffset": 108}, {"referenceID": 4, "context": "According to the authors of ERP [5], the constant g should be set to 0 for some intuitive geometric interpretation and in order to preserve the mean value of the transformed time series when adding gap samples.", "startOffset": 32, "endOffset": 35}, {"referenceID": 11, "context": "4 Time warp edit distance Time Warp Edit Distance (TWED) [12], [13] is defined similarly to the edit distance defined for string [11][24].", "startOffset": 57, "endOffset": 61}, {"referenceID": 12, "context": "4 Time warp edit distance Time Warp Edit Distance (TWED) [12], [13] is defined similarly to the edit distance defined for string [11][24].", "startOffset": 63, "endOffset": 67}, {"referenceID": 10, "context": "4 Time warp edit distance Time Warp Edit Distance (TWED) [12], [13] is defined similarly to the edit distance defined for string [11][24].", "startOffset": 129, "endOffset": 133}, {"referenceID": 22, "context": "4 Time warp edit distance Time Warp Edit Distance (TWED) [12], [13] is defined similarly to the edit distance defined for string [11][24].", "startOffset": 133, "endOffset": 137}, {"referenceID": 5, "context": "We report below the first known counter-example produced by [6].", "startOffset": 60, "endOffset": 63}, {"referenceID": 15, "context": "This has been done successfully for the Smith and Waterman symbolic distance that is also known to be indefinite [16] and we propose in the following sub sections some generalizations and extensions of this result.", "startOffset": 113, "endOffset": 117}, {"referenceID": 17, "context": "As in general the cost function \u0393 is conditionally negative definite, choosing for f(h) the exponential ensures that f(\u0393(a \u2192 b)) is a positive definite kernel [18].", "startOffset": 159, "endOffset": 163}, {"referenceID": 6, "context": "We empirically evaluate the effectiveness of some STWK comparatively to Gaussian Radial Basis Function (RBF) Kernels or elastic distance substituting kernels [7] using some classification tasks on a set of times series coming from quite different application fields.", "startOffset": 158, "endOffset": 161}, {"referenceID": 9, "context": "The classification task we have considered consists of assigning one of the possible categories to an unknown time series for the 20 data sets available at UCR repository [10].", "startOffset": 171, "endOffset": 175}, {"referenceID": 3, "context": "\u2022 the second one is a SVM classifier [4], [22] configured with a Gaussian RBF kernel whose parameters are C > 0, a trade off between regularization and constraint violation and \u03c3 that determines the width of the Gaussian function.", "startOffset": 37, "endOffset": 40}, {"referenceID": 14, "context": "For \u03b4erp, \u03b4twed, STWKerp and STWKtwed we used the L1-norm, while the L2-norm has been implemented for \u03b4dtw and STWKdtw, a classical choice for DTW [15].", "startOffset": 147, "endOffset": 151}, {"referenceID": 8, "context": "Following the works on convolution kernels [9] and local alignment kernels defined for strings processing around the Smith and Waterman algorithm [20] [16], we summative time warp kernels (STWK) applicable for string and time series processing.", "startOffset": 43, "endOffset": 46}, {"referenceID": 19, "context": "Following the works on convolution kernels [9] and local alignment kernels defined for strings processing around the Smith and Waterman algorithm [20] [16], we summative time warp kernels (STWK) applicable for string and time series processing.", "startOffset": 146, "endOffset": 150}, {"referenceID": 15, "context": "Following the works on convolution kernels [9] and local alignment kernels defined for strings processing around the Smith and Waterman algorithm [20] [16], we summative time warp kernels (STWK) applicable for string and time series processing.", "startOffset": 151, "endOffset": 155}, {"referenceID": 2, "context": "As \u22c6 is either the addition or the multiplication and as positive definite kernels are closed under summation or multiplication [3], all this terms are positive.", "startOffset": 128, "endOffset": 131}], "year": 2017, "abstractText": "This paper proposes some extensions to the work on kernels dedicated to string alignment (biological sequence alignment) based on the summing up of scores obtained by local alignments with gaps. The extensions we propose allow to construct, from classical time warp distances, what we called summative time warp kernels that are positive definite if some simple sufficient conditions are satisfied. Furthermore, from the same formalism, we derive a time warp inner product that extend the usual euclidean inner product, providing the capability to handle discrete sequences or time series of variable lengths in an Hilbert space. The classification experiment we conducted, using either first near neighbor classifier or Support Vector Machine classifier leads to conclude that the positive definite elastic kernels we propose outperform the distance substituting kernels for the classical elastic distances we tested. In a similar way, the kernel based on the distance induced by the time warp inner product outperforms significantly on the considered task the kernel based on the euclidean distance.", "creator": "LaTeX with hyperref package"}}}