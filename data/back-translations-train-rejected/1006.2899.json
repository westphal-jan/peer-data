{"id": "1006.2899", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2010", "title": "Approximated Structured Prediction for Learning Large Scale Graphical Models", "abstract": "In this paper we propose an approximated structured prediction framework for large scale graphical models and derive message-passing algorithms for learning their parameters efficiently. We first relate CRFs and structured SVMs and show that in CRFs a variant of the log-partition function, known as soft-max, smoothly approximates the hinge loss function of structured SVMs. We then propose an intuitive approximation for the structured prediction problem, using duality, based on local entropy approximations and derive an efficient message-passing algorithm that is guaranteed to converge to the optimum for concave entropy approximations. Unlike existing approaches, this allows us to learn efficiently graphical models with cycles and very large number of parameters. We demonstrate the effectiveness of our approach in an image denoising task. This task was previously solved by sharing parameters across cliques. In contrast, our algorithm is able to efficiently learn large number of parameters resulting in orders of magnitude better prediction.", "histories": [["v1", "Tue, 15 Jun 2010 06:55:03 GMT  (968kb,D)", "https://arxiv.org/abs/1006.2899v1", null], ["v2", "Mon, 9 Jul 2012 18:22:27 GMT  (14kb)", "http://arxiv.org/abs/1006.2899v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["tamir hazan", "raquel urtasun"], "accepted": false, "id": "1006.2899"}, "pdf": {"name": "1006.2899.pdf", "metadata": {"source": "CRF", "title": "Approximated Structured Prediction for Learning Large Scale Graphical Models", "authors": ["Tamir Hazan", "Raquel Urtasun"], "emails": ["hazan@ttic.edu", "rurtasun@ttic.edu"], "sections": [{"heading": null, "text": "ar Xiv: 100 6.28 99v2 [cs.LG] 9 Jul 201 2"}, {"heading": "Approximated Structured Prediction for Learning Large Scale Graphical Models", "text": "Tamir Hazan TTI Chicagohazan @ ttic.eduRaquel Urtasun TTI Chicagorurtasun @ ttic.eduThis manuscript contains the evidence for \"A Primal Dual Message Passing Algorithm for Approximated, Large Scale Structured Prediction\" claim 1 (2), the dual program of structured prediction program in claim 1 (3), the formmax px, y (y), the formmax px, the formmax px, y (x), Y (x), x (x), y), S (px, y), S (px), x), the formmax px (x, y), the formmax px (x, y), the formmax px (x, y), Y (x), Y (x), y (x), x (x), x (x), x, x, x, x, the formmax (x), x, x, the (x, x, x, x, x, x, x, the, max, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x (x), x (x), x (x), x (x), x (x, x, x, x), x (x, x, x), x (x, x, x), x), x (x), x, x, x (x, x), x (x), x, x (x), x), x, x, x (x), x, x, x, x, x (x, x, x), x), x, x, x, x, x (x), x, x, x, x (x, x, x, x, x, x), x (x), x, x, x, x, x, x, x, x, x, x, x, x (x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x,"}], "references": [{"title": "Convex Analysis and Optimization", "author": ["D.P. Bertsekas", "A. Nedi\u0107", "A.E. Ozdaglar"], "venue": "Athena Scientific,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "Convex analysis", "author": ["R.T. Rockafellar"], "venue": "Princeton university press,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1970}, {"title": "Relaxation methods for problems with strictly convex separable costs and linear constraints", "author": ["P. Tseng", "D.P. Bertsekas"], "venue": "Mathematical Programming,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1987}, {"title": "Graphical models, exponential families, and variational inference", "author": ["M.J. Wainwright", "M.I. Jordan"], "venue": "Foundations and Trends R \u00a9 in Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}], "referenceMentions": [{"referenceID": 3, "context": "[4] Theorem 8.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2]), where in our case z = \u2211 (x,y),\u0177 px,y(\u0177)\u03a6(x, \u0177)\u2212 d.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1], Theorem 4.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1], Theorem 4.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "The claim properties are a direct consequence of [3] for this type of programs.", "startOffset": 49, "endOffset": 52}], "year": 2012, "abstractText": "and composed from the conjugate dual of the soft-max and the conjugate dual of the lp norm. Recall that the conjugate dual for the soft-max is the entropy barrier \u01ebH(px,y) over the set of probability distributions \u2206Y (cf. [4] Theorem 8.1), and that the linear shift of the soft-max argument by ey(\u0177) result in the linear shift of the conjugate dual, thus we get the first part of the dual function \u2211 (x,y)(\u01ebH(px,y) + e \u22a4 y px,y). Similarly, the conjugate dual of 1 p \u2016\u03b8\u2016p is 1 q \u2016z\u2016q for the dual norm 1/p+ 1/q = 1 (cf. [2]), where in our case z = \u2211 (x,y),\u0177 px,y(\u0177)\u03a6(x, \u0177)\u2212 d. Theorem 1 The approximation of the structured prediction program in (3) takes the form min \u03bbx,y,v\u2192\u03b1,\u03b8 \u2211", "creator": "LaTeX with hyperref package"}}}