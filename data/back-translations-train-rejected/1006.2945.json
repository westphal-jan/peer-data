{"id": "1006.2945", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2010", "title": "Two-Timescale Learning Using Idiotypic Behaviour Mediation For A Navigating Mobile Robot", "abstract": "A combined Short-Term Learning (STL) and Long-Term Learning (LTL) approach to solving mobile-robot navigation problems is presented and tested in both the real and virtual domains. The LTL phase consists of rapid simulations that use a Genetic Algorithm to derive diverse sets of behaviours, encoded as variable sets of attributes, and the STL phase is an idiotypic Artificial Immune System. Results from the LTL phase show that sets of behaviours develop very rapidly, and significantly greater diversity is obtained when multiple autonomous populations are used, rather than a single one. The architecture is assessed under various scenarios, including removal of the LTL phase and switching off the idiotypic mechanism in the STL phase. The comparisons provide substantial evidence that the best option is the inclusion of both the LTL phase and the idiotypic system. In addition, this paper shows that structurally different environments can be used for the two phases without compromising transferability.", "histories": [["v1", "Tue, 15 Jun 2010 10:17:21 GMT  (326kb)", "http://arxiv.org/abs/1006.2945v1", "40 pages, 12 tables, Journal of Applied Soft Computing"]], "COMMENTS": "40 pages, 12 tables, Journal of Applied Soft Computing", "reviews": [], "SUBJECTS": "cs.AI cs.NE cs.RO", "authors": ["amanda whitbrook", "uwe aickelin", "jonathan m garibaldi"], "accepted": false, "id": "1006.2945"}, "pdf": {"name": "1006.2945.pdf", "metadata": {"source": "CRF", "title": "TWO-TIMESCALE LEARNING USING IDIOTYPIC BEHAVIOUR MEDIATION FOR A NAVIGATING MOBILE ROBOT", "authors": ["Amanda M. Whitbrook", "Uwe Aickelin", "Jonathan M. Garibaldi"], "emails": ["jmg}@cs.nott.ac.uk"], "sections": [{"heading": null, "text": "The LTL phase consists of fast simulations that use a genetic algorithm to derive different behaviors encoded as variable sets of attributes, and the STL phase is an idiotypic artificial immune system. Results from the LTL phase show that behaviors evolve very quickly and significantly greater diversity is achieved when multiple autonomous populations are used, rather than just one. Architecture is evaluated under various scenarios, including the removal of the LTL phase and the elimination of the idiotypic mechanism in the STL phase. The comparisons provide important evidence that the best option is the inclusion of both the LTL phase and the idiotypic system. Furthermore, this work shows that structurally different environments can be used for the two phases without compromising systems."}, {"heading": "1 INTRODUCTION", "text": "An important decision in designing effective controllers for mobile robots is how much a priori knowledge should be allocated to them. Should they try to learn all the behaviors during the task, or should they start with a series of prefabricated actions? Both alternatives have significant disadvantages, as the robot has to go through a learning phase in which it is also at risk. However, if it relies solely on predetermined behavior, it has no capacity for learning and adaptation. The architecture is inspired by the vertebrate immune system to overcome these problems."}, {"heading": "2 BACKGROUND AND MOTIVATION", "text": "This year, it has reached the point where it will be able to leave the country without being able to leave it."}, {"heading": "3 TEST ENVIRONMENTS AND PROBLEMS", "text": "In fact, the fact is that most of them will be able to feel as if they are able to move, and that they will be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to move."}, {"heading": "4 LONG-TERM LEARNING (GA) SYSTEM ARCHITECTURE", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Antigens and Antibodies", "text": "There are only two basic types of antigen, whether the target is visible (a \"target\" type) and whether an obstacle is nearby (an \"obstacle\" type), with the latter taking precedence over the former. An obstacle is detected if the IR sensor with the maximum reading Imax has a value of Vmax of 250 or more. If this is the case, the antigen is of the type \"obstacle,\" and the antigen is further classified in terms of the distance of the obstacle from and its orientation towards the robot. Distance is \"near\" if Vmax is between 250 (about 0.03 m) and 2400 (about 0.01 m), and \"collision\" if Vmax is 2400 or more. The IR sensors correspond to the quantity of reflected light, so that higher readings mean narrower obstacles that the orientation is \"right\" if Imax sensor is 0, 1 or 2, \"back\" if they are 3 or 4 and left, \"if it is seven or seven)."}, {"heading": "4.2 GA System Structure", "text": "The GA control program uses the two-dimensional array of behaviors Bij, i = 0,..., x-1, j = 0,..., y-1, where x is the number of robots in the population (x \u2265 5) and y is the number of antigens, i.e. eight. When the program starts, it is zero, and the array is set to zero. Infrared sensors are read every 192 milliseconds, but the camera is read only when no obstacles are found, as this increases computing efficiency. As soon as an antigen code is detected, a behavior or antibody is created to deal with it by randomly selecting a behavior type and its attribute values. For example, the behavior WANDER _ SINGLE (605, 50, 90, LEFT, NULL) can be constructed. This behavior consists of traveling forward at a speed of 605 speed units / s, but by reducing the speed of the left wheel by 90%."}, {"heading": "4.3 GA Details", "text": "Two different parent robots are selected by the roulette wheel method and each of the x pairs mixes to create x children robots (x is the number of robots in the population).The process involves assigning attribute values to each of the infant robots for each of the eight antigens in the system. It can take the form of a complete antibody exchange, the adoption of attribute values from only one parent or a cross between both parents and a mutation of the attribute value. \u2022 The complete antibody exchange takes place according to the prescribed mutation rate \u03b5. Here, the infant robot is assigned a completely new random behavior for the respective antigen, i.e. both parent behaviors are ignored. \u2022 Crossover is used when there is no complete replacement, and the method used depends on whether the behavior of the parent is of the same antibody type."}, {"heading": "4.4 Reinforcement Learning in the Long-Term Learning Phase", "text": "Reinforcement Learning (RL) is used to accelerate GA convergence, and works by comparing current and previous antibody codes to determine the effectiveness of the behavior. Ten points are awarded for each positive change in the environment, and ten points are subtracted for each negative change. Table 4 shows the possible antigen code combinations, and column 3 shows the points added or subtracted in the LTL phase. For example, 20 points are awarded if the antigen code changes from an \"obstacle type\" to a \"seen target\" because the robot has moved away from an obstacle and has reached or kept an eye on the target. \"In the case that the antigen code remains at 1 (the target is kept in mind), the awarded score depends on how the orientation of the target has moved with respect to the robot. In addition, if an obstacle is detected in both the current and previous iteration,\" the maximum number of points in the next iteration is then determined by the next iteration, and the max number of changes in the next iteration, including multiple factors."}, {"heading": "5 SHORT-TERM LEARNING (AIS) SYSTEM ARCHITECTURE", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Creating the Paratope and Idiotope Matrices", "text": "The GA selects the five fittest robots of the last generation, so that five different sets of antibodies are used as soon as the relative fitness values are calculated. Each set consists of eight behaviours, i.e. one antibody for each antigen. Therefore, the 40 antibodies in the system can be represented as Aij, i = 0,..., v-1, j = 0,..., y-1, where v is the number of sets and y is the number of antibodies. However, the antibody types developed and the associated attribute values, the task fulfilment times L Ci are taken directly from the file generated in the LTL phase. The STL phase calculates the relative fitness of each antibody set S \u00b5i:,] [1 0 1 0 0 1 - \u2212 = v ki i S ff \u00b5 (3) using (2) the antibody values set to 8, in order to give the antibodies an approximately equal weight in comparison to the task time, no point is accepted because this is permissible."}, {"heading": "5.2 Antibody Selection Process", "text": "At the beginning of the STL phase, each antibody has 1000 clones in the system, but the numbers fluctuate specifically according to a variation in the Farmer equation:), 1 (3) () 1 (kNbSN ttt imimimim \u2212 + = + (7), where Nim represents the number of clones of each antibody corresponding to the penetrating antigen m, Sim is the current strength match of each of these antibodies with m \u2212 b is a scaling constant and k3 is the mortality rate constant. Consequently, the concentration of each antibody in the system changes accordingly: 1 0 1 0 0 0. - = = = Antibody match with each of these antibodies-C (8), where another scaling factor can be used to control the level of antibody stimulation and suppression (25 is used here)."}, {"heading": "5.3 Reinforcement Learning within the Short-Term Learning Phase", "text": "In the STL phase, the RL values are scaled to one hundredth of the values used for the LTL phase (see column 4 of Table 4), because the RL is closely linked to the idiotypic selection process and greater values would lead to over-stimulation and over-suppression. In addition, a reward is granted if no obstacles arise and penalties are imposed if they are. This is in contrast to the LTL case, where no reward or punishment is given and which is necessary to increase the flow of the system. In the LTL, neutral values are permitted because there is sufficient time to develop good strategies, but in the STL, the idiotypic system must remain in a state of flow if suppression and stimulation are to occur at all. The maximum cumulative RL score (or Pij value) is permissible because the minimum Pij value is 0.00. Pij values are also adjusted if the anotype code is detected, which means that the robot will not spend more than 250 IDs."}, {"heading": "6 EXPERIMENTAL PROCEDURES AND RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Long-Term Learning General Procedures", "text": "GA is performed in worlds 1 and 2 with individual populations of 25, 40 and 50 robots and with five autonomous populations of five, eight and ten. A mutation rate \u03b5 of 5% is used throughout, as previous studies have shown that this represents a good compromise between fast convergence, high diversity and good solution quality. Solution quality L q is taken as half of the absolute fitness value (2) at B = 8 to give approximately the same weighting to the collisions. For each scenario, ten repetitions are performed and the means of convergence time \u03c4, solution quality L q and diversity in type ZU and speed ZS (see section 6.2) are recorded."}, {"heading": "6.2 Measuring Antibody Diversity", "text": "Antibody diversity is measured by the characteristics U and velocity S, as these are the only action-controlling characteristics common to all behaviors; the final antibodies are grouped by the number of antigen, and the groups are evaluated by comparing each of the five members with the others, i.e. ten pairs of comparisons of the same value are made in each group; one point is awarded for each comparison if the attribute values are different; if they are equal, no points are awarded; for example, the behavioral types [1 3 4 4 1] are compared in pairs with the same value, so eight points. Table 5 summarizes possible attribute-value combinations and the result of performing the paired comparisons on them; the individual diversity values for each of U and S are added and divided to obtain a diversity value for each attribute, so eight points. Here, the expected diversity value for a large number of randomly selected groups of five antibodies is summarized."}, {"heading": "6.3 Long-Term Learning Phase Results", "text": "The programs being compared use the same number of robots, for example, a single population of 25 is compared with five populations of five. Tables show that for both worlds, there are no significant differences between the convergence times when the individual and multiple populations are compared. Furthermore, speed diversity is significantly better for the different populations in all cases. Multiple populations always show a speed diversity of 100%, suggesting that the ultimately selected genes are completely independent of each other, as expected. In contrast, speed diversity of the individual population never reaches 100%, as there are repeated genes in the ultimately selected robots. Evidence from previous experiments with individual populations of five, ten and 20 suggests that the level of gene duplication decreases as the population grows. This explains the lower ZU and ZS values for a population of 25 robots."}, {"heading": "6.4 Short-Term Learning General Procedures", "text": "Pre-trials have shown that the antibody sets from the above LTL experiments produce a higher number of collisions compared to a handmade controller when used to restart the AIS in Worlds 3 and 4. Since the handmade controller is dealing with much slower speeds, the GA in World 1 will be restarted with five autonomous populations of ten robots and with the upper limit of the static antibody reduced to 100 speed units / s, and the lower speed limit of the reverse antibody will be reduced to 300 speed units / s. Stopping criteria will also be simplified to g > 0 AND L Tg < 500 AND L Cg < 25 OR g > 30 to allow for the overall increase in task time. Thirty STL experiments will be performed in each of the two simulated worlds, World 3 and World 4, and 20 will be completed in the real world."}, {"heading": "6.5 Short-Term Learning Phase Results", "text": "It shows the mean S C, S T, and S q values for each of the systems in each of the worlds, and Table 9 presents the significant difference levels when comparing the systems. Table 10 highlights the error rates, which indicate the percentage of failures due to an excessive number of collisions, but the unsaturated systems are significantly better in all cases, i.e. for all the metrics, in all worlds the idiotype system proves to be better in terms of fewer collisions, a faster completion time, and a higher qualitative solution. When comparing with the unsaturated systems, it is significantly better in all cases, i.e. the metrics, in all worlds, regardless of whether the unsaturated systems use idiotype effects, or the random behavior is set. The saturated idiotype systems also exceed the tradable systems in all cases, i.e. for all the metrics that are not the metrics, the idiotype systems, the worlds that are formed and the untyped systems, the worlds in which and the untyped systems, and the worlds in which are formed."}, {"heading": "6.6 Representation of the Antigen Space", "text": "The aforementioned brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated brainless consecrated cnllcnlcnnnnnnnnnnnnnnnnnllllllllllllllnlllllllllllnllnlllnllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll"}, {"heading": "6.7 Discussion", "text": "The observations detailed in Section 6.5 provide very strong statistical evidence to support H1, i.e. they defend the idea that seed seeding schemes outperform non-seeding schemes. Results also confirm H2, since the performance of the robot seems to be further enhanced by the inclusion of an idiotypical network in the STL architecture. In the seed idiotypic system, the seed system has the same initial knowledge, but relies only on RL for adaptation, so it is less flexible how to begin the task, and the idiotypic AIS allows it to change and adapt its behavior as needed. Without idiotypical effects, the seed system has the same initial knowledge, but relies only on RL for adaptation, so it is less flexible when the unseeded systems are compared in this way, there is no significant difference. This is because the untypical phase of the search process is likely to have a lot of untypical search space even if the initial knowledge of the STL is used and it is very large in view of the STL."}, {"heading": "7 CONCLUSIONS", "text": "This paper describes the fusion of LTL (an accelerated CLA) with STL (an idiotypic AIS) to provide the AIS with a range of very different behaviors that can work together to solve a target finding problem between mobile and robots. It describes the unique antibody coding and the GA method used to develop the original antibody set, and shows that significantly higher antibody diversity can be achieved when using a number of autonomous populations rather than a single one. Furthermore, the GA can be performed for five autonomous populations without significantly increasing the convergence time or decreasing the solution quality, and the diversity assessments do not appear to be affected by the difficulty of the problem. The LTL system has proven to be able to deliver the starting antibodies performed in a realistic time frame, i.e. within approximately ten minutes in a static world, and within approximately 25 minutes in a dynamic world, the STL anticles are already performing better than the ones already performed in a number of perquities."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work was funded by the UK Government's Engineering and Physical Sciences Research Council (EPSCRC)."}], "references": [{"title": "Artificial life and real robots", "author": ["R.A. Brooks"], "venue": "Toward a Practice of Autonomous Systems, Proc. of the First European Conf. on Artificial Life,", "citeRegEx": "Brooks,? \\Q1992\\E", "shortCiteRegEx": "Brooks", "year": 1992}, {"title": "Robot Error Detection Using an Artificial Immune System", "author": ["R. Canham", "A.H. Jackson", "A. Tyrell"], "venue": "in: Proc. of the NASA/DoD Conf. on Evolvable Hardware,", "citeRegEx": "Canham et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Canham et al\\.", "year": 2003}, {"title": "The immune system, adaptation, and machine learning, Physica, D", "author": ["J.D. Farmer", "N.H. Packard", "A. S", "Perelson"], "venue": null, "citeRegEx": "Farmer et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Farmer et al\\.", "year": 1986}, {"title": "Evolution of homing navigation in a real mobile robot", "author": ["D. Floreano", "F. Mondada"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics- Part B: Cybernetics,", "citeRegEx": "Floreano and Mondada,? \\Q1996\\E", "shortCiteRegEx": "Floreano and Mondada", "year": 1996}, {"title": "A role for immunology in \u2018next generation\u2019 robot controllers", "author": ["E. Hart", "P. Ross", "A. Webb", "A. Lawson"], "venue": "in: Proc. of the 2nd International Conf. on Artificial Immune Systems,", "citeRegEx": "Hart et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hart et al\\.", "year": 2003}, {"title": "Evolving robust gaits with AIBO", "author": ["G. Hornby", "S. Takamura", "J. Yokono", "O. Hanagata", "T. Yamamoto", "M. Fujita"], "venue": "in: Proc. of the IEEE International Conf. on Robotics and Automation (ICRA),", "citeRegEx": "Hornby et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Hornby et al\\.", "year": 2000}, {"title": "Towards a network theory of the immune system", "author": ["N.K. Jerne"], "venue": "Ann. Immunol. (Inst Pasteur),", "citeRegEx": "Jerne,? \\Q1974\\E", "shortCiteRegEx": "Jerne", "year": 1974}, {"title": "Comparison between an offline model-free and an on-line model-based evolution applied to a robotics navigation system using evolvable hardware", "author": ["D. Keymeulen", "M. Iwata", "Y. Kuniyoshi", "T. Higuchi"], "venue": "in: Proc. of the 6th International Conf. on Artificial Life,", "citeRegEx": "Keymeulen et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Keymeulen et al\\.", "year": 1998}, {"title": "AIS based robot navigation in a rescue", "author": ["M. Krautmacher", "W. Dilger"], "venue": "scenario, in: Proc. of the 3rd International Conf. on Artificial Immune Systems,", "citeRegEx": "Krautmacher and Dilger,? \\Q2004\\E", "shortCiteRegEx": "Krautmacher and Dilger", "year": 2004}, {"title": "Reactive immune network based mobile robot navigation", "author": ["G.C. Luh", "Gand W.W. Liu"], "venue": "in: Proc. of the 3rd International Conf. on Artificial Immune Systems,", "citeRegEx": "Luh and Liu,? \\Q2004\\E", "shortCiteRegEx": "Luh and Liu", "year": 2004}, {"title": "Cyberbotics Ltd \u2013 WebotsTM: Professional Mobile Robot Simulation", "author": ["O. Michel"], "venue": "International Journal of Advanced Robotic Systems,", "citeRegEx": "Michel,? \\Q2004\\E", "shortCiteRegEx": "Michel", "year": 2004}, {"title": "Decentralized control system for autonomous navigation based on an evolved artificial immune network", "author": ["R. Michelan", "F.J. Von Zuben"], "venue": "in: Proc. of the 2002 Congress on Evolutionary Computation,", "citeRegEx": "Michelan and Zuben,? \\Q2002\\E", "shortCiteRegEx": "Michelan and Zuben", "year": 2002}, {"title": "Timidity: A useful mechanism for robot control", "author": ["M.J. Neal", "J. Timmis"], "venue": null, "citeRegEx": "Neal and Timmis,? \\Q2003\\E", "shortCiteRegEx": "Neal and Timmis", "year": 2003}, {"title": "The balance between initial training and life-long adaptation in evolving robot controllers", "author": ["J.H. Walker", "S.M. Garrett", "M.S. Wilson"], "venue": "IEEE Transactions on Systems, Man and Cybernetics- Part B: Cybernetics,", "citeRegEx": "Walker et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Walker et al\\.", "year": 2006}, {"title": "Emergent construction of behavior arbitration mechanism based on the immune system", "author": ["Y. Watanabe", "A. Ishiguro", "Y. Shirai", "Y. Uchikawa"], "venue": "in: Proc. of the 1998 IEEE International Conf. on Evolutionary Computation,", "citeRegEx": "Watanabe et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Watanabe et al\\.", "year": 1998}, {"title": "Evolutionary construction of an immune network-based behavior arbitration mechanism for autonomous mobile robots, Electrical Engineering in Japan", "author": ["Y. Watanabe", "T. Kondo", "A. Ishiguro", "Y. Shirai", "Y. Uchikawa"], "venue": null, "citeRegEx": "Watanabe et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Watanabe et al\\.", "year": 1998}, {"title": "Idiotypic Immune Networks in Mobile Robot Control", "author": ["A.M. Whitbrook", "U. Aickelin", "J.M. Garibaldi"], "venue": "IEEE Transactions on Systems, Man and CyberneticsPart B: Cybernetics,", "citeRegEx": "Whitbrook et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Whitbrook et al\\.", "year": 2007}, {"title": "Genetic-Algorithm Seeding of Idiotypic Networks for Mobile-Robot Navigation", "author": ["A.M. Whitbrook", "U. Aickelin", "J.M. Garibaldi"], "venue": "in: Proc. the 5th International Conf. on Informatics in Control, Automation and Robotics,", "citeRegEx": "Whitbrook et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Whitbrook et al\\.", "year": 2008}, {"title": "An Idiotypic Immune Network as a Short-Term Learning Architecture for Mobile Robots", "author": ["A.M. Whitbrook", "U. Aickelin", "J.M. Garibaldi"], "venue": "in: Proc. of the 7th International Conf. on Artificial Immune Systems,", "citeRegEx": "Whitbrook et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Whitbrook et al\\.", "year": 2008}, {"title": "Evolving dynamic gaits on a physical robot", "author": ["V. Zykov", "J. Bongard", "H. Lipson"], "venue": "in: Proc. of The Genetic and Evolutionary Computation Conf. (GECCO),", "citeRegEx": "Zykov et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Zykov et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 6, "context": "antigen matching is selected for the AIS system, and Farmer\u2019s computational model (Farmer 1986) of Jerne\u2019s idiotypic-network theory (Jerne 1974) is adopted.", "startOffset": 132, "endOffset": 144}, {"referenceID": 1, "context": "(Canham et al. 2003) and software (Neal and Timmis 2003) robotics.", "startOffset": 0, "endOffset": 20}, {"referenceID": 12, "context": "2003) and software (Neal and Timmis 2003) robotics.", "startOffset": 19, "endOffset": 41}, {"referenceID": 1, "context": "(Canham et al. 2003) and software (Neal and Timmis 2003) robotics. However, the most popular robotics software model has been the idiotypic network, based on Farmer\u2019s model of continuous antibody-concentration change. In this model the concentrations are not only dependent upon past matching to antigens, they also depend on the other antibodies present in the system, i.e. antibodies are continually suppressed and stimulated by each other as well as being stimulated by antigens. In theory this design permits great variability of robot behaviour since the antibody that best matches the invading antigen is not necessarily selected for execution; the complex dynamics of stimulation and suppression ensure that suitable alternative antibodies are tried when the need arises (see Whitbrook et al. 2007). However, past work in this area has mostly focused on how the antibodies in the network should be connected and, for simplicity, has used a single set of preengineered behaviours for the antibodies, which limits the potential of the method. For example, Watanabe et al. (1998a and 1998b) use an idiotypic network to control a garbage-collecting robot. Their antibodies are composed of a precondition, a behaviour, and an idiotope part that defines antibody connection. However, the sets of possible behaviours and preconditions are fixed, and only the idiotope part is evolved. Michelan and Von Zuben (2002) and Vargas et al.", "startOffset": 1, "endOffset": 1415}, {"referenceID": 1, "context": "(Canham et al. 2003) and software (Neal and Timmis 2003) robotics. However, the most popular robotics software model has been the idiotypic network, based on Farmer\u2019s model of continuous antibody-concentration change. In this model the concentrations are not only dependent upon past matching to antigens, they also depend on the other antibodies present in the system, i.e. antibodies are continually suppressed and stimulated by each other as well as being stimulated by antigens. In theory this design permits great variability of robot behaviour since the antibody that best matches the invading antigen is not necessarily selected for execution; the complex dynamics of stimulation and suppression ensure that suitable alternative antibodies are tried when the need arises (see Whitbrook et al. 2007). However, past work in this area has mostly focused on how the antibodies in the network should be connected and, for simplicity, has used a single set of preengineered behaviours for the antibodies, which limits the potential of the method. For example, Watanabe et al. (1998a and 1998b) use an idiotypic network to control a garbage-collecting robot. Their antibodies are composed of a precondition, a behaviour, and an idiotope part that defines antibody connection. However, the sets of possible behaviours and preconditions are fixed, and only the idiotope part is evolved. Michelan and Von Zuben (2002) and Vargas et al. (2003) also use GAs, but again only the idiotypic-network connections are derived.", "startOffset": 1, "endOffset": 1440}, {"referenceID": 1, "context": "(Canham et al. 2003) and software (Neal and Timmis 2003) robotics. However, the most popular robotics software model has been the idiotypic network, based on Farmer\u2019s model of continuous antibody-concentration change. In this model the concentrations are not only dependent upon past matching to antigens, they also depend on the other antibodies present in the system, i.e. antibodies are continually suppressed and stimulated by each other as well as being stimulated by antigens. In theory this design permits great variability of robot behaviour since the antibody that best matches the invading antigen is not necessarily selected for execution; the complex dynamics of stimulation and suppression ensure that suitable alternative antibodies are tried when the need arises (see Whitbrook et al. 2007). However, past work in this area has mostly focused on how the antibodies in the network should be connected and, for simplicity, has used a single set of preengineered behaviours for the antibodies, which limits the potential of the method. For example, Watanabe et al. (1998a and 1998b) use an idiotypic network to control a garbage-collecting robot. Their antibodies are composed of a precondition, a behaviour, and an idiotope part that defines antibody connection. However, the sets of possible behaviours and preconditions are fixed, and only the idiotope part is evolved. Michelan and Von Zuben (2002) and Vargas et al. (2003) also use GAs, but again only the idiotypic-network connections are derived. Krautmacher and Dilger (2004) apply the idiotypic method to robot navigation, but their emphasis is on the use of a", "startOffset": 1, "endOffset": 1546}, {"referenceID": 9, "context": "Luh and Liu (2004) address targetfinding using an idiotypic system, modelling their antibodies as steering directions.", "startOffset": 0, "endOffset": 19}, {"referenceID": 3, "context": "For example, Floreano and Mondada (1996) adopt this approach and report a", "startOffset": 13, "endOffset": 41}, {"referenceID": 5, "context": "More recent evolutionary experiments with physical robots, for example Marocca and Floreano (2002,) Hornby et al. (2000), and Zykov et al.", "startOffset": 100, "endOffset": 121}, {"referenceID": 5, "context": "More recent evolutionary experiments with physical robots, for example Marocca and Floreano (2002,) Hornby et al. (2000), and Zykov et al. (2004) have produced reliable and robust systems, but have not overcome the problems of potential damage and slow, impractical convergence times.", "startOffset": 100, "endOffset": 146}, {"referenceID": 0, "context": "Simulated robots provide a definite advantage for speed of convergence, but the tradeoff is the huge difference between the simulated and real domains (Brooks 1992).", "startOffset": 151, "endOffset": 164}, {"referenceID": 0, "context": "Simulated robots provide a definite advantage for speed of convergence, but the tradeoff is the huge difference between the simulated and real domains (Brooks 1992). Systems that employ an evolutionary training period (LTL) and some form of lifelong adaptation (STL) have been used to try to address the problem of domain differences, for example, Walker et al. (2006) use a GA in the simulated LTL phase and an evolutionary strategy (ES) on the physical robot.", "startOffset": 152, "endOffset": 369}, {"referenceID": 0, "context": "Simulated robots provide a definite advantage for speed of convergence, but the tradeoff is the huge difference between the simulated and real domains (Brooks 1992). Systems that employ an evolutionary training period (LTL) and some form of lifelong adaptation (STL) have been used to try to address the problem of domain differences, for example, Walker et al. (2006) use a GA in the simulated LTL phase and an evolutionary strategy (ES) on the physical robot. They note improved performance when the LTL phase is implemented, and remark that the ES provides continued adaptation to the environment, but they deal with a limited number of behaviour parameters in the GA, and do not state the duration of the LTL phase. Keymeulen et al. (1998) run their LTL and STL phases simultaneously, as the physical robot maps its environment at the same time as carrying out its goal-seeking task, thus creating the simulated world.", "startOffset": 152, "endOffset": 744}, {"referenceID": 10, "context": "For this reason the Webots simulator (Michel 2004) is selected as it is able to run simulations up to 600 times faster than real time, depending on computer power, graphics card, world design and the number and complexity of the robots used.", "startOffset": 37, "endOffset": 50}, {"referenceID": 16, "context": "Further details on the LTL architecture are provided in Whitbrook et al. (2008a).", "startOffset": 56, "endOffset": 81}, {"referenceID": 16, "context": "Here, idiotypic selection is governed by equations (9)-(12), which are based on those in Whitbrook et al. (2007). Equation (9) concerns the increase in strength-of-match value \u03b5im when stimulation occurs,", "startOffset": 89, "endOffset": 113}, {"referenceID": 16, "context": "Further details on the STL architecture are provided in Whitbrook et al. (2008b).", "startOffset": 56, "endOffset": 81}, {"referenceID": 16, "context": "These values are chosen in order to yield a mean idiotypic difference rate of approximately 20%, as suggested in Whitbrook et al. (2007). Note that an idiotypic difference occurs when the antibodies \u03b1 and \u03b2 are different.", "startOffset": 113, "endOffset": 137}], "year": 2010, "abstractText": "A combined Short-Term Learning (STL) and Long-Term Learning (LTL) approach to solving mobile-robot navigation problems is presented and tested in both the real and virtual domains. The LTL phase consists of rapid simulations that use a Genetic Algorithm to derive diverse sets of behaviours, encoded as variable sets of attributes, and the STL phase is an idiotypic Artificial Immune System. Results from the LTL phase show that sets of behaviours develop very rapidly, and significantly greater diversity is obtained when multiple autonomous populations are used, rather than a single one. The architecture is assessed under various scenarios, including removal of the LTL phase and switching off the idiotypic mechanism in the STL phase. The comparisons provide substantial evidence that the best option is the inclusion of both the LTL phase and the idiotypic system. In addition, this paper shows that structurally different environments can be used for the two phases without compromising transferability.", "creator": "PrimoPDF http://www.primopdf.com/"}}}