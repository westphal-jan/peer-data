{"id": "1006.3035", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2010", "title": "Products of Weighted Logic Programs", "abstract": "Weighted logic programming, a generalization of bottom-up logic programming, is a well-suited framework for specifying dynamic programming algorithms. In this setting, proofs correspond to the algorithm's output space, such as a path through a graph or a grammatical derivation, and are given a real-valued score (often interpreted as a probability) that depends on the real weights of the base axioms used in the proof. The desired output is a function over all possible proofs, such as a sum of scores or an optimal score. We describe the PRODUCT transformation, which can merge two weighted logic programs into a new one. The resulting program optimizes a product of proof scores from the original programs, constituting a scoring function known in machine learning as a ``product of experts.'' Through the addition of intuitive constraining side conditions, we show that several important dynamic programming algorithms can be derived by applying PRODUCT to weighted logic programs corresponding to simpler weighted logic programs. In addition, we show how the computation of Kullback-Leibler divergence, an information-theoretic measure, can be interpreted using PRODUCT.", "histories": [["v1", "Tue, 15 Jun 2010 17:22:55 GMT  (4322kb,DS)", "http://arxiv.org/abs/1006.3035v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.PL", "authors": ["shay b cohen", "robert j simmons", "noah a smith"], "accepted": false, "id": "1006.3035"}, "pdf": {"name": "1006.3035.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["SHAY B. COHEN", "ROBERT J. SIMMONS", "NOAH A. SMITH", "Shay B. Cohen", "Robert J. Simmons", "Noah A. Smith"], "emails": ["scohen@cs.cmu.edu", "rjsimmon@cs.cmu.edu", "nasmith@cs.cmu.edu"], "sections": [{"heading": null, "text": "Key concepts: weighted logic programming, program transformations, natural language processing"}, {"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Weighted Logic Programming", "text": "To motivate weighted logic programming, we start with a logic program for connectivity of single sources based on a directed graph, shown in Figure 1. In the usual bottom-up interpretation of this program, an initial database (i.e. a set of axioms) would describe the edge relationship and one (or more) starting points as beginning axioms (a) for some a. Repeated forward conclusions can then be applied to the rules in Figure 1 to find the least closed database under these rules. In traditional logic programming, however, this program can only be understood as a program that calculates connectivity over a graph. In weighted logic programming, we generalize traditional logic programming. In traditional logic programming, a proof is a tree of valid (deductive) conclusions from axioms, and a valid atomic proposition is one that has at least one single proof. In weighted logic programming, \"instead of generalizing these sources, we generalize these axions,\" and \"Axioms\" are valid."}, {"heading": "2.1 Non-Boolean Programs", "text": "In Figure 3, each axiom of the shape edge (X, Y) is a value underlying the costs associated with that edge in the graph, and the axiom initial (a) is then the value 0. If we take the value or \"score\" of a proof to be the sum of the values that the axioms have on their sheets and assume the value of a suggestion to be the minimum score over all possible proofs, then the program from Figure 1 gives a declarative specification of the individual source categories of the shortest path problem. Multiple applications of an axiom in a proof are significant: if a proof includes the edge (d), it corresponds to a single crossing of the loop from d to d and adds the cost of 2, and if a proof the axiom twice the cost of the 4.We replace the connecting lines (d)."}, {"heading": "2.2 Formal Definition", "text": "This year, the time has come for us to find a solution that is able to find a solution, that is able to find a solution, that is able to find a solution, and that is able to find a solution that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution. \""}, {"heading": "3 Weighted Logic Programs and Probabilistic Reasoning", "text": "In this section, we will again focus on the probabilistic interpretation of weighted logic programs, which we first described in the introduction. In \u00a7 3.1, we will describe in more detail how the results of weighted logic programs are interpreted as probabilities - readers with a background in statistics and machine learning will probably be able to skip or skip this section. In \u00a7 3.2, we will present the presentation of an expert product that motivates the PRODUCT transformation. Our running example for this section is a probabilistic finite state automaton via the alphabet {0, 1}, as in Figure 6. The most likely path through the graph is the one that recognizes the string \"01\" by going through the states a, b, and c, and that the probability of this path is 0.4. Unlike the labels on the edges, this is the same constellation used in the example of graph accessibility from Figure 4. The edge predicate from the previous section is now represented by an arc, and the argument has been expanded to include a third."}, {"heading": "3.1 The Probabilistic Interpretation of Weighted Logic Programming", "text": "In this case, I would correspond to one of the various possible sentences recognized by the FSA (i.e., 00, 01, 10, and 11). A corresponds to a particular directed graph with weighted edges encoded by a series of axioms. In this case, it corresponds to one of the various possible sentences recognized by the FSA (i.e., 00, 01, 10, and 11). A corresponds to a particular directed graph with weighted edges encoded by a series of axioms. P corresponds to an individual proof / path through graph 7, which is the direct adaptation of the accessibility program in Figure 5 to marked edges, the value of the target in the most likely path semiring is maxproof p (P = sentence | A = graph graph) - the value of the most likely accessibility program in Figure 5, which we represent the value of the target in the most likely path-marked sentence."}, {"heading": "3.2 Products of Experts", "text": "Of current interest are probability models p that take a factorial form, for example: p = y = x = p1 (Y = y | x) \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 pn (Y = y | X = x) (13), where the probability of an event under p is literally \"proportional\" and suppresses the means by which the probability distribution is extrapolated to one. (This type of model is called the product of experts (Hinton 2002). Intuitively, the probability of an event under p can only be relatively high if \"all experts agree,\" i.e. if the probability is high under each of the Pi.) Any single expert can make an event arbitrarily unlikely (even impossible) by making it very likely, and the solution of Equation 12 is for a product of expert model that is the least objective."}, {"heading": "4 Products of Weighted Logic Programs", "text": "In this section, we will motivate the products of weighted logic programs in the context of the ongoing example of the general accessibility of graphs, precisely define the PRODUCT transformation, and describe the process of specifying new algorithms as limited versions of product programs. PRODUCT transformation can be seen as an example of tupling transformation in combination with an unfolding / folding transformation (Pettorossi and Proietti 1994; Pettorossi 1999) that preserves the importance of programs. However, we are not interested in this transformation for efficiency reasons, but because it has the effect of revealing the common structure of the two individual programs in such a way that by manually adding constraints, we can force the two original programs to optimize via the same structures, thereby implementing optimization via the product by experts, as described in the previous section."}, {"heading": "4.1 The Product of Graph Reachability Experts", "text": "In this context, the question must also be asked to what extent the question of the amount of the compensation is actually a compensation which depends on the amount of the compensation, which depends on the amount of the compensation. In this case, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the compensation, the amount of the amount of the compensation, the amount of the compensation, the amount of the amount of the compensation, the amount of the compensation, the amount of the amount of the compensation, the amount of the amount of the compensation, the amount of the amount of the compensation, the amount of the amount of the compensation, the amount of the amount of the compensation, the amount of the compensation, the amount of the amount of the compensation, the amount of the compensation, the amount of the amount of the compensation, the amount of the compensation, the amount of the amount of the amount, the amount of the compensation, the amount of the amount of the amount of the compensation, the amount of the compensation, the amount of the amount of the compensation, the amount of the compensation, the amount of the amount of the amount, the amount of the compensation, the amount of the amount of the compensation, the amount of the compensation, the amount of the amount of the amount of the compensation, the amount of the compensation, the amount of the amount, the amount of the compensation, the amount of the compensation, the amount of the amount of the amount, the amount of the compensation, the amount of the compensation, the amount of the amount of the compensation, the amount of the amount of the amount of the compensation, the amount of the amount of the compensation, the amount of the amount of the amount of the amount of the compensation, the amount of the amount of the amount of the"}, {"heading": "5 Examples", "text": "In this section we give some examples of constructing weighted logic programs as limited products of simple weighted logic programs."}, {"heading": "5.1 Finite-State Algorithms", "text": "In fact, the fact is that most of them will be able to play by the rules that they have shown over the last five years, and that they will be able to play by the rules, \"he said.\" It's very likely that they will be able to play by the rules, \"he said."}, {"heading": "5.2 Context-Free Parsing", "text": "One analysis (the most likely in the real world) is that Alice had the binoculars and saw Bob through them. Another example is that Bob had the binoculars, and Alice saw the binoculars, that he saw the binoculars. It also shows that some of the axioms that could be used to describe a context-free grammar describe English sentences in Chomsky normal form (Hopcroft and Ullrich 1979). Proof corresponds to a derivation of the given sentence in a context-free grammar, i.e. that we are describing a parsectarian grammar."}, {"heading": "5.3 Translation Algorithms", "text": "Another example of two probable models that play the role of experts would be a candidate for translating sentences from one natural language to another. We will summarize how the PRODUCT transformation was applied to a simple form of phrase-to-phrase translation (Koehn et al. 2003) by Lopez (2009).Lopez (2009) proposed a deductive view of algorithms for machine translation, similar to the view of the gramaticality of a sentence given in Shieber et al. (1995) Lopez used the PRODUCT transformation to derive an algorithm for phrase translation from two different factor programs, one that attempts to enforce the grammaticality of a sentence, and one that tries to enforce the appropriateness of the meaning of an original sentence is preserved in the translation.) If the fluctuation is a measure of the grammaticality of a sentence, then it seems paralysis to the algorithm of free grammar."}, {"heading": "6.1 Fixing One of the Factor Structures", "text": "The usual use of the PRODUCT transformation is joint optimization on two structures, but the general lateral conditions can be used to perform the additional step of determining one of the two structures and the weighted logic program optimization on the other structure that is imposed by the pairing. In the setting in which we consider the weights as probabilities, this is useful for solving certain probable inference problems. With the path-sum semiring (i.e., < R \u2265 0, 0, 1 >), the result is a program that uses the marginalized quantity p (x) = x, y \"s, where x\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s."}, {"heading": "6.2 Axiom Generalization", "text": "In fact, it is in such a way that most of them will be able to go into another world, in which they are able to move, in which they are able to move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live"}, {"heading": "7 The Entropy Semiring and Kullback-Leibler Divergence", "text": "An important construct in information theory and machine learning is the KullbackLeibler (KL) divergence (Kullback and Leibler 1951).KL divergence is a function of two probability distributions over the same event space. It measures their divergence even though strictly speaking it is not a distance (it is not symmetrical).For two distributions p and q for random variable X, which extends over events x x x x, KL divergence becomes KL (p) = x) p (X = x) log p (X = x) q (X = x) q (79) = x) p (X = x) log p (X = x) log p (P = x) log p (X = x)."}, {"heading": "7.1 Generalized Entropy Semiring", "text": "The multiplication and addition of operations is defined as < x1, y1, y1, z1, z1, z1, z2, z2, z2, z1x2, z1x2, z1z2, z1z2 > (82) These operations have the required closure, association and pendativity properties previously discussed for semirings. See Cortes et al. (2006) for evidence that can be trivially extended to our generalized semiring."}, {"heading": "7.3 KL Divergence and Projections", "text": "We use PRODUCT to calculate the KL divergence between the profile distributions, even if P > Q = Q are not two instances of the same program. < 1) We look at cases where the proofs of P and the proofs of Q have a common semantics, that is, any proof of P or Q cards for an event in an \"interpretation space.\" As an example, we look at the WLP in Figure 16, which describes a weighted finite-state transducer. In a more general formulation, in which each state depends on the states visited previously, rather than just the single current state. This modification is reflected in Figure 32 for N = 2. The biarc axiom (P, P, A, B) is: \"if the last two states are Q and P, transfer to symbol A and P.\" Since the two programs have different axioms, the spaces of their respective proofs are different."}, {"heading": "8 Conclusion", "text": "We have described a framework for dynamic programming algorithms, the solutions of which correspond to evidence values in two restricted weighted logic programs. Our framework includes a program transformation, PRODUCT, which combines the two weighted logic programs, which compute via two structures, into a single weighted logic program for a common proof. Appropriate constraints, intuitively encoded as variable unification or ancillary conditions in the weighted logic program, are then added manually. Of course, the framework captures and allows the generalization of many existing algorithms. We have shown how deviations in program transformation can include a greater number of algorithms as a result of program transformation. Finally, we have shown how the program transformation9 satisfies these constraints in two identical programs with the \"natural\" measurement, as in \u00a7 7.2. to interpret the calculation of Kullback-Leibler divergences for two weighted logic programs, which are defined over an identical interpretation space."}, {"heading": "Acknowledgments", "text": "The authors note the helpful comments of two anonymous reviewers, Jason Eisner, Rebecca Hwa, Adam Lopez, Alberto Pettorossi, Frank Pfenning, Sylvia Rebholz, and David Smith. This research was supported by an NSF graduate scholarship for the second author and an NSF scholarship IIS-0713265, as well as an IBM faculty award for the third author."}], "references": [], "referenceMentions": [], "year": 2010, "abstractText": "Weighted logic programming, a generalization of bottom-up logic programming, is a wellsuited framework for specifying dynamic programming algorithms. In this setting, proofs correspond to the algorithm\u2019s output space, such as a path through a graph or a grammatical derivation, and are given a real-valued score (often interpreted as a probability) that depends on the real weights of the base axioms used in the proof. The desired output is a function over all possible proofs, such as a sum of scores or an optimal score. We describe the PRODUCT transformation, which can merge two weighted logic programs into a new one. The resulting program optimizes a product of proof scores from the original programs, constituting a scoring function known in machine learning as a \u201cproduct of experts.\u201d Through the addition of intuitive constraining side conditions, we show that several important dynamic programming algorithms can be derived by applying PRODUCT to weighted logic programs corresponding to simpler weighted logic programs. In addition, we show how the computation of Kullback-Leibler divergence, an information-theoretic measure, can be interpreted using PRODUCT.", "creator": "LaTeX with hyperref package"}}}