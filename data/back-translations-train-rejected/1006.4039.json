{"id": "1006.4039", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jun-2010", "title": "Distributed Autonomous Online Learning: Regrets and Intrinsic Privacy-Preserving Properties", "abstract": "Online learning is becoming increasingly popular for training on large datasets. However, the sequential nature of online learning requires a centralized learner to store data and update parameters. In this paper, we consider a fully decentralized setting, cooperative autonomous online learning, with a distributed data source. The learners perform learning with local parameters while periodically communicating with a small subset of neighbors to exchange information. We define the regret in terms of an implicit aggregated parameter of the learners for such a setting and prove regret bounds similar to the classical sequential online learning.", "histories": [["v1", "Mon, 21 Jun 2010 11:30:06 GMT  (24kb)", "http://arxiv.org/abs/1006.4039v1", null], ["v2", "Tue, 1 Feb 2011 03:16:12 GMT  (74kb,D)", "http://arxiv.org/abs/1006.4039v2", "24 pages, 2 figures"], ["v3", "Fri, 4 Feb 2011 16:06:35 GMT  (69kb,D)", "http://arxiv.org/abs/1006.4039v3", "25 pages, 2 figures"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["feng yan", "shreyas sundaram", "s v n vishwanathan", "yuan qi"], "accepted": false, "id": "1006.4039"}, "pdf": {"name": "1006.4039.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 100 6,40 39v1 [cs.LG] 2 1Ju n014015016017018019020021022023024025026027029030031032033034035036037038039040041042044045046047048049050051052053"}, {"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2 Preliminaries", "text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "3 Cooperative Autonomous Online Learning", "text": "It is the way of learning, in which the learners are able to locate themselves in the real world of learning, in which they are able to identify themselves, understand and understand what they are doing. (It is the way of learning in the real world, in which the learners learn in the real world.) (It is the way of learning in the real world, in which the learners learn in the real world, in which the learners learn in the real world, in which the learners learn in the real world, in which they learn themselves in the real world and in the real world of learning, in which they learn in the real world, in which they learn. (It is the way and way of learning in the real world, in which they learn to learn in the real world, in which they learn in the world of learning, in which they learn in the world of learning, in which they learn in the world of learning, and in which they learn in the world of learning, in which they learn in which they learn in the world of learning, in which they learn in which they learn in the world of learning, in which they learn in which they learn in the world of learning, in which they learn in which they learn in the world of learning, in which they learn in which they learn in which they learn in the world of learning, in which they learn in which they learn in which they learn in which they learn in the world of learning, in which they learn in which they learn in which they learn in which they learn in the world of learning, in which they learn in which they learn in which they learn in which they learn in the world of learning, in which they learn in which they learn in which they learn in the world of learning, in which they learn in which they learn in which they learn in which they learn in which they learn in the world of learning, in which they learn in which they learn in which they learn in the world of learning, in which they learn in which they learn in which they learn in which they learn in which they learn in which they learn in the world, in which they learn in which they learn in which they learn in which they learn in which they learn in which they learn in the world, in which they learn in which they learn in which they learn in which they learn in which they learn in the world, in which they learn in which they learn in which they learn in which they learn in which they learn"}, {"heading": "4 Regret Bounds", "text": "For our analysis, we make the following standard assumptions that apply to all the proofs and theorems listed below. \u2022 Each f is strongly convex with the module. \u2212 Aji 6 = 0 if and only if the learner communicates with the learner. We also assume that A is irreducible, aperiodic, and there is \u03b2 < 1 as defined in Theorem 1. \u2212 Aji 6 = 0 is a closed convex subset of Rn with non-empty interior. \u2022 The subset of (8) wf it (w) can be calculated for any w value. \u2022 The diam (B) = supx, x-x-x-x-x-x-x-x-x-x-x-x-x is limited by F <. \u2022 The set of optimal solutions of (8) is not (W)."}, {"heading": "Proof", "text": "Definerit: = w \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 \u2212 \u2212 p \u2212 p \u2212 p \u2212 \u2212 \u2212 \u2212 p \u2212 p \u2212 \u2212 p \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 p \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 p \u2212 p \u2212 p \u2212 p \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 p \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 p \u2212"}, {"heading": "Proof", "text": "Using the notations defined in the Lemma 2 evidence, we unroll the relation Wt = Wt \u2212 1A \u2212 333333333k = 333333333k = 333333333k = 333333333k = 3333333b = 33333b = 333b = 333b = 333b = 333b = 333b = 333b = 333b = 333b = 273b = 273b = 273b = 273b = 303b = 303b = 303b = 303b = 303b = 303b = 303b = 303b = 303b = 303b \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 3b = 303b = 303b = 303b = 303b = 303b \u2212 3b \u2212 3b = 303b \u2212 3b = 303b \u2212 3b = 303b \u2212 3b = 303b \u2212 3b = 303b = 303b \u2212 3b = 303b \u2212 3b = 303b \u2212 3b = 303b \u2212 3b = 303b = 303b \u2212 3b = 303b \u2212 3b = 303b \u2212 3b = 303b = 303b = 303b \u2212 3b = 303b \u2212 3b = 303b \u2212 3b = 303b = 303b = 303b = 303b \u2212 3b = 303b = 303b = 303b = 303b = 303b = 303b \u2212 3b = 303b = 303b = 303b = 303b = 303b = 303b = 303b = 303b = 303b = 303b = 303b = 303b = 30b = 30b = 30b = 303b = 30b = 303b = 30b = 303b = 30b = 303b = 303b = 303b = 303b = 303b = 303b = 30b = 30b = 303b = 30b = 30b = 303b = 30b = 30b = 30b = 30b = 303b = 30b = 303b = 30b = 30b = 30b = 30b = 30b = 30b ="}, {"heading": "4.1 Interpreting the Bounds", "text": "In this case, the regret of online sequential learning and, unsurprisingly, (24) and (23) the restoration of the classic quadratic regret of [7] and the logarithmic regret of [8]. If > 1 has to be careful when interpreting the limits, then our limits can be rewritten, such as O (\u221a mN) and O (m + m log (N / m). Compare these limits with those reached by [3], which are from Form O (\u221a mN) and O (m + log (N / m)). Compare these limits with those of [3], which are from Form O (\u0430) and O (\u0430 + stick + stick + stick + stick), where Rod is the delay in calculating the subgradient. Another interesting exercise is the comparison of our limits with that of an online sequential learning algorithm that processes N = mT data."}, {"heading": "4.2 Generalization to Bregman Divergences", "text": "Our evidence techniques can be generalized to Bregman divergences. We assume that access to a function that is continuously differentiable and strongly convex is defined with the module of strong convexity \u03c3 > 0, and use it to define a Bregman divergence [13, 14]: The diameter of, \"as defined by,\" \",\" \",\" \",\" \",\" \",\" \",\" \",\", \",\", \",\", \",\", \",\", \",\", \",\" \",\", \",\" \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \",\", \",\" \",\" \",\", \",\", \"\", \",\", \",\", \",\" \",\", \",\", \"\", \",\", \"\", \",\", \",\" \",\", \",\", \",\", \",\", \",\", \"\", \",\", \""}, {"heading": "5 Outlook and Discussion", "text": "It is a question of the extent to which people are able to survive themselves, and the question to what extent they see themselves able to survive themselves. (...) It is a question of the extent to which they are able to survive themselves. (...) It is a question of the extent to which they are able to survive themselves. (...) It is a question to what extent they are able to survive themselves. (...) It is a question to what extent they are able to survive themselves. (...) It is a question to what extent they are able to survive themselves. (...) It is a question to what extent they are able to survive themselves. (...) It is a question to what extent is the question to what is the question to what is the question to what is the question to what is the question to what is the question to what is \"how they can survive themselves.\" (...)"}, {"heading": "Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Lemma 4", "text": "Proof sentence w = w = p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212"}], "references": [{"title": "Bundle methods for regularized risk minimization", "author": ["Choon Hui Teo", "S.V.N. Vishwanthan", "Alex J. Smola", "Quoc V. Le"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Validity of the single processor approach to achieving large-scale computing capabilities", "author": ["Gene Amdahl"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1967}, {"title": "Slow learners are fast", "author": ["J. Langford", "A.J. Smola", "M. Zinkevich"], "venue": "arXiv:0911.0491", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Convex Analysis and Minimization Algorithms", "author": ["J.B. Hiriart-Urruty", "C. Lemar\u00e9chal"], "venue": "I and II, volume 305 and 306. Springer-Verlag", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1993}, {"title": "Tracking the best linear predictor", "author": ["M. Herbster", "M.K. Warmuth"], "venue": "Journal of Machine Learning Research, 1:281\u2013309", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Monte Carlo strategies in scientific computing", "author": ["Jun S. Liu"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Online convex programming and generalised infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": "Proc. Intl. Conf. Machine Learning, pages 928\u2013936", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["Elad Hazan", "Amit Agarwal", "Satyen Kale"], "venue": "Machine Learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Distributed subgradient methods for multi-agent optimization", "author": ["Angelia Nedic", "Asu Ozdaglar"], "venue": "IEEE Trans. on Automatic Control,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Subgradient Methods for Convex Minimization", "author": ["Angelia Nedic"], "venue": "PhD thesis,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "Mirror descent and nonlinear projected subgradient methods for convex optimization", "author": ["Amir Beck", "Marc Teboulle"], "venue": "Operations Research Letters,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Logarithmic regret algorithms for strongly convex repeated games", "author": ["S. Shalev-Shwartz", "Y. Singer"], "venue": "Technical report, School of Computer Science, Hebrew University", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "Relative loss bounds for on-line density estimation with the exponential family of distributions", "author": ["K. Azoury", "M.K. Warmuth"], "venue": "Machine Learning, 43(3):211\u2013246", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Parallel Optimization", "author": ["Y. Censor", "S.A. Zenios"], "venue": "Oxford, New York", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1997}, {"title": "Convergence rate of incremental subgradient algorithms", "author": ["A. Nedich", "D. P Bertsekas"], "venue": "S. Uryasev and P. M. Pardalos, editors, Stochastic Optimization: Algorithms and Applications, pages 263\u2013304. Kluwer Academic Publishers", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2000}, {"title": "Robust probabilistic inference in distributed systems", "author": ["Mark Paskin", "Carlos Guestrin"], "venue": "In Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "Constrained consensus and optimization in multiagent networks", "author": ["A. Nedic", "A. Ozdaglar", "P.A. Parrilo"], "venue": "Automatic Control, IEEE Transactions on, 55", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "For instance, [1] cast many machine learning problems as a regularized risk minimization problem.", "startOffset": 14, "endOffset": 17}, {"referenceID": 0, "context": "However, as [1] observe, when the number of processors increases Amdahls law [2] kicks in and the cost of communicating and synchronizing becomes prohibitively expensive.", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "However, as [1] observe, when the number of processors increases Amdahls law [2] kicks in and the cost of communicating and synchronizing becomes prohibitively expensive.", "startOffset": 77, "endOffset": 80}, {"referenceID": 2, "context": "Another notable effort is the work by [3], where they show that one can avoid the expensive synchronization step above.", "startOffset": 38, "endOffset": 41}, {"referenceID": 2, "context": "Even though the gradients received by the master may be out of sync, that is, it may not be computed using the current parameter vector, [3] show that their algorithm suffers small regret.", "startOffset": 137, "endOffset": 140}, {"referenceID": 3, "context": "Subgradients and Strongly Convex Functions: The subgradient (set) \u2202xf(\u00b7) of a convex function f(x) at x0 is defined as [4] g \u2208 \u2202f(x0) \u21d0\u21d2 \u2200y, f(y)\u2212 f(x0) \u2265 \u3008y \u2212 x0, g\u3009 .", "startOffset": 119, "endOffset": 122}, {"referenceID": 3, "context": "(1) A convex function f(\u00b7) defined on domain \u03a9 is said to be strongly convex with modulus \u03bb > 0 if and only if [4]", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "equation (59) in [5]):", "startOffset": 17, "endOffset": 20}, {"referenceID": 5, "context": "Chapter 12 of [6]):", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "In particular, we are interested in generalizing the celebrated \u221a T and log T bounds [7, 8] of sequential online learning to cooperative autonomous online learning.", "startOffset": 85, "endOffset": 91}, {"referenceID": 7, "context": "In particular, we are interested in generalizing the celebrated \u221a T and log T bounds [7, 8] of sequential online learning to cooperative autonomous online learning.", "startOffset": 85, "endOffset": 91}, {"referenceID": 8, "context": "We start from a key result concerning the decomposition of regret is Lemma 2 given below (also see Lemma 5 of [9]).", "startOffset": 110, "endOffset": 113}, {"referenceID": 9, "context": "2 in [10], Theorem 4.", "startOffset": 5, "endOffset": 9}, {"referenceID": 10, "context": "15) in [11], in the proof of Theorem 1 of [7], as well as Lemma 3 of [12].", "startOffset": 7, "endOffset": 11}, {"referenceID": 6, "context": "15) in [11], in the proof of Theorem 1 of [7], as well as Lemma 3 of [12].", "startOffset": 42, "endOffset": 45}, {"referenceID": 11, "context": "15) in [11], in the proof of Theorem 1 of [7], as well as Lemma 3 of [12].", "startOffset": 69, "endOffset": 73}, {"referenceID": 6, "context": "Whenm = 1, then algorithm 1 reduces to the familiar sequential online learning, and unsurprisingly (24) and (23) recover the classical square root regret of [7] and logarithmic regret of [8].", "startOffset": 157, "endOffset": 160}, {"referenceID": 7, "context": "Whenm = 1, then algorithm 1 reduces to the familiar sequential online learning, and unsurprisingly (24) and (23) recover the classical square root regret of [7] and logarithmic regret of [8].", "startOffset": 187, "endOffset": 190}, {"referenceID": 2, "context": "Contrast these bounds with the ones obtained by [3] which are of the form O( \u221a \u03c4N ) and O(\u03c4 + \u03c4 log(N/m)), where \u03c4 is the delay in the subgradient calculation.", "startOffset": 48, "endOffset": 51}, {"referenceID": 2, "context": "This is in contrast to the algorithm of [3] where the optimistic scenario is achieved for gradients which are completely de-correlated, which in turn means that the data points are de-correlated.", "startOffset": 40, "endOffset": 43}, {"referenceID": 12, "context": "We assume access to a function \u03c8 : \u03a9 \u2192 R which is continuously differentiable and strongly convex with modulus of strong convexity \u03c3 > 0, and use it to define a Bregman divergence [13, 14]:", "startOffset": 180, "endOffset": 188}, {"referenceID": 13, "context": "We assume access to a function \u03c8 : \u03a9 \u2192 R which is continuously differentiable and strongly convex with modulus of strong convexity \u03c3 > 0, and use it to define a Bregman divergence [13, 14]:", "startOffset": 180, "endOffset": 188}, {"referenceID": 8, "context": "Stochastic optimization with autonomous agents is also gaining research attention in optimization [9].", "startOffset": 98, "endOffset": 101}, {"referenceID": 14, "context": "[15]) and regret bounds in online learning (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "However, the tasks here are rather specific such as probabilistic inference [16] or evolving consensus [17].", "startOffset": 76, "endOffset": 80}, {"referenceID": 16, "context": "However, the tasks here are rather specific such as probabilistic inference [16] or evolving consensus [17].", "startOffset": 103, "endOffset": 107}, {"referenceID": 2, "context": "\u2019s algorithm [3]) may disclose information about data points.", "startOffset": 13, "endOffset": 16}], "year": 2017, "abstractText": "Online learning is becoming increasingly popular for training on large datasets. However, the sequential nature of online learning requires a centralized learner to store data and update parameters. In this paper, we consider a fully decentralized setting, cooperative autonomous online learning, with a distributed data source. The learners perform learning with local parameters while periodically communicating with a small subset of neighbors to exchange information. We define the regret in terms of an implicit aggregated parameter of the learners for such a setting and prove regret bounds similar to the classical sequential online learning.", "creator": "LaTeX with hyperref package"}}}