{"id": "1006.4540", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2010", "title": "A Novel Rough Set Reduct Algorithm for Medical Domain Based on Bee Colony Optimization", "abstract": "Feature selection refers to the problem of selecting relevant features which produce the most predictive outcome. In particular, feature selection task is involved in datasets containing huge number of features. Rough set theory has been one of the most successful methods used for feature selection. However, this method is still not able to find optimal subsets. This paper proposes a new feature selection method based on Rough set theory hybrid with Bee Colony Optimization (BCO) in an attempt to combat this. This proposed work is applied in the medical domain to find the minimal reducts and experimentally compared with the Quick Reduct, Entropy Based Reduct, and other hybrid Rough Set methods such as Genetic Algorithm (GA), Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO).", "histories": [["v1", "Wed, 23 Jun 2010 14:53:33 GMT  (177kb)", "http://arxiv.org/abs/1006.4540v1", "IEEE Publication Format,this https URL"]], "COMMENTS": "IEEE Publication Format,this https URL", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.NE", "authors": ["n suguna", "k thanushkodi"], "accepted": false, "id": "1006.4540"}, "pdf": {"name": "1006.4540.pdf", "metadata": {"source": "CRF", "title": "A Novel Rough Set Reduct Algorithm for Medical Domain Based on Bee Colony Optimization", "authors": ["N. Suguna"], "emails": [], "sections": [{"heading": null, "text": "Index terms - Feature Selection, Rough Set, QuickReduct, Genetic algorithm, Ant Colony Optimization, Particle Swarm Optimization, Bee Colony Optimization. - - - - - - - - - - - - - - - - - - - -"}, {"heading": "1 INTRODUCTION", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2 ROUGH SET THEORY", "text": "Rough Set Attribute Reduction (RSAR) [3] is an extension of conventional set theory that supports approximate values in decision-making. Rough Set Attribute Reduction (RSAR) [16] provides a filter-based tool that can be used to extract knowledge in a concise manner from a domain; the information content is retained while the amount of knowledge involved is reduced. Central to RSAR is the concept of indistinguishability. I = (U, A) is to be a - - - - - - - - - - - - - - - - - - - 1Assistant Professor of Computer Science and Engineering at Akshaya College of Engineering and Technology, Coimbatore, Tamil Nadu, India. 2Director at Akshaya College of Engineering and Technology, Coimbatore, Tamil Nadu, India. TInformation system in which U generates a non-empty set of finite objects (the universe \u2192 A) and A is not an endless set of A (A is a)."}, {"heading": "A  B = { X  Y : X  A, Y  B, X Y \u2260 } (3)", "text": "In fact, most of them will be able to play by the rules they have established in the past."}, {"heading": "QUICKREDUCT (C,D)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C, the set of all conditional features;", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "D, the set of decision features.", "text": "Note that an intuitive understanding of QuickReduct implies that for a dimensionality of n, (n2 + n) / 2, evaluations of the dependency function can be performed for the worst-case dataset. According to the QuickReduct algorithm, the dependency of each attribute is calculated and the best candidate is selected, and the next best attribute is added until the dependence of the reduced candidate matches the consistency of the dataset (1 if the dataset is consistent), but this process is not guaranteed to find a minimal reduction. Using the dependency function to distinguish between candidates can lead to the search for a non-minimal path. It is impossible to predict which combinations of attributes will lead to an optimal reduction on the dependence with the addition or deletion of individual attributes."}, {"heading": "EBR (C)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C, the set of all conditional features;", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.3 Genetic Based Reduct (GenRSAR)", "text": "Genetic algorithms (GAs) are generally very effective for the quick search for large, non-linear and poorly understood spaces [5]. Unlike classical trait selection strategies where a solution is optimized, a population of solutions can be modified simultaneously [8], which can result in several optimal (or near-optimal) traits. A trait subset is typically represented by a binary string whose length corresponds to the number of traits present in the dataset. From this pool of trait subgroups, the typical genetic operators (crossover and mutation) that characterize the absence or presence of the jten trait in that particular subset are applied are applied. Also, the selection of which types of crossover and mutation are used, as well as their probabilities of application, must be carefully considered. From this pool of trait subgroups, the typical genetic operators (crossover and mutation) are applied."}, {"heading": "3. SWARM INTELLIGENCE BASED REDUCT ALGORITHMS", "text": "In this section we have discussed two different reduction algorithms based on swarm intelligence, AntRSAR and PSORSAR hybrid with the rough set theory."}, {"heading": "3.1 Ant Colony Based Reduct (AntRSAR)", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "ROUGHBEE (C,D)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C, the set of all conditional features;", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "D, the set of decision features.", "text": "The parameters used in the proposed method: The population size (number of bees) 10 The dimension of the population N Lower limit 1 Upper limit N Maximum number of iterations 1000 The number of passes 3"}, {"heading": "4. EXPERIMENTS & RESULTS", "text": "The performance of the reduction calculation approaches discussed in this paper was tested with 5 different medical data sets obtained from the UCI machine learning data store. Table 1 shows the details of the data sets used in this paper."}, {"heading": "DATASETS USED FOR REDUCT", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "REDUCTS FOUND FOR THE DATASETS", "text": "Table 2 shows the reduction results of the different methods on the 5 different medical datasets. It shows the size of the reduction found for each method. QuickReduction and EBR methods produced the same reduction each time, in contrast to GenRSAR, AntRSAR, PSORSAR and BeeRSAR, which found different reduction cardinalities and sometimes different reduction cardinalities. Overall, it seems to be the case that BeeRSAR outperforms the other methods. However, compared to the other methods, BeeRSAR takes more time to find the reduction."}, {"heading": "5. CONCLUSION", "text": "This paper starts with the basic concepts of rough set theory and explains two basic techniques: QuickReduct and Entropy-Based Reduct. These methods may be close to the minimum reduction quantity, but not optimal. Swarm intelligence methods were used to guide this method to find the minimum reductions. In this paper, we have discussed three different computerized intelligence-based reductions: GenRSAR, AntRSAR and PSO-RSAR. Although these methods work well, there is no consistency as they deal with more random parameters. In this paper, we have proposed an algorithm for bee colony optimization to find minimum reductions. This method does not require random parameter assumptions. All these methods are analyzed using medical datasets. As shown in the results, our proposed method has a consistent and better performance than the other methods."}, {"heading": "Author Biographies", "text": "N.Suguna received her B.E degree in Computer Science and Engineering from Madurai Kamaraj University in 1999 and her M.E. degree in Computer Science and Engineering from Bangalore University in 2003. She has more than a decade of teaching experience at various engineering schools in Tamil Nadu and Karnataka. Dr.K.Thanushkodi has more than 35 years of teaching experience at various state and private engineering colleges in Coimbatore, Tamilnadu, India. His research interests include data mining, soft computing and object-oriented systems. Dr.K.Thanushkodi has more than 35 years of teaching experience at various state and private engineering colleges. He has published 45 essays in international journals and conferences. He currently directs 15 research scholars in the area of Power System Engineering, Power Electronics and Computer Networks. He was a senior government representative and dean in the Government College of Engineering Bargur, he was a senate member in Periyar Anna Engineering College, Salem was a member of the Administrative Council of the Electrical University, he was a member of the Electrical University of Amennai."}], "references": [{"title": "Rough Sets and Current Trends in Computing", "author": ["Alpigini", "J.J. Peters", "J.F. Skowronek", "N.J. Zhong"], "venue": "Third International Conference,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "Swarm Intelligence: From Natural to Artificial Systems", "author": ["Bonabeau", "M.E. Dorigo", "G. Theraulez"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Rough set-aided keyword reduction for text categorization", "author": ["A. Chouchoulas", "Q. Shen"], "venue": "Applied Artificial Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2001}, {"title": "Feature Selection for Classification", "author": ["M. Dash", "H. Liu"], "venue": "Intelligent Data Analysis,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "Adaptation in Natural and Artificial Systems, The University of Michigan Press, Ann Arbour", "author": ["J. Holland"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1975}, {"title": "A Rough Set-Aided System for Sorting WWW Bookmarks", "author": ["R. Jensen", "Q. Shen"], "venue": "Web Intelligence: Research and Development,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Finding rough set reducts with ant colony optimization", "author": ["R. Jensen", "Q. Shen"], "venue": "Proceedings UK Workshop on Computational Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Comparison of algorithms that select features for pattern classifiers", "author": ["M. Kudo", "J. Skalansky"], "venue": "Pattern Recognition,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2000}, {"title": "An idea based on honey bee swarm for numerical optimization", "author": ["D. Karaboga"], "venue": "Technical Report TR06,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "An Artificial Bee Colony (ABC) algorithm for numeric function optimization", "author": ["D. Karaboga", "B Basturk"], "venue": "In IEEE Swarm Intelligence Symposium", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "A powerful and efficient algorithm for numerical function optimization: Artificial Bee Colony (ABC) algorithm", "author": ["D. Karaboga", "B. Basturk"], "venue": "Journal of Global Optimization,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Artificial Bee Colony (ABC) Optimization Algorithm for Solving Constrained Optimization Problems", "author": ["D. Karaboga", "B. Basturk"], "venue": "Foundations of Fuzzy Logic and Soft Computing\u2019, LNCS, Springer-Verlag,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "On the performance of Artificial Bee Colony (ABC) algorithm", "author": ["D. Karaboga", "B. Basturk"], "venue": "Applied Soft Computing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Nature Inspired Population-Based Heuristics for Rough Set Reduction", "author": ["Liu", "A.H. Abraham", "Y. Li"], "venue": "Rough Set Theory, SCI, Springer-Verlag,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Rough Sets", "author": ["Z. Pawlak"], "venue": "International Journal of Computer and Information Sciences,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1982}, {"title": "Rough Sets: Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers", "author": ["Z. Pawlak"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1991}, {"title": "Rough Sets: Present State and The Future", "author": ["Z. Pawlak"], "venue": "Foundations of Computing and Decision Sciences,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1993}, {"title": "Rough Sets and Intelligent Data Analysis", "author": ["Z. Pawlak"], "venue": "Information Sciences,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2002}, {"title": "Programs for Machine Learning, The Morgan Kaufmann Series in Machine Learning", "author": ["J.R. Quinlan"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1993}], "referenceMentions": [{"referenceID": 3, "context": "HE main goal of feature selection is to find a minimal feature subset from a problem domain with high accuracy in representing the original features [4].", "startOffset": 149, "endOffset": 152}, {"referenceID": 14, "context": "Rough set theory [15,17,18] provides a mathematical tool that can be used for both feature selection and knowledge discovery.", "startOffset": 17, "endOffset": 27}, {"referenceID": 16, "context": "Rough set theory [15,17,18] provides a mathematical tool that can be used for both feature selection and knowledge discovery.", "startOffset": 17, "endOffset": 27}, {"referenceID": 17, "context": "Rough set theory [15,17,18] provides a mathematical tool that can be used for both feature selection and knowledge discovery.", "startOffset": 17, "endOffset": 27}, {"referenceID": 1, "context": "Swarm Intelligence is the property of a system whereby the collective behaviours of simple agents interacting locally with their environment cause coherent functional global patterns to emerge [2].", "startOffset": 193, "endOffset": 196}, {"referenceID": 15, "context": "Rough set theory [16] is an extension of conventional set theory that supports approximations in decision making.", "startOffset": 17, "endOffset": 21}, {"referenceID": 2, "context": "Rough Set Attribute Reduction (RSAR) [3] provides a filterbased tool by which knowledge may be extracted from a domain in a concise way; retaining the information content whilst reducing the amount of knowledge involved.", "startOffset": 37, "endOffset": 40}, {"referenceID": 0, "context": "The problem of finding a minimal reduct of an information system has been the subject of much research [1].", "startOffset": 103, "endOffset": 106}, {"referenceID": 5, "context": "Another technique for discovering rough set reducts is entropy-based reduction (EBR), developed from work carried out in [6] and is based on the entropy heuristic employed by machine learning techniques such as C4.", "startOffset": 121, "endOffset": 124}, {"referenceID": 18, "context": "5 [19].", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": "Genetic Algorithms (GAs) are generally quite effective for rapid search of large, nonlinear and poorly understood spaces [5].", "startOffset": 121, "endOffset": 124}, {"referenceID": 7, "context": "Unlike classical feature selection strategies where one solution is optimized, a population of solutions can be modified at the same time [8].", "startOffset": 138, "endOffset": 141}, {"referenceID": 6, "context": "ACO requires a problem to be represented as a graph; where nodes represent features, with the edges between them denoting the choice of the next feature [7].", "startOffset": 153, "endOffset": 156}, {"referenceID": 13, "context": "Therefore, we introduce a discrete particle swarm optimization for this combinatorial problem [14].", "startOffset": 94, "endOffset": 98}, {"referenceID": 0, "context": "r1 and r2 are random numbers in the interval [0,1].", "startOffset": 45, "endOffset": 50}, {"referenceID": 0, "context": "\uf072 is a random number in the closed interval [0, 1].", "startOffset": 44, "endOffset": 50}, {"referenceID": 9, "context": "Artificial Bee Colony (ABC) algorithm, proposed by Karaboga (2005) for real parameter optimization, is a recently introduced optimization algorithm and simulates the foraging behaviour of bee colony for unconstrained optimization problems [10-13].", "startOffset": 239, "endOffset": 246}, {"referenceID": 10, "context": "Artificial Bee Colony (ABC) algorithm, proposed by Karaboga (2005) for real parameter optimization, is a recently introduced optimization algorithm and simulates the foraging behaviour of bee colony for unconstrained optimization problems [10-13].", "startOffset": 239, "endOffset": 246}, {"referenceID": 11, "context": "Artificial Bee Colony (ABC) algorithm, proposed by Karaboga (2005) for real parameter optimization, is a recently introduced optimization algorithm and simulates the foraging behaviour of bee colony for unconstrained optimization problems [10-13].", "startOffset": 239, "endOffset": 246}, {"referenceID": 12, "context": "Artificial Bee Colony (ABC) algorithm, proposed by Karaboga (2005) for real parameter optimization, is a recently introduced optimization algorithm and simulates the foraging behaviour of bee colony for unconstrained optimization problems [10-13].", "startOffset": 239, "endOffset": 246}, {"referenceID": 0, "context": "where ij \uf06a is a uniformly distributed real random number within the range [-1,1], k is the index of the solution chosen randomly from the colony (k = int (rand * N) + 1), j = 1, .", "startOffset": 74, "endOffset": 80}], "year": 2010, "abstractText": "Feature selection refers to the problem of selecting relevant features which produce the most predictive outcome. In particular, feature selection task is involved in datasets containing huge number of features. Rough set theory has been one of the most successful methods used for feature selection. However, this method is still not able to find optimal subsets. This paper proposes a new feature selection method based on Rough set theory hybrid with Bee Colony Optimization (BCO) in an attempt to combat this. This proposed work is applied in the medical domain to find the minimal reducts and experimentally compared with the Quick Reduct, Entropy Based Reduct, and other hybrid Rough Set methods such as Genetic Algorithm (GA), Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO).", "creator": "PScript5.dll Version 5.2.2"}}}