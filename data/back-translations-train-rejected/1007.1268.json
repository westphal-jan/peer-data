{"id": "1007.1268", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jul-2010", "title": "Application of Data Mining to Network Intrusion Detection: Classifier Selection Model", "abstract": "As network attacks have increased in number and severity over the past few years, intrusion detection system (IDS) is increasingly becoming a critical component to secure the network. Due to large volumes of security audit data as well as complex and dynamic properties of intrusion behaviors, optimizing performance of IDS becomes an important open problem that is receiving more and more attention from the research community. The uncertainty to explore if certain algorithms perform better for certain attack classes constitutes the motivation for the reported herein. In this paper, we evaluate performance of a comprehensive set of classifier algorithms using KDD99 dataset. Based on evaluation results, best algorithms for each attack category is chosen and two classifier algorithm selection models are proposed. The simulation result comparison indicates that noticeable performance improvement and real-time intrusion detection can be achieved as we apply the proposed models to detect different kinds of network attacks.", "histories": [["v1", "Thu, 8 Jul 2010 00:23:40 GMT  (195kb)", "http://arxiv.org/abs/1007.1268v1", "Presented at The 11th Asia-Pacific Network Operations and Management Symposium (APNOMS 2008)"]], "COMMENTS": "Presented at The 11th Asia-Pacific Network Operations and Management Symposium (APNOMS 2008)", "reviews": [], "SUBJECTS": "cs.NI cs.AI", "authors": ["huy nguyen", "deokjai choi"], "accepted": false, "id": "1007.1268"}, "pdf": {"name": "1007.1268.pdf", "metadata": {"source": "CRF", "title": "Application of Data Mining to Network Intrusion Detection: Classifier Selection Model", "authors": ["Huy Anh Nguyen", "Deokjai Choi"], "emails": ["anhhuy@gmail.com,", "dchoi@chonnam.ac.kr"], "sections": [{"heading": null, "text": "Y. Ma, D. Choi, and S. Ata (eds.): APNOMS 2008, LNCS 5297, pp. 399-408, 2008. \u00a9 Springer-Verlag Berlin Heidelberg 2008Tags: data mining, machine learning, classifier, network security, intrusion detection, algorithm selection, KDD dataset."}, {"heading": "1 Introduction", "text": "In the era of the information society, computer networks and their related applications are becoming increasingly popular, as is the potential thread to the global information infrastructure. In order to protect against various cyber attacks and computer viruses, many computer security techniques have been intensively researched over the last decade, namely cryptography, anomalies and intrusion detection. As important areas of data collection, they are considered to be one of the most promising methods of defending complex and dynamic intrusion."}, {"heading": "2 Related Works on KDD99 Dataset", "text": "Agarwal and Joshir have developed a two-step universal disease detection system (PNR) to detect whether it is a disease or a disease."}, {"heading": "3 Empirical Study", "text": "In order to verify the effectiveness of different classification algorithms in the field of intrusion detection, we use the KDD99 dataset to perform step-by-step relevant experiments. First, we build the experimental environment with important steps: setting up the environment, data pre-processing, selecting the data mining software. Second, we select a comprehensive set of the most popular classification algorithms, selecting ten widely used classification algorithms to represent a variety of areas: Bayesian approaches, decision trees, rule-based models and function studies, and rotten functions. An overview of how specific values of these algorithms were identified and their detection performance. Finally, we arrive at a performance comparison between the ten selected classifiers."}, {"heading": "3.1 Evaluation Setup", "text": "All the experiments were carried out in a one-year computer with Intel (R) Core (TM) 2 CPU 2.13 GHz, 2 GB RAM configurations, and the operating system platform is Microsoft Windows XP Professional (SP2). We used an open source machine learning package - Weka (the latest version of Windows: Weka 3.5.7). Weka is a collection of machine learning algorithms for data mining tasks that are implemented in Weka so that they are easily and fairly compared with each other, association rules and visualization. However, this empirical study only deals with a subset of classification algorithms. All the machine learning techniques used in this paper will be compared."}, {"heading": "3.2 Classifier Algorithms", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1 BayesNet", "text": "BayesNet [8] learns Bayesian networks under the assumptions: nominal attributes (numerical ones are pre-descretized) and no missing values (such values are replaced globally) There are two different parts to estimate the conditional probability tables of the network. We run BayesNet using the SimpleEstimator and the search algorithm K2 without using ADTree."}, {"heading": "3.2.2 Na\u00efveBayes", "text": "The classifier Na\u00efveBayes [8] offers a simple approach with clear semantics to represent and learn probabilistic knowledge. It is called naive because it is based on two important simplistic assumptions that predictive attributes are conditionally independent of class, and it postulates that no hidden or latent attributes affect the prediction process."}, {"heading": "3.2.3 J48 (C4.5 Decision Tree Revision 8)", "text": "Perhaps the most popular tree classifier is the C4.5 algorithm developed by Quinlan [9]. The Weka classification package has its own version of C4.5, known as J48. J48 is an optimized implementation of C4.5 Rev. 8. In this study, J48 is experimented with the parameters: confidenceFactor = 0.25; numFolds = 3; seed = 1; unpruned = False."}, {"heading": "3.2.4 NBTree", "text": "NBTree [10] is a hybrid between decision trees and Na\u00efveBayes. It creates trees whose leaves serve as Na\u00efveBayes classifiers for the cases that reach the leaf. It is perfectly reasonable to expect that NBTree can surpass the Na\u00efveBayes, but instead we need to chart some speed."}, {"heading": "3.2.5 Decision Table", "text": "The decision table [3] forms a majority classifier for decision tables. It evaluates feature subsets using best-first search and can use cross-validation for evaluation. There are a number of methods that can be used in the search phase (e.g.: BestFirst, RankSearch, GeneticSearch...) and we can also use LBk to support the result. In this experiment, we choose crossVal = 1; searchMethod = BestFirst and useIBk = False."}, {"heading": "3.2.6 JRip (RIPPER)", "text": "RIPPER [3] is one of the most basic and popular algorithms. Classes are examined in increasing size and an initial rulebook for the class is created by incremental error-reduced truncation. We evaluate RIPPER by JRip, an implementation of RIPPER in Weka with the parameters: Folds = 3; minNo = 2; Optimizations = 2; Seed = 1; usePruning = true."}, {"heading": "3.2.7 OneR", "text": "OneR [3] is another basic algorithm that uses rules-based model. It creates a one-step decision tree expressed in the form of a set of rules that all test a certain attribute. OneR is a simple, inexpensive method that often contains quite good rules for characterizing the structure in data."}, {"heading": "3.2.8 Multilayer Perceptron (MLP)", "text": "Multilayer perceptron (MLP) [11] is one of the most commonly used algorithms for classifying neural networks. The architecture used for MLP during KDD dataset simulations consisted of a three-layer advanced neural network: an input, a hidden layer and an output layer. Selected parameters for the model are: LearningRate = 0.3; Pulse = 0.2; RandomSeed = 0; Validation Threshold = 20."}, {"heading": "3.2.9 SMO", "text": "SMO [3] implements the minimum sequential optimization algorithm to form a support vector classifier using polynomial or Gaussian nuclei. SMO is evaluated using the following parameters: c = 1.0; epsilon = 1.0E-12; kernel = PolyKernel; numFolds = -1; randomSeed = 1."}, {"heading": "3.2.10 LBk", "text": "LBk [12] is a lazy classifier algorithm that uses the k-next-neighbor classifier. In this study, we select the parameters for LBk as follows: k = 1; crossValidate = False; searchAlgorithm = LinearNNSearch; windowSize = 0."}, {"heading": "3.3 Performance Comparison", "text": "The results of the simulation are in Table 4. To compare the classifiers, we capture TP and FP of each algorithm. These parameters will be the most important criteria for the classifier to consider the best algorithm for the given attack category. In addition, it is equally important to record the average accuracy (AA = Total Correctly Classified Instances / Total Instances) and training time (TT) of each algorithm. In the selection process, an algorithm is disqualified if its AA is too low, despite its outstanding performance in a specific attack category. TT, on the other hand, will give us an idea of what algorithm can be implemented in a real-time network intrusion detection system. Just as we expected, Table 1 shows that no single algorithm can detect all attack categories with a high probability of Baye and a low false alarm rate."}, {"heading": "4 Classifier Selection Model", "text": "After experiencing the performance comparison with the ten classification algorithms, we generalize the empirical results with a model for selecting algorithms. The observation from Table 4 suggests that for a particular attack category, certain subsets of classification algorithms perform better than the others. It is perfectly reasonable to expect a significant increase in performance, since we can select the best classification candidate for a particular attack category. Section 3 identifies the best algorithms for each attack category: JRip for DoS and Probe, Decision Table for U2R, and OneR for R2L. We then propose a model for classification selection, as shown in Fig. 1 (a). Applying for the model proposed in Fig. 1 (a) is expected to allow network intrusion detection systems with data mining capability to be flexible in selecting the classification technology that can best handle the attack. Although the improvement in detection rate is something we can expect to implement in IDs, which is something we can see from IDs."}, {"heading": "5 Model Evaluation and Discussion", "text": "The results indicate that the two proposed models showed minor improvements in TP for DoS and probe; and significant improvements for U2R and R2L attack categories. Indeed, FP was relatively small for all attack categories, as we may have to hardcode the algorithms; and if we have a better dataset than KDD99 used in this paper, then the best classifiers may be different, and the classifiers become so annoying because we have to hardcode the algorithms; and if we have a better dataset than KDD99, then the classifiers will become so annoying. (2) Another problem when the models are implemented is the resource requirements."}, {"heading": "6 Conclusion", "text": "For this paper, we first conducted a recent study of recent studies on network intrusion detection, which was evaluated using the KDD99 dataset, and then used Weka to perform a comprehensive performance comparison between the most popular classification algorithms. Finally, two promising models for detecting network intrusion and applying real-time systems are proposed. However, we are fully aware of the issues raised with the KDD99 dataset [13] and strongly discourage its continued use in the development of data mining algorithms for detecting network intrusions. As explained, the reason we use KDD99 in this paper is because we need a baseline to evaluate different algorithms and compare our work with others. In the future, we would like to evaluate our work on another dataset, and we would like to make real implementations of our algorithm selection models to test their effectiveness in practice."}, {"heading": "Acknowledgement", "text": "This research was supported by the Industry Promotion Project for Regional Innovation. The authors thank Prof. Park Hyukro and anonymous reviewers for their valuable comments and suggestions on this paper."}], "references": [{"title": "Data Mining: Practical Machine Learning Tools and Techniques, 2nd edn", "author": ["I.H. Witten", "E. Frank"], "venue": "Morgan Kaufmann, San Francisco", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "PNrule: A New Framework for Learning Classifier Models in Data Mining", "author": ["R. Agarwal", "M.V. Joshi"], "venue": "Tech. Report, Dept. of Computer Science, University of Minnesota", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "Prazen-window Network Intrusion Detectors", "author": ["D.Y. Yeung", "C. Chow"], "venue": "16th International Conference on Pattern Recognition, Quebec, Canada, pp. 11\u201315", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Adaptive Intrusion Detection Based on Machine Learning: Feature Extraction, Classifier Construction and Sequential Pattern Prediction", "author": ["X. Xu"], "venue": "International Journal of Web Services Practices 2(1-2), 49\u201358", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "An Active Learning Based TCM-KNN Algorithm for Supervised Network Intrusion Detection", "author": ["Y. Li", "L. Guo"], "venue": "26th Computers & Security, pp. 459\u2013467", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Estimating Continuous Distributions in Bayesian Classifiers", "author": ["G.H. John", "P. Langley"], "venue": "Proc. of the 11th Conf. on Uncertainty in Artificial Intelligence", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "Programs for Machine Learning", "author": ["J. Quinlan"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1993}, {"title": "Scaling up the accuracy of na\u00efve-bayes classifier: A decision-tree hybrid", "author": ["R. Kohavi"], "venue": "Proc. of the 2nd International Conference on Knowledge Discovery and Data Mining, pp. 202\u2013207. AAAI Press, Menlo Park", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences", "author": ["P. Werbos"], "venue": "PhD Thesis, Harvard University", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1974}, {"title": "k-Nearest Neighbor Classifier and Distance Functions", "author": ["S. Aksoy"], "venue": "Technical Report, Department of Computer Engineering, Bilkent University", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Why Machine Learning Algorithms Fail in Misuse Detection on KDD Intrusion Detection Dataset", "author": ["M. Sabhnani", "G. Serpen"], "venue": "Intelligent Data Analysis, vol. 6", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 5, "context": "Different researchers propose different algorithms in different categories, from Bayesian approaches [8] to decision trees [9, 10], from rule based models [3] to functions studying [11].", "startOffset": 101, "endOffset": 104}, {"referenceID": 6, "context": "Different researchers propose different algorithms in different categories, from Bayesian approaches [8] to decision trees [9, 10], from rule based models [3] to functions studying [11].", "startOffset": 123, "endOffset": 130}, {"referenceID": 7, "context": "Different researchers propose different algorithms in different categories, from Bayesian approaches [8] to decision trees [9, 10], from rule based models [3] to functions studying [11].", "startOffset": 123, "endOffset": 130}, {"referenceID": 0, "context": "Different researchers propose different algorithms in different categories, from Bayesian approaches [8] to decision trees [9, 10], from rule based models [3] to functions studying [11].", "startOffset": 155, "endOffset": 158}, {"referenceID": 8, "context": "Different researchers propose different algorithms in different categories, from Bayesian approaches [8] to decision trees [9, 10], from rule based models [3] to functions studying [11].", "startOffset": 181, "endOffset": 185}, {"referenceID": 1, "context": "Agarwal and Joshi [4] proposed a two-stage general-to-specific framework for learning a rule-based model (PNrule) to learn classifier models on a data set that has widely different class distributions in the training data.", "startOffset": 18, "endOffset": 21}, {"referenceID": 2, "context": "Yeung and Chow [5] proposed a novelty detection approach using no-parametic density estimation based on Parzen-window estimators with Gaussian kernels to build an intrusion detection system using normal data only.", "startOffset": 15, "endOffset": 18}, {"referenceID": 10, "context": "However, due to the fact that no FP was reported by the authors and a nearly impossible detection rate [13] of 93.", "startOffset": 103, "endOffset": 107}, {"referenceID": 3, "context": "[6] presented a framework for adaptive intrusion detection based on machine learning.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Yang Li and Li Guo [7] though realize the deficiencies of KDD dataset, developed a supervised network intrusion detection method based on Transductive Confidence Machines for K-Nearest Neighbors (TCM-KNN) machine learning algorithm and active learning based training data selection method.", "startOffset": 19, "endOffset": 22}, {"referenceID": 10, "context": "set might have been criticized for its potential problems [13], but the fact is that it is", "startOffset": 58, "endOffset": 62}, {"referenceID": 5, "context": "1 BayesNet BayesNet [8] learns Bayesian networks under the presumptions: nominal attributes (numeric one are predescretized) and no missing values (any such values are replaced globally).", "startOffset": 20, "endOffset": 23}, {"referenceID": 5, "context": "2 Na\u00efveBayes The Na\u00efveBayes [8] classifier provides a simple approach, with clear semantics, to representing and learning probabilitistic knowledge.", "startOffset": 28, "endOffset": 31}, {"referenceID": 6, "context": "5 algorithm which was developed by Quinlan [9] is the most popular tree classifier.", "startOffset": 43, "endOffset": 46}, {"referenceID": 7, "context": "4 NBTree NBTree [10] is a hybrid between decision trees and Na\u00efveBayes.", "startOffset": 16, "endOffset": 20}, {"referenceID": 0, "context": "5 Decision Table Decision Table [3] builds a decision table majority classifier.", "startOffset": 32, "endOffset": 35}, {"referenceID": 0, "context": "RIPPER [3] is one of the basic and most popular algorithms.", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "7 OneR OneR [3] is another basic algorithm using Rule based model.", "startOffset": 12, "endOffset": 15}, {"referenceID": 8, "context": "8 Multilayer Perceptron (MLP) Multilayer perceptron (MLP) [11] is one of the most commonly used neural network classification algorithms.", "startOffset": 58, "endOffset": 62}, {"referenceID": 0, "context": "9 SMO SMO [3] implements the sequential minimal optimization algorithm for training a support vector classifier, using polynomial or Gaussian kernels.", "startOffset": 10, "endOffset": 13}, {"referenceID": 9, "context": "10 LBk LBk [12] is a lazy classifier algorithm that makes use of the k-nearest-neighbor classifier.", "startOffset": 11, "endOffset": 15}, {"referenceID": 10, "context": "we are fully aware of problems that have been cited with the KDD99 dataset [13] and strongly discourage its further use in developing network intrusion detection data mining algorithms.", "startOffset": 75, "endOffset": 79}], "year": 2008, "abstractText": "As network attacks have increased in number and severity over the past few years, intrusion detection system (IDS) is increasingly becoming a critical component to secure the network. Due to large volumes of security audit data as well as complex and dynamic properties of intrusion behaviors, optimizing performance of IDS becomes an important open problem that is receiving more and more attention from the research community. The uncertainty to explore if certain algorithms perform better for certain attack classes constitutes the motivation for the reported herein. In this paper, we evaluate performance of a comprehensive set of classifier algorithms using KDD99 dataset. Based on evaluation results, best algorithms for each attack category is chosen and two classifier algorithm selection models are proposed. The simulation result comparison indicates that noticeable performance improvement and real-time intrusion detection can be achieved as we apply the proposed models to detect different kinds of network attacks.", "creator": "PScript5.dll Version 5.2.2"}}}