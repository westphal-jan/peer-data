{"id": "1012.0322", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2010", "title": "A Bayesian Methodology for Estimating Uncertainty of Decisions in Safety-Critical Systems", "abstract": "Uncertainty of decisions in safety-critical engineering applications can be estimated on the basis of the Bayesian Markov Chain Monte Carlo (MCMC) technique of averaging over decision models. The use of decision tree (DT) models assists experts to interpret causal relations and find factors of the uncertainty. Bayesian averaging also allows experts to estimate the uncertainty accurately when a priori information on the favored structure of DTs is available. Then an expert can select a single DT model, typically the Maximum a Posteriori model, for interpretation purposes. Unfortunately, a priori information on favored structure of DTs is not always available. For this reason, we suggest a new prior on DTs for the Bayesian MCMC technique. We also suggest a new procedure of selecting a single DT and describe an application scenario. In our experiments on the Short-Term Conflict Alert data our technique outperforms the existing Bayesian techniques in predictive accuracy of the selected single DTs.", "histories": [["v1", "Wed, 1 Dec 2010 21:08:04 GMT  (203kb)", "http://arxiv.org/abs/1012.0322v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["vitaly schetinin", "jonathan fieldsend", "derek partridge", "wojtek krzanowski", "richard everson", "trevor bailey", "adolfo hernandez"], "accepted": false, "id": "1012.0322"}, "pdf": {"name": "1012.0322.pdf", "metadata": {"source": "CRF", "title": "A Bayesian Methodology for Estimating Uncertainty of Decisions in Safety-Critical Systems", "authors": ["Vitaly SCHETININ", "Jonathan E. FIELDSEND", "Derek PARTRIDGE", "Wojtek J. KRZANOWSKI", "Richard M. EVERSON", "Trevor C. BAILEY"], "emails": ["vitaly.schetinin@luton.ac.uk."], "sections": [{"heading": null, "text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _"}, {"heading": "1. Bayesian Averaging over Decision Tree Models", "text": "In general, a DT is a hierarchical system consisting of splitting and terminal nodes. DTs are binary when the splitting nodes ask a specific question and then divide the data points into two separate subsets [3]. The terminal node assigns all data points falling within that node to the class whose points are dominant. Within a Bayesian framework, the class background distribution for each terminal node is calculated, making Bayesian integration computationally expensive [4]. To make Bayesian avoidance of DTs a viable approach, Denison et al have proposed the use of the MCMC technique, taking a stochastic sample from the posterior distribution. During the sample, the parameters of the candidate models are drawn from the given proposal distributions and the candidate is accepted or rejected accordingly to Bayes."}, {"heading": "2. A Sweeping Strategy", "text": "In order to reduce the uncertainty of decisions, a new Bayesian strategy of capturing DT models has been proposed [8]. The basic idea behind this strategy is to determine the probability of further splitting of DT nodes from the outset depending on the range within which the number of data points will not be less than pmin. This is explicit, because the range of such values is unknown in the current partition. Within the range above, the new column value \"jq for variable j is derived from a uniform distribution:), (~,\" 1max, 1 min yy yxUq, and from a gauss with a given variance j:), (~ \"jj qNq,\" for birth and change. Due to the hierarchical structure, new moves applied to the first partition level can vastly change the shape of the DT if the data contains fewer points than the node T, as a node."}, {"heading": "3. Selection of a Single DT", "text": "In this section we describe our method of interpreting Bayesian DT ensembles. This method is based on the estimates of confidence in the results of the DT ensemble, which can be quantified using the training data within the Uncertainty Envelope technique."}, {"heading": "3.1. Selection Techniques", "text": "There are two approaches to interpreting DT ensembles: the first is based on the search for a DT from MAP [11]; the second is based on the idea of clustering DT's in the two-dimensional space of DT size and DT fitness [12]; our approach is based on the quantitative estimate of classification reliability that can be made within the uncertainty envelope technique described in [9]; the idea behind our method of interpreting the Bayesian DT ensemble is to find a single DT that covers most of the training examples classified as safe and correct; for multiple classification systems, the reliability of classification results can easily be estimated by counting the consistency of classification results; in fact, the results of the multiple classification system depend on how well the classifiers were trained and how representative the training data were; for a given sample, the consistency of the classification results comes within the class boundaries."}, {"heading": "3.2. A Selection Procedure", "text": "In practice, the number of DTs in the total Selected Selected Select Selects as well as the number of training examples can be large. Nevertheless, the number of confident and correct results counted as described above may find a desired DT that can be used to interpret the self-confident classification. The performance of such DTs may be slightly inferior to that of the Bayesian DT ensemble. Within the chapter, we offer the experimental comparison of their performances. The most important steps of the selection process are side by side. All we need is to find a set of DTs that cover the maximum number of training samples classified as safe and correct, while the number of misclassifications in the remaining examples is kept to a minimum. In order to find such a set of DTs, we can remove the contradictory examples from the training data and then select the DTs with a maximum coverage of the training samples classified as safe and correct by the DT ensemble. The most important steps of the selection process are as follows: Selected Minimum Selected Selects shall find Selects among a series of selected Selects."}, {"heading": "4. Experimental Results", "text": "In this section, we first describe the data used in our experiments, then show how the proposed Bayesian technique works on these data, and the resulting Bayesian averaging over DT models gives us a diagram of the meaning of the features, the suggested selection process gives us the individual DTs for each run, and finally, we compare the obtained predictive accuracies with the existing methods."}, {"heading": "4.1. The Experimental Data", "text": "The data used in our experiments relate to the problem of short-term conflict alarm (STCA), which arises when the distance between two aircraft landing or taking off could be critically short. Table 1 lists 12 features selected to predict STCA. In this table are the distances between aircraft pairs on the X, Y and Z axes. Feature 2224 zyxx is the distance between aircraft pairs in three-dimensional space. 1, xV is the speed of aircraft 1 on axis X,..., 2, zV is the speed of aircraft 2 at altitude Z. 1T and 2T are the times since the last correlated diagram in the side plane 1 and aircraft 2. In our experiments we used 2500 examples of radar cycles recorded every 6 seconds. From these examples, 984 cycles are referred to as warning cycles relating to one pair."}, {"heading": "4.2. Performance of the Bayesian DT averaging technique", "text": "The minimum number of data points allowed in the columns pmin was set at 15% and 1.2% of the 1250 training examples, respectively; the probabilities of proposed death, birth, change splitting, and change rules were set at 0.1, 0.1, 0.2, and 0.6; the number of burn-in and post-burn-in samples was set at 100k and 10k, respectively; the sampling rate was set at 7; and the deviation of the proposal was set at 0.3 to achieve the rational acceptance rate of 0.25 recommended in [5]; the 5-fold cross validation was used to estimate the variability of the resulting DTs; the performances of all five runs were almost identical; and for the first run of Figure 2, the sampling rate for the probability of the protocol and the number of DT nodes, as well as the density of the combustion and combustion rates after the combustion phase, were almost identical."}, {"heading": "4.3. Feature Importance", "text": "Table 2 lists the average rear weights of all 12 features sorted by values. The greater the rear weight of a feature, the greater its contribution to the result. On this basis, Table 2 provides rankings for all 12 features. Figure 3 shows us the error bars calculated for the contributions of the 12 features to the result, averaged over the 5-fold cross validation. From this figure, it emerges that features such as x8, x1 and x9 are used on average more frequently than the others in Bayesian DTs. In contrast, feature x12 is used with a lower frequency. Furthermore, the widths of the error bars in Figure 3 give us estimates of the variance of applications.Table 2. Rear weights of the features sorted according to their contribution to the result. Feature Posterior weightRankx8 0.168 1 x1 0.137 2 x9 0.120 3 x6 0.110 4 x5 0.090 x3 0.090 x78 0.001 0.001 010 010 010 120.010 0.010 0.010."}, {"heading": "4.4. A Resultant DT", "text": "The resulting DT selected by the SC procedure is shown as a machine diagram in Fig. 4. Each splitting node of the DT returns a specific question with a yes / no answer and two branches. The terminal nodes provide the predictive alarm probabilities with values between 0.0 and 1.0 nodes 01 X04 < 1847.05, then node 03, otherwise node 45 nodes 03 X04 < 1459.91, then node 06, otherwise node 28 Node06 X05 < -281.95, then node 15, otherwise node 07 Node07 X03 < 1713.61, then node 08, otherwise node 12"}, {"heading": "4.5. Comparison of Performances", "text": "In this section, we compare our technique for extracting a safely correct (SC) DT with the MAP technique and the maximum posterior weight (MAPW), with a view to misclassification within a 5x cross-validation. The misclassification rates of the above three techniques: SC, MAP and MAPW are shown in Fig. 5. The left side shows the misclassification rates of the individual DTs on the test data, and the right side shows their size.Theoretically, the Bayesian averaging technique should offer lower misclassification rates than all the other individual DTs selected by the SC-, MAP- and MAPW technique. In the first run, we can see that all individual DTs perform worse than the Bayesian DTs ensemble, which misclassified 14.3% of the test data."}, {"heading": "5. An Application Scenario", "text": "This year, it will be able to get to grips with the problems mentioned, \"he said in an interview with the German Press Agency.\" We have never experienced such a scenario, \"he said,\" but we are not yet in a position to do it. \""}, {"heading": "6. Conclusion", "text": "In order to estimate the uncertainty of decisions in safety-critical technical applications, we have proposed Bayesian averaging over decision models, using a new strategy of the RJ MCMC sampling method for cases where a priori no information about the preferred structure of models is available. However, the use of DT models helps experts interpret causal relationships and find factors that take into account uncertainty. However, the Bayesian averaging method over DTs allows experts to accurately estimate the uncertainty when a priori information about the preferred structure of DTs is available. In order to interpret an entire ensemble of different DTs sampled by the RJ MCMC technique, experts select the single DT model with maximum a posteriori probability. In practice, however, this selection method tends to select overpaired DTs that are unable to provide a high degree of predictable accuracy. In this chapter, we have proposed a new method to select an overall uncertainty based on this Bayesian model of uncertainty."}, {"heading": "7. Acknowledgements", "text": "The work reported was largely supported by an EPSRC grant under the Critical Systems Program (GR / R24357 / 01)."}], "references": [{"title": "Probability and Statistical Methods in Engineering Design", "author": ["A. Haldar", "S. Mahadevan"], "venue": "Wiley", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1999}, {"title": "Multi-Objective optimization of safety related Systems: An application to short term conflict alert", "author": ["R. Everson", "J.E. Fieldsend"], "venue": "IEEE Transactions on Evolutionary Computation (forthcoming)", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Combining Pattern Classifiers: Methods and Algorithms", "author": ["L. Kuncheva"], "venue": "Wiley", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "Classification and Regression Trees", "author": ["L. Brieman", "J. Friedman", "R. Olshen", "C. Stone"], "venue": "Belmont, CA, Wadsworth", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1984}, {"title": "Bayesian Methods for Nonlinear Classification and Regression", "author": ["D. Denison", "C. Holmes", "B. Malick", "A. Smith"], "venue": "Wiley", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Bayesian CART model search", "author": ["H. Chipman", "E. George", "R. McCullock"], "venue": "J. American Statistics 93 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1998}, {"title": "Bayesian averaging of classifiers and the overfitting problem, International Conference on Machine Learning", "author": ["P. Domingos"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "The Bayesian decision tree technique with a sweeping strategy", "author": ["V. Schetinin", "J.E. Fieldsend", "D. Partridge", "W.J. Krzanowski", "R.M. Everson", "T.C. Bailey", "A. Hernandez"], "venue": "Int. Conference on Advances in Intelligent Systems - Theory and Applications, ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Bayesian inductively learned modules for safety critical systems", "author": ["J.E. Fieldsend", "T.C. Bailey", "R.M. Everson", "W.J. Krzanowski", "D. Partridge", "V. Schetinin"], "venue": "Symposium on the Interface: Computing Science and Statistics, Salt Lake City", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Reversible jump Markov Chain Monte Carlo computation and Bayesian model determination", "author": ["P. Green"], "venue": "Biometrika 82 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1995}, {"title": "Knowledge discovery via multiple models", "author": ["P. Domingos"], "venue": "Intelligent Data Analysis 2 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1998}, {"title": "Making sense of a forest of trees", "author": ["H. Chipman", "E. George", "R. McCulloch"], "venue": "Symposium on the Interface, S. Weisberg, Ed., Interface Foundation of North America", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "The assessment of uncertainty of decisions is of crucial importance for many safetycritical engineering applications [1], e.", "startOffset": 117, "endOffset": 120}, {"referenceID": 1, "context": ", in air-traffic control [2].", "startOffset": 25, "endOffset": 28}, {"referenceID": 2, "context": "For such applications Bayesian model averaging provides reliable estimates of the uncertainty [3, 4, 5].", "startOffset": 94, "endOffset": 103}, {"referenceID": 3, "context": "For such applications Bayesian model averaging provides reliable estimates of the uncertainty [3, 4, 5].", "startOffset": 94, "endOffset": 103}, {"referenceID": 4, "context": "For such applications Bayesian model averaging provides reliable estimates of the uncertainty [3, 4, 5].", "startOffset": 94, "endOffset": 103}, {"referenceID": 2, "context": "The use of decision trees (DT) for Bayesian model averaging is attractive for experts who want to interpret causal relations and find factors to account for the uncertainty [3, 4, 5].", "startOffset": 173, "endOffset": 182}, {"referenceID": 3, "context": "The use of decision trees (DT) for Bayesian model averaging is attractive for experts who want to interpret causal relations and find factors to account for the uncertainty [3, 4, 5].", "startOffset": 173, "endOffset": 182}, {"referenceID": 4, "context": "The use of decision trees (DT) for Bayesian model averaging is attractive for experts who want to interpret causal relations and find factors to account for the uncertainty [3, 4, 5].", "startOffset": 173, "endOffset": 182}, {"referenceID": 5, "context": "Bayesian averaging over DT models allows the uncertainty of decisions to be estimated accurately when a priori information on favored structure of DTs is available as described in [6].", "startOffset": 180, "endOffset": 183}, {"referenceID": 6, "context": "model which provides the Maximum a Posteriori (MAP) performance [7].", "startOffset": 64, "endOffset": 67}, {"referenceID": 7, "context": "For this reason, we suggest a new prior on DT models within a sweeping strategy that we described in [8].", "startOffset": 101, "endOffset": 104}, {"referenceID": 8, "context": "This procedure is based on the estimates obtained within the Uncertainty Envelope technique that we described in [9].", "startOffset": 113, "endOffset": 116}, {"referenceID": 2, "context": "DTs are binary if the splitting nodes ask a specific question and then divide the data points into two disjoint subsets [3].", "startOffset": 120, "endOffset": 123}, {"referenceID": 3, "context": "Within a Bayesian framework, the class posterior distribution is calculated for each terminal node, which makes the Bayesian integration computationally expensive [4].", "startOffset": 163, "endOffset": 166}, {"referenceID": 4, "context": "[5] have suggested the use of the MCMC technique, taking a stochastic sample from the posterior distribution.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Sampling across DT models of variable dimensionality, the above technique exploits a Reversible Jump (RJ) extension suggested by Green [10].", "startOffset": 135, "endOffset": 139}, {"referenceID": 4, "context": "[5] and Chipman et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] suggested exploring the posterior probability by using the following types of moves: Birth.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "The first two moves, birth and death, are reversible and change the dimensionality of \uf071 as described in [10].", "startOffset": 104, "endOffset": 108}, {"referenceID": 10, "context": "However, in practice the lack of a priori information brings bias to the posterior estimates, and as a result the evaluation of classification uncertainty may be incorrect [11].", "startOffset": 172, "endOffset": 176}, {"referenceID": 4, "context": "As a result, the use of inappropriately assigned priors leads to poor results [5, 6].", "startOffset": 78, "endOffset": 84}, {"referenceID": 5, "context": "As a result, the use of inappropriately assigned priors leads to poor results [5, 6].", "startOffset": 78, "endOffset": 84}, {"referenceID": 5, "context": "[6] suggested the prior probability, with which a terminal node should be split further.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "To decrease the uncertainty of decisions, a new Bayesian strategy of sampling DT models has been suggested [8].", "startOffset": 107, "endOffset": 110}, {"referenceID": 10, "context": "The first approach is based on searching a DT of MAP [11].", "startOffset": 53, "endOffset": 57}, {"referenceID": 11, "context": "The second approach is based on the idea of clustering DTs in the two-dimensional space of DT size and DT fitness [12].", "startOffset": 114, "endOffset": 118}, {"referenceID": 8, "context": "Our approach is based on the quantitative estimates of classification confidence, which can be made within the Uncertainty Envelope technique described in [9].", "startOffset": 155, "endOffset": 158}, {"referenceID": 4, "context": "25, which was recommended in [5].", "startOffset": 29, "endOffset": 32}], "year": 2010, "abstractText": "Uncertainty of decisions in safety-critical engineering applications can be estimated on the basis of the Bayesian Markov Chain Monte Carlo (MCMC) technique of averaging over decision models. The use of decision tree (DT) models assists experts to interpret causal relations and find factors of the uncertainty. Bayesian averaging also allows experts to estimate the uncertainty accurately when a priori information on the favored structure of DTs is available. Then an expert can select a single DT model, typically the Maximum a Posteriori model, for interpretation purposes. Unfortunately, a priori information on favored structure of DTs is not always available. For this reason, we suggest a new prior on DTs for the Bayesian MCMC technique. We also suggest a new procedure of selecting a single DT and describe an application scenario. In our experiments on real data our technique outperforms the existing Bayesian techniques in predictive accuracy of the selected single DTs.", "creator": "Microsoft Word - book_chapter_final - Bayesian Methodology for Estimating Uncertainty of Decisions in Safety-Critical Systems.doc"}}}