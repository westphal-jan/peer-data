{"id": "1012.0498", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2010", "title": "Estimating Probabilities in Recommendation Systems", "abstract": "Recommendation systems are emerging as an important business application with significant economic impact. Currently popular systems include Amazon's book recommendations, Netflix's movie recommendations, and Pandora's music recommendations. In this paper we address the problem of estimating probabilities associated with recommendation system data using non-parametric kernel smoothing. In our estimation we interpret missing items as randomly censored observations and obtain efficient computation schemes using combinatorial properties of generating functions. We demonstrate our approach with several case studies involving real world movie recommendation data. The results are comparable with state-of-the-art techniques while also providing probabilistic preference estimates outside the scope of traditional recommender systems.", "histories": [["v1", "Thu, 2 Dec 2010 17:04:19 GMT  (653kb)", "http://arxiv.org/abs/1012.0498v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mingxuan sun", "guy lebanon", "paul kidwell"], "accepted": false, "id": "1012.0498"}, "pdf": {"name": "1012.0498.pdf", "metadata": {"source": "CRF", "title": "Estimating Probabilities in Recommendation Systems", "authors": ["Mingxuan Sun", "Guy Lebanon", "Paul Kidwell"], "emails": ["msun3@gatech.edu"], "sections": [{"heading": null, "text": "ar Xiv: 101 2.04 98v1 [cs.LG] 2 Dec 2"}, {"heading": "1 Introduction", "text": "The data in such systems are collections of incomplete, bound preferences about n articles associated with m + 1 users. Given an incomplete, bound preference associated with an additional m + 1 user, the system recommends disregarded articles to that user based on the preferential relationships of m + 1 users. Recommendation systems currently used include book recommendations on amazon.com, film recommendations on netflix.com, and music recommendations on pandora.com. The construction of precise recommendation systems (which recommend articles that are really preferred to other articles) is important for assisting users as well as increasing business profitability. It is an important unresolved goal in machine learning and data mining.In most cases of practical interest, the number of articles indexed by the system (articles can include books, movies, songs, etc.) is relatively high in the 103 \u2212 104 ranges. Perhaps due to the size of n, it is almost always the case of 10, that one subset of articles is typically observed in the subset of users."}, {"heading": "2 Definitions and Estimation Framework", "text": "We describe the following notations and conventions for permutations taken from [3], where more details can be found = 1. We define a permutation by listing the most preferred and least separated positions by a person (1). The binding order occurs when judges do not provide enough information to construct a total account. Specifically, we define tied rankings as partitions from {1,., n} to k < n disjointed subsets A1,., Ak \u00b2 such that all items in Ai + 1 are preferred, but no information about the relativization of items under the Ai sets. We denounce such rankings by separating or tying the items in Ai and Ai + 1 with a person."}, {"heading": "3 Computationally Efficient Kernel Smoothing", "text": "In the previous paper [10], the estimator (6) is proposed for bound (but complete) rankings. This work derives closed form expressions and efficient calculation for (6) the assumption of a mallows kernel [11] Kh (T (\u03c0, \u03c3)) = exp (\u2212 T (\u03c0, \u03c3) h) n (11 \u2212 e \u2212 j / h (9)), where T is Kendall's tau distance to permutations (below I (x) = 1 for x > 0 and 0 otherwise) T (\u03c0) = n \u2212 1 [1], [1], [1], [1], [2], [1], (l). Unfortunately, these simplifications do not apply to the case of incomplete rankings, where the sets of consistent permutations S1,.,., Sm are not cosets of the symmetrical group. As a result, the problem of probability estimation in recommendation systems, where n is high and many items are missing, we present a special challenge as a replacement for the Melle."}, {"heading": "4 Applications and Case Studies", "text": "In our experiments, we used three sets of data: The Movielens dataset 1 contains one million reviews from 6040 users over 3952 movies; the EachMovie dataset 2 contains 2.6 million reviews from 74424 users over 1648 movies; and the Netflix dataset 3 contains 100 million reviews from 480,189 users over 17770. In all of these datasets, users typically rated only a small number of items. Histograms of the distribution of votes per user, the number of votes per item, and the distribution of votes appear in Figure 3."}, {"heading": "4.1 Estimating Probabilities", "text": "We consider here the task of estimating more complex events. (R), where R is a set of permutations that correspond to a tied incomplete ranking. (R), Most estimates can be used to calculate conditional estimates. (R), Most of them are very probable. (R), Most of us are very probable. (R), Most of us are very probable. (R), Most of us are very probable. (R), Most of us are very probable. (R), Most of us are very probable. (R), Most of us are very probable. (R), Most of us are very probable. (R), Most of us. (R), Most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us. (R), most of us."}, {"heading": "4.2 Rank Prediction", "text": "We follow the standard procedure in collaborative filtering: the group of users is divided into two groups, a training set and a test set. For each of the test participants, we divide the observed items into two groups: a set that is used to estimate the preferences (along with the preferences of the training participants) and the second set to evaluate the performance of the prediction [14]. Faced with a loss function L (i, j) that measures the loss of the prediction of rank i if the true rank is j (rank refers here to the number of sets of equivalent items that are more or less preferred than the current position), we evaluate a prediction rule by the expected loss. We focus on three loss functions: L0 (i, j) = 0 if i = j and 1 otherwise, L1 (i, j) = 0 \u2212 j | which is reduced to the standard CF evaluation technology."}, {"heading": "4.3 Rule Discovery", "text": "In the third task, we used the estimator p to detect remarkable rules of association of type i \u00b2 j \u00b2 k \u00b2 l (if I am preferred j \u00b2 l, than it is likely that k is preferred over l). Such rules of association are important both for economic analysis (the development of marketing and manufacturing strategies) and for recommendation system engineering. Specifically, we used p \u00b2 to select sentences of four items i, j, k, l, for which the mutual information I (i \u00b2 j; k \u00b2 l) is maximized. Once these sentences are identified, we recognized the exact form of the rule (i.e., i \u00b2 j \u00b2 k \u00b2 l instead of j \u00b2 s \u00b2 s films used by studying the summands in mutual information expectation).Figure 9 (above) shows the top 10 rules that were discovered. These rules isolate the viewer's preferences for genres such as fantasy, romantic comedies, genre, action, and action (but not) information that was used in the application."}, {"heading": "5 Related Work", "text": "The collaborative filter or recommendation system has been an active field of research in computer science since the 1990s, and the earliest efforts made a prediction for the evaluation of items based on the similarity of the test user and the training user [17, 2, 6]. Specifically, these experiments used similarity metrics such as Pearson correlation [17] and vector cosine similarity [2, 6] to evaluate the similarity level between different users. Recent work includes user and movie clusters [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence networks [5] and probable latent variable models [14, 7, 13]. More recently, art methods, including the winner of the Netflix competition, have been based on non-negative item similarities [18], Bayesian networks [2], dependence networks [14, 7, and probable variable models]."}, {"heading": "6 Summary", "text": "Estimating distributions of bound and incomplete data is a central task in many applications, perhaps the most obvious of which is collaborative filtering. An accurate estimator p enables us to go beyond the traditional task of item rank prediction. It can be used to calculate probabilities of interest, find association rules, and perform a wide range of additional data analysis tasks. We demonstrate the first non-parametric estimator for such data that is computationally comprehensible, i.e., polynomial rather than exponential in n. Calculation is made possible by using generation functions and dynamic programming techniques. We examine the behavior of the estimator p \u0442 in three groups of experiments. The first set of experiments involves estimating probabilities of interest such as p (i).The second set of experiments involves predicting preferences of items held that are directly applicable in recommendation systems and does not exceed the one that our other estimator performs in a similar way."}], "references": [{"title": "Recommendation as classification: Using social and content-based information in recommendation", "author": ["C. Basu", "H. Hirsh", "W. Cohen"], "venue": "In Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Empirical analysis of predictive algorithms for collaborative filtering", "author": ["J. Breese", "D. Heckerman", "C. Kadie"], "venue": "In Proc. of Uncertainty in Artificial Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "Group Representations in Probability and Statistics", "author": ["P. Diaconis"], "venue": "Institute of Mathematical Statistics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1988}, {"title": "Eigentaste: A constant time collaborative filtering algorithm", "author": ["K. Goldberg", "T. Roeder", "D. Gupta", "C. Perkins"], "venue": "Information Retrieval,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2001}, {"title": "Dependency networks for inference, collaborative filtering, and data visualization", "author": ["David Heckerman", "David Maxwell Chickering", "Christopher Meek", "Robert Rounthwaite", "Carl Kadie"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "An algorithmic framework for performing collaborative filtering", "author": ["J.L. Herlocker", "J.A. Konstan", "A. Borchers", "J. Riedl"], "venue": "In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "Latent semantic models for collaborative filtering", "author": ["T. Hofmann"], "venue": "ACM Transactions on Information Systems (TOIS),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Factor in the neighbors: Scalable and accurate collaborative filtering", "author": ["Y. Koren"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Non-linear matrix factorization with gaussian processes", "author": ["N.D. Lawrence", "R. Urtasun"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Non-parametric modeling of partially ranked data", "author": ["G. Lebanon", "Y. Mao"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Non-null ranking models", "author": ["C.L. Mallows"], "venue": "Biometrika, 44:114\u2013130,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1957}, {"title": "Analyzing and modeling rank data", "author": ["J.I. Marden"], "venue": "CRC Press,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1996}, {"title": "Modeling user rating profiles for collaborative filtering", "author": ["B. Marlin"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Collaborative filtering by personality diagnosis: A hybrid memory- and model-based approach", "author": ["D.M. Pennock", "E. Horvitz", "S. Lawrence", "C.L. Giles"], "venue": "In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2000}, {"title": "Probabilistic models for unified collaborative and content-based recommendation in sparse-data environments", "author": ["A. Popescul", "L.H. Ungar", "D.M. Pennock", "S. Lawrence"], "venue": "In Proceedings of the 17th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2001}, {"title": "Fast maximum margin matrix factorization for collaborative prediction", "author": ["J.D.M. Rennie", "N. Srebro"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "Grouplens: an open architecture for collaborative filtering of netnews", "author": ["P. Resnick", "N. Iacovou", "M. Suchak", "P. Bergstrom", "J. Riedl"], "venue": "In Proceedings of the Conference on Computer Supported Cooperative Work,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1994}, {"title": "Item-based collaborative filtering recommendation algorithms", "author": ["B. Sarwar", "G. Karypis", "J. Konstan", "J. Reidl"], "venue": "In Proceedings of the 10th international conference on World Wide Web,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2001}, {"title": "Methods and metrics for cold-start recommendations", "author": ["A.I. Schein", "A. Popescul", "L.H. Ungar", "D.M. Pennock"], "venue": "In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Enumerative Combinatorics, volume 1", "author": ["R.P. Stanley"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2000}, {"title": "Clustering methods for collaborative filtering", "author": ["L.H. Ungar", "D.P. Foster"], "venue": "In AAAI Workshop on Recommendation Systems,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1998}, {"title": "Scalable collaborative filtering using cluster-based smoothing", "author": ["G.R. Xue", "C. Lin", "Q. Yang", "W.S. Xi", "H.J. Zeng", "Y. Yu", "Z. Chen"], "venue": "In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}], "referenceMentions": [{"referenceID": 2, "context": "2 Definitions and Estimation Framework We describe the following notations and conventions for permutations, which are taken from [3] where more detail may be found.", "startOffset": 130, "endOffset": 133}, {"referenceID": 11, "context": ", Sm are possible, experimental evidence point to the fact that in recommendation systems with high n, the distribution p does not follow a simple parametric form such as the Mallows, Bradley-Terry, or Thurstone models [12] (see Figure 1 for a demonstration how parametric assumptions break down with increasing n).", "startOffset": 219, "endOffset": 223}, {"referenceID": 9, "context": "3 Computationally Efficient Kernel Smoothing In previous work [10] the estimator (6) is proposed for tied (but complete) rankings.", "startOffset": 62, "endOffset": 66}, {"referenceID": 10, "context": "That work derives closed form expressions and efficient computation for (6) assuming a Mallows kernel [11] Kh(T (\u03c0, \u03c3)) = exp (", "startOffset": 102, "endOffset": 106}, {"referenceID": 19, "context": "Kendall\u2019s tau T (\u03c0, \u03c3) is the total number of discordant pairs or inversions between \u03c0, \u03c3 [20] and thus its computation becomes a combinatorial counting problem.", "startOffset": 90, "endOffset": 94}, {"referenceID": 19, "context": "As shown for example in [20] the coefficient of z of Gn(z), which we denote as [z ]Gn(z), corresponds to the number of permutations \u03c3 for which T (\u03c3, \u03c0) = k.", "startOffset": 24, "endOffset": 28}, {"referenceID": 13, "context": "For each of the test set users we further split the observed items into two sets: one set used for estimating preferences (together with the preferences of the training set users) and the second set to evaluate the performance of the prediction [14].", "startOffset": 245, "endOffset": 249}, {"referenceID": 13, "context": "We focus on three loss functions: L0(i, j) = 0 if i = j and 1 otherwise, L1(i, j) = |i\u2212j| which reduces to the standard CF evaluation technique described in [14], and an asymmetric loss function (rows correspond to estimated number of stars (0-5) and columns to actual number of stars (0-5)", "startOffset": 157, "endOffset": 161}, {"referenceID": 1, "context": ", [2], and a recent state-of-the-art non-negative matrix (NMF) factorization (gnmf) [9].", "startOffset": 2, "endOffset": 5}, {"referenceID": 8, "context": ", [2], and a recent state-of-the-art non-negative matrix (NMF) factorization (gnmf) [9].", "startOffset": 84, "endOffset": 87}, {"referenceID": 16, "context": "The earliest efforts made a prediction for the rating of items based on the similarity of the test user and the training users [17, 2, 6].", "startOffset": 127, "endOffset": 137}, {"referenceID": 1, "context": "The earliest efforts made a prediction for the rating of items based on the similarity of the test user and the training users [17, 2, 6].", "startOffset": 127, "endOffset": 137}, {"referenceID": 5, "context": "The earliest efforts made a prediction for the rating of items based on the similarity of the test user and the training users [17, 2, 6].", "startOffset": 127, "endOffset": 137}, {"referenceID": 16, "context": "Specifically, these attempts used similarity measures such as Pearson correlation [17] and Vector cosine similarity [2, 6] to evaluate the similarity level between different users.", "startOffset": 82, "endOffset": 86}, {"referenceID": 1, "context": "Specifically, these attempts used similarity measures such as Pearson correlation [17] and Vector cosine similarity [2, 6] to evaluate the similarity level between different users.", "startOffset": 116, "endOffset": 122}, {"referenceID": 5, "context": "Specifically, these attempts used similarity measures such as Pearson correlation [17] and Vector cosine similarity [2, 6] to evaluate the similarity level between different users.", "startOffset": 116, "endOffset": 122}, {"referenceID": 1, "context": "More recent work includes user and movie clustering [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence network [5] and probabilistic latent variable models [14, 7, 13].", "startOffset": 52, "endOffset": 63}, {"referenceID": 20, "context": "More recent work includes user and movie clustering [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence network [5] and probabilistic latent variable models [14, 7, 13].", "startOffset": 52, "endOffset": 63}, {"referenceID": 21, "context": "More recent work includes user and movie clustering [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence network [5] and probabilistic latent variable models [14, 7, 13].", "startOffset": 52, "endOffset": 63}, {"referenceID": 17, "context": "More recent work includes user and movie clustering [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence network [5] and probabilistic latent variable models [14, 7, 13].", "startOffset": 88, "endOffset": 92}, {"referenceID": 1, "context": "More recent work includes user and movie clustering [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence network [5] and probabilistic latent variable models [14, 7, 13].", "startOffset": 112, "endOffset": 115}, {"referenceID": 4, "context": "More recent work includes user and movie clustering [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence network [5] and probabilistic latent variable models [14, 7, 13].", "startOffset": 136, "endOffset": 139}, {"referenceID": 13, "context": "More recent work includes user and movie clustering [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence network [5] and probabilistic latent variable models [14, 7, 13].", "startOffset": 181, "endOffset": 192}, {"referenceID": 6, "context": "More recent work includes user and movie clustering [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence network [5] and probabilistic latent variable models [14, 7, 13].", "startOffset": 181, "endOffset": 192}, {"referenceID": 12, "context": "More recent work includes user and movie clustering [2, 21, 22], item-item similarities [18], Bayesian networks [2], dependence network [5] and probabilistic latent variable models [14, 7, 13].", "startOffset": 181, "endOffset": 192}, {"referenceID": 3, "context": "The factorized matrix can be used to fill out the unobserved entries in a way similar to latent factor analysis [4, 16, 9, 8].", "startOffset": 112, "endOffset": 125}, {"referenceID": 15, "context": "The factorized matrix can be used to fill out the unobserved entries in a way similar to latent factor analysis [4, 16, 9, 8].", "startOffset": 112, "endOffset": 125}, {"referenceID": 8, "context": "The factorized matrix can be used to fill out the unobserved entries in a way similar to latent factor analysis [4, 16, 9, 8].", "startOffset": 112, "endOffset": 125}, {"referenceID": 7, "context": "The factorized matrix can be used to fill out the unobserved entries in a way similar to latent factor analysis [4, 16, 9, 8].", "startOffset": 112, "endOffset": 125}, {"referenceID": 0, "context": ", [1, 15, 19].", "startOffset": 2, "endOffset": 13}, {"referenceID": 14, "context": ", [1, 15, 19].", "startOffset": 2, "endOffset": 13}, {"referenceID": 18, "context": ", [1, 15, 19].", "startOffset": 2, "endOffset": 13}], "year": 2010, "abstractText": "Recommendation systems are emerging as an important business application with significant economic impact. Currently popular systems include Amazon\u2019s book recommendations, Netflix\u2019s movie recommendations, and Pandora\u2019s music recommendations. In this paper we address the problem of estimating probabilities associated with recommendation system data using non-parametric kernel smoothing. In our estimation we interpret missing items as randomly censored observations and obtain efficient computation schemes using combinatorial properties of generating functions. We demonstrate our approach with several case studies involving real world movie recommendation data. The results are comparable with state-of-the-art techniques while also providing probabilistic preference estimates outside the scope of traditional recommender systems.", "creator": "LaTeX with hyperref package"}}}