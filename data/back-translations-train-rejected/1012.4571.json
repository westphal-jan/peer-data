{"id": "1012.4571", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2010", "title": "How I won the \"Chess Ratings - Elo vs the Rest of the World\" Competition", "abstract": "This article discusses in detail the rating system that won the kaggle competition \"Chess Ratings: Elo vs the rest of the world\". The competition provided a historical dataset of outcomes for chess games, and aimed to discover whether novel approaches can predict the outcomes of future games, more accurately than the well-known Elo rating system. The winning rating system, called Elo++ in the rest of the article, builds upon the Elo rating system. Like Elo, Elo++ uses a single rating per player and predicts the outcome of a game, by using a logistic curve over the difference in ratings of the players. The major component of Elo++ is a regularization technique that avoids overfitting these ratings. The dataset of chess games and outcomes is relatively small and one has to be careful not to draw \"too many conclusions\" out of the limited data. Many approaches tested in the competition showed signs of such an overfitting. The leader-board was dominated by attempts that did a very good job on a small test dataset, but couldn't generalize well on the private hold-out dataset. The Elo++ regularization takes into account the number of games per player, the recency of these games and the ratings of the opponents. Finally, Elo++ employs a stochastic gradient descent scheme for training the ratings, and uses only two global parameters (white's advantage and regularization constant) that are optimized using cross-validation.", "histories": [["v1", "Tue, 21 Dec 2010 09:11:53 GMT  (80kb,DS)", "http://arxiv.org/abs/1012.4571v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yannis sismanis"], "accepted": false, "id": "1012.4571"}, "pdf": {"name": "1012.4571.pdf", "metadata": {"source": "CRF", "title": "How I won the \u201cChess Ratings \u2014 Elo vs the Rest of the World\u201d Competition", "authors": ["Yannis Sismanis"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, it is so that most people who have lived in the United States for the last five years are not able to understand the world and understand why they do what they do. (...) It is not as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...). (...) It is as if they do it. (...) It is so. (...). \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (. \"(.).\" (. \"(.).\" (. \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.).\" (.). \"(. (.).\" (.). \"(.\" (.). \"(.).\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.). (.).\" (.). (.). (. \"(.).).\" (. (.). \"(. (.). (.).). (.). (.).\" (. (.). \"(.). (. (.). (.\" (.). (.). (.). (.). (.). (.). (.). (.). (. \"(.).). (.). (.). (.). (.). (. (.). (.). (.)."}, {"heading": "2 Basics & Notation", "text": "The result of a game between player i with white and player j with black is called oij. The result of a game is 1 if white wins, 1 / 2 if it is a tie, and 0 if black wins. We distinguish between predicted results and known ones by using the o-ij notation for the predicted dots. The month in which a game between player i and j takes place regardless of the color is called tij. Note that two players have played many games in different (or even equal) months. For simplicity of presentation, we will use the simple notations oij, o-ij, and tij to refer to all of these games. The training dataset T consists of tuples of the form < i, j, tij, oij, oij, oij >. Submission consists of predicting the form < i, j, o-ij >, for all games in the form < ij >."}, {"heading": "3.1 Time Scaling", "text": "Elo + + takes into account the time of each game, because old games are less important than newer games. For example, young players improve quickly, while top players maintain a stable high rating throughout their careers before they grow older and gradually lose some of their competitiveness. Capturing this time dynamic is important for any rating system; in Elo + + a simple weighting scheme was applied for the frequency of games. Suppose that tmin is the time when the earliest game in our data set happened (i.e. month 1 + tmin in the training data set) and tmax is the time when the last game took place (i.e. month 100). For a game that happened at a given time, the weight that worked best in the Elo + + experiments is: wij = (1 + tij \u2212 tmin 1 + tmin \u2212 tmin) 2.During the training of the ratings, the meaning of each game is scaled with the corresponding Wij."}, {"heading": "3.2 Neighbors", "text": "To avoid this, Elo + + assumes that most games between chess players take place in tournaments where players of comparable strength play against each other. In this section, we define a weighted average of a player's opponents i. In Section 3.3, we show how to use regulation to \"draw\" any rating ri close to their weighted average. Let's define the neighborhood Ni of a player i as the multiset of all opponents I played against, regardless of color. It is defined as a player's multiset, as a player has played the same opponent many times or with different colors. As we described, we expect there to be a precise link between the average connection of all opponents I played against, regardless of color."}, {"heading": "3.3 Rating Update Formulas", "text": "In this section we will discuss exactly how Elo + + optimizes the ratings so that the overall loss is minimized. (The logistical curve that Elo + + uses to predict the outcome of a game between white players and black players is: o) The total failure rate between the predicted and actual results in Elo + + is defined as: l = 0 The total failure rate in Elo + + + the actual results in Elo + + the differences between the results and the actual results in Elo + + the differences between the results and predictions and finally the results of the neighbors. \"The recession is expressed in the wij weights and the differences between the results and predictions. (oij \u2212 o) The total failure rate takes into account the differences between games, the differences between the results and the predictions.\" The l2 regulation \"of the ratings that are disproportionate away from the corresponding neighbors. Training in Elo + means the optimization of the ratings so that the overall failure is minimized."}, {"heading": "4 Quality Comparison", "text": "In this section we discuss the quality of the actual ratings given by Elo + +. Following the end of the competition, a list was provided with the actual names and Elo ratings of all players in the competition datasets. Below, we refer to this list as the Elo list. We compare and discuss the ratings given by Elo + + against these widely used Elo ratings. First, we \"normalize\" the ratings given by Elo + + to bring them in the same order as the Elo ratings. However, the normalization helps to directly compare the ratings. It is necessary because (a) Elo uses a basic 10 logistic curve instead of Elo +'s base e, (b) Elo scales the ratings by a factor of 400 and (c) Elo has limitations on the ratings of players at average level and master level that make the differences. Normalization simplifies the x-axis to multiply each player."}, {"heading": "5 Conclusions", "text": "My intention in writing this article is to celebrate the completion of the first Kaggle competition around chess ratings. It was the most popular Kaggle contest so far in terms of participation. Hopefully, a follow-up contest will allow further improvements in this interesting area. The science of chess rating systems is the main beneficiary of the competition. Many new people (including the author) got involved in this area and made their contributions. Of the numerous new algorithmic contributions discussed in the forums, I would like to emphasize (a) how important it is to regulate the ratings properly and (b) the basic logistic curve, which is still strong. Although more complex algorithmic aspects and models are possible, an accurate treatment of the basics is at least as important as the preparation of new modeling breakthroughs. The winning submission took place less than four weeks after the start of the competition. However, the discrepancies between these own cross-validations and the leaderboard deserved an improvement."}], "references": [{"title": "A limited memory algorithm for bound constrained optimization", "author": ["R.H. Byrd", "P. Lu", "J. Nocedal", "C. Zhu"], "venue": "SIAM J. Sci. Comput.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1995}, {"title": "Introduction to Stochastic Search and Optimization", "author": ["J.C. Spall"], "venue": "ISBN 0-471-33052-3,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}], "referenceMentions": [{"referenceID": 1, "context": "To address this optimization, Elo++ uses a stochastic gradient descent technique [10].", "startOffset": 81, "endOffset": 85}, {"referenceID": 1, "context": "The learning rate \u03b7 (see [10] for details) in Elo++ is defined as: \u03b7 = ( 1 + 0.", "startOffset": 25, "endOffset": 29}, {"referenceID": 0, "context": "Other alternatives for this optimization problem would be to use a deterministic optimization library, like for example L-BFGS-B [8].", "startOffset": 129, "endOffset": 132}], "year": 2010, "abstractText": "This article discusses in detail the rating system that won the kaggle competition \u201cChess Ratings: Elo vs the rest of the world\u201d. The competition provided a historical dataset of outcomes for chess games, and aimed to discover whether novel approaches can predict the outcomes of future games, more accurately than the well-known Elo rating system. The winning rating system, called Elo++ in the rest of the article, builds upon the Elo rating system. Like Elo, Elo++ uses a single rating per player and predicts the outcome of a game, by using a logistic curve over the difference in ratings of the players. The major component of Elo++ is a regularization technique that avoids overfitting these ratings. The dataset of chess games and outcomes is relatively small and one has to be careful not to draw \u201ctoo many conclusions\u201d out of the limited data. Many approaches tested in the competition showed signs of such an overfitting. The leader-board was dominated by attempts that did a very good job on a small test dataset, but couldn\u2019t generalize well on the private hold-out dataset. The Elo++ regularization takes into account the number of games per player, the recency of these games and the ratings of the opponents. Finally, Elo++ employs a stochastic gradient descent scheme for training the ratings, and uses only two global parameters (white\u2019s advantage and regularization constant) that are optimized using cross-validation.", "creator": "LaTeX with hyperref package"}}}