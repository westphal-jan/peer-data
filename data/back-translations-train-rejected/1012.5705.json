{"id": "1012.5705", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Dec-2010", "title": "Looking for plausibility", "abstract": "In the interpretation of experimental data, one is actually looking for plausible explanations. We look for a measure of plausibility, with which we can compare different possible explanations, and which can be combined when there are different sets of data. This is contrasted to the conventional measure for probabilities as well as to the proposed measure of possibilities. We define what characteristics this measure of plausibility should have.", "histories": [["v1", "Tue, 28 Dec 2010 07:14:32 GMT  (104kb)", "http://arxiv.org/abs/1012.5705v1", "6 pages, invited paper presented at the International Conference on Advanced Computer Science and Information Systems 2010 (ICACSIS2010), Bali, Indonesia, 20-22 November 2010"]], "COMMENTS": "6 pages, invited paper presented at the International Conference on Advanced Computer Science and Information Systems 2010 (ICACSIS2010), Bali, Indonesia, 20-22 November 2010", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["wan ahmad tajuddin wan abdullah"], "accepted": false, "id": "1012.5705"}, "pdf": {"name": "1012.5705.pdf", "metadata": {"source": "CRF", "title": "Looking for plausibility", "authors": ["Wan Ahmad Tajuddin", "Wan Abdullah"], "emails": [], "sections": [{"heading": null, "text": "In the interpretation of experimental data, one is actually looking for plausible explanations. We are looking for a measure of plausibility with which we can compare different possible explanations and which can be combined if there are different sets of data. In contrast to the conventional measure of probabilities and the proposed measure of possibilities, we are defining what characteristics this measure of plausibility should have. In order to arrive at the conception of this measure, we are investigating the relationship between plausibility and abductive thinking and Bayesian probabilities. We are also comparing with the Dempster-Schaefer theory of evidence, which also has its own definition of plausibility. Abduction can be associated with biconditionality in consequential rules, and this provides a platform to relate to the Collins-Michalski theory of plausibility. Finally, using a formalism for wiring the logic to neural networks of Hopfield, we are asking whether this is relevant for obtaining this measure."}, {"heading": "INTRODUCTION", "text": "Traditionally, uncertainty in sentences is handled by the concept of probability with its statistical interpretation. However, it is a bit strange when such an approach, based on the counting of events, is applied to hypotheses such as explanatory approaches. For example, when interpreting experimental data, one is looking for plausible explanations to describe the observed data. While probability can be seen as the basis of data measurement, a statistical picture may only be useful for explanations in a universe with several worlds. Therefore, we are looking for a measure of plausibility with which we can compare various possible explanations. Furthermore, this measure of plausibility should allow an appropriate combination when combining different explanations and / or data sets."}, {"heading": "UNCERTAINTY MEASURES", "text": "Probabilities are calculated from the number of events that satisfy and normalize the respective propositions from a total number of probabilities. Thus, probabilities for alternative explanations are exclusive, and the more alternatives there are, the fewer are the values for probabilities in general. Plausibility, on the other hand, should not behave as such... The plausibility of a proposition should not depend on the plausibility of an alternative proposition, let alone reduce it. In logical conjunctions, probabilities are combined by multiplication, and in conjunctions additionally, if the atoms are exclusive: P (X-Y) = P (X) \u00d7 P (Y) P (X-Y) = P (X) + P (Y) -P (X-Y) -P (X-Y) -P (X-Y). This does not necessarily follow for plausibility; in fact, for example, it does not seem intuitively correct that the plausibility of (X or Y) is the sum of the individual plausibility of X and Y.Plausibility is rather based on the clarity of (1) of the possibility of (1)."}, {"heading": "PLAUSIBILITY", "text": "Let us now define what properties the plausibility measure should have. \u2022 We can have a normalized scale from 0, which would indicate something that is not plausible at all, to 1, which indicates something that is completely plausible. \u2022 Let us call plausibility by \"pl\": pl (X) = 0: X is not all plausibility pl (X) = 1: X is completely plausible. \u2022 Plausibilities are not exclusive. For example, even if X and Y are not logically compatible, X can at the same time be perfectly plausible that Y is perfectly plausible: pl (X) + pl (Y) > 1 although X (Y) > Y = \"Like possibility, and unlike probability, plausibility is not self-explanatory. So that means pl (X), pl (\u00ac X).\" In other words, if something is not plausible at all, it does not mean that it is completely plausible that something is implausible."}, {"heading": "ABDUCTIVE REASONING", "text": "Abduction (see e.g. [4]), which Peirce first described more than a hundred years ago, is the process of arriving at the premise that would \"explain\" a given situation. Since the sentence of sentences C formally follows the sentence of sentences A, it is subject to the logical rules T, then the derivative of C from T and A is deduction, the derivative of T from C and A is induction, and the derivative of A from T and C is abduction. Note that the kidnapped sentence is sufficient but not necessary for C to follow from T, and can be one of many alternatives; in abduction, moreover, one usually seeks the most natural explanation in the form of the most economic. In the face of a series of true statements, a kidnapped thesis is then a plausible thesis. Plausibility is then a measure of how good the statement is in explaining the available facts. It can be related to how much of the requirement for sufficiency has been fulfilled."}, {"heading": "BAYESIAN PROBABILITIES", "text": "If propositions have probability values, then the abduction is related to conditional probabilities. Bayes \"theorem states that the probability for \u03b8 given x, P (\u03b8 | x) = P (x | \u03b8) P (\u03b8) / P (x) depends on the conditional probability or probability of x given \u03b8 multiplied by the previous probability for \u03b8. Abduction is the\" inversion \"of the deduction and the conditional probability is the\" inversion \"of the probability. Conditional probabilities then represent a possible model for plausibility. Combinations of plausibility in conclusions can copy those in Bayesian networks [5]. However, determining earlier probabilities poses a problem for the calculation of conditional probabilities."}, {"heading": "DEMPSTER-SHAFER THEORY", "text": "The Dempster-Shafer theory of proof [3] has its own definition of plausibility, which is based on a certain function of faith. Plausibility for a proposition is the sum of the \"masses of faith\" of other propositions that overlap with this proposition, while belief applies to those that are subsets and limits the probability: bel (X) \u2264 P (X) \u2264 pl (X) and are related, pl (X) = 1 - bel (\u00ac X). Theory prescribes a method of combining masses of faith from different assignments, in the spirit of Bayesian theory. To obtain the plausibility of a combined set of propositions, one must recalculate using the primary definition. Assignment of masses of faith is problematic here, and its association with probabilities is also misleading."}, {"heading": "BICONDITIONALITY AND COLLINS-MICHALSKI", "text": "Collins and Michalski have proposed a theory of plausible reasoning [6] that contains several kinds of conclusions, namely mutual implications, interdependence, generalization, specialization, and similarity / analogy. One drawback is that it has a limited number of parameters to model uncertainty. [7] This refers to abduction, since abduction coincides with deduction when implications are replaced by equivalencies. In the probability picture, this is like equating conditional probability with probability, P (\u03b8 | x) = P (x | \u03b8) Of course, this is not rational; after all, this is a plausible reasoning. However, this supports the idea that plausibility has an abductive basis."}, {"heading": "CONNECTIONIST", "text": "It has been shown [8,9] that logic can be linked to a neural Hopfield network [10]. The Hopfield network minimizes a Lyapunov or \"energy\" function related to synaptic strengths [11]. By writing an expression that results in a value proportional to dissatisfied clauses, the network then searches for an optimal logical interpretation of the proposition atoms represented by neurons, resulting in the values for the synapses. In a sense, logic is contained in the synapses. From the synaptic strengths, we can then draw conclusions about the logical clauses [12], which may be helpful in our search for a measure of plausibility."}, {"heading": "PLAUSIBILITY, PLAUSIBLY", "text": "Finally, we can take some preliminary steps towards plausibility. If one assumes an abductive interpretation, this means that the more of the set of existing \"measured\" propositions C is a hypothetical set of Ai forces, the more plausible Ai should be. Perhaps, then, the plausibility of Ai corresponds to the fraction of the propositions in C that Ai is forced to be correct (both true and false). If Ai has no effect on C, then Ai should have plausibility 0, and if the forces in C are all known propositions correct, then Ai has plausibility. What is interesting is the combination of plausibility. Is it possible to have simple combination rules for conjunctions and disjunctions, for example? For propositions Ai and Aj, which each force disjunct subsets of C and have no common impact on the accuracy of any subset, then plausibility is of interest (Ai plausibility)."}, {"heading": "CONCLUSIONS", "text": "In summary, we have examined the concept of plausibility and tried to characterize a measurement parameter for it. In particular, we have chosen an abductive basis and suspect that a hypothesis is more plausible if it forces more of the measured truth. In simple cases, we can write down the rules for combinations. Furthermore, we have shown how plausibility can be measured using a logical neural network. This exploratory proposal for plausibility needs to be further investigated, especially for the non-trivial cases of combinations. It is hoped that the combination of plausibility would help in the interpretation of measurement combinations in experimental data."}, {"heading": "13 (1989) 1-49.", "text": "[7] W. A. T. Wan Abdullah, \"Biconditionality, Analogy, Induction and Predicate Logic,\" Malaysian J. Comput. Sci. 3 (1987) 21-28. [8] W. A. T. Wan Abdullah, \"Neural Network Logic,\" in: O. Benhar, C. Bosio, P. del Giudice & E. Tabet (eds.), Neural Networks: From Biology to High Energy Physics, ETS Editrice, Pisa, 1991, pp. 135-142. [9] W. A. T. Wan Abdullah, \"Logic Programming on a Neural Network,\" J. of Intelligent Systems 7 (1992) 513-519. [10] J. Hopfield, \"Neural Networks and Physical Systems with Emerent Collective Computational abilities,\" Proc. Natl. Acad. Sci. USA 79 (1982) 2554-2558. [11] J. J. J. Hopfield & D. W. Tank, \"Neural Computation of Biol in 652. Acad."}], "references": [{"title": "Fuzzy Sets as the Basis for a Theory of Possibility", "author": ["L. Zadeh"], "venue": "Fuzzy Sets and Systems 1 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1978}, {"title": "Fuzzy sets", "author": ["L.A. Zadeh"], "venue": "Information and Control 8 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1965}, {"title": "A Mathematical Theory of Evidence", "author": ["G. Shafer"], "venue": "Princeton Univ. Press, Princeton NJ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1976}, {"title": "Abduction", "author": ["L. Magnani"], "venue": "Reason and Science: Processes of Discovery and Explanation, Kluwer, New York", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Probabilistic Inferences in Bayesian Networks", "author": ["J. Ding"], "venue": "e-print arXiv:1011.0935", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Biconditionality", "author": ["W.A.T. Wan Abdullah"], "venue": "Analogy, Induction and Predicate Logic\u201d, Malaysian J. Comput. Sci. 3 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1987}, {"title": "Neural Network Logic", "author": ["W.A.T. Wan Abdullah"], "venue": "O. Benhar, C. Bosio, P. del Giudice & E. Tabet (eds.), Neural Networks: From Biology to High Energy Physics, ETS Editrice, Pisa", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1991}, {"title": "Logic Programming on a Neural Network", "author": ["W.A.T. Wan Abdullah"], "venue": "J. of Intelligent Systems 7 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1992}, {"title": "Neural networks and physical systems with emergent collective computational abilities", "author": ["J.J. Hopfield"], "venue": "Proc. Natl. Acad. Sci. USA 79 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1982}, {"title": "Neural\u201d Computation of Decisions in Optimization Problems", "author": ["J.J. Hopfield", "D.W. Tank"], "venue": "Biol. Cybern", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1985}, {"title": "The Logic of Neural Networks", "author": ["W.A.T. Wan Abdullah"], "venue": "Phys. Lett. 176A ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 0, "context": "Plausibility seems closer to the notion of possibility [1] (based on fuzzy sets, thus rather similar to fuzzy logic [2]) when combinations are concerned.", "startOffset": 55, "endOffset": 58}, {"referenceID": 1, "context": "Plausibility seems closer to the notion of possibility [1] (based on fuzzy sets, thus rather similar to fuzzy logic [2]) when combinations are concerned.", "startOffset": 116, "endOffset": 119}, {"referenceID": 2, "context": "Other than probabilities and possibilities, other uncertainty measures (sometimes with similar names) have been proposed by, for example Dempster and Shafer [3], further studied below, and others.", "startOffset": 157, "endOffset": 160}, {"referenceID": 0, "context": "This means that now pl(X) \u2208 [-1,1], giving values for fully plausibly false on the one end, and fully plausibly true on the other, with nonplausibility (\u2018non-relevance\u2019) in the middle.", "startOffset": 28, "endOffset": 34}, {"referenceID": 3, "context": "[4]), first described by Peirce more than a hundred years ago, is the process of arriving at the premise which would 'explain' some situation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Combinations of plausibilities in inferences can copy those in Bayesian networks [5].", "startOffset": 81, "endOffset": 84}, {"referenceID": 2, "context": "The Dempster-Shafer theory of evidence [3] has its own definition for plausibility which is based on some belief function.", "startOffset": 39, "endOffset": 42}, {"referenceID": 5, "context": "The inferences existing in Collins-Michalski theory are mostly explained by biconditionality, wherein implications are taken to also include some degree of equivalences [7].", "startOffset": 169, "endOffset": 172}, {"referenceID": 6, "context": "It has been shown [8,9] that logic can be hardwired onto a Hopfield neural network [10].", "startOffset": 18, "endOffset": 23}, {"referenceID": 7, "context": "It has been shown [8,9] that logic can be hardwired onto a Hopfield neural network [10].", "startOffset": 18, "endOffset": 23}, {"referenceID": 8, "context": "It has been shown [8,9] that logic can be hardwired onto a Hopfield neural network [10].", "startOffset": 83, "endOffset": 87}, {"referenceID": 9, "context": "The Hopfield network minimizes a Lyapunov or \u201cenergy\u201d function related to the synaptic strengths [11].", "startOffset": 97, "endOffset": 101}, {"referenceID": 10, "context": "From the synaptic strengths then, we can make inferences about the logical clauses [12].", "startOffset": 83, "endOffset": 87}, {"referenceID": 10, "context": "For this, synaptic weights, or equivalently, clauses in T need to be known explicitly; however, this can be obtained [12] through Hebbian learning.", "startOffset": 117, "endOffset": 121}], "year": 2010, "abstractText": "In the interpretation of experimental data, one is actually looking for plausible explanations. We look for a measure of plausibility, with which we can compare different possible explanations, and which can be combined when there are different sets of data. This is contrasted to the conventional measure for probabilities as well as to the proposed measure of possibilities. We define what characteristics this measure of plausibility should have. In getting to the conception of this measure, we explore the relation of plausibility to abductive reasoning, and to Bayesian probabilities. We also compare with the Dempster-Schaefer theory of evidence, which also has its own definition for plausibility. Abduction can be associated with biconditionality in inference rules, and this provides a platform to relate to the Collins-Michalski theory of plausibility. Finally, using a formalism for wiring logic onto Hopfield neural networks, we ask if this is relevant in obtaining this measure.", "creator": "Writer"}}}