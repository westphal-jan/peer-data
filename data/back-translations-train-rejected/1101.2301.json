{"id": "1101.2301", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jan-2011", "title": "A Factorial Experiment on Scalability of Search Based Software Testing", "abstract": "Software testing is an expensive process, which is vital in the industry. Construction of the test-data in software testing requires the major cost and to decide which method to use in order to generate the test data is important. This paper discusses the efficiency of search-based algorithms (preferably genetic algorithm) versus random testing, in soft- ware test-data generation. This study differs from all previous studies due to sample programs (SUTs) which are used. Since we want to in- crease the complexity of SUTs gradually, and the program generation is automatic as well, Grammatical Evolution is used to guide the program generation. SUTs are generated according to the grammar we provide, with different levels of complexity. SUTs will first undergo genetic al- gorithm and then random testing. Based on the test results, this paper recommends one method to use for automation of software testing.", "histories": [["v1", "Wed, 12 Jan 2011 09:28:22 GMT  (376kb,D)", "http://arxiv.org/abs/1101.2301v1", "3d Artificial Intelligence Techniques in Software Engineering Workshop, 7 October, 2010, Larnaca, Cyprus"]], "COMMENTS": "3d Artificial Intelligence Techniques in Software Engineering Workshop, 7 October, 2010, Larnaca, Cyprus", "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["arash mehrmand", "robert feldt"], "accepted": false, "id": "1101.2301"}, "pdf": {"name": "1101.2301.pdf", "metadata": {"source": "CRF", "title": "A Factorial Experiment on Scalability of Search Based Software Testing", "authors": ["Arash Mehrmand", "Robert Feldt"], "emails": [], "sections": [{"heading": null, "text": "Keywords: Automated Software Testing, Search-based Software Testing, Genetic Algorithms, Random Testing, Grammatical Evolution"}, {"heading": "1 Introduction", "text": "The term \"testing\" is one of the most critical and time-consuming and costly activities in software development [1]. In order to reduce these costs as much as possible, we need to employ effective techniques to automate this process. What really needs to be automated is the generation of test data, which is a demanding process [2]. Test data automation helps to have a fast, cheap and error-free process."}, {"heading": "2 Previous Research and Related Work", "text": "There are many studies in the field of software testing automation and SBST. Some of them also deal with software complexity, but we could not find any that would be similar to this study, as we are dealing with increasing software complexity along our study. Thus, authors in [4] discuss experiments with test case generation with large and complex programs and come to the conclusion that there is a large gap between the techniques based on GA and those based on random testing. They have selected some programs that are written in C language and they call them SUT.Compared with what the authors tried to explain in [4], our study shows a big difference, and that is the use of many Java programs that vary in size and complexity. Many other studies have tried to experiment software tests with genetic algorithms and compare the results with other techniques. Authors in [5] conducted experiments on some small and some complex test objects through BA, and they came to this test situation: software testing situations with GA does not always meet with GA-based optimization."}, {"heading": "3 Experiment Approach", "text": "The approach chosen for this study is the factorial experiment, which compares GA- and random efficiency tests. Factorial experiment is an experiment whose design consists of two or more factors, and each factor has discrete possible values, which we call levels [1]. Factors mentioned in Table 1 are the test search techniques, which have GA- and random values, complexity, which has low, middle, and high levels, statement coverage, and industry coverage with their defined levels. Since we need to gradually increase the complexity of our generated programs, there are some factors that we need to increase or decrease in order to change the complexity of the programs. Code complexity is actually an independent variable in our experiment. Statement and industry are independent, but dependent on the level of complexity; the more complexity level we have, the more industry or statement we have to deal with. Below is a table showing the factual design of this experiment."}, {"heading": "4 Experiment Design", "text": "To design a fully automated process for our experiment, we must follow a step-by-step structure. These steps are the following subsections: 4"}, {"heading": "4.1 Generate Software Under Test (SUT) Using Grammatical Evolution (GE)", "text": "The reason for this is that the number of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to move, to dance, to dance, to move, to dance, to dance, to dance, to dance, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance"}, {"heading": "4.2 GA", "text": "In fact, it is as if most people who are able to determine for themselves what they want and what they want to do are not doing it. (...) It is as if they are doing it. (...) It is as if they are doing it. (...) It is as if they are doing it. (...) It is as if they are doing it. (...) It is as if they are doing it. (...) It is as if they are doing it. (...) It is as if they are doing it. (...) It is as if they are doing it. (...) It is as if they are doing it. (...) It is as if they are going to do it. \"(...)\" It is as if they are doing it. (...) It is as if they are doing it. \""}, {"heading": "4.3 Random Testing", "text": "Random testing is the approach chosen in this study, which is to be compared to SBST. [16] Random testing is actually the use of randomly generated test data, which has some advantages, such as simple and simple implementation and execution speed, which means less runtime. If we do the test by random testing, we need to define a parameter; this parameter determines how often we should generate test data by random testing. For example, setting the parameter to 100 generates 100 test cases. From these [e.g.] 100 we take the best one and compare it to the most suitable result of GA. In this experiment, however, this number is set to 100000.By random testing, we need to define our input domain for test data so that the numbers are randomly generated from this domain. In this study, this sentence starts from \u2212 1000000 to + 100000000.7."}, {"heading": "5 Experiment Results", "text": "As already mentioned, the entire experiment includes the testing of 60 programs; 30 (10 with low, 10 with medium, and 10 with high complexity) for the purpose of instruction coverage; and 30 (10 with low, 10 with medium, and 10 with high complexity) for the purpose of instruction coverage. The programs generated are also different in that they are generated with two different fitness functions. Example programs for instruction coverage are generated with the number of instructions and the programs used for instruction coverage are generated with the number of branches. Please note that the following diagrams each contain 10 programs randomly selected from several runs that we did not have. 8As mentioned above, these diagrams represent the result of 10 selected programs, but to see how efficient GA is, please refer to Tables II and III, where they show the average percentage of coverage with significantly different probability."}, {"heading": "6 Discussion", "text": "In fact, the fact is that most of them are able to move to another world in which they are able to be in, in which they are able to be in, in which they are able to be in, in which they are able to move."}, {"heading": "7 Conclusion", "text": "In this paper, we reported on the results of a factor experiment comparing the effectiveness of GA with random testing in the automation of software testing. In this experiment, the process of generating SUTs was also automated, which means that we used GE to create our sample Java programs. To our knowledge, we focus on the efficiency of the techniques and do not take into account other attributes such as time, cost, etc. The following are our observations from the experiments and the results recorded. - GA is better at random testing and indeed did so in this study with our automatically generated SUTs. We proved it with a factor experiment. This factor experiment with different levels of software complexity and two methods of code coverage shows that GA is more efficient than random testing in most situations. - Random testing could be a quicker solution, however, as it hardly proves more complex in the real world."}], "references": [{"title": "A Novel Approach To Automated Testing To Increase Software Reliability", "author": ["M. Catelani", "L. Ciani", "V. Scarano", "A. Bacioccola"], "venue": "Instrumentation and Measurement Technology Conference Proceedings 1499\u20131502", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Automated Test Data Generation using Search Based Software Engineering", "author": ["Harman", "Mark"], "venue": "AST \u201907: Proceedings of the Second International Workshop on Automation of Software Test, 2", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "A Search-Based Automated Test-Data Generation Framework for Safety-Critical Software", "author": ["Nigel James Tracy"], "venue": "University of York", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2000}, {"title": "Genetic algorithms for dynamic test data generation", "author": ["Christoph C. Michael", "Gary E. Mcgraw", "Michael A", "Curtis C. Walton"], "venue": "In Proc. ASE97, 307\u2013308", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1997}, {"title": "Applying particle swarm soptimization to software testing", "author": ["Windisch", "Andreas", "Wappler", "Stefan", "Wegener", "Joachim"], "venue": "GECCO \u201907: Proceedings of the 9th annual conference on Genetic and evolutionary computation, 1121\u20131128", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Genetic algorithm based software testing", "author": ["Alander", "Jarmo T.", "Mantere", "Timo", "Turunen", "Pekka."], "venue": "Turku Centre for Computer Science, Springer-Verlag", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1998}, {"title": "Observations in using parallel and sequential evolutionary algorithms for automatic software testing", "author": ["Alba", "Enrique", "Chicano", "Francisco."], "venue": "Comput. Oper. Res., 3161\u20133183", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Search-based test case generation for object-oriented java software using strongly-typed genetic programming", "author": ["Ribeiro", "Jos\u00e9 Carlos Bregieiro"], "venue": "GECCO \u201908: Proceedings of the 2008 GECCO conference companion on Genetic and evolutionary computation, 1819\u20131822", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "The Automatic Generation of Software Test Data Using Genetic Algorithms", "author": ["Harmen-Hinrich Sthamer"], "venue": "University of Glamorgan", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1995}, {"title": "Effective Black-Box Testing with Genetic Algorithms", "author": ["Mark Last", "Shay Eyal", "Abraham Kandel"], "venue": "Hardware and Software, Verification and Testing, 134\u2013148", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Selection in factorial experiments", "author": ["Bechhofer", "Robert E."], "venue": "WSC \u201977: Proceedings of the 9th conference on Winter simulation 65\u201370", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1977}, {"title": "GEVA: grammatical evolution in Java", "author": ["O\u2019Neill", "Michael", "Hemberg", "Erik", "Gilligan", "Conor", "Bartley", "Eliott", "McDermott", "James", "Brabazon", "Anthony"], "venue": "SIGEVOlution,ACM, 17\u201322", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "A BNF-based automatic test program generator for compatible microprocessor verification ACM Trans", "author": ["Wu", "Lieh-Ming", "Wang", "Kuochen", "Chiu", "Chuang-Yi"], "venue": "Des. Autom. Electron. Syst., 105\u2013132", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}, {"title": "Automatic test generation for functional verification of microprocessors", "author": ["J. BMiyake", "G. Brown"], "venue": "In Proceedings of the Third Asian Test Symposium , 292\u2013297", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1994}, {"title": "Experimental assessment of random testing for object-oriented software", "author": ["Ciupa", "Ilinca", "Leitner", "Andreas", "Oriol", "Manuel", "Meyer", "Bertrand."], "venue": "ISSTA \u201907: Proceedings of the 2007 international symposium on Software testing and analysis, 84\u201394", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Generating Software Test Data by Evolution", "author": ["Gary Mcgraw", "Christoph Michael", "Michael Schatz"], "venue": "IEEE Transactions on Software Engineering, 1085\u20131110", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1997}, {"title": "Genetic Programming with simple loops", "author": ["Yuesheng Qi", "Baozhong Wang", "Lishan Kang."], "venue": "Journal of Computer Science and Technology,429\u2013434", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "Designing and Prototyping a Functor Language Using Denotational Semantics", "author": ["Wolfgang Stcher"], "venue": "RISC Report Series, University of Linz, Austria,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1997}, {"title": "Towards a simpler method of operational semantics for language definition", "author": ["M.D. Derk"], "venue": "SIGPLAN Not., ACM, 39\u201344", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "Genetic Algorithm Fitness Function for Mutation Testing", "author": ["Bottaci", "Leonardo."], "venue": "Department of Computer Science, The University of Hull, Hull HU6 7RX, U.K.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "Software testing is one of the most critical and at the same time most time and cost consuming activity in software development process [1].", "startOffset": 136, "endOffset": 139}, {"referenceID": 1, "context": "What actually needs to be automated is generating the test data which is a demanding process [2].", "startOffset": 93, "endOffset": 96}, {"referenceID": 1, "context": "Automation of generating test data helps to have fast, cheap and error free process [2].", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "Among optimization techniques, search based optimization is the one which has been applied to different areas of Software Engineering applications [2].", "startOffset": 147, "endOffset": 150}, {"referenceID": 1, "context": "The recent years show a dramatic rise of interest in Search Based Testing (SBT) [2].", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": "SBT has been applied to different testing areas such as structural, functional, non-functional, mutation, regression and so on [2].", "startOffset": 127, "endOffset": 130}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "According to [3] flexibility and strength of these heuristic optimization techniques help a lot in finding the optimal solutions in large and complex search spaces.", "startOffset": 13, "endOffset": 16}, {"referenceID": 3, "context": "For example, authors in [4] discuss the experiments with test case generation with large and complex programs and they conclude that, there is a wide gap between the techniques based on GA and those based on random testing.", "startOffset": 24, "endOffset": 27}, {"referenceID": 3, "context": "Compared to what the authors tried to explain in [4], our study has a major difference and that is the use of many Java programs that vary in size and complexity.", "startOffset": 49, "endOffset": 52}, {"referenceID": 4, "context": "Authors in [5] performed experiments on some small and a few complex test objects and they came up with this results: Particle Swarm Optimization overcomes GA in coverage of many code elements so not always GA is the best solution.", "startOffset": 11, "endOffset": 14}, {"referenceID": 5, "context": "Another paper also talks about GA based software testing and the main idea is to find problematic situations while testing programs with GA [6].", "startOffset": 140, "endOffset": 143}, {"referenceID": 6, "context": "Alba and Chicano in their paper [7] describe how canonical genetic algorithms and evolutionary strategies can help in software testing.", "startOffset": 32, "endOffset": 35}, {"referenceID": 7, "context": "[8],[9],[10]) have used SBT specially GA in order to test the software and compare the results with other techniques.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[8],[9],[10]) have used SBT specially GA in order to test the software and compare the results with other techniques.", "startOffset": 4, "endOffset": 7}, {"referenceID": 9, "context": "[8],[9],[10]) have used SBT specially GA in order to test the software and compare the results with other techniques.", "startOffset": 8, "endOffset": 12}, {"referenceID": 0, "context": "Factorial experiment is an experiment whose design consists of two or more factors and each factor has discrete possible values which we call them levels [1].", "startOffset": 154, "endOffset": 157}, {"referenceID": 11, "context": "This advantage actually originates from the use of grammar to describe the structures that are generated by GE [12].", "startOffset": 111, "endOffset": 115}, {"referenceID": 15, "context": "\u2013 Population size: 200 \u2013 Generation: 10000 \u2013 Initial chromosome-size: 200 \u2013 Selection type: Roulette wheel [17].", "startOffset": 107, "endOffset": 111}, {"referenceID": 15, "context": "However, the followings are the steps, GA basically, uses to test a software where P (t) is the population and t is the generation [17]:", "startOffset": 131, "endOffset": 135}, {"referenceID": 19, "context": "The more cost each input value has, the more appropriate it is, so we aim to maximize this value and therefore maximize the fitness function [21].", "startOffset": 141, "endOffset": 145}, {"referenceID": 15, "context": "We used the term which is called function minimization [17].", "startOffset": 55, "endOffset": 59}, {"referenceID": 14, "context": "According to [16] random testing is actually the use of randomly generated of test data which has some advantages such as easy and simple implementation and speed of execution, which means less run time.", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "However, having breaks, even if we assign maximum iteration to a large number, causes the code not to get tested completely [14,15].", "startOffset": 124, "endOffset": 131}, {"referenceID": 13, "context": "However, having breaks, even if we assign maximum iteration to a large number, causes the code not to get tested completely [14,15].", "startOffset": 124, "endOffset": 131}, {"referenceID": 16, "context": "The authors in [18] do not recommend using nested loops; instead they suggest another way which is called LoopN.", "startOffset": 15, "endOffset": 19}], "year": 2016, "abstractText": "Software testing is an expensive process, which is vital in the industry. Construction of the test-data in software testing requires the major cost and to decide which method to use in order to generate the test data is important. This paper discusses the efficiency of searchbased algorithms (preferably genetic algorithm) versus random testing, in software test-data generation. This study differs from all previous studies due to sample programs ot software under test (SUT) which are used. Since we want to increase the complexity of SUTs gradually, and the program generation is automatic as well, Grammatical Evolution is used to guide the program generation. SUTs are generated according to the grammar we provide, with different levels of complexity. SUTs will first undergo genetic algorithm and then random testing. Based on the test results, this paper recommends one method to use for automation of software testing.", "creator": "LaTeX with hyperref package"}}}