{"id": "1102.2748", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2011", "title": "Feature Selection via Sparse Approximation for Face Recognition", "abstract": "Inspired by biological vision systems, the over-complete local features with huge cardinality are increasingly used for face recognition during the last decades. Accordingly, feature selection has become more and more important and plays a critical role for face data description and recognition. In this paper, we propose a trainable feature selection algorithm based on the regularized frame for face recognition. By enforcing a sparsity penalty term on the minimum squared error (MSE) criterion, we cast the feature selection problem into a combinatorial sparse approximation problem, which can be solved by greedy methods or convex relaxation methods. Moreover, based on the same frame, we propose a sparse Ho-Kashyap (HK) procedure to obtain simultaneously the optimal sparse solution and the corresponding margin vector of the MSE criterion. The proposed methods are used for selecting the most informative Gabor features of face images for recognition and the experimental results on benchmark face databases demonstrate the effectiveness of the proposed methods.", "histories": [["v1", "Mon, 14 Feb 2011 12:05:47 GMT  (102kb)", "http://arxiv.org/abs/1102.2748v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["yixiong liang", "lei wang", "yao xiang", "beiji zou"], "accepted": false, "id": "1102.2748"}, "pdf": {"name": "1102.2748.pdf", "metadata": {"source": "CRF", "title": "Feature Selection via Sparse Approximation for Face Recognition", "authors": ["Yixiong Liang", "Lei Wang", "Yao Xiang", "Beiji Zou"], "emails": ["bjzou}@mail.csu.edu.cn"], "sections": [{"heading": null, "text": "ar Xiv: 110 2.27 48v1 [cs.CV] 1 4Fe b20 11Index Terms - Face detection, feature selection, low approximation, minimum square error criterion, Ho-Kashyap method."}, {"heading": "1 INTRODUCTION", "text": "In fact, it is such that most of them will be able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there"}, {"heading": "4 GABOR FEATURE SELECTION FOR", "text": "FACE RECOGNITION In this section, we describe how to specialize the proposed selection frame in the case of face recognition. We first briefly review the Gabor representation of the face and then describe how we apply the suggested selection methods to select Gabor features for face recognition."}, {"heading": "4.1 Gabor representation", "text": "We begin with the widely distributed Gabor presentation, because the cores of the Gabor filters \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "4.2 Feature selection for face recognition", "text": "Similar to Moghaddam et al. [24], we temporarily throw facial recognition into a classification of intrapersonal (hereinafter referred to as positive) and extrapersonal (hereinafter referred to as negative) variation. For each pair of facial images Ii and I \u2032 i, we then compare the corresponding gabor characteristics components. In particular, we obtain for each pair of input images a feature vector xi, the elements of which are the absolute difference between the corresponding gabor representations. In view of a training set, we can then obtain the extended feature matrix Y following the routine described in Section 2. A by no means negligible problem in practice is the overwhelmingly huge size and imbalance of the training samples [16]. In the face of a training set containing K images for each of the C individuals, the total number of image pairs (CK2), while only a small minority, C (K2) of these pairs we present in the separation systems = 7eral can be."}, {"heading": "5 EXPERIMENTS AND RESULTS", "text": "To evaluate the proposed approach, we are conducting some experiments on two large facial databases: CAS-PEAL-R1 [11] and LFW [15] Facial Database. The CAS-PEAL-R1 Facial Database contains 30, 863 images of 1 040 Chinese subjects with different poses, facial expressions, accessories, age and lighting. The LFW Facial Database contains 13, 233 labeled face images collected from news sites on the Internet. These images belong to 5, 749 different individuals and exhibit major differences in position, pose, lighting, background, camera, and quality. Therefore, the LFW Database is better suited for evaluating face recognition methods in realistic and unrestricted environments. In all of our experiments, each image is rotated and scaled so that the eye centers are set to specific pixels and then cropped to 64 x 64 pixels. As described above, we select only 32 gabor filters to extract the Gabor from the Gabor."}, {"heading": "5.1 Results on CAS-PEAL-R1 database", "text": "We strictly follow the CAS-PEAL-R1 evaluation protocol, which specifies a training set, a gallery set and six probe sets [11]. Therefore, the training sets contain 1, 200 images of 300 subjects and the ratio of intrapersonal sample size to extrapersonal sample size is 1, 800: 717, 600. We keep all intrapersonal samples while randomly scanning the extra-personal samples at a ratio of 1: 7. Taking into account all Gabor characteristics, the linear problem we are going to create is quite large. In fact, the size of the extended feature matrix Y is 131, 073 x 14, 400. Obviously, direct multiplication on such a matrix is not feasible. One possible choice is to reduce the number of Gabor characteristics if possible, with the prior knowledge that the size of the Gabor filters is not sensitive to the positions, so we can reduce the total number of 16 by a number of keys with approximately 16 x."}, {"heading": "5.1.1 Feature selection results", "text": "We conducted experiments with the CAS-PEALR1 training set in which SSMES, SFisher and SHK procedures were used to select 500 Gabor characteristics each, the characteristics of which can be observed on the basis of their statistics. The location distribution of selected Gabor characteristics is shown in Fig. 1. It is interesting to see that most of the Gabor characteristics selected, resulting from all three methods, lie around prominent facial characteristics such as eyebrows, eyes, nose and mouth, while they are rarely in the area of the corners. This indicates that the most prominent facial characteristics contain the most important differentiating information, while the cheek region conveys less information. In addition, a minority of selected characteristics are located on outer characteristics such as cheek contour and jawline. Although the outer region does not strongly cover the face, the outer characteristics implicitly use shape information and are therefore useful to distinguish thin faces from outer characteristics such as cheek contour and jawline."}, {"heading": "5.1.2 Classification results", "text": "The selected Gabor characteristics are then used for face recognition. \"The classic classifiers, NNC and FC, are selected to recognize the faces.\" As mentioned above, the proposed feature selection framework can perform the intra-personal and extra-personal recognition task. So we have used it for face recognition as well, treating facial recognition as a series of couple matching problems. However, in many situations there is more than one issue that meets the separation requirement. To make a final decision, we simply classify the unknown face as a subject whose samples can maximize the linear discrimination function, i.e. the margin. Therefore, it can in a sense be considered the maximum margin classification method (MMC). We also implement 3 previous aborted-based approaches for comparison. The first uses Gabor function without face selection and NNC for recognition, which is referred to as \"G + NNNC.\" The second method is called \"FC + FC + GFC + the second method.\""}, {"heading": "5.2 Results on LFW database", "text": "Unlike the CAS-PEAL-R1 database, the LFW database has a higher degree of variability, and detection occurs only through pairs matching, rather than looking for the most similar face in the database. View 2 still consists of ten sets of 600 images each, which can be combined into 10 different training / test set pairs. In our experiments, the training sets from View 1 are selected for training the feature selection model, and performance is reported with 10x cross validation on View 2. The proposed feature selection frame is used as a feature selector to select 500 of the most informative features from the original 131, 072 original features. We have adopted the proposed frame directly as a classifier to detect the unknown pairs in the company with the SVM classification. \"The proposed feature selection boxes are used as a feature selector to select 500 of the most informative features from the original 131, 072 original features."}, {"heading": "6 CONCLUSION", "text": "We presented a novel feature selection algorithm based on well-founded sparsity-enforcing regulation techniques for facial recognition. We transformed the feature selection problem into a combinatorial sparse approach problem by imposing a sparse penalty expression on the MSE criterion, which can be solved by greedy methods or convex relaxation methods. Furthermore, we introduced the sparsity restriction into the traditional HK procedure and proposed a sparse HK procedure in order to simultaneously obtain the optimal sparse solution and the corresponding margin vector of the MSE criterion. The proposed framework was applied to select the most informative gabor features for facial recognition, and the experimental results on the CAS-PEAL-R1 facial database and the LFW facial database are advantageous compared to the most modern gabor-based methods available to date, and our future work includes the development of other facial identification techniques to achieve better effectiveness."}, {"heading": "ACKNOWLEDGMENTS", "text": "This research is partially supported by the National Natural Science Funds of China (# 60803024 and # 60970098), the Doctoral Program Foundation of Institutions of Higher Education of China (# 200805331107 and # 20090162110055), the Major Program of National Natural Science Foundation of China (# 90715043), and the Open Project Program of the State Key Lab of CAD & CG (# A0911 and # A1011) of Zhejiang University."}], "references": [{"title": "Face recognition using HOG-EBGM,", "author": ["A. Albiol", "D. Monzo", "A. Martin", "J. Sastre"], "venue": "Pattern Recogn. Lett.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Face recognition by independent component analysis,", "author": ["M.S. Bartlett", "J.R. Movellan", "T.J. Sejnowski"], "venue": "IEEE Trans. Neural Netw.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Eigenfaces vs. Fisherfaces: Recognition using class specific linear projection,", "author": ["P.N. Belhumeur", "J.P. Hespanha", "D.J. Kriegman"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "On the use of SIFT features for face authentication,", "author": ["M. Bicego", "A. Lagorio", "E. Grosso", "M. Tistarelli"], "venue": "Proc. IEEE Conf. Computer Vision and Pattern RecognitionWorkshop,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Face Recognition with Learning-based Descriptor,\u201d,Proc", "author": ["Z.M. Cao", "Q. Yin", "X.O. Tang", "J. Sun"], "venue": "IEEE Conf. Computer Vision and Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "LIBSVM: a library for support vector machines", "author": ["C. Chang", "C. Lin"], "venue": "ntu. edu. tw/cjlin/libsvm", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "A regularized framework for feature selection in face detection and authentication", "author": ["A. Destrero", "C.De Mol", "F. Odone", "A. Verri"], "venue": "Int. J. Comput. Vis.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Optimal Gabor filters for texture segmentation,", "author": ["D. Dunn", "W. Higgins"], "venue": "IEEE Trans. Image Process.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1995}, {"title": "The CAS-PEAL large-scale chinese face database and baseline evaluations,", "author": ["W. Gao", "B. Cao", "S.G. Shan", "X.L. Chen", "D.L. Zhou", "X.H. Zhang", "D.B. Zhao"], "venue": "IEEE Trans. Syst. Man Cybern. A.,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "An introduction to variable and feature selection,", "author": ["I. Guyon", "E. Elisseeff"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Face recognition using laplacianfaces,", "author": ["X. He", "S. Yan", "Y. Hu", "P. Niyogi", "H.J. Zhang"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Face recognition: Component-based versus global approaches,", "author": ["B. Heisele", "P. Ho", "J. Wu", "T. Poggio"], "venue": "Comput. Vis. Image Understand.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments,", "author": ["G.B. Huang", "M. Ramesh", "T. Berg", "E. Learned-Miller"], "venue": "Technical Report 07-49,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Face recognition using boosted local features,", "author": ["M. Jones", "P. Viola"], "venue": "Proc. IEEE Int\u2019l Conf. Computer Vision,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2003}, {"title": "Volterrafaces: Discriminant analysis using volterra kernels,", "author": ["R. Kumar", "A. Banerjee", "B.C. Vemuri"], "venue": "Proc. IEEE Conf. Computer Vision and Pattern Recognition,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Gabor volume based local binary pattern for face representation and recognition,", "author": ["Z. Lei", "S.C. Liao", "R. He", "M. Pietikainen", "S.T. Li"], "venue": "Proc. IEEE Conf. Automatic Face and Gesture Recognition,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Illumination invariant face recognition using near-infrared images,", "author": ["S.Z. Li", "R.F. Chu", "S.C. Liao", "L. Zhang"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Matching pursuits with timefrequency dictionaries,", "author": ["S. Mallat", "Z. Zhang"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1993}, {"title": "On the recent use of local binary patterns for face authentication,", "author": ["S. Marcel", "Y. Rodriguez", "G. Heusch"], "venue": "Int. J. Image Video Process, Special Issue on Facial Image Processing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Using biologically inspired features for face processing,", "author": ["E. Meyers", "L. Wolf"], "venue": "Int. J. Comput. Vis.,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Beyond Eigenfaces: Probabilistic matching for face recognition,", "author": ["B. Moghaddam", "Wahid W", "A. Pentland"], "venue": "Proc. IEEE Conf. Automatic Face and Gesture Recognition,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1998}, {"title": "Local feature analysis: A general statistical theory for object representation,", "author": ["P. Penev", "J. Atick"], "venue": "Network: Computationin Neural Systems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1996}, {"title": "AdaBoost Gabor Fisher classifier for face recognition,", "author": ["S.G. Shan", "P. Yang", "X.L. Chen", "W. Gao"], "venue": "Proc. IEEE Int. Workshop Analysis and Modeling of Faces and Gestures,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "Adaboost Gabor feature selection for classification,", "author": ["L. Shen", "L. Bai"], "venue": "Proc. Int\u2019l Conf. Image and Vision Computing,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2004}, {"title": "Recognition of faces in unconstrained environments: A comparative study,", "author": ["J. Ruiz del Solar", "R. Verschae", "M. Correa"], "venue": "EURASIP J. ADV. SIG. PR.,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "Regression shrinkage and selection via the lasso,", "author": ["R. Tibshirani"], "venue": "J Roy. Statist. Soc. B,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1996}, {"title": "Greed is good: Algorithmic results for sparse approximation,", "author": ["J.A. Tropp"], "venue": "IEEE Trans. Inf. Theory,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2004}, {"title": "Topics in sparse approximation,", "author": ["J.A. Tropp"], "venue": "Ph.D. dissertation, Univ. of Texas at Austin, Austin,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2004}, {"title": "Signal recovery from random measurements via orthogonal matching pursuit,", "author": ["J.A. Tropp", "A.C. Gilbert"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2007}, {"title": "Eigenfaces for recognition,", "author": ["M. Turk", "A. Pentland"], "venue": "J. Cogn. Neurosci.,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1991}, {"title": "Towards a practical face recognition system: Robust registration and illumination by sparse Representation,", "author": ["A. Wagner", "J. Wright", "A. Ganesh", "Z.H. Zhou", "Y. Ma"], "venue": "Proc. IEEE Conf. Computer Vision and Pattern Recognition,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Boosted multi-task learning for face verification with applications to web images and video search,", "author": ["X.G. Wang", "C. Zhang", "Z.Y. Zhang"], "venue": "Proc. IEEE Conf. Computer Vision and Pattern Recognition,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2009}, {"title": "Face recognition by elastic bunch graph matching,", "author": ["L. Wiskott", "J.M. Fellous", "N. Kruger", "C.von der Malsburg"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1997}, {"title": "Robust face recognition via sparse representation,", "author": ["J. Wright", "A.Y. Yang", "A. Ganesh", "S.S. Sastry", "Y. Ma"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Implicit elastic matching with random projections for pose-variant face recognition,", "author": ["J. Wright", "G. Hua"], "venue": "Proc. IEEE Conf. Computer Vision and Pattern Recognition,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2009}, {"title": "Exploring feature descriptors for face recognition,", "author": ["S.C. Yan", "H. Wang", "X.O. Tang", "T. Huang"], "venue": "Proc. IEEE Int\u2019l Conf. Acoustics, Speech, and Signal Processing,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2007}, {"title": "Face recognition using Ada-boosted Gabor features,", "author": ["P. Yang", "S.G. Shan", "W. Gao", "S.Z. Li", "D. Zhang"], "venue": "Proc. IEEE Conf. Automatic Face and Gesture Recognition,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2004}, {"title": "Boosting local binary pattern (LBP)-based face recognition,", "author": ["G.C. Zhang", "X.S. Huang", "S.Z. Li", "Y.S.Wang", "X.H. Wu"], "venue": "Proc. Advances in Biometric Person Authentication,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2004}, {"title": "P.Phillips, and A.Rosenfeld, \u201dFace recognition: A literature survey,", "author": ["W. Zhao", "R. Chellappa"], "venue": "ACM Comp. Survey,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2003}], "referenceMentions": [{"referenceID": 38, "context": "W ITHIN the last several decades, face recognition has received extensive attention due to its wide range of application from identity authentication, access control and surveillance to human-computer interaction and numerous novel face recognition algorithms have been proposed [43], [28].", "startOffset": 279, "endOffset": 283}, {"referenceID": 24, "context": "W ITHIN the last several decades, face recognition has received extensive attention due to its wide range of application from identity authentication, access control and surveillance to human-computer interaction and numerous novel face recognition algorithms have been proposed [43], [28].", "startOffset": 285, "endOffset": 289}, {"referenceID": 29, "context": "After the introduction of the well-known Eigenfaces [33], the holistic representation meth-", "startOffset": 52, "endOffset": 56}, {"referenceID": 2, "context": "cn ods were extensively studied [4], [24], [3], [13], [37], [34].", "startOffset": 32, "endOffset": 35}, {"referenceID": 20, "context": "cn ods were extensively studied [4], [24], [3], [13], [37], [34].", "startOffset": 37, "endOffset": 41}, {"referenceID": 1, "context": "cn ods were extensively studied [4], [24], [3], [13], [37], [34].", "startOffset": 43, "endOffset": 46}, {"referenceID": 10, "context": "cn ods were extensively studied [4], [24], [3], [13], [37], [34].", "startOffset": 48, "endOffset": 52}, {"referenceID": 33, "context": "cn ods were extensively studied [4], [24], [3], [13], [37], [34].", "startOffset": 54, "endOffset": 58}, {"referenceID": 30, "context": "cn ods were extensively studied [4], [24], [3], [13], [37], [34].", "startOffset": 60, "endOffset": 64}, {"referenceID": 21, "context": "Local feature analysis (LFA) [25] pioneers the study of local representation for face recognition.", "startOffset": 29, "endOffset": 33}, {"referenceID": 32, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 109, "endOffset": 113}, {"referenceID": 11, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 115, "endOffset": 119}, {"referenceID": 13, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 121, "endOffset": 125}, {"referenceID": 3, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 127, "endOffset": 130}, {"referenceID": 35, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 137, "endOffset": 141}, {"referenceID": 0, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 143, "endOffset": 146}, {"referenceID": 19, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 148, "endOffset": 152}, {"referenceID": 14, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 154, "endOffset": 158}, {"referenceID": 34, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 160, "endOffset": 164}, {"referenceID": 4, "context": "Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6].", "startOffset": 166, "endOffset": 169}, {"referenceID": 13, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 27, "endOffset": 31}, {"referenceID": 3, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 47, "endOffset": 50}, {"referenceID": 0, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 90, "endOffset": 93}, {"referenceID": 35, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 129, "endOffset": 133}, {"referenceID": 32, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 150, "endOffset": 154}, {"referenceID": 15, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 156, "endOffset": 160}, {"referenceID": 15, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 195, "endOffset": 199}, {"referenceID": 18, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 201, "endOffset": 205}, {"referenceID": 19, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 229, "endOffset": 233}, {"referenceID": 4, "context": "such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc.", "startOffset": 254, "endOffset": 257}, {"referenceID": 9, "context": "large cardinality is often limited and a consistent theory is still missing, numerous learned methods are emerging in the empirical practice due to their effectiveness (refer to [12] for an excellent review of feature selection approaches in machine learning).", "startOffset": 178, "endOffset": 182}, {"referenceID": 13, "context": "[16], [42], [40], [27], [26], [19], [35].", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "[16], [42], [40], [27], [26], [19], [35].", "startOffset": 6, "endOffset": 10}, {"referenceID": 36, "context": "[16], [42], [40], [27], [26], [19], [35].", "startOffset": 12, "endOffset": 16}, {"referenceID": 23, "context": "[16], [42], [40], [27], [26], [19], [35].", "startOffset": 18, "endOffset": 22}, {"referenceID": 22, "context": "[16], [42], [40], [27], [26], [19], [35].", "startOffset": 24, "endOffset": 28}, {"referenceID": 16, "context": "[16], [42], [40], [27], [26], [19], [35].", "startOffset": 30, "endOffset": 34}, {"referenceID": 31, "context": "[16], [42], [40], [27], [26], [19], [35].", "startOffset": 36, "endOffset": 40}, {"referenceID": 25, "context": "An alternative is the regularizedbased method which sparsify with respect to a dictionary of features by the sparsity-enforcing regularization techniques [29], [8].", "startOffset": 154, "endOffset": 158}, {"referenceID": 6, "context": "An alternative is the regularizedbased method which sparsify with respect to a dictionary of features by the sparsity-enforcing regularization techniques [29], [8].", "startOffset": 160, "endOffset": 163}, {"referenceID": 6, "context": "The main merits of such a regularized approach are its effectiveness even in the presence of a very small number of data coupled with the fact that it is supported by well-grounded theory [8].", "startOffset": 188, "endOffset": 191}, {"referenceID": 17, "context": "penalty term on the MSE criterion and the solution can be obtained by greedy methods such as matching pursuit (MP) [21] or the orthogonal matching pursuit (OMP) [30], [31], [32] and convex relaxation methods [31].", "startOffset": 115, "endOffset": 119}, {"referenceID": 26, "context": "penalty term on the MSE criterion and the solution can be obtained by greedy methods such as matching pursuit (MP) [21] or the orthogonal matching pursuit (OMP) [30], [31], [32] and convex relaxation methods [31].", "startOffset": 161, "endOffset": 165}, {"referenceID": 27, "context": "penalty term on the MSE criterion and the solution can be obtained by greedy methods such as matching pursuit (MP) [21] or the orthogonal matching pursuit (OMP) [30], [31], [32] and convex relaxation methods [31].", "startOffset": 167, "endOffset": 171}, {"referenceID": 28, "context": "penalty term on the MSE criterion and the solution can be obtained by greedy methods such as matching pursuit (MP) [21] or the orthogonal matching pursuit (OMP) [30], [31], [32] and convex relaxation methods [31].", "startOffset": 173, "endOffset": 177}, {"referenceID": 27, "context": "penalty term on the MSE criterion and the solution can be obtained by greedy methods such as matching pursuit (MP) [21] or the orthogonal matching pursuit (OMP) [30], [31], [32] and convex relaxation methods [31].", "startOffset": 208, "endOffset": 212}, {"referenceID": 6, "context": "Our method may be mainly inspired by the work [8] which is also applying the sparse regularized term to the linear model to perform the feature selection.", "startOffset": 46, "endOffset": 49}, {"referenceID": 6, "context": "Nevertheless, the linear model in [8] neglects the bias on the one hand and only enforces the linear dependence between the feature components and the class labels on the other hand.", "startOffset": 34, "endOffset": 37}, {"referenceID": 6, "context": "Our method starts off with the MSE criterion and considers simultaneously the bias and the adaptive margin vector and hence can be seemed as a generalization of the method in [8].", "startOffset": 175, "endOffset": 178}, {"referenceID": 6, "context": "Moreover, in [8] the sparse solution is obtained through iterative soft-thresholding method and the convergence relies on the careful normalization of each features component of all training samples at a time, which may de-", "startOffset": 13, "endOffset": 16}, {"referenceID": 20, "context": "personal variation [24], we focus on a binary", "startOffset": 19, "endOffset": 23}, {"referenceID": 27, "context": "solution to SMSE criterion (4) and no others [31].", "startOffset": 45, "endOffset": 49}, {"referenceID": 6, "context": "Moreover, if we set b = 1n and \u03c90 = 0 (we refer to the resulting algorithm as simplified SMES procedure, or SSMES), in this special case the RSMSE criterion (5) degenerates into the linear model described in [8], and thus our method can also be seemed as a generalization of the method in [8].", "startOffset": 208, "endOffset": 211}, {"referenceID": 6, "context": "Moreover, if we set b = 1n and \u03c90 = 0 (we refer to the resulting algorithm as simplified SMES procedure, or SSMES), in this special case the RSMSE criterion (5) degenerates into the linear model described in [8], and thus our method can also be seemed as a generalization of the method in [8].", "startOffset": 289, "endOffset": 292}, {"referenceID": 32, "context": "We start with the widely used Gabor representation because the kernels of Gabor filters are similar to the 2D receptive field profiles of the mammalian cortical simple cells and exhibit desirable characteristics of spatial locality and orientation selectivity [36], [40], [26].", "startOffset": 260, "endOffset": 264}, {"referenceID": 36, "context": "We start with the widely used Gabor representation because the kernels of Gabor filters are similar to the 2D receptive field profiles of the mammalian cortical simple cells and exhibit desirable characteristics of spatial locality and orientation selectivity [36], [40], [26].", "startOffset": 266, "endOffset": 270}, {"referenceID": 22, "context": "We start with the widely used Gabor representation because the kernels of Gabor filters are similar to the 2D receptive field profiles of the mammalian cortical simple cells and exhibit desirable characteristics of spatial locality and orientation selectivity [36], [40], [26].", "startOffset": 272, "endOffset": 276}, {"referenceID": 7, "context": "As suggested in [10], we truncate the Gabor filters to six times the span of the Gaussian function.", "startOffset": 16, "endOffset": 20}, {"referenceID": 20, "context": "[24], we temporarily cast the face recognition into a classification of the intra-personal (hereafter as positive) and extra-personal (hereafter as negative) variation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "A by-no-means negligible problem in practical is the overwhelmingly huge size and unbalance of the training samples [16].", "startOffset": 116, "endOffset": 120}, {"referenceID": 5, "context": "However, one can also consider its usage as a pure feature selection tool to reduce the numbers of Gabor features and adopt some other common classifiers such as nearest neighbor classifier (NNC), Fisher classifier (FC) [9] or support vector machines (SVM) [7] for the recognition.", "startOffset": 257, "endOffset": 260}, {"referenceID": 8, "context": "In order to evaluate the proposed approach, we carry out some experiments on two large face databases: CAS-PEAL-R1 [11] and LFW [15] face database.", "startOffset": 115, "endOffset": 119}, {"referenceID": 12, "context": "In order to evaluate the proposed approach, we carry out some experiments on two large face databases: CAS-PEAL-R1 [11] and LFW [15] face database.", "startOffset": 128, "endOffset": 132}, {"referenceID": 8, "context": "We restrictively follow the CAS-PEAL-R1 evaluation protocol which specifies one training set, one gallery set and six probe sets [11].", "startOffset": 129, "endOffset": 133}, {"referenceID": 22, "context": "The third method, \u201dG Ada+FC\u201d, is the AGFC method in [26] which using Adaboost to select Gabor features and FC for classification.", "startOffset": 52, "endOffset": 56}], "year": 2011, "abstractText": "Inspired by biological vision systems, the over-complete local features with huge cardinality are increasingly used for face recognition during the last decades. Accordingly, feature selection has become more and more important and plays a critical role for face data description and recognition. In this paper, we propose a trainable feature selection algorithm based on the regularized frame for face recognition. By enforcing a sparsity penalty term on the minimum squared error (MSE) criterion, we cast the feature selection problem into a combinatorial sparse approximation problem, which can be solved by greedy methods or convex relaxation methods. Moreover, based on the same frame, we propose a sparse Ho-Kashyap (HK) procedure to obtain simultaneously the optimal sparse solution and the corresponding margin vector of the MSE criterion. The proposed methods are used for selecting the most informative Gabor features of face images for recognition and the experimental results on benchmark face databases demonstrate the effectiveness of the", "creator": "LaTeX with hyperref package"}}}