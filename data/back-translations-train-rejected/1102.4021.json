{"id": "1102.4021", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Feb-2011", "title": "Privacy Preserving Spam Filtering", "abstract": "We present an approach to training a binary logistic regression classifier in the setting where the training data needs to be kept private. We provide a theoretical analysis of the security of this procedure and experimental results for the problem of large scale spam detection. High performance spam filters often use character n-grams as features which result in large sparse vectors to which applying our protocol directly is not feasible. We explore various dimensionality reduction and parallelization approaches and provide a detailed analysis of the speed and accuracy trade-off. Our results show that we can achieve the accuracy of state of the art spam filters at comparable training and testing time of non-private version of logistic regression.", "histories": [["v1", "Sat, 19 Feb 2011 20:40:56 GMT  (206kb,D)", "http://arxiv.org/abs/1102.4021v1", "9 pages"], ["v2", "Sun, 18 Sep 2011 05:37:43 GMT  (208kb,D)", "http://arxiv.org/abs/1102.4021v2", "9 pages"]], "COMMENTS": "9 pages", "reviews": [], "SUBJECTS": "cs.LG cs.CR", "authors": ["manas a pathak", "mehrbod sharifi", "bhiksha raj"], "accepted": false, "id": "1102.4021"}, "pdf": {"name": "1102.4021.pdf", "metadata": {"source": "CRF", "title": "Privacy Preserving Spam Filtering", "authors": ["Manas A. Pathak", "Mehrbod Sharifi", "Bhiksha Raj"], "emails": ["manasp@cs.cmu.edu", "mehrbod@cs.cmu.edu", "bhiksha@cs.cmu.edu"], "sections": [{"heading": null, "text": "General Terms and Conditions Data protection, spam filtering, logistic regression"}, {"heading": "1. INTRODUCTION", "text": "In fact, it is the case that most of them will be able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process, a process, a process, a process, a process and a process, a process in which there is a process, a process and a process, a process in which there is a process, and a process in which there is a process, and a process in which there is a process, and a process in which there is a process in which there is a process, and a process in which there is a process in which there is a process, and a process in which there is a process in which there is a process in which there is a process and a process in which there is a process in which there is a process in which there is a process and a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process and a process in which there is a process in which there is a process in which there is a process, a process and a process in which there is a process in which there is a process and a process in which there is a process and a process in which there is a process in which there is a process and a process in which there is a process in which there is a process and there is a process in which there is a process in which there is a process and there is a process in which there is a process and there is a process in which there is a process in which there is a process in which there is a process and there is a process in which there is a process and there is a process in which there is a process and there is a process in which there is a process in which there is a process in which there"}, {"heading": "2. RELATED WORK", "text": "The accuracy of the best systems in the 2007 CEAS Spam Filter Competition was better than 0.9999 [3]. Our implementation is an [7] inspired implementation of a logistical regression classifier that has near-state-of-the-art accuracy when applied to binary characteristics [3]. The development of privacy-preserving protocols for other tasks such as decision trees [14], set matching [5], clustering [9], naive bayes [15], support for vector machines [16], and so on. Applying privacy-preservation techniques to big real-world problems of practical importance, such as spam filters, is an emerging area of research. Li, et al. [8] represent a distributed framework for privacy-conscious spam filtering. Their method is based on the application of a unilateral fingerprinting transformation [1] to the text of the message and the comparison of two emails using a hamming distance that does not fit with our privacy criteria [1]."}, {"heading": "3. PRELIMINARIES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Classification Model: Logistic Regression in the Batch and Online Settings", "text": "The training data set, which consists of n documents classified by the user as spam or ham (i.e., not spam), is represented as the labeled data instances (x, y) = {(x1, y1),..., (xn, yn)} where the class probabilities are represented by a sigmoid functionP (yi = 1 | xi, w) = 11 + e \u2212 yiwT xi. We assume that the complete data set is available at a given time. In the logistic regression classification algorithm, we model the class probabilities by a sigmoid functionP (yi = 1 | xi, w) = 11 + e \u2212 yiwT xi. We define the protocol probability for the weight vector w, calculated via the data instances (x, y) by L (w, x, y)."}, {"heading": "3.2 Homomorphic Encryption", "text": "rE \"s tis, sdsa eeisrsrteeeiD rf\u00fc ide rf\u00fc ide rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rfu the rfu the rf\u00fc the rf\u00fc the rfu the rf\u00fc the rf\u00fc the rfu the rfu the rfu the rf\u00fc the rfu the rfu"}, {"heading": "4. PRIVACY PRESERVING CLASSIFIER TRAINING AND EVALUATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Data Setup and Privacy Conditions", "text": "We define two parties as \"Alice\" and \"Bob.\" Alice has access to a sequence of labeled training data instances (x, y) = {(x1, y1),..., (xn, yn)}. Bob is interested in training a logistic regression classifier with weight vector w, y about (x, y) as discussed in Section 3.1. In the online learning environment, multiple users can interact with Bob at the same time to update his classifier using their training data. As each of these parties plays the same role as Alice in their interaction with Bob, we represent them hereby. Privacy restrictions imply that Alice should not be able to observe w and Bob should not be able to (xi, yi). It is assumed that the parties are semi-malicious, i.e. that they are performing the steps of the protocol correctly and do not attempt to cheat by using fraudulent data to extract additional information about the other parties."}, {"heading": "4.2 Private Training Protocol", "text": "Bob generates a public and private key pair for an N-bit paillier cryptosystem 5. He provides the public key to Alice. In this cryptosystem Bob is able to perform both encryption and decryption operations, while Alice can only perform one decryption. As mentioned before, we use the cryptographic properties of paillier encryption to allow the parties to perform calculations using private data. The update rule requires Bob to calculate the gradient of the data log liquidity function. L (t), y) involves exposing and dividing and cannot be done with only homomorphic additions and multiplications. We complement the homomorphic operations with Bob, who performs these operations to maintain privacy."}, {"heading": "4.3 Private Evaluation Protocol", "text": "Another party, \"Carol,\" which has a test data instance, is interested in applying the classification model with the weight vector w belonging to Bob. Here, the privacy restriction requires that Bob should not be able to observe x and Carol should not be able to observe w. Similar to the training protocol, Bob generates a public and private key pair for a N-bit pailer crypto system and returns the public key for Carol.To label the data instance as y, Carol must check whether P (y) = 1 | x, \"w) = 11 + e \u2212 wT x\" > 1 \"and vice versa for y.\" This corresponds to checking whether wTx \"> 0.\" We are developing the following protocol toward this purpose. Input: Bob has w \"and generates a public-private key pair.\" Carol has x \"and Bob's public key.\" Output: Carol knows if wTx \"and Bob.\" b. \"encrypted\" and 4. \""}, {"heading": "5.1 Correctness", "text": "The private training protocol does not change the calculations of the original training algorithm and therefore leads to the same result. Additive randomization ri introduced in step 3 is removed in step 6, leaving the results unchanged. Likewise, the multiplicative randomization qi introduced in step 7 is removed in step 9. As discussed in section 3.2, the only source of error is the abbreviation of less significant digits in the finite precision representation of real numbers. In practice, we observe that the error in the calculation of the weight vector w is negligible and does not result in a loss of accuracy."}, {"heading": "5.2 Security", "text": "The main requirement of a valid multi-party calculation (SMC) is that each party must learn something about the data provided by the other parties. (SMC) The main requirement of a valid multi-party calculation (SMC) is that each party must learn nothing about the data provided by the other parties (Section 4.2) is demonstrably uncertain. (SMC) It is only assumed that the parties will learn nothing about Bob and thus nothing about the weight vector used by Bob. (Section 4.2) The Party Carol with the audit protocol will only receive the final result of the classification in plain text. Thus, the only additional information available to it is what is the output of the classifier itself, which is permitted under the privacy criteria of the problems.Bob: During the training phase, Bob will receive unencrypted data from Alice in plain text."}, {"heading": "5.3 Complexity", "text": "We analyze the encryption / decryption of Alice and the cost of data transmission for a single execution of the protocol, as these consume much of the time. There are 6 steps of the protocol in which encryption or decryption operations are performed. 1. In Step 1, Bob encrypts the d-dimensional vector w (t).2. In Step 3, Alice encrypts the n random numbers ri.3. In Step 4, Bob decrypts the n inner products used by Alice.4. In Step 5, Bob encrypts the exposures of the n inner products. 5. In Step 8, Bob decrypts the n random numbers and encrypts the n multiplicatively scaled quantities. 6. In Step 12, Bob decrypts the d dimensional updated weight vectors used by Alice.Total: 3n + 2d encryptions and decryptions."}, {"heading": "6. EXPERIMENTS", "text": "We offer an experimental evaluation of our approach to the task of email spam filtering. The privacy-preserving training protocol requires a much longer runtime than the non-private algorithm. In this section, we analyze the training protocol in terms of runtime and accuracy, and also provide solutions for how it can be used in practice by effectively balancing accuracy and computing time.As is common in spam filter research, we report AUC2 values. It is considered a more appropriate metric for this task compared to other metrics such as classification accuracy or F measurement, as it measures the performance of the classifier at different precision points that correspond to different thresholds for the predictability of the classifier. The AUC value of a random classifier is 0.5 and the one for the perfect classifier is 1.We have compared the performance of the classifier in different precision points that are given by the non-private training protocol."}, {"heading": "6.1 Email Spam Dataset", "text": "Generally, we refer to e-mails as documents. The performance of different algorithms on this data set is described in [12]. The data set consists of 3,067 training documents and 206,207 test documents, which are manually marked as spam or ham (i.e. not spam). To simplify benchmark calculations, we used the first 3000 documents from each data set (Table 1)."}, {"heading": "6.2 Spam Filter Implementation", "text": "Our classification approach is based on an online logistic regression [7] as described in Section 3.1. Characteristics are overlapping characters of four grams, which are extracted from documents through a sliding window of four characters. Characteristics are binary and indicate the presence or absence of the given four gram. Documents are in ASCII or UTF-8 encoding, which represents each character in 8 bits, so the space of possible four gram characteristics is 232. Following the previous work, we used Module 106 to reduce the four gram feature space to one million features, and only the first 35 KB of the documents are used to calculate the characteristics."}, {"heading": "6.3 Protocol Implementation", "text": "We developed a prototype of implementing the protocol in C + + and used the precision variable arithmetic libraries of OpenSSL [10] to implement the Paillier cryptosystem. We used the GSL libraries [6] for matrix operations. We conducted the experiments with a 3.2 GHz Intel3The dataset is at http: / / plg.uwaterloo.ca / ~ gvcormac / ceascorpus / The part of the dataset we used corresponds to the pretrain nofeedback task."}, {"heading": "9, 10 1.81 8.33", "text": "Pentium 4 machine with 2 GB RAM and 64-bit Ubuntu. In Table 2, we offer a comparison between the time it takes to train a simple logistic regression classifier and a privacy-preserving logistic regression classifier. It can be seen that the protocol is a factor of 104 slower than the non-private version. To further analyze the behavior of the various steps of the protocol, we report in Table 4 on the runtime of the individual steps of the protocol, which are outlined in Section 4.2 on two test sets of random vectors. It can be observed that encryption is the most important bottleneck among the other operations of the protocol. For all experiments, we used the pailler cryptosystem with 256-bit keys. However, the recommended key size for pailler encryption is 1024-bit for the state of the art. [4] As shown in Table 3, the use of 1024-bit cryptosystem with 256-bit cryptosystem is a comparison with 256-bit for the state of the art."}, {"heading": "6.4 Dimensionality Reduction", "text": "Since the time complexity of the data protection protocol is linearly linked to the dimensionality of the data, we can improve it by reducing the dimensionality of the data. Data with fewer dimensions require fewer encryptions and decryptions. On the other hand, reducing the dimensionality of the features, especially for sparse features such as n-gram numbers, can negatively affect the classification performance of the classification. We experimented with six different dimensionality reduction techniques and compared the runtime and AUC of the classifier learned through the training protocol for various reduced dimensions."}, {"heading": "6.5 Parallel Processing", "text": "Another approach to solving the performance problem is parallelization. We experimented with a multi-thread implementation of the algorithm. On average, we observed a speed improvement of 6.3% on a single core machine. We expect the improvement to be more significant on a multi-core architecture. A similar scheme can be used to parallelise the protocol on a cluster of machines, e.g. in a MapReduce framework. In both cases, the accuracy of the online algorithms will decrease slightly if the number of threads or machines increases, because the gradient L (w (t), x (y) calculated in each of the parallel processes are based on an older value of the weight vector w (t). A more promising approach that does not affect accuracy is parallel encryption of vectors. In the protocol, we need to encrypt vectors together and the method used for each element is identical."}, {"heading": "7. CONCLUSION", "text": "We introduced protocols for training and evaluation of a private email spam filter based on a logistical regression classifier in both batch and online learning environments. We used four grammars on text data as characteristics for the training. We presented an information theoretical analysis of the security of the protocol and also found that both the encryption / decryption and transmission costs of the protocol are linear in terms of the number of training instances and the dimensions of the data. We also experimented with a prototype implementation of the protocol in a large email data set and showed that our protocol is capable of achieving the latest state of the art in a workable execution time. Future guidelines for this work include the use of the spam filter classifier to maintain privacy in a real email system. We also plan to increase our protocols to make full use of scalable architectures, further enhancing the speed and flexibility."}, {"heading": "8. REFERENCES", "text": "[1] A. Z. Broder. Some applications of Rabin's fingerprinting method. Sequences II: Methods in Communications, Security, and Computer Science, pp. 143-152, 1993. [2] M. Charikar. Similarity estimation techniques from rounding algorithms. In 34th Annual ACM Symposium on Theory of Computing, 2002. [3] G. V. Cormack. TREC 2007 spam track overview. In Text REtrieval Conference TREC, 2007. [4] Cryptographic key length sempation. http: / / keylength.com, 2009. [5] M. Freedman, K. Nissim, and B. Pinkas. Efficient private matching and set intersection. In Advances in Cryptology - EUROCRYPT, pp. 1-19. Springer, 2004. [6] M. Galassi, J. Davies, J. Theiler, B. Gough, G. Jungman, P. Systems."}], "references": [{"title": "Some applications of Rabin\u2019s fingerprinting method. Sequences II: Methods in Communications, Security, and Computer Science, pages", "author": ["A.Z. Broder"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1993}, {"title": "Similarity estimation techniques from rounding algorithms", "author": ["M. Charikar"], "venue": "In 34th Annual ACM Symposium on Theory of Computing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "TREC 2007 spam track overview", "author": ["G.V. Cormack"], "venue": "In Text REtrieval Conference TREC,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Efficient private matching and set intersection", "author": ["M. Freedman", "K. Nissim", "B. Pinkas"], "venue": "In Advances in Cryptology - EUROCRYPT,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "GNU Scientific Library Reference Manual (v1.12)", "author": ["M. Galassi", "J. Davies", "J. Theiler", "B. Gough", "G. Jungman", "P. Alken", "M. Booth", "F. Rossi"], "venue": "Network Theory Ltd., third edition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Online discriminative spam filter training", "author": ["J. Goodman", "W. Yih"], "venue": "In Conference on Email and Anti-Spam CEAS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Privacy-aware collaborative spam filtering", "author": ["K. Li", "Z. Zhong", "L. Ramaswamy"], "venue": "IEEE Transactions on Parallel and Distributed Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Privacy-preserving clustering with distributed EM mixture modeling", "author": ["X. Lin", "C. Clifton", "M.Y. Zhu"], "venue": "Knowledge and Information Systems,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Public-key cryptosystems based on composite degree residuosity classes", "author": ["P. Paillier"], "venue": "In EUROCRYPT,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "Going mini: Extreme lightweight spam filters", "author": ["D. Sculley", "G.V. Cormack"], "venue": "In Conference on Email and Anti-Spam CEAS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Privacy-preserving decision trees over vertically partitioned data", "author": ["J. Vaidya", "C. Clifton", "M. Kantarcioglu", "S. Patterson"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Privacy-preserving naive Bayes classification", "author": ["J. Vaidya", "M. Kantarcioglu", "C. Clifton"], "venue": "VLDB J,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Privacy-preserving SVM classification", "author": ["J. Vaidya", "H. Yu", "X. Jiang"], "venue": "Knowledge and Information Systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Protocols for secure computations", "author": ["A. Yao"], "venue": "In IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1982}], "referenceMentions": [{"referenceID": 13, "context": "Our privacy preserving protocol falls into the broad class of secure multiparty computation (SMC) algorithms [17].", "startOffset": 109, "endOffset": 113}, {"referenceID": 8, "context": "We construct our protocol using a cryptosystem satisfying homomorphic encryption [11], in which operations on encrypted data correspond to operations on the original unencrypted data (Section 3.", "startOffset": 81, "endOffset": 85}, {"referenceID": 2, "context": "9999 [3].", "startOffset": 5, "endOffset": 8}, {"referenceID": 5, "context": "Our implementation is an online logistic regression classifier implementation inspired by [7] which on application to binary character four-gram features was shown to have near state of the art accuracy [3].", "startOffset": 90, "endOffset": 93}, {"referenceID": 2, "context": "Our implementation is an online logistic regression classifier implementation inspired by [7] which on application to binary character four-gram features was shown to have near state of the art accuracy [3].", "startOffset": 203, "endOffset": 206}, {"referenceID": 10, "context": "There has also been a much recent work on constructing privacy preserving protocols for other data mining tasks such as decision trees [14], set matching [5], clustering [9], naive Bayes [15], support vector machines [16], etc.", "startOffset": 135, "endOffset": 139}, {"referenceID": 3, "context": "There has also been a much recent work on constructing privacy preserving protocols for other data mining tasks such as decision trees [14], set matching [5], clustering [9], naive Bayes [15], support vector machines [16], etc.", "startOffset": 154, "endOffset": 157}, {"referenceID": 7, "context": "There has also been a much recent work on constructing privacy preserving protocols for other data mining tasks such as decision trees [14], set matching [5], clustering [9], naive Bayes [15], support vector machines [16], etc.", "startOffset": 170, "endOffset": 173}, {"referenceID": 11, "context": "There has also been a much recent work on constructing privacy preserving protocols for other data mining tasks such as decision trees [14], set matching [5], clustering [9], naive Bayes [15], support vector machines [16], etc.", "startOffset": 187, "endOffset": 191}, {"referenceID": 12, "context": "There has also been a much recent work on constructing privacy preserving protocols for other data mining tasks such as decision trees [14], set matching [5], clustering [9], naive Bayes [15], support vector machines [16], etc.", "startOffset": 217, "endOffset": 221}, {"referenceID": 6, "context": "[8] present a distributed framework for privacy aware spam filtering.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Their method is based on applying a one-way fingerprinting transformation [1] to the message text and comparing two emails using a Hamming distance metric and does not involve any form of statistical learning.", "startOffset": 74, "endOffset": 77}, {"referenceID": 8, "context": "In this work, we use the additively homomorphic Paillier cryptosystem [11] which also satisfies semantic security.", "startOffset": 70, "endOffset": 74}, {"referenceID": 0, "context": "Alice homomorphically adds E[1] to these quantities", "startOffset": 28, "endOffset": 31}, {"referenceID": 13, "context": "Bob and Carol execute a variant of the secure millionaire protocol [17] to with inputs r and s and both learn whether r > s.", "startOffset": 67, "endOffset": 71}, {"referenceID": 9, "context": "Performance of various algorithms on this dataset is reported in [12].", "startOffset": 65, "endOffset": 69}, {"referenceID": 5, "context": "Our classification approach is based on online logistic regression [7], as described in Section 3.", "startOffset": 67, "endOffset": 70}, {"referenceID": 4, "context": "We used the GSL libraries [6] for matrix operations.", "startOffset": 26, "endOffset": 29}, {"referenceID": 1, "context": "Locality Sensitive Hashing (LSH): In LSH [2], we choose K random hyper-planes in the original d dimensional space which represent each dimension in the target space.", "startOffset": 41, "endOffset": 44}], "year": 2017, "abstractText": "We present an approach to training a binary logistic regression classifier in the setting where the training data needs to be kept private. We provide a theoretical analysis of the security of this procedure and experimental results for the problem of large scale spam detection. High performance spam filters often use character n-grams as features which result in large sparse vectors to which applying our protocol directly is not feasible. We explore various dimensionality reduction and parallelization approaches and provide a detailed analysis of speed and accuracy trade-off. Our results show that we can achieve the accuracy of state of the art spam filters at comparable training and testing time of nonprivate version of logistic regression.", "creator": "LaTeX with hyperref package"}}}