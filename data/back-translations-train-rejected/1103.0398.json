{"id": "1103.0398", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2011", "title": "Natural Language Processing (almost) from Scratch", "abstract": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.", "histories": [["v1", "Wed, 2 Mar 2011 11:34:50 GMT  (338kb,D)", "http://arxiv.org/abs/1103.0398v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CL", "authors": ["ronan collobert", "jason weston", "leon bottou", "michael karlen", "koray kavukcuoglu", "pavel kuksa"], "accepted": false, "id": "1103.0398"}, "pdf": {"name": "1103.0398.pdf", "metadata": {"source": "CRF", "title": "Natural Language Processing (almost) from Scratch", "authors": ["Ronan Collobert", "Jason Weston", "Michael Karlen", "Koray Kavukcuoglu"], "emails": ["ronan@collobert.com", "jweston@google.com", "leon@bottou.org", "michael.karlen@gmail.com", "koray@cs.nyu.edu", "pkuksa@cs.rutgers.edu"], "sections": [{"heading": null, "text": "ar Xi vKeywords: processing natural language, neural networks"}, {"heading": "1. Introduction", "text": "In fact, most of us are able to set out in search of new paths to follow."}, {"heading": "2. The Benchmark Tasks", "text": "In this section, we briefly present four standard NLP tasks against which we will measure our architectures in this article: Part-Of-Speech Tagging (POS), Chunking (CHUNK), Named Entity Recognition (NER) and Semantic Role Labeling (SRL). For each of these tasks, we consider a standard test setup and give an overview of state-of-the-art systems for this setup. The test setups are summarized in Table 1, while state-of-the-art systems are described in Table 2."}, {"heading": "2.1 Part-Of-Speech Tagging", "text": "POS aims to mark each word with a unique tag indicating its syntactical role, e.g. plural nouns, adverb,.. A standard benchmark setup is described in detail by ToutanovaarXivSystem Accuracy Shen et al. (2007) 97.33% Toutanova et al. (2003) 97.24% Gime \u0301 nez and Ma rquez (2004) 97.16% (a) POSSystem F1 Shen and Sarkar (2005) 95.23% Sha and Pereira (2003) 94.29% Kudo and Matsumoto (2001) 93.91% (b) CHUNKSystem F1 Ando and Zhang (2005) 89.31% Florian et al. (2003) 88.76% Kudo and Matsumoto (2001) 88.31% (c) NERSystem F1 Koomen et al al. (2005) 77.92% Pradhan et al. (2005) 77.30% Hagi highal. (2005)."}, {"heading": "2.2 Chunking", "text": "Also referred to as shallow parsing, chunking aims to mark segments of a sentence with syntactical components such as nouns or verb phrases (NP or VP), each of which is assigned only one unique tag, often encoded as a starting block (e.g. B-NP) or within a chunk tag (e.g. I-NP). Chunking is often evaluated using the CoNLL 2000 Shared Task1. Sections 15-18 of the WSJ data are used for training and Section 20 for testing, and validation is achieved by using the training set.Kudoh and Matsumoto (2000) won the CoNLL 2000 challenge in chunking with an F1 score of 93.48%. Their system is based on Support Vector Machines (SVMs). Each SVM was trained in a paired classification mode and fed a window around the word of interest that includes POS and words as features."}, {"heading": "2.3 Named Entity Recognition", "text": "As with the chunking task, each word is assigned a tag preceded by an indicator of the beginning or interior of a unit. The CoNLL 2003 setup3 is an NER benchmark dataset based on Reuters data. The competition provides training, validation and testing sets.Florian et al. (2003) presented the best system at the NER CoNLL 2003 Challenge with a score of 88.76% F1. They used a combination of different machine-learning classifiers. They selected words, POS tags, CHUNK tags, prefixes and suffixes, a large gazetteer (not provided by the Challenge), and the output of two other NER classifiers trained on richer datasets."}, {"heading": "2.4 Semantic Role Labeling", "text": "SRL aims to give a semantic role to a syntactical constituent of a sentence. In propaganda aesthetics (Palmer et al., 2005), roles are assigned ARG0-5 words that contain arguments of a verb (or rather a predicate) in the sentence, e.g. the following sentence, which includes several keywords: \"ARG0-5 keywords\" ARG1, \"\" where \"ate\" is the predicate. \"The precise arguments depend on a verb, and if there are several verbs in a sentence, there could be several keywords. In addition to the ARG0-5 keywords, there are several modifier keywords such as ARGM-LOC and ARGM-TMP, which operate in a similar manner, containing several verbs in a sentence, there are several keywords. We chose CoNLL 20054 as our SRL benchmark."}, {"heading": "2.5 Evaluation", "text": "In our experiments, we strictly followed the standard evaluation procedure for each CoNLL challenge for NER, CHUNK, and SRL. All three tasks are evaluated by calculating the F1 values from chunks generated by our models. POS tasks are evaluated by calculating the accuracy per word, as is the case with the standard benchmark we refer to (Toutanova et al., 2003). We chose the conlleval script 5 to evaluate POS6, NER, and CHUNK. For SRL, we used the srl-eval.pl. script included in the srlconll package."}, {"heading": "2.6 Discussion", "text": "If we are participating in an (open) challenge, it is legitimate to increase the generalization by all means. Therefore, it is not surprising that many top CoNLL systems use externally marked data, such as additional NER classifiers for the NER architecture by Florian et al. (2003) or additional parse trees for SRL systems (Koomen et al., 2005). Combining several systems or careful optimization of properties is also a common approach, as in the chunking top system (Shen and Sarkar, 2005).However, when comparing systems, we do not learn about the quality of each system when they have been trained with different marked tasks. For this reason, we will refer to benchmark systems, that is, top existing systems that avoid the use of external data and are well established in the NLP field: (Toutanova et al., 2003) for POS and (Sha and Pereira, 2003) for the chunking tasks. For NER, we will consider it (Appendix 2005 and we will use additional data, as we use them for our systems, not for our anchoring systems)."}, {"heading": "3. The Networks", "text": "The traditional NLP approach is to extract from the set a set of hand-crafted functions, which are then fed into a standard classification algorithm, such as a support vector machine (SVM), often with a linear kernel. Property selection is a fully empirical process that relies mainly on linguistic intuition and then trial and error, and the selection of functions is task-dependent, implying additional research for each new NLP task. Complex tasks such as SRL then require a large number of potentially complex properties (e.g., extracted from a parse tree) that can be seen in can5. http: / / www.cnts.be / conll2000 / chunking / conlleval.txt. We used the \"-r\" option of the conlleval script to get per-word accuracy."}, {"heading": "3.1 Transforming Words into Feature Vectors", "text": "The ability of our method to learn good word representation is therefore critical to our approach. For efficiency reasons, words are fed to our architecture as indexes from a finite dictionary D. Obviously, a simple index does not contain much useful information about the word. However, the first layer of our network maps each of these word indexes through a search into a feature vector. In the face of an interesting task, a relevant representation of each word is then given by the corresponding search table feature vector, which is trained by backward propagation. More formally, for each word w-D, the search table LTW (\u00b7) gives a relevant representation of each word: LTW (w) = < W > 1w, where W-Rdwrd \u00d7 | D | is a matrix of parameters to be learned, < W > riw > word is applied to any layer (T) (< W > 1)."}, {"heading": "3.1.1 Extending to Any Discrete Features", "text": "If it is assumed that these characteristics are of interest for the task, for example, a characteristic could be provided for the task stating whether or not a word is in a gazette. Another common practice is to introduce some basic pre-processing characteristics, such as word origin or the handling of upper and lower case letters. In this latter option, the word would then be represented by three discrete characteristics: its lowercase characters originated from the root, its lowercase endings and a capitalization. Generally speaking, however, we can consider a word as discrete characteristics w, which are represented by w: D1 \u00b7 \u00b7 DK, whereby Dk is the dictionary for the kth characteristic. We associate each characteristic with a reference table LTWK, with the parameters W, K would \u00d7 \u00b7 \u00b7 DK, where dkwrd is the dictionary dictionary for the kth characteristic."}, {"heading": "3.2 Extracting Higher Level Features from Word Feature Vectors", "text": "Feature vectors generated by the Lookup Layer table must be combined in subsequent layers of the neural network to generate a tag decision for each word in the sentence. Generating tags for each element in variable-length sequences (here a sentence is a sequence of words) is a standard problem in machine learning. We will consider two common approaches that each mark a word: a window line and a (winding) line."}, {"heading": "3.2.1 Window Approach", "text": "A window approach assumes that the tag of a word mainly depends on its adjacent words. In view of a word being tagged, we consider a fixed size ksz (a hyperparameter window) as a word window around that word. Each word in the window is first passed through the lookup table layer (1) or (2), which creates a matrix of fixed-size word characteristics dwrd \u00b7 ksz. Formally, this matrix can be considered as a dwrd ksz-dimensional vector by concatenating each column vector that can be fed into further neural network layers. Formally, the word characteristic given by the first network layer can be written as: f1\u03b8 = < LTW ([w] T1) > dwint = < W > 1 [w] t \u2212 dwin / 2... < W > 1 [w] t > 1 [w] t [w] t > f \"."}, {"heading": "3.2.2 Sentence Approach", "text": "We will see in the experimental section that a window approach is good for most of the natural language processing tasks we are interested in. However, this approach fails at SRL, where the marking of a word depends on a verb (or, more correctly, predicate) chosen earlier in the sentence. If the verb falls outside the window, you cannot expect that word to be marked correctly. In this particular case, the marking of a word requires consideration of the entire sentence. If we use neural networks, the natural choice to address this issue becomes a revolutionary approach first introduced by Waibel et al. (1989) and also referred to as Time Delay Neural Networks (TDNNs) requires consideration of the whole sentence. We describe in detail our Constitutional Network below. It successively leads the full sentence through the lookup table (1), producing local features around each word of the sentence thanks to revolutionary levels, which can then be converted into a global feature vector."}, {"heading": "3.2.3 Tagging Schemes", "text": "As already explained, the network output levels calculate values for all possible tags for the respective task. In the window approach, these tags apply to the word located in the center of the window. In the (revolutionary) sentence approach, however, these tags apply to the word designated by additional markers in the network input. In fact, the POS task is to mark the syntactic role of each word. However, the remaining three tasks associate labels with segments of a sentence. This is usually achieved by using special tagging schemes to identify the segment boundaries, as in Table 3. Several such schemes have been defined (IOB, IOE, IOBES,...) without making a clear statement about which scheme is generally better. Most modern performance is sometimes achieved by combining classifiers formed with different tagging schemes (e.g. Kudo and Matsumoto, 2001).The truth for the tasks of NERCHUN- and SRL is achieved by using most of the tag emata for two different types of emata."}, {"heading": "3.3 Training", "text": "All our neural networks are trained by maximizing the probability of the training data by using stochastic gradient ascent. If we define \u03b8 as all trainable parameters of the network trained with a training set T, we want to maximize the following logarithoodare Xi vin relation to \u03b8: \u03b8 7 \u2192 \u2211 (x, y) and Tlog p (y | x, \u03b8), (8), where x corresponds to either a training word window or a sentence and its associated characteristics and y represents the corresponding element. The probability p (\u00b7) is calculated from the outputs of the neural network. In this section we will see two ways to interpret the outputs of neural networks as probabilities."}, {"heading": "3.3.1 Word-Level Log-Likelihood", "text": "In this approach, each word in a sentence is considered independently. To simplify the notation, we drop x from now on and write [f\u03b8] i instead. This value can be interpreted as a conditional tag probability p (i | x, \u03b8) by applying a softmax operation (Bridle, 1990) over all tags: p (i | x, \u03b8) = e [f\u03b8] i. (9) In defining the log add operation aslogadd i zi = log (\u2211 i ezi), (10) we can express the log probability for a training example (x, y) as follows: log p (y | x, \u03b8) = [f\u03b8] y \u2212 logadd j [f\u03b8] j. (11) During this training criterion, which is often referred to as crossword, the problem between another sentence and another, which is often not ideal, is in dependencies that we apply between networks."}, {"heading": "3.3.2 Sentence-Level Log-Likelihood", "text": "We know that there are interdependencies between the word marks in a sentence: not only are the keywords organized in blocks, but some keywords cannot follow other keywords. [1] Training with a word-level approach casts off this type of tagging information while we consider the sentence structure: given the predictions of all the keywords in a sentence, and given a score for going from one day to another, we want to promote valid ways of tagging during the training, while considering all other ways. We look at the matrix of scores issued by our network ([x] T 1) output through the network. As before, we drop the input [x] T1 for the simplification of notation. The element of the matrix is the score output by the network with the parameters."}, {"heading": "3.3.3 Stochastic Gradient", "text": "Maximum utilization (8) with stochastic gradient (Bottou, 1991) is achieved by selecting a random example (x, y) and making a gradient step:.................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "3.4 Supervised Benchmark Results", "text": "In fact, most of them are able to play by the rules that they have adopted in recent years."}, {"heading": "4. Lots of Unlabeled Data", "text": "Since most of the traceable parameters of our system are linked to the Word embeddings, these poor results suggest that we should use much more training data. Following our NLP philosophy from the ground up, we will now describe how we can dramatically improve these embeddings using large, unlabeled data sets. Subsequently, we will use these improved embeddings to initialize the word search tables of the networks described in Section 3.4.ar Xi v."}, {"heading": "4.1 Datasets", "text": "Our first English corpus is the entire English Wikipedia.11 We have removed all paragraphs that contain non-Roman characters and all MediaWiki markups.The resulting text was symbolized by the Penn Treebank Tokenizer script.12 The resulting record contains about 631 million words. As in our previous experiments, we use a dictionary that contains the 100,000 most common words in WSJ, with the same processing of capital letters and numbers. Again, words outside the dictionary have been replaced by the special word \"RARE.\" Our second English corpus consists of an additional 221 million words extracted from the Reuters RCV1 datasets (Lewis et al., 2004).13 We have also expanded the dictionary to 130,000 words by adding the 30,000 most common words in Reuters. This is useful to determine whether improvements can be achieved by further increasing the unlabeled record size."}, {"heading": "4.2 Ranking Criterion versus Entropy Criterion", "text": "These language models, in turn, are large neural networks that use the window approach described in Section 3.2.1 and Figure 1. Their goal was to estimate the probability of a word containing the previous words in a sentence. However, matching conditional probabilities indicate a crossentropy criterion similar to the one described in Section 3.3.1. Because the dictionary is large, the normalization term may be extremely demanding and demanding approximations required. More important for us is that neither work results in significant word embeddings nor significant word embedded.Shannon (1951) estimated the entropy of the English language between 0.6 and 1.3 bits per character."}, {"heading": "4.3 Training Language Models", "text": "The language model network was trained by stochastic gradient minimization of the ranking criterion (18), which we did not spend enough to search for the cell by adding a sentence-word pair (s, w) in each iteration.Since the training times for such large systems are counted in weeks, it is not possible to try many combinations of hyperparameters. It also makes sense to speed up the training time by initializing new networks with the embedding calculated by previous networks. In particular, we found it expedient to form a sequence of networks with ever larger words, initializing each network with the embedding of the previous network. Successive dictionary sizes and switching times are chosen arbitrarily. (Bengio et al., 2009) provides a more detailed discussion of the (previously poorly understood) \"curricula.\" For the purposes of model selection, we use the process of \"breeding.\""}, {"heading": "4.4 Embeddings", "text": "Both networks produce much more attractive word embeddings than in Section 3.4. Table 7 shows the ten closest neighbors of some randomly selected query words for the LM1 model. Syntactic and semantic properties of the neighbors are clearly related to those of the query word. These results are much more satisfactory than those in Table 7 for embeddings obtained by purely supervised training of the benchmark NLP tasks."}, {"heading": "4.5 Semi-supervised Benchmark Results", "text": "Semi-supervised learning has been the subject of much attention in recent years (see Chapelle et al., 2006). Previous semi-supervised learning approaches to NLP can be roughly categorized as: \u2022 Ad-hoc approaches such as (Rosenfeld and Feldman, 2007) for relationship extraction. \u2022 Self-training approaches such as (Ueffing et al., 2007) for machine translation, and (McClosky et al., 2006) for analysis. These methods supplement the designated trainingar Xi vset with examples from the unlabeled data set using the labels predicted by the model itself. Transductive approaches such as (Joachims, 1999) for text classification can be viewed as a refined form of self-training. \u2022 Parameter sharing approaches such as (Ando and Zhang, 2005; Suzuki and Isozaki, 2008) are fast vists."}, {"heading": "4.6 Ranking and Language", "text": "There is broad agreement in the NLP community that syntax is a necessary prerequisite for semantic role designation, which is why state-of-the-art semantic role markup systems thoroughly exploit multiple parse trees. Parsers themselves (Charniak, 2000; Collins, 1999) contain considerable prior information about the syntax (one can imagine this as a kind of informed pre-processing), and our system does not use such parse trees because we try to learn this information from the unlabeled data sets, so it is legitimate to ask whether our ranking criterion (18) has the conceptual ability to capture such rich hierarchical information. At first glance, the ranking task seems to have nothing to do with inducing probable grammatical grammars that are standard parser algorithms, and the lack of hierarchical representation seems to be a fatal error."}, {"heading": "5. Multi-Task Learning", "text": "This idea was already used in the previous section, when certain features of the language model, namely word embedding, were used to initialize the monitored networks. Multi-task learning (MTL) uses this idea in a more systematic way. Models for all tasks of interest are trained together with an additional linkage between their trainable parameters, in the hope of improving the generalization error. This linkage can take the form of a regularization term in the common cost function that tends the models to share representations. A much simpler approach is that the models define certain parameters together from the outset. Multi-task learning has a long history in machine learning and neural networks. Caruana (1997) gives a good overview of these past efforts."}, {"heading": "5.1 Joint Decoding versus Joint Training", "text": "This common decoding approach has been successfully applied to structurally more complex NLP tasks. Sutton and McCallum (2005b) obtain improved results by combining the predictions of independently trained CRF models using a common decoding process at test dates that require more complex probabilistic inference techniques. Sutton and McCallum (2005a) obtain results that are slightly below the state of the art by performing common decoding for SRL and syntactic parsing. Musillo and Merlo (2006) also describe a negative result from the same common training that inevitably works by considering additional probabilistic pathways of dependency between models."}, {"heading": "5.2 Multi-Task Benchmark Results", "text": "Table 9 reports on results obtained by jointly trained models for the POS, CHUNK, NER and SRL tasks with the same setup as Section 4.5. We trained jointly POS, CHUNK and NER with the window base network. As already mentioned, SRL can only be trained with the sentence base network due to extensive dependencies related to the verb predicate. Therefore, we also trained all four tasks with the sentence base network. In both cases, all models share the search table parameters (2). The parameters of the first linear layers (4) were divided in the window base case (see Figure 5), and the first fold layer parameters (6) were shared in the sentence base network. For the window base, the best results were obtained by increasing the first hidden layer size to n1hu = 500 (chosen by validation) to take into account the common responsibilities."}, {"heading": "6. The Temptation", "text": "We have shown that, thanks to large, unlabeled data sets, our generic neural networks are still able to come close to state-of-the-art by discovering useful features. This section examines what happens when we increase the level of task-specific engineering in our systems by incorporating some common techniques from the NLP literature. Frequently, we get further improvements. These numbers are useful to quantify how far we have gone by using large data sets rather than relying on a priori knowledge."}, {"heading": "6.1 Suffix Features", "text": "Word suffixes in many Western languages are strong predictors of the syntactic function of the word and can therefore benefit the POS system. For example, Ratnaparkhi (1996) 15. We have performed some basic pre-processing of raw input words, as described in Section 3.4, hence the \"fast\" in the title of this article. An entirely new approach would probably know nothing about words and would only work from letters (or, more extreme, from language or optical character recognition, as humans do).ar Xi uses inputs that represent word suffixes and prefixes up to four characters, which we achieve in the POS task by adding discrete word features (Section 3.1.1) representing the last two characters of each word. Suffix dictionary size was 455, which resulted in a small improvement in POS performance (Table 10, series NN + SLL + LM2 + Suffix2)."}, {"heading": "6.2 Gazetteers", "text": "State-of-the-art NER systems often use a large dictionary of well-known named units (e.g. Florian et al., 2003). We limited ourselves to the Gazetteer provided by the CoNLL challenge, which contained 8,000 locations, person names, organizations and other entities. We trained an NER network with 4 additional word features that (feature \"on\" or \"off\") indicate whether the word is found in the Gazetteer under one of these four categories. The Gazetteer includes not only words, but also word chunks. If a sentence chunk is found in the Gazetteer, then all words in the Gazetteer have turned their corresponding Gazetteer function into \"a.\" The resulting system shows a clear performance improvement (Table 10, line NN + SLL + LM2 + Gazetteer) that slightly exceeds the baseline."}, {"heading": "6.3 Cascading", "text": "Conventional NLP systems often use features derived from the output of other existing NLP systems. Shen and Sarkar (2005) describe a chunking system that uses POS tags as input; Florian et al. (2003) describes an NER system whose inputs include POS and CHUNK tags, as well as the output of two other NER classifiers. State-of-the-art SRL systems analyze trees (Gildea and Palmer, 2002; Punyakanok et al., 2005) that are associated with CHUNK tags and created with POS tags (Charniak, 2000; Collins, 1999). Table 10 reports on the results obtained for CHUNK and NER tasks by adding discrete word features (Section 3.1.1) that represent the POS tags. To facilitate comparisons, we do not use the more precise tags from our POS network, but the results we provide for each task by providing the NL consistent features."}, {"heading": "6.4 Ensembles", "text": "Setting up classifier ensembles is a proven method of swapping computing efficiency with generalization power (Bell et al., 2007), so it is not surprising that many NLP systems achieve state-of-the-art performance by combining the results of multiple Xi classifiers. Kudo and Matsumoto (2001), for example, use a classifier ensemble trained in different tagging conventions (see Section 3.2.3). Winning a challenge is, of course, a legitimate goal, but it is often difficult to determine which ideas are most responsible for the state-of-the-art performance of a large ensemble. As neural networks are not convex, training runs with different output parameters usually yield different solutions. Table 11 reports the results obtained for the CHUNK and NER task after ten training runs with random output parameters. Adjusting the ten network outputs on a tag basis (\"Voting Ensemble\") results in a small improvement in average network performance."}, {"heading": "6.5 Parsing", "text": "In fact, it is so that most people are able to identify themselves, as most people do. (In fact) In fact, it is so that most people are able to identify themselves. (In fact) In fact, it is so that most people are able to identify themselves. (In fact) In fact, it is so that most people are able to identify themselves. (In fact) In fact, it is so that most people are able to identify themselves. (In fact) In fact, it is so that most people are able to identify themselves. (In fact) In fact, it is so that most people are able to identify themselves. (in the other world)"}, {"heading": "6.6 Word Representations", "text": "(...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...).). (...). (...). (...). (...). (...). (...). (...).). (...). (...).). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (). (...). (...). (). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...). (...). (...). (...).). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...). (...).). (...). (...). (...). (...). (...). (...).). (...). (...). (...).). (...). (...).). (...). (...).). (...). (...).). (...). (...). (...).). (...). (...).). (...). (...).). (...). (...).). (...).). (...).).). (...).).). (...). (...). (...). (...).).).).). (...).).)."}, {"heading": "6.7 Engineering a Sweet Spot", "text": "In this context, it should be noted that this is a very complex and complex matter."}, {"heading": "7. Critical Discussion", "text": "Although we believe that this contribution represents a step towards the \"NLP from scratch\" goal, we are well aware that both our goal and our resources can be critical.ar Xi vThe main criticism of our goal can be summarized as follows: Over the years, the NLP community has developed considerable expertise in developing effective NLP functions. Why should they forget this painfully acquired know-how and instead painfully acquire the skills needed to train large neural networks? As mentioned in our introduction, we find that not a single NLP task really covers the goals of NLP. Therefore, we believe that task-specific engineering (i.e. not generalizing to other tasks) is undesirable, but we also recognize how much our neural networks owe owe to previous task-specific research.The main criticism of our resources is easier to address. Why did we choose to rely on a twenty-year-old technology, namely multi-layered networks?"}, {"heading": "8. Conclusion", "text": "We have introduced a multi-layered neural network architecture that can handle a range of NLP tasks at both speed and accuracy, and the design of this system was driven by our desire to avoid task-specific engineering as much as possible. Instead, we rely on large, unlabeled data sets and let the training algorithm discover internal representations that prove useful for all interesting tasks. On this strong foundation, we have developed a fast and efficient \"general purpose\" NLP tagger that we hope will prove useful to the community."}, {"heading": "Acknowledgments", "text": "We thank Yoshua Bengio, Samy Bengio, Eric Cosatto, Vincent Etter, Hans-Peter Graf, Ralph Grishman and Vladimir Vapnik for their useful feedback and comments."}, {"heading": "Appendix A. Neural Network Gradients", "text": "We consider a neural network f\u03b8 (\u00b7) as a parameter of the network in relation to each of them. < / p > p > p > p (8), we maximize the probability (8), or minimize the ranking criterion (18), in relation to the parameters. < p (0) p > p (0) p > p (0) p > p (0) p > p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (0) p (p (0) p) p (0) p) p (0) p (0) p (p) p (0) p (p) p (p) p (0) p (0) p (p) p (0) p) p (0) p (p) p (0) p) p (0) p (p) p (0) p (0) p \"p\" p \"p\" p) p (0) p \"p) p (p) p\" p)."}], "references": [{"title": "A framework for learning predictive structures from multiple tasks and unlabeled data", "author": ["R.K. Ando", "T. Zhang"], "venue": "JMLR, 6:1817\u20131953,", "citeRegEx": "Ando and Zhang.,? \\Q2005\\E", "shortCiteRegEx": "Ando and Zhang.", "year": 2005}, {"title": "The BellKor solution to the Netflix Prize", "author": ["R.M. Bell", "Y. Koren", "C. Volinsky"], "venue": "Technical report, AT&T Labs,", "citeRegEx": "Bell et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bell et al\\.", "year": 2007}, {"title": "Greedy layer-wise training of deep networks", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bengio et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2007}, {"title": "Curriculum learning", "author": ["Y. Bengio", "J. Louradour", "R. Collobert", "J. Weston"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Bengio et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2009}, {"title": "Stochastic gradient learning in neural networks", "author": ["L. Bottou"], "venue": "In Proceedings of Neuro-N\u0131\u0302mes 91, Nimes,", "citeRegEx": "Bottou.,? \\Q1991\\E", "shortCiteRegEx": "Bottou.", "year": 1991}, {"title": "Online algorithms and stochastic approximations", "author": ["L. Bottou"], "venue": "Online Learning and Neural Networks", "citeRegEx": "Bottou.,? \\Q1998\\E", "shortCiteRegEx": "Bottou.", "year": 1998}, {"title": "A framework for the cooperation of learning algorithms", "author": ["L. Bottou", "P. Gallinari"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Bottou and Gallinari.,? \\Q1991\\E", "shortCiteRegEx": "Bottou and Gallinari.", "year": 1991}, {"title": "Global training of document processing systems using graph transformer networks", "author": ["L. Bottou", "Y. LeCun", "Yoshua Bengio"], "venue": "In Proc. of Computer Vision and Pattern Recognition,", "citeRegEx": "Bottou et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Bottou et al\\.", "year": 1997}, {"title": "Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition", "author": ["J.S. Bridle"], "venue": "In F. Fogelman Soulie\u0301 and J. He\u0301rault, editors, Neurocomputing: Algorithms, Architectures and Applications,", "citeRegEx": "Bridle.,? \\Q1990\\E", "shortCiteRegEx": "Bridle.", "year": 1990}, {"title": "Class-based n-gram models of natural language", "author": ["P.F. Brown", "P.V. deSouza", "R.L. Mercer", "V.J.D. Pietra", "J C. Lai"], "venue": "Computational Linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "An estimate of an upper bound for the entropy of english", "author": ["P.F. Brown", "V.J. Della Pietra", "R.L. Mercer", "S.A. Della Pietra", "J.C. Lai"], "venue": "Computational Linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "Learning to rank with nonsmooth cost functions", "author": ["C.J.C. Burges", "R. Ragno", "Quoc Viet Le"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Burges et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Burges et al\\.", "year": 2007}, {"title": "Multitask Learning", "author": ["R. Caruana"], "venue": "Machine Learning,", "citeRegEx": "Caruana.,? \\Q1997\\E", "shortCiteRegEx": "Caruana.", "year": 1997}, {"title": "Semi-Supervised Learning. Adaptive computation and machine learning", "author": ["O. Chapelle", "B. Schlkopf", "A. Zien"], "venue": null, "citeRegEx": "Chapelle et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2006}, {"title": "A maximum-entropy-inspired parser", "author": ["E. Charniak"], "venue": "Proceedings of the first conference on North American chapter of the Association for Computational Linguistics,", "citeRegEx": "Charniak.,? \\Q2000\\E", "shortCiteRegEx": "Charniak.", "year": 2000}, {"title": "Named entity recognition with a maximum entropy approach", "author": ["H.L. Chieu"], "venue": "Proceedings of the Seventh Conference on Natural Language Learning (CoNLL-2003,", "citeRegEx": "Chieu.,? \\Q2003\\E", "shortCiteRegEx": "Chieu.", "year": 2003}, {"title": "Three models for the description of language", "author": ["N. Chomsky"], "venue": "IRE Transactions on Information Theory,", "citeRegEx": "Chomsky.,? \\Q1956\\E", "shortCiteRegEx": "Chomsky.", "year": 1956}, {"title": "Ranking the best instances", "author": ["S. Cl\u00e9men\u00e7on", "N. Vayatis"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Cl\u00e9men\u00e7on and Vayatis.,? \\Q2007\\E", "shortCiteRegEx": "Cl\u00e9men\u00e7on and Vayatis.", "year": 2007}, {"title": "Learning to order things", "author": ["W.W. Cohen", "R.E. Schapire", "Y. Singer"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Cohen et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 1998}, {"title": "Semantic role labelling with tree conditional random fields", "author": ["T. Cohn", "P. Blunsom"], "venue": "In Ninth Conference on Computational Natural Language (CoNLL),", "citeRegEx": "Cohn and Blunsom.,? \\Q2005\\E", "shortCiteRegEx": "Cohn and Blunsom.", "year": 2005}, {"title": "Head-Driven Statistical Models for Natural Language Parsing", "author": ["M. Collins"], "venue": "PhD thesis, University of Pennsylvania,", "citeRegEx": "Collins.,? \\Q1999\\E", "shortCiteRegEx": "Collins.", "year": 1999}, {"title": "Large Scale Machine Learning", "author": ["R. Collobert"], "venue": "PhD thesis, Universite\u0301 Paris VI,", "citeRegEx": "Collobert.,? \\Q2004\\E", "shortCiteRegEx": "Collobert.", "year": 2004}, {"title": "A convergent gambling estimate of the entropy of english", "author": ["T. Cover", "R. King"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cover and King.,? \\Q1978\\E", "shortCiteRegEx": "Cover and King.", "year": 1978}, {"title": "Named entity recognition through classifier combination", "author": ["R. Florian", "A. Ittycheriah", "H. Jing", "T. Zhang"], "venue": "In Proceedings of the seventh conference on Natural language learning at HLT-NAACL", "citeRegEx": "Florian et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Florian et al\\.", "year": 2003}, {"title": "Automatic labeling of semantic roles", "author": ["D. Gildea", "D. Jurafsky"], "venue": "Computational Linguistics,", "citeRegEx": "Gildea and Jurafsky.,? \\Q2002\\E", "shortCiteRegEx": "Gildea and Jurafsky.", "year": 2002}, {"title": "The necessity of parsing for predicate argument recognition", "author": ["D. Gildea", "M. Palmer"], "venue": "Proceedings of the 40th Annual Meeting of the ACL,", "citeRegEx": "Gildea and Palmer.,? \\Q2002\\E", "shortCiteRegEx": "Gildea and Palmer.", "year": 2002}, {"title": "SVMTool: A general POS tagger generator based on support vector machines", "author": ["J. Gim\u00e9nez", "L. M\u00e0rquez"], "venue": "In Proceedings of the 4th International Conference on Language Resources and Evaluation", "citeRegEx": "Gim\u00e9nez and M\u00e0rquez.,? \\Q2004\\E", "shortCiteRegEx": "Gim\u00e9nez and M\u00e0rquez.", "year": 2004}, {"title": "A joint model for semantic role labeling", "author": ["A. Haghighi", "K. Toutanova", "C.D. Manning"], "venue": "In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005). Association for Computational Linguistics,", "citeRegEx": "Haghighi et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Haghighi et al\\.", "year": 2005}, {"title": "Mathematical Structures of Language", "author": ["Z.S. Harris"], "venue": null, "citeRegEx": "Harris.,? \\Q1968\\E", "shortCiteRegEx": "Harris.", "year": 1968}, {"title": "Dependency networks for inference, collaborative filtering, and data visualization", "author": ["D. Heckerman", "D.M. Chickering", "C. Meek", "R. Rounthwaite", "C. Kadie"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Heckerman et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Heckerman et al\\.", "year": 2001}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.-W. Teh"], "venue": "Neural Comp.,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Comparing and combining finite-state and context-free parsers", "author": ["K. Hollingshead", "S. Fisher", "B. Roark"], "venue": "Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,", "citeRegEx": "Hollingshead et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hollingshead et al\\.", "year": 2005}, {"title": "Distributional representations for handling sparsity in supervised sequence-labeling. In Proceedings of the Association for Computational Linguistics (ACL), pages 495\u2013503", "author": ["F. Huang", "A. Yates"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Huang and Yates.,? \\Q2009\\E", "shortCiteRegEx": "Huang and Yates.", "year": 2009}, {"title": "Continuous speech recognition by statistical methods", "author": ["F. Jelinek"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Jelinek.,? \\Q1976\\E", "shortCiteRegEx": "Jelinek.", "year": 1976}, {"title": "Transductive inference for text classification using support vector machines", "author": ["T. Joachims"], "venue": "In ICML,", "citeRegEx": "Joachims.,? \\Q1999\\E", "shortCiteRegEx": "Joachims.", "year": 1999}, {"title": "Natural language grammar induction using a constituentcontext model", "author": ["D. Klein", "C.D. Manning"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Klein and Manning.,? \\Q2002\\E", "shortCiteRegEx": "Klein and Manning.", "year": 2002}, {"title": "Simple semi-supervised dependency parsing", "author": ["T. Koo", "X. Carreras", "M. Collins"], "venue": "In Proceedings of the Association for Computational Linguistics (ACL),", "citeRegEx": "Koo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2008}, {"title": "Generalized inference with multiple semantic role labeling systems (shared task paper)", "author": ["P. Koomen", "V. Punyakanok", "D. Roth", "W. Yih"], "venue": "Proc. of the Annual Conference on Computational Natural Language Learning (CoNLL),", "citeRegEx": "Koomen et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Koomen et al\\.", "year": 2005}, {"title": "Chunking with support vector machines", "author": ["T. Kudo", "Y. Matsumoto"], "venue": "Proceedings of the 2nd Meeting of the North American Association for Computational Linguistics: NAACL", "citeRegEx": "Kudo and Matsumoto.,? \\Q2001\\E", "shortCiteRegEx": "Kudo and Matsumoto.", "year": 2001}, {"title": "Use of support vector learning for chunk identification", "author": ["T. Kudoh", "Y. Matsumoto"], "venue": "In Proceedings of CoNLL-2000 and LLL-2000,", "citeRegEx": "Kudoh and Matsumoto.,? \\Q2000\\E", "shortCiteRegEx": "Kudoh and Matsumoto.", "year": 2000}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F. Pereira"], "venue": "In Eighteenth International Conference on Machine Learning,", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Gradient based learning applied to document recognition", "author": ["Y. Le Cun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of IEEE,", "citeRegEx": "Cun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Cun et al\\.", "year": 1998}, {"title": "A learning scheme for asymmetric threshold networks", "author": ["Y. LeCun"], "venue": "In Proceedings of Cognitiva", "citeRegEx": "LeCun.,? \\Q1985\\E", "shortCiteRegEx": "LeCun.", "year": 1985}, {"title": "Efficient backprop", "author": ["Y. LeCun", "L. Bottou", "G.B. Orr", "K.-R. M\u00fcller"], "venue": "Neural Networks: Tricks of the Trade,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Rcv1: A new benchmark collection for text categorization research", "author": ["D.D. Lewis", "Y. Yang", "T.G. Rose", "F. Li"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Lewis et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lewis et al\\.", "year": 2004}, {"title": "Semi-supervised learning for natural language", "author": ["P. Liang"], "venue": "Master\u2019s thesis, Massachusetts Institute of Technology,", "citeRegEx": "Liang.,? \\Q2005\\E", "shortCiteRegEx": "Liang.", "year": 2005}, {"title": "Structure compilation: trading structure for features", "author": ["P. Liang", "III H. Daum\u00e9", "D. Klein"], "venue": "In International conference on Machine learning (ICML),", "citeRegEx": "Liang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Liang et al\\.", "year": 2008}, {"title": "Phrase clustering for discriminative learning. In Proceedings of the Association for Computational Linguistics (ACL), pages 1030\u20131038", "author": ["D. Lin", "X. Wu"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Lin and Wu.,? \\Q2009\\E", "shortCiteRegEx": "Lin and Wu.", "year": 2009}, {"title": "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm", "author": ["N. Littlestone"], "venue": "In Machine Learning,", "citeRegEx": "Littlestone.,? \\Q1988\\E", "shortCiteRegEx": "Littlestone.", "year": 1988}, {"title": "Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons", "author": ["A. McCallum", "Wei Li"], "venue": "In Proceedings of the seventh conference on Natural language learning at HLT-NAACL", "citeRegEx": "McCallum and Li.,? \\Q2003\\E", "shortCiteRegEx": "McCallum and Li.", "year": 2003}, {"title": "Effective self-training for parsing", "author": ["D. McClosky", "E. Charniak", "M. Johnson"], "venue": "Proceedings of HLT-NAACL", "citeRegEx": "McClosky et al\\.,? \\Q2006\\E", "shortCiteRegEx": "McClosky et al\\.", "year": 2006}, {"title": "Flexible text segmentation with structured multilabel classification", "author": ["R. McDonald", "K. Crammer", "F. Pereira"], "venue": "Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,", "citeRegEx": "McDonald et al\\.,? \\Q2005\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "A novel use of statistical parsing to extract information from text", "author": ["S. Miller", "H. Fox", "L. Ramshaw", "R. Weischedel"], "venue": "6th Applied Natural Language Processing Conference,", "citeRegEx": "Miller et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Miller et al\\.", "year": 2000}, {"title": "Name tagging with word clusters and discriminative training", "author": ["S. Miller", "J. Guinness", "A. Zamanian"], "venue": "In Proceedings of HLT-NAACL,", "citeRegEx": "Miller et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Miller et al\\.", "year": 2004}, {"title": "Three new graphical models for statistical language modelling", "author": ["A Mnih", "G.E. Hinton"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Mnih and Hinton.,? \\Q2007\\E", "shortCiteRegEx": "Mnih and Hinton.", "year": 2007}, {"title": "Robust Parsing of the Proposition Bank", "author": ["G. Musillo", "P. Merlo"], "venue": "ROMAND 2006: Robust Methods in Analysis of Natural language Data,", "citeRegEx": "Musillo and Merlo.,? \\Q2006\\E", "shortCiteRegEx": "Musillo and Merlo.", "year": 2006}, {"title": "Bayesian Learning for Neural Networks", "author": ["R.M. Neal"], "venue": "Number 118 in Lecture Notes in Statistics. Springer-Verlag,", "citeRegEx": "Neal.,? \\Q1996\\E", "shortCiteRegEx": "Neal.", "year": 1996}, {"title": "A discriminative language model with pseudo-negative samples", "author": ["D. Okanohara", "J. Tsujii"], "venue": "Proceedings of the 45th Annual Meeting of the ACL,", "citeRegEx": "Okanohara and Tsujii.,? \\Q2007\\E", "shortCiteRegEx": "Okanohara and Tsujii.", "year": 2007}, {"title": "The proposition bank: An annotated corpus of semantic roles", "author": ["M. Palmer", "D. Gildea", "P. Kingsbury"], "venue": "Comput. Linguist.,", "citeRegEx": "Palmer et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Palmer et al\\.", "year": 2005}, {"title": "Probabilistic Reasoning in Intelligent Systems", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl.,? \\Q1988\\E", "shortCiteRegEx": "Pearl.", "year": 1988}, {"title": "Learning sets of filters using back-propagation", "author": ["D.C. Plaut", "G.E. Hinton"], "venue": "Computer Speech and Language,", "citeRegEx": "Plaut and Hinton.,? \\Q1987\\E", "shortCiteRegEx": "Plaut and Hinton.", "year": 1987}, {"title": "An algorithm for suffix stripping", "author": ["M.F. Porter"], "venue": null, "citeRegEx": "Porter.,? \\Q1980\\E", "shortCiteRegEx": "Porter.", "year": 1980}, {"title": "Shallow semantic parsing using support vector machines", "author": ["S. Pradhan", "W. Ward", "K. Hacioglu", "J. Martin", "D. Jurafsky"], "venue": "Proceedings of HLT/NAACL-2004,", "citeRegEx": "Pradhan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2004}, {"title": "Semantic role chunking combining complementary syntactic views", "author": ["S. Pradhan", "K. Hacioglu", "W. Ward", "J.H. Martin", "D. Jurafsky"], "venue": "In Proceedings of the Ninth Conference on Computational Natural Language Learning", "citeRegEx": "Pradhan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2005}, {"title": "The necessity of syntactic parsing for semantic role labeling", "author": ["V. Punyakanok", "D. Roth", "W. Yih"], "venue": "In IJCAI,", "citeRegEx": "Punyakanok et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Punyakanok et al\\.", "year": 2005}, {"title": "Design challenges and misconceptions in named entity recognition", "author": ["L. Ratinov", "D. Roth"], "venue": "In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL),", "citeRegEx": "Ratinov and Roth.,? \\Q2009\\E", "shortCiteRegEx": "Ratinov and Roth.", "year": 2009}, {"title": "A maximum entropy model for part-of-speech tagging", "author": ["A. Ratnaparkhi"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Ratnaparkhi.,? \\Q1996\\E", "shortCiteRegEx": "Ratnaparkhi.", "year": 1996}, {"title": "Using Corpus Statistics on Entities to Improve Semisupervised Relation Extraction from the Web", "author": ["B. Rosenfeld", "R. Feldman"], "venue": "Proceedings of the 45th Annual Meeting of the ACL,", "citeRegEx": "Rosenfeld and Feldman.,? \\Q2007\\E", "shortCiteRegEx": "Rosenfeld and Feldman.", "year": 2007}, {"title": "Learning internal representations by back-propagating errors", "author": ["D.E. Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": "Parallel Distributed Processing: Explorations in the Microstructure of Cognition,", "citeRegEx": "Rumelhart et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1986}, {"title": "Distributional part-of-speech tagging. In Proceedings of the Association for Computational Linguistics (ACL), pages 141\u2013148", "author": ["H. Sch\u00fctze"], "venue": null, "citeRegEx": "Sch\u00fctze.,? \\Q1995\\E", "shortCiteRegEx": "Sch\u00fctze.", "year": 1995}, {"title": "Connectionist language modeling for large vocabulary continuous speech recognition", "author": ["H. Schwenk", "J.L. Gauvain"], "venue": "In IEEE International Conference on Acoustics, Speech, and Signal Processing,", "citeRegEx": "Schwenk and Gauvain.,? \\Q2002\\E", "shortCiteRegEx": "Schwenk and Gauvain.", "year": 2002}, {"title": "Shallow parsing with conditional random fields", "author": ["F. Sha", "F. Pereira"], "venue": "In NAACL \u201903: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,", "citeRegEx": "Sha and Pereira.,? \\Q2003\\E", "shortCiteRegEx": "Sha and Pereira.", "year": 2003}, {"title": "Prediction and entropy of printed english", "author": ["C.E. Shannon"], "venue": "Bell Systems Technical Journal,", "citeRegEx": "Shannon.,? \\Q1951\\E", "shortCiteRegEx": "Shannon.", "year": 1951}, {"title": "Voting between multiple data representations for text chunking", "author": ["H. Shen", "A. Sarkar"], "venue": "Advances in Artificial Intelligence,", "citeRegEx": "Shen and Sarkar.,? \\Q2005\\E", "shortCiteRegEx": "Shen and Sarkar.", "year": 2005}, {"title": "Guided learning for bidirectional sequence classification", "author": ["L. Shen", "G. Satta", "A.K. Joshi"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Shen et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2007}, {"title": "Contrastive estimation: Training log-linear models on unlabeled data. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 354\u2013362", "author": ["N.A. Smith", "J. Eisner"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Smith and Eisner.,? \\Q2005\\E", "shortCiteRegEx": "Smith and Eisner.", "year": 2005}, {"title": "Symbolic-neural systems and the use of hints for developing complex systems", "author": ["S.C. Suddarth", "A.D.C. Holden"], "venue": "International Journal of Man-Machine Studies,", "citeRegEx": "Suddarth and Holden.,? \\Q1991\\E", "shortCiteRegEx": "Suddarth and Holden.", "year": 1991}, {"title": "Modeling latent-dynamic in shallow parsing: a latent conditional model with improved inference", "author": ["X. Sun", "L.-P. Morency", "D. Okanohara", "J. Tsujii"], "venue": "In COLING \u201908: Proceedings of the 22nd International Conference on Computational Linguistics,", "citeRegEx": "Sun et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2008}, {"title": "Joint parsing and semantic role labeling", "author": ["C. Sutton", "A. McCallum"], "venue": "In Proceedings of CoNLL-2005,", "citeRegEx": "Sutton and McCallum.,? \\Q2005\\E", "shortCiteRegEx": "Sutton and McCallum.", "year": 2005}, {"title": "Composition of conditional random fields for transfer learning", "author": ["C. Sutton", "A. McCallum"], "venue": "Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,", "citeRegEx": "Sutton and McCallum.,? \\Q2005\\E", "shortCiteRegEx": "Sutton and McCallum.", "year": 2005}, {"title": "Dynamic Conditional Random Fields: Factorized Probabilistic Models for Labeling and Segmenting Sequence", "author": ["C. Sutton", "A. McCallum", "K. Rohanimanesh"], "venue": "Data. JMLR,", "citeRegEx": "Sutton et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 2007}, {"title": "Semi-supervised sequential labeling and segmentation using gigaword scale unlabeled data", "author": ["J. Suzuki", "H. Isozaki"], "venue": "In Proceedings of ACL-08: HLT,", "citeRegEx": "Suzuki and Isozaki.,? \\Q2008\\E", "shortCiteRegEx": "Suzuki and Isozaki.", "year": 2008}, {"title": "The entropy of english using ppm-based models", "author": ["W.J. Teahan", "J.G. Cleary"], "venue": "Data Compression Conference", "citeRegEx": "Teahan and Cleary.,? \\Q1996\\E", "shortCiteRegEx": "Teahan and Cleary.", "year": 1996}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["K. Toutanova", "D. Klein", "C.D. Manning", "Y. Singer"], "venue": "In HLT-NAACL,", "citeRegEx": "Toutanova et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2003}, {"title": "Word representations: A simple and general method for semi-supervised learning. In Proceedings of the Association for Computational Linguistics (ACL), pages 384\u2013392", "author": ["J. Turian", "L. Ratinov", "Y. Bengio"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Turian et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Transductive learning for statistical machine translation", "author": ["N. Ueffing", "G. Haffari", "A. Sarkar"], "venue": "Proceedings of the 45th Annual Meeting of the ACL,", "citeRegEx": "Ueffing et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ueffing et al\\.", "year": 2007}, {"title": "Phoneme recognition using time-delay neural networks", "author": ["A. Waibel", "T. Hanazawa", "G. Hinton", "K. Shikano", "K.J. Lang"], "venue": "IEEE Transactions on Acoustics, Speech, and Signal Processing,", "citeRegEx": "Waibel et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Waibel et al\\.", "year": 1989}, {"title": "Deep learning via semi-supervised embedding", "author": ["J. Weston", "F. Ratle", "R. Collobert"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Weston et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 83, "context": "Task Benchmark Dataset Training set Test set (#tokens) (#tokens) (#tags) POS Toutanova et al. (2003) WSJ sections 0\u201318 sections 22\u201324 ( 45 ) ( 912,344 ) ( 129,654 ) Chunking CoNLL 2000 WSJ sections 15\u201318 section 20 ( 42 ) ( 211,727 ) ( 47,377 ) (IOBES) NER CoNLL 2003 Reuters \u201ceng.", "startOffset": 77, "endOffset": 101}, {"referenceID": 70, "context": "System Accuracy Shen et al. (2007) 97.", "startOffset": 16, "endOffset": 35}, {"referenceID": 70, "context": "System Accuracy Shen et al. (2007) 97.33% Toutanova et al. (2003) 97.", "startOffset": 16, "endOffset": 66}, {"referenceID": 26, "context": "24% Gim\u00e9nez and M\u00e0rquez (2004) 97.", "startOffset": 4, "endOffset": 31}, {"referenceID": 26, "context": "24% Gim\u00e9nez and M\u00e0rquez (2004) 97.16% (a) POS System F1 Shen and Sarkar (2005) 95.", "startOffset": 4, "endOffset": 79}, {"referenceID": 26, "context": "24% Gim\u00e9nez and M\u00e0rquez (2004) 97.16% (a) POS System F1 Shen and Sarkar (2005) 95.23% Sha and Pereira (2003) 94.", "startOffset": 4, "endOffset": 109}, {"referenceID": 26, "context": "24% Gim\u00e9nez and M\u00e0rquez (2004) 97.16% (a) POS System F1 Shen and Sarkar (2005) 95.23% Sha and Pereira (2003) 94.29% Kudo and Matsumoto (2001) 93.", "startOffset": 4, "endOffset": 142}, {"referenceID": 0, "context": "System F1 Ando and Zhang (2005) 89.", "startOffset": 10, "endOffset": 32}, {"referenceID": 0, "context": "System F1 Ando and Zhang (2005) 89.31% Florian et al. (2003) 88.", "startOffset": 10, "endOffset": 61}, {"referenceID": 0, "context": "System F1 Ando and Zhang (2005) 89.31% Florian et al. (2003) 88.76% Kudo and Matsumoto (2001) 88.", "startOffset": 10, "endOffset": 94}, {"referenceID": 0, "context": "System F1 Ando and Zhang (2005) 89.31% Florian et al. (2003) 88.76% Kudo and Matsumoto (2001) 88.31% (c) NER System F1 Koomen et al. (2005) 77.", "startOffset": 10, "endOffset": 140}, {"referenceID": 0, "context": "System F1 Ando and Zhang (2005) 89.31% Florian et al. (2003) 88.76% Kudo and Matsumoto (2001) 88.31% (c) NER System F1 Koomen et al. (2005) 77.92% Pradhan et al. (2005) 77.", "startOffset": 10, "endOffset": 169}, {"referenceID": 0, "context": "System F1 Ando and Zhang (2005) 89.31% Florian et al. (2003) 88.76% Kudo and Matsumoto (2001) 88.31% (c) NER System F1 Koomen et al. (2005) 77.92% Pradhan et al. (2005) 77.30% Haghighi et al. (2005) 77.", "startOffset": 10, "endOffset": 199}, {"referenceID": 29, "context": "(2003), who use maximum entropy classifiers, and a bidirectional dependency network (Heckerman et al., 2001) at inference, reach 97.", "startOffset": 84, "endOffset": 108}, {"referenceID": 80, "context": "Toutanova et al. (2003), who use maximum entropy classifiers, and a bidirectional dependency network (Heckerman et al.", "startOffset": 0, "endOffset": 24}, {"referenceID": 26, "context": "Gim\u00e9nez and M\u00e0rquez (2004) proposed a SVM approach also trained on text windows, with bidirectional inference achieved with two Viterbi decoders (left-to-right and right-to-left).", "startOffset": 0, "endOffset": 27}, {"referenceID": 26, "context": "Gim\u00e9nez and M\u00e0rquez (2004) proposed a SVM approach also trained on text windows, with bidirectional inference achieved with two Viterbi decoders (left-to-right and right-to-left). They obtained 97.16% per-word accuracy. More recently, Shen et al. (2007) pushed the state-of-the-art up to 97.", "startOffset": 0, "endOffset": 254}, {"referenceID": 38, "context": "91% (Kudo and Matsumoto, 2001) using an ensemble of classifiers trained with different tagging conventions (see Section 3.", "startOffset": 4, "endOffset": 30}, {"referenceID": 71, "context": "Since then, a certain number of systems based on second-order random fields were reported (Sha and Pereira, 2003; McDonald et al., 2005; Sun et al., 2008), all reporting around 94.", "startOffset": 90, "endOffset": 154}, {"referenceID": 51, "context": "Since then, a certain number of systems based on second-order random fields were reported (Sha and Pereira, 2003; McDonald et al., 2005; Sun et al., 2008), all reporting around 94.", "startOffset": 90, "endOffset": 154}, {"referenceID": 77, "context": "Since then, a certain number of systems based on second-order random fields were reported (Sha and Pereira, 2003; McDonald et al., 2005; Sun et al., 2008), all reporting around 94.", "startOffset": 90, "endOffset": 154}, {"referenceID": 38, "context": "Kudoh and Matsumoto (2000) won the CoNLL 2000 challenge on chunking with a F1score of 93.", "startOffset": 0, "endOffset": 27}, {"referenceID": 38, "context": "91% (Kudo and Matsumoto, 2001) using an ensemble of classifiers trained with different tagging conventions (see Section 3.2.3). Since then, a certain number of systems based on second-order random fields were reported (Sha and Pereira, 2003; McDonald et al., 2005; Sun et al., 2008), all reporting around 94.3% F1 score. These systems use features composed of words, POS tags, and tags. More recently, Shen and Sarkar (2005) obtained 95.", "startOffset": 5, "endOffset": 425}, {"referenceID": 21, "context": "Florian et al. (2003) presented the best system at the NER CoNLL 2003 challenge, with 88.", "startOffset": 0, "endOffset": 22}, {"referenceID": 14, "context": "Chieu (2003), the second best performer of CoNLL 2003 (88.", "startOffset": 0, "endOffset": 13}, {"referenceID": 0, "context": "Later, Ando and Zhang (2005) reached 89.", "startOffset": 7, "endOffset": 29}, {"referenceID": 58, "context": "In the PropBank (Palmer et al., 2005) formalism one assigns roles ARG0-5 to words that are arguments of a verb (or more technically, a predicate) in the sentence, e.", "startOffset": 16, "endOffset": 37}, {"referenceID": 24, "context": "Feature categories commonly used by these system include (Gildea and Jurafsky, 2002; Pradhan et al., 2004): \u2022 the parts of speech and syntactic labels of words and nodes in the tree; \u2022 the node\u2019s position (left or right) in relation to the verb; \u2022 the syntactic path to the verb in the parse tree; \u2022 whether a node in the parse tree is part of a noun or verb phrase; \u2022 the voice of the sentence: active or passive; \u2022 the node\u2019s head word; and \u2022 the verb sub-categorization.", "startOffset": 57, "endOffset": 106}, {"referenceID": 62, "context": "Feature categories commonly used by these system include (Gildea and Jurafsky, 2002; Pradhan et al., 2004): \u2022 the parts of speech and syntactic labels of words and nodes in the tree; \u2022 the node\u2019s position (left or right) in relation to the verb; \u2022 the syntactic path to the verb in the parse tree; \u2022 whether a node in the parse tree is part of a noun or verb phrase; \u2022 the voice of the sentence: active or passive; \u2022 the node\u2019s head word; and \u2022 the verb sub-categorization.", "startOffset": 57, "endOffset": 106}, {"referenceID": 48, "context": "(2005) hold the state-of-the-art with Winnow-like (Littlestone, 1988) classifiers, followed by a decoding stage based on an integer program that enforces specific constraints on SRL tags.", "startOffset": 50, "endOffset": 69}, {"referenceID": 25, "context": "In the same spirit, Haghighi et al. (2005) use log-linear models on each tree node, re-ranked globally with a dynamic algorithm.", "startOffset": 20, "endOffset": 43}, {"referenceID": 14, "context": "04% using the five top Charniak parse trees. Koomen et al. (2005) hold the state-of-the-art with Winnow-like (Littlestone, 1988) classifiers, followed by a decoding stage based on an integer program that enforces specific constraints on SRL tags.", "startOffset": 23, "endOffset": 66}, {"referenceID": 14, "context": "04% using the five top Charniak parse trees. Koomen et al. (2005) hold the state-of-the-art with Winnow-like (Littlestone, 1988) classifiers, followed by a decoding stage based on an integer program that enforces specific constraints on SRL tags. They reach 77.92% F1 on CoNLL 2005, thanks to the five top parse trees produced by the Charniak (2000) parser (only the first one was provided by the contest) as well as the Collins (1999) parse tree.", "startOffset": 23, "endOffset": 350}, {"referenceID": 14, "context": "04% using the five top Charniak parse trees. Koomen et al. (2005) hold the state-of-the-art with Winnow-like (Littlestone, 1988) classifiers, followed by a decoding stage based on an integer program that enforces specific constraints on SRL tags. They reach 77.92% F1 on CoNLL 2005, thanks to the five top parse trees produced by the Charniak (2000) parser (only the first one was provided by the contest) as well as the Collins (1999) parse tree.", "startOffset": 23, "endOffset": 436}, {"referenceID": 83, "context": "The POS task is evaluated by computing the per-word accuracy, as it is the case for the standard benchmark we refer to (Toutanova et al., 2003).", "startOffset": 119, "endOffset": 143}, {"referenceID": 37, "context": "(2003) or additional parse trees for SRL systems (Koomen et al., 2005).", "startOffset": 49, "endOffset": 70}, {"referenceID": 73, "context": "Combining multiple systems or tweaking carefully features is also a common approach, like in the chunking top system (Shen and Sarkar, 2005).", "startOffset": 117, "endOffset": 140}, {"referenceID": 83, "context": "For that reason, we will refer to benchmark systems, that is, top existing systems which avoid usage of external data and have been well-established in the NLP field: (Toutanova et al., 2003) for POS and (Sha and Pereira, 2003) for chunking.", "startOffset": 167, "endOffset": 191}, {"referenceID": 71, "context": ", 2003) for POS and (Sha and Pereira, 2003) for chunking.", "startOffset": 20, "endOffset": 43}, {"referenceID": 0, "context": "For NER we consider (Ando and Zhang, 2005) as they were using additional unlabeled data only.", "startOffset": 20, "endOffset": 42}, {"referenceID": 37, "context": "We picked (Koomen et al., 2005) for SRL, keeping in mind they use 4 additional parse trees not provided by the challenge.", "startOffset": 10, "endOffset": 31}, {"referenceID": 22, "context": "It is thus not surprising to see many top CoNLL systems using external labeled data, like additional NER classifiers for the NER architecture of Florian et al. (2003) or additional parse trees for SRL systems (Koomen et al.", "startOffset": 145, "endOffset": 167}, {"referenceID": 21, "context": "It has the advantage of being slightly cheaper to compute (compared to the exact hyperbolic tangent), while leaving the generalization performance unchanged (Collobert, 2004).", "startOffset": 157, "endOffset": 174}, {"referenceID": 86, "context": "When using neural networks, the natural choice to tackle this problem becomes a convolutional approach, first introduced by Waibel et al. (1989) and also called Time Delay Neural Networks (TDNNs) in the literature.", "startOffset": 124, "endOffset": 145}, {"referenceID": 8, "context": "This score can be interpreted as a conditional tag probability p(i |x, \u03b8) by applying a softmax (Bridle, 1990) operation over all the tags:", "startOffset": 96, "endOffset": 110}, {"referenceID": 7, "context": "Remark 3 (Graph Transformer Networks) Our approach is a particular case of the discriminative forward training for graph transformer networks (GTNs) (Bottou et al., 1997; Le Cun et al., 1998).", "startOffset": 149, "endOffset": 191}, {"referenceID": 40, "context": "If this was the case, the scores could be viewed as the logarithms of conditional transition probabilities, and our model would be subject to the label-bias problem that motivates Conditional Random Fields (CRFs) (Lafferty et al., 2001).", "startOffset": 213, "endOffset": 236}, {"referenceID": 40, "context": "CRFs have been widely used in the NLP world, such as for POS tagging (Lafferty et al., 2001), chunking (Sha and Pereira, 2003), NER (McCallum and Li, 2003) or SRL (Cohn and Blunsom, 2005).", "startOffset": 69, "endOffset": 92}, {"referenceID": 71, "context": ", 2001), chunking (Sha and Pereira, 2003), NER (McCallum and Li, 2003) or SRL (Cohn and Blunsom, 2005).", "startOffset": 18, "endOffset": 41}, {"referenceID": 49, "context": ", 2001), chunking (Sha and Pereira, 2003), NER (McCallum and Li, 2003) or SRL (Cohn and Blunsom, 2005).", "startOffset": 47, "endOffset": 70}, {"referenceID": 19, "context": ", 2001), chunking (Sha and Pereira, 2003), NER (McCallum and Li, 2003) or SRL (Cohn and Blunsom, 2005).", "startOffset": 78, "endOffset": 102}, {"referenceID": 4, "context": "3 Stochastic Gradient Maximizing (8) with stochastic gradient (Bottou, 1991) is achieved by iteratively selecting a random example (x, y) and making a gradient step:", "startOffset": 62, "endOffset": 76}, {"referenceID": 42, "context": "Remark 6 (Modular Approach) The well known \u201cback-propagation\u201d algorithm (LeCun, 1985; Rumelhart et al., 1986) computes gradients using the chain rule.", "startOffset": 72, "endOffset": 109}, {"referenceID": 68, "context": "Remark 6 (Modular Approach) The well known \u201cback-propagation\u201d algorithm (LeCun, 1985; Rumelhart et al., 1986) computes gradients using the chain rule.", "startOffset": 72, "endOffset": 109}, {"referenceID": 4, "context": "compute derivatives with respect to its inputs and with respect to its trainable parameters, as proposed by Bottou and Gallinari (1991). This allows us to easily build variants of our networks.", "startOffset": 108, "endOffset": 136}, {"referenceID": 43, "context": "Remark 7 (Tricks) Many tricks have been reported for training neural networks (LeCun et al., 1998).", "startOffset": 78, "endOffset": 98}, {"referenceID": 60, "context": "We employed only two of them: the initialization and update of the parameters of each network layer were done according to the \u201cfan-in\u201d of the layer, that is the number of inputs used to compute each output of this layer (Plaut and Hinton, 1987).", "startOffset": 221, "endOffset": 245}, {"referenceID": 46, "context": "This result is in line with existing NLP studies comparing sentence-level and wordlevel likelihoods (Liang et al., 2008).", "startOffset": 100, "endOffset": 120}, {"referenceID": 43, "context": "Second order methods (LeCun et al., 1998) could be another speedup technique.", "startOffset": 21, "endOffset": 41}, {"referenceID": 44, "context": "Our second English corpus is composed by adding an extra 221 million words extracted from the Reuters RCV1 (Lewis et al., 2004) dataset.", "startOffset": 107, "endOffset": 127}, {"referenceID": 67, "context": "Similar language models were already proposed by Bengio and Ducharme (2001) and Schwenk and Gauvain (2002). Their goal was to estimate the probability of a word given the previous words in a sentence.", "startOffset": 80, "endOffset": 107}, {"referenceID": 67, "context": "Similar language models were already proposed by Bengio and Ducharme (2001) and Schwenk and Gauvain (2002). Their goal was to estimate the probability of a word given the previous words in a sentence. Estimating conditional probabilities suggests a crossentropy criterion similar to those described in Section 3.3.1. Because the dictionary size is large, computing the normalization term can be extremely demanding, and sophisticated approximations are required. More importantly for us, neither work leads to significant word embeddings being reported. Shannon (1951) has estimated the entropy of the English language between 0.", "startOffset": 80, "endOffset": 569}, {"referenceID": 20, "context": "Cover and King (1978) give a lower bound of 1.", "startOffset": 0, "endOffset": 22}, {"referenceID": 9, "context": "Meanwhile, using a simple word trigram model, Brown et al. (1992b) reach 1.", "startOffset": 46, "endOffset": 67}, {"referenceID": 9, "context": "Meanwhile, using a simple word trigram model, Brown et al. (1992b) reach 1.75 bits per character. Teahan and Cleary (1996) obtain entropies as low as 1.", "startOffset": 46, "endOffset": 123}, {"referenceID": 35, "context": "However, Klein and Manning (2002) describe a rare example of realistic unsupervised grammar induction using a cross-entropy approach on binary-branching parsing trees, that is, by forcing the system to generate a hierarchical representation.", "startOffset": 9, "endOffset": 34}, {"referenceID": 18, "context": "We propose here to use a pairwise ranking approach (Cohen et al., 1998).", "startOffset": 51, "endOffset": 71}, {"referenceID": 17, "context": "Because the ranking literature often deals with information retrieval applications, many authors define complex ranking criteria that give more weight to the ordering of the best ranking instances (see Burges et al., 2007; Cl\u00e9men\u00e7on and Vayatis, 2007).", "startOffset": 197, "endOffset": 251}, {"referenceID": 57, "context": "Okanohara and Tsujii (2007) use a related approach to avoiding the entropy criteria using a binary classification approach (correct/incorrect phrase).", "startOffset": 0, "endOffset": 28}, {"referenceID": 57, "context": "Okanohara and Tsujii (2007) use a related approach to avoiding the entropy criteria using a binary classification approach (correct/incorrect phrase). Their work focuses on using a kernel classifier, and not on learning word embeddings as we do here. Smith and Eisner (2005) also propose a contrastive criterion which estimates the likelihood of the data conditioned to a \u201cnegative\u201d neighborhood.", "startOffset": 0, "endOffset": 275}, {"referenceID": 3, "context": "(Bengio et al., 2009) provides a more detailed discussion of this, the (as yet, poorly understood) \u201ccurriculum\u201d process.", "startOffset": 0, "endOffset": 21}, {"referenceID": 67, "context": "Previous semi-supervised approaches for NLP can be roughly categorized as follows: \u2022 Ad-hoc approaches such as (Rosenfeld and Feldman, 2007) for relation extraction.", "startOffset": 111, "endOffset": 140}, {"referenceID": 85, "context": "\u2022 Self-training approaches, such as (Ueffing et al., 2007) for machine translation, and (McClosky et al.", "startOffset": 36, "endOffset": 58}, {"referenceID": 50, "context": ", 2007) for machine translation, and (McClosky et al., 2006) for parsing.", "startOffset": 37, "endOffset": 60}, {"referenceID": 34, "context": "Transductive approaches, such as (Joachims, 1999) for text classification can be viewed as a refined form of self-training.", "startOffset": 33, "endOffset": 49}, {"referenceID": 0, "context": "\u2022 Parameter sharing approaches such as (Ando and Zhang, 2005; Suzuki and Isozaki, 2008).", "startOffset": 39, "endOffset": 87}, {"referenceID": 81, "context": "\u2022 Parameter sharing approaches such as (Ando and Zhang, 2005; Suzuki and Isozaki, 2008).", "startOffset": 39, "endOffset": 87}, {"referenceID": 30, "context": "Note that our procedure is clearly linked to the (semi-supervised) deep learning procedures of (Hinton et al., 2006; Bengio et al., 2007; Weston et al., 2008).", "startOffset": 95, "endOffset": 158}, {"referenceID": 2, "context": "Note that our procedure is clearly linked to the (semi-supervised) deep learning procedures of (Hinton et al., 2006; Bengio et al., 2007; Weston et al., 2008).", "startOffset": 95, "endOffset": 158}, {"referenceID": 87, "context": "Note that our procedure is clearly linked to the (semi-supervised) deep learning procedures of (Hinton et al., 2006; Bengio et al., 2007; Weston et al., 2008).", "startOffset": 95, "endOffset": 158}, {"referenceID": 25, "context": "6 Ranking and Language There is a large agreement in the NLP community that syntax is a necessary prerequisite for semantic role labeling (Gildea and Palmer, 2002).", "startOffset": 138, "endOffset": 163}, {"referenceID": 14, "context": "The parsers themselves (Charniak, 2000; Collins, 1999) contain considerable prior information about syntax (one can think of this as a kind of informed pre-processing).", "startOffset": 23, "endOffset": 54}, {"referenceID": 20, "context": "The parsers themselves (Charniak, 2000; Collins, 1999) contain considerable prior information about syntax (one can think of this as a kind of informed pre-processing).", "startOffset": 23, "endOffset": 54}, {"referenceID": 16, "context": "The lack of hierarchical representation seems a fatal flaw (Chomsky, 1956).", "startOffset": 59, "endOffset": 74}, {"referenceID": 28, "context": "However, ranking is closely related to an alternative description of the language structure: operator grammars (Harris, 1968).", "startOffset": 111, "endOffset": 125}, {"referenceID": 12, "context": "Caruana (1997) gives a good overview of these past efforts.", "startOffset": 0, "endOffset": 15}, {"referenceID": 33, "context": "For instance, modern speech recognition systems use Bayes rule to combine the outputs of an acoustic model trained on speech data and a language model trained on phonetic or textual corpora (Jelinek, 1976).", "startOffset": 190, "endOffset": 205}, {"referenceID": 33, "context": "For instance, modern speech recognition systems use Bayes rule to combine the outputs of an acoustic model trained on speech data and a language model trained on phonetic or textual corpora (Jelinek, 1976). This joint decoding approach has been successfully applied to structurally more complex NLP tasks. Sutton and McCallum (2005b) obtains improved results by combining the predictions of independently trained CRF models using a joint decoding process at test time that requires more sophisticated probabilistic inference techniques.", "startOffset": 191, "endOffset": 334}, {"referenceID": 33, "context": "For instance, modern speech recognition systems use Bayes rule to combine the outputs of an acoustic model trained on speech data and a language model trained on phonetic or textual corpora (Jelinek, 1976). This joint decoding approach has been successfully applied to structurally more complex NLP tasks. Sutton and McCallum (2005b) obtains improved results by combining the predictions of independently trained CRF models using a joint decoding process at test time that requires more sophisticated probabilistic inference techniques. On the other hand, Sutton and McCallum (2005a) obtain results somewhat below the state-of-the-art using joint decoding for SRL and syntactic parsing.", "startOffset": 191, "endOffset": 584}, {"referenceID": 33, "context": "For instance, modern speech recognition systems use Bayes rule to combine the outputs of an acoustic model trained on speech data and a language model trained on phonetic or textual corpora (Jelinek, 1976). This joint decoding approach has been successfully applied to structurally more complex NLP tasks. Sutton and McCallum (2005b) obtains improved results by combining the predictions of independently trained CRF models using a joint decoding process at test time that requires more sophisticated probabilistic inference techniques. On the other hand, Sutton and McCallum (2005a) obtain results somewhat below the state-of-the-art using joint decoding for SRL and syntactic parsing. Musillo and Merlo (2006) also describe a negative result at the same joint task.", "startOffset": 191, "endOffset": 712}, {"referenceID": 76, "context": "It is then sufficient to train a model that computes multiple outputs for each pattern (Suddarth and Holden, 1991).", "startOffset": 87, "endOffset": 114}, {"referenceID": 56, "context": "makes sense when the training data blocks these additional dependency paths (in the sense of d-separation, Pearl, 1988). This implies that, without joint training, the additional dependency paths cannot directly involve unobserved variables. Therefore, the natural idea of discovering common internal representations across tasks requires joint training. Joint training is relatively straightforward when the training sets for the individual tasks contain the same patterns with different labels. It is then sufficient to train a model that computes multiple outputs for each pattern (Suddarth and Holden, 1991). Using this scheme, Sutton et al. (2007) demonstrates improvements on POS tagging and nounphrase chunking using jointly trained CRFs.", "startOffset": 107, "endOffset": 653}, {"referenceID": 51, "context": "Miller et al. (2000) achieves performance improvements by jointly training NER, parsing, and relation extraction in a statistical parsing model.", "startOffset": 0, "endOffset": 21}, {"referenceID": 0, "context": "Ando and Zhang (2005) propose a setup that works around the joint labeling requirements.", "startOffset": 0, "endOffset": 22}, {"referenceID": 66, "context": "For instance, Ratnaparkhi (1996)", "startOffset": 14, "endOffset": 33}, {"referenceID": 61, "context": "We also tried suffixes obtained with the Porter (1980) stemmer and obtained the same performance as when using two character suffixes.", "startOffset": 41, "endOffset": 55}, {"referenceID": 25, "context": "State-of-the-art SRL systems exploit parse trees (Gildea and Palmer, 2002; Punyakanok et al., 2005), related to CHUNK tags, and built using POS tags (Charniak, 2000; Collins, 1999).", "startOffset": 49, "endOffset": 99}, {"referenceID": 64, "context": "State-of-the-art SRL systems exploit parse trees (Gildea and Palmer, 2002; Punyakanok et al., 2005), related to CHUNK tags, and built using POS tags (Charniak, 2000; Collins, 1999).", "startOffset": 49, "endOffset": 99}, {"referenceID": 14, "context": ", 2005), related to CHUNK tags, and built using POS tags (Charniak, 2000; Collins, 1999).", "startOffset": 57, "endOffset": 88}, {"referenceID": 20, "context": ", 2005), related to CHUNK tags, and built using POS tags (Charniak, 2000; Collins, 1999).", "startOffset": 57, "endOffset": 88}, {"referenceID": 68, "context": "For instance, Shen and Sarkar (2005) describe a chunking system that uses POS tags as input; Florian et al.", "startOffset": 14, "endOffset": 37}, {"referenceID": 21, "context": "For instance, Shen and Sarkar (2005) describe a chunking system that uses POS tags as input; Florian et al. (2003) describes a NER system whose inputs include POS and CHUNK tags, as well as the output of two other NER classifiers.", "startOffset": 93, "endOffset": 115}, {"referenceID": 1, "context": "4 Ensembles Constructing ensembles of classifiers is a proven way to trade computational efficiency for generalization performance (Bell et al., 2007).", "startOffset": 131, "endOffset": 150}, {"referenceID": 56, "context": "On the other hand, multiple training times could be improved using smart sampling strategies (Neal, 1996).", "startOffset": 93, "endOffset": 105}, {"referenceID": 43, "context": "The local minima found by the training algorithm are usually good local minima, thanks to the oversized parameter space and to the noise induced by the stochastic gradient procedure (LeCun et al., 1998).", "startOffset": 182, "endOffset": 202}, {"referenceID": 38, "context": "For instance, Kudo and Matsumoto (2001) use an ensemble of classifiers trained with different tagging conventions (see Section 3.", "startOffset": 14, "endOffset": 40}, {"referenceID": 37, "context": "State-ofthe-art systems often exploit additional parse trees such as the k top ranking parse trees (Koomen et al., 2005; Haghighi et al., 2005).", "startOffset": 99, "endOffset": 143}, {"referenceID": 27, "context": "State-ofthe-art systems often exploit additional parse trees such as the k top ranking parse trees (Koomen et al., 2005; Haghighi et al., 2005).", "startOffset": 99, "endOffset": 143}, {"referenceID": 23, "context": "5 Parsing Gildea and Palmer (2002) offer several arguments suggesting that syntactic parsing is a necessary prerequisite for the SRL task.", "startOffset": 10, "endOffset": 35}, {"referenceID": 14, "context": "The CoNLL 2005 SRL benchmark task provides parse trees computed using both the Charniak (2000) and Collins (1999) parsers.", "startOffset": 79, "endOffset": 95}, {"referenceID": 14, "context": "The CoNLL 2005 SRL benchmark task provides parse trees computed using both the Charniak (2000) and Collins (1999) parsers.", "startOffset": 79, "endOffset": 114}, {"referenceID": 14, "context": "We show performance of our system fed with different levels of depth of the Charniak parse tree. We report previous results of our architecture with no parse tree as a baseline. Koomen et al. (2005) report test and validation performance using six parse trees, as well as validation performance using only the top Charniak parse tree.", "startOffset": 76, "endOffset": 199}, {"referenceID": 35, "context": "Koomen et al. (2005) also report a 74.", "startOffset": 0, "endOffset": 21}, {"referenceID": 14, "context": "76% F1 score on the validation set using only the Charniak parse tree. Using the first three parse tree levels, we reach this performance on the validation set. We also reported in Table 12 our previous performance obtained with the CHUNK feature (see Table 10). It is surprising to observe that adding chunking features into the semantic role labeling network performs significantly worse than adding features describing the level 0 of the Charniak parse tree (Table 12). Indeed, if we ignore the label prefixes \u201cBIES\u201d defining the segmentation, the parse tree leaves (at level 0) and the chunking have identical labeling. However, the parse trees identify leaf sentence segments that are often smaller than those identified by the chunking tags, as shown by Hollingshead et al. (2005).16 Instead of relying on Charniak parser, we chose to train a second chunking network to identify the segments delimited by the leaves of the Penn Treebank parse trees (level 0).", "startOffset": 50, "endOffset": 787}, {"referenceID": 31, "context": "As in (Hollingshead et al., 2005), consider the sentence and chunk labels \u201c(NP They) (VP are starting to buy) (NP growth stocks)\u201d.", "startOffset": 6, "endOffset": 33}, {"referenceID": 69, "context": "The induced word representation has been used with success in a wide variety of NLP tasks, including POS (Sch\u00fctze, 1995), NER (Miller et al.", "startOffset": 105, "endOffset": 120}, {"referenceID": 53, "context": "The induced word representation has been used with success in a wide variety of NLP tasks, including POS (Sch\u00fctze, 1995), NER (Miller et al., 2004; Ratinov and Roth, 2009), or parsing (Koo et al.", "startOffset": 126, "endOffset": 171}, {"referenceID": 65, "context": "The induced word representation has been used with success in a wide variety of NLP tasks, including POS (Sch\u00fctze, 1995), NER (Miller et al., 2004; Ratinov and Roth, 2009), or parsing (Koo et al.", "startOffset": 126, "endOffset": 171}, {"referenceID": 36, "context": ", 2004; Ratinov and Roth, 2009), or parsing (Koo et al., 2008).", "startOffset": 44, "endOffset": 62}, {"referenceID": 47, "context": "Other related approaches exist, like phrase clustering (Lin and Wu, 2009) which has been shown to work well for NER.", "startOffset": 55, "endOffset": 73}, {"referenceID": 47, "context": "Mnih and Hinton (2007) proposed a related language model approach inspired from Restricted Boltzmann Machines.", "startOffset": 0, "endOffset": 23}, {"referenceID": 9, "context": "One popular approach is the Brown clustering algorithm (Brown et al., 1992a), which builds hierachical word clusters by maximizing the bigram\u2019s mutual information. The induced word representation has been used with success in a wide variety of NLP tasks, including POS (Sch\u00fctze, 1995), NER (Miller et al., 2004; Ratinov and Roth, 2009), or parsing (Koo et al., 2008). Other related approaches exist, like phrase clustering (Lin and Wu, 2009) which has been shown to work well for NER. Finally, Huang and Yates (2009) have recently proposed a smoothed language modelling approach based on a Hidden Markov Model, with success on POS and Chunking tasks.", "startOffset": 56, "endOffset": 517}, {"referenceID": 63, "context": "Following the Ratinov and Roth (2009) and Koo et al.", "startOffset": 14, "endOffset": 38}, {"referenceID": 36, "context": "Following the Ratinov and Roth (2009) and Koo et al. (2008) setups, we generated 1, 000 Brown clusters using the implementation17 from Liang (2005).", "startOffset": 42, "endOffset": 60}, {"referenceID": 36, "context": "Following the Ratinov and Roth (2009) and Koo et al. (2008) setups, we generated 1, 000 Brown clusters using the implementation17 from Liang (2005). To make the comparison fair, the clusters were first induced on the concatenation of Wikipedia and Reuters datasets, as we did in Section 4 for training our largest language model LM2, using a 130K word dictionary.", "startOffset": 42, "endOffset": 148}, {"referenceID": 84, "context": "For instance, Turian et al. (2010) performed a comparison of Brown Clusters and embeddings trained in the same spirit as ours18, with additional features combining labels and tokens.", "startOffset": 14, "endOffset": 35}, {"referenceID": 81, "context": "Table 16 compares the tagging speeds for our system and for the few available state-of-the-art systems: the Toutanova et al. (2003) POS tagger20, the Shen et al.", "startOffset": 108, "endOffset": 132}, {"referenceID": 73, "context": "(2003) POS tagger20, the Shen et al. (2007) POS tagger21 and the Koomen et al.", "startOffset": 25, "endOffset": 44}, {"referenceID": 37, "context": "(2007) POS tagger21 and the Koomen et al. (2005) SRL system.", "startOffset": 28, "endOffset": 49}, {"referenceID": 84, "context": "Secondly, they predict the correctness of the final word of each window instead of the center word (Turian et al., 2010), effectively restricting the model to unidirectional prediction.", "startOffset": 99, "endOffset": 120}, {"referenceID": 82, "context": "POS System RAM (MB) Time (s) Toutanova et al. (2003) 800 64 Shen et al.", "startOffset": 29, "endOffset": 53}, {"referenceID": 74, "context": "(2003) 800 64 Shen et al. (2007) 2200 833 SENNA 32 4", "startOffset": 14, "endOffset": 33}, {"referenceID": 37, "context": "SRL System RAM (MB) Time (s) Koomen et al. (2005) 3400 6253 SENNA 124 51", "startOffset": 29, "endOffset": 50}, {"referenceID": 42, "context": "Following the classical \u201cback-propagation\u201d derivations (LeCun, 1985; Rumelhart et al., 1986) and the modular approach shown in (Bottou, 1991), any feed-forward neural network with L layers, like the ones shown in Figure 1 and Figure 2, can be seen as a composition of functions f l \u03b8(\u00b7), corresponding to each layer l: f\u03b8(\u00b7) = f \u03b8 (fL\u22121 \u03b8 (.", "startOffset": 55, "endOffset": 92}, {"referenceID": 68, "context": "Following the classical \u201cback-propagation\u201d derivations (LeCun, 1985; Rumelhart et al., 1986) and the modular approach shown in (Bottou, 1991), any feed-forward neural network with L layers, like the ones shown in Figure 1 and Figure 2, can be seen as a composition of functions f l \u03b8(\u00b7), corresponding to each layer l: f\u03b8(\u00b7) = f \u03b8 (fL\u22121 \u03b8 (.", "startOffset": 55, "endOffset": 92}, {"referenceID": 4, "context": ", 1986) and the modular approach shown in (Bottou, 1991), any feed-forward neural network with L layers, like the ones shown in Figure 1 and Figure 2, can be seen as a composition of functions f l \u03b8(\u00b7), corresponding to each layer l: f\u03b8(\u00b7) = f \u03b8 (fL\u22121 \u03b8 (.", "startOffset": 42, "endOffset": 56}], "year": 2011, "abstractText": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.", "creator": "LaTeX with hyperref package"}}}