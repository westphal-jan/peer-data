{"id": "1104.0235", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Apr-2011", "title": "Gaussian Robust Classification", "abstract": "Supervised learning is all about the ability to generalize knowledge. Specifically, the goal of the learning is to train a classifier using training data, in such a way that it will be capable of classifying new unseen data correctly. In order to acheive this goal, it is important to carefully design the learner, so it will not overfit the training data. The later can is done usually by adding a regularization term. The statistical learning theory explains the success of this method by claiming that it restricts the complexity of the learned model. This explanation, however, is rather abstract and does not have a geometric intuition. The generalization error of a classifier may be thought of as correlated with its robustness to perturbations of the data: a classifier that copes with disturbance is expected to generalize well. Indeed, Xu et al. [2009] have shown that the SVM formulation is equivalent to a robust optimization (RO) formulation, in which an adversary displaces the training and testing points within a ball of pre-determined radius. In this work we explore a different kind of robustness, namely changing each data point with a Gaussian cloud centered at the sample. Loss is evaluated as the expectation of an underlying loss function on the cloud. This setup fits the fact that in many applications, the data is sampled along with noise. We develop an RO framework, in which the adversary chooses the covariance of the noise. In our algorithm named GURU, the tuning parameter is a spectral bound on the noise, thus it can be estimated using physical or applicative considerations. Our experiments show that this framework performs as well as SVM and even slightly better in some cases. Generalizations for Mercer kernels and for the multiclass case are presented as well. We also show that our framework may be further generalized, using the technique of convex perspective functions.", "histories": [["v1", "Fri, 1 Apr 2011 19:33:05 GMT  (892kb,D)", "http://arxiv.org/abs/1104.0235v1", "Master's dissertation of the first author, carried out under the supervision of the second author"]], "COMMENTS": "Master's dissertation of the first author, carried out under the supervision of the second author", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ido ginodi", "amir globerson"], "accepted": false, "id": "1104.0235"}, "pdf": {"name": "1104.0235.pdf", "metadata": {"source": "CRF", "title": "Gaussian Robust Classification", "authors": ["Ido Ginodi", "Amir Globerson"], "emails": [], "sections": [{"heading": null, "text": "The generalization error of a classifier can be considered to be correlated with its robustness with disturbances in the data. Indeed, it was found that the ordinary SVM formulation corresponds to a robust formulation in which an opponent can move the training and test points within a ball with a predetermined radius (Xu et al. [2009]). In this work, we are investigating a different type of robustness. We propose to change each data point with a Gaussian cloud centered at the original point. Loss is evaluated as an expectation of an underlying loss function on the cloud. This setup fits the fact that the data is sampled with noise in many applications. We are developing a robust optimization framework (RO) in which the opponent chooses the covariance of noise as a basis."}, {"heading": "1 Introduction 5", "text": "1. Motivation..........................................................................................................................................................................................................................................................................."}, {"heading": "2 Gaussian Robust Classification 12", "text": "1. Formulation of problems...................................................................................................................."}, {"heading": "3 Dual formulation 27", "text": "1 Mathematical derivation.............................. 27 2 A general framework.........................."}, {"heading": "4 Introducing Kernels 37", "text": ".................................................................."}, {"heading": "5 The Multiclass Case 45", "text": "1. Problem formulation.............................. 45 2. The choice of the opponent.............................. 462.1 Application of a spectral standard limitation.................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "6 Discussion 52", "text": "1 Contribution......................................... 52 2 Generalizations............................................"}, {"heading": "A Single-Point Algorithms 57", "text": "1. Presentation of problems.........................................................................................................................................................................................................................................................................................................................."}, {"heading": "B Diagonal Covariance 61", "text": "C Using Multi-Hinge Loss 63Chapter 1Introduction"}, {"heading": "1. Motivation", "text": "The ability to understand new invisible data, based on knowledge gained with the help of a training sample, is probably the main goal of machine learning. In this case, the learning task is to develop a decision rule that makes it possible to predict the correct designation of unknown data. Since the main goal is to be able to generalize data, it makes sense to design the learning process to reflect the conditions under which the classifier is tested and used. In many real-world applications, the data is corrupted by noise. Noise may be inherent in the process that generates the data, or vice versa. Examples of inherent noise include a loud sensor and the natural variability of the data. Mutual noise is present, for example, in spam emails."}, {"heading": "2. The supervised learning framework", "text": "This means that the data are the different classes to which the data can be assigned (e.g. 0, 1,.., 9 in the handwritten digit example).A distribution D is defined via X, X, and Y. It dictates the probability that a data point x will be taken together with a label x, Y, and Y. In our discussion, we will limit ourselves to the Euclidean case, namely X = Rd. Otherwise, we assume a binary setting in which Y = {+ 1, \u2212 1}.2. Hypothesis class considers hypotheses from class H. This class consists of functions from X to Y."}, {"heading": "3. Support Vector Machines", "text": "In the support vector machine (SVM), the present loss measure is the hinge-loss hinge (x m, ym; w) = [1 \u2212 ymwTxm] + 'hinge is a substitute loss function in the sense that it limits the zero-one loss upwards. Moreover, \"the hinge is convex, which makes it a much more convenient target for numerical optimization than the zero-one loss. Note that the hinge loss entails a penalty if the classifier correctly predicts the margin of a sample, but does so with too little margin, i.e. wTxm < 1. The penalty for an incorrect classification is linear in the distance of the sample from the hyperplan. As discussed, the optimization of the loss sum can only lead to a poor generalization formacy.The SVM solution is to add an L2 regulation term."}, {"heading": "4. Robustness", "text": "In fact, most of them will be able to move to another world, in which they will be able to escape rather than to another world."}, {"heading": "5. Between robustness and regularization", "text": "The fact that robustness is related to the regulation and generalization of SVM is not too surprising. In fact, first equivalence results for learning problems other than the classification more than a decade ago have been established (Ghaoui and Lebret [1997]; Xu et al. [2008]; Bishop [1994]). Recently, Xu et al. [2009] have proven the fact that the regulation applied by SVM corresponds to a robust formulation. Specifically, they have shown that the following two formulations are equivalent w, b \u03bb w + M = 1 [1 \u2212 ym (wTxm \u2212 b)] + min w, b max \u0445 m \u00b2 \u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0438\u0441\u0442\u0438\u0441\u0442\u0438\u0441\u0442\u0438\u0441\u0442\u0438\u0441\u0442\u0438\u0441\u0442\u0438\u0441\u0442\u0438\u0441\u0442\u0438\u0441\u0438\u0441\u0442\u0438\u043c = 1 [1 \u2212 ym (wT (xm \u2212 \u0441\u043am) \u2212 b)]] + where it is the dual norm. This equivalence casts a new light on the SVM equivalence and the tuneometric interface."}, {"heading": "6. Our contribution", "text": "We present a new robust learning system in which each data point is centered by a stochastic cloud, and the loss is then evaluated as an expectation of an underlying loss on the cloud. We then select the parameters of the distribution of this cloud in contradictory ways. We analyze the case in which the opponent is limited to selecting a Gaussian cloud with a tracebounded covariance matrix. Then, we show that this formulation culminates in a gentle approximation of the hinged loss, which becomes narrower as the cloud shrinks around each sample of data, a loss function that has been proven to have a convex perspective structure. By deriving the dual problem, we are able to demonstrate a method for generating new smooth loss functions. Our algorithmic approach is to directly solve the original problem, and we show that this leads to a learning algorithm that generates both synthetic and real data on SVM, as well as non-real data."}, {"heading": "7. Related work", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "1. Problem Formulation", "text": "In this section, we formally describe the model we are examining in the work. We take hinge loss as the underlying loss function and build on it the learning framework. We then show that the new frame we are introducing is equivalent to an unlimited minimization of an effective loss function. Remember that hinge loss is defined as \"hinge (x m, ym; w)\" = [1 \u2212 ymwTxm] + (2,1) We perform the expected hinge loss' hinge (x m, ym; D) = En \u0445 D [1 \u2212 ymwT (xm, ym; n) + (2,2) where D is a predefined sound distribution over the sample space. The optimization problem for learning a classifier w.r.t. the expected hinge loss is thusmin w m = 1 'hinge (x m, ym; w, D) + (2,3), where the opponent has the ability to select the sound distribution min, we have to determine at the end w x x x x with 2.5 x x x (formulation x x)."}, {"heading": "2. The adversarial Choice", "text": "Eq.2,5 represents the general noise-resistant formulation. In the following, we derive an explicit loss function for a specific collection of sound distributions. We focus on the case in which the opponent is forced to distribute a Gaussian noise that has a conductive covariance matrix. The motivation behind this restriction is physical. Gaussian noise is the worst noise in the sense that it has the maximum entropy of all distributions with a certain Poer constraint. Thus, by limiting the sum of eigenvalues of the covariance matrix, we bind the power that the opponent can distribute. Gaussian noise is the worst noise in the sense that it has the maximum entropy among all distributions with a certain Poer constraint. On the basis of the notations of the previous section, we place the constraint on the opponent asC = C\u03b2 = {D \u00b2 N (0, \u0445 N), in the sense that it exhibits the maximum entropy among all distributions with a certain Poer constraint."}, {"heading": "2.1 The structure of the loss function", "text": "The following paragraphs are of a more technical nature. For later use, we will introduce the integration of the robust hinge loss function = = Q = = Q = =. We will then prove a monotony property of integrated loss. This property will help us to analyze the type of opposing choice in our case. The key observation throughout the derivative is that multivariate expectation can be transformed into a univariate problem. We will conclude with the notations introduced and obtained in Equation 2.6 above: \"robhinge (x m, ym; w) = max."}, {"heading": "2.2 The optimal covariance matrix subject to a trace constraint", "text": "We will now focus on finding the optimal adversary, i.e. maximizing the \u03b2-equation 2,8 over the range of permitted covariance matrices. The next theorem determines which covariance matrix achieves the worst loss. In our terminology, we refer to this result as the adversary's choice. Theorem 2,1: The idea behind the expected loss is to replace the original sample point with a Gaussian cloud centered at the original point (Figure 2,1a). Consider an arbitrary shift x-m = xm + n. For fixed w, n can be written as n-equation + n-equation. The relevant quantity is wT x-m = wTxm + wTn-m, i.e., the orthogonal results do not make sense."}, {"heading": "3. A smooth loss function", "text": "In the previous sections, we have performed the technical calculations necessary to derive the robust hinge loss explicitly and to find the optimal covariance matrix. In the following, we will summarize these results and present an explicit formulation of the loss function resulting from our model. Furthermore, it is shown that our robust loss can be presented as the perspective of a scalar smooth approximation of the hinge loss. If the \"diameter\" of the noise cloud has shrunk, we can gain a better understanding of the \"noise effect.\" We conclude this section by showing that our loss function is a smooth approximation of the hinge loss. If the \"diameter of the smoke cloud has shrunk, we will obtain a notation for the result of Proposition 1L (xm, ym; w) = (1 \u2212 ymwTxm) erf (1 \u2212 ymwTxm) f."}, {"heading": "4. GURU: a primal algorithm", "text": "We are now ready to develop an algorithm that solves our learning problem. In this section we describe a stochastic gradient descent method (SGD) that minimizes the strictly convex loss function (see Shalev-Shwartz et al. [2007b]; Kivinen et al. [2003]; Zhang et al. [2003]; Nedic and Bertsekas [2000]; Bottou and Bousquet [2008], e.g.: Capturing the robust hinge loss function that we derived from the original optimization task (Equation 2,15) (Equation 2,5); Nedic and Bertsekas [2000]; Bottou and Bousquet [2008]."}, {"heading": "5. Experiments", "text": "In this area, we are in a position to seek a solution that meets the needs of the individual."}, {"heading": "1. Mathematical Derivation", "text": "This section is quite technical and goes through the derivative of the dual system. We start with the perspective representation of \"robhinge\" and imagine that other loss functions can be included in the derivative. The main result of this section is that the dual form of equation 2.22 ismax. m, the effects of f, in such a way that other loss functions can be included in the derivative, is quite simple. The main result of this section is that we will go through the details. The optimization task Equation 2.22 can be written asmin w as we know it (1 \u2212 ymwTxm)."}, {"heading": "2. A general framework", "text": "In this section we discuss the relationship between the loss function f and the norm constraint that appears in the dual problem. We claim that there is a correspondence between approximations of f and relaxations of the dual problem. More specifically: approximations of the loss function culminate in approximations of the feasible region of the dual problem. Thus, the norm constraint in the dual problem is a core component of the optimization. We call bys (\u03b1) = exp (\u2212 inventive (\u03b1) 22) (3,24) the function below the sum. It is complicated to handle and understand s (\u03b1), so it is attractive to approximate it with elementary functions."}, {"heading": "1. A representer result", "text": "The first step in the direction of the GURU is to rely on the development of the technical evidence, as it is the foundations for the derivation of kerenelized algorithms."}, {"heading": "2. KEN-GURU: A primal kernelized version of GURU", "text": "The next step in the derivative is to edit the components of the algorithm so that the only dependence on the data samples and the classifier can be no more than one dot. (This is the case, we can apply the kernel trick, namely to replace each dot product (xm) Txn with the kernel entry (xm, xn) (for example, Aizerman et al.). We start by extending the quantities that appear in the update formula in relation to the value of the new formula. (Then we introduce a method to update the value of the norm, cheaply as we compile the results, and prsenting the KEN-GURU (KNelized GaUssian RobUst)."}, {"heading": "3. Experiments", "text": "In this section, we present experimental results relating to the performance of KEN-GURU. We show how \u03c3 affects the learned classifiers and then compare KEN-GURU to SVM on USPS pairs and on the ionosphere database (see Table 2.1 for details). For the USPS tasks, a polynomial core of Grade 2 was used and for the ionosphere, RBF with \u03b3 = 1. The results are summarized in Table 4.1.Consider Figure 4.1, in which KEN-GURU classifiers for various values of the parameter trained own weight are presented with a polynomial core of Grade 2. The toy probelm was uniformly taken by the initial generation of points to [\u2212 7.5, 7.5] \u00d7 7.5, 7.5]. Points that fall within the ball of Radius 2 around the origin, we were assigned a positive designation. Points farther from the origin than 3.5 units were taken as negative examples."}, {"heading": "1. Problem formulation", "text": "In this section we formally describe the generalization of the learning task from binary to multi-class case. We show that the generalization culminates in a loss function, which is the sum of several suitable binary loss.In Chapter 2 we have our derivation from the hinge loss' scharge (x m, ym; w) = [1 \u2212 ymwTx] + (5,2) The most common generalization of the hinge loss to multi-class case is' mult (x m, ym; w1,..., wC) = maxy [wTy x m \u2212 wTymxm + \u03b4y, ym] (5,3) However, this loss function is not applicable within our scope (see Appendix C). Instead, we propose to minimize the following replacement loss function (Weston & Watkins, e.g. ref):'sum (x m, ym \u2212 w2,.., wC) wsym, where the primary loss function (Weston & Watkins, e.g. ref):' wsum (x \u2212 wsum)."}, {"heading": "2. The adversarial choice", "text": "In the following, we will focus on deriving the opposing selection for the problem at hand. It seems that the solution in the current situation is simpler than the one we had in Chapter 2."}, {"heading": "2.1 Applying a spectral norm constraint", "text": "Let us examine what is the optimal way in which the opponent interprets the noise (5,9). The ideas of development are similar to those of theorem 2,1. Denote \"W y,\" y. \"(5,7) Using the same procedure we used in the binary case (see section 2,1 and Equation 2,15), we can write Equation 5,5 as: min w1, w2,..., wC\" m \"max.\" (5,7), the task being to optimize the effective loss function \"robsum\" (x m, ym. \"(w1, ym.\"), W \"ym,\" y \"W.\" (W \"ym,\" y \"),\" W. \"(5,8), i.e. the task is to optimize the effective loss function\" robsum. \"(w1, ym.\"), wC \", \u03b2\") = maxx. \""}, {"heading": "2.2 The connection to the trace constraint", "text": "It is interesting to examine the reduction of the loss of the multi-class that we have derived in the binary case. Note that, since we have used a much larger matrix collection, we have no aprix reason to expect that the results will match. If we take C = 2, we return to the binary case. We use w + 1, w \u2212 1 for the weight vectors of the classes. If we extend the equation 5.9, we end up with \"robsum (x m, ym; w + 1, w \u2212 1, \u03b2) =\" rob sharp (x m, + 1; wym \u2212 w \u2212 ym, \u03b2) (5,15). If we take w = w + 1 \u2212 w \u2212 w \u2212 1, we end up with \"robsum (x m, ym; w + 1, w \u2212 1, \u03b2) =\" rob hinge (x m, ym; w \u2212 ym, \u03b2) (5,16) It is interesting to observe that the resulting losses are different from the constraints we put on the matrix functions, although the phenomena are identical."}, {"heading": "3. M-GURU: a primal algorithm for the multiclass case", "text": "In the following, we generalize GURU (presented in Section 4) in the case of multi-class updating. As a direct corrosion of the results presented in the previous chapters, we have that our loss function is strictly convex in this case. Therefore, we turn to the development of an SGD procedure. We start by calculating the course of \"robsum\" (x m, ym; w1, w2,...). Randomly, we write it in relation to the binary loss function \"robhinge:\" wr'robsum (xm, ym; w1, w2,.., wC, \u03b2) = \"r\" w'robhinge \"(xn, + 1; w, \u03b2). Randomness:\" robhinge. \"(b, \u03b2). Randomness:\" robhinge \"robhinge.\" (w, \u03b2). Randomness: \"robsum\" robhinge. \"(w, \u03b2)."}, {"heading": "4. Experiments", "text": "M-GURU and M-GURU-S2 have been tested on toy problems, USPS and some UCI databases (Frank and Asuncion [2010]). Data sets are detailed in Table 5.1. In Toys-3 and Toys-4, each class is a Gaussian distribution. These problems are visualized in Figure 5.3. Results are summarized in Table 5.2. Note that the performance of M-GURU is similar to that of SVM. Nevertheless, it should be noted that SVM slightly surpasses M M-GURU. This difference is explained by the fact that M-GURU is based on the sum of hinge losses, which is a looser replacement for zero-one loss than the SVM multi-hinge loss function. We have tested the relative performance of M-GURU and M-GURU-S2 on the Toys-3 data sets."}, {"heading": "1. Contribution", "text": "In this case, it is that it is a reactionary act that has an effect in the way it has taken place in the United States over the last two decades. (...) It is not as if he has been able to trump himself. (...) It is not as if he has been able to trump himself. (...) It is not as if he has been able to trump himself. (...) It is not as if he has been able to trump himself. (...) It is as if he is able to trump himself. (...) It is not as if he is able to trump himself. (...) It is not as if he is able to exaggerate himself. (...) It is not as if he is able to exaggerate himself. (...) It is not as if he is able to exaggerate himself. (...) It is not as if he is able to exaggerate himself."}, {"heading": "2. Generalizations", "text": "Vandenberghe et al. [2007] have shown that the probability of a theorem defined by quadratic inequalities can be calculated by means of semi-defined programming. Furthermore, they have shown that the optimum is achieved by means of a discrete probability distribution. We suspect that in our case a similar technique can be used to show that the optimum of loss expectation is achieved by means of a discrete distribution. Furthermore, the same scaffolding can be used to investigate more convex disturbances. Thus, in the field of computer vision, for example, it is possible to assume that the opponent rotates or translates the sample and that the distribution of these disturbances is chosen unfavorably. In order to make this practicable, it is crucial to understand in which cases the integration of this framework remains interesting for the work."}, {"heading": "Appendix A", "text": "As already discussed, one possible way to achieve this goal is to apply a contradictory framework. The most important problem in this case is the development of an effective opponent. While we have examined more sophisticated opponents in the previous chapters of the paper, it is nice to end the journey with a rather simple mathematical formulation.The binary version of the algorithms has been extensively examined. We review the results here for a full presentation of the results, followed by a simple generalization for the case of the multiclass classclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclassclass."}, {"heading": "1. Problem presentation", "text": "Perhaps the simplest action that the opponent can perform at the test point is to shift a test point in a way that will cause that point to be misclassified. If we restrict the opponent's freedom, he may not be able to corrupt the classification of the point, but only reduce the denomination associated with it. The model that we will examine below gives the opponent the ability to move a pattern point within a ball centered at the starting point. To make the learned classifier robust to such shifts, we should modify the goal of the learning task. In the following, we will introduce and analyze a way to do this by optimizing the worst-case scenario: min w max. \u2212 xm: m = 1.. M \u00b2 w \u00b2 w \u00b2 w \u00b2 m = 1 [ymwT (xm + \u0445 xm) + (A.1) This formulation has an additive structure in which each term \u00b2 xm appears exactly once."}, {"heading": "2. Computing the optimal displacement", "text": "Intuitively, the opponent will try to move the point to the wrong side of the dividing hyperplane. To this end, it is pointless to move the point along an axis that is not orthogonal to the dividing hyperplane. This idea is illustrated in Figure A.1. We will now prove this simple theorem: Theorem 2.1: The optimum of maximization in Equation A.4 is achieved with xopt = x \u2212 \u0445 w-Proof: First, we find that the function f (z) = [1 \u2212 z] + is a monotonous, non-increasing function of its argument. Therefore, the maximization of f (z) corresponds to the minimization of f (z). Through the Cauchy-Schwartz inequality, we have the possibility that the equality f (z) = [ywT) = [1 \u2212 w] x is."}, {"heading": "3. ASVC: Adversarial Support Vector Classification", "text": "The fact that Equation A.4 has a simple solution in a closed form enables us to apply the algorithmic scheme of alternating optimization for Equation A.1. The structure of the algorithm is quite simple: 1. Alternatively: (a) Optimize for w (b) Optimize for \u2206 x1, \u0445 x2,..., \u0445 xMUp to convergence. Note that 1a is nothing else than an SVM that takes the displaced points as input. Moreover, 1b has a closed solution, as we have proven in Theorem 2.1. Therefore, in order to solve the optimal classifier, any commercially available SVM solver can be used. In the end, we stand at Algorithm 5.Algorithm: Data: ASS, a comprehensive solution as we have demonstrated in Theorem 2.1. Thus, in order to solve the optimal classifier, any commercially available SVM solver can be used."}, {"heading": "4. The Multiclass Case", "text": "The multiclass loss is defined as \"mult (x m, ym; w1, w2,..., wC) = maxy = 1,2,..., C [\u03b4y, ym \u2212 (wym \u2212 wy) Txm] (A.6) Using the terms of the previous section, we define\" singlemult (x m, ym; w1, w2,..., wC) = max."}, {"heading": "5. Related work", "text": "Our ASVC algorithm is a mirror image of the TSVC presented in (Bi & Zhang, NIPS04).TSVC performs alternately optimizations and each time replaces the set of training samples with {xi + yi\u03b4i w \u0441\u0435\u0441w \u0439} which are further away from the separator (hence easier to classify).The idea is to address the case where noisy data distracts the classifier by using the postponed training sets."}, {"heading": "Appendix B", "text": "Diagonal covarianceIn this appendix we will discuss the case in which the opponent is forced to choose a diagonal covariance matrix. This setting corresponds to the case in which the noise is aligned with the primary axes. In this case, we are able to provide an analytical result in closed form subject to a limitation of the covariance matrix. The opposing selection problem can be described as Writtenmax \u03a3 = diag (a1, a2,..., ad) tr (\u03a3) \u2264 \u03b2L (xm, ym; w, wT\u0448w) (B.1). Extend the problem of the opposing choice: w = wTdiag (a1, a2,.., ad) w = d \u0432i = 1 aiwi 2 = aTw \u00b7 2where w \u00b7 2 represents the coordinate-wise product w with itself."}, {"heading": "Appendix C", "text": "The most common generalization of the hinge loss for the multi-class case is the following loss function \"mult\" (x m, ym; w1,., wC) = maxy [wTy x m \u2212 wTymxm + \u03b4y, ym] (C.1) (see Crammer and Singer [2002]). In this appendix we show some of the problems that led us to work with the sum of the hinge loss function and not with the one. If we include the multi-hinge loss in our frame, we get the following learning problem: min w \u00b2 m \u00b2 s \u00b2 s \u00b2 s \u00b2 p (x \u00b2 xm) max \u2212 y \u2212 wTymx \u2212 piey, ym] dx \u00b2 s \u00b2 (C.2) Define \u00b2 wy, ym = wy \u00b2 s \u00b2 s and write: min \u00b2 m \u00b2 s \u00b2 s \u00b2 s (x \u00b2 s)."}], "references": [{"title": "Theoretical foundations of the potential function method in pattern recognition learning", "author": ["M.A. Aizerman", "E.A. Braverman", "L. Rozonoer"], "venue": "In Automation and Remote Control,,", "citeRegEx": "Aizerman et al\\.,? \\Q1964\\E", "shortCiteRegEx": "Aizerman et al\\.", "year": 1964}, {"title": "Natural gradient works efficiently in learning", "author": ["Shun-Ichi Amari"], "venue": "Neural Comput.,", "citeRegEx": "Amari.,? \\Q1998\\E", "shortCiteRegEx": "Amari.", "year": 1998}, {"title": "Incorporating prior information into support vector machines in the form of ellipsoidal knowledge", "author": ["Jean baptiste Pothin", "Cdric Richard"], "venue": null, "citeRegEx": "Pothin and Richard.,? \\Q2008\\E", "shortCiteRegEx": "Pothin and Richard.", "year": 2008}, {"title": "Local rademacher complexities", "author": ["Peter L. Bartlett", "Olivier Bousquet", "Shahar Mendelson"], "venue": "In Annals of Statistics,", "citeRegEx": "Bartlett et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2002}, {"title": "Convex analysis and optimization", "author": ["Dimitri P. Bertsekas", "Angelia Nedic", "Asuman E. Ozdaglar"], "venue": "Athena Scientific, Nashua,", "citeRegEx": "Bertsekas et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bertsekas et al\\.", "year": 2003}, {"title": "Robust sparse hyperplane classifiers: Application to uncertain molecular profiling data", "author": ["Chiranjib Bhattacharyya", "L.R. Grate", "Michael I. Jordan", "Laurent El Ghaoui", "I. Saira Mian"], "venue": "Journal of Computational Biology,", "citeRegEx": "Bhattacharyya et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bhattacharyya et al\\.", "year": 2004}, {"title": "A second order cone programming formulation for classifying missing data", "author": ["Chiranjib Bhattacharyya", "Pannagadatta K. Shivaswamy", "Alex J. Smola"], "venue": "In NIPS,", "citeRegEx": "Bhattacharyya et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bhattacharyya et al\\.", "year": 2004}, {"title": "Support vector classification with input data uncertainty", "author": ["Jinbo Bi", "Tong Zhang"], "venue": "nips,", "citeRegEx": "Bi and Zhang.,? \\Q2004\\E", "shortCiteRegEx": "Bi and Zhang.", "year": 2004}, {"title": "Training with noise is equivalent to tikhonov regularization", "author": ["Chris M. Bishop"], "venue": "Neural Computation,", "citeRegEx": "Bishop.,? \\Q1994\\E", "shortCiteRegEx": "Bishop.", "year": 1994}, {"title": "The Tradeoffs of Large Scale Learning", "author": ["L\u00e9on Bottou", "Olivier Bousquet"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Bottou and Bousquet.,? \\Q2008\\E", "shortCiteRegEx": "Bottou and Bousquet.", "year": 2008}, {"title": "Large scale online learning", "author": ["L\u00e9on Bottou", "Yann LeCun"], "venue": null, "citeRegEx": "Bottou and LeCun.,? \\Q2003\\E", "shortCiteRegEx": "Bottou and LeCun.", "year": 2003}, {"title": "Convex Optimization", "author": ["Stephen Boyd", "Lieven Vandenberghe"], "venue": "URL http://www.stanford.edu/ \u0303boyd/ cvxbook/", "citeRegEx": "Boyd and Vandenberghe.,? \\Q2004\\E", "shortCiteRegEx": "Boyd and Vandenberghe.", "year": 2004}, {"title": "Training a support vector machine in the primal", "author": ["Olivier Chapelle"], "venue": "Neural Computation,", "citeRegEx": "Chapelle.,? \\Q2007\\E", "shortCiteRegEx": "Chapelle.", "year": 2007}, {"title": "On the algorithmic implementation of multiclass kernelbased vector machines", "author": ["Koby Crammer", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Crammer and Singer.,? \\Q2002\\E", "shortCiteRegEx": "Crammer and Singer.", "year": 2002}, {"title": "Regularization networks and support vector machines", "author": ["Theodoros Evgeniou", "Massimiliano Pontil", "Tomaso Poggio"], "venue": "In Advances in Computational Mathematics,", "citeRegEx": "Evgeniou et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Evgeniou et al\\.", "year": 2000}, {"title": "Robust solutions to least-squares problems with uncertain", "author": ["Laurent El Ghaoui", "Herve Lebret"], "venue": null, "citeRegEx": "Ghaoui and Lebret.,? \\Q1997\\E", "shortCiteRegEx": "Ghaoui and Lebret.", "year": 1997}, {"title": "Nightmare at test time: robust learning by feature deletion", "author": ["Amir Globerson", "Sam T. Roweis"], "venue": "ICML, volume 148 of ACM International Conference Proceeding Series,", "citeRegEx": "Globerson and Roweis.,? \\Q2006\\E", "shortCiteRegEx": "Globerson and Roweis.", "year": 2006}, {"title": "Advances in Neural Information Processing Systems", "author": ["Daphne Koller", "Dale Schuurmans", "Yoshua Bengio", "L\u00e9on Bottou", "editors"], "venue": "Proceedings of the Twenty-Second Annual Conference on Neural Information Processing Systems,", "citeRegEx": "Koller et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Koller et al\\.", "year": 2008}, {"title": "Convergence rate of incremental subgradient algorithms. In Stochastic Optimization: Algorithms and Applications, pages 263\u2013304", "author": ["Angelia Nedic", "Dimitri Bertsekas"], "venue": null, "citeRegEx": "Nedic and Bertsekas.,? \\Q2000\\E", "shortCiteRegEx": "Nedic and Bertsekas.", "year": 2000}, {"title": "A kernel classifier for distributions", "author": ["Alexei Pozdnoukhov", "Samy Bengio"], "venue": null, "citeRegEx": "Pozdnoukhov et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pozdnoukhov et al\\.", "year": 2005}, {"title": "Useful bounds on the expected maximum of correlated normal variables", "author": ["Andrew M. Ross"], "venue": null, "citeRegEx": "Ross.,? \\Q2003\\E", "shortCiteRegEx": "Ross.", "year": 2003}, {"title": "Learning with kernels : support vector machines, regularization, optimization, and beyond. Adaptive computation and machine learning", "author": ["Bernhard Sch\u00f6lkopf", "Alexander J. Smola"], "venue": null, "citeRegEx": "Sch\u00f6lkopf and Smola.,? \\Q2002\\E", "shortCiteRegEx": "Sch\u00f6lkopf and Smola.", "year": 2002}, {"title": "Mind the duality gap: Logarithmic regret algorithms for online optimization", "author": ["Shai Shalev-Shwartz", "Sham M. Kakade"], "venue": "In Koller et al", "citeRegEx": "Shalev.Shwartz and Kakade.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz and Kakade.", "year": 2009}, {"title": "Pegasos: Primal estimated subgradient solver for svm", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro"], "venue": "In Zoubin Ghahramani, editor, ICML, volume 227 of ACM International Conference Proceeding Series,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2007}, {"title": "Pegasos: Primal estimated subgradient solver for svm. 2007b. URL http://ttic.uchicago.edu/ \u0303shai/ papers/ShalevSiSr07.pdf. A fast online algorithm for solving the linear svm in primal using sub-gradients", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro"], "venue": null, "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2007}, {"title": "Second order cone programming approaches for handling missing and uncertain data", "author": ["Pannagadatta K. Shivaswamy", "Chiranjib Bhattacharyya", "Alexander J. Smola"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Shivaswamy et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Shivaswamy et al\\.", "year": 2006}, {"title": "From regularization operators to support vector kernels", "author": ["Alexander Smola", "Bernhard Schlkopf", "Rudower Chaussee", "Bernhard Sch Olkopf"], "venue": "Advances in Neural information processings systems", "citeRegEx": "Smola et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Smola et al\\.", "year": 1998}, {"title": "Generalized chebyshev bounds via semidefinite programming", "author": ["Lieven Vandenberghe", "Stephen Boyd", "Katherine Comanor"], "venue": "SIAM Review,", "citeRegEx": "Vandenberghe et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Vandenberghe et al\\.", "year": 2007}, {"title": "The Nature of Statistical Learning", "author": ["Vladimir Vapnik"], "venue": null, "citeRegEx": "Vapnik.,? \\Q1995\\E", "shortCiteRegEx": "Vapnik.", "year": 1995}, {"title": "Support vector machines for multi-class pattern recognition", "author": ["J. Weston", "C. Watkins"], "venue": "In Proceedings of the Seventh European Symposium On Artificial Neural Networks,", "citeRegEx": "Weston and Watkins.,? \\Q1999\\E", "shortCiteRegEx": "Weston and Watkins.", "year": 1999}, {"title": "Robust regression and lasso", "author": ["Huan Xu", "Constantine Caramanis", "Shie Mannor"], "venue": "In Koller et al", "citeRegEx": "Xu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2009}, {"title": "Robustness and regularization of support vector machines", "author": ["Huan Xu", "Constantine Caramanis", "Shie Mannor"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Xu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2009}, {"title": "Modified logistic regression: An approximation to svm and its applications in large-scale text categorization", "author": ["Jian Zhang", "Rong Jin", "Yiming Yang", "Alexander G. Hauptmann"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2003}, {"title": "In this appendix we point out some of the issues that made us choose to work with the sum-of-hinges loss function and not with the one above. If we plug the multi-hinge loss", "author": ["Crammer", "Singer"], "venue": null, "citeRegEx": "Crammer and Singer,? \\Q2002\\E", "shortCiteRegEx": "Crammer and Singer", "year": 2002}], "referenceMentions": [{"referenceID": 30, "context": "Indeed, it was established that the ordinary SVM formulation is equivalent to a robust formulation, in which an adversary may displace the training and testing points within a ball of pre-determined radius (Xu et al. [2009]).", "startOffset": 207, "endOffset": 224}, {"referenceID": 25, "context": "For a detailed review see Vapnik [1995]. A common solution for this problem is to add a regularization term to the objective of the minimization problem.", "startOffset": 26, "endOffset": 40}, {"referenceID": 24, "context": "From the statistical learning theory\u2019s point of view, the regularization restricts the complexity of the model, and by that controls the difference between the training and testing error (Smola et al. [1998]; Evgeniou et al.", "startOffset": 188, "endOffset": 208}, {"referenceID": 13, "context": "[1998]; Evgeniou et al. [2000]; Bartlett et al.", "startOffset": 8, "endOffset": 31}, {"referenceID": 3, "context": "[2000]; Bartlett et al. [2002]).", "startOffset": 8, "endOffset": 31}, {"referenceID": 7, "context": "In some cases, the training data and the testing data are sampled from different processes, which are similar to some extent but are not identical (Bi and Zhang [2004]).", "startOffset": 148, "endOffset": 168}, {"referenceID": 24, "context": "In the Robust-SVM model, the adversary may apply a bounded additive distrubance, by displacing a sample point within a ball around it (Shivaswamy et al. [2006]).", "startOffset": 135, "endOffset": 160}, {"referenceID": 16, "context": "Globerson and Roweis [2006] assumed a different type of adversary.", "startOffset": 0, "endOffset": 28}, {"referenceID": 14, "context": "Indeed, first equivalence results have been established for learning problems other than classification more than a decade ago (Ghaoui and Lebret [1997]; Xu et al.", "startOffset": 128, "endOffset": 153}, {"referenceID": 14, "context": "Indeed, first equivalence results have been established for learning problems other than classification more than a decade ago (Ghaoui and Lebret [1997]; Xu et al. [2008]; Bishop [1994]).", "startOffset": 128, "endOffset": 171}, {"referenceID": 8, "context": "[2008]; Bishop [1994]).", "startOffset": 8, "endOffset": 22}, {"referenceID": 8, "context": "[2008]; Bishop [1994]). Recently, Xu et al. [2009] have proven the fact that the regularization employed by SVM is equivalent to a robust formulation.", "startOffset": 8, "endOffset": 51}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids.", "startOffset": 22, "endOffset": 48}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids. Pozdnoukhov et al. [2005] have shown how to train classifiers for distributions.", "startOffset": 22, "endOffset": 119}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids. Pozdnoukhov et al. [2005] have shown how to train classifiers for distributions. Similar to what we do in this work, they use tails of distributions in their derivation. Their work, however, treated each data class as a distribution, whereas in this work we attach a noise distribution for each data point separately. Bhattacharyya et al. [2004b]; Shivaswamy et al.", "startOffset": 22, "endOffset": 440}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids. Pozdnoukhov et al. [2005] have shown how to train classifiers for distributions. Similar to what we do in this work, they use tails of distributions in their derivation. Their work, however, treated each data class as a distribution, whereas in this work we attach a noise distribution for each data point separately. Bhattacharyya et al. [2004b]; Shivaswamy et al. [2006] have employed second order cone programming (SOCP) methods in order to handle the uncertainty in the data.", "startOffset": 22, "endOffset": 466}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids. Pozdnoukhov et al. [2005] have shown how to train classifiers for distributions. Similar to what we do in this work, they use tails of distributions in their derivation. Their work, however, treated each data class as a distribution, whereas in this work we attach a noise distribution for each data point separately. Bhattacharyya et al. [2004b]; Shivaswamy et al. [2006] have employed second order cone programming (SOCP) methods in order to handle the uncertainty in the data. Bhattacharyya et al. [2004a] have assumed stochastic clouds instead of discrete points, as we do, but they did not try to minimize the expectation of the loss function over the cloud.", "startOffset": 22, "endOffset": 602}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids. Pozdnoukhov et al. [2005] have shown how to train classifiers for distributions. Similar to what we do in this work, they use tails of distributions in their derivation. Their work, however, treated each data class as a distribution, whereas in this work we attach a noise distribution for each data point separately. Bhattacharyya et al. [2004b]; Shivaswamy et al. [2006] have employed second order cone programming (SOCP) methods in order to handle the uncertainty in the data. Bhattacharyya et al. [2004a] have assumed stochastic clouds instead of discrete points, as we do, but they did not try to minimize the expectation of the loss function over the cloud. Instead, their idea was to incorporate the idea with the soft margin framework. Bi and Zhang [2004] have tried to learn a better classifier by presenting the learning algorithm \u2019more reasonable\u2019 samples.", "startOffset": 22, "endOffset": 857}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids. Pozdnoukhov et al. [2005] have shown how to train classifiers for distributions. Similar to what we do in this work, they use tails of distributions in their derivation. Their work, however, treated each data class as a distribution, whereas in this work we attach a noise distribution for each data point separately. Bhattacharyya et al. [2004b]; Shivaswamy et al. [2006] have employed second order cone programming (SOCP) methods in order to handle the uncertainty in the data. Bhattacharyya et al. [2004a] have assumed stochastic clouds instead of discrete points, as we do, but they did not try to minimize the expectation of the loss function over the cloud. Instead, their idea was to incorporate the idea with the soft margin framework. Bi and Zhang [2004] have tried to learn a better classifier by presenting the learning algorithm \u2019more reasonable\u2019 samples. We elaborate on this model in Appendix A. Smooth loss function were studied by Zhang et al. [2003]; Chapelle [2007].", "startOffset": 22, "endOffset": 1060}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids. Pozdnoukhov et al. [2005] have shown how to train classifiers for distributions. Similar to what we do in this work, they use tails of distributions in their derivation. Their work, however, treated each data class as a distribution, whereas in this work we attach a noise distribution for each data point separately. Bhattacharyya et al. [2004b]; Shivaswamy et al. [2006] have employed second order cone programming (SOCP) methods in order to handle the uncertainty in the data. Bhattacharyya et al. [2004a] have assumed stochastic clouds instead of discrete points, as we do, but they did not try to minimize the expectation of the loss function over the cloud. Instead, their idea was to incorporate the idea with the soft margin framework. Bi and Zhang [2004] have tried to learn a better classifier by presenting the learning algorithm \u2019more reasonable\u2019 samples. We elaborate on this model in Appendix A. Smooth loss function were studied by Zhang et al. [2003]; Chapelle [2007]. Analysis of methods for Solving SVM and SVM-like problems using the primal formulation was done by Shalev-Shwartz et al.", "startOffset": 22, "endOffset": 1077}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids. Pozdnoukhov et al. [2005] have shown how to train classifiers for distributions. Similar to what we do in this work, they use tails of distributions in their derivation. Their work, however, treated each data class as a distribution, whereas in this work we attach a noise distribution for each data point separately. Bhattacharyya et al. [2004b]; Shivaswamy et al. [2006] have employed second order cone programming (SOCP) methods in order to handle the uncertainty in the data. Bhattacharyya et al. [2004a] have assumed stochastic clouds instead of discrete points, as we do, but they did not try to minimize the expectation of the loss function over the cloud. Instead, their idea was to incorporate the idea with the soft margin framework. Bi and Zhang [2004] have tried to learn a better classifier by presenting the learning algorithm \u2019more reasonable\u2019 samples. We elaborate on this model in Appendix A. Smooth loss function were studied by Zhang et al. [2003]; Chapelle [2007]. Analysis of methods for Solving SVM and SVM-like problems using the primal formulation was done by Shalev-Shwartz et al. [2007a]; Chapelle [2007].", "startOffset": 22, "endOffset": 1207}, {"referenceID": 2, "context": "For example, baptiste Pothin and Richard [2008] have warped the data points with ellipsoids. Pozdnoukhov et al. [2005] have shown how to train classifiers for distributions. Similar to what we do in this work, they use tails of distributions in their derivation. Their work, however, treated each data class as a distribution, whereas in this work we attach a noise distribution for each data point separately. Bhattacharyya et al. [2004b]; Shivaswamy et al. [2006] have employed second order cone programming (SOCP) methods in order to handle the uncertainty in the data. Bhattacharyya et al. [2004a] have assumed stochastic clouds instead of discrete points, as we do, but they did not try to minimize the expectation of the loss function over the cloud. Instead, their idea was to incorporate the idea with the soft margin framework. Bi and Zhang [2004] have tried to learn a better classifier by presenting the learning algorithm \u2019more reasonable\u2019 samples. We elaborate on this model in Appendix A. Smooth loss function were studied by Zhang et al. [2003]; Chapelle [2007]. Analysis of methods for Solving SVM and SVM-like problems using the primal formulation was done by Shalev-Shwartz et al. [2007a]; Chapelle [2007].", "startOffset": 22, "endOffset": 1224}, {"referenceID": 11, "context": "Definition 3 Perspective of a function (from Boyd and Vandenberghe [2004] 3.", "startOffset": 45, "endOffset": 74}, {"referenceID": 11, "context": "For a proof see Boyd and Vandenberghe [2004] 3.", "startOffset": 16, "endOffset": 45}, {"referenceID": 11, "context": "Consider the following lemma (Boyd and Vandenberghe [2004] 3.", "startOffset": 30, "endOffset": 59}, {"referenceID": 21, "context": "A convergence result for the algorithm stems from general properties of SGD that were studied extensively (see Shalev-Shwartz et al. [2007b]; Kivinen et al.", "startOffset": 111, "endOffset": 141}, {"referenceID": 21, "context": "A convergence result for the algorithm stems from general properties of SGD that were studied extensively (see Shalev-Shwartz et al. [2007b]; Kivinen et al. [2003]; Zhang et al.", "startOffset": 111, "endOffset": 164}, {"referenceID": 21, "context": "A convergence result for the algorithm stems from general properties of SGD that were studied extensively (see Shalev-Shwartz et al. [2007b]; Kivinen et al. [2003]; Zhang et al. [2003]; Nedic and Bertsekas [2000]; Bottou and Bousquet [2008], e.", "startOffset": 111, "endOffset": 185}, {"referenceID": 17, "context": "[2003]; Nedic and Bertsekas [2000]; Bottou and Bousquet [2008], e.", "startOffset": 8, "endOffset": 35}, {"referenceID": 9, "context": "[2003]; Nedic and Bertsekas [2000]; Bottou and Bousquet [2008], e.", "startOffset": 36, "endOffset": 63}, {"referenceID": 1, "context": "It has been suggested that using the stochastic version yields better generalization performance in learning tasks (Amari [1998]; Bottou and LeCun [2003]).", "startOffset": 116, "endOffset": 129}, {"referenceID": 1, "context": "It has been suggested that using the stochastic version yields better generalization performance in learning tasks (Amari [1998]; Bottou and LeCun [2003]).", "startOffset": 116, "endOffset": 154}, {"referenceID": 17, "context": "We therefore suggest the following SGD procedure Algorithm 1: GURU(S,\u03b70, ) Data: Training set S , learning rate \u03b70, accuracy Result: w w \u2190 0; while \u2206L \u2265 do m\u2190 rand(M); w \u2190 w \u2212 \u03b70 \u221a t \u2207w` hinge(x, y;w, \u03c3); end return w; For convergence results see Nedic and Bertsekas [2000]. For a full treatment, see Bertsekas et al.", "startOffset": 247, "endOffset": 274}, {"referenceID": 4, "context": "For a full treatment, see Bertsekas et al. [2003], chapter 8.", "startOffset": 26, "endOffset": 50}, {"referenceID": 30, "context": "Nontheless, this result gives an experimental support to the theoretical result in Xu et al. [2009], where it was shown that the ordinary SVM formulation is equivalent to a robust formulation, in which the adversary is capable of displacing the data samples.", "startOffset": 83, "endOffset": 100}, {"referenceID": 11, "context": "where g\u2217 is by definition the conjugate function of g (for details see Boyd and Vandenberghe [2004] 3.", "startOffset": 71, "endOffset": 100}, {"referenceID": 11, "context": "If when substituting the dual optimum in the Lagrangian, there exists a unique primal feasible solution, then it must be primal optimal (see Boyd and Vandenberghe [2004], 5.", "startOffset": 141, "endOffset": 170}, {"referenceID": 21, "context": "For a proof and more details, see for example Sch\u00f6lkopf and Smola [2002]. As mentioned, we will discuss three techniques to establis the required result.", "startOffset": 46, "endOffset": 73}, {"referenceID": 0, "context": "That being the case, we can apply the kernel trick, namely to replace each dot product (xm)xn with the kernel entry \u03ba(x,x) (for details see, for example, Aizerman et al. [1964]; Sch\u00f6lkopf and Smola [2002]).", "startOffset": 154, "endOffset": 177}, {"referenceID": 0, "context": "That being the case, we can apply the kernel trick, namely to replace each dot product (xm)xn with the kernel entry \u03ba(x,x) (for details see, for example, Aizerman et al. [1964]; Sch\u00f6lkopf and Smola [2002]).", "startOffset": 154, "endOffset": 205}, {"referenceID": 29, "context": "First, we work with the sum-of-hinges loss function (Weston and Watkins [1999]).", "startOffset": 53, "endOffset": 79}, {"referenceID": 30, "context": "Xu et al. [2009] have shown that SVM is equivalent to a robust formulation in which the parameter corrsponds to the radius of a rigid ball in which the sample point may be displaced.", "startOffset": 0, "endOffset": 17}, {"referenceID": 22, "context": "see Shalev-Shwartz et al. [2007a] for details), it is probably possible to use it in order to achieve even faster algorithms.", "startOffset": 4, "endOffset": 34}, {"referenceID": 22, "context": "In this ball, it is possible that our loss function is strongly-convex,hence it can be optimized using more aggressive procedure (Shalev-Shwartz and Kakade [2008]).", "startOffset": 130, "endOffset": 163}, {"referenceID": 27, "context": "Vandenberghe et al. [2007] have shown that the probability of a set defined by quadratic inequalities may be computed using semidefinite programming.", "startOffset": 0, "endOffset": 27}], "year": 2011, "abstractText": "Supervised learning is all about the ability to generalize knowledge. Specifically, the goal of the learning is to train a classifier using training data, in such a way that it will be capable of classifying new unseen data correctly. In order to acheive this goal, it is important to carefully design the learner, so it will not overfit the training data. The later can be done in a couple of ways, where adding a regularization term is probably the most common one. The statistical learning theory explains the success of the regularization method by claiming that it restricts the complexity of the learned model. This explanation, however, is rather abstract and does not have a geometric intuition. The generalization error of a classifier may be thought of as correlated with its robustness to perturbations of the data. Namely, if a classifier is capable of coping with distrubance, it is expected to generalize well. Indeed, it was established that the ordinary SVM formulation is equivalent to a robust formulation, in which an adversary may displace the training and testing points within a ball of pre-determined radius (Xu et al. [2009]). In this work we explore a different kind of robustness. We suggest changing each data point with a Gaussian cloud centered at the original point. The loss is evaluated as the expectation of an underlying loss function on the cloud. This setup fits the fact that in many applications, the data is sampled along with noise. We develop a robust optimization (RO) framework, in which the adversary chooses the covariance of the noise. In our algorithm named GURU, the tuning parameter is the variance of the noise that contaminates the data, and so it can be estimated using physical or applicative considerations. Our experiments show that this framework generates classifiers that perform as well as SVM and even slightly better in some cases. Generalizations for Mercer kernels and for the multiclass case are presented as well. We also show that our framework may be further generalized, using the technique of convex perspective functions.", "creator": "LaTeX with hyperref package"}}}