{"id": "1105.3486", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2011", "title": "Xapagy: a cognitive architecture for narrative reasoning", "abstract": "We introduce the Xapagy cognitive architecture: a software system designed to perform narrative reasoning. The architecture has been designed from scratch to model and mimic the activities performed by humans when witnessing, reading, recalling, narrating and talking about stories.", "histories": [["v1", "Tue, 17 May 2011 20:28:31 GMT  (659kb,DS)", "http://arxiv.org/abs/1105.3486v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ladislau b\\\"ol\\\"oni"], "accepted": false, "id": "1105.3486"}, "pdf": {"name": "1105.3486.pdf", "metadata": {"source": "CRF", "title": "Xapagy: a cognitive architecture for narrative reasoning", "authors": ["Ladislau B\u00f6l\u00f6ni"], "emails": ["lboloni@eecs.ucf.edu"], "sections": [{"heading": null, "text": "CONTENTSI Introduction 2"}, {"heading": "II A top-down introduction 2", "text": "II-A External view: the Pidgin language..... 2 II-B From words to concepts and verbs...... 3 II-C instances...................... 4 II-D The focus.................... 4 II-E shadows.............. 4 II-D The focus................"}, {"heading": "III The primitive components of the architecture 5", "text": "III-A Random Identifiers............ 5 III-B Concepts and Overlays............. 5 III-C Negation............. 6 III-D Verbs and Verb Overlays............. 7 III-E Instances, Attributes and Relationships.......... 7 III-F Verb Instances............. 7 III-D Verbs and Verb Overlays............. 7 III-E Instances, Attributes and Relationships......"}, {"heading": "IV Focus and shadows 7", "text": "IV-A Terminology and notation......... 7 consecutive IV-B stories and the focus........ 8 IV-C shadows............."}, {"heading": "V Core knowledge 8", "text": "V-A scenes..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "VI Episodic knowledge 12", "text": "VI-A Memorization................. 12 VI-B Forgetting.................."}, {"heading": "VII The Xapi abstraction and reference resolution 13", "text": "VII-A Word Interpretation............ 14 VII-B Reference resolution.............. 14VII-B1 Special resolution rules for quotations 15 VII-C Reference resolution...................... 15 VII-D Verbalization.............. 15"}, {"heading": "VIII Narrative reasoning in Xapagy 15", "text": "VIII-A Headless Shadows. VIII-C Storytelling: Recall and Confusion. 16VIII-C1 Case 1: Pure Memory of a Testified History. VIII-C4 Case 4: Self Shadowing Recall. Drift 19 VIII-C5 Case 5: Forced Recall. Case 2: Competitive Recall. 17 VIII-C3 Case 3: Recall of Common Events. 18 VIII-C4 Case 4: Self Shadowing Recall. Drift 19 VIII-C5 Case 5: Forced Recall. 19 VIII-C6 Case 6: Leading Questions. 17 VIII-C3 Case 3: Recall of Common Events. 18 VIII-C4 Case 4: Self Shadowing Recall. Drift 19 VIII-C5 Case 5: Forced Recall. 19 VIII-C6 Case 6: Leading Questions. 20 VIII-C3 C3 C3 Case 3. VIII-C7 C7: Storyline Jumping. 20 CIII-C8 C8 C8-C8 C8-20VIII-D."}, {"heading": "IX Related work 23", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "X Conclusion 26", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Appendix A: Abbreviations, notations and typographical conventions 26", "text": "As a matter of fact, the majority of them will be able to survive on their own, without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is not a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is not in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is not a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a"}, {"heading": "II. A TOP-DOWN INTRODUCTION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. External look: the pidgin language", "text": "In fact, it is such that most of them will be able to move to another world, in which they are able to integrate themselves, in which they are able to live, in which they are able to live, in which they are able to live, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live that they live, in which they live, in which they live, in which they live that they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live"}, {"heading": "B. From words to concepts and verbs", "text": "This year, it is only a matter of time before agreement is reached."}, {"heading": "D. The focus", "text": "The focus in the Xapagy system holds instances and verb instances for a limited period of time after their creation, during which they are variable. After an instance or verb instance leaves the focus, it can never return - and therefore remains immutable. Instances in focus can acquire new attributes, participate in verb instances as subject or object, and become part of relationships. Verb instances in focus can become part of a sequence or summary of relationships, and they can be referenced by new verb instances. A visually thinking reader might think about the focus in the following way: The focus is a dynamically evolving graph. New nodes (instances and verb instances) are added by different events. The same events could also create new edges between the nodes of focus. If a node leaves the focus, it retains its attributes and edges, but it cannot acquire new ones."}, {"heading": "E. Shadows", "text": "Instances and verbs that leave the focus are downgraded to the memory of the Xapagy agent with a certain amount of validity; they will never come back into focus. On the other hand, each instance and verb instance in focus has a shadow, a weighted collection of instances and verb instances from memory. Shadows are maintained by a combination of techniques aimed at reconciling the shadows."}, {"heading": "III. THE PRIMITIVE COMPONENTS OF THE ARCHITECTURE", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Random identifiers", "text": "The Xapagy system works by adding verb instances (continuous) and instances (occasional) into focus. The need for new instances is met by a generator that delivers a continuous flow of random identifiers. If a new instance or verb instance is needed, the Xapagy agent selects the current identifier from the continuous flow and introduces it into focus. Identifiers that become verb instances are decorated with attributes in the form of a concept overlay and can participate in relationships that are suitable for instances (such as ownership, group affiliation, and scene involvement).Identifiers that become verb instances are decorated with attributes in the form of a verb concept overlay, can participate in sentence subordination relationships (subject, object, etc.) and can be parts of relationships between verb instances (succession and summary).The identifiers that become verb instances, however, do not constitute an illustration of each instance, we can force the number to be 0001 or 0001 in this case."}, {"heading": "B. Concepts and overlays", "text": "A concept in Xapagy is the representation of an indivisible attribute (\"Hector\" = 100.1 range).A weighted range (weighted overlay of terms) is called a concept (weighted overlay of terms is defined as a concept (weighted overlay of terms).For specific concepts, we will use descriptive terms in parentheses such as [man].For specific overlaps, we will list the participating concepts within parentheses if necessary, specifying the explicit energy level of each concept in the overlapping.The specificity of a concept is characterized by its area (c).The more specific a concept is, the smaller its area. We will assign a range of 1.0 to concepts that correspond to the basic objects of the hierarchy in the sense."}, {"heading": "C. Negation", "text": "In fact, it is a way in which one sees oneself in a position to surpass oneself."}, {"heading": "IV. FOCUS AND SHADOWS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Terminology and notation", "text": "To simplify this representation, let's start with several definitions. We define a weighted group of instances IS by saying that the involvement of instance I in instance IS is a value w (IS, I). Unlike COs, where concepts have effects and overlaps, instance sets deal with independent and non-interacting instances. The primary operation of instance sets is quotient addition: The state of an Xapagy agent is modified by two types of activity: spike activity (SA) and diffusion activity (DA). SAs are immediate operations on overlays and weighted sets. Examples of activities modeled by SAs include inserting an instance into the focus, inserting an instance into the instance, the effects of the instance and not the effects of the matter on the respective time."}, {"heading": "B. Story following and the focus", "text": "The focus is on the collection of instances and VIs currently active in the Xapagy Agent. Instances and VIs in focus are variable: they can acquire attributes, and they can enter into new relationships. Once an instance or VI leaves the focus (is degraded to memory), it will not change except through gradual decay. The focus can be regarded as two weighted sets of instances ISF and VIs VSF. The focus is maintained by a number of SAs and DAs. In the following description we will list the SAs informally, the exact formulas are beyond the scope of this paper. Let's start by listing the activities that affect the instances of the Focus ISF. We will anticipate their descriptions with S and D, depending on whether it is spike or diffusion activity."}, {"heading": "C. Shadows", "text": "Instances and VIs that have been demoted to memory can affect the current state of the agent by shadowing the focus. Each instance (or VI) in focus is the head of an associated instance (or verb instance) that is referred to as the body of the shadow. (S +) The shadows are created in such a way that their components reflect the previous experience of the agent in relation to the ongoing narration. Shadows are dynamic and are sustained by a number of activities: (S +) The addition of an unexpected instance or VI creates a new shadow from the headless shadow that predicts the instance (see Section VIII-B for more details). (D-) In the absence of other factors, all shadows disintegrate over time. The energy released in this DA is added to the energy of the environment: the involvement of the body: instances from memory that coincide with the shadow head."}, {"heading": "V. CORE KNOWLEDGE", "text": "The problem of domain knowledge appears in the Xapagy architecture in three forms: - Dictionary knowledge encompasses knowledge of the words in the Xapi language and the way they access COs and VOs. Xapagy agents do not need domain-specific grammatical knowledge, because pidgin grammar is very simple and rigid. - The non-identity relationship is created explicitly for different instances in the same line of action, including their areas, overlaps, implications and, for a small number of meta-verbs that are not nonially identical to Lancelot.9 - Conceptual knowledge is encoded in the properties of concepts and verbs."}, {"heading": "A. Scenes", "text": "A scene in Xapagy is a division of the reference space. Each Xapi sentence dissolves its references within a single scene that must be dissolved before it dissolves. It follows from this modus operandi that for VIs created from Xapi, only instances that are members of the same scene can interact with each other. If an agent talks to a friend in a restaurant while talking to another on the phone, the mechanical rules of interaction will not always apply. For example, a conversation, either face to face or by remote means, is a scene. If an agent talks to a friend in a restaurant, he will be part of three scenes at the same time: two non-physical conversation scenes, and the physical scene of the room, including the furniture, his friend and other customers. Scenes are translated as relationships between the scene and the entease."}, {"heading": "B. Groups", "text": "The concept of a group in Xapagy allows us to have VIs where the subject or object is a collection of entities. Groups are implemented as instances that have the special attribute [group], and they can be in a composite relationship with a number of other instances. Instances can be part of more than one group, and they can dynamically join and leave groups. An explicit group is a group of individually known instances: 1 An explicit group / exists. 2 The group / contains / Billy. 3 The group / is joined by / \"Johnny.\" Side effects of most meta verbs are distributed among members of explicit groups. For example, we can remove all members of the group from the current scene by saying: 1 The group / contains / \"Johnny.\" In the case of implicit groups, the elements are not enumerated: 1 A group / exists. 2 The group / is-a / many man.An implicit group can still have explicit members: 1 The group / contains / Johnny. \""}, {"heading": "C. Ownership-type relations", "text": "In fact, it is as if most of them are able to survive themselves by putting themselves on the side of the other. (...) It is not as if they put themselves on the side of the other. (...) It is as if they put themselves on the side of the other. (...) It is as if they put themselves on the side of the other. (...) It is as if they put themselves on the side of the other. (...) It is as if they put themselves on the side of the other. (...) It is as if they put themselves on the side of the other. (...) It is as if they put themselves on the side of the other. (...) It is as if they put themselves on the side of the other. (...). (...) It is as if they put themselves. (...). (...) It is. (...). (...) It is. (...) It is. (...). (...) It is. (...) It is. (...) It is. (...). It is. (...) It is. (...). It is. (...). It is. (...). It is. (...). It is. (... It is. (...). It is. It is. (). (...). It is. It is. (. (). It is. It is. (. It is. (). It is. (...). It is. It is. It is. (. It is. (). It is. It is. (). It is. (. It is. It is. (). (. It is. It is. (.). It is. It is. It is. (). It is. It is. It is. (. It is. (). (). It is. It is. It is. It is. (). (). (. It is. (). It is. (). It is. It is. It is. It is. (. (). It is. (). It is. It is. (). It is. (. (). It is. It is. It is. (. It is. It is. (). (). It is. (. It is. It is."}, {"heading": "E. The succession chain", "text": "The successive relationship is established between a predecessor VI and a successor VI when a new action VI is inserted into the focus. SA, which is activated when inserting the verbal instance Vn, creates successive relations between Vn and all VIs V in focus, where the strength of the relationship is determined by: rs (Vn, V) = \u03c3 \u00b7 (w \u00b7 M (Vn, V) + 1 \u2212 w) \u00b7 focus (V) r (10) The matching relationship M (Vn, V) takes the value 1 if V and Vn have at least one part in common, and 0 otherwise. The compensation factor w determines whether successive relationships are established only with VIs that have parts in common with the new VI (w = 1), with all VIs in focus (w = 0) or intermediate values."}, {"heading": "F. Summarization relationships", "text": "Figure 5 shows an example of the summary process (the VIs are represented with the corresponding Xapi statement); the left column of the VIs is created by direct observation, while the VI in the right column is created by the summary process; the VI summary is created when the second \"hit\" verb instance is output; as long as the running VIs are inserted into the focus, they match the current summary VIs, they will match the current summary VI. Like other VIs, the summary VIs will participate in successive and summary relationships, allowing future recall processes to remember some stories in more detail than others. Multiple summary VIs can be active in the focus at the same time; some of them may be summaries of VIs that are self-summarizing."}, {"heading": "G. Creation of instances", "text": "The meta-verb [create-instance] creates a new instance with a specified set of attributes and adds a relationship that the new instance is a participant in the scenes.1 Scene / create-instance / attribute list. In most cases, this type of statement does not need to be explicitly made in Xapi, since it is automatically created as a side effect when an a / a article is used. The statement is explicitly created by the callback mechanism. If the callback is verbalized, the verbalization component could roll the instance creation into the sentence that the new instance first refers to."}, {"heading": "H. Additive composition of attributes", "text": "An instance can acquire a new attribute by adding another CO to the CO associated with the instance, which is described in S-ADJ Type VI. This functionality is the side effect of the [is-a] verb: 1 \"Hector\" / is-a / warrior. The general assumption about Xapagy instances is that they reflect a story unit with an immutable set of attributes. Therefore, the continuous addition of attributes by [is-a] is considered an act of discovery, not a record of change. The attributes added should not have a negative impact on the existing sentence. If a real change in attributes is what we want to record, it must be done by the [change] verb that creates a new instance).Similar considerations apply to the VIs whose verb can be acquired by an S-ADV verb, as a side effect of the [is-action verb]: \"Achilles\" / 1. \""}, {"heading": "I. Creation of a new instance through change", "text": "If the story unit had changed its attributes (lost existing or acquired new) in a way that was not consistent with the discovery of a previously unknown but existing attribute, the Xapagy agent would have to represent it by creating a new instance. This functionality is implemented with the verb [changes]: 1 \"Hector\" / Changes / Death. A new instance is created that takes over the previous attributes of Hector (including the proper name \"Hector\"), to which the concept [not alive] is added, causing a series of negative and positive effects (e.g. the removal of the [living] concept from its attributes). At the same time, the original instance is immediately withdrawn from focus and a type relationship [somatic-identical] is created between the old and the new instances. Side effects of the verb [changes] are described by the following SAs: (S +) the creation of the new instance, with a set of attributes, the effects of the old ones are achieved by the old instances."}, {"heading": "J. Destroying an instance", "text": "Certain actions in the real world, such as eating, drinking, or dissolving, cause this unit to disappear as an identifiable part of the scene. If this unit has been assigned to an Xapagy instance, the instance cannot be destroyed, as instances and their attributes are immutable. Destruction in the real world reverberates in the Xapagy agent by removing the instance from focus and scenarios. This can be done by the meta-verb [destroy], which is part of the VOs associated with words such as \"eat,\" \"drink,\" or \"swallow.\" 1 \"Billy\" / eats / an apple. On the other hand, many operations that are informally referred to as destruction, in Xapagy parlance, are not a destructive operation, but a change: 1 \"Billy\" / drops / the bottle. 2 The bottle / changes / shards of glass of numerous groups."}, {"heading": "K. Representing questions", "text": "A question in Xapagy is a verb instance that is partially unspecified and can form an answer relationship to VIs that correspond to the question. These VIs that answer questions could already be in focus, or they could be generated on demand by the headless shadow mechanism. There is no requirement that there be a single answer to a question. Some questions could not be answered (not even attempted to be answered) or one could have multiple answers to the same question. Generally, the general flow of the question-answer mechanism exceeds the scope of this paper. We will only describe the nature and specification of the question VIs.The Xapagy CoreDKL defines a specific verb [wh] and a corresponding specific concept [wh] that, as part of a VO or CO, turns the VI part into an unspecified one. Any VI that has at least one unspecified part is a question: 1 Johnny / wh weeps?"}, {"heading": "L. Representing a conversation", "text": "Xapagy defines as conversation the exchange of communicative actions between two entities in a story. It is possible to represent an exchange of words without understanding the meaning of communication. In this case, no additional knowledge is required about the definition of communicative actions themselves (\"say,\" \"ask,\" and so on). However, if we understand the content of communication, we need a method to simultaneously represent the communicative act and the meaning of communication.12The exhaustive discussion of communication models goes beyond the scope of this paper. We will illustrate the representation by an example, the famous exchange between the wolf and Red Riding Hood. We look at the external view of history: that is, the case of an Xapagy agent who translates the brothers to Xapi. Understanding starts from the point of view of the Xapagy agent: It does not require the wolf and the girl to be Xapagy agents."}, {"heading": "M. Representing a narration", "text": "The narrative scene does not normally overlap with the current scene: 1 A scene \"Smyrna\" / is-current-scene. 2 A human being / is-a / \"Homer.\" 3 A scene \"Iliad\" / exists. 4 Scene \"Iliad\" / is-before / Scene \"Smyrna.\" 5 \"Homer\" / says / \"Iliad\" / / 6 A human being / is-a / \"Achilles.\" 7 \"Homer\" / says / \"Iliad\" / / 8 \"Achilles\" / is-a / angry.In this example, Homer begins the story of the Iliad in his birthplace of Smyrna. Line 4 defines the temporal relationship between the scenes, i.e. the establishment of the scene of the Iliad occurs in the past."}, {"heading": "VI. EPISODIC KNOWLEDGE", "text": "After about a minute, he goes to Doug, who ritually lights a cigar. \"This is a good time to smoke,\" he mutters. \"Do you want one?\" \"Sure. Thank you.\" Randy pulls out a foldable multi-purpose tool and cuts off the end of the cigar, a pretty impressive-looking Cuban number. \"Why do you say it's a good time to smoke?\" \"To fix it in your memory. To mark it.\" Doug soaks his gaze off the horizon and looks at Randy, almost begging to understand it. \"This is one of the most important moments of your life. Nothing will ever be the same. We could get rich. We could just have an adventure or learn something. But we've changed.\" (\"Cryptonomicon\" by Neal Stephenson) The episode of Valience is informal, the episodic knowledge of an Xapagy agent is the totality of stories ever experienced."}, {"heading": "A. Memorization", "text": "We will describe the equations for the case of the VIs, the case of the instances is similar. Suppose that the VI enters into the focus at creation time tc and leaves it the demoting rate in time tc. While the involvement of the verb instance in focus gradually decreases, its significance will increase during the entire stay in focus, which reaches its maximum significance at the moment it is demoted to memory: Smax (V) = S (V, td) = the marking rate of the focus in focusing the verb instance in focus will gradually decrease, its meaning will increase during the entire stay in focus when it is demoted to memory: Smax (V, td) = D tc m (t) w (VSF, V).What this formula tells us is that the memorization level will increase proportionally to the time spent in focus."}, {"heading": "B. Forgetting", "text": "After being demoted to memory, the highlighting of a VI decreases along an exponential decay curve: S (V, tx) = \u03bb tx \u2212 tdSmax (V) (13) The highlighting of a VI never increases after it leaves focus. VI does not increase its highlighting: it only generates a new, similar VI that could enhance its memory (see case 4 in Section VIII-C). However, in most situations, the biggest challenge of appropriate memory is not the decreasing highlighting of verb instances, but the initialization of the recall, which must generate an appropriate focus and shadow. 8But the attribute itself remains because it depends on the instance that may have spent much more time in focus. Thus, the Xapagy agent might remember an attribute of the instance, but not when he acquired it - imitating the limitations of human source memory."}, {"heading": "VII. THE XAPI ABSTRACTION AND REFERENCE RESOLUTION", "text": "The most important means of communication between an Xapagy agent and an external entity (say, a human person or another Xapagy agent) is the Xapi Pidgin language. If we refer to an internal element of an Xapagy agent, then two sentences are merged that describe the sentence. Second, the reference to an internal instance must be made, namely by reference resolution."}, {"heading": "A. Word interpretation", "text": "In fact, most of them will be able to orient themselves in a particular direction they are in."}, {"heading": "B. Reference resolution", "text": "In fact, it is so that most people who are able are able to determine for themselves what they want and what they do not want. In fact, it is so that they are not able to be able to move, are able to be able to move. In fact, it is so that they are able to be able to move, are able to be able to be able to move."}, {"heading": "C. Reference finding", "text": "As we discussed in the introduction to this section, the Xapagy system assumes that the target agent must be the same as the source agent. However, additional criteria apply for the choice of the reference word, and these criteria usually include a preference against ambiguity in reference12. A better choice is to find a reference to it that refers either to instances with their full set of attributes: 1 The Greek warrior man \"Achilles\" / hit / 2 the Trojan warrior man \"Hector.\" A better choice is to find a minimal reference to CO, that is, an overlay that has the least energy but turns off all other alternatives. Since proper names have the smallest range, this almost always means that we refer to the proper name: 1 \"Achilles\" / hit / \"Hector.\" This reference mode, which repeats itself throughout history, seems boring to a human reader."}, {"heading": "VIII. NARRATIVE REASONING IN XAPAGY", "text": "We begin by describing the common framework of all narrative reasoning techniques, the headless shadows (Section VIII-A), and then devote a subsection to each of the following aspects of narrative reasoning techniques: - The following story (Section VIII-B): Predicting current events, expressing surprise at events and supplementing missing events. - Creation of new stories (Section VIII-C): Creation of new stories by memory or confusion (or different shades in between). - Divagations (Section VIII-D): Creation of VIs that do not advance the plot line but may be necessary (such as the introduction of instances) or helpful (such as the elaboration of instances or the justification of VIs). - Steering of stories (Section VIII-E) the means by which the creation process of the story can be guided either by the agent himself or by external agents."}, {"heading": "A. Headless shadows", "text": "All narrative reasoning techniques rely on the mechanism of headless shadows (HLS), collections of related and aligned inmemory VIs that are not paired with a current focused VI. Like shadows, HLS-s are maintained on a continuous basis by a collection of SAs and DAs. However, all narrative reasoning models can be understood in terms of a single procedural pattern. \u2022 Maintain a collection of HLS-s that maintain the current state of thenarration13It is obvious that the reference finding and concept verbalism components need to communicate in some way. This communication does not exist in the current version of Xapagy.16 \u2022 Choose an HLS for instantiation based on a specific criterion. \u2022 Instantiate the HLS by creating a new VI into focus and transform the HLS into its regular shadows."}, {"heading": "B. Story following: Predicting ongoing events, expectation fulfillment and surprise", "text": "In this simplest narrative reasoning method, the agent is a passive observer of the continuous flow of events. If a new VI is included in the focus of external sources (witnesses, readings, conversations), it is balanced against the continuation of HLSs. However, when there is a game, the HLS becomes the shadow of the new VI. This activity is an SA, and in turn changes are triggered in both the other shadows and in the continuation of HLSs. However, the consistency of history will ensure that the shadow components predicting the correct continuation are amplified and HLSs that are compatible with the new HLS are amplified. New HLSs are calculated based on the current focus and shadow, while those that become incompatible with the current status are supported or even discarded. We introduce two metrics relating to the coming event: expectation fulfillment and surprise."}, {"heading": "C. Story creation: recalling and confabulating", "text": "This year is the highest in the history of the country."}, {"heading": "D. Divagations", "text": "In fact, it is the case that most of them are able to survive themselves without being able to survive themselves, and that they are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. \""}, {"heading": "E. Story steering", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "IX. RELATED WORK", "text": "The Xapagy system has been redesigned from the ground up, but not in a single way of reasoning, and we will weigh it up and compare it. Xapagy does not currently use the summary as a guide, so it cannot automatically go to the beginning of a story. However, this is an obvious and necessary way of working in the future. Most of these systems represent work bodies that meet the Newell definition of cognitive architecture [19], as integrative systems that attempt to provide a model of a large part of human cognition, even if they do not respond to all the requirements of a human cognitive architecture as proposed in the \"Newell Test\" (Anderson and Lives), and some of them are not explicitly positioned as cognitive architecture. We will consider differences as well as similarities and similarities in approach."}, {"heading": "X. CONCLUSION", "text": "The Xapagy system is an active software project that has been in development since 2008. It was designed to perform narrative thinking, that is, to mimic human behavior when thinking about stories. The purpose of this essay was to convey the architecture of the system, focusing on the design choices that distinguish it from its counterparts in the artificial intelligence literature.To adopt the description of architecture in a single essay, we had to omit certain details, such as the informal presentation of the spike and diffusion activities that maintain shadows and headless shadows, and the various narrative thinking modes in Section VIII would merit separate and comprehensive treatment, which will be outlined in future essays."}, {"heading": "APPENDIX A ABBREVIATIONS, NOTATIONS AND TYPOGRAPHICAL CONVENTIONS", "text": "This paper uses a relatively extensive list of mathematical notations to describe the interaction between the various components of the system. We also use specific typographic conventions to represent the different levels of input, intermediate values, and output of the system, which are listed here."}, {"heading": "A. Acronyms", "text": "The following abbreviations are used in the thesis: VI Verb instanceCO concept overlay VCO verb concept overlaySA spike activity DA diffusion activity HLS headless shadow"}, {"heading": "B. Notations for basic components", "text": "V a verb instance I an instance ci a concept (an attribute or adjective) vi a verb (or adverb) \u2212 ci, \u2212 vi the negation of a concept or verb C an overlay of conceptsCV an overlay of verbs area (c) area of a concept (similar to a verb) overlap (ci, cj) the overlap between concepts ci and cj impact (ci, cj) the effect of the concept ci over concept cj een (C, c) explicit energy of the concept c in overlay C (similar to the verbs) en (C, c) implicit energy of the concept c in overlay C (similar to the verbs) act (C, c) activation of the concept c in overlay C (similar to the verbs)"}, {"heading": "C. Notations for reference resolution", "text": "match (C1, C2) the correspondence between two concept superimpositions corresponds (V1, V2) the correspondence between two verbal superimpositions"}, {"heading": "D. Notations for verb instances", "text": "vitype (V) the nature of the verb instance V (can S-V-O, S-V, S-ADJ, S-ADV, IND) comp (V) the list of components of the verb instance V V erb (V) the verb instance that defines the verb instance V SubI (V) the instance that serves as the subject of the verb instance V (if type S-V-O, S-V, S-ADJ, IND) ObjI (V) the instance that serves as the subject of the verb instance V (if type S-V-O) ObjCO (V) the concept overlay that serves as the adjective of the verb instance V (if type S-ADJ) SubV (V) the verb instance that serves as the subject of the verb instance V (if type S-VADV) (Vd instance) the strength of the V2 instance (V2) the relationship of Sub-1 (V)"}, {"heading": "E. Notations for focus and shadow", "text": "sh (IF, IS) the involvement of the instance IS in the shadow of the focus instance WF sh (VF, VS) the involvement of the verbal instance VS in the shadow of the focus verb instance VF MI (IF, IS) the intrinsic agreement between instance IF in focus and instance IS in shadow MC (IF, IS) the contextual agreement between instance IF in focus and instance IS in shadow M (IF, IS) the general agreement between instance IF in focus and instance IS in shadow MSC (VF, VS) the semi-contextual agreement between verb instance VF in focus and verb instance VS in shadow M (VF, VS) the overall agreement between verb instance VF in focus and verb instance VS in shadow"}], "references": [{"title": "An integrated theory of the mind", "author": ["J. Anderson", "D. Bothell", "M. Byrne", "S. Douglass", "C. Lebiere", "Y. Qin"], "venue": "Psychological review,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "The atomic components of thought", "author": ["J. Anderson", "C. Lebiere"], "venue": "Lawrence Erlbaum,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "The Newell test for a theory of cognition", "author": ["J. Anderson", "C. Lebiere"], "venue": "Behavioral and Brain Sciences,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Integrating cognition, perception and action through mental simulation in robots", "author": ["N. Cassimatis", "J. Trafton", "M. Bugajska", "A. Schultz"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Unsupervised learning of narrative event chains", "author": ["N. Chambers", "D. Jurafsky"], "venue": "Proceedings of ACL-08: HLT,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Unsupervised learning of narrative schemas and their participants", "author": ["N. Chambers", "D. Jurafsky"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2- Volume", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Repeated encounters of a similar kind: Effects of familiarity on children\u2019s autobiographic memory", "author": ["J. Hudson", "K. Nelson"], "venue": "Cognitive Development,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1986}, {"title": "SAL: An explicitly pluralistic cognitive architecture", "author": ["D. Jilk", "C. Lebiere", "R. O\u2019Reilly", "J. Anderson"], "venue": "Journal of Experimental & Theoretical Artificial Intelligence,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "An overview of the EPIC architecture for cognition and performance with application to human-computer interaction", "author": ["D.E. Kieras", "D.E. Meyer"], "venue": "Human\u2013Computer Interaction,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "Extending the Soar cognitive architecture", "author": ["J. Laird"], "venue": "In Proceedings of the 2008 conference on Artificial General Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Soar: An architecture for general intelligence", "author": ["J. Laird", "A. Newell", "P. Rosenbloom"], "venue": "Artificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1987}, {"title": "Toward a Computational Model of Narrative", "author": ["G. Lakoff", "S. Narayanan"], "venue": "In 2010 AAAI Fall Symposium Series,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "A unified cognitive architecture for physical agents", "author": ["P. Langley", "D. Choi"], "venue": "In Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "Towards a computational theory of human daydreaming", "author": ["E. Mueller", "M. Dyer"], "venue": "In Proceedings of the Seventh Annual Conference of the Cognitive Science Society,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1985}, {"title": "What is it like to be a bat", "author": ["T. Nagel"], "venue": "The Philosophical Review,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1974}, {"title": "KARMA: Knowledge-based active representations for metaphor and aspect", "author": ["S. Narayanan"], "venue": "PhD thesis,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1997}, {"title": "John Dean\u2019s memory: A case study", "author": ["U. Neisser"], "venue": "Cognition, 9(1):1\u201322,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1981}, {"title": "Unified theories of cognition", "author": ["A. Newell"], "venue": "Harvard Univ Pr,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1994}, {"title": "Stanford encyclopedia of philosophy: Identity", "author": ["H. Noonan"], "venue": "URL http://plato.stanford.edu/entries/identity/,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Stanford encyclopedia of philosophy: Personal identity", "author": ["E.T. Olson"], "venue": "URL http://plato.stanford.edu/entries/identity/,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Learnability and cognition: the acquisition of argument structure", "author": ["S. Pinker"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1989}, {"title": "Boyes-Braem. Basic objects in natural categories", "author": ["E. Rosch", "C. Mervis", "W. Gray", "D. Johnson"], "venue": "Cognitive psychology,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1976}, {"title": "Dynamic memory: A theory of reminding and learning in computers and people", "author": ["R. Schank"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1982}, {"title": "Scripts, plans, goals and understanding: An inquiry into human knowledge structures, volume 2", "author": ["R. Schank", "R. Abelson"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1977}, {"title": "Contact languages: Pidgins and creoles", "author": ["M. Sebba"], "venue": "Palgrave Macmillan,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1997}, {"title": "Anatomy and physiology for speech, language, and hearing", "author": ["A. Seikel", "D. King", "D. Drumright"], "venue": "Delmar Cengage Learning,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "The CLARION cognitive architecture: Extending cognitive modeling to social simulation. Cognition and multi-agent interaction: From cognitive modeling to social simulation, pages", "author": ["R. Sun"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2006}, {"title": "Episodic and semantic memory", "author": ["E. Tulving"], "venue": "Organization of memory,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1972}, {"title": "Using anytime algorithms in intelligent systems", "author": ["S. Zilberstein"], "venue": "AI magazine,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1996}], "referenceMentions": [{"referenceID": 28, "context": "It is true, using anytime algorithms [30] can turn any architecture into a constant time architecture.", "startOffset": 37, "endOffset": 41}, {"referenceID": 25, "context": "In this endeavor we are encouraged by the fact that the human brain can perform narrative reasoning with only about a dozen synapses separating input from output [27].", "startOffset": 162, "endOffset": 166}, {"referenceID": 24, "context": "In linguistics, pidgin languages [26] are natural languages with a simplified syntactic structure which appear when two groups of people need to communicate without the time necessary to properly learn each other\u2019s languages.", "startOffset": 33, "endOffset": 37}, {"referenceID": 18, "context": "These instances, of course, are connected through various relations of identity (for a discussion on the philosophical problem of personal identity we refer the reader to [20], [21]).", "startOffset": 171, "endOffset": 175}, {"referenceID": 19, "context": "These instances, of course, are connected through various relations of identity (for a discussion on the philosophical problem of personal identity we refer the reader to [20], [21]).", "startOffset": 177, "endOffset": 181}, {"referenceID": 21, "context": "[23].", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "For a certain overlay C and concept c we can define the activation act(C, c) \u2208 [0, 1] of the concept in the overlay with:", "startOffset": 79, "endOffset": 85}, {"referenceID": 20, "context": "An interesting future research direction could be to investigate the relationship between this composition model and Pinker\u2019s microfeatures [22].", "startOffset": 140, "endOffset": 144}, {"referenceID": 0, "context": "We define a weighted set of instances IS by saying that the participation of instance I in instance set IS is a value w(IS, I) \u2208 [0, 1].", "startOffset": 129, "endOffset": 135}, {"referenceID": 14, "context": "[16], but even in a purely technical reading there is a major challenge that an agent can not generate an optimal output unless it knows the dictionary and concepts of the target agents.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "The phenomena has been identified and well documented since the 1980s [8] and still under active research [4].", "startOffset": 70, "endOffset": 73}, {"referenceID": 16, "context": "A very famous example of self shadowing is the case of Nixon\u2019s counsel John Dean analyzed by Neisser [18].", "startOffset": 101, "endOffset": 105}, {"referenceID": 21, "context": "[23]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Most of these systems represent bodies of work which fit the Newell definition of cognitive architecture [19] as integrative systems which try to provide a model of a large subset of the human cognition even if they do not answer to all the twelve requirements of a human cognitive architecture as proposed in the \u201cNewell test\u201d (Anderson and Lebiere [3]).", "startOffset": 105, "endOffset": 109}, {"referenceID": 2, "context": "Most of these systems represent bodies of work which fit the Newell definition of cognitive architecture [19] as integrative systems which try to provide a model of a large subset of the human cognition even if they do not answer to all the twelve requirements of a human cognitive architecture as proposed in the \u201cNewell test\u201d (Anderson and Lebiere [3]).", "startOffset": 350, "endOffset": 353}, {"referenceID": 1, "context": "ACT-R (Anderson and Lebiere [2], Anderson et al.", "startOffset": 28, "endOffset": 31}, {"referenceID": 0, "context": "[1]) is a cognitive architecture developed based on the theoretical models of John R.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "In its initial version (Laird, Newell and Rosenbloom [12]) SOAR was primarily", "startOffset": 53, "endOffset": 57}, {"referenceID": 9, "context": "However, its recent development path increasingly integrates non-symbolic memory and processing components in the architecture (Laird [11]).", "startOffset": 134, "endOffset": 138}, {"referenceID": 12, "context": "The ICARUS system (Langley and Choi [14]) is a cognitive architecture which focuses on cognition occurring in the physical context.", "startOffset": 36, "endOffset": 40}, {"referenceID": 3, "context": "[5]) is a cognitive architecture designed to integrate multiple different representations and reasoning algorithms.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "The EPIC cognitive architecture (Kieras and Meyer [10]) has been implemented with the explicit goal to model the human multimodal and multiple task performance.", "startOffset": 50, "endOffset": 54}, {"referenceID": 26, "context": "The stated goal of the CLARION architecture (Sun [28]) is to capture cognitive modeling aspects not adequately addressed by other cognitive architectures: the implicit-explicit interaction, the cognitivemetacognitive interaction and the cognitive-motivational interaction.", "startOffset": 49, "endOffset": 53}, {"referenceID": 15, "context": "The KARMA system for story understanding (Narayanan [17]) had demonstrated the understanding of simple stories and narrative fragments in the domain of international politics and economics as described in journalism.", "startOffset": 52, "endOffset": 56}, {"referenceID": 11, "context": "A recent paper (Lakoff and Narayanan [13]) described a roadmap towards a system which understand human narratives by exploiting the cognitive structures of human motivations, goals, actions, events and outcomes.", "startOffset": 37, "endOffset": 41}, {"referenceID": 13, "context": "The DAYDREAMER system (Mueller and Dyer [15]) was a system which generated stories, based on, and initiated from actual experiences.", "startOffset": 40, "endOffset": 44}, {"referenceID": 27, "context": "DAYDREAMER modeled a dynamic episodic memory (Tulving [29], Schank [24]), constantly modified during daydreaming.", "startOffset": 54, "endOffset": 58}, {"referenceID": 22, "context": "DAYDREAMER modeled a dynamic episodic memory (Tulving [29], Schank [24]), constantly modified during daydreaming.", "startOffset": 67, "endOffset": 71}, {"referenceID": 4, "context": "An body of work, with a high relevance to the Xapagy system has been recently reported by Chambers and Jurafsky [6], [7].", "startOffset": 112, "endOffset": 115}, {"referenceID": 5, "context": "An body of work, with a high relevance to the Xapagy system has been recently reported by Chambers and Jurafsky [6], [7].", "startOffset": 117, "endOffset": 120}, {"referenceID": 23, "context": "This work can bee seen as a restart of the semantic NLP tradition of the 1970 and 80s, which used representations such as scripts (Shank and Abelson [25]).", "startOffset": 149, "endOffset": 153}, {"referenceID": 4, "context": "In [6], [7] successfully show scema and role inference, starting from preprocessed natural language.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "In [6], [7] successfully show scema and role inference, starting from preprocessed natural language.", "startOffset": 8, "endOffset": 11}], "year": 2011, "abstractText": "We introduce the Xapagy cognitive architecture: a software system designed to perform narrative reasoning. The architecture has been designed from scratch to model and mimic the activities performed by humans when witnessing, reading, recalling, narrating and talking about stories.", "creator": "LaTeX with hyperref package"}}}