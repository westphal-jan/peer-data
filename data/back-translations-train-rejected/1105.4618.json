{"id": "1105.4618", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2011", "title": "Bounding the Fat Shattering Dimension of a Composition Function Class Built Using a Continuous Logic Connective", "abstract": "We begin this report by describing the Probably Approximately Correct (PAC) model for learning a concept class, consisting of subsets of a domain, and a function class, consisting of functions from the domain to the unit interval. Two combinatorial parameters, the Vapnik-Chervonenkis (VC) dimension and its generalization, the Fat Shattering dimension of scale e, are explained and a few examples of their calculations are given with proofs. We then explain Sauer's Lemma, which involves the VC dimension and is used to prove the equivalence of a concept class being distribution-free PAC learnable and it having finite VC dimension.", "histories": [["v1", "Mon, 23 May 2011 20:04:16 GMT  (20kb)", "http://arxiv.org/abs/1105.4618v1", "Winter 2011 Honours research project done under the supervision of Dr. Vladimir Pestov at the University of Ottawa; 35 pages"]], "COMMENTS": "Winter 2011 Honours research project done under the supervision of Dr. Vladimir Pestov at the University of Ottawa; 35 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["hubert haoyang duan"], "accepted": false, "id": "1105.4618"}, "pdf": {"name": "1105.4618.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Haoyang Duan"], "emails": [], "sections": [{"heading": null, "text": "We begin this report by describing the model of probable near-correct function (PAC) for learning a concept class consisting of subsets of a domain, and a function class consisting of functions from the domain to the unit interval. Then, we explain two combinatorial parameters, the Vapnik-Tschervonenkis dimension (VC) and its generalization, the fat-shattering dimension of the scale, and give some examples of their calculations with evidence. Then, we explain Sauer's lemma, which encompasses the VC dimension and is used to prove the equivalence of a concept class that is non-distributed and has a finite VC dimension. As the most important new result of our research, we examine the construction of a new functional class that is achieved by forming compositions with a continuous logical connection, a uniform continuous function from the unit hypercube to the unit interval."}, {"heading": "1 Introduction 2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Brief Overview of Analysis and Measure Theory 3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3 The Probably Approximately Correct Learning Model 7", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4 The Vapnik-Chervonenkis Dimension 11", "text": "4.1 Sour Lemma.................................... 12 4.2 Characterization of concept-free PAC learning.... 14"}, {"heading": "5 The Fat Shattering Dimension 15", "text": "5.1 Sufficient Requirement for Functional Class Distribution-Free PAC Learning. 17"}, {"heading": "6 The Fat Shattering Dimension of a Composition Function Class 19", "text": "6.1 Construction in the Context of Concept Classes........... 19 6.2 Construction of a New Functional Class Combining Throughout Logic. 20 6.3 Main Result........................................................................... 21 6.4 Evidence......................"}, {"heading": "7 Open Questions 29", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8 Conclusion 31", "text": "References 32"}, {"heading": "1 Introduction", "text": "In the field of statistical learning theory, we will first formalize two definitions of PAC, one concept for another class and then another for another. (VC) Learning Model formalizes the concept of learning by using sample data to produce valid hypotheses through algorithms. For example, the following shows a learning problem that can be formalized in the PAC Model. Given that there is a disease that affects certain people and out of 100 people in a hospital, 12 of them are ill with this disease. Is there a way to predict whether a given person in a hospital has the disease or not? This report includes the PAC Learning Model, which is applied to learning a collection of subsets C, referred to as Concept Class, a domain X and general collection of functions F, called Function Class, from X to the Unit Interval [0, 1]. The report mainly includes concepts from analysis and some concepts from probability theory, but only the completion of the first two years of basic research in mathematics."}, {"heading": "2 Brief Overview of Analysis and Measure Theory", "text": "This section lists some definitions and results in measure theory and analysis used in standard textbooks such as [6], [18], and [2] used in this report.Probability spaceDefinition 2.1. If X is a set, then a non-empty collection of subsets of X is such that the following units of measurement are met: 1. If A \u00b2 S, then X\\ A \u00b2 S2. If A \u00b2 S is for i \u00b2 N, then N Ai N Ai SIf S is a non-empty collection of subsets of X, then the pair (X, S) is designated as a measurable space size. Definition 2.2. Suppose (X, S) and (Y) are two measurable spaces. A function f: X \u00b2 Y is designated as measurable, if f \u2212 1 (T) S is designated as measurable for all parts of T T T. Definition 2.3."}, {"heading": "3 The Probably Approximately Correct Learning", "text": "A function class F is a collection of measurable functions from X to the unit interval [0, 1]. C: a concept class and F: a function class and F: a function class4. [0, 1] X: the set of all measurable functions f: X, 1], instead of the usual notation of all functions from X to [0, 1]. This section provides the definitions of learning C and F in probability class4. [0, 1] Correct (PAC) learning model, introduced in 1984 by Valiant. Concept class AC learning includes the production of a valid hypothesis for each concept."}, {"heading": "4 The Vapnik-Chervonenkis Dimension", "text": "The Vapnik-Chervonenkis dimension is a combinatorial parameter defined using the term fragmentation (first defined in 1971 by Vapnik and Chervonenkis. Definition 4.1 ([17]). Since each set of X and a collection of A are defined by subsets of X, collection A breaks a subset of S X, if for each B S, there is a subset S = \u00b2. There is an equivalent condition that is sometimes easier to work on, expressed in terms of characteristic functions of the subsets of X. Collection A breaks a subset S = {x1,.,. xn} There is an equivalent condition if and only if for each e = (e1,.,.,., en) {0, 1} n, there exists such a subset of X.Proposition 4.2."}, {"heading": "4.1 Sauer\u2019s Lemma", "text": "In view of a concept class C of X, another way of expressing that C shatters a subset S X with cardinality n, is to consider the totality of all A S in which A stands. In Chapter 4 of [18], C shatters S if and only if | {A S: A C} | = 2n.In more general terms, the VC dimension of C can now be expressed as n in terms of growth of \u03c0 (n; C). Statement 4.7. In view of a concept class C, the following conditions are equivalent: 1. VC (C) \u2265 n; 2. C shatters some subset S X with cardinality n; 3. GDP (n; C) as worth."}, {"heading": "4.2 Characterization of concept class distribution-free PAC", "text": "The following is one of the most important PAC learning theorems, as evidenced by the work of Vapnik and Chervonenkis [17] in 1971 and the work of Blumer et al. Theorem 4.9 ([17] and [5]) in 1989. Let C be a concept class of measurable space (X, S), the following being equivalent: 1. C is non-distributive; 2. VC (C) < \u221e. Both directions of evidence require specifying the number of sample training points required for learning in relation to the VC dimension of C; Sauer's Lemma is used to provide a sufficient number of points needed for learning toward 2)."}, {"heading": "5 The Fat Shattering Dimension", "text": "Let us be a function class in which the following sections (still) assume that X = (X, S) is a measurable space and function class F (7) is a function class F (7). Let us assume F (7) is a function class."}, {"heading": "5.1 Sufficient condition for function class distribution-free", "text": "PAC LearningOne direction of Theorem 4.9 can be generalized and stated in terms of the Fat Shattering dimensions of a function class.Theorem 5.5 ([1] and [18]). Let F be a function class. If fat\u044b (F) < \u221e for all Ps > 0, then F is distribution-free PAC learnable.However, the converse to Theorem 5.5 is false. Set up a-free PAC learnable function class with infinite Fat Shattering dimension of some scale. \"Indeed, for each concept class C with cardinality.\" (FAC) and 2\u04450, there is an associated function class FC. \""}, {"heading": "6 The Fat Shattering Dimension of a Composition", "text": "Functional ClassesThe objectives of this section are to construct a new functional class from old functional classes using a continuous logical connector and to bind the fat-shattering dimension of the scale \u0445 of the new functional class to the dimensions of the old functional classes. In the following section, this construction, which can be found in Chapter 4 of [18], is presented in the context of concept classes using a connector of classical logic."}, {"heading": "6.1 Construction in the context of concept classes", "text": "Let C1, C2,. < Ck = conceptual classes in which k \u2265 2, and let u: {0, 1} k \u2192 {0, 1} be some function, commonly known as a combination of classical logic. A new collection of subsets of X results from C1,.., Ck as the following. As mentioned earlier in this report, each element A \u00b2 Ci can be considered a binary function f: X,., k, let us consider a new function u (f1,., fk): X \u2192 1} functions f1,., fk:., fk: X \u2192 {0, 1}, where fi \u00b2 Ci = 1,."}, {"heading": "6.2 Construction of new function class with continuous logic", "text": "In the logic of the first order there are only two truth values 0 or 1. Thus, a connective is a function {0, 1} k \u2192 {0, 1} in the classical sense. In continuous logic, however, truth values can be found anywhere in the interval [0, 1]. Therefore, we should consider a function u: [0, 1] k (0, 1] k that transforms function classes and requires u to be a continuous logic binding. In other words, u should be continuous from the (product) metric [0, 1] k to the unit [19]; indeed, because u is continuous from a compact metric space to a metric space. The following definition provides the definition of a uniform continuous function u from another metric space, but we must first qualify with a modulus of unitary continuity."}, {"heading": "6.3 Main Result", "text": "Fix k \u2265 2 and the following theory is our new main result. Theorem 6.4. Let us say that Fk will be function classes of X, and u: [0, 1] k \u2192 [0, 1] a uniformly continuous function with continuity module. (F1,.., Fk)) \u2264 (0, c) k (4c \"k\" k / (\u03b5 / (2c \").) K\" log \"(2) n\" F1 \"i = 1fat c\" (\u0432 / (2c \"). k\" (Fi), where c, c \"k,\" K \"are any absolute constants. Extracting the actual values of these absolute constants is not easy, and we hope to find them in future research. Therefore, the comparison of the bound in Theorem 6.4 with the existing estimate is."}, {"heading": "6.4 Proofs", "text": "To prove this, we first present the concept of coverage for each metric space, based on [9], and set this number for a function class in relation to its size. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < &lt"}, {"heading": "7 Open Questions", "text": "The definitions of distribution-free PAC learning, for both concept and function classes, in Section 3, do not contain assumptions about probability measures, since a learning algorithm must establish a valid hypothesis for all probability measures. If we determine a probability measure and ask whether a term class or function class is actually learnable, then we work in the context of the fixed distribution of PAC knowledge. Definition 7.1 ([18]) Let us define a probability measure and ask whether a function class F is likely to be considered learnable if there is an algorithm."}, {"heading": "8 Conclusion", "text": "This report introduces the definitions of probably approximately correct learning for concept and function classes and defines the Vapnik-Chervonenkis dimension for concept classes and the fat-shattering dimension for function classes. The finiteness of the VC dimension characterizes concept-class distribution-free PAC learning; however, the finiteness of the fat-shattering dimension of all scales is still sufficient and not necessarily sufficient for learning the function classes. In view of function classes F1,..., Fk one can construct a new class u (F1,..., Fk) by using a continuous function u: [0, 1] k \u2192 [0, 1], a continuous logical connection. The main new result of this report shows that the fat-shattering dimension of the scale of u (F1,..., Fk) is limited by the sum of fat-shattering dimensions of the scale of classes F1."}], "references": [{"title": "Scale-Sensitive Dimensions", "author": ["N. Alon", "S. Ben-David", "N. Cesa-Bianchi", "D. Haussler"], "venue": "Uniform Convergence, and Learnability. Journal of the ACM 44.4 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1997}, {"title": "Math\u00e9matiques: Topologie et Analyse", "author": ["G. Auliac", "J.Y. Caby"], "venue": "3rd Ed. Belgium: EdiScience", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Fat-Shattering and the Learnability of Real-Valued Functions", "author": ["P.L. Bartlett", "P.M. Long", "R.C. Williamson"], "venue": "Journal of Computer and System Sciences 52.3 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1994}, {"title": "Learnability with respect to Fixed Distributions", "author": ["G.M. Benedek", "A. Itai"], "venue": "Theoretical Computer Science 86.2 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1991}, {"title": "Learnability and the Vapnik-Chervonenkis Dimension", "author": ["A. Blumer", "A. Ehrenfeucht", "D. Haussler", "M. Warmuth"], "venue": "Journal of the ACM 36.4 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1989}, {"title": "Measure Theory", "author": ["J.L. Doob"], "venue": "New York: Springer-Verlag", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1994}, {"title": "Efficient Distribution-free Learning of Probabilistic Concepts", "author": ["M.J. Kearns", "R. Schapire"], "venue": "Journal of Computer System Sciences 48.3 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1994}, {"title": "An Introduction to Computational Learning Theory", "author": ["M.J. Kearns", "U.V. Vazirani"], "venue": "Cambridge, Massachusetts: The MIT Press", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1994}, {"title": "Entropy and the Combinatorial Dimension", "author": ["S. Mendelson", "R. Vershynin"], "venue": "Inventiones Mathematicae 152 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Indexability", "author": ["V. Pestov"], "venue": "Concentration, and VC Theory. An invited paper, Proc. of the 3rd International Conf. on Similarity Search and Applications ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "A Note on Sample Complexity of Learning Binary Output Neural Networks Under Fixed Input Distributions", "author": ["V. Pestov"], "venue": "Proc. 2010 Eleventh Brazilian Symposium on Neural Networks, IEEE Computer Society, Los Alamitos-Washington-Tokyo ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "On the Densities of Families of Sets", "author": ["N. Sauer"], "venue": "J. Combinatorial Theory 13 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1972}, {"title": "The Glivenko-Cantelli Problem", "author": ["M. Talagrand"], "venue": "Annals of Probability 15 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1987}, {"title": "The Glivenko-Cantelli Problem", "author": ["M. Talagrand"], "venue": "Ten Years Later. J. Theoret. Probab. 9 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1996}, {"title": "Vapnik-Chervonenkis Type Conditions and Uniform Donsker Classes of Functions", "author": ["M. Talagrand"], "venue": "Annals of Probability 31.3 ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2003}, {"title": "A Theory of the Learnable", "author": ["L.G. Valiant"], "venue": "Communications of the ACM 27.11 ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1984}, {"title": "On the Uniform Convergence of Relative Frequencies of Events to Their Probabilities", "author": ["V.N. Vapnik", "A.Y. Chervonenkis"], "venue": "Theory of Prob. and its Appl. 16.2 ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1971}, {"title": "A Theory of Learning and Generalization: With Applications to Neural Networks and Control Systems", "author": ["M. Vidyasagar"], "venue": "London: Springer-Verlag London Limited", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "Model Theory for Metric Structures", "author": ["I.B. Yaacov", "A. Berenstein", "C.W. Henson", "A. Usvyatsov"], "venue": "London Math Society Lecture Note Series 350 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Is there a way to predict whether any given person in the hospital has the disease or not? This report covers the PAC learning model applied to learning a collection of subsets C, called a concept class, of a domain X and more generally, a collection of functions F , called a function class, from X to the unit interval [0, 1].", "startOffset": 321, "endOffset": 327}, {"referenceID": 0, "context": ",Fk and a \u201ccontinuous logic connective\u201d (that is, a continuous function u : [0, 1] \u2192 [0, 1]), we consider the construction of a new composition function class u(F1, .", "startOffset": 76, "endOffset": 82}, {"referenceID": 0, "context": ",Fk and a \u201ccontinuous logic connective\u201d (that is, a continuous function u : [0, 1] \u2192 [0, 1]), we consider the construction of a new composition function class u(F1, .", "startOffset": 85, "endOffset": 91}, {"referenceID": 17, "context": "There is a previously known analogous estimate for a composition of concept classes built using a usual connective of classical logic [18].", "startOffset": 134, "endOffset": 138}, {"referenceID": 5, "context": "This section lists some definitions and results in measure theory and analysis, found in standard textbooks, such as [6], [18], and [2], which are used in this report.", "startOffset": 117, "endOffset": 120}, {"referenceID": 17, "context": "This section lists some definitions and results in measure theory and analysis, found in standard textbooks, such as [6], [18], and [2], which are used in this report.", "startOffset": 122, "endOffset": 126}, {"referenceID": 1, "context": "This section lists some definitions and results in measure theory and analysis, found in standard textbooks, such as [6], [18], and [2], which are used in this report.", "startOffset": 132, "endOffset": 135}, {"referenceID": 0, "context": "More generally, given two measurable functions f, g : X \u2192 [0, 1], one can look at the expected value of their absolute difference by integrating with respect to \u03bc:", "startOffset": 58, "endOffset": 64}, {"referenceID": 0, "context": "Validating hypotheses in the PAC learning model uses the idea of measuring the symmetric difference of two subsets of a probability space (X,S, \u03bc) and calculating the expected value of the difference of f, g : X \u2192 [0, 1].", "startOffset": 214, "endOffset": 220}, {"referenceID": 0, "context": "The unit interval [0, 1] is a subset of R, so it is a metric sub-space of (R, d), and this space will be used quite often in this report.", "startOffset": 18, "endOffset": 24}, {"referenceID": 0, "context": "Write [0, 1] for the set of all measurable functions from a probability space (X,S, \u03bc) to [0, 1].", "startOffset": 6, "endOffset": 12}, {"referenceID": 0, "context": "Write [0, 1] for the set of all measurable functions from a probability space (X,S, \u03bc) to [0, 1].", "startOffset": 90, "endOffset": 96}, {"referenceID": 0, "context": "Then, it is a metric sub-space of V with distance induced by the L2(\u03bc) norm on V , restricted of course to [0, 1] X .", "startOffset": 107, "endOffset": 113}, {"referenceID": 0, "context": "10, the set [0, 1], which denotes the set-theoretic product [0, 1]\u00d7 .", "startOffset": 12, "endOffset": 18}, {"referenceID": 0, "context": "10, the set [0, 1], which denotes the set-theoretic product [0, 1]\u00d7 .", "startOffset": 60, "endOffset": 66}, {"referenceID": 0, "context": "\u00d7 [0, 1] is then a metric space with distance d defined by d((r1, .", "startOffset": 2, "endOffset": 8}, {"referenceID": 0, "context": ",Fk are sets of measurable functions from a probability space (X,S, \u03bc) to the unit interval, then Fi \u2286 [0, 1] for each i = 1, .", "startOffset": 103, "endOffset": 109}, {"referenceID": 0, "context": "A function class F is a collection of measurable functions from X to the unit interval [0, 1].", "startOffset": 87, "endOffset": 93}, {"referenceID": 0, "context": "[0, 1] : the set of all measurable functions f : X \u2192 [0, 1], instead of the customary notation of all functions from X to [0, 1].", "startOffset": 0, "endOffset": 6}, {"referenceID": 0, "context": "[0, 1] : the set of all measurable functions f : X \u2192 [0, 1], instead of the customary notation of all functions from X to [0, 1].", "startOffset": 53, "endOffset": 59}, {"referenceID": 0, "context": "[0, 1] : the set of all measurable functions f : X \u2192 [0, 1], instead of the customary notation of all functions from X to [0, 1].", "startOffset": 122, "endOffset": 128}, {"referenceID": 15, "context": "1 ([16]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "Even more generally, \u03c7A is a function from X to [0, 1]; in other words, every concept class C can be identified as a function class FC = {\u03c7A : X \u2192 [0, 1] : A \u2208 C}, so it is natural to generalize Definition 3.", "startOffset": 48, "endOffset": 54}, {"referenceID": 0, "context": "Even more generally, \u03c7A is a function from X to [0, 1]; in other words, every concept class C can be identified as a function class FC = {\u03c7A : X \u2192 [0, 1] : A \u2208 C}, so it is natural to generalize Definition 3.", "startOffset": 147, "endOffset": 153}, {"referenceID": 0, "context": "1 involves the symmetric difference of two concepts and its generalization to measurable functions f, g : X \u2192 [0, 1] is the expected value of their absolute difference E\u03bc(f, g), as seen in the previous section:", "startOffset": 110, "endOffset": 116}, {"referenceID": 0, "context": "A simple exercise can show that if f, g \u2208 [0, 1] take values in {0, 1}, so they are indicator functions of two concepts A,B \u2286 X , then E\u03bc(f, g) coincide with the measure of their symmetric difference: E\u03bc(f, g) = \u03bc(A\u25b3 B), where f = \u03c7A and g = \u03c7B.", "startOffset": 42, "endOffset": 48}, {"referenceID": 0, "context": "Then, the set of all labeled samples of m points can be identified with (X \u00d7 [0, 1]), and producing a hypothesis is the process of associating a labeled sample to a function H \u2208 F (just as in concept class learning).", "startOffset": 77, "endOffset": 83}, {"referenceID": 17, "context": "2 ([18]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "A function class F is distribution-free Probably Approximately Correct learnable if there exists an algorithm L : \u222am\u2208N(X \u00d7 [0, 1]) \u2192 F with the following property: for every \u01eb > 0, for every \u03b4 > 0, there exists a M \u2208 N such that for every f \u2208 F , for every probability measure \u03bc, for every m \u2265 M , for any x1, .", "startOffset": 123, "endOffset": 129}, {"referenceID": 5, "context": "The symbol \u03bc denotes the product measure on X; the reader can refer to [6] for the details.", "startOffset": 71, "endOffset": 74}, {"referenceID": 7, "context": "Hence, the name \u201cProbably (\u03b4) Approximately (\u01eb) Correct\u201d is used [8].", "startOffset": 65, "endOffset": 68}, {"referenceID": 17, "context": "Both the statement and its proof can be found in Chapter 3 of [18] and Chapter 1 of [8].", "startOffset": 62, "endOffset": 66}, {"referenceID": 7, "context": "Both the statement and its proof can be found in Chapter 3 of [18] and Chapter 1 of [8].", "startOffset": 84, "endOffset": 87}, {"referenceID": 16, "context": "1 ([17]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "3 ([17]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "The first example is trivial and the second is fairly well-known, seen in [8] and [10], but we believe the third, Example 4.", "startOffset": 74, "endOffset": 77}, {"referenceID": 9, "context": "The first example is trivial and the second is fairly well-known, seen in [8] and [10], but we believe the third, Example 4.", "startOffset": 82, "endOffset": 86}, {"referenceID": 17, "context": "Following Chapter 4 of [18], C shatters S if and only if |{A \u2229 S : A \u2208 C}| = 2.", "startOffset": 23, "endOffset": 27}, {"referenceID": 11, "context": "8 (Sauer\u2019s Lemma [12]).", "startOffset": 17, "endOffset": 21}, {"referenceID": 16, "context": "2 Characterization of concept class distribution-free PAC learning The following is one of the main theorems concerning PAC learning, whose proof results from Vapnik and Chervonenkis\u2019 paper [17] in 1971 and the 1989 paper [5] by Blumer et al.", "startOffset": 190, "endOffset": 194}, {"referenceID": 4, "context": "2 Characterization of concept class distribution-free PAC learning The following is one of the main theorems concerning PAC learning, whose proof results from Vapnik and Chervonenkis\u2019 paper [17] in 1971 and the 1989 paper [5] by Blumer et al.", "startOffset": 222, "endOffset": 225}, {"referenceID": 16, "context": "9 ([17] and [5]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 4, "context": "9 ([17] and [5]).", "startOffset": 12, "endOffset": 15}, {"referenceID": 0, "context": "Every concept class C can be viewed as a function class FC = {\u03c7A : X \u2192 [0, 1] : A \u2208 C}, as seen in Section 3, so a natural question is whether the notion of shattering can be generalized.", "startOffset": 71, "endOffset": 77}, {"referenceID": 0, "context": "This dimension, assigned to function classes, involves the notion of \u01eb-shattering, but similar to the notion of (regular) shattering, it can be defined for any collection of functions f : X \u2192 [0, 1], where X is any set, but for sake of this report, the following sections (still) assume X = (X,S) is a measurable space and the collection of functions is a function class F .", "startOffset": 192, "endOffset": 198}, {"referenceID": 6, "context": "1 ([7]).", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": ", cn) \u2208 [0, 1], if for every e \u2208 {0, 1}n, there exists f \u2208 F such that f(xi) \u2265 ci + \u01eb for ei = 1, and f(xi) \u2264 ci \u2212 \u01eb for ei = 0.", "startOffset": 8, "endOffset": 14}, {"referenceID": 6, "context": "2 ([7]).", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "5) \u2208 [0, 1].", "startOffset": 5, "endOffset": 11}, {"referenceID": 0, "context": ", cn) \u2208 [0, 1].", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "Let X = R and let F be the set of all continuous functions f : X \u2192 [0, 1].", "startOffset": 67, "endOffset": 73}, {"referenceID": 0, "context": "5, and consider a collection of continuous [0, 1]-valued functions defined as follows.", "startOffset": 43, "endOffset": 49}, {"referenceID": 0, "context": "Given e \u2208 {0, 1}N, a countable binary sequence, define fe : X \u2192 [0, 1] by fe(x) = {", "startOffset": 64, "endOffset": 70}, {"referenceID": 0, "context": "5) \u2208 [0, 1]: for each e \u2208 {0, 1}n, it can be extended to a countable binary sequence \u1ebd, where \u1ebdi = ei for all i = 1, .", "startOffset": 5, "endOffset": 11}, {"referenceID": 0, "context": "5 ([1] and [18]).", "startOffset": 3, "endOffset": 6}, {"referenceID": 17, "context": "5 ([1] and [18]).", "startOffset": 11, "endOffset": 15}, {"referenceID": 0, "context": "Set up a bijection b : C \u2192 [0, 1/3] or to [0, 1/3]\u2229 Q, depending on the cardinality of C, and for every A \u2208 C, define a function fA : X \u2192 [0, 1] by fA(x) = \u03c7A(x) + (\u22121)Ab(A).", "startOffset": 138, "endOffset": 144}, {"referenceID": 17, "context": "5, which are much simpler than the one found in [18].", "startOffset": 48, "endOffset": 52}, {"referenceID": 10, "context": "10 in [11].", "startOffset": 6, "endOffset": 10}, {"referenceID": 0, "context": "5) \u2208 [0, 1].", "startOffset": 5, "endOffset": 11}, {"referenceID": 17, "context": "The following subsection provides this construction, which can be found in Chapter 4 of [18], in the context of concept classes using a connective of classical logic.", "startOffset": 88, "endOffset": 92}, {"referenceID": 17, "context": "1 ([18]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 17, "context": "The proof of this theorem can be found in [18] and uses Sauer\u2019s Lemma to bound the VC dimension of u(C1, .", "startOffset": 42, "endOffset": 46}, {"referenceID": 0, "context": "The main objective of our project was to generalize this theorem for function classes, in terms of the Fat Shattering dimension of scale \u01eb, but the connective of classical logic u would have to be replaced by a continuous logic connective, a continuous function u : [0, 1] \u2192 [0, 1].", "startOffset": 266, "endOffset": 272}, {"referenceID": 0, "context": "The main objective of our project was to generalize this theorem for function classes, in terms of the Fat Shattering dimension of scale \u01eb, but the connective of classical logic u would have to be replaced by a continuous logic connective, a continuous function u : [0, 1] \u2192 [0, 1].", "startOffset": 275, "endOffset": 281}, {"referenceID": 0, "context": "However, in continuous logic, truth-values can be found anywhere in the unit interval [0, 1].", "startOffset": 86, "endOffset": 92}, {"referenceID": 0, "context": "Therefore, we should consider a function u : [0, 1] \u2192 [0, 1], which will transform function classes, and require that u be a continuous logic connective.", "startOffset": 45, "endOffset": 51}, {"referenceID": 0, "context": "Therefore, we should consider a function u : [0, 1] \u2192 [0, 1], which will transform function classes, and require that u be a continuous logic connective.", "startOffset": 54, "endOffset": 60}, {"referenceID": 0, "context": "In other words, u should be continuous from the (product) metric space [0, 1] to the unit interval [19]; in fact, because u is continuous from a compact metric space to a metric space, it is automatically uniformly continuous.", "startOffset": 71, "endOffset": 77}, {"referenceID": 18, "context": "In other words, u should be continuous from the (product) metric space [0, 1] to the unit interval [19]; in fact, because u is continuous from a compact metric space to a metric space, it is automatically uniformly continuous.", "startOffset": 99, "endOffset": 103}, {"referenceID": 18, "context": "[19]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "In particular, u : [0, 1] \u2192 [0, 1], where [0, 1] is equipped with the L2 product distance d, is uniformly continuous with modulus of uniform continuity \u03b4 if for every More specifically, \u03b1 = \u03b1k is the smallest integer such that", "startOffset": 19, "endOffset": 25}, {"referenceID": 0, "context": "In particular, u : [0, 1] \u2192 [0, 1], where [0, 1] is equipped with the L2 product distance d, is uniformly continuous with modulus of uniform continuity \u03b4 if for every More specifically, \u03b1 = \u03b1k is the smallest integer such that", "startOffset": 28, "endOffset": 34}, {"referenceID": 0, "context": "In particular, u : [0, 1] \u2192 [0, 1], where [0, 1] is equipped with the L2 product distance d, is uniformly continuous with modulus of uniform continuity \u03b4 if for every More specifically, \u03b1 = \u03b1k is the smallest integer such that", "startOffset": 42, "endOffset": 48}, {"referenceID": 0, "context": ", r\u2032 k) \u2208 [0, 1], d((r1, .", "startOffset": 10, "endOffset": 16}, {"referenceID": 0, "context": ",Fk and a uniformly continuous function u : [0, 1] \u2192 [0, 1], consider the new function class u(F1, .", "startOffset": 44, "endOffset": 50}, {"referenceID": 0, "context": ",Fk and a uniformly continuous function u : [0, 1] \u2192 [0, 1], consider the new function class u(F1, .", "startOffset": 53, "endOffset": 59}, {"referenceID": 17, "context": "It is a known result, seen in Chapter 5 of [18], that this new class u(F1, .", "startOffset": 43, "endOffset": 47}, {"referenceID": 0, "context": ",Fk be function classes of X, and u : [0, 1] \u2192 [0, 1] be a uniformly continuous function with modulus of continuity \u03b4(\u01eb).", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": ",Fk be function classes of X, and u : [0, 1] \u2192 [0, 1] be a uniformly continuous function with modulus of continuity \u03b4(\u01eb).", "startOffset": 47, "endOffset": 53}, {"referenceID": 0, "context": "\u00d7 Fk \u2192 [0, 1] , which is uniformly continuous from the metric space F1\u00d7 .", "startOffset": 7, "endOffset": 13}, {"referenceID": 0, "context": "\u00d7Fk with the L2 product distance d\u0303 to the metric space [0, 1] with distance induced by the L2(\u03bc) norm, and prove the following lemma.", "startOffset": 56, "endOffset": 62}, {"referenceID": 0, "context": "\u00d7Fk \u2192 [0, 1] be uniformly continuous with some modulus of continuity \u03b4(\u01eb, k), a function", "startOffset": 6, "endOffset": 12}, {"referenceID": 0, "context": "If u : [0, 1] \u2192 [0, 1] is uniformly continuous with modulus of continuity \u03b4(\u01eb), then the function \u03c6 : F1 \u00d7 .", "startOffset": 7, "endOffset": 13}, {"referenceID": 0, "context": "If u : [0, 1] \u2192 [0, 1] is uniformly continuous with modulus of continuity \u03b4(\u01eb), then the function \u03c6 : F1 \u00d7 .", "startOffset": 16, "endOffset": 22}, {"referenceID": 0, "context": "\u00d7 Fk \u2192 [0, 1] defined by \u03c6(f1, .", "startOffset": 7, "endOffset": 13}, {"referenceID": 8, "context": "5, we first introduce the concept of an \u01eb-covering number for any metric space, based on [9], and relate this number for a function class to its Fat Shattering dimension of scale \u01eb by using results from Mendelson and Vershynin [9] and Talagrand [15].", "startOffset": 89, "endOffset": 92}, {"referenceID": 8, "context": "5, we first introduce the concept of an \u01eb-covering number for any metric space, based on [9], and relate this number for a function class to its Fat Shattering dimension of scale \u01eb by using results from Mendelson and Vershynin [9] and Talagrand [15].", "startOffset": 227, "endOffset": 230}, {"referenceID": 14, "context": "5, we first introduce the concept of an \u01eb-covering number for any metric space, based on [9], and relate this number for a function class to its Fat Shattering dimension of scale \u01eb by using results from Mendelson and Vershynin [9] and Talagrand [15].", "startOffset": 245, "endOffset": 249}, {"referenceID": 0, "context": "\u00d7 Fk \u2192 [0, 1] is uniformly continuous with modulus of continuity \u03b4(\u01eb, k).", "startOffset": 7, "endOffset": 13}, {"referenceID": 8, "context": "10 ([9]).", "startOffset": 4, "endOffset": 7}, {"referenceID": 14, "context": "11 ([15]).", "startOffset": 4, "endOffset": 8}, {"referenceID": 0, "context": "Suppose u : [0, 1] \u2192 [0, 1] is uniformly continuous with a modulus of continuity \u03b4(\u01eb), where [0, 1] is a metric space with the L2 product distance d.", "startOffset": 12, "endOffset": 18}, {"referenceID": 0, "context": "Suppose u : [0, 1] \u2192 [0, 1] is uniformly continuous with a modulus of continuity \u03b4(\u01eb), where [0, 1] is a metric space with the L2 product distance d.", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": "Suppose u : [0, 1] \u2192 [0, 1] is uniformly continuous with a modulus of continuity \u03b4(\u01eb), where [0, 1] is a metric space with the L2 product distance d.", "startOffset": 93, "endOffset": 99}, {"referenceID": 0, "context": "\u00d7Fk \u2192 [0, 1] defined by \u03c6(f1, .", "startOffset": 6, "endOffset": 12}, {"referenceID": 0, "context": "6, if u : [0, 1] \u2192 [0, 1] is uniformly continuous with modulus of continuity \u03b4(\u01eb), then \u03c6 : F1 \u00d7 .", "startOffset": 10, "endOffset": 16}, {"referenceID": 0, "context": "6, if u : [0, 1] \u2192 [0, 1] is uniformly continuous with modulus of continuity \u03b4(\u01eb), then \u03c6 : F1 \u00d7 .", "startOffset": 19, "endOffset": 25}, {"referenceID": 0, "context": "\u00d7 Fk \u2192 [0, 1] defined by \u03c6(f1, .", "startOffset": 7, "endOffset": 13}, {"referenceID": 0, "context": "\u00d7fk // [0, 1] u // [0, 1] ,", "startOffset": 7, "endOffset": 13}, {"referenceID": 0, "context": "\u00d7fk // [0, 1] u // [0, 1] ,", "startOffset": 19, "endOffset": 25}, {"referenceID": 0, "context": "\u00d7 Fk \u03c6 // [0, 1] .", "startOffset": 10, "endOffset": 16}, {"referenceID": 0, "context": "For instance, the function u : [0, 1] \u2192 [0, 1] defined by u(r1, r2) = r1 \u00b7 r2 (multiplication) is uniformly continuous with a modulus of continuity \u03b4(\u01eb) = \u01eb 2 .", "startOffset": 31, "endOffset": 37}, {"referenceID": 0, "context": "For instance, the function u : [0, 1] \u2192 [0, 1] defined by u(r1, r2) = r1 \u00b7 r2 (multiplication) is uniformly continuous with a modulus of continuity \u03b4(\u01eb) = \u01eb 2 .", "startOffset": 40, "endOffset": 46}, {"referenceID": 0, "context": "Indeed, let \u01eb > 0 and consider (r1, r2), (r \u2032 1, r \u2032 2) \u2208 [0, 1].", "startOffset": 58, "endOffset": 64}, {"referenceID": 17, "context": "1 ([18]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "A function class F is Probably Approximately Correct learnable under \u03bc if there exists an algorithm L : \u222am\u2208N(X \u00d7 [0, 1]) \u2192 F with the following property: for every \u01eb > 0, for every \u03b4 > 0, there exists a M \u2208 N such that for every f \u2208 F , for every m \u2265 M , for any x1, .", "startOffset": 113, "endOffset": 119}, {"referenceID": 3, "context": "2 ([4]).", "startOffset": 3, "endOffset": 6}, {"referenceID": 12, "context": "Talagrand had proved that a function class is a GlivenkoCantelli (GC) function class with regard to a single measure \u03bc if and only if the class has no witness of irregularity, a property that involves shattering [13],[14].", "startOffset": 212, "endOffset": 216}, {"referenceID": 13, "context": "Talagrand had proved that a function class is a GlivenkoCantelli (GC) function class with regard to a single measure \u03bc if and only if the class has no witness of irregularity, a property that involves shattering [13],[14].", "startOffset": 217, "endOffset": 221}, {"referenceID": 10, "context": "Every GC function class is PAC learnable under \u03bc [11], but the property of having no witness of irregularity is strictly stronger than PAC learnability.", "startOffset": 49, "endOffset": 53}, {"referenceID": 2, "context": "The paper [3] written by Bartlett et al.", "startOffset": 10, "endOffset": 13}, {"referenceID": 0, "context": ",Fk) using a continuous function u : [0, 1] \u2192 [0, 1], a continuous logic connective.", "startOffset": 37, "endOffset": 43}, {"referenceID": 0, "context": ",Fk) using a continuous function u : [0, 1] \u2192 [0, 1], a continuous logic connective.", "startOffset": 46, "endOffset": 52}], "year": 2011, "abstractText": "We begin this report by describing the Probably Approximately Correct (PAC) model for learning a concept class, consisting of subsets of a domain, and a function class, consisting of functions from the domain to the unit interval. Two combinatorial parameters, the Vapnik-Chervonenkis (VC) dimension and its generalization, the Fat Shattering dimension of scale \u01eb, are explained and a few examples of their calculations are given with proofs. We then explain Sauer\u2019s Lemma, which involves the VC dimension and is used to prove the equivalence of a concept class being distributionfree PAC learnable and it having finite VC dimension. As the main new result of our research, we explore the construction of a new function class, obtained by forming compositions with a continuous logic connective, a uniformly continuous function from the unit hypercube to the unit interval, from a collection of function classes. Vidyasagar had proved that such a composition function class has finite Fat Shattering dimension of all scales if the classes in the original collection do; however, no estimates of the dimension were known. Using results by Mendelson-Vershynin and Talagrand, we bound the Fat Shattering dimension of scale \u01eb of this new function class in terms of the Fat Shattering dimensions of the collection\u2019s classes. We conclude this report by providing a few open questions and future research topics involving the PAC learning model.", "creator": "LaTeX with hyperref package"}}}