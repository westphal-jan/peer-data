{"id": "1105.5444", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-May-2011", "title": "Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language", "abstract": "This article presents a measure of semantic similarity in an IS-A taxonomy based on the notion of shared information content. Experimental evaluation against a benchmark set of human similarity judgments demonstrates that the measure performs better than the traditional edge-counting approach. The article presents algorithms that take advantage of taxonomic similarity in resolving syntactic and semantic ambiguity, along with experimental results demonstrating their effectiveness.", "histories": [["v1", "Fri, 27 May 2011 01:46:05 GMT  (108kb)", "http://arxiv.org/abs/1105.5444v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["p resnik"], "accepted": false, "id": "1105.5444"}, "pdf": {"name": "1105.5444.pdf", "metadata": {"source": "CRF", "title": "Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language", "authors": ["Philip Resnik"], "emails": ["resnik@umiacs.umd.edu"], "sections": [{"heading": null, "text": "In fact, it is as if most people who live and work in the United States have come up with the idea of denying themselves, and that they are able to deny themselves. (...) It is not as if they are able to deny themselves. (...) It is as if they are able to deny themselves. (...) It is not as if they are able to deny themselves. (...) It is as if they are able to deny themselves. (...) It is as if they are able to deny themselves. (...) It is as if they are able to deny themselves. (...) It is as if they are in denial of themselves. (...) It is as if they are in denial of themselves. (...) It is as if they are in denial of themselves. (...) It is as if they are in denial of themselves."}, {"heading": "Information-Based Semantic Similarity", "text": "In fact, it will be able to come out on top in the way that they have come out on top."}, {"heading": "Resnik", "text": "In fact, most of them are able to reform themselves, both in terms of the way they move, in terms of the way they move, in terms of the way they move, in terms of the way they move, in terms of the way they move, in terms of the way they move."}], "references": [{"title": "A simple but useful approach to conjunct", "author": ["R. Agarwal", "L. Boggess"], "venue": null, "citeRegEx": "Agarwal and Boggess,? \\Q1992\\E", "shortCiteRegEx": "Agarwal and Boggess", "year": 1992}, {"title": "An occurrence-based model of word categorization", "author": ["P.A. Bensch", "W.J. Savitch"], "venue": null, "citeRegEx": "Bensch and Savitch,? \\Q1992\\E", "shortCiteRegEx": "Bensch and Savitch", "year": 1992}, {"title": "Discovering the lexical features of a language", "author": ["E. Brill"], "venue": "Proceedings of the 29th", "citeRegEx": "Brill,? 1991", "shortCiteRegEx": "Brill", "year": 1991}, {"title": "A rule-based approach to prepositional phrase attachment", "author": ["E. Brill", "P. Resnik"], "venue": null, "citeRegEx": "Brill and Resnik,? \\Q1994\\E", "shortCiteRegEx": "Brill and Resnik", "year": 1994}, {"title": "Introduction to the special issue", "author": ["K.W. Church", "R. Mercer"], "venue": null, "citeRegEx": "Church and Mercer,? \\Q1993\\E", "shortCiteRegEx": "Church and Mercer", "year": 1993}, {"title": "Coping with syntactic ambiguity or how to put", "author": ["K.W. Church", "R. Patil"], "venue": null, "citeRegEx": "Church and Patil,? \\Q1982\\E", "shortCiteRegEx": "Church and Patil", "year": 1982}, {"title": "A spreading activation theory of semantic processing", "author": ["A. Collins", "E. Loftus"], "venue": null, "citeRegEx": "Collins and Loftus,? \\Q1975\\E", "shortCiteRegEx": "Collins and Loftus", "year": 1975}, {"title": "Prepositional phrase attachment through a backed-o", "author": ["M. Collins", "J. Brooks"], "venue": null, "citeRegEx": "Collins and Brooks,? \\Q1995\\E", "shortCiteRegEx": "Collins and Brooks", "year": 1995}, {"title": "Lexical disambiguation using simulated anneal", "author": ["J. Cowie", "J. Guthrie", "L. Guthrie"], "venue": null, "citeRegEx": "Cowie et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Cowie et al\\.", "year": 1992}, {"title": "Large-Scale Dictionary Construction for Foreign Language Tutoring", "author": ["B.J. Dorr"], "venue": null, "citeRegEx": "Dorr,? \\Q1997\\E", "shortCiteRegEx": "Dorr", "year": 1997}, {"title": "WordNet: An Electronic Lexical Database", "author": ["C. Fellbaum"], "venue": null, "citeRegEx": "Fellbaum,? \\Q1998\\E", "shortCiteRegEx": "Fellbaum", "year": 1998}, {"title": "Frequency Analysis of English Usage: Lexicon", "author": ["W.N. Francis", "H. Ku cera"], "venue": null, "citeRegEx": "Francis and cera,? \\Q1982\\E", "shortCiteRegEx": "Francis and cera", "year": 1982}, {"title": "Similarity", "author": ["R.L. Goldstone"], "venue": "MIT Encyclopedia of the Cognitive Sciences. MIT", "citeRegEx": "Goldstone,? 1999", "shortCiteRegEx": "Goldstone", "year": 1999}, {"title": "Use of syntactic context to produce term association lists for text", "author": ["G. Grefenstette"], "venue": null, "citeRegEx": "Grefenstette,? \\Q1992\\E", "shortCiteRegEx": "Grefenstette", "year": 1992}, {"title": "Explorations in Automatic Thesaurus Discovery", "author": ["G. Grefenstette"], "venue": "Kluwer, Boston.", "citeRegEx": "Grefenstette,? 1994", "shortCiteRegEx": "Grefenstette", "year": 1994}, {"title": "Relevance feedback revisited", "author": ["D. Harman"], "venue": "Proceedings of the Fifteenth Annual", "citeRegEx": "Harman,? 1992", "shortCiteRegEx": "Harman", "year": 1992}, {"title": "Noun homograph disambiguation using local context in large corpora", "author": ["M. Hearst"], "venue": null, "citeRegEx": "Hearst,? \\Q1991\\E", "shortCiteRegEx": "Hearst", "year": 1991}, {"title": "Structural ambiguity and lexical relations", "author": ["D. Hindle", "M. Rooth"], "venue": null, "citeRegEx": "Hindle and Rooth,? \\Q1993\\E", "shortCiteRegEx": "Hindle and Rooth", "year": 1993}, {"title": "Combining a Chinese thesaurus with a Chinese", "author": ["D. Ji", "J. Gong", "C. Huang"], "venue": null, "citeRegEx": "Ji et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Ji et al\\.", "year": 1998}, {"title": "Estimation of probabilities from sparse data for the language model", "author": ["S.M. Katz"], "venue": null, "citeRegEx": "Katz,? \\Q1987\\E", "shortCiteRegEx": "Katz", "year": 1987}, {"title": "Mathematical Foundations of Information Theory", "author": ["A.I. Khinchin"], "venue": "New York: Dover", "citeRegEx": "Khinchin,? 1957", "shortCiteRegEx": "Khinchin", "year": 1957}, {"title": "Dictionaries and Corpora: Combining Corpus", "author": ["J.L. Klavans", "E. Tzoukermann"], "venue": null, "citeRegEx": "Klavans and Tzoukermann,? \\Q1995\\E", "shortCiteRegEx": "Klavans and Tzoukermann", "year": 1995}, {"title": "Analysis of Japanese compound nouns", "author": ["Y. Kobayasi", "T. Takunaga", "H. Tanaka"], "venue": null, "citeRegEx": "Kobayasi et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Kobayasi et al\\.", "year": 1994}, {"title": "Lexical ambiguity and information retrieval", "author": ["R. Krovetz", "W.B. Croft"], "venue": null, "citeRegEx": "Krovetz and Croft,? \\Q1992\\E", "shortCiteRegEx": "Krovetz and Croft", "year": 1992}, {"title": "Dynamic programming method for analyzing conjunc", "author": ["S. Kurohashi", "M. Nagao"], "venue": null, "citeRegEx": "Kurohashi and Nagao,? \\Q1992\\E", "shortCiteRegEx": "Kurohashi and Nagao", "year": 1992}, {"title": "Conceptual association for compound noun analysis", "author": ["M. Lauer"], "venue": "Proceedings of the", "citeRegEx": "Lauer,? 1994", "shortCiteRegEx": "Lauer", "year": 1994}, {"title": "Designing Statistical Language Learners: Experiments on", "author": ["M. Lauer"], "venue": null, "citeRegEx": "Lauer,? \\Q1995\\E", "shortCiteRegEx": "Lauer", "year": 1995}, {"title": "Filling in a sparse training space for word sense", "author": ["C. Leacock", "M. Chodorow"], "venue": null, "citeRegEx": "Leacock and Chodorow,? \\Q1994\\E", "shortCiteRegEx": "Leacock and Chodorow", "year": 1994}, {"title": "Similarity-based approaches to natural language processing", "author": ["L. Lee"], "venue": "Tech. rep.", "citeRegEx": "Lee,? 1997", "shortCiteRegEx": "Lee", "year": 1997}, {"title": "Automatic sense disambiguation using machine readable dictionaries", "author": ["M. Lesk"], "venue": null, "citeRegEx": "Lesk,? \\Q1986\\E", "shortCiteRegEx": "Lesk", "year": 1986}, {"title": "Generalizing case frames using a thesaurus and the MDL principle", "author": ["H. Li", "N. Abe"], "venue": null, "citeRegEx": "Li and Abe,? \\Q1995\\E", "shortCiteRegEx": "Li and Abe", "year": 1995}, {"title": "Using syntactic dependency as local context to resolve word sense ambigu", "author": ["D. Lin"], "venue": null, "citeRegEx": "Lin,? \\Q1997\\E", "shortCiteRegEx": "Lin", "year": 1997}, {"title": "An information-theoretic de nition of similarity", "author": ["D. Lin"], "venue": "Proceedings of the", "citeRegEx": "Lin,? 1998", "shortCiteRegEx": "Lin", "year": 1998}, {"title": "Building a large annotated", "author": ["M.P. Marcus", "B. Santorini", "M. Marcinkiewicz"], "venue": null, "citeRegEx": "Marcus et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Augmenting lexicons automatically", "author": ["K. McKeown", "V. Hatzivassiloglou"], "venue": null, "citeRegEx": "McKeown and Hatzivassiloglou,? \\Q1993\\E", "shortCiteRegEx": "McKeown and Hatzivassiloglou", "year": 1993}, {"title": "Respects for similarity", "author": ["D. Medin", "R. Goldstone", "D. Gentner"], "venue": null, "citeRegEx": "Medin et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Medin et al\\.", "year": 1993}, {"title": "WordNet: An on-line lexical database", "author": ["G. Miller"], "venue": "International Journal of Lexicog-", "citeRegEx": "Miller,? 1990", "shortCiteRegEx": "Miller", "year": 1990}, {"title": "Contextual correlates of semantic similarity", "author": ["G.A. Miller", "W.G. Charles"], "venue": null, "citeRegEx": "Miller and Charles,? \\Q1991\\E", "shortCiteRegEx": "Miller and Charles", "year": 1991}, {"title": "Distributional clustering of English words", "author": ["F. Pereira", "N. Tishby", "L. Lee"], "venue": null, "citeRegEx": "Pereira et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Pereira et al\\.", "year": 1993}, {"title": "Semantic memory", "author": ["M.R. Quillian"], "venue": "Minsky, M. (Ed.), Semantic Information", "citeRegEx": "Quillian,? 1968", "shortCiteRegEx": "Quillian", "year": 1968}, {"title": "Ranking documents with a thesaurus. JASIS", "author": ["R. Rada", "E. Bicknell"], "venue": null, "citeRegEx": "Rada and Bicknell,? \\Q1989\\E", "shortCiteRegEx": "Rada and Bicknell", "year": 1989}, {"title": "Development and application", "author": ["R. Rada", "H. Mili", "E. Bicknell", "M. Blettner"], "venue": null, "citeRegEx": "Rada et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Rada et al\\.", "year": 1989}, {"title": "A maximum entropy model for prepositional phrase", "author": ["A. Ratnaparkhi", "S. Roukos"], "venue": null, "citeRegEx": "Ratnaparkhi and Roukos,? \\Q1994\\E", "shortCiteRegEx": "Ratnaparkhi and Roukos", "year": 1994}, {"title": "Selection and Information: A Class-Based Approach to", "author": ["P. Resnik"], "venue": null, "citeRegEx": "Resnik,? \\Q1993\\E", "shortCiteRegEx": "Resnik", "year": 1993}, {"title": "Semantic classes and syntactic ambiguity", "author": ["P. Resnik"], "venue": "Proceedings of the 1993", "citeRegEx": "Resnik,? 1993b", "shortCiteRegEx": "Resnik", "year": 1993}, {"title": "Using information content to evaluate semantic similarity in a taxonomy", "author": ["P. Resnik"], "venue": null, "citeRegEx": "Resnik,? \\Q1995\\E", "shortCiteRegEx": "Resnik", "year": 1995}, {"title": "Selectional constraints: An information-theoretic model and its compu", "author": ["P. Resnik"], "venue": null, "citeRegEx": "Resnik,? \\Q1996\\E", "shortCiteRegEx": "Resnik", "year": 1996}, {"title": "Disambiguating noun groupings with respect to Wordnet senses", "author": ["P. Resnik"], "venue": "In", "citeRegEx": "Resnik,? 1998a", "shortCiteRegEx": "Resnik", "year": 1998}, {"title": "WordNet and class-based probabilities", "author": ["P. Resnik"], "venue": "Fellbaum, C. (Ed.),WordNet:", "citeRegEx": "Resnik,? 1998b", "shortCiteRegEx": "Resnik", "year": 1998}, {"title": "A perspective on word sense disambiguation methods", "author": ["P. Resnik", "D. Yarowsky"], "venue": null, "citeRegEx": "Resnik and Yarowsky,? \\Q1997\\E", "shortCiteRegEx": "Resnik and Yarowsky", "year": 1997}, {"title": "Distinguishing systems and distinguishing senses", "author": ["P. Resnik", "D. Yarowsky"], "venue": null, "citeRegEx": "Resnik and Yarowsky,? \\Q1999\\E", "shortCiteRegEx": "Resnik and Yarowsky", "year": 1999}, {"title": "A First Course in Probability", "author": ["S. Ross"], "venue": "Macmillan.", "citeRegEx": "Ross,? 1976", "shortCiteRegEx": "Ross", "year": 1976}, {"title": "Contextual correlates of synonymy", "author": ["H. Rubenstein", "J. Goodenough"], "venue": null, "citeRegEx": "Rubenstein and Goodenough,? \\Q1965\\E", "shortCiteRegEx": "Rubenstein and Goodenough", "year": 1965}, {"title": "Automatic Text Processing", "author": ["G. Salton"], "venue": "Addison-Wesley.", "citeRegEx": "Salton,? 1989", "shortCiteRegEx": "Salton", "year": 1989}, {"title": "Word sense disambiguation for free-text indexing using a massive", "author": ["M. Sussna"], "venue": null, "citeRegEx": "Sussna,? \\Q1993\\E", "shortCiteRegEx": "Sussna", "year": 1993}, {"title": "Features of similarity", "author": ["A. Tversky"], "venue": "Psychological Review, 84, 327{352.", "citeRegEx": "Tversky,? 1977", "shortCiteRegEx": "Tversky", "year": 1977}, {"title": "Using WordNet to disambiguate word senses for text retrieval", "author": ["E.M. Voorhees"], "venue": "In", "citeRegEx": "Voorhees,? 1993", "shortCiteRegEx": "Voorhees", "year": 1993}, {"title": "Query expansion using lexical-semantic relations", "author": ["E.M. Voorhees"], "venue": "17th Inter-", "citeRegEx": "Voorhees,? 1994", "shortCiteRegEx": "Voorhees", "year": 1994}, {"title": "Special issue on EuroWordNet", "author": ["P. Vossen"], "venue": "Computers and the Humanities, 32 (2/3).", "citeRegEx": "Vossen,? 1998", "shortCiteRegEx": "Vossen", "year": 1998}, {"title": "Empirical study of predictive powers", "author": ["G. Whittemore", "K. Ferrara", "H. Brunner"], "venue": null, "citeRegEx": "Whittemore et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Whittemore et al\\.", "year": 1990}, {"title": "The grammar of sense: Is word-sense tagging", "author": ["Y. Wilks", "M. Stevenson"], "venue": null, "citeRegEx": "Wilks and Stevenson,? \\Q1996\\E", "shortCiteRegEx": "Wilks and Stevenson", "year": 1996}, {"title": "Verb Semantics and Lexical Selection", "author": ["Z. Wu", "M. Palmer"], "venue": null, "citeRegEx": "Wu and Palmer,? \\Q1994\\E", "shortCiteRegEx": "Wu and Palmer", "year": 1994}], "referenceMentions": [{"referenceID": 54, "context": "(Rada, Mili, Bicknell, & Blettner, 1989) suggest that the assessment of similarity in semantic networks can in fact be thought of as involving just taxonomic (is-a) links, to the exclusion of other link types; that view will also be taken here, although admittedly links such as part-of can also be viewed as attributes that contribute to similarity (cf. Richardson, Smeaton, & Murphy, 1994; Sussna, 1993).", "startOffset": 350, "endOffset": 405}, {"referenceID": 30, "context": "edu Department of Linguistics and Institute for Advanced Computer Studies University of Maryland College Park, MD 20742 USA Abstract This article presents a measure of semantic similarity in an is-a taxonomy based on the notion of shared information content. Experimental evaluation against a benchmark set of human similarity judgments demonstrates that the measure performs better than the traditional edge-counting approach. The article presents algorithms that take advantage of taxonomic similarity in resolving syntactic and semantic ambiguity, along with experimental results demonstrating their e ectiveness. 1. Introduction Evaluating semantic relatedness using network representations is a problem with a long history in arti cial intelligence and psychology, dating back to the spreading activation approach of Quillian (1968) and Collins and Loftus (1975).", "startOffset": 18, "endOffset": 838}, {"referenceID": 6, "context": "Introduction Evaluating semantic relatedness using network representations is a problem with a long history in arti cial intelligence and psychology, dating back to the spreading activation approach of Quillian (1968) and Collins and Loftus (1975). Semantic similarity represents a special case of semantic relatedness: for example, cars and gasoline would seem to be more closely related than, say, cars and bicycles, but the latter pair are certainly more similar.", "startOffset": 222, "endOffset": 248}, {"referenceID": 41, "context": "Given multiple paths, one takes the length of the shortest one (Lee, Kim, & Lee, 1993; Rada & Bicknell, 1989; Rada et al., 1989).", "startOffset": 63, "endOffset": 128}, {"referenceID": 36, "context": "For example, in WordNet (Miller, 1990; Fellbaum, 1998), a widely used, broad-coverage semantic network for English, it is not at all di cult to nd links that cover an intuitively narrow distance (rabbit ears is-a television antenna) or an intuitively wide one (phytoplankton is-a living thing).", "startOffset": 24, "endOffset": 54}, {"referenceID": 10, "context": "For example, in WordNet (Miller, 1990; Fellbaum, 1998), a widely used, broad-coverage semantic network for English, it is not at all di cult to nd links that cover an intuitively narrow distance (rabbit ears is-a television antenna) or an intuitively wide one (phytoplankton is-a living thing).", "startOffset": 24, "endOffset": 54}, {"referenceID": 51, "context": "Following the standard argumentation of information theory (Ross, 1976), the information content of a concept c can be quanti ed as negative the log likelihood, log p(c).", "startOffset": 59, "endOffset": 71}, {"referenceID": 41, "context": "Taking the maximum with respect to information content is analogous to taking the rst intersection in semantic network marker-passing or the shortest path with respect to edge distance (cf. Quillian, 1968; Rada et al., 1989); a generalization from taking the maximum to taking a weighted average is introduced in Section 3.", "startOffset": 185, "endOffset": 224}, {"referenceID": 41, "context": "This is consistent with Rada et al.'s (1989) treatment of \\disjunctive concepts\" using edge-counting: they de ne the distance between two disjunctive sets of concepts as the minimum path length from any element of the rst set to any element of the second.", "startOffset": 24, "endOffset": 45}, {"referenceID": 36, "context": "Concept as used here refers to what Miller et al. (1990) call a synset, essentially a node in the taxonomy.", "startOffset": 36, "endOffset": 57}, {"referenceID": 35, "context": "An experiment by Miller and Charles (1991) provided appropriate human subject data for the task.", "startOffset": 17, "endOffset": 43}, {"referenceID": 4, "context": "As Church and Patil (1982) point out, the class of \\every way ambiguous\" syntactic constructions | those for which the number of analyses is the number of binary trees over the terminal elements | includes such frequent constructions as prepositional phrases, coordination, and nominal compounds.", "startOffset": 3, "endOffset": 27}, {"referenceID": 2, "context": "Progress on broad-coverage prepositional phrase attachment ambiguity has been particularly notable, now that the dominant approach has shifted from structural strategies to quantitative analysis of lexical relationships (Whittemore, Ferrara, & Brunner, 1990; Hindle & Rooth, 1993; Brill & Resnik, 1994; Ratnaparkhi & Roukos, 1994; Li & Abe, 1995; Collins & Brooks, 1995; Merlo, Crocker, & Berthouzoz, 1997). Noun compounds have received comparatively less attention (Kobayasi, Takunaga, & Tanaka, 1994; Lauer, 1994, 1995), as has the problem of coordination ambiguity (Agarwal & Boggess, 1992; Kurohashi & Nagao, 1992). In this section, I investigate the role of semantic similarity in resolving coordination ambiguities involving nominal compounds. I began with noun phrase coordinations of the form n1 and n2 n3, which admit two structural analyses, one in which n1 and n2 are the two noun phrase heads being conjoined (1a) and one in which the conjoined heads are n1 and n3 (1b). (1) a. a (bank and warehouse) guard b. a (policeman) and (park guard) Identifying which two head nouns are conjoined is necessary in order to arrive at a correct interpretation of the phrase's content. For example, analyzing (1b) according to the structure of (1a) could lead a machine translation system to produce a noun phrase describing somebody who guards both policemen and parks. Analyzing (1a) according to the structure of (1b) could lead an information retrieval system to miss this phrase when looking for queries involving the term bank guard. Kurohashi and Nagao (1992) point out that similarity of form and similarity of meaning are important cues to conjoinability.", "startOffset": 281, "endOffset": 1566}, {"referenceID": 46, "context": "In order to measure the appropriateness of noun-noun modi cation, I use a quantitative measure of selectional t called selectional association (Resnik, 1996), which takes into account both lexical cooccurrence frequencies and semantic class membership in the WordNet taxonomy.", "startOffset": 143, "endOffset": 157}, {"referenceID": 19, "context": "What I am calling \\backing o \" is related in spirit to Katz's well known smoothing technique (Katz, 1987), but the \\backing o \" strategy used here is not quantitative.", "startOffset": 93, "endOffset": 105}, {"referenceID": 13, "context": "As examples, query expansion using related words is a well studied technique in information retrieval (e.g., Harman, 1992; Grefenstette, 1992), clusters of similar words can play a role in smoothing stochastic language models for speech recognition (Brown, Della Pietra, deSouza, Lai, & Mercer, 1992), classes of verbs that share semantic structure form the basis for an approach to interlingual machine translation (Dorr, 1997), and clusterings of related words can be used in characterizing subgroupings of retrieved documents in largescale Web searches (e.", "startOffset": 102, "endOffset": 142}, {"referenceID": 9, "context": ", Harman, 1992; Grefenstette, 1992), clusters of similar words can play a role in smoothing stochastic language models for speech recognition (Brown, Della Pietra, deSouza, Lai, & Mercer, 1992), classes of verbs that share semantic structure form the basis for an approach to interlingual machine translation (Dorr, 1997), and clusterings of related words can be used in characterizing subgroupings of retrieved documents in largescale Web searches (e.", "startOffset": 309, "endOffset": 321}, {"referenceID": 2, "context": "There is a wide body of research on the use of distributional methods for measuring word similarity in order to obtain groups of related words (e.g., Bensch & Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1992, 1994; McKeown & Hatzivassiloglou, 1993; Pereira, Tishby, & Lee, 1993; Sch\u007f utze, 1993), and thesauri such as WordNet are another source of word relationships (e.", "startOffset": 143, "endOffset": 313}, {"referenceID": 18, "context": "With that crucial caveat, it is nonetheless interesting to note that the results obtained here are broadly consistent with Kurohashi and Nagao (1992), who report accuracy results in the range of 80-83% at 100% coverage when analyzing a broad range of conjunctive structures in Japanese using a combination of string matching, syntactic similarity, and thesaurus-based similarity, and with Agarwal and Boggess (1992), who use syntactic types and structure, along with partly domain-dependent semantic labels, to obtain accuracies in a similar range for identifying conjuncts in English.", "startOffset": 123, "endOffset": 150}, {"referenceID": 0, "context": "With that crucial caveat, it is nonetheless interesting to note that the results obtained here are broadly consistent with Kurohashi and Nagao (1992), who report accuracy results in the range of 80-83% at 100% coverage when analyzing a broad range of conjunctive structures in Japanese using a combination of string matching, syntactic similarity, and thesaurus-based similarity, and with Agarwal and Boggess (1992), who use syntactic types and structure, along with partly domain-dependent semantic labels, to obtain accuracies in a similar range for identifying conjuncts in English.", "startOffset": 389, "endOffset": 416}, {"referenceID": 0, "context": "With that crucial caveat, it is nonetheless interesting to note that the results obtained here are broadly consistent with Kurohashi and Nagao (1992), who report accuracy results in the range of 80-83% at 100% coverage when analyzing a broad range of conjunctive structures in Japanese using a combination of string matching, syntactic similarity, and thesaurus-based similarity, and with Agarwal and Boggess (1992), who use syntactic types and structure, along with partly domain-dependent semantic labels, to obtain accuracies in a similar range for identifying conjuncts in English. 5. Using Taxonomic Similarity in Word Sense Selection This section considers the application of the semantic similarity measure in resolving another form of ambiguity: selecting the appropriate sense of a noun when it appears in the context of other nouns that are related in meaning. 5.1 Associating Word Senses with Noun Groupings Knowledge about groups of related words plays a role in many natural language applications. As examples, query expansion using related words is a well studied technique in information retrieval (e.g., Harman, 1992; Grefenstette, 1992), clusters of similar words can play a role in smoothing stochastic language models for speech recognition (Brown, Della Pietra, deSouza, Lai, & Mercer, 1992), classes of verbs that share semantic structure form the basis for an approach to interlingual machine translation (Dorr, 1997), and clusterings of related words can be used in characterizing subgroupings of retrieved documents in largescale Web searches (e.g., Digital Equipment Corporation, 1998). There is a wide body of research on the use of distributional methods for measuring word similarity in order to obtain groups of related words (e.g., Bensch & Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1992, 1994; McKeown & Hatzivassiloglou, 1993; Pereira, Tishby, & Lee, 1993; Sch\u007f utze, 1993), and thesauri such as WordNet are another source of word relationships (e.g., Voorhees, 1994). Distributional techniques can sometimes do a good job of identifying groups of related words (see Resnik, 1998b, for an overview and critical discussion), but for some tasks the relevant relationships are not among words, but among word senses. For example, Brown et al. (1992) illustrate the notion of a distributionally derived, \\semantically sticky\" cluster using an automatically derived word group containing attorney, counsel, trial, court, and judge.", "startOffset": 389, "endOffset": 2299}, {"referenceID": 43, "context": "13 Resnik (1998a) introduces an algorithm that uses taxonomically-de ned semantic similarity in order to derive grouping relationships among word senses from grouping relationships among words.", "startOffset": 3, "endOffset": 18}, {"referenceID": 47, "context": "Resnik Algorithm (Resnik, 1998a).", "startOffset": 17, "endOffset": 32}, {"referenceID": 54, "context": "This observation is similar in spirit to other approaches to word sense disambiguation based on maximizing relatedness of meaning (e.g., Lesk, 1986; Sussna, 1993).", "startOffset": 130, "endOffset": 162}, {"referenceID": 58, "context": "2 Linking to WordNet using a Bilingual Dictionary Multilingual resources for natural language processing can be di cult to obtain, although some promising e orts are underway in projects like EuroWordNet (Vossen, 1998).", "startOffset": 204, "endOffset": 218}, {"referenceID": 16, "context": "As the relatively low accuracies for human judges demonstrate, disambiguation using WordNet's ne-grained senses is quite a bit more di cult than disambiguation to the level of homographs (Hearst, 1991; Cowie, Guthrie, & Guthrie, 1992).", "startOffset": 187, "endOffset": 234}, {"referenceID": 40, "context": "Resnik (1998a) illustrates the algorithm of Figure 3 using word groupings from a variety of sources, including several of the sources on distributional clustering cited above, and evaluates the algorithm more rigorously on the task of associating WordNet senses with nouns in Roget's thesaurus, based on their thesaurus category membership.", "startOffset": 0, "endOffset": 15}, {"referenceID": 47, "context": "This is unsurprising, given previous experience with the problem of selecting among WordNet's ne-grained senses (Resnik, 1998a; Resnik & Yarowsky, 1997).", "startOffset": 112, "endOffset": 152}, {"referenceID": 31, "context": "perch, rod, pole { ((British) a linear measure of 16.5 feet) 5. perch, rod, pole { (a square rod of land) 6. pole, celestial pole { (one of two points of intersection of the Earth's axis and the celestial sphere) 7. pole { (one of two antipodal points where the Earth's axis of rotation intersects the Earth's surface) 8. terminal, pole { (a point on an electrical device (such as a battery) at which electric current enters or leaves) 9. pole { (a long berglass implement used for pole vaulting) 10. pole, magnetic pole { (one of the two ends of a magnet where the magnetism seems to be concentrated) Figure 9: List of WordNet senses for pole a noun, displayed as in Figure 9. Notice that if a user of WEDT had simply gone directly to the WordNet server to look up pole, the full list of 10 senses would have appeared with no indication of which are most potentially related to the WEDT dictionary entry under consideration. In contrast, the WEDT hyperlinks, introduced via the sense selection algorithm, lter out the majority of the irrelevant senses and provide the user a measure of con dence in selecting among those that remain. Although no formal evaluation of the WEDT/WordNet connection has been attempted, the results of the bilingual dictionary experiment suggest that this application of word sense disambiguation | ltering out the least relevant senses, and then leaving the user in the loop | is a task for which the sense disambiguation algorithm is well suited. This is supported by user feedback on the XWN feature of WEDT, which has been favorable (Robert Parks, personal communication). The site has been growing in popularity, with a current estimate of 1000-1500 hits per day. 6. Related Work There is an extensive literature on measuring similarity in general, and on word similarity in particular; for a classic paper see Tversky (1977). Recent work in information retrieval and computational linguistics has emphasized a distributional approach, in which words are represented as vectors in a space of features and similarity measures are de ned in terms of those vectors; see Resnik (1998b) for discussion, and Lee (1997) for a good recent example.", "startOffset": 32, "endOffset": 1860}, {"referenceID": 31, "context": "perch, rod, pole { ((British) a linear measure of 16.5 feet) 5. perch, rod, pole { (a square rod of land) 6. pole, celestial pole { (one of two points of intersection of the Earth's axis and the celestial sphere) 7. pole { (one of two antipodal points where the Earth's axis of rotation intersects the Earth's surface) 8. terminal, pole { (a point on an electrical device (such as a battery) at which electric current enters or leaves) 9. pole { (a long berglass implement used for pole vaulting) 10. pole, magnetic pole { (one of the two ends of a magnet where the magnetism seems to be concentrated) Figure 9: List of WordNet senses for pole a noun, displayed as in Figure 9. Notice that if a user of WEDT had simply gone directly to the WordNet server to look up pole, the full list of 10 senses would have appeared with no indication of which are most potentially related to the WEDT dictionary entry under consideration. In contrast, the WEDT hyperlinks, introduced via the sense selection algorithm, lter out the majority of the irrelevant senses and provide the user a measure of con dence in selecting among those that remain. Although no formal evaluation of the WEDT/WordNet connection has been attempted, the results of the bilingual dictionary experiment suggest that this application of word sense disambiguation | ltering out the least relevant senses, and then leaving the user in the loop | is a task for which the sense disambiguation algorithm is well suited. This is supported by user feedback on the XWN feature of WEDT, which has been favorable (Robert Parks, personal communication). The site has been growing in popularity, with a current estimate of 1000-1500 hits per day. 6. Related Work There is an extensive literature on measuring similarity in general, and on word similarity in particular; for a classic paper see Tversky (1977). Recent work in information retrieval and computational linguistics has emphasized a distributional approach, in which words are represented as vectors in a space of features and similarity measures are de ned in terms of those vectors; see Resnik (1998b) for discussion, and Lee (1997) for a good recent example.", "startOffset": 32, "endOffset": 2116}, {"referenceID": 28, "context": "Recent work in information retrieval and computational linguistics has emphasized a distributional approach, in which words are represented as vectors in a space of features and similarity measures are de ned in terms of those vectors; see Resnik (1998b) for discussion, and Lee (1997) for a good recent example.", "startOffset": 275, "endOffset": 286}, {"referenceID": 53, "context": "The inverse document frequency (idf) for term weighting in information retrieval makes use of logarithmic scaling, and serves to identify terms that do not discriminate well among di erent documents, a concept very similar in spirit to the idea that such terms have low information content (Salton, 1989).", "startOffset": 290, "endOffset": 304}, {"referenceID": 4, "context": ", see Church and Mercer (1993). The information of an event is a fundamental notion in stochastic language modeling for speech recognition, where the contribution of a correct word prediction based on its conditional probability, p(wordjcontext), is measured as the information conveyed by that prediction, log p(wordjcontext).", "startOffset": 6, "endOffset": 31}, {"referenceID": 4, "context": ", see Church and Mercer (1993). The information of an event is a fundamental notion in stochastic language modeling for speech recognition, where the contribution of a correct word prediction based on its conditional probability, p(wordjcontext), is measured as the information conveyed by that prediction, log p(wordjcontext). This forms the basis for standard measures of language model performance, such as cross entropy. Frequency of shared and unshared features has also long been a factor in computing similarity over vector representations. The inverse document frequency (idf) for term weighting in information retrieval makes use of logarithmic scaling, and serves to identify terms that do not discriminate well among di erent documents, a concept very similar in spirit to the idea that such terms have low information content (Salton, 1989). Although the counting of edges in is-a taxonomies seems to be something many people have tried, there seem to be few published descriptions of attempts to directly evaluate the e ectiveness of this method. A number of researchers have attempted to make use of conceptual distance in information retrieval. For example, Rada et al. (1989, 1989) and Lee et al. (1993) report experiments using conceptual distance, implemented using the edgecounting metric, as the basis for ranking documents by their similarity to a query.", "startOffset": 6, "endOffset": 1220}, {"referenceID": 4, "context": ", see Church and Mercer (1993). The information of an event is a fundamental notion in stochastic language modeling for speech recognition, where the contribution of a correct word prediction based on its conditional probability, p(wordjcontext), is measured as the information conveyed by that prediction, log p(wordjcontext). This forms the basis for standard measures of language model performance, such as cross entropy. Frequency of shared and unshared features has also long been a factor in computing similarity over vector representations. The inverse document frequency (idf) for term weighting in information retrieval makes use of logarithmic scaling, and serves to identify terms that do not discriminate well among di erent documents, a concept very similar in spirit to the idea that such terms have low information content (Salton, 1989). Although the counting of edges in is-a taxonomies seems to be something many people have tried, there seem to be few published descriptions of attempts to directly evaluate the e ectiveness of this method. A number of researchers have attempted to make use of conceptual distance in information retrieval. For example, Rada et al. (1989, 1989) and Lee et al. (1993) report experiments using conceptual distance, implemented using the edgecounting metric, as the basis for ranking documents by their similarity to a query. Sussna (1993) uses semantic relatedness measured with WordNet in word sense disambiguation, de ning a measure of distance that weights di erent types of links and also explicitly takes depth in the taxonomy into account.", "startOffset": 6, "endOffset": 1390}, {"referenceID": 4, "context": ", see Church and Mercer (1993). The information of an event is a fundamental notion in stochastic language modeling for speech recognition, where the contribution of a correct word prediction based on its conditional probability, p(wordjcontext), is measured as the information conveyed by that prediction, log p(wordjcontext). This forms the basis for standard measures of language model performance, such as cross entropy. Frequency of shared and unshared features has also long been a factor in computing similarity over vector representations. The inverse document frequency (idf) for term weighting in information retrieval makes use of logarithmic scaling, and serves to identify terms that do not discriminate well among di erent documents, a concept very similar in spirit to the idea that such terms have low information content (Salton, 1989). Although the counting of edges in is-a taxonomies seems to be something many people have tried, there seem to be few published descriptions of attempts to directly evaluate the e ectiveness of this method. A number of researchers have attempted to make use of conceptual distance in information retrieval. For example, Rada et al. (1989, 1989) and Lee et al. (1993) report experiments using conceptual distance, implemented using the edgecounting metric, as the basis for ranking documents by their similarity to a query. Sussna (1993) uses semantic relatedness measured with WordNet in word sense disambiguation, de ning a measure of distance that weights di erent types of links and also explicitly takes depth in the taxonomy into account. Following the original proposal to measure semantic similarity in a taxonomy using information content (Resnik, 1993b, 1993a), a number of related proposals have been explored. Leacock and Chodorow (1994) de ne a measure resembling information content, but using the normalized path length between the two concepts being compared rather than the probability of a subsuming concept.", "startOffset": 6, "endOffset": 1802}, {"referenceID": 20, "context": "Lin (1997, 1998) has recently proposed an alternative information-theoretic similarity measure, derived from a set of basic assumptions about similarity in a style reminiscent of the way in which entropy/information itself has a formal de nition derivable from a set of basic properties (Khinchin, 1957).", "startOffset": 287, "endOffset": 303}], "year": 2011, "abstractText": null, "creator": "dvips 5.55 Copyright 1986, 1994 Radical Eye Software"}}}