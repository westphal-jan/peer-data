{"id": "1105.5449", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-May-2011", "title": "AntNet: Distributed Stigmergetic Control for Communications Networks", "abstract": "This paper introduces AntNet, a novel approach to the adaptive learning of routing tables in communications networks. AntNet is a distributed, mobile agents based Monte Carlo system that was inspired by recent work on the ant colony metaphor for solving optimization problems. AntNet's agents concurrently explore the network and exchange collected information. The communication among the agents is indirect and asynchronous, mediated by the network itself. This form of communication is typical of social insects and is called stigmergy. We compare our algorithm with six state-of-the-art routing algorithms coming from the telecommunications and machine learning fields. The algorithms' performance is evaluated over a set of realistic testbeds. We run many experiments over real and artificial IP datagram networks with increasing number of nodes and under several paradigmatic spatial and temporal traffic distributions. Results are very encouraging. AntNet showed superior performance under all the experimental conditions with respect to its competitors. We analyze the main characteristics of the algorithm and try to explain the reasons for its superiority.", "histories": [["v1", "Fri, 27 May 2011 01:48:39 GMT  (256kb)", "http://arxiv.org/abs/1105.5449v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["g di caro", "m dorigo"], "accepted": false, "id": "1105.5449"}, "pdf": {"name": "1105.5449.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Gianni Di Caro", "Marco Dorigo"], "emails": ["gdicaro@iridia.ulb.ac.be", "mdorigo@ulb.ac.be"], "sections": [{"heading": null, "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times. \""}], "references": [{"title": "Neuronlike adaptive elements", "author": ["A.G. Barto", "R.S. Sutton", "C.W. Anderson"], "venue": null, "citeRegEx": "Barto et al\\.,? \\Q1983\\E", "shortCiteRegEx": "Barto et al\\.", "year": 1983}, {"title": "Trails and U-turns in the selection", "author": ["R. Beckers", "J.L. Deneubourg", "S. Goss"], "venue": null, "citeRegEx": "Beckers et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Beckers et al\\.", "year": 1992}, {"title": "Dynamic Programming", "author": ["R. Bellman"], "venue": null, "citeRegEx": "Bellman,? \\Q1957\\E", "shortCiteRegEx": "Bellman", "year": 1957}, {"title": "On a routing problem", "author": ["R. Bellman"], "venue": "Quarterly of Applied Mathematics,", "citeRegEx": "Bellman,? \\Q1958\\E", "shortCiteRegEx": "Bellman", "year": 1958}, {"title": "Dynamic Programming and Optimal Control", "author": ["D. Bertsekas"], "venue": "Athena Scienti c", "citeRegEx": "Bertsekas,? \\Q1995\\E", "shortCiteRegEx": "Bertsekas", "year": 1995}, {"title": "The case for chaotic adaptive routing", "author": ["K. Bolding", "M.L. Fulgham", "L. Snyder"], "venue": null, "citeRegEx": "Bolding et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bolding et al\\.", "year": 1994}, {"title": "Packet routing in dinamically changing networks: A rein", "author": ["J. Boyan", "M. Littman"], "venue": null, "citeRegEx": "Boyan and Littman,? \\Q1994\\E", "shortCiteRegEx": "Boyan and Littman", "year": 1994}, {"title": "TCP vegas: New techniques", "author": ["L.S. Brakmo", "S.W. O'Malley", "L.L. Peterson"], "venue": null, "citeRegEx": "Brakmo et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Brakmo et al\\.", "year": 1994}, {"title": "Shortest paths algorithms: Theory", "author": ["B.V. Cherkassky", "A.V. Goldberg", "T. Radzik"], "venue": null, "citeRegEx": "Cherkassky et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Cherkassky et al\\.", "year": 1994}, {"title": "Predictive Q-routing: A memory-based reinforcement", "author": ["S. Choi", "Yeung", "D.-Y"], "venue": null, "citeRegEx": "Choi et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Choi et al\\.", "year": 1996}, {"title": "Distributed optimization by ant colonies", "author": ["A. Colorni", "M. Dorigo", "V. Maniezzo"], "venue": null, "citeRegEx": "Colorni et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Colorni et al\\.", "year": 1991}, {"title": "Ants can colour graphs", "author": ["D. Costa", "A. Hertz"], "venue": "Journal of the Operational Research", "citeRegEx": "Costa and Hertz,? \\Q1997\\E", "shortCiteRegEx": "Costa and Hertz", "year": 1997}, {"title": "A framework for QoS-based", "author": ["E. Crawley", "R. Nair", "B. Rajagopalan", "H. Sandick"], "venue": null, "citeRegEx": "Crawley et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Crawley et al\\.", "year": 1996}, {"title": "An evaluation of TCP Vegas by live emulation", "author": ["P.B. Danzig", "Z. Liu", "L. Yan"], "venue": null, "citeRegEx": "Danzig et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Danzig et al\\.", "year": 1994}, {"title": "Two ant colony algorithms for best-e ort routing", "author": ["G. Di Caro", "M. Dorigo"], "venue": null, "citeRegEx": "Caro and Dorigo,? \\Q1998\\E", "shortCiteRegEx": "Caro and Dorigo", "year": 1998}, {"title": "A note on two problems in connection with graphs", "author": ["E.W. Dijkstra"], "venue": null, "citeRegEx": "Dijkstra,? \\Q1959\\E", "shortCiteRegEx": "Dijkstra", "year": 1959}, {"title": "Optimization, Learning and Natural Algorithms (in Italian)", "author": ["M. Dorigo"], "venue": null, "citeRegEx": "Dorigo,? \\Q1992\\E", "shortCiteRegEx": "Dorigo", "year": 1992}, {"title": "Ant algorithms for distributed", "author": ["M. Dorigo", "G. Di Caro", "L.M. Gambardella"], "venue": null, "citeRegEx": "Dorigo et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Dorigo et al\\.", "year": 1998}, {"title": "Ant colony system: A cooperative learning", "author": ["M. Dorigo", "L.M. Gambardella"], "venue": null, "citeRegEx": "Dorigo and Gambardella,? \\Q1997\\E", "shortCiteRegEx": "Dorigo and Gambardella", "year": 1997}, {"title": "Positive feedback as a search strategy", "author": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "venue": null, "citeRegEx": "Dorigo et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Dorigo et al\\.", "year": 1991}, {"title": "The ant system: Optimization by a colony", "author": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "venue": null, "citeRegEx": "Dorigo et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Dorigo et al\\.", "year": 1996}, {"title": "Self-organized shortcuts", "author": ["S. Goss", "S. Aron", "J.L. Deneubourg", "J.M. Pasteels"], "venue": null, "citeRegEx": "Goss et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Goss et al\\.", "year": 1989}, {"title": "La reconstruction du nid et les coordinations interindividuelles", "author": ["P.P. e"], "venue": null, "citeRegEx": "e,? \\Q1959\\E", "shortCiteRegEx": "e", "year": 1959}, {"title": "Reinforcement learning algorithm", "author": ["T. Jaakkola", "S.P. Singh", "M.I. Jordan"], "venue": null, "citeRegEx": "Jaakkola et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Jaakkola et al\\.", "year": 1995}, {"title": "Reinforcement learning: A survey", "author": ["L.P. Kaelbling", "M.L. Littman", "A.W. Moore"], "venue": null, "citeRegEx": "Kaelbling et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Kaelbling et al\\.", "year": 1996}, {"title": "The revised ARPANET routing metric", "author": ["A. Khanna", "J. Zinky"], "venue": null, "citeRegEx": "Khanna and Zinky,? \\Q1989\\E", "shortCiteRegEx": "Khanna and Zinky", "year": 1989}, {"title": "Reinforcement learning with selective perception and hidden state", "author": ["A.K. McCallum"], "venue": null, "citeRegEx": "McCallum,? \\Q1995\\E", "shortCiteRegEx": "McCallum", "year": 1995}, {"title": "The new routing algorithm", "author": ["J.M. McQuillan", "I. Richer", "E.C. Rosen"], "venue": null, "citeRegEx": "McQuillan et al\\.,? \\Q1980\\E", "shortCiteRegEx": "McQuillan et al\\.", "year": 1980}, {"title": "A failsafe distributed routing protocol", "author": ["P. Merlin", "A. Segall"], "venue": "IEEE Transactions", "citeRegEx": "Merlin and Segall,? \\Q1979\\E", "shortCiteRegEx": "Merlin and Segall", "year": 1979}, {"title": "OSPF Anatomy of an Internet Routing Protocol", "author": ["J.T. Moy"], "venue": null, "citeRegEx": "Moy,? \\Q1998\\E", "shortCiteRegEx": "Moy", "year": 1998}, {"title": "On the behavior of a learning", "author": ["K.S. Narendra", "M.A. Thathachar"], "venue": null, "citeRegEx": "Narendra and Thathachar,? \\Q1980\\E", "shortCiteRegEx": "Narendra and Thathachar", "year": 1980}, {"title": "Nonstationary models of learning automata", "author": ["O.V. Nedzelnitsky", "K.S. Narendra"], "venue": null, "citeRegEx": "Nedzelnitsky and Narendra,? \\Q1987\\E", "shortCiteRegEx": "Nedzelnitsky and Narendra", "year": 1987}, {"title": "Probability, Random Variables and Stochastic Process (Third edition)", "author": ["A. Papoulis"], "venue": null, "citeRegEx": "Papoulis,? \\Q1991\\E", "shortCiteRegEx": "Papoulis", "year": 1991}, {"title": "Computer Networks: A System", "author": ["L.L. Peterson", "B. Davie"], "venue": null, "citeRegEx": "Peterson and Davie,? \\Q1996\\E", "shortCiteRegEx": "Peterson and Davie", "year": 1996}, {"title": "Simulation and the Monte Carlo Method", "author": ["R.Y. Rubistein"], "venue": null, "citeRegEx": "Rubistein,? \\Q1981\\E", "shortCiteRegEx": "Rubistein", "year": 1981}, {"title": "QoS routing (qosr) working group report", "author": ["H. Sandick", "E. Crawley"], "venue": null, "citeRegEx": "Sandick and Crawley,? \\Q1997\\E", "shortCiteRegEx": "Sandick and Crawley", "year": 1997}, {"title": "Ant-like agents for load balancing", "author": ["R. Schoonderwoerd", "O. Holland", "J. Bruten"], "venue": null, "citeRegEx": "Schoonderwoerd et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Schoonderwoerd et al\\.", "year": 1997}, {"title": "Reinforcement learning with replacing eligibility", "author": ["S.P. Singh", "R.S. Sutton"], "venue": null, "citeRegEx": "Singh and Sutton,? \\Q1996\\E", "shortCiteRegEx": "Singh and Sutton", "year": 1996}, {"title": "Learning without state estimation", "author": ["S.P. Singh", "T. Jaakkola", "M.I. Jordan"], "venue": null, "citeRegEx": "Singh et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Singh et al\\.", "year": 1994}, {"title": "Multiagent systems: A survey from a machine learning", "author": ["P. Stone", "M.M. Veloso"], "venue": null, "citeRegEx": "Stone and Veloso,? \\Q1996\\E", "shortCiteRegEx": "Stone and Veloso", "year": 1996}, {"title": "Variance reduction algorithms for parallel replicated", "author": ["S. Streltsov", "P. Vakili"], "venue": null, "citeRegEx": "Streltsov and Vakili,? \\Q1996\\E", "shortCiteRegEx": "Streltsov and Vakili", "year": 1996}, {"title": "Ants and reinforcement learning: A", "author": ["D. Subramanian", "P. Druschel", "J. Chen"], "venue": null, "citeRegEx": "Subramanian et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Subramanian et al\\.", "year": 1997}, {"title": "High-performance Communication Networks", "author": ["J. Walrand", "P. Varaiya"], "venue": null, "citeRegEx": "Walrand and Varaiya,? \\Q1996\\E", "shortCiteRegEx": "Walrand and Varaiya", "year": 1996}, {"title": "Analysis of shortest-path routing algorithms in a dynamic", "author": ["Z. Wang", "J. Crowcroft"], "venue": null, "citeRegEx": "Wang and Crowcroft,? \\Q1992\\E", "shortCiteRegEx": "Wang and Crowcroft", "year": 1992}, {"title": "A Simulation Laboratory for Evaluation of Dynamic Tra c Manage", "author": ["Q. Yang"], "venue": null, "citeRegEx": "Yang,? \\Q1997\\E", "shortCiteRegEx": "Yang", "year": 1997}], "referenceMentions": [{"referenceID": 21, "context": "Journal of Arti cial Intelligence Research 9 (1998) 317-365 Submitted 5/98; published 12/98 AntNet: Distributed Stigmergetic Control for Communications Networks Gianni Di Caro gdicaro@iridia.", "startOffset": 24, "endOffset": 52}, {"referenceID": 16, "context": "Algorithms that take inspiration from real ants' behavior in nding shortest paths (Goss, Aron, Deneubourg, & Pasteels, 1989; Beckers, Deneubourg, & Goss, 1992) using as information only the trail of a chemical substance (called pheromone) deposited by other ants, have recently been successfully applied to several discrete optimization problems (Dorigo, Maniezzo, & Colorni, 1991; Dorigo, 1992; Dorigo, Maniezzo, & Colorni, 1996; Dorigo & Gambardella, 1997; Schoonderwoerd, Holland, Bruten, & Rothkrantz, 1996; Schoonderwoerd, Holland, & Bruten, 1997; Costa & Hertz, 1997).", "startOffset": 346, "endOffset": 573}, {"referenceID": 26, "context": "It is interesting to note that the above characteristics make the problem of routing belong to the class of reinforcement learning problems with hidden state (Bertsekas & Tsitsiklis, 1996; Kaelbling, Littman, & Moore, 1996; McCallum, 1995).", "startOffset": 158, "endOffset": 239}, {"referenceID": 4, "context": "Citing Bertsekas and Gallager (1992), page 367: \\the e ect of good routing is to increase throughput for the same value of average delay per packet under high o ered load conditions and to decrease average delay per packet under low and moderate o ered load conditions\".", "startOffset": 7, "endOffset": 37}, {"referenceID": 29, "context": "A hierarchical structure is adopted on the Internet, organized in hierarchical Autonomous Systems and multiple routing areas inside each Autonomous System (Moy, 1998).", "startOffset": 155, "endOffset": 166}, {"referenceID": 19, "context": "AntNet takes inspiration from previous work on arti cial ant colonies techniques to solve combinatorial optimization problems (Dorigo et al., 1991; Dorigo, 1992; Dorigo et al., 1996; Dorigo & Gambardella, 1997) and telephone network routing (Schoonderwoerd et al.", "startOffset": 126, "endOffset": 210}, {"referenceID": 16, "context": "AntNet takes inspiration from previous work on arti cial ant colonies techniques to solve combinatorial optimization problems (Dorigo et al., 1991; Dorigo, 1992; Dorigo et al., 1996; Dorigo & Gambardella, 1997) and telephone network routing (Schoonderwoerd et al.", "startOffset": 126, "endOffset": 210}, {"referenceID": 20, "context": "AntNet takes inspiration from previous work on arti cial ant colonies techniques to solve combinatorial optimization problems (Dorigo et al., 1991; Dorigo, 1992; Dorigo et al., 1996; Dorigo & Gambardella, 1997) and telephone network routing (Schoonderwoerd et al.", "startOffset": 126, "endOffset": 210}, {"referenceID": 24, "context": "This gives rise to a credit assignment problem typical of the reinforcement learning eld (Bertsekas & Tsitsiklis, 1996; Kaelbling et al., 1996).", "startOffset": 89, "endOffset": 143}, {"referenceID": 21, "context": "In this case, the core of the algorithm is based on the capability of \\real\" ants to discover shortest paths communicating by means of pheromone trails (Goss et al., 1989; Beckers et al., 1992).", "startOffset": 152, "endOffset": 193}, {"referenceID": 1, "context": "In this case, the core of the algorithm is based on the capability of \\real\" ants to discover shortest paths communicating by means of pheromone trails (Goss et al., 1989; Beckers et al., 1992).", "startOffset": 152, "endOffset": 193}, {"referenceID": 32, "context": "The expression is obtained by using the Tchebyche inequality that allows the de nition of a con dence interval for a random variable following any distribution (Papoulis, 1991) Usually, for speci c probability densities the Tchebyche bound is too high, but here we can conveniently use it because (i) we want to avoid to make assumptions on the distribution of and, (ii) we need only a raw estimate of the con dence interval.", "startOffset": 160, "endOffset": 176}, {"referenceID": 29, "context": "OSPF (static, link state): is our implementation of the current Interior Gateway Protocol (IGP) of Internet (Moy, 1998).", "startOffset": 108, "endOffset": 119}, {"referenceID": 2, "context": "BF (adaptive, distance-vector): is an implementation of the asynchronous distributed Bellman-Ford algorithm with dynamic metrics (Bertsekas & Gallager, 1992; Shankar et al., 1992a). The algorithm has been implemented following the guidelines of Appendix A, while link costs are assigned in the same way as described for SPF above. Vector-distance Bellman-Ford-like algorithms are today in use mainly for intra-domain routing, because they are used in the Routing Information Protocol (RIP) (Malkin & Steenstrup, 1995) supplied with the BSD version of Unix. Several enhanced versions of the basic adaptive Bellman-Ford algorithm can be found in the literature (for example the Merlin-Segall (Merlin & Segall, 1979) and the Extended Bellman-Ford (Cheng, Riley, Kumar, & Garcia-Luna-Aceves, 1989) algorithms). They focus mainly on reducing the information dissemination time in case of link failures. When link failures are not a major issue, as in this paper, their behavior is in general equivalent to that of the basic adaptive Bellman-Ford. Q-R (adaptive, distance-vector): is the Q-Routing algorithm as proposed by Boyan and Littman (1994). This is an online asynchronous version of the Bellman-Ford algorithm.", "startOffset": 85, "endOffset": 1142}, {"referenceID": 16, "context": "Di Caro & Dorigo paths on the basis of a network-wide shortest paths re-calculation for every packet hop. Links costs used in shortest paths calculations are the following: Cl = dl + Sp bl + (1 )SQ(l) bl + SQ(l) bl ; where dl is the transmission delay for link l, bl is its bandwidth, Sp is the size (in bits) of the data packet doing the hop, SQ(l) is the size (in bits) of the queue of link l, SQ(l) is the exponential mean of the size of links queue and it is a correction to the actual size of the link queue on the basis of what observed until that moment. This correction is weighted by the value set to 0.4. Of course, given the arbitrariness we introduced in calculating Cl, it could be possible to de ne an even better Daemon algorithm. 6. Experimental Settings The functioning of a communication network is governed by many components, which may interact in nonlinear and unpredictable ways. Therefore, the choice of a meaningful testbed to compare competing algorithms is no easy task. A limited set of classes of tunable components is de ned and for each class our choices are explained. 6.1 Topology and physical properties of the net Topology can be de ned on the basis of a real net instance or it can de ned by hand, to better analyze the in uence of important topological features (like diameter, connectivity, etc.). Nodes are mainly characterized by their bu ering and processing capacity, whereas links are characterized by their propagation delay, bandwidth and streams multiplexing scheme. For both, fault probability distributions should be de ned. In our experiments, we used three signi cant net instances with increasing numbers of nodes. For all of them we describe the main characteristics and we summarize the topological properties by means of a triple of numbers ( , , N) indicating respectively the mean shortest path distance, in terms of hops, between all pairs of nodes, the variance of this average, and the total number of nodes. From these three numbers we can get an idea about the degree of connectivity and balancing of the network. The di culty of the routing problem roughly increases with the value of these numbers. SimpleNet (1.9, 0.7, 8) is a small network speci cally designed to study some aspects of the behavior of the algorithms we compare. Experiments with SimpleNet were designed to closely study how the di erent algorithms manage to distribute the load on the di erent possible paths. SimpleNet is composed of 8 nodes and 9 bi-directional links with a bandwidth of 10 Mbit/s and propagation delay of 1 msec. The topology is shown in Figure 5. NSFNET (2.2, 0.8, 14) is the old USA T1 backbone (1987). NSFNET is a WAN composed of 14 nodes and 21 bi-directional links with a bandwidth of 1.", "startOffset": 10, "endOffset": 2655}, {"referenceID": 34, "context": "1 AntNet as an on-line Monte Carlo system with biased exploration The AntNet routing system can be seen as a collection of mobile agents collecting data about the network status by concurrently performing on-line Monte Carlo simulations (Rubistein, 1981; Streltsov & Vakili, 1996).", "startOffset": 237, "endOffset": 280}, {"referenceID": 16, "context": "Di Caro & Dorigo maintained at the node. The T updates are carried out in an asynchronous way and as a function of their previous values. Moreover, while T is used in a straightforward probabilistic way by the data packets, traveling ants select the next node by using both T , that is, an adaptive representation of the past policy, and a model of the current local link queues, that is, an instantaneous representation of the node status. It is evident that AntNet builds and uses more information than its competitors: two di erent memory-based components and an instantaneous predictor are used and combined at di erent levels. Moreover, in this way AntNet robustly redistributes among these completely local components the criticality of all the estimates and decisions. 8.3 AntNet's robustness to wrong estimates As remarked above, AntNet, di erently from its competitors, does not propagate local estimates to other nodes. Each node routing table is updated independently, by using local information and the ants' experienced trip time. Moreover, (i) each ant experiment a ects only one entry in the routing table of the visited nodes, the one relative to the ant's destination, and, (ii) the local information is built from the \\global\" information collected by traveling ants, implicitly reducing in this way the variance in the estimates. These characteristics make AntNet particularly robust to wrong estimates. On the contrary, in all the other algorithms a locally wrong estimate will be propagated to all other nodes and will be used to compute estimates to many di erent destinations. How bad this is for the algorithm performance depends on how long the wrong estimate e ect lasts. In particular, this will be a function of the time window over which estimates are computed for SPF and BF, and of the learning parameters for Q-R and PQ-R. 8.4 AntNet's probabilistic use of routing tables to route data packets All the tested algorithms but AntNet use deterministic routing tables.15 In these algorithms, entries in the routing tables contain distance/time estimates to the destinations. These estimates can provide misleading information if the algorithm is not fast enough to follow the tra c uctuations, as can be the case under heavy load conditions. Instead, AntNet routing tables have probabilistic entries that, although re ecting the goodness of a particular path choice with respect to the others available, do not force the data packets to choose the perceived best path. This has the positive e ect of allowing a better balancing of the tra c load on di erent paths, with a resulting better utilization of the resources (as was shown in particular in the experiments with the SimpleNet). As remarked at the end of Section 4.1, the intrinsic probabilistic structure of the routing tables and the way they are updated allow AntNet to exploit the ant's arrival rate as a way to assign implicit (cumulative) reinforcements to discovered paths. It is not obvious how the same e ect could be obtained by using routing tables containing distance/time estimates and using this estimates in a probabilistic way. In fact, in this case each new trip time sample would 15. Singh, Jaakkola, and Jordan (1994) showed that stochastic policies can yield higher performance than deterministic policies in the case of an incomplete access to the state information of the environment.", "startOffset": 10, "endOffset": 3222}, {"referenceID": 16, "context": "Di Caro & Dorigo veloped, are problems where, unlike routing, assumptions like Markovianity or stationarity of the process considered are satis ed. The characteristics of the adaptive routing problem make it very di cult and not well suited to be solved with usual RL algorithms. This fact, as we explain below, determines a departure of AntNet from classical RL algorithms. A rst way to relate the structure of AntNet to that of a (general) RL algorithm is connected to the way the outcomes of the experiments, the trip times Tk!d, are processed. The transformation from the raw values Tk!d to the more re ned reinforcements r are reminiscent of what happens in Actor-Critic systems (Barto, Sutton, & Anderson, 1983): the raw reinforcement signal is processed by a critic module, which is learning a model (the node's componentM) of the underlying process, and then is fed to the learning system (the routing table T ) transformed into an evaluation of the policy followed by the ants. In our case, the critic is both adaptive, to take into account the variability of the tra c process, and rather simple, to meet computational requirements. Another way of seeing AntNet as a classical RL system is related to its interpretation as a parallel replicated Monte Carlo (MC) system. As was shown by Singh and Sutton (1996), a rst-visit MC (only the rst visit to a state is used to estimate its value during a trial) simulation system is equivalent to a batch temporal di erence (TD) method with replacing traces and decay parameter =1.", "startOffset": 10, "endOffset": 1320}, {"referenceID": 1, "context": "Related Work Algorithms based on the ant colony metaphor were inspired by the ant colony foraging behavior (Beckers et al., 1992).", "startOffset": 107, "endOffset": 129}, {"referenceID": 16, "context": "When in node i an ant chooses the next node j to move to among those not visited yet with a probability Pij that is a function of the amount of pheromone trail on the edge connecting i to j (as well as of a local heuristic function; the interested reader can nd a detailed description of ant-cycle elsewhere (Dorigo, 1992; Dorigo et al., 1996)).", "startOffset": 308, "endOffset": 343}, {"referenceID": 20, "context": "When in node i an ant chooses the next node j to move to among those not visited yet with a probability Pij that is a function of the amount of pheromone trail on the edge connecting i to j (as well as of a local heuristic function; the interested reader can nd a detailed description of ant-cycle elsewhere (Dorigo, 1992; Dorigo et al., 1996)).", "startOffset": 308, "endOffset": 343}, {"referenceID": 1, "context": "Related Work Algorithms based on the ant colony metaphor were inspired by the ant colony foraging behavior (Beckers et al., 1992). These were rst proposed by Dorigo (1992), Colorni et al.", "startOffset": 108, "endOffset": 172}, {"referenceID": 1, "context": "Related Work Algorithms based on the ant colony metaphor were inspired by the ant colony foraging behavior (Beckers et al., 1992). These were rst proposed by Dorigo (1992), Colorni et al. (1991) and Dorigo et al.", "startOffset": 108, "endOffset": 195}, {"referenceID": 19, "context": "This choice, which is reminiscent of the pheromone trail updating strategy implemented in ant-density, another of the rst ant colony based algorithms (Dorigo et al., 1991; Dorigo, 1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possible by the cost-symmetry assumption made by the authors.", "startOffset": 150, "endOffset": 207}, {"referenceID": 16, "context": "This choice, which is reminiscent of the pheromone trail updating strategy implemented in ant-density, another of the rst ant colony based algorithms (Dorigo et al., 1991; Dorigo, 1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possible by the cost-symmetry assumption made by the authors.", "startOffset": 150, "endOffset": 207}, {"referenceID": 10, "context": "This choice, which is reminiscent of the pheromone trail updating strategy implemented in ant-density, another of the rst ant colony based algorithms (Dorigo et al., 1991; Dorigo, 1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possible by the cost-symmetry assumption made by the authors.", "startOffset": 150, "endOffset": 207}, {"referenceID": 15, "context": "Di Caro & Dorigo same level of congestion in both directions because the congestion depends only on the state of the nodes in the path. Moreover, dealing with telephone networks, each call occupies Link 4 N bidirectional channels Link 1 Link 3 n << N possible connections Link 2 Figure 18: Network node in the telecommunications network model of Schoonderwoerd et al. (1996). exactly one physical channel across the path.", "startOffset": 10, "endOffset": 375}, {"referenceID": 10, "context": ", 1991; Dorigo, 1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possible by the cost-symmetry assumption made by the authors. Other di erences are that ABC does not use local models to score the ants trip times, nor local heuristic information and ant-private memory to improve the ants decision policies. Also, it does not recover from cycles and does not use the information contained in all the ant sub-paths. Because of the di erent network model used and of the many implementation details tightly bound to the network model, it was impossible for us to re-implement and compare the ABC algorithm with AntNet. Subramanian, Druschel, and Chen (1997) have proposed an ant-based algorithm for packet-switched nets.", "startOffset": 22, "endOffset": 689}], "year": 2011, "abstractText": null, "creator": "dvipsk 5.58f Copyright 1986, 1994 Radical Eye Software"}}}