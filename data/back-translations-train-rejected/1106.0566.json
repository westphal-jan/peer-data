{"id": "1106.0566", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2011", "title": "The Impact of Mutation Rate on the Computation Time of Evolutionary Dynamic Optimization", "abstract": "Mutation has traditionally been regarded as an important operator in evolutionary algorithms. In particular, there have been many experimental studies which showed the effectiveness of adapting mutation rates for various static optimization problems. Given the perceived effectiveness of adaptive and self-adaptive mutation for static optimization problems, there have been speculations that adaptive and self-adaptive mutation can benefit dynamic optimization problems even more since adaptation and self-adaptation are capable of following a dynamic environment. However, few theoretical results are available in analyzing rigorously evolutionary algorithms for dynamic optimization problems. It is unclear when adaptive and self-adaptive mutation rates are likely to be useful for evolutionary algorithms in solving dynamic optimization problems. This paper provides the first rigorous analysis of adaptive mutation and its impact on the computation times of evolutionary algorithms in solving certain dynamic optimization problems. More specifically, for both individual-based and population-based EAs, we have shown that any time-variable mutation rate scheme will not significantly outperform a fixed mutation rate on some dynamic optimization problem instances. The proofs also offer some insights into conditions under which any time-variable mutation scheme is unlikely to be useful and into the relationships between the problem characteristics and algorithmic features (e.g., different mutation schemes).", "histories": [["v1", "Fri, 3 Jun 2011 05:31:34 GMT  (155kb)", "http://arxiv.org/abs/1106.0566v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CC", "authors": ["tianshi chen", "yunji chen", "ke tang", "guoliang chen", "xin yao"], "accepted": false, "id": "1106.0566"}, "pdf": {"name": "1106.0566.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "Key words: Evolutionary algorithm, mutation rate, adaptation, dynamic optimization."}, {"heading": "1 Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2 Problem and Algorithm", "text": "In this section, we present some preparatory work for this paper, including the notations of asymptotic orders, the BDOP class, and the EAs discussed in this paper."}, {"heading": "2.1 Preliminaries", "text": "To facilitate our analysis, we first present some notations used to compare the asymptotic growth order of functions. \u2022 Let g1 = g1 (n) and g2 = g2 (n) be two positive functions of n, then [32]: \u2022 g1 = O (g2), iff n0 (n), c N, c N > n0, g1 (n) \u2264 cg2 (n) (g1) is asymptotically limited to a constant factor above g2, and the asymptotic order of g1 is not greater than that of g2); 1The (1 +) EA is a population-based ability of n \u2212 n that maintains a unique parental personality and produces offspring in each generation. \u2022 g1 = (g2), iff g2 = O (g1) (the asymptotic order of g1) is not less than the ability of g2); \u2022 g1, which is not less than the ability of g2, is the ability of g2."}, {"heading": "2.2 A Theoretical DOP Model", "text": "In this area we are able to define a theoretical model for dynamic optimization problems in binary search."}, {"heading": "2.3 Time-variable Mutation Rate Schemes and Evolutionary Algorithms", "text": "In this thesis, both individual and population-based EAs are used in our theoretical analysis, and the aim is to demonstrate the effects of time-variable mutation rates on different EAs in solving DOPs. Specifically, the individual-based EA scheme is referred to in this thesis as (1 + 1) EA. For each generation, the EA maintains a unique parent-individual, and the parent-individual can only create a unique progeny-individual via mutation; the selection operator preserves the individual with better fitness between parents and progeny individuals (i.e., 1 parent + 1 progeny-individual). A concrete description of the (1 + 1) EA generation studied in this thesis is given below: algorithm 1 (1 + 1) EA. Choose the initial individual x (P) 0 randomly through the uniform distribution across the entire search space. Place the initial generation index t = 0. The tth generation of the EA consists of the following steps of the individual parent: each individual Bx \u2022 (P)."}, {"heading": "2.4 Measure of Time Complexity", "text": "So far, we have introduced the problem studied in this paper and the algorithm. In this subsection, we present the measurement of the performance of EAs, which is indispensable for our theoretical studies. Traditionally, the performance of an EA can be measured against a static optimization problem based on the first hit time [24, 25, 26, 54, 53]. This concept measures the number of generations that an EA needs to find the optimum of a static optimization problem, which can be generalized to facilitate the theoretical analysis of evolutionary dynamic optimization. For (1 + 1) and (1 +) EAs at the DOPs, we formally define the first hit time as follows: Definition 7 \u00b7 \u00b7 (first hit time). On a DOP {ft: t: t, N}, the first hit time of a (1 +) EA (\u03bb N + in n) polynomial schemes of the first hit time of EAs is defined as follows: Target: min {\u00b7 \u00b7 x, 0, As: t, N}, (x) where x (P) x x x is the first hit time (1)."}, {"heading": "3 (1 + 1) EA with Time-Variable Mutation Schemes", "text": "Over the last decade, a number of studies have been conducted to prove or confirm that some specific time-variable mutation rate schemes are helpful in improving the performance of EAs, although it is unclear whether this is generally true. In this section, we present several theoretical results regarding the performance of the (1 + 1) EA with different time-variable mutation rate schemes for BDOPs. In the first subsection, we provide a general result showing that the BDOPs with shift rate \u03c3 = \u03c9 (logn / n2) cannot be efficiently solved by the (1 + 1) EA with a time-variable mutation rate scheme that meets the requirements of the (1 + 1) EA with a time-variable mutation scheme [0, 1 \u2212 1 / logn]. In the second subsection, we generalize the above result to a specific BDOP called BitMatchingD problem and show that the (1 + 1) EA with any time-variable mutation scheme (i.e., match logn) says (Bitm) efficiently."}, {"heading": "3.1 A General Result", "text": "The BDOPs examined in this section are displacement \u03c3 = \u03c9 (logn / n2), which implies that the displacement rate of the BDOPs (EA = 1) meets this limit (log n / n2) / \u03c3 = 0. The average movement of the global optimum in each DOP phase (which corresponds to a generation of the global optimum, as mentioned above) measured by the hamming distance is greater than the hamming distance (logn / n), including the case that in each DOP phase the global changes occur by less than one bit on average. Intuitively, such a small movement speed of the global optimum does not seem to seriously affect the optimization process, and the (1 + 1) EA is likely to manage such situations by switching to corresponding mutation rates. In this subsection, Theorem 1 discovers that even such small movements have a significant impact on the first meeting time of the (1 + 1) EA with different time variable mutation schemes."}, {"heading": "4 (1 + \u03bb) EA with Time-Variable Mutation Schemes", "text": "So far, we have analyzed the effectiveness of time-variable mutation schemes in the context of (1 + 1) EA. In this section, our analysis is performed in the context of a population-based EA called (1 + \u03bb) EA. A case study on the BitMatchingD problem is given to show the general effects of population and time-variable mutation schemes."}, {"heading": "4.1 A General Result", "text": "The (1 + \u03bb) EA studied in this paper follows the concept presented in algorithm 2. The time-variable mutation programs for the (1 + \u03bb) EA, defined in definition 6, allow the EA to use different mutation rates in generating different offspring in the same generation. (EA) However, in solving BDOPs, such an EA scheme can still be inefficient if the displacement rate of a BDOP exceeds the number of proposed offspring (logn / n): Theorem 4. Given any BDOP with displacement rate (logn / n) and any time-variable mutation rate scheme {Pm (n, t), the displacement rate of a BDOP [0, 1 \u2212 1 / logn]: Theorem 4: Theorem. The first meeting time of the (1 + 1) EA is super-polynomial with overwhelming probability where the progeny size is a polynomial function of the n.The proof of the theorem 4 is a direct realization of the idea of the progeny 4."}, {"heading": "5 Discussions", "text": "In this section we will discuss some questions related to the theoretical results presented in previous sections."}, {"heading": "5.1 Generalizations of Theoretical Results", "text": "Here we discuss possible ways to generalize our theoretical results from different perspectives."}, {"heading": "5.1.1 What if the shifting rate of a DOP is also time-variable?", "text": "Technically, the theoretical results presented so far can be generalized to a broader class of DOPs. In particular, we can modify the definition of Bitwise Shifting Global Optimum (BSGO) (Definition 3) by allowing the global optimum to move at different shift rates in different DOP phases: Definition 13 (Bitwise Shifting Global Optimum with Time-variable Shifting Rate (BSGO-TSR). The global optimum of a DOP is referred to as BSGO-TSR when it shifts according to the \"t\" N rule: x \u0445 t + 1 = Bn, t (x), where Bn: {0, 1} n \u2192 {0, 1} n flips each bit of the input binary string with a probability of \u03c3 (t) - (0, 1 / 2] - and vice versa."}, {"heading": "5.1.2 Characterizing all forms of adaptations by condition-variable mutation rate schemes", "text": "In our theoretical analysis, which shows theoretical limitations of time-variable mutation rates, we avoid using the concrete values of mutation rates. Instead, we optimistically assume that an EA can always select the most promising mutation rates in each generation with the help of an oracle. Alternatively, such an idea can be characterized by explicitly incorporating complex information (e.g. fitness of current individuals) as conditions for specifying mutation rates, which is the definition of condition-variable mutation rates for (1 +) EA2: Definition 14 (condition-variable mutation rate for (1 +) EA: The condition-variable mutation rate of (1 + \u03bb) EA is a mapping rate for Pm: N \u00d7 {1,."}, {"heading": "5.2 Conjectures about (\u00b5+ \u03bb) EA", "text": "In the evolutionary computational community, the (\u00b5 + \u03bb) EAs obtained by \u00b5 parents and produced \u03bb offspring in each generation have been extensively studied over the last few decades. Apparently, the (\u00b5 + 1) and (1 + \u03bb) EAs studies in this paper are special cases of (\u00b5 + \u03bb) EAs. Having demonstrated the theoretical limitations of temporally variable mutation rate schemes for both EAs, the natural question is whether such theoretical results can be generalized to other (\u00b5 + \u03bb) EAs \"cases. Let us assume that each time-variable mutation scheme of a (\u00b5 + \u03bb) EA allows the algorithm to assume mutation rates (not necessarily different) in each generation of \u03bb offspring. In each of these EAs, we assume that the temporally variable mutation rate schemes do not help to operate efficiently when the shift rate of a BDOP exceeds a threshold."}, {"heading": "5.3 Impact of Population on Evolutionary Dynamic Optimization", "text": "In this paper, we examine both the (1 + 1) and (1 + \u03bb) EAs in such a way that the effects of the population can be demonstrated, the former being an individual-based EA, and the latter being a population-based EA that implements the Multiple Offspring Strategy (a concrete method of using the population). Our theoretical results clearly show the positive effects of the population on the performance of the EA in relation to BDOPs with significant shift rates. To be precise, in the absence of the Multiple Offspring Strategy, the largest shift rate of the BDOP class that one (1 + 1) EA can efficiently handle is (logn / n2) (theorems 1 and 3). After adopting the Multiple Offspring Strategy, the (1 + \u03bb) EA can efficiently solve the BitMatchingD problem, increasing the shift rate to an order of magnitude of \u2264 1 / (5n). In the field of evolutionary calculation, this is the first time that the positive effects in the context of evolutionary optimization are validated."}, {"heading": "5.4 Adaptation of Mutation Rate is not a Panacea", "text": "This paper examines the effectiveness of time-variable mutation rate schemes on two test beds, the (1 + 1) and (1 + \u03bb) EAs. For a BDOP whose global optimum is constantly shifting, one might expect that there is a time-variable mutation scheme that can help the EA to track the optimum by \"skillfully\" and dynamically selecting the appropriate mutation rate so that the mutation rates of an EA can \"match\" the stochastic motion of the global optimum. However, we show that there are classes of BDOPs where different time-variable mutation rate schemes cannot help to work efficiently. Furthermore, our theoretical analysis on a specific instance of the BDOP class called BitMatchingD has been generalized that the BitMatchingD optimum rate (when optimizing the BitMatchingD problem whose displacement rate exceeds the theoretical threshold (nlogn / 2) cannot be a time-variable variation rate."}, {"heading": "6 Conclusion and Future Work", "text": "In this paper, we theoretically examine the relationship between time-variable mutation rate schemes and the temporal complexity of EAs on a class of DOPs. Analytical results are given in terms of the initial hit time when finding the moving global optimum. By splitting the search space and estimating the transitions between the resulting subspaces (intervals), our analysis shows that when optimizing a class of DOPs, theoretical limitations exist for both (1 + 1) and (1 +) EAs with arbitrary time-variable mutation rates. Such theoretical results could lead to a new understanding of the role of mutation in solving DOPs: Although some specific time-variable mutation schemes have proven or validated to be helpful for some static optimization problems, it may not be advantageous to look for a sophisticated time-variable mutation rate scheme to improve the performance of EAs on many DOPs with moving global optimizations."}, {"heading": "A Analytical Tools", "text": "Before we provide the proof for Lemma 1 and Theorem 1, we must introduce a number of Lemmata. First, three mathematical tools from earlier literature are presented directly without proofs. Lemma 4 (Chernoff limits [35]). Let a1, a2,.., ak {0, 1} k be independent random variables with the same distribution."}, {"heading": "B Transition Lemmas with Proofs", "text": "B. 1 Transition LemmasBased on the three basic lemmas, the definitions and notations introduced in previous sections, we will present several \"transition lemmas\" (in relation to the transition probabilities between the various sub-intervals of [0, n], in responses to the DOP change and the mutation operator of EA (in relation to the transitions between the different intervals defined in Section 3, so that they are directly in the proofs of Lemmas 1 and 2, theorems 1 and 2. As a result, the above proofs can be significantly simplified. Considering the notations N (P) t, N (O) t and Nt defined in Section 4.2, the transition lemmas can be represented as follows: Lemma 7. Considering any BDOP with the two positions (logn / n) and considering the other BDOP positions (0, 1 / 2), considering the tth-generation (t), the tth-generation (t)."}, {"heading": "C Proofs of Lemmas 1 and 2, and Theorems 4 and 6", "text": "C.1 Lemmas 1 and 2The only difference between the proofs of Lemmas 1 and 2 is that is that the first number of matching bits) (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2. (2). (2). (2). (2). (2). (2. (2). (2). (2). (2). (2. (2). (2). (2). (2). (2. (2). (2). (2). (2. (2). (2). (2. (2). (2). (2). (2. (2). (2). (2). (2). (2. (2). (2). (2). (2. (2). (2). (2).). (2.). (2. (2.). (2.).). (2.). (2. (2.). (2.).). (2. (2.).). (2.).). (2. (2.). (2.).). (2.).)."}, {"heading": "D Proof of Theorems 1 and 2", "text": "The main difference between the proofs of theorems 1 and 2 is that the former use the result of Lemma 1 to restrict the analysis of the general BDOP class. < n (< n) < n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n n (n) n n (n) n (n) n (n) n (n) n (n) n (n) n (n) n n (n) n n (n) n n n (n) n n (n) n n n n (n) n n n n (n) n) n (n) n n n (n) n) n (n) n n n n (n) n) n (n) n n) n (n) n n (n) n) n (n) n) n (n) n) n (n) n) n (n) n) n n (n) n) n (n) n) n (n) n) n n (n) n) n n n (n) n (n) n) n (n) n) n (n) n) n (n) n n n n (n) n) n n (n) n (n) n) n (n) n (n) n n) n (n) n) n (n) n) n (n) n n) n (n (n) n) n) n (n) n (n) n) n (n) n (n) n (n) n) n (n) n (n) n) n (n) n) n (n) n (n) n) n (n) n) n (n) n (n) n) n (n) n (n) n) n) n (n) n (n) n) n (n)"}, {"heading": "Acknowledgements", "text": "The authors would like to thank Dr. Yang Yu for his constructive comments on this paper, which is supported in part by grants from the Natural Science Foundation of China (No. 61033009, No. 61028009, No. 61003064 and No. U0835002), the National S & T Major Project (No. 2010ZX01036-001-002) and a grant from the Engineering and Physical Science Research Council in the UK (No. EP / I010297 / 1)."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "Mutation has traditionally been regarded as an important operator in evolutionary algorithms. In particular, there have been many experimental studies which showed the effectiveness of adapting mutation rates for various static optimization problems. Given the perceived effectiveness of adaptive and self-adaptive mutation for static optimization problems, there have been speculations that adaptive and self-adaptive mutation can benefit dynamic optimization problems even more since adaptation and self-adaptation are capable of following a dynamic environment. However, few theoretical results are available in analyzing rigorously evolutionary algorithms for dynamic optimization problems. It is unclear when adaptive and self-adaptive mutation rates are likely to be useful for evolutionary algorithms in solving dynamic optimization problems. This paper provides the first rigorous analysis of adaptive mutation and its impact on the computation times of evolutionary algorithms in solving certain dynamic optimization problems. More specifically, for both individual-based and population-based EAs, we have shown that any time-variable mutation rate scheme will not significantly outperform a fixed mutation rate on some dynamic optimization problem instances. The proofs also offer some insights into conditions under which any time-variable mutation scheme is unlikely to be useful and into the relationships between the problem characteristics and algorithmic features (e.g., different mutation schemes).", "creator": "LaTeX with hyperref package"}}}