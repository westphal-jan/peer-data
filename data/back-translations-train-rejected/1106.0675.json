{"id": "1106.0675", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2011", "title": "The FF Planning System: Fast Plan Generation Through Heuristic Search", "abstract": "We describe and evaluate the algorithmic techniques that are used in the FF planning system. Like the HSP system, FF relies on forward state space search, using a heuristic that estimates goal distances by ignoring delete lists. Unlike HSP's heuristic, our method does not assume facts to be independent. We introduce a novel search strategy that combines hill-climbing with systematic search, and we show how other powerful heuristic information can be extracted and used to prune the search space. FF was the most successful automatic planner at the recent AIPS-2000 planning competition. We review the results of the competition, give data for other benchmark domains, and investigate the reasons for the runtime performance of FF compared to HSP.", "histories": [["v1", "Fri, 3 Jun 2011 14:55:02 GMT  (181kb)", "http://arxiv.org/abs/1106.0675v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["j hoffmann", "b nebel"], "accepted": false, "id": "1106.0675"}, "pdf": {"name": "1106.0675.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Bernhard Nebel"], "emails": ["hoffmann@informatik.uni-freiburg.de", "nebel@informatik.uni-freiburg.de"], "sections": [{"heading": null, "text": "In fact, most of them are able to survive themselves, and they are able to survive themselves, \"he told the German Press Agency in an interview with the\" Frankfurter Allgemeine Zeitung \"(Friday)."}], "references": [{"title": "Conditional e ects in Graphplan", "author": ["C.R. Anderson", "D.E. Smith", "D.S. Weld"], "venue": null, "citeRegEx": "Anderson et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Anderson et al\\.", "year": 1998}, {"title": "Subset of PDDL for the AIPS2000 Planning Competition", "author": ["F. Bacchus"], "venue": null, "citeRegEx": "Bacchus,? \\Q2000\\E", "shortCiteRegEx": "Bacchus", "year": 2000}, {"title": "Fast planning through planning graph analysis", "author": ["A.L. Blum", "M.L. Furst"], "venue": null, "citeRegEx": "Blum and Furst,? \\Q1995\\E", "shortCiteRegEx": "Blum and Furst", "year": 1995}, {"title": "Fast planning through planning graph analysis", "author": ["A.L. Blum", "M.L. Furst"], "venue": null, "citeRegEx": "Blum and Furst,? \\Q1997\\E", "shortCiteRegEx": "Blum and Furst", "year": 1997}, {"title": "HSP: Heuristic search planner", "author": ["B. Bonet", "H. Ge ner"], "venue": null, "citeRegEx": "Bonet and ner,? \\Q1998\\E", "shortCiteRegEx": "Bonet and ner", "year": 1998}, {"title": "Planning as heuristic search: New results", "author": ["B. Bonet", "H. Ge ner"], "venue": null, "citeRegEx": "Bonet and ner,? \\Q1999\\E", "shortCiteRegEx": "Bonet and ner", "year": 1999}, {"title": "Planning as heuristic search", "author": ["B. Bonet", "H. Ge ner"], "venue": null, "citeRegEx": "Bonet and ner,? \\Q2001\\E", "shortCiteRegEx": "Bonet and ner", "year": 2001}, {"title": "A robust and fast action selection", "author": ["B. Bonet", "G. Loerincs", "H. Ge ner"], "venue": null, "citeRegEx": "Bonet et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Bonet et al\\.", "year": 1997}, {"title": "The computational complexity of propositional STRIPS planning", "author": ["T. Bylander"], "venue": null, "citeRegEx": "Bylander,? \\Q1994\\E", "shortCiteRegEx": "Bylander", "year": 1994}, {"title": "Ordering problem subgoals", "author": ["J. Cheng", "K.B. Irani"], "venue": null, "citeRegEx": "Cheng and Irani,? \\Q1989\\E", "shortCiteRegEx": "Cheng and Irani", "year": 1989}, {"title": "Goal ordering in partially ordered plans", "author": ["M. Drummond", "K. Currie"], "venue": "In Sridha-", "citeRegEx": "Drummond and Currie,? \\Q1989\\E", "shortCiteRegEx": "Drummond and Currie", "year": 1989}, {"title": "Heuristic search planning with BDDs. In ECAI-Workshop: PuK", "author": ["S. Edelkamp"], "venue": null, "citeRegEx": "Edelkamp,? \\Q2000\\E", "shortCiteRegEx": "Edelkamp", "year": 2000}, {"title": "NP-completeness of several arrangement problems", "author": ["S. Even", "Y. Shiloach"], "venue": null, "citeRegEx": "Even and Shiloach,? \\Q1975\\E", "shortCiteRegEx": "Even and Shiloach", "year": 1975}, {"title": "STRIPS: A new approach to the application of theorem", "author": ["R.E. Fikes", "N. Nilsson"], "venue": null, "citeRegEx": "Fikes and Nilsson,? \\Q1971\\E", "shortCiteRegEx": "Fikes and Nilsson", "year": 1971}, {"title": "The automatic inference of state invariants in tim", "author": ["M. Fox", "D. Long"], "venue": null, "citeRegEx": "Fox and Long,? \\Q1998\\E", "shortCiteRegEx": "Fox and Long", "year": 1998}, {"title": "Hybrid STAN: Identifying and managing combinatorial op", "author": ["M. Fox", "D. Long"], "venue": null, "citeRegEx": "Fox and Long,? \\Q2001\\E", "shortCiteRegEx": "Fox and Long", "year": 2001}, {"title": "When gravity fails: Local search topology", "author": ["J. Frank", "P. Cheeseman", "J. Stutz"], "venue": null, "citeRegEx": "Frank et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Frank et al\\.", "year": 1997}, {"title": "Combining the expressiveness of UCPOP with", "author": ["B.C. Gazen", "C. Knoblock"], "venue": null, "citeRegEx": "Gazen and Knoblock,? \\Q1997\\E", "shortCiteRegEx": "Gazen and Knoblock", "year": 1997}, {"title": "A heuristic for domain independent planning and its use", "author": ["J. Ho mann"], "venue": null, "citeRegEx": "mann,? \\Q2000\\E", "shortCiteRegEx": "mann", "year": 2000}, {"title": "Local search topology in planning benchmarks: An empirical analysis", "author": ["J. Ho mann"], "venue": null, "citeRegEx": "mann,? \\Q2001\\E", "shortCiteRegEx": "mann", "year": 2001}, {"title": "Solving the entailment problem in the uent calculus", "author": ["orr", "H.-P"], "venue": null, "citeRegEx": "orr and H..P.,? \\Q2000\\E", "shortCiteRegEx": "orr and H..P.", "year": 2000}, {"title": "Subgoal ordering and goal augmentation for heuristic", "author": ["K.B. Irani", "J. Cheng"], "venue": null, "citeRegEx": "Irani and Cheng,? \\Q1987\\E", "shortCiteRegEx": "Irani and Cheng", "year": 1987}, {"title": "Planning - a randomized approach", "author": ["P. Jonsson", "P. Haslum", "C. B\u007fackstr\u007fom"], "venue": null, "citeRegEx": "Jonsson et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Jonsson et al\\.", "year": 2000}, {"title": "A theoretical analysis of conjunctive-goal problems", "author": ["D. Joslin", "J.W. Roach"], "venue": null, "citeRegEx": "Joslin and Roach,? \\Q1990\\E", "shortCiteRegEx": "Joslin and Roach", "year": 1990}, {"title": "Understanding and extending", "author": ["S. Kambhampati", "E. Parker", "E. Lambrecht"], "venue": null, "citeRegEx": "Kambhampati et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Kambhampati et al\\.", "year": 1997}, {"title": "Unifying SAT-based and graph-based planning", "author": ["H. Kautz", "B. Selman"], "venue": null, "citeRegEx": "Kautz and Selman,? \\Q1999\\E", "shortCiteRegEx": "Kautz and Selman", "year": 1999}, {"title": "Pushing the envelope: Planning, propositional logic", "author": ["H.A. Kautz", "B. Selman"], "venue": null, "citeRegEx": "Kautz and Selman,? \\Q1996\\E", "shortCiteRegEx": "Kautz and Selman", "year": 1996}, {"title": "Solving complex planning tasks through extraction of subproblems", "author": ["J. Koehler"], "venue": null, "citeRegEx": "Koehler,? \\Q1998\\E", "shortCiteRegEx": "Koehler", "year": 1998}, {"title": "On reasonable and forced goal orderings and their use", "author": ["J. Koehler", "J. Ho mann"], "venue": null, "citeRegEx": "Koehler and mann,? \\Q2000\\E", "shortCiteRegEx": "Koehler and mann", "year": 2000}, {"title": "On the instantiation of ADL operators involving", "author": ["J. Koehler", "J. Ho mann"], "venue": null, "citeRegEx": "Koehler and mann,? \\Q2000\\E", "shortCiteRegEx": "Koehler and mann", "year": 2000}, {"title": "Extending planning graphs", "author": ["J. Koehler", "B. Nebel", "J. Ho mann", "Y. Dimopoulos"], "venue": null, "citeRegEx": "Koehler et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Koehler et al\\.", "year": 1997}, {"title": "Elevator control as a planning problem", "author": ["J. Koehler", "K. Schuster"], "venue": null, "citeRegEx": "Koehler and Schuster,? \\Q2000\\E", "shortCiteRegEx": "Koehler and Schuster", "year": 2000}, {"title": "E cient implementation of the plan graph in stan", "author": ["D. Long", "M. Fox"], "venue": null, "citeRegEx": "Long and Fox,? \\Q1999\\E", "shortCiteRegEx": "Long and Fox", "year": 1999}, {"title": "Systematic nonlinear planning", "author": ["D.A. McAllester", "D. Rosenblitt"], "venue": null, "citeRegEx": "McAllester and Rosenblitt,? \\Q1991\\E", "shortCiteRegEx": "McAllester and Rosenblitt", "year": 1991}, {"title": "A heuristic estimator for means-ends analysis in planning", "author": ["D. McDermott"], "venue": null, "citeRegEx": "McDermott,? \\Q1996\\E", "shortCiteRegEx": "McDermott", "year": 1996}, {"title": "The PDDL Planning Domain De nition Language", "author": ["D McDermott"], "venue": null, "citeRegEx": "McDermott,? \\Q1998\\E", "shortCiteRegEx": "McDermott", "year": 1998}, {"title": "Using regression-match graphs to control search in planning", "author": ["D.V. McDermott"], "venue": null, "citeRegEx": "McDermott,? \\Q1999\\E", "shortCiteRegEx": "McDermott", "year": 1999}, {"title": "Hard and easy distributions of SAT", "author": ["D. Mitchell", "B. Selman", "H.J. Levesque"], "venue": null, "citeRegEx": "Mitchell et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 1992}, {"title": "On the compilability and expressive power of propositional planning", "author": ["B. Nebel"], "venue": null, "citeRegEx": "Nebel,? \\Q2000\\E", "shortCiteRegEx": "Nebel", "year": 2000}, {"title": "Ignoring irrelevant facts and operators", "author": ["B. Nebel", "Y. Dimopoulos", "J. Koehler"], "venue": null, "citeRegEx": "Nebel et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Nebel et al\\.", "year": 1997}, {"title": "ADL: Exploring the middle ground between STRIPS and the", "author": ["E.P. Pednault"], "venue": null, "citeRegEx": "Pednault,? \\Q1989\\E", "shortCiteRegEx": "Pednault", "year": 1989}, {"title": "GRT: a domain independent heuristic for STRIPS", "author": ["I. Refanidis", "I. Vlahavas"], "venue": null, "citeRegEx": "Refanidis and Vlahavas,? \\Q1999\\E", "shortCiteRegEx": "Refanidis and Vlahavas", "year": 1999}, {"title": "Exploiting state constraints in heuristic state-space", "author": ["I. Refanidis", "I. Vlahavas"], "venue": null, "citeRegEx": "Refanidis and Vlahavas,? \\Q2000\\E", "shortCiteRegEx": "Refanidis and Vlahavas", "year": 2000}, {"title": "Nonparametric Statistics for the Behavioral Sciences", "author": ["S. Siegel", "J.N.J. Castellan"], "venue": null, "citeRegEx": "Siegel and Castellan,? \\Q1988\\E", "shortCiteRegEx": "Siegel and Castellan", "year": 1988}, {"title": "Blocks world revisited", "author": ["J. Slaney", "S. Thiebaux"], "venue": "Arti cial Intelligence,", "citeRegEx": "Slaney and Thiebaux,? \\Q2001\\E", "shortCiteRegEx": "Slaney and Thiebaux", "year": 2001}], "referenceMentions": [{"referenceID": 38, "context": "Their paper started a whole series of research e orts that re ned this approach by making it even more e cient (Fox & Long, 1998; Kambhampati, Parker, & Lambrecht, 1997) and by extending it to cope with more expressive planning languages (Koehler, Nebel, Ho mann, & Dimopoulos, 1997; Gazen & Knoblock, 1997; Anderson, Smith, & Weld, 1998; Nebel, 2000).", "startOffset": 238, "endOffset": 351}, {"referenceID": 2, "context": "The rst approach was developed by Blum and Furst (1995, 1997). In their seminal paper on the GRAPHPLAN system (Blum & Furst, 1995), they described a new plan generation technique based on planning graphs, which was much faster than any other technique known at this time. Their paper started a whole series of research e orts that re ned this approach by making it even more e cient (Fox & Long, 1998; Kambhampati, Parker, & Lambrecht, 1997) and by extending it to cope with more expressive planning languages (Koehler, Nebel, Ho mann, & Dimopoulos, 1997; Gazen & Knoblock, 1997; Anderson, Smith, & Weld, 1998; Nebel, 2000). The second approach is the planning as satis ability method, which translates planning to propositional satis ability (Kautz & Selman, 1996). In particular there is the hope that advances in the state of the art of propositional reasoning systems carry directly over to planning systems relying on this technology. In fact, Kautz and Selman (1999) predicted that research on planning methods will become super uous because the state of the art in propositional reasoning systems will advance much faster than in planning systems.", "startOffset": 34, "endOffset": 973}, {"referenceID": 8, "context": "Planning is known to be PSPACE-complete even in its simplest form (Bylander, 1994).", "startOffset": 66, "endOffset": 82}, {"referenceID": 8, "context": "To some extent, this idea has been pursued by posing severe syntactical restrictions to the planning task speci cations (Bylander, 1994).", "startOffset": 120, "endOffset": 136}, {"referenceID": 27, "context": "{ The goal agenda technique, adapted from work by Jana Koehler (1998), feeds the goals to the planner in an order determined as a pre-process (Section 6.", "startOffset": 55, "endOffset": 70}, {"referenceID": 13, "context": "Notational Conventions For introducing FF's basic techniques, we consider simple STRIPS planning tasks, as were introduced by Fikes and Nilsson (1971). Our notations are as follows.", "startOffset": 126, "endOffset": 151}, {"referenceID": 8, "context": "As computing the optimal solution length to P 0 S| which would make an admissible heuristic|is NP-hard (Bylander, 1994), the HSP estimate is a rough approximation based on computing the following weight values.", "startOffset": 103, "endOffset": 119}, {"referenceID": 8, "context": "Proof: Hardness is proven by polynomially reducing PLANSAT (Bylander, 1994)|the decision problem of whether P is solvable|to the problem of deciding DEADEND-FREE.", "startOffset": 59, "endOffset": 75}, {"referenceID": 8, "context": "Proof: Hardness is proven by polynomially reducing PLANSAT (Bylander, 1994)|the decision problem of whether P is solvable|to the problem of deciding DEADEND-FREE. We simply add an operator to O that is executable in all states, and re-establishes the initial state. O1 := O [ foI := h;;I; [ o2O add(o) n Iig Applying oI to any state reachable in P leads back to the initial state: all facts that can ever become true are removed, and those in the initial state are added. Now, the modi ed problem P1 = (O1;I;G) is dead-end free i P is solvable. From left to right, if P1 is deadend free, then it is solvable, which implies that P is solvable, as we have not added any new possibility of reaching the goal. From right to left, if P is solvable, then also is P1, by the same solution plan P . One can then, from all states in P1, achieve the goal by going back to the initial state with the new operator, and executing P thereafter. Membership in PSPACE follows from the fact that PLANSAT and its complement are both in PSPACE. A non-deterministic algorithm that decides the complement of DEADENDFREE and that needs only polynomial space can be speci ed as follows. Guess a state S. Verify in polynomial space that S is reachable from the initial state. Further, verify that the goal cannot be reached from S. If this algorithm succeeds, it follows that the instance is not dead-end free|since S constitutes a dead end. This implies that DEADEND-FREE is in NPSPACE, and hence in PSPACE. 2 Though we can not e ciently decide whether a given task is dead-end free, there are easily testable su cient criteria in the literature. Johnsson et al. (2000) de ne a notion of symmetric planning tasks, which is su cient for dead-end freeness, but co-NP-complete.", "startOffset": 60, "endOffset": 1647}, {"referenceID": 8, "context": "Proof: Hardness is proven by polynomially reducing PLANSAT (Bylander, 1994)|the decision problem of whether P is solvable|to the problem of deciding DEADEND-FREE. We simply add an operator to O that is executable in all states, and re-establishes the initial state. O1 := O [ foI := h;;I; [ o2O add(o) n Iig Applying oI to any state reachable in P leads back to the initial state: all facts that can ever become true are removed, and those in the initial state are added. Now, the modi ed problem P1 = (O1;I;G) is dead-end free i P is solvable. From left to right, if P1 is deadend free, then it is solvable, which implies that P is solvable, as we have not added any new possibility of reaching the goal. From right to left, if P is solvable, then also is P1, by the same solution plan P . One can then, from all states in P1, achieve the goal by going back to the initial state with the new operator, and executing P thereafter. Membership in PSPACE follows from the fact that PLANSAT and its complement are both in PSPACE. A non-deterministic algorithm that decides the complement of DEADENDFREE and that needs only polynomial space can be speci ed as follows. Guess a state S. Verify in polynomial space that S is reachable from the initial state. Further, verify that the goal cannot be reached from S. If this algorithm succeeds, it follows that the instance is not dead-end free|since S constitutes a dead end. This implies that DEADEND-FREE is in NPSPACE, and hence in PSPACE. 2 Though we can not e ciently decide whether a given task is dead-end free, there are easily testable su cient criteria in the literature. Johnsson et al. (2000) de ne a notion of symmetric planning tasks, which is su cient for dead-end freeness, but co-NP-complete. They also give a polynomial su cient criterion for symmetry. This is, however, very trivial. Hardly any of the current benchmarks ful lls it. Koehler and Ho mann (2000a) have de ned notions of invertible planning tasks|su cient for dead-end freeness, and inverse actions| su cient for invertibility, under certain restrictions.", "startOffset": 60, "endOffset": 1922}, {"referenceID": 18, "context": "Fast Plan Generation Through Heuristic Search One could adopt Koehler and Ho mann's methodology, and use the existence of inverse actions to recognize dead-end free tasks. If the test fails, one could then employ a di erent search strategy than enforced hill-climbing. We have two reasons for not going this way: Even amongst our benchmarks, there are tasks that do not contain inverse actions, but are nevertheless dead-end free. An example is the Tireworld domain, where enforced hill-climbing leads to excellent results. Enforced hill-climbing can often quite successfully solve tasks that do contain dead ends, as it does not necessarily get caught in one. Examples for that are contained in the Mystery and Mprime domains, which we will look at in Section 8.2.1. The observation that forms the basis for our way of dealing with completeness is the following. If enforced hill-climbing can not solve a planning task, it usually fails very quickly. One can then simply switch to a di erent search algorithm. We have experimented with randomizing enforced hill-climbing, and doing a restart when one attempt failed. This didn't lead to convincing results. Though we tried a large variety of randomization strategies, we did not nd a planning task in our testing domains where one randomized restart did signi cantly better than the previous one, i.e., all attempts su ered from the same problems. The tasks that enforced hill-climbing does not solve right away are apparently so full of dead ends that one can not avoid those dead ends at random. We have therefore arranged our overall search strategy in FF as follows: 1. Do enforced hill-climbing until the goal is reached or the algorithm fails. 2. If enforced hill-climbing failed, skip everything done so far and try to solve the task by a complete heuristic search algorithm. In the current implementation, this is what Russel and Norvig (1995) term greedy best- rst search.", "startOffset": 77, "endOffset": 1903}, {"referenceID": 18, "context": "What one can ask in a situation like this is, was it a good idea to achieve G right now? Or should some other goal be achieved rst? Our answer is inspired by recent work of Koehler and Ho mann (2000a), which argues that achieving G should be postponed if the remaining goals can not be achieved without destroying G again.", "startOffset": 188, "endOffset": 201}, {"referenceID": 27, "context": "This is also the basic principle underlying the so-called \\goal agenda\" approach (Koehler, 1998).", "startOffset": 81, "endOffset": 96}, {"referenceID": 40, "context": "We will now show how our approach can be extended to deal with ADL (Pednault, 1989) tasks, more precisely, with the ADL subset of PDDL (McDermott et al.", "startOffset": 67, "endOffset": 83}, {"referenceID": 1, "context": ", 1998) that was used in the 2nd international planning systems competition (Bacchus, 2000).", "startOffset": 76, "endOffset": 91}, {"referenceID": 1, "context": "The planner starts with a planning task speci cation given in the subset of PDDL de ned for the AIPS-2000 planning competition (Bacchus, 2000).", "startOffset": 127, "endOffset": 142}, {"referenceID": 18, "context": "Hoffmann & Nebel list of parameters, a precondition, and a list of e ects. Instantiating the parameters yields, just like STRIPS tasks are usually speci ed, the actions to the schema. The precondition is an arbitrary ( rst order) formula. For an action to be applicable in a given state S, its instantiation of this formula must be satis ed in S. Each e ect i in the list has the form 8yi 0; : : : ; yi ni : ( i(o); addi(o);deli(o)) Here, yi 0; : : : ; yi ni are the e ect parameters, i(o) is the e ect condition|again, an arbitrary formula|and addi(o) and deli(o) are the atomic add and delete e ects, respectively. The atomic e ects are sets of uninstantiated atoms, i.e., relational symbols containing variables. The semantics are that, if an instantiated action is executed, then, for each single e ect i in the list, and for each instantiation of its parameters, the condition i(o) is evaluated. If i(o) holds in the current state, then the corresponding instantiations of the atoms in addi(o) are added to the state, and the instantiations of atoms in deli(o) are removed from the state. In FF's heuristic method, each single state evaluation can involve thousands of operator applications|building the relaxed planning graph, one needs to determine all applicable actions at each single fact layer. We therefore invest the e ort to compile the operator descriptions down into a much simpler propositional normal form, such that heuristic evaluation can be implemented e ciently. Our nal normal form actions o have the following format. Precondition: pre(o) E ects: (pre0(o); add0(o);del0(o)) ^ (pre1(o); add1(o);del1(o)) ^ ...(prem(o); addm(o);delm(o)) The precondition is a set of ground atoms. Likewise, the e ect conditions prei(o) of the single e ects are restricted to be ground atoms. We also represent the goal state as a set of atoms. Thus, we compile away everything except the conditional e ects. Compiling away the logical formulae involves transforming them into DNF, which causes an exponential blow up in general. In our testing domains, however, we found that this transformation can be done in reasonable time. Concerning the conditional e ects, those can not be compiled away without another exponential blow up, given that we want to preserve solution length. This was proven by Nebel (2000). As we will see, conditional e ects can e ciently be integrated into our algorithmic framework, so there is no need for compiling them away.", "startOffset": 4, "endOffset": 2317}, {"referenceID": 17, "context": "Following Gazen and Knoblock (1997), this process expands all quanti ers, and translates negations.", "startOffset": 10, "endOffset": 36}, {"referenceID": 17, "context": "Following Gazen and Knoblock (1997), this process expands all quanti ers, and translates negations. We end up with formulae that are made up out of conjunctions, disjunctions, and atoms containing variables. (b) Instantiate all parameters. This is simply done by instantiating all operator and e ect parameters with all type consistent constants one after the other. The process makes use of knowledge about static predicates, in the sense that the instantiated formulae can often be simpli ed (Koehler & Ho mann, 2000b). For example, if an instantiated static predicate (p ~a) occurs in a formula, and that instantiation is not contained in the initial state, then (p ~a) can be replaced with false. (c) Transform formulae into DNF. This is postponed until after instantiation, because it can be costly, so it should be applied to as small formulae as possible. In a fully instantiated formula, it is likely that many static or one-way predicate occurrences can be replaced by true or false, resulting in a much simpler formula structure. 3. Finally, if the DNF of any formula contains more than one disjunct, then the corresponding e ect, operator, or goal condition gets split up in the manner proposed by Gazen and Knoblock (1997). 7.", "startOffset": 10, "endOffset": 1235}, {"referenceID": 18, "context": "Hoffmann & Nebel plus o's preconditions need to be put into their corresponding goal sets. Afterwards, not only the e ect's own add e ects addi(o) are marked true at the time being, but also the added facts of all e ects that are implied, i.e., those e ects j of o with prej(o) prei(o) (in particular, this will be the unconditional e ects of o, which have an empty e ect condition). 7.3 ADL Pruning Techniques Both pruning techniques from Section 6 easily carry over to actions with conditional e ects. 7.3.1 Helpful Actions For STRIPS, we de ned as helpful all applicable actions achieving at least one goal at time step 1, cf. Section 6.1. For our ADL normal form, we simply change this to all applicable actions having an appearing e ect that achieves a goal at time step 1, where an e ect appears i its e ect condition is satis ed in the current state. H(S) := fo j pre(o) S;9i : prei(o) S ^ addi(o) \\G1(S) 6= ;g (6) 7.3.2 Added Goal Deletion Originally, we cut o a state S if one of the actions selected for the relaxed plan to S deleted a goal A that had just been achieved, cf. Section 6.2. We now simply take as criterion the e ects that are selected for the relaxed plan, i.e., a state is cut o if one of the e ects selected for its relaxed solution deletes a goal A that has just been achieved. 7.4 ADL State Transitions Finally, for enabling the search algorithms to handle our propositional ADL normal form, it is su cient to rede ne the state transition function. Forward search, no matter if it does hill-climbing, best- rst search, or whatsoever, always faces a completely speci ed search state.3 It can therefore compute exactly the e ects of executing a context dependent action. Following Koehler et al.(1997), we de ne our ADL state transition function Res, mapping states and ADL normal form actions to states, as follows.", "startOffset": 4, "endOffset": 1729}, {"referenceID": 11, "context": "These planners were FF, HSP2 (Bonet & Ge ner, 1998, 1999), System-R, GRT (Refanidis & Vlahavas, 1999), Mips (Edelkamp, 2000), and STAN (Long & Fox, 1999; Fox & Long, 2001).", "startOffset": 108, "endOffset": 124}, {"referenceID": 30, "context": "Apart from those planners already seen, we have runtime curves in Figure 6 for IPP (Koehler et al., 1997), PropPlan, and BDDPlan (H\u007folldobler & St\u007f orr, 2000).", "startOffset": 83, "endOffset": 105}, {"referenceID": 36, "context": "In Figure 9, we compare FF's results on both domains to that reported by Drew McDermott for the Unpop system (McDermott, 1999).", "startOffset": 109, "endOffset": 126}, {"referenceID": 36, "context": "Results for Unpop have been taken by McDermott on a 300 MHz Pentium-II workstation (McDermott, 1999).", "startOffset": 83, "endOffset": 100}, {"referenceID": 18, "context": "Koehler and Ho mann (2000a) modi ed the task such that an arbitrary number of n tires need to be replaced.", "startOffset": 15, "endOffset": 28}, {"referenceID": 39, "context": "The similarity of the helpful actions heuristic to McDermott's favored actions (1996), and to irrelevance detection mechanisms (Nebel et al., 1997).", "startOffset": 127, "endOffset": 147}, {"referenceID": 27, "context": "The inspiration of the added goal deletion heuristic by work done by Koehler and Ho mann (2000a), and the adaption of the goal agenda approach (Koehler, 1998).", "startOffset": 143, "endOffset": 158}, {"referenceID": 17, "context": "Hoffmann & Nebel on the other hand, randomly choose either ordering with equal probability. As said in Section 8.3.1, hill-climbing was given ve tries on each task, and results averaged. In ve tries, around half of the solutions use the correct ordering, such that, for all tasks, the average value is lower than the corresponding value for the enforced hill-climbing planners. Finally, we compare consideration of all actions versus consideration of only the helpful ones, results depicted in the rightmost four columns of Figure 12. Coming a bit unexpected, there is only one single case where solution length performance is degraded by turning on helpful actions. This indicates that the actions on the shortest path to the goal are, in fact, usually considered helpful|unless all solution paths are thrown away, as is sometimes the case only in the Briefcaseworld and Bulldozer domains. Quite the other way around than one should think, pruning the search space with helpful actions sometimes leads to signi cantly shorter solution plans, especially when the underlying search method is hillclimbing. Though this may sound paradoxical, there is a simple explanation to it. Consider what we said above about the plateau behavior of hill-climbing, randomly adding actions to the current plan in the search for a better state. If such a search engine is armed with the helpful actions successors choice, focusing it into the direction of the goals, it might well take less steps to nd the way o a plateau. 9. Related Work The most important connections of the FF approach to methodologies reported in the literature are the following: HSP's basic idea of forward state space search and heuristic evaluation by ignoring delete lists (Bonet & Ge ner, 1998). The view of our heuristic as a special case of GRAPHPLAN (Blum & Furst, 1995), and its connection to HSP's heuristic method. The similarity of the helpful actions heuristic to McDermott's favored actions (1996), and to irrelevance detection mechanisms (Nebel et al.", "startOffset": 4, "endOffset": 1968}, {"referenceID": 17, "context": "Hoffmann & Nebel on the other hand, randomly choose either ordering with equal probability. As said in Section 8.3.1, hill-climbing was given ve tries on each task, and results averaged. In ve tries, around half of the solutions use the correct ordering, such that, for all tasks, the average value is lower than the corresponding value for the enforced hill-climbing planners. Finally, we compare consideration of all actions versus consideration of only the helpful ones, results depicted in the rightmost four columns of Figure 12. Coming a bit unexpected, there is only one single case where solution length performance is degraded by turning on helpful actions. This indicates that the actions on the shortest path to the goal are, in fact, usually considered helpful|unless all solution paths are thrown away, as is sometimes the case only in the Briefcaseworld and Bulldozer domains. Quite the other way around than one should think, pruning the search space with helpful actions sometimes leads to signi cantly shorter solution plans, especially when the underlying search method is hillclimbing. Though this may sound paradoxical, there is a simple explanation to it. Consider what we said above about the plateau behavior of hill-climbing, randomly adding actions to the current plan in the search for a better state. If such a search engine is armed with the helpful actions successors choice, focusing it into the direction of the goals, it might well take less steps to nd the way o a plateau. 9. Related Work The most important connections of the FF approach to methodologies reported in the literature are the following: HSP's basic idea of forward state space search and heuristic evaluation by ignoring delete lists (Bonet & Ge ner, 1998). The view of our heuristic as a special case of GRAPHPLAN (Blum & Furst, 1995), and its connection to HSP's heuristic method. The similarity of the helpful actions heuristic to McDermott's favored actions (1996), and to irrelevance detection mechanisms (Nebel et al., 1997). The inspiration of the added goal deletion heuristic by work done by Koehler and Ho mann (2000a), and the adaption of the goal agenda approach (Koehler, 1998).", "startOffset": 4, "endOffset": 2128}, {"referenceID": 17, "context": "The adaption of IPP's ADL preprocessing phase (Koehler & Ho mann, 2000b), inspired by ideas from Gazen and Knoblock (1997). We have discussed all of these connections in the respective sections already.", "startOffset": 97, "endOffset": 123}], "year": 2011, "abstractText": null, "creator": "dvipsk 5.58f Copyright 1986, 1994 Radical Eye Software"}}}