{"id": "1106.1770", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2011", "title": "Reinforcement learning based sensing policy optimization for energy efficient cognitive radio networks", "abstract": "This paper introduces a machine learning based collaborative multi band spectrum sensing policy for cognitive radios. The proposed sensing policy guides secondary users to focus the search of unused radio spectrum to those frequencies that persistently provide them high data rate. The proposed policy is based on machine learning, which makes it adaptive with the temporally and spatially varying radio spectrum. Furthermore, there is no need for dynamic modeling of the primary activity since it is implicitly learned over time. Energy efficiency is achieved by minimizing the number of assigned sensors per each subband under a constraint on miss detection probability. It is important to control the missed detections because they cause collisions with primary transmissions and lead to retransmissions at both the primary and secondary user. The minimization of the number of active sensors is formulated as a binary integer programming problem. Simulations show that the proposed machine learning based sensing policy improves the overall throughput of the secondary network and improves the energy efficiency while controlling the miss detection probability.", "histories": [["v1", "Thu, 9 Jun 2011 10:40:08 GMT  (441kb,D)", "https://arxiv.org/abs/1106.1770v1", "10 pages, 13 figures, Submitted to Neurocomputing June 2011"], ["v2", "Wed, 27 Jul 2011 11:08:21 GMT  (753kb,D)", "http://arxiv.org/abs/1106.1770v2", "10 pages, 13 figures, Accepted to Neurocomputing special issue: MLSP 2011"], ["v3", "Tue, 4 Oct 2011 06:02:16 GMT  (586kb,D)", "http://arxiv.org/abs/1106.1770v3", "10 pages, 13 figures, Accepted to Neurocomputing special issue: Machine learning for signal processing, 2011"]], "COMMENTS": "10 pages, 13 figures, Submitted to Neurocomputing June 2011", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jan oksanen", "jarmo lund\\'en", "visa koivunen"], "accepted": false, "id": "1106.1770"}, "pdf": {"name": "1106.1770.pdf", "metadata": {"source": "CRF", "title": "Reinforcement learning based sensing policy optimization for energy efficient cognitive radio networks", "authors": ["Jan Oksanena", "Jarmo Lund\u00e9na", "Visa Koivunena"], "emails": ["jhoksane@wooster.hut.fi", "jrlunden@wooster.hut.fi", "visa@wooster.hut.fi"], "sections": [{"heading": null, "text": "The proposed policy is based on machine learning and is therefore adaptable to the temporally and spatially varying radio spectrum. In addition, there is no need for dynamic modelling of primary activity as it is implicitly learned over time. Energy efficiency is achieved by minimising the number of sensors assigned per subband while limiting the probability of error detection. It is important to control missed detections as they cause collisions with primary transmissions and lead to retransmissions for both primary and secondary users. Simulations show that the proposed policy of machine learning based on sensors improves the overall throughput of the secondary network and improves energy efficiency while controlling the probability of error detection.Keywords: cognitive radio, frequency hopping, machine learning, sensory diversity, spatial sensors, sensor sensing sensors"}, {"heading": "1. Introduction", "text": "Increasing demand for wireless services has made usable radio spectrum a scarce and costly resource. Part of the problem is spectrum allocation, which does not take advantage of the fact that the state of the radio spectrum varies in time and location. Measurements have shown that large parts of the spectrum are underutilized because licensees do not use the spectrum, or because the radio signals are able to attenuate in 2-4 dimensions that are not fully utilized."}, {"heading": "1.1. Contribution of the paper", "text": "This paper provides for the reinforcement of multi-user learning."}, {"heading": "2. Related work", "text": "The term restless stems from the fact that the states of the unplayed machines can also change; much like the state of the unfelt frequency bands can change in a CR environment. In [3, 7-13] Spectrum scanning strategies are derived based on the framework of partially observable Markov decision processes (POMDPs). In [13] a closed form, Whittle index policy for perfectly known Markovian reward distributions has been derived and demonstrated to be optimal under certain conditions. In a case where the player has no prior knowledge of the reward distributions of the different machines (or, as in this case, the throughputs of the different frequency bands), it is impossible to derive optimal measures."}, {"heading": "3. System model", "text": "The SU network consists of NS cooperating wireless SU terminals that capture the radio spectrum. Depending on the front-end design of the SU device, an SU up to Ks sub-band may make sense at a given time. In this paper, it is assumed that the SUs cooperate by sending their local binary decisions to a FC that makes a global decision on the availability of the spectrum for all SUs. This results in spatial diversity and increased scanning speed. Spatial diversity is achieved when multiple SUs simultaneously perceive the same part of the spectrum from different locations and then make a global decision. Scanning speed is increased as each SU can obtain information on the availability of the spectrum for all SUs sub-bands at the same time."}, {"heading": "4. Reinforcement learning based sensing policy", "text": "In the PU network, as in most communication systems, the traffic load can vary depending on time and location. For example, the expected amount of available radio spectrum for opportunistic secondary use during peak hours and densely populated areas may be much lower than at night and in rural areas. Radio channel conditions also vary in time depending on location, speed and frequency. Therefore, the conception of a sensor policy for the Czech Republic as a dynamic problem must be addressed."}, {"heading": "4.1. The -greedy method", "text": "The -greedy policy is an ad hoc method that strikes a balance between exploration and exploitation by selecting the action that has the highest estimated action value, i.e. \u03b1 k = arg maxaQk (a), with the probability of 1 \u2212 or a random action, uniformly, with the probability of being estimated independently of the action value [15]. The -greedy method is a simple and robust method that has low computing and storage requirements. The random exploration phase allows the random action selections to be replaced by carefully designed pseudorandom action selections with desired properties, which is detailed in Section 4.2.1.After actions are taken, a reward r (a) is collected, after which the Q value of the action a is updated as [15] Qk + 1 (a) = Qk (a) + esk (a)."}, {"heading": "4.2. The proposed sensing policy", "text": "In this paper, we propose a sensitivity policy with -greedy exploration for the selection of the frequency to capture subbands and for the selection of the corresponding sampling in a CR network. The policy is administered by the FC, which has two types of Q values: the Q values for the subbands and the Q values for all subbands. A natural way to capture the reward rk + 1 (b) for the selection of subband b is the throughput obtained: rk + 1 (b) when B is accessed and is free when B is occupied, (4) where Rk + 1 (b) is the instantaneous throughput on subband b. In this paper, it is assumed that the SU that has been granted permission to access the band and that is free."}, {"heading": "4.2.1. Exploration", "text": "In this section, the pseudo-andom frequency hopping based sensing policy is briefly summarised in [20] q, since it represents the exploration phase of the sensor politics developed in this paper. The pseudo-andom frequency hopping based sensing policy offers a quick sampling of the spectrum of interests with minimal signalisation of control, whereby it is extremely well suited for researching the spectrum. The frequency hopping code design makes it possible to trade in the sampling speed and diversity (and consequently the detector power) in an elegant manner. Furthermore, the desired order of diversity D is guaranteed, whereby the reliable performance is ensured in demanding expansion environments. In the pseudo-andom frequency hopping based multi-band sensing spectrum sensing policy is in design and assignment pseudo-andom frequency hopping codes S, which guides the subbandits, the subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbanbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, subbandits, frequency hopping based multi-band, spectrum sensing policy is in design and assignment pseudo-andom frequency hopping frequency hopping, subbandits, subbanbanbanbandits, subbanden, subbandits, subbanbanbandits, subbanden, subbandits, subbandits, subbanden, subbandits, subbandits, subbandits, subbandits, the subbandits, subbandits,"}, {"heading": "4.2.2. Exploitation", "text": "In many practical scenarios, the cooperating SUs, even though they are close to each other, can be used in very different channel conditions as they fade. Then, the cooperation between the SUs can be better optimized to save energy of the SUs. Suppose that the secondary network of NS SUs wants to generate a high reward (throughput) for the SU network in the hope of spectral opportunities. Let's denote the set of all selected L subband indices as B and the set of all SU indices as S. In addition, we assume that the SU network has knowledge of the SUs probabilities of detecting Psb, where s, S and b, B, B, B to obtain the energy of the SUs, which we would like to minimize the number of SUs allocated for sensing while guaranteeing a desired level of recognition performance on the bands of interest."}, {"heading": "4.2.3. Sensing assignment for the OR-fusion rule", "text": "In fact, it is as if it were an unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen, unforeseen,"}, {"heading": "4.3. SU Q-value and the local detection probability", "text": "The solution of the optimization problem of (7) requires the estimation of the probabilities of missed recognition at the FC = = = = = = For the definition of the reward as in (5), a simple estimation of the detection probabilities of the SUs results at the same time. As the SU Q values are updated according to Equation (1) similar to the Q values of the subband, it can be shown that the asymptotically expected Q values E [Qk (s, b)] correspond to the expected detection probability as k \u2192 \u221e. Equation (5) shows that E [Qk + 1 (s, b)] the detection probability E [Qk (s, b)] and getlim k \u2022 the probability E [Qk + 1 (s, b)] the expected reward as k."}, {"heading": "4.4. Convergence of the subband Q-values", "text": "Since all subbands are not necessarily captured all the time, we have to introduce another time variable Tk (b) b (b) \u2264 Q (b), which indicates the number of sensor instances (and value updates) in band b until the last run of the greedy algorithm. A regrouping of the components in Equation (1) the Q value of subband b can be expressed as a QTk value (b) + 1 (b) = (1 \u2212 \u03b1) QTk (b) (b) + (b), with the expectation of both sides leading to E [QTk (b) + 1 (b) + 1 (b \u2212 \u03b1) E [QTk (b) + p \u2212 p \u2212 b), where \u00b5 (b) = E [rk) is a linear repetition, the solution of which is given by E [QTk) (b), + 1 (b)."}, {"heading": "5. Simulation examples", "text": "This section presents the simulation results for the proposed sensor policy, focusing on the obtained throughput of the secondary network and the error detection probability."}, {"heading": "5.1. Stationary case", "text": "This subsection provides the results for a stationary scenario in which the occupancy statistics of the primary bands remain constant throughout the entire simulation period; the results are shown for the throughput, average detection probability and relative number of sensations in the SU network with different values of. Furthermore, the simulations are used for comparison with the exact BB search and an approximate iterative Hungarian (IH) method used by [22]. In the stationary case, the mean detection performance of the SUs remains constant; the simulations are performed for NS = 6 SUs and NP = 10 primary subbands; the availability of each subband is modeled according to a two-step Markov chain (see Figure 4) with state probabilities P00 = P00. Different subbands are assumed to be independent of each other; the mean SNRs of the primary signal in the secondary network are assumed to be distributed according to the log normal shadow model with a standard deviation of B9."}, {"heading": "5.2. Expected throughput for non-stationary cases", "text": "For a non-stationary scenario, the throughput of the proposed sensor policy is compared with two other methods = 51 = simultaneously.The results are shown only for the first stage of the proposed sensor policy, which attempts to maximize the throughput of the secondary network.The results are shown for a case where the availability of the sub-bands is Markov process and for a case where the availability is a Bernoulli process (i.e. a specific case of a two-state Markov chain).In addition, the proposed policy is compared with two other state-of-the-art strategies, namely the comparison against the discounted UCB (DUCB) policy with a discount factor. [17] and a near-optimal sensor policy [13], the Whittle Index policy, which assumes the state transitional probabilities in the Markov chain to be known. The comparison between the Whittle Index policy and the two Machine Learning-based strategies is performed."}, {"heading": "6. Conclusions", "text": "This paper proposes a policy of multi-band frequency detection based on machine learning. In the proposed policy, the greedy method is used to track the occupancy statistics of the PU and to estimate the detection performance of the SUs. With the greedy method, the proposed policy uses the knowledge gained about the throughputs of the different subbands by selecting the identified subbands as those with the highest Q value. Furthermore, the knowledge about the detection performance of the different SUs is utilized by minimizing the number of SUs allocated for detection, which are collectively able to achieve a desired detection probability threshold. In addition, the research of the radio spectrum and the different detection assignments are realized by means of pseudo-landomer frequency hopping codes with fixed diversity sequence. Firstly, pseudo-andom detection with fixed diversity order guarantees a reliable detection of all the probability and the probability of the D in the final analysis."}], "references": [{"title": "Implementation Issues in Spectrum Sensing for Cognitive Radios", "author": ["D. Cabric", "S.M. Mishra", "R.W. Brodersen"], "venue": "in: Proc. of the Asilomar Conference on Signals, Systems and Computers, vol. 1, 772\u2013776", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Cognitive Radio: Brain-Empowered Wireless Communications", "author": ["S. Haykin"], "venue": "IEEE J. Sel. Areas Commun. 23 (2) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "A Survey of Dynamic Spectrum Access", "author": ["Q. Zhao", "B.M. Sadler"], "venue": "IEEE Signal Process. Mag. 24 (3) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Collaborative Cyclostationary Spectrum Sensing for Cognitive Radio Systems", "author": ["J. Lund\u00e9n", "V. Koivunen", "A. Huttunen", "H.V. Poor"], "venue": "IEEE Trans. Signal Process. 57 (11) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Autocorrelation-Based Decentralized Sequential Detection of OFDM Signals in Cognitive Radios", "author": ["S. Chaudhari", "V. Koivunen", "H.V. Poor"], "venue": "IEEE Trans. Signal Process. 57 (7) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Reinforcement Learning Method for Energy Efficient Cooperative Multiband Spectrum Sensing", "author": ["J. Oksanen", "J. Lund\u00e9n", "V. Koivunen"], "venue": "in: Proc. of the MLSP Conference, Kittil\u00e4, Finland, 59\u201364", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "On Myopic Sensing for Multi-Channel Opportunistic Access: Structure", "author": ["Q. Zhao", "B. Krishnamachari", "K. Liu"], "venue": "Optimality and Performance, IEEE Trans. Wireless Commun. ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Opportunistic Spectrum Access via Periodic Channel Sensing", "author": ["Q. Zhao", "S. Geirhofer", "L. Tong", "B.M. Sadler"], "venue": "IEEE Trans. Signal Process. 56 (2) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Decentralized Cognitive MAC for Opportunistic Spectrum Access in Ad Hoc Networks: A POMDP Framework", "author": ["Q. Zhao", "L. Tong", "A. Swami", "Y. Chen"], "venue": "IEEE J. Sel. Areas Commun. 25 (3) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "A Near Optimal Policy for Channel Allocation in Cognitive Radio", "author": ["S. Filippi", "O. Capp\u00e9", "F. Cl\u00e9rot", "E. Moulines"], "venue": "in: Proc. of the EWRL workshop, 69\u201381", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Cooperation and Learning in Multiuser Opportunistic Spectrum Access", "author": ["H. Liu", "B. Krishnamachari", "Q. Zhao"], "venue": "in: Proc. of ICC Workshops, 487\u2013492", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Dynamic Multichannel Access With Imperfect Channel State Detection", "author": ["K. Liu", "Q. Zhao", "B. Krishnamachari"], "venue": "IEEE Trans. Signal Process. 58 (5) ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Indexability of Restless Bandit Problems and Optimality of Whittle Index for Dynamic Multichannel Access", "author": ["K. Liu", "Q. Zhao"], "venue": "IEEE Trans. Inf. Theory 56 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Technical Note: Q-Learning", "author": ["C. Watkins", "P. Dayan"], "venue": "Machine Learning 8 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1992}, {"title": "Reinforcement Learning: An Introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "Cambridge, MA: MIT Press", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "Finite-time Analysis of the Multiarmed Bandit Problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning 47 ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Discounted-UCB", "author": ["L. Kocsis", "C. Szepesv\u00e1ri"], "venue": "in: 2nd PASCAL Challenges Workshop", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "M", "author": ["U. Berthold", "F. Fu"], "venue": "van der Schaar, F. Jondral, Detection of Spectral Resources in Cognitive Radios Using Reinforcement Learning, in: Proc. of DySPAN, 1\u20135", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Capacity of Burst-noise Channels", "author": ["E.N. Gilbert"], "venue": "Bell Syst. Tech. J. 39 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1960}, {"title": "Diversitybased Spectrum Sensing Policy for Detecting Primary Signal Over Multiple Frequency Bands", "author": ["J. Oksanen", "V. Koivunen", "J. Lund\u00e9n", "A. Huttunen"], "venue": "in: Proc. of the ICASSP Conference, Dallas Texas, 3130\u20133133", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "An Iterative Hungarian Algorithm Based Coordinated Spectrum Sensing Strategy", "author": ["Z. Wang", "Z. Feng", "P. Zhang"], "venue": "IEEE Commun. Lett. 15 (1) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "The Hungarian Method for the Assignment Problem", "author": ["H.W. Kuhn"], "venue": "Naval Res. Logistics Q. 2 ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1955}], "referenceMentions": [{"referenceID": 0, "context": "Measurement campaigns [1] have in fact shown that large parts of the spectrum are underutilized because the license holders are not using the spectrum or because the fact that wireless signals attenuate in 2\u2212 4 power of distance is not fully exploited.", "startOffset": 22, "endOffset": 25}, {"referenceID": 1, "context": "Identifying temporal and spatial spectrum holes has been the key motivation behind cognitive radio (CR) and dynamic spectrum access (DSA) [2].", "startOffset": 138, "endOffset": 141}, {"referenceID": 2, "context": "interfered by the PU [3].", "startOffset": 21, "endOffset": 24}, {"referenceID": 1, "context": "In order to mitigate the effects of fading, cooperative detection schemes have been proposed in the literature [2, 4, 5].", "startOffset": 111, "endOffset": 120}, {"referenceID": 3, "context": "In order to mitigate the effects of fading, cooperative detection schemes have been proposed in the literature [2, 4, 5].", "startOffset": 111, "endOffset": 120}, {"referenceID": 4, "context": "In order to mitigate the effects of fading, cooperative detection schemes have been proposed in the literature [2, 4, 5].", "startOffset": 111, "endOffset": 120}, {"referenceID": 5, "context": "Some preliminary ideas and results related to this paper were presented in [6].", "startOffset": 75, "endOffset": 78}, {"referenceID": 2, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 6, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 7, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 8, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 9, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 10, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 11, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 12, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 12, "context": "In [13] a closed form Whittle index policy for perfectly known Markovian reward distributions was derived and shown to be optimal under certain conditions.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "A standard method for tackling multi-armed bandit problems is the Q-learning algorithm [14] with -greedy exploration [15].", "startOffset": 87, "endOffset": 91}, {"referenceID": 14, "context": "A standard method for tackling multi-armed bandit problems is the Q-learning algorithm [14] with -greedy exploration [15].", "startOffset": 117, "endOffset": 121}, {"referenceID": 15, "context": "Namely, in [16] a simple policy based on upper confidence bounds (UCB) was proposed and shown to reach the optimal regret rate when the rewards are independent and stationary.", "startOffset": 11, "endOffset": 15}, {"referenceID": 16, "context": "An UCB policy that suits better for non-stationary rewards was developed in [17].", "startOffset": 76, "endOffset": 80}, {"referenceID": 17, "context": "In [18] a single-user reinforcement learning method was proposed for selecting between 3 future actions: continuing sensing at the current frequency band b and transmitting data, sensing an out-of-band frequency band b\u0303, and switching the SU system to an out-of-band frequency band b\u0303.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "One proposed approach to model the PU activity is a two-state Markov chain shown in figure 4 [9].", "startOffset": 93, "endOffset": 96}, {"referenceID": 18, "context": "Figure 4: The Gilbert-Elliot channel model [19].", "startOffset": 43, "endOffset": 47}, {"referenceID": 14, "context": "ak = arg maxaQk(a), with probability 1\u2212 , or a random action, uniformly, with probability regardless of the action-value estimates [15].", "startOffset": 131, "endOffset": 135}, {"referenceID": 14, "context": "After taking action a reward r(a) is collected after which the Q-value of action a is updated as [15]", "startOffset": 97, "endOffset": 101}, {"referenceID": 14, "context": "In a stationary scenario convergence is guaranteed with probability 1 when the step size parameter \u03b1k satisfies the following conditions [15]", "startOffset": 137, "endOffset": 141}, {"referenceID": 14, "context": "[15]", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "In this section the pseudorandom frequency hopping based sensing policy proposed in [20] is briefly summarized, since it constitutes the exploration phase of the sensing policy developed in this paper.", "startOffset": 84, "endOffset": 88}, {"referenceID": 19, "context": "For more information about the choice of \u2206q and the design of the frequency hopping sequences as well as simulation results see [20].", "startOffset": 128, "endOffset": 132}, {"referenceID": 20, "context": "In [22] an iterative Hungarian algorithm is proposed to find a sensing assignment that minimizes the probability of miss detection.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "The policy assigns SUs to sense the subbands one by one using the Hungarian method [23].", "startOffset": 83, "endOffset": 87}, {"referenceID": 20, "context": "In our problem formulation, the Hungarian method can be employed iteratively, similarly to [22], to find a near optimal solution for the SAP with ws = 1 by modifying the algorithm to stop immediately once a feasible solution is found.", "startOffset": 91, "endOffset": 95}, {"referenceID": 20, "context": "Furthermore, the simulations are shown for comparison using the exact BB search and an approximative iterative Hungarian (IH) method adapted from [22].", "startOffset": 146, "endOffset": 150}, {"referenceID": 16, "context": "Namely, the comparison is done against the discounted UCB (DUCB) policy with a discount factor \u03b3 [17] and a near-optimal sensing policy [13], the Whittle index policy, that assumes the state transition probabilities in the Markov chain to be known.", "startOffset": 97, "endOffset": 101}, {"referenceID": 12, "context": "Namely, the comparison is done against the discounted UCB (DUCB) policy with a discount factor \u03b3 [17] and a near-optimal sensing policy [13], the Whittle index policy, that assumes the state transition probabilities in the Markov chain to be known.", "startOffset": 136, "endOffset": 140}, {"referenceID": 10, "context": "The mean throughputs of the bands bands are [11, 21, 31, 41, 51].", "startOffset": 44, "endOffset": 64}], "year": 2011, "abstractText": "This paper introduces a machine learning based collaborative multi-band spectrum sensing policy for cognitive radios. The proposed sensing policy guides secondary users to focus the search of unused radio spectrum to those frequencies that persistently provide them high data rate. The proposed policy is based on machine learning, which makes it adaptive with the temporally and spatially varying radio spectrum. Furthermore, there is no need for dynamic modeling of the primary activity since it is implicitly learned over time. Energy efficiency is achieved by minimizing the number of assigned sensors per each subband under a constraint on miss detection probability. It is important to control the missed detections because they cause collisions with primary transmissions and lead to retransmissions at both the primary and secondary user. Simulations show that the proposed machine learning based sensing policy improves the overall throughput of the secondary network and improves the energy efficiency while controlling the miss detection probability.", "creator": "LaTeX with hyperref package"}}}