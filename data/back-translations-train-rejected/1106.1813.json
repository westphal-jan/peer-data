{"id": "1106.1813", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2011", "title": "SMOTE: Synthetic Minority Over-sampling Technique", "abstract": "An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of \"normal\" examples with only a small percentage of \"abnormal\" or \"interesting\" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.", "histories": [["v1", "Thu, 9 Jun 2011 13:53:42 GMT  (229kb)", "http://arxiv.org/abs/1106.1813v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["n v chawla", "k w bowyer", "l o hall", "w p kegelmeyer"], "accepted": false, "id": "1106.1813"}, "pdf": {"name": "1106.1813.pdf", "metadata": {"source": "CRF", "title": "SMOTE: Synthetic Minority Over-sampling Technique", "authors": ["Nitesh V. Chawla", "Kevin W. Bowyer", "Philip Kegelmeyer"], "emails": ["chawla@csee.usf.edu", "kwb@cse.nd.edu", "hall@csee.usf.edu", "wpk@california.sandia.gov"], "sections": [{"heading": "1. Introduction", "text": "Most of them are able to survive themselves, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own."}, {"heading": "2. Performance Measures", "text": "In the confusion matrix, TN is the number of negative examples that may have been correctly classified (True Negatives), FP is the number of negative examples that have been wrongly classified as positive (False Positives), FN is the number of positive examples that have been correctly classified (True Positives), Predictive Accuracy is the number of positive examples that have been correctly classified (True Positives), Predictive Accuracy is the number that is commonly associated with machine learning algorithms and Accuracy = (TP + FP + FN), and TP is the number of positive examples that have been correctly classified (True Positives). Predictive Accuracy is the number that is commonly associated with machine learning algorithms and Accuracy = (TP + FP + FN). In the context of balanced data sets and equal error costs, it is reasonable to use error rates as a performance indicator."}, {"heading": "3. Previous Work: Imbalanced datasets", "text": "eSi rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "4. SMOTE: Synthetic Minority Over-sampling TEchnique", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Minority over-sampling with replacement", "text": "Previous research (Ling & Li, 1998; Japkowicz, 2000) has discussed the oversample by substitution and found that it does not significantly improve the recognition of minorities. We interpret the underlying effect with respect to decision regions in the trait space. As the minority class is oversampled by increasing amounts, the effect is to identify similar but more specific regions in the trait space as decision regions for the minority class. This effect for decision trees can be seen from the diagrams in Figure 3. Data for the chart in Figure 3 were extracted from a mammography dataset 1 (Woods et al., 1993). Minority samples are represented by + and majority samples are represented by o in the diagram. In Figure 3 (a), the region indicated by the rectangle executed is a majority class decision region. Nevertheless, it contains three minority samples that \"cause a decision to be very specific to the decision class\" and \"we are represented as a\" negative for the previous decision. \""}, {"heading": "4.2 SMOTE", "text": "We propose an over-sampling approach, in which the minority class is trampled by creating \"synthetic\" examples rather than by over-sampling with substitutes, inspired by a technique that has proven successful in handwritten character recognition (Ha & Bunke, 1997), which created additional training data by performing specific samples on real data. In their case, operations such as rotation and skew were performed naturally to alter training data. We generate synthetic examples in a less application-specific manner by operating in \"feature space\" rather than \"minority sample.\" The minority class is sampled by taking each minority class and introducing synthetic examples along the line that connect to all segments of the minority class that join the nearest neighbors. Depending on the amount of over-sampling required, neighbors from the nearest neighbors are randomly selected and our next five neighbors are currently being implemented."}, {"heading": "4.3 Under-sampling and SMOTE Combination", "text": "When describing our experiments, our terminology will be such that if we evaluate the majority class at 200% sample, the majority class will end up with 25 samples. By using a combination of subsamples and oversamples, the learner's initial bias against the negative (majority) class will be reversed in favor of the positive (minority) class."}, {"heading": "5. Experiments", "text": "We used three different machine learning algorithms for our experiments. Figure 6 provides an overview of our experiments. 1. C4.5: We compared different combinations of SMOTE and sub-sampling with simple sub-sampling using C4.5 Release 8 (Quinlan, 1992) as the base classifier. 2. Ripper: We compared different combinations of SMOTE and sub-sampling with simple sub-sampling using ripper (Cohen, 1995b) as the base classifier. We also varied Ripper's loss ratio (Cohen & Singer, 1996; Lewis & Catlett, 1994) from 0.9 to 0.001 (as a means of varying misclassification costs) and compared the effect of this variation with the combination of SMOTE and sub-sampling. By reducing the loss ratio from 0.9 to 0.001, we were able to establish a set of rules for the minority class. 3. Naive Bayes Classifier: The naive classifiers can be made cost sensitive by making the lower class more cost sensitive."}, {"heading": "5.1 Datasets", "text": "We experimented on nine different datasets with 11,687 samples. These datasets are summarized in Table 5.2. These datasets vary widely in size and class proportions and therefore offer different domains for SMOTE. In order of the increasing imbalance they are: 1. The Pima Indian Diabetes (Blake & Merz, 1998) has two classes and 768 samples. The data is used to identify the positive cases of diabetes in a population near Phoenix, Arizona. The number of positive class samples is only 268. Good sensitivity to the detection of diabetes cases will be a desirable attribute of the classification. 2. The phoneme dataset is from the ELENA projection 3. The goal of the datasets is to distinguish between classes 0 and oral sounds (Class 1). There are 5 characteristics. The class distribution is 3,818 samples in class 0 and 1,586 samples in class 1.3. The Adult Merdatet 1998 (11,642) has samples with 88,487 samples."}, {"heading": "5.2 ROC Creation", "text": "In fact, the fact is that most of them are in a position to go to another world, in which they go to another world, in which they find themselves in another world, in which they find themselves in another world, in which they find themselves in another world, in which they find themselves in another world, in which they find themselves in another world, in which they find themselves in another world, in which they find themselves in another world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "5.3 AUC Calculation", "text": "The lower left point for a given ROC curve is the performance of a classifier on the raw data. The upper right point is always (100%, 100%). If the curve does not end naturally at this point, the point is added, which is necessary for the AUCs to be over the same range of% FP.The AUCs listed in Table 5.3 show that for all data sets, the combined synthetic minority acquisition and majority oversampling is capable of improving over the simple majority oversampling with C4.5 as the base classifier. Therefore, our SMOTE approach provides an improvement in the correct classification of data in the underrepresented class. The same conclusion applies from an examination of the ROC convex treatments. Some of the entries are missing from the table as SMOTE was not applied to all data sets at the same height."}, {"heading": "5.4 Additional comparison to changing the decision thresholds", "text": "Provost (2000) suggested that simply changing the decision threshold should always be seen as an alternative to more complex approaches. In the case of C4.5, this would mean changing the decision threshold on the leaves of the decision trees. Thus, a leaf could classify examples as a minority class, even if more than 50% of the training examples on the leaf represent the majority class. We experimented by setting the decision thresholds on the leaves of the C4.5 decision tree to 0.5, 0.45, 0.42, 0.4, 0.35, 0.32, 0.3, 0.27, 0.25, 0.22, 0.2, 0.17, 0.15, 0.12, 0.1, 0.05, 0.0. We experimented with the phoneme dataset. Figure 24 shows the comparison of the SMOTE and sub-sampling combination with the C4.5 learning by matching bias against the minority class. The graph shows that the SMOTE and sub-sampling combination dominates the entire value range."}, {"heading": "5.5 Additional comparison to one-sided selection and SHRINK", "text": "To alleviate the problem of unbalanced data sets, the authors have proposed (a) unilateral selection for the majority class subsample (Kubat & Matwin, 1997) and (b) the SHRINK system (Kubat et al., 1998). Table 5.5 contains the results from (Kubat et al., 1998). Acc + is the accuracy of the positive (minority) examples and Acc - the accuracy of the negative (majority) examples. Figure 25 shows the trend for Acc + and Acc - for a combination of the SMOTE strategy and the different degree of majority class subsample sampling. The Y axis represents the accuracy and the X axis represents the accuracy of the percentage majority class among the samples. Diagrams show that in the range of the subsample sample between 50% and 125% the results are comparable to those obtained by INHRK results, and the X axis represents the majority class among the samples."}, {"heading": "800% 90.7% 33.3%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "700% 96.0% 32.8%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "600% 98.0% 40.0%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "500% 98.0% 35.5%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "400% 95.5% 44.2%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "300% 89.0% 55.0%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "200% 81.7% 56.7%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "175% 85.0% 57.8%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "150% 83.3% 57.8%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "125% 84.2% 68.1%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "100% 78.3% 68.7%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "75% 83.7% 73.0%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "50% 89.5% 78.9%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "25% 64.0% 89.1%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "15% 62.8% 91.3%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10% 64.7% 94.2%", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6. Future Work", "text": "Automated adaptive selection of the number of nearest neighbors would be valuable. Various strategies for creating synthetic neighbors can improve performance, and selecting the nearest neighbors with a focus on examples that are misclassified can improve performance. A minority study could possibly have a majority study as the nearest neighbor, rather than a minority study. This crowding is likely to help redraw decision areas in favor of the minority class. In addition to these topics, two possible extensions of SMOTE and an application of SMOTE to information gathering will be discussed in the following subsections."}, {"heading": "6.1 SMOTE-NC", "text": "We call this approach Synthetic Minority Over-sampling TEchnique-Nominal Continuous [SMOTE-NC]. We tested this approach on the adult data set from the UCI repository. The SMOTE-NC algorithm is described below. 3. Populate the synthetic sample: The continuous features of the new synthetic minority sample are created using the same SMOTE approach as described before.The nominal feature is given by the value found in the majority of the k-nearest neighborhood.The SMOTE-NC experiments reported here are constructed in the same way as those reported with SMOTE, except for the fact that we positively examine only one dataset. SMOTE-NC with the adult datasets differs from our typical result: The SMOTE-NC experiments perform worse than pure subsamples based on AUC because in Figure 26 we have a better and only superimposed the effect of SME-NC on the features."}, {"heading": "6.2 SMOTE-N", "text": "A matrix that defines the distance between the corresponding feature values for all feature vectors is thus created. (V1, V2) Considering the overlap of the feature values over all feature vectors, (V1, V2) Considering the overlap of the feature values over all feature vectors, a matrix is defined that defines the distance between the corresponding feature vectors. (V1, V2) The matrix defines the distance between the corresponding feature vectors, V1 and V2 are the two corresponding feature values. (V1) The total number of occurrences of feature value V1, and V1i is the number of occurrences of feature value V1 and V2 class."}, {"heading": "6.3 Application of SMOTE to Information Retrieval", "text": "The IR problems have a wealth of features and potentially many categories. SMOTE would have to be applied in conjunction with a feature selection algorithm after the given document or web page has been transformed into a sack-of-word format. An interesting comparison to SMOTE would be the combination of Naive Bayes and Odds Ratio. Odds Ratio focuses on a target class and classifies documents according to their relevance to the target or positive class. SMOTE also focuses on a target class by creating more examples of this class."}, {"heading": "7. Summary", "text": "The results show that the SMOTE approach can improve the accuracy of classifiers for a minority class. SMOTE offers a new approach to oversampling, making the combination of SMOTE and undersampling better than pure undersampling. SMOTE has been tested on a variety of datasets, with imbalances and different amounts of data varying in education, creating a diverse testing environment. Combining SMOTE and undersampling also results in better performance based on ROC domination than the loss rates in rippers or variation of class priorities in Naive Bayes Classifiers: The methods that could directly handle the distribution of classes lead to a bias in the minority class."}, {"heading": "Acknowledgments", "text": "This research has been partially supported by the US Department of Energy through the Sandia National Laboratories ASCI VIEWS Data Discovery Program under Contract No. DE-AC04-76DO00789. We thank Robert Holte for providing the oil spill data set used in their work. We also thank Foster Provost for clarifying his method of using the Satimage data set. We would also like to thank the anonymous critics for their various insightful comments and suggestions."}, {"heading": "Appendix A. ROC graphs for Oil Dataset", "text": "The following figures show different sets of ROC curves for the oil data set. Figure 29 (a) shows the ROC curves for the oil data set as shown in the main text; Figure 29 (b) shows the ROC curves without the ROC convex hull; Figure 29 (c) shows the two convex hulls obtained with and without SMOTE. The ROC convex hull, represented by dashed lines and stars in Figure 29 (c), was calculated by including Under-C4.5 and Naive Bayes in the family of ROC curves. The ROC convex hull, represented by a solid line and small circles in Figure 29 (c), was calculated by including 500 SMOTE-C4.5, Under-C4.5 and Naive Bayes in the family of ROC curves."}], "references": [{"title": "UCI Repository of Machine Learning Databases http://www.ics.uci.edu/\u223cmlearn/\u223cMLRepository.html", "author": ["C. Blake", "C. Merz"], "venue": "Department of Information and Computer Sciences,", "citeRegEx": "Blake and Merz,? \\Q1998\\E", "shortCiteRegEx": "Blake and Merz", "year": 1998}, {"title": "The Use of the Area Under the ROC Curve in the Evaluation of Machine Learning Algorithms", "author": ["A.P. Bradley"], "venue": "Pattern Recognition, 30(6), 1145\u20131159.", "citeRegEx": "Bradley,? 1997", "shortCiteRegEx": "Bradley", "year": 1997}, {"title": "SMOTE: Synthetic Minority Over-sampling TEchnique", "author": ["N. Chawla", "K. Bowyer", "L. Hall", "P. Kegelmeyer"], "venue": "In International Conference of Knowledge Based Computer Systems,", "citeRegEx": "Chawla et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Chawla et al\\.", "year": 2000}, {"title": "Modifying MUSTAFA to capture salient data", "author": ["N. Chawla", "L. Hall"], "venue": "Tech. rep. ISL-99-01,", "citeRegEx": "Chawla and Hall,? \\Q1999\\E", "shortCiteRegEx": "Chawla and Hall", "year": 1999}, {"title": "Learning to Classify English Text with ILP Methods", "author": ["W. Cohen"], "venue": "Proceedings of the 5th International Workshop on Inductive Logic Programming, pp. 3\u201324. Department of Computer Science, Katholieke Universiteit Leuven.", "citeRegEx": "Cohen,? 1995a", "shortCiteRegEx": "Cohen", "year": 1995}, {"title": "Fast Effective Rule Induction", "author": ["W.W. Cohen"], "venue": "Proc. 12th International Conference on Machine Learning, pp. 115\u2013123 Lake Tahoe, CA. Morgan Kaufmann.", "citeRegEx": "Cohen,? 1995b", "shortCiteRegEx": "Cohen", "year": 1995}, {"title": "Context-sensitive Learning Methods for Text Categorization", "author": ["W.W. Cohen", "Y. Singer"], "venue": "Proceedings of SIGIR-96,", "citeRegEx": "Cohen and Singer,? \\Q1996\\E", "shortCiteRegEx": "Cohen and Singer", "year": 1996}, {"title": "A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features", "author": ["S. Cost", "S. Salzberg"], "venue": "Machine Learning,", "citeRegEx": "Cost and Salzberg,? \\Q1993\\E", "shortCiteRegEx": "Cost and Salzberg", "year": 1993}, {"title": "Neural Network Training on Unequally Represented Classes", "author": ["E. DeRouin", "J. Brown", "L. Fausett", "M. Schneider"], "venue": "In Intellligent Engineering Systems Through Artificial Neural Networks,", "citeRegEx": "DeRouin et al\\.,? \\Q1991\\E", "shortCiteRegEx": "DeRouin et al\\.", "year": 1991}, {"title": "Metacost: A General Method for Making Classifiers Cost-sensitive", "author": ["P. Domingos"], "venue": "Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 155\u2013164 San Diego, CA. ACM Press.", "citeRegEx": "Domingos,? 1999", "shortCiteRegEx": "Domingos", "year": 1999}, {"title": "Explicitly Representing Expected Cost: An Alternative to ROC Representation", "author": ["C. Drummond", "R. Holte"], "venue": "In Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Drummond and Holte,? \\Q2000\\E", "shortCiteRegEx": "Drummond and Holte", "year": 2000}, {"title": "Inductive Learning Algorithms and Representations for Text Categorization", "author": ["S. Dumais", "J. Platt", "D. Heckerman", "M. Sahami"], "venue": "In Proceedings of the Seventh International Conference on Information and Knowledge Management.,", "citeRegEx": "Dumais et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Dumais et al\\.", "year": 1998}, {"title": "Learning Goal Oriented Bayesian Networks for Telecommunications Risk Management", "author": ["K. Ezawa", "M. Singh", "S. Norton"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Ezawa et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Ezawa et al\\.", "year": 1996}, {"title": "Combining Data Mining and Machine Learning for Effective User Profile", "author": ["T. Fawcett", "F. Provost"], "venue": "In Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Fawcett and Provost,? \\Q1996\\E", "shortCiteRegEx": "Fawcett and Provost", "year": 1996}, {"title": "Off-line, Handwritten Numeral Recognition by Perturbation Method", "author": ["T.M. Ha", "H. Bunke"], "venue": "Pattern Analysis and Machine Intelligence,", "citeRegEx": "Ha and Bunke,? \\Q1997\\E", "shortCiteRegEx": "Ha and Bunke", "year": 1997}, {"title": "The Electrotopological State: Structure Information at the Atomic Level for Molecular Graphs", "author": ["L. Hall", "B. Mohney", "L. Kier"], "venue": "Journal of Chemical Information and Computer Science,", "citeRegEx": "Hall et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Hall et al\\.", "year": 1991}, {"title": "The Class Imbalance Problem: Significance and Strategies", "author": ["N. Japkowicz"], "venue": "Proceedings of the 2000 International Conference on Artificial Intelligence (IC-AI\u20192000): Special Track on Inductive Learning Las Vegas, Nevada.", "citeRegEx": "Japkowicz,? 2000", "shortCiteRegEx": "Japkowicz", "year": 2000}, {"title": "Machine Learning for the Detection of Oil Spills in Satellite Radar Images", "author": ["M. Kubat", "R. Holte", "S. Matwin"], "venue": "Machine Learning,", "citeRegEx": "Kubat et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kubat et al\\.", "year": 1998}, {"title": "Addressing the Curse of Imbalanced Training Sets: One Sided Selection", "author": ["M. Kubat", "S. Matwin"], "venue": "In Proceedings of the Fourteenth International Conference on Machine Learning,", "citeRegEx": "Kubat and Matwin,? \\Q1997\\E", "shortCiteRegEx": "Kubat and Matwin", "year": 1997}, {"title": "Noisy Replication in Skewed Binary Classification", "author": ["S. Lee"], "venue": "Computational Statistics and Data Analysis, 34.", "citeRegEx": "Lee,? 2000", "shortCiteRegEx": "Lee", "year": 2000}, {"title": "Heterogeneous Uncertainity Sampling for Supervised Learning", "author": ["D. Lewis", "J. Catlett"], "venue": "In Proceedings of the Eleventh International Conference of Machine Learning,", "citeRegEx": "Lewis and Catlett,? \\Q1994\\E", "shortCiteRegEx": "Lewis and Catlett", "year": 1994}, {"title": "A Comparison of Two Learning Algorithms for Text Categorization", "author": ["D. Lewis", "M. Ringuette"], "venue": "In Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval,", "citeRegEx": "Lewis and Ringuette,? \\Q1994\\E", "shortCiteRegEx": "Lewis and Ringuette", "year": 1994}, {"title": "Data Mining for Direct Marketing Problems and Solutions", "author": ["C. Ling", "C. Li"], "venue": "In Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining", "citeRegEx": "Ling and Li,? \\Q1998\\E", "shortCiteRegEx": "Ling and Li", "year": 1998}, {"title": "Feature Selection for Unbalanced Class Distribution and Naive Bayes", "author": ["D. Mladeni\u0107", "M. Grobelnik"], "venue": "In Proceedings of the 16th International Conference on Machine Learning.,", "citeRegEx": "Mladeni\u0107 and Grobelnik,? \\Q1999\\E", "shortCiteRegEx": "Mladeni\u0107 and Grobelnik", "year": 1999}, {"title": "Computational Geometry in C", "author": ["J. O\u2019Rourke"], "venue": null, "citeRegEx": "O.Rourke,? \\Q1998\\E", "shortCiteRegEx": "O.Rourke", "year": 1998}, {"title": "Reducing Misclassification Costs", "author": ["M. Pazzani", "C. Merz", "P. Murphy", "K. Ali", "T. Hume", "C. Brunk"], "venue": "In Proceedings of the Eleventh International Conference on Machine Learning", "citeRegEx": "Pazzani et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Pazzani et al\\.", "year": 1994}, {"title": "Robust Classification for Imprecise Environments", "author": ["F. Provost", "T. Fawcett"], "venue": "Machine Learning,", "citeRegEx": "Provost and Fawcett,? \\Q2001\\E", "shortCiteRegEx": "Provost and Fawcett", "year": 2001}, {"title": "The Case Against Accuracy Estimation for Comparing Induction Algorithms", "author": ["F. Provost", "T. Fawcett", "R. Kohavi"], "venue": "In Proceedings of the Fifteenth International Conference on Machine Learning,", "citeRegEx": "Provost et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Provost et al\\.", "year": 1998}, {"title": "A Large-Scale Evaluation of Features for Automatic Detection of Oil Spills in ERS SAR Images", "author": ["A. Solberg", "R. Solberg"], "venue": "In International Geoscience and Remote Sensing Symposium,", "citeRegEx": "Solberg and Solberg,? \\Q1996\\E", "shortCiteRegEx": "Solberg and Solberg", "year": 1996}, {"title": "Toward Memory-based Reasoning", "author": ["C. Stanfill", "D. Waltz"], "venue": "Communications of the ACM,", "citeRegEx": "Stanfill and Waltz,? \\Q1986\\E", "shortCiteRegEx": "Stanfill and Waltz", "year": 1986}, {"title": "Measuring the Accuracy of Diagnostic Systems", "author": ["J. Swets"], "venue": "Science, 240, 1285\u20131293.", "citeRegEx": "Swets,? 1988", "shortCiteRegEx": "Swets", "year": 1988}, {"title": "Two Modifications of CNN", "author": ["I. Tomek"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, 6, 769\u2013772.", "citeRegEx": "Tomek,? 1976", "shortCiteRegEx": "Tomek", "year": 1976}, {"title": "Cost Sensitive Bibliography", "author": ["P. Turney"], "venue": "http://ai.iit.nrc.ca/bibiliographies/costsensitive.html.", "citeRegEx": "Turney,? 1996", "shortCiteRegEx": "Turney", "year": 1996}, {"title": "The Selection of Good Search Terms", "author": ["C. van Rijsbergen", "D. Harper", "M. Porter"], "venue": "Information Processing and Management,", "citeRegEx": "Rijsbergen et al\\.,? \\Q1981\\E", "shortCiteRegEx": "Rijsbergen et al\\.", "year": 1981}, {"title": "Comparative Evaluation of Pattern Recognition Techniques for Detection of Microcalcifications in Mammography", "author": ["K. Woods", "C. Doss", "K. Bowyer", "J. Solka", "C. Priebe", "P. Kegelmeyer"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence,", "citeRegEx": "Woods et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Woods et al\\.", "year": 1993}], "referenceMentions": [{"referenceID": 4, "context": "There have been attempts to deal with imbalanced datasets in domains such as fraudulent telephone calls (Fawcett & Provost, 1996), telecommunications management (Ezawa, Singh, & Norton, 1996), text classification (Lewis & Catlett, 1994; Dumais, Platt, Heckerman, & Sahami, 1998; Mladeni\u0107 & Grobelnik, 1999; Lewis & Ringuette, 1994; Cohen, 1995a) and detection of oil spills in satellite images (Kubat, Holte, & Matwin, 1998).", "startOffset": 213, "endOffset": 345}, {"referenceID": 30, "context": "The Receiver Operating Characteristic (ROC) curve is a standard technique for summarizing classifier performance over a range of tradeoffs between true positive and false positive error rates (Swets, 1988).", "startOffset": 192, "endOffset": 205}, {"referenceID": 1, "context": "The Area Under the Curve (AUC) is an accepted traditional performance metric for a ROC curve (Duda, Hart, & Stork, 2001; Bradley, 1997; Lee, 2000).", "startOffset": 93, "endOffset": 146}, {"referenceID": 19, "context": "The Area Under the Curve (AUC) is an accepted traditional performance metric for a ROC curve (Duda, Hart, & Stork, 2001; Bradley, 1997; Lee, 2000).", "startOffset": 93, "endOffset": 146}, {"referenceID": 9, "context": "One is to assign distinct costs to training examples (Pazzani, Merz, Murphy, Ali, Hume, & Brunk, 1994; Domingos, 1999).", "startOffset": 53, "endOffset": 118}, {"referenceID": 16, "context": "The other is to re-sample the original dataset, either by oversampling the minority class and/or under-sampling the majority class (Kubat & Matwin, 1997; Japkowicz, 2000; Lewis & Catlett, 1994; Ling & Li, 1998).", "startOffset": 131, "endOffset": 210}, {"referenceID": 5, "context": "5 decision tree classifier (Quinlan, 1992), Ripper (Cohen, 1995b), and a Naive Bayes Classifier show that our approach improves over other previous re-sampling, modifying loss ratio, and class priors approaches, using either the AUC or ROC convex hull.", "startOffset": 51, "endOffset": 65}, {"referenceID": 1, "context": "In the presence of imbalanced datasets with unequal error costs, it is more appropriate to use the ROC curve or other similar techniques (Ling & Li, 1998; Drummond & Holte, 2000; Provost & Fawcett, 2001; Bradley, 1997; Turney, 1996).", "startOffset": 137, "endOffset": 232}, {"referenceID": 32, "context": "In the presence of imbalanced datasets with unequal error costs, it is more appropriate to use the ROC curve or other similar techniques (Ling & Li, 1998; Drummond & Holte, 2000; Provost & Fawcett, 2001; Bradley, 1997; Turney, 1996).", "startOffset": 137, "endOffset": 232}, {"referenceID": 19, "context": "If the ROC curves are intersecting, the total AUC is an average comparison between models (Lee, 2000).", "startOffset": 90, "endOffset": 101}, {"referenceID": 31, "context": "The borderline examples were detected using the Tomek links concept (Tomek, 1976).", "startOffset": 68, "endOffset": 81}, {"referenceID": 18, "context": "Previous Work: Imbalanced datasets Kubat and Matwin (1997) selectively under-sampled the majority class while keeping the original population of the minority class.", "startOffset": 35, "endOffset": 59}, {"referenceID": 17, "context": "related work proposed the SHRINK system that classifies an overlapping region of minority (positive) and majority (negative) classes as positive; it searches for the \u201cbest positive region\u201d (Kubat et al., 1998).", "startOffset": 189, "endOffset": 209}, {"referenceID": 16, "context": "She noted that both the sampling approaches were effective, and she also observed that using the sophisticated sampling techniques did not give any clear advantage in the domain considered (Japkowicz, 2000).", "startOffset": 189, "endOffset": 206}, {"referenceID": 16, "context": "Japkowicz (2000) discussed the effect of imbalance in a dataset.", "startOffset": 0, "endOffset": 17}, {"referenceID": 16, "context": "Japkowicz (2000) discussed the effect of imbalance in a dataset. She evaluated three strategies: under-sampling, resampling and a recognition-based induction scheme. We focus on her sampling approaches. She experimented on artificial 1D data in order to easily measure and construct concept complexity. Two resampling methods were considered. Random resampling consisted of resampling the smaller class at random until it consisted of as many samples as the majority class and \u201cfocused resampling\u201d consisted of resampling only those minority examples that occurred on the boundary between the minority and majority classes. Random under-sampling was considered, which involved under-sampling the majority class samples at random until their numbers matched the number of minority class samples; focused under-sampling involved under-sampling the majority class samples lying further away. She noted that both the sampling approaches were effective, and she also observed that using the sophisticated sampling techniques did not give any clear advantage in the domain considered (Japkowicz, 2000). One approach that is particularly relevant to our work is that of Ling and Li (1998). They combined over-sampling of the minority class with under-sampling of the majority class.", "startOffset": 0, "endOffset": 1182}, {"referenceID": 9, "context": "The relabeling of the examples expands the decision space as it creates new samples from which the classifier may learn (Domingos, 1999).", "startOffset": 120, "endOffset": 136}, {"referenceID": 11, "context": "The information retrieval (IR) domain (Dumais et al., 1998; Mladeni\u0107 & Grobelnik, 1999; Lewis & Ringuette, 1994; Cohen, 1995a) also faces the problem of class imbalance in the dataset.", "startOffset": 38, "endOffset": 126}, {"referenceID": 4, "context": "The information retrieval (IR) domain (Dumais et al., 1998; Mladeni\u0107 & Grobelnik, 1999; Lewis & Ringuette, 1994; Cohen, 1995a) also faces the problem of class imbalance in the dataset.", "startOffset": 38, "endOffset": 126}, {"referenceID": 23, "context": "Solberg and Solberg (1996) considered the problem of imbalanced data sets in oil slick classification from SAR imagery.", "startOffset": 0, "endOffset": 27}, {"referenceID": 7, "context": "Another approach that is similar to our work is that of Domingos (1999). He compares the \u201cmetacost\u201d approach to each of majority under-sampling and minority over-sampling.", "startOffset": 56, "endOffset": 72}, {"referenceID": 7, "context": "Another approach that is similar to our work is that of Domingos (1999). He compares the \u201cmetacost\u201d approach to each of majority under-sampling and minority over-sampling. He finds that metacost improves over either, and that under-sampling is preferable to minority over-sampling. Error-based classifiers are made cost-sensitive. The probability of each class for each example is estimated, and the examples are relabeled optimally with respect to the misclassification costs. The relabeling of the examples expands the decision space as it creates new samples from which the classifier may learn (Domingos, 1999). A feed-forward neural network trained on an imbalanced dataset may not learn to discriminate enough between classes (DeRouin, Brown, Fausett, & Schneider, 1991). The authors proposed that the learning rate of the neural network be adapted to the statistics of class representation in the data. They calculated an attention factor from the proportion of samples presented to the neural network for training. The learning rate of the network elements was adjusted based on the attention factor. They experimented on an artificially generated training set and on a real-world training set, both with multiple (more than two) classes. They compared this to the approach of replicating the minority class samples to balance the data set used for training. The classification accuracy on the minority class was improved. Lewis and Catlett (1994) examined heterogeneous uncertainty sampling for supervised learning.", "startOffset": 56, "endOffset": 1456}, {"referenceID": 16, "context": "1 Minority over-sampling with replacement Previous research (Ling & Li, 1998; Japkowicz, 2000) has discussed over-sampling with replacement and has noted that it doesn\u2019t significantly improve minority class recognition.", "startOffset": 60, "endOffset": 94}, {"referenceID": 34, "context": "The data for the plot in Figure 3 was extracted from a Mammography dataset1 (Woods et al., 1993).", "startOffset": 76, "endOffset": 96}, {"referenceID": 5, "context": "Ripper: We compared various combinations of SMOTE and under-sampling with plain under-sampling using Ripper (Cohen, 1995b) as the base classifier.", "startOffset": 108, "endOffset": 122}, {"referenceID": 27, "context": "We chose the smallest class as the minority class and collapsed the rest of the classes into one as was done in (Provost et al., 1998).", "startOffset": 112, "endOffset": 134}, {"referenceID": 16, "context": "Most other approaches only work for only two classes (Ling & Li, 1998; Japkowicz, 2000; Kubat & Matwin, 1997; Provost & Fawcett, 2001).", "startOffset": 53, "endOffset": 134}, {"referenceID": 17, "context": "The Oil dataset was provided by Robert Holte and is used in their paper (Kubat et al., 1998).", "startOffset": 72, "endOffset": 92}, {"referenceID": 34, "context": "The Mammography dataset (Woods et al., 1993) has 11,183 samples with 260 calcifications.", "startOffset": 24, "endOffset": 44}, {"referenceID": 16, "context": "The ROC curve for plain under-sampling of the majority class (Ling & Li, 1998; Japkowicz, 2000; Kubat & Matwin, 1997; Provost & Fawcett, 2001) is compared with our approach of combining synthetic minority class over-sampling (SMOTE) with majority class under-sampling.", "startOffset": 61, "endOffset": 142}, {"referenceID": 24, "context": "The ROC convex hull is generated using the Graham\u2019s algorithm (O\u2019Rourke, 1998).", "startOffset": 62, "endOffset": 78}, {"referenceID": 17, "context": "For the oil dataset, we also followed a slightly different line of experiments to obtain results comparable to (Kubat et al., 1998).", "startOffset": 111, "endOffset": 131}, {"referenceID": 17, "context": "To alleviate the problem of imbalanced datasets the authors have proposed (a) one-sided selection for under-sampling the majority class (Kubat & Matwin, 1997) and (b) the SHRINK system (Kubat et al., 1998).", "startOffset": 185, "endOffset": 205}, {"referenceID": 17, "context": "5 contains the results from (Kubat et al., 1998).", "startOffset": 28, "endOffset": 48}, {"referenceID": 17, "context": "Table 4: Cross-validation results (Kubat et al., 1998)", "startOffset": 34, "endOffset": 54}, {"referenceID": 7, "context": "2 SMOTE-N Potentially, SMOTE can also be extended for nominal features \u2014 SMOTE-N \u2014 with the nearest neighbors computed using the modified version of Value Difference Metric (Stanfill & Waltz, 1986) proposed by Cost and Salzberg (1993). The Value Difference Metric (VDM) looks at the overlap of feature values over all feature vectors.", "startOffset": 210, "endOffset": 235}], "year": 2011, "abstractText": "An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of \u201cnormal\u201d examples with only a small percentage of \u201cabnormal\u201d or \u201cinteresting\u201d examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.", "creator": "dvips(k) 5.86 Copyright 1999 Radical Eye Software"}}}