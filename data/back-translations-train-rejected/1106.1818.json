{"id": "1106.1818", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2011", "title": "Inducing Interpretable Voting Classifiers without Trading Accuracy for Simplicity: Theoretical Results, Approximation Algorithms", "abstract": "Recent advances in the study of voting classification algorithms have brought empirical and theoretical results clearly showing the discrimination power of ensemble classifiers. It has been previously argued that the search of this classification power in the design of the algorithms has marginalized the need to obtain interpretable classifiers. Therefore, the question of whether one might have to dispense with interpretability in order to keep classification strength is being raised in a growing number of machine learning or data mining papers. The purpose of this paper is to study both theoretically and empirically the problem. First, we provide numerous results giving insight into the hardness of the simplicity-accuracy tradeoff for voting classifiers. Then we provide an efficient \"top-down and prune\" induction heuristic, WIDC, mainly derived from recent results on the weak learning and boosting frameworks. It is to our knowledge the first attempt to build a voting classifier as a base formula using the weak learning framework (the one which was previously highly successful for decision tree induction), and not the strong learning framework (as usual for such classifiers with boosting-like approaches). While it uses a well-known induction scheme previously successful in other classes of concept representations, thus making it easy to implement and compare, WIDC also relies on recent or new results we give about particular cases of boosting known as partition boosting and ranking loss boosting. Experimental results on thirty-one domains, most of which readily available, tend to display the ability of WIDC to produce small, accurate, and interpretable decision committees.", "histories": [["v1", "Thu, 9 Jun 2011 13:56:01 GMT  (160kb)", "http://arxiv.org/abs/1106.1818v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["r nock"], "accepted": false, "id": "1106.1818"}, "pdf": {"name": "1106.1818.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": "Indu ing Interpretable Voting Classi ers without Trading", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A ura y for Simpli ity: Theoreti al Results, Approximation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Algorithms, and Experiments", "text": "Ri hard No k rno k martinique.univ-ag.fr Universit e Antilles-Guyane Grimaag-D epartement S ienti que Interfa ultaire Campus Universitaire de S hoel her B.P. 7209 97275 S hoel her, Martinique, Fran e"}, {"heading": "Abstra t", "text": "In the past, it has been argued that the validity of this validity in the design of algorithms has marginalized the need for interpretable validity, so the purpose of this work is to examine the problem both theoretically and empirically. First, we provide numerous results that provide insights into the harshness of the simplicity of validity for elective lasers. Then, we offer a top-down and bottom-up study of heuristi induction, WIDC, which stems mainly from poor learning outcomes and the promotion of frameworks."}, {"heading": "1. Introdu tion", "text": "These methods are based on the fact that their power is based on the ability to build potentially very large lasers within an ensemble; it is widely used, and formally proven in ertain ases (S hapire, Freund, Bartlett, & Lee, 1998; S hapire & Singer, 1998; S hapire & Singer, 1998; S hapire & Singer, 1998; S hapire & Singer, 1998; S hapire & Singer, 1998; S hapire & Singer, 1998; S hapire & Singer, 1998), that their power is based on the ability to build potentially very large lasers. Indeed, it has been observed that an ensemble is sometimes as large as (or larger than) the data used to build the ensemble (Margineantu & Dietteri h, 1997)! Then one simple question arises, namely, what is the interest in an ensemble?"}, {"heading": "2. Our Contribution", "text": "This paper, in contrast to the latter two, is completely dissimilar."}, {"heading": "3. De ision Committees", "text": "Unless it is an example that has a number of problems (o; o), which are an observation that goes beyond n variables, and where the probability of a learning test is higher than the one we dispose of. LS is itself a subset of a whole domain that we call X. Obviously, we do not have the full bandwidth of X (LS X): in general, we even have jLSj jX (j: j) the ardinality; we assume that X is rete with nite ardinality). In parti ular asewhere = 2, the two LSj (o = 1) and\\ +. \""}, {"heading": "4. Building Small A urate De ision Committees (and Alike) is Hard", "text": "We now show that the formation of committees is a difficult task when trying to obtain both small and urate formulas; there are two common size terms that can, of course, be used for committees: the first is the total number of dictionaries of the formula (if a dictionary exists i-times, it is output i-times) (No k & Gas uel, 1995; No k & Jappy, 1998), the second is the number of rules of the formula (Kearns, Li, Pitt, & Valiant, 1987) Our results suggest that minimizing the size of a committee is just as difficult for both size committees as solving known NP-Harter problems (as long as they are elements of a group with normality 2) and already for two-class problems, where minimizing the size of a committee is as difficult for both size committees as solving known NP-Harter problems."}, {"heading": "4.1 The Size of a DC is Measured as its Whole Number of Literals", "text": "Theorem 1 If the size of a DC is measured as the total number of letters, it is NP - difficult to reconcile the smallest voting results with a number of examples LS.Proof: See the Appendix.We an easily adapting Theorem 1 to the ase, where the rules are repla by weighted DT as advo in boosted C4.5 (S hapire & Singer, 1998).Here comes back the ea h tree alass 2 f + 1; 1g, and ea h tree is real weight to heel its vote. The sign of the linear combination gives the example of an example. The following theorem applies again with any limitations on leverage of economic ients (as long as at least one non-zero value is authorized), or without limitation on the oiling ients. By this we mean that for ea h of the applicable restrictions (or without) the problem of economic economics."}, {"heading": "4.2 The Size of a DC is Measured as its Number of Rules", "text": "rf\u00fc nde eeirsdBnree\u00fcgn rf\u00fc ide eeirgcnlrteeaeVnlrlhsrtee\u00fccnh hacu ide eeirsrdtee\u00fcGr ni rde eeirsrdteeVnlrrteeeeeu ni ende eeirsrdteeVnlrlhsrteee\u00fccnh hsci-eaJnlrrsrrteeaeaeaetnrsrsrdteeeeeerrrrrrdteeeeeeeaeSn ni ni eeirrrrrf\u00fc ide e\u00fccehnlrrrlrrrrf\u00fc eeeeeeeeeeeeeeaeeeeeaeeeeeeeeeeeeeeeeecrrrrrrsrrrsrrrrrrrlrrrrrrrrrrrrrdrdteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeSn nrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrlllllsrdne nrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"}, {"heading": "5.1 Building a Large De ision Committee using Partition Boosting", "text": "If we assume that the hypothesis (which does not necessarily have to be led to a definition), that it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about which it is about a way in which it is about which it is about a way in which it is about which it is about which it is about which it is about which it is about a way in which it is about which it is about which it is about which it is about which it is about which it is not only about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is"}, {"heading": "5.2 Cal ulating Rule Ve tors using Ranking Loss Boosting", "text": "S hapire & Singer (1998) have investigated the problems in which the goal of the pro-dure policy is that it is not a read-read-read for any observations; rather, the algorithm is read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-O-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-O-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-read-"}, {"heading": "5.2.1 Optimizing Z in the Setting of S hapire & Singer (1998)", "text": "In the base where the component of ~ v is traced back to the sentence f 1; + 1g, S hapire & Singer (1998) give a way to minimize Z for any height of ~ v (using our notation): = 12logW + W!; (4) with: W + = Xo; k; jw ((o; k; j))) [~ v [j v [k s = 2; (5) W = Xo; k; jw (((o; k; j)))) [~ v [j v [k s]. (2) yields the following new expression for Z = W0 + 2pW + W + W; (7) with W0 = Po; k; k; jw (o; k; s)."}, {"heading": "5.2.2 Optimizing Z in our Setting", "text": "It is not a matter of whether or not there is a connection between the author and the author, but rather whether or not there is a connection between the author and the author, whether or not there is a connection between the author and the author, whether or not there is a connection between the author and the author, whether or not there is a connection between the author and the author and the author, whether or not there is a connection between the author and the author and the author, whether or not there is a connection between the author and the author, whether or not there is a connection between the author and the author, whether or not there is a connection between the author and the author, whether or not there is a connection between the author and the author, whether or not there is a connection between the author and the author, whether or not there is a connection between the author and the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, and the author, the author, the author, the author, the author, the author, the author, and the author, the author, the author, the author, the author, and the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, the author, and the author, the author,"}, {"heading": "5.2.3 Expli it Solution in the Two-Classes Case", "text": "For the sake of simplicity, we should rename W + 0 = W and W + 1 = W +, which represent the examples from the negative and positive let resp., satisfactorily t. The rule for Hoose ~ v is: Lemma 2 The following table gives the rule for Hoose ~ v: If we then hooseW + We3 2 ~ v = (1; + 1) peW + W < e3 2 ~ v = (1; 0) or ~ v = (0; + 1) 1 peW + W < pe ~ v = (1; 1) or ~ v = (0; 0) or ~ v = (+ 1; + 1) 1e3 2W + W < 1 pe ~ v = (0; 1) or ~ v = (+ 1; 0) W + W < 1e3 2 ~ v = (+ 1; 1) Proof: See Appendix."}, {"heading": "5.3 Pruning a DC", "text": "The algorithm is a single-pass algorithm: the ea h rule is only tested on e, from the first rule to the last. For the ea h rule, one criterion (.), depending on whether the rule should be removed or not, returns the criterion \"TRUE\" or \"FALSE.\" There are two versions of this criterion: the first, \"whi h we all\\ pessimisti,\" is based on conventional error minimization; the second, called \"optimisti,\" comes from an earlier work on the pruning of vision trees (Kearns & Mansour, 1998)."}, {"heading": "5.3.1 Pessimisti Pruning", "text": "Pessimistic intersection forms a sequence e of DC from the original one. In each h-step we remove a rule, namely that its elimination entails the lowest error of all possible control distances in the urrent DC. If the error of the urrent DC is not greater than the lowest error already found, criterion (.) applies to all rules already tested for elimination. This intersection returns the smallest DC with the lowest error of the sequence e. This intersection is rather natural (and simple) and motivated by the fact that the injection of the large DC before intersection does not lead to a conventional error minimization. Thus, a property is rather rare in the induction algorithms of\\ top-down and curve. For example, in the ommon de ision tree indu tion algorithms in this heme in orporate very sophisticated cutiated riteria (CART (Breiman et al., 1984), C4.5 (Quinlan)."}, {"heading": "5.3.2 Optimisti Pruning", "text": "The reason why it was able to get so far is as follows: \"It is an error that we managed to get a grip on the node to which we are oriented\" (S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "6. Experiments", "text": "In the following, three experimental studies are presented, which aim to test the WIDC in three areas: Therst presents comprehensive results on the simplicity of trading achieved by the WIDC, and compares the results with those achieved for state-of-the-art algorithms. In the following, in-depth analyses on mining / interpretability are carried out, and in the third, results on noise tolerance are presented."}, {"heading": "6.1 Tradeo Simpli ity-A ura y", "text": "In fact, most of them are able to survive by themselves if they do not play by the rules. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are able to survive by themselves. \"(...) Most of them are able to survive by themselves.\""}, {"heading": "6.2 Interpretability Issues", "text": "The tenth is irrelevant in the strongest sense of the word (John, Kohavi, & P eger, 1994).The goal on the one hand is a 3-DNF (one + internal node).To indicate an observation, the left margin of a node is tracked when an observation is made on the other side of the node, and the right margin is handled differently (i.e., the dictionary is negative in the observation).The bold square is used to indicate the irrelevant variables in the tree.A naive version of this tree in the rules for both lots generates 30 rules, for a total of 179 letters, meaning that we have a monomial listing in most three letters) over the rst nine variables: (x0 ^ x2) _ (x3 ^ x4 ^ x5) _."}, {"heading": "6.3 Noise Handling", "text": "Dre rf\u00fc ide eeisrcnh-eaWnlhsrcnlhUeaeaeaaJnlhsdcnlhsrteeaeaeaeoiuiuiuiuiugnngn ni rde eeirlrrrgVnlrteeeeeeegnln rf\u00fc ide nlrgneeeaeaeFnlrgn rf\u00fc ide eaeaeWnlrln rf\u00fc ide nlrllrrreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"}, {"heading": "7. Con lusion", "text": "From a theoretical and empirical point of view, this paper deals with the question of whether one has to renounce the possibilities of interpretation in order to maintain the discharge power of the ensemble members. To get a handle on this problem, we have tried to examine a series of on-ept representations, which resemble multilinear opposing polynomials and are suitable for mining problems when it comes to electoral procedures. Our theorems show that the pursuit of simplicity, as with many other lessons of on-ept representations, is a hard omputational problem in dealing with DC or other omplex electoral procedures, and that the heuristicisation of tendentistic formulas, which seek to accelerate adaptive stimuli, boost the art to build weak learners, is reading-addictive results for the construction of DC lists with usually strong ideal."}, {"heading": "8. A knowledgments", "text": "Thanks are due to DDAF Martinique, ENESAD (Etablissement National d'Enseignement Sup erieur Agronomique de Dijon) and Lise Jean-Louis for providing the agricultural data, for stimulating discussions around our results and for authorising the publication of some of the results obtained. Thanks to Ahmed Ainou for pointing out the interest in minimising submodular pleasures. Finally, the author would like to thank Pedro Domingos and the reviewers for their valuable suggestions."}, {"heading": "Appendix A", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Theorem 1", "text": "Sin e the hardness results of a nite set S, K jon QuestionA over the two-lasses ase, we shall use the notation (i) = ~ v (i) [1 \u20ac~ v (i) [0 \u20acfor some arbitrary rule (t (i); ~ v (i))), where ~ v (i) is thevalue for lass\\ - \"and ~ v (i) [1 \u20acis the value for lass\\ +.\" A positive value for (i) meansthat t (i) is in favor of lass\\, whereas a negative value gives a t (i) in favor of lass\\ -. \""}, {"heading": "Proof of Theorem 3", "text": "We use a redu tion from NP -Hard problem\\ 2-NM-Colorability \"(Kearns et al., 1987): Name:\\ 2-NM-Colorability; Instan e: A nite set S = fs1; s2;::; sjSjg and a olle tion of onstraints over S, C = f1;::; jCjg, su h that 8i 2 f1; 2;:; jCjg; iS.Question: Is there a 2-NM-Coloration of the elements of S, i.e. a fun: S! f1; 2g su h that (8i 2 f1;:: jCjg); (9sk; sl2i): (sk) 6 = (sl)? The redu tion is onstru ted as follows: from a\\ 2-NM-Colorability.\""}, {"heading": "Proof of Theorem 4", "text": "The key to investigating the problem is:; 1g! IR su h that8A f0; 1;::; 1g; f [A = Xo; k; jw ((o; k; j)))) qA (j; k); (21) withqA (j; k) = e [[j 2 A ^ k 62 A e [[j 62 A ^ k 2 A k + [j 2 A ^ k 2 A) _ (j 62 A ^ k 62 A): f f the three expressions of Z in equations (2), (3) and (7) withadequate values for."}, {"heading": "Proofsket h of Theorem 5", "text": "The reeBi nvo dme eSrte\u00fcn, n \"i so iwr.\" r eD \"eSi nvo eenei, ndS\" s os, n os os, n os os, n os, n os os, \"n os os,\" n os os, \"e\" n, n \", n\" i os, n os, n \"os, n\" os, n \"os, n\" os, \"n\" os, n \"os,\" n \",\" n \",\" \",\", \",\" \",\" \",\" \",\", \",\", \",\", \",\", \"\", \"\", \"\", \"\", \"\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\" \",\", \",\" \",\", \",\", \"\", \",\", \",\", \"\" \",\" \",\", \"\", \",\", \",\" \",\", \"\", \",\", \",\", \"\", \",\", \",\", \"\", \",\", \",\", \",\" \",\", \",\" \"\", \",\", \"\", \",\", \"\", \",\", \""}, {"heading": "Proof of Lemma 1", "text": "The proof of this dilemma is quite simple, but we give it for completeness. Z gives (b) b (b) b = Xj 6 = kZj; k; (26) with 8j 6 = k; Zj; k = W + j1e1 2 (j; k) + W + k1e1 2 (j; k); (27) where (j; k) = ~ v [j ~ v [k, and we show that the new value of Z after, Za, is not greater than Z before the permutation, Zb. The di e between weenZaand Zban are simply expressed with the notation Z (i; j) b (i; j) b (i; j 2 f0; k = j) as the value of Za; Zb."}, {"heading": "Proof of Theorem 6", "text": "To avoid merging, we have all overlooked the value of Z across the transformed set of examples, and U (~ u) for U 2 fZ; Z0g and ~ u 2 f ~ v; ~ vg as the value of criterion U using ve tor ~ u. It is easy to get a term tied to it. We have Z (~ v) = Z0 (~ v) + XS V jSj > 1WS jSj0Xi2Se1 2 ~ v [i Xj2Snfige1 2 ~ v [j 1A; (30) Z0 (~ v) = Z (~ v) + XS V jSj > 1WS j0Xi2Se1 2 ~ v [i Xj2Snfige1 2 ~ v [j 1A: (31) Slt1S; (WSis the sum of the weights of the examples in the original group, of which have the elements of S. Zv ~ j1 ~ jjjjjk ~ hing)."}, {"heading": "Proof of Lemma 2", "text": "Z are omes in the aseZ = W + e1 2 + W e1 2; (32) where = ~ v [1 ~ v [0]. There are ve erent values for, which lead to nine di erent ~ v: = + 2) ~ v = (1; + 1); = + 1) ~ v = (1; 0) _ ~ v = (0; + 1); = 0) ~ v = (1; 1) _ ~ v = (0; 0) _ ~ v = (+ 1; = 1); = 1) ~ v = (0; 1) _ ~ v = (+ 1; 0); = 2) ~ v = (+ 1; 1): Fix = k wo k 2 f 2; 1; 0; 1; 2g. 8k 2 f 1; 0; 1; 2g, the value = k should be preferred to the value = k 1 i the ordering Z is smaller, i.e.: W + ek 2 + Wek 2 < W + Wek 2 f; 1; 1 g."}, {"heading": "Referen es", "text": "Bauer, E., E., R. (1999). An empiri al omparison of voting lassi ation algorithms: Bagging, Boosting, and variants. Ma hine Learning, 24, 123 {140.Breiman, L., J. H., Olshen, R. A., C. J. (1984). Bagging predi tors. Ma hine Learning, 24 {140.Breiman, L., J. H., Olshen, R. A., C. J. (1984). Wadsworth.Buja, A., Lee, Y.-S. (2001). Data mining riteria for tree-based regression and lassi a-tion."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "Re ent advan es in the study of voting lassi ation algorithms have brought empiri al and theoreti al results learly showing the dis rimination power of ensemble lassi ers. It has been previously argued that the sear h of this lassi ation power in the design of the algorithms has marginalized the need to obtain interpretable lassi ers. Therefore, the question of whether one might have to dispense with interpretability in order to keep lassi ation strength is being raised in a growing number of ma hine learning or data mining papers. The purpose of this paper is to study both theoreti ally and empiri ally the problem. First, we provide numerous results giving insight into the hardness of the simpli ity-a ura y tradeo for voting lassi ers. Then we provide an e\u00c6 ient \\top-down and prune\" indu tion heuristi , WIDC, mainly derived from re ent results on the weak learning and boosting frameworks. It is to our knowledge the rst attempt to build a voting lassi er as a base formula using the weak learning framework (the one whi h was previously highly su essful for de ision tree indu tion), and not the strong learning framework (as usual for su h lassi ers with boosting-like approa hes). While it uses a well-known indu tion s heme previously su essful in other lasses of on ept representations, thus making it easy to implement and ompare, WIDC also relies on re ent or new results we give about parti ular ases of boosting known as partition boosting and ranking loss boosting. Experimental results on thirty-one domains, most of whi h readily available, tend to display the ability of WIDC to produ e small, a urate, and interpretable de ision ommittees.", "creator": "dvips(k) 5.86 Copyright 1999 Radical Eye Software"}}}