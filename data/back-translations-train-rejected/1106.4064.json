{"id": "1106.4064", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jun-2011", "title": "Algorithmic Programming Language Identification", "abstract": "Motivated by the amount of code that goes unidentified on the web, we introduce a practical method for algorithmically identifying the programming language of source code. Our work is based on supervised learning and intelligent statistical features. We also explored, but abandoned, a grammatical approach. In testing, our implementation greatly outperforms that of an existing tool that relies on a Bayesian classifier.", "histories": [["v1", "Tue, 21 Jun 2011 00:37:23 GMT  (7kb)", "https://arxiv.org/abs/1106.4064v1", "11 pages"], ["v2", "Wed, 9 Nov 2011 19:45:30 GMT  (7kb)", "http://arxiv.org/abs/1106.4064v2", "11 pages. Code:this https URL"]], "COMMENTS": "11 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["david klein", "kyle murray", "simon weber"], "accepted": false, "id": "1106.4064"}, "pdf": {"name": "1106.4064.pdf", "metadata": {"source": "CRF", "title": "Algorithmic Programming Language Identification", "authors": ["David Klein", "Kyle Murray"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 110 6.40 64v2 [cs.LG] 9 N"}, {"heading": "1 Introduction and Motivation", "text": "The goal of this research is to develop techniques for recognizing and accurately identifying code from as many programming languages as possible, without starting with information other than the code itself. A large area where many extremely useful programs and code fragments cannot be identified is the Web. Such code appears in blogs, forums, mailing lists, documentation, and many other contexts where the supporting web software does not provide a way to identify the language of a particular program. Identifying information opens up various possibilities. For example, code found on the Web is now more searchable, even more so than the limited form of searchability that tools such as Google's code search for explicitly marked full programs provide. Furthermore, code fragments could become more readable if they are automatically synchronized based on the correct linguistic grammar."}, {"heading": "2 Existing Tools", "text": "Simple tools for identifying the source code already exist. Various syntax highlighting tools, such as Google Code Prettify, automatically highlight the syntax when a code exists [3]. However, in fact, these tools do not identify languages; instead, they use heuristics that make highlighting work well. In the case of Google Code Prettify, broad grammars (such as C-like, Bash-like, and Xml-like) are pre-programmed; these grammars are then used to scan code, and the most appropriate grammar is used for highlighting. Languages that share a common grammar are clearly indistinguishable (and they do not have to be for highlighting to work); more relevant is SourceClassifier, which attempts to identify a programming language that contains a particular code [2]. However, it is based on a simple Bayesian classicist, so its strength is limited to the quality of the training data, and it can easily be discarded by our work with comments and we can confidently discard them from existing ones."}, {"heading": "3 Approach", "text": "Our approach involves acquiring a large database of source code written in a variety of languages. We then train our program on the database by providing it with source code portions in specific languages. We can use the resulting knowledge to evaluate source code from unknown languages and determine in which language it is likely to be written."}, {"heading": "3.1 Training Data", "text": "All training data was collected by a custom web crawler on the code hosting website Github. Github's code tag was initially used to identify samples, but this was unlikely to be true in all cases. To fix this, we checked the samples by file extension; only files matching the common extension of a language were used to train this language.Our training data is 324 megabytes in size and contains over 41,000 source code files in the following languages: \u2022 Actionscript \u2022 Ada \u2022 Brainfuck \u2022 C \u2022 C # \u2022 C + + \u2022 Common Lisp \u2022 CSS \u2022 Erlang \u2022 Haskell \u2022 HTML \u2022 Java \u2022 Javascript \u2022 Lua \u2022 Matlab \u2022 Objective C \u2022 Perl \u2022 PHP \u2022 Python \u2022 Ruby \u2022 Scala \u2022 Scheme \u2022 Smalltalk \u2022 Latex \u2022 XML"}, {"heading": "3.1.1 Comment and String Detection", "text": "In fact, it is such that most of us will be able to move to another world, in which they are able to move to another world, in which they are able to move to another world, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, that they live, in which they live, that they live, that they live, that they are, that they live, that they are, that they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live"}, {"heading": "3.2 Statistical Analysis", "text": "The statistical aspects of our algorithm are based on several specific characteristics. We evaluate the individual parts of the source code for these characteristics and compare the results with those of each language in our database. The characteristics we use are as follows: \u2022 Parentheses: We evaluate the code based on the relative prevalence of the different types of brackets: brackets, curly braces, square brackets and square brackets. These characteristics allow us to distinguish between languages such as C and Java and languages such as Lisp. \u2022 FirstWord: We consider the first word of each line of the code. A word is defined as a string that is not separated by spaces, including punctuation, letters and numbers. This feature is intended to find common prefixes, such as \"public.\" In this feature, we examine every single word in the source code. We examine only letters and are separated by spaces."}, {"heading": "3.3 Grammatical Approach", "text": "To add another dimension to our identification, we also explored a grammar-based approach. After ruling out grammar learning from the ground up as too difficult and unlikely to achieve precise results, we decided to start with basic grammars for different characteristics of broad types of languages (a C-style loop would be an example, as well as a \"new\" definition in Java). From here, when we learned from a new source file, we tried to match each grammar with the file. Those who matched well were combined into a general grammar for that language that could then help identify it in the future. OMeta, an object-oriented language for pattern comparison, was explored to facilitate this in the code [4]. This project is based on parsing expression programs that are similar to context-free grammars but use prioriented selections to eliminate ambiguities in the parsing process [4]."}, {"heading": "3.3.1 Scoring a Grammar to Code", "text": "First, for a piece of grammar to be useful to us, we need to have a way to evaluate how well it fits a particular piece of code. Measuring the amount of code covered by parsing would be an easy way to do this. However, it would be inaccurate to use the actual length of the tokens as a measurement; a better method would be to count the number of matching tokens. It would even try to emphasize the meaning of different grammar pieces, since the inclusion of token lengths weights elements with lengthy tokens in the natural language unfairly, such as variations or comments."}, {"heading": "3.3.2 Combining Grammars", "text": "The next step was to combine two grammar pieces into a single grammar. OMeta's ability to easily switch between grammars would have enabled us to compose a grammar purely by ordering the pieces. However, without knowing the priority of the order, a PEG would be difficult to construct. Despite our efforts in this area, we were unable to integrate this approach into our main frame. Finding grammar pieces as well as combining grammar pieces proved to be obstacles to implementation, which is an approach we will leave to future work."}, {"heading": "4 Results", "text": "We tested our algorithm on 25 randomly selected source files from our database. Note that we do not examine the file extension as part of our identification, as we intend to do so as a simulation of the uses described above. Our program classifies languages from most likely to least likely. \u2022 Here are the results of this test: \u2022 Twelve of the 25 files (48%) were correctly identified. \u2022 Four times (12%) the algorithm chose the correct language as the second most likely language. \u2022 Four times (12%) the algorithm chose the correct language as the third most likely language. \u2022 Once (4%) the algorithm chose the correct language as the fourth most likely language. \u2022 Four times (12%) the algorithm did not identify the correct language as one of the five languages. Note that we chose the correct language from a total of 25 known languages."}, {"heading": "5 Code", "text": "Python code is available on GitHub under an MIT license [1]. It was written quickly for a short period of time and has not been refactored since, to allow others to reproduce our results."}, {"heading": "6 Future Work", "text": "Certainly, the grammatical approach can be explored more extensively to compare its effectiveness with that of the statistical approach and see if the two can be combined to form an even more accurate system. Although we have examined a variety of statistical features in our analysis, more needs to be explored. Since many interesting applications depend on the language identification features we have researched, it would be an exciting direction to embed our system in an application that uses our system in a practical and user-friendly way. References [1] https: / / github.com / simon-weber / Programming-Language-Identification /. [2] Chris Lowe. Identify programming languages with source code. http: / / blog.chrislowis.co.uk / 2009 / 01 / 04 / identify-programming-languages-with-source- [3] Mike Samuel. Google the code with source code. http: / / blog.chrislowis.co.uk / 2009 / 01 / identify-programming-languages-with-Samuel-source- Mike-3]."}], "references": [{"title": "Identify programming languages with sourceclassifier", "author": ["Chris Lowe"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Ometa: an object-oriented language for pattern matching", "author": ["Alessandro Warth", "Ian Piumarta"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "More relevant is SourceClassifier, which will attempt to identify a programming language given some code [2].", "startOffset": 105, "endOffset": 108}, {"referenceID": 1, "context": "OMeta, an object-oriented language for pattern matching, was explored to facilitate this in code [4].", "startOffset": 97, "endOffset": 100}], "year": 2011, "abstractText": "Motivated by the amount of code that goes unidentified on the web, we introduce a practical method for algorithmically identifying the programming language of source code. Our work is based on supervised learning and intelligent statistical features. We also explored, but abandoned, a grammatical approach. In testing, our implementation greatly outperforms that of an existing tool that relies on a Bayesian classifier. Code is written in Python and available under an MIT license.", "creator": "LaTeX with hyperref package"}}}