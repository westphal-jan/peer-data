{"id": "1106.4571", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jun-2011", "title": "Acquiring Word-Meaning Mappings for Natural Language Interfaces", "abstract": "This paper focuses on a system, WOLFIE (WOrd Learning From Interpreted Examples), that acquires a semantic lexicon from a corpus of sentences paired with semantic representations. The lexicon learned consists of phrases paired with meaning representations. WOLFIE is part of an integrated system that learns to transform sentences into representations such as logical database queries. Experimental results are presented demonstrating WOLFIE's ability to learn useful lexicons for a database interface in four different natural languages. The usefulness of the lexicons learned by WOLFIE are compared to those acquired by a similar system, with results favorable to WOLFIE. A second set of experiments demonstrates WOLFIE's ability to scale to larger and more difficult, albeit artificially generated, corpora. In natural language acquisition, it is difficult to gather the annotated data needed for supervised learning; however, unannotated data is fairly plentiful. Active learning methods attempt to select for annotation and training only the most informative examples, and therefore are potentially very useful in natural language applications. However, most results to date for active learning have only considered standard classification tasks. To reduce annotation effort while maintaining accuracy, we apply active learning to semantic lexicons. We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance.", "histories": [["v1", "Wed, 22 Jun 2011 20:57:18 GMT  (226kb)", "http://arxiv.org/abs/1106.4571v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["c thompson"], "accepted": false, "id": "1106.4571"}, "pdf": {"name": "1106.4571.pdf", "metadata": {"source": "CRF", "title": "Acquiring Word-Meaning Mappings for Natural Language Interfaces", "authors": ["Cynthia A. Thompson", "Raymond J. Mooney"], "emails": ["cindi@cs.utah.edu", "mooney@cs.utexas.edu"], "sections": [{"heading": null, "text": "The usefulness of the lexicographies Wolfie learns is compared to the results of a similar system, with the results beneficial to Wolfie. A second set of experiments shows Wolfie's ability to scale larger and more difficult, albeit artificially generated corporations. When acquiring natural language, it is difficult to collect the annotated data needed for supervised learning, but unannotated data is abundant. Active learning methods try to select only the most informative examples of commenting and training, and are therefore potentially very useful for applications in natural language. However, most previous results for active learning have only considered standard classification tasks. To reduce the burden of commenting while maintaining accuracy, we apply active learning to semantic lexicographs. We show that active learning can significantly reduce the number of annotated examples needed to achieve a certain level of performance."}, {"heading": "1. Introduction and Overview", "text": "In fact, most of them are able to go to another world, where they can go to another world, where they can go to another world, where they can go to another world."}, {"heading": "2. Background", "text": "In this section, we give an overview of Chill, the system that complements our research. We also describe Jeff Siskind's lexicon collection system.2.1 ChillThe output produced by Wolfie can be used to support a larger language acquisition system; in particular, it is currently used as part of the entry to a parser collection system called Chill (Constructive Heuristics Induction for Language Learning). Chill uses inductive logic programming (Muggleton, 1992; Lavrac '& Dz'eroski, 1994) to learn a deterministic shift-reducing parser (Tomita, 1986) written in Prologue. Chill input is a corpus of sentences paired with semantic representations, the same input required by Wolfie. The learned parser is able to map the sentences into their correct representations, as well as generalize well to novel sentences."}, {"heading": "2.2 Jeff Siskind\u2019s Lexicon Learning Research", "text": "The most closely related previous research on the automated acquisition of a lexicon is that of Siskind (1996), himself inspired by the work of Rayner, Hugosson and Hagert (1988). While comparing our system with his in Section 5, we describe the main features of his research in this section. His goal is to cognitively model the acquisition of the lexicon by children, using a learning process that does not require cognitive plausibility, and with the aim of learning a lexicon that generalizes well from a small number of training examples. His system focuses on a lexicon for understanding and use in parsing, using a learning process that does not require cognitive plausibility, and with the aim of learning a lexicon that generalizes well from a small number of training examples. His system takes a step-by-step approach to acquiring a lexicon."}, {"heading": "3. The Lexicon Acquisition Problem", "text": "Although our ultimate goal is to acquire a complete user interface for the natural language, we currently divide the task into two parts: the lexicon acquisition component and the parser acquisition component. In this section, we will discuss the problem of acquiring semantic lexicographies that support parsing and acquiring parsers. Training input consists of sentences in the natural language paired with their meaning representations, from which we extract a lexicographic consisting of phrases paired with their meaning representations. Some training pairs were given in the previous section, and a sample lexicographic is shown in Figure 2."}, {"heading": "3.1 Formal Definition", "text": "In order to formally present the learning problem, some definitions are needed. While we use the terms \"string\" and \"substring\" below, these extend to the terms of natural language sentences and phrases. We also refer to labeled trees, which implies the assumption that the semantic meanings of interest can be represented as such. Most common representations can be redefined as endless unlabeled trees or forests, and our formalism easily extends to the latter. Definition: Let's represent all terms of vertex labels and edge labels, respectively. Let's be an endless series of indentations, l a total function l: V \u2192 a series of disordered pairs of different indentations, called edges, and a total function a: E \u2192 a total function E. G = (V, l, a) is a described description of indentations of indentations, a total function of indentations, a total function of indentations."}, {"heading": "3.2 Implications of the Definition", "text": "In fact, it is such that most people will be able to move into another world, in which they are in a position, in which they are in a position, in which they live, in which they live, in which they are in a position, in which they are in a position, in which they live, in which they live, in which they live, in the world, in which they live, in the world, in which they live, in the world, in which they live, in which they live, in which they, in the world, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, live, in which they, in which they, in which they, live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, live, in which they, in which they, in which they, live, in which they, in which they, in which they"}, {"heading": "4.1 Solving the Lexicon Acquisition Problem", "text": "In fact, it is the case that most of them will be able to play by the rules that have marginalised them in recent years. (...) In fact, it is the case that they are able to play by the rules. (...) In fact, it is the case that they are able to play by the rules. (...) In fact, it is the case that they are able to play by the rules. (...) In fact, it is the case that they are able to play by the rules. (...) It is as if they are able to play by the rules. (...)"}, {"heading": "4.2.1 Candidate Generation Phase", "text": "Initial candidate meanings for a phrase are produced by calculating the maximum common substructure (s) between sampled pairs of representations of sentences that contain them. We derive common substructure by calculating the largest isomorphic connected subgraphs (LICS) of two designated trees, taking into account labels in the isomorphism. Analog greatest common subgraph problem (Garey & Johnson, 1979) is solvable in polynomial time if, as we assume, both inputs are trees and if K is given the number of edges to include. Thus, we start with the largest number of edges in the two trees that are compared, test for common subgraph (s) and iterate to K = 1, stop if one or more subgraphs are found that are complicated for a given K.For prolog representation, the algorithm is one bit by variable."}, {"heading": "4.2.2 Adding to the Final Lexicon", "text": "The question is whether it concerns a way in which the people in the individual countries who are in a position, in the EU, in the EU, in the EU, in the EU, in the EU, in the USA, in the USA, in the EU, in the USA, in the USA, in the USA, in the EU, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA,"}, {"heading": "5.1 A Database Query Application", "text": "The first part of the book, which deals with the question of how this crisis came about, is in fact as if it were a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, a crisis, etc."}, {"heading": "5.1.1 Comparisons using English", "text": "The first experiment was a comparison on the original English corpus. Figure 9 shows learning curves for chill when using the lexicon learned from Wolfie (CHILL + Wolfie) and the Siskind system (CHILL + Siskind). The topmost curve (CHILL + handmade) shows chill's performance when the handmade lexicon is given. CHILL Testlex shows the performance when words that never appear in the training data (e.g. are only in the test sentences) are deleted from the handmade lexicon (since a learning algorithm has no chance of learning them). Finally, the horizontal line shows the performance of the geobase benchmark. Results show that a lexicon learned from Wolfie was almost as accurate as those generated with a handmade lexicon. Best accuracy is achieved by parsers using the handmade lexicon."}, {"heading": "5.1.2 Performance for Other Natural Languages", "text": "Figure 10 shows the results. The differences between the use of Wolfie and Siskind learned lexicographs for Chill are again statistically significant for all sizes of training sets. We also show the performance with handmade lexicographs, both with and without phrases, which are only available in the test set. Performance is still competitive compared to handmade lexicographs with remote test sets, with the difference being significant only in 225 examples. Figure 11 shows the accuracy of learned parsers with Wolfie learned lexicographs for all four languages. Performance differences between the four languages are quite small, showing that our methods are not language-dependent."}, {"heading": "5.1.3 A Larger Corpus", "text": "Next, we present the results on a larger, more diverse geographical corpus, where the additional sets of computer science students were collected in an introductory AI course; the questionnaire in the smaller corpus was collected by students in a German class, without any specific instructions on the complexity of the queries they wanted; the AI students tended to ask more complex and varied questions: their task was to ask five interesting questions and the corresponding logical form for a homework assignment, although they again did not have direct access to the database; they were asked to enter at least one sentence, the representation of which contained a predicate containing embedded predicates, e.g. the largest (S, State (S)), and we asked for variety in their sentences; there were 221 new sentences, for a total of 471 (including the original 250 sentences); for these experiments, we divided the data into 425 training sets and 46 test sets, for 10 random splits, then we tracked sentences, and then we were asked to see if this Wolfie was as effective as we had been in 175 previous ones."}, {"heading": "5.1.4 LICS versus Fracturing", "text": "One component of the algorithm that has not yet been explicitly evaluated is the method of candidate generation. As mentioned in Section 4.1, instead of using LICS, we could use fractures of sentence representations where a phrase appears to generate the meaning of the candidate for that phrase. We used this approach and compared it with the previously described method of using the largest isomorphic related subgraphs of collected representations as candidate meanings. To try to make a fairer comparison, we also stitched representations for fracturing, using the same number of source representations as the number of pairs sampled for LICS. Furthermore, the accuracy of chill when using the resulting learned lexicon as background knowledge is shown in Figure 13. Fracturing (fractWOLFIE) shows little or no advantage; none of the differences between the two systems is statistically significant. Furthermore, the number of LICS entry terms we can choose from is much larger than the ICS method we can choose for ICS, as shown in Figure 14."}, {"heading": "5.2 Artificial Data", "text": "In fact, in a country where most people live in poverty, it is possible to find a new home."}, {"heading": "6. Active Learning", "text": "In fact, most of them are able to determine for themselves how they have behaved."}, {"heading": "7. Related Work", "text": "In this section, we divide previous research on related topics into the areas of lexicon acquisition and active learning."}, {"heading": "7.1 Lexicon Acquisition", "text": "In fact, it is the case that most of them are able to abide by the rules that they have imposed on themselves. (...) Most of them are able to understand the rules. (...) Most of them are able to understand the rules. (...) Most of them are able to understand the rules. (...) Most of them are able to understand the rules. (...) Most of them are able to understand the rules. (...) Most of them are able to understand the rules. (...) Most of them are able to understand the rules. (...) Most of them are able to understand themselves. (...) Most of them are not able to understand themselves. (...) Most of them are not able to understand themselves. (...) Most of them are not able to understand themselves. (...) Most of them are not able to understand themselves. (...) Most of them are able to understand themselves. (...)"}, {"heading": "7.2 Active Learning", "text": "(Regarding additional active learning techniques, Cohn et al. (1994) were among the first to discuss safety-based active learning methods in detail (Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and most of them have dealt with classification tasks such as language tagging and text categorization. Thus, Liere and Tadepalli (1997) apply active learning with committees to the problem of text categorization, showing improvements through active learning similar to those we receive, but the use of a committee of Winnow-based learning tasks based on annotators to a traditional classification task."}, {"heading": "8. Future Work", "text": "Although Wolfie's current greedy search method has worked quite well, a better heuristic or alternative search strategy could lead to improvements. We should morally evaluate Wolfie's ability to learn long phrases, since we have limited this ability in the ratings here. Another problem is robustness in the face of noise. However, the current algorithm does not guarantee to learn a correct lexicon even in a noise-free corpus. Adding noise makes it difficult to analyze the circumstances in which errors are likely. However, further theoretical and empirical analysis of these problems is warranted. Reference uncertainty could be handled by increasing complexity by forming LICS from more pairs of presentations with which a phrase appears, but not between alternative presentations of the same sentence. Then, once a pair is added to the lexicon, for each sentence containing that word, presentations can be eliminated if they do not contain the learned meaning, provided another one contains it."}, {"heading": "9. Conclusions", "text": "Acquiring a semantic lexicon from a corpus of sentences labeled with representations of their meaning is an important problem that has not been fully studied. We present both a formalism of the learning problem and a greedy algorithm to find an approximate solution to it. Wolfie shows that our methods extend to a variety of natural languages in addition to English, and that they are relatively applicable to larger, more difficult companies. Active learning is a new area of machine learning that has been applied almost exclusively to classification tasks. We have demonstrated its successful application to more complex natural speech mappings ranging from phrases to semantic meanings, and support the acquisition of lexicographs and parsers. The abundance of unannotated natural language data, along with the difficulty of commenting on such data, make selective sampling of a potentially invaluable technique for learning natural language systems effective results that can only be achieved through a realistic selection of 22%."}, {"heading": "Acknowledgments", "text": "We would like to thank Jeff Siskind for providing his software and for all his help in adapting it to our body. We would also like to thank Agapito Sustaita, Esra Erdem and Marshall Mayberry for their translation efforts and the three anonymous reviewers for their comments, which helped to improve the work. This research was supported by the National Science Foundation with grants IRI-9310819 and IRI-9704943."}], "references": [{"title": "Induction of augmented transition networks", "author": ["J.R. Anderson"], "venue": "Cognitive Science,", "citeRegEx": "Anderson,? \\Q1977\\E", "shortCiteRegEx": "Anderson", "year": 1977}, {"title": "Queries and concept learning", "author": ["D. Angluin"], "venue": "Machine Learning,", "citeRegEx": "Angluin,? \\Q1988\\E", "shortCiteRegEx": "Angluin", "year": 1988}, {"title": "Committee-based sample selection for probabilistic classifiers", "author": ["S. Argamon-Engelson", "I. Dagan"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Argamon.Engelson and Dagan,? \\Q1999\\E", "shortCiteRegEx": "Argamon.Engelson and Dagan", "year": 1999}, {"title": "WordNet: A lexical database organized on psycholinguistic principles", "author": ["R. Beckwith", "C. Fellbaum", "D. Gross", "G. Miller"], "venue": null, "citeRegEx": "Beckwith et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Beckwith et al\\.", "year": 1991}, {"title": "Automatic acquisition of subcategorization frames from untagged text", "author": ["M. Brent"], "venue": "In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Brent,? \\Q1991\\E", "shortCiteRegEx": "Brent", "year": 1991}, {"title": "A statistical approach to machine translation", "author": ["P Brown"], "venue": "Computational Linguistics,", "citeRegEx": "Brown,? \\Q1990\\E", "shortCiteRegEx": "Brown", "year": 1990}, {"title": "Deriving translation data from bilingual texts", "author": ["R. Catizone", "G. Russell", "S. Warwick"], "venue": "In Proceedings of the First International Lexical Acquisition Workshop", "citeRegEx": "Catizone et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Catizone et al\\.", "year": 1993}, {"title": "Improving generalization with active learning", "author": ["D. Cohn", "L. Atlas", "R. Ladner"], "venue": "Machine Learning,", "citeRegEx": "Cohn et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 1994}, {"title": "Unsupervised models for named entity classification", "author": ["M. Collins", "Y. Singer"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-99) University of Maryland", "citeRegEx": "Collins and Singer,? \\Q1999\\E", "shortCiteRegEx": "Collins and Singer", "year": 1999}, {"title": "Three generative, lexicalised models for statistical parsing", "author": ["M.J. Collins"], "venue": "In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Collins,? \\Q1997\\E", "shortCiteRegEx": "Collins", "year": 1997}, {"title": "Linguistic relativity and word acquisition: a computational approach", "author": ["E. Colunga", "M. Gasser"], "venue": "In Proceedings of the Twenty First Annual Conference of the Cognitive Science Society,", "citeRegEx": "Colunga and Gasser,? \\Q1998\\E", "shortCiteRegEx": "Colunga and Gasser", "year": 1998}, {"title": "Committee-based sampling for training probabilistic classifiers", "author": ["I. Dagan", "S.P. Engelson"], "venue": "In Proceedings of the Twelfth International Conference on Machine Learning", "citeRegEx": "Dagan and Engelson,? \\Q1995\\E", "shortCiteRegEx": "Dagan and Engelson", "year": 1995}, {"title": "The acquisition of a lexicon from paired phoneme sequences and semantic representations", "author": ["C. De Marcken"], "venue": "In Lecture Notes in Computer Science,", "citeRegEx": "Marcken,? \\Q1994\\E", "shortCiteRegEx": "Marcken", "year": 1994}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": "Journal of the Royal Statistical Society B,", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "Learning categorial grammars from semantic types", "author": ["Dudau-Sofronie", "Tellier", "Tommasi"], "venue": "In Proceedings of the 13th Amsterdam Colloquium,", "citeRegEx": "Dudau.Sofronie et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Dudau.Sofronie et al\\.", "year": 2001}, {"title": "The neural theory of language project http://www.icsi.berkeley.edu/ntl", "author": ["J. Feldman", "G. Lakoff", "L. Shastri"], "venue": "International Computer Science Institute,", "citeRegEx": "Feldman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 1995}, {"title": "The case for case", "author": ["C. Fillmore"], "venue": "Universals in Linguistic Theory", "citeRegEx": "Fillmore,? \\Q1968\\E", "shortCiteRegEx": "Fillmore", "year": 1968}, {"title": "The mechanisms of \u201cConstruction Grammar", "author": ["C. Fillmore"], "venue": "Proceedings of the Fourteenth Annual Meeting of the Berkeley Linguistics Society,", "citeRegEx": "Fillmore,? \\Q1988\\E", "shortCiteRegEx": "Fillmore", "year": 1988}, {"title": "Knowledge acquisition via incremental conceptual clustering", "author": ["D.H. Fisher"], "venue": "Machine Learning,", "citeRegEx": "Fisher,? \\Q1987\\E", "shortCiteRegEx": "Fisher", "year": 1987}, {"title": "Selective sampling using the query by committee algorithm", "author": ["Y. Freund", "H.S. Seung", "E. Shamir", "N. Tishby"], "venue": "Machine Learning,", "citeRegEx": "Freund et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1997}, {"title": "Representation and acquisition of verbal polysemy", "author": ["F. Fukumoto", "J. Tsujii"], "venue": null, "citeRegEx": "Fukumoto and Tsujii,? \\Q1995\\E", "shortCiteRegEx": "Fukumoto and Tsujii", "year": 1995}, {"title": "Identifying word correspondences in parallel texts", "author": ["W. Gale", "K. Church"], "venue": "In Proceedings of the Fourth DARPA Speech and Natural Language Workshop", "citeRegEx": "Gale and Church,? \\Q1991\\E", "shortCiteRegEx": "Gale and Church", "year": 1991}, {"title": "Computers and Intractability: A Guide to the Theory of NP-Completeness", "author": ["M. Garey", "D. Johnson"], "venue": null, "citeRegEx": "Garey and Johnson,? \\Q1979\\E", "shortCiteRegEx": "Garey and Johnson", "year": 1979}, {"title": "Constructions: A Construction Grammar Approach to Argument Structure", "author": ["A. Goldberg"], "venue": null, "citeRegEx": "Goldberg,? \\Q1995\\E", "shortCiteRegEx": "Goldberg", "year": 1995}, {"title": "Sextant: Extracting semantics from raw text, implementation details", "author": ["G. Grefenstette"], "venue": "Integrated Computer-Aided Engineering,", "citeRegEx": "Grefenstette,? \\Q1994\\E", "shortCiteRegEx": "Grefenstette", "year": 1994}, {"title": "From context-free to definite-clause grammars: a typetheoretic approach", "author": ["J. Haas", "B. Jayaraman"], "venue": "Journal of Logic Programming,", "citeRegEx": "Haas and Jayaraman,? \\Q1997\\E", "shortCiteRegEx": "Haas and Jayaraman", "year": 1997}, {"title": "A case frame learning method for Japanese polysemous verbs. In Papers from the 1995 AAAI Symposium on the Representation and Acquisition of Lexical Knowledge: Polysemy, Ambiguity, and Generativity", "author": ["M. Haruno"], "venue": null, "citeRegEx": "Haruno,? \\Q1995\\E", "shortCiteRegEx": "Haruno", "year": 1995}, {"title": "Implications of an automatic lexical acquisition mechanism", "author": ["P. Hastings"], "venue": null, "citeRegEx": "Hastings,? \\Q1996\\E", "shortCiteRegEx": "Hastings", "year": 1996}, {"title": "On minimizing training corpus for parser acquisition", "author": ["R. Hwa"], "venue": "In Proceedings of the Fifth Computational Natural Language Learning Workshop", "citeRegEx": "Hwa,? \\Q2001\\E", "shortCiteRegEx": "Hwa", "year": 2001}, {"title": "Semantic Structures", "author": ["R. Jackendoff"], "venue": null, "citeRegEx": "Jackendoff,? \\Q1990\\E", "shortCiteRegEx": "Jackendoff", "year": 1990}, {"title": "The acquisition and interpretation of complex nominals. In Papers from the 1995 AAAI Symposium on the Representation and Acquisition of Lexical Knowledge: Polysemy, Ambiguity, and Generativity", "author": ["M. Johnston", "B. Boguraev", "J. Pustejovsky"], "venue": null, "citeRegEx": "Johnston et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Johnston et al\\.", "year": 1995}, {"title": "Learning word meanings by instruction", "author": ["K. Knight"], "venue": "In Proceedings of the Thirteenth National Conference on Artificial Intelligence", "citeRegEx": "Knight,? \\Q1996\\E", "shortCiteRegEx": "Knight", "year": 1996}, {"title": "Automatic parameter selection by minimizing estimated error", "author": ["R. Kohavi", "G. John"], "venue": "In Proceedings of the Twelfth International Conference on Machine Learning", "citeRegEx": "Kohavi and John,? \\Q1995\\E", "shortCiteRegEx": "Kohavi and John", "year": 1995}, {"title": "Building an MT dictionary from parallel texts based on linguistic and statistical information", "author": ["A. Kumano", "H. Hirakawa"], "venue": "In Proceedings of the Fifteenth International Conference on Computational Linguistics,", "citeRegEx": "Kumano and Hirakawa,? \\Q1994\\E", "shortCiteRegEx": "Kumano and Hirakawa", "year": 1994}, {"title": "Inductive Logic Programming: Techniques and Applications", "author": ["N. Lavrac", "S. Dz\u0306eroski"], "venue": null, "citeRegEx": "Lavrac\u0306 and Dz\u0306eroski,? \\Q1994\\E", "shortCiteRegEx": "Lavrac\u0306 and Dz\u0306eroski", "year": 1994}, {"title": "Heterogeneous uncertainty sampling for supervised learning", "author": ["D.D. Lewis", "J. Catlett"], "venue": "In Proceedings of the Eleventh International Conference on Machine Learning", "citeRegEx": "Lewis and Catlett,? \\Q1994\\E", "shortCiteRegEx": "Lewis and Catlett", "year": 1994}, {"title": "A probabilistic approach to lexical semantic knowledge acquisition and structural disambiguation", "author": ["H. Li"], "venue": "Ph.D. thesis,", "citeRegEx": "Li,? \\Q1998\\E", "shortCiteRegEx": "Li", "year": 1998}, {"title": "Active learning with committees for text categorization", "author": ["R. Liere", "P. Tadepalli"], "venue": "In Proceedings of the Fourteenth National Conference on Artificial Intelligence", "citeRegEx": "Liere and Tadepalli,? \\Q1997\\E", "shortCiteRegEx": "Liere and Tadepalli", "year": 1997}, {"title": "Automatic acquisition of a large subcategorization dictionary from corpora", "author": ["C.D. Manning"], "venue": "In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Manning,? \\Q1993\\E", "shortCiteRegEx": "Manning", "year": 1993}, {"title": "Employing EM and pool-based active learning for text classification", "author": ["A.K. McCallum", "K. Nigam"], "venue": "In Proceedings of the Fifteenth International Conference on Machine Learning", "citeRegEx": "McCallum and Nigam,? \\Q1998\\E", "shortCiteRegEx": "McCallum and Nigam", "year": 1998}, {"title": "Automatic evaluation and uniform filter cascades for inducing n-best translation lexicons", "author": ["I.D. Melamed"], "venue": "In Proceedings of the Third Workshop on Very Large Corpora", "citeRegEx": "Melamed,? \\Q1995\\E", "shortCiteRegEx": "Melamed", "year": 1995}, {"title": "Models of translational equivalence among words", "author": ["I.D. Melamed"], "venue": "Computational Linguistics,", "citeRegEx": "Melamed,? \\Q2000\\E", "shortCiteRegEx": "Melamed", "year": 2000}, {"title": "Inductive Logic Programming", "author": ["S. Muggleton"], "venue": null, "citeRegEx": "Muggleton,? \\Q1992\\E", "shortCiteRegEx": "Muggleton", "year": 1992}, {"title": "Inverse entailment and Progol", "author": ["S. Muggleton"], "venue": "New Generation Computing Journal,", "citeRegEx": "Muggleton,? \\Q1995\\E", "shortCiteRegEx": "Muggleton", "year": 1995}, {"title": "Efficient induction of logic programs", "author": ["S. Muggleton", "C. Feng"], "venue": "In Proceedings of the First Conference on Algorithmic Learning Theory Tokyo, Japan. Ohmsha", "citeRegEx": "Muggleton and Feng,? \\Q1990\\E", "shortCiteRegEx": "Muggleton and Feng", "year": 1990}, {"title": "Perceptually grounded language learning: Part 2\u2013 DETE: A neural/procedural model", "author": ["V.I. Nenov", "M.G. Dyer"], "venue": "Connection Science,", "citeRegEx": "Nenov and Dyer,? \\Q1994\\E", "shortCiteRegEx": "Nenov and Dyer", "year": 1994}, {"title": "Using syntax to learn semantics: an experiment in language acquisition with a mobile robot", "author": ["T. Oates", "Z. Eyler-Walker", "P. Cohen"], "venue": "Tech. rep. 99-35,", "citeRegEx": "Oates et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Oates et al\\.", "year": 1999}, {"title": "Mathematical Methods in Linguistics", "author": ["B. Partee", "A. Meulen", "R. Wall"], "venue": null, "citeRegEx": "Partee et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Partee et al\\.", "year": 1990}, {"title": "Lexical acquisition via constraint solving", "author": ["T. Pedersen", "W. Chen"], "venue": null, "citeRegEx": "Pedersen and Chen,? \\Q1995\\E", "shortCiteRegEx": "Pedersen and Chen", "year": 1995}, {"title": "A note on inductive generalization", "author": ["G.D. Plotkin"], "venue": "Machine Intelligence (Vol", "citeRegEx": "Plotkin,? \\Q1970\\E", "shortCiteRegEx": "Plotkin", "year": 1970}, {"title": "Using a logic grammar to learn a lexicon", "author": ["M. Rayner", "A. Hugosson", "G. Hagert"], "venue": "Tech. rep. R88001, Swedish Institute of Computer Science", "citeRegEx": "Rayner et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Rayner et al\\.", "year": 1988}, {"title": "The human semantic potential: spatial language and constrained connectionism", "author": ["T. Regier"], "venue": null, "citeRegEx": "Regier,? \\Q1996\\E", "shortCiteRegEx": "Regier", "year": 1996}, {"title": "Selection and information: a class-based approach to lexical relationships", "author": ["P. Resnik"], "venue": "Ph.D. thesis,", "citeRegEx": "Resnik,? \\Q1993\\E", "shortCiteRegEx": "Resnik", "year": 1993}, {"title": "Learning rigid lambek grammars and minimalist grammars from structured sentences", "author": ["C. Retore", "R. Bonato"], "venue": "In Proceedings of the Third Learning Language in Logic Workshop Strasbourg, France", "citeRegEx": "Retore and Bonato,? \\Q2001\\E", "shortCiteRegEx": "Retore and Bonato", "year": 2001}, {"title": "An experiment on learning appropriate selectional restrictions from a parsed corpus", "author": ["F. Ribas"], "venue": "In Proceedings of the Fifteenth International Conference on Computational Linguistics,", "citeRegEx": "Ribas,? \\Q1994\\E", "shortCiteRegEx": "Ribas", "year": 1994}, {"title": "Learning dictionaries for information extraction by multilevel bootstrapping", "author": ["E. Riloff", "R. Jones"], "venue": "In Proceedings of the Sixteenth National Conference on Artificial Intelligence", "citeRegEx": "Riloff and Jones,? \\Q1999\\E", "shortCiteRegEx": "Riloff and Jones", "year": 1999}, {"title": "Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon construction", "author": ["B. Roark", "E. Charniak"], "venue": "In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and COLING-98", "citeRegEx": "Roark and Charniak,? \\Q1998\\E", "shortCiteRegEx": "Roark and Charniak", "year": 1998}, {"title": "Inducing a semantically annotated lexicon via EM-based clustering", "author": ["M. Rooth", "S. Riezler", "D. Prescher", "G. Carroll", "F. Beil"], "venue": "In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Rooth et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Rooth et al\\.", "year": 1999}, {"title": "Language Acquisition in a Unification-Based Grammar Processing System Using a Real World Knowledge Base", "author": ["D. Russell"], "venue": "Ph.D. thesis,", "citeRegEx": "Russell,? \\Q1993\\E", "shortCiteRegEx": "Russell", "year": 1993}, {"title": "Conceptual Information Processing", "author": ["R.C. Schank"], "venue": null, "citeRegEx": "Schank,? \\Q1975\\E", "shortCiteRegEx": "Schank", "year": 1975}, {"title": "A lexically-intensive algorithm for domain-specific knowledge acquisition", "author": ["R. Schneider"], "venue": "In Proceedings of the Joint Conference on New Methods in Language Processing and Computational Natural Language Learning,", "citeRegEx": "Schneider,? \\Q1998\\E", "shortCiteRegEx": "Schneider", "year": 1998}, {"title": "Less is more: Active learning with support vector machines", "author": ["G. Schohn", "D. Cohn"], "venue": "In Proceedings of the Seventeenth International Conference on Machine Learning", "citeRegEx": "Schohn and Cohn,? \\Q2000\\E", "shortCiteRegEx": "Schohn and Cohn", "year": 2000}, {"title": "Inductive logic programming for corpus-based acquisition of semantic lexicons", "author": ["P. S\u00e9billot", "P. Bouillon", "C. Fabre"], "venue": "In Proceedings of 2nd Learning Language in Logic (LLL) Workshop Lisbon,", "citeRegEx": "S\u00e9billot et al\\.,? \\Q2000\\E", "shortCiteRegEx": "S\u00e9billot et al\\.", "year": 2000}, {"title": "Query by committee", "author": ["H.S. Seung", "M. Opper", "H. Sompolinsky"], "venue": "In Proceedings of the ACM Workshop on Computational Learning Theory Pittsburgh,", "citeRegEx": "Seung et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Seung et al\\.", "year": 1992}, {"title": "Natural language learning by computer", "author": ["L. Siklossy"], "venue": null, "citeRegEx": "Siklossy,? \\Q1972\\E", "shortCiteRegEx": "Siklossy", "year": 1972}, {"title": "Learning word-to-meaning mappings", "author": ["J.M. Siskind"], "venue": null, "citeRegEx": "Siskind,? \\Q2000\\E", "shortCiteRegEx": "Siskind", "year": 2000}, {"title": "Naive Physics, Event Perception, Lexical Semantics and Language Acquisition", "author": ["J.M. Siskind"], "venue": "Ph.D. thesis,", "citeRegEx": "Siskind,? \\Q1992\\E", "shortCiteRegEx": "Siskind", "year": 1992}, {"title": "A computational study of cross-situational techniques for learning word-to-meaning", "author": ["J.M. Siskind"], "venue": "mappings. Cognition,", "citeRegEx": "Siskind,? \\Q1996\\E", "shortCiteRegEx": "Siskind", "year": 1996}, {"title": "Lexical acquisition as constraint satisfaction", "author": ["J.M. Siskind"], "venue": "Tech. rep. IRCS-93-41,", "citeRegEx": "Siskind,? \\Q1993\\E", "shortCiteRegEx": "Siskind", "year": 1993}, {"title": "Translating collocations for bilingual lexicons: A statistical approach", "author": ["F. Smadja", "K.R. McKeown", "V. Hatzivassiloglou"], "venue": "Computational Linguistics,", "citeRegEx": "Smadja et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Smadja et al\\.", "year": 1996}, {"title": "Learning information extraction rules for semi-structured and free text", "author": ["S. Soderland"], "venue": "Machine Learning,", "citeRegEx": "Soderland,? \\Q1999\\E", "shortCiteRegEx": "Soderland", "year": 1999}, {"title": "Complexity issues in robotic machine learning of natural language", "author": ["P. Suppes", "L. Liang", "M. B\u00f6ttner"], "venue": "Modeling Complex Phenomena, Proceedings of the 3rd Woodward Conference,", "citeRegEx": "Suppes et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Suppes et al\\.", "year": 1991}, {"title": "Active learning for natural language parsing and information extraction", "author": ["C.A. Thompson", "M.E. Califf", "R.J. Mooney"], "venue": "In Proceedings of the Sixteenth International Conference on Machine Learning", "citeRegEx": "Thompson et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Thompson et al\\.", "year": 1999}, {"title": "Acquisition of a lexicon from semantic representations of sentences", "author": ["C.A. Thompson"], "venue": "In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Thompson,? \\Q1995\\E", "shortCiteRegEx": "Thompson", "year": 1995}, {"title": "Algebraic learning of statistical associations for language acquisition", "author": ["N. Tishby", "A. Gorin"], "venue": "Computer Speech and Language,", "citeRegEx": "Tishby and Gorin,? \\Q1994\\E", "shortCiteRegEx": "Tishby and Gorin", "year": 1994}, {"title": "Efficient Parsing for Natural Language", "author": ["M. Tomita"], "venue": null, "citeRegEx": "Tomita,? \\Q1986\\E", "shortCiteRegEx": "Tomita", "year": 1986}, {"title": "Support vector machine active learning with applications to text classification", "author": ["S. Tong", "D. Koller"], "venue": "In Proceedings of the Seventeenth International Conference on Machine Learning", "citeRegEx": "Tong and Koller,? \\Q2000\\E", "shortCiteRegEx": "Tong and Koller", "year": 2000}, {"title": "Unsupervised lexical learning with categorial grammars using the lll corpus. In Learning Language In Logic (LLL) Workshop Bled, Slovenia", "author": ["S. Watkinson", "S. Manandhar"], "venue": null, "citeRegEx": "Watkinson and Manandhar,? \\Q1999\\E", "shortCiteRegEx": "Watkinson and Manandhar", "year": 1999}, {"title": "Automatic acquisition of the lexical semantics of verbs from sentence frames", "author": ["M. Webster", "M. Marcus"], "venue": "In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics (ACL-89),", "citeRegEx": "Webster and Marcus,? \\Q1995\\E", "shortCiteRegEx": "Webster and Marcus", "year": 1995}, {"title": "Large-scale automatic extraction of an English-Chinese translation lexicon", "author": ["D. Wu", "X. Xia"], "venue": "Machine Translation,", "citeRegEx": "Wu and Xia,? \\Q1995\\E", "shortCiteRegEx": "Wu and Xia", "year": 1995}, {"title": "Learning hierarchies from ambiguous natural language data", "author": ["T. Yamazaki", "M. Pazzani", "C. Merz"], "venue": "In Proceedings of the Twelfth International Conference on Machine Learning", "citeRegEx": "Yamazaki et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Yamazaki et al\\.", "year": 1995}, {"title": "Using Inductive Logic Programming to Automate the Construction of Natural Language Parsers", "author": ["J.M. Zelle"], "venue": "Ph.D. thesis, Department of Computer Sciences,", "citeRegEx": "Zelle,? \\Q1995\\E", "shortCiteRegEx": "Zelle", "year": 1995}, {"title": "Learning to parse database queries using inductive logic programming", "author": ["J.M. Zelle", "R.J. Mooney"], "venue": "In Proceedings of the Thirteenth National Conference on Artificial Intelligence", "citeRegEx": "Zelle and Mooney,? \\Q1996\\E", "shortCiteRegEx": "Zelle and Mooney", "year": 1996}, {"title": "Human behavior and the principle of least effort", "author": ["G. Zipf"], "venue": null, "citeRegEx": "Zipf,? \\Q1949\\E", "shortCiteRegEx": "Zipf", "year": 1949}], "referenceMentions": [{"referenceID": 67, "context": "Although many others (S\u00e9billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs.", "startOffset": 21, "endOffset": 142}, {"referenceID": 27, "context": "Although many others (S\u00e9billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs.", "startOffset": 21, "endOffset": 142}, {"referenceID": 24, "context": "Although many others (S\u00e9billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs.", "startOffset": 21, "endOffset": 142}, {"referenceID": 4, "context": "Although many others (S\u00e9billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs.", "startOffset": 21, "endOffset": 142}, {"referenceID": 81, "context": "First, its output can be used by a system, Chill (Zelle & Mooney, 1996; Zelle, 1995), that learns to parse sentences into semantic representations.", "startOffset": 49, "endOffset": 84}, {"referenceID": 4, "context": "Although many others (S\u00e9billot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind, 1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) have presented systems for learning information about lexical semantics, we present here a system for learning lexicons of phrasemeaning pairs. Further, our work is unique in its combination of several features, though prior work has included some of these aspects. First, its output can be used by a system, Chill (Zelle & Mooney, 1996; Zelle, 1995), that learns to parse sentences into semantic representations. Second, it uses a fairly straightforward batch, greedy, heuristic learning algorithm that requires only a small number of examples to generalize well. Third, it is easily extendible to new representation formalisms. Fourth, it requires no prior knowledge although it can exploit an initial lexicon if provided. Finally, it simplifies the learning problem by making several assumptions about the training data, as described further in Section 3.2. We test Wolfie\u2019s ability to acquire a semantic lexicon for a natural language interface to a geographical database using a corpus of queries collected from human subjects and annotated with their logical form. In this test, Wolfie is integrated with Chill, which learns parsers but requires a semantic lexicon (previously built manually). The results demonstrate that the final acquired parser performs nearly as accurately at answering novel questions when using a learned lexicon as when using a hand-built lexicon. Wolfie is also compared to an alternative lexicon acquisition system developed by Siskind (1996), demonstrating superior performance on this task.", "startOffset": 130, "endOffset": 1619}, {"referenceID": 42, "context": "Chill uses inductive logic programming (Muggleton, 1992; Lavrac\u0306 & Dz\u0306eroski, 1994) to learn a deterministic shift-reduce parser (Tomita, 1986) written in Prolog.", "startOffset": 39, "endOffset": 83}, {"referenceID": 75, "context": "Chill uses inductive logic programming (Muggleton, 1992; Lavrac\u0306 & Dz\u0306eroski, 1994) to learn a deterministic shift-reduce parser (Tomita, 1986) written in Prolog.", "startOffset": 129, "endOffset": 143}, {"referenceID": 81, "context": "For details on this and the other two parsing operators, see Zelle and Mooney (1996). By using Wolfie, the lexicon is provided automatically.", "startOffset": 61, "endOffset": 85}, {"referenceID": 65, "context": "2 Jeff Siskind\u2019s Lexicon Learning Research The most closely related previous research into automated lexicon acquisition is that of Siskind (1996), itself inspired by work by Rayner, Hugosson, and Hagert (1988).", "startOffset": 7, "endOffset": 147}, {"referenceID": 65, "context": "2 Jeff Siskind\u2019s Lexicon Learning Research The most closely related previous research into automated lexicon acquisition is that of Siskind (1996), itself inspired by work by Rayner, Hugosson, and Hagert (1988). As we will be comparing our system to his in Section 5, we describe the main features of his research in this section.", "startOffset": 7, "endOffset": 211}, {"referenceID": 66, "context": "Earlier work (Siskind, 1992) also evaluated versions of his technique on a quite small corpus of real English and Japanese sentences.", "startOffset": 13, "endOffset": 28}, {"referenceID": 65, "context": "Siskind (1996) shows the effectiveness of his approach on a series of artificial corpora.", "startOffset": 0, "endOffset": 15}, {"referenceID": 59, "context": "\u201d Using a conceptual dependency (Schank, 1975) representation in Prolog list form, the meaning is: [ingest, agent:[person, sex:female, age:child], patient:[food, type:pasta, accomp:[food, type:cheese]]].", "startOffset": 32, "endOffset": 46}, {"referenceID": 53, "context": "2 Implications of the Definition This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7.", "startOffset": 136, "endOffset": 160}, {"referenceID": 53, "context": "2 Implications of the Definition This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7.", "startOffset": 136, "endOffset": 176}, {"referenceID": 37, "context": "2 Implications of the Definition This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7.", "startOffset": 177, "endOffset": 192}, {"referenceID": 4, "context": "2 Implications of the Definition This definition of the lexicon acquisition problem differs from that given by other authors, including Riloff and Jones (1999), Siskind (1996), Manning (1993), Brent (1991) and others, as further discussed in Section 7.", "startOffset": 193, "endOffset": 206}, {"referenceID": 17, "context": ", Haas and Jayaraman, 1997; Siskind, 19964) While there is some debate in the linguistics community about the ability of compositional techniques to handle all phenomena (Fillmore, 1988; Goldberg, 1995), making this assumption simplifies the learning process and works reasonably for the domains of interest here.", "startOffset": 170, "endOffset": 202}, {"referenceID": 23, "context": ", Haas and Jayaraman, 1997; Siskind, 19964) While there is some debate in the linguistics community about the ability of compositional techniques to handle all phenomena (Fillmore, 1988; Goldberg, 1995), making this assumption simplifies the learning process and works reasonably for the domains of interest here.", "startOffset": 170, "endOffset": 202}, {"referenceID": 25, "context": "This assumption is similar to the linking rules of Jackendoff (1990), and has been used in previous work on grammar and language acquisition (e.", "startOffset": 51, "endOffset": 69}, {"referenceID": 65, "context": "In fact, all of these assumptions except for single-use were made by Siskind (1996); see Section 7 for details.", "startOffset": 69, "endOffset": 84}, {"referenceID": 64, "context": "Siskind (1993) defined fracturing (he also calls it the Unlink* operation) over terms such that the result includes all subterms of an expression plus \u22a5.", "startOffset": 0, "endOffset": 15}, {"referenceID": 0, "context": "for each phrase, as proposed by Anderson (1977). However, the meanings of an ambiguous phrase are disjunctive, and this intersection would be empty.", "startOffset": 32, "endOffset": 48}, {"referenceID": 0, "context": "for each phrase, as proposed by Anderson (1977). However, the meanings of an ambiguous phrase are disjunctive, and this intersection would be empty. A similar difficulty would be expected with the positive-only compression of Muggleton (1995).", "startOffset": 32, "endOffset": 243}, {"referenceID": 65, "context": "Though, of course, interpretation functions are not the only way to guarantee a covering lexicon \u2013 see Siskind (1993) for an alternative.", "startOffset": 103, "endOffset": 118}, {"referenceID": 73, "context": "We previously (Thompson, 1995) presented results demonstrating learning representations of a different form, that of a case-role representation (Fillmore, 1968) augmented with Conceptual Dependency (Schank, 1975) information.", "startOffset": 14, "endOffset": 30}, {"referenceID": 16, "context": "We previously (Thompson, 1995) presented results demonstrating learning representations of a different form, that of a case-role representation (Fillmore, 1968) augmented with Conceptual Dependency (Schank, 1975) information.", "startOffset": 144, "endOffset": 160}, {"referenceID": 59, "context": "We previously (Thompson, 1995) presented results demonstrating learning representations of a different form, that of a case-role representation (Fillmore, 1968) augmented with Conceptual Dependency (Schank, 1975) information.", "startOffset": 198, "endOffset": 212}, {"referenceID": 49, "context": "Therefore, we use LICS with an addition similar to computing the Least General Generalization of first-order clauses (Plotkin, 1970).", "startOffset": 117, "endOffset": 132}, {"referenceID": 18, "context": "heuristic used by Cobweb (Fisher, 1987), which measures the utility of clusters based on attribute-value pairs and categories, instead of meanings and phrases.", "startOffset": 25, "endOffset": 39}, {"referenceID": 65, "context": "We compared our system to an incremental (on-line) lexicon learner developed by Siskind (1996). To make a more equitable comparison to our batch algorithm, we ran his in a \u201csimulated\u201d batch mode, by repeatedly presenting the corpus 500 times, analogous to running 500 epochs to train a neural network.", "startOffset": 80, "endOffset": 95}, {"referenceID": 29, "context": "In this corpus, both the sentences and their representations are completely artificial, and the sentence representation is a variable-free representation, as suggested by the work of Jackendoff (1990) and others.", "startOffset": 183, "endOffset": 201}, {"referenceID": 83, "context": "We used a grammar to generate utterances and their meanings from each original lexicon, with terminal categories selected using a distribution based on Zipf\u2019s Law (Zipf, 1949).", "startOffset": 163, "endOffset": 175}, {"referenceID": 65, "context": "We generated several lexicons and associated corpora, varying the ambiguity rate (number of meanings per word) and synonymy rate (number of words per meaning), as in Siskind (1996). Meaning representations were generated using a set of \u201cconceptual symbols\u201d that combined to form the meaning for each word.", "startOffset": 166, "endOffset": 181}, {"referenceID": 1, "context": "Active learning is a research area in machine learning that features systems that automatically select the most informative examples for annotation and training (Angluin, 1988; Seung, Opper, & Sompolinsky, 1992), rather than relying on a benevolent teacher or random sampling.", "startOffset": 161, "endOffset": 211}, {"referenceID": 7, "context": "The last approach, selective sampling (Cohn et al., 1994), is particularly attractive in natural language learning, since there is an abundance of text, and we would like to annotate only the most informative sentences.", "startOffset": 38, "endOffset": 57}, {"referenceID": 7, "context": "Existing work in the area has emphasized two approaches, certainty-based methods (Lewis & Catlett, 1994), and committee-based methods (McCallum & Nigam, 1998; Freund, Seung, Shamir, & Tishby, 1997; Liere & Tadepalli, 1997; Dagan & Engelson, 1995; Cohn et al., 1994); we focus here on the former.", "startOffset": 134, "endOffset": 265}, {"referenceID": 73, "context": "See Thompson, Califf, and Mooney (1999) for a description of active learning for Chill.", "startOffset": 4, "endOffset": 40}, {"referenceID": 64, "context": "Work on automated lexicon and language acquisition dates back to Siklossy (1972), who demonstrated a system that learned transformation patterns from logic back to natural", "startOffset": 65, "endOffset": 81}, {"referenceID": 68, "context": "Our definition of the learning problem can be compared to his \u201cmapping problem\u201d (Siskind, 1993).", "startOffset": 80, "endOffset": 95}, {"referenceID": 65, "context": "His later work (Siskind, 2000) relaxes this to allow ambiguity and noise, but still biases towards minimizing ambiguity.", "startOffset": 15, "endOffset": 30}, {"referenceID": 68, "context": "Siskind\u2019s work on this topic has explored many different variations along a continuum of using many constraints but requiring more time to incorporate each new example (Siskind, 1993), versus few constraints but requiring more training data (Siskind, 1996).", "startOffset": 168, "endOffset": 183}, {"referenceID": 67, "context": "Siskind\u2019s work on this topic has explored many different variations along a continuum of using many constraints but requiring more time to incorporate each new example (Siskind, 1993), versus few constraints but requiring more training data (Siskind, 1996).", "startOffset": 241, "endOffset": 256}, {"referenceID": 12, "context": "For example, De Marcken (1994) also uses child language learning as a motivation, but approaches the segmentation problem instead of the learning of semantics.", "startOffset": 16, "endOffset": 31}, {"referenceID": 40, "context": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own.", "startOffset": 62, "endOffset": 240}, {"referenceID": 26, "context": "Many systems (Fukumoto & Tsujii, 1995; Haruno, 1995; Johnston, Boguraev, & Pustejovsky, 1995; Webster & Marcus, 1995) focus only on acquisition of verbs or nouns, rather than all types of words.", "startOffset": 13, "endOffset": 117}, {"referenceID": 9, "context": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-", "startOffset": 16, "endOffset": 135}, {"referenceID": 54, "context": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-", "startOffset": 16, "endOffset": 135}, {"referenceID": 38, "context": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-", "startOffset": 16, "endOffset": 135}, {"referenceID": 52, "context": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-", "startOffset": 16, "endOffset": 135}, {"referenceID": 4, "context": "Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas, 1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss the acquisition of subcategoriza-", "startOffset": 16, "endOffset": 135}, {"referenceID": 35, "context": "For example, Nenov and Dyer (1994) describe a neural network model to map between visual and verbal-motor commands, and Colunga and Gasser (1998) use neural network modeling techniques for learning spatial concepts.", "startOffset": 13, "endOffset": 35}, {"referenceID": 6, "context": "For example, Nenov and Dyer (1994) describe a neural network model to map between visual and verbal-motor commands, and Colunga and Gasser (1998) use neural network modeling techniques for learning spatial concepts.", "startOffset": 120, "endOffset": 146}, {"referenceID": 6, "context": "For example, Nenov and Dyer (1994) describe a neural network model to map between visual and verbal-motor commands, and Colunga and Gasser (1998) use neural network modeling techniques for learning spatial concepts. Feldman and his colleagues at Berkeley (Feldman, Lakoff, & Shastri, 1995) are actively pursuing cognitive models of the acquisition of semantic concepts. Another Berkeley effort, the system by Regier (1996) is given examples of pictures paired with natural language descriptions that apply to the picture, and learns to judge whether a new sentence is true of a given picture.", "startOffset": 120, "endOffset": 423}, {"referenceID": 6, "context": "For example, Nenov and Dyer (1994) describe a neural network model to map between visual and verbal-motor commands, and Colunga and Gasser (1998) use neural network modeling techniques for learning spatial concepts. Feldman and his colleagues at Berkeley (Feldman, Lakoff, & Shastri, 1995) are actively pursuing cognitive models of the acquisition of semantic concepts. Another Berkeley effort, the system by Regier (1996) is given examples of pictures paired with natural language descriptions that apply to the picture, and learns to judge whether a new sentence is true of a given picture. Similar work by Suppes, Liang, and B\u00f6ttner (1991) uses robots to demonstrate lexicon learning.", "startOffset": 120, "endOffset": 643}, {"referenceID": 6, "context": "For example, Nenov and Dyer (1994) describe a neural network model to map between visual and verbal-motor commands, and Colunga and Gasser (1998) use neural network modeling techniques for learning spatial concepts. Feldman and his colleagues at Berkeley (Feldman, Lakoff, & Shastri, 1995) are actively pursuing cognitive models of the acquisition of semantic concepts. Another Berkeley effort, the system by Regier (1996) is given examples of pictures paired with natural language descriptions that apply to the picture, and learns to judge whether a new sentence is true of a given picture. Similar work by Suppes, Liang, and B\u00f6ttner (1991) uses robots to demonstrate lexicon learning. A robot is trained on cognitive and perceptual concepts and their associated actions, and learns to execute simple commands. Along similar lines, Tishby and Gorin (1994) have a system that learns associations between words and actions, but they use a statistical framework to learn these associations, and do not handle structured representations.", "startOffset": 120, "endOffset": 858}, {"referenceID": 6, "context": "For example, Nenov and Dyer (1994) describe a neural network model to map between visual and verbal-motor commands, and Colunga and Gasser (1998) use neural network modeling techniques for learning spatial concepts. Feldman and his colleagues at Berkeley (Feldman, Lakoff, & Shastri, 1995) are actively pursuing cognitive models of the acquisition of semantic concepts. Another Berkeley effort, the system by Regier (1996) is given examples of pictures paired with natural language descriptions that apply to the picture, and learns to judge whether a new sentence is true of a given picture. Similar work by Suppes, Liang, and B\u00f6ttner (1991) uses robots to demonstrate lexicon learning. A robot is trained on cognitive and perceptual concepts and their associated actions, and learns to execute simple commands. Along similar lines, Tishby and Gorin (1994) have a system that learns associations between words and actions, but they use a statistical framework to learn these associations, and do not handle structured representations. Similarly, Oates, Eyler-Walker, and Cohen (1999) discuss the acquisition of lexical hierarchies and their associated meaning as defined by the sensory environment of a robot.", "startOffset": 120, "endOffset": 1085}, {"referenceID": 4, "context": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own. While most of these methods also compute association scores between pairs (in their case, word-word pairs) and use a greedy algorithm to choose the best translation(s) for each word, they do not take advantage of the constraints between pairs. One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does.", "startOffset": 219, "endOffset": 554}, {"referenceID": 4, "context": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own. While most of these methods also compute association scores between pairs (in their case, word-word pairs) and use a greedy algorithm to choose the best translation(s) for each word, they do not take advantage of the constraints between pairs. One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does. Also, Yamazaki, Pazzani, and Merz (1995) learn both translation rules and semantic hierarchies from parsed parallel sentences in Japanese and English.", "startOffset": 219, "endOffset": 718}, {"referenceID": 4, "context": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own. While most of these methods also compute association scores between pairs (in their case, word-word pairs) and use a greedy algorithm to choose the best translation(s) for each word, they do not take advantage of the constraints between pairs. One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does. Also, Yamazaki, Pazzani, and Merz (1995) learn both translation rules and semantic hierarchies from parsed parallel sentences in Japanese and English. Of course, the main difference between this body of work and this paper is that we map words to semantic structures, not to other words. As mentioned in the introduction, there is also a large body of work on learning lexical semantics but using different problem formulations than our own. For example, Collins and Singer (1999), Riloff and Jones (1999), Roark and Charniak (1998), and Schneider (1998) define semantic lexicons as a grouping of words into semantic categories, and in the latter case, add relational information.", "startOffset": 219, "endOffset": 1158}, {"referenceID": 4, "context": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own. While most of these methods also compute association scores between pairs (in their case, word-word pairs) and use a greedy algorithm to choose the best translation(s) for each word, they do not take advantage of the constraints between pairs. One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does. Also, Yamazaki, Pazzani, and Merz (1995) learn both translation rules and semantic hierarchies from parsed parallel sentences in Japanese and English. Of course, the main difference between this body of work and this paper is that we map words to semantic structures, not to other words. As mentioned in the introduction, there is also a large body of work on learning lexical semantics but using different problem formulations than our own. For example, Collins and Singer (1999), Riloff and Jones (1999), Roark and Charniak (1998), and Schneider (1998) define semantic lexicons as a grouping of words into semantic categories, and in the latter case, add relational information.", "startOffset": 219, "endOffset": 1183}, {"referenceID": 4, "context": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own. While most of these methods also compute association scores between pairs (in their case, word-word pairs) and use a greedy algorithm to choose the best translation(s) for each word, they do not take advantage of the constraints between pairs. One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does. Also, Yamazaki, Pazzani, and Merz (1995) learn both translation rules and semantic hierarchies from parsed parallel sentences in Japanese and English. Of course, the main difference between this body of work and this paper is that we map words to semantic structures, not to other words. As mentioned in the introduction, there is also a large body of work on learning lexical semantics but using different problem formulations than our own. For example, Collins and Singer (1999), Riloff and Jones (1999), Roark and Charniak (1998), and Schneider (1998) define semantic lexicons as a grouping of words into semantic categories, and in the latter case, add relational information.", "startOffset": 219, "endOffset": 1210}, {"referenceID": 4, "context": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own. While most of these methods also compute association scores between pairs (in their case, word-word pairs) and use a greedy algorithm to choose the best translation(s) for each word, they do not take advantage of the constraints between pairs. One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does. Also, Yamazaki, Pazzani, and Merz (1995) learn both translation rules and semantic hierarchies from parsed parallel sentences in Japanese and English. Of course, the main difference between this body of work and this paper is that we map words to semantic structures, not to other words. As mentioned in the introduction, there is also a large body of work on learning lexical semantics but using different problem formulations than our own. For example, Collins and Singer (1999), Riloff and Jones (1999), Roark and Charniak (1998), and Schneider (1998) define semantic lexicons as a grouping of words into semantic categories, and in the latter case, add relational information.", "startOffset": 219, "endOffset": 1232}, {"referenceID": 4, "context": "The problem of automatic construction of translation lexicons (Smadja, McKeown, & Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) has a definition similar to our own. While most of these methods also compute association scores between pairs (in their case, word-word pairs) and use a greedy algorithm to choose the best translation(s) for each word, they do not take advantage of the constraints between pairs. One exception is Melamed (2000); however, his approach does not allow for phrases in the lexicon or for synonymy within one text segment, while ours does. Also, Yamazaki, Pazzani, and Merz (1995) learn both translation rules and semantic hierarchies from parsed parallel sentences in Japanese and English. Of course, the main difference between this body of work and this paper is that we map words to semantic structures, not to other words. As mentioned in the introduction, there is also a large body of work on learning lexical semantics but using different problem formulations than our own. For example, Collins and Singer (1999), Riloff and Jones (1999), Roark and Charniak (1998), and Schneider (1998) define semantic lexicons as a grouping of words into semantic categories, and in the latter case, add relational information. The result is typically applied as a semantic lexicon for information extraction or entity tagging. Pedersen and Chen (1995) describe a method for acquiring syntactic and semantic features of an unknown word, assuming access to an initial concept hierarchy, but they give no experimental results.", "startOffset": 219, "endOffset": 1483}, {"referenceID": 38, "context": "tion information for verbs, and others describe work on learning selectional restrictions (Manning, 1993; Brent, 1991).", "startOffset": 90, "endOffset": 118}, {"referenceID": 4, "context": "tion information for verbs, and others describe work on learning selectional restrictions (Manning, 1993; Brent, 1991).", "startOffset": 90, "endOffset": 118}, {"referenceID": 31, "context": "Finally, several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available.", "startOffset": 25, "endOffset": 70}, {"referenceID": 27, "context": "Finally, several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available.", "startOffset": 25, "endOffset": 70}, {"referenceID": 58, "context": "Finally, several systems (Knight, 1996; Hastings, 1996; Russell, 1993) learn new words from context, assuming that a large initial lexicon and parsing system are already available.", "startOffset": 25, "endOffset": 70}, {"referenceID": 4, "context": "tion information for verbs, and others describe work on learning selectional restrictions (Manning, 1993; Brent, 1991). Both of these are different from the information required for mapping to semantic representation, but could be useful as a source of information to further constrain the search. Li (1998) further expands on the subcategorization work by inducing clustering information.", "startOffset": 106, "endOffset": 308}, {"referenceID": 28, "context": "Only a few of the researchers applying machine learning to natural language processing have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of these have addressed classification tasks such as part of speech tagging and text categorization.", "startOffset": 117, "endOffset": 273}, {"referenceID": 72, "context": "Only a few of the researchers applying machine learning to natural language processing have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of these have addressed classification tasks such as part of speech tagging and text categorization.", "startOffset": 117, "endOffset": 273}, {"referenceID": 6, "context": "2 Active Learning With respect to additional active learning techniques, Cohn et al. (1994) were among the first to discuss certainty-based active learning methods in detail.", "startOffset": 73, "endOffset": 92}, {"referenceID": 6, "context": "2 Active Learning With respect to additional active learning techniques, Cohn et al. (1994) were among the first to discuss certainty-based active learning methods in detail. They focus on a neural network approach to active learning in a version-space of concepts. Only a few of the researchers applying machine learning to natural language processing have utilized active learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999; Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994), and the majority of these have addressed classification tasks such as part of speech tagging and text categorization. For example, Liere and Tadepalli (1997) apply active learning with committees to the problem of text categorization.", "startOffset": 73, "endOffset": 699}, {"referenceID": 2, "context": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging.", "startOffset": 0, "endOffset": 34}, {"referenceID": 2, "context": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging. In their work, a committee of hidden Markov models is used to select examples for annotation. Lewis and Catlett (1994) use heterogeneous certainty-based methods, in which a simple classifier is used to select examples that are then annotated and presented to a more powerful classifier.", "startOffset": 0, "endOffset": 216}, {"referenceID": 2, "context": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging. In their work, a committee of hidden Markov models is used to select examples for annotation. Lewis and Catlett (1994) use heterogeneous certainty-based methods, in which a simple classifier is used to select examples that are then annotated and presented to a more powerful classifier. However, many language learning tasks require annotating natural language text with a complex output, such as a parse tree, semantic representation, or filled template. The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001), Soderland (1999), Thompson et al.", "startOffset": 0, "endOffset": 687}, {"referenceID": 2, "context": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging. In their work, a committee of hidden Markov models is used to select examples for annotation. Lewis and Catlett (1994) use heterogeneous certainty-based methods, in which a simple classifier is used to select examples that are then annotated and presented to a more powerful classifier. However, many language learning tasks require annotating natural language text with a complex output, such as a parse tree, semantic representation, or filled template. The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001), Soderland (1999), Thompson et al.", "startOffset": 0, "endOffset": 705}, {"referenceID": 2, "context": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging. In their work, a committee of hidden Markov models is used to select examples for annotation. Lewis and Catlett (1994) use heterogeneous certainty-based methods, in which a simple classifier is used to select examples that are then annotated and presented to a more powerful classifier. However, many language learning tasks require annotating natural language text with a complex output, such as a parse tree, semantic representation, or filled template. The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001), Soderland (1999), Thompson et al. (1999). The latter two include work on active learning applied to information extraction, and Thompson et al.", "startOffset": 0, "endOffset": 729}, {"referenceID": 2, "context": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging. In their work, a committee of hidden Markov models is used to select examples for annotation. Lewis and Catlett (1994) use heterogeneous certainty-based methods, in which a simple classifier is used to select examples that are then annotated and presented to a more powerful classifier. However, many language learning tasks require annotating natural language text with a complex output, such as a parse tree, semantic representation, or filled template. The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001), Soderland (1999), Thompson et al. (1999). The latter two include work on active learning applied to information extraction, and Thompson et al. (1999) includes work on active learning for semantic parsing.", "startOffset": 0, "endOffset": 839}, {"referenceID": 2, "context": "Argamon-Engelson and Dagan (1999) also apply committee-based learning to part-of-speech tagging. In their work, a committee of hidden Markov models is used to select examples for annotation. Lewis and Catlett (1994) use heterogeneous certainty-based methods, in which a simple classifier is used to select examples that are then annotated and presented to a more powerful classifier. However, many language learning tasks require annotating natural language text with a complex output, such as a parse tree, semantic representation, or filled template. The application of active learning to tasks requiring such complex outputs has not been well studied, the exceptions being Hwa (2001), Soderland (1999), Thompson et al. (1999). The latter two include work on active learning applied to information extraction, and Thompson et al. (1999) includes work on active learning for semantic parsing. Hwa (2001) describes an interesting method for evaluating a statistical parser\u2019s uncertainty, when applied for syntactic parsing.", "startOffset": 0, "endOffset": 905}, {"referenceID": 7, "context": "One critical problem is obtaining diverse committees that properly sample the version space (Cohn et al., 1994).", "startOffset": 92, "endOffset": 111}], "year": 2017, "abstractText": "This paper focuses on a system, Wolfie (WOrd Learning From Interpreted Examples), that acquires a semantic lexicon from a corpus of sentences paired with semantic representations. The lexicon learned consists of phrases paired with meaning representations. Wolfie is part of an integrated system that learns to transform sentences into representations such as logical database queries. Experimental results are presented demonstrating Wolfie\u2019s ability to learn useful lexicons for a database interface in four different natural languages. The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system, with results favorable to Wolfie. A second set of experiments demonstrates Wolfie\u2019s ability to scale to larger and more difficult, albeit artificially generated, corpora. In natural language acquisition, it is difficult to gather the annotated data needed for supervised learning; however, unannotated data is fairly plentiful. Active learning methods attempt to select for annotation and training only the most informative examples, and therefore are potentially very useful in natural language applications. However, most results to date for active learning have only considered standard classification tasks. To reduce annotation effort while maintaining accuracy, we apply active learning to semantic lexicons. We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance.", "creator": "dvips(k) 5.86 Copyright 1999 Radical Eye Software"}}}