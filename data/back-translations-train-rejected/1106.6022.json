{"id": "1106.6022", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jun-2011", "title": "Use of Markov Chains to Design an Agent Bidding Strategy for Continuous Double Auctions", "abstract": "As computational agents are developed for increasingly complicated e-commerce applications, the complexity of the decisions they face demands advances in artificial intelligence techniques. For example, an agent representing a seller in an auction should try to maximize the seller's profit by reasoning about a variety of possibly uncertain pieces of information, such as the maximum prices various buyers might be willing to pay, the possible prices being offered by competing sellers, the rules by which the auction operates, the dynamic arrival and matching of offers to buy and sell, and so on. A naive application of multiagent reasoning techniques would require the seller's agent to explicitly model all of the other agents through an extended time horizon, rendering the problem intractable for many realistically-sized problems. We have instead devised a new strategy that an agent can use to determine its bid price based on a more tractable Markov chain model of the auction process. We have experimentally identified the conditions under which our new strategy works well, as well as how well it works in comparison to the optimal performance the agent could have achieved had it known the future. Our results show that our new strategy in general performs well, outperforming other tractable heuristic strategies in a majority of experiments, and is particularly effective in a 'seller?s market', where many buy offers are available.", "histories": [["v1", "Wed, 29 Jun 2011 18:38:48 GMT  (449kb)", "http://arxiv.org/abs/1106.6022v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["w p birmingham", "e h durfee", "s park"], "accepted": false, "id": "1106.6022"}, "pdf": {"name": "1106.6022.pdf", "metadata": {"source": "CRF", "title": "Use of Markov Chains to Design an Agent Bidding Strategy for Continuous Double Auctions", "authors": ["Sunju Park", "Edmund H. Durfee"], "emails": ["SPARK@BUSINESS.RUTGERS.EDU", "DURFEE@UMICH.EDU", "WPBIRMINGHAM@GCC.EDU"], "sections": [{"heading": null, "text": "\u00a9 2004 AI Access Foundation. All Rights Reserved.The complexity of the decisions they face requires advances in artificial intelligence techniques. For example, an agent representing a seller at an auction should try to maximize the seller's profit by thinking about a variety of potentially uncertain information, such as the maximum prices that different buyers might be willing to pay, the possible prices offered by competing sellers, the rules by which the auction runs, the dynamic arrival and matching of purchase and sale offers, etc. A naive application of multi-agent reasoning techniques would require the seller's agent to explicitly model all other agents over a longer time horizon, making the problem insolvable for many realistically large problems. Instead, we have designed a new strategy that an agent can use to determine its offer price on the basis of a more traceable Markov chain model of the auction process that is better known to others than our strategy to have optimized and to determine the future performance of the auction process."}, {"heading": "1. Introduction", "text": "One example of such a problem, which has been the focus of recent research, is answering the question of where to buy from and how much they are willing to pay, but automated trading agents are increasingly being developed and used (Eriksson & Janson, 2002; Greenwald, 2003; Arunachalam et al., 2003). To a large extent, automated agents are limited to simpler types of e-commerce problems, where decisions about buying and selling and the prices at which they are to buy and sell are relatively formulaic (see, for example, http: / / www.ebay.com). The construction of certain types of auctions and other mechanisms designed for e-commerce systems can also simplify the decisions of agents, for example, by offering an offer price that differs from their true valuation for the object being exchanged (Vickrey, 1961).However, there are many types of trading problems where an agent must make decisions that an agent needs to formulate less."}, {"heading": "2. Related Work", "text": "In fact, it is as if most of them are able to abide by the rules that they have imposed on themselves. (...) In fact, it is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...)"}, {"heading": "3. The P-Strategy", "text": "First, we define the agent's decision problem in a CDA. Then we describe the p strategy algorithm using a simple Markov chain as an example."}, {"heading": "3.1. An Agent\u2019s Decision Problem in a CDA", "text": "As a result, most of them are no longer able to play by the rules they have imposed on themselves. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...)"}, {"heading": "3.2. The P-strategy Algorithm", "text": "In fact, most of them are able to survive themselves if they do not play by the rules. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...)"}, {"heading": "4. The Markov Chain Model for the CDA", "text": "In such a case, modelling the auction process using readily available information (such as the bidding history) is more appropriate than modelling the inner reasoning of each participating agent. Even if the information about each individual agent is available, such a model is usually too complex to be workable. For example, the complexity of the solution of the RMM model developed to level l is better than that of the individual agents."}, {"heading": "4.1. Variables Captured in the MC Model", "text": "We divide these variables into three groups, as shown in Table 1. Depending on the information available, you could use a different set of information for the brokerage strategy. Table 1 variables are the information that is readily available in most CDAs, and we have decided to capture them all in the MC model. The variables in the first group capture information about the current status of the auction. These variables are used to determine the amount of possible initial states. The amount of information available to the seller of the p strategy may vary, but we identify three parts of the information: the number of pending bids in the auction, the likely distribution2 of the permanent offer prices, and the clearing price quote. In Section 4.2, we will show an example of how MC models would differ if different amounts of information were used. The variables in the second group capture the history of the auction that is used to model the future auction process."}, {"heading": "4.2. Determining the Set of Initial States", "text": "In fact, most of them will be able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...)"}, {"heading": "4.3. Modeling the Auction Process", "text": "It is reasonable to assume that at most one single bid enters the auction at a time when CDA makes offers that arrive simultaneously and tries to enter each new offer (i.e., clear offers). We use the term clearing interval to indicate the interval between successive attempts at the auction to match buy and sell offers. Assuming that the offers arrive at a time, the auction may go to any of the following states from the (bbssp) state. (bbssp): No offer arrives during the clearing interval. (bbsp) A purchase offer arrives and is matched with the lowest sale offer. (bbbssp): A new purchase offer becomes a standing offer because there is no match. (bssp)"}, {"heading": "4.4. Computation of the Transition Probabilities", "text": "To complete the MC model, the p-seller must calculate the transition probabilities between the MC states. Note that, although we describe the structure of the MC model and calculate its transition probabilities separately, they are in fact a one-step process: the p-strategy agent calculates the transition probabilities during the build-up of the MC model. Assuming that the current clearing price, the highest purchase price, is available, we treat it as constant when calculating the transition probabilities. We use the transition from the initial state (bbs) to the (bbssp) state and the transition from the (bbssp) state to the (bbsp) state as our two examples. Although we represent the transition probability in two cases - the transition from a starting state (when receiving information about the auction) to a set of initial states (when making an offer) and the transition between the MC states, both are essentially the same."}, {"heading": "4.5. Computing the Expected Utility Value", "text": "In fact, the fact is that most of us will be able to be in a position to be in a position to be in a position to be in a position to be in a position to be able to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "5. Evaluation", "text": "So far, we have advocated incorporating techniques based on Markov chain models into the AI repertoire to support intelligent decision-making (bidding) in a continuous dual auction, and we have described the techniques we have developed along with the rationale for certain modeling decisions we have made along the way. We now turn to the question of whether our new techniques, embodied in the p strategy, actually lead to improved decisions, and if so, under what conditions. Essentially, we are trying to answer the question \"what bidding strategy should you as a seller use to maximize your profit?\" by comparing the p strategy with some heuristic strategies in a number of situations. We also analyze how close (or far) the p strategy is to performance and ex-post optimum."}, {"heading": "5.1. Experimental Testbed", "text": "In fact, it is in such a way that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process"}, {"heading": "5.2. Comparison of Agent Strategies", "text": "We compare the performance of the p strategy with that of the other strategies (FM, CP and OPT), and the most important questions are: whether the p strategy exceeds what we perceive as reasonable, realistic action strategies (other than the OPT strategy), and how far the p strategy goes compared to the (ideal) OPT strategy. We vary the negotiation zones and offer the arrival rates of buyers and sellers. To compare the action strategies, we replace the target seller, who is compared with the FM, RM, and OPT strategy seller in each series of experiments, while all other sellers participating in the auction simply offer their true costs and their CP strategy. Figure 85 shows the profits of the FM and CP strategy. RM, RM, P, OPT seller (represented as F, C, O)."}, {"heading": "5.3. Optimal Markups of the FM and CP Strategies", "text": "The value of 5 is close to the optimal markup value for the FM and CP vendors in the experiment in Figure 8- (b) - (ii), which contributes to their high performance (i.e., not significantly different from the FM vendor) in this experiment. This raises the question of whether the FM vendor with an optimal markup will be better (or similar to the vendor in any other case). After determining the optimal markup, we then examined the relationship between the markups and the performance of the FM vendor and the CP vendor. To answer this question, we first find the optimal markup of the FM and CP strategies in each case."}, {"heading": "5.4. Comparison to the OPT-strategy", "text": "Instead of comparing the p strategy with all possible strategies of the agent (which is impossible), we compare the p strategy with the OPT strategy (i.e., the ideal upper limit). In particular, we are interested in how closely the p strategy relates to the OPT strategy. Figure 9 shows the profit per offer of the agent that is normalized to the OPT strategy. Note that the p seller adjusts its offer price depending on the auction situation. If the negotiation zone is tight, he tries to increase the number of matches. If the negotiation zone is broad, he tries to increase the profit per match. If the arrival rate of the purchase offers is high, he tries to increase the profit per match while he tries to increase the number of matches when the arrival rate of the sales offers is high. Similar behavior is observed by the OPT seller, while the FM, RM and CP sellers exhibit completely different behaviors."}, {"heading": "5.5. Comparison of Agent Strategies under Different Agent Populations", "text": "This year, it is more than ever before in the history of the city in which we find ourselves."}, {"heading": "5.6. Performance of the P-strategy in the Presence of Competing P-strategy Sellers", "text": "Given the fact that most of them are able to survive themselves, it is not surprising that they are able to survive themselves, and that they are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "6. Conclusion", "text": "In fact, most of them are able to survive on their own."}, {"heading": "Acknowledgements", "text": "We thank the anonymous reviewers for their constructive comments. Organization, presentation and many details of the paper reflect their suggestions. We also thank Michael P. Wellman and Gary Olson for their feedback. This work was partly funded by the joint NSF / DARPA / NASA Digital Libraries Initiative under CERA IRI-9411287 and NSF grants IIS-9872057 and IIS-0112669."}, {"heading": "Appendix A: Notations", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "As computational agents are developed for increasingly complicated e-commerce applications, the complexity of the decisions they face demands advances in artificial intelligence techniques. For example, an agent representing a seller in an auction should try to maximize the seller\u2019s profit by reasoning about a variety of possibly uncertain pieces of information, such as the maximum prices various buyers might be willing to pay, the possible prices being offered by competing sellers, the rules by which the auction operates, the dynamic arrival and matching of offers to buy and sell, and so on. A na\u00efve application of multiagent reasoning techniques would require the seller\u2019s agent to explicitly model all of the other agents through an extended time horizon, rendering the problem intractable for many realistically-sized problems. We have instead devised a new strategy that an agent can use to determine its bid price based on a more tractable Markov chain model of the auction process. We have experimentally identified the conditions under which our new strategy works well, as well as how well it works in comparison to the optimal performance the agent could have achieved had it known the future. Our results show that our new strategy in general performs well, outperforming other tractable heuristic strategies in a majority of experiments, and is particularly effective in a \u201cseller\u2019s market,\u201d where many buy offers are available.", "creator": "(PScript5.dll Version 5.2)"}}}