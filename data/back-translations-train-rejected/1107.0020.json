{"id": "1107.0020", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2011", "title": "Learning to Order BDD Variables in Verification", "abstract": "The size and complexity of software and hardware systems have significantly increased in the past years. As a result, it is harder to guarantee their correct behavior. One of the most successful methods for automated verification of finite-state systems is model checking. Most of the current model-checking systems use binary decision diagrams (BDDs) for the representation of the tested model and in the verification process of its properties. Generally, BDDs allow a canonical compact representation of a boolean function (given an order of its variables). The more compact the BDD is, the better performance one gets from the verifier. However, finding an optimal order for a BDD is an NP-complete problem. Therefore, several heuristic methods based on expert knowledge have been developed for variable ordering. We propose an alternative approach in which the variable ordering algorithm gains 'ordering experience' from training models and uses the learned knowledge for finding good orders. Our methodology is based on offline learning of pair precedence classifiers from training models, that is, learning which variable pair permutation is more likely to lead to a good order. For each training model, a number of training sequences are evaluated. Every training model variable pair permutation is then tagged based on its performance on the evaluated orders. The tagged permutations are then passed through a feature extractor and are given as examples to a classifier creation algorithm. Given a model for which an order is requested, the ordering algorithm consults each precedence classifier and constructs a pair precedence table which is used to create the order. Our algorithm was integrated with SMV, which is one of the most widely used verification systems. Preliminary empirical evaluation of our methodology, using real benchmark models, shows performance that is better than random ordering and is competitive with existing algorithms that use expert knowledge. We believe that in sub-domains of models (alu, caches, etc.) our system will prove even more valuable. This is because it features the ability to learn sub-domain knowledge, something that no other ordering algorithm does.", "histories": [["v1", "Thu, 30 Jun 2011 20:32:16 GMT  (214kb)", "http://arxiv.org/abs/1107.0020v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["o grumberg", "s livne", "s markovitch"], "accepted": false, "id": "1107.0020"}, "pdf": {"name": "1107.0020.pdf", "metadata": {"source": "CRF", "title": "Learning to Order BDD Variables in Verification", "authors": ["Orna Grumberg", "Shlomi Livne", "Shaul Markovitch"], "emails": ["orna@cs.technion.ac.il", "slivne@cs.technion.ac.il", "shaulm@cs.technion.ac.il"], "sections": [{"heading": null, "text": "We propose an alternative approach where the variable ordering algorithm draws \"ordering experience\" from training models and uses the knowledge learned to search for good order. Our methodology is based on offline learning of pair preference classifiers from training models, i.e. learning which variable pair permutation is more likely to lead to good order. A number of training sequences are evaluated for each training model. Each training model is then marked on the rated orders with variable pair preference classifiers based on its performance, and constructs a pair preference table that is used to create the order.Our algorithm is integrated with SMV, which is one of the most commonly used verification systems. Preliminary empirical evaluation of our methodology, using real benchmark models, shows that the sub-models are more valuable than the existing knowledge (etc.)."}, {"heading": "1. Introduction", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want."}, {"heading": "2. Background", "text": "The use of binary decision diagrams (BDDs) to represent finite state systems and perform symbolic state violations is referred to as symbolic model check. BDDs have greatly expanded the capacity of model checkers, and models with 2100 states and more are routinely verified. BDDs were introduced by Akers (1978) as compact representations for Boolean functions. Bryant (1986) proposed ordered binary decision diagrams (OBDDs) as canonical representations of Boolean functions, and also showed algorithms for efficiently compressing Boolean operations to OBDD. The following subsection provides an overview of how finite state systems are represented in symbolic model check. BDDs are then described and the variable order problem is defined."}, {"heading": "2.1 Finite State Machines in Symbolic Model Checking", "text": "A state typically describes values of components (e.g. latches in digital circuits), with each component represented by a state variable. Let V = {v0, v1,... vn \u2212 1} represent the set of variables in a system. Let Kvi be the set of possible values for variable vi. Then, a state in the system can be described by assigning values to all variables in V. The set of all possible states SA = Kv0 \u00b7 Kv0 \u00b7 Kvn \u2212 1.A state can be written with a function that is true only in that state: n \u2212 1 = 0 (vi = = cj), where Cj Kvi is the value of vi in the state. A state set of states SA = Kv0 \u00b7 Kv0 \u00b7 Kvn \u2212 1.A state can be written using a function that is true only in that state."}, {"heading": "2.2 Binary Decision Diagrams", "text": "A binary decision diagram (ROBDD) is an OBDD in which each function represents a representative one. A BDD consists of two sink nodes and several non-sink nodes. The two sink nodes, labeled 0 and 1 Ross, represent the corresponding Boolean values. Each non-sink node is labeled with a Boolean function that corresponds to its 0-edge function if it has two output edges labeled 1 (or then) and 0 (or otherwise). Each non-sink node represents the Boolean function that corresponds to its 1-edge, or the Boolean function that corresponds to its 0-edge function if it has an ordered binary decision diagram (OBDD) is a BDD with the restriction that the variables are ordered, and each root-to-sink path in the OBDD represents the variables in the cending function."}, {"heading": "2.3 Static Ordering", "text": "To do this, they extract topological data from the model and use that data to determine an order. All algorithms convert the model, which is described by a series of other state functions, into a directed graph, called a model connectivity graph. Vertices in the graph are variables and Boolean operations (gates). A variable vertex represents a variable, while a gate vertex represents a function. The edges ni \u2192 nj in the graph lie between ni, which is either a variable or a gate vertex, and nj, which is a gate vertex. An edge ni \u2192 nj is placed if the function represented by ni is an operation (i.e. an immediate sub-function) of the function represented by nj. We can divide the static algorithms into four groups that differ in the way they use the graph information."}, {"heading": "2.3.1 Graph Search Algorithms", "text": "The method proposed by Malik et al. (1988) assigns a level metric to each vertex and arranges the variables in descending level value. The level of vertex without edges is set to zero, and the level of each other vertex (vi) is set to level (vi) = maxvj | vi \u2192 vj (level (vj) + 1) This method is similar to a BFS (wide first search), which originates in nodes that have no outer edges and progresses backwards in the model. Fujita et al. (1988) proposed to perform a DFS (depth first search) from the vertex without outer edges and to go backwards. Variables in this algorithm are added in post-order form. Malik et al. and Fujita et al. (1988) proposed to perform a DFS (depth first search) from the vertex without outer edges and to go backwards. This is rarely the case of the model check of multiplier algorithms (this algorithm is the base algorithm)."}, {"heading": "2.3.2 Graph Evaluation Algorithms", "text": "In this context, it should be noted that the figures, which in most cases have been figures in recent years, are not numbers, but numbers that are able to differ. In this context, it should be noted that the numbers which have soared in the last ten years have soared in the last ten years, the number of burglaries has soared in the last ten years, and the number of burglaries has soared in the last ten years. In this period, the number of burglaries has soared in the amount, and the number of burglaries has soared in the amount, and the number of burglaries has soared in the amount. In the last ten years, the number of burglaries has doubled, the number of burglaries and the number of burglaries has doubled, the number of burglaries has doubled, the number of burglaries has doubled, and the number of burglaries has tripled. In the last ten years, the number of burglaries has tripled, the number of burglaries has tripled, the number of burglaries has tripled, the number of burglaries has tripled, the number of burglaries has tripled, and the number of burglaries has tripled in the last ten years, the number of burglaries has tripled, the number of burglaries has tripled, and the number of burglaries has tripled in the last ten years, the number of the number of burglaries has tripled, the number of burglaries has tripled, the number of burglaries have tripled, the number of burglaries and the number of burglaries have tripled, and the number of the number of last ten years, the number of the number of burglaries has tripled, and the number of burglaries has tripled in the number, and the number of the number of the last ten years, and the number of the last ten years, and the number of burglaries has tripled in the number, and the number of the last ten years."}, {"heading": "2.3.3 Decomposition Algorithms", "text": "The algorithm of Malik et al. was extended by Toutai et al. (1990) and adapted for finite state machines (FSM). In their algorithm, a model is broken down into its next state functions, each of which is considered separately. Variables of each next state function are sorted according to Malik et al. The next state functions are then sorted according to a cost function. They are arranged so that functions with many overlapping variables stand side by side. Variable order is achieved by adding the variables of the next state functions according to the order of the parts, while the next state functions are sorted according to a cost function. Aziz et al. (1994) \"s algorithm breaks down the model in a different order. A hierarchically composed part is a part that forms a composition within the internal parts."}, {"heading": "2.3.4 Sample-Based Algorithms", "text": "Sample-based static algorithms (Jain et al., 1998) are not true static algorithms in the sense that they do not generate the order based on information from the model description. Sample algorithms perform tests on parts of the model (establishing transition relationships and attainable states), evaluating a number of jobs for each part, which are then merged into a complete order for the model. Sample algorithms use \"traditional\" algorithms to find the candidate jobs for the parts, and these candidate jobs are then checked by the scanning algorithm."}, {"heading": "2.3.5 Summary", "text": "Much of the graph search algorithms and graph evaluation algorithms have been developed for other problems and adapted for symbolic model verification; some of the algorithms have been developed in the context of combinational circuits, while others have been developed for the simple case of a function. In symbolic model verification, the models are rarely combinational (their results almost always depend on input from previous cycles), and there is more than one function that can be displayed. However, the adaptation of existing algorithms to the needs of symbolic model verification has had varying degrees of success. Most of the customized algorithms are heuristic and apply a simple rule with some logical considerations.The splitting algorithms are either heuristic or represent a theoretical upper limit. However, the limits they use are rarely realistic; for most models, we need much smaller BDDs. The algorithms are also based on splitting the model into parts and solving the order of each part by means of graph search algorithms."}, {"heading": "2.4 Learning to Order Elements", "text": "The preference predicate induction is based on a series of tagged element pairs in which the binary tag identifies the preferred element. Broos and Branting (1994) provide a method to induce a preference predicate using the next adjacent classification; the distance between an untagged pair and each tagged pair is calculated as the sum of the distances between the corresponding elements; the closest pair is selected; the preferred element of the untagged pair is the one that represents the preferred element in the tagged pair. Utgoff and Saxena (1987) represent a pair A, B by the concatenated feature vector < a1,. one, b1,.. bn >. The preference predicate is a decision tree that emerges from these examples.Utgoff and Clouse (1991) are elements < a predicate = a preference tree."}, {"heading": "3. A Learning Algorithm for Static Variable Ordering", "text": "Establishing a good variable order requires a comprehensive understanding of the BDDs and their relationship to the model they represent. < > This knowledge can be inserted manually by a human expert. However, this task is too complex for large models, so it is rarely done. Existing static order algorithms use relatively simple heuristic rules based on expert knowledge. These rules consider the model structure to compose the order. As the rules must be applied to all variables in all models, they are general and therefore limited in the ability to produce good orders. Alternatively, we can try to build a program that automatically acquires more specific knowledge based on order experience. In this section, we present such an algorithm. The first step in building such a learning algorithm determines what knowledge we want to gain from the ordering experience. Existing order algorithms show that the preferential relationship between variables is a key consideration for creating variables."}, {"heading": "3.1 Algorithm Framework", "text": "We begin by describing the general framework of the learning algorithm. Our goal is to find variable orders that result in BDDs with a small number of nodes. In the face of a training model, the algorithm first generates a series of orders of its variables. We define a utility function u over variable orders as follows: Each of the orders is used as the initial order to build the BDD representation of the model.This BDD (referred to as M-BDD) encompasses the partitioned transition relationship of the model and its sets of initial states. The instruction for use of a generated order is then defined in such a way that it is inversely proportional to the number of nodes in the M-BDD constructed with this order.A subset consisting of all the variable pairs appearing together in a next-state function is selected by the example extractor from all possible variable pairs. We call such pairs interacting variable pairs based on variable pairs."}, {"heading": "3.2 The Training Sequence Generator", "text": "The simplest strategy for generating such sequences is to generate random orders. In fact, this is the strategy we have applied in the experiments described in this paper. A potential problem with this approach is in areas where good orders (or bad orders) are rare. In such a case, a random generator will not necessarily produce sequences with the desired qualitative diversity.2 We use the SMV system (McMillan, 1993) for this purpose. An alternative approach is to actively try to produce orders that are very good, and orders that are very bad, resulting in a great variety in quality.2 One way to produce a good order is to take orders that are the result of the dynamic ordering process. Another option is to use an existing static ordering algorithm. An interesting idea is to try and start the process by using the results of the adaptive ordering algorithm as examples that affect it in a more varied way."}, {"heading": "3.3 The Example Extractor", "text": "Given a set of n variables, we can extract n \u043c (n \u2212 1) sample ordered pairs for training, but should we actually use all of these ordered pairs as examples? There are two main reasons for being selective about which examples to use: 1. Each example carries computational costs associated with marking, feature extraction, and additional calculation by the induction process; 2. Noisy examples are known to have adverse effects on the induction process; the process of selecting a subset of examples to be marked is called selective sampling; and there are two common methods of performing selective sampling: One is through automatic methods that use various general metrics to select informative examples (Lindenbaum, Markovitch, & Rusakov, 1999); the other is to use domain-specific heuristics about the potential of an example to be informative."}, {"heading": "3.4 The Example Tagger", "text": "An ordered variable pair (vi, vj) should be marked as belonging to C + if it is preferable to put vi before vj. Let V = {v1,.., vn} be the set of variables of a given model. Let O be the set of all possible orders over V. Let Ovi-vj be the set of all o-vj where vi is before vj. The ordered variable pair (vi, vj) is defined as being preferable to (vj, vi) if and only ifAverage {u (o) | o-vj-vj-vj-vj-v. Since it is not possible to evaluate all possible orders, examine, evaluate them and divide the samples into two sets as described above. Since the averages now estimate only the real averages of vi, we replace the term \"smaller\" in the above definition with \"significantly smaller.\""}, {"heading": "3.5 The Feature Extractor", "text": "If we want to generalize from training models to future invisible models, we cannot represent the pairs by the variable names. Rather, we should use a representation that can be used across models. Most induction algorithms require the examples to be represented by feature vectors. It is the process of constructing an appropriate feature set that is a critical part of applying a learning algorithm to a problem. It is a general scientific process in which a domain expert develops a set of features that could be relevant. It is the role of the induction algorithm to determine which feature combination is relevant to the specific problem. We have found a set of features via variable pairs. These features are extracted from the model connectivity graph. Some of these attributes are inspired by traditional static order algorithms. Attributes can be categorized into three groups: Variable attributes are defined by an individual variable and attempt to capture their properties."}, {"heading": "3.6 The Induction Algorithm", "text": "This type of representation can be used to generate classifiers by many inductive algorithms, including decision trees (Hunt, Marin, & Stone, 1966; Friedman, 1977; Quinlan, 1979; Breiman, Frieman, Olshen, & Stone, 1984), neural networks (Widrow & Hoff, 1960; Parker, 1985; Rumelhart & McClelland, 1986), and nearest neighbors (Cover & Hart, 1967; Duda & Hart, 1973)."}, {"heading": "3.7 The Ordering Algorithm", "text": "The result of the learning process described in the last four subsections is a set of decision trees, one for each training model. We could also create a tree based on the merging of generated samples. An advantage of the multi-tree approach is that we expect the examples from the same model to be more consistent, enabling compact trees to be created. In contrast, a set of examples from different models is likely to be louder and produce a large tree. In addition, the multi-tree version allows the use of a matching scheme during the ordering process as described below. In a Model M, the algorithm first extracts the interacting variable pairs. Each of the classifiers is then applied to the characteristic vector representations of these pairs. For each classifier, the classifications of all pairs are merged into a preference table. These tables are then merged into a table. The algorithm used to create the sequence uses the summarized preference table to describe the variable sequences of the following component."}, {"heading": "3.7.1 Building the Precedence Table", "text": "To create a precedent table based on a given classifier, the algorithm asks two questions for each interacting pair of variables vi, vj: 1. Should vi-vj? 2. Should vj-vi? If the two match, the pair order is set to the agreed order. If they do not match, the order is set to unknown. Table 2 summarizes all possible answers for the two questions and the resulting pair order."}, {"heading": "3.7.2 The Merging Algorithm", "text": "After constructing the precedent tables from the classifiers of the training model, we merge the tables according to a matching scheme. For each variable pair vi, vj, we count the number of tables that choose vi \u00b2 vj and the number of tables that choose vj \u00b2 vi. Then, we decide their matching order according to the majority (without taking into account the unknown votes). Assuming that the majority vote chooses the order vi \u00b2 vj, the trust for this matching is calculated by conf (vi \u00b2 vj) -conf (vj \u00b2 vi) -vote (vi \u00b2 vj) + vote (vj \u00b2 vi), where Voting (vi \u00b2 vj) is the number of tables that votevi \u00b2 vj and conf (vi \u00b2 vj) is the sum of the trust values of these ballots. Vote (vj \u00b2 vi) and conf (vj \u00b2 vi) are defined similarly. If this value turns out to be less than 0.1, we set it to a minimum value of 0.1."}, {"heading": "3.7.3 Cycle Resolution", "text": "In order to form a complete, strict order from the merged table, the table must not contain a cycle, but the above algorithm does not guarantee this. Therefore, we must apply a cycle resolution algorithm that makes the table cycle-free. The precedence table can be considered a directed graph in which the nodes are variables, and there is a weighted edge vi \u2192 vj, if and only if vi \u00b2 vj. There are many possible ways to eliminate cycles in a directed graph. A reasonable bias is the removal of the least number of edges. This problem is known as a minimal feedback arc and has been proven to be NP-hard (Karp, 1972). There are approximation algorithms for this problem (Even, Naor, Slider, & Sudan, 1998), but they are too costly for our purposes. Instead, we use a simple greedy algorithm to solve the problem (Edges). All limitations (are summarized in a list of weights)."}, {"heading": "3.7.4 Pair Precedence Ordering", "text": "At this stage of the algorithm, we maintain an acyclic summarized precedent table. The final step of the ordering process is the conversion of the partial order represented by this table into a total order. This is done by topological arrangement. At each stage, the algorithm finds all the minimum variables, i.e. variables that are not forced to follow other disordered variables. From this sentence, we select a variable with maximum fan-out and add them after the last variable ordered. We then add all variables that are larger than vadd but do not appear in any limitation with a disordered variable. We do this because it is desirable to place interacting variables close together. The algorithm of the pair precedent arrangement (PPO) is listed in Figure 7. Figure 8 lists the selection of vadd in the PO. One possible change in the ordering process is to delay the resolution of the cycle to the last stage."}, {"heading": "3.8 Experiments", "text": "This year it will be able to mention the aforementioned brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated csrteBnlrc\u00fce."}, {"heading": "4. Learning Context-Based Precedence for Static Ordering", "text": "Another important consideration is the clustering of variables and their subsequent sequence. The algorithms try to place highly interacting variables close together. The effect of variable clustering in a BDD can be seen in the simple example in Figure 3. In this function, switching between the two variables v2 and v3 leads to an increase of the BDD size by 3 nodes. In this function, all sequences in which the variables of the two clusters v1, v3 and v2, v4 are held together result in the minimum BDD representation. Other variable orders result in a less compact BDD. Therefore, the only key consideration in this function is compliance with clustering (precedence is not taken into account)."}, {"heading": "4.1 Variable Distance", "text": "The above discussion leads to the hypothesis that the distance between variables is an important factor when considering alternative orders. One way to obtain distance information is to learn the distance function between pairs of variables. However, there are two problems with this approach: 1. The target distance function is not well defined between models. If, for example, we train on small models, the absolute distance function is probably not applicable to large models. 2. Information about absolute distances between variables is not sufficient to construct a good order. This is because the absolute distance does not clearly define the order between the variables. In fact, it defines two possible orders, one being the opposite of the other. The example in Figure 11 shows that an order and its inversion can produce BDDs of significantly different sizes. Each of the BDDs in Figure 11 represents two functions, f1 (a, b, c, d, e)."}, {"heading": "4.2 Context-Based Precedence", "text": "A precedent relationship in context is a triple relationship vi-vj-vk: Since vi precedes vj and vk, the variable vj should precede the variable vk. Thus, the precedent relationship adds context in the context of paired order decisions. As in pair precedent learning, we define the universe as pairs < (vi, vj, vk), M >, where vi, vj, vk are variables in model M. The universe is divided into three classes, C +, C \u2212, C?, as before. Examples of these classes are drawn in the same way. The precedent system for pairs can be applied with minor changes to work with precedent relationships in context. These minor changes are described below."}, {"heading": "4.3 The Example Tagger", "text": "A triplet of variables (vi, vj, vk) should be marked as C + if, given that vi precedes vj and vk, it is preferable to place vj before vk (i.e. vi-vj-vk). As with pair preference learning, we use a set of evaluated variable orders to highlight each set of such orders, which can be divided into three subsets depending on which of the three variables is first defined. For a partition defined by, say, vi, we can test the order of vj and vk using t-test, as described in Section 3.4. To reduce the number of noisy examples, we only use the partition that provides the most significant t test results."}, {"heading": "4.4 The Feature Extractor", "text": "The attributes of a triplet (vi, vj, vk) are calculated on the basis of the attributes of the two pairs vi-vj and vi-vk. Each attribute value is the division / subtraction of two corresponding attribute values from the two pair attributes. Specifically, let's assume that the pair vi-vj has attributes f1 (vi, vj),..., fn (vi, vj) and the pair vi-vk attributes f1 (vi, vk),.., fn (vi, vk), then triple (vi, vj, vk) has attributes f1 (vi, vj) / f1 (vi, vk),..., fn (vi, vj) / fn (vi, vk). If a part of the fl (vi, vk) is closer than the path (vi, vk-vk function), then vj-vk is greater than the path (vd-j)."}, {"heading": "4.5 The Ordering Algorithm", "text": "The result of the learning phase is a series of decision trees, one for each model. This is the same as for context-free pairs. In this section we describe ways to use these trees for ordering."}, {"heading": "4.5.1 Building the Context Precedence Table", "text": "Whereas in the case of pair preference we had a table of size n2 (where n is the number of variables), we now create such a table for each context variable. For each table we perform an inconsistency removal similar to the one described in Section 3.7.1. However, if we ask the classifier the two questions vj, vk and vk, vj, we add the context variable vi to the query."}, {"heading": "4.5.2 Pair Precedence Ordering with Context Precedence Filtering", "text": "The ordering algorithm uses the pair preference table in the same way as the PPO algorithm. However, it often turns out that the PPO algorithm had several minimum variables, even after the use of the maximum fanout filter. We use the context-based preference table to further reduce the size of the set of minimum elements. We use the variables in the already ordered sequence as context variables and consider their associated tables. If the set of minimum elements contains a variable pair that is limited as vj-vk in one of the tables, we remove vk from the set. Figure 12 lists the code that, when added to the PPO algorithm, accepts a collection of variables Vadd (from which we previously randomly selected) and returns a variable. We call the new algorithm PPOCPF."}, {"heading": "4.6 Experiments", "text": "The results are shown in Figure 14. For comparison, we also show the performance of the PPO algorithm and the two expert algorithms. The PPOCPF algorithm outperforms all other algorithms on the two models tested. Results show that the context-based precedent relationships add valuable information. We tested the effect of the resources invested in the learning phase on the performance of the algorithms. Since the learning examples are tagged based on the evaluated training orders and since the evaluation of the training orders is the most resource-intensive operation, we used the number of these orders as a resource estimator. Figure 15 shows the learning curves of our algorithms, i.e. it shows how the system performance changes according to the used offline resources (the number of evaluated training orders)."}, {"heading": "5. Discussion", "text": "This year, it is only a matter of time before agreement is reached."}, {"heading": "Appendix A. Variable Pair Attributes", "text": "The following definitions and symbols are used in the attribute description: \u2022 NS-dependency on the next state description of the variables vi-vj to indicate that the variables vi-vj are dependent on the number of variables in model A.1. \u2022 Dependence on the number of variables vj-vj, on the number of variables in model A.1 Variable AttributesThe attributes computed for the variables vi-vj are: the number of variables on which the variables vi-vj-vj depend, the number of variables vj-vj-vj-vj-vj, the number of variables vi-vj-vj-vj-vj-vj, the number of variables vj-vj-vj-vj-vj-vj-vj-vj-vj vj, the number of vj-vj-vj-vj-vj-vv vv vj vv, the number of vj-vj-vj-vj-vj-vv vj vj-vj vv, the number of vj-vj-vj-vj-vj-vj-vj vj vj-vj vj-vj vj vv, the number of vj-vj-vj-vj-vj vj-vj vj vj-vj vj vj vj vj-vj vj vj-vj vj vj vj-vj vj vj vj vj vj-vj vj vj vj vj vj vj, the number of vj-vj-vj-vj-vj-vj-vj-vj-vj vj-vj vj vj vj vj vj vj-vj vj-vj vj vj vj vj vj vj-vj vj vj vj-vj vj vj vj-vj vj vj vj-vj vj vj vj vj-vj vj vj vj vj vj vj vj vj, the number of the vj-vj"}], "references": [{"title": "Binary decision diagrams", "author": ["S. Akers"], "venue": "IEEE Transactions on Computers, C-27 (6), 509\u2013516.", "citeRegEx": "Akers,? 1978", "shortCiteRegEx": "Akers", "year": 1978}, {"title": "BDD variable ordering for interacting finite state machines", "author": ["A. Aziz", "S. Tasiran", "R. Brayton"], "venue": "In Proceedings of the 31st Design Automation Conference (DAC),", "citeRegEx": "Aziz et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Aziz et al\\.", "year": 1994}, {"title": "RuleBase: An industry-oriented formal verification tool", "author": ["I. Beer", "S. Ben-David", "C. Eisner", "A. Landver"], "venue": "In Proceedings of the 33rd Design Automation Conference (DAC),", "citeRegEx": "Beer et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Beer et al\\.", "year": 1996}, {"title": "Efficient OBDD-based boolean manipulation in CAD beyond current limits", "author": ["J. Bern", "C. Meinel", "A. Slobodova"], "venue": "In Proceedings of the 32nd Design Automation Conference (DAC),", "citeRegEx": "Bern et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Bern et al\\.", "year": 1995}, {"title": "Simulated annealing to improve variable orderings for OBDDs", "author": ["B. Bollig", "M. Lobbing", "I. Wegener"], "venue": "In Proceedings of the International Workshop on Logic Synthesis, pp. 5b:5.1\u20135.10,", "citeRegEx": "Bollig et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Bollig et al\\.", "year": 1995}, {"title": "Improving the variable ordering of OBDDs is NP-complete", "author": ["B. Bollig", "I. Wegener"], "venue": "IEEE Transactions on Computers,", "citeRegEx": "Bollig and Wegener,? \\Q1996\\E", "shortCiteRegEx": "Bollig and Wegener", "year": 1996}, {"title": "Classification and Regression Trees", "author": ["L. Breiman", "J.H. Frieman", "R.A. Olshen", "C.J. Stone"], "venue": null, "citeRegEx": "Breiman et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Breiman et al\\.", "year": 1984}, {"title": "Combinational profiles of sequential benchmark circuits", "author": ["F. Brglez", "D. Bryan", "K. Kozminski"], "venue": "In Proceedings of the International Symposium on Circuits and Systems,", "citeRegEx": "Brglez et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Brglez et al\\.", "year": 1989}, {"title": "Compositional instance-based learning", "author": ["P. Broos", "K. Branting"], "venue": "In Proceedings of the 12th National Conference on Artificial Intelligence,", "citeRegEx": "Broos and Branting,? \\Q1994\\E", "shortCiteRegEx": "Broos and Branting", "year": 1994}, {"title": "Graph-based algorithms for boolean function manipulation", "author": ["R. Bryant"], "venue": "IEEE Transactions on Computers, C-35 (8), 677\u2013691.", "citeRegEx": "Bryant,? 1986", "shortCiteRegEx": "Bryant", "year": 1986}, {"title": "Heuristics to compute variable orderings for efficient manipulation of ordered binary decision diagrams", "author": ["K.M. Butler", "D.E. Ross", "Rohit Kapur", "a. M.R. M"], "venue": "In Proceedings of the 28th Design Automation Conference (DAC),", "citeRegEx": "Butler et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Butler et al\\.", "year": 1991}, {"title": "Parallel logic simulation of VLSI systems", "author": ["R. Chamberlain"], "venue": "Proceedings of the 32nd Design Automation Conference (DAC), pp. 139\u2013143, San Francisco, California.", "citeRegEx": "Chamberlain,? 1995", "shortCiteRegEx": "Chamberlain", "year": 1995}, {"title": "Efficient variable ordering heuristics for shared ROBDD", "author": ["P. Chung", "I. Hajj", "J. Patel"], "venue": "In Proceedings of the International Symposium on Circuits and Systems,", "citeRegEx": "Chung et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Chung et al\\.", "year": 1993}, {"title": "Automatic verification of finite state concurrent systems using temporal logic specifications", "author": ["E.M. Clarke", "F.A. Emerson", "A.P. Sistla"], "venue": "ACM Transactions on Programming Languages and Systems,", "citeRegEx": "Clarke et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Clarke et al\\.", "year": 1986}, {"title": "Learning to order things", "author": ["W.W. Cohen", "R.E. Schapire", "Y. Singer"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Cohen et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 1999}, {"title": "Nearest neighbor pattern classification", "author": ["T.M. Cover", "P.E. Hart"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cover and Hart,? \\Q1967\\E", "shortCiteRegEx": "Cover and Hart", "year": 1967}, {"title": "Genetic algorithm for variable ordering of OBDDs", "author": ["R. Drechsler", "B. Becker", "N. Gockel"], "venue": "IEEE Proceedings on Computers and Digital Techniques,", "citeRegEx": "Drechsler et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Drechsler et al\\.", "year": 1996}, {"title": "Fast exact minimization of BDDs", "author": ["R. Drechsler", "N. Drechsler", "A. Slobodova"], "venue": "In Proceedings of the 35th Design Automation Conference (DAC),", "citeRegEx": "Drechsler et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Drechsler et al\\.", "year": 1998}, {"title": "Pattern Classification and Scene Analysis", "author": ["R.O. Duda", "P.E. Hart"], "venue": null, "citeRegEx": "Duda and Hart,? \\Q1973\\E", "shortCiteRegEx": "Duda and Hart", "year": 1973}, {"title": "Approximating minimum feedback sets and multi-cuts in directed graphs", "author": ["G. Even", "J. Naor", "B. Schieber", "M. Sudan"], "venue": null, "citeRegEx": "Even et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Even et al\\.", "year": 1998}, {"title": "A recursive partitioning decision rule for nonparametric classification", "author": ["J. Friedman"], "venue": "IEEE Transactions on Computers, C-26 (4), 404\u2013408.", "citeRegEx": "Friedman,? 1977", "shortCiteRegEx": "Friedman", "year": 1977}, {"title": "Finding the optimal variable ordering for binary decision diagrams", "author": ["S.J. Friedman", "K.J. Supowit"], "venue": "In Proceedings of the 24th Design Automation Conference (DAC),", "citeRegEx": "Friedman and Supowit,? \\Q1987\\E", "shortCiteRegEx": "Friedman and Supowit", "year": 1987}, {"title": "Interleaving based variable ordering methods for ordered binary decision diagrams", "author": ["H. Fujii", "G. Ootomo", "C. Hori"], "venue": "In Proceedings of the IEEE/ACM international conference on Computer-aided design,", "citeRegEx": "Fujii et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Fujii et al\\.", "year": 1993}, {"title": "Evaluation and improvements of boolean comparison method based on binary decision diagrams", "author": ["M. Fujita", "H. Fujisawa", "N. Kawato"], "venue": "In Proceedings of the International Conference on Computer-Aided Design,", "citeRegEx": "Fujita et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Fujita et al\\.", "year": 1988}, {"title": "Variable ordering algorithms for ordered binary decision diagrams and their evaluation", "author": ["M. Fujita", "H. Fujisawa", "Y. Matsunaga"], "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,", "citeRegEx": "Fujita et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Fujita et al\\.", "year": 1993}, {"title": "BDD minimization by truth table permutations", "author": ["M. Fujita", "Y. Kukimoto", "R. Brayton"], "venue": "In Proceedings of the International Workshop on Logic Synthesis,", "citeRegEx": "Fujita et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Fujita et al\\.", "year": 1995}, {"title": "Experiments in Induction", "author": ["E. Hunt", "J. Marin", "P. Stone"], "venue": null, "citeRegEx": "Hunt et al\\.,? \\Q1966\\E", "shortCiteRegEx": "Hunt et al\\.", "year": 1966}, {"title": "Minimization of binary decision diagrams based on exchanges of variables", "author": ["N. Ishiura", "H. Sawada", "S. Yajima"], "venue": "In Proceedings of the International Conference on Computer-Aided Design,", "citeRegEx": "Ishiura et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Ishiura et al\\.", "year": 1991}, {"title": "FIRE: A fault-independent combinational redundancy identification algorithm", "author": ["M. Iyer", "M. Abramovici"], "venue": "IEEE Transactions on VLSI Systems,", "citeRegEx": "Iyer and Abramovici,? \\Q1996\\E", "shortCiteRegEx": "Iyer and Abramovici", "year": 1996}, {"title": "Sampling schemes for computing variable orderings", "author": ["J. Jain", "W. Adams", "M. Fujita"], "venue": "In Proceedings of the International Conference on Computer-Aided Design,", "citeRegEx": "Jain et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Jain et al\\.", "year": 1998}, {"title": "Reducibility among combinatorial problems", "author": ["R.M. Karp"], "venue": "Miller, R., & Thatcher, J. (Eds.), Complexity of Computer Computations, pp. 85\u2013103, New York. Plenum Press.", "citeRegEx": "Karp,? 1972", "shortCiteRegEx": "Karp", "year": 1972}, {"title": "Intertwined development and formal verification of a 60x bus model", "author": ["M. Kaufmann", "C. Pixley"], "venue": "In Proceedings of the International Conference on Computer Design: VLSI in Computers and Processors (ICCD\u2019", "citeRegEx": "Kaufmann and Pixley,? \\Q1997\\E", "shortCiteRegEx": "Kaufmann and Pixley", "year": 1997}, {"title": "Explorations of sequential atpg using boolean satisfiability", "author": ["H. Konuk", "R. Larrabee"], "venue": "In Proceedings of the 11th IEEE VLSI Test Symposium,", "citeRegEx": "Konuk and Larrabee,? \\Q1993\\E", "shortCiteRegEx": "Konuk and Larrabee", "year": 1993}, {"title": "Selective sampling for nearest neighbor classifiers", "author": ["M. Lindenbaum", "S. Markovitch", "D. Rusakov"], "venue": "In Proceedings of the Sixteenth national confernce on Artificial Intelligence,", "citeRegEx": "Lindenbaum et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Lindenbaum et al\\.", "year": 1999}, {"title": "Identifying sequentially untestable faults using illegal states", "author": ["D. Long", "M. Iyer", "M. Abramovici"], "venue": "In Proceedings of the 13th IEEE VLSI Test Symposium,", "citeRegEx": "Long et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Long et al\\.", "year": 1995}, {"title": "Logic verification using binary decision diagrams in a logic synthesis environment", "author": ["S. Malik", "A. Wang", "R. Brayton", "A. Sangiovanni-Vincentelli"], "venue": "In Proceedings of the International Conference on Computer-Aided Design,", "citeRegEx": "Malik et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Malik et al\\.", "year": 1988}, {"title": "Symbolic Model Checking: An Approach to the State Explosion Problem", "author": ["K. McMillan"], "venue": "Kluwer Academic Publisher.", "citeRegEx": "McMillan,? 1993", "shortCiteRegEx": "McMillan", "year": 1993}, {"title": "Speeding up variable ordering of OBDDs", "author": ["C. Meinel", "A. Slobodova"], "venue": "In Proceedings of the International Conference on Computer-Aided Design,", "citeRegEx": "Meinel and Slobodova,? \\Q1997\\E", "shortCiteRegEx": "Meinel and Slobodova", "year": 1997}, {"title": "Sample method for minimization of OBDDs", "author": ["C. Meinel", "A. Slobodova"], "venue": "In Proceedings of the Conference on Current Trends in Theory and Practice of Informatics,", "citeRegEx": "Meinel and Slobodova,? \\Q1998\\E", "shortCiteRegEx": "Meinel and Slobodova", "year": 1998}, {"title": "Linear sifting of decison diagrams", "author": ["C. Meinel", "F. Somenzi", "T. Theobald"], "venue": "In Proceedings of the 34th Design Automation Conference (DAC),", "citeRegEx": "Meinel et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Meinel et al\\.", "year": 1997}, {"title": "Functional approaches to generating orderings for efficient symbolic representations", "author": ["M.R. Mercer", "R. Kapur", "D.E. Ross"], "venue": "In Proceedings of the 29th Design Automation Conference (DAC)", "citeRegEx": "Mercer et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Mercer et al\\.", "year": 1992}, {"title": "Shared binary decision diagrams with attributed edges for efficient boolean function manipulation", "author": ["S. Minato", "N. Ishiura", "S. Yajima"], "venue": "In Proceedings of the 27th Design Automation Conference (DAC),", "citeRegEx": "Minato et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Minato et al\\.", "year": 1990}, {"title": "Waiting false path analysis of sequential logic circuits for performance optimization", "author": ["K. Nakamura", "K. Takagi", "S. Kimura", "K. Watanabe"], "venue": "In Proceedings of the International Conference on Computer-Aided Design,", "citeRegEx": "Nakamura et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Nakamura et al\\.", "year": 1998}, {"title": "Who are the variables in your neighbourhood", "author": ["S. Panda", "F. Somenzi"], "venue": "In Proceedings of the International Conference on Computer-Aided Design,", "citeRegEx": "Panda and Somenzi,? \\Q1995\\E", "shortCiteRegEx": "Panda and Somenzi", "year": 1995}, {"title": "Symmetry detection and dynamic variable ordering of decision diagrams", "author": ["S. Panda", "F. Somenzi", "B.F. Plessier"], "venue": "In Proceedings of the International Conference on Computer-Aided Design,", "citeRegEx": "Panda et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Panda et al\\.", "year": 1994}, {"title": "Learning logic", "author": ["D.B. Parker"], "venue": "Tech. rep. TR-47, Center for Computational Research in Economics and Management Science, MIT, Cambridge, MA.", "citeRegEx": "Parker,? 1985", "shortCiteRegEx": "Parker", "year": 1985}, {"title": "Specification and verification of concurrent systems in cesar", "author": ["J. Queille", "J. Sifakis"], "venue": "Proceedings of the 5th International Symposium on Programming,", "citeRegEx": "Queille and Sifakis,? \\Q1981\\E", "shortCiteRegEx": "Queille and Sifakis", "year": 1981}, {"title": "Discovering rules by induction from large collections of examples", "author": ["J.R. Quinlan"], "venue": "Expert Systems in the Micro Electronic Age, pp. 168\u2013201. Edinburgh University Press.", "citeRegEx": "Quinlan,? 1979", "shortCiteRegEx": "Quinlan", "year": 1979}, {"title": "Induction of decision trees", "author": ["J.R. Quinlan"], "venue": "Machine Learning, 1 (1), 81\u2013106.", "citeRegEx": "Quinlan,? 1986", "shortCiteRegEx": "Quinlan", "year": 1986}, {"title": "Dynamic variable ordering for ordered binary decision diagrams", "author": ["R. Rudell"], "venue": "Proceedings of the International Conference on Computer-Aided Design, pp. 42\u201347, Santa Clara, California.", "citeRegEx": "Rudell,? 1993", "shortCiteRegEx": "Rudell", "year": 1993}, {"title": "Parallel distibuted processing: Exploration in the microstructure of cognition", "author": ["D.E. Rumelhart", "J.L. McClelland"], "venue": null, "citeRegEx": "Rumelhart and McClelland,? \\Q1986\\E", "shortCiteRegEx": "Rumelhart and McClelland", "year": 1986}, {"title": "Implicit state enumeration of finite state machines using BDDs", "author": ["H. Touati", "H. Savoj", "B. Lin", "R. Brayton", "A. Sangiovanni-Vincetelli"], "venue": "In Proceedings of the International Conference on Computer-Aided Design,", "citeRegEx": "Touati et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Touati et al\\.", "year": 1990}, {"title": "Two kinds of training information for evaluation function learning", "author": ["P. Utgoff", "J. Clouse"], "venue": "In Proceedings of the Ninth National Conference on Artificial Intelligence,", "citeRegEx": "Utgoff and Clouse,? \\Q1991\\E", "shortCiteRegEx": "Utgoff and Clouse", "year": 1991}, {"title": "Learning a preference predicate", "author": ["P.E. Utgoff", "S. Saxena"], "venue": "In Proceedings of the Fourth International Workshop on Machine Learning,", "citeRegEx": "Utgoff and Saxena,? \\Q1987\\E", "shortCiteRegEx": "Utgoff and Saxena", "year": 1987}, {"title": "Design error diagnosis in sequential circuits", "author": ["A. Wahba", "D. Borrione"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "Wahba and Borrione,? \\Q1995\\E", "shortCiteRegEx": "Wahba and Borrione", "year": 1995}, {"title": "Adaptive switching circuits", "author": ["B. Widrow", "M.E. Hoff"], "venue": "IRE WESCON Convention Record,", "citeRegEx": "Widrow and Hoff,? \\Q1960\\E", "shortCiteRegEx": "Widrow and Hoff", "year": 1960}, {"title": "Improved variable ordering of BDDs with novel genetic algorithm", "author": ["N. Zhuang", "M. Benten", "P. Cheung"], "venue": "In Proceedings of the International Symposium on Circuits and Systems.,", "citeRegEx": "Zhuang et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Zhuang et al\\.", "year": 1996}], "referenceMentions": [{"referenceID": 0, "context": "One of the most promising solutions to this problem is the use of binary decision diagrams (BDDs) (Akers, 1978; Bryant, 1986) as the basic data structure in model checking.", "startOffset": 98, "endOffset": 125}, {"referenceID": 9, "context": "One of the most promising solutions to this problem is the use of binary decision diagrams (BDDs) (Akers, 1978; Bryant, 1986) as the basic data structure in model checking.", "startOffset": 98, "endOffset": 125}, {"referenceID": 36, "context": "Our algorithm was integrated with SMV (McMillan, 1993), which is the backbone of many verification systems.", "startOffset": 38, "endOffset": 54}, {"referenceID": 44, "context": "Model checking was introduced by Clarke and Emerson (1986) and by Queille and Sifakis (1981) in the early 1980s.", "startOffset": 66, "endOffset": 93}, {"referenceID": 0, "context": "BDDs were introduced by Akers (1978) as compact representations for boolean functions.", "startOffset": 24, "endOffset": 37}, {"referenceID": 0, "context": "BDDs were introduced by Akers (1978) as compact representations for boolean functions. Bryant (1986) proposed ordered binary decision diagrams (OBDDs) as canonical representations of boolean functions.", "startOffset": 24, "endOffset": 101}, {"referenceID": 5, "context": "Bollig and Wegener (1996) proved that finding an optimal variable ordering is an NPcomplete problem.", "startOffset": 0, "endOffset": 26}, {"referenceID": 5, "context": "Bollig and Wegener (1996) proved that finding an optimal variable ordering is an NPcomplete problem. An order is optimal if it yields a BDD with the smallest number of nodes. Bryant (1986) pointed out that variable ordering greatly influences the size of the BDD.", "startOffset": 0, "endOffset": 189}, {"referenceID": 31, "context": "The method suggested by Malik et al. (1988) assigns to each vertex a level metric and orders the variables in decreasing level value.", "startOffset": 24, "endOffset": 44}, {"referenceID": 22, "context": "Fujita et al. (1988) proposed executing a DFS (depth first search) from the vertices with no out edges, and progressing backwards.", "startOffset": 0, "endOffset": 21}, {"referenceID": 10, "context": "Butler et al. (1991) adapted the algorithm of Fujita et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 22, "context": "Another DFS-based algorithm relies on interleaving the variables in the order (Fujii et al., 1993).", "startOffset": 78, "endOffset": 98}, {"referenceID": 40, "context": "Minato et al. (1990) propagate values backward through the graph, starting from vertices with no out edges, whose value is set to 1.", "startOffset": 0, "endOffset": 21}, {"referenceID": 12, "context": "Chung et al.(1993) proposed two algorithm frameworks.", "startOffset": 0, "endOffset": 19}, {"referenceID": 34, "context": "The algorithm of Malik et al. was extended and adapted for finite-state machines (FSM) by Toutai et al. (1990). In their algorithm, a model is decomposed to its next state functions, each of which is considered separately.", "startOffset": 17, "endOffset": 111}, {"referenceID": 1, "context": "The algorithm of Aziz et al. (1994) decomposes the model in a different way.", "startOffset": 17, "endOffset": 36}, {"referenceID": 29, "context": "Sample-based static algorithms (Jain et al., 1998) are not real static algorithms in the sense that they do not create the order based on information extracted from the model description.", "startOffset": 31, "endOffset": 50}, {"referenceID": 8, "context": "Broos and Branting (1994) present a method for inducing a preference predicate using nearest neighbor classification.", "startOffset": 0, "endOffset": 26}, {"referenceID": 8, "context": "Broos and Branting (1994) present a method for inducing a preference predicate using nearest neighbor classification. The distance between an untagged pair and each tagged pair is computed as the sum of distances between the corresponding elements. The closest tagged pair is selected. The preferred element of the untagged pair is the one matching the preferred element in the tagged pair. Utgoff and Saxena (1987) represent a pair A,B by the concatenated feature vector \u3008a1, .", "startOffset": 0, "endOffset": 416}, {"referenceID": 8, "context": "Broos and Branting (1994) present a method for inducing a preference predicate using nearest neighbor classification. The distance between an untagged pair and each tagged pair is computed as the sum of distances between the corresponding elements. The closest tagged pair is selected. The preferred element of the untagged pair is the one matching the preferred element in the tagged pair. Utgoff and Saxena (1987) represent a pair A,B by the concatenated feature vector \u3008a1, . . . an, b1, . . . bn\u3009. The preference predicate is a decision tree induced from these examples. Utgoff and Clouse (1991) represent a preference predicate by a polynomial.", "startOffset": 0, "endOffset": 600}, {"referenceID": 48, "context": "The learner, which is an ID3 (Quinlan, 1986) decision tree generator, uses the tagged feature vectors to create a pair precedence classifier.", "startOffset": 29, "endOffset": 44}, {"referenceID": 36, "context": "We use the SMV (McMillan, 1993) system for this purpose.", "startOffset": 15, "endOffset": 31}, {"referenceID": 10, "context": "This attribute was inspired by the value used by Butler et al. (1991) to guide the DFS search.", "startOffset": 49, "endOffset": 70}, {"referenceID": 12, "context": "The distance-based ordering framework (Chung et al., 1993) uses a similar feature to order variables.", "startOffset": 38, "endOffset": 58}, {"referenceID": 20, "context": "This type of representation can be used to produce classifiers by many induction algorithms, including decision trees (Hunt, Marin, & Stone, 1966; Friedman, 1977; Quinlan, 1979; Breiman, Frieman, Olshen, & Stone, 1984), neural networks (Widrow & Hoff, 1960; Parker, 1985; Rumelhart & McClelland, 1986) and nearest neighbor (Cover & Hart, 1967; Duda & Hart, 1973).", "startOffset": 118, "endOffset": 218}, {"referenceID": 47, "context": "This type of representation can be used to produce classifiers by many induction algorithms, including decision trees (Hunt, Marin, & Stone, 1966; Friedman, 1977; Quinlan, 1979; Breiman, Frieman, Olshen, & Stone, 1984), neural networks (Widrow & Hoff, 1960; Parker, 1985; Rumelhart & McClelland, 1986) and nearest neighbor (Cover & Hart, 1967; Duda & Hart, 1973).", "startOffset": 118, "endOffset": 218}, {"referenceID": 45, "context": "This type of representation can be used to produce classifiers by many induction algorithms, including decision trees (Hunt, Marin, & Stone, 1966; Friedman, 1977; Quinlan, 1979; Breiman, Frieman, Olshen, & Stone, 1984), neural networks (Widrow & Hoff, 1960; Parker, 1985; Rumelhart & McClelland, 1986) and nearest neighbor (Cover & Hart, 1967; Duda & Hart, 1973).", "startOffset": 236, "endOffset": 301}, {"referenceID": 30, "context": "This problem is known as the minimum feedback arc set and is proven to be NP-hard (Karp, 1972).", "startOffset": 82, "endOffset": 94}, {"referenceID": 11, "context": "The ISCAS89 benchmark circuits have been used to empirically evaluate many algorithms that deal with various aspects of circuit design (Chamberlain, 1995; Wahba & Borrione, 1995; Nakamura, Takagi, Kimura, & Watanabe, 1998; Long, Iyer, & Abramovici, 1995; Iyer & Abramovici, 1996; Konuk & Larrabee, 1993).", "startOffset": 135, "endOffset": 303}, {"referenceID": 10, "context": "In both algorithms we used the adaptation for multiple starting points (Butler et al., 1991) and its expanded version, which includes the tie breaking rule (Fujita et al.", "startOffset": 71, "endOffset": 92}, {"referenceID": 24, "context": ", 1991) and its expanded version, which includes the tie breaking rule (Fujita et al., 1993).", "startOffset": 71, "endOffset": 92}, {"referenceID": 21, "context": "In addition, we compared our results to two advanced graph search algorithms for static ordering: the DFS append algorithm of Fujita et al. (1988) and the interleave algorithm of Fujii et al.", "startOffset": 126, "endOffset": 147}, {"referenceID": 21, "context": "(1988) and the interleave algorithm of Fujii et al. (1993). In both algorithms we used the adaptation for multiple starting points (Butler et al.", "startOffset": 39, "endOffset": 59}, {"referenceID": 53, "context": "Compared with previous work in machine learning, our precedence relations most resemble these of Utgoff and Saxena (1987). Our ordering approach, in which we construct a total order of elements by finding the precedence relation between them, is in essence the same as that of Cohen, Schapire and Singer (1999).", "startOffset": 97, "endOffset": 122}, {"referenceID": 53, "context": "Compared with previous work in machine learning, our precedence relations most resemble these of Utgoff and Saxena (1987). Our ordering approach, in which we construct a total order of elements by finding the precedence relation between them, is in essence the same as that of Cohen, Schapire and Singer (1999). Specifically, the second ordering algorithm of Cohen, Schapire and Singer also uses the topological ordering approach to create an order.", "startOffset": 97, "endOffset": 311}, {"referenceID": 14, "context": "Few works have applied learning to ordering techniques that are not utility based (Cohen et al., 1999).", "startOffset": 82, "endOffset": 102}], "year": 2011, "abstractText": "The size and complexity of software and hardware systems have significantly increased in the past years. As a result, it is harder to guarantee their correct behavior. One of the most successful methods for automated verification of finite-state systems is model checking. Most of the current model-checking systems use binary decision diagrams (BDDs) for the representation of the tested model and in the verification process of its properties. Generally, BDDs allow a canonical compact representation of a boolean function (given an order of its variables). The more compact the BDD is, the better performance one gets from the verifier. However, finding an optimal order for a BDD is an NP-complete problem. Therefore, several heuristic methods based on expert knowledge have been developed for variable ordering. We propose an alternative approach in which the variable ordering algorithm gains \u201cordering experience\u201d from training models and uses the learned knowledge for finding good orders. Our methodology is based on offline learning of pair precedence classifiers from training models, that is, learning which variable pair permutation is more likely to lead to a good order. For each training model, a number of training sequences are evaluated. Every training model variable pair permutation is then tagged based on its performance on the evaluated orders. The tagged permutations are then passed through a feature extractor and are given as examples to a classifier creation algorithm. Given a model for which an order is requested, the ordering algorithm consults each precedence classifier and constructs a pair precedence table which is used to create the order. Our algorithm was integrated with SMV, which is one of the most widely used verification systems. Preliminary empirical evaluation of our methodology, using real benchmark models, shows performance that is better than random ordering and is competitive with existing algorithms that use expert knowledge. We believe that in sub-domains of models (alu, caches, etc.) our system will prove even more valuable. This is because it features the ability to learn sub-domain knowledge, something that no other ordering algorithm does.", "creator": "dvips(k) 5.92a Copyright 2002 Radical Eye Software"}}}