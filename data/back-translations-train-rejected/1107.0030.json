{"id": "1107.0030", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2011", "title": "Coherent Integration of Databases by Abductive Logic Programming", "abstract": "We introduce an abductive method for a coherent integration of independent data-sources. The idea is to compute a list of data-facts that should be inserted to the amalgamated database or retracted from it in order to restore its consistency. This method is implemented by an abductive solver, called Asystem, that applies SLDNFA-resolution on a meta-theory that relates different, possibly contradicting, input databases. We also give a pure model-theoretic analysis of the possible ways to `recover' consistent data from an inconsistent database in terms of those models of the database that exhibit as minimal inconsistent information as reasonably possible. This allows us to characterize the `recovered databases' in terms of the `preferred' (i.e., most consistent) models of the theory. The outcome is an abductive-based application that is sound and complete with respect to a corresponding model-based, preferential semantics, and -- to the best of our knowledge -- is more expressive (thus more general) than any other implementation of coherent integration of databases.", "histories": [["v1", "Thu, 30 Jun 2011 20:34:53 GMT  (254kb)", "http://arxiv.org/abs/1107.0030v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["o arieli", "m bruynooghe", "m denecker", "b van nuffelen"], "accepted": false, "id": "1107.0030"}, "pdf": {"name": "1107.0030.pdf", "metadata": {"source": "CRF", "title": "Coherent Integration of Databases by Abductive Logic Programming", "authors": ["Ofer Arieli", "Marc Denecker", "Bert Van Nuffelen", "Maurice Bruynooghe"], "emails": ["oarieli@mta.ac.il", "Marc.Denecker@cs.kuleuven.ac.be", "Bert.VanNuffelen@cs.kuleuven.ac.be", "Maurice.Bruynooghe@cs.kuleuven.ac.be"], "sections": [{"heading": "1. Introduction", "text": "There are a number of problems involved in this process, most of which are as follows: 1) uniting the various ontologies and / or databases to obtain a fixed (global) schema, and translating the individual databases into the new ontology; 2) unifying integrity claims in a single global context, in particular, means eliminating contradictions among translators; 3) This property is sometimes referred to as compositionality (Verbaeten, Denecker & De Schreye, 2000)."}, {"heading": "2. Coherent Integration of Databases", "text": "We begin with a formal definition of our goal. In this work, we assume that we have a first-order database based on a fixed database schema S and a fixed domain D. Each element of D has a unique name. A database instance D indeed consists of atoms in the language L, which are instances of the schema S. As such, however, each instance D has a finite active database, which is a subset of D. Definition 1. A database is a pair (D, IC), where D is a database instance, and IC, the set of integrity constraints is a finite and classically consistent set of formulas in L. In view of a database DB = (D, IC), we apply the closed word assumptions, so that only the facts explicitly mentioned in D are considered true. Therefore, the underlying semantics correspond with minimal herbranding theory Definition 2 is the model of a minimum database, the model of an HD."}, {"heading": "3. Model-based Characterization of Repairs", "text": "In this section, we provide a semantics for describing repairs and preferred repairs in relation to a corresponding model theory, which in particular allows us to provide an alternative description of the favoured repairs, which is then used in relation to favoured semantics for database theory. We show that arbitrary repairs can be represented by two rated models of integrity constraints. If a database is inconsistent, then there is no second-rated interpretation that meets both its database and its integrity constraints. We show that arbitrary repairs can be represented by two rated models of integrity constraints. If a database is inconsistent, then there is no second-rated database that meets both its database and its integrity constraints."}, {"heading": "4. Computing Repairs through Abduction", "text": "In this section, we present an inductive system that consistently integrates possibly contradictory data sources, which calculates \u2264 -repaired databases18 for a number of data sources and a preference criterion \u2264. Our framework consists of an abductive logic program (Denecker & Kakas, 2000) and an abductive solver A system (Kakas, Van Nuffelen, & Denecker, 2001; Van Nuffelen & Kakas, 2001), which is on the 18th level. It is important to note already at this stage that it will not be necessary to produce all repaired databases for the calculation of \u2264 -repaired databases. SLDNFA deductive refutation method (Denecker & De Schreye, 1992, 1998). In the first three parts of this section, we describe these components: in Section 4.1, we give a general description of the abductive reasoning; in Section 4.2, we show how it can be applied to database recovery, and in Section 4.3, we show the results of our system. \""}, {"heading": "4.1 Abductive Logic Programming", "text": "A term is either a variable, a constant, or a compound term f (t1,.., tn), where f is a n-like function symbol and terms. An atom is an expression of the form p (t1,.., tm), where p is a m-like predicate symbol and ti (i = 1,., m) are terms. A letter is an atom or a negated atom. A denial is an expression of the form p (t1,., tm), where F is a concatenation of words and X is a subset of variables in F. The free variables in F (those that are not in the X) can be considered placeholders for objects of unspecified identity."}, {"heading": "4.2 An Abductive Meta-Program for Encoding Database Repairs", "text": "The task of repairing the union of n given databases DBi in relation to the integration of local integrity constraints IC, can be represented by an abductive theory T = (P, A, IC), where P is a metaprogram encoding the integrity constraints as a new database is obtained by updating existing databases, A is the sentence {insert, retract} of inductable predicates used to describe updates, and IC \"encodes the integrity constraints.\" In P, facts appearing in at least one of the databases are encoded by atomic rules db (p), and facts appearing in the updated database are represented by atoms fact (p). The latter predicate is defined as follows: fact (X), facts appearing in at least one of the databases are encoded by atomic rules."}, {"heading": "4.3.1 Abductive Inference", "text": "The answer to this question is: \"I believe it is not as if.\" - \"It is as if.\" - \"It is as if.\" - \"It is as if.\" - \"It is as if.\" - \"It is as if.\" - \"It is as if.\" - \"It is as if.\" - \"It is as if.\" - \"It is as if.\" - \"It is.\" - \"It is.\" - \"It is.\" - \"It.\" - \"It.\" - \"It.\" - \"It.\" - \"It.\" -. - \"-. -\" - \"-\" -. - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-. -\" - -. - - \"- -\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-."}, {"heading": "4.3.2 Constraint Transformation to Denial Form", "text": "Since the derivative rules of the A system are applied only to integrity constraints in the denial form, the integrity constraints IC must be translated into this form in the abductive theory T. This is done by applying a variant of the Lloyd-Topor transformation (Lloyd & Topor, 1984) to the integrity constraints (see Denecker & De Schreye, 1998), the same procedure as the known method used in deductive databases to transform a quantified first-order query into a logically equivalent pair of an atomic query and a non-recursive database method (see Denecker & De Schreye, 1998)."}, {"heading": "4.3.3 Control Strategy", "text": "The selection strategy used during the derivation process is crucial. A prologue-like selection strategy (first left, then deep) often leads to trashing because it is blind to other decisions and does not provide a global overview of the current state of the calculation. In the development of the A system, the emphasis was on improving the control strategy. The idea is to first apply those rules that lead to a deterministic change of state so that information is disseminated. If none of these rules is applicable, one of the remaining decisions is selected. By this strategy, the commitment to a choice is suspended until no other information can be derived in a deterministic manner, similar to a CLP solver where the restrictions disseminate their information as soon as a choice is made. This dissemination can reduce the number of decisions to be made and thus often dramatically increase performance."}, {"heading": "4.3.4 Implementation", "text": "In this section we describe the structure of our implementation. Figure 3 shows a layered view. The top level consists of the specific abductive logic theory of the integration task, i.e. database information and integrity constraints. This layer, together with the composer, forms the abductive meta-theory (see Section 4.2), which is processed by the Asystem. As mentioned above, the composer consists of a meta-theory for the coherent integration of the databases. It is interpreted here as an abductive theory, in which the abductable predicates provide the information on how to restore the consistency of the amalgamated data. The abductive system (surrounded by dashed lines in Figure 3) consists of three main components: a finite domain constraint solver (part of Sicstus prolog), an abductive meta interpreter (described in the previous sections), and an optimizer is a component that prefers a branch solution, which is a space constraint."}, {"heading": "4.3.5 Complexity", "text": "It is well known that the task of repairing a database cannot be undone, as there can be an exponential number of different types of repair. Also, in cases where integrity limitations are assumed, it is possible that a particular database exists in which a certain query Q is fulfilled, in which a fact is fulfilled by all repaired databases, it is in P 2 (see Greco & Zumpano, 2000). This is not surprising given the correspondence between the compositions of \u2264 -minimal repairs and calculations of entailment relationships defined by maximally consistent models (see Propositions 5-8), which are also known at the second level of the polynomial hierarchy. A pure upper limit for the system is still unknown, because - up to the best results of our knowledge."}, {"heading": "Ei = Ei\u22121, and", "text": "Gi = Gi \u2212 1\\ {retract (teaches (c2, n3))) leads to failure (already since (c2, n2) = 2 (teaches (c2, n3)).Since the last goal is certainly fulfilled, ic1 is successful in this area, so the only interesting case is if x = n3. In this case, the evaluation leads to the goal gives courses (X).The unfolding of this goal results in the fact (teaches (Y, n3) appearing in the set goal. To fulfill this goal, it should be solved either with one of the composer's rules (using D.1).The first rule (i.e., the fact (X) that db (X) is explicit."}, {"heading": "4.5 Soundness and Completeness", "text": "In this section we give some solid and complete results for the A system, and relate these results to the model-based preferred semantics, which is in Section 3.In what follows, we are of T an abductive meta-theory (constructed as described in Section 4.2) for the compilation n given databases DB1,., DBn. Let also ProcALP be an abductive solution, which is obtained by ProcALP for the query \"true\" on a theory T, is a repair of UDB.25. The variable Y is free and {Y / c3} is an answer substitution as it reasoned and satisfied E."}, {"heading": "4.6 Handling Specialized Information", "text": "The purpose of this section is to demonstrate the potential use of our system in more complex scenarios in which different types of specialized data flow into the system. In particular, we briefly consider time information and source identification. We also provide some guidelines on how the system can be expanded with capabilities to handle such information."}, {"heading": "4.6.1 Timestamped Information", "text": "Many database applications contain temporal information, which can be divided into two types: time information that is part of the data itself, and time information that relates to database operations (e.g. records of database updates), such as the date of birth (John, 15 / 05 / 2001). In our approach, time information can be integrated by adding a temporal theory that describes the state of the database at a given time. One way to do this is to use situational calculations, in which a database is performed through some initial information and a history of events during the database's lifetime (see Tab, 1995). Here, we use a different approach based on event calculations (Kowalski & Sergot, 1986)."}, {"heading": "4.6.2 Keeping Track of Source Identities", "text": "In fact, it is important to obtain the identity of the database from which most of the information comes. (...) This type of information can be decoded by adding another argument to the individual factors. (...) It is possible to identify the identity of the database. (...) It is so that it is the only component that can track the source of the information. (...) It is so that there is another argument to each database that identifies its source. (...) It is as if there is the way in which the data is integrated. (...) It is the only component that can track the track of the database. (...) It is so that it adds a further argument to each database that identifies its source. (...) It is a fact that X is a fact that originated from a database. (...)"}, {"heading": "5. Discussion and an Overview of Related Works", "text": "Interest in systems for the coherent integration of databases has grown steadily in recent years (see, for example, Olive \u0301, 1991; Baral et al., 1991, 1992; Revesz, 1993; Subrahmanian, 1994; Bry, 1997; Gertz & Lipeck, 1997; Messing, 1997; Lin & Mendelzon, 1998; Liberatore & Schaerf, 2000; Ullman, 2000; Greco & Zumpano, 2000; Greco et al., 2001; Franconi et al., 2001; Lenzerini, 2002; Arenas et al., 1999; Bravo & Bertossi, 2003; Cali et al., 2003 and many others). Early work on this topic has shown that the design of systems for data integration is a complex task requiring solutions to many questions from different disciplines, such as faith revision and updating."}, {"heading": "6. Summary and Future Work", "text": "In fact, most of them are able to survive on their own."}, {"heading": "Acknowledgements", "text": "We would like to thank the anonymous reviewers for many helpful comments and suggestions. This research was supported by the Research Fund K.U.Leuven and FWO-Vlaanderen."}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": "We introduce an abductive method for a coherent integration of independent datasources. The idea is to compute a list of data-facts that should be inserted to the amalgamated database or retracted from it in order to restore its consistency. This method is implemented by an abductive solver, called Asystem, that applies SLDNFA-resolution on a meta-theory that relates different, possibly contradicting, input databases. We also give a pure model-theoretic analysis of the possible ways to \u2018recover\u2019 consistent data from an inconsistent database in terms of those models of the database that exhibit as minimal inconsistent information as reasonably possible. This allows us to characterize the \u2018recovered databases\u2019 in terms of the \u2018preferred\u2019 (i.e., most consistent) models of the theory. The outcome is an abductive-based application that is sound and complete with respect to a corresponding model-based, preferential semantics, and \u2013 to the best of our knowledge \u2013 is more expressive (thus more general) than any other implementation of coherent integration of databases.", "creator": "dvips(k) 5.92b Copyright 2002 Radical Eye Software"}}}