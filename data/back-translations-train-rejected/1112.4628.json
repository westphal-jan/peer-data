{"id": "1112.4628", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2011", "title": "Using Artificial Bee Colony Algorithm for MLP Training on Earthquake Time Series Data Prediction", "abstract": "Nowadays, computer scientists have shown the interest in the study of social insect's behaviour in neural networks area for solving different combinatorial and statistical problems. Chief among these is the Artificial Bee Colony (ABC) algorithm. This paper investigates the use of ABC algorithm that simulates the intelligent foraging behaviour of a honey bee swarm. Multilayer Perceptron (MLP) trained with the standard back propagation algorithm normally utilises computationally intensive training algorithms. One of the crucial problems with the backpropagation (BP) algorithm is that it can sometimes yield the networks with suboptimal weights because of the presence of many local optima in the solution space. To overcome ABC algorithm used in this work to train MLP learning the complex behaviour of earthquake time series data trained by BP, the performance of MLP-ABC is benchmarked against MLP training with the standard BP. The experimental result shows that MLP-ABC performance is better than MLP-BP for time series data.", "histories": [["v1", "Tue, 20 Dec 2011 09:50:53 GMT  (289kb)", "http://arxiv.org/abs/1112.4628v1", "8 pages,8 figures;this http URL"]], "COMMENTS": "8 pages,8 figures;this http URL", "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.LG", "authors": ["habib shah", "rozaida ghazali", "nazri mohd nawi"], "accepted": false, "id": "1112.4628"}, "pdf": {"name": "1112.4628.pdf", "metadata": {"source": "CRF", "title": "Using Artificial Bee Colony Algorithm for MLP Training on Earthquake Time Series Data Prediction", "authors": ["Habib Shah", "Rozaida Ghazali", "Nazri Mohd Nawi"], "emails": [], "sections": [{"heading": null, "text": "With the help of the artificial bee colony algorithm for the MLP Training on Earthquake Time Series DataPrediction Habib Shah, Rozaida Ghazali and Nazri Mohd NawiAbstract, computer scientists have now shown interest in studying the behaviour of social insects in the field of neural networks to solve various combinatorial and statistical problems, notably the Artificial Bee Colony (ABC) algorithm, which investigates the use of an ABC algorithm that simulates the intelligent dietary behaviour of a swarm of honeybees. Multilayer Perceptron (MLP), which is trained with the standard algorithm for the propagation of bees, usually uses computer-intensive training algorithms. One of the fundamental problems with the baking propagation (BP) algorithm is that it can sometimes produce networks with suboptimal weights, as many local optima are present in the solution space."}, {"heading": "1 INTRODUCTION", "text": "In fact, it is as if most people are able to survive themselves if they go into another world. (...) It is as if they go into another world. (...) It is as if they go into another world. (...) It is as if they go into another world. (...) It is as if they go into another world. (...) It is as if they go back into another world. (...) It is as if they go back into another world. (...) It is as if they come into another world. (...) It is as if they go into another world. (...) It is as if they go into another world. (...) It is as if they go back into another world. (...). (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. It is. (...) It is. (... It is. (...) It is. It is. (...) It is. It is. (...) It is. (it is. (...) It is. It is. (...) It is. (it is. (...) It is. (it is. It is. It is. (...). It is. It is. It is. (it is. It is. It is. It is. It is. (...). It is. It is. It is. It is. It is. (it is. It is. It is. It is. It is. (...). It is. It is. It is. (it is. It is. It is. It is. It is."}, {"heading": "2 ARTIFICIAL NEURAL NETWORKS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 TRAINING OF MLP NEURAL NETWORKS", "text": "MLP was introduced in 1957 to solve various combinatorial problems [27]. MLP, also known as feed forward neural networks, was first introduced for non-linear XOR and then successfully applied to various combinatorial problems. MLP is mainly used for information processing and pattern recognition in predicting seismic activity. In this section, the properties and interaction of MLP with seismic signals are explained. MLP works as a universal approach in which the input signal propagates forward. It is widely used and tested with different problems such as predicting time series and function approximation [1], [3], [4], [8]. Figure 1 shows the architecture of the MLP with two hidden layers, an output layer and an input layer. F ig 1: M u lt i L a y r Prediction and function approximation is the precipitation of the sign of the starting point and the starting point."}, {"heading": "3 ARTIFICIAL BEE COLONY", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Swarm Intelligence", "text": "For the past two decades, swarm intelligence (SI) has been the focus of much research because of its unique behavior inherent in social insects [13], [14], [22], [25]. Bonabeau defined SI as \"any attempt to design algorithms or distribute problem solvers inspired by the collective behavior of social insect colonies and other animal societies.\" [28] He focused mainly on the behavior of social insects alone such as termites, bees, wasps, and various ant species. However, Swarm can be considered as any collection of interacting agents or individuals. Ants are individual agents of ACO [29]. An immune system can be considered as a group of cells and molecules, as well as a swarm of humans [31]. PSO and ABC are popular population-based stochastic optimization algorithms adapted to optimize nonlinear functions in multidimensional space [32]."}, {"heading": "3.2 Artificial Bee Colony algorithm", "text": "In fact, it is the case that most people who are able to save themselves, to save themselves and their environment, are not able to save themselves. (...) In fact, it is the case that people are able to save themselves. (...) In fact, it is the case that people are able to save themselves. (...) It is the case that people are able to save themselves. (...) In fact, it is the case that people are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves. (...) People are able to save themselves."}, {"heading": "4 THE PROPOSED FRAMEWORK FOR MLP-ABC", "text": "The proposed flow chart of the ABC algorithm for predicting earthquake time series is reproduced in Figure 2. In the figure, each search cycle consists of three steps after initialization of the colony, foods and three control parameters in the number of food sources corresponding to the number of employed bees or show bees (SN), the limit, the maximum cycle number (MCN) for the MLP-ABC algorithm. The initialization of the weights was compared with the yield and the best weight cycle was selected from the selection phase of the bees. The bees (busy bees, show bees) continued to search until the last cycle to find the best weights for the networks. The food source from which the nectar was neglected by the bees was replaced by a new food source by the show bees. Each bee (busy bees, show bees, show bees) continued to find the last cycle of the show bee, the best source of the show bee was replaced by the show bee."}, {"heading": "5 PREDICTION OF EARTHQUAKE EVENT", "text": "The data from the Southern California Earthquake Data Center (SCEDC) for 2011 were selected [30]. The data included local, regional and quarry-induced events with epicentres between the latitudes 32.0 S and 37.0 N and longitudes between -122.0 W and -114.0 E. There were four important earthquake parameters, namely earthquake depth, time of occurrence, geographical area and magnitude of the earthquakes. Significant parameters on the Richter scale were used to simulate earthquake size prediction. Data collected from the SCEC website were used to define entry classes and test the MLP-ABC model proposed in this study. Earthquake records of Southern California between January 1, 2010 and May 30, 2011 were divided into fifty seismic size forecasting datasets."}, {"heading": "6 SIMULATION RESULTS", "text": "In order to evaluate the performance of the proposed ABC to train MLP for benchmark testing earthquake time series scheme for prediction techniques, simulation experiments were conducted on a 1.66 GHz Core 2 Duo Intel workstation with 1GB of RAM with Matlab 2010a software. Comparison of standard BP training and ABC algorithms is discussed based on simulation results in Matlab 2010a. California earthquake data for 2011 were obtained from http: / / www.data.scec.org /. The earthquake parameter magnitude was used to train the MLP with ABC algorithms. Data was divided into two datasets: 70% for training and 30% for testing. Learning rate (LR) and Dynamics (MOM) were set to 0.6 and 0.5, bearing in mind that the range of weights for both experiments is different."}, {"heading": "LR 0.6 __________", "text": "No. of hidden nodes From 2 to 4 nodes Number of input nodes From 2 to 4 nodes q = 84 nodes Number of output nodes From 1 to 4 nodes Weights range [1, -1] [10, -10] Runtime _ _ _ _ _ _ _ _ _ _ _ From 2 to 10 where OFE = ABC FoodSource.The dimension (D) can change the structure of MLPABC network model selected where 6, 9, 13, 16, 22, and 28 showed 2-2-1, 2-3-1, 3-1, 4-2-4-4-4, respectively.From Table 1, we can see that the maximum cycle numbers are less than maximum epochs for MLP-ABC training during the OFE increases. The network structure used in this experiment began with two inputs, two hidden and one output layer up to four inputs, four hidden and two output nodes containing the MSE for training MP-ABC-ABC-ABC training."}, {"heading": "F ig 7 : T e s tin g o f E a r th q u a k e D a ta b y M L P -B P", "text": "F ig 8: T e s t in g o f E a r th q u a k e D a ta b y M L P -A B CFigures 5, 6, 7 and 8 show that the prediction of the ABC algorithm follows the actual trend during training and testing phases. Overall, the ABC algorithm has shown an accuracy of 99.89 percent for earthquake data in time series, which is significantly higher than the MLP-BP algorithm. Meanwhile, the MLP-BP has an accuracy of 89 percent, which is significantly lower than MLP-ABC."}, {"heading": "7 CONCLUSION", "text": "The ABC algorithm successfully combines the exploration and recovery processes, demonstrating the high performance of the MLP training for predicting earthquake time series. It has the powerful ability to search for global optimal solutions. Therefore, the correct weighting of the algorithms can accelerate initialization and improve the predictive accuracy of the trained NNs. The simulation results show that the proposed ABC algorithm can successfully train real-time data for prediction purposes, which further increases the quality of the given approach. ABC's performance is compared with the traditional BP algorithm. ABC shows significantly higher results than the reverse propagation during the experiment. ABC also shows higher accuracy in predicting. The proposed frameworks have successfully predicted the magnitude of the earthquake."}, {"heading": "ACKNOWLEDGEMENT", "text": "The authors thank the University of Tun Hussein Onn Malaysia (UTHM) for supporting this research as part of the Postgraduate Incentive Research Grant Vote No.0739."}], "references": [{"title": "Neural network models for earthquake magnitude prediction using multiple seismicity indicators", "author": ["A. Panakkat", "H. Adeli"], "venue": "International Journal of Neural Systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Artificial neural networks classification and clustering of methodologies and applications - literature analysis from 1995 to 2005.\" Expert Systems with Applications", "author": ["Liao", "S.-H", "C.-H"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Non-stationary and stationary prediction of financial time series using dynamic ridge polynomial neural network.", "author": ["R. Ghazali", "A. Jaafar Hussain"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Clustering: A neural network approach.", "author": ["K.L. Du"], "venue": "Neural Networks", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "A comparison of discrete and continuous neural network approaches to solve the class/teacher timetabling problem.", "author": ["M.P. Carrasco", "M.V. Pato"], "venue": "European Journal of Operational Research", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Application of Neural Networks in Image Definition Recognition,", "author": ["Chen Guojin", "Zhu Miaofen"], "venue": "Signal Processing and Communications,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Artificial neural network for tsunami forecasting,", "author": ["Romano", "Michele"], "venue": "Journal of Asian Earth Sciences", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Application of Artificial Neural Networks for Temperature forecasting,", "author": ["Mohsen Hayati", "Zahra Mohebi"], "venue": "World Academy of Science, Engineering and Technology", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Artificial neural networks and bankruptcy forecasting: a state of the art,", "author": ["Muriel Perez"], "venue": "Neural Comput & Application", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "A Hybrid Global Learning Algorithm Based on Global Search and Least Squares Techniques for Backpropagation Networks, Neural Networks,1997", "author": ["C. Leung", "Member", "W.S. Chow"], "venue": "In: International Conference on,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Evolutionary artificial neural networks", "author": ["X. Yao"], "venue": "International Journal of Neural Systems", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1993}, {"title": "Particle swarm for feedforward neural network training", "author": ["R. Mendes", "P. Cortez", "M. Rocha", "J. Neves"], "venue": "Proceedings of the International Joint Conference on Neural Networks,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "Cooperative learning in neural networks using particle swarm optimizers", "author": ["F. Van der Bergh", "A. Engelbrecht"], "venue": "South African Computer Journal", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2000}, {"title": "Training Radial Basis Function Networks with Differential Evolution", "author": ["B. Yu", "X. He"], "venue": "Granular Computing,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Evolving Neural Networks Using the Hybrid of Ant Colony Optimization and BP Algorithms", "author": ["Liu", "Y.-P", "M.-G. Wu"], "venue": "Advances in Neural Networks - ISNN", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "G h a z a l i , and M.N.M Salleh: \u201cPredicting Patients with Heart Disease by Using an Improved Backpropagation Algorithm", "author": ["R.N.M. Nawi"], "venue": "Journal of Computing", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vols. 1 and 2", "author": ["J.L.D.E. Rumelhart"], "venue": "McClelland, and the PDP Research Group", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1986}, {"title": "A comparative study of Artificial Bee Colony algorithm", "author": ["D.Karaboga", "Bahriye Akay"], "venue": "Applied Mathematics and Computation\u201d", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Introduction to Evolutionary Computing", "author": ["A.E. Eiben", "J.E. Smith"], "venue": "Springer", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2003}, {"title": "Swarm Intelligence", "author": ["R.C. Eberhart", "Y. Shi", "J. Kennedy"], "venue": "Morgan Kaufmann", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "B", "author": ["D. Karaboga"], "venue": "Akay ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "An artificial bee colony approach for clustering.", "author": ["C. Zhang", "D. Ouyang"], "venue": "Expert Systems with Applications", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "An idea based on honey Bee Swarm for Numerical Optimization Technique", "author": ["Darvis. Karaboga"], "venue": "Erciyes University Engineering Faculty,Computer", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Neural networks for applied sciences and engineering", "author": ["Sandhya Samarasinghe"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "A Probabilistic Model for Information Storage and Organization in the Brain", "author": ["F. Rosenblatt"], "venue": "\u201cCornell Aeronautical Laboratory\u201d, vol. 65, pp.386-108", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1958}, {"title": "Swarm Intelligence: From Natural to Artificial Systems, Oxford University Press, NY,1999", "author": ["E. Bonabeau", "M. Dorigo", "G. Theraulaz"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1999}, {"title": "The ant system: optimization by a colony of cooperating agents", "author": ["M Dorigo", "V Maniezzo", "A Colorni"], "venue": "IEEE Trans Syst Man Cybern part B", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1996}, {"title": "Von Zuben, Artificial immune systems, Part I", "author": ["F.J.L.N. De Castro"], "venue": "Basic theory and applications, Technical Report Rt Dca 01/99,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1999}, {"title": "Swarm Intelligence", "author": ["R.C. Eberhart", "Y. Shi", "J. Kennedy"], "venue": "Morgan Kaufmann", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2001}, {"title": "Neural Networks and EvolutionaryComputation", "author": ["G. Wei\u00df"], "venue": "PartI: Hybrid Approaches in Artificial Intelligence. In: International Conference on Evolutionary Computation, pp", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1994}, {"title": "GPS receivers timing data processing using neural networks:Optimal estimation and errors modeling", "author": ["M.R. Mosavi"], "venue": "International Journal of Neural", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2007}, {"title": "Parallel backpropagation learning algorithms on cray Y-MP8/864", "author": ["Hung", "S. L", "H. Adeli"], "venue": "supercomputer. Neurocomputing,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1993}, {"title": "Fuzzy-wavelet RBFNN model for freeway incident detection", "author": ["H. Adeli", "A. Karim"], "venue": "Journal of Transportation Engineering,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2000}, {"title": "A fast method for implicit surface reconstruction based on radial basis functions network from 3D scattered points", "author": ["H. Liu", "X. Wang", "W. Qiang"], "venue": "International Journal of Neural Systems,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2007}, {"title": "A radial basis function network approach forthe computational of inverse continuous time variant functions", "author": ["R.V. Mayorga", "J. Carrera"], "venue": "International Journal of Neural Systems,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2007}, {"title": "Recurrent neural networks are universal approximators", "author": ["A.M. Schaefer", "H.G. Zimmermann"], "venue": "International Journal of Neural Systems,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2007}, {"title": "A probabilistic neural network for earthquake magnitude prediction", "author": ["Adeli", "Hojjat", "Panakkat", "Ashif"], "venue": "Earthquake engineering VL:", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "RTIFICIAL Neural Networks (ANNs) are the most novel and powerful artificial tool suitable for solving combinatorial problems such as prediction and classification [1], [2], [3], [4].", "startOffset": 163, "endOffset": 166}, {"referenceID": 1, "context": "RTIFICIAL Neural Networks (ANNs) are the most novel and powerful artificial tool suitable for solving combinatorial problems such as prediction and classification [1], [2], [3], [4].", "startOffset": 168, "endOffset": 171}, {"referenceID": 2, "context": "RTIFICIAL Neural Networks (ANNs) are the most novel and powerful artificial tool suitable for solving combinatorial problems such as prediction and classification [1], [2], [3], [4].", "startOffset": 173, "endOffset": 176}, {"referenceID": 3, "context": "ANNs are being used extensively for solving universal problems intelligently like continuous, discrete, and clustering [5], [6].", "startOffset": 119, "endOffset": 122}, {"referenceID": 4, "context": "ANNs are being used extensively for solving universal problems intelligently like continuous, discrete, and clustering [5], [6].", "startOffset": 124, "endOffset": 127}, {"referenceID": 3, "context": "ANNs are being applied for different optimisation and mathematical problems such as classification, object and image recognition, signal processing, seismic events prediction, temperature and weather forecasting, bankruptcy, tsunami intensity, earthquake, and sea level [5], [7], [8], [9], [10].", "startOffset": 270, "endOffset": 273}, {"referenceID": 5, "context": "ANNs are being applied for different optimisation and mathematical problems such as classification, object and image recognition, signal processing, seismic events prediction, temperature and weather forecasting, bankruptcy, tsunami intensity, earthquake, and sea level [5], [7], [8], [9], [10].", "startOffset": 275, "endOffset": 278}, {"referenceID": 6, "context": "ANNs are being applied for different optimisation and mathematical problems such as classification, object and image recognition, signal processing, seismic events prediction, temperature and weather forecasting, bankruptcy, tsunami intensity, earthquake, and sea level [5], [7], [8], [9], [10].", "startOffset": 280, "endOffset": 283}, {"referenceID": 7, "context": "ANNs are being applied for different optimisation and mathematical problems such as classification, object and image recognition, signal processing, seismic events prediction, temperature and weather forecasting, bankruptcy, tsunami intensity, earthquake, and sea level [5], [7], [8], [9], [10].", "startOffset": 285, "endOffset": 288}, {"referenceID": 8, "context": "ANNs are being applied for different optimisation and mathematical problems such as classification, object and image recognition, signal processing, seismic events prediction, temperature and weather forecasting, bankruptcy, tsunami intensity, earthquake, and sea level [5], [7], [8], [9], [10].", "startOffset": 290, "endOffset": 294}, {"referenceID": 9, "context": "Different techniques are used for optimal network performance for training ANNs such as evolutionary algorithms (EA), genetic algorithms (GA), partial swarm optimisation (PSO), differential evolution (DE), ant colony, and backpropagation algorithm [11], [12], [13], [14], [15], [16], [17].", "startOffset": 248, "endOffset": 252}, {"referenceID": 10, "context": "Different techniques are used for optimal network performance for training ANNs such as evolutionary algorithms (EA), genetic algorithms (GA), partial swarm optimisation (PSO), differential evolution (DE), ant colony, and backpropagation algorithm [11], [12], [13], [14], [15], [16], [17].", "startOffset": 254, "endOffset": 258}, {"referenceID": 11, "context": "Different techniques are used for optimal network performance for training ANNs such as evolutionary algorithms (EA), genetic algorithms (GA), partial swarm optimisation (PSO), differential evolution (DE), ant colony, and backpropagation algorithm [11], [12], [13], [14], [15], [16], [17].", "startOffset": 260, "endOffset": 264}, {"referenceID": 12, "context": "Different techniques are used for optimal network performance for training ANNs such as evolutionary algorithms (EA), genetic algorithms (GA), partial swarm optimisation (PSO), differential evolution (DE), ant colony, and backpropagation algorithm [11], [12], [13], [14], [15], [16], [17].", "startOffset": 266, "endOffset": 270}, {"referenceID": 13, "context": "Different techniques are used for optimal network performance for training ANNs such as evolutionary algorithms (EA), genetic algorithms (GA), partial swarm optimisation (PSO), differential evolution (DE), ant colony, and backpropagation algorithm [11], [12], [13], [14], [15], [16], [17].", "startOffset": 278, "endOffset": 282}, {"referenceID": 14, "context": "Different techniques are used for optimal network performance for training ANNs such as evolutionary algorithms (EA), genetic algorithms (GA), partial swarm optimisation (PSO), differential evolution (DE), ant colony, and backpropagation algorithm [11], [12], [13], [14], [15], [16], [17].", "startOffset": 284, "endOffset": 288}, {"referenceID": 15, "context": "These techniques are used for initialisation of optimal weights, parameters, activation function, and selection of proper network structure [18].", "startOffset": 140, "endOffset": 144}, {"referenceID": 16, "context": "Backpropagation (BP) algorithm is accepted algorithm used for MLP training [19].", "startOffset": 75, "endOffset": 79}, {"referenceID": 9, "context": "In order to overcome the disadvantages of standard BP, many global optimisation populationbased techniques have been proposed for MLP training such as EA, GA, improved GA, DE, BP-ant colony, and PSO [11], [12], [13], [16], [17].", "startOffset": 199, "endOffset": 203}, {"referenceID": 10, "context": "In order to overcome the disadvantages of standard BP, many global optimisation populationbased techniques have been proposed for MLP training such as EA, GA, improved GA, DE, BP-ant colony, and PSO [11], [12], [13], [16], [17].", "startOffset": 205, "endOffset": 209}, {"referenceID": 11, "context": "In order to overcome the disadvantages of standard BP, many global optimisation populationbased techniques have been proposed for MLP training such as EA, GA, improved GA, DE, BP-ant colony, and PSO [11], [12], [13], [16], [17].", "startOffset": 211, "endOffset": 215}, {"referenceID": 13, "context": "In order to overcome the disadvantages of standard BP, many global optimisation populationbased techniques have been proposed for MLP training such as EA, GA, improved GA, DE, BP-ant colony, and PSO [11], [12], [13], [16], [17].", "startOffset": 217, "endOffset": 221}, {"referenceID": 14, "context": "In order to overcome the disadvantages of standard BP, many global optimisation populationbased techniques have been proposed for MLP training such as EA, GA, improved GA, DE, BP-ant colony, and PSO [11], [12], [13], [16], [17].", "startOffset": 223, "endOffset": 227}, {"referenceID": 17, "context": "Artificial Bee Colony (ABC) algorithm is a populationbased algorithm that can provide the best possible solutions for different mathematical problems by using inspiration techniques from nature [20].", "startOffset": 194, "endOffset": 198}, {"referenceID": 18, "context": "Population-based optimisation algorithms are categorised into two sections namely evolutionary algorithm (EA) and SI-based algorithm [21], [22].", "startOffset": 133, "endOffset": 137}, {"referenceID": 19, "context": "Population-based optimisation algorithms are categorised into two sections namely evolutionary algorithm (EA) and SI-based algorithm [21], [22].", "startOffset": 139, "endOffset": 143}, {"referenceID": 20, "context": "It has been successfully used in solving combinatorial optimisation problems such as clustering and MLP training for XOR problem [23], [24].", "startOffset": 129, "endOffset": 133}, {"referenceID": 21, "context": "It has been successfully used in solving combinatorial optimisation problems such as clustering and MLP training for XOR problem [23], [24].", "startOffset": 135, "endOffset": 139}, {"referenceID": 22, "context": "ABC algorithm is an easily understandable technique for training MLP on classification problems [25].", "startOffset": 96, "endOffset": 100}, {"referenceID": 23, "context": "This algorithm uses randomly selected natural techniques with colony to train NNs by optimal weights [26].", "startOffset": 101, "endOffset": 105}, {"referenceID": 24, "context": "MLP was introduced in 1957 to solve different combinatorial problems [27].", "startOffset": 69, "endOffset": 73}, {"referenceID": 0, "context": "It is highly used and tested with different problems such as in time series prediction and function approximation [1], [3], [4], [8].", "startOffset": 114, "endOffset": 117}, {"referenceID": 2, "context": "It is highly used and tested with different problems such as in time series prediction and function approximation [1], [3], [4], [8].", "startOffset": 119, "endOffset": 122}, {"referenceID": 6, "context": "It is highly used and tested with different problems such as in time series prediction and function approximation [1], [3], [4], [8].", "startOffset": 129, "endOffset": 132}, {"referenceID": 11, "context": "Since the last two decades, swarm intelligence (SI) has been the focus of many researches because of its unique behaviour inherent from the social insects [13], [14], [22], [25].", "startOffset": 155, "endOffset": 159}, {"referenceID": 12, "context": "Since the last two decades, swarm intelligence (SI) has been the focus of many researches because of its unique behaviour inherent from the social insects [13], [14], [22], [25].", "startOffset": 161, "endOffset": 165}, {"referenceID": 19, "context": "Since the last two decades, swarm intelligence (SI) has been the focus of many researches because of its unique behaviour inherent from the social insects [13], [14], [22], [25].", "startOffset": 167, "endOffset": 171}, {"referenceID": 22, "context": "Since the last two decades, swarm intelligence (SI) has been the focus of many researches because of its unique behaviour inherent from the social insects [13], [14], [22], [25].", "startOffset": 173, "endOffset": 177}, {"referenceID": 25, "context": "Bonabeau has defined the SI as \u201cany attempt to design algorithm or distributed problem-solving devices inspired by the collective behaviour of social insect colonies and other animal societies\u201d [28].", "startOffset": 194, "endOffset": 198}, {"referenceID": 26, "context": "Ants are individual agents of ACO [29].", "startOffset": 34, "endOffset": 38}, {"referenceID": 27, "context": "An immune system can be considered as a group of cells and molecules as well as a crowd is a swarm of people [31].", "startOffset": 109, "endOffset": 113}, {"referenceID": 28, "context": "optimisation of non-linear functions in multidimensional space [32].", "startOffset": 63, "endOffset": 67}, {"referenceID": 17, "context": "Artificial Bee Colony algorithm (ABC) was proposed for optimisation, classification, and NNs problem solution based on the intelligent foraging behaviour of honey bee swarm [20], [21], [22], [26].", "startOffset": 173, "endOffset": 177}, {"referenceID": 18, "context": "Artificial Bee Colony algorithm (ABC) was proposed for optimisation, classification, and NNs problem solution based on the intelligent foraging behaviour of honey bee swarm [20], [21], [22], [26].", "startOffset": 179, "endOffset": 183}, {"referenceID": 19, "context": "Artificial Bee Colony algorithm (ABC) was proposed for optimisation, classification, and NNs problem solution based on the intelligent foraging behaviour of honey bee swarm [20], [21], [22], [26].", "startOffset": 185, "endOffset": 189}, {"referenceID": 23, "context": "Artificial Bee Colony algorithm (ABC) was proposed for optimisation, classification, and NNs problem solution based on the intelligent foraging behaviour of honey bee swarm [20], [21], [22], [26].", "startOffset": 191, "endOffset": 195}, {"referenceID": 13, "context": "Therefore, ABC is more successful and most robust on multimodal functions included in the set with respect to DE, PSO, and GA [16], [21], [23].", "startOffset": 126, "endOffset": 130}, {"referenceID": 18, "context": "Therefore, ABC is more successful and most robust on multimodal functions included in the set with respect to DE, PSO, and GA [16], [21], [23].", "startOffset": 132, "endOffset": 136}, {"referenceID": 20, "context": "Therefore, ABC is more successful and most robust on multimodal functions included in the set with respect to DE, PSO, and GA [16], [21], [23].", "startOffset": 138, "endOffset": 142}, {"referenceID": 0, "context": "where k is a solution in the neighbourhood of i, \u03a6 is a random number in the range [-1, 1] and evaluate them.", "startOffset": 83, "endOffset": 90}, {"referenceID": 0, "context": "Normalise pi values into [0, 1] 8: Produce the new solutions (new positions) \u03c5i for the onlookers from the solutions xi, selected depending on Pi, and evaluate them 9: Apply the Greedy Selection process for the onlookers between xi and vi 10: Determine the abandoned solution (source), if exists, replace it with a new randomly produced solution xi for the scout using the following equation", "startOffset": 25, "endOffset": 31}, {"referenceID": 8, "context": "The foods area was limited in range [10,-10].", "startOffset": 36, "endOffset": 44}, {"referenceID": 2, "context": "Neural networks have been used successfully to solve complicated pattern recognition and classification problems in different domains such as satellite data, GPS data, and financial forecasting [3], [34].", "startOffset": 194, "endOffset": 197}, {"referenceID": 30, "context": "Neural networks have been used successfully to solve complicated pattern recognition and classification problems in different domains such as satellite data, GPS data, and financial forecasting [3], [34].", "startOffset": 199, "endOffset": 203}, {"referenceID": 0, "context": "Recently, NNs are also applied for earthquake prediction by using different models such as Backpropagation Neural Networks (BPNNs), Radial-Basis Function (RBF) NNs, Recurrent NNs, and probabilistic NNs [1], [35], [36], [37], [38], [39], [40].", "startOffset": 202, "endOffset": 205}, {"referenceID": 31, "context": "Recently, NNs are also applied for earthquake prediction by using different models such as Backpropagation Neural Networks (BPNNs), Radial-Basis Function (RBF) NNs, Recurrent NNs, and probabilistic NNs [1], [35], [36], [37], [38], [39], [40].", "startOffset": 207, "endOffset": 211}, {"referenceID": 32, "context": "Recently, NNs are also applied for earthquake prediction by using different models such as Backpropagation Neural Networks (BPNNs), Radial-Basis Function (RBF) NNs, Recurrent NNs, and probabilistic NNs [1], [35], [36], [37], [38], [39], [40].", "startOffset": 213, "endOffset": 217}, {"referenceID": 33, "context": "Recently, NNs are also applied for earthquake prediction by using different models such as Backpropagation Neural Networks (BPNNs), Radial-Basis Function (RBF) NNs, Recurrent NNs, and probabilistic NNs [1], [35], [36], [37], [38], [39], [40].", "startOffset": 219, "endOffset": 223}, {"referenceID": 34, "context": "Recently, NNs are also applied for earthquake prediction by using different models such as Backpropagation Neural Networks (BPNNs), Radial-Basis Function (RBF) NNs, Recurrent NNs, and probabilistic NNs [1], [35], [36], [37], [38], [39], [40].", "startOffset": 225, "endOffset": 229}, {"referenceID": 35, "context": "Recently, NNs are also applied for earthquake prediction by using different models such as Backpropagation Neural Networks (BPNNs), Radial-Basis Function (RBF) NNs, Recurrent NNs, and probabilistic NNs [1], [35], [36], [37], [38], [39], [40].", "startOffset": 231, "endOffset": 235}, {"referenceID": 36, "context": "Recently, NNs are also applied for earthquake prediction by using different models such as Backpropagation Neural Networks (BPNNs), Radial-Basis Function (RBF) NNs, Recurrent NNs, and probabilistic NNs [1], [35], [36], [37], [38], [39], [40].", "startOffset": 237, "endOffset": 241}, {"referenceID": 0, "context": "[1,-1] is for MLP-BP and [10,-10] is for MLP-ABC.", "startOffset": 0, "endOffset": 6}, {"referenceID": 8, "context": "[1,-1] is for MLP-BP and [10,-10] is for MLP-ABC.", "startOffset": 25, "endOffset": 33}, {"referenceID": 0, "context": "The weight values of MLP-ABC were initialised, evaluated, and fitted using ABC algorithm, while the weight values of MLP-BP were adjusted from the range [1,-1] randomly.", "startOffset": 153, "endOffset": 159}, {"referenceID": 0, "context": "Weights range [1,-1] [10,-10]", "startOffset": 14, "endOffset": 20}, {"referenceID": 8, "context": "Weights range [1,-1] [10,-10]", "startOffset": 21, "endOffset": 29}], "year": 2011, "abstractText": "Nowadays, computer scientists have shown the interest in the study of social insect\u2019s behaviour in neural networks area for solving different combinatorial and statistical problems. Chief among these is the Artificial Bee Colony (ABC) algorithm. This paper investigates the use of ABC algorithm that simulates the intelligent foraging behaviour of a honey bee swarm. Multilayer Perceptron (MLP) trained with the standard back propagation algorithm normally utilises computationally intensive training algorithms. One of the crucial problems with the backpropagation (BP) algorithm is that it can sometimes yield the networks with suboptimal weights because of the presence of many local optima in the solution space. To overcome ABC algorithm used in this work to train MLP learning the complex behaviour of earthquake time series data trained by BP, the performance of MLP-ABC is benchmarked against MLP training with the standard BP. The experimental result shows that MLP-ABC performance is better than MLP-BP for time series data.", "creator": "easyPDF SDK 6.0"}}}