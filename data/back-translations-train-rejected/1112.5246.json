{"id": "1112.5246", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2011", "title": "Combining One-Class Classifiers via Meta-Learning", "abstract": "We examine various methods for combining the output of one-class models. In particular, we show that simple meta-learning based ensemble achieves better result than weighting methods. Furthermore we propose a new one-class ensemble scheme, called TUPSO that uses meta-learning for combining multiple one-class classifiers. We also present a new one-class classification performance measures to weigh the base-classifiers, a process that proved helpful for increasing the classification performance of the induced ensemble. Our experimental study shows that the proposed method significantly outperforms exiting methods.", "histories": [["v1", "Thu, 22 Dec 2011 08:07:56 GMT  (116kb,D)", "http://arxiv.org/abs/1112.5246v1", "Related to both Ensemble learning and one-class learning. Length of 6 pages. This document is the smaller version of a journal version. Will be submitted to a conference"], ["v2", "Thu, 3 Jan 2013 14:27:14 GMT  (1887kb)", "http://arxiv.org/abs/1112.5246v2", "Related to both Ensemble learning and one-class learning. Length of 35 pages. This document is the journal version"], ["v3", "Sun, 21 Jul 2013 12:08:43 GMT  (1177kb,D)", "http://arxiv.org/abs/1112.5246v3", "To appear in CIKM 2013. Related to both Ensemble learning and one-class learning. Length: 10 pages"]], "COMMENTS": "Related to both Ensemble learning and one-class learning. Length of 6 pages. This document is the smaller version of a journal version. Will be submitted to a conference", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["eitan menahem", "lior rokach", "yuval elovici"], "accepted": false, "id": "1112.5246"}, "pdf": {"name": "1112.5246.pdf", "metadata": {"source": "CRF", "title": "Combining One-Class Classifiers via Meta-Learning", "authors": ["Eitan Menahem", "Lior Rokach", "Yuval Elovici"], "emails": ["ELOVICI}@BGU.AC.IL"], "sections": [{"heading": "1 Introduction and Background", "text": "Single-class classification aims to distinguish instances of class interest from all other instances. In addition, the single-class classifier is trained by a training set that contains only the instances of that class. Many single-class classifier algorithms have been studied [1, 2]. The variety of classifier techniques is both positive and negative. On the one hand, there are many techniques from which to choose, but on the other hand, choosing the right classifier can be difficult, because the evaluation of single-class classifier performance is problematic. Data collections contain only single-class examples and therefore performance indicators, such as false-positive (FP) and true negative indicators (TN), which cannot be calculated. In the absence of FP and TN derived performance indicators, such as classification accuracy, precision, AUC and others, cannot be calculated. One way to address this difficulty is to use an ensemble."}, {"heading": "2 Meta-Learning-Based Ensembles for One-Class Problems", "text": "The proposed ensemble method, TUPSO, is designed to work in single-class scenarios in which multiple and possibly different classifiers exist; its main task is to combine single-class base classifiers using meta-classifiers; the estimated performance is then supported by a heuristic performance evaluator that estimates the classification performance of each of the base classifiers and outputs a power vector, Perfvect = {Pref1,..., P refm}; the estimated performance is then translated into static weights, \u03b1i, which the meta learning algorithm applies; \u03b1i = Perfi \u0445 1 / \u2211 m j = 1 Perfj, \u03c6i = 1... m, where m is the number of instance; and the TUPSO ensemble, as shown in Figure 1, consists of four main components: (1) base classifier, (2) power evaluator, (3) aggregate characteristics Extractor & Metric (4) and Metric (4)."}, {"heading": "3 Estimating the Performance of One-Class Classifiers", "text": "The performance of the basic classifiers is a key factor in generating effective aggregated meta-characteristics. Unfortunately, the lack of negative examples makes it difficult to evaluate the performance. This is because the two important values, the false positive (FP) and the true negative (TN) values, cannot be measured, making it impossible to calculate some performance indicators such as accuracy, precision and F-value. Note that each of the following performance indicators misses one or more values: Accuracy = TP + TNTP + TN, Precision = TP TP + FPand F-value = 2PRP + R, where P is the precision and R is the recall. Alternatively, we propose a one-class approach to estimate the performance of the classifiers. A criterion proposed in [8] estimates the F-score f + FPand F-value f x x, with the prediction of the classifier x x. The criterion, rpr [Y + 1] shares with some features of Y = F-Y."}, {"heading": "4 Evaluation", "text": "In this section, we examine two aspects related to TUPSO: First, we test the proposed aggregation functions on the basis of different data sets. Second, we test how well TUPSO performs compared to some common fix rule methods. In order to estimate the general classification performance of the above-mentioned ensemble schemes, a 5x2 cross-validation procedure was performed [9]."}, {"heading": "4.1 Experiment Setup", "text": "The evaluation of TUPSO is divided into three dimensions: data sets (12 popular data sets from the UCI collection [10]), combined with methods (TUPSO or Fixed Rule Method) and measures of the performance of base classifiers (POF or none). We used six inductor setups (i.e. base classifiers) induced by four algorithms: (i) ADIFA-HM and (ii) ADIFA-GM [11], (iii) GDE [12], (iv) PGA [13], (v) OC-SVM1 and (vi) OC-SVM2 [1]. The properties of the base classifiers remained static throughout the evaluation."}, {"heading": "4.2 Measured Metrics", "text": "To evaluate the real performance of individual classifiers and ensemble methods, we used a two-class metric instead of POF. In contrast to the training process, where the absence of negative examples dictates the use of one-class metrics (i.e. POF), the data set in the test phase included instances of both classes, thus allowing the use of two-class metrics. Specifically, we used the area below the ROC curve (AUC)."}, {"heading": "4.3 Experimental Results", "text": "In Table 4 we present the evaluation results. We use \"All,\" \"WF\" and \"Non-WF\" to denote all weighted and non-weighted aggregate characteristics (see Table 2). Within the bracket is the AUC rank of the corresponding ensemble method. We can see that the weighted characteristics (SumWP and V arWP) together performed best. It appears that the mixing of the unweighted and the weighted characteristics is a slightly weaker ensemble. In Figure 2 we present the ROC charts of the tested ensemble methods generated using the Optical Digits dataset. The best curve belongs to a TUPSO version that uses all the aggregated characteristics defined in Table 2. A weakness of the fix-rule technique is demonstrated in Figure 3. Since we have 60 base classifiers, we will test \"the density of both the normal and the non-weighted characteristics\" as being the least likely to be the one of the classes, which is also the lowest for the classification."}, {"heading": "5 Conclusions and Future Work", "text": "In this thesis, we proposed a new meta-learning-based ensemble scheme for single-class problems, which learns a combined function based on aggregates of the predictions of the basic classifiers. In order to improve the inductive performance of the aggregates, we implemented a classification performance evaluator, which we considered to be very effective. Furthermore, we would like to examine TUPSO for more data sets and examine additional single-class evaluators. Finally, we would like to find out how TUPSO performs compared to the ensemble's best classifier."}], "references": [{"title": "Novelty detection and neural network validation", "author": ["Chris M. Bishop"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1994}, {"title": "Metric anomaly detection via asymmetric risk minimization", "author": ["Aryeh Kontorovich", "Danny Hendler", "Eitan Menahem"], "venue": "In SIMBAD,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Troika - an improved stacking schema for classification", "author": ["Eitan Menahem", "Lior Rokach", "Yuval Elovici"], "venue": "tasks. Inf. Sci.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Intrusion detection in computer networks by a modular ensemble of one-class classifiers", "author": ["Giorgio Giacinto", "Roberto Perdisci", "Mauro Del Rio", "Fabio Roli"], "venue": "Information Fusion,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Combining one-class classifiers", "author": ["David M.J. Tax", "Robert P.W. Duin"], "venue": "In in Proc. Multiple Classifier Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Combining one-class classifiers to classify missing data", "author": ["Piotr Juszczak", "Robert P.W. Duin"], "venue": "In Multiple Classifier Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Weighted bagging for graph based one-class classifiers", "author": ["Santi Seg\u00fa\u0131", "Laura Igual", "Jordi Vitri\u00e0"], "venue": "In MCS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Learning with positive and unlabeled examples using weighted logistic regression", "author": ["Wee Sun Lee", "Bing Liu"], "venue": "In ICML,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Approximate statistical test for comparing supervised classification learning algorithms", "author": ["Thomas G. Dietterich"], "venue": "Neural Computation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Anomaly detection via attribute distribution function approximation", "author": ["E. Menahem", "L. Roakach", "Y. Elovici"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "A geometric framework for unsupervised anomaly detection: Detecting intrusions in unlabeled data", "author": ["Eleazar Eskin", "Andrew Arnold", "Michael Prerau", "Leonid Portnoy", "Sal Stolfo"], "venue": "In Applications of Data Mining in Computer Security. Kluwer,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "A unified notion of outliers: Properties and computation", "author": ["Edwin M. Knorr", "Raymond T. Ng"], "venue": "Proc. of the International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}], "referenceMentions": [{"referenceID": 0, "context": "Many one-class classification algorithms have been investigated [1, 2].", "startOffset": 64, "endOffset": 70}, {"referenceID": 1, "context": "Many one-class classification algorithms have been investigated [1, 2].", "startOffset": 64, "endOffset": 70}, {"referenceID": 2, "context": "Indeed, previous works in supervised ensemble learning show that combining classification models can produce a better classifier in terms of prediction accuracy [3].", "startOffset": 161, "endOffset": 164}, {"referenceID": 3, "context": "Compared to supervised-learning, research in the one-class ensemble research is limited [4].", "startOffset": 88, "endOffset": 91}, {"referenceID": 4, "context": "In particular, only one combining method, the Fix-rule ensemble, was considered for one-class ensemble [5, 6, 7].", "startOffset": 103, "endOffset": 112}, {"referenceID": 5, "context": "In particular, only one combining method, the Fix-rule ensemble, was considered for one-class ensemble [5, 6, 7].", "startOffset": 103, "endOffset": 112}, {"referenceID": 6, "context": "In particular, only one combining method, the Fix-rule ensemble, was considered for one-class ensemble [5, 6, 7].", "startOffset": 103, "endOffset": 112}, {"referenceID": 7, "context": "A criterion proposed in [8] estimates the F -score by using classifier\u2019s prediction on positive instances.", "startOffset": 24, "endOffset": 27}, {"referenceID": 8, "context": "In order to estimate the generalized classification performance of the mentioned ensemble schemes, a 5x2 cross-validation procedure was performed [9].", "startOffset": 146, "endOffset": 149}, {"referenceID": 9, "context": "base-classifiers), induced by four algorithms: (i) ADIFA-HM and (ii) ADIFA-GM [11], (iii) GDE [12], (iv) PGA [13], (v) OC-SVM1 and (vi) OC-SVM2 [1].", "startOffset": 78, "endOffset": 82}, {"referenceID": 10, "context": "base-classifiers), induced by four algorithms: (i) ADIFA-HM and (ii) ADIFA-GM [11], (iii) GDE [12], (iv) PGA [13], (v) OC-SVM1 and (vi) OC-SVM2 [1].", "startOffset": 94, "endOffset": 98}, {"referenceID": 11, "context": "base-classifiers), induced by four algorithms: (i) ADIFA-HM and (ii) ADIFA-GM [11], (iii) GDE [12], (iv) PGA [13], (v) OC-SVM1 and (vi) OC-SVM2 [1].", "startOffset": 109, "endOffset": 113}, {"referenceID": 0, "context": "base-classifiers), induced by four algorithms: (i) ADIFA-HM and (ii) ADIFA-GM [11], (iii) GDE [12], (iv) PGA [13], (v) OC-SVM1 and (vi) OC-SVM2 [1].", "startOffset": 144, "endOffset": 147}], "year": 2017, "abstractText": "We examine various methods for combining the output of one-class models. In particular, we show that simple meta-learning based ensemble achieves better result than weighting methods. Furthermore we propose a new one-class ensemble scheme, called TUPSO that uses metalearning for combining multiple one-class classifiers. We also present a new one-class classification performance measures to weigh the base-classifiers, a process that proved helpful for increasing the classification performance of the induced ensemble. Our experimental study shows that the proposed method significantly outperforms exiting methods.", "creator": "LaTeX with hyperref package"}}}