{"id": "1112.5309", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2011", "title": "POWERPLAY: Training an Increasingly General Problem Solver by Continually Searching for the Simplest Still Unsolvable Problem", "abstract": "Most of computer science focuses on automatically solving given computational problems. I focus on automatically inventing or discovering problems in a way inspired by the playful behavior of animals and humans, to train a more and more general problem solver from scratch in an unsupervised fashion. At any given time, the novel algorithmic framework POWERPLAY searches the space of possible pairs of new tasks and modifications of the current problem solver, until it finds a more powerful problem solver that provably solves all previously learned tasks plus the new one, while the unmodified predecessor does not. The new task and its corresponding task-solving skill are those first found and validated. Newly invented tasks may require making previously learned skills more efficient. The greedy search of typical POWERPLAY variants orders candidate pairs of tasks and solver modifications by their conditional computational complexity, given the stored experience so far. This biases the search towards pairs that can be described compactly and validated quickly. Standard problem solver architectures of personal computers or neural networks tend to generalize by solving numerous tasks outside the self-invented training set; POWERPLAY's ongoing search for novelty keeps fighting to extend beyond the generalization abilities of its present solver. The continually increasing repertoire of problem solving procedures can be exploited by a parallel search for solutions to additional externally posed tasks. POWERPLAY may be viewed as a greedy but practical implementation of basic principles of creativity. The present paper is purely conceptual though; detailed experimental analysis of various problem solver architectures with different generalization properties is left to separate papers.", "histories": [["v1", "Thu, 22 Dec 2011 13:50:46 GMT  (28kb)", "http://arxiv.org/abs/1112.5309v1", "19 pages"], ["v2", "Sun, 4 Nov 2012 17:22:46 GMT  (30kb)", "http://arxiv.org/abs/1112.5309v2", "21 pages, additional connections to previous work, references to first experiments with POWERPLAY"]], "COMMENTS": "19 pages", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["j\\\"urgen schmidhuber"], "accepted": false, "id": "1112.5309"}, "pdf": {"name": "1112.5309.pdf", "metadata": {"source": "CRF", "title": "POWERPLAY: Training an Increasingly General Problem Solver by Continually Searching for the Simplest Still Unsolvable Problem", "authors": ["J\u00fcrgen Schmidhuber"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 111 2.53 09v1 [cs.AI] 2Table of Contents"}, {"heading": "1 Introduction 3", "text": "Based on data, data, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts, facts"}, {"heading": "5 Outgrowing Trivial Tasks - Compressing Previous Solutions 11", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6 Adding External Tasks 11", "text": "6.1 Self-reference through novel task search as an external task......... 127 Task Acceptance Criteria of POWERPLAY 12 7.1 POWERPLAY Variant II: Explicit Punishment of Time and Space Complexity......... 12 7.2 Probabilistic POWERPLAY Variants................."}, {"heading": "8 First Illustrative Experiments 13", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9 Previous Relevant Work 15", "text": "9.1 Existing theoretically optimal universal problem solvers.............. 15 9.2 Greedy implementation of formal theory of creativity............ 15"}, {"heading": "10 Words of Caution 17", "text": "11 Acknowledgements 17"}, {"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to assert themselves, that they are able to survive on their own."}, {"heading": "1.1 Basic Ideas", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "1.2 Outline of Remainder", "text": "It is about the question of the extent to which people are able to solve their own tasks, in the same way as they do it, as they do it, and as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do it, as they do, as they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they do, they, they do, they do, they do, they do, they, they do, they, they do, they do, they, they do, they do, they, they do, they, they do, they, they, they do, they, they do, they do, they, they, they, they do, they, they, they do, they do, they do, they do, they, they, they do, they, they, they do, they, they, they do, they, they, they, they, they do, they do, they, they, they, they, they do, they do, they, they, they do, they, they, they, they, they, they do, they, they, they, they, they, they, they, they, they, they do, they, they, they, they, they, they, they, they, they, they, they, they, they,"}, {"heading": "3.1.1 Example: Pattern Recognition Tasks", "text": "In the context of learning to recognize or analyze patterns, Ti could be a quadruple (Ii, Oi, ti, ni) pattern (Ii, O \u00b7 N \u00b7 N), where I, O, B * and Ti are solved if si meets L (si) < ni and requires at most discrete time steps to read Ii and calculate and stop Oi. Here, Ii itself can be a pair (I1i, I 2 i) if I1i must be the address of an image in a given database of patterns, and I 2 i is a pi-generated \"query\" that clearly specifies how the image should be classified by the target pattern Oi, so that the same image can be analyzed in different ways during different tasks. For example, depending on the nature of the invented task sequence, the problem solver might ultimately learn that O = 1 if I2 = 1001 (the suppression of task indices) and the image addressed by I1 contains at least one black pattern."}, {"heading": "3.1.2 Example: General Decision Making Tasks", "text": "In the general context of general problem solving / sequential decision-making / reinforcement of internal application addresses, a particular environment (16, 12, 41) may exist in unclear environments (16, 12, 41), in which a number of possible problem solving patterns and a number of programs are implemented that test the properties of bit strings. (Ti could then create a 4-tuple system (Ii, Ji, ni) that can perform a constant array of perceptions and actions to achieve some computable goals, which Ji.More solves precisely, while Ti is solved within ti time steps, in which most discrete time steps can occur on the first reading of Ii and then interacting with an environment through a sequence of perceptions and actions. (t), while Ti is solved within ti time steps, at any given time1 that can detect the internal state of the problem solver (t)."}, {"heading": "3.3.1 Most General: Proof Search", "text": "The most general way to demonstrate correctness is to encode (in read-only memory) an axiomatic system A which formally describes the arithmetic properties of the problem solver and possible si, and to allow Pi to search the space of possible evidence derivable from A by using a subroutine of the evidence seeker which systematically provides evidence until it finds a theorem stating that si \u2212 1 but not si \u2212 1 T1, T2,... Ti (evidence searches can achieve this efficiently without explicitly re-testing si on T1, T2, Ti,...), as could be done in the Go-del Machine [35] (Section 9.1), which uses an online extension of Universal Search [13] to systematically test evidentiary techniques: evidence-generation programs that provide specific instructions for generating axioms and applying follow-up rules for the extension of an originally empty proof, which can be easily combined with, for example, theorems or earlier ones."}, {"heading": "3.3.2 Keeping Track Which Components of the Solver Affect Which Tasks", "text": "It is often possible to divide s-S into components, such as individual bits of the software of a PC or weights of an NN. Here, the k-th component of s is called sk. For each k (k = 1, 2,..), a variable list Lk = (T k1, T k 2,..) is introduced. Its initial value before starting POWERPLAY is L k 0, an empty list. Whenever pi si si si and Ti are found at the end of the CORRECTNESS DEMONSTRATION, each Lk is updated as follows: its new value Lki is achieved by appending to L k i-1 these Tj / L k i-1 strategies (j = 1,.. i), whose current (possibly revised) solutions now require sk at least once during the solution process, and the Tj, whose current solutions do not invent more or less tasks than if the previous task is not fulfilled."}, {"heading": "3.3.3 Advantages of Prefix Code-Based Problem Solvers", "text": "Let's limit P so that tested p-P cannot change components of si-1 during the previous processing of SOLVER MODIFICATION, but only add a new si to si-1. (This means that all components used will be frozen by each sk as soon as Tk is found.) By limiting it to self-separating prefix codes such as those generated by the Optimal Ordered Problem Solver (OOPS), one can now benefit from a sometimes particularly efficient type of CORRECTNESS DEMONSTRATION that ensures that differences between si and si \u2212 1 cannot affect solutions for T < i under certain conditions. (Specifically, to spend half the search time to process Ti \u2212 si first with si \u2212 1, the extension or extension of si \u2212 1 only if the ongoing calculation requests for new components are added by special instructions."}, {"heading": "4.1 Implementation Based on Optimal Ordered Problem Solver", "text": "The i-th problem is to find a program that generates si and Ti and shows that si but not si \u2212 1 can T1, T2,., Ti. This results in a perfectly ordered problem sequence for a variant of the Optimal Ordered Problem Solver OOPS (32) described next.While a candidate is running a program p (32), it will at any given discrete time step t = 1, 2... be called its internal state or dynamic memory U (t) (not to be confused with the internal state of the solver u (t) of section 3.1.2). Its initial default value is U (0). For example, U (t) could encode the current contents of the internal tape of a TM (modified by p), or certain cells in the dynamic memory area of a PC.Once it is found, pi, si, si racei (if applicable)."}, {"heading": "4.1.1 Building on Existing OOPS Source Code", "text": "Existing OOPS source code [31] uses a universal programming language such as FORTH to define P. It already contains a framework for testing new code for tasks already solved and for efficiently reversing all U modifications of each tested program. The source code requires a few changes to implement the additional task search described above."}, {"heading": "4.1.2 Alternative Problem Solver Based on Recurrent Neural Networks", "text": "Recurrent NN (RNN) are general calculators that allow both sequential and parallel calculations, as opposed to strictly sequential FORTH-like calculations in Section 4.1.1. Here, an RNN called RNN1 is used to define S. Let's expand the notation of Section 3.1.2. RNN1 has n (u) N units or neurons; the k-te neuron is called uk. At a discrete time, step t = 1, 2,.., tends to be a finite interaction sequence with the environment, uk (t) denotes the real activation of uk. The current input vector x (t) (which also contains a unique encoding of the current task identifier) is transformed by a specified procedure into a real vector with n (x) real N components in which the k-te component is called x."}, {"heading": "4.2 Adapting the Probability Distribution on Programs", "text": "A simple extension of the above works as follows: Whenever a new Pi is found, P is updated to make either only Pi or all P1, P2, Pi more likely. Simple ways to do this are described in previous work [37]. This may be justified in so far as it turns out that future successful programs are similar to those of previous ones."}, {"heading": "4.3 Implementation Based on Stochastic or Evolutionary Search", "text": "A perhaps simpler, but less general, approach is to use an evolutionary algorithm to generate a s-modifying and task-generating program p, as requested by POWERPLAY, according to algorithm 4.3, which refers to the recurring net problem solver of Section 4.1.2.Alg. 4.3: POWERPLAY for RNN by means of stochastic or evolutionary search randomly initializes the variable weight matrix of RNN1 < wlk > and the result as s0 (see Section 4.1.2) for i: = 1, 2,. doses Boolean variable DONE = FALSE repeats a black box optimization algorithm BBOA (many are also possible [20, 8, 43, 38]) with an adaptive parameter vector. To generate some T (to define the task input to RNNNN1; see Section 3.1) and a new modification of &ltk = 1, and &ltk = 3 \u2212"}, {"heading": "5 Outgrowing Trivial Tasks - Compressing Previous Solutions", "text": "Could it be that POWERPLAY invents eternally trivial tasks? Not on realistic architectures, but on general architectures such as PCs and RNNs. At least when the upper memory size limit of s is reached, POWERPLAY will begin to \"compress\" earlier solutions, making new tasks that can be solved by partially reusing previously discovered code often easier to find than new tasks that can be solved by previously unused parts of s. This also applies to growing architectures with potentially unlimited memory space. POWERPLAY Variant II component from Section 7.1, whose tasks may explicitly require an improvement in the average time and space complexity of earlier solutions, however, it is generally becoming increasingly difficult to invent new tasks without forgetting previous solutions."}, {"heading": "6 Adding External Tasks", "text": "The growing repertoire of problem solvers can make it easier to learn solutions to externally generated tasks. For example, POWERPLAY can be modified to define i, Ti externally for certain self-generated tasks, rather than being invented by the system itself. In general, the resulting si will contain an externally inserted bias in the form of code that will make it easier to locate some future self-generated tasks than others. It should be possible to push the system in a humanly understandable or otherwise useful direction by regularly inserting appropriate external targets. See Algorithm 7.1.Another way to take advantage of the growing repertoire is to simply copy si for some i and use it as a starting point for finding a solution to an externally set task T, without insisting that the modified si can also solve T1, T2, etc., Ti. This can be much faster than trying to solve T from scratch, to the extent that the code is regenerated for the T."}, {"heading": "6.1 Self-Reference Through Novel Task Search as an External Task", "text": "The reasons why Section 2 is already mentioned should include instructions on how to read and execute the problem (the problem creates Ti and si (a modification of si \u2212 1) and shows that it can be a way in which it is a more and more universal problem solving that could in many ways contribute to achieving such goals in a self-referential manner. Thus, for example, the old solution approach can read a clear formal description of the tasks (that of pi) of POWERPLAY's i-th goal of treating it as an external task and producing an output that clearly describes a candidate for (Ti, si). If there is a theory-based component (Section 3.1), there might even be complete proof of (Ti, si) s validity; it could use the possibly suboptimal suggestions of si \u2212 1 to restrict and speed up the search, one of the reasons why Section 2 has already been mentioned."}, {"heading": "8 First Illustrative Experiments", "text": "The question of the causes and the causes of this development arises not only in the U.S., but also in many other countries. (...) The question of the causes of this development arises also in the U.S., in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other countries, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in another, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other, in other"}, {"heading": "9 Previous Relevant Work", "text": "At this point, I will discuss (a) why this work is of interest despite the recent emergence of theoretically optimal universal problem solvers (Section 9.1) and (b) how it can be viewed as a greedy but feasible and solid implementation of the formal theory of creativity (Section 9.2)."}, {"heading": "9.1 Existing Theoretically Optimal Universal Problem Solvers", "text": "In fact, most of them will be able to survive on their own."}, {"heading": "9.2 Greedy Implementation of the Formal Theory of Creativity", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "10 Words of Caution", "text": "The behavior of POWERPLAY is determined by the nature and limitations of S, P and its algorithm for searching for P. If both S and P allow the implementation of arbitrary programs, and the search algorithm is a general method for searching in program space (Section 4), then there are few limits to what it can do (apart from the limits of predictability [7]). It may not be advisable to release a generic variant of POWERPLAY in an uncontrolled situation, for example, on a multi-computer network on the Internet, possibly with access to physical devices, and the potential to acquire additional computing and physical resources (Section 3.1.2) by executing programs during POWERPLAY. Unlike traditional virus programs, POWERPLAY-based systems will continually change in a manner that is difficult to predict, constantly inventing and solving new, self-generated tasks, driven only by the desire to increase their problem-solving capacity."}, {"heading": "11 Acknowledgments", "text": "Thanks to Mark Ring, Bas Steunebrink, Faustino Gomez, Sohrob Kazerounian, Hung Ngo, Leo Pape, Giuseppe Cuccu for useful comments. Thanks to Rupesh Srivastava for first implementations and vivid experiments."}], "references": [{"title": "Intrinsic motivation and reinforcement learning", "author": ["A. Barto"], "venue": "Intrinsically Motivated Learning in Natural and Artificial Systems. Springer,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Neural networks for pattern recognition", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "Intrinsically motivated evolutionary search for vision-based reinforcement learning", "author": ["G. Cuccu", "M. Luciw", "J. Schmidhuber", "F. Gomez"], "venue": "In Proceedings of the 2011 IEEE Conference on Development and Learning and Epigenetic Robotics IEEE-ICDL-EPIROB. IEEE,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Exploration from generalization mediated by multiple controllers", "author": ["P. Dayan"], "venue": "Intrinsically Motivated Learning in Natural and Artificial Systems. Springer,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Theory of optimal experiments", "author": ["V.V. Fedorov"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1972}, {"title": "First-Order Logic and Automated Theorem Proving", "author": ["M.C. Fitting"], "venue": "Graduate Texts in Computer Science. Springer-Verlag, Berlin,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1996}, {"title": "\u00dcber formal unentscheidbare S\u00e4tze der Principia Mathematica und verwandter Systeme I", "author": ["K. G\u00f6del"], "venue": "Monatshefte fu\u0308r Mathematik und Physik,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1931}, {"title": "Efficient non-linear control through neuroevolution", "author": ["F.J. Gomez", "J. Schmidhuber", "R. Miikkulainen"], "venue": "Journal of Machine Learning Research JMLR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "A method for construction of minimum-redundancy codes", "author": ["D.A. Huffman"], "venue": "Proceedings IRE,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1952}, {"title": "The fastest and shortest algorithm for all well-defined problems", "author": ["M. Hutter"], "venue": "International Journal of Foundations of Computer Science,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Reinforcement learning: a survey", "author": ["L.P. Kaelbling", "M.L. Littman", "A.W. Moore"], "venue": "Journal of AI research,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1996}, {"title": "Universal sequential search problems", "author": ["L.A. Levin"], "venue": "Problems of Information Transmission,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1973}, {"title": "Artificial curiosity with planning for autonomous perceptual and cognitive development", "author": ["M. Luciw", "V. Graziano", "M. Ring", "J. Schmidhuber"], "venue": "In Proceedings of the First Joint Conference on Development Learning and on Epigenetic Robotics ICDL-EPIROB,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Novelty detection as an intrinsic motivation for cumulative learning robots", "author": ["U. Nehmzow", "Y. Gatsoulis", "E. Kerr", "J. Condell", "N.H. Siddique", "T.M. McGinnity"], "venue": "Intrinsically Motivated Learning in Natural and Artificial Systems. Springer,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "GPS, a program that simulates human thought", "author": ["A. Newell", "H. Simon"], "venue": "Computers and Thought,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1963}, {"title": "Compression progress-based curiosity drive for developmental learning", "author": ["H. Ngo", "M. Ring", "J. Schmidhuber"], "venue": "In Proceedings of the 2011 IEEE Conference on Development and Learning and Epigenetic Robotics IEEE-ICDL-EPIROB. IEEE,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Intrinsically motivated learning of real world sensorimotor skills with developmental constraints", "author": ["P.-Y. Oudeyer", "A. Baranes", "F. Kaplan"], "venue": "Intrinsically Motivated Learning in Natural and Artificial Systems. Springer,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "The Child\u2019s Construction of Reality", "author": ["J. Piaget"], "venue": "London: Routledge and Kegan Paul,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1955}, {"title": "Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien der biologischen Evolution", "author": ["I. Rechenberg"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1971}, {"title": "Continual Learning in Reinforcement Environments", "author": ["M.B. Ring"], "venue": "PhD thesis, University of Texas at Austin, Austin, Texas", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1994}, {"title": "Curiosity-Driven Optimization", "author": ["T. Schaul", "Yi Sun", "D. Wierstra", "F. Gomez", "J. Schmidhuber"], "venue": "In IEEE Congress on Evolutionary Computation (CEC),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Dynamische neuronale Netze und das fundamentale raumzeitliche Lernproblem", "author": ["J. Schmidhuber"], "venue": "Dissertation, Institut fu\u0308r Informatik, Technische Universita\u0308t Mu\u0308nchen,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1990}, {"title": "Curious model-building control systems", "author": ["J. Schmidhuber"], "venue": "In Proceedings of the International Joint Conference on Neural Networks, Singapore,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1991}, {"title": "A possibility for implementing curiosity and boredom in model-building neural controllers", "author": ["J. Schmidhuber"], "venue": "Proc. of the International Conference on Simulation of Adaptive Behavior: From Animals to Animats,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1991}, {"title": "Learning to control fast-weight memories: An alternative to recurrent nets", "author": ["J. Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1992}, {"title": "On decreasing the ratio between learning complexity and number of time-varying variables in fully recurrent nets", "author": ["J. Schmidhuber"], "venue": "In Proceedings of the International Conference on Artificial Neural Networks,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1993}, {"title": "A self-referential weight matrix", "author": ["J. Schmidhuber"], "venue": "In Proceedings of the International Conference on Artificial Neural Networks,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1993}, {"title": "Artificial curiosity based on discovering novel algorithmic predictability through coevolution", "author": ["J. Schmidhuber"], "venue": "Congress on Evolutionary Computation,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1999}, {"title": "Exploring the predictable", "author": ["J. Schmidhuber"], "venue": "Advances in Evolutionary Computing,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2002}, {"title": "OOPS source code in crystalline format: http://www.idsia.ch/ \u0303juergen/oopscode.c", "author": ["J. Schmidhuber"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2004}, {"title": "Optimal ordered problem solver", "author": ["J. Schmidhuber"], "venue": "Machine Learning,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2004}, {"title": "Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts", "author": ["J. Schmidhuber"], "venue": "Connection Science,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2006}, {"title": "G\u00f6del machines: Fully self-referential optimal universal self-improvers", "author": ["J. Schmidhuber"], "venue": "Artificial General Intelligence,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2006}, {"title": "Ultimate cognition \u00e0 la G\u00f6del", "author": ["J. Schmidhuber"], "venue": "Cognitive Computation,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2009}, {"title": "Formal theory of creativity, fun, and intrinsic motivation (1990-2010)", "author": ["J. Schmidhuber"], "venue": "IEEE Transactions on Autonomous Mental Development,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2010}, {"title": "Shifting inductive bias with success-story algorithm, adaptive Levin search, and incremental self-improvement", "author": ["J. Schmidhuber", "J. Zhao", "M. Wiering"], "venue": "Machine Learning,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1997}, {"title": "Parameter-exploring policy gradients", "author": ["F. Sehnke", "C. Osendorfer", "T. R\u00fcckstie\u00df", "A. Graves", "J. Peters", "J. Schmidhuber"], "venue": "Neural Networks,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2010}, {"title": "A mathematical theory of communication (parts I and II)", "author": ["C.E. Shannon"], "venue": "Bell System Technical Journal,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1948}, {"title": "Reinforcement driven information acquisition in nondeterministic environments", "author": ["J. Storck", "S. Hochreiter", "J. Schmidhuber"], "venue": "In Proceedings of the International Conference on Artificial Neural Networks, Paris,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1995}, {"title": "Reinforcement Learning: An Introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1998}, {"title": "On computable numbers, with an application to the Entscheidungsproblem", "author": ["A.M. Turing"], "venue": "Proceedings of the London Mathematical Society, Series", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1936}, {"title": "Natural evolution strategies", "author": ["D. Wierstra", "T. Schaul", "J. Peters", "J. Schmidhuber"], "venue": "In Congress of Evolutionary Computation", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2008}, {"title": "Planning to be surprised: Optimal Bayesian exploration in dynamic environments", "author": ["S. Yi", "F. Gomez", "J. Schmidhuber"], "venue": "In Proc. Fourth Conference on Artificial General Intelligence (AGI),", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2011}], "referenceMentions": [{"referenceID": 32, "context": "greedy but practical implementation of basic principles of creativity [33, 36].", "startOffset": 70, "endOffset": 78}, {"referenceID": 35, "context": "greedy but practical implementation of basic principles of creativity [33, 36].", "startOffset": 70, "endOffset": 78}, {"referenceID": 12, "context": "Given a realistic piece of computational hardware with specific resource limitations, how can one devise software for it that will solve all, or at least many, of the a priori unknown tasks that are in principle easily solvable on this architecture? In other words, how to build a practical general problem solver, given the computational restrictions? It does not need to be universal and asymptotically optimal [13, 11, 32, 35] like the recent (not necessarily practically feasible) general problem solvers discussed in Section 9.", "startOffset": 413, "endOffset": 429}, {"referenceID": 10, "context": "Given a realistic piece of computational hardware with specific resource limitations, how can one devise software for it that will solve all, or at least many, of the a priori unknown tasks that are in principle easily solvable on this architecture? In other words, how to build a practical general problem solver, given the computational restrictions? It does not need to be universal and asymptotically optimal [13, 11, 32, 35] like the recent (not necessarily practically feasible) general problem solvers discussed in Section 9.", "startOffset": 413, "endOffset": 429}, {"referenceID": 31, "context": "Given a realistic piece of computational hardware with specific resource limitations, how can one devise software for it that will solve all, or at least many, of the a priori unknown tasks that are in principle easily solvable on this architecture? In other words, how to build a practical general problem solver, given the computational restrictions? It does not need to be universal and asymptotically optimal [13, 11, 32, 35] like the recent (not necessarily practically feasible) general problem solvers discussed in Section 9.", "startOffset": 413, "endOffset": 429}, {"referenceID": 34, "context": "Given a realistic piece of computational hardware with specific resource limitations, how can one devise software for it that will solve all, or at least many, of the a priori unknown tasks that are in principle easily solvable on this architecture? In other words, how to build a practical general problem solver, given the computational restrictions? It does not need to be universal and asymptotically optimal [13, 11, 32, 35] like the recent (not necessarily practically feasible) general problem solvers discussed in Section 9.", "startOffset": 413, "endOffset": 429}, {"referenceID": 24, "context": "(See [25, 24, 29, 33, 36, 44] and Section 9.", "startOffset": 5, "endOffset": 29}, {"referenceID": 23, "context": "(See [25, 24, 29, 33, 36, 44] and Section 9.", "startOffset": 5, "endOffset": 29}, {"referenceID": 28, "context": "(See [25, 24, 29, 33, 36, 44] and Section 9.", "startOffset": 5, "endOffset": 29}, {"referenceID": 32, "context": "(See [25, 24, 29, 33, 36, 44] and Section 9.", "startOffset": 5, "endOffset": 29}, {"referenceID": 35, "context": "(See [25, 24, 29, 33, 36, 44] and Section 9.", "startOffset": 5, "endOffset": 29}, {"referenceID": 43, "context": "(See [25, 24, 29, 33, 36, 44] and Section 9.", "startOffset": 5, "endOffset": 29}, {"referenceID": 20, "context": "The framework is called POWERPLAY because it continually [21] aims at boosting computational prowess and problem solving capacity, reminiscent of humans or human societies trying to boost their general power/capabilities/knowledge/skills in playful ways, even in the absence of externally defined goals, although the skills learned by this type of pure curiosity may later help to solve externally posed tasks.", "startOffset": 57, "endOffset": 61}, {"referenceID": 23, "context": "Unlike our first implementations of curious/creative/playful agents from the 1990s [24, 40, 29] (Section 9.", "startOffset": 83, "endOffset": 95}, {"referenceID": 39, "context": "Unlike our first implementations of curious/creative/playful agents from the 1990s [24, 40, 29] (Section 9.", "startOffset": 83, "endOffset": 95}, {"referenceID": 28, "context": "Unlike our first implementations of curious/creative/playful agents from the 1990s [24, 40, 29] (Section 9.", "startOffset": 83, "endOffset": 95}, {"referenceID": 0, "context": "2; compare [1, 4, 18, 15]), POWERPLAY provably (by design) does not have any problems with online learning\u2014it cannot forget previously learned skills, automatically segmenting its life into a sequence of clearly identified tasks with explicitly recorded solutions.", "startOffset": 11, "endOffset": 25}, {"referenceID": 3, "context": "2; compare [1, 4, 18, 15]), POWERPLAY provably (by design) does not have any problems with online learning\u2014it cannot forget previously learned skills, automatically segmenting its life into a sequence of clearly identified tasks with explicitly recorded solutions.", "startOffset": 11, "endOffset": 25}, {"referenceID": 17, "context": "2; compare [1, 4, 18, 15]), POWERPLAY provably (by design) does not have any problems with online learning\u2014it cannot forget previously learned skills, automatically segmenting its life into a sequence of clearly identified tasks with explicitly recorded solutions.", "startOffset": 11, "endOffset": 25}, {"referenceID": 14, "context": "2; compare [1, 4, 18, 15]), POWERPLAY provably (by design) does not have any problems with online learning\u2014it cannot forget previously learned skills, automatically segmenting its life into a sequence of clearly identified tasks with explicitly recorded solutions.", "startOffset": 11, "endOffset": 25}, {"referenceID": 32, "context": "Unlike the task search of theoretically optimal creative agents [33, 36] (Section 9.", "startOffset": 64, "endOffset": 72}, {"referenceID": 35, "context": "Unlike the task search of theoretically optimal creative agents [33, 36] (Section 9.", "startOffset": 64, "endOffset": 72}, {"referenceID": 23, "context": "The present paper formalizes this in a way that may be more convenient to implement than those of previous work [24, 29, 33, 36], and describes a simple practical framework for building creative artificial scientists or explorers that by design continually come up with the fastest to find, initially novel, but eventually solvable problems.", "startOffset": 112, "endOffset": 128}, {"referenceID": 28, "context": "The present paper formalizes this in a way that may be more convenient to implement than those of previous work [24, 29, 33, 36], and describes a simple practical framework for building creative artificial scientists or explorers that by design continually come up with the fastest to find, initially novel, but eventually solvable problems.", "startOffset": 112, "endOffset": 128}, {"referenceID": 32, "context": "The present paper formalizes this in a way that may be more convenient to implement than those of previous work [24, 29, 33, 36], and describes a simple practical framework for building creative artificial scientists or explorers that by design continually come up with the fastest to find, initially novel, but eventually solvable problems.", "startOffset": 112, "endOffset": 128}, {"referenceID": 35, "context": "The present paper formalizes this in a way that may be more convenient to implement than those of previous work [24, 29, 33, 36], and describes a simple practical framework for building creative artificial scientists or explorers that by design continually come up with the fastest to find, initially novel, but eventually solvable problems.", "startOffset": 112, "endOffset": 128}, {"referenceID": 12, "context": "1, 8) orders candidate pairs of the type (task, solver) by computational complexity, using concepts of optimal universal search [13, 32], with a bias towards pairs that can be described by few additional bits of information (given the experience so far) and that can be validated quickly.", "startOffset": 128, "endOffset": 136}, {"referenceID": 31, "context": "1, 8) orders candidate pairs of the type (task, solver) by computational complexity, using concepts of optimal universal search [13, 32], with a bias towards pairs that can be described by few additional bits of information (given the experience so far) and that can be validated quickly.", "startOffset": 128, "endOffset": 136}, {"referenceID": 1, "context": "The computational architecture of the problem solver may be a deterministic universal computer, or a more limited device such as a finite state automaton or a feedforward neural network (NN) [2].", "startOffset": 191, "endOffset": 194}, {"referenceID": 6, "context": "All such problem solvers can be uniquely encoded [7] or implemented on universal computers such as universal Turing Machines (TM) [42].", "startOffset": 49, "endOffset": 52}, {"referenceID": 41, "context": "All such problem solvers can be uniquely encoded [7] or implemented on universal computers such as universal Turing Machines (TM) [42].", "startOffset": 130, "endOffset": 134}, {"referenceID": 1, "context": "Note that ni and ti may be unnecessary in special cases such as the problem solver being a fixed topology feedforward NN [2] whose input and target patterns have constant size and whose computational efforts per pattern need constant time and space resources.", "startOffset": 121, "endOffset": 124}, {"referenceID": 15, "context": "In the more general context of general problem solving/sequential decision making/reinforcement learning/reward optimization [16, 12, 41] in unknown environments, there may be a set I \u2282 B of possible task identification patterns and a set J \u2282 B of programs that test properties of bitstrings.", "startOffset": 125, "endOffset": 137}, {"referenceID": 11, "context": "In the more general context of general problem solving/sequential decision making/reinforcement learning/reward optimization [16, 12, 41] in unknown environments, there may be a set I \u2282 B of possible task identification patterns and a set J \u2282 B of programs that test properties of bitstrings.", "startOffset": 125, "endOffset": 137}, {"referenceID": 40, "context": "In the more general context of general problem solving/sequential decision making/reinforcement learning/reward optimization [16, 12, 41] in unknown environments, there may be a set I \u2282 B of possible task identification patterns and a set J \u2282 B of programs that test properties of bitstrings.", "startOffset": 125, "endOffset": 137}, {"referenceID": 8, "context": "For example, ui(t) may encode the current contents of the internal tape of a TM, or of certain addresses in the dynamic storage area of a PC, or the present activations of an LSTM recurrent NN [9].", "startOffset": 193, "endOffset": 196}, {"referenceID": 34, "context": "This could be done like in the G\u00f6del Machine [35] (Section 9.", "startOffset": 45, "endOffset": 49}, {"referenceID": 12, "context": "1), which uses an online extension of Universal Search [13] to systematically test proof techniques: proof-generating programs that may invoke special instructions for generating axioms and applying inference rules to prolong an initially empty proof \u2208 B by theorems, which are either axioms or inferred from previous theorems through rules such as modus ponens combined with unification, e.", "startOffset": 55, "endOffset": 59}, {"referenceID": 5, "context": ", [6].", "startOffset": 2, "endOffset": 5}, {"referenceID": 34, "context": "P can be easily limited to programs generating only syntactically correct proofs [35].", "startOffset": 81, "endOffset": 85}, {"referenceID": 31, "context": ") By restricting S to self-delimiting prefix codes like those generated by the Optimal Ordered Problem Solver (OOPS) [32], one can now profit from a sometimes particularly efficient type of CORRECTNESS DEMONSTRATION, ensuring that differences between si and si\u22121 cannot affect solutions to T<i under certain conditions.", "startOffset": 117, "endOffset": 121}, {"referenceID": 31, "context": "More precisely, to obtain si, half the search time is spent on trying to process Ti first by si\u22121, extending or prolonging si\u22121 only when the ongoing computation requests to add new components through special instructions [32]\u2014then CORRECTNESS DEMONSTRATION has less to do as the set T<i is guaranteed to remain solvable, by induction.", "startOffset": 222, "endOffset": 226}, {"referenceID": 31, "context": "The other half of the time is spent on processing Ti by a new sub-program with new components s\u2032i, a part of si but not of si\u22121, where s\u2032i may read si\u22121 or invoke parts of si\u22121 as sub-programs to solve T\u2264i \u2014 only then CORRECTNESS DEMONSTRATION has to test si not only on Ti but also on T<i (see [32] for details).", "startOffset": 295, "endOffset": 299}, {"referenceID": 31, "context": "However, in this simple setup there is no immediate generalization across tasks like in OOPS [32] and the previous paragraph: the trivial task identifier i will always first invoke some s\u2032i different from all s\u2032k(k 6= i), instead of allowing for solving a new task solely by previously found code.", "startOffset": 93, "endOffset": 97}, {"referenceID": 31, "context": "This yields a perfectly ordered problem sequence for a variant of the Optimal Ordered Problem Solver OOPS [32] described next.", "startOffset": 106, "endOffset": 110}, {"referenceID": 31, "context": ", k\u2212 1) and for copying the read code into modifiable storage U , where pk may further edit the code, and execute the result, which may be a useful subprogram [32].", "startOffset": 159, "endOffset": 163}, {"referenceID": 12, "context": "Define a probability distributionP (p) on P to represent the searcher\u2019s initial bias (more likely programs p will be tested earlier [13]).", "startOffset": 132, "endOffset": 136}, {"referenceID": 31, "context": ",P (p) = 2, or on a probabilistic syntax diagram [32, 31].", "startOffset": 49, "endOffset": 57}, {"referenceID": 30, "context": ",P (p) = 2, or on a probabilistic syntax diagram [32, 31].", "startOffset": 49, "endOffset": 57}, {"referenceID": 31, "context": "1: Implementing POWERPLAY with Procedure OOPS [32]", "startOffset": 46, "endOffset": 50}, {"referenceID": 31, "context": "This does not cost more time than executing p in the while loop above [32].", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "OOPS allocates time to programs according to an asymptotically optimal universal search method [13] for problems with easily verifiable solutions, that is, solutions whose validity can be quickly tested.", "startOffset": 95, "endOffset": 99}, {"referenceID": 31, "context": "Since OOPS may re-use previously generated solutions and solution-computing programs, however, it may be possible to greatly reduce the constant factor associated with plain universal search [32].", "startOffset": 191, "endOffset": 195}, {"referenceID": 30, "context": "Existing OOPS source code [31] uses a FORTH-like universal programming language to define P .", "startOffset": 26, "endOffset": 30}, {"referenceID": 22, "context": "Given enough additive and multiplicative neurons and an appropriate weight matrix, RNN1 can compute any function computable by a standard PC [23].", "startOffset": 141, "endOffset": 145}, {"referenceID": 25, "context": "P may itself be the set of weight matrices of a separate RNN called RNN2, computing tasks for RNN1, and modifications of RNN1, using techniques for network-modifying networks as described in [26, 28, 27].", "startOffset": 191, "endOffset": 203}, {"referenceID": 27, "context": "P may itself be the set of weight matrices of a separate RNN called RNN2, computing tasks for RNN1, and modifications of RNN1, using techniques for network-modifying networks as described in [26, 28, 27].", "startOffset": 191, "endOffset": 203}, {"referenceID": 26, "context": "P may itself be the set of weight matrices of a separate RNN called RNN2, computing tasks for RNN1, and modifications of RNN1, using techniques for network-modifying networks as described in [26, 28, 27].", "startOffset": 191, "endOffset": 203}, {"referenceID": 36, "context": "Simple ways of doing this are described in previous work [37].", "startOffset": 57, "endOffset": 61}, {"referenceID": 19, "context": "do set Boolean variable DONE=FALSE repeat use a black box optimization algorithm BBOA (many are possible [20, 8, 43, 38]) with adaptive parameter vector \u03b8 to create some T \u2208 T (to define the task input to RNN1; see Section 3.", "startOffset": 105, "endOffset": 120}, {"referenceID": 7, "context": "do set Boolean variable DONE=FALSE repeat use a black box optimization algorithm BBOA (many are possible [20, 8, 43, 38]) with adaptive parameter vector \u03b8 to create some T \u2208 T (to define the task input to RNN1; see Section 3.", "startOffset": 105, "endOffset": 120}, {"referenceID": 42, "context": "do set Boolean variable DONE=FALSE repeat use a black box optimization algorithm BBOA (many are possible [20, 8, 43, 38]) with adaptive parameter vector \u03b8 to create some T \u2208 T (to define the task input to RNN1; see Section 3.", "startOffset": 105, "endOffset": 120}, {"referenceID": 37, "context": "do set Boolean variable DONE=FALSE repeat use a black box optimization algorithm BBOA (many are possible [20, 8, 43, 38]) with adaptive parameter vector \u03b8 to create some T \u2208 T (to define the task input to RNN1; see Section 3.", "startOffset": 105, "endOffset": 120}, {"referenceID": 42, "context": ", by gradient-based search [43, 38], or according to the principles of evolutionary computation [20, 8, 43].", "startOffset": 27, "endOffset": 35}, {"referenceID": 37, "context": ", by gradient-based search [43, 38], or according to the principles of evolutionary computation [20, 8, 43].", "startOffset": 27, "endOffset": 35}, {"referenceID": 19, "context": ", by gradient-based search [43, 38], or according to the principles of evolutionary computation [20, 8, 43].", "startOffset": 96, "endOffset": 107}, {"referenceID": 7, "context": ", by gradient-based search [43, 38], or according to the principles of evolutionary computation [20, 8, 43].", "startOffset": 96, "endOffset": 107}, {"referenceID": 42, "context": ", by gradient-based search [43, 38], or according to the principles of evolutionary computation [20, 8, 43].", "startOffset": 96, "endOffset": 107}, {"referenceID": 23, "context": "One should analyze theoretically and experimentally under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies in this vein.", "startOffset": 174, "endOffset": 205}, {"referenceID": 39, "context": "One should analyze theoretically and experimentally under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies in this vein.", "startOffset": 174, "endOffset": 205}, {"referenceID": 28, "context": "One should analyze theoretically and experimentally under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies in this vein.", "startOffset": 174, "endOffset": 205}, {"referenceID": 29, "context": "One should analyze theoretically and experimentally under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies in this vein.", "startOffset": 174, "endOffset": 205}, {"referenceID": 13, "context": "One should analyze theoretically and experimentally under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies in this vein.", "startOffset": 174, "endOffset": 205}, {"referenceID": 2, "context": "One should analyze theoretically and experimentally under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies in this vein.", "startOffset": 174, "endOffset": 205}, {"referenceID": 21, "context": "One should analyze theoretically and experimentally under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies in this vein.", "startOffset": 174, "endOffset": 205}, {"referenceID": 43, "context": "One should analyze theoretically and experimentally under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies in this vein.", "startOffset": 174, "endOffset": 205}, {"referenceID": 12, "context": ", in the style of asymptotically optimal Universal Search [13], which essentially trades one bit of additional space complexity for a runtime speedup factor of 2.", "startOffset": 58, "endOffset": 62}, {"referenceID": 1, "context": "matrix of a fixed-size feedforward NN [2] which maps 2-dimensional real-valued input vectors from the unit square [0, 1) \u00d7 [0, 1) to binary labels 0 or 1, depending on whether the real-valued activation of the NN\u2019s single output neuron exceeds 0.", "startOffset": 38, "endOffset": 41}, {"referenceID": 38, "context": "The simplicity measure derives from a Gaussian prior with zero mean on all weights (the costs of encoding a weight with a certain precision given by some interval size is proportional to the logarithm of its probability [39, 10, 2]).", "startOffset": 220, "endOffset": 231}, {"referenceID": 9, "context": "The simplicity measure derives from a Gaussian prior with zero mean on all weights (the costs of encoding a weight with a certain precision given by some interval size is proportional to the logarithm of its probability [39, 10, 2]).", "startOffset": 220, "endOffset": 231}, {"referenceID": 1, "context": "The simplicity measure derives from a Gaussian prior with zero mean on all weights (the costs of encoding a weight with a certain precision given by some interval size is proportional to the logarithm of its probability [39, 10, 2]).", "startOffset": 220, "endOffset": 231}, {"referenceID": 1, "context": "To run p for t steps (on a training set of i patterns so far) means to execute \u230at/i\u230b iterations (or epochs) of gradient descent [2] on the training set and to check whether all patterns are correctly classified (CORRECTNESS DEMONSTRATION).", "startOffset": 128, "endOffset": 131}, {"referenceID": 4, "context": "There also is a novel, computational resources-based active learning [5] variant of this setup, where the system does not invent labels/targets/classifications by itself, but relies on a teacher-given pre-determined label for each input vector it proposes, essentially querying the teacher through input patterns (that is, the bit p above is not needed).", "startOffset": 69, "endOffset": 72}, {"referenceID": 12, "context": "Then the next task is defined by the following simple enumerative search (in the style of Universal Search [13]) which combines task simplification in the sense of Algorithm 7.", "startOffset": 107, "endOffset": 111}, {"referenceID": 18, "context": "At some point, however, there is a phase transition to more complex non-linear functions, indicating a new developmental stage [19, 30, 17].", "startOffset": 127, "endOffset": 139}, {"referenceID": 29, "context": "At some point, however, there is a phase transition to more complex non-linear functions, indicating a new developmental stage [19, 30, 17].", "startOffset": 127, "endOffset": 139}, {"referenceID": 16, "context": "At some point, however, there is a phase transition to more complex non-linear functions, indicating a new developmental stage [19, 30, 17].", "startOffset": 127, "endOffset": 139}, {"referenceID": 23, "context": "1, it is also intended to study under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies along these lines.", "startOffset": 154, "endOffset": 185}, {"referenceID": 39, "context": "1, it is also intended to study under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies along these lines.", "startOffset": 154, "endOffset": 185}, {"referenceID": 28, "context": "1, it is also intended to study under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies along these lines.", "startOffset": 154, "endOffset": 185}, {"referenceID": 29, "context": "1, it is also intended to study under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies along these lines.", "startOffset": 154, "endOffset": 185}, {"referenceID": 13, "context": "1, it is also intended to study under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies along these lines.", "startOffset": 154, "endOffset": 185}, {"referenceID": 2, "context": "1, it is also intended to study under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies along these lines.", "startOffset": 154, "endOffset": 185}, {"referenceID": 21, "context": "1, it is also intended to study under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies along these lines.", "startOffset": 154, "endOffset": 185}, {"referenceID": 43, "context": "1, it is also intended to study under which conditions the creation of self-generated tasks can accelerate the solution to externally generated tasks\u2014see [24, 40, 29, 30, 14, 3, 22, 44] for previous simple experimental studies along these lines.", "startOffset": 154, "endOffset": 185}, {"referenceID": 6, "context": "The fully self-referential [7] G\u00f6del machine [34, 35] may interact with some initially unknown, partially observable environment to maximize future expected utility or reward by solving arbitrary user-defined computational tasks.", "startOffset": 27, "endOffset": 30}, {"referenceID": 33, "context": "The fully self-referential [7] G\u00f6del machine [34, 35] may interact with some initially unknown, partially observable environment to maximize future expected utility or reward by solving arbitrary user-defined computational tasks.", "startOffset": 45, "endOffset": 53}, {"referenceID": 34, "context": "The fully self-referential [7] G\u00f6del machine [34, 35] may interact with some initially unknown, partially observable environment to maximize future expected utility or reward by solving arbitrary user-defined computational tasks.", "startOffset": 45, "endOffset": 53}, {"referenceID": 6, "context": "Self-rewrites due to this approach can be shown to be globally optimal, relative to G\u00f6del\u2019s well-known fundamental restrictions of provability [7].", "startOffset": 143, "endOffset": 146}, {"referenceID": 10, "context": "To make sure the G\u00f6del machine is at least asymptotically optimal even before the first self-rewrite, one may initialize it by Hutter\u2019s non-self-referential but asymptotically fastest algorithm for all well-defined problems Hsearch [11], which uses a hardwired brute force proof searcher and ignores the costs of proof search.", "startOffset": 232, "endOffset": 236}, {"referenceID": 10, "context": "Hsearch is as fast as the fastest algorithm that provably computes f(z) for all z \u2208 X , save for a constant factor smaller than 1+\u01eb (arbitrarily small real-valued \u01eb > 0) and an f -specific but x-independent additive constant [11].", "startOffset": 225, "endOffset": 229}, {"referenceID": 23, "context": "As mentioned in Section 6, however, one must now analyze under which conditions POWERPLAY\u2019s self-generated tasks can accelerate the solution to externally generated tasks (compare previous experimental studies of this type [24, 40, 29, 30]).", "startOffset": 223, "endOffset": 239}, {"referenceID": 39, "context": "As mentioned in Section 6, however, one must now analyze under which conditions POWERPLAY\u2019s self-generated tasks can accelerate the solution to externally generated tasks (compare previous experimental studies of this type [24, 40, 29, 30]).", "startOffset": 223, "endOffset": 239}, {"referenceID": 28, "context": "As mentioned in Section 6, however, one must now analyze under which conditions POWERPLAY\u2019s self-generated tasks can accelerate the solution to externally generated tasks (compare previous experimental studies of this type [24, 40, 29, 30]).", "startOffset": 223, "endOffset": 239}, {"referenceID": 29, "context": "As mentioned in Section 6, however, one must now analyze under which conditions POWERPLAY\u2019s self-generated tasks can accelerate the solution to externally generated tasks (compare previous experimental studies of this type [24, 40, 29, 30]).", "startOffset": 223, "endOffset": 239}, {"referenceID": 32, "context": "The Formal Theory of Creativity [33, 36] considers agents living in initially unknown environments.", "startOffset": 32, "endOffset": 40}, {"referenceID": 35, "context": "The Formal Theory of Creativity [33, 36] considers agents living in initially unknown environments.", "startOffset": 32, "endOffset": 40}, {"referenceID": 11, "context": "At any given time, such an agent uses a reinforcement learning (RL) method [12] to maximize not only expected future external reward for achieving certain goals, but also intrinsic reward for improving an internal model of the environmental responses to its actions, learning to better predict or compress the growing history of observations influenced by its behavior, actively learning skills to influence the input stream such that it contains previously unknown but learnable algorithmic regularities.", "startOffset": 75, "endOffset": 79}, {"referenceID": 32, "context": ", [33, 36].", "startOffset": 2, "endOffset": 10}, {"referenceID": 35, "context": ", [33, 36].", "startOffset": 2, "endOffset": 10}, {"referenceID": 0, "context": ", [1, 4, 18, 15].", "startOffset": 2, "endOffset": 16}, {"referenceID": 3, "context": ", [1, 4, 18, 15].", "startOffset": 2, "endOffset": 16}, {"referenceID": 17, "context": ", [1, 4, 18, 15].", "startOffset": 2, "endOffset": 16}, {"referenceID": 14, "context": ", [1, 4, 18, 15].", "startOffset": 2, "endOffset": 16}, {"referenceID": 32, "context": "Instead of maximizing future expected reward, POWERPLAY is greedy, always trying to find the simplest (easiest to find and validate) task to add to the repertoire, or the simplest way of improving the efficiency or compressibility of previous solutions, instead of looking further ahead, as a universal RL method [33, 36] would do.", "startOffset": 313, "endOffset": 321}, {"referenceID": 35, "context": "Instead of maximizing future expected reward, POWERPLAY is greedy, always trying to find the simplest (easiest to find and validate) task to add to the repertoire, or the simplest way of improving the efficiency or compressibility of previous solutions, instead of looking further ahead, as a universal RL method [33, 36] would do.", "startOffset": 313, "endOffset": 321}, {"referenceID": 32, "context": "The general creative agent above [33, 36] is motivated to improve performance on the entire history of previous still unsolved tasks, while POWERPLAY will discard much of this history, keeping only a selective list of previously solved tasks.", "startOffset": 33, "endOffset": 41}, {"referenceID": 35, "context": "The general creative agent above [33, 36] is motivated to improve performance on the entire history of previous still unsolved tasks, while POWERPLAY will discard much of this history, keeping only a selective list of previously solved tasks.", "startOffset": 33, "endOffset": 41}, {"referenceID": 32, "context": "POWERPLAY as in Section 2 has a binary criterion for adding knowledge (was the new task solvable without forgetting old solutions?), while the general agent [33, 36] uses a more informative information-theoretic measure.", "startOffset": 157, "endOffset": 165}, {"referenceID": 35, "context": "POWERPLAY as in Section 2 has a binary criterion for adding knowledge (was the new task solvable without forgetting old solutions?), while the general agent [33, 36] uses a more informative information-theoretic measure.", "startOffset": 157, "endOffset": 165}, {"referenceID": 23, "context": "Some previous approximative implementations [24, 40] used traditional RL methods [12] with theoretically unlimited look-ahead, but those are not guaranteed to work well in partially observable and/or non-stationary environments where the reward function changes over time, and won\u2019t necessarily generate an optimal sequence of future tasks or experiments.", "startOffset": 44, "endOffset": 52}, {"referenceID": 39, "context": "Some previous approximative implementations [24, 40] used traditional RL methods [12] with theoretically unlimited look-ahead, but those are not guaranteed to work well in partially observable and/or non-stationary environments where the reward function changes over time, and won\u2019t necessarily generate an optimal sequence of future tasks or experiments.", "startOffset": 44, "endOffset": 52}, {"referenceID": 11, "context": "Some previous approximative implementations [24, 40] used traditional RL methods [12] with theoretically unlimited look-ahead, but those are not guaranteed to work well in partially observable and/or non-stationary environments where the reward function changes over time, and won\u2019t necessarily generate an optimal sequence of future tasks or experiments.", "startOffset": 81, "endOffset": 85}, {"referenceID": 23, "context": "Previous approximative implementations based on traditional RL [24, 40] and on co-evolution of program-like task generators and task solvers [29, 30] also did not have a built-in guarantee that they cannot forget solutions to previously solved tasks, while POWERPLAY as in Section 2 does (and the time and space complexitybased variant Alg.", "startOffset": 63, "endOffset": 71}, {"referenceID": 39, "context": "Previous approximative implementations based on traditional RL [24, 40] and on co-evolution of program-like task generators and task solvers [29, 30] also did not have a built-in guarantee that they cannot forget solutions to previously solved tasks, while POWERPLAY as in Section 2 does (and the time and space complexitybased variant Alg.", "startOffset": 63, "endOffset": 71}, {"referenceID": 28, "context": "Previous approximative implementations based on traditional RL [24, 40] and on co-evolution of program-like task generators and task solvers [29, 30] also did not have a built-in guarantee that they cannot forget solutions to previously solved tasks, while POWERPLAY as in Section 2 does (and the time and space complexitybased variant Alg.", "startOffset": 141, "endOffset": 149}, {"referenceID": 29, "context": "Previous approximative implementations based on traditional RL [24, 40] and on co-evolution of program-like task generators and task solvers [29, 30] also did not have a built-in guarantee that they cannot forget solutions to previously solved tasks, while POWERPLAY as in Section 2 does (and the time and space complexitybased variant Alg.", "startOffset": 141, "endOffset": 149}, {"referenceID": 32, "context": "Theoretically optimal implementations [33, 36] are currently still impractical, for reasons similar to those discussed in Section 9.", "startOffset": 38, "endOffset": 46}, {"referenceID": 35, "context": "Theoretically optimal implementations [33, 36] are currently still impractical, for reasons similar to those discussed in Section 9.", "startOffset": 38, "endOffset": 46}, {"referenceID": 32, "context": "Hence POWERPLAY may be viewed as a greedy but feasible implementation of basic principles of creativity [33, 36].", "startOffset": 104, "endOffset": 112}, {"referenceID": 35, "context": "Hence POWERPLAY may be viewed as a greedy but feasible implementation of basic principles of creativity [33, 36].", "startOffset": 104, "endOffset": 112}, {"referenceID": 6, "context": "If both S and P allow for implementing arbitrary programs, and the search algorithm is a general method for search in program space (Section 4), then there are few limits to what it may do (besides the limits of computability [7]).", "startOffset": 226, "endOffset": 229}], "year": 2017, "abstractText": "Most of computer science focuses on automatically solving given computational problems. I focus on automatically inventing or discovering problems in a way inspired by the playful behavior of animals and humans, to train a more and more general problem solver from scratch in an unsupervised fashion. At any given time, the novel algorithmic framework POWERPLAY searches the space of possible pairs of new tasks and modifications of the current problem solver, until it finds a more powerful problem solver that provably solves all previously learned tasks plus the new one, while the unmodified predecessor does not. The new task and its corresponding task-solving skill are those first found and validated. Newly invented tasks may require making previously learned skills more efficient. The greedy search of typical POWERPLAY variants orders candidate pairs of tasks and solver modifications by their conditional computational complexity, given the stored experience so far. This biases the search towards pairs that can be described compactly and validated quickly. Standard problem solver architectures of personal computers or neural networks tend to generalize by solving numerous tasks outside the self-invented training set; POWERPLAY\u2019s ongoing search for novelty keeps fighting to extend beyond the generalization abilities of its present solver. The continually increasing repertoire of problem solving procedures can be exploited by a parallel search for solutions to additional externally posed tasks. POWERPLAY may be viewed as a greedy but practical implementation of basic principles of creativity [33, 36]. The present paper is purely conceptual though; detailed experimental analysis of various problem solver architectures with different generalization properties is left to separate papers.", "creator": "LaTeX with hyperref package"}}}