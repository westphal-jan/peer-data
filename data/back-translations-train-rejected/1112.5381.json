{"id": "1112.5381", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2011", "title": "Improving the Efficiency of Approximate Inference for Probabilistic Logical Models by means of Program Specialization", "abstract": "We consider the task of performing probabilistic inference with probabilistic logical models. Many algorithms for approximate inference with such models are based on sampling. From a logic programming perspective, sampling boils down to repeatedly calling the same queries on a knowledge base composed of a static part and a dynamic part. The larger the static part, the more redundancy there is in these repeated calls. This is problematic since inefficient sampling yields poor approximations.", "histories": [["v1", "Thu, 22 Dec 2011 17:01:34 GMT  (100kb,S)", "http://arxiv.org/abs/1112.5381v1", "17 pages"]], "COMMENTS": "17 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["daan fierens"], "accepted": false, "id": "1112.5381"}, "pdf": {"name": "1112.5381.pdf", "metadata": {"source": "CRF", "title": "Improving the Efficiency of Approximate Inference for Probabilistic Logical Models by means of Program Specialization", "authors": ["Daan Fierens"], "emails": ["Daan.Fierens@cs.kuleuven.be"], "sections": [{"heading": null, "text": "ar Xiv: 111 2.53 81v1 [cs.AI] 22 Dec 201 1Keywords: probabilistic logical models, logic program specialization"}, {"heading": "1 Introduction", "text": "In this area, there is a great deal of interest in the models that are able to go in search of a solution that is capable of finding a solution that meets the needs of the individual."}, {"heading": "2 Background", "text": "Probability Theory. In probability theory [9], one models the world in relation to random variables (RVs). Each state of the world corresponds to a common state of all RVs considered. We use uppercase letters to denote single RVs and uppercase letters to denote sets of RVs. We refer to the set of possible states / values of an RV X as a range of X, designated range (X). We only consider RVs with a finite range (i.e. discrete RVs). A probability distribution for an RV X is a function that maps each x-range (X) to a number P (x), designated range [0, 1] such that an x-range (X) P (x) = 1. A conditional probability distribution (CPD) for an RV X conditional probability distribution (Vs conditional probability) is a function that maps any common state from Y to a probability distribution (CPD) for an RV X conditional (Vs conditional probability)."}, {"heading": "3 Parameterized Bayesian Networks", "text": "This year it is more than ever before."}, {"heading": "4 Sampling-based Probabilistic Inference", "text": "The most likely conclusion is the probability that a particular camper is in a certain state. Considering the grades of all students in all courses (the evidence), for example, we can determine the probability of each student having a high IQ. Such probabilities can theoretically be calculated by performing arithmetic operations based on the probabilities given in the parameterized CPDs, but for the real population size this is impenetrable (inference with Bayesian networks is NP-hard [9])."}, {"heading": "4.1 Sampling-based Approximate Inference", "text": "An important class of approximate probabilistic inference algorithms are sample-based (\"Monte Carlo\") algorithms such as repulsion sampling, meaning sampling, Gibbs sampling, MCMC, and many variants [1,2,13]. All of these algorithms take samples from the probability distribution P (X), which is based on the evidence. A sample is the assignment of a value to each relevant RV. To effectively condition on the evidence, only samples that match the evidence are taken into consideration (a sample is consistent if it assigns its known value to each observed RV). Given such samples, we can construct an approximate answer to the inference questions. For marginal probabilities, this is straightforward. For example, the marginal probability that the student s1 has a high IQ can be estimated on the evidence, since the number of samples in which the RV iq has a value for a common algorithm is \"high\" (measured by some sampling)."}, {"heading": "4.2 Generic Structure of Sampling-based Inference Algorithms", "text": "This requires a structure that stores the \"current state\" of all RVs. Essentially, sampling is a process that continuously modifies this data structure in a stochastic way. Therefore, the generic structure common to many sampling-based inference algorithms is shown in Figure 1. As explained, we are only interested in samples that are consistent with the evidence. Therefore, we start by initializing all observed RVs to their known value (lines 1 and 2 in Figure 1). These RVs remain in this state throughout the sampling process. Next, we start taking samples that are consistent with the evidence. Therefore, we start by initializing all observed RVs to their known value (lines 1 and 2 in Figure 1). These RVs remain in this state throughout the sampling process."}, {"heading": "4.3 Sampling: The Prolog Implementation Perspective", "text": "In fact, the fact is that most of us are able to go in search of a solution that is capable, in that they are able to find a solution that is capable of finding a solution, and that is able to find a solution that is capable of finding a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution. \""}, {"heading": "5 Applying Logic Program Specialization to CPDs", "text": "One solution to the above redundancy is to specialize the definitions of CPD predicates in relation to the static part of the state KB (the evidence). Remember that each CPD predicate is defined by a series of prologue clauses that form a decision list, and that the bodies of these clauses refer to the state predicates. Evidence is a partial interpretation of the state predicates. Our specialization approach is a source-to-source transformation that takes the decision lists for all CPD predicates plus the evidence as input and returns as output a specialized version of the decision lists. Decision lists are used in inference only one way, namely by calling CPD queries, and there is a fixed set of possible CPD queries. For each CPD query, our specialized decision lists provide the same response as the original decision lists. This ensures that sampling produces exactly the same sequence of samples with specialization (but without being more efficient)."}, {"heading": "5.1 Outer Loops of the Specialization Algorithm", "text": "iSe rf\u00fc ide rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc"}, {"heading": "5.2 Inner Loops of the Specialization Algorithm", "text": "This year, it has reached the stage where it will be able to take the lead in order to achieve the objectives I have mentioned."}, {"heading": "5.3 Discussion.", "text": "From the perspective of the efficiency of the specialization process, our specialization algorithm is clearly not optimal: the specialization time can be reduced slightly, for example by merging the three different steps. However, in experiments (Section 6.2) we have observed that the specialization time is negligible compared to the runtime of the sampling with the specialized decision lists. Therefore, we keep our specialization algorithm as simple as possible, rather than complicating it to reduce the specialization time. This also makes it easier to see that the specialization actually preserves the semantics of the CPD predicate and therefore produces the same samples as without specialization."}, {"heading": "6 Experiments", "text": "We are now experimentally analyzing the influence of specialization on sampling efficiency. As a case study, we are looking at the Gibbs sampling algorithm [1,13]. For the pseudo-code of this algorithm, see [4]."}, {"heading": "6.1 Setup", "text": "We use three real data sets: IMDB, UWCSE and WebKB. These data sets are common benchmarks in the field of probabilistic logical models [3]. In previous work, we have applied machine learning algorithms to these data sets [5]. For each data set, we have converted the learned model into a parameterized Bayesian network. Table 1 contains some statistics on the models and data (see Fierens et al. [5] for more information). We use two inference scenarios that correspond to the two scenarios in Section 4.3. We measure the time it takes to pull 10,000 samples using the Gibbs sampling algorithm. Since our main goal is to investigate the relative efficiency of the various settings (with specialization versus without specialization), the choice of the number of samples does not greatly affect our conclusions. We report runtime in minutes. Runtime without specialization is the runtime of the sampling with parameterized packs that have not been sampled or specialized with the sampling."}, {"heading": "6.2 Results", "text": "The results for the missing data scenario are shown in Figure 5. Results show that the use of specializations always leads to an acceleration. Of course, the magnitude of the acceleration depends greatly on the amount of evidence. In the smaller data sets (IMDB and UWCSE), the accelerations are more modest. Results for the classification scenario are presented in Table 2. In 4 of the 7 tasks, the specialization leads to significant accelerations of a factor from 4.3 to 6.5. In the other tasks, the acceleration is low to negligible (\u2264 1.5); these are usually cases where the state makes the calculation of bottlenecks (e.g. because they occur within a financial system)."}, {"heading": "7 Conclusions", "text": "We used the framework of Bayesian parameterized networks and demonstrated how sample-based inference algorithms can be implemented in Prolog. We argued that specializing in logical programs is capable of making scanning more efficient, which in turn can make the results more accurate. We developed a specialization algorithm and experimented on the impact of specialization on the efficiency of scanning Gibbs. We found that specialization produces accelerations up to orders of magnitude and that these accelerations increase with the size of data.Recognition. This research is supported by the Flanders Research Foundation (FWO Vlaanderen), GOA / 08 / 008 \"Probabilistic Logic Learning\" and the K.U.Leuven. Research Fund."}], "references": [{"title": "Cutset sampling for Bayesian networks", "author": ["B. Bidyuk", "R. Dechter"], "venue": "Journal of Artificial Intelligence Research, 28:1\u201348,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": "Springer,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Probabilistic Inductive Logic Programming", "author": ["L. De Raedt", "P. Frasconi", "K. Kersting", "S. Muggleton"], "venue": "Springer,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Improving the efficiency of gibbs sampling for probabilistic logical models by means of program specialization", "author": ["D. Fierens"], "venue": "In Technical Communications of the 26th International Conference on Logic Programming (ICLP 2010), volume 7 of Leibniz International Proceedings in Informatics (LIPIcs), pages 74\u201383, Dagstuhl, Germany, July", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning directed probabilistic logical models: Ordering-search versus structure-search", "author": ["D. Fierens", "J. Ramon", "M. Bruynooghe", "H. Blockeel"], "venue": "Annals of Mathematics and Artificial Intelligence, 54(1):99\u2013133,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Logic program specialisation through partial deduction: Control issues", "author": ["M. Leuschel", "M. Bruynooghe"], "venue": "Theory and Practice of Logic Programming, 2(4-5):461\u2013 515,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Specialising interpreters using offline partial deduction", "author": ["M. Leuschel", "S. Craig", "M. Bruynooghe", "W. Vanhoof"], "venue": "In Program Development in Computational Logic, volume 3094 of Lecture Notes in Computer Science, pages 340\u2013375. Springer,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Structure learning of probabilistic relational models from incomplete relational data", "author": ["X.-L. Li", "Z.-H. Zhou"], "venue": "In Proceedings of the 18th European Conference on Machine Learning (ECML 2007), volume 4701 of Lecture Notes in Computer Science, pages 214\u2013225. Springer,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning Bayesian Networks", "author": ["R. Neapolitan"], "venue": "Prentice Hall, New Jersey,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Transformation of logic programs: Foundations and techniques", "author": ["A. Pettorossi", "M. Proietti"], "venue": "Journal of Logic Programming, 19-20:261\u2013320,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1994}, {"title": "First-order probabilistic inference", "author": ["D. Poole"], "venue": "In Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI 1997), pages 985\u2013991. Morgan Kaufmann,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "Sound and efficient inference with probabilistic and deterministic dependencies", "author": ["H. Poon", "P. Domingos"], "venue": "In Proceedings of the 21st National Conference on Artificial Intelligence (AAAI 2006), pages 214\u2013225. AAAI Press,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "On the implementation of the CLP(BN) language", "author": ["V. Santos Costa"], "venue": "In Proceedings of the 12th International Symposium on Practical Aspects of Declarative Languages (PADL 2010), volume 5937 of Lecture Notes in Artificial Intelligence, pages 234\u2013 248. Springer,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "andW", "author": ["V. Santos Costa", "A. Srinivasan", "R. Camacho", "H. Blockeel", "B. Demoen", "G. Janssens", "J. Struyf", "H. Vandecasteele"], "venue": "Van Laer. Query transformations for improving the efficiency of ILP systems. Journal of Machine Learning Research, 4:465\u2013491,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Improving the efficiency of inductive logic programming in the context of relational data mining", "author": ["J. Struyf"], "venue": "PhD thesis, Department of Computer Science, Katholieke Universiteit Leuven, December", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 2, "context": "In the field of artificial intelligence there is a large interest in probabilistic logical models, namely probabilistic extensions of logic programs as well as first-order logical extensions of probabilistic models such as Bayesian networks [3,5,11].", "startOffset": 241, "endOffset": 249}, {"referenceID": 4, "context": "In the field of artificial intelligence there is a large interest in probabilistic logical models, namely probabilistic extensions of logic programs as well as first-order logical extensions of probabilistic models such as Bayesian networks [3,5,11].", "startOffset": 241, "endOffset": 249}, {"referenceID": 10, "context": "In the field of artificial intelligence there is a large interest in probabilistic logical models, namely probabilistic extensions of logic programs as well as first-order logical extensions of probabilistic models such as Bayesian networks [3,5,11].", "startOffset": 241, "endOffset": 249}, {"referenceID": 0, "context": "While a variety of inference algorithms is being used, many of them are based on sampling [1,2,9,13].", "startOffset": 90, "endOffset": 100}, {"referenceID": 1, "context": "While a variety of inference algorithms is being used, many of them are based on sampling [1,2,9,13].", "startOffset": 90, "endOffset": 100}, {"referenceID": 8, "context": "While a variety of inference algorithms is being used, many of them are based on sampling [1,2,9,13].", "startOffset": 90, "endOffset": 100}, {"referenceID": 12, "context": "While a variety of inference algorithms is being used, many of them are based on sampling [1,2,9,13].", "startOffset": 90, "endOffset": 100}, {"referenceID": 5, "context": "While a lot of work about logic program specialization is about exploiting static information about the input arguments of queries (partial deduction [6]), we instead exploit static information about the knowledge base on which the queries are called.", "startOffset": 150, "endOffset": 153}, {"referenceID": 3, "context": "This paper extends an earlier paper [4].", "startOffset": 36, "endOffset": 39}, {"referenceID": 2, "context": "In this paper we focus on models that are first-order logical or \u201crelational\u201d extensions of Bayesian networks [3,5].", "startOffset": 110, "endOffset": 115}, {"referenceID": 4, "context": "In this paper we focus on models that are first-order logical or \u201crelational\u201d extensions of Bayesian networks [3,5].", "startOffset": 110, "endOffset": 115}, {"referenceID": 10, "context": "Concretely, we use the general framework of parameterized Bayesian networks [11].", "startOffset": 76, "endOffset": 80}, {"referenceID": 8, "context": "In probability theory [9] one models the world in terms of random variables (RVs).", "startOffset": 22, "endOffset": 25}, {"referenceID": 0, "context": "A probability distribution for an RV X is a function that maps each x \u2208 range(X) to a number P (x) \u2208 [0, 1] such that \u2211 x\u2208range(X) P (x) = 1.", "startOffset": 101, "endOffset": 107}, {"referenceID": 8, "context": "A Bayesian network [9] for a set of RVs X is a set of CPDs: for eachX \u2208 X there is one CPD forX conditioned on a (possibly empty) set of RVs called the parents of X .", "startOffset": 19, "endOffset": 22}, {"referenceID": 4, "context": "6,7,13] [5,13].", "startOffset": 8, "endOffset": 14}, {"referenceID": 12, "context": "6,7,13] [5,13].", "startOffset": 8, "endOffset": 14}, {"referenceID": 10, "context": "While there are many different frameworks for first-order logical (or \u201crelational\u201d) extensions of Bayesian networks, we focus on parameterized Bayesian networks [11] since they offer a simple yet adequate representation.", "startOffset": 161, "endOffset": 165}, {"referenceID": 8, "context": "Such probabilities can in theory be computed by performing arithmetic on the probabilities specified in the parameterized CPDs, but for real-world population sizes this is intractable (inference with Bayesian networks is NP-hard [9]).", "startOffset": 229, "endOffset": 232}, {"referenceID": 0, "context": "An important class of approximate probabilistic inference algorithms are samplingbased (\u2018Monte Carlo\u2019) algorithms such as rejection sampling, importance sampling, Gibbs sampling, MCMC, and many variants [1,2,13].", "startOffset": 203, "endOffset": 211}, {"referenceID": 1, "context": "An important class of approximate probabilistic inference algorithms are samplingbased (\u2018Monte Carlo\u2019) algorithms such as rejection sampling, importance sampling, Gibbs sampling, MCMC, and many variants [1,2,13].", "startOffset": 203, "endOffset": 211}, {"referenceID": 12, "context": "An important class of approximate probabilistic inference algorithms are samplingbased (\u2018Monte Carlo\u2019) algorithms such as rejection sampling, importance sampling, Gibbs sampling, MCMC, and many variants [1,2,13].", "startOffset": 203, "endOffset": 211}, {"referenceID": 0, "context": "the closer they are to the correct value, with convergence for N \u2192 \u221e) [1].", "startOffset": 70, "endOffset": 73}, {"referenceID": 1, "context": "\u2013 Simple algorithms such as forward sampling and rejection sampling [2] define Psample(U) as the distribution on U conditioned on the current state of U \u2019s parents.", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "\u2013 More advanced algorithms such as Gibbs sampling [1,13] and other MCMC variants [2] use a more complex definition of Psample(U).", "startOffset": 50, "endOffset": 56}, {"referenceID": 12, "context": "\u2013 More advanced algorithms such as Gibbs sampling [1,13] and other MCMC variants [2] use a more complex definition of Psample(U).", "startOffset": 50, "endOffset": 56}, {"referenceID": 1, "context": "\u2013 More advanced algorithms such as Gibbs sampling [1,13] and other MCMC variants [2] use a more complex definition of Psample(U).", "startOffset": 81, "endOffset": 84}, {"referenceID": 0, "context": "simple arithmetic to combine the results into the distribution Psample(U) [1,4].", "startOffset": 74, "endOffset": 79}, {"referenceID": 3, "context": "simple arithmetic to combine the results into the distribution Psample(U) [1,4].", "startOffset": 74, "endOffset": 79}, {"referenceID": 3, "context": "In experiments (with the Gibbs sampling algorithm for parameterized Bayesian networks [4]) we found that there is one operation that is clearly the computational bottleneck, namely calling CPD-queries.", "startOffset": 86, "endOffset": 89}, {"referenceID": 11, "context": "For instance, we can predict the class of web pages based on observations of their textual content and hyperlinks [12].", "startOffset": 114, "endOffset": 118}, {"referenceID": 7, "context": "3], [8].", "startOffset": 4, "endOffset": 7}, {"referenceID": 9, "context": "There is a lot of work on specialization, or more generally transformation, of logic programs that has the same end-goal as our work, namely to derive from a given program an \u2018equivalent\u2019 but more efficient program [10].", "startOffset": 215, "endOffset": 219}, {"referenceID": 5, "context": "In particular, this setting makes our work different from the work on partial deduction for logic programs [6,7].", "startOffset": 107, "endOffset": 112}, {"referenceID": 6, "context": "In particular, this setting makes our work different from the work on partial deduction for logic programs [6,7].", "startOffset": 107, "endOffset": 112}, {"referenceID": 6, "context": "[7]) are, as far as we see, not optimal for our setting.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "1 Leuschel and Bruynooghe [6] have similar observations about code explosion.", "startOffset": 26, "endOffset": 29}, {"referenceID": 13, "context": "[14] and Struyf [15, Ch.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "As a case study we consider the Gibbs sampling algorithm [1,13].", "startOffset": 57, "endOffset": 63}, {"referenceID": 12, "context": "As a case study we consider the Gibbs sampling algorithm [1,13].", "startOffset": 57, "endOffset": 63}, {"referenceID": 3, "context": "For pseudocode of this algorithm, see [4].", "startOffset": 38, "endOffset": 41}, {"referenceID": 2, "context": "These datasets are common benchmarks in the area of probabilistic logical models [3].", "startOffset": 81, "endOffset": 84}, {"referenceID": 4, "context": "In previous work we have applied machine learning algorithms to these datasets [5].", "startOffset": 79, "endOffset": 82}, {"referenceID": 4, "context": "[5] for more information).", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "We consider the task of performing probabilistic inference with probabilistic logical models. Many algorithms for approximate inference with such models are based on sampling. From a logic programming perspective, sampling boils down to repeatedly calling the same queries on a knowledge base composed of a static and a dynamic part. The larger the static part, the more redundancy there is in the repeated calls. This is problematic since inefficient sampling yields poor approximations. We show how to apply logic program specialization to make samplingbased inference more efficient. We develop an algorithm that specializes the query-predicates with respect to the static part of the knowledge base. In experiments on real-world data we obtain speedups of up to an order of magnitude, and these speedups grow with the data-size.", "creator": "LaTeX with hyperref package"}}}