{"id": "1201.0490", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jan-2012", "title": "Scikit-learn: Machine Learning in Python", "abstract": "Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from", "histories": [["v1", "Mon, 2 Jan 2012 16:42:40 GMT  (12kb)", "http://arxiv.org/abs/1201.0490v1", "Journal of Machine Learning Research (2011)"], ["v2", "Sun, 3 Mar 2013 10:24:49 GMT  (12kb)", "http://arxiv.org/abs/1201.0490v2", null], ["v3", "Tue, 10 Jan 2017 14:37:34 GMT  (12kb)", "http://arxiv.org/abs/1201.0490v3", null]], "COMMENTS": "Journal of Machine Learning Research (2011)", "reviews": [], "SUBJECTS": "cs.LG cs.MS", "authors": ["fabian pedregosa", "ga\\\"el varoquaux", "alexandre gramfort", "vincent michel", "bertrand thirion", "olivier grisel", "mathieu blondel", "gilles louppe", "peter prettenhofer", "ron weiss", "vincent dubourg", "jake vanderplas", "alexandre passos", "david cournapeau", "matthieu brucher", "matthieu perrot", "\\'edouard duchesnay"], "accepted": false, "id": "1201.0490"}, "pdf": {"name": "1201.0490.pdf", "metadata": {"source": "CRF", "title": "Scikit-learn: Machine Learning in Python", "authors": ["Fabian Pedregosa", "Alexandre Gramfort", "Olivier Grisel", "Vincent Dubourg", "Alexandre Passos", "Matthieu Brucher", "Matthieu Perrot", "Mikio Braun"], "emails": ["fabian.pedregosa@inria.fr", "gael.varoquaux@normalesup.org", "alexandre.gramfort@inria.fr", "vincent.michel@logilab.fr", "bertrand.thirion@inria.fr", "olivier.grisel@ensta.fr", "mblondel@ai.cs.kobe-u.ac.jp", "peter.prettenhofer@gmail.com", "ronweiss@gmail.com", "vincent.dubourg@gmail.com", "vanderplas@astro.washington.edu", "alexandre.tp@gmail.com", "cournape@gmail.com", "matthieu.brucher@gmail.com", "matthieu.perrot@cea.fr", "edouard.duchesnay@cea.fr"], "sections": [{"heading": null, "text": "Keywords: Python, supervised learning, unsupervised learning, model selection"}, {"heading": "1. Introduction", "text": "The Python programming language is establishing itself as one of the most popular languages for scientific computing. Thanks to its high-level interactive character and its maturing ecosystem of scientific libraries, it is an attractive choice for algorithmic development and exploratory data analysis (Dubois, 2007; Milmann and Avaizis, 2011). However, as a general purpose language, it is increasingly used not only in the academic environment, but also in industry. Scikit-learn uses this rich environment to provide state-of-the-art implementations of many well-known machine learning algorithms, while maintaining an easy-to-use interface that is tightly integrated with the Python language. This responds to the growing need for statistical data analysis by non-specialists in the software and web industries as well as in areas outside of computer science, such as biology or physics. Scikit-learn differs from other Python machine learning tools for several reasons: i) it is distributed under the BSD license, Linux platforms are integrated with the Python system."}, {"heading": "2. Project Vision", "text": "Code Quality. Instead of providing as many features as possible, the goal of the project was to provide solid implementations. Code quality is ensured by unit testing - from release 0.8 onwards, test coverage is 81% - and the use of static analysis tools such as pyflakes and pep8. Finally, we strive to use consistent naming for the functions and parameters used during strict adherence to Python coding guidelines and numeric documentation. BSD licensing. Most of the Python ecosystem is licensed with non-copyleft licenses. Although such a policy is beneficial for the adoption of these tools by commercial projects, it imposes some limitations: We are unable to use an existing scientific code such as the GSL.Bare bare design and the API. To lower the entry barrier, we avoid framework codes and the number of different objects to a minimum by limiting us to containers for arrays."}, {"heading": "3. Underlying Technologies", "text": "Numpy: the basic data structure used for data and model parameters. Input data is represented as numpy arrays, integrating seamlessly with other Python scientific libraries. Numpy's vision-based storage model limits copies even when they are associated with compiled code (Van der Walt et al., 2011). It also provides basic computing. Scipy: efficient algorithms for linear algebra, sparse matrix representation, special functions, and basic statistical functions. Scipy includes bindings for many standard formatic packages such as LAPACK. This is important for easy installation and portability, as providing libraries around Fortran code on different platforms can prove difficult. Cython: a language for combining C in Python. Cython makes it easy to achieve the performance of compiled languages with python syntax and high-grade operations."}, {"heading": "4. Code Design", "text": "To facilitate the use of external objects with scikit learning, inheritance is not enforced; instead, code conventions provide a consistent interface; the central object is an estimator that implements a suitable method by taking as arguments an input data field and optionally an array of labels for monitored problems; supervised estimators, such as SVM classifiers, can implement a prediction method; another important object is the cross-validation iterator, which provides traction and test indices that return modified input data; and estimators can provide a score method that provides an increasing assessment of fit accuracy: a log probability or a negated loss function; and the other important object is the cross-validation iterator, which provides pairs of traction and test indices to separate input data, such as K-fold, one or layered cross-validation."}, {"heading": "5. High-level yet Efficient: Some Trade Offs", "text": "While scikit-learn focuses on ease of use and is largely written in a high-level language, care has been taken to maximize computing power. In Table 1, we compare the computing time for a few algorithms implemented in the main machine learning toolkits available in Python. We use the Madelon dataset (Guyon et al., 2004), 4400 instances and 500 attributes, the dataset is quite large but small enough for most algorithms to run. While all packages call libsvm in the background, the performance of scikit-learn can be explained by two factors. Firstly, our bindings avoid memory copies and have up to 40% less overhead than the original libsvm Python bindings. Secondly, we patch libsvm to improve the efficiency of dense data, we use a smaller memory footprint and better applications of PCs and pipelining capabilities of modern processors."}, {"heading": "6. Conclusion", "text": "Scikit-learn provides a wide variety of both supervised and unsupervised machine learning algorithms using a unified task-oriented user interface, enabling easy comparison of methods for a particular application. As it is based on the Python scientific ecosystem, it can be easily integrated into applications outside the traditional field of statistical data analysis. Importantly, the algorithms implemented in a high-level language can be used as building blocks for approaches that are specifically tailored to a specific use case, such as medical imaging (Michel et al., 2011)."}], "references": [{"title": "PyMVPA: A Python toolbox for multivariate pattern analysis of fMRI", "author": ["M. Hanke", "Y.O. Halchenko", "P.B. Sederberg", "S.J. Hanson", "J.V. Haxby", "S. Pollmann"], "venue": "data. Neuroinformatics,", "citeRegEx": "Hanke et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hanke et al\\.", "year": 2009}, {"title": "Least Angle Regression, Lasso and Forward Stagewise", "author": ["T. Hastie", "B. Efron"], "venue": "http://cran.r-project.org/web/packages/lars/lars.pdf,", "citeRegEx": "Hastie and Efron.,? \\Q2004\\E", "shortCiteRegEx": "Hastie and Efron.", "year": 2004}, {"title": "A supervised clustering approach for fMRI-based inference of brain states", "author": ["V. Michel", "A. Gramfort", "G. Varoquaux", "E. Eger", "C. Keribin", "B. Thirion"], "venue": "Patt Rec, page epub ahead of print,", "citeRegEx": "Michel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Michel et al\\.", "year": 2011}, {"title": "Scientific Python, volume 11 of Computing in Science & Engineering", "author": ["K.J. Milmann", "M. Avaizis", "editors"], "venue": "IEEE/AIP,", "citeRegEx": "Milmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Milmann et al\\.", "year": 2011}, {"title": "Five balltree construction algorithms", "author": ["S.M. Omohundro"], "venue": "ICSI Technical Report TR-89-063,", "citeRegEx": "Omohundro.,? \\Q1989\\E", "shortCiteRegEx": "Omohundro.", "year": 1989}, {"title": "A randomized algorithm for principal component analysis", "author": ["V. Rokhlin", "A. Szlam", "M. Tygert"], "venue": "SIAM Journal on Matrix Analysis and Applications,", "citeRegEx": "Rokhlin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Rokhlin et al\\.", "year": 2009}, {"title": "The SHOGUN Machine Learning Toolbox", "author": ["S. Sonnenburg", "G. R\u00e4tsch", "S. Henschel", "C. Widmer", "J. Behr", "A. Zien", "F. de Bona", "A. Binder", "C. Gehl", "V. Franc"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Sonnenburg et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sonnenburg et al\\.", "year": 2010}, {"title": "The NumPy array: a structure for efficient numerical computation", "author": ["S. Van der Walt", "S.C Colbert", "G. Varoquaux"], "venue": "Computing in Science and Engineering,", "citeRegEx": "Walt et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Walt et al\\.", "year": 2011}, {"title": "Modular toolkit for Data Processing (MDP): a Python data processing framework", "author": ["T. Zito", "N. Wilbert", "L. Wiskott", "P. Berkes"], "venue": "Frontiers in neuroinformatics,", "citeRegEx": "Zito et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zito et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 8, "context": "Scikit-learn differs from other machine learning toolboxes in Python for various reasons: i) it is distributed under the BSD license ii) it incorporates compiled code for efficiency, unlike MDP (Zito et al., 2008) and pybrain (Schaul et al.", "startOffset": 194, "endOffset": 213}, {"referenceID": 0, "context": ", 2010), iii) it depends only on numpy and scipy to facilitate easy distribution, unlike pymvpa (Hanke et al., 2009) that has optional dependencies such as R and shogun, and iv) it focuses on imperative programming, unlike pybrain which uses a data-flow framework.", "startOffset": 96, "endOffset": 116}, {"referenceID": 0, "context": ", 2010), pymvpa (Hanke et al., 2009), MDP (Zito et al.", "startOffset": 16, "endOffset": 36}, {"referenceID": 8, "context": ", 2009), MDP (Zito et al., 2008) and Shogun (Sonnenburg et al.", "startOffset": 13, "endOffset": 32}, {"referenceID": 6, "context": ", 2008) and Shogun (Sonnenburg et al., 2010).", "startOffset": 19, "endOffset": 44}, {"referenceID": 1, "context": "Iteratively refining the residuals instead of recomputing them gives performance gains of 2\u201310 times over the reference R implementation (Hastie and Efron, 2004).", "startOffset": 137, "endOffset": 161}, {"referenceID": 4, "context": "The k-nearest neighbors classifier implementation constructs a ball tree (Omohundro, 1989) of the samples, but uses a more efficient brute force search in large dimensions.", "startOffset": 73, "endOffset": 90}, {"referenceID": 5, "context": "For medium to large data sets, scikit-learn provides an implementation of a truncated PCA based on random projections (Rokhlin et al., 2009).", "startOffset": 118, "endOffset": 140}, {"referenceID": 2, "context": "Importantly, the algorithms, implemented in a high-level language, can be used as building blocks for approaches specific to a use case, for example, in medical imaging (Michel et al., 2011).", "startOffset": 169, "endOffset": 190}], "year": 2017, "abstractText": "Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.", "creator": "LaTeX with hyperref package"}}}