{"id": "1201.2240", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2012", "title": "Bengali text summarization by sentence extraction", "abstract": "Text summarization is a process to produce an abstract or a summary by selecting significant portion of the information from one or more texts. In an automatic text summarization process, a text is given to the computer and the computer returns a shorter less redundant extract or abstract of the original text(s). Many techniques have been developed for summarizing English text(s). But, a very few attempts have been made for Bengali text summarization. This paper presents a method for Bengali text summarization which extracts important sentences from a Bengali document to produce a summary.", "histories": [["v1", "Wed, 11 Jan 2012 04:56:59 GMT  (236kb)", "http://arxiv.org/abs/1201.2240v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["kamal sarkar"], "accepted": false, "id": "1201.2240"}, "pdf": {"name": "1201.2240.pdf", "metadata": {"source": "CRF", "title": "BENGALI TEXT SUMMARIZATION BY SENTENCE EXTRACTION", "authors": ["Kamal Sarkar"], "emails": ["jukamal2001@yahoo.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, it is such that most of them will be able to move to another world, in which they are able to move to another world, in which they are able to move to another world, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they"}, {"heading": "2 A SURVEY ON SINGLE DOCUMENT TEXT SUMMARIZATION IN ENGLISH DOMAIN", "text": "In this section we present a brief overview of individual documents Text Summary for English. Although new research on text summaries was presented in the English domain in 1997, most work on text summaries today still relies on sentence extraction to form a summary. Many previous work on extractive summaries involves two main steps: (1) ranking sentences based on their scores, which are calculated by combining few or all features such as term frequency (TF), position information and keywords (Baxendale, 1958; Luhn, 1958; Lin and Hovy 1997), and (2) selecting some top sentences to form an extract. The first work on automatic text summary by Luhn (1958) compresses important sentences based on word frequency (number of times a word occurs in a document) and phrase frequency. Although subsequent research has developed sophisticated summary methods based on various new features, the work is presented by Edundson."}, {"heading": "3 PROPOSED SUMMARIZATION METHOD", "text": "The proposed method of summary is based on extraction. It comprises three main steps: (1) pre-processing (2) sentence ranking (3) generation of the summary."}, {"heading": "3.1 Preprocessing", "text": "The pre-processing step involves removing stopwords, inserting the input document into a collection of sentences. To remove stopwords, we have used the Bengali stopword list, which can be downloaded from the Information Rerevaluation Forum (FIRE) website (http: / / www.isical.ac.in / ~ fire / stopwords _ list _ ben.txt)."}, {"heading": "3.2 Stemming", "text": "The design of a stamper is language specific and requires some significant linguistic knowledge of the language. A typical simple stamping algorithm involves removing suffixes from a list of common suffixes, while a more complex suffix would use morphological knowledge to derive a stem from the words. Since Bengali is a highly inflexible language, stamping is necessary while calculating the frequency of a term. In our work we use a light stamper for Bengali that strips the suffixes from a predefined list of suffixes on a \"longest match,\" the algorithm being similar to that for Hindi (Ramanathan and Rao, 2003)."}, {"heading": "3.3 Sentence Ranking", "text": "After an input document is formatted and originated, the document is divided into a collection of sentences and the sentences are arranged according to two important characteristics: thematic term and position. Thematic term: The thematic terms are the terms related to the main topic of a document. We define the thematic terms are the terms whose TFIDF values exceed a predefined threshold. The TFIDF value of a term is calculated based on the product of TF and IDF, where TF (term frequency) is the number of times a word occurs in a document, and IDF is Inverse Document Frequency. The IDF value of a word is calculated based on a corpus, using the formula: IDF = log (N / df), where N = number of documents in the corpus and df (document frequency) indicates the number of documents in which a word occurs. The score of a sentence is calculated based on the similarity of the sentence."}, {"heading": "3.4 Summary Generation", "text": "A summary is created after the sentences have been evaluated on the basis of their scores and the K-top sentences have been selected when the value of K is set by the user. To increase the legibility of the summary, the sentences in the summary are reordered on the basis of their appearance in the original text, for example, the sentence that appears first in the original text appears first in the summary."}, {"heading": "4 EVALUATION, EXPERIMENTS AND RESULTS", "text": "To test our summary system, we collected 38 Bengali documents from the Bengali daily Ananda Bazar Patrika, which are typed in UTF-8 format and stored in the text files. For each document in our corpus, we consider only one reference summary for evaluation. The evaluation of a system-generated summary is done by comparing it to the reference summary."}, {"heading": "4.1 Evaluation", "text": "It is very difficult to determine whether a summary is good or bad."}, {"heading": "4.2 Experiments and Results", "text": "This year is the highest in the history of the country."}, {"heading": "5 Conclusion", "text": "This paper describes a single text summary for Bengali. Many techniques have been developed for the summary of English texts (s), but very few attempts have been made for the Bengali text summary. The performance of the proposed system can be further improved by examining more features and the use of learning algorithms for effective combination. Traditionally, more than one reference summary is used to evaluate each system, but in our work we have used only one reference summary for summary evaluation. In the future, we will consider more than one reference summary for summary evaluation. REFERENCESDas, A. & Bandyopadhyay, p. 2010. Topic Based Bengali Opinion Summarization. COLING (Posters) 2010: 232-240."}], "references": [{"title": "Topic-Based Bengali Opinion Summarization", "author": ["A. Das", "S. Bandyopadhyay"], "venue": "COLING (Posters)", "citeRegEx": "Das and Bandyopadhyay,? \\Q2010\\E", "shortCiteRegEx": "Das and Bandyopadhyay", "year": 2010}, {"title": "A Lightweight Stemmer for Hindi", "author": ["A. Ramanathan", "D.D. Rao"], "venue": "In the Proceedings of EACL", "citeRegEx": "Ramanathan and Rao,? \\Q2003\\E", "shortCiteRegEx": "Ramanathan and Rao", "year": 2003}, {"title": "Hedge trimmer: A parse-and-trim approach to headline generation", "author": ["B.J. Dorr", "D. Zajic", "R. Schwartz"], "venue": "In Proceedings of the HLT/NAACL", "citeRegEx": "Dorr et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Dorr et al\\.", "year": 2003}, {"title": "The identification of important concepts in highly structured technical papers", "author": ["C.D. Paice", "P.A. Jones"], "venue": "In the proceedings of the 16th International Conference on Research and Development in Information Retrieval", "citeRegEx": "Paice and Jones,? \\Q1993\\E", "shortCiteRegEx": "Paice and Jones", "year": 1993}, {"title": "Identifying Topics by Position", "author": ["Lin", "C \u2013 Y", "E. Hovy"], "venue": "In proceedings of the 5th Applied Natural Language Processing Conference,", "citeRegEx": "Lin et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Lin et al\\.", "year": 1997}, {"title": "Centroid-based summarization of multiple documents", "author": ["D.R. Radev", "H. Jing", "M. Sty", "D. Tam"], "venue": "Journal of Information Processing and Management, Elsevier,", "citeRegEx": "Radev et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Radev et al\\.", "year": 2004}, {"title": "MEAD - A platform for multidocument multilingual text summarization", "author": ["D. Radev", "T. Allison", "S. Blair-Goldensohn", "J. Blitzer", "A. Celebi", "E. Drabek", "W. Lam", "D. Liu", "J. Otterbacher", "H. Qi", "H. Saggion", "S. Teufel", "M. Topper", "A. Winkel", "Z. Zhang"], "venue": "In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004),", "citeRegEx": "Radev et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Radev et al\\.", "year": 2004}, {"title": "BBN/UMD at DUC-2004: Topiary", "author": ["D. Zajic", "B.J. Dorr", "R. Schwartz"], "venue": "In Proceedings of the North American Chapter of the Association for Computational Linguistics Workshop on Document Understanding,", "citeRegEx": "Zajic et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Zajic et al\\.", "year": 2004}, {"title": "Automatic Headline Generation for Newspaper Stories", "author": ["D. Zajic", "B. Dorr", "R. Schwartz"], "venue": "In Workshop on Automatic Summarization,", "citeRegEx": "Zajic et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Zajic et al\\.", "year": 2002}, {"title": "WordNet: A Lexical Database for English, Communications of the Association for Computing Machinery (CACM), 38(11):39-41", "author": ["G. Miller"], "venue": null, "citeRegEx": "Miller,? \\Q1995\\E", "shortCiteRegEx": "Miller", "year": 1995}, {"title": "Automatic text structuring and summary", "author": ["G. Salton", "A. Singhal", "M. Mitra", "C. Buckley"], "venue": "Journal of Information Processing and Management", "citeRegEx": "Salton et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Salton et al\\.", "year": 1997}, {"title": "New methods in automatic extracting", "author": ["H.P. Edmundson"], "venue": "Journal of the Association for Computing Machinery, 16(2):264\u2013285.", "citeRegEx": "Edmundson,? 1969", "shortCiteRegEx": "Edmundson", "year": 1969}, {"title": "The automatic creation of literature abstracts", "author": ["H.P. Luhn"], "venue": "IBM Journal of Research Development, 2(2):159\u2013165.", "citeRegEx": "Luhn,? 1958", "shortCiteRegEx": "Luhn", "year": 1958}, {"title": "Automatic summarization\u201d, Volume 3 of Natural language processing, Amsterdam/Philadelphia", "author": ["I. Mani"], "venue": null, "citeRegEx": "Mani,? \\Q2001\\E", "shortCiteRegEx": "Mani", "year": 2001}, {"title": "Using hidden Markov modeling to decompose human-written summaries", "author": ["H. Jing."], "venue": "Computational Linguistics, 28(4), 527\u2013543.", "citeRegEx": "Jing.,? 2002", "shortCiteRegEx": "Jing.", "year": 2002}, {"title": "The decomposition of human-written summary sentences", "author": ["H. Jing", "K. McKeown"], "venue": "In the Proceedings of SIGIR\u201999: 22nd International Conference on Research and Development in Information Retrieval,", "citeRegEx": "Jing and McKeown,? \\Q1999\\E", "shortCiteRegEx": "Jing and McKeown", "year": 1999}, {"title": "A trainable document summarizer", "author": ["J. Kupiec", "J.O. Pedersen", "F. Chen"], "venue": "In proceedings of Research and Development in Information Retrieval,", "citeRegEx": "Kupiec et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Kupiec et al\\.", "year": 1995}, {"title": "Text summarization via hidden Markov models and pivoted QR matrix decomposition", "author": ["J.M. Conroy", "D.P. O'Leary"], "venue": null, "citeRegEx": "Conroy and O.Leary,? \\Q2001\\E", "shortCiteRegEx": "Conroy and O.Leary", "year": 2001}, {"title": "Lexical cohesion computed by thesaural relations as an indicator of the structure of text, Computational Linguistics, 17(1):21-43", "author": ["J. Morris", "G. Hirst"], "venue": null, "citeRegEx": "Morris and Hirst,? \\Q1991\\E", "shortCiteRegEx": "Morris and Hirst", "year": 1991}, {"title": "Headline generation based on statistical Translation", "author": ["M. Banko", "V. Mittal", "Witbrock M"], "venue": "In Proceedings of the 38th Annual Meeting of the Association for Comptational Linguistics (ACL-2000),", "citeRegEx": "Banko et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Banko et al\\.", "year": 2000}, {"title": "Using maximum entropy for sentence extraction", "author": ["M. Osborne"], "venue": "Proceedings of the Acl-02, Workshop on Automatic Summarization, Volume 4 (Philadelphia, Pennsylvania), Annual Meeting of the ACL, Association for Computational Linguistics, Morristown. Baxendale, P. 1958. Man-made index for technical literature \u2014 An experiment. IBM", "citeRegEx": "Osborne,? 2002", "shortCiteRegEx": "Osborne", "year": 2002}, {"title": "Using Lexical Chains for Text Summarization", "author": ["R. Barzilay", "Elhadad. M"], "venue": "In Proceedings of the Workshop on Intelligent Scalable Text Summarization", "citeRegEx": "Barzilay and M.,? \\Q1997\\E", "shortCiteRegEx": "Barzilay and M.", "year": 1997}], "referenceMentions": [{"referenceID": 13, "context": "We can also categorize the text summarization based on the type of users the summary is intended for: User focused (query focused) summaries are tailored to the requirements of a particular user or group of users and generic summaries are aimed at a broad readership community (Mani, 2001).", "startOffset": 277, "endOffset": 289}, {"referenceID": 0, "context": "(Das and Bandyopadhyay, 2010) because we mainly focus on generic text summarization for Bengali.", "startOffset": 0, "endOffset": 29}, {"referenceID": 11, "context": "Many previous works on extractive summarization use two major steps: (1) ranking the sentences based on their scores which are computed by combining few or all of the features such as term frequency (TF), positional information and cue phrases (Baxendale, 1958; Edmundson, 1969; Luhn, 1958; Lin and Hovy 1997) and (2) selecting few top ranked sentences to form an extract.", "startOffset": 244, "endOffset": 309}, {"referenceID": 12, "context": "Many previous works on extractive summarization use two major steps: (1) ranking the sentences based on their scores which are computed by combining few or all of the features such as term frequency (TF), positional information and cue phrases (Baxendale, 1958; Edmundson, 1969; Luhn, 1958; Lin and Hovy 1997) and (2) selecting few top ranked sentences to form an extract.", "startOffset": 244, "endOffset": 309}, {"referenceID": 11, "context": "Many previous works on extractive summarization use two major steps: (1) ranking the sentences based on their scores which are computed by combining few or all of the features such as term frequency (TF), positional information and cue phrases (Baxendale, 1958; Edmundson, 1969; Luhn, 1958; Lin and Hovy 1997) and (2) selecting few top ranked sentences to form an extract. The very first work on automatic text summarization by Luhn (1958) computes salient sentences based on word frequency (number of times a word occurs in a document) and phrase frequency.", "startOffset": 262, "endOffset": 440}, {"referenceID": 11, "context": "Many previous works on extractive summarization use two major steps: (1) ranking the sentences based on their scores which are computed by combining few or all of the features such as term frequency (TF), positional information and cue phrases (Baxendale, 1958; Edmundson, 1969; Luhn, 1958; Lin and Hovy 1997) and (2) selecting few top ranked sentences to form an extract. The very first work on automatic text summarization by Luhn (1958) computes salient sentences based on word frequency (number of times a word occurs in a document) and phrase frequency. Although subsequent research has developed sophisticated summarization methods based on various new features, the work presented by Edmundson (1969) is still followed today as the foundation for extraction based summarization.", "startOffset": 262, "endOffset": 708}, {"referenceID": 18, "context": "The concept of lexical chain was introduced in (Morris and Hirst, 1991).", "startOffset": 47, "endOffset": 71}, {"referenceID": 9, "context": "Barzilay and Elhadad (1997) used a WordNet (Miller, 1995) to construct the lexical chains.", "startOffset": 43, "endOffset": 57}, {"referenceID": 17, "context": "The concept of lexical chain was introduced in (Morris and Hirst, 1991). They characterized lexical chain as a sequence of related words that spans a topical unit of text. In other words, lexical chain is basically lexical cohesion that occurs between two terms and among sequences of related words. Barzilay and Elhadad (1997) used a WordNet (Miller, 1995) to construct the lexical chains.", "startOffset": 48, "endOffset": 328}, {"referenceID": 17, "context": "The work in (Conroy and O\u2019Leary, 2001) considered the fact that the probability of inclusion of a sentence in an extract depends on whether the previous sentence had been included as well and applied hidden Markov models (HMMs) in sentence extraction task.", "startOffset": 12, "endOffset": 38}, {"referenceID": 7, "context": "TOPIARY (Zajic et al., 2004), a headline generation system, combines the compressed version of the lead sentence and a set of topic descriptors generated from the corpus to form a headline.", "startOffset": 8, "endOffset": 28}, {"referenceID": 2, "context": "The sentence is compressed using the approach similar to the approach in (Dorr et al. 2003) and the topic descriptors.", "startOffset": 73, "endOffset": 91}, {"referenceID": 1, "context": "In our work, we use a lightweight stemmer for Bengali that strips the suffixes using a predefined suffix list, on a \u201clongest match\u201d basis, using the algorithm similar to that for Hindi (Ramanathan and Rao, 2003).", "startOffset": 185, "endOffset": 211}], "year": 2011, "abstractText": "Text summarization is a process to produce an abstract or a summary by selecting significant portion of the information from one or more texts. In an automatic text summarization process, a text is given to the computer and the computer returns a shorter less redundant extract or abstract of the original text(s). Many techniques have been developed for summarizing English text(s). But, a very few attempts have been made for Bengali text summarization. This paper presents a method for Bengali text summarization which extracts important sentences from a Bengali document to produce a summary. Keyword: Bengali Text Summarization, Sentence Extraction, Indian Languages", "creator": "PScript5.dll Version 5.2"}}}