{"id": "1201.4906", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jan-2012", "title": "Adaptive Shortest-Path Routing under Unknown and Stochastically Varying Link States", "abstract": "We consider the adaptive shortest-path routing problem in wireless networks under unknown and stochastically varying link states. In this problem, we aim to optimize the quality of communication between a source and a destination through adaptive path selection. Due to the randomness and uncertainties in the network dynamics, the quality of each link varies over time according to a stochastic process with unknown distributions. After a path is selected for communication, the aggregated quality of all links on this path (e.g., total path delay) is observed. The quality of each individual link is not observable. We formulate this problem as a multi-armed bandit with dependent arms. We show that by exploiting arm dependencies, a regret polynomial with network size can be achieved while maintaining the optimal logarithmic order with time. This is in sharp contrast with the exponential regret order with network size offered by a direct application of the classic MAB policies that ignore arm dependencies. Furthermore, our results are obtained under a general model of link-quality distributions (including heavy-tailed distributions) and find applications in cognitive radio and ad hoc networks with unknown and dynamic communication environments.", "histories": [["v1", "Tue, 24 Jan 2012 02:45:58 GMT  (63kb)", "http://arxiv.org/abs/1201.4906v1", "10 pages, 1 figure"]], "COMMENTS": "10 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.NI cs.LG", "authors": ["keqin liu", "qing zhao"], "accepted": false, "id": "1201.4906"}, "pdf": {"name": "1201.4906.pdf", "metadata": {"source": "CRF", "title": "Adaptive Shortest-Path Routing under Unknown and Stochastically Varying Link States", "authors": ["Keqin Liu", "Qing Zhao"], "emails": ["kqliu@ucdavis.edu", "qzhao@ucdavis.edu"], "sections": [{"heading": null, "text": "ar Xiv: 120 1.49 06v1 [cs.NI] 24 Jan 20We are looking at the adaptive short-distance routing problem in wireless networks under unknown and stochastically different connection states. In this problem, we aim to optimize the quality of communication between a source and a target by adaptive path selection. Due to the randomness and uncertainties in network dynamics, the quality of each link varies over time according to a stochastic process with unknown distributions. After a path for communication is selected, the aggregate quality of all links on this path (e.g. total path lag) is observed. The quality of each link is not observable. We are formulating this problem as a multi-species bandit with dependent weapons. We show that by exploiting dependencies with weapons, a polynomic regret with network size can be achieved, while the optimal logarithmic order is maintained over time."}, {"heading": "A. Stochastic Online Learning based on Multi-Armed Bandit", "text": "The above problem can be modeled as a generalized Multi-Armed Bandit (MAB) with a growing number of regrets. In the classic MAB [1] - [6] there are N-independent arms and a player must decide which arm to play at any time. An arm, when played, provides a random cost drawn from an unknown distribution. The performance of a sequential arm selection is measured by regret, defined as the difference in the expected total cost in terms of the optimal policy in the known cost model in which the player always plays the best arm. The optimal regret has been measured over time in logarithmic, since the cost observations of one arm do not provide the information about the cost of other weapons, the optimal regret grows linearly with the number of weapons. We can treat the adaptive routing problem as MAB by treating each path as an arm."}, {"heading": "B. Applications", "text": "One application example is adaptive routing in cognitive radio networks where secondary users communicate using channels temporarily unoccupied by primary users. In this case, the availability of each link varies dynamically depending on the communication activities of the primary users in the vicinity. The delay of each link can therefore be modelled as a stochastic process unknown to secondary users. The goal is to trace the path with the lowest latency (i.e. the lowest primary traffic) through stochastic online learning. Other applications include ad-hoc networks where connection states vary stochastically due to channel fading or random altercations with other users."}, {"heading": "C. Related Work", "text": "The classic MAB was addressed by Lai and Robbins in 1985, where they demonstrated that the minimum regret has a logarithmic sequence over time and specific strategies were proposed to asymptotically achieve the optimal regret for multiple cost distributions in the light-driven family [2]. Since Lai and Robbins \"seminar paper, simpler regret strategies for different classes of light-driven cost distributions have been proposed to achieve the logarithmic regret sequence over time [3] - [5]. In [6] we proposed the DSEE approach, which proposes the logarithmic regret sequence over time for all light-driven cost distributions and sublinear regret over time for poorly controlled cost distributions [3]. All regrets established in [2] - [6] grow linearly with the number of weapons. This work builds on the general DSEE structure that we suggest in SE6 that incorporation into the use of SEE may be significant."}, {"heading": "II. PROBLEM STATEMENT", "text": "In this section we will deal with the adaptive routing problem under unknown and stochastically varying connection states. Consider a network with a source s and a destination r. Let G = (V, E) denote the steered graph, which consists of all simple paths from s to r. Let m and n each denote the number of edges and vertices in the diagram G.At each point in time, each edge in E is assigned a random weight / cost We (t), which consists of an unknown distribution. We assume that {We (t)} over time for each edge e. At the beginning of each time window t, a path pn-P (i-P (i-P, 2,...) is selected from s to r, where P is the set of all paths from s to r in G. Subsequently, the total end-to-end cost Ct (pn) of the path pn, given by the sum of the weights of all edges on the path, is shown in G."}, {"heading": "III. ADAPTIVE SHORTEST PATH ROUTING ALGORITHM", "text": "In this section we present the proposed Short Path Adaptive Routing Algorithm. We look at cost allocations that affect both sides."}, {"heading": "A. Light-Tailed Cost Distributions", "text": "We look at the cost distributions according to the true mean for the variables randomly."}, {"heading": "B. Heavy-Tailed Cost Distributions", "text": "Now we look at the heavily loaded cost distributions where the moment of cost exists to the q-th (q > 1) order. Of [6], we have the following limit with respect to the deviation of the sample mean from the true mean for the heavily loaded cost distributions. Let's leave {X (t)} \u221e t = 1 i.i.d. random variables drawn from a distribution with the q-th moment (q > 1). (6) Let's leave Xt = (\u03a3 t = 1X (k)) / t and \u03b8 = E [X (1)]. We have for all cases (A (t \u2212 1) | < vt1 \u2212 d) = o (t1 \u2212 q). (6) Theorem 3: Construct an exploration sequence as follows. Choose a constant v > 0. For each t > 1, if | A (t \u2212 1) the exploitation (< vt1 \u2212 d \u2212 d)."}, {"heading": "IV. GENERALIZATION TO STOCHASTIC ONLINE LINEAR OPTIMIZATION PROBLEMS", "text": "In this section, we look at the general stochastic linear optimization problems (SOLO), which include adaptive routing as a special case. In a SOLO problem, there is a compact set of U-Rd with dimension d, which is called an action set. At each point, we select a point x-U and observe a cost framework in which ~ Ct-x is drawn from an unknown distribution.2 We assume that {~ Ct-t-1 is about t. The goal is to design a sequential selection policy to minimize regret R\u03c0 (T), defined as the total difference in expected costs over T slots compared to the optimal action x-p = argmin {E [~ Ct-x]}: to design a sequential selection strategy."}, {"heading": "V. CONCLUSION", "text": "In this paper, we looked at the adaptive routing problem in networks with unknown and stochastically varying link states, where only the total cost of a path can be observed after path selection.2The following result applies in a more general scenario where only the expected cost of x.10 for routing is linear. For both light and heavy link state distributions, we proposed efficient online learning algorithms to minimize regret in terms of both time and network size, and the result was further extended to the general stochastic optimization problems in the online liner."}], "references": [{"title": "Some Aspects of the Sequential Design of Experiments", "author": ["H. Robbins"], "venue": "Bull. Amer. Math. Soc., vol. 58, no. 5, pp. 527-535, 1952.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1952}, {"title": "Asymptotically Efficient Adaptive Allocation Rules", "author": ["T. Lai", "H. Robbins"], "venue": "Advances in Applied Mathematics, vol. 6, no. 1, pp. 4-22, 1985.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1985}, {"title": "Adaptive Treatment Allocation and The Multi-Armed Bandit Problem", "author": ["T. Lai"], "venue": "Ann. Statist., vol 15, pp. 1091-1114, 1987.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1987}, {"title": "Sample Mean Based Index Policies with O(logn) Regret for the Multi-armed Bandit Problem", "author": ["R. Agrawal"], "venue": "Advances in Applied Probability, vol. 27, pp. 1054-1078, 1995.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1995}, {"title": "Finite-time Analysis of the Multiarmed Bandit Problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning, vol. 47, pp. 235-256, 2002.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Multi-Armed Bandit Problems with Heavy Tail Reward Distributions", "author": ["K. Liu", "Q. Zhao"], "venue": "Proc. of Allerton Conference on Communications, Control, and Computing, September, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Efficient Algorithms for Online Decision Problems", "author": ["A. Kalai", "S. Vempala"], "venue": "J. Computer and System Sciences, vol. 71, 291-307, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Path Kernels and Multiplicative Updates", "author": ["E. Takimoto", "M. Warmuth"], "venue": "Journal of Machine Learning Research, vol. 4, pp. 773-818, 2003.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Combinatorial Network Optimization with Unknown Variables: Multi-Armed Bandits with Linear Rewards", "author": ["Y. Gai", "B. Krishnamachari", "R. Jain"], "venue": "USC Technical Report, CENG-2010-9.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Online Linear Optimization and Adaptive Routing", "author": ["B. Awerbuch", "R. Kleinberg"], "venue": "Journal of Computer and System Sciences, pp. 97-114, 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Stochastic Linear Optimization under Bandit Feedback", "author": ["V. Dani", "T. Hayes", "S. Kakade"], "venue": "Proc. of the 21st Annual Conference on Learning Theory, 2008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Locally Sub-Gaussian Random Variable and the Strong Law of Large Numbers", "author": ["P. Chareka", "O. Chareka", "S. Kennendy"], "venue": "Atlantic Electronic Journal of Mathematics, vol. 1, no. 1, pp. 75-81, 2006.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "In the classic MAB [1]\u2013[6], there are N independent arms and a player needs to decide which arm to play at each time.", "startOffset": 19, "endOffset": 22}, {"referenceID": 5, "context": "In the classic MAB [1]\u2013[6], there are N independent arms and a player needs to decide which arm to play at each time.", "startOffset": 23, "endOffset": 26}, {"referenceID": 1, "context": "The optimal regret was shown to be logarithmic with time in [2].", "startOffset": 60, "endOffset": 63}, {"referenceID": 1, "context": "The classic MAB was addressed by Lai and Robbins in 1985, where they showed that the minimum regret has a logarithmic order with time and proposed specific policies to asymptotically achieve the optimal regret for several cost distributions in the light-tailed family [2].", "startOffset": 268, "endOffset": 271}, {"referenceID": 2, "context": "Since Lai and Robbins\u2019s seminar work, simpler index policies were proposed for different classes of light-tailed cost distributions to achieve the logarithmic regret order with time [3]\u2013[5].", "startOffset": 182, "endOffset": 185}, {"referenceID": 4, "context": "Since Lai and Robbins\u2019s seminar work, simpler index policies were proposed for different classes of light-tailed cost distributions to achieve the logarithmic regret order with time [3]\u2013[5].", "startOffset": 186, "endOffset": 189}, {"referenceID": 5, "context": "In [6], we proposed the DSEE approach that achieves the logarithmic regret order with time for all light-tailed cost distributions and sublinear regrets with time for heavy-tailed cost distributions.", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "All regrets established in [2]\u2013[6] grow linearly with the number of arms.", "startOffset": 27, "endOffset": 30}, {"referenceID": 5, "context": "All regrets established in [2]\u2013[6] grow linearly with the number of arms.", "startOffset": 31, "endOffset": 34}, {"referenceID": 5, "context": "This work builds upon the general DSEE structure proposed in [6].", "startOffset": 61, "endOffset": 64}, {"referenceID": 6, "context": "This work generalizes the previous work [7]\u2013[9] that assumes fully observable link costs on a chosen path.", "startOffset": 40, "endOffset": 43}, {"referenceID": 8, "context": "This work generalizes the previous work [7]\u2013[9] that assumes fully observable link costs on a chosen path.", "startOffset": 44, "endOffset": 47}, {"referenceID": 8, "context": "In particular, the adaptive routing problem under this more informative observation model was considered in [9] and an algorithm was proposed to achieve O(m4 log T ) regret, where m is the number of links in the network.", "startOffset": 108, "endOffset": 111}, {"referenceID": 9, "context": "The problems considered in this paper were also studied under an adversarial bandit model in which the cost functions are chosen by an adversary and are treated as arbitrary bounded deterministic quantities [10].", "startOffset": 207, "endOffset": 211}, {"referenceID": 9, "context": "The problem formulation and results established in this paper can be considered as a stochastic version of those in [10].", "startOffset": 116, "endOffset": 120}, {"referenceID": 10, "context": "For the special class of stochastic online linear optimization problems where there exists a nonzero gap in expected cost between the optimal action and the rest of the action space and the cost has a finite support, an algorithm was proposed in [11] to achieve an O(d2 log T ) regret given that a nontrivial", "startOffset": 246, "endOffset": 250}, {"referenceID": 10, "context": "For the general case with finite-support cost distributions, the regret was shown to be lower bounded by O(d \u221a T ) and an efficient algorithm was proposed to achieve an O((d ln T )3/2 \u221a T ) regret [11].", "startOffset": 197, "endOffset": 201}, {"referenceID": 10, "context": "Compared to the algorithm in [11], our algorithm for the general stochastic online linear optimization problems performs worse in T but better in d.", "startOffset": 29, "endOffset": 33}, {"referenceID": 11, "context": "For a zero-mean light-tailed random variable X, we have [12],", "startOffset": 56, "endOffset": 60}, {"referenceID": 5, "context": "From (1), we have the following extended Chernoff-Hoeffding bound on the deviation of the sample mean from the true mean for light-tailed random variables [6].", "startOffset": 155, "endOffset": 158}, {"referenceID": 5, "context": "The general structure of the algorithm follows the DSEE framework established in [6] for the classic MAB.", "startOffset": 81, "endOffset": 84}, {"referenceID": 9, "context": "In the exploration sequence, we sample the d basis vectors (barycentric spanner [10] as defined in the following) evenly to estimate the qualities of these vectors.", "startOffset": 80, "endOffset": 84}, {"referenceID": 9, "context": "Note that a compact subset of Rd always has a barycentric spanner, which can be constructed efficiently (see an algorithm in [10]).", "startOffset": 125, "endOffset": 129}, {"referenceID": 9, "context": "We can thus construct a barycentric spanner consisting of d paths in P by using the algorithm in [10].", "startOffset": 97, "endOffset": 101}, {"referenceID": 5, "context": "1 in [6], we have", "startOffset": 5, "endOffset": 8}, {"referenceID": 5, "context": "Similar to [6], we can show that without any knowledge of the cost models, increasing the cardinality of the exploration sequence of \u03c0 by an arbitrarily small amount leads to a regret linear with d and arbitrarily close to the logarithmic order with time.", "startOffset": 11, "endOffset": 14}, {"referenceID": 5, "context": "From [6], we have the following bound on the deviation of the sample mean from the true mean for heavy-tailed cost distributions.", "startOffset": 5, "endOffset": 8}], "year": 2012, "abstractText": "We consider the adaptive shortest-path routing problem in wireless networks under unknown and stochastically varying link states. In this problem, we aim to optimize the quality of communication between a source and a destination through adaptive path selection. Due to the randomness and uncertainties in the network dynamics, the quality of each link varies over time according to a stochastic process with unknown distributions. After a path is selected for communication, the aggregated quality of all links on this path (e.g., total path delay) is observed. The quality of each individual link is not observable. We formulate this problem as a multi-armed bandit with dependent arms. We show that by exploiting arm dependencies, a regret polynomial with network size can be achieved while maintaining the optimal logarithmic order with time. This is in sharp contrast with the exponential regret order with network size offered by a direct application of the classic MAB policies that ignore arm dependencies. Furthermore, our results are obtained under a general model of link-quality distributions (including heavy-tailed distributions) and find applications in cognitive radio and ad hoc networks with unknown and dynamic communication environments.", "creator": "LaTeX with hyperref package"}}}