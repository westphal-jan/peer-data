{"id": "1201.5217", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jan-2012", "title": "Unsupervised Classification Using Immune Algorithm", "abstract": "Unsupervised classification algorithm based on clonal selection principle named Unsupervised Clonal Selection Classification (UCSC) is proposed in this paper. The new proposed algorithm is data driven and self-adaptive, it adjusts its parameters to the data to make the classification operation as fast as possible. The performance of UCSC is evaluated by comparing it with the well known K-means algorithm using several artificial and real-life data sets. The experiments show that the proposed UCSC algorithm is more reliable and has high classification precision comparing to traditional classification methods such as K-means.", "histories": [["v1", "Wed, 25 Jan 2012 09:44:06 GMT  (165kb)", "http://arxiv.org/abs/1201.5217v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["m t al-muallim", "r el-kouatly"], "accepted": false, "id": "1201.5217"}, "pdf": {"name": "1201.5217.pdf", "metadata": {"source": "META", "title": "Unsupervised Classification Using Immune Algorithm", "authors": ["M.T. Al-Muallim"], "emails": [], "sections": [{"heading": null, "text": "The new proposed algorithm is data-driven and self-adjusting, adjusting its parameters to the data in order to make the classification process as fast as possible. UCSC's performance is evaluated by comparing it to the well-known K-mean algorithm, using several artificial and real datasets. Experiments show that the proposed UCSC algorithm is more reliable and has a high classification precision compared to traditional classification methods such as K-Means.General Terms Pattern Recognition, Algorithms.Keywords Artificial Immune Systems, Clonal Selection Algorithms, Clustering, K-Means Algorithm."}, {"heading": "1. INTRODUCTION", "text": "We believe that most of them will be able to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position, to put themselves in a position to survive."}, {"heading": "2. UNSUPERVISED CLONAL SELECTION CLASSIFICATION (UCSC)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Basic Principle", "text": "In UCSC, the cluster problem is considered an optimization problem, and the goal is to find the optimal data distributions where the resulting clusters tend to be as compact as possible. In contrast to K means, which use the square error criterion to measure the distribution within the cluster, UCSC uses the sum of Euclidean distances of the points from their respective cluster centers as a cluster center and uses the clonal selection algorithm as a cluster algorithm to ensure that the global optimum is found when most other algorithms such as K means are embedded in local optima. The number of clusters K should be known and the corresponding cluster centers m1, m2,... mk must be found so that the cluster metric J is minimized. Mathematically, the cluster metric J for the K clusters C = {C1, C2,... Cjij} is the following equation (Njij = 1):"}, {"heading": "2.2 Clonal Selection Algorithm", "text": "All clonal selection algorithms have the same basic steps, which are summarized as follows: Generating Population P of antibodies (candidate solutions) while not fulfilling the stop criterion do {clone P based on their affinity Subject the result population to a hypermutation scheme Select the highest affinity solution to maintain population diversity} Select the highest affinity antibody to form the immune memory that is the solution to the problem. There are certain critical questions that must be taken into account in the development and execution of a clonal selection algorithm, such as the representation of the solution, maintaining diversity in the population, affinity metric and hypermutation mechanism. Even a small change in one of these aspects can lead to a significant change in the performance of clonal selection algorithms [26]. The UCSC algorithm is summarized as following generation initialization of generic: P for highest candidate loci: P for population loci."}, {"heading": "2.3 Solution Representing", "text": "Each antibody in P forms a series of real numbers representing the K cluster centers.For d-dimensional space, the length of the string is the d * K number, with the coordinates of the centers located one after the other.],....., [21 nAbAbp (4)],.....,,,..., [2111211 Kddl mmmAb, l = 1,..., n (5) The first d numbers represent the d dimensions of the first cluster center, the next d positions those of the second cluster center, and so on."}, {"heading": "2.4 Affinity Metric", "text": "In order to measure the affinity of an antibody, the clusters are formed according to the centers encoded in the antibody under consideration, by assigning each point djx, j = 1,..., N to one of the clusters Ci whose center is closest to the point. After cluster centering, the new cluster centroids are calculated by determining the centers of the respective clusters, then the cluster criterion J is calculated by equation. (1) Affinity is defined as: J aff1 (6) The maximum value of affinity, which represents the minimum value of J. Zero, is assigned to affinity when a cluster becomes empty."}, {"heading": "2.5 Cloning", "text": "Antibodies in P are cloned proportionally to their affinities, the higher the affinity, the higher the number of clones produced for the antibody. Antibodies are sorted according to their affinity in descending order and then the amount of clones produced for the antibodies is given by: ln roundncl (7), where ncl is the number of clones and \u03b2 is the clonal factor."}, {"heading": "2.6 Hypermutation Mechanism", "text": "Each antibody in the PC is subjected to a mutation inversely proportional to the affinity, and this is done according to the following equations:) 1.0 (* NAbAb (8) affe (9) Where Ab * is the resulting antibody of the mutation Ab, N (0.1) is a matrix d * K Gaussian random variables with zero mean and standard deviation = 1, aff is the affinity of the antibody normalized in the range [0 1]. \u03b1 is a factor that changes the value of the Gaussian mutation and is inversely proportional to the affinity, is a factor that controls the range of \u03b1. To speed up the algorithm and the data generated by this factor are given as:) min (max datadata (10), where maxdata and mindata are the maximum and minimum values of the data characteristics in all dimensions. Thus, the probability of mutation depends on the affinity of the antibody and also on the extent of the search."}, {"heading": "2.7 New Antibodies Generator", "text": "In order to generate new random solutions, the scope of the search, which represents the data distribution area in the feature space, has been determined using the upper and lower data boundaries in each dimension:], [21 ddata ULULULUL (11),, [21 ddata LLLLLLLLLLL (12), where UL data or LL data are matrices of the upper and lower boundaries of the features, respectively, and then a new random solution is generated using: TTdatadatatatanew randLLULLLAb)))) (diag (((((13) Where rand is a matrix of d * K random variables with uniform probability distribution within the range [0 1]. This random solution generator is used to ensure fast and precise performance of UCSC and to accelerate the convergence rate of the algorithm, as all solutions are within the scope of the search."}, {"heading": "3. EXPERIMENTS", "text": "The UCSC was tested with several artificial and real data sets, which were then compared with the known K mean algorithm [1]. The UCSC was tested with the following parameters: n = 10, \u03b2 = 5, L = 4 and the number of generations gen = 30. For the K mean algorithm [1], 1000 was used as the maximum number of iterations if it does not end normally. In each experiment, the algorithms were executed 100 times with different random initial configurations to allow statistical evaluation of performance. The data sets are described below:"}, {"heading": "3.1 Artificial Data Sets", "text": "Dataset 1: An artificial dataset that overlaps two classes (each 100 patterns) of bivariate Gaussian density with the following parameters: m1 = (0.1, 0.1), m2 = (0.35, 0.1), 1,00011.21, \u03a3 being a covariance matrix. The dataset is shown in Figure (1). Figure 1: An artificial dataset 1 with two classes. Dataset 2: An artificial dataset consisting of nine classes (each 25 patterns) of bivariate Gaussian density with the following parameters: m1 = (0.1, 0.1), m2 = (0.1, 0.5), m3 = (0.1, 0.9), m4 = (0.5, 0.1), m5 = (0.5, 0.5), m6 = (0.5, 0.9), m7 = (0.9, 0.1), m8 = (0.9, 0.5), mouse. Classes (0.9, 02.5), 3.03 (2.03) (2.03) and (2.03) (2.03)."}, {"heading": "3.2 Real-life Data Sets", "text": "The following real dataset was tested: 1-iris dataset [27] consists of 150 four-dimensional patterns in three classes (50 patterns each) representing different categories of iris flowers with four characteristic values: cup length, cup width, petal length, and petal width in centimeters. The three classes are: Iris Setosa, Iris Versicolor, and Iris Virginica. 2-Wisconsin Breast Cancer dataset [28] consists of 699nine-dimensional patterns in two classes that are benign (458 patterns) and malignant (241 patterns). The nine characteristics are: clump thickness, uniformity of cell size, uniformity of cell shape, marginal adhesion, single epithelial cell size, bare nuclei, bland chromatin, normal nucleoli, and mitosis."}, {"heading": "4. RESULTS", "text": "The best classification results of UCSC and K-means after 100 times execution are presented in Table (1), which includes the obtained classification accuracy for all datasets. As we can see from Table (1), the UCSC algorithm provides better accuracy than the K-mean algorithm. Experiments show that the K-mean algorithm is stuck to suboptimal solutions even with simple data, but UCSC did not exhibit such behavior. Table (2) shows the best values of J and its percentages of the total runs of UCSC and K-mean algorithms for each dataset. As we can see from Table (2) for all datasets, UCSC finds better solutions than the K-mean algorithm, and the clusters formed by UCSC are more compact than those formed by the K-mean algorithm. The results show that the UCSC algorithm is more reliable than the K-mean algorithm, because it always finds the best solution, as opposed to the K, it always finds the best solution."}, {"heading": "5. DISCUSSION", "text": "The experiments show that the proposed UCSC algorithm is more reliable because it finds the best solution, unlike K-means that are stuck to suboptimal solutions. UCSC algorithm has a high classification precision compared to other evolutionary algorithms. The new proposed algorithm is data-driven and self-adaptive, adjusting its parameters to the data to make the classification process as fast as possible. UCSC algorithm has many advantages over other evolutionary algorithms. One is the small population size n = 10, where most other evolutionary algorithms require at least a population size of 100. Second, it found the solution in less than 30 generations. Based on the cluster criterion used in UCSC, it should provide correct results when the clusters are compact and hyperspherical."}, {"heading": "6. CONCLUSION", "text": "The new algorithm is data-driven and self-adjusting, adjusting its parameters to the data in order to make the classification process as fast as possible. UCSC is tested on several artificial and real data sets and its performance is compared with the well-known K-mean algorithm [1]. Experiments show that the UCSC algorithm has a higher classification precision than the K-mean algorithm, which is stuck with suboptimal solutions even for simple data sets. The new algorithm takes thirty generations to find the solution and uses a small population size n = 10. Most other evolutionary algorithms require good results when the clusters are present in compact form at the smallest population size of the UC100."}, {"heading": "7. REFERENCES", "text": "[1] R. Xu, et al. [6] D. Brown and C. Huntley, \"A Practical Application of Simulating Systems,\" John Wiley & Sons, Inc. [2] G. Babu and M. Murty, \"Clustering with Evolutionary Computation Strategies,\" Pattern Recognition, vol. 27, pp. 321-329, 1994. [3] L. Hall, et al. \"Clustering with a genetically optimized approach,\" IEEE Transactions on Evolutionary Computation, pp. 103-112, 1999. [4] U. Maulik and S. Bandyopadhyay, \"Genetic algorithm-based clustering technique,\" Pattern Recognition, \"vol. 33, pp. 1465, 2000. L. Y. and S. B. Yang,\" A genetic approach to the automatic clustering problem, \"Pattern Recognition vol., pp. 34, pp. 424, 2001."}], "references": [{"title": "Clustering with evolution strategies,", "author": ["G. Babu", "M. Murty"], "venue": "Pattern Recognition,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1994}, {"title": "Clustering with a genetically optimized approach,", "author": ["L. Hall"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Genetic algorithm-based clustering technique,", "author": ["U. Maulik", "S. Bandyopadhyay"], "venue": "Pattern Recognition,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "A genetic approach to the automatic clustering problem,", "author": ["L.Y. Tseng", "S.B. Yang"], "venue": "Pattern Recognition", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "A practical application of simulated annealing to clustering,", "author": ["D. Brown", "C. Huntley"], "venue": "Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1992}, {"title": "Experiments in projection and clustering by simulated annealing,", "author": ["R. Klein", "R. Dubes"], "venue": "Pattern Recognition", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1989}, {"title": "Alsultan, \"A simulated annealing algorithm for the clustering problems,", "author": ["K.S. Selim"], "venue": "Pattern Recognition", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1991}, {"title": "A Tabu search approach to the clustering problem,", "author": ["K. Al-Sultan"], "venue": "Pattern Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1995}, {"title": "Immunological Computation Theory and Applications", "author": ["D. Dasgupta", "L.F. Ni\u00f1o"], "venue": "Boca Raton: CRC Prees, Taylor & Francis Group", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "An evolutionary immune network for data clustering,", "author": ["L.N. de Castro", "F.J. Von Zuben"], "venue": "presented at the Proceeding of Sixth Brazilian Symposium on Neural Networks,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "The Clonal Selection Algorithm with Engineering Applications,\" presented at the Proceedings of GECCO", "author": ["L.N. de Castro", "F.J. Von Zuben"], "venue": "Workshop on Artificial Immune Systems and Their Applications, Las Vegas, USA,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Learning and Optimization Using the Clonal Selection Principle,", "author": ["L.N. de Castro", "F.J. Von Zuben"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "aiNet: An Artificial Immune Network for Data Analysis,\" presented at the in Data Mining: A Heuristic Approach", "author": ["L.N. de Castro", "F.J. Von Zuben"], "venue": "Idea Group Publishing,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2001}, {"title": "Artificial Immune Recognition System (AIRS): An Immune-Inspired Supervised Learning Algorithm,", "author": ["A. Watkins", "J. Timmis"], "venue": "Journal Genetic Programming and Evolvable Machines,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Novelty Detection in Time Series Data using Ideas from Immunology,\" presented at the", "author": ["D. Dasgupta", "S. Forrest"], "venue": "Proceedings of The 5th International Conference on Intelligent Systems, Reno, Nevada,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "An Immunological Approach to Change Detection: Algorithms, Analisys and Implications,\" presented at the", "author": ["P. D'haeseleer"], "venue": "IEEE Symposium on Security and Privacy,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1996}, {"title": "Self-Nonself Discrimination in a Computer,\" presented at the IEEE Computer", "author": ["S. Forrest"], "venue": "Society Symposium on Research in Security and Privacy,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1994}, {"title": "An artificial immune network for multimodal function optimization,\" presented at the", "author": ["L.N. de Castro", "J. Timmis"], "venue": "Proceedings of the 2002 Congress on Evolutionary Computation,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Design of mixed control systems using algorithms inspired by the immune system,", "author": ["F. Guimar\u00e3es"], "venue": "Information Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Intelligent tuning of PID controller with disturbance function using immune", "author": ["D.H. Kim", "J.H. Cho"], "venue": "algorithm,\" presented at the IEEE International Conference on Computational Intelligence for Measurement Systems and Applications,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}, {"title": "Application areas of AIS: The past, the present and the future,", "author": ["E. Hart", "J. Timmis"], "venue": "Applied Soft Computing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Real coded clonal selection algorithm for unconstrained global optimization using a hybrid inversely proportional hypermutation", "author": ["V. Cutello"], "venue": "operator,\" presented at the Symposium on Applied Computing archive,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "An Immune Algorithm for Protein Structure Prediction on Lattice Models,", "author": ["V. Cutello"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "Fast clonal algorithm,", "author": ["N. Khilwani"], "venue": "Engineering Applications of Artificial Intelligence,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "The use of multiple measurements in taxonomic Problems,", "author": ["R.A. Fisher"], "venue": "Ann. Eugenics,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1936}, {"title": "Cancer diagnosis via linear programming,", "author": ["O.L. Mangasarian", "W.H. Wolberg"], "venue": "SIAM News,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1990}], "referenceMentions": [{"referenceID": 0, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 103, "endOffset": 108}, {"referenceID": 1, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 103, "endOffset": 108}, {"referenceID": 2, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 103, "endOffset": 108}, {"referenceID": 3, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 103, "endOffset": 108}, {"referenceID": 4, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 135, "endOffset": 140}, {"referenceID": 5, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 135, "endOffset": 140}, {"referenceID": 6, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 135, "endOffset": 140}, {"referenceID": 7, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 162, "endOffset": 165}, {"referenceID": 8, "context": "It is an emerging area that explores and employs different immunological mechanisms to solve computational problems [10] A lot of immune algorithms were developed aiming to finding solutions to a broad class of complex problems.", "startOffset": 116, "endOffset": 120}, {"referenceID": 9, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 10, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 11, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 12, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 13, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 14, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 112, "endOffset": 119}, {"referenceID": 15, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 112, "endOffset": 119}, {"referenceID": 16, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 112, "endOffset": 119}, {"referenceID": 11, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 134, "endOffset": 142}, {"referenceID": 17, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 134, "endOffset": 142}, {"referenceID": 18, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 152, "endOffset": 159}, {"referenceID": 19, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 152, "endOffset": 159}, {"referenceID": 20, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 266, "endOffset": 270}, {"referenceID": 11, "context": "The first clonal selection algorithm was proposed by [13] which named CLONALG and used for optimization.", "startOffset": 53, "endOffset": 57}, {"referenceID": 21, "context": "Other versions of clonal selection algorithm are designed to improve the performance of CLONALG such as [24-26].", "startOffset": 104, "endOffset": 111}, {"referenceID": 22, "context": "Other versions of clonal selection algorithm are designed to improve the performance of CLONALG such as [24-26].", "startOffset": 104, "endOffset": 111}, {"referenceID": 23, "context": "Other versions of clonal selection algorithm are designed to improve the performance of CLONALG such as [24-26].", "startOffset": 104, "endOffset": 111}, {"referenceID": 23, "context": "Even a small change in any of these aspects may lead to a considerable change in the performance of clonal selection algorithms [26].", "startOffset": 128, "endOffset": 132}, {"referenceID": 24, "context": "1- Iris dataset [27] consists of 150 four-dimensional patterns in three classes (50 patterns each) represent different categories of iris flowers which have four feature values.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "2- Wisconsin Breast Cancer dataset [28] consists of 699 nine-dimensional patterns in two classes which are Benign (458 patterns) and Malignant (241 patterns).", "startOffset": 35, "endOffset": 39}], "year": 2010, "abstractText": "Unsupervised classification algorithm based on clonal selection principle named Unsupervised Clonal Selection Classification (UCSC) is proposed in this paper. The new proposed algorithm is data driven and self-adaptive, it adjusts its parameters to the data to make the classification operation as fast as possible. The performance of UCSC is evaluated by comparing it with the well known K-means algorithm using several artificial and real-life data sets. The experiments show that the proposed UCSC algorithm is more reliable and has high classification precision comparing to traditional classification methods such as K-means. General Terms Pattern Recognition, Algorithms.", "creator": "Microsoft\u00ae Office Word 2007"}}}