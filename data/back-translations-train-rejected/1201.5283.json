{"id": "1201.5283", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jan-2012", "title": "An Efficient Primal-Dual Prox Method for Non-Smooth Optimization", "abstract": "We consider the non-smooth optimization problems in machine learning, where both the loss function and the regularizer are non-smooth functions. Previous studies on efficient empirical loss minimization assume either a smooth loss function or a strongly convex regularizer, making them unsuitable for non-smooth optimization. We develop an efficient method for a family of non-smooth optimization where the dual form of the loss function is bilinear in primal and dual variables. We cast a non-smooth optimization problem into a minimax optimization problem, and develop a primal dual prox method that solves the minimax optimization problem at a rate of $O(1/T)$, significantly faster than a standard gradient descent method ($O(1/\\sqrt{T})$). Our empirical study verifies the efficiency of the proposed method for non-smooth optimization by comparing it to the state-of-the-art first order methods.", "histories": [["v1", "Tue, 24 Jan 2012 04:09:54 GMT  (75kb)", "https://arxiv.org/abs/1201.5283v1", null], ["v2", "Fri, 27 Jan 2012 17:50:21 GMT  (75kb)", "http://arxiv.org/abs/1201.5283v2", null], ["v3", "Fri, 10 Feb 2012 16:11:15 GMT  (79kb)", "http://arxiv.org/abs/1201.5283v3", null], ["v4", "Mon, 2 Apr 2012 15:50:38 GMT  (124kb)", "http://arxiv.org/abs/1201.5283v4", null], ["v5", "Fri, 26 Jul 2013 05:03:51 GMT  (130kb)", "http://arxiv.org/abs/1201.5283v5", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["tianbao yang", "mehrdad mahdavi", "rong jin", "shenghuo zhu"], "accepted": false, "id": "1201.5283"}, "pdf": {"name": "1201.5283.pdf", "metadata": {"source": "CRF", "title": "An Efficient Primal Dual Prox Method for Non-Smooth Optimization", "authors": ["Tianbao Yang", "Mehrdad Mahdavi", "Rong Jin", "Shenghuo Zhu"], "emails": ["yangtia1@msu.edu", "mahdavim@msu.edu", "rongjin@cse.msu.edu", "zsh@sv.nec-labs.com"], "sections": [{"heading": null, "text": "ar Xiv: 120 1.52 83v5 [cs.LG] Previous studies on efficient empirical loss minimization assume either a smooth loss function or a strongly convex regulator, making them unsuitable for smooth optimization. We are developing a simple but efficient method for a family of non-smooth optimization problems where the dual form of loss function in primary and dual variables is bilinear. We are throwing a non-smooth optimization problem into a Minimax optimization problem and are developing a primary dual prox method that solves the Minimax optimization problem at a rate of O (1 / T), provided that the proximal step can be efficiently solved, much faster than a standard method of subgradient descent that has a convergence rate of O (1 / \u221a T). Our empirical study does not confirm the efficiency of the two-fold method proposed by the first convergence of the two-order, and does not yield convergence of the two-fold method in the first order."}, {"heading": "1. Introduction", "text": "The formulation of machine learning tasks as a regularized empirical loss minimization problem establishes a close link between machine learning and mathematical optimization. (In regulated empirical loss minimization, efforts have been made to jointly minimize empirical loss beyond training problems.) This formulation includes support vectors (SVM) (Hastie et al., 2008), support vector regression (Smola and Scho \u00fclkopf, 2004), lasso (Zhu et al., 2003), logistic regression and backbone regression (Hastie et al., 2008) among many others. Therefore, optimization methods play a central role in solving machine learning applications that require the development of new optimization algorithms. Depending on the application, various types of losses and regulatory functions have been introduced in the literature."}, {"heading": "2. Related Work", "text": "It is not as if it is a real loss, but a real loss that affects the way it is able to minimise real losses. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "3. Notations and Definitions", "text": "In this section, we provide the basic breakdown, some preliminary definitions, and notations used during this work. We denote by [n] the set of integers {1, \u00b7 \u00b7, n}. We denote by (xi, yi), i [n] the training examples in which xi, \u00b7 X Rd, and yi are the assigned class names that are discrete for classification and continuous for regression. We assume that xi, \u2212 R, i [n] are the training examples in which xi, \u00b7 X Rd, and yi are the assigned class names that are discrete for classification and continuous for regression. Let us leave w Rd the linear hypothesis, w; x, y) the loss of the prediction made by the hypothesis."}, {"heading": "4. Pdprox: A Primal Dual Prox Method for Non-Smooth Optimization", "text": "We first describe the problems of uneven optimization to which the proposed algorithm can be applied, and then present the original dual-prox method for uneven optimization. We then examine the convergence rate of the proposed algorithms and discuss several extensions. Evidence of technical terms are moved to the annex."}, {"heading": "4.1 Non-Smooth Optimization", "text": "The extension of non-linear models is discussed in Section 4.5. Also the extension to a collection of linear models W-Rd-K can be done easily. (2) We consider the following general non-smooth optimization problems: min w-Qw [L (w) = max\u03b1-Qs [L (w) = max\u03b1-Qs, respectively. Since it is impossible to develop an efficient first order method for the general non-smooth optimization, we focus on the family of non-smooth loss functions that can be characterized by bilinear functions. L (w, \u03b1), i.e.L (w, y) = c0 (X, y) + explicitly on the bilinear functions that we can characterize."}, {"heading": "4.2 The Proposed Primal-Dual Prox Methods", "text": "The main advantages of the proposed algorithms are that they are able to capture the thriftiness structures of algorithm 1. Pdprox dual algorithms for each iteration of optimization1: Input: Step 1 / (2c), where c is specified in (6). 2: Initialization: w0 = 0 3: for t = 1, 2:. do 4: Er = Quantity Q\u03b1 [\u03b2t \u2212 1 + Quantity G\u03b1 (wt \u2212 1). We assume that we (wt \u2212 1)."}, {"heading": "4.3 Convergence Analysis", "text": "In this section, the convergence rate of the proposed algorithms is determined. We begin with a theory of the convergence rate of algorithms 1 and 2. To simplify the analysis, we first write (2) into the following equivalent Minimax formula. By executing algorithm 1 or algorithm 2 with T steps, we have F (w, \u03b1) - F (w, \u03b1) - F (w, \u03b1) - F (w) - F (w) - F (w) - F (w) - F (w) - F (f) - F (w) - F (w) - F (w) - F (w) - F (w) - F (w) - F (w) - F (w) - F (w) - F - F - (w) - F - (w) (w) - F (w) - F (w) - F (w) - F - (w) - F (w) - F (w) - F (w) - F (w) - F (w) - F (w) - F (w) - F (w) - F (w) - F - F (w) - F (w) - F (w) - F - F (w) - F - F (w) - F - F - F - (w) - F - F - (w) - F - F - (w) - F - F - (w) - F - F - F - F - F - (w) (w) - F - F - F (w - F - F - F - F - F - F (w) (w) - F - F - F - F - F - F - F (w) (w) - F - F - F - F - F - F - F - F - F - F (w) (w) (w - F - F - F - F - F - F - F - F (w) (w) (w) - F - F - F - F - F - F (w) (w) (w - F - F - F - F - F - F (w) (w) (w) (w - F - F - F - F - F - F - F (w) (w) (w) (w - F - F - F - F - F"}, {"heading": "4.3.1 Convergence Analysis of Algorithm 1", "text": "For the simplicity of the analysis, we assume that Qw = Rd is the entire Euclidean space (1). We discuss how to generalize the analysis to a convex domain Qw (1). To assign theorem 6 to algorithm 1, we introduce a series of lemmas to pave the path for the proof. We first present the key updates in algorithm 1 as follows: wt = Q\u03b1 (1), wt \u2212 Q\u03b1 (1), wt (wt), wp (wt \u2212 1), wt (wt \u2212 1), wt (wt \u2212 1), wt (wt \u2212 1), wp (wt \u2212 1), wp (wt \u2212 1), wp (wt \u2212 1), wp (wt \u2212 1), wp (wp), wp (wp), wp, wp, wp, wp (wp), wp, wp, wp (wp), wp, wp (wp), wp (wp, wp, wp (wp), wp, wp (wp), wp (wp, wp (wp), wp (wp (wp), wp, wp (wp, wp), wp (wp (wp), wp (wp, wp, wp, wp (wp), wp (wp), wp (wp (wp), wp, wp, wp (wp), wp (wp (wp), wp, wp (wp), wp, wp (wp (wp), wp (wp), wp (wp (wp), wp (wp)."}, {"heading": "4.3.2 Convergence Analysis of Algorithm 2", "text": "In the following, we present the key lemmas that are similar to lemmas 9 and 10, with evidence that is not executed. \u2212 There is a fixed sub-gradient that cannot be executed, so that the updates in algorithm 2 are equivalent to the following gradient mappings, (wt, \u03b2t \u2212 1) and (ut \u03b2t) = 1 \u2212 22 \u2212 22 \u2212 22 \u2212 22 \u2212 22, in which the updates in algorithm 2 are equivalent to the following gradient mappings, (wt, \u03b2t \u2212 1) and (ut \u03b2t) = 12 \u2212 22 \u2212 22, in which the updates in algorithm 2 are equivalent to the following gradient mappings, (wt, \u03b2t \u2212 1) and (ut \u03b2t) = 22 \u2212 22 \u2212 22, in which the updates in algorithm 2 are equivalent to the following gradient mappings, (22) and \u03b244 (22) and 22 \u2212 22 (1)."}, {"heading": "4.4 Implementation Issues", "text": "In this subsection we will discuss some implementation questions: (1) how to solve the optimization problems efficiently to update the primary and dual variables in algorithms 1 and 2 (2), how to set a good step size and (3) how to implement the algorithms efficiently. (Both alpha and \u03b2 are updated by a gradient mapping that requires the calculation of the projection into domain Q\u03b1. (2) If Q\u03b1 consists only of box constraints and a linear constraint (e.g. generalized hinge loss, absolute loss and insensitive loss), the projection Q\u03b1 [\u03b1] can be calculated by threshold calculation. (WhenQ\u03b1 consists of both box constraints and a linear constraint (e.g., generalized hinge loss and insensitive loss), the following problem results in an efficient algorithm for calculating Q\u03b1 [\u03b1 Lemma {: 13 for the Qa: Alpha: Alpha Size {: Alpha: Alpha: Alpha: Alpha Size]."}, {"heading": "4.5 Extensions and Discussion", "text": "We have the option of opting for the extension of the nonlinear model. (1) We make several comments. (1) We can extend the extension to the nonlinear models. (1) We can extend the extension to the nonlinear models. (1) We can extend the extension to the nonlinear models. (1) We can extend the extension to the nonlinear models. (1) We can extend the extension to the nonlinear models. (1) We can extend the extension to the nonlinear models. (2) We can extend the extension to the nonlinear models. (1) We can extend the extension to the nonlinear models. (1) We can extend the extension to the nonlinear models. (2) We can extend the extension to the nonlinear models. (2) We can not extend the extension to the models."}, {"heading": "5. Experiments", "text": "In this section, we present empirical studies to verify the efficiency of the proposed algorithm. We organize our experiments as follows. \u2022 In sub-sections 5.1, 5.2 and 5.3, we compare the proposed algorithm with first-order methods that directly update the primary variable with each iteration. We apply all algorithms to three different tasks with different non-smooth loss functions and regulators. The methods used in this study include the first-order gradient descend algorithm (gd), the forward and backward dividing algorithm (fobos) (Duchi and Singer, 2009), the regulated dual medium-size algorithm (rda) (Xiao, 2009), the accelerated gradient descend algorithm (agd), the forward and backward dividing algorithm (fobos). Since the proposed method is a non-stochastic method, we compare it with the non-stochastic, prochastic, variant of bogd and rbod."}, {"heading": "5.1 Group lasso regularizer for Grouped Feature Selection", "text": "In this experiment, we use the group lasso for regularization, i.e., R (w) = \u2211 g. \"dg.\" wg. \"2, where wg corresponds to the gth group variables and dg to the number of variables in group g. To apply Nesterov's method, we can originally write R (w) = max.\" ug. \"2 \u2264 1.\" dg. \"g.\" We use the MEMset Donar dataset (Yeo and Burge, 2003) as a test bed. This dataset was originally used to detect splice sites. It is divided into a training set and a test set: The training set consists of 8, 415 matching and 179, 438 incorrect donor sites, and the test set shows 4, 208 matching and 89, 717 incorrect donor sites. Each example in this dataset was originally created by a sequence of {A, C, G, T. \"d\" conditional impairments of the 7. (We follow the Yang to 7.) and 3."}, {"heading": "5.2 \u21131,\u221e regularization for Multi-Task Learning", "text": "In this experiment, we perform a regression with multiple tasks (Argyriou et al., 2009). Let us let W = (w1, \u00b7 \u00b7, wk) give the k-linear hypotheses for the regression. To apply Nesterov's method, we write the results of the test as R (W) = max. number of tests as R (W) = max. number of tests as J = 1. We use the data set of the school (Argyriou et al., 2008), a common data set for learning with multiple tasks. This data set contains the exam results of 15,362 students from 139 secondary schools, corresponding to 139 tasks, one for each school. Each student in this data set is described by 27 attributes. We follow the setup in (Argyriou et al., 2008)."}, {"heading": "5.3 Trace norm regularization for Max-Margin Matrix Factorization/ Matrix Completion", "text": "In this experiment, we evaluate the proposed method using the track norm regularization, a regularizer commonly used in max margin matrix factorization and matrix completion, with the goal of restoring a complete matrix X from partially observed matrix Y. However, the goal consists of a loss function that measures the difference between X and Y on the observed entries and a track normalizer on X. (Srebro et al., 2005) and an absolute loss is used instead of a square loss in matrix completion. We test for 100K MovieLens data containing 1 million ratings from 943 users on 1682 movies. Since there are five different ratings that can be assigned to each movie, we follow (Rennie and Srebro et al, 2005) by introducing four thresholds from 2.4 to 3.4 to demonstrate the proposed value."}, {"heading": "5.4 Comparison: Pdprox vs Primal-Dual method with excessive gap technique", "text": "In this section we compare the proposed dual methods with the complex methods of Nesterov. (Nesterov, 2005b) However, the algorithms in (Nesterov, 2005a) for non-smooth optimizations suffer from a problem of setting the value of smoothing parameters, which requires the number of iterations to be fixed in advance. (Nesterov, 2005b) The algorithms in (Nesterov, 2005b) address the problem by updating both the primary and dual variables, which are similar to the proposed Pdprox method. We refer to this baseline as Pdexg to the three tasks as subsections 5.2 and 5.3, i.e., group characteristics selection with hinge loss and group lasso on MEMset Donar data set, multi-task learning with insensitive losses."}, {"heading": "5.5 Sparsity constraint on the dual variables", "text": "In this subsection, we will empirically examine the proposed algorithm for optimizing the problem in Equation (19), which introduces a constraint on the thriftiness of the dual variables. We will test the algorithm on three large data sets from the UCI repository, namely a9a, rcv1 (binary), and covtye4. In the experiments, we will use the regulator and fix \u03bb = 1 / n. First, we will run the proposed algorithm for 100 seconds on the three data sets with different values of m = 100, 200, 400, and plot the target against the number of iterations. The results are shown in Figure 6, which demonstrate that convergence with smaller m is faster, which is equivalent to the convergence bound O ([D + m] / [2 n\u043c]) of the proposed algorithm for (19)."}, {"heading": "5.6 Comparison: double-primal vs double-dual implementation", "text": "From the discussion in Section 4.4, we have seen that both the Pdprox-primary and Pdproxdual algorithms can be implemented by either maintaining two dual variables, which we refer to as a dual implementation, or by maintaining two primary variables, which we refer to as a double primary implementation. One implementation could be more efficient than the other implementation, depending on the type of applications. For example, in the multitask regression with two losses (Nie et al., 2010), if the number of examples is much greater than the number of attributes, i.e. n, and the number of tasks K is large, then the size of the dual variable implementation with two losses (Nie et al., 2010) is greater than the number of attributes, i.e. n, and the number of tasks K is large, then the size of the dual variable implementation with two losses is greater than the size of the W with two losses."}, {"heading": "5.7 Comparison for solving \u211322 regularized SVM", "text": "In this subsection, we compare the proposed Pdprox method with Pegasos to solve the problem. ~ We compare Pdprox with one step size and two step sizes and compare it to the accelerated version proposed in (Chambolle and Pock, 2011) for strongly convex functions. We implement Pdprox dual algorithm (through dual implementation) in C + + using the same data structures encoded by Shai Shalev-Shwartz. (Figure 8 shows the comparison of Pdprox vs. Pegasos on covtype datasets with three different levels of \u03bb = n \u2212 0.5, n \u2212 0.8, n \u2212 1. We calculate the objective value of Pdprox after each iteration and calculate the objective value of Pegasos after an effective transfer of all data (i.e. n number of iterations."}, {"heading": "6. Conclusions", "text": "In this paper, we investigate uneven optimization in machine learning, where both the loss function and the regulator are uneven. We develop an efficient gradient-based method for a family of uneven optimization problems, in which the dual form of the loss function can be expressed as a bilinear function in primary and dual variables. We show that the proposed algorithm, assuming that the proximal step can be efficiently solved, achieves a convergence rate of O (1 / T) faster than many other first-order methods for uneven optimization. Unlike existing studies of uneven optimization, our work enjoys easier implementation and analysis, and provides a unified methodology for a number of uneven optimization problems. Our empirical studies show the efficiency of the proposed algorithm compared to the first-order methods for solving many uneven machine learning problems and the effectiveness of the proposed algorithm for optimizing the problem with an economical solution."}, {"heading": "Appendix A. Derivation of constant c for (generalized) hinge loss", "text": "\u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2"}, {"heading": "Appendix B. Proof of Lemma 3", "text": "SinceG\u03b1 (w, \u03b1; X, y) = a (X, y) + H (X, y) w, Gw (w, \u03b1; X, y) = b (X, y) + H (X, y).Then it is G\u03b1 (w1, \u03b11; X, y) \u2212 G\u03b1 (w2, \u03b12; X, y) 22 \u2264 H (X, y) (w1 \u2212 w2) 22 \u2264 c w1 \u2212 w2 22, Gw (w1, \u03b11; X, y) \u2212 Gw (w2, \u03b12; X, y) 22 \u2264 H (a1 \u2212 a2) 22 \u2264 c 1 \u2212 a2 22, assuming that H (X, y) = H (X, y) 22 \u2264 c."}, {"heading": "Appendix C. The differences between Algorithm 1", "text": "in Chambolle and Pock, 2011) and Pdprox-Primal Algorithm (Algorithm 2) and Pdprox-dual algorithm (Algorithm 3) We make the following correspondences between our notations (appear the R.H.S of the following equations) and the notations in (Chambolle and Pock, 2011) (appear the L.H.S of the following qualities), x = w, y = a, x = u G (w) + w (w) + w (w) + w (w) w (F) or the notations in (Chambolle and Pock, 2011) (appear the L.H.S of the following qualities), x = w, y = a, x = u G (w) + w (w) w (w) w) w (w) w) w (w) w) or the notations in (w) F (f) or) or the (f), c0 = L (w))) or the dependence in a, b), H, c0, c) and the c are (c), and (c), and (Q) (we are) (x)."}, {"heading": "Appendix D. Proof of Lemma 10", "text": "To prove Lemma 10, we first present the following problem with its effects: Lemma 17 Lass Z (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) (Z) ("}, {"heading": "Appendix E. Proof of Lemma 13", "text": "By introducing Lagrange's multiplier for the constraint \u2211 i \u03b1ivi \u2264 \u03c1, we have the following min-max problem max \u03b7 min \u03b1 \u0432 [0,1] n1 2 \u0445 \u03b1 \u2212 \u03b1 \u0435\u0435 2 + \u03b7 (\u0445 i\u03b1ivi \u2212 \u03c1). The solution to \u03b1 is \u03b1i = [\u03b1-i \u2212 \u03b7 \u0445 vi] [0,1]. Under KKT condition, the optimal \u03b7 \u0432 is equal to 0, if we were equal to 0 \u0445 i [\u03b1ivi] [0,1] vi < \u03c1, otherwise we have \u0445 i [\u03b1-i \u2212 \u03b7 vi] [0,1] vi \u2212 \u03c1 = 0.Since the left side of the above equation is a monotonously decreasing function in \u03b7 \u0445, we can calculate the corresponding amount by efficiently searching for two sections."}, {"heading": "Appendix F. Proof of Lemma 16", "text": "Using the convex conjugate V \u0445 (\u03b7) of V (z), the composite mapping can be described as follows: asmin w1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 22 + \u03bbmax\u03b7 (\u03b7). Then the optimal solution of the \"satisfaction problems\" is the \"satisfaction problems.\" Then the optimal solution of the \"satisfaction problems\" is the \"satisfaction problems,\" i.e. the \"satisfaction factors,\" \"V\" 3 \"and\" V. \"It is easy to prove that\" w \"and\" a non-increasing function. \"Since the\" V \"function is a convex function, its negative gradient \u2212 V\" is a non-increasing function. Therefore, we can calculate the optimal function by two-part search."}], "references": [{"title": "Convex multi-task feature learning", "author": ["Andreas Argyriou", "Theodoros Evgeniou", "Massimiliano Pontil"], "venue": "Machine Learning,", "citeRegEx": "Argyriou et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2008}, {"title": "Optimization with Sparsity-Inducing Penalties (Foundations and Trends(R) in Machine Learning)", "author": ["Francis Bach", "Rodolphe Jenatton", "Julien Mairal"], "venue": "Now Publishers Inc.,", "citeRegEx": "Bach et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bach et al\\.", "year": 2011}, {"title": "Classification with a reject option using a hinge loss", "author": ["Peter L. Bartlett", "Marten H. Wegkamp"], "venue": "JMLR, 9:1823\u20131840,", "citeRegEx": "Bartlett and Wegkamp.,? \\Q2008\\E", "shortCiteRegEx": "Bartlett and Wegkamp.", "year": 2008}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["Amir Beck", "Marc Teboulle"], "venue": "SIAM J. Img. Sci.,", "citeRegEx": "Beck and Teboulle.,? \\Q2009\\E", "shortCiteRegEx": "Beck and Teboulle.", "year": 2009}, {"title": "Convex Optimization", "author": ["Stephen Boyd", "Lieven Vandenberghe"], "venue": null, "citeRegEx": "Boyd and Vandenberghe.,? \\Q2004\\E", "shortCiteRegEx": "Boyd and Vandenberghe.", "year": 2004}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["Stephen Boyd", "Neal Parikh", "Eric Chu", "Borja Peleato", "Jonathan Eckstein"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "A forward-backward splitting algorithm for the minimization of non-smooth convex functionals in banach space", "author": ["Kristian Bredies"], "venue": "Inverse Problems, 25:Article ID 015005,", "citeRegEx": "Bredies.,? \\Q2009\\E", "shortCiteRegEx": "Bredies.", "year": 2009}, {"title": "Fast implementation of l1 regularized learning algorithms using gradient descent methods", "author": ["Yunpeng Cai", "Yijun Sun", "Yubo Cheng", "Jian Li", "Steve Goodison"], "venue": "In SDM,", "citeRegEx": "Cai et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2010}, {"title": "Exact matrix completion via convex optimization", "author": ["Emmanuel J. Cand\u00e8s", "Benjamin Recht"], "venue": "CoRR, abs/0805.4471,", "citeRegEx": "Cand\u00e8s and Recht.,? \\Q2008\\E", "shortCiteRegEx": "Cand\u00e8s and Recht.", "year": 2008}, {"title": "A first-order primal-dual algorithm for convex problems with applications to imaging", "author": ["Antonin Chambolle", "Thomas Pock"], "venue": "J. Math. Imaging Vis.,", "citeRegEx": "Chambolle and Pock.,? \\Q2011\\E", "shortCiteRegEx": "Chambolle and Pock.", "year": 2011}, {"title": "Accelerated gradient method for multi-task sparse learning problem", "author": ["Xi Chen", "Weike Pan", "James T. Kwok", "Jaime G. Carbonell"], "venue": "In ICDM,", "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "Support vector machines on a budget", "author": ["Ofer Dekel", "Yoram Singer"], "venue": "In NIPS,", "citeRegEx": "Dekel and Singer.,? \\Q2006\\E", "shortCiteRegEx": "Dekel and Singer.", "year": 2006}, {"title": "Efficient online and batch learning using forward backward splitting", "author": ["John Duchi", "Yoram Singer"], "venue": "JMLR., 10:2899\u20132934,", "citeRegEx": "Duchi and Singer.,? \\Q2009\\E", "shortCiteRegEx": "Duchi and Singer.", "year": 2009}, {"title": "Efficient projections onto the l1-ball for learning in high dimensions", "author": ["John Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Tushar Chandra"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Duchi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2008}, {"title": "A general framework for a class of first order Primal-Dual algorithms for convex optimization in imaging science", "author": ["Ernie Esser", "Xiaoqun Zhang", "Tony F. Chan"], "venue": "SIAM J. Imaging Sciences,", "citeRegEx": "Esser et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Esser et al\\.", "year": 2010}, {"title": "A feature selection newton method for support vector machine classification", "author": ["Glenn Fung", "O.L. Mangasarian"], "venue": "Technical report, Computational Optimization and Applications,", "citeRegEx": "Fung and Mangasarian.,? \\Q2002\\E", "shortCiteRegEx": "Fung and Mangasarian.", "year": 2002}, {"title": "The elements of statistical learning: data", "author": ["Trevor Hastie", "Robert Tibshirani", "Jerome Friedman"], "venue": null, "citeRegEx": "Hastie et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hastie et al\\.", "year": 2008}, {"title": "1/epsilon iteration-complexity for cone programming", "author": ["Qihang Lin"], "venue": "Math. Program.,", "citeRegEx": "Lin.,? \\Q2011\\E", "shortCiteRegEx": "Lin.", "year": 2011}, {"title": "A primal-dual algorithm for group", "author": ["Sofia Mosci", "Silvia Villa", "Alessandro Verri", "Lorenzo Rosasco"], "venue": null, "citeRegEx": "Mosci et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mosci et al\\.", "year": 2009}, {"title": "Gradient methods for minimizing composite objective function", "author": ["Yu. Nesterov"], "venue": "Core discussion papers,", "citeRegEx": "Nesterov.,? \\Q2007\\E", "shortCiteRegEx": "Nesterov.", "year": 2007}, {"title": "Efficient and robust feature selection via joint 2,1-Norms minimization", "author": ["Feiping Nie", "Heng Huang", "Xiao Cai", "Chris Ding"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Nie et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nie et al\\.", "year": 2010}, {"title": "Fast training of support vector machines using sequential minimal optimization", "author": ["John C. Platt"], "venue": "In Advances in Kernel Methods: Support Vector Learning,", "citeRegEx": "Platt.,? \\Q1998\\E", "shortCiteRegEx": "Platt.", "year": 1998}, {"title": "Diagonal preconditioning for first order primal-dual algorithms in convex optimization", "author": ["Thomas Pock", "Antonin Chambolle"], "venue": "In Proceedings of the 2011 International Conference on Computer Vision,", "citeRegEx": "Pock and Chambolle.,? \\Q2011\\E", "shortCiteRegEx": "Pock and Chambolle.", "year": 2011}, {"title": "A modification of the arrow-hurwitz method of search for saddle points", "author": ["L.D. Popov"], "venue": "Mat. Zametki,", "citeRegEx": "Popov.,? \\Q1980\\E", "shortCiteRegEx": "Popov.", "year": 1980}, {"title": "An efficient projection for l1, infinity regularization", "author": ["Ariadna Quattoni", "Xavier Carreras", "Michael Collins", "Trevor Darrell"], "venue": "In ICML,", "citeRegEx": "Quattoni et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Quattoni et al\\.", "year": 2009}, {"title": "A primal-dual splitting algorithm for finding zeros of sums of maximally monotone operators", "author": ["Andre Heinrich Radu loan Bot", "Ern\u00f6 Robert Csetnek"], "venue": "ArXiv e-prints,", "citeRegEx": "Bot and Csetnek.,? \\Q2012\\E", "shortCiteRegEx": "Bot and Csetnek.", "year": 2012}, {"title": "Guaranteed Minimum-Rank solutions of linear matrix equations via nuclear norm minimization", "author": ["Benjamin Recht", "Maryam Fazel", "Pablo A. Parrilo"], "venue": "SIAM Rev.,", "citeRegEx": "Recht et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Recht et al\\.", "year": 2010}, {"title": "Fast maximum margin matrix factorization for collaborative prediction", "author": ["Jasson D.M. Rennie", "Nathan Srebro"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Rennie and Srebro.,? \\Q2005\\E", "shortCiteRegEx": "Rennie and Srebro.", "year": 2005}, {"title": "Monotone operators and the proximal point algorithm", "author": ["R. Tyrrell Rockafellar"], "venue": "SIAM J. on Control and Optimization,", "citeRegEx": "Rockafellar.,? \\Q1976\\E", "shortCiteRegEx": "Rockafellar.", "year": 1976}, {"title": "Are loss functions all the same", "author": ["Lorenzo Rosasco", "Ernesto De Vito", "Andrea Caponnetto", "Michele Piana", "Alessandro Verri"], "venue": "Neural Comput.,", "citeRegEx": "Rosasco et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Rosasco et al\\.", "year": 2004}, {"title": "Pegasos: primal estimated sub-gradient solver for svm", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro", "Andrew Cotter"], "venue": "Math. Program.,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2011}, {"title": "Estimating the approximation error in learning theory", "author": ["Steve Smale", "Ding-Xuan Zhou"], "venue": "Anal. Appl. (Singap.),", "citeRegEx": "Smale and Zhou.,? \\Q2003\\E", "shortCiteRegEx": "Smale and Zhou.", "year": 2003}, {"title": "A tutorial on support vector regression", "author": ["Alex J. Smola", "Bernhard Sch\u00f6lkopf"], "venue": "Statistics and Computing,", "citeRegEx": "Smola and Sch\u00f6lkopf.,? \\Q2004\\E", "shortCiteRegEx": "Smola and Sch\u00f6lkopf.", "year": 2004}, {"title": "Maximum-margin matrix factorization", "author": ["N. Srebro", "J.D.M. Rennie", "T.S. Jaakkola"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Srebro et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2005}, {"title": "Efficient recovery of jointly sparse vectors", "author": ["Liang Sun", "Jun Liu", "Jianhui Chen", "Jieping Ye"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Sun et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2009}, {"title": "On accelerated proximal gradient methods for convex-concave optimization", "author": ["Paul Tseng"], "venue": "Technical report,", "citeRegEx": "Tseng.,? \\Q2008\\E", "shortCiteRegEx": "Tseng.", "year": 2008}, {"title": "Svm soft margin classifiers: Linear programming versus quadratic", "author": ["Yang"], "venue": "V.N. Vapnik. Statistical Learning Theory. Wiley-Interscience,", "citeRegEx": "Yang,? \\Q1998\\E", "shortCiteRegEx": "Yang", "year": 1998}, {"title": "Nesvm: a fast gradient method for support vector", "author": ["Tianyi Zhou", "Dacheng Tao", "Xindong Wu"], "venue": null, "citeRegEx": "Zhou et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2006}, {"title": "1-norm support vector machines", "author": ["Ji Zhu", "Saharon Rosset", "Trevor Hastie", "Rob Tibshirani"], "venue": "AISTAT,", "citeRegEx": "Zhu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2010}, {"title": "An efficient primal-dual hybrid gradient algorithm for total variation image", "author": ["M. Zhu", "T. Chan"], "venue": null, "citeRegEx": "Zhu and Chan.,? \\Q2003\\E", "shortCiteRegEx": "Zhu and Chan.", "year": 2003}, {"title": "The differences between Algorithm 1 in (Chambolle and Pock, 2011) and Pdprox-primal algorithm (Algorithm 2) and Pdprox-dual algorithm", "author": ["C. Appendix"], "venue": null, "citeRegEx": "Appendix,? \\Q2011\\E", "shortCiteRegEx": "Appendix", "year": 2011}], "referenceMentions": [{"referenceID": 16, "context": "This formulation includes support vector machine (SVM) (Hastie et al., 2008), support vector regression (Smola and Sch\u00f6lkopf, 2004), Lasso (Zhu et al.", "startOffset": 55, "endOffset": 76}, {"referenceID": 32, "context": ", 2008), support vector regression (Smola and Sch\u00f6lkopf, 2004), Lasso (Zhu et al.", "startOffset": 35, "endOffset": 62}, {"referenceID": 16, "context": ", 2003), logistic regression, and ridge regression (Hastie et al., 2008) among many others.", "startOffset": 51, "endOffset": 72}, {"referenceID": 30, "context": "A well-known example is the Pegasos algorithm (Shalev-Shwartz et al., 2011) which minimizes the l2 regularized hinge loss (i.", "startOffset": 46, "endOffset": 75}, {"referenceID": 10, "context": "Several other first order algorithms (Ji and Ye, 2009; Chen et al., 2009) are also proposed for smooth loss functions (e.", "startOffset": 37, "endOffset": 73}, {"referenceID": 2, "context": "Examples of non-smooth loss functions include hinge loss (Vapnik, 1998), generalized hinge loss (Bartlett and Wegkamp, 2008), absolute loss (Hastie et al.", "startOffset": 96, "endOffset": 124}, {"referenceID": 16, "context": "Examples of non-smooth loss functions include hinge loss (Vapnik, 1998), generalized hinge loss (Bartlett and Wegkamp, 2008), absolute loss (Hastie et al., 2008), and \u01eb-insensitive loss (Rosasco et al.", "startOffset": 140, "endOffset": 161}, {"referenceID": 29, "context": ", 2008), and \u01eb-insensitive loss (Rosasco et al., 2004); examples of non-smooth regularizers include lasso (Zhu et al.", "startOffset": 32, "endOffset": 54}, {"referenceID": 24, "context": ", 2010b), l1,\u221e regularizer (Quattoni et al., 2009), and trace norm regularizer (Rennie and Srebro, 2005).", "startOffset": 27, "endOffset": 50}, {"referenceID": 27, "context": ", 2009), and trace norm regularizer (Rennie and Srebro, 2005).", "startOffset": 36, "endOffset": 61}, {"referenceID": 21, "context": "A number of algorithms have been proposed to minimize the l2 regularized hinge loss (Platt, 1998; Joachims, 1999, 2006; Hsieh et al., 2008; Shalev-Shwartz et al., 2011), and the l1 regularized hinge loss (Cai et al.", "startOffset": 84, "endOffset": 168}, {"referenceID": 30, "context": "A number of algorithms have been proposed to minimize the l2 regularized hinge loss (Platt, 1998; Joachims, 1999, 2006; Hsieh et al., 2008; Shalev-Shwartz et al., 2011), and the l1 regularized hinge loss (Cai et al.", "startOffset": 84, "endOffset": 168}, {"referenceID": 7, "context": ", 2011), and the l1 regularized hinge loss (Cai et al., 2010; Zhu et al., 2003; Fung and Mangasarian, 2002).", "startOffset": 43, "endOffset": 107}, {"referenceID": 15, "context": ", 2011), and the l1 regularized hinge loss (Cai et al., 2010; Zhu et al., 2003; Fung and Mangasarian, 2002).", "startOffset": 43, "endOffset": 107}, {"referenceID": 2, "context": "Besides the hinge loss, recently a generalized hinge loss function (Bartlett and Wegkamp, 2008) has been proposed for cost sensitive learning.", "startOffset": 67, "endOffset": 95}, {"referenceID": 16, "context": "However, non-smooth loss functions such as absolute loss (Hastie et al., 2008) and \u01eb-insensitive loss (Rosasco et al.", "startOffset": 57, "endOffset": 78}, {"referenceID": 29, "context": ", 2008) and \u01eb-insensitive loss (Rosasco et al., 2004) are useful for robust regression.", "startOffset": 31, "endOffset": 53}, {"referenceID": 16, "context": "Therefore absolute loss is more robust for long-tailed error distributions and outliers (Hastie et al., 2008).", "startOffset": 88, "endOffset": 109}, {"referenceID": 29, "context": "(Rosasco et al., 2004) also proved that the estimation error bound for absolute loss and \u01eb-insensitive loss converges faster than that of square loss.", "startOffset": 0, "endOffset": 22}, {"referenceID": 12, "context": "Non-smooth regularizers Besides the simple non-smooth regularizers such as l1, l2, and l\u221e norms (Duchi and Singer, 2009), many other non-smooth regularizers have been employed in machine learning tasks.", "startOffset": 96, "endOffset": 120}, {"referenceID": 0, "context": "The l1,\u221e norm regularizer has been used for multi-task learning (Argyriou et al., 2008).", "startOffset": 64, "endOffset": 87}, {"referenceID": 20, "context": "In addition, several recent works (Hou et al., 2011; Nie et al., 2010; Liu et al., 2009) considered mixed l2,1 regularizer for feature selection.", "startOffset": 34, "endOffset": 88}, {"referenceID": 26, "context": "Trace norm regularizer is another non-smooth regularizer, which has found applications in matrix completion (Recht et al., 2010; Cand\u00e8s and Recht, 2008), matrix factorization (Rennie and Srebro, 2005; Srebro et al.", "startOffset": 108, "endOffset": 152}, {"referenceID": 8, "context": "Trace norm regularizer is another non-smooth regularizer, which has found applications in matrix completion (Recht et al., 2010; Cand\u00e8s and Recht, 2008), matrix factorization (Rennie and Srebro, 2005; Srebro et al.", "startOffset": 108, "endOffset": 152}, {"referenceID": 27, "context": ", 2010; Cand\u00e8s and Recht, 2008), matrix factorization (Rennie and Srebro, 2005; Srebro et al., 2005), and multi-task learning (Argyriou et al.", "startOffset": 54, "endOffset": 100}, {"referenceID": 33, "context": ", 2010; Cand\u00e8s and Recht, 2008), matrix factorization (Rennie and Srebro, 2005; Srebro et al., 2005), and multi-task learning (Argyriou et al.", "startOffset": 54, "endOffset": 100}, {"referenceID": 0, "context": ", 2005), and multi-task learning (Argyriou et al., 2008; Ji and Ye, 2009).", "startOffset": 33, "endOffset": 73}, {"referenceID": 0, "context": "The optimization algorithms presented in these works are usually limited: either the convergence rate is not guaranteed (Argyriou et al., 2008; Recht et al., 2010; Hou et al., 2011; Nie et al., 2010; Rennie and Srebro, 2005; Srebro et al., 2005) or the loss functions are assumed to be smooth (e.", "startOffset": 120, "endOffset": 245}, {"referenceID": 26, "context": "The optimization algorithms presented in these works are usually limited: either the convergence rate is not guaranteed (Argyriou et al., 2008; Recht et al., 2010; Hou et al., 2011; Nie et al., 2010; Rennie and Srebro, 2005; Srebro et al., 2005) or the loss functions are assumed to be smooth (e.", "startOffset": 120, "endOffset": 245}, {"referenceID": 20, "context": "The optimization algorithms presented in these works are usually limited: either the convergence rate is not guaranteed (Argyriou et al., 2008; Recht et al., 2010; Hou et al., 2011; Nie et al., 2010; Rennie and Srebro, 2005; Srebro et al., 2005) or the loss functions are assumed to be smooth (e.", "startOffset": 120, "endOffset": 245}, {"referenceID": 27, "context": "The optimization algorithms presented in these works are usually limited: either the convergence rate is not guaranteed (Argyriou et al., 2008; Recht et al., 2010; Hou et al., 2011; Nie et al., 2010; Rennie and Srebro, 2005; Srebro et al., 2005) or the loss functions are assumed to be smooth (e.", "startOffset": 120, "endOffset": 245}, {"referenceID": 33, "context": "The optimization algorithms presented in these works are usually limited: either the convergence rate is not guaranteed (Argyriou et al., 2008; Recht et al., 2010; Hou et al., 2011; Nie et al., 2010; Rennie and Srebro, 2005; Srebro et al., 2005) or the loss functions are assumed to be smooth (e.", "startOffset": 120, "endOffset": 245}, {"referenceID": 4, "context": "When the objective function is strongly convex and smooth, it is well known that gradient descent methods can achieve a geometric convergence rate (Boyd and Vandenberghe, 2004).", "startOffset": 147, "endOffset": 176}, {"referenceID": 19, "context": "When the objective function is smooth but not strongly convex, the optimal convergence rate of a gradient descent method is O(1/T ), and is achieved by the Nesterov\u2019s methods (Nesterov, 2007).", "startOffset": 175, "endOffset": 191}, {"referenceID": 30, "context": "For the objective function which is strongly convex but not smooth, the convergence rate becomes O(1/T ) (Shalev-Shwartz et al., 2011).", "startOffset": 105, "endOffset": 134}, {"referenceID": 19, "context": "In addition, several methods are developed for composite optimization, where the objective function is written as a sum of a smooth and a non-smooth function (Lan, 2010; Nesterov, 2007; Lin, 2010).", "startOffset": 158, "endOffset": 196}, {"referenceID": 12, "context": ", 2010a), general regularized empirical loss minimization (Duchi and Singer, 2009; Hu et al., 2009), trace norm minimization (Ji and Ye, 2009), and multi-task sparse learning (Chen et al.", "startOffset": 58, "endOffset": 99}, {"referenceID": 10, "context": ", 2009), trace norm minimization (Ji and Ye, 2009), and multi-task sparse learning (Chen et al., 2009).", "startOffset": 83, "endOffset": 102}, {"referenceID": 34, "context": "Tseng (2008) and Nemirovski (2005) developed prox methods that have a convergence rate of O(1/T ), provided the gradients are Lipschitz continuous and have been applied to machine learning problems (Sun et al., 2009).", "startOffset": 198, "endOffset": 216}, {"referenceID": 14, "context": "It was generalized in (Esser et al., 2010), which shares the similar spirit of the proposed algorithm.", "startOffset": 22, "endOffset": 42}, {"referenceID": 19, "context": ", 2011) considered the primal-dual convex formulations for general cone programming and apply Nesterov\u2019s optimal first order method (Nesterov, 2007), Nesterov\u2019s smoothing technique (Nesterov, 2005a), and Nemirovski\u2019s prox method (Nemirovski, 2005).", "startOffset": 132, "endOffset": 148}, {"referenceID": 9, "context": "Finally we noticed that, as we are preparing our manuscript, a related work (Chambolle and Pock, 2011) has recently been published in the Journal of Mathematical Imaging and Vision that shares a similar idea as this work.", "startOffset": 76, "endOffset": 102}, {"referenceID": 9, "context": "However, our work distinguishes from (Chambolle and Pock, 2011) in following aspects: (i) We propose and analyze two primal dual prox methods: one gives an extra gradient updating to dual variables and the other gives an extra gradient updating to primal vari-", "startOffset": 37, "endOffset": 63}, {"referenceID": 9, "context": ", 2009), trace norm minimization (Ji and Ye, 2009), and multi-task sparse learning (Chen et al., 2009). Despite these efforts, one major limitation of the existing (sub)gradient based algorithms is that in order to achieve a convergence rate better than O(1/ \u221a T ), they have to assume that the loss function is smooth or the regularizer is strongly convex, making them unsuitable for non-smooth optimization. Convex-concave optimization The present work is also related to convex-concave minimization. Tseng (2008) and Nemirovski (2005) developed prox methods that have a convergence rate of O(1/T ), provided the gradients are Lipschitz continuous and have been applied to machine learning problems (Sun et al.", "startOffset": 84, "endOffset": 516}, {"referenceID": 9, "context": ", 2009), trace norm minimization (Ji and Ye, 2009), and multi-task sparse learning (Chen et al., 2009). Despite these efforts, one major limitation of the existing (sub)gradient based algorithms is that in order to achieve a convergence rate better than O(1/ \u221a T ), they have to assume that the loss function is smooth or the regularizer is strongly convex, making them unsuitable for non-smooth optimization. Convex-concave optimization The present work is also related to convex-concave minimization. Tseng (2008) and Nemirovski (2005) developed prox methods that have a convergence rate of O(1/T ), provided the gradients are Lipschitz continuous and have been applied to machine learning problems (Sun et al.", "startOffset": 84, "endOffset": 538}, {"referenceID": 9, "context": ", 2009), trace norm minimization (Ji and Ye, 2009), and multi-task sparse learning (Chen et al., 2009). Despite these efforts, one major limitation of the existing (sub)gradient based algorithms is that in order to achieve a convergence rate better than O(1/ \u221a T ), they have to assume that the loss function is smooth or the regularizer is strongly convex, making them unsuitable for non-smooth optimization. Convex-concave optimization The present work is also related to convex-concave minimization. Tseng (2008) and Nemirovski (2005) developed prox methods that have a convergence rate of O(1/T ), provided the gradients are Lipschitz continuous and have been applied to machine learning problems (Sun et al., 2009). In contrast, our method achieves a rate of O(1/T ) without requiring the whole gradient but part of the gradient to be Lipschitz continuous. Several other primal-dual algorithms have been developed for regularized empirical loss minimization that update both primal and dual variables. (Zhu and Chan, 2008) proposed a primal-dual method based on gradient descent, which only achieves a rate of O(1/ \u221a T ). It was generalized in (Esser et al., 2010), which shares the similar spirit of the proposed algorithm. However, the explicit convergence rate was not established even though the convergence is proved. (Mosci et al., 2010) presented a primal-dual algorithm for group sparse regularization, which updates the primal variable by a prox method and the dual variable by a Newton\u2019s method. In contrast, the proposed algorithm is a first order method that does not require computing the Hessian matrix as the Newton\u2019s method does, and is therefore more scalable to large datasets. (Combettes and Pesquet; Radu loan Bot, 2012) proposed primal-dual splitting algorithms for finding zeros of maximal monotone operators of special types. (Lan et al., 2011) considered the primal-dual convex formulations for general cone programming and apply Nesterov\u2019s optimal first order method (Nesterov, 2007), Nesterov\u2019s smoothing technique (Nesterov, 2005a), and Nemirovski\u2019s prox method (Nemirovski, 2005). Nesterov (2005b) proposed a primal dual gradient method for a special class of structured non-smooth optimization problems by exploring an excessive gap technique.", "startOffset": 84, "endOffset": 2131}, {"referenceID": 9, "context": "In contrast, (Chambolle and Pock, 2011) simply assumes that the interim projection problems can be solved efficiently; (iii) We focus our analysis and empirical studies on the optimization problems that are closely related to machine learning.", "startOffset": 13, "endOffset": 39}, {"referenceID": 9, "context": "In contrast, the study (Chambolle and Pock, 2011) only considers the application in image problems.", "startOffset": 23, "endOffset": 49}, {"referenceID": 28, "context": "We also note that the proposed algorithm is closely related to proximal point algorithm (Rockafellar, 1976) as shown in (He and Yuan, 2012), and many variants including the modified Arrow-Hurwicz method (Popov, 1980), the Doughlas-Rachford (DR) splitting algorithm (Lions and Mercier, 1979), the alternating method of multipliers (ADMM) (Boyd et al.", "startOffset": 88, "endOffset": 107}, {"referenceID": 23, "context": "We also note that the proposed algorithm is closely related to proximal point algorithm (Rockafellar, 1976) as shown in (He and Yuan, 2012), and many variants including the modified Arrow-Hurwicz method (Popov, 1980), the Doughlas-Rachford (DR) splitting algorithm (Lions and Mercier, 1979), the alternating method of multipliers (ADMM) (Boyd et al.", "startOffset": 203, "endOffset": 216}, {"referenceID": 5, "context": "We also note that the proposed algorithm is closely related to proximal point algorithm (Rockafellar, 1976) as shown in (He and Yuan, 2012), and many variants including the modified Arrow-Hurwicz method (Popov, 1980), the Doughlas-Rachford (DR) splitting algorithm (Lions and Mercier, 1979), the alternating method of multipliers (ADMM) (Boyd et al., 2011), the forward-backward splitting algorithm (Bredies, 2009), the FISTA algorithm (Beck and Teboulle, 2009).", "startOffset": 337, "endOffset": 356}, {"referenceID": 6, "context": ", 2011), the forward-backward splitting algorithm (Bredies, 2009), the FISTA algorithm (Beck and Teboulle, 2009).", "startOffset": 50, "endOffset": 65}, {"referenceID": 3, "context": ", 2011), the forward-backward splitting algorithm (Bredies, 2009), the FISTA algorithm (Beck and Teboulle, 2009).", "startOffset": 87, "endOffset": 112}, {"referenceID": 9, "context": "For a detailed comparison with some of these algorithms, one can refer to (Chambolle and Pock, 2011).", "startOffset": 74, "endOffset": 100}, {"referenceID": 2, "context": "\u2022 Generalized hinge loss (Bartlett and Wegkamp, 2008):", "startOffset": 25, "endOffset": 53}, {"referenceID": 16, "context": "\u2022 Absolute loss (Hastie et al., 2008): l(w;x, y) = |w\u22a4x\u2212 y| = max \u03b1\u2208[\u22121,1] \u03b1(w\u22a4x\u2212 y).", "startOffset": 16, "endOffset": 37}, {"referenceID": 29, "context": "\u2022 \u01eb-insensitive loss (Rosasco et al., 2004) : l(w;x, y) = max(|w\u22a4x\u2212 y| \u2212 \u01eb, 0) = max \u03b11\u22650,\u03b12\u22650 \u03b11+\u03b12\u22641 [ (w\u22a4x\u2212 y)(\u03b11 \u2212 \u03b12)\u2212 \u01eb(\u03b11 + \u03b12) ] .", "startOffset": 21, "endOffset": 43}, {"referenceID": 20, "context": "\u2022 l2 loss (Nie et al., 2010): l(W;x,y) = \u2016W\u22a4x\u2212 y\u20162 = max \u2016\u03b1\u20162\u22641 \u03b1\u22a4(W\u22a4x\u2212 y), where y \u2208 R is multiple class label vector and W = (w1, \u00b7 \u00b7 \u00b7 ,wK).", "startOffset": 10, "endOffset": 28}, {"referenceID": 35, "context": ", Gw(w,\u03b1) + \u03bb\u2202R(w) is not Lipschitz continuous due to the general non-smooth term R(w), which prevents previous convex-concave minimization scheme (Tseng, 2008; Nemirovski, 2005) not applicable.", "startOffset": 147, "endOffset": 178}, {"referenceID": 19, "context": "(iii) the primal variable w is updated by a composite gradient mapping (Nesterov, 2007) in step 5.", "startOffset": 71, "endOffset": 87}, {"referenceID": 12, "context": "Similar to many other approaches for composite optimization (Duchi and Singer, 2009; Hu et al., 2009), we assume that the mapping in step 5 can be solved efficiently.", "startOffset": 60, "endOffset": 101}, {"referenceID": 9, "context": "Remark 5 A similar algorithm with an extra primal variable is also proposed in a recent work (Chambolle and Pock, 2011).", "startOffset": 93, "endOffset": 119}, {"referenceID": 9, "context": "We discuss the differences between the Pdprox method and the algorithm in (Chambolle and Pock, 2011) with our notations in Appendix C.", "startOffset": 74, "endOffset": 100}, {"referenceID": 30, "context": "Comparison with Pegasos on l2 regularizer We compare the proposed algorithm to the Pegasos algorithm (Shalev-Shwartz et al., 2011) 2 for minimizing the l2 regularized hinge loss.", "startOffset": 101, "endOffset": 130}, {"referenceID": 31, "context": "According to the common assumption of learning theory (Wu and Zhou, 2005; Smale and Zhou, 2003), the optimal \u03bb is O(n\u22121/(\u03c4+1)) if the probability measure can be approximated by the closure of RKHS H\u03ba with exponent 0 < \u03c4 \u2264 1.", "startOffset": 54, "endOffset": 95}, {"referenceID": 13, "context": "(Duchi et al., 2008) has proposed more efficient algorithms for solving the projection problem.", "startOffset": 0, "endOffset": 20}, {"referenceID": 9, "context": "Remark 15 In Appendix C, we show that the updates on (wt,\u03b1t) of Algorithm 3 are essentially the same to the Algorithm 1 in (Chambolle and Pock, 2011), if we remove the extra dual variable in Algorithm 3 and the extra primal variable in Algorithm 1 in (Chambolle and Pock, 2011).", "startOffset": 123, "endOffset": 149}, {"referenceID": 9, "context": "Remark 15 In Appendix C, we show that the updates on (wt,\u03b1t) of Algorithm 3 are essentially the same to the Algorithm 1 in (Chambolle and Pock, 2011), if we remove the extra dual variable in Algorithm 3 and the extra primal variable in Algorithm 1 in (Chambolle and Pock, 2011).", "startOffset": 251, "endOffset": 277}, {"referenceID": 9, "context": "However, the difference is that in Algorithm 3, we maintain two dual variables and one primal variable at each iteration, while the Algorithm 1 in (Chambolle and Pock, 2011) maintains two primal variables and one dual variable at each iteration.", "startOffset": 147, "endOffset": 173}, {"referenceID": 12, "context": "More details can be found in (Duchi and Singer, 2009; Ji and Ye, 2009).", "startOffset": 29, "endOffset": 70}, {"referenceID": 9, "context": "In addition, the authors in (Chambolle and Pock, 2011) suggested a two step sizes scheme with \u03c4 for updating the primal variable and \u03c3 for updating the dual variable.", "startOffset": 28, "endOffset": 54}, {"referenceID": 22, "context": "Furthermore, (Pock and Chambolle, 2011) presents a technique for computing diagonal preconditioners in the cases when estimating the value of c is difficult for complex problems, and applies it to general linear programing problems and some computer vision problems.", "startOffset": 13, "endOffset": 39}, {"referenceID": 1, "context": "(2) We can perform the computation by manipulating on a finite number of parameters due to the representer theorem provided that the regularizerR(g) is a monotonic norm (Bach et al., 2011).", "startOffset": 169, "endOffset": 188}, {"referenceID": 1, "context": "((Bach et al., 2011) considers how to compute the proximal mapping in (18) for more general sparsity induced norms.", "startOffset": 1, "endOffset": 20}, {"referenceID": 11, "context": "In (Dekel and Singer, 2006), the authors address a budget SVM problem by introducing a 1 \u2212 \u221e interpolation norm on the empirical hinge loss, leading to a sparsity constraint \u2016\u03b1\u20161 \u2264 m on the dual variables, where m is the target number of support vectors.", "startOffset": 3, "endOffset": 27}, {"referenceID": 12, "context": "The baseline first order methods used in this study include the gradient descent algorithm (gd), the forward and backward splitting algorithm (fobos) (Duchi and Singer, 2009), the regularized dual averaging algorithm (rda) (Xiao, 2009), the accelerated gradient descent algorithm (agd) (Chen et al.", "startOffset": 150, "endOffset": 174}, {"referenceID": 10, "context": "The baseline first order methods used in this study include the gradient descent algorithm (gd), the forward and backward splitting algorithm (fobos) (Duchi and Singer, 2009), the regularized dual averaging algorithm (rda) (Xiao, 2009), the accelerated gradient descent algorithm (agd) (Chen et al., 2009).", "startOffset": 286, "endOffset": 305}, {"referenceID": 10, "context": "2 l1,\u221e regularization for Multi-Task Learning In this experiment, we perform multi-task regression with l1,\u221e regularizer (Chen et al., 2009).", "startOffset": 121, "endOffset": 140}, {"referenceID": 0, "context": "We use the School data set (Argyriou et al., 2008), a common dataset for multi-task learn-", "startOffset": 27, "endOffset": 50}, {"referenceID": 0, "context": "We follow the setup in (Argyriou et al., 2008), and generate a training data set with 75% of the examples from each school and a testing data set with the remaining examples.", "startOffset": 23, "endOffset": 46}, {"referenceID": 10, "context": "34 (optimized by Pdprox), comparable to the performance reported in (Chen et al., 2009).", "startOffset": 68, "endOffset": 87}, {"referenceID": 27, "context": "Hinge loss function is used in max-margin matrix factorization (Rennie and Srebro, 2005; Srebro et al., 2005), and absolute loss is used instead of square loss in matrix completion.", "startOffset": 63, "endOffset": 109}, {"referenceID": 33, "context": "Hinge loss function is used in max-margin matrix factorization (Rennie and Srebro, 2005; Srebro et al., 2005), and absolute loss is used instead of square loss in matrix completion.", "startOffset": 63, "endOffset": 109}, {"referenceID": 27, "context": "Since there are five distinct ratings that can be assigned to each movie, we follow (Rennie and Srebro, 2005; Srebro et al., 2005) by introducing four thresholds \u03b81,2,3,4 to measure the hinge loss between the predicted value Xij and the ground truth Yij .", "startOffset": 84, "endOffset": 130}, {"referenceID": 33, "context": "Since there are five distinct ratings that can be assigned to each movie, we follow (Rennie and Srebro, 2005; Srebro et al., 2005) by introducing four thresholds \u03b81,2,3,4 to measure the hinge loss between the predicted value Xij and the ground truth Yij .", "startOffset": 84, "endOffset": 130}, {"referenceID": 27, "context": "Note that we did not compare to the optimization algorithm in (Rennie and Srebro, 2005) since it cast the problem into a non-convex problem by using explicit factorization of X = UV\u22a4, which suffers a local minimum, and the optimization algorithm in (Srebro et al.", "startOffset": 62, "endOffset": 87}, {"referenceID": 33, "context": "Note that we did not compare to the optimization algorithm in (Rennie and Srebro, 2005) since it cast the problem into a non-convex problem by using explicit factorization of X = UV\u22a4, which suffers a local minimum, and the optimization algorithm in (Srebro et al., 2005) since it formulated the problem into a SDP problem, which suffers from a high computational cost.", "startOffset": 249, "endOffset": 270}, {"referenceID": 20, "context": "For example, in multitask regression with l2 loss (Nie et al., 2010), if the number of examples is much larger than the number of attributes, i.", "startOffset": 50, "endOffset": 68}, {"referenceID": 9, "context": "We also compare Pdprox using one step size and two step sizes, and compare them to the accelerated version proposed in (Chambolle and Pock, 2011) for strongly convex functions.", "startOffset": 119, "endOffset": 145}, {"referenceID": 9, "context": "(\u03c4, \u03c3)) and the accelerated version (Pdprox-ac(\u03c4, \u03c3)) proposed in (Chambolle and Pock, 2011) for strongly convex functions.", "startOffset": 66, "endOffset": 92}], "year": 2013, "abstractText": "We study the non-smooth optimization problems in machine learning, where both the loss function and the regularizer are non-smooth functions. Previous studies on efficient empirical loss minimization assume either a smooth loss function or a strongly convex regularizer, making them unsuitable for non-smooth optimization. We develop a simple yet efficient method for a family of non-smooth optimization problems where the dual form of the loss function is bilinear in primal and dual variables. We cast a non-smooth optimization problem into a minimax optimization problem, and develop a primal dual prox method that solves the minimax optimization problem at a rate of O(1/T ) assuming that the proximal step can be efficiently solved, significantly faster than a standard subgradient descent method that has an O(1/ \u221a T ) convergence rate. Our empirical study verifies the efficiency of the proposed method for various non-smooth optimization problems that arise ubiquitously in machine learning by comparing it to the state-of-the-art first order methods.", "creator": "LaTeX with hyperref package"}}}