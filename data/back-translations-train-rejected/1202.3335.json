{"id": "1202.3335", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Feb-2012", "title": "An efficient high-quality hierarchical clustering algorithm for automatic inference of software architecture from the source code of a software system", "abstract": "It is a high-quality algorithm for hierarchical clustering of large software source code. This effectively allows to break the complexity of tens of millions lines of source code, so that a human software engineer can comprehend a software system at high level by means of looking at its architectural diagram that is reconstructed automatically from the source code of the software system. The architectural diagram shows a tree of subsystems having OOP classes in its leaves (in the other words, a nested software decomposition). The tool reconstructs the missing (inconsistent/incomplete/inexistent) architectural documentation for a software system from its source code. This facilitates software maintenance: change requests can be performed substantially faster. Simply speaking, this unique tool allows to lift the comprehensible grain of object-oriented software systems from OOP class-level to subsystem-level. It is estimated that a commercial tool, developed on the basis of this work, will reduce software maintenance expenses 10 times on the current needs, and will allow to implement next-generation software systems which are currently too complex to be within the range of human comprehension, therefore can't yet be designed or implemented. Implemented prototype in Open Source:", "histories": [["v1", "Wed, 15 Feb 2012 15:03:01 GMT  (4469kb)", "http://arxiv.org/abs/1202.3335v1", "130 pages. I am looking for someone serious about investing into development of a commercial tool on the basis of my algorithm and my prototype. arXiv admin note: text overlap witharXiv:0803.4025by other authors"]], "COMMENTS": "130 pages. I am looking for someone serious about investing into development of a commercial tool on the basis of my algorithm and my prototype. arXiv admin note: text overlap witharXiv:0803.4025by other authors", "reviews": [], "SUBJECTS": "cs.AI cs.LG cs.SE", "authors": ["sarge rogatch"], "accepted": false, "id": "1202.3335"}, "pdf": {"name": "1202.3335.pdf", "metadata": {"source": "META", "title": "Automatic Structure Discovery for Large Source Code", "authors": ["Etienne Gagnon", "Laurie Hendren", "Tamara Munzner", "Peter Sweeney", "Heidar Pirzadeh", "Abdelwahab Hamou-Lhadj", "Timothy Lethbridge", "Luay Alawneh"], "emails": [], "sections": [{"heading": null, "text": "Automatic Structure Discovery for Large Source Code Page 1 of 130Master Thesis, AI Sarge Rogatch, University of Amsterdam July 2010Automatic Structure Discovery for Large Source CodeBy Sarge RogatchMaster ThesisUniversiteit van Amsterdam, Artificial Intelligence, 2010Automatic Structure Discovery for Large Source Code Page 2 of 130Master Thesis, AI Sarge Rogatch, University of Amsterdam July 2010"}, {"heading": "Acknowledgements", "text": "I would like to acknowledge the researchers and developers who are not even aware of this project, but their results have played a very important role: Soot Developers: Raja Vall'ee-Rai, Phong Co, Etienne Gagnon, Laurie Hendren, PatrickLam, and others. TreeViz Developer: Werner Randelshofer H3 Layout Author and H3Viewer Developer: Tamara Munzner Researcher of the static call graph construction: Ond\u00ed rej Lhot 'ak, Vijay Sundaresan, DavidBacon, Peter Sweeney Researcher of the reverse architecting: Heidar Pirzadeh, Abdelwahab Hamou-Lhadj, Timothy Lethbridge, Luay Alawneh Researcher of the Min Cut related problems: Dan Gusfield, Andrew Goldberg, MaximBabenko, Boris Cherkassky, Kostas Tsioutsiouliklis, Gary Flake, Robert TarjanStructure Discovery for Large Source Code 3 of the University....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................of Amsterdam University of the University of Amsterdam."}, {"heading": "1 Abstract", "text": "In this thesis, we attempt to automatically deduce software architecture from the source code. We have studied and used unattended learning methods for these, namely clustering. State-of-the-art source code (structure) analysis methods and tools have been researched, and ongoing research in software reverse architecture has been investigated. Graph clustering based on minimal cut trees is a newer algorithm that meets strong theoretical criteria and performs well in practice, both in terms of speed and accuracy. Its successful applications in the field of web and citation graphs have been reported. To our knowledge, however, there has been no application of this algorithm to the domain of reverse architecture. Furthermore, most existing software artifacts clusters are research addressed in procedural languages or C + +, while we aim at modern object-oriented languages and the implicit character of relationships between software engineering artifacts, we consider the direction of research important because this cluster method allows for much larger tasks to be solved."}, {"heading": "2 Introduction", "text": "In fact, most of them will be able to play by the rules they had in the past, and they will be able to play by the rules that were in place in the past."}, {"heading": "2.1 Project Summary", "text": "This year, we have reached a point where it can only take one year to reach an agreement."}, {"heading": "2.2 Global Context", "text": "In fact, the fact is that most of them will be able to demonstrate that they are able, that they are able to achieve their goals, and that they are able to achieve their goals."}, {"heading": "2.3 Relevance for Artificial Intelligence", "text": "Many AI methods require parameters, and the performance of the methods depends on the choice of parameter values. The best choice of methods or parameter values is almost always domain-specific, usually problem-specific and sometimes even data-specific. We want to investigate these peculiarities in the field of source code visualization and reverse engineering. The purpose of an automatic cluster algorithm in artificial intelligence is to group similar entities.Automatic cluster algorithms are used in the automatic Structure Discovery for Large Source Code Page 11 of the 130Master Thesis, AI Sarge Rogatch, University of Amsterdam July 2010 in the context of program understanding to discover the structure (architecture) of the examined program."}, {"heading": "2.4 Problem Analysis", "text": "The particular problem of interest is the conclusion of the architecture and various facts about software from its source code. However, it is desirable that the high-level view of software source code is automatically made available to human experts, omitting the details that do not require human attention at this stage. Software products often lack documentation about the design of their source code, or software architecture. Although complete documentation can only be created by human designers, an automatic inference tool can also provide a high-level overview of the source code by grouping, generalizing, and abstracting. Such a tool could also show the places that human experts should pay attention to. Semi-automatic inferences can be used when the documentation is partially available. The key step we are making in this project is to split the clustering of the source code into parts, i.e. it leads to groupings, i.e. this is combined with the generalization of software artifacts and the detection of layers within the source code."}, {"heading": "2.5 Hypotheses", "text": "In the early stages of this project, we had hypotheses as listed below.) By applying cluster analyses to a graph of SE artifacts and their dependencies, we can save human efforts on some common tasks within the software structure, namely the identification of linked artifacts and the decomposition of the nearby system."}, {"heading": "2.6 Business Applications", "text": "In fact, most of them are able to survive themselves if they do not see themselves as being able to survive themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I do not believe that we will be able to put the world in order and that we will be able to change the world. \""}, {"heading": "2.7 Thesis Outline", "text": "In this section, we will present the state of the art in the field of reverse architecture and put artificial intelligence techniques in this context. We will also discuss the candidate AI techniques in Section 3, analyze the weaknesses of existing approaches and give counter examples. In this section, we will also discuss the state of the art in source code analysis, as we need some source code analysis to extract input data for our approach. Section 4 provides the background material for a proper understanding of our contributions by the reader. The theory we have developed to implement the project is given in Section 5. Since we often use problem-solving approaches, we are not always confident as to the originality and optimism or superiority of the solutions we have developed. Certainly, we will give this as a weakness of our paper in Section 9. The most likely original, optimal or superior solutions will be given in Section 5. The solutions that are suspicious of not being original will be discussed together with the background material in Section 4. The solutions that will be discussed in Section 7, together with our optimal, or everything else that is needed in Section 6."}, {"heading": "3 Literature and Tools Survey", "text": "Architecture reconstruction typically involves three steps [Kosc2009]: 1 extracting raw data on the system; 2 applying the appropriate abstraction technique; 3 presenting or visualizing information. In this project, we perform integrative tasks using the above-mentioned steps. We select appropriate methods and state-of-the-art tools, making realistic assessments of practical needs, porting methods and tools from other areas to our field and solving the problems that arise."}, {"heading": "3.1 Source code analysis", "text": "In fact, it is as if most of them are able to surpass themselves by placing themselves at the center of the public's attention. (...) In fact, it is as if they are able to place themselves at the center of attention. (...) In fact, it is as if they are able to place themselves at the center of attention. (...) It is as if they are able to place themselves at the center of the public's attention. (...) It is as if they are able to place themselves at the center of attention. (...) It is as if they are able to place themselves at the center of public's interest. (...) It is as if they are able to place themselves at the center of the public's attention. (...) It is as if they place themselves at the center of the public's attention. (...) It is as if they place themselves at the center of the public's interest. (...) It is as if they place themselves at the center. (... It is as if they place themselves at the center.) It is as if they place themselves at the center. (... It is as if they place themselves at the center.) It is as if they place themselves at the center. (... It is as if they place themselves at the center of the center."}, {"heading": "3.2 Clustering", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "3.2.1.1 Affinity Propagation", "text": "In fact, most of us are able to move to another world, in which we move to another world."}, {"heading": "3.2.1.2 Clique Percolation Method", "text": "Cfinder is a tool for finding and visualizing intersecting groups of nodes in networks, based on the Clique Percolation Method [Pal2005]. Unlike Cfinder / CPM, we used it \"as it is\" in an attempt to cluster software engineering artifacts using cutting-edge tools from another area, namely social networking analysis. Unlike Cfinder / CPM, other existing community finders for large networks, including the core method used in our project, find disconnected communities. According to [Pal2005], most of the actual networks consist of highly overlapping coherent groups of nodes. Although Cfinder claims that it is \"a quick and efficient method for clustering data represented by large graphs, such as genetic or social networks and microarray data,\" and \"very efficient for locating clicks of large sparse graphics,\" our experiments showed that it is not applicable to our domain."}, {"heading": "3.2.1.3 Based on Graph Cut", "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, a country, a city, a city and a country."}, {"heading": "3.2.2.1 Network Structure Indices based", "text": "It's not like it's a real process. (...) It's not like it's a real process. (...) It's not like it's a real process. (...) It's not like it's a real process. (...) It's not like it's a real process. (...) It's not like it's a real process. (...) It's like it's a real process. (...) It's like it's a real process. (...) It's like it's a process. (...) It's like it's a process. (...) It's like it's a process. (...) It's like it's a process. (...) It's like it's a process."}, {"heading": "3.2.2.2 Hierarchical clustering methods", "text": "In fact, most of them will be able to play by the rules they have set themselves in order to play by the rules."}, {"heading": "4 Background", "text": "The methods and tools used in our project are described and formalized in this section. We also consider it worthwhile to discuss the known challenges in clustering software engineering artifacts. In Section 5, we provide the theory that we have developed in addition to the background material presented here."}, {"heading": "4.1 Max Flow & Min Cut algorithm", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "4.2 Min Cut Tree algorithm", "text": "In fact, the majority of them will be able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to struggle, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "4.3 Flake-Tarjan clustering", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "4.4 Call Graph extraction", "text": "A dynamic call graph is a call graph that is supposed to represent every possible run of the program. The exact static call graph is indecipherable, so static call graph algorithms are generally approximations. That is, every occurring call relationship is represented in the diagram, and possibly some call relationships that would never occur in actual program runs. Below are some examples of the difficulties that occur when generating call graphs from source code (static): Polymorphism: Depending on the class of the object that is assigned to a base class variable, different methods are called invariants: If in the code below x > = 0 always, then the call to Func2 () actually never occurs: o if (x < 0) {func1 (x);} otherwise {func2 (x); contextuality: in the example above, you can consider the call graph as the dynamic function for the above reasons."}, {"heading": "4.5 The Problem of Utility Artifacts", "text": "This is especially true for usage components called by many other components of the system, and as such they strain the structure of the system without putting much emphasis on its intelligibility. [1] However, an investigation into the properties of utilities and concepts has concluded that utilities may have a different framework based on the calculation of a component that is able to unite, but not necessarily utilities that implement general design concepts at a lower level of design concepts. Common practice for commodity detection is based on the calculation of a component that is executed in the form of fan-in and fan-out. The rationality behind this is that something that is called from many places is likely to be a utility, while something that makes many calls to other components that are likely to be more complex."}, {"heading": "4.6 Various Algorithms", "text": "A reader who needs more background can refer to [CLR2003], [AHU1983] and [Knu1998] Comments on the Breadth & Depth First SearchesPriority QueuePriority Blocking Queue Java Minimum Spanning Tree Traversals, Metrics & Manipulations Heiverse, depth, cardinality etc. Lowest Common Ancestor Disjoint-set data structure / union-find algorithmReindexing Techniques Graph contractionSubgraph / subset processingReusable full-indexing map Insertion / Removal: O (1) Creation: O (nIndices) Listing: Theory (nStoredItems) Dynamic Programming For the statistics Suffix Tree Discovery For the Saratic Source Amsterdam 13sticCode of July 2010"}, {"heading": "5 Theory", "text": "As part of this work, we have developed and applied some theories that are necessary to: apply the [Fla2004] cluster method to the domain of source code analysis Solve the problems that arise during the application, namely the excessive number of sibling nodes (also called alpha threshold), due to the peculiarities of the domain, namely that software systems are usually almost hierarchical, i.e. there are only a few (ideally none) cycles. Optimize the search direction to get the most important solutions as early as possible during the iterative runtime of the hierarchical cluster algorithm. Allow parallel computation, since the cluster process still requires considerable timeframes. The following subsections provide this theory in order to implement our system. Some proofs and empirical evaluations require considerable effort and are therefore made by our scope.We present the source code of the software as directed graphs (EVG, which corresponds to each software object, usually a point V and a technical E in a rule)."}, {"heading": "5.1 Normalization", "text": "In fact, most of them are able to go to another world, to go to another world, to go to another world, to go to another world."}, {"heading": "5.2 Merging Heterogeneous Dependencies", "text": "The phase of extracting relationships between software engineering artifacts can create different kinds of relationships. In this project, we used several methods to explore the inheritance of classes. One method takes parameters or return values that are instances of a particular class. Type 5 is not exhausted, such as methods in an interface that therefore have no statements. 130Master Thesis, AI Sarge Rogatch, does not exhaust the automatic structure Discovery for Large Source Page 45."}, {"heading": "5.3 Alpha-search", "text": "In fact, it is the case that most of us are able to go to another world, in which they go to another world, in which they go to another world, in which they find themselves in another world, in which they find themselves in another world, in which they find themselves in another world, in which they live in another world, in which they live in another world, in which they find themselves in a world in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live."}, {"heading": "5.4 Hierarchizing the Partitions", "text": "The way we merge the partitions generated by the basic cut-clustering algorithm differs from the simple hierarchical method described and applied in [Fla2004], because we do not pass all alpha-s from the highest to the smallest formula, which is determined by a parametric max-flow algorithm as flow breakpoints (see [Bab2006]), but perform the basic cut-clustering with the \"most desirable\" alpha, as determined heuristically by our prioritization (Section 5.3). Therefore, we must be able to merge the result of a basic cut-clustering algorithm (a partition of clusters in clusters) into the globally maintained clustering hierarchy for arbitrary alpha (Section 5.3)."}, {"heading": "5.5 Distributed Computation", "text": "Automatic Structure Discovery for Large Source Code Page 49 of 130Master Thesis, AI Sarge Rogatch, University of Amsterdam July 2010"}, {"heading": "5.6 Perfect Dependency Structures", "text": "It is now easy to notice that in the cluster tree (Section 5.4) alpha threshold can imply a parent node, i.e. a cluster created by the basic clustering at l, with an excessive number of children, while each child corresponds to a cluster created at r. However, all lr-kk children's clusters do not have to have the same parent, as shown in a counter-example, see Figure 5-12 below: Automatic Structure Discovery for Large Source Code Page 50 of 130Master Thesis, AI Sarge Rogatch, University of Amsterdam July 2010. In practice, some nodes in the cluster tree actually have an excessive number of children. In our source code experiments, we observed that there is always an alpha threshold that includes a single node with many children. For example, an alpha threshold of 433lk to 3839rk clusters is, while all 3406 children's clusters under the same parent appear in the cluster hierarchy."}, {"heading": "5.6.1 Maximum Spanning Tree", "text": "Consider the problem of an excessive number of children (due to the alpha threshold, Section 5.6) occurred for some nodes in the cluster tree, so its cluster has many nested clusters at the immediate next level, i.e. the decomposition is flat. A flat decomposition that contains many elements is not nearly as comprehensible as if we were hierarchizing the elements, so a kind of divide-nconquer approach is applicable to understanding the subsystem. So let us hierarchize the flat decomposition. Let pC be the parent cluster that contains np (excessive number) child cluster nppp CCC, 2,1,..., i.e. pnpp CCCC, 2,1,... for a cluster C leave the set of input graphs of the input graph (they are also the leaf nodes of the cluster tree, and they are also SE artifacts like Java classes) that form cluster C."}, {"heading": "5.6.2 Root Selection Heuristic", "text": "In fact, there is a very high level of understanding that the aforementioned beginnings are a real diversionary manoeuvre."}, {"heading": "6 Implementation and Specification", "text": "We implemented the parallel calculation of hierarchical flake-tarjan clusters within this project as multiple OS processes on our dual-core processor, each working in a separate directory. Changing the prototype to work on multiple computers amounts to sharing the parent directory over the network and starting remote processes, rather than locally. Choosing the programming language was determined by whether we needed implementation speed or runtime of the program. Most of InSoAr, 14K code, is implemented in Java: the source code is 434 KB in size, and everything was written by a programmer, the author of the thesis, within the short timeframe of this project. Some state-of-the-of-the-art source code metrics on InSoAr are created with STAN ([Stan2009] and demonstrated to the right in Figure 6-1. The bottleneck part, minimal intersection tree algorithm (Section 4.2.1) is best used under the gold-hayardous section (4.2)."}, {"heading": "6.1 Key Choices", "text": "Most of them are able to be in the position in which they are able, in which they are able to move."}, {"heading": "6.2 File formats", "text": "\"< n, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c,"}, {"heading": "6.3 Visualization", "text": "Pure XML or HTML formats, GraphVice and FreeMind tools were considered, but we chose the following visualization tools because they work well with large trees: H3Viewer: http: / / graphics.stanford.edu / ~ munzner / h3 / download.html This tool can draw large trees in 3D hyperbolic space TreeViz: http: / / www.randelshofer.ch / treeviz / index.html This tool supports 7 different presentations for large trees."}, {"heading": "6.4 Processing Pipeline", "text": "In fact, most of them will be able to move into a different world, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live."}, {"heading": "7 Evaluation", "text": "The main premise for the high quality of a cluster hierarchy produced is the theoretical grounding of the cluster algorithm we use: the quality of the clusters produced is limited by strict minimum intersection and expansion criteria [Fla2004]. We consider the intersection size to be a rational criterion in the field of software development, since the sum of edge weights reflects the amount of interaction (relationships) between SE artifacts (e.g. Java classes) that a software engineer must study in the source code to understand the coupling between two SE artifacts or two groups (communities, clusters) of SE artifacts. This corresponds to the basic idea behind the maxflow / min-cut cluster technique according to [Fla2004]: \"To create clusters that have small cluster sections (i.e. between clusters) and relatively large intra-cluster sections (i.e. within clusters). This guarantees strong networking within the cluster and is also a strong criterion in general.\""}, {"heading": "7.1 Experiments", "text": "In the largest of our experiments, we processed software with 2.07M (2 070 645) graph edges (relationships) over heterogeneous correlations (SEartifacts), which contain 11.2K (11 199) Java classes, 163K (163183) of class members contain artifacts (methods and fields) This is a real medium-sized project provided by KPMG for our experiments during the internship. The client code contains about 500 classes, i.e. the remaining 10.7K classes are in libraries that include Java system libraries, Spring Framework, Hibernate, Apache Commons, JBPM, Mule, Jaxen, Log4j, Dom4j, and others. Together with libraries, the project becomes 22 times larger and falls into the category of large software. Note that our conception of a medium-sized project differs significantly from the claims of other scientific work. In [Patent 2009], we will classify them as a medium-sized project that contains 147 classes, so we must classify them as a small-scale project."}, {"heading": "1 InSoAr processing", "text": "1.1 Cluster hierarchy we demonstrate in this paper 72 hours, 0.6GB RAM 1.2 Acceptable results (differences are empirically visible, conclusions need statistical studies) 1-2 hours1.3 The largest experiment (11.2K classes, 2M relationships) 1.3GB RAM, 120 hours2 Calling graph construction (and other relationships with soot) 2.1 VTA in common experiments, 7.5K classes: 2GB RAM 0.5 hours2.2. RTA in largest experiment, 11.2K classes: (VTA loses memory in this case) 2GB RAM, 2 hours3 Basic cut clustering (one alpha, in a separate process) 3.1 In common experiments 4.5 minutes 3.2 In largest experiment, 20 minutes 3.3 Memory requirement, no more than 35MB"}, {"heading": "7.2 Interpretation of the Results", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "7.2.2.1 Obvious from class name", "text": "It can be argued that the clustering hierarchy does not add value to the purpose of an SE class when the class appears near similarly named, sometimes library classes, because the class purpose was already obvious, as in Figure 7-3 below. In this illustration we see that the application class com.kpmg.web.security.EmployeeUserDetailsService and others appear coupled (descendants of cluster # 8604) with library classes org.springframework.security.UserDetailsService and org.springframework.userdetailsUserdetails.UserDetailsUserDetails is the point that these similarly named classes inform us about goodarchitectural style: classes with similar names serve a similar purpose."}, {"heading": "7.2.2.2 Hardly obvious from class name", "text": "Contrary to the previous example, it is not so easy to understand the purpose of a class called com.kpmg.kpo.generated.jaxws.crmSOAP. CRM probably stands for Customer Relations Management and SOAP is the well-known (otherwise it is as simple as searching in Google) Simple Object Access Protocol for exchanging structured information for web services. The latter two potential concepts are quite far apart. His situation in the cluster hierarchy makes things much clearer, namely for a human software engineer:... CrmSOAP is much more about SOAP than about CRM because it is clustered with SOAP-related library classes. If the software engineer was not familiar with SOAP, he / she can see after seeing the cluster hierarchy that XML SOAP is based because the adjacent library classes are included in javax.xml. See Figure 7-4 below and a 3D view of the July 13, 2010 part of the Discovery hierarchy here."}, {"heading": "7.2.2.3 Not obvious from class name", "text": "In this example, a class is called... AuditEntryDTO, which does not say anything about its purpose unless we know that the software project is strongly related to audit and DTO lookup on Wikipedia: http: / / en.wikipedia.org / wiki / Data _ transfer _ object. After the two steps above, we still do not know why it is \"entry,\" i.e. entry of what? However, a look at the cluster hierarchy makes things clear; perhaps even replacing the need for the two steps above, see Figure 7-5. Obviously, there is some logging (classes that contain \"trail,\" which is a synonym for logging, and ConsoleAuditLogImpl), so \"entry\" - it is an entry of a protocol (namely audit log), and logging is implemented as a service, whereby AuditEntryDTO objects are transferred between software application subsystems."}, {"heading": "7.2.2.4 Class name seems to contradict the purpose", "text": "In fact, the majority of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "7.2.3.1 Coupled classes are in different packages", "text": "Recognition of class linkages between packages / namespaces is important for the reasons discussed throughout the essay (implicit architecture, without manually scanning millions of lines of source code).Below are just a few examples to prove that InSoAr groups classes according to their purpose unit, which can be validated by the names of the classes. Automatic structure discovery for large source code page 69 of the master thesis by AI Sarge Rogatch, University of Amsterdam July 2010"}, {"heading": "7.2.3.2 Coupled classes are in the same package", "text": "In fact, most of them are able to move to another world, where they can move to another world, where they can find their way to another world."}, {"heading": "8 Further Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8.1 A Self-Improving Program", "text": "In order to develop a program that improves itself, we first need to create a program that improves programs and points to itself. Before we create a program that improves programs, we need a program that understands programs, at least as people do. Obviously, ability to understand requires the ability to analyze as a prerequisite. State-of-the-art tools for source code analysis exist, but they do processing without understanding. In this project, we have implemented a program that builds the structure of the source code to facilitate its further understanding for humans. Another direction of work is to implement a program that tries to understand the structure without humans, and then perform some forward engineering of an improved source code."}, {"heading": "8.2 Cut-based clustering", "text": "As we discussed in Section 5.1, Flake-Tarjan Clustering [Fla2004] is only available for undirected graphs. This constraint is set by the minimal cut-tree algorithm [GoHu1961], but maximum flow algorithms are available for both directed and undirected graphs. To meet this constraint, in our project we converted directed graphs from artefact relationships of software development to undirected branches using normalization, similar to those described in [Fla2004] and PageRank [Brin1998]. Although the cluster formation showed good results, it is evident that important information is lost when converting directed to undirected graphs branching out using normalization. In the framework of our project, we have also tried to eliminate the constraint by minimal cut, since we do not need a full cut-tree, but only the edges that the artificial split from the rest of the branch of our project requires a minimum branch, given that flake is a hard task in 2004."}, {"heading": "8.3 Connection strengths", "text": "Our standardization, motivated in Section 4.5 and foreseen in Section 5.1, enables clustering to produce good results (Section 7) that alleviate the problem of utility artifacts. It is interesting to investigate whether edge weighting, taking into account other characteristics (fan-out, graph-wide facts), can lead to an even better cluster hierarchy."}, {"heading": "8.4 Alpha-threshold", "text": "We observed this phenomenon during the adaptation of Flake-Tarjan clusters in the field of source code and discussed it in 5.6 and proposed an ad hoc solution that alleviates the problem. Nevertheless, it is interesting to analyze and formalize the cases in which this phenomenon occurs, and its magnitude in terms of the properties of the input graph. According to our intuition, the following two theoretical facts should lead to a solid theoretical conclusion: 1 The central theorem of [Fla2004], discussed in Section 4.3.1:), min (), (), (QPQPcSVSc Automatic Structure Discovery for Large Source Code Page 80 of 130 Master Thesis, AI Sarge Rogatch, University of Amsterdam July 20102 The formalization of the alpha threshold phenomenon that we have provided in Section 5.6: 0), (tt kKkkSVSc Automatic Structure Discovery for Large Code Page 80 of 130 Master Thesis, Sarge Rogatch, University of Amsterdam July 20102, the formalization of the alpha threshold phenomenon that we should have provided in Section 81: The KKKKSVSc Alpha Alpha Automatic Structure Discovery for Large Code Page 80 of 130 Master Thesis, so that in Section 81: The KKKKKKSVSc Alpha Alpha Automatic Structure Discovery for Large Code Page 80 of 130, Sarge Rogatom University July 2016 In Section 81, the KSelective Phenomenon Phenomenon Section 6, we have further investigated this phenomenon."}, {"heading": "9 Conclusion", "text": "In fact, most people who are able to survive themselves are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "9.1 Major challenges", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "9.2 Gain over the state of the art", "text": "In fact, it is such that most of them will be able to move into a different world, in which they are able to integrate themselves, in which they are able to live, in which they are able to live, in which they live, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they are able to integrate themselves, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they"}], "references": [{"title": "Multi-terminal network flows", "author": ["Gomory", "Hu"], "venue": "In J. of the Society for Industrial and Applied Mathematics,", "citeRegEx": "Gomory and Hu,? \\Q1961\\E", "shortCiteRegEx": "Gomory and Hu", "year": 1961}, {"title": "Composing Subsystem Structures using (k, 2)-partite Graphs", "author": ["Muller", "Uhl"], "venue": "In Proc. Of the International Conference on Software Maintenance,", "citeRegEx": "Muller and Uhl,? \\Q1990\\E", "shortCiteRegEx": "Muller and Uhl", "year": 1990}, {"title": "Simple and effective analysis of statically-typed object-oriented programs", "author": ["Diwan", "Moss", "McKinley"], "venue": "In Proceedings of OOPSLA,", "citeRegEx": "Diwan et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Diwan et al\\.", "year": 1996}, {"title": "On implementing push-relabel method for the maximum flow problem", "author": ["Cherkassky", "Goldberg"], "venue": "In Algorithmica,", "citeRegEx": "Cherkassky and Goldberg,? \\Q1997\\E", "shortCiteRegEx": "Cherkassky and Goldberg", "year": 1997}, {"title": "Using automatic clustering", "author": ["Mancoridis", "Mitchell", "Rorres", "Chen", "Gansner"], "venue": null, "citeRegEx": "Mancoridis et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Mancoridis et al\\.", "year": 1998}, {"title": "Bunch: A Clustering Tool for the Recovery and Maintenance of Software System Structures", "author": ["Mancoridis", "Mitchell", "Chen", "Gansner"], "venue": "In Proc. Of the International Conference on Software Maintenance,", "citeRegEx": "Mancoridis et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Mancoridis et al\\.", "year": 1999}, {"title": "Data Clustering: A Review", "author": ["Jain", "Murty", "Flynn"], "venue": "In ACM Computing Surveys,", "citeRegEx": "Jain et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Jain et al\\.", "year": 1999}, {"title": "The Effect of Call Graph Construction Algorithms for Object-Oriented Programs on Automatic Clustering", "author": ["Rayside", "Reuss", "Hedges", "Kontogiannis"], "venue": "In Proc. Of the", "citeRegEx": "Rayside et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Rayside et al\\.", "year": 2000}, {"title": "Normalized cuts and image segmentation", "author": ["Shi", "Malik"], "venue": "In IEEE Transactions on Pattern Analysis and Machine Learning,", "citeRegEx": "Shi and Malik,? \\Q2000\\E", "shortCiteRegEx": "Shi and Malik", "year": 2000}, {"title": "A Min-max Cut Algorithm for Graph Partitioning and Data Clustering", "author": ["Ding", "Zha", "Gu", "Simon"], "venue": "In Proc. of International Conference on Data Mining,", "citeRegEx": "Ding et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Ding et al\\.", "year": 2001}, {"title": "Software Architecture In Practice", "author": ["Bass", "Clements", "Kazman"], "venue": "Second Edition. Boston: Addison-Wesley,pp", "citeRegEx": "Bass et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bass et al\\.", "year": 2003}, {"title": "Reasoning about the Concept of Utilities", "author": ["Hamou-Lhadj", "Lethbridge"], "venue": "In Proc. Of the ECOOP International Workshop on Practical Problems of Programming in the Large, LNCS,", "citeRegEx": "Hamou.Lhadj and Lethbridge,? \\Q2004\\E", "shortCiteRegEx": "Hamou.Lhadj and Lethbridge", "year": 2004}, {"title": "Uncovering the overlapping community structure of complex networks in nature and society", "author": ["Palla", "Der\u00e9nyi", "Farkas", "Vicsek"], "venue": "In Nature", "citeRegEx": "Palla et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Palla et al\\.", "year": 2005}, {"title": "Experimental Evaluation of a Parametric Flow Algorithm", "author": ["Babenko", "Goldberg"], "venue": "Technical Report, Microsoft Research,", "citeRegEx": "Babenko and Goldberg,? \\Q2006\\E", "shortCiteRegEx": "Babenko and Goldberg", "year": 2006}, {"title": "Fast SDP Relaxations of Graph Cut Clustering, Transduction, and Other Combinatorial Problems", "author": ["De Bie", "Cristianini"], "venue": "In Journal of Machine Learning Research", "citeRegEx": "Bie and Cristianini,? \\Q2006\\E", "shortCiteRegEx": "Bie and Cristianini", "year": 2006}, {"title": "Summarizing the Content of Large Traces to Facilitate the Understanding of the Behavior of a Software System", "author": ["Hamou-Lhadj", "Lethbridge"], "venue": "In Proc. Of the", "citeRegEx": "Hamou.Lhadj and Lethbridge,? \\Q2006\\E", "shortCiteRegEx": "Hamou.Lhadj and Lethbridge", "year": 2006}, {"title": "Clustering large software systems", "author": ["Andreopolos", "An", "Tzerpos", "Wang"], "venue": null, "citeRegEx": "Andreopolos et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Andreopolos et al\\.", "year": 2007}, {"title": "Hierarchical Clustering for Software Architecture Recovery", "author": ["Maqbool", "Babri"], "venue": "In IEEE Transactions on Software Ingineering,", "citeRegEx": "Maqbool and Babri,? \\Q2007\\E", "shortCiteRegEx": "Maqbool and Babri", "year": 2007}, {"title": "Graph clustering with network structure indices", "author": ["Rattigan", "Maier", "Jensen"], "venue": "In Proc. of", "citeRegEx": "Rattigan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Rattigan et al\\.", "year": 2007}, {"title": "SQuAVisiT: A Software Quality Assessment and Visualization Toolset", "author": ["Roubtsov", "Telea", "Holten"], "venue": "In Proceedings 7th International Conference on Source Code Analysis and Manipulation,", "citeRegEx": "Roubtsov et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Roubtsov et al\\.", "year": 2007}, {"title": "A Survivor\u2019s Guide to Java Program Analysis with Soot", "author": ["Einarsson", "Nielsen"], "venue": "BRICS, Department of Computer Science,", "citeRegEx": "Einarsson and Nielsen,? \\Q2008\\E", "shortCiteRegEx": "Einarsson and Nielsen", "year": 2008}, {"title": "Structure and Interpretation of Computer Programs", "author": ["Narayan", "Gopinath", "Varadarajan"], "venue": "In Proc. Of the", "citeRegEx": "Narayan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Narayan et al\\.", "year": 2008}, {"title": "An Approach for Mapping Features to Code Based on Static and Dynamic Analysis", "author": ["Rohatgi", "Hamou-Lhadj", "Rilling"], "venue": "In Proc. Of the", "citeRegEx": "Rohatgi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rohatgi et al\\.", "year": 2008}, {"title": "Software Clustering Using Dynamic Analysis", "author": ["Patel", "Hamou-Lhadj", "Rilling"], "venue": null, "citeRegEx": "Patel et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Patel et al\\.", "year": 2009}, {"title": "A Binary Variable Model for Affinity Propagation", "author": ["Givoni", "Frey"], "venue": "In Neural Comput.,", "citeRegEx": "Givoni and Frey,? \\Q2009\\E", "shortCiteRegEx": "Givoni and Frey", "year": 2009}, {"title": "Quality of the Source Code for Design and Architecture Recovery Techniques: Utilities are the Problem", "author": ["Pirzadeh", "Alawneh", "Hamou-Lhadj"], "venue": "In Ninth International Conference on Quality Software,", "citeRegEx": "Pirzadeh et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Pirzadeh et al\\.", "year": 2009}], "referenceMentions": [], "year": 2012, "abstractText": "String getQueueName(); abstract Serializable getCommandObject(Long workflowInstanceId,Serializable getCommandObject(Long workflowInstanceId, String taskName, String messageType, ExecutionContext context);", "creator": "Microsoft\u00ae Word 2010"}}}