{"id": "1202.3703", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2012", "title": "Factored Filtering of Continuous-Time Systems", "abstract": "We consider filtering for a continuous-time, or asynchronous, stochastic system where the full distribution over states is too large to be stored or calculated. We assume that the rate matrix of the system can be compactly represented and that the belief distribution is to be approximated as a product of marginals. The essential computation is the matrix exponential. We look at two different methods for its computation: ODE integration and uniformization of the Taylor expansion. For both we consider approximations in which only a factored belief state is maintained. For factored uniformization we demonstrate that the KL-divergence of the filtering is bounded. Our experimental results confirm our factored uniformization performs better than previously suggested uniformization methods and the mean field algorithm.", "histories": [["v1", "Tue, 14 Feb 2012 16:41:17 GMT  (432kb)", "http://arxiv.org/abs/1202.3703v1", null]], "reviews": [], "SUBJECTS": "cs.SY cs.AI", "authors": ["e busra celikkaya", "christian r shelton", "william lam"], "accepted": false, "id": "1202.3703"}, "pdf": {"name": "1202.3703.pdf", "metadata": {"source": "CRF", "title": "Factored Filtering of Continuous-Time Systems", "authors": ["E. Busra Celikkaya", "Christian R. Shelton"], "emails": ["celikkae@cs.ucr.edu", "cshelton@cs.ucr.edu", "willmlam@ics.uci.edu"], "sections": [{"heading": null, "text": "We assume that the velocity matrix of the system can be represented compactly and that the faith distribution is approximated as a product of marginals.The essential calculation is the matrix exponential calculation. We consider two different methods for its calculation: the ODE integration and the unification of the Taylor expansion.For both, we consider approximations in which only one factorial state of belief is maintained. For factorized uniformization, we show that the KL divergence of filtration is limited. Our experimental results confirm that our factorized uniformization performs better than previously proposed uniformization methods and the mean field algorithm."}, {"heading": "1 Continuous-Time Markov Systems", "text": "We are interested in monitoring (alternatively tracking or filtering) a continuous finite time system with homogeneous Markovian stochastic systems, which means that proofs and events arrive at any (asynchronous) real time and can be either instantaneous or with real time values. The system is stationary and has discrete states, which means that a sample (trajectory) for the system consists of a series of times in which the system jumped from one state to another. Such models are common in queue theory and verification literature, and the algorithms developed there focus almost exclusively on stationary properties of the system. A singular exception is the work of Sutton and Jordan (2008), who applied Gibbs sampling to queue models. In contrast, the continuous Bayesian networks (Nodelman et al., 2002) stimulate the literature has focused on finite time properties, so we compare with these algorithms."}, {"heading": "1.1 Parameterization", "text": "Such a system is described by an initial distribution over the territory of the state and a rate matrix, often referred to as Qii. The diagonal element Qii = \u2212 qi is the rate of exit from the state i. This means that the density of the Qij remaining in a closed system represents an exponential distribution. (The rate of exit from one state is equal to the rate of exit from another state.) The probability of exit from one state i into the state apparatus i. Qij in a closed system is very high. (The rate of exit from one state is equal to the rate from another state.)"}, {"heading": "2 Matrix Exponential Calculations", "text": "Moler and Loan (2003) describe the numerical difficulties in calculating the matrix exponential in an excellent way. Here, we focus on two of the most important methods for calculating peQt."}, {"heading": "2.1 ODE", "text": "One method is to rewrite and solve f (t) = peQt as an ordinary differential equation using ODE integration methods. The most common ODE solver is the Runge-Kutta-Fehlberg method (RKF), which adapts the step size to the current error, allowing rapid progress in times of slow system changes. Basically, the calculation is to multiply a current estimate of the distribution by Q to calculate the time derivative."}, {"heading": "2.2 Uniformization", "text": "Uniformity is a transformation of a continuous Markovian system into a discrete time system. However, it does not correspond to the construction of the embedded Markov chain of the continuous time process, nor to the periodic division of the system at regular intervals. It corresponds to the scanning of the intervals between potential state changes from an exponential state at the rate \u03b1 and subsequent scanning of a suitable Markov chain exactly at these times (with stochastic matrix M), so that the resulting distribution via trajectories coincides with the original continuous time markov system. Mathematically, we can construct \u03b1 and M as follows. We express the rate matrix Q \u2212 chaze M = \u03b1 (M \u2212 I) in such a way that - provided \u03b1 maxi qi - M is a stochastic matrix: All elements are on [0, 1] and the lines add up to 1. Ideally, the matrix should be as small as possible as it represents the rate of the process."}, {"heading": "2.3 Approximate Versions", "text": "Both methods involve the calculation of state distributions and their multiplication by either Q or M. However, we will use v to denote any state distribution vector that is generated in the course of such a calculation. To the ODE method, v is a specific point and vQ is its time derivative. For uniformity, v is an element of the sum, and vM is the next element. While we might assume that the problem specification is compact, assuming that p and Q have compact representations, it is usually not possible for a system with many variables to express intermediate v values precisely, since the structure that exists in p and Q is not in v. Therefore, the most direct method for constructing an uncompromised filter algorithm is to keep v limited to a smaller representation. In the case of uniformity, Sidje et al. (2007) suggests keeping an economical representation for v (by dropping elements less than a certain threshold)."}, {"heading": "2.4 Notation", "text": "We will focus on approximate calculations of vM (vQ is similar). We will consider an undercalculation in the form v = vM. Let v, the current approximation of v, be in factored form: v (x) = vQ = vQ i (xi). Similarly, let v, the result of the multiplication of v, be multiplied by M, which is not necessarily fully taken into account. Finally, let v, the projection of v, be on the set of factored distributions. LetM, the operator that projects both by M and into the space of factored distributions. Thus, let vi be the boundary distribution of v (even if v is not factored). We will abuse notation and let each vector stand for the distribution it embodies. Further, let vi be the boundary distribution of v over the variable xi for each vector v (even if v is not factored), v \u2212 the boundary distribution over all the variable and all the variable."}, {"heading": "3 Factored Rate Matrix", "text": "While our methods apply to petri nets (Petri, 1962), edge-weighted decision diagrams (Wan et al., 2011), and other compact representations of the rate matrix, we focus on using a continuous Bayesian network (CTBN) to represent Q. We note that correspondence between CTBNs and petri nets has already been established (Raiteri and Portinale, 2009)."}, {"heading": "3.1 Continuous Time Bayesian Network", "text": "A continuous time Bayesian network (CTBN) (Nodelman et al., 2002) has an initial distribution described by a Bayesian network that is not of direct relevance to this work. It has a factored representation of the matrix Q. Each variable depends only on a subset of the other variables (which we call parents). Let U i be the parents of Xi. For each assignment Xi to U i there is an intensity matrix QXi | ui of dimension equal to the number of states of Xi. It describes the rates of change for Xi if their parents are equal to ui. If we allow the number of variable indices for which the assignments in x and x are different to be the complete Q matrix isQ (x, x) equal."}, {"heading": "3.2 Calculating Factored vM", "text": "Given the mix-of-DBN interpretation of M, it is not surprising that v-j = v-j-j | v-j can be calculated in one step without constructing v-M. Since Q has the same structure, the same method also works for them. Since the projection on a certain variable, xj, is linear if M-j is the composition of M and the projection on xj, in Mi only the variable i can change: v-j = v-j-j-j-j-j-j, where Mi-j is the composition of Mi-j and the projection operation on xj. Moreover, in Mi only the variable i can change: v-j = v-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j-j."}, {"heading": "4 Bounds for Factored Uniformization", "text": "Although we have not found a suitable way to limit the approximation error for the factorized RKF, we can derive limits similar to the BK algorithm (Boyen and Koller, 1998) for discrete stochastic processes in order to bind the error in propagation and projection through a single M-matrix. However, since the process is a mixture of processes in which only a single component changes, the BK result is not transferable for compound processes. We use this limit to bind the error of the entire Taylor expansion and thus the factorized uniformization method."}, {"heading": "4.1 Divergence Bound for Single Step", "text": "We would like to show that the KL divergence between v (= vM) and v (= v) is not greater than that between v (x) and v (xi). We start with a simple property of KL divergence and p (x) is a (not factored) distribution over the same sample space, but is a consequence of the fact that entropy does not increase with the condition that the number of all variables except xi, p (xi) and i (xi) q (xi) is a factor distribution and p (x) is a distribution over the same sample space, and x \u2212 i is the set of all variables except xi, p (xi) and i (xi) q (xi). We need a mixing rate of Boyen and Koller (1998): The mixing rate of a chastostic matrix-M is defined as such."}, {"heading": "4.2 Bound on Approximate Taylor Expansion", "text": "Our aim is not to limit the error to a single step, but rather to exponentially limit the error of our entire approach to the matrix. Equation 3 implies that the equation 3 + (1 \u2212) kDKL (1 \u2212) kDKL (1 \u2212) kDKL (1 \u2212) kDKL (1 \u2212) kDKL (1 \u2212) kDKL (1 \u2212) kDKL (1 \u2212) kDKL (1) kDKL (1 \u2212) kDKL (1 \u2212) kL (1 \u2212) kDKL (1 \u2212) kDKL (1 \u2212) kL) kDKL (1 \u2212) kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL) kL (1 \u2212 kL)."}, {"heading": "5 Adding Evidence", "text": "In a continuous time process, the evidence can assume two forms: = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "6 Experimental Results", "text": "The synthetic networks we use are the annular and toroid dynamic issuing networks with 20 binary variables by ElHay et al. (2010). The annular network is bidirectional while the toroid is directed. We set both networks on a deterrent start distribution. For the toroid, the first 5 variables are in state 0 and the remaining variables are in state 1. The initial distribution of the annular network is inversely proportional to the expected time between the switching operation. The real network we used was created from the British Household Panel Survey (BHPS)."}, {"heading": "6.1 KL-Divergence Bound", "text": "Our first experiment tested the theoretical margin of error. Figure 1 shows the KL divergence between the true marginal and the marginal, which is calculated by factorial uniformity for the BHPS network and the toroid network. The boundary between the KL divergence of the full distribution is also a boundary for each marginal, and experimentally the marginal errors grow first and then asymptomatic, as Theorem 4 shows."}, {"heading": "6.2 Approximation Comparison", "text": "We then compared our factor uniformization method (UF) with other approaches. In particular, we compared the factor uniformization method (RKFF), as explained in Section 2.1, with sparse uniformization (US), and the mid-field approach (MF) by Cohn et al. (2009) for CTBNs. For comparison purposes, the MF method was expanded to accept evidence for subsets of variables. We varied a fault tolerance parameter for each method to map the trade-off between error and runtime. For UF, we varied the uniformization-specific parameters that determine the number of intervals propagation intervals (see Sidje et al., 2007). We fixed the number of terms of expansion of the Taylor series (l) to a value that was reasonably executed. Similarly, the uniformization-specific parameters that determine the categories of the number of intervals (see) varied."}, {"heading": "7 Conclusion", "text": "Our experimental results show that the theoretically limited error persists in practice. In addition, our method offers superior time-accuracy compromises for most of the examples tested in this paper. We have shown that approximate continuous time filtering is based on uniformity, is easy to implement, and we have demonstrated limitations in terms of the clarity of its error. Approximation can be made more precise by lumping variables into one pot. Stylistically, the limits are similar to those of BK and also depend on the mixing time of each component (adapted to the continuous nature of the system). Our experimental results show that the theoretically limited error persists in practice. In addition, our method provides superior time-accuracy compromises for most of the examples tested in this work."}], "references": [{"title": "Model checking algorithms for continuous-time Markov chains", "author": ["C. Baier", "B. Haverkort", "H. Hermanns", "Katoen", "J.-P."], "venue": "IEEE Trans. on Soft. Eng., 29(6):524\u2013 541.", "citeRegEx": "Baier et al\\.,? 2003", "shortCiteRegEx": "Baier et al\\.", "year": 2003}, {"title": "Tractable inference for complex stochastic processes", "author": ["X. Boyen", "D. Koller"], "venue": "UAI, pages 33\u201342.", "citeRegEx": "Boyen and Koller,? 1998", "shortCiteRegEx": "Boyen and Koller", "year": 1998}, {"title": "Exploiting the architecture of dynamic systems", "author": ["X. Boyen", "D. Koller"], "venue": "AAAI, pages 313\u2013320.", "citeRegEx": "Boyen and Koller,? 1999", "shortCiteRegEx": "Boyen and Koller", "year": 1999}, {"title": "Mean field variational approximation for continuous-time Bayesian networks", "author": ["I. Cohn", "T. El-Hay", "R. Kupferman", "N. Friedman"], "venue": "UAI.", "citeRegEx": "Cohn et al\\.,? 2009", "shortCiteRegEx": "Cohn et al\\.", "year": 2009}, {"title": "Elements of Information Theory", "author": ["T.M. Cover", "J.A. Thomas"], "venue": "John Wiley & Sons, Inc.", "citeRegEx": "Cover and Thomas,? 1991", "shortCiteRegEx": "Cover and Thomas", "year": 1991}, {"title": "Continuous-time belief propagation", "author": ["T. El-Hay", "I. Cohn", "N. Friedman", "R. Kupferman"], "venue": "ICML, pages 343\u2013350.", "citeRegEx": "El.Hay et al\\.,? 2010", "shortCiteRegEx": "El.Hay et al\\.", "year": 2010}, {"title": "Learning continuoustime social network dynamics", "author": ["Y. Fan", "C.R. Shelton"], "venue": "UAI.", "citeRegEx": "Fan and Shelton,? 2009", "shortCiteRegEx": "Fan and Shelton", "year": 2009}, {"title": "Importance sampling for continuous time Bayesian networks", "author": ["Y. Fan", "J. Xu", "C.R. Shelton"], "venue": "JMLR, 11(Aug):2115\u20132140.", "citeRegEx": "Fan et al\\.,? 2010", "shortCiteRegEx": "Fan et al\\.", "year": 2010}, {"title": "Nineteen dubious ways to compute the exponential of a matrix, twentyfive years later", "author": ["C. Moler", "C.V. Loan"], "venue": "SIAM Review, 45(1):3\u201349.", "citeRegEx": "Moler and Loan,? 2003", "shortCiteRegEx": "Moler and Loan", "year": 2003}, {"title": "Continuous time particle filtering", "author": ["B. Ng", "A. Pfeffer", "R. Dearden"], "venue": "IJCAI, pages 1360\u20131365.", "citeRegEx": "Ng et al\\.,? 2005", "shortCiteRegEx": "Ng et al\\.", "year": 2005}, {"title": "Continuous time Bayesian networks", "author": ["U. Nodelman", "C.R. Shelton", "D. Koller"], "venue": "UAI, pages 378\u2013387.", "citeRegEx": "Nodelman et al\\.,? 2002", "shortCiteRegEx": "Nodelman et al\\.", "year": 2002}, {"title": "Expectation maximization and complex duration distributions for continuous time Bayesian networks", "author": ["U. Nodelman", "C.R. Shelton", "D. Koller"], "venue": "UAI, pages 421\u2013430.", "citeRegEx": "Nodelman et al\\.,? 2005", "shortCiteRegEx": "Nodelman et al\\.", "year": 2005}, {"title": "Kommunikation mit Automaten", "author": ["C.A. Petri"], "venue": "PhD thesis, University of Bonn.", "citeRegEx": "Petri,? 1962", "shortCiteRegEx": "Petri", "year": 1962}, {"title": "A GSPN semantics for continuous time Bayesian networks with immediate nodes", "author": ["D.C. Raiteri", "L. Portinale"], "venue": "Technical Report TR-INF-2009-03-03-UNIPMN, U. of Piemonte Orientale CS Dept.", "citeRegEx": "Raiteri and Portinale,? 2009", "shortCiteRegEx": "Raiteri and Portinale", "year": 2009}, {"title": "Inexact uniformization method for computing transient distributions of Markov chains", "author": ["R.B. Sidje", "K. Burrage", "S. MacNamara"], "venue": "SIAM Journal of Scientific Computation, 29(6):2562\u20132580.", "citeRegEx": "Sidje et al\\.,? 2007", "shortCiteRegEx": "Sidje et al\\.", "year": 2007}, {"title": "Probabilistic inference in queueing networks", "author": ["C.A. Sutton", "M.I. Jordan"], "venue": "SysML.", "citeRegEx": "Sutton and Jordan,? 2008", "shortCiteRegEx": "Sutton and Jordan", "year": 2008}, {"title": "Approximate steady-state analysis of large Markov models based on the structure of their decision diagram encoding", "author": ["M. Wan", "G. Ciardo", "A.S. Miner"], "venue": "Performance Evaluation, 68(5):463\u2013486.", "citeRegEx": "Wan et al\\.,? 2011", "shortCiteRegEx": "Wan et al\\.", "year": 2011}, {"title": "Intrusion detection using continuous time Bayesian networks", "author": ["J. Xu", "C.R. Shelton"], "venue": "JAIR, 39:745\u2013774.", "citeRegEx": "Xu and Shelton,? 2010", "shortCiteRegEx": "Xu and Shelton", "year": 2010}], "referenceMentions": [{"referenceID": 10, "context": "By contrast, the continuous time Bayesian network (Nodelman et al., 2002) literature has focused on finite-time properties, so we compare against those algorithms.", "startOffset": 50, "endOffset": 73}, {"referenceID": 13, "context": "A singular exception is the work of Sutton and Jordan (2008) which applied Gibbs sampling to queueing models.", "startOffset": 36, "endOffset": 61}, {"referenceID": 0, "context": "In verification, continuous-time models can be used to compute the probability a system will function by a given time, such as in continuous stochastic logic (Baier et al., 2003).", "startOffset": 158, "endOffset": 178}, {"referenceID": 17, "context": "Other problems of interest include state estimation in asynchronous systems, such as distributed computer systems (Xu and Shelton, 2010), robotics (Ng et al.", "startOffset": 114, "endOffset": 136}, {"referenceID": 9, "context": "Other problems of interest include state estimation in asynchronous systems, such as distributed computer systems (Xu and Shelton, 2010), robotics (Ng et al., 2005), social networks (Fan and Shelton, 2009), or phylogenetic trees (Cohn et al.", "startOffset": 147, "endOffset": 164}, {"referenceID": 6, "context": ", 2005), social networks (Fan and Shelton, 2009), or phylogenetic trees (Cohn et al.", "startOffset": 25, "endOffset": 48}, {"referenceID": 3, "context": ", 2005), social networks (Fan and Shelton, 2009), or phylogenetic trees (Cohn et al., 2009).", "startOffset": 72, "endOffset": 91}, {"referenceID": 14, "context": "Previous results have looked at sparse representations of p and p\u2032 (Sidje et al., 2007).", "startOffset": 67, "endOffset": 87}, {"referenceID": 14, "context": "In the case for uniformization, Sidje et al. (2007) proposed keeping a sparse representation for v (by dropping elements less than a given threshold).", "startOffset": 32, "endOffset": 52}, {"referenceID": 12, "context": "While our methods are applicable to Petri nets (Petri, 1962), edge-valued decision diagrams (Wan et al.", "startOffset": 47, "endOffset": 60}, {"referenceID": 16, "context": "While our methods are applicable to Petri nets (Petri, 1962), edge-valued decision diagrams (Wan et al., 2011), and other compact representation of the rate matrix, we focus on using a continuous time Bayesian network (CTBN) to representQ.", "startOffset": 92, "endOffset": 110}, {"referenceID": 13, "context": "We note that a correspondence between CTBNs and Petri nets has already been established (Raiteri and Portinale, 2009).", "startOffset": 88, "endOffset": 117}, {"referenceID": 10, "context": "A continuous time Bayesian network (CTBN) (Nodelman et al., 2002) has an initial distribution described by a Bayesian network that is not of direct importance to this work.", "startOffset": 42, "endOffset": 65}, {"referenceID": 1, "context": "While we have not found a suitable way of bounding the approximation error for factored RKF, we can derive bounds similar to those of the BK algorithm (Boyen and Koller, 1998) for discrete-time stochastic processes to bound the error in propagation and projection through a single M matrix.", "startOffset": 151, "endOffset": 175}, {"referenceID": 1, "context": "We require a mixing rate definition from Boyen and Koller (1998):", "startOffset": 41, "endOffset": 65}, {"referenceID": 1, "context": "As shown by Boyen and Koller (1999), better bounds can be placed by more careful analysis or considering the average case.", "startOffset": 12, "endOffset": 36}, {"referenceID": 11, "context": "The structure and parameters of both the initial distribution and the dynamics were learned by the structural EM algorithm (Nodelman et al., 2005) and we used the learned network model for our experiments.", "startOffset": 123, "endOffset": 146}, {"referenceID": 7, "context": "We use the same network model as in Fan et al. (2010) and Nodelman et al.", "startOffset": 36, "endOffset": 54}, {"referenceID": 7, "context": "We use the same network model as in Fan et al. (2010) and Nodelman et al. (2005) which chooses 4 variables: employment (student, employed, unemployed), children (0, 1,\u22652), married (not married, married) and smoking (non-smoker, smoker) and adds a hidden binary variable for each (Figure 1a).", "startOffset": 36, "endOffset": 81}, {"referenceID": 3, "context": "1, sparse uniformization (US), and the mean field (MF) approach of Cohn et al. (2009) for CTBNs.", "startOffset": 67, "endOffset": 86}], "year": 2011, "abstractText": "We consider filtering for a continuous-time, or asynchronous, stochastic system where the full distribution over states is too large to be stored or calculated. We assume that the rate matrix of the system can be compactly represented and that the belief distribution is to be approximated as a product of marginals. The essential computation is the matrix exponential. We look at two different methods for its computation: ODE integration and uniformization of the Taylor expansion. For both we consider approximations in which only a factored belief state is maintained. For factored uniformization we demonstrate that the KL-divergence of the filtering is bounded. Our experimental results confirm our factored uniformization performs better than previously suggested uniformization methods and the mean field algorithm. 1 Continuous-Time Markov Systems We are interested in monitoring (alternatively tracking or filtering) a continuous-time finite-state homogeneous Markovian stochastic system. This implies that evidence and events can arrive at any real-valued time (asynchronously) and be either instantaneous or have real-valued time durations. The system is stationary and has discrete states which means that a sample (trajectory) for the system consists of a series of times at which the system jumped from one state to another. Such models are common in the queueing theory and verification literatures. The algorithms developed there almost exclusively focus on steady-state properties of the system. A singular exception is the work of Sutton and Jordan (2008) which applied Gibbs sampling to queueing models. By contrast, the continuous time Bayesian network (Nodelman et al., 2002) literature has focused on finite-time properties, so we compare against those algorithms. In verification, continuous-time models can be used to compute the probability a system will function by a given time, such as in continuous stochastic logic (Baier et al., 2003). Other problems of interest include state estimation in asynchronous systems, such as distributed computer systems (Xu and Shelton, 2010), robotics (Ng et al., 2005), social networks (Fan and Shelton, 2009), or phylogenetic trees (Cohn et al., 2009). 1.1 Parameterization Such a Markovian system is described by an initial distribution over the state space and an intensity (or rate) matrix, often denoted Q. The diagonal element qii = \u2212qi where qi \u2265 0 is the rate of leaving state i. This means that the density of the duration of the process remaining in state i for exactly a duration \u2206t is an exponential distribution: qiei. The non-diagonal elements, qij \u2265 0 are the rates of transitioning from state i to state j. qi = \u2211 j qij in a closed system. (The rate of leaving a state is equal to the sum of the rates of moving to any other state.) The probability of transitioning to state j immediately upon leaving state i is qij/qi. Note that the diagonal elements of Q are non-positive and the non-diagonal elements are non-negative. The sum of each row is 0. Monitoring such a system consists of keeping track of the probability distribution over the state at the current time t, given all evidence prior to t. We would like a recursive solution in which evidence before t can be discarded once the distribution (or its estimate) at t has been computed. As an initial problem, we will be interested in tracking in the absence of any evidence. We will cover how to incorporate evidence in Section 5. To simplify notation, we will assume that we have the distribution at time 0 and wish to propagate this distribution to time t. If p is the distribution at time 0, represented as a row vector, then p\u2032, the distribution at t also represented as a row vector, is", "creator": "TeX"}}}