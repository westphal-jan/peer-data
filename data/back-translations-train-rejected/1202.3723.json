{"id": "1202.3723", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2012", "title": "Approximation by Quantization", "abstract": "Inference in graphical models consists of repeatedly multiplying and summing out potentials. It is generally intractable because the derived potentials obtained in this way can be exponentially large. Approximate inference techniques such as belief propagation and variational methods combat this by simplifying the derived potentials, typically by dropping variables from them. We propose an alternate method for simplifying potentials: quantizing their values. Quantization causes different states of a potential to have the same value, and therefore introduces context-specific independencies that can be exploited to represent the potential more compactly. We use algebraic decision diagrams (ADDs) to do this efficiently. We apply quantization and ADD reduction to variable elimination and junction tree propagation, yielding a family of bounded approximate inference schemes. Our experimental tests show that our new schemes significantly outperform state-of-the-art approaches on many benchmark instances.", "histories": [["v1", "Tue, 14 Feb 2012 16:41:17 GMT  (149kb)", "http://arxiv.org/abs/1202.3723v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["vibhav gogate", "pedro domingos"], "accepted": false, "id": "1202.3723"}, "pdf": {"name": "1202.3723.pdf", "metadata": {"source": "CRF", "title": "Approximation by Quantization", "authors": ["Vibhav Gogate"], "emails": ["vgogate@cs.washington.edu", "pedrod@cs.washington.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "2 PRELIMINARIES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 MARKOV NETWORKS", "text": "For the sake of simplicity, we will focus on Markov networks defined by bi-weighted variables. Our approach is easily applicable1 The only exception we know of is the recent work of (Lowd and Domingos, 2010), which compiled an arithmetic circuit from dependent samples generated from the posterior distribution (which are structural representations similar to ADDs).Our approach is very different and empirically seems to yield much greater accelerations (although to date there is no direct comparison in the same areas, because a conversion of the low and domingos schemas is not available).on multi-value variables and other graphical models such as the Bayesian networks and the Markov logic (Domingos and Lowd, 2009).Let us leave X = {X1,., Xn} a series of biweighted (Boolean) variables that define the values from the domain {0, 1} (True, or False,} Markov logic (M = 1), with the pair M = 1."}, {"heading": "2.2 ALGEBRAIC DECISION DIAGRAMS", "text": "An algebraic decision diagram (ADD) is an efficient graph representation of a real ADD function. It is a directed acyclic graph (DAG) in which each leaf node is labeled with a real value and each non-leaf decision node is labeled with a variable. However, each decision node has two outgoing slurs corresponding to the true and false assignment of the corresponding variable. ADDs impose a strict variable arrangement from root to leaf node and impose the following three constraints on the DAG: (i) no two slurs emanating from a decision node can point to the same node, (ii) if two decision nodes have the same variable label, then they (both) cannot label the same true child node and the same false child node, and (iii) no two leaf nodes with the same real value."}, {"heading": "3 QUANTIZATION", "text": "Quantization is the process of replacing a range of real numbers with a single number. Formally, a quantization function designated by Q is much less than Q, a multiplicity-to-one mapping from a set of T to a series of Q of real numbers, which is unfortunately a real error, and Q is a series of real numbers, and Q is a quantization function from R (F) to Q. We say that a function FQ is a quantization of F w.r.t. Q is when FQ is constructed by F by replacing each value w in the range of F with Q (w). Quantization can decrease the size of the ADD of a function, but it will never increase it. Formally, FQ will quantize F w.r.t. Q. Then, the ADD of FQ is less than or equal to the ADD of F. Figure 2 is the effect of quantization on the size of the ADD (b)."}, {"heading": "4 APPROXIMATION BY QUANTIZATION", "text": "In this section, we apply quantization and ADD reduction to two standard inference algorithms: (i) Bucket or Variable Elimination (Dechter, 1999) and (ii) Junction Tree Propagation (Lauritzen and Mirrors, 1988). Applying quantization and ADD reduction to the former yields a one-pass algorithm for calculating the partition function similar to minibucket elimination (Dechter and Rish, 2003), and applying it to the latter yields an iterative algorithm that can calculate the posterior boundary distribution for each variable, similar to the expectation propagation (Minka, 2001)."}, {"heading": "4.1 ONE-PASS APPROXIMATION BY QUANTIZATION (ABQ)", "text": "In fact, it is the case that it is a matter of a way in which people are able to determine for themselves what they want and what they want. (...) In fact, it is the case that people are able to decide what they want and what they do not want. (...) It is as if they are able to decide. (...) It is as if they are able to decide what they want. (...) It is as if they do not want it. (...) It is as if they do not want it. (...) It is as if they do not want it. (...) \"We do not want it.\" (...) \"We do not want it.\" (...) \"We do not want it.\" We do not want it. \"(...) We do not want it.\" We do not want it. \"(...) We do not want it.\" We do not want it. \""}, {"heading": "4.2 ITERATIVE APPROXIMATION BY QUANTIZATION (IABQ)", "text": "In this section we will show how to approach the node tree algorithm (Lauritzen und Spiegelhalter, 1988) with quantization and ADD reduction. The node tree algorithm is an algorithm of message delivery via a modified graph called the node tree, which is achieved by clustering variables from a Markov network until the network becomes a tree. Also, the clusters are called cliques. Each clique is associated with a subset of potentials, so that the extent of each potential is covered by the variables in the cliques. Message transmission works as follows: First, we designate an arbitrary cluster as root and send messages in two passes: from the leaves to the root (inwards) and then from the root to the leaves (outwards). The message that a clique is sending to its neighbors v is constructed as follows."}, {"heading": "5 EXPERIMENTS", "text": "In this section we compare the performance of ABQ and IABQ with other algorithms from the literature. We also evaluate the impact of different quantization euristics on accuracy. We experimented with examples from four benchmark areas: (i) logistics planning (Sang et al., 2005), (ii) linear block coding, (iii) Promeda's Bayesian medical diagnostic networks (Wemmenhove et al., 2007) and (iv) output models. We implemented our algorithms in C + +. We conducted our experiments on a Linux machine with a 2.33 GHz Intel Xeon quad-core processor and 16 GB of RAM. We gave each algorithm a memory limit of 2GB and (unless otherwise specified) a time limit of 2 hours. We used the CUDD package (Somenzi, 1998) to implement ADDs."}, {"heading": "5.1 EXPERIMENTS EVALUATING THE BOUNDING POWER OF ABQ", "text": "This year, it has reached the point where it will be able to leave the country in which it is able to leave it, and it is able to occupy it."}, {"heading": "5.2 EXPERIMENTS EVALUATING THE QUANTIZATION HEURISTICS", "text": "In this subsection, we evaluate the performance of the three quantization heuristics described in Section 3. Table 2 shows the results. We see that the minimum error heuristics generally perform the best. Minimum error heuristics are only slightly inferior to the minimum error heuristics. Minimum error heuristics are inferior to the minimum error heuristics, except for the promedas networks. Promedas networks have many similar probability values (approximately context-specific independence), which the minimum error heuristics exploits quite effectively. On the other hand, the issuing models represent the worst case scenario for minimum error heuristics, because the intermediate potentials generated during the execution of ABQs have almost no similar probability values."}, {"heading": "5.3 EXPERIMENTS EVALUATING THE ACCURACY OF IABQ", "text": "We compare IABQ with Iterative Join Graph Propagation (IJGP) (Mateescu et al., 2010), a state-of-the-art generalized belief propagation scheme (IJGP won 2 of the 3 marginal estimate categories in the 2010 UAI Approximate Assessment Challenge (Elidan and Globerson, 2010)). As a starting point, we compare Gibbs Sampling (Geman and Geman, 1984) with both IJGP and IABQ as always available algorithms. Both algorithms take a size parameter as an input size that determines their complexity, varying this parameter from its lowest possible value and gradually increasing it until the algorithm runs out of memory or time."}, {"heading": "6 CONCLUSION", "text": "The most difficult problem with approximate conclusions is how to solve a large function that cannot be performed mathematically by a collection of tractable functions by quantization. Quantification replaces a number of values in the range of a function by a single value, thus introducing artificially context-specific independence. Conventional tabular representations of functions are insufficient when using this structure. We therefore proposed to use structured representations such as algebraic decision diagrams (ADDs). We showed how quantification can be applied to two standard algorithms in probabilistic inference, variable elimination, and the propagation of crossing trees, resulting in two new schemes: (i) A one-pass algorithm that can be used to approximate and limit the partition function, and (ii) An iterative algorithm that can be used to determine nultraperior margins is the quantification of ONA-FAU algorithms that can be used to approximate A-FAU algorithms."}], "references": [{"title": "Algebraic decision diagrams and their applications", "author": ["R. Bahar", "E. Frohm", "C. Gaona", "G. Hachtel", "E. Macii", "A. Pardo", "F. Somenzi"], "venue": "ICCAD, pages 188\u2013191.", "citeRegEx": "Bahar et al\\.,? 1993", "shortCiteRegEx": "Bahar et al\\.", "year": 1993}, {"title": "Context-specific independence in Bayesian networks", "author": ["C. Boutilier", "N. Friedman", "M. Goldszmidt", "D. Koller"], "venue": "UAI, pages 115\u2013123.", "citeRegEx": "Boutilier et al\\.,? 1996", "shortCiteRegEx": "Boutilier et al\\.", "year": 1996}, {"title": "Compiling bayesian networks using variable elimination", "author": ["M. Chavira", "A. Darwiche"], "venue": "IJCAI, pages 2443\u20132449.", "citeRegEx": "Chavira and Darwiche,? 2007", "shortCiteRegEx": "Chavira and Darwiche", "year": 2007}, {"title": "On probabilistic inference by weighted model counting", "author": ["M. Chavira", "A. Darwiche"], "venue": "Arti. Intell., 172(6-7):772\u2013799.", "citeRegEx": "Chavira and Darwiche,? 2008", "shortCiteRegEx": "Chavira and Darwiche", "year": 2008}, {"title": "A differential approach to inference in Bayesian networks", "author": ["A. Darwiche"], "venue": "JACM, 50(3):280\u2013305.", "citeRegEx": "Darwiche,? 2003", "shortCiteRegEx": "Darwiche", "year": 2003}, {"title": "Results from the Probablistic Inference Evaluation of UAI\u201908", "author": ["A. Darwiche", "R. Dechter", "A. Choi", "V. Gogate", "L. Otten"], "venue": "Available online at: http://graphmod.ics.uci.edu/uai08/Evaluation/Report.", "citeRegEx": "Darwiche et al\\.,? 2008", "shortCiteRegEx": "Darwiche et al\\.", "year": 2008}, {"title": "Bucket elimination: A unifying framework for reasoning", "author": ["R. Dechter"], "venue": "Arti. Intell., 113(1-2):41\u201385.", "citeRegEx": "Dechter,? 1999", "shortCiteRegEx": "Dechter", "year": 1999}, {"title": "Mini-buckets: A general scheme for bounded inference", "author": ["R. Dechter", "I. Rish"], "venue": "JACM, 50(2):107\u2013153.", "citeRegEx": "Dechter and Rish,? 2003", "shortCiteRegEx": "Dechter and Rish", "year": 2003}, {"title": "Markov Logic: An Interface Layer for Artificial Intelligence", "author": ["P. Domingos", "D. Lowd"], "venue": "Morgan and Claypool.", "citeRegEx": "Domingos and Lowd,? 2009", "shortCiteRegEx": "Domingos and Lowd", "year": 2009}, {"title": "The 2010 UAI approximate inference challenge", "author": ["G. Elidan", "A. Globerson"], "venue": "Available online at: http://www.cs.huji.ac.il/project/UAI10/index.php", "citeRegEx": "Elidan and Globerson,? 2010", "shortCiteRegEx": "Elidan and Globerson", "year": 2010}, {"title": "Stochastic relaxations, Gibbs distributions and the Bayesian restoration of images", "author": ["S. Geman", "D. Geman"], "venue": "IEEE Transaction on Pattern analysis and Machine Intelligence, 6(6):721\u2013742.", "citeRegEx": "Geman and Geman,? 1984", "shortCiteRegEx": "Geman and Geman", "year": 1984}, {"title": "Formula-based probabilistic inference", "author": ["V. Gogate", "P. Domingos"], "venue": "UAI, pages 210\u2013219.", "citeRegEx": "Gogate and Domingos,? 2010", "shortCiteRegEx": "Gogate and Domingos", "year": 2010}, {"title": "Mini-bucket heuristics for improved search", "author": ["K. Kask", "R. Dechter"], "venue": "UAI, pages 314\u2013323.", "citeRegEx": "Kask and Dechter,? 1999", "shortCiteRegEx": "Kask and Dechter", "year": 1999}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "Koller and Friedman.,? \\Q2009\\E", "shortCiteRegEx": "Koller and Friedman.", "year": 2009}, {"title": "Bayesian inference in presence of determinism", "author": ["D. Larkin", "R. Dechter"], "venue": "AISTATS.", "citeRegEx": "Larkin and Dechter,? 2003", "shortCiteRegEx": "Larkin and Dechter", "year": 2003}, {"title": "Local computation with probabilities on graphical structures and their application to expert systems", "author": ["S. Lauritzen", "D. Spiegelhalter"], "venue": "Journal of the Royal Statistical Society, Series B, 50(2):157\u2013224.", "citeRegEx": "Lauritzen and Spiegelhalter,? 1988", "shortCiteRegEx": "Lauritzen and Spiegelhalter", "year": 1988}, {"title": "Approximate inference by compilation to arithmetic circuits", "author": ["D. Lowd", "P. Domingos"], "venue": "NIPS, pages 1477\u20131485.", "citeRegEx": "Lowd and Domingos,? 2010", "shortCiteRegEx": "Lowd and Domingos", "year": 2010}, {"title": "AND/OR multi-valued decision diagrams (AOMDDs) for graphical models", "author": ["R. Mateescu", "R. Dechter", "Marinescu"], "venue": null, "citeRegEx": "Mateescu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mateescu et al\\.", "year": 2008}, {"title": "Joingraph propagation algorithms", "author": ["R. Mateescu", "K. Kask", "V. Gogate", "R. Dechter"], "venue": "JAIR, 37:279\u2013328.", "citeRegEx": "Mateescu et al\\.,? 2010", "shortCiteRegEx": "Mateescu et al\\.", "year": 2010}, {"title": "Expectation Propagation for approximate Bayesian inference", "author": ["T. Minka"], "venue": "UAI, pages 362\u2013369.", "citeRegEx": "Minka,? 2001", "shortCiteRegEx": "Minka", "year": 2001}, {"title": "Bounds on marginal probability distributions", "author": ["J.M. Mooij", "H.J. Kappen"], "venue": "NIPS, pages 1105\u20131112.", "citeRegEx": "Mooij and Kappen,? 2008", "shortCiteRegEx": "Mooij and Kappen", "year": 2008}, {"title": "Loopy belief propagation for approximate inference: An empirical study", "author": ["K.P. Murphy", "Y. Weiss", "M.I. Jordan"], "venue": "UAI, pages 467\u2013475.", "citeRegEx": "Murphy et al\\.,? 1999", "shortCiteRegEx": "Murphy et al\\.", "year": 1999}, {"title": "Exploiting contextual independence in probabilistic inference", "author": ["D. Poole", "N. Zhang"], "venue": "JAIR, 18:263\u2013313.", "citeRegEx": "Poole and Zhang,? 2003", "shortCiteRegEx": "Poole and Zhang", "year": 2003}, {"title": "New mini-bucket partitioning heuristics for bounding the probability of evidence", "author": ["E. Rollon", "R. Dechter"], "venue": "AAAI, pages 1199\u20131204.", "citeRegEx": "Rollon and Dechter,? 2010", "shortCiteRegEx": "Rollon and Dechter", "year": 2010}, {"title": "Heuristics for fast exact model counting", "author": ["T. Sang", "P. Beame", "H. Kautz"], "venue": "SAT, pages 226\u2013240.", "citeRegEx": "Sang et al\\.,? 2005", "shortCiteRegEx": "Sang et al\\.", "year": 2005}, {"title": "Probabilistic diagnosis using a reformulation of the internist- 1/qmr knowledge base i", "author": ["M. Shwe", "B. Middleton", "D. Heckerman", "M. Henrion", "E. Horvitz", "H. Lehmann", "G. Cooper."], "venue": "the probabilistic model and inference algorithms. Methods of Information in Medicine, 30:241\u2013255.", "citeRegEx": "Shwe et al\\.,? 1991", "shortCiteRegEx": "Shwe et al\\.", "year": 1991}, {"title": "Cudd: CU decision diagram package release", "author": ["F. Somenzi"], "venue": null, "citeRegEx": "Somenzi,? \\Q1998\\E", "shortCiteRegEx": "Somenzi", "year": 1998}, {"title": "Tree-reweighted belief propagation algorithms and approximate ml estimation by pseudo-moment matching", "author": ["M.J. Wainwright", "T.S. Jaakkola", "A.S. Willsky"], "venue": "AISTATS.", "citeRegEx": "Wainwright et al\\.,? 2003", "shortCiteRegEx": "Wainwright et al\\.", "year": 2003}, {"title": "Inference in the promedas medical expert system", "author": ["B. Wemmenhove", "J. Mooij", "W. Wiegerinck", "M. Leisink", "H. Kappen", "J. Neijt"], "venue": "AI in Medicine, volume 4594, pages 456\u2013460.", "citeRegEx": "Wemmenhove et al\\.,? 2007", "shortCiteRegEx": "Wemmenhove et al\\.", "year": 2007}, {"title": "Optimal quantization by matrix searching", "author": ["X. Wu"], "venue": "Journal of Algorithms 12(4):663\u2013673.", "citeRegEx": "Wu,? 1991", "shortCiteRegEx": "Wu", "year": 1991}, {"title": "A generalized mean field algorithm for variational inference in exponential families", "author": ["E. Xing", "M. Jordan", "S. Russell"], "venue": "UAI, pages 583\u2013591.", "citeRegEx": "Xing et al\\.,? 2003", "shortCiteRegEx": "Xing et al\\.", "year": 2003}, {"title": "Constructing free energy approximations and generalized belief propagation algorithms", "author": ["J.S. Yedidia", "W.T. Freeman", "Y. Weiss"], "venue": "IEEE Transactions on Information Theory, 51:2282\u20132312.", "citeRegEx": "Yedidia et al\\.,? 2004", "shortCiteRegEx": "Yedidia et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 7, "context": "Many widely used approximate inference algorithms such as mini-bucket elimination (Dechter and Rish, 2003) and the generalized mean-field algorithm (Xing et al.", "startOffset": 82, "endOffset": 106}, {"referenceID": 30, "context": "Many widely used approximate inference algorithms such as mini-bucket elimination (Dechter and Rish, 2003) and the generalized mean-field algorithm (Xing et al., 2003) are essentially scope-based approximations.", "startOffset": 148, "endOffset": 167}, {"referenceID": 22, "context": "Many structured representations have been proposed in literature such as confactors (Poole and Zhang, 2003), sparse representations (Larkin and Dechter, 2003), algebraic decision diagrams (ADDs) (Chavira and Darwiche, 2007), arithmetic circuits (Darwiche, 2003), AND/OR multi-valued decision diagrams (Mateescu et al.", "startOffset": 84, "endOffset": 107}, {"referenceID": 14, "context": "Many structured representations have been proposed in literature such as confactors (Poole and Zhang, 2003), sparse representations (Larkin and Dechter, 2003), algebraic decision diagrams (ADDs) (Chavira and Darwiche, 2007), arithmetic circuits (Darwiche, 2003), AND/OR multi-valued decision diagrams (Mateescu et al.", "startOffset": 132, "endOffset": 158}, {"referenceID": 2, "context": "Many structured representations have been proposed in literature such as confactors (Poole and Zhang, 2003), sparse representations (Larkin and Dechter, 2003), algebraic decision diagrams (ADDs) (Chavira and Darwiche, 2007), arithmetic circuits (Darwiche, 2003), AND/OR multi-valued decision diagrams (Mateescu et al.", "startOffset": 195, "endOffset": 223}, {"referenceID": 4, "context": "Many structured representations have been proposed in literature such as confactors (Poole and Zhang, 2003), sparse representations (Larkin and Dechter, 2003), algebraic decision diagrams (ADDs) (Chavira and Darwiche, 2007), arithmetic circuits (Darwiche, 2003), AND/OR multi-valued decision diagrams (Mateescu et al.", "startOffset": 245, "endOffset": 261}, {"referenceID": 17, "context": "Many structured representations have been proposed in literature such as confactors (Poole and Zhang, 2003), sparse representations (Larkin and Dechter, 2003), algebraic decision diagrams (ADDs) (Chavira and Darwiche, 2007), arithmetic circuits (Darwiche, 2003), AND/OR multi-valued decision diagrams (Mateescu et al., 2008) and formula-based representations (Gogate and Domingos, 2010).", "startOffset": 301, "endOffset": 324}, {"referenceID": 11, "context": ", 2008) and formula-based representations (Gogate and Domingos, 2010).", "startOffset": 42, "endOffset": 69}, {"referenceID": 0, "context": "Although one can use any of these structured representations or combinations to compactly represent a quantized function, in this paper we propose to use ADDs (Bahar et al., 1993).", "startOffset": 159, "endOffset": 179}, {"referenceID": 0, "context": "Although one can use any of these structured representations or combinations to compactly represent a quantized function, in this paper we propose to use ADDs (Bahar et al., 1993). ADDs are canonical representations of functions, and have many efficient manipulation algorithms. In particular, all inference operations: multiplication, maximization, and elimination can be efficiently implemented using standard ADD operations. Another advantage of ADDs is that there is a large literature on them. This has led to the wide availability of many efficient open source software implementations (e.g., CUDD Somenzi (1998)), which can be leveraged to efficiently and quickly implement the ideas presented in this paper.", "startOffset": 160, "endOffset": 619}, {"referenceID": 6, "context": "In this paper, we apply it to two standard algorithms: bucket (or variable) elimination (Dechter, 1999) and the junction tree algorithm (Lauritzen and Spiegelhalter, 1988), yielding approximate, anytime and coarse-to-fine versions of these schemes.", "startOffset": 88, "endOffset": 103}, {"referenceID": 15, "context": "In this paper, we apply it to two standard algorithms: bucket (or variable) elimination (Dechter, 1999) and the junction tree algorithm (Lauritzen and Spiegelhalter, 1988), yielding approximate, anytime and coarse-to-fine versions of these schemes.", "startOffset": 136, "endOffset": 171}, {"referenceID": 7, "context": "Just like mini-bucket elimination (Dechter and Rish, 2003) and related iterative algorithms such as expectation propagation (Minka, 2001) and generalized belief propagation (Yedidia et al.", "startOffset": 34, "endOffset": 58}, {"referenceID": 19, "context": "Just like mini-bucket elimination (Dechter and Rish, 2003) and related iterative algorithms such as expectation propagation (Minka, 2001) and generalized belief propagation (Yedidia et al.", "startOffset": 124, "endOffset": 137}, {"referenceID": 31, "context": "Just like mini-bucket elimination (Dechter and Rish, 2003) and related iterative algorithms such as expectation propagation (Minka, 2001) and generalized belief propagation (Yedidia et al., 2004), one can view our new schemes as running exact inference on a simplified version of the graphical model.", "startOffset": 173, "endOffset": 195}, {"referenceID": 3, "context": "1 However, treewidth is an overly strong condition for determining feasibility of exact inference (Chavira and Darwiche, 2008).", "startOffset": 98, "endOffset": 126}, {"referenceID": 2, "context": "For example, algorithms such as ADD-VE (Chavira and Darwiche, 2007) and formula decomposition and conditioning (Gogate and Domingos, 2010) can solve problems having large treewidth by taking advantage of context-specific independence (or identical potential values) (Boutilier et al.", "startOffset": 39, "endOffset": 67}, {"referenceID": 11, "context": "For example, algorithms such as ADD-VE (Chavira and Darwiche, 2007) and formula decomposition and conditioning (Gogate and Domingos, 2010) can solve problems having large treewidth by taking advantage of context-specific independence (or identical potential values) (Boutilier et al.", "startOffset": 111, "endOffset": 138}, {"referenceID": 1, "context": "For example, algorithms such as ADD-VE (Chavira and Darwiche, 2007) and formula decomposition and conditioning (Gogate and Domingos, 2010) can solve problems having large treewidth by taking advantage of context-specific independence (or identical potential values) (Boutilier et al., 1996) and determinism.", "startOffset": 266, "endOffset": 290}, {"referenceID": 16, "context": "The only exception we are aware of is the recent work of (Lowd and Domingos, 2010), who compile an arithmetic circuit (which are structured representations similar to ADDs) from dependent samples generated from the posterior distribution.", "startOffset": 57, "endOffset": 82}, {"referenceID": 8, "context": "to multi-valued variables, and other graphical models such as Bayesian networks and Markov logic (Domingos and Lowd, 2009).", "startOffset": 97, "endOffset": 122}, {"referenceID": 0, "context": "An unreduced ADD can be reduced by merging isomorphic subgraphs and eliminating any nodes whose two children are isomorphic (for details, see Bahar et al. (1993)).", "startOffset": 142, "endOffset": 162}, {"referenceID": 29, "context": "This problem can be solved in O(lt) time using dynamic programming and matrix searching (see Wu (1991) for details).", "startOffset": 93, "endOffset": 103}, {"referenceID": 6, "context": "In this section, we apply quantization and ADD reduction to two standard inference algorithms: (i) bucket or variable elimination (Dechter, 1999), and (ii) junction tree propagation (Lauritzen and Spiegelhalter, 1988).", "startOffset": 130, "endOffset": 145}, {"referenceID": 15, "context": "In this section, we apply quantization and ADD reduction to two standard inference algorithms: (i) bucket or variable elimination (Dechter, 1999), and (ii) junction tree propagation (Lauritzen and Spiegelhalter, 1988).", "startOffset": 182, "endOffset": 217}, {"referenceID": 7, "context": "Applying quantization and ADD reduction to the former yields a one-pass algorithm for computing the partition function similar to mini-bucket elimination (Dechter and Rish, 2003), and applying it to the latter yields an iterative algorithm that can compute posterior marginal distribution at each variable, similar to expectation propagation (Minka, 2001).", "startOffset": 154, "endOffset": 178}, {"referenceID": 19, "context": "Applying quantization and ADD reduction to the former yields a one-pass algorithm for computing the partition function similar to mini-bucket elimination (Dechter and Rish, 2003), and applying it to the latter yields an iterative algorithm that can compute posterior marginal distribution at each variable, similar to expectation propagation (Minka, 2001).", "startOffset": 342, "endOffset": 355}, {"referenceID": 6, "context": "Bucket elimination (BE) (Dechter, 1999) is an exact algorithm for computing the partition function.", "startOffset": 24, "endOffset": 39}, {"referenceID": 2, "context": "It can be easily extended to use ADDs yielding the ADD-BE algorithm, first presented in (Chavira and Darwiche, 2007).", "startOffset": 88, "endOffset": 116}, {"referenceID": 2, "context": "Note that when k = \u221e the algorithm runs full bucket elimination and is equivalent to the ADD-BE algorithm of (Chavira and Darwiche, 2007).", "startOffset": 109, "endOffset": 137}, {"referenceID": 15, "context": "In this section, we will show how to approximate the junction tree algorithm (Lauritzen and Spiegelhalter, 1988) using quantization and ADD reduction.", "startOffset": 77, "endOffset": 112}, {"referenceID": 18, "context": "IABQ belongs to the class of sum-product expectation propagation (EP) algorithms (see Minka (2001) and Koller and Friedman (2009), Chapter 11) which perform inference by sending approximate messages.", "startOffset": 86, "endOffset": 99}, {"referenceID": 13, "context": "IABQ belongs to the class of sum-product expectation propagation (EP) algorithms (see Minka (2001) and Koller and Friedman (2009), Chapter 11) which perform inference by sending approximate messages.", "startOffset": 103, "endOffset": 130}, {"referenceID": 24, "context": "We experimented with instances from four benchmark domains: (i) logistics planning (Sang et al., 2005), (ii) linear block coding, (iii) Promedas Bayesian networks for medical diagnosis (Wemmenhove et al.", "startOffset": 83, "endOffset": 102}, {"referenceID": 28, "context": ", 2005), (ii) linear block coding, (iii) Promedas Bayesian networks for medical diagnosis (Wemmenhove et al., 2007) and (iv) Ising models.", "startOffset": 90, "endOffset": 115}, {"referenceID": 26, "context": "We used the CUDD package (Somenzi, 1998) to implement ADDs.", "startOffset": 25, "endOffset": 40}, {"referenceID": 7, "context": "To allow some comparison on large, hard instances, we evaluate the upper bounding power of ABQ, and compare it with three algorithms from literature: mini-bucket elimination (MBE) (Dechter and Rish, 2003; Rollon and Dechter, 2010), Treereweighted Belief Propagation (TRW) (Wainwright et al.", "startOffset": 180, "endOffset": 230}, {"referenceID": 23, "context": "To allow some comparison on large, hard instances, we evaluate the upper bounding power of ABQ, and compare it with three algorithms from literature: mini-bucket elimination (MBE) (Dechter and Rish, 2003; Rollon and Dechter, 2010), Treereweighted Belief Propagation (TRW) (Wainwright et al.", "startOffset": 180, "endOffset": 230}, {"referenceID": 27, "context": "To allow some comparison on large, hard instances, we evaluate the upper bounding power of ABQ, and compare it with three algorithms from literature: mini-bucket elimination (MBE) (Dechter and Rish, 2003; Rollon and Dechter, 2010), Treereweighted Belief Propagation (TRW) (Wainwright et al., 2003) and Box propagation (BoxProp) (Mooij and Kappen, 2008).", "startOffset": 272, "endOffset": 297}, {"referenceID": 20, "context": ", 2003) and Box propagation (BoxProp) (Mooij and Kappen, 2008).", "startOffset": 38, "endOffset": 62}, {"referenceID": 28, "context": "Medical Diganosis: Promedas networks Our second domain is that of noisy-OR medical diagnosis networks generated by the Promedas expert system for internal medicine (Wemmenhove et al., 2007).", "startOffset": 164, "endOffset": 189}, {"referenceID": 25, "context": "The global architecture of the diagnostic model in Promedas is similar to the QMR-DT medical diagnosis networks (Shwe et al., 1991).", "startOffset": 112, "endOffset": 131}, {"referenceID": 5, "context": "The networks are available from UAI 2008 evaluation website (Darwiche et al., 2008).", "startOffset": 60, "endOffset": 83}, {"referenceID": 12, "context": "Coding networks Our third domain is random coding networks from the class of linear block codes (Kask and Dechter, 1999) (the networks are available from the UAI 2008 evaluation website (Darwiche et al.", "startOffset": 96, "endOffset": 120}, {"referenceID": 5, "context": "Coding networks Our third domain is random coding networks from the class of linear block codes (Kask and Dechter, 1999) (the networks are available from the UAI 2008 evaluation website (Darwiche et al., 2008)).", "startOffset": 186, "endOffset": 209}, {"referenceID": 23, "context": "MBE employs sophisticated partitioning heuristics (Rollon and Dechter, 2010) that could also be incorporated into ABQ, and many other optimizations characteristic of a mature system; its good performance relative to ABQ is likely due to these improvements, rather than to the basic algorithm.", "startOffset": 50, "endOffset": 76}, {"referenceID": 18, "context": "We compare IABQ with Iterative Join Graph propagation (IJGP) (Mateescu et al., 2010), a state-of-the-art generalized belief propagation scheme (IJGP won 2 out of the 3 marginal estimation categories at the 2010 UAI approximate evaluation challenge (Elidan and Globerson, 2010)).", "startOffset": 61, "endOffset": 84}, {"referenceID": 9, "context": ", 2010), a state-of-the-art generalized belief propagation scheme (IJGP won 2 out of the 3 marginal estimation categories at the 2010 UAI approximate evaluation challenge (Elidan and Globerson, 2010)).", "startOffset": 171, "endOffset": 199}, {"referenceID": 10, "context": "compare with Gibbs sampling (Geman and Geman, 1984).", "startOffset": 28, "endOffset": 51}], "year": 2011, "abstractText": "Inference in graphical models consists of repeatedly multiplying and summing out potentials. It is generally intractable because the derived potentials obtained in this way can be exponentially large. Approximate inference techniques such as belief propagation and variational methods combat this by simplifying the derived potentials, typically by dropping variables from them. We propose an alternate method for simplifying potentials: quantizing their values. Quantization causes different states of a potential to have the same value, and therefore introduces contextspecific independencies that can be exploited to represent the potential more compactly. We use algebraic decision diagrams (ADDs) to do this efficiently. We apply quantization and ADD reduction to variable elimination and junction tree propagation, yielding a family of bounded approximate inference schemes. Our experimental tests show that our new schemes significantly outperform state-of-the-art approaches on many benchmark instances.", "creator": "gnuplot 4.4 patchlevel 2"}}}