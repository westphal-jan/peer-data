{"id": "1202.3743", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2012", "title": "Belief change with noisy sensing in the situation calculus", "abstract": "Situation calculus has been applied widely in artificial intelligence to model and reason about actions and changes in dynamic systems. Since actions carried out by agents will cause constant changes of the agents' beliefs, how to manage these changes is a very important issue. Shapiro et al. [22] is one of the studies that considered this issue. However, in this framework, the problem of noisy sensing, which often presents in real-world applications, is not considered. As a consequence, noisy sensing actions in this framework will lead to an agent facing inconsistent situation and subsequently the agent cannot proceed further. In this paper, we investigate how noisy sensing actions can be handled in iterated belief change within the situation calculus formalism. We extend the framework proposed in [22] with the capability of managing noisy sensings. We demonstrate that an agent can still detect the actual situation when the ratio of noisy sensing actions vs. accurate sensing actions is limited. We prove that our framework subsumes the iterated belief change strategy in [22] when all sensing actions are accurate. Furthermore, we prove that our framework can adequately handle belief introspection, mistaken beliefs, belief revision and belief update even with noisy sensing, as done in [22] with accurate sensing actions only.", "histories": [["v1", "Tue, 14 Feb 2012 16:41:17 GMT  (288kb)", "http://arxiv.org/abs/1202.3743v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jianbing ma", "weiru liu", "paul miller"], "accepted": false, "id": "1202.3743"}, "pdf": {"name": "1202.3743.pdf", "metadata": {"source": "CRF", "title": "Belief change with noisy sensing in the situation calculus", "authors": ["Jianbing Ma", "Weiru Liu"], "emails": ["jma03@qub.ac.uk,", "w.liu@qub.ac.uk,", "p.miller@ecit.qub.ac.uk"], "sections": [{"heading": null, "text": "Since actions undertaken by agents cause constant changes in agents \"beliefs, the question of how to manage these changes is a very important question. Shapiro et al. [22] is one of the studies that has considered this issue. However, within this framework, the problem of noise perception, which often occurs in real-life applications, is not taken into account. Consequently, sound perceptions within this framework lead to an agent facing an inconsistent situation, and as a result, the agent cannot proceed any further. In this paper, we examine how noise perceptual actions can be dealt with in repeated changes of belief within the situation. We expand the framework proposed in [22] to include the ability to handle noise perceptions. We show that an agent can still detect the actual situation if the ratio of noise perceptual actions to exact perceptual actions is limited. We prove that our framework of repeated beliefs can be combined with our belief strategy [22], if we can accurately translate all of these beliefs into [22]."}, {"heading": "1 Introduction", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "2 Background", "text": "The framework in [22] is based on an extension of the theory of action [17] based on the situation calculation [14, 15]. At this point, we present the concept of situation calculation from [22], which includes a belief provider [19, 20].The initial situation is a predicate calculus to represent dynamically changing areas. A situation represents a snapshot of the initial situation (1), which corresponds to the initial situations that agents believe to be what the domain might initially be. The actual initial state is represented by a distinguishable starting constant, S0, which may or may not be among the initial situations assumed by an agent. Do (a, s) refers to the unique situation executed by the agent acting in a situation. A predicate (or function) whose value may change according to a situation (his last argument) is referred to as fluent. For example, we use the situation that is (1) to represent an influent in a situation."}, {"heading": "3 Definitions and Axioms", "text": "In this section, we expand the scope in [22] to include a non-fixed plausibility operator to take into account the respective functionalities. (1) The non-fixed plausibility situations do not allow us to discard situations, and therefore the accessibility relationship B is very brief. (2) The revised accessibility relationship B is clearly much simpler than Equation 1. Equation 2 ensures that if a set of situations are B-related, their successors are B-related, and so on. That is, if we first have a set of B-related situations, then the successors of these situations are taken, the successors of these situations are B-related, and so on if we have a set of B-related situations."}, {"heading": "4 Properties", "text": "In this section, we will first present the key contribution of the paper, the tolerance of sound sensation, which goes beyond previous approaches, and then present the correspondences of the properties given in [22], which show that our framework faithfully extends its scope to sound sensation situations. To make the comparisons easier to follow, we have incorporated many of the notations and results proposed in [22] in the corresponding sub-sections below."}, {"heading": "4.1 Noisy Sensing Tolerance", "text": "In this subsection, we show that we can deal with the actual situation. \u00b7 More precisely, we then prove that in the sense of probability that it is a real situation, it is not a real situation, but a real situation, in which the actual situation is disconnected from the real situation. \u00b7 Whether it is an exact or real situation, which is an exact number of experimental runs, the chance of an accurate being is almost certain and P (a = aF) it is very rare that a false result is returned. Definition 2 A situation over a domain is called sensing-sensitive if it is a sequence (multi-set) of actions SEQ = {a1, \u00b7 \u00b7 such a situation: \u2022 a situation in which there is an exact response to a wrong result.Definition 2 A situation is called sensing-sensitive if it is a sequence (multi-set) of actions SEQ {a1, such a situation."}, {"heading": "4.2 Recovering the Beliefs in (Shapiro et al. 2011)", "text": "Similar to [22], if there is no confusion, in [22] (with different definitions of B relations and successive state axioms for pl) the argument of flowing behavior is often omitted, as opposed to the use of cautious action theory within our framework. Similarly, we use plS and BelS for plausibility functions and beliefs in [22]. In [22] the successor axiom for pl is defined as: plS (do (a, s) = plS (s) = beliefs. (3) Its believer is defined as: BelS (\u03c6, s) def = its functions and beliefs in [22]. In [22] the successor axiom for pl is defined as: plS (do (s)) = plS (s) = influences in our sense as: BelS (\u03c6, s) def = s (s), B (s), s), in his sense."}, {"heading": "4.3 Belief Revision", "text": "Faith Revision examines how an agent's beliefs can be altered based on some new information if the new information needs to be believed. Sensory actions are a way of obtaining certain new information that an agent can use to revise his beliefs about the actual situation without actually changing the environment. In the following, we assume that there is corresponding sensory action for each formula to be revised after the revision. Definition 3 (Uniform formula adapted to [22]) A formula is uniform if it does not contain unbound variables. Definition 4 (Revision action for the agent adapted to [22]) A revision action A for a uniform formula that remains unchanged in terms of action theory. Definition 3 (Uniform formula adapted to [22]) A formula is uniform if it does not contain unbound variables. Definition 4 (Revision action for the agent adapted to [22] An action for the agent is uniform in terms of a formula A."}, {"heading": "4.4 Introspection", "text": "Like [19, 20, 22], our framework supports faith introspection. Theorem 7 \u03a3 | = [Bel (\u03c6, s) \u2192 Bel (Bel (\u03c6), s) \u2022 [\u00ac Bel (\u03c6, s) \u2192 Bel (\u00ac Bel (\u03c6), s).This is not surprising, since in our framework the relationship is transitive and euclidean. Note that in [22] the beliefs are generated from the most plausible B-related situations and not from all B-related situations. The proof of the above theorem is simply similar to the proof of theorem 26 in [22]. In [22] it is argued that variations in their formalization, in which the plausibility values are updated, lead to problems with introspection. They can produce counterintuitive results about future beliefs (cf. [22] for details. Note that variations mentioned in [22] are plausible because our framework is intuitive, while our theory is intuitive, our intuitive situation is not."}, {"heading": "4.5 Awareness of errors", "text": "As in [22], we assume that an agent believes in s, but after performing a revision action A in s, the agent discovers that \u03c6 is true and believes \u03c6. In other words, the agent should recognize that he is in s.Definition 5 ([22]) Prev = a, s, \"s.t., s = do (a, s\"). Prev (\u03c6, s) indicates that \u03c6 took place in the situation immediately preceding it. The following theorem provided for in [22] also applies here.Theorem 8 Let A be a revision action for a uniform formula independent of the domain."}, {"heading": "5 Example", "text": "We now expand Example 1 to illustrate our framework.Example 3, Assumption: an agent with three actions: the agent leaves the current room and enters the other room (LEAVE); the agent guesses if he is in room 1 (SR); the agent guesses if the light in the room he is currently in is on (SL); and for noise perception we comment on it as an NSL. Note: The agent himself does not know whether the perception is correct or un.The successor state axiomes and guarded fluent axioms for the example are as follows: Light1 (do (a, s) sensory: Light1 (s) sensory: Light2 (do (a, s) sensory: Light2 (a) sensory: Lightsorted (a) sensory: Light2 (a), Sensory: Lightsorted (a) Sensory: The Agent in room (s), Sensory (2): Lightsorted (a) Sensory (2): The Lightsorted (a)."}, {"heading": "6 Related Work", "text": "In [3] the problem of noisy sensors is also examined and a probabilistic method is applied for such situations, i.e. the probability of a sensor effect follows a Gaussian distribution. Moreover, the convictions resulting from the situations are also probabilistic. [23] This approach is extended to investigate its properties and allows the use of conditional probability densities in the noisy sensor measurements. To some extent, it could be regarded as a probabilistic counterpart to our framework, although the tolerance of noise sensation is not taken into account in these papers. [21] the problem of noise sensation is also investigated by adding plausibility values to the B relationship, i.e. B (s), n, s), which means that the agent considers s with a plausibility value n possible. Similar to our approach, noisy sensor results will influence the n value based on whether the situation coincides with the sensor result, i.e. [22] it is discussed that this type of climaticity relatedness is in conflict with the proposed."}, {"heading": "7 Conclusion", "text": "In this paper, we have proposed a framework that can deal with noisy perceptual actions and handle nested beliefs, beliefs introspection, false beliefs, beliefs and beliefs actualizations. Furthermore, we show that rare noisy perceptions do not prevent an agent from recognizing the actual situation, and limited noisy perceptions allow a certain degree of recognition of the actual situation. Furthermore, we show that our framework leads to what can be discovered through the framework of [22] if all perceptual actions are precise. Due to space limitations, we do not offer in this paper a comparison of our framework with the various faith changes that are postulated, for example, the AGM postulates faith actualization [1], the KM postulates faith actualization [7], the DP postulates repeated faith actualizations [4], epistemic state actualizations postulates our framework [12], but we can prove that most of the above [11] postulates our faith actualizations."}], "references": [{"title": "On the logic of theory change: Partial meet functions for contraction and revision", "author": ["C.E. Alchourr\u00f3n", "P. G\u00e4rdenfors", "D. Makinson"], "venue": "Symbolic Logic,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1985}, {"title": "From statistical knowledge bases to degrees of belief", "author": ["F. Bacchus", "A. Grove", "J. Halpern", "D. Koller"], "venue": "Artificial Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1996}, {"title": "Reasoning about noisy sensors and effectors in the situation calculus", "author": ["F. Bacchus", "J. Halpern", "H. Levesque"], "venue": "Artificial Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "On the logic of iterated belief revision", "author": ["A. Darwiche", "J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "Progression using regression and sensors", "author": ["G. De Giacomo", "H. Levesque"], "venue": "In Procs. of IJCAI,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1999}, {"title": "Representing beliefs in the fluent calculus", "author": ["Y. Jin", "M. Thielscher"], "venue": "In Procs. of ECAI,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Propositional knowledge base revision and minimal change", "author": ["H. Katsuno", "A.O. Mendelzon"], "venue": "Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1991}, {"title": "A semantic characterization of a useful fragment of the situation calculus with knowledge", "author": ["G. Lakemeyer", "H. Levesque"], "venue": "Artificial Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "What is planning in the presence of sensing", "author": ["H. Levesque"], "venue": "In Procs. of AAAI,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1996}, {"title": "Modeling belief change on epistemic states", "author": ["J. Ma", "W. Liu"], "venue": "In Proc. of 22th Flairs,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "A framework for managing uncertain inputs: an axiomization of rewarding", "author": ["J. Ma", "W. Liu"], "venue": "Inter. J. of Appro. Reason.,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "A belief revision framework for revising epistemic states with partial epistemic states", "author": ["J. Ma", "W. Liu", "S. Benferhat"], "venue": "In Proc. of AAAI\u201910,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Handling sequential observations in intelligent surveillance", "author": ["J. Ma", "W. Liu", "P. Miller"], "venue": "In Procs. of SUM,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Situations, Actions and Causal Laws", "author": ["J. McCarthy"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1963}, {"title": "Some philosophical problems from the standpoint of artificial intelligence", "author": ["J. McCarthy", "P. Hayes"], "venue": "In Machine Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1969}, {"title": "Semantic considerations on nonmonotonic logic", "author": ["R. Moore"], "venue": "Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1985}, {"title": "The frame problem in the situation calculus: A simple solution (sometimes) and a completeness result for goal regression", "author": ["R. Reiter"], "venue": "In Aritificial Intelligence and Mathematical Theory of Computation: Papers in Honor of John Mc- Carthy,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1991}, {"title": "Extending DT- Golog to deal with POMDPs", "author": ["G. Rens", "A. Ferrein", "E. van der Poel"], "venue": "In Procs. 19th Annual Symposium of the Pattern Recognition Association of South Africa (PRASA),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "The frame problem and knowledge-producing actions", "author": ["R. Scherl", "H. Levesque"], "venue": "In Procs. of AAAI,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1993}, {"title": "Knowledge, action, and the frame problem", "author": ["R. Scherl", "H. Levesque"], "venue": "Artificial Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}, {"title": "Belief change with noisy sensing and introspection", "author": ["S. Shapiro"], "venue": "In Procs. of NRAC,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "Iterated belief change in the situation calculus", "author": ["S. Shapiro", "M. Pagnucco", "Y. Lesp\u00e9rance", "H. Levesque"], "venue": "Artificial Intelligence,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Knowledge, belief, and noisy sensing in the situation calculus. In www.cs.jhu.edu/ psimari/publications/simari msc.pdf", "author": ["P. Simari"], "venue": "Master Thesis,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "Ordinal conditional functions: A dynamic theory of epistemic states. Causation in Decision", "author": ["W. Spohn"], "venue": "Belief Change, and Statistics,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1988}], "referenceMentions": [{"referenceID": 21, "context": "[22] is one of the studies that considered this issue.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "We extend the framework proposed in [22] with the capability of managing noisy sensings.", "startOffset": 36, "endOffset": 40}, {"referenceID": 21, "context": "We prove that our framework subsumes the iterated belief change strategy in [22] when all sensing actions are accurate.", "startOffset": 76, "endOffset": 80}, {"referenceID": 21, "context": "Furthermore, we prove that our framework can adequately handle belief introspection, mistaken beliefs, belief revision and belief update even with noisy sensing, as done in [22] with accurate sensing actions only.", "startOffset": 173, "endOffset": 177}, {"referenceID": 13, "context": "Situation calculus, introduced by John McCarthy [14, 15], has been applied widely to model and reason about actions and changes in dynamic systems.", "startOffset": 48, "endOffset": 56}, {"referenceID": 14, "context": "Situation calculus, introduced by John McCarthy [14, 15], has been applied widely to model and reason about actions and changes in dynamic systems.", "startOffset": 48, "endOffset": 56}, {"referenceID": 16, "context": "It was reinterpreted in [17] as basic action theories which are comprised of a set of foundational axioms defining the space of situations, unique-name axioms for actions, action preconditions and effects axioms, and the initial situation axioms [8].", "startOffset": 24, "endOffset": 28}, {"referenceID": 7, "context": "It was reinterpreted in [17] as basic action theories which are comprised of a set of foundational axioms defining the space of situations, unique-name axioms for actions, action preconditions and effects axioms, and the initial situation axioms [8].", "startOffset": 246, "endOffset": 249}, {"referenceID": 18, "context": ", [19, 20, 22, 13].", "startOffset": 2, "endOffset": 18}, {"referenceID": 19, "context": ", [19, 20, 22, 13].", "startOffset": 2, "endOffset": 18}, {"referenceID": 21, "context": ", [19, 20, 22, 13].", "startOffset": 2, "endOffset": 18}, {"referenceID": 12, "context": ", [19, 20, 22, 13].", "startOffset": 2, "endOffset": 18}, {"referenceID": 21, "context": "In [22], a new framework exceeding previous approaches was proposed in which a plausibility value is attached to every situation.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "Example 1 (adapted from [22]) Assume that the initial situation S0 is InR1(S0) \u2227 \u00acLight1(S0) \u2227 \u00acLight2(S0) which states that the agent is in Room 1 (InR1(S0)), the lights in both Room 1 and Room 2 (assume there are only two rooms) are off.", "startOffset": 24, "endOffset": 28}, {"referenceID": 23, "context": "Not knowing the truth, the agent assigns S1 and S2 with plausibility values 0 and 1 respectively, which are the \u03ba-rankings in [24] such that the lower the plausibility value is, the more plausible the situation is.", "startOffset": 126, "endOffset": 130}, {"referenceID": 21, "context": "As a consequence, with this framework in [22], S2, the right situation, will be discarded.", "startOffset": 41, "endOffset": 45}, {"referenceID": 21, "context": "In this paper, we extend the framework in [22] to manage noisy sensing actions.", "startOffset": 42, "endOffset": 46}, {"referenceID": 21, "context": "On the other hand, when every sensing action is accurate, our extended framework is capable of discovering what can be derived from the framework in [22].", "startOffset": 149, "endOffset": 153}, {"referenceID": 21, "context": "\u2022 When all sensing actions are accurate, the beliefs that can be induced by the framework of [22] can also be induced from our framework.", "startOffset": 93, "endOffset": 97}, {"referenceID": 21, "context": "The framework in [22] is based on an extension of the action theory [17] stemming from situation calculus [14, 15].", "startOffset": 17, "endOffset": 21}, {"referenceID": 16, "context": "The framework in [22] is based on an extension of the action theory [17] stemming from situation calculus [14, 15].", "startOffset": 68, "endOffset": 72}, {"referenceID": 13, "context": "The framework in [22] is based on an extension of the action theory [17] stemming from situation calculus [14, 15].", "startOffset": 106, "endOffset": 114}, {"referenceID": 14, "context": "The framework in [22] is based on an extension of the action theory [17] stemming from situation calculus [14, 15].", "startOffset": 106, "endOffset": 114}, {"referenceID": 21, "context": "Here we introduce the notion of situation calculus from [22] which includes a belief operator [19, 20].", "startOffset": 56, "endOffset": 60}, {"referenceID": 18, "context": "Here we introduce the notion of situation calculus from [22] which includes a belief operator [19, 20].", "startOffset": 94, "endOffset": 102}, {"referenceID": 19, "context": "Here we introduce the notion of situation calculus from [22] which includes a belief operator [19, 20].", "startOffset": 94, "endOffset": 102}, {"referenceID": 16, "context": "The effects of actions on fluents are defined using successor state axioms [17], which provide a succinct representation for both effect axioms and frame axioms [14, 15].", "startOffset": 75, "endOffset": 79}, {"referenceID": 13, "context": "The effects of actions on fluents are defined using successor state axioms [17], which provide a succinct representation for both effect axioms and frame axioms [14, 15].", "startOffset": 161, "endOffset": 169}, {"referenceID": 14, "context": "The effects of actions on fluents are defined using successor state axioms [17], which provide a succinct representation for both effect axioms and frame axioms [14, 15].", "startOffset": 161, "endOffset": 169}, {"referenceID": 8, "context": "Levesque [9] introduced a predicate, SF(a, s), to describe the result of performing the binary-valued sensing action a.", "startOffset": 9, "endOffset": 12}, {"referenceID": 4, "context": "The property sensed by an action is associated with the action using a guarded sensed fluent axiom [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 18, "context": "Scherl and Levesque [19, 20] defined a successor state axiom for B, an accessibility relation on situations based on the possible-worlds semantics by [16], that shows how actions, including sensing actions, affect the beliefs of an agent.", "startOffset": 20, "endOffset": 28}, {"referenceID": 19, "context": "Scherl and Levesque [19, 20] defined a successor state axiom for B, an accessibility relation on situations based on the possible-worlds semantics by [16], that shows how actions, including sensing actions, affect the beliefs of an agent.", "startOffset": 20, "endOffset": 28}, {"referenceID": 15, "context": "Scherl and Levesque [19, 20] defined a successor state axiom for B, an accessibility relation on situations based on the possible-worlds semantics by [16], that shows how actions, including sensing actions, affect the beliefs of an agent.", "startOffset": 150, "endOffset": 154}, {"referenceID": 21, "context": "Similar to [22], we take the following conventions about the guarded action theories \u03a3 consisting of: (A) successor state axioms for each fluent, and guarded sensed fluent axioms for each action; (B) unique names axioms for actions, and domain-independent foundational axioms; and (C) initial state axioms which describe the initial state of the domain and the initial beliefs of agents.", "startOffset": 11, "endOffset": 15}, {"referenceID": 21, "context": "In this section, we extend the framework in [22] to include a non-fixed plausibility operator to account for iterated belief changes in the situation calculus.", "startOffset": 44, "endOffset": 48}, {"referenceID": 21, "context": "Surprisingly, it has a more expressive power than that in [22].", "startOffset": 58, "endOffset": 62}, {"referenceID": 23, "context": "This axiom follows a similar manner to OCF conditionalization [24].", "startOffset": 62, "endOffset": 66}, {"referenceID": 21, "context": "This successor state axiom for pl follows the spirit of the intuition stated for the plausibility settings in [22] that if the accessible situation agrees with the actual situation upon the result of a sensing action, the plausibility of the accessible should increase (i.", "startOffset": 110, "endOffset": 114}, {"referenceID": 21, "context": "However, this intuition was not implemented in the pl function in [22] because it is considered in conflict with positive and negative introspection of beliefs [22].", "startOffset": 66, "endOffset": 70}, {"referenceID": 21, "context": "However, this intuition was not implemented in the pl function in [22] because it is considered in conflict with positive and negative introspection of beliefs [22].", "startOffset": 160, "endOffset": 164}, {"referenceID": 21, "context": "This is intuitively the same as the one defined in [22].", "startOffset": 51, "endOffset": 55}, {"referenceID": 21, "context": "We then provide the counterparts of properties given in [22] which demonstrate that our framework faithfully extend their framework to noisy sensing situations.", "startOffset": 56, "endOffset": 60}, {"referenceID": 21, "context": "To make the comparisons easier to follow, in the corresponding subsections below, we have adopted many notations and results proposed in [22].", "startOffset": 137, "endOffset": 141}, {"referenceID": 1, "context": "Let P be a probability function that measures the statistical outcome of the accuracy of sensing actions performed by an agent [2].", "startOffset": 127, "endOffset": 130}, {"referenceID": 21, "context": "This issue was not explicitly considered in [22] but could be seen as a default assumption for their framework.", "startOffset": 44, "endOffset": 48}, {"referenceID": 21, "context": "Similar to [22], for clarity, if there is no confusion, the situation argument of a fluent is often omitted in a belief operator, e.", "startOffset": 11, "endOffset": 15}, {"referenceID": 21, "context": "For comparison, let \u03a3S denote a guarded action theory used in [22] (with different definitions of B relations and successive state axioms for pl) in contrast to using \u03a3 for a guarded action theory in our framework.", "startOffset": 62, "endOffset": 66}, {"referenceID": 21, "context": "Similarly, we use plS and BelS for plausibility functions and beliefs in [22].", "startOffset": 73, "endOffset": 77}, {"referenceID": 21, "context": "In [22], the successor state axiom for pl is defined as:", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "Two axioms for initializing the B-related situations are used [22] to complete its framework.", "startOffset": 62, "endOffset": 66}, {"referenceID": 21, "context": "Axiom 4 [22] Init(s) \u2227 B(s\u2032, s) \u2192 ( \u2200s\u2032\u2032, B(s\u2032\u2032, s\u2032) \u2261 B(s\u2032\u2032, s) ) .", "startOffset": 8, "endOffset": 12}, {"referenceID": 21, "context": "Axiom 5 [22] Init(s) \u2227B(s\u2032, s) \u2192 Init(s\u2032).", "startOffset": 8, "endOffset": 12}, {"referenceID": 21, "context": "This theorem shows that when all sensing actions are accurate, our framework truly discovers the beliefs which can be induced by the framework in [22].", "startOffset": 146, "endOffset": 150}, {"referenceID": 21, "context": "In fact, it is easy to show that if all sensing actions are accurate, then the situations that do not match the sensing results will henceforth have no chance to influence the change of beliefs, just like being discarded by the B-relations as done in [22].", "startOffset": 251, "endOffset": 255}, {"referenceID": 21, "context": "Definition 3 (Uniform formula, adapted from [22]) A formula is uniform if it contains no unbound variables.", "startOffset": 44, "endOffset": 48}, {"referenceID": 21, "context": "Definition 4 (Revision action for \u03c6, adapted from [22]) A revision action A for a uniform formula \u03c6 with respect to action theory \u03a3 is a sensing action that satisfies the following condition for every domain-dependent fluent F : \u03a3 |= [\u2200s, SF (A, s) \u2261 \u03c6[s]] \u2227 [\u2200s\u2200\u2212\u2192x , F (\u2212\u2192x , s) \u2261 F (\u2212\u2192x , do(A, s))], \u2212\u2192x is the set of arguments of F .", "startOffset": 50, "endOffset": 54}, {"referenceID": 21, "context": "The following two theorems provided in [22] also hold in our framework.", "startOffset": 39, "endOffset": 43}, {"referenceID": 18, "context": "This theorem is also consistent with the framework in [19, 20].", "startOffset": 54, "endOffset": 62}, {"referenceID": 19, "context": "This theorem is also consistent with the framework in [19, 20].", "startOffset": 54, "endOffset": 62}, {"referenceID": 18, "context": "Like [19, 20, 22], our framework supports belief introspection.", "startOffset": 5, "endOffset": 17}, {"referenceID": 19, "context": "Like [19, 20, 22], our framework supports belief introspection.", "startOffset": 5, "endOffset": 17}, {"referenceID": 21, "context": "Like [19, 20, 22], our framework supports belief introspection.", "startOffset": 5, "endOffset": 17}, {"referenceID": 21, "context": "Note that in [22], the beliefs are induced from the most plausible B-related situations instead of from all B-related situations.", "startOffset": 13, "endOffset": 17}, {"referenceID": 21, "context": "The proof of the above theorem is simply similar to the proof of Theorem 26 in [22].", "startOffset": 79, "endOffset": 83}, {"referenceID": 21, "context": "In [22], it is argued that variations of their formalization where plausibility values are updated lead to problems with introspection.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "[22] for details).", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Note that variations mentioned in [22] have plausibilities between Baccessible situations, while our plausibility is assigned to single situations, so our framework does not have such weakness, as can be seen from Theorem 4 (showing that we will not produce counterintuitive results since the framework [22] does not) and Theorem 7 (showing that introspection holds).", "startOffset": 34, "endOffset": 38}, {"referenceID": 21, "context": "Note that variations mentioned in [22] have plausibilities between Baccessible situations, while our plausibility is assigned to single situations, so our framework does not have such weakness, as can be seen from Theorem 4 (showing that we will not produce counterintuitive results since the framework [22] does not) and Theorem 7 (showing that introspection holds).", "startOffset": 303, "endOffset": 307}, {"referenceID": 21, "context": "As in [22], suppose that an agent believes \u00ac\u03c6 in s, however after performing a revision action A in s, the agent discovers that \u03c6 is true and believes \u03c6.", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "Definition 5 ([22]) Prev(\u03c6, s) def = \u2203a, s\u2032, s.", "startOffset": 14, "endOffset": 18}, {"referenceID": 21, "context": "The following theorem provided in [22] also holds here.", "startOffset": 34, "endOffset": 38}, {"referenceID": 21, "context": "The ability of belief update [22] is also provable from our framework.", "startOffset": 29, "endOffset": 33}, {"referenceID": 21, "context": "Also note that the framework in [22] cannot proceed after the sensing action SR.", "startOffset": 32, "endOffset": 36}, {"referenceID": 2, "context": "In [3], the problem of noisy sensors is also studied and a probabilistic method is applied for such situations.", "startOffset": 3, "endOffset": 6}, {"referenceID": 22, "context": "This approach is extended in [23] to study its properties and allows for using conditional probability densities in the noisy sensor readings.", "startOffset": 29, "endOffset": 33}, {"referenceID": 20, "context": "In [21], the noisy sensor problem is also studied by adding plausibility values into the B-relation, i.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "However, in [22], it is discussed that this kind of accessibility relations, together", "startOffset": 12, "endOffset": 16}, {"referenceID": 5, "context": "In [6], a fluent calculus framework is proposed to deal with the problem of observations contradicting the model which is to some extent similar to noisy sensing.", "startOffset": 3, "endOffset": 6}, {"referenceID": 21, "context": "Moreover, we show that our framework induces what can be discovered by the framework of [22] when all sensing actions are accurate.", "startOffset": 88, "endOffset": 92}, {"referenceID": 0, "context": ", AGM belief revision postulates [1], KM belief update postulates [7], DP iterated belief revision postulates [4], epistemic state revision postulates [12], belief change postulates [10, 11], etc.", "startOffset": 33, "endOffset": 36}, {"referenceID": 6, "context": ", AGM belief revision postulates [1], KM belief update postulates [7], DP iterated belief revision postulates [4], epistemic state revision postulates [12], belief change postulates [10, 11], etc.", "startOffset": 66, "endOffset": 69}, {"referenceID": 3, "context": ", AGM belief revision postulates [1], KM belief update postulates [7], DP iterated belief revision postulates [4], epistemic state revision postulates [12], belief change postulates [10, 11], etc.", "startOffset": 110, "endOffset": 113}, {"referenceID": 11, "context": ", AGM belief revision postulates [1], KM belief update postulates [7], DP iterated belief revision postulates [4], epistemic state revision postulates [12], belief change postulates [10, 11], etc.", "startOffset": 151, "endOffset": 155}, {"referenceID": 9, "context": ", AGM belief revision postulates [1], KM belief update postulates [7], DP iterated belief revision postulates [4], epistemic state revision postulates [12], belief change postulates [10, 11], etc.", "startOffset": 182, "endOffset": 190}, {"referenceID": 10, "context": ", AGM belief revision postulates [1], KM belief update postulates [7], DP iterated belief revision postulates [4], epistemic state revision postulates [12], belief change postulates [10, 11], etc.", "startOffset": 182, "endOffset": 190}, {"referenceID": 21, "context": "Especially, DP\u2019s C2 postulate is satisfied in our framework, whilst in [22], C2 cannot be defined.", "startOffset": 71, "endOffset": 75}, {"referenceID": 17, "context": "In addition, a study of the relationship between our framework and the Partially Observable Markov Decision Process (POMDP) [18] could be helpful.", "startOffset": 124, "endOffset": 128}], "year": 2011, "abstractText": "Situation calculus has been applied widely in artificial intelligence to model and reason about actions and changes in dynamic systems. Since actions carried out by agents will cause constant changes of the agents\u2019 beliefs, how to manage these changes is a very important issue. Shapiro et al. [22] is one of the studies that considered this issue. However, in this framework, the problem of noisy sensing, which often presents in real-world applications, is not considered. As a consequence, noisy sensing actions in this framework will lead to an agent facing inconsistent situation and subsequently the agent cannot proceed further. In this paper, we investigate how noisy sensing actions can be handled in iterated belief change within the situation calculus formalism. We extend the framework proposed in [22] with the capability of managing noisy sensings. We demonstrate that an agent can still detect the actual situation when the ratio of noisy sensing actions vs. accurate sensing actions is limited. We prove that our framework subsumes the iterated belief change strategy in [22] when all sensing actions are accurate. Furthermore, we prove that our framework can adequately handle belief introspection, mistaken beliefs, belief revision and belief update even with noisy sensing, as done in [22] with accurate sensing actions only.", "creator": " TeX output 2011.06.15:2022"}}}