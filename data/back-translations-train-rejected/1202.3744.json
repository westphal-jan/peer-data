{"id": "1202.3744", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2012", "title": "Improving the Scalability of Optimal Bayesian Network Learning with External-Memory Frontier Breadth-First Branch and Bound Search", "abstract": "Previous work has shown that the problem of learning the optimal structure of a Bayesian network can be formulated as a shortest path finding problem in a graph and solved using A* search. In this paper, we improve the scalability of this approach by developing a memory-efficient heuristic search algorithm for learning the structure of a Bayesian network. Instead of using A*, we propose a frontier breadth-first branch and bound search that leverages the layered structure of the search graph of this problem so that no more than two layers of the graph, plus solution reconstruction information, need to be stored in memory at a time. To further improve scalability, the algorithm stores most of the graph in external memory, such as hard disk, when it does not fit in RAM. Experimental results show that the resulting algorithm solves significantly larger problems than the current state of the art.", "histories": [["v1", "Tue, 14 Feb 2012 16:41:17 GMT  (240kb)", "http://arxiv.org/abs/1202.3744v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["brandon malone", "changhe yuan", "eric a hansen", "susan bridges"], "accepted": false, "id": "1202.3744"}, "pdf": {"name": "1202.3744.pdf", "metadata": {"source": "CRF", "title": "Improving the Scalability of Optimal Bayesian Network Learning with External-Memory Frontier Breadth-First Branch and Bound Search", "authors": ["Brandon Malone"], "emails": ["bm542@msstate.edu,", "bridgess}@cse.msstate.edu"], "sections": [{"heading": null, "text": "Previous work has shown that the problem of learning the optimal structure of a Bayesian network can be formulated as a short-term problem in a graph and solved by A * search. In this paper, we improve the scalability of this approach by developing a memory-efficient heuristic search algorithm to learn the structure of a Bayesian network. Instead of using A *, we propose a cross-border search that effectively uses the layered structure of the search graph of this problem, so that no more than two layers of the graph plus solution reconstruction information must be stored in memory at the same time. To further improve scalability, the algorithm stores most of the graph in external memory, e.g. on the hard disk when it does not fit into the main memory. Experimental results show that the resulting algorithm solves significantly larger problems than the current state of the art."}, {"heading": "1 INTRODUCTION", "text": "In fact, it is a question of a \"yes,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no,\" a \"no.\""}, {"heading": "2 BACKGROUND", "text": "A Bayesian network consists of a directional acyclic structure (DAG) and a series of parameters. The vertices of the diagram correspond each to a random variable V = {X1,..., Xn}. All parents of Xi are referred to as PAi. A variable is conditionally independent of their parents. The parameters of the network determine a conditional probability distribution, P (Xi | PAi) for each X. Given a dataset D = {D1,..., DN}, where Di is an instantiation of all variables in V, the optimal structure is the DAG over all variables that best fit D (Heckerman 1998). A scoring function measures the fit of a network structure according to D. For example, the minimum description length (MDL) of the scoring function (Cracks 1978) of the MDL function can punish Myexi of the reward variables with low entropy and another."}, {"heading": "3 DYNAMIC PROGRAMMING", "text": "Dynamic programming algorithms learn optimal network structures in O (n2n) time and memory (Ott, Imoto and Miyano 2004; Koivisto and Sood 2004; Singh and Moore 2005; Silander and Myllymaki 2006). Since a network structure is a DAG, the optimal structure can be divided into an optimal leaf vertex and its parents, as well as an optimal subnetwork for the rest of the variables. This subnetwork is also a DAG, so it can be divided recursively until the subnetwork is just a singlevertex. At this point in time, the optimal parents for all variables in the network have been found and the optimal structure can be constructed. It has been shown (Silander and Myllymaki 2006) that a more efficient algorithm starts with a 0 - variable subnetwork and the optimal subvariables V are calculated as subvariables."}, {"heading": "4 GRAPH SEARCH FORMULATION", "text": "In fact, it is that we are able to assert ourselves, that we are able to be able to hide ourselves, and that we are able to hide ourselves, \"he said."}, {"heading": "5 AN EXTERNAL-MEMORY FRONTIER BREADTH-FIRST BRANCH AND BOUND ALGORITHM", "text": "& # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & & & # 10; & # 10; & # 10; & & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10"}, {"heading": "5.1 BRANCH AND BOUND", "text": "We need a heuristic function f (U) = g (U) + h (U), which calculates the cost of the best path from the start node to a destination node with the order node U. The g cost is simply the sum of the edge cost of the best path from the start node to U. The h cost provides a lower limit on the cost from U to the destination node. (3) This heuristic function relativizes the acyclic constraint on the remaining variables in V\\ U and allows you to choose parents from all variables in V\\ UBestMDL (X\\ {X}). (3) This heuristic function relativizes the acyclic constraint on the remaining variables in V\\ U."}, {"heading": "5.2 COORDINATING THE GRAPH SEARCHES", "text": "In fact, it is so that it will be able to put itself at the head of the party that is able to hold its own, \"he said in an interview with\" Welt am Sonntag. \""}, {"heading": "5.3 ORDERING THE SCORES ON DISK", "text": "As described in Section 5.2, parent graph nodes are expanded in lexicographic order; however, they are not generated in that order. MDL (X, U), U = {Y1... Yl} is required when the U\\ {Yl} node in parent graph is expanded for X. Therefore, the scores must be written to disk in that order. Pseudo-code uses the writeScoresToDisk function to sort the scores in that order and write them to disk. For each variable, a file is created for each level to store those sorted scores. The file for a particular level can be deleted after it has been expanded in the corresponding parent graph."}, {"heading": "5.4 DUPLICATE DETECTION", "text": "Duplicates in the parent and in the order graphs correspond to nodes that consider the same sets of variables (candidate parent sets and optimal subnets, respectively). Since the successors of a node always look at exactly one more variable in the parent and ordered graphs, the successors of a node in the layer l should always be in the layer l + 1. Therefore, when a node is created, it is possible that there could be only one duplicate of a node in the open list l + 1. We use a variant of parent and ordered graphs, the duplicates with the best score should be cepted. For large data sets, it is possible that one layer of the parent or ordered graph is too large to fit into memory."}, {"heading": "5.5 RECONSTRUCTING THE OPTIMAL NETWORK STRUCTURE", "text": "In order to trace the optimal path and reconstruct the optimal network structure, we write a portion of each node of the job graph into a disk file as soon as it is expanded during the job graph search. For each job graph node, we write the subset of variables, the sheet variable, and their optimal parents. The solution reconstruction works as follows: The final sheet variable X and its optimal parent set are retrieved from the target node. Since the target node takes all variables into account, its predecessor in the optimal path is U = V\\ {X}. This predecessor is retrieved from the Layer | U | file. This node has the optimal sheet and parent set for this subnet. Recursively, the optimal sheets and parent sets are retrieved until the reconstruction of the entire network structure is complete. We use this approach instead of the standard division-and-conquer solution reconstruction because, as shown in Section 6, it requires relatively little memory sets."}, {"heading": "5.6 ADVANTAGES OF OUR ALGORITHM", "text": "In fact, most of them are able to decide for themselves what they want."}, {"heading": "6 EXPERIMENTS", "text": "In fact, most of them are able to survive by themselves if they do not play by the rules. (...) Most of them are able to survive by themselves. (...) Most of them are not able to survive by themselves. (...) Most of them are not able to survive by themselves. (...) Most of them are able to survive by themselves. (...) Most of them are not able to survive by themselves. (...) Most of them are not able to survive by themselves. (...) Most of them are able to survive by themselves. \"(...) Most of them are able to survive by themselves.\" (...)"}, {"heading": "7 CONCLUSION", "text": "Learning optimal Bayesian network structures was conceived with dynamic programming in mind; however, such a formulation naively requires the memory of O (n2n). Other formulations have been shown to have similar or slower runtimes or require other exponential resources, such as processors. Consequently, we delete layers of parent diagrams after expansion and store only part of each job diagram in disk files to reduce memory complexity. Delayed duplicate detection strategy further improves the scalability of the algorithm by writing sub-layers to disk instead of storing an entire layer that fits in RAM. Moreover, a heuristic function allows parts of the order diagram to be completely ignored; this also reduces the scalability of the algorithm by writing sub-layers to disk."}], "references": [{"title": "Learning Bayesian networks is NP-complete", "author": ["D.M. Chickering"], "venue": "Learning from Data: Artificial Intelligence and Statistics V, 121\u2013130. Springer-Verlag.", "citeRegEx": "Chickering,? 1996", "shortCiteRegEx": "Chickering", "year": 1996}, {"title": "A Bayesian method for the induction of probabilistic networks from data", "author": ["G.F. Cooper", "E. Herskovits"], "venue": "Mach. Learn. 9:309\u2013347.", "citeRegEx": "Cooper and Herskovits,? 1992", "shortCiteRegEx": "Cooper and Herskovits", "year": 1992}, {"title": "Structure learning of Bayesian networks using constraints", "author": ["C.P. de Campos", "Z. Zeng", "Q. Ji"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Campos et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Campos et al\\.", "year": 2009}, {"title": "Learning Bayesian network structure from massive datasets: The \u201csparse candidate\u201d algorithm", "author": ["N. Friedman", "I. Nachman", "D. Peer"], "venue": "Proceedings of UAI-13, 206\u2013215.", "citeRegEx": "Friedman et al\\.,? 1999", "shortCiteRegEx": "Friedman et al\\.", "year": 1999}, {"title": "Learning Bayesian networks: The combination of knowledge and statistical data", "author": ["D. Heckerman", "D. Geiger", "D.M. Chickering"], "venue": "20:197\u2013243.", "citeRegEx": "Heckerman et al\\.,? 1995", "shortCiteRegEx": "Heckerman et al\\.", "year": 1995}, {"title": "A tutorial on learning with Bayesian networks", "author": ["D. Heckerman"], "venue": "Holmes, D., and Jain, L., eds., Innovations in Bayesian Networks, volume 156 of Studies in Computational Intelligence. Springer Berlin / Heidelberg. 33\u201382.", "citeRegEx": "Heckerman,? 1998", "shortCiteRegEx": "Heckerman", "year": 1998}, {"title": "Learning Bayesian network structure using LP relaxations", "author": ["T. Jaakkola", "D. Sontag", "A. Globerson", "M. Meila"], "venue": "Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS).", "citeRegEx": "Jaakkola et al\\.,? 2010", "shortCiteRegEx": "Jaakkola et al\\.", "year": 2010}, {"title": "The Art of Computer Programming, Volume 4, Fascicles 0-4", "author": ["D.E. Knuth"], "venue": "Addison-Wesley Professional, 1st edition.", "citeRegEx": "Knuth,? 2009", "shortCiteRegEx": "Knuth", "year": 2009}, {"title": "Exact Bayesian structure discovery in Bayesian networks", "author": ["M. Koivisto", "K. Sood"], "venue": "Journal of Machine Learning Research 549\u2013573.", "citeRegEx": "Koivisto and Sood,? 2004", "shortCiteRegEx": "Koivisto and Sood", "year": 2004}, {"title": "Frontier search", "author": ["R. Korf", "W. Zhang", "I. Thayer", "H. Hohwald"], "venue": "Journal of the ACM 52(5):715\u2013748.", "citeRegEx": "Korf et al\\.,? 2005", "shortCiteRegEx": "Korf et al\\.", "year": 2005}, {"title": "Linear-time disk-based implicit graph search", "author": ["R. Korf"], "venue": "Journal of the ACM 35(6).", "citeRegEx": "Korf,? 2008", "shortCiteRegEx": "Korf", "year": 2008}, {"title": "Memoryefficient dynamic programming for learning optimal Bayesian networks", "author": ["B. Malone", "C. Yuan", "E. Hansen"], "venue": "Proceedings of the 25th national conference on Artifical intelligence.", "citeRegEx": "Malone et al\\.,? 2011", "shortCiteRegEx": "Malone et al\\.", "year": 2011}, {"title": "Cached sufficient statistics for efficient machine learning with large datasets", "author": ["A. Moore", "M.S. Lee"], "venue": "J. Artif. Int. Res. 8:67\u201391.", "citeRegEx": "Moore and Lee,? 1998", "shortCiteRegEx": "Moore and Lee", "year": 1998}, {"title": "Finding optimal models for small gene networks", "author": ["S. Ott", "S. Imoto", "S. Miyano"], "venue": "Pac. Symp. Biocomput, 557\u2013567.", "citeRegEx": "Ott et al\\.,? 2004", "shortCiteRegEx": "Ott et al\\.", "year": 2004}, {"title": "Exact structure discovery in Bayesian networks with less space", "author": ["P. Parviainen", "M. Koivisto"], "venue": "Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. Montreal, Quebec, Canada: AUAI Press.", "citeRegEx": "Parviainen and Koivisto,? 2009", "shortCiteRegEx": "Parviainen and Koivisto", "year": 2009}, {"title": "Modeling by shortest data description", "author": ["J. Rissanen"], "venue": "Automatica 14:465\u2013471.", "citeRegEx": "Rissanen,? 1978", "shortCiteRegEx": "Rissanen", "year": 1978}, {"title": "A simple approach for finding the globally optimal Bayesian network structure", "author": ["T. Silander", "P. Myllymaki"], "venue": "Proceedings of the 22nd Annual Conference on Uncertainty in Artificial Intelligence (UAI-06). Arlington, Virginia: AUAI Press.", "citeRegEx": "Silander and Myllymaki,? 2006", "shortCiteRegEx": "Silander and Myllymaki", "year": 2006}, {"title": "Finding optimal Bayesian networks by dynamic programming", "author": ["A. Singh", "A. Moore"], "venue": "Technical report, Carnegie Mellon University.", "citeRegEx": "Singh and Moore,? 2005", "shortCiteRegEx": "Singh and Moore", "year": 2005}, {"title": "A branch-and-bound algorithm for MDL learning Bayesian networks", "author": ["J. Tian"], "venue": "Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence, 580\u2013 588. Morgan Kaufmann Publishers Inc.", "citeRegEx": "Tian,? 2000", "shortCiteRegEx": "Tian", "year": 2000}, {"title": "The max-min hill-climbing Bayesian network structure learning algorithm", "author": ["I. Tsamardinos", "L. Brown", "C. Aliferis"], "venue": "Machine learning.", "citeRegEx": "Tsamardinos et al\\.,? 2006", "shortCiteRegEx": "Tsamardinos et al\\.", "year": 2006}, {"title": "Learning optimal Bayesian networks using A* search", "author": ["C. Yuan", "B. Malone", "X. Wu"], "venue": "Proceedings of the 22nd International Joint Conference on Artificial Intelligence.", "citeRegEx": "Yuan et al\\.,? 2011", "shortCiteRegEx": "Yuan et al\\.", "year": 2011}, {"title": "Sweep A*: Space-efficient heuristic search in partially ordered graphs", "author": ["R. Zhou", "E. Hansen"], "venue": "Proceedings of 15th IEEE International Conf. on Tools with Artificial Intelligence, 427\u2013434.", "citeRegEx": "Zhou and Hansen,? 2003", "shortCiteRegEx": "Zhou and Hansen", "year": 2003}, {"title": "Breadth-first heuristic search", "author": ["R. Zhou", "E.A. Hansen"], "venue": "Artificial Intelligence 170:385\u2013408.", "citeRegEx": "Zhou and Hansen,? 2006", "shortCiteRegEx": "Zhou and Hansen", "year": 2006}], "referenceMentions": [{"referenceID": 1, "context": "A common learning approach entails searching for a structure which optimizes a particular scoring function (Cooper and Herskovits 1992; Heckerman, Geiger, and Chickering 1995).", "startOffset": 107, "endOffset": 175}, {"referenceID": 1, "context": "Because of the difficulty of the problem, early approaches focused on approximation techniques to learn \u201cgood\u201d networks (Cooper and Herskovits 1992; Heckerman, Geiger, and Chickering 1995; Heckerman 1998; Friedman, Nachman, and Peer 1999; Tsamardinos, Brown, and Aliferis 2006).", "startOffset": 120, "endOffset": 277}, {"referenceID": 5, "context": "Because of the difficulty of the problem, early approaches focused on approximation techniques to learn \u201cgood\u201d networks (Cooper and Herskovits 1992; Heckerman, Geiger, and Chickering 1995; Heckerman 1998; Friedman, Nachman, and Peer 1999; Tsamardinos, Brown, and Aliferis 2006).", "startOffset": 120, "endOffset": 277}, {"referenceID": 8, "context": "Exact dynamic programming algorithms have been developed to learn provably optimal Bayesian network structures (Ott, Imoto, and Miyano 2004; Koivisto and Sood 2004; Singh and Moore 2005; Silander and Myllymaki 2006).", "startOffset": 111, "endOffset": 215}, {"referenceID": 17, "context": "Exact dynamic programming algorithms have been developed to learn provably optimal Bayesian network structures (Ott, Imoto, and Miyano 2004; Koivisto and Sood 2004; Singh and Moore 2005; Silander and Myllymaki 2006).", "startOffset": 111, "endOffset": 215}, {"referenceID": 16, "context": "Exact dynamic programming algorithms have been developed to learn provably optimal Bayesian network structures (Ott, Imoto, and Miyano 2004; Koivisto and Sood 2004; Singh and Moore 2005; Silander and Myllymaki 2006).", "startOffset": 111, "endOffset": 215}, {"referenceID": 8, "context": "Exact dynamic programming algorithms have been developed to learn provably optimal Bayesian network structures (Ott, Imoto, and Miyano 2004; Koivisto and Sood 2004; Singh and Moore 2005; Silander and Myllymaki 2006). These algorithms identify optimal small subnetworks and add optimal leaves to find large optimal networks until finding the optimal network including all variables. Unfortunately, all of these algorithms must store an exponential number of subnetworks and associated information in memory. Parviainen and Koivisto (2009) recently proposed a divide-and-conquer algorithm in which fewer subnetworks are stored in memory at once at the expense of longer running time.", "startOffset": 141, "endOffset": 538}, {"referenceID": 2, "context": "de Campos et al. (2009) proposed a systematic search algorithm to identify optimal network structures.", "startOffset": 3, "endOffset": 24}, {"referenceID": 6, "context": "Optimal networks have also been learned using linear programming (Jaakkola et al. 2010).", "startOffset": 65, "endOffset": 87}, {"referenceID": 6, "context": "This algorithm was shown to have similar or slightly better runtime performance as dynamic programming (Jaakkola et al. 2010).", "startOffset": 103, "endOffset": 125}, {"referenceID": 5, "context": ", DN}, where Di is an instantiation of all the variables in V, the optimal structure is the DAG over all of the variables which best fits D (Heckerman 1998).", "startOffset": 140, "endOffset": 156}, {"referenceID": 15, "context": "For example, the minimum description length (MDL) scoring function (Rissanen 1978) uses one term to reward structures with low entropy and another to penalize complex structures.", "startOffset": 67, "endOffset": 82}, {"referenceID": 18, "context": "The MDL score for a structure G is defined as follows (Tian 2000),", "startOffset": 54, "endOffset": 65}, {"referenceID": 5, "context": "MDL is decomposable (Heckerman 1998), so the score for a structure is simply the sum of the score for each variable.", "startOffset": 20, "endOffset": 36}, {"referenceID": 4, "context": "MDL is decomposable (Heckerman 1998), so the score for a structure is simply the sum of the score for each variable. Our algorithm can be adapted to use any decomposable function. Some sets of parents cannot form an optimal parent for any variable, as described in the following theorems from Tian (2000) and de Campos et al.", "startOffset": 21, "endOffset": 305}, {"referenceID": 2, "context": "Some sets of parents cannot form an optimal parent for any variable, as described in the following theorems from Tian (2000) and de Campos et al. (2009).", "startOffset": 132, "endOffset": 153}, {"referenceID": 0, "context": "Learning an optimal Bayesian network structure is NPHard (Chickering 1996).", "startOffset": 57, "endOffset": 74}, {"referenceID": 8, "context": "Dynamic programming algorithms learn optimal network structures in O(n2) time and memory (Ott, Imoto, and Miyano 2004; Koivisto and Sood 2004; Singh and Moore 2005; Silander and Myllymaki 2006).", "startOffset": 89, "endOffset": 193}, {"referenceID": 17, "context": "Dynamic programming algorithms learn optimal network structures in O(n2) time and memory (Ott, Imoto, and Miyano 2004; Koivisto and Sood 2004; Singh and Moore 2005; Silander and Myllymaki 2006).", "startOffset": 89, "endOffset": 193}, {"referenceID": 16, "context": "Dynamic programming algorithms learn optimal network structures in O(n2) time and memory (Ott, Imoto, and Miyano 2004; Koivisto and Sood 2004; Singh and Moore 2005; Silander and Myllymaki 2006).", "startOffset": 89, "endOffset": 193}, {"referenceID": 16, "context": "It has been shown (Silander and Myllymaki 2006) that a more efficient algorithm begins with a 0variable subnetwork and exhaustively adds optimal leaves.", "startOffset": 18, "endOffset": 47}, {"referenceID": 12, "context": "An AD-tree (Moore and Lee 1998) is an unbalanced tree which contains AD-nodes and varying nodes.", "startOffset": 11, "endOffset": 31}, {"referenceID": 10, "context": "It is also similar to the frontier search described by Korf (2005).", "startOffset": 55, "endOffset": 67}, {"referenceID": 10, "context": "Yet another difference is that we use a variant of delayed duplicate detection (Korf 2008) in which a hash table is used to detect as many duplicates in RAM as possible before resorting to external memory, as described in Section 5.", "startOffset": 79, "endOffset": 90}, {"referenceID": 20, "context": "We use the following heuristic function h from Yuan et al. (2011).", "startOffset": 47, "endOffset": 66}, {"referenceID": 20, "context": "The following theorem from Yuan et al. (2011) proves that the function is consistent.", "startOffset": 27, "endOffset": 46}, {"referenceID": 5, "context": "We use a greedy beam search algorithm based on a local search algorithm described by Heckerman (1998) to quickly find the upper bound.", "startOffset": 85, "endOffset": 102}, {"referenceID": 7, "context": "The lexicographic ordering (Knuth 2009) of nodes within each layer is one possible ordering that ensures the queues remain synchronized.", "startOffset": 27, "endOffset": 39}, {"referenceID": 10, "context": "We use a variant of the delayed duplicate detection (DDD) (Korf 2008) in our algorithm to utilize external memory to solve such large learning problems.", "startOffset": 58, "endOffset": 69}, {"referenceID": 16, "context": "The AD-tree method is in contrast to the bottom-up method used by other algorithms (Silander and Myllymaki 2006).", "startOffset": 83, "endOffset": 112}, {"referenceID": 17, "context": "Previous formulations, such as PCaches (Singh and Moore 2005) and arrays (Silander and Myllymaki 2006), could not take advantage of this structure.", "startOffset": 39, "endOffset": 61}, {"referenceID": 16, "context": "Previous formulations, such as PCaches (Singh and Moore 2005) and arrays (Silander and Myllymaki 2006), could not take advantage of this structure.", "startOffset": 73, "endOffset": 102}, {"referenceID": 6, "context": "The LP algorithm (Jaakkola et al. 2010) uses the same mechanism to identify optimal parent sets as DP; therefore, it cannot complete when all optimal parent sets do not fit in memory.", "startOffset": 17, "endOffset": 39}, {"referenceID": 16, "context": "We compared a Java implementation of the externalmemory frontier BFBnB search with DDD (BFBnB) to an efficient version (Silander and Myllymaki 2006) of dynamic programming which uses external memory written", "startOffset": 119, "endOffset": 148}, {"referenceID": 16, "context": "Previous results (Silander and Myllymaki 2006) have shown DP is more efficient than other dynamic programming implementations.", "startOffset": 17, "endOffset": 46}, {"referenceID": 14, "context": "Previous results (Silander and Myllymaki 2006) have shown DP is more efficient than other dynamic programming implementations. We also compared to Yuan et al.\u2019s A* implementation (2011) (A*) and de Campos et al.", "startOffset": 18, "endOffset": 186}, {"referenceID": 2, "context": "\u2019s A* implementation (2011) (A*) and de Campos et al.\u2019s branch and bound systematic search algorithm (de Campos, Zeng, and Ji 2009) (SS) downloaded from http://www.ecse.rpi.edu/ cvrl/structlearning.html. We did not include comparison to the DP implementation of Malone et al. (2011) (MDP) because the codebase is similar; however, MDP does not incorporate pruning or delayed duplicate detection.", "startOffset": 40, "endOffset": 283}, {"referenceID": 14, "context": "Previous results found that memory is the main bottleneck restricting the size of learnable networks (Parviainen and Koivisto 2009).", "startOffset": 101, "endOffset": 131}, {"referenceID": 14, "context": "This suggests that our method should scale to larger networks better than the method of Parviainen and Koivisto (2009). They observe that their implementation would take 4 weeks on 100 processors to learn a 31-variable network, and, even with coding improvements and massive parallelization, only networks up to 34 variables would be possible.", "startOffset": 88, "endOffset": 119}, {"referenceID": 14, "context": "Also, like existing methods (Parviainen and Koivisto 2009; Silander and Myllymaki 2006), our algorithm can benefit from parallel computing.", "startOffset": 28, "endOffset": 87}, {"referenceID": 16, "context": "Also, like existing methods (Parviainen and Koivisto 2009; Silander and Myllymaki 2006), our algorithm can benefit from parallel computing.", "startOffset": 28, "endOffset": 87}], "year": 2011, "abstractText": "Previous work has shown that the problem of learning the optimal structure of a Bayesian network can be formulated as a shortest path finding problem in a graph and solved using A* search. In this paper, we improve the scalability of this approach by developing a memoryefficient heuristic search algorithm for learning the structure of a Bayesian network. Instead of using A*, we propose a frontier breadth-first branch and bound search that leverages the layered structure of the search graph of this problem so that no more than two layers of the graph, plus solution reconstruction information, need to be stored in memory at a time. To further improve scalability, the algorithm stores most of the graph in external memory, such as hard disk, when it does not fit in RAM. Experimental results show that the resulting algorithm solves significantly larger problems than the current state of the art.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}