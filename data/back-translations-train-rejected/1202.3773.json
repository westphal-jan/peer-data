{"id": "1202.3773", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2012", "title": "Measuring the Hardness of Stochastic Sampling on Bayesian Networks with Deterministic Causalities: the k-Test", "abstract": "Approximate Bayesian inference is NP-hard. Dagum and Luby defined the Local Variance Bound (LVB) to measure the approximation hardness of Bayesian inference on Bayesian networks, assuming the networks model strictly positive joint probability distributions, i.e. zero probabilities are not permitted. This paper introduces the k-test to measure the approximation hardness of inference on Bayesian networks with deterministic causalities in the probability distribution, i.e. when zero conditional probabilities are permitted. Approximation by stochastic sampling is a widely-used inference method that is known to suffer from inefficiencies due to sample rejection. The k-test predicts when rejection rates of stochastic sampling a Bayesian network will be low, modest, high, or when sampling is intractable.", "histories": [["v1", "Tue, 14 Feb 2012 16:41:17 GMT  (224kb)", "http://arxiv.org/abs/1202.3773v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["haohai yu", "robert a van engelen"], "accepted": false, "id": "1202.3773"}, "pdf": {"name": "1202.3773.pdf", "metadata": {"source": "CRF", "title": "Measuring the Hardness of Stochastic Sampling on Bayesian Networks with Deterministic Causalities: the k-Test", "authors": ["Haohai Yu"], "emails": [], "sections": [{"heading": null, "text": "Dagum and Luby defined the Local Variance Bound (LVB) to measure the approximation hardness of Bayesian inference to Bayesian networks, with the network model providing only positive common probability distributions, i.e. zero probabilities are not permitted. In this paper, the k-test is introduced to measure the approximation hardness of inference to Bayesian networks with deterministic causalities in the probability distribution, i.e. when zero conditional probabilities are permissible. Approximation by stochastic sampling is a widely used inference method that is known to suffer from inefficiencies due to sample repulsion. k-test predicts when the rejection rates of stochastic sampling of a Bayesian network are low, modest, high, or when sampling is intractable."}, {"heading": "1 Introduction", "text": "It is time for us to set out in search of new ways to travel the world, to travel the world in which we live."}, {"heading": "2 Background", "text": "This section briefly introduces Bayesian networking formalism, Bayesian inference by importance testing, and the problem of sample repulsion."}, {"heading": "2.1 Bayesian Networks", "text": "A Bayesian network is defined as follows: Definition 1 A Bayesian network BN = (G, Pr) consists of a directed acyclic graph (DAG) G = (V, A) with vertices V, arcs A V \u00b7 V, and a JPD Pr via the discrete random variable V (represented by the vertices of G). Pr is defined by Pr (V) = VP (V | V Pr (V))) for all V-V. In this essay, variables are denoted by uppercase letters and their states by lowercase letters. Sentences (vertices, slurs, and states) of the BN have domain-specific probabilities Pr (V | \u03c0 (V) for all V-V. In this essay, variables are denoted by uppercase letters and their states by lowercase letters."}, {"heading": "2.2 Approximate Bayesian Inference by Importance Sampling", "text": "Let g (X) a function over m variable X = {X1, say that it is easier to create a sample than we do. (X) Let p is a probability density over X. Consider the problem of estimating the integral requirements (X). (D) Sampling (X) p (X) p (x) dx. (1) Suppose it is a density that is easy to grasp, the integral principle can be achieved by drawing a set of independent and identically distributed (i.d.) samples {x1,.) xN) of p (X) and using this to calculate the sample. (D) The integral requirements can be achieved by drawing a set of independent and identically distributed (i.D) sampling (X)."}, {"heading": "3.1 Hardness of Sample Rejection", "text": "The calculation method Pr (x) for each x problem is generally very difficult; the calculation method Pr (x) for classifying inconsistent samples x with Pr (x) = 0 of consistent samples with Pr (x) > 0 is prohibitively expensive as a measure for determining the hardness of sampling. Furthermore, the approximate sample refusal problem is too difficult to be polynomial, as the JPDs of these networks are not exclusively positive (an assumption used in their evidence); empirically, the refusal rate estimates a significant number of samples that need to be produced to cover the exponential state space of a network."}, {"heading": "4 Results", "text": "This year, the number of working women in Germany has risen by more than 20 percent."}, {"heading": "5 Conclusions", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "A Appendix", "text": "\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}], "references": [{"title": "Random k-SAT: Two moments suffice to cross a sharp threshold", "author": ["D. Achlioptas", "C. Moore"], "venue": "SIAM J. Comput.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Two theorems on random polynomial time", "author": ["L. Adleman"], "venue": "SFCS", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1978}, {"title": "MUNIN \u2014 an expert EMG assistant", "author": ["S. Andreassen", "F. Jensen", "S. Andersen", "B. Falck", "U. Kj\u00e6rulff", "M. Woldbye", "A.R. Sorensen", "A. Rosenfalck"], "venue": "Computer-Aided Electromyography and Expert Systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1989}, {"title": "Computational Complexity: A Modern Approach", "author": ["S. Arora", "B. Barak"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Evaluation of Probabilistic Inference System, 2006. http://ssli.ee.washington.edu/~bilmes/ uai06InferenceEvaluation", "author": ["J. Bilmes", "R. Dechter"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Probabilistic analysis of a generalization of the unit clause literal selection heuristic for the k-satisfiability problem", "author": ["M. Chao", "J. Franco"], "venue": "Information Science,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1990}, {"title": "AIS-BN: An adaptive importance sampling algorithm for evidential reasoning in large Bayesian networks", "author": ["J. Cheng", "M.J. Druzdzel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Mick gets some (the odds are on his side) (satisfiability)", "author": ["V. Chvatal", "B. Reed"], "venue": "SFCS", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1992}, {"title": "A better algorithm for random k-SAT", "author": ["A. Coja-Oghlan"], "venue": "SIAM Journal on Computing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "On-line student modeling for coached problem solving using Bayesian networks", "author": ["C. Conati", "A.S. Gertner", "K. VanLehn", "M.J. Druzdzel"], "venue": "In Proceedings of the Sixth International Conference on User Modeling", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "The computational complexity of probabilistic inference using Bayesian belief networks", "author": ["G.F. Cooper"], "venue": "Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1990}, {"title": "Approximating probabilistic inference in Bayesian belief networks is NP-hard", "author": ["P. Dagum", "M. Luby"], "venue": "Artificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1993}, {"title": "An optimal approximation algorithm for Bayesian inference", "author": ["P. Dagum", "M. Luby"], "venue": "Artif. Intell.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}, {"title": "Mixtures of deterministic-probabilistic networks and their and/or search space", "author": ["R. Dechter", "R. Mateescu"], "venue": "Proceedings of the 20th conference on Uncertainty in artificial intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Probabilistic analysis of the Davis Putnam procedure for solving the satisfiability problem", "author": ["J. Franco", "M. Paull"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1983}, {"title": "Necessary and sufficient conditions for sharp thresholds of graph properties and k- SAT problem", "author": ["E. Friedgut"], "venue": "J. Amer. Math. Soc.,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "A survey of research in deliberative real-time artificial intelligence", "author": ["A.J. Garvey", "V.R. Lesser"], "venue": "Real-Time Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1994}, {"title": "The log-support encoding of CSP into SAT", "author": ["M. Gavanelli"], "venue": "In Proceedings of the 13th international conference on principles and practice of constraint programming,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Approximate inference algorithms for hybrid Bayesian networks with discrete constraints", "author": ["V. Gogate", "R. Dechter"], "venue": "In Proceedings of Uncertainty in Artificial Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "A new algorithm for sampling CSP solutions uniformly at random", "author": ["V. Gogate", "R. Dechter"], "venue": "In International Conference on Principles and Practice of Constraint Programming (CP),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Approximate counting by sampling the backtrack-free search space", "author": ["V. Gogate", "R. Dechter"], "venue": "In Conference on Artificial Intelligence (AAAI),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "SampleSearch: Importance sampling in presence of determinism", "author": ["V. Gogate", "R. Dechter"], "venue": "Artificial Intelligence,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "A survey on algorithms for real-time Bayesian network inference. In In the joint AAAI-02/KDD-02/UAI-02 workshop on Real-Time Decision Support and Diagnosis", "author": ["H. Guo", "W. Hsu"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2002}, {"title": "Toward normative expert systems: Part I the pathfinder project", "author": ["D.E. Heckerman", "E.J. Horvitz", "B.N. Nathwani"], "venue": "Methods of Information in Medicine,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1992}, {"title": "Turing machines that take advice", "author": ["R. Karp", "R. Lipton"], "venue": "L\u2019Enseignement Mathe\u0301matiques,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1982}, {"title": "Mixed deterministic and probabilistic networks", "author": ["R. Mateescu", "R. Dechter"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "Dynamic importance sampling in Bayesian networks based on probability trees", "author": ["S. Moral", "A. Salmer\u00f3n"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2005}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1988}, {"title": "Knowledge engineering for large belief networks", "author": ["M. Pradhan", "G. Provan", "B. Middleton", "M. Henrion"], "venue": "In Proceedings of the 10th conference on Uncertainty in artificial intelligence,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1994}, {"title": "Simulation and Monte Carlo Method", "author": ["R.Y. Rubinstein"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1981}, {"title": "Artificial intelligence: A modern approach", "author": ["S. Russell", "P. Norvig"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1995}, {"title": "Simulation approaches to general probabilistic inference on belief networks", "author": ["R.D. Shachter", "M.A. Peot"], "venue": "In Proceedings of the 5th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1990}, {"title": "Halting space-bounded computations", "author": ["M. Sipser"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1980}, {"title": "Refractor importance sampling", "author": ["H. Yu", "R. van Engelen"], "venue": "In Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2008}, {"title": "An importance sampling algorithm based on evidence prepropagation", "author": ["C. Yuan", "M.J. Druzdzel"], "venue": "In Proceedings of the 19th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2003}, {"title": "Theoretical analysis and practical insights on importance sampling in Bayesian networks", "author": ["C. Yuan", "M.J. Druzdzel"], "venue": "Int. J. Approx. Reasoning,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2007}], "referenceMentions": [{"referenceID": 27, "context": "A Bayesian network, belief network, or directed acyclic graphical model, is a probabilistic graph model [28] that has gained wide acceptance in several areas of", "startOffset": 104, "endOffset": 108}, {"referenceID": 30, "context": "artificial intelligence [31].", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": "Exact and approximate probabilistic Bayesian inference is known to be NP-hard [11, 12].", "startOffset": 78, "endOffset": 86}, {"referenceID": 11, "context": "Exact and approximate probabilistic Bayesian inference is known to be NP-hard [11, 12].", "startOffset": 78, "endOffset": 86}, {"referenceID": 16, "context": "Approximate inference algorithms are popular due to their anytime property [17] to produce an approximate result, possibly in real time [23].", "startOffset": 75, "endOffset": 79}, {"referenceID": 22, "context": "Approximate inference algorithms are popular due to their anytime property [17] to produce an approximate result, possibly in real time [23].", "startOffset": 136, "endOffset": 140}, {"referenceID": 30, "context": "For this reason, stochastic sampling algorithms, especially importance sampling, are among the most widely-used approximate inference methods [31].", "startOffset": 142, "endOffset": 146}, {"referenceID": 31, "context": "Examples are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 17, "endOffset": 21}, {"referenceID": 6, "context": "Examples are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 30, "endOffset": 33}, {"referenceID": 26, "context": "Examples are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 39, "endOffset": 43}, {"referenceID": 33, "context": "Examples are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 49, "endOffset": 53}, {"referenceID": 34, "context": "Examples are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 66, "endOffset": 70}, {"referenceID": 12, "context": "The local variance bound (LVB) [13] metric demarcates the boundary between the class of Bayesian networks with tractable approximations and those with intractable approximations.", "startOffset": 31, "endOffset": 35}, {"referenceID": 2, "context": "This means that the LVB is undefined for many real-world networks that model JPDs with zero probabilities, such as Munin [3], Pathfinder [24], Andes [10] and the CPCS [29] networks.", "startOffset": 121, "endOffset": 124}, {"referenceID": 23, "context": "This means that the LVB is undefined for many real-world networks that model JPDs with zero probabilities, such as Munin [3], Pathfinder [24], Andes [10] and the CPCS [29] networks.", "startOffset": 137, "endOffset": 141}, {"referenceID": 9, "context": "This means that the LVB is undefined for many real-world networks that model JPDs with zero probabilities, such as Munin [3], Pathfinder [24], Andes [10] and the CPCS [29] networks.", "startOffset": 149, "endOffset": 153}, {"referenceID": 28, "context": "This means that the LVB is undefined for many real-world networks that model JPDs with zero probabilities, such as Munin [3], Pathfinder [24], Andes [10] and the CPCS [29] networks.", "startOffset": 167, "endOffset": 171}, {"referenceID": 29, "context": "For more details refer to [30, 36].", "startOffset": 26, "endOffset": 34}, {"referenceID": 35, "context": "For more details refer to [30, 36].", "startOffset": 26, "endOffset": 34}, {"referenceID": 6, "context": "This is true for AIS-BN [7], EPIS-BN [35], and SIS [32].", "startOffset": 24, "endOffset": 27}, {"referenceID": 34, "context": "This is true for AIS-BN [7], EPIS-BN [35], and SIS [32].", "startOffset": 37, "endOffset": 41}, {"referenceID": 31, "context": "This is true for AIS-BN [7], EPIS-BN [35], and SIS [32].", "startOffset": 51, "endOffset": 55}, {"referenceID": 26, "context": "By contrast, the tractable sampling order of DIS [27] is a reversed elimination order, which may or may not be consistent with a Bayesian network\u2019s topological order of the vertices.", "startOffset": 49, "endOffset": 53}, {"referenceID": 10, "context": "Cooper [11] proved that computing Pr(x) for any x is NP-hard in general.", "startOffset": 7, "endOffset": 11}, {"referenceID": 11, "context": "Dagum and Luby [12] proved that approximate Bayesian inference is NP-hard.", "startOffset": 15, "endOffset": 19}, {"referenceID": 14, "context": "Franco and Paull [15] first observed, among other important results, that random instances of the k-SAT problem undergo a \u201cphase transition\u201d as the ratio of clauses to variables passes through a threshold.", "startOffset": 17, "endOffset": 21}, {"referenceID": 14, "context": "Franco and Paull [15] claim that F k is with high probability (w.", "startOffset": 17, "endOffset": 21}, {"referenceID": 15, "context": "stone paper [16], Friedgut used the second moment method to prove the existence of a nonuniform satisfiability threshold, i.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "Inspired by [16], Dimitris and Cristopher [1] further narrowed the threshold around O(2k\u22121 ln 2).", "startOffset": 12, "endOffset": 16}, {"referenceID": 0, "context": "Inspired by [16], Dimitris and Cristopher [1] further narrowed the threshold around O(2k\u22121 ln 2).", "startOffset": 42, "endOffset": 45}, {"referenceID": 5, "context": "In [6] and [8] this method is used to narrow the lower bound of rk to O(2/k).", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "In [6] and [8] this method is used to narrow the lower bound of rk to O(2/k).", "startOffset": 11, "endOffset": 14}, {"referenceID": 8, "context": "The current best result is from [9], which not only presents a polynomial algorithm that finds a satisfying truth assignment w.", "startOffset": 32, "endOffset": 35}, {"referenceID": 17, "context": "Convert all variables V to Boolean variables by log encoding [18].", "startOffset": 61, "endOffset": 65}, {"referenceID": 2, "context": "Munin [3], Pathfinder [24], Andes [10] and CPCS [29] are networks with significant levels of determinism, suggesting difficulties with high rejection rates to sample them.", "startOffset": 6, "endOffset": 9}, {"referenceID": 23, "context": "Munin [3], Pathfinder [24], Andes [10] and CPCS [29] are networks with significant levels of determinism, suggesting difficulties with high rejection rates to sample them.", "startOffset": 22, "endOffset": 26}, {"referenceID": 9, "context": "Munin [3], Pathfinder [24], Andes [10] and CPCS [29] are networks with significant levels of determinism, suggesting difficulties with high rejection rates to sample them.", "startOffset": 34, "endOffset": 38}, {"referenceID": 28, "context": "Munin [3], Pathfinder [24], Andes [10] and CPCS [29] are networks with significant levels of determinism, suggesting difficulties with high rejection rates to sample them.", "startOffset": 48, "endOffset": 52}, {"referenceID": 4, "context": "mark networks from the UAI contest [5] is shown in Table 2.", "startOffset": 35, "endOffset": 38}, {"referenceID": 31, "context": "Example sampling improvements are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 38, "endOffset": 42}, {"referenceID": 6, "context": "Example sampling improvements are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 51, "endOffset": 54}, {"referenceID": 26, "context": "Example sampling improvements are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 60, "endOffset": 64}, {"referenceID": 33, "context": "Example sampling improvements are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 70, "endOffset": 74}, {"referenceID": 34, "context": "Example sampling improvements are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35].", "startOffset": 87, "endOffset": 91}, {"referenceID": 6, "context": "The rejection problem in importance sampling has been extensively studied in the work on adaptive sampling schemes [7], in the context of constraint propagation [20], and Boolean satisfiability problems [21].", "startOffset": 115, "endOffset": 118}, {"referenceID": 19, "context": "The rejection problem in importance sampling has been extensively studied in the work on adaptive sampling schemes [7], in the context of constraint propagation [20], and Boolean satisfiability problems [21].", "startOffset": 161, "endOffset": 165}, {"referenceID": 20, "context": "The rejection problem in importance sampling has been extensively studied in the work on adaptive sampling schemes [7], in the context of constraint propagation [20], and Boolean satisfiability problems [21].", "startOffset": 203, "endOffset": 207}, {"referenceID": 18, "context": "A restricted form of constraint propagation can be used to reduce the amount of rejection [19].", "startOffset": 90, "endOffset": 94}, {"referenceID": 19, "context": "An approach to circumvent the rejection problem by systematically searching for a nonzero weight sample for constraintbased systems was introduced in [20].", "startOffset": 150, "endOffset": 154}, {"referenceID": 20, "context": "The proposed backtracking algorithm, SampleSearch was further improved in [21] and shown to generate a backtrack-free distribution.", "startOffset": 74, "endOffset": 78}, {"referenceID": 21, "context": "In [22], the SampleSearch method is fur-", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "ther generalized as a scheme in the framework of mixed networks [14, 26].", "startOffset": 64, "endOffset": 72}, {"referenceID": 25, "context": "ther generalized as a scheme in the framework of mixed networks [14, 26].", "startOffset": 64, "endOffset": 72}, {"referenceID": 12, "context": "The LVB [13] metric demarcates the boundary between the class of Bayesian networks with tractable approximations and those with intractable approximations.", "startOffset": 8, "endOffset": 12}, {"referenceID": 2, "context": "LVB is undefined for many real-world networks that model JPDs with zero probabilities, such as Munin [3], Pathfinder [24], Andes [10] and the CPCS [29] networks.", "startOffset": 101, "endOffset": 104}, {"referenceID": 23, "context": "LVB is undefined for many real-world networks that model JPDs with zero probabilities, such as Munin [3], Pathfinder [24], Andes [10] and the CPCS [29] networks.", "startOffset": 117, "endOffset": 121}, {"referenceID": 9, "context": "LVB is undefined for many real-world networks that model JPDs with zero probabilities, such as Munin [3], Pathfinder [24], Andes [10] and the CPCS [29] networks.", "startOffset": 129, "endOffset": 133}, {"referenceID": 28, "context": "LVB is undefined for many real-world networks that model JPDs with zero probabilities, such as Munin [3], Pathfinder [24], Andes [10] and the CPCS [29] networks.", "startOffset": 147, "endOffset": 151}], "year": 2011, "abstractText": "Approximate Bayesian inference is NP-hard. Dagum and Luby defined the Local Variance Bound (LVB) to measure the approximation hardness of Bayesian inference on Bayesian networks, assuming the networks model strictly positive joint probability distributions, i.e. zero probabilities are not permitted. This paper introduces the k-test to measure the approximation hardness of inference on Bayesian networks with deterministic causalities in the probability distribution, i.e. when zero conditional probabilities are permitted. Approximation by stochastic sampling is a widely-used inference method that is known to suffer from inefficiencies due to sample rejection. The k-test predicts when rejection rates of stochastic sampling a Bayesian network will be low, modest, high, or when sampling is intractable.", "creator": "TeX"}}}