{"id": "1202.4905", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2012", "title": "A Bi-Directional Refinement Algorithm for the Calculus of (Co)Inductive Constructions", "abstract": "The paper describes the refinement algorithm for the Calculus of (Co)Inductive Constructions (CIC) implemented in the interactive theorem prover Matita.", "histories": [["v1", "Wed, 22 Feb 2012 13:33:26 GMT  (62kb,D)", "https://arxiv.org/abs/1202.4905v1", null], ["v2", "Thu, 1 Mar 2012 20:49:22 GMT  (65kb,D)", "http://arxiv.org/abs/1202.4905v2", null]], "reviews": [], "SUBJECTS": "cs.LO cs.AI", "authors": ["andrea asperti", "wilmer ricciotti", "claudio sacerdoti coen", "enrico tassi"], "accepted": false, "id": "1202.4905"}, "pdf": {"name": "1202.4905.pdf", "metadata": {"source": "CRF", "title": "A BI-DIRECTIONAL REFINEMENT ALGORITHM FOR THE CALCULUS OF (CO)INDUCTIVE CONSTRUCTIONS", "authors": ["ANDREA ASPERTI", "WILMER RICCIOTTI", "CLAUDIO SACERDOTI COEN"], "emails": ["asperti@cs.unibo.it", "ricciott@cs.unibo.it", "sacerdot@cs.unibo.it", "enrico.tassi@inria.fr"], "sections": [{"heading": null, "text": "The refinement algorithm is responsible for giving meaning to terms, types and proofs written directly by the user or generated by the use of tactics, decision-making processes or general automation; the terms are written in an \"external syntax\" that is intended to be user-friendly and allows for the omission of information, untyped folders and a certain liberal use of custom sub-typing; the refinement algorithm modifies the terms to obtain related well-typed terms in the internal syntax understood by the core of the ITP; in particular, it acts as a kind of sequencing algorithm when all binder types are untyped; the proposed algorithm is bidirectional: in the face of a term in the external syntax and a type expected for the term, it propagates as much typing of information as possible towards the sheets of the term. Traditional mono-type algorithms are bidirectional: given a term in the external syntax and a type expected for the term, it propagates as much typing as possible towards the sheets of the term."}, {"heading": "1. Introduction", "text": "In fact, the fact is that most of them are able to move to another world in which they are able to live."}, {"heading": "2. Preliminaries", "text": "We start with the introduction of the syntax for CIC terms and objects in Table 1 and some naming conventions. (To denote constants, we use c, c1, c2.) The special case of (co) recursively defined constants is therefore also denoted by f, f1, f2. (We reserve x, y, x1, x2.) for variables and we use s, s, s1, t, t. \"We specify a context of variable declarations (x: T) or typed definitions (x: T)."}, {"heading": "3. Mono-directional refinement", "text": "In this section, we assume that the external syntax can only be achieved by adding new typing. To specify what a refinement algorithm is, we must first introduce the concept of evidence facilitation. A pair (proof, substitution) is refined by another pair when the second is replaced by the reduction of some evidentiary duties to new ones. Thus, it represents an evolution of the evidentiary facilitation."}, {"heading": "4. Bi-directional refinement", "text": "In order to achieve bidirectional implementation in frequently occurring situations, we must add new rules to the R algorithms. (These ad hoc rules for certain cases must take precedence over the generic (R standard) rule. (The ad hoc rules are responsible for propagating information of the expected type to the sheets of the term.) The new rule for the use of constructors is completely new and it uses additional knowledge of the constant parameters of an inductive type. It is also the only one to be implemented in Coq. (Co) Productive constructions are also the rule that, in our experience, affects the behavior of the constructors. It makes it possible to refix many other terms in which a mono-directional construction is used. (Co) Productive constructions are also the rule that influences the behavior of the refiners."}, {"heading": "5. Extension to placeholders", "text": "It is about the question of to what extent it is actually about a way, in which it is about the question of whether and to what extent it is actually about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, and in which it is about a way, and in which it is about a way, and in which it is about a way, and in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way in which it is about a way and in which it is about a way in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way in which it is about a way and in which it is about a way and in which it is about a way in which it is about a way and in which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about which it is about a way and in which it is about which it is about which it is about which it is about which it is about which it is about a way and in which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which"}, {"heading": "6. Coercions", "text": "The second case is handy in two situations. First, if the head of the application is implicit in the standard notation, as in 3x, where the intended headroom is the multiplication."}, {"heading": "7. Comparison with related work on Type Inference", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "8. Conclusion", "text": "In fact, it is such that it is a matter of a way in which one sees oneself in a position to recognize and understand one's identity. (...) In fact, it is not such that one is able to recognize one's identity. (...) In fact, it is such that one is able to question one's own identity. (...) In fact, it is such that one is able to recognize one's own identity. (...) \"(...)\" () \"() (() () (()) (() () () () () () () () () () () () () () () () () () () () () () () ()) () () () () () ()) () () ()) () () () () () () ()) () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () (() (() (() () () (() (() () () (() ((() (() (() () () (() (() ((() (() (() ((() () (((() () (() (() () () (() ((() (() ((() (((((() () (() () ((((() (() (() (((((() () (((()"}, {"heading": "Appendix A. Syntax-directed type-checking rules", "text": "The following appendix is an excerpt from the paper [4], in which the reader can find all the details of the type verification algorithm implemented in the Matita interactive evidence collection. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 Verifying the consistency of WF WF WF with respect to the WF-WF adopted in this paper. The main differences are summarized in the following list: \u2022 We use the membership relationship via PTS verification, which is set to the type of varieties and products \u2022 Verification for the consistency of metavariable local substitution has been included in the rule \u2022 A new generic judgment (r: T) \"Env\" has been introduced to provide a compact syntax for searching for the type of generic object in the environment. \u2022 We have several auxiliary functions used in the presentation of the Typecheck rule for case analysis. This was made possible by the following misuse of the notation: Env,"}], "references": [{"title": "A page in number theory", "author": ["Andrea Asperti", "Cristian Armentano"], "venue": "Journal of Formalized Reasoning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "About the formalization of some results by Chebyshev in number theory", "author": ["Andrea Asperti", "Wilmer Ricciotti"], "venue": "In Proc. of TYPES\u201908,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Formal metatheory of programming languages in the Matita interactive theorem prover", "author": ["Andrea Asperti", "Wilmer Ricciotti", "Claudio Sacerdoti Coen", "Enrico Tassi"], "venue": "Journal of Automated Reasoning: Special Issue on the Poplmark Challenge. Published online,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "A compact kernel for the Calculus of Inductive Constructions. Sadhana", "author": ["Andrea Asperti", "Wilmer Ricciotti", "Claudio Sacerdoti Coen", "Enrico Tassi"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Hints in unification", "author": ["Andrea Asperti", "Wilmer Ricciotti", "Claudio Sacerdoti Coen", "Enrico Tassi"], "venue": "In TPHOLs 2009,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "User interaction with the Matita proof assistant", "author": ["Andrea Asperti", "Claudio Sacerdoti Coen", "Enrico Tassi", "Stefano Zacchiroli"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Lambda Calculi with Types", "author": ["Henk Barendregt"], "venue": "In Abramsky, Samson and others, editor, Handbook of Logic in Computer Science,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1992}, {"title": "A brief overview of Agda - a functional language with dependent types", "author": ["Ana Bove", "Peter Dybjer", "Ulf Norell"], "venue": "In Theorem Proving in Higher Order Logics, 22nd International Conference,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Coherence checking of coercions in Plastic", "author": ["P. Callaghan"], "venue": "Proc. Workshop on Subtyping and Dependent Types in Programming,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Subtyping, Type Conversion and Transitivity Elimination", "author": ["Gang Chen"], "venue": "PhD thesis, University Paris", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Formalizing Overlap Algebras in Matita", "author": ["Claudio Sacerdoti Coen", "Enrico Tassi"], "venue": "Mathematical Structures in Computer Science,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "The Calculus of Constructions", "author": ["Thierry Coquand", "G\u00e9rard P. Huet"], "venue": "Inf. Comput.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "Greedy bidirectional polymorphism", "author": ["Joshua Dunfield"], "venue": "In ML Workshop (ML", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Tridirectional typechecking", "author": ["Joshua Dunfield", "Frank Pfenning"], "venue": "In X. Leroy, editor, Conference Record of the 31st Annual Symposium on Principles of Programming Languages", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Packaging mathematical structures", "author": ["Fran\u00e7ois Garillot", "Georges Gonthier", "Assia Mahboubi", "Laurence Rideau"], "venue": "In Proceedings of the 22nd International Conference on Theorem Proving in Higher Order Logics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "A unification algorithm for typed lambda-calculus", "author": ["G\u00e9rard P. Huet"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1975}, {"title": "Coercive subtyping", "author": ["Zhaohui Luo"], "venue": "J. Logic and Computation,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1999}, {"title": "A Calculus of Substitutions for Incomplete-Proof Representation in Type Theory", "author": ["C\u00e9sar Mu\u00f1oz"], "venue": "PhD thesis,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1997}, {"title": "Towards a practical programming language based on dependent type theory", "author": ["Ulf Norell"], "venue": "PhD thesis, Department of Computer Science and Engineering, Chalmers University of Technology,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "D\u00e9finitions Inductives en Th\u00e9orie des Types d\u2019Ordre Sup\u00e9rieur", "author": ["Christine Paulin-Mohring"], "venue": "Habilitation a\u0300 diriger les recherches,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1996}, {"title": "Local type inference", "author": ["Benjamin C. Pierce", "David N. Turner"], "venue": "ACM Trans. Program. Lang. Syst.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2000}, {"title": "Dependently typed records in type theory", "author": ["Robert Pollack"], "venue": "Formal Aspects of Computing,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Mathematical Knowledge Management and Interactive Theorem Proving", "author": ["Claudio Sacerdoti Coen"], "venue": "PhD thesis, University of Bologna,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2004}, {"title": "Spurious disambiguation errors and how to get rid of them", "author": ["Claudio Sacerdoti Coen", "Stefano Zacchiroli"], "venue": "Journal of Mathematics in Computer Science, special issue on Management of Mathematical Knowledge,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2008}, {"title": "Typing algorithm in type theory with inheritance", "author": ["Amokrane S\u00e4\u0131bi"], "venue": "In Proceedings of the 24th ACM SIGPLAN-SIGACT symposium on Principles of programming languages,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1997}, {"title": "Subset coercions in Coq. In Types for Proofs and Programs, volume 4502/2007 of LNCS, pages 237\u2013252", "author": ["Matthieu Sozeau"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2006}, {"title": "First-class type classes", "author": ["Matthieu Sozeau", "Nicolas Oury"], "venue": "In Proceedings of TPHOLs,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Verified Computing in Homological Algebra. A Journey Esploring the Power and Limits of Dependent Type Theory", "author": ["Arnaud Spiwack"], "venue": "PhD thesis, E\u0301cole Polytechniqe,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Construction and Deduction in Type Theories", "author": ["Martin Strecker"], "venue": "PhD thesis, Universita\u0308t Ulm,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1998}, {"title": "Type processing by constraint reasoning", "author": ["Peter J. Stuckey", "Martin Sulzmann", "Jeremy Wazny"], "venue": "In APLAS, pages", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2006}, {"title": "Interactive Theorem Provers: issues faced as a user and tackled as a developer", "author": ["Enrico Tassi"], "venue": "PhD thesis,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2008}, {"title": "Une Th\u00e9orie des Constructions Inductives", "author": ["Benjamin Werner"], "venue": "PhD thesis,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1994}], "referenceMentions": [{"referenceID": 5, "context": "This paper is devoted to the description of a refinement algorithm for the Calculus of (Co)Inductive Constructions, the type theory on which the Matita [6], Coq [12] and Lego [19] ITPs are based on.", "startOffset": 152, "endOffset": 155}, {"referenceID": 3, "context": "In this and in the previous paper [4] we are interested in the implementation of interactive theorem provers (ITP) for dependently typed languages that are heavily based on the Curry-Howard isomorphism.", "startOffset": 34, "endOffset": 37}, {"referenceID": 7, "context": "Agda [8] and Matita [6] are examples of systems implemented in this way.", "startOffset": 5, "endOffset": 8}, {"referenceID": 5, "context": "Agda [8] and Matita [6] are examples of systems implemented in this way.", "startOffset": 20, "endOffset": 23}, {"referenceID": 27, "context": "thesis [31] partially describes a forthcoming release of Coq 8.", "startOffset": 7, "endOffset": 11}, {"referenceID": 3, "context": "The implementation of a kernel for a variant of the Calculus of (Co)Inductive Constructions (CIC) has been described in [4] down to the gory details that make the implementation efficient.", "startOffset": 120, "endOffset": 123}, {"referenceID": 14, "context": "Canonical structures [16], unification hints [5] and type classes [30] are devices that let the user drive some form of proof search that is seamlessly integrated in the refinement process.", "startOffset": 21, "endOffset": 25}, {"referenceID": 4, "context": "Canonical structures [16], unification hints [5] and type classes [30] are devices that let the user drive some form of proof search that is seamlessly integrated in the refinement process.", "startOffset": 45, "endOffset": 48}, {"referenceID": 26, "context": "Canonical structures [16], unification hints [5] and type classes [30] are devices that let the user drive some form of proof search that is seamlessly integrated in the refinement process.", "startOffset": 66, "endOffset": 70}, {"referenceID": 20, "context": "To avoid or mitigate the drawbacks of type inference, bi-directional type-checking algorithms have been introduced in the literature [24].", "startOffset": 133, "endOffset": 137}, {"referenceID": 15, "context": "3To the authors knowledge, Isabelle [18] is the only interactive prover implementing Huet\u2019s algorithm [17] capable of generating all second order unifiers", "startOffset": 102, "endOffset": 106}, {"referenceID": 9, "context": "In the latter case, the system needs to recognize that lists are containers and has to have code to lift coercions over containers, like in [10].", "startOffset": 140, "endOffset": 144}, {"referenceID": 5, "context": "The rest of the paper explains the bi-directional refinement algorithm implemented in Matita [6].", "startOffset": 93, "endOffset": 96}, {"referenceID": 3, "context": "For the sake of the reader, Appendix 8 is taken from [4] with minor modifications and it shows the type checking algorithm implemented by the kernel.", "startOffset": 53, "endOffset": 56}, {"referenceID": 17, "context": "The CIC calculus extended with metavariables has been studied in [21] and the flavor of metavariables implemented in Matita is described in [26].", "startOffset": 65, "endOffset": 69}, {"referenceID": 22, "context": "The CIC calculus extended with metavariables has been studied in [21] and the flavor of metavariables implemented in Matita is described in [26].", "startOffset": 140, "endOffset": 144}, {"referenceID": 6, "context": "We regard CIC as a Pure Type System [7], and we denote by PTS the set of axioms.", "startOffset": 36, "endOffset": 39}, {"referenceID": 3, "context": "The details for the actual PTS used in Matita are given in [4].", "startOffset": 59, "endOffset": 62}, {"referenceID": 3, "context": "This is relevant for CIC since the sort of propositions, Prop, is non informative and cannot be eliminated to inhabit a data type of sort Typeu for any u (but for few exceptions described in [4] Section 6).", "startOffset": 191, "endOffset": 194}, {"referenceID": 31, "context": "The typing judgment implemented in our kernel is an extension of the regular typing judgment for CIC [35, 23, 13].", "startOffset": 101, "endOffset": 113}, {"referenceID": 19, "context": "The typing judgment implemented in our kernel is an extension of the regular typing judgment for CIC [35, 23, 13].", "startOffset": 101, "endOffset": 113}, {"referenceID": 11, "context": "The typing judgment implemented in our kernel is an extension of the regular typing judgment for CIC [35, 23, 13].", "startOffset": 101, "endOffset": 113}, {"referenceID": 3, "context": "It is described in [4] and reported in the Appendix 8.", "startOffset": 19, "endOffset": 22}, {"referenceID": 28, "context": "thesis [32], the order is not preserved by unification and thus in any realistic implementation \u03a3 is to be implemented as a set and the fact that \u03a3 remains a partial order must be preserved as an invariant.", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": "The unification algorithm implemented in Matita goes beyond the scope of this paper, the interested reader can find more details in [26, 5].", "startOffset": 132, "endOffset": 139}, {"referenceID": 4, "context": "The unification algorithm implemented in Matita goes beyond the scope of this paper, the interested reader can find more details in [26, 5].", "startOffset": 132, "endOffset": 139}, {"referenceID": 3, "context": "A precise definition of smallness together with the corresponding rules for pattern matching can be found in [4].", "startOffset": 109, "endOffset": 112}, {"referenceID": 3, "context": "Another important design choice is to design the kernel of the system so that it handles metavariables [4].", "startOffset": 103, "endOffset": 106}, {"referenceID": 27, "context": "thesis [31] discusses this issue at length as a motivation for a complete re-design of the data type for proofs in Coq.", "startOffset": 7, "endOffset": 11}, {"referenceID": 25, "context": "This problem was already partially addressed by Sozeau [29] where he added a new system layer around the refiner to achieve the behavior that our refiner already provides.", "startOffset": 55, "endOffset": 59}, {"referenceID": 20, "context": "The new rule for lambda-abstraction is well known in the literature [24] and it is also the only one implemented in Coq.", "startOffset": 68, "endOffset": 72}, {"referenceID": 16, "context": "While the literature [20] considers them mostly as a device to mimic sub-typing in a calculus lacking it, they have other interesting applications.", "startOffset": 21, "endOffset": 25}, {"referenceID": 21, "context": "The last case is recurrent when algebraic structures are encoded as dependently typed records [25] embedding the type (or carrier) for the elements together with the operations and properties defining the structure.", "startOffset": 94, "endOffset": 98}, {"referenceID": 30, "context": "In Matita, for various reasons detailed in [34], \u2206 is not a graph, but a set of arcs for the transitive closure of the graph.", "startOffset": 43, "endOffset": 47}, {"referenceID": 8, "context": "The last detail worth mentioning is that, all systems known to the authors with the notable exception of Plastic [9], adopt some approximated representation for the nodes in the coercion graph, usually the name of the head constant of the source and target types.", "startOffset": 113, "endOffset": 116}, {"referenceID": 28, "context": "6In the case of dependent types the unification of the types is a necessary condition for the unification of the two terms, as claimed by Strecker [32].", "startOffset": 147, "endOffset": 151}, {"referenceID": 24, "context": "The extension to the typing algorithm of CIC with explicit casts in [28] follows the same spirit of our refinement algorithm for raw terms.", "startOffset": 68, "endOffset": 72}, {"referenceID": 18, "context": "Another work in topic is [22] where Norell describes the bi-directional type inference algorithm implemented in the Agda interactive prover.", "startOffset": 25, "endOffset": 29}, {"referenceID": 18, "context": "The most notable example of type inference algorithm based on constraint solving is the one adopted for the Agda system [22].", "startOffset": 120, "endOffset": 124}, {"referenceID": 29, "context": "A strong characteristic of constraint based type inference is precise error reporting, as described in [33].", "startOffset": 103, "endOffset": 107}, {"referenceID": 23, "context": "Even if it the heuristics adopted in Matita [27] to discard spurious error reports are slightly more complex than the ones proposed by Stuckey, we believe that they provide a similar precision.", "startOffset": 44, "endOffset": 48}, {"referenceID": 12, "context": "Greedy algorithms [14], like the one presented in this paper, are characterized by a very predictable behavior, at the cost of being forced to take early decisions leading to the rejection of some possibly well typed terms.", "startOffset": 18, "endOffset": 22}, {"referenceID": 20, "context": "Many algorithms to infer a polymorphic type for a program prefer to avoid the use of unification [24] since unification variables may represent type constraints coming from distant, loosely related, sub-terms.", "startOffset": 97, "endOffset": 101}, {"referenceID": 13, "context": "These approaches also scaled up to types with some sort of dependency over terms, as in [15].", "startOffset": 88, "endOffset": 92}, {"referenceID": 14, "context": "Recent important developments [16] heavily rely on a user-extensible unification algorithm [5], using it as a predictable form of Prolog-like inference engine.", "startOffset": 30, "endOffset": 34}, {"referenceID": 4, "context": "Recent important developments [16] heavily rely on a user-extensible unification algorithm [5], using it as a predictable form of Prolog-like inference engine.", "startOffset": 91, "endOffset": 94}, {"referenceID": 10, "context": "Its effectiveness has been validated in all the formalizations carried on using the Matita interactive theorem prover [11, 1, 2, 3], whose refiner is based", "startOffset": 118, "endOffset": 131}, {"referenceID": 0, "context": "Its effectiveness has been validated in all the formalizations carried on using the Matita interactive theorem prover [11, 1, 2, 3], whose refiner is based", "startOffset": 118, "endOffset": 131}, {"referenceID": 1, "context": "Its effectiveness has been validated in all the formalizations carried on using the Matita interactive theorem prover [11, 1, 2, 3], whose refiner is based", "startOffset": 118, "endOffset": 131}, {"referenceID": 2, "context": "Its effectiveness has been validated in all the formalizations carried on using the Matita interactive theorem prover [11, 1, 2, 3], whose refiner is based", "startOffset": 118, "endOffset": 131}, {"referenceID": 25, "context": "This eased the implementation of subset coercions in the style of [29], but that topic falls outside the scope of the present paper and is thus not discussed.", "startOffset": 66, "endOffset": 70}, {"referenceID": 3, "context": "The following appendix is an extract of the paper [4] in which the reader can find all the details of the type checking algorithm implemented in the Matita interactive prover.", "startOffset": 50, "endOffset": 53}, {"referenceID": 3, "context": "Moreover, the rule presented in [4] is more liberal than the one presented here that just uses the test (s, s\u2032) \u2208 elim(PTS) to check that a non informative data is never analyzed to obtain an informative one.", "startOffset": 32, "endOffset": 35}, {"referenceID": 3, "context": "The actual rules used in the kernel and the refiner of Matita also allow in every situation the elimination of inhabitants of singleton inductive types, whose definition is given in [4].", "startOffset": 182, "endOffset": 185}, {"referenceID": 3, "context": "\u2212 \u2192 tn guarded by destructors ([4], Sect.", "startOffset": 31, "endOffset": 34}, {"referenceID": 3, "context": "\u2212 \u2192 tn guarded by constructors ([4], Sect.", "startOffset": 32, "endOffset": 35}, {"referenceID": 3, "context": ", kmn n undefined in Env Env,\u03a3 `WF Env,\u03a3,\u03a6 `WF all the conditions in [4], Sect.", "startOffset": 69, "endOffset": 72}, {"referenceID": 3, "context": "Typeu \u2264 Typev Typev \u2264 Typeu are declared constraints ([4], Sect.", "startOffset": 54, "endOffset": 57}, {"referenceID": 3, "context": "3) Env,\u03a3,\u03a6,\u0393 ` Typeu \u2193= Typev Typeu \u2264 Typev is a declared constraint ([4], Sect.", "startOffset": 70, "endOffset": 73}], "year": 2012, "abstractText": "The paper describes the refinement algorithm for the Calculus of (Co)Inductive Constructions (CIC) implemented in the interactive theorem prover Matita. The refinement algorithm is in charge of giving a meaning to the terms, types and proof terms directly written by the user or generated by using tactics, decision procedures or general automation. The terms are written in an \u201cexternal syntax\u201d meant to be user friendly that allows omission of information, untyped binders and a certain liberal use of user defined sub-typing. The refiner modifies the terms to obtain related well typed terms in the internal syntax understood by the kernel of the ITP. In particular, it acts as a type inference algorithm when all the binders are untyped. The proposed algorithm is bi-directional: given a term in external syntax and a type expected for the term, it propagates as much typing information as possible towards the leaves of the term. Traditional mono-directional algorithms, instead, proceed in a bottomup way by inferring the type of a sub-term and comparing (unifying) it with the type expected by its context only at the end. We propose some novel bi-directional rules for CIC that are particularly effective. Among the benefits of bi-directionality we have better error message reporting and better inference of dependent types. Moreover, thanks to bi-directionality, the coercion system for sub-typing is more effective and type inference generates simpler unification problems that are more likely to be solved by the inherently incomplete higher order unification algorithms implemented. Finally we introduce in the external syntax the notion of vector of placeholders that enables to omit at once an arbitrary number of arguments. Vectors of placeholders allow a trivial implementation of implicit arguments and greatly simplify the implementation of primitive and simple tactics. 1998 ACM Subject Classification: D.3.1, F.3.0.", "creator": "LaTeX with hyperref package"}}}