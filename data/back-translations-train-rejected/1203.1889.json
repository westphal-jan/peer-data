{"id": "1203.1889", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2012", "title": "Distributional Measures as Proxies for Semantic Relatedness", "abstract": "The automatic ranking of word pairs as per their semantic relatedness and ability to mimic human notions of semantic relatedness has widespread applications. Measures that rely on raw data (distributional measures) and those that use knowledge-rich ontologies both exist. Although extensive studies have been performed to compare ontological measures with human judgment, the distributional measures have primarily been evaluated by indirect means. This paper is a detailed study of some of the major distributional measures; it lists their respective merits and limitations. New measures that overcome these drawbacks, that are more in line with the human notions of semantic relatedness, are suggested. The paper concludes with an exhaustive comparison of the distributional and ontology-based measures. Along the way, significant research problems are identified. Work on these problems may lead to a better understanding of how semantic relatedness is to be measured.", "histories": [["v1", "Thu, 8 Mar 2012 19:03:37 GMT  (66kb)", "http://arxiv.org/abs/1203.1889v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["saif m mohammad", "graeme hirst"], "accepted": false, "id": "1203.1889"}, "pdf": {"name": "1203.1889.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Graeme Hirst"], "emails": ["(smm@cs.toronto.edu)", "(gh@cs.toronto.edu)"], "sections": [{"heading": null, "text": "ar Xiv: 120 3.18 89v1 [cs.CL] 8 March 201 2Keywords: distributional similarity / relatedness, semantic similarity / relatedness, word association, relative entropy, asymmetric metrics, compositional / non-compositional metrics, pseudo-fuzzy metric abbreviations: PCM - primary composition measurement; CRM - co-occurrence retrieval model; KLD - Kullback-Leibler divergence; PMI - Pointwise Mutual Information"}, {"heading": "1. Introduction", "text": "Humans are naturally able to determine whether one word pair is more semantic than another. For example, given the pairs of words honey-bee and paper-car, one can easily identify the former pair to be more semantic than the latter. However, this does not apply to machines. A lot of work has been done in automating the process over the past fifteen years. While some approaches are better than others and have been applied to solving practical problems, no one has assigned human judgment to them. Typically, automated systems display a score of semantic relationships to a particular word pair (target words) calculated from a relatedness measurement. The absolute score is usually irrelevant to one's own judgment. For example, a relatedness score of 0.7 between one and a possible range of 0 to 1 does not imply that one and one average word pair are more related than the average word pair."}, {"heading": "2. Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. CO-OCCURRENCES", "text": "Words that occur within a specific window of a target word are referred to as random events of the word. Window size can be a few words on both sides, the complete sentence, a paragraph, or the entire document. Consider the following sentence: The airplane flew through a cloud. Consider the window size as the complete sentence, flew simultaneously with the airplane, through a cloud, and an airplane. The amount of words that occur simultaneously with a word forms the context of the word. They are used in tasks such as retrieving information, decoding word meanings, and semantic correlations. Distribution measures such as Proxies for Semantic Relatedness 3"}, {"heading": "2.2. WORD ASSOCIATION RATIO", "text": "Given that two events x and y are defined with probabilities P (x) and P (y) (estimated by correlation), their pointwise reciprocal information (Fano, 1961) 1, PMI for short or simple I, is defined as follows: I (x, y) = log2 P (x, y) P (x) P (y) q (y) (1) P (x, y) is the common probability of x and y. If I (x, y) is rated to be close to zero, i, e, P (x, y) \u2248 P (x) \u00d7 P (y), then it means that events x and y occur together as often as is expected by their individual probabilities. If I (x, y), it means that x and y occur together as are expected by their individual probabilities and frequencies."}, {"heading": "2.3. RELATEDNESS VS SIMILARITY", "text": "While there is some overlap in their meanings and they can be used interchangeably in certain contexts, it is important to be aware of their distinction. Budanitsky and Hirst (2001) and Budanitsky and Hirst (2004) point out that semantic similarity is used when comparing similar units such as apples and bananas or table and furniture, which are close to each other in an actual hierarchy. In this case, apples and bananas are hyponyms of fruit and table, a hyponymic synonym for furniture. However, even unequal units can be semantically related, such as door and knob, tree and shade, or gym and weights. In this case, the two units are not inherently similar, but are related in some way. This relationship can be semantic, like semantic relationships (is part of the hierarchy) or a relationship between door and button, or two units that are not classically related to each other."}, {"heading": "2.4. THE DISTRIBUTIONAL HYPOTHESIS", "text": "In fact, most people who live and work in the United States live and work in the United States and other countries, in the United States, in Europe and in the United States."}, {"heading": "2.5. RELATEDNESS OF WORDS AND CONCEPTS", "text": "Measures of semantic kinship and similarity are applied to certain concepts (or certain senses of the words); for example, one can determine the semantic kinship of the bank in the sense of the financial institution and the interest in the sense of the interest rate. Distribution measures, on the other hand, normally assign scores to word pairs, regardless of the nature of their polysemy (how many senses they have) or the special senses in which they were used. Distribution measures require a much more knowledgeable source (such as large amounts of meaning-labeled corpora) than raw text to match word-meaning pairs to score numbers."}, {"heading": "2.6. EVALUATION", "text": "The presence of a large number of kinship measurements requires appropriate evaluation to determine which methods come closest to human notions of kinship and how good each is. There are two evaluation modes, the first of which involves creating two rankings of particular pairs of words, one based on a measure of kinship, while the other is evaluated by humans. Correlation between the two rankings is indicative of how closely the chosen measure mimics human judgment of kinship. Rubenstein and Goodenough (1965) were the first to conduct quantitative experiments on human subjects who were asked to rate 65 pairs of words on a scale from 0.0 to 4.0 by kinship, and the chosen word pairs ranged from very similar and almost synonymous to independent. Miller and Charles (1991) also conducted a similar study of 30 word pairs taken from the Rubenstein-Goodenough pairs. However, the absence of large sets of data from human language experiments limits this evaluation mode."}, {"heading": "3. Distributional Measures", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. SPATIAL METRICS", "text": "A popular method for determining the distribution ratios between two words is to represent them in a multidimensional space in such a way that the distance between the two points is an indicator of the distribution and thus semantic distance between the individual words. (The number of words that belong to each word can be represented by a point in this space in such a way that the vector ~ w1 from the original size to this point has the same positive components in all dimensions that occur together with words that are equivalent to w1 word. (This section describes three distribution distances that quantify the distance between ~ w1 and ~ w2.1.1. Cosine The cosmic method (denoted by Cos) is one of the earliest distribution distances between two words. (This section describes three distribution distances that quantify the distance between two measurements.)"}, {"heading": "3.2. SET OPERATIONS", "text": "Distribution measures, as discussed earlier, are aimed at determining semantic similarity (or similarity) that have two pairs of two pairs of words that accompany the target words. < The problem can be switched to finding the similarity of two sentences (W1 and W2, say), where each sentence considers as its members the contiguous words of the two target words (w1) or w2). Operations such as Jaccard and Dice coefficient can now be applied to determine the similarity of the two sentences and thus the semantic similarity of the target words."}, {"heading": "3.3. MUTUAL INFORMATION\u2013BASED MEASURES", "text": "Hindle (1990) was one of the first factors to incorporate the strength of the association of common words into a distributive similarity measurement. < p > The hypothesis is that the more similar the association of common words with the two target words is, the more similar they are. Hindle used formula (25) to determine the distributional similarity of n j and nk solely by their occurrences as the object of vi. Hindle used formula (25) to determine the distributional similarity of n j and nk solely from their occurrences. Hinobj (vi, n j j j, nk) is the similarity of vi to each of the two nouns."}, {"heading": "3.5. CO-OCCURRENCE RETRIEVAL MODELS", "text": "The distributional yardsticks of Weeds (2003) are based on the concept of substitutionality, which we have not listed. The more appropriate it is to replace the word, the better it is to replace it.The better it is to recall the word in place of the word, the better it is to replace it.The distributional yardsticks of the word retrieved from a text corpus, and the more the definition of the term differs from the definition of appropriateness, the more different distributional yardsticks it applies to determine how appropriate it is to decide in place of w2 how important it is to list as many cookurrences in N2 as possible."}, {"heading": "4. Discussion and Analysis of Distributional Measures", "text": "Numerous distributional scales have been described in the previous section. Variations of the scales are possible depending on certain general properties of a distributional scale. In this section, some of the important properties are discussed together with an analysis of their effect in the assignment of semantic references."}, {"heading": "4.1. SIMPLE CO-OCCURRENCES VS SYNTACTICALLY RELATED WORDS", "text": "Harris (1968), one of the early proponents of the distribution hypothesis, compared to other results, there are few syntactical terms to represent the context of a word, but the strength of the association of each word that appears in the context of the target words can be used to determine its distributional similarity. Dagan et al. (1997), Lee (1999) and Weeds (2003) represent the context of a word with verbs whose subject it is (single syntactical relationship), Hindle (1990) represents the context of a word with which it shares the verb-object or the subject-verb relationship, while Lin (1998a) uses words that refer to any one of the many distinct syntactic relationships to determine the distributional similarity. Protects and Pedersen (1997) and Yoshida et al. (2003) use all words that occur in a distinct window."}, {"heading": "4.2. COMPOSITIONALITY", "text": "The different measures of distributional justice are therefore divided into two types, which are reflected in their composition."}, {"heading": "4.3. MEASURE OF ASSOCIATION", "text": ", w1), w1 (w1), P (w1), w1 (w1), w1 (w1), w1 (w1), 3 (w1), w2 (w1), w1 (w1), 2, w1 (w1), w2, w1, w2, w2, w1, w2, w2, w2, w1, w2, w, 2, w2, w, 2, w2, w, w2, w1, w2, w, w2, w2, w, w2, w, w2, w2, w1, w2, w, w2, w2, w2, w2, w2, w2, w2, w2, w2, w2, w2, w1, w2, w2, w2, w2, w2, w2, w2, w1, w2, w2, w1, w2, w2, w2, w2, w1, w2, w2, w1, w2, w2, w2, w2, w1, w2, w2, w2, w2, w1, w2, w2, w2, w1, w2, w2, w2, w1, w1, 3, w2, w2, w1, 3, w2, w1, 3, 3, 3, w2, w2, w2, w2, 3, w2, 3, 3, w2, 3, 3, 3, w2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, w2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, w2, 3, 3, w2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, w2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, w2, 3, 3, 3, 3, 3),"}, {"heading": "4.4. PREDICTORS OF SEMANTIC RELATEDNESS", "text": "Considering a pair of target words, the vocabulary can be divided into three groups: (1) the set of words that accompany both target words (together); (2) words that accompany exactly one of the two target words (exclusive); (3) words that accompany only one of the two target words (together); Hindle (1990) uses evidence only from words that accompany both target words to determine distribution equality; and all other measures discussed so far in this paper use words that accompany only one target word, as well. It can be argued that the more common occurrences between two words the more they are related; for example, drink and sip can be considered related as they share a number of common occurrences, such as water, tea, and so on."}, {"heading": "4.5. CAPITALIZING ON ASYMMETRY", "text": "In view of a hypernym-hyponym relationship, they will most likely be similar."}, {"heading": "4.6. HOW CRMS FIT", "text": "The distribution quantities proposed by Weeds (2003) are evaluated by comparing the pairs of words with the pairs of words recorded by humans (Miller and Charles). At first glance, the CRMs may look very different from the other distribution quantities examined to date (due to their relatively complex formulas and multiple optimization parameters (w).The difference-weighted distribution quantities of Weeds have identical values for precision and callback. It proves that precision (or callback) is inversely related to the L1 standard values. These seemingly odd results of equating a distribution distance make sense due to the following distribution similarity - defined as substitution efficiency - metrics such as precision and callback, which quantify how good the substitution efficiency is."}, {"heading": "4.7. HIT AND MISS CO-OCCURRENCES", "text": "Finally, we examine two types of coexistence that pose a challenge to existing distributional measures: (1) pairs of words that occur less often together than might be expected by chance. Measures such as PMI cannot confidently predict their association values, and as mentioned earlier, this is counteracted by completely ignoring them, meaning that the system disregards evidence from this series of coexistence pairs. (2) Coexistence pairs 32 Saif Mohammad and Graeme Hirst formed by a word with target words that are close synonyms. Inkpen and Hirst (2002) point out that close synonyms (e.g. hidden and hidden) can form strong and anti-collocations, each with the same common word (e.g. Agenda). Any distributional measures that use the strength of association to determine semantic connections consider the large discrepancy in the strength of association as evidence of incoexistence."}, {"heading": "4.8. SUMMARIZING THE DISTRIBUTIONAL MEASURES", "text": "In the last two sections, we have seen numerous distributional measures, the characteristics of which are summarized in Tables I, II, III and IV in the annex."}, {"heading": "5. Semantic Network and Ontology-Based Measures", "text": "In fact, it is the case that most of us are in a position to move into a different world, in which they are able, in which they are able, in which they are able, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live."}, {"heading": "6. Comparison of Distributional and Ontology-Based Measures", "text": "Distributive and ontology-based metrics use different sources of knowledge to achieve the same goal - the ability to mimic human judgments on semantic contexts. Due to the different methodologies, many interesting comparisons can be made, and the next subsections aim to bring them to light."}, {"heading": "6.1. KNOWLEDGE SOURCE VERSUS SIMILARITY MEASURE", "text": "Ontologies are much more expensive resources than freely available raw data. Creating an ontology requires human experts, is time-consuming and fragile in terms of linguistic change. Once created, updating an ontology is again expensive, and there is usually a lag between the current state of language use / understanding and the semantic network it represents. Moreover, the complexity of human languages makes it impossible to create even a near-perfect semantic network of its concepts. Therefore, the ontology-based metrics are in many ways as good as the networks on which they are based. On the other hand, large corpora, trillions of words in size, can now be collected by a simple web crawler. Large corpora of more formal writing are also available (for example, the Wall Street Journal or the American Printing House for the Blind (APHB) corpus)."}, {"heading": "6.2. DOMAIN-SPECIFIC SEMANTIC SIMILARITY", "text": "However, two words can be very similar semantically in one area, but not so much in another. For example, the pair of words space and time are closely related in the field of quantum mechanics, but not so much in most others. Ontologies have been developed for specific areas that can be used to determine semantic similarities that are specific to those areas. However, the number of such ontologies is very limited. On the other hand, large amounts of corpora that are specific to specific areas are much easier to capture, allowing widespread use of domain-specific distributed similarities."}, {"heading": "6.3. ASSOCIATED WORDS", "text": "Certain pairs of words have a special relationship to each other, such as strawberry and cream, doctor and scalpel, and so on. These words are similar physically or not in their properties, but strawberries are usually eaten with cream and a doctor uses a scalpel to make a cut. An ontology-based measurement only correctly identifies the degree of semantic kinship if these relationships are inherent in ontology. For example, if the agent-instrument relationship concepts are not linked in a semantic network (as in WordNet), the ontology-based measurements are not identified as related to the doctor and scalpel. Of the various distribution variables discussed, those who use simple co-occurrences capture such a semantic kinship, since words that tend to occur together probably have a large number of common co-occurrences. Measures (e.g. Lin (1998a), Hindle (1990), which are a word that probably refer to synchronized words, where the two words are related only to synchronized words."}, {"heading": "6.4. MULTI-FACETED CONCEPTS", "text": "It is as if most of them are able to hide without being able to play by the rules. It is as if they are able to play by the rules. It is as if they are able to play by the rules. It is as if they are able to play by the rules. It is as if they are able to play by the rules, and it is as if they are able to play by the rules. It is as if they are able to play by the rules."}, {"heading": "6.5. EVALUATION AND COMPLEMENTARITY", "text": "Ontology and distribution measures of similarity have each proved to be reasonable quantifiers of semantic similarity, while distribution measures have been used primarily to estimate the probabilities of invisible bigrams. Extensive comparisons of WordNet-based measures with each other (e.g. Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003) have shown that the Jiang-Conrath measure works better than the rest of the Dagan et al. (1994) experiment with some relative entropy-based measures and find that Jensen-Shannon divergence is slightly better than Kullback-Leibler divergence and L1 standard in estimating Bigram probabilities of invisible words and in a pseudo-word disambigulation experiment."}, {"heading": "7. Conclusions", "text": "The paper has provided a detailed analysis of the various distribution mechanisms between the different types of distribution systems and compares them with measures based on ontologies and semantic networks. (It is not only the way in which the distribution mechanisms of the different types of distribution mechanisms are applied, but also the way in which the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the different types of distribution mechanisms are applied. (It is the way in which the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms and the distribution mechanisms of the distribution mechanisms of the distribution mechanisms of the distribution mechanisms, the distribution mechanisms of the distribution mechanisms, the distribution mechanisms of the distribution mechanisms of the distribution mechanisms, the distributions of the distributions, the distributions of the distributions, the distributions, the distributions, the distributions, the"}, {"heading": "Acknowledgements", "text": "We would like to thank Dr. Suzanne Stevenson, Dr. Gerald Penn, and Dr. Ted Pedersen for their valuable feedback and thought-provoking discussions. This research is funded by the Natural Sciences and Engineering Research Council of Canada and the University of Toronto. Notes1 In their respective papers, Robert Fano, Ken Church, and Patrick Hanks pointwise each other's information as mutual information.2 It is difficult to reliably predict negative word association relationships (Church and Hanks (1989)).3 In their respective papers, Donald Hindle and Dekang Lin pointwise each other's information as mutual information.4 P stands for P (w1, w2), R for R (w1, w2). Abbreviations are taken for space reasons and to improve readability."}], "references": [{"title": "Lexical Semantic Relatedness and its Application in Natural Language Processing", "author": ["A. Budanitsky"], "venue": "Technical Report, CSRG-390. Department of Computer Science,", "citeRegEx": "Budanitsky,? \\Q1999\\E", "shortCiteRegEx": "Budanitsky", "year": 1999}, {"title": "Semantic Distance in WordNet: An Experimental, Application-oriented Evaluation of Five Measures", "author": ["A. Budanitsky", "G. Hirst"], "venue": null, "citeRegEx": "Budanitsky and Hirst,? \\Q2001\\E", "shortCiteRegEx": "Budanitsky and Hirst", "year": 2001}, {"title": "Evaluating WordNet-based measures of semantic distance", "author": ["A. Budanitsky", "G. Hirst"], "venue": null, "citeRegEx": "Budanitsky and Hirst,? \\Q2004\\E", "shortCiteRegEx": "Budanitsky and Hirst", "year": 2004}, {"title": "Word Association Norms, Mutual Information and Lexicography", "author": ["K. Church", "P. Hanks"], "venue": "Computational Linguistics", "citeRegEx": "Church and Hanks,? \\Q1989\\E", "shortCiteRegEx": "Church and Hanks", "year": 1989}, {"title": "Similarity-Based Estimation of Word Cooccurrence Probabilities", "author": ["I. Dagan", "L. Lee", "F. Pereira"], "venue": "Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Dagan et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Dagan et al\\.", "year": 1994}, {"title": "Similarity-Based Methods for Word Sense Disambiguation", "author": ["I. Dagan", "L. Lee", "F. Pereira"], "venue": "Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Dagan et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Dagan et al\\.", "year": 1997}, {"title": "Similarity-Based Models of Cooccurrence Probabilities", "author": ["I. Dagan", "L. Lee", "F. Pereira"], "venue": "Machine Learning", "citeRegEx": "Dagan et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Dagan et al\\.", "year": 1999}, {"title": "Contextual Word Similarity and Estimation from Sparse Data", "author": ["I. Dagan", "S. Marcus", "S. Markovitch"], "venue": "Computer Speech and Language", "citeRegEx": "Dagan et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Dagan et al\\.", "year": 1995}, {"title": "Transmission of Information: A Statistical Theory of Communications", "author": ["R.M. Fano"], "venue": null, "citeRegEx": "Fano,? \\Q1961\\E", "shortCiteRegEx": "Fano", "year": 1961}, {"title": "A synopsis of linguistic theory 1930-55.", "author": ["J.R. Firth"], "venue": null, "citeRegEx": "Firth,? \\Q1957\\E", "shortCiteRegEx": "Firth", "year": 1957}, {"title": "Lexis as a Linguistic Level", "author": ["M.A.K. Halliday"], "venue": "In memory of J.R. Firth. London,", "citeRegEx": "Halliday,? \\Q1966\\E", "shortCiteRegEx": "Halliday", "year": 1966}, {"title": "Overview of the First Text Retrieval Conference", "author": ["D. Harman"], "venue": null, "citeRegEx": "Harman,? \\Q1993\\E", "shortCiteRegEx": "Harman", "year": 1993}, {"title": "Noun Classification from Predicate-Argument Structures", "author": ["D. Hindle"], "venue": "Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics (ACL-90). Pittsburgh,", "citeRegEx": "Hindle,? \\Q1990\\E", "shortCiteRegEx": "Hindle", "year": 1990}, {"title": "Lexical Chains as Representations of Context for the Detection and Correction of Malapropisms", "author": ["G. Hirst", "D. St-Onge"], "venue": "In: C. Fellbaum (ed.): WordNet: An Electronic Lexical Database", "citeRegEx": "Hirst and St.Onge,? \\Q1998\\E", "shortCiteRegEx": "Hirst and St.Onge", "year": 1998}, {"title": "Acquiring collocations for lexical choice between nearsynonyms", "author": ["D. Inkpen", "G. Hirst"], "venue": "SIGLEX Workshop on Unsupervised Lexical Acquisition,", "citeRegEx": "Inkpen and Hirst,? \\Q2002\\E", "shortCiteRegEx": "Inkpen and Hirst", "year": 2002}, {"title": "Semantic Similarity Based on Corpus Statistics and Lexical Taxonomy", "author": ["J.J. Jiang", "D.W. Conrath"], "venue": "Proceedings of the International Conference on Research on Computational Linguistics (ROCLING X). Taiwan", "citeRegEx": "Jiang and Conrath,? \\Q1997\\E", "shortCiteRegEx": "Jiang and Conrath", "year": 1997}, {"title": "Combining Local Context and WordNet Similarity for Word Sense Identification", "author": ["C. Leacock", "M. Chodrow"], "venue": "In: C. Fellbaum (ed.): WordNet: An Electronic Lexical Database", "citeRegEx": "Leacock and Chodrow,? \\Q1998\\E", "shortCiteRegEx": "Leacock and Chodrow", "year": 1998}, {"title": "Measures of Distributional Similarity", "author": ["L. Lee"], "venue": "Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Lee,? \\Q1999\\E", "shortCiteRegEx": "Lee", "year": 1999}, {"title": "On the Effectiveness of the Skew Divergence for Statistical Language Analysis", "author": ["L. Lee"], "venue": "Artificial Intelligence and Statistics", "citeRegEx": "Lee,? \\Q2001\\E", "shortCiteRegEx": "Lee", "year": 2001}, {"title": "Using Syntactic Dependency as Local Context to Resolve Word Sense Ambiguity", "author": ["D. Lin"], "venue": "Proceedings of the 8th Conference of the European Chapter of the Association for Computational Linguistics", "citeRegEx": "Lin,? \\Q1997\\E", "shortCiteRegEx": "Lin", "year": 1997}, {"title": "Automatic Retreival and clustering of Similar Words", "author": ["D. Lin"], "venue": "Proceedings of the 17th International Conference on Computational Linguistics (COLING-98). Montreal,", "citeRegEx": "Lin,? \\Q1998\\E", "shortCiteRegEx": "Lin", "year": 1998}, {"title": "An Information-Theoretic Definition of Similarity", "author": ["D. Lin"], "venue": "Proceedings of the 15th International Conference on Machine Learning", "citeRegEx": "Lin,? \\Q1998\\E", "shortCiteRegEx": "Lin", "year": 1998}, {"title": "Contextual Correlates of Semantic Similarity", "author": ["G.A. Miller", "W.G. Charles"], "venue": "Language and Cognitive Processes", "citeRegEx": "Miller and Charles,? \\Q1991\\E", "shortCiteRegEx": "Miller and Charles", "year": 1991}, {"title": "Discovering word senses from text", "author": ["P. Pantel", "D. Lin"], "venue": "Proceedings of the 8th Association of Computing Machinery SIGKDD International Conference On Knowledge Discovery and Data Mining. Edmonton,", "citeRegEx": "Pantel and Lin,? \\Q2002\\E", "shortCiteRegEx": "Pantel and Lin", "year": 2002}, {"title": "Using Measures of Semantic Relatedness for Word Sense Disambiguation", "author": ["S. Patwardhan", "S. Banerjee", "T. Pedersen"], "venue": "Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics (CICLING-03). Mexico City,", "citeRegEx": "Patwardhan et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Patwardhan et al\\.", "year": 2003}, {"title": "Experience with a Stack Decoder-Based HMM CSR and Back-off n-gram Language Models", "author": ["D.B. Paul"], "venue": "Proceedings of the Speech and Natural Language Workshop. Palo Alto, California,", "citeRegEx": "Paul,? \\Q1991\\E", "shortCiteRegEx": "Paul", "year": 1991}, {"title": "Distributional Clustering of English Words", "author": ["F. Pereira", "N. Tishby", "L. Lee"], "venue": "Proceedings of the 31st Annual Meeting of the Association of Computational Linguistics (ACL-93)", "citeRegEx": "Pereira et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Pereira et al\\.", "year": 1993}, {"title": "Development and Application of a Metric on Semantic Nets", "author": ["R. Rada", "H. Mili", "E. Bicknell", "M. Blettner"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics", "citeRegEx": "Rada et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Rada et al\\.", "year": 1989}, {"title": "Using Information Content to Evaluate Semantic Similarity", "author": ["P. Resnik"], "venue": "Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI-95)", "citeRegEx": "Resnik,? \\Q1995\\E", "shortCiteRegEx": "Resnik", "year": 1995}, {"title": "Contextual Correlates of Synonymy", "author": ["H. Rubenstein", "J.B. Goodenough"], "venue": "Communications of the Association for Computing Machinery (ACM-65)", "citeRegEx": "Rubenstein and Goodenough,? \\Q1965\\E", "shortCiteRegEx": "Rubenstein and Goodenough", "year": 1965}, {"title": "A Cooccurrence-Based Thesaurus and Two Applications to Information Retreival", "author": ["H. Sch\u00fctze", "J.O. Pedersen"], "venue": "Information Processing and Management", "citeRegEx": "Sch\u00fctze and Pedersen,? \\Q1997\\E", "shortCiteRegEx": "Sch\u00fctze and Pedersen", "year": 1997}, {"title": "Measures and Applications of Lexical Distributional Similarity", "author": ["J.E. Weeds"], "venue": "Ph.D. thesis, Department of Informatics,", "citeRegEx": "Weeds,? \\Q2003\\E", "shortCiteRegEx": "Weeds", "year": 2003}, {"title": "Constructing and Examining Personalized Cooccurrence-based Thesauri on Web pages", "author": ["S. Yoshida", "T. Yukawa", "K. Kuwabara"], "venue": "Proceedings of the 12th International World Wide Web Conference. Budapest,", "citeRegEx": "Yoshida et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Yoshida et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al.", "startOffset": 0, "endOffset": 47}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003) do an extensive survey and comparison of the various WordNet-based measures.", "startOffset": 0, "endOffset": 76}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003) do an extensive survey and comparison of the various WordNet-based measures. Measures that use just raw text, known as the distributional measures, have been described individually (for example, in Sch\u00fctze and Pedersen (1997), Hindle (1990), Lin (1998a), Pereira et al.", "startOffset": 0, "endOffset": 302}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003) do an extensive survey and comparison of the various WordNet-based measures. Measures that use just raw text, known as the distributional measures, have been described individually (for example, in Sch\u00fctze and Pedersen (1997), Hindle (1990), Lin (1998a), Pereira et al.", "startOffset": 0, "endOffset": 317}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003) do an extensive survey and comparison of the various WordNet-based measures. Measures that use just raw text, known as the distributional measures, have been described individually (for example, in Sch\u00fctze and Pedersen (1997), Hindle (1990), Lin (1998a), Pereira et al.", "startOffset": 0, "endOffset": 330}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003) do an extensive survey and comparison of the various WordNet-based measures. Measures that use just raw text, known as the distributional measures, have been described individually (for example, in Sch\u00fctze and Pedersen (1997), Hindle (1990), Lin (1998a), Pereira et al. (1993), etc) but have not been extensively compared among each other.", "startOffset": 0, "endOffset": 353}, {"referenceID": 8, "context": "Given two events x and y with probabilities P(x) and P(y), their pointwise mutual information (Fano, 1961)1, PMI for short, or just I, is defined as follows:", "startOffset": 94, "endOffset": 106}, {"referenceID": 3, "context": "Church and Hanks (1989)1 introduce word association ratio, which is similar to pointwise mutual information.", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "Church and Hanks (1989)1 introduce word association ratio, which is similar to pointwise mutual information. If x and y are words with probabilities P(x) and P(y) (estimated by corpus counts), their association ratio is defined to be the same as in (1), except that P(x,y) stands for the probability that x appears, within a certain window, before y. It should be noted that P(x,y) is no longer symmetric (P(x,y) 6= P(y,x)) as P(x,y) and P(y,x) represent two different events. If two words have a word association ratio close to zero then they do not share an interesting relationship but if I(w1,w2) \u226b 0, then w2 follows w1 (within a certain window) more often than chance and the words w1 and w2 are strong co-occurrences. Theoretically, word association ratio may yield negative values (word pair occurs less frequently than expected by random chance) but Church and Hanks (1989) show that it is hard to accurately predict negative word association ratios with confidence.", "startOffset": 0, "endOffset": 883}, {"referenceID": 3, "context": "Church and Hanks (1989)1 introduce word association ratio, which is similar to pointwise mutual information. If x and y are words with probabilities P(x) and P(y) (estimated by corpus counts), their association ratio is defined to be the same as in (1), except that P(x,y) stands for the probability that x appears, within a certain window, before y. It should be noted that P(x,y) is no longer symmetric (P(x,y) 6= P(y,x)) as P(x,y) and P(y,x) represent two different events. If two words have a word association ratio close to zero then they do not share an interesting relationship but if I(w1,w2) \u226b 0, then w2 follows w1 (within a certain window) more often than chance and the words w1 and w2 are strong co-occurrences. Theoretically, word association ratio may yield negative values (word pair occurs less frequently than expected by random chance) but Church and Hanks (1989) show that it is hard to accurately predict negative word association ratios with confidence. Systems which use word association ratio may be adversely affected by this. A common approach to counter this is to equate the negative association values to 0 (for example, Lin (1998a)).", "startOffset": 0, "endOffset": 1162}, {"referenceID": 3, "context": "Church and Hanks (1989)1 introduce word association ratio, which is similar to pointwise mutual information. If x and y are words with probabilities P(x) and P(y) (estimated by corpus counts), their association ratio is defined to be the same as in (1), except that P(x,y) stands for the probability that x appears, within a certain window, before y. It should be noted that P(x,y) is no longer symmetric (P(x,y) 6= P(y,x)) as P(x,y) and P(y,x) represent two different events. If two words have a word association ratio close to zero then they do not share an interesting relationship but if I(w1,w2) \u226b 0, then w2 follows w1 (within a certain window) more often than chance and the words w1 and w2 are strong co-occurrences. Theoretically, word association ratio may yield negative values (word pair occurs less frequently than expected by random chance) but Church and Hanks (1989) show that it is hard to accurately predict negative word association ratios with confidence. Systems which use word association ratio may be adversely affected by this. A common approach to counter this is to equate the negative association values to 0 (for example, Lin (1998a)). This usually means that the system will ignore such words. A problem with PMI in general (which is inherited by word association ratio) is that low frequency events get higher scores than expected. Pantel and Lin (2002) try to overcome this by multiplying the PMI value with a correction factor.", "startOffset": 0, "endOffset": 1384}, {"referenceID": 0, "context": "Budanitsky and Hirst (2001) and Budanitsky and Hirst (2004) point out that semantic similarity is used when similar entities such as apples and bananas or table and furniture are compared.", "startOffset": 0, "endOffset": 28}, {"referenceID": 0, "context": "Budanitsky and Hirst (2001) and Budanitsky and Hirst (2004) point out that semantic similarity is used when similar entities such as apples and bananas or table and furniture are compared.", "startOffset": 0, "endOffset": 60}, {"referenceID": 0, "context": "Budanitsky and Hirst (2001) and Budanitsky and Hirst (2004) point out that semantic similarity is used when similar entities such as apples and bananas or table and furniture are compared. These entities are close to each other in an is-a hierarchy. For example, apples and bananas are hyponyms of fruit and table is a hyponym of furniture. However, even dissimilar entities may be semantically related, for example, door and knob, tree and shade, or gym and weights. In this case the two entities are not similar per se, but are related by some relationship. This relationship may be one of the classical relationships such as meronymy (is part of) as in door\u2013knob or a non-classical one as in tree\u2013shade and gym\u2013weights. Thus two entities are semantically related if they are semantically similar (close together in the is-a hierarchy) or share any other classical or non-classical relationships. As Budanitsky and Hirst (2004) point out, semantic similarity is a subset of semantic relatedness.", "startOffset": 0, "endOffset": 930}, {"referenceID": 6, "context": "This is known as the distributional hypothesis (Firth (1957) and Harris (1968)) and such measures have traditionally been referred to as measures of distributional similarity.", "startOffset": 48, "endOffset": 61}, {"referenceID": 6, "context": "This is known as the distributional hypothesis (Firth (1957) and Harris (1968)) and such measures have traditionally been referred to as measures of distributional similarity.", "startOffset": 48, "endOffset": 79}, {"referenceID": 0, "context": "The hypothesis makes intuitive sense as Budanitsky and Hirst (2004) point out.", "startOffset": 40, "endOffset": 68}, {"referenceID": 30, "context": "Distributional Measures as Proxies for Semantic Relatedness 5 Like measures of distributional similarity there exist measures of what we will call distributional relatedness (Sch\u00fctze and Pedersen (1997) and Yoshida et al.", "startOffset": 175, "endOffset": 203}, {"referenceID": 30, "context": "Distributional Measures as Proxies for Semantic Relatedness 5 Like measures of distributional similarity there exist measures of what we will call distributional relatedness (Sch\u00fctze and Pedersen (1997) and Yoshida et al. (2003)).", "startOffset": 175, "endOffset": 229}, {"referenceID": 28, "context": "Rubenstein and Goodenough (1965) were the first to conduct quantitative experiments with human subjects who were asked to rate 65 word pairs on a scale of 0.", "startOffset": 0, "endOffset": 33}, {"referenceID": 22, "context": "Miller and Charles (1991) also conducted a similar study on 30 word pairs taken from the Rubenstein-Goodenough pairs.", "startOffset": 0, "endOffset": 26}, {"referenceID": 29, "context": "A popular variation (Yoshida et al. (2003), Lee (1999), and Sch\u00fctze and Pedersen (1997)) that incorporates this information is stated below:", "startOffset": 21, "endOffset": 43}, {"referenceID": 17, "context": "(2003), Lee (1999), and Sch\u00fctze and Pedersen (1997)) that incorporates this information is stated below:", "startOffset": 8, "endOffset": 19}, {"referenceID": 17, "context": "(2003), Lee (1999), and Sch\u00fctze and Pedersen (1997)) that incorporates this information is stated below:", "startOffset": 8, "endOffset": 52}, {"referenceID": 11, "context": "Sch\u00fctze and Pedersen (1997) use the Tipster category B corpus (Harman, 1993) (450,000 unique terms) and the Wall Street Journal to create a large but sparse co-occurrence matrix of 3,000 medium-frequency words (frequency rank between 2,000 and 5,000).", "startOffset": 62, "endOffset": 76}, {"referenceID": 29, "context": "The cosine is used, among others, by Sch\u00fctze and Pedersen (1997) and Yoshida et al.", "startOffset": 37, "endOffset": 65}, {"referenceID": 29, "context": "The cosine is used, among others, by Sch\u00fctze and Pedersen (1997) and Yoshida et al. (2003), who suggest methods of automatically generating thesauri from text corpora.", "startOffset": 37, "endOffset": 91}, {"referenceID": 29, "context": "The cosine is used, among others, by Sch\u00fctze and Pedersen (1997) and Yoshida et al. (2003), who suggest methods of automatically generating thesauri from text corpora. Sch\u00fctze and Pedersen (1997) use the Tipster category B corpus (Harman, 1993) (450,000 unique terms) and the Wall Street Journal to create a large but sparse co-occurrence matrix of 3,000 medium-frequency words (frequency rank between 2,000 and 5,000).", "startOffset": 37, "endOffset": 196}, {"referenceID": 11, "context": "Sch\u00fctze and Pedersen (1997) use the Tipster category B corpus (Harman, 1993) (450,000 unique terms) and the Wall Street Journal to create a large but sparse co-occurrence matrix of 3,000 medium-frequency words (frequency rank between 2,000 and 5,000). Latent semantic indexing and single-value decomposition (see Sch\u00fctze and Pedersen (1997) for details) are used to reduce the dimensionality of the matrix and get for each term a word vector of its 20 strongest co-occurrences.", "startOffset": 63, "endOffset": 341}, {"referenceID": 11, "context": "Sch\u00fctze and Pedersen (1997) use the Tipster category B corpus (Harman, 1993) (450,000 unique terms) and the Wall Street Journal to create a large but sparse co-occurrence matrix of 3,000 medium-frequency words (frequency rank between 2,000 and 5,000). Latent semantic indexing and single-value decomposition (see Sch\u00fctze and Pedersen (1997) for details) are used to reduce the dimensionality of the matrix and get for each term a word vector of its 20 strongest co-occurrences. The cosine of a word vector (say ~w1) with each of the other word vectors is calculated and the top scores along with the words whose vector generated the top scores is noted. These words form the thesaurus entries for w1. Yoshida et al. (2003) believe that words that are closely related for one person may be distant for another.", "startOffset": 63, "endOffset": 723}, {"referenceID": 4, "context": "In the Manhattan distance (5) (Dagan et al. (1997), Dagan et al.", "startOffset": 31, "endOffset": 51}, {"referenceID": 4, "context": "In the Manhattan distance (5) (Dagan et al. (1997), Dagan et al. (1999), and Lee (1999)), the disparity in strength of association of w1 and w2 with each word that they co-occur with, is summed.", "startOffset": 31, "endOffset": 72}, {"referenceID": 4, "context": "In the Manhattan distance (5) (Dagan et al. (1997), Dagan et al. (1999), and Lee (1999)), the disparity in strength of association of w1 and w2 with each word that they co-occur with, is summed.", "startOffset": 31, "endOffset": 88}, {"referenceID": 4, "context": "In the Manhattan distance (5) (Dagan et al. (1997), Dagan et al. (1999), and Lee (1999)), the disparity in strength of association of w1 and w2 with each word that they co-occur with, is summed. The more the disparity in association, the more is the distributional distance between the two words. The Euclidean distance (6) (Lee (1999)) employs the root mean squared of the disparity in association to get the final distributional distance.", "startOffset": 31, "endOffset": 336}, {"referenceID": 17, "context": "Lee (1999) compared the ability of all three spatial metrics to determine the probability of an unseen (not found in training data) word pair.", "startOffset": 0, "endOffset": 11}, {"referenceID": 17, "context": "Lee (1999) compared the ability of all three spatial metrics to determine the probability of an unseen (not found in training data) word pair. The measures in order of their performance (from better to worse) were: L1 norm, cosine, and L2 norm. Weeds (2003) determined the correlation of word pair ranking as per a handful of distributional measures with human rankings (Miller and Charles word pairs Miller and Charles (1991)).", "startOffset": 0, "endOffset": 258}, {"referenceID": 17, "context": "Lee (1999) compared the ability of all three spatial metrics to determine the probability of an unseen (not found in training data) word pair. The measures in order of their performance (from better to worse) were: L1 norm, cosine, and L2 norm. Weeds (2003) determined the correlation of word pair ranking as per a handful of distributional measures with human rankings (Miller and Charles word pairs Miller and Charles (1991)).", "startOffset": 0, "endOffset": 427}, {"referenceID": 17, "context": "Lee (1999) shows that the Jaccard coefficient performs better than L1 norm in an unseen bigram probability estimation task.", "startOffset": 0, "endOffset": 11}, {"referenceID": 4, "context": "Dagan et al. (1995) use a weighted version of the Jaccard coefficient on pseudo-fuzzy sets with PMI as the strength of association.", "startOffset": 0, "endOffset": 20}, {"referenceID": 12, "context": "MUTUAL INFORMATION\u2013BASED MEASURES Hindle (1990) was one of the first to factor the strength of association of co-occurring words into a distributional similarity measure.", "startOffset": 34, "endOffset": 48}, {"referenceID": 19, "context": "Lin (1998a) suggests a different measure derived from his information theoretic definition of similarity (Lin, 1998b).", "startOffset": 0, "endOffset": 12}, {"referenceID": 11, "context": "Note that this is different from Hindle (1990) where even the cases of negative PMI were also considered.", "startOffset": 33, "endOffset": 47}, {"referenceID": 3, "context": "As mentioned earlier, Church and Hanks (1989) show that it is hard to accurately predict negative word association ratios with confidence.", "startOffset": 22, "endOffset": 46}, {"referenceID": 12, "context": "Also notice that like Hindle\u2019s measure, both Lin\u2019s and mine are measures of distributional similarity. Hindle (1990) used a portion of the Associated Press news stories (6 million words) to classify the nouns into semantically related classes.", "startOffset": 22, "endOffset": 117}, {"referenceID": 12, "context": "Also notice that like Hindle\u2019s measure, both Lin\u2019s and mine are measures of distributional similarity. Hindle (1990) used a portion of the Associated Press news stories (6 million words) to classify the nouns into semantically related classes. Lin (1998a) used his measure to generate a thesaurus from a 64-million-word", "startOffset": 22, "endOffset": 256}, {"referenceID": 22, "context": "Pereira et al. (1993) and Dagan et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "(1993) and Dagan et al. (1994) point out that words have probabilistic distributions with respect to neighboring syntactically related words.", "startOffset": 11, "endOffset": 31}, {"referenceID": 25, "context": "Use of Kullback-Leibler distance as the semantic distance metric yielded a 20% improvement in perplexity on the Wall Street Journal and dictation corpora provided by ARPA\u2019s HLT program (Paul, 1991).", "startOffset": 185, "endOffset": 197}, {"referenceID": 24, "context": "This asymmetry is counter-intuitive to the general notion of semantic similarity of words, although Weeds (2003) has argued in favor of asymmetric measures.", "startOffset": 100, "endOffset": 113}, {"referenceID": 20, "context": "Pereira et al. (1993) use relative entropy to create clusters of nouns from verb-object pairs corresponding to a thousand most frequent nouns in the Grolier\u2019s Encyclopedia, June 1991 version (10 million words).", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "Dagan et al. (1994) use Kullback-Leibler distance to estimate the probabilities of bigrams that were not seen in a text corpus.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "Dagan et al. (1994) use Kullback-Leibler distance to estimate the probabilities of bigrams that were not seen in a text corpus. They point out that a significant number of possible bigrams are not seen in any given text corpus. The probabilities of such bigrams may be determined by taking a weighted average of the probabilities of bigrams composed of distributionally similar words. Use of Kullback-Leibler distance as the semantic distance metric yielded a 20% improvement in perplexity on the Wall Street Journal and dictation corpora provided by ARPA\u2019s HLT program (Paul, 1991). The use of distributionally similar words to estimate unseen bigram probabilities will likely lead to erroneous results in case of less-preferred and strongly-preferred collocations (word pairs). Inkpen and Hirst (2002) point out that even though words like task and job are semantically very similar, the collocations they form with other words may have varying degrees of usage.", "startOffset": 0, "endOffset": 804}, {"referenceID": 17, "context": "Distributional Measures as Proxies for Semantic Relatedness 17 Lee (2001) shows that \u03b1 skew divergence performs better than KullbackLeibler divergence in estimating word co-occurrence probabilities.", "startOffset": 63, "endOffset": 74}, {"referenceID": 17, "context": "Distributional Measures as Proxies for Semantic Relatedness 17 Lee (2001) shows that \u03b1 skew divergence performs better than KullbackLeibler divergence in estimating word co-occurrence probabilities. Weeds (2003) achieves a correlation of 0.", "startOffset": 63, "endOffset": 212}, {"referenceID": 31, "context": "CO-OCCURRENCE RETRIEVAL MODELS The distributional measures suggested by Weeds (2003) are based on the notion of substitutability.", "startOffset": 72, "endOffset": 85}, {"referenceID": 31, "context": "Weeds argues that the asymmetry in substitutability is intuitive as in many cases it may be okay to substitute a word, say dog, with another, say animal, but the reverse is not likely to be acceptable as often. Since substitutability is a measure of semantic similarity, she believes that distributional similarity between two words should reflect this property as well. Hence, like the Kullback-Leibler divergence, all her distributional similarity models are inherently asymmetric. A word\u2019s co-occurrence information may be specified by the set of cooccurring words alone, or by specifying the strength of co-occurrences, as well. This strength may be captured by a suitable measure of word association such as conditional probability or pointwise mutual information between the co-occurring words and the target words. Also, the difference in the strength of co-occurrence may or may not be used to penalize the substitutability of one word for another. Weeds (2003) provides six distinct formulae for precision and recall, depending on the the strength of co-occurrence and penalty for differences in strength of association.", "startOffset": 0, "endOffset": 970}, {"referenceID": 30, "context": "Weeds (2003) extracted verb-object pairs of 2,000 nouns from the British National Corpus (BNC).", "startOffset": 0, "endOffset": 13}, {"referenceID": 4, "context": "Dagan et al. (1997), Lee (1999), and Weeds (2003) represent the context of a noun with verbs whose object it is (single syntactic relation), Hindle (1990) represents the context of a noun with verbs with which it shares the verb-object or subject-verb relation, while Lin (1998a) uses words related to a noun by any of the many pre-decided syntactic relations to determine distributional similarity.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "Dagan et al. (1997), Lee (1999), and Weeds (2003) represent the context of a noun with verbs whose object it is (single syntactic relation), Hindle (1990) represents the context of a noun with verbs with which it shares the verb-object or subject-verb relation, while Lin (1998a) uses words related to a noun by any of the many pre-decided syntactic relations to determine distributional similarity.", "startOffset": 0, "endOffset": 32}, {"referenceID": 4, "context": "Dagan et al. (1997), Lee (1999), and Weeds (2003) represent the context of a noun with verbs whose object it is (single syntactic relation), Hindle (1990) represents the context of a noun with verbs with which it shares the verb-object or subject-verb relation, while Lin (1998a) uses words related to a noun by any of the many pre-decided syntactic relations to determine distributional similarity.", "startOffset": 0, "endOffset": 50}, {"referenceID": 4, "context": "Dagan et al. (1997), Lee (1999), and Weeds (2003) represent the context of a noun with verbs whose object it is (single syntactic relation), Hindle (1990) represents the context of a noun with verbs with which it shares the verb-object or subject-verb relation, while Lin (1998a) uses words related to a noun by any of the many pre-decided syntactic relations to determine distributional similarity.", "startOffset": 0, "endOffset": 155}, {"referenceID": 4, "context": "Dagan et al. (1997), Lee (1999), and Weeds (2003) represent the context of a noun with verbs whose object it is (single syntactic relation), Hindle (1990) represents the context of a noun with verbs with which it shares the verb-object or subject-verb relation, while Lin (1998a) uses words related to a noun by any of the many pre-decided syntactic relations to determine distributional similarity.", "startOffset": 0, "endOffset": 280}, {"referenceID": 4, "context": "Dagan et al. (1997), Lee (1999), and Weeds (2003) represent the context of a noun with verbs whose object it is (single syntactic relation), Hindle (1990) represents the context of a noun with verbs with which it shares the verb-object or subject-verb relation, while Lin (1998a) uses words related to a noun by any of the many pre-decided syntactic relations to determine distributional similarity. Sch\u00fctze and Pedersen (1997) and Yoshida et al.", "startOffset": 0, "endOffset": 428}, {"referenceID": 4, "context": "Dagan et al. (1997), Lee (1999), and Weeds (2003) represent the context of a noun with verbs whose object it is (single syntactic relation), Hindle (1990) represents the context of a noun with verbs with which it shares the verb-object or subject-verb relation, while Lin (1998a) uses words related to a noun by any of the many pre-decided syntactic relations to determine distributional similarity. Sch\u00fctze and Pedersen (1997) and Yoshida et al. (2003) use all cooccurring words in a pre-decided window size.", "startOffset": 0, "endOffset": 454}, {"referenceID": 4, "context": "Dagan et al. (1997), Lee (1999), and Weeds (2003) represent the context of a noun with verbs whose object it is (single syntactic relation), Hindle (1990) represents the context of a noun with verbs with which it shares the verb-object or subject-verb relation, while Lin (1998a) uses words related to a noun by any of the many pre-decided syntactic relations to determine distributional similarity. Sch\u00fctze and Pedersen (1997) and Yoshida et al. (2003) use all cooccurring words in a pre-decided window size. Although Lin (1998a) shows that the use of multiple syntactic relations is more beneficial as compared to just one, there exist no published results on whether using only syntactically related words (as compared to all co-occurrences) improves or worsens the quality of semantic similarity assignment.", "startOffset": 0, "endOffset": 531}, {"referenceID": 19, "context": "Use of Multiple Syntactic Relations Lin (1998a) used a subset of words that co-occurred with the target words to determine their distributional similarity.", "startOffset": 36, "endOffset": 48}, {"referenceID": 4, "context": "Taking the maximum of the two as the weight (Dagan et al. (1995)) will mean that more weight is given to a co-occurring word if it has high strength of association with any of the two target words.", "startOffset": 45, "endOffset": 65}, {"referenceID": 4, "context": "Taking the maximum of the two as the weight (Dagan et al. (1995)) will mean that more weight is given to a co-occurring word if it has high strength of association with any of the two target words. As Dagan et al. (1995) point out, there is strong evidence for dissimilarity if the strength of association with the other target word is much lower than the maximum, and strong evidence of similarity if the strength of association with both target words is more or less the same.", "startOffset": 45, "endOffset": 221}, {"referenceID": 18, "context": "Lin (1998a) and Hindle (1990) use pointwise mutual information as the measure of association.", "startOffset": 0, "endOffset": 12}, {"referenceID": 12, "context": "Lin (1998a) and Hindle (1990) use pointwise mutual information as the measure of association.", "startOffset": 16, "endOffset": 30}, {"referenceID": 12, "context": "Lin (1998a) and Hindle (1990) use pointwise mutual information as the measure of association. The mutual information\u2013based CRMs of Weeds (2003) also use the same.", "startOffset": 16, "endOffset": 144}, {"referenceID": 11, "context": "Hindle (1990) uses evidence only from words that co-occur with both target words to determine the distributional similarity.", "startOffset": 0, "endOffset": 14}, {"referenceID": 10, "context": "Consider the classic strong tea vs powerful tea example (Halliday (1966)).", "startOffset": 57, "endOffset": 73}, {"referenceID": 31, "context": "Weeds (2003) argues that this behavior is intuitive as it is more often okay to substitute a generic concept in place of a specific one than vice versa, and substitutability is a indicator of semantic similarity.", "startOffset": 0, "endOffset": 13}, {"referenceID": 30, "context": "The CRMs suggested by Weeds (2003) are the first distributional measures to be evaluated by comparing ranked word pairs with those ranked by humans (Miller and Charles word pairs).", "startOffset": 22, "endOffset": 35}, {"referenceID": 14, "context": "Inkpen and Hirst (2002) point out that near synonyms (for example, hidden and concealed) may form strong and anti-collocations, respectively, with the same co-occurring word (for example, agenda).", "startOffset": 0, "endOffset": 24}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al.", "startOffset": 0, "endOffset": 47}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003) have done an extensive survey of the various WordNet-based measures, their comparisons with human judgment on selected word pairs, and their efficacy in applications such as spelling correction and word sense disambiguation.", "startOffset": 0, "endOffset": 76}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003) have done an extensive survey of the various WordNet-based measures, their comparisons with human judgment on selected word pairs, and their efficacy in applications such as spelling correction and word sense disambiguation. Hence, this paper provides just a brief summary of the major WordNet-based measures of similarity and focuses on their comparison with distributional ones. One of the earliest and simplest measures is the Rada et al. (1989) edge counting method.", "startOffset": 0, "endOffset": 525}, {"referenceID": 0, "context": "Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003) have done an extensive survey of the various WordNet-based measures, their comparisons with human judgment on selected word pairs, and their efficacy in applications such as spelling correction and word sense disambiguation. Hence, this paper provides just a brief summary of the major WordNet-based measures of similarity and focuses on their comparison with distributional ones. One of the earliest and simplest measures is the Rada et al. (1989) edge counting method. The shortest path in the network between the two target words (target path) is determined. The more edges there are between two words, the more distant they are. Elegant as it may be, the measure relies on the unlikely assumption that all the network edges correspond to identical semantic distance between the nodes they connect. Nodes in a network may be connected by numerous relations such as hyponymy, meronymy and so on. Edge counts apart, Hirst and St-Onge (1998) take into account the fact that if the target path consists of edges that belong to a number of such relations, the target words are likely more distant.", "startOffset": 0, "endOffset": 1018}, {"referenceID": 16, "context": "Leacock and Chodrow (1998) used just one relation (hyponymy) and modified the path length formula to reflect the fact that edges lower down in the is-a hierarchy correspond to smaller semantic distance than the ones higher up.", "startOffset": 0, "endOffset": 27}, {"referenceID": 16, "context": "Leacock and Chodrow (1998) used just one relation (hyponymy) and modified the path length formula to reflect the fact that edges lower down in the is-a hierarchy correspond to smaller semantic distance than the ones higher up. For example, sports car and car (low in the hierarchy) are much more similar than transport and instrumentation (higher up in the hierarchy) even though both pairs of words are separated by exactly one edge in the is-a hierarchy of WordNet. LC(c1,c2) =\u2212 log len(c1,c2) 2D (81) where D is the depth in the taxonomy. Resnik (1995) suggested a measure that used corpus statistics along with the knowledge obtained from a semantic network.", "startOffset": 0, "endOffset": 556}, {"referenceID": 15, "context": "Jiang and Conrath (1997) and Lin (1997) incorporate this notion into their measures which are arithmetic variations of the same terms.", "startOffset": 0, "endOffset": 25}, {"referenceID": 15, "context": "Jiang and Conrath (1997) and Lin (1997) incorporate this notion into their measures which are arithmetic variations of the same terms.", "startOffset": 0, "endOffset": 40}, {"referenceID": 15, "context": "Jiang and Conrath (1997) and Lin (1997) incorporate this notion into their measures which are arithmetic variations of the same terms. The Jiang and Conrath (1997) measure (denoted by JC) determines how dissimilar each target concept is from the lso (IC(c1)\u2212 IC(lso) and IC(c2)\u2212 IC(lso)).", "startOffset": 0, "endOffset": 164}, {"referenceID": 0, "context": "(see Budanitsky (1999) for more details).", "startOffset": 5, "endOffset": 23}, {"referenceID": 0, "context": "(see Budanitsky (1999) for more details). Lin (1997) points out that the lso is what is common between the two target concepts and that its information content is the common information between the two concepts.", "startOffset": 5, "endOffset": 53}, {"referenceID": 18, "context": ", Lin (1998a), Hindle (1990)) that consider a word w to be a shared cooccurrence only if w is related to both target words by the same syntactic relation, will not find such words related, simply because such words that tend to occur in the same sentence are likely to have different thematic roles and thus different syntactic relations with common co-occurring words.", "startOffset": 2, "endOffset": 14}, {"referenceID": 12, "context": ", Lin (1998a), Hindle (1990)) that consider a word w to be a shared cooccurrence only if w is related to both target words by the same syntactic relation, will not find such words related, simply because such words that tend to occur in the same sentence are likely to have different thematic roles and thus different syntactic relations with common co-occurring words.", "startOffset": 15, "endOffset": 29}, {"referenceID": 0, "context": ", Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al.", "startOffset": 2, "endOffset": 20}, {"referenceID": 0, "context": ", Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al.", "startOffset": 2, "endOffset": 49}, {"referenceID": 0, "context": ", Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003)) have found that the Jiang-Conrath measure performs better than the rest.", "startOffset": 2, "endOffset": 78}, {"referenceID": 0, "context": ", Budanitsky (1999), Budanitsky and Hirst (2001) and Patwardhan et al. (2003)) have found that the Jiang-Conrath measure performs better than the rest. Dagan et al. (1994) perform experiments with a few relative entropy\u2013 based measures and find that Jensen-Shannon divergence is slightly better than Kullback-Leibler divergence and L1 norm in estimating bigram probabilities of unseen words and in a pseudo\u2013word sense disambiguation experiment.", "startOffset": 2, "endOffset": 172}, {"referenceID": 12, "context": "Specifically, a distributional measure that keeps the best of Hindle (1990) and Lin (1998a), overcoming their respective drawbacks, was proposed.", "startOffset": 62, "endOffset": 76}, {"referenceID": 12, "context": "Specifically, a distributional measure that keeps the best of Hindle (1990) and Lin (1998a), overcoming their respective drawbacks, was proposed.", "startOffset": 62, "endOffset": 92}, {"referenceID": 31, "context": "CO-OCCURRENCE RETRIEVAL MODELS The precision and recall of additive and difference-weighted CRMs (Weeds, 2003).", "startOffset": 97, "endOffset": 110}, {"referenceID": 3, "context": "2 It is hard to accurately predict negative word association ratios with confidence (Church and Hanks (1989)).", "startOffset": 85, "endOffset": 109}], "year": 2012, "abstractText": "The automatic ranking of word pairs as per their semantic relatedness and ability to mimic human notions of semantic relatedness has widespread applications. Measures that rely on raw data (distributional measures) and those that use knowledge-rich ontologies both exist. Although extensive studies have been performed to compare ontological measures with human judgment, the distributional measures have primarily been evaluated by indirect means. This paper is a detailed study of some of the major distributional measures; it lists their respective merits and limitations. New measures that overcome these drawbacks, that are more in line with the human notions of semantic relatedness, are suggested. The paper concludes with an exhaustive comparison of the distributional and ontology-based measures. Along the way, significant research problems are identified. Work on these problems may lead to a better understanding of how semantic relatedness is to be measured.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}