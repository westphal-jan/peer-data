{"id": "1203.3473", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2012", "title": "Lifted Inference for Relational Continuous Models", "abstract": "Relational Continuous Models (RCMs) represent joint probability densities over attributes of objects, when the attributes have continuous domains. With relational representations, they can model joint probability distributions over large numbers of variables compactly in a natural way. This paper presents a new exact lifted inference algorithm for RCMs, thus it scales up to large models of real world applications. The algorithm applies to Relational Pairwise Models which are (relational) products of potentials of arity 2. Our algorithm is unique in two ways. First, it substantially improves the efficiency of lifted inference with variables of continuous domains. When a relational model has Gaussian potentials, it takes only linear-time compared to cubic time of previous methods. Second, it is the first exact inference algorithm which handles RCMs in a lifted way. The algorithm is illustrated over an example from econometrics. Experimental results show that our algorithm outperforms both a groundlevel inference algorithm and an algorithm built with previously-known lifted methods.", "histories": [["v1", "Thu, 15 Mar 2012 11:17:56 GMT  (427kb)", "http://arxiv.org/abs/1203.3473v1", "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jaesik choi", "eyal amir", "david j hill"], "accepted": false, "id": "1203.3473"}, "pdf": {"name": "1203.3473.pdf", "metadata": {"source": "CRF", "title": "Lifted Inference for Relational Continuous Models", "authors": ["Jaesik Choi", "David J. Hill"], "emails": ["jaesik@illinois.edu", "eyal@illinois.edu", "ecodavid@rci.rutgers.edu"], "sections": [{"heading": null, "text": "Relational Continuous Models (RCMs) represent common probability densities over attributes of objects if the attributes have continuous domains; with relational representations, they can compactly model common probability distributions over a large number of variables in a natural way.This paper presents a new, accurate upscale inference algorithm for RCMs, scaling to large models of real-world applications; the algorithm applies to pairs of relative models that are (relational) products of strength 2 potentials.Our algorithm is unique in two respects: firstly, it significantly improves the efficiency of upscale inference with continuous domain variables; secondly, if a relational model has Gaussian potential, it requires only linear time compared to the cubic time of previous methods; and secondly, it is the first exact inference algorithm that handles RCMs in an upscale way.The algorithm is illustrated using an example from econometrics."}, {"heading": "1 Introduction", "text": "In fact, most of them are able to survive on their own, and they are able to survive on their own."}, {"heading": "2 Relational Continuous Models", "text": "We present a new relationship model for continuous variables, but Relational Continuity Models (RCMs) allow a general representation of variables. Relations between the attributes of objects are represented by parfactor models. 1 Each parfactor (L, C, AR, \u03c6) consists of a series of logical variables (L) 2, constraints to L (C), a list of attributes of objects (AR) and a potential to AR (\u03c6). Here, each attribute is a random variable with a continuous domain. We define a set of soil attributes to refer to compactly. For example, Revenue [B] is a relational atom related to bank revenues (e.g. B = \"Pacific Bank\"). To make the parameter compactness, a list of relational atoms is used, and terms are based on the previous work (Poole, 2003; de Salvo Braz et al, 2005)."}, {"heading": "3 Algorithm Overview for RCMs", "text": "Our FOVE-Continuous (First-Order Variable Elimination) inference algorithm eliminates relational atoms recursively for RCMs. Firstly, it splits (terminology of (Poole, 2003); shattering in (de Salvo Braz et al., 2005) 4 Relational4Please refer (Poole, 2003; de Salvo Braz et al., 2005) to fur atoms. Splitting separates earths (e.g. RV (X) RV (Y)) of all relational atoms (e.g. X Y). It introduces observations as observations of fundamentals of separate relational variables. Observing market (auto) = 30% generates two separate relational atoms: market (M), market (M), market (IME). \""}, {"heading": "4 Inference with Gaussian Potentials", "text": "In this section we present our first technical contribution, efficient elimination algorithms for variable variables for relational Gaussian models. We focus on the consequence problem of calculating the back side of query variables of given observations. It is important to integrate the relational atoms (e.g. Revenue [B] = {Revenue (b1), \u00b7 \u00b7, Revenue (bm)}) efficiently to solve this inference problem. In the following description we leave out the constraints (inequality between logical variables and objects) from the parameters, which allows us to focus on the potential functions within these parameters."}, {"heading": "4.1 Relational Pairwise Potentials", "text": "This x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "4.2 Constant Time Relational Atom Eliminations", "text": "We provide two constant time animation algorithms for RNs that contain a single relational potential \u03c6 (i.e. the product of potentials across different instances of relational atoms), which eliminate variables while maintaining the same shape, the product of RNs."}, {"heading": "4.2.1 Elimination of a relational atom X in \u03c6RN(X,Y)", "text": "The first problem is the marginalization of a relational atom (X) in the product of Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y"}, {"heading": "4.2.2 Elimination of n random variables in \u03c6RN(X,X)", "text": "The second problem is to marginalize some variables in a relational atom (X) in the product of the RN within the relational atom: \u03c6RN (X, X). The potential is the product of | X | (| X | \u2212 1) 2 pairs of RNs between two random variables within the X algorithm \"pair constant 2.\" It updates the margins after eliminating a random variable without iteration. If it eliminates xm, it calculates the parameters of the RN given as the following equation."}, {"heading": "4.3 A Linear Time Relational Atom Elimination", "text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "5 Exact Lifted Inference with RCM", "text": "In this section we present our algorithm ELIMINATECONTINUOUS, which creates a new parameter after elimination of a number of relational atoms taking into account a number of parameters. A potential of each parameter is the product of Relational Pairwise Potentials (RPPs): \u03c6RPP (X, Y) = \u0394RPP (X, Y) = \u0394X, y \u0394RPP (x, y) A relational pair-wise model is an RCM, whose potentials are RPPs. In this section, RPPs are not limited to the RNs in Section 4.1."}, {"heading": "5.1 Conditions for Exact Lifted Inference", "text": "The raised ELIMINATE CONTINUOUS algorithm provides the exact solution for the potentials of parameters if the potentials meet three conditions: condition (I), analytically integrable; condition (II), closed under product operations; and condition (III), closed under marginalizations, thus again represented with the product of relational paired potentials. RNs are an example that meets the conditions. At this point we present another potential, a linear Gaussian that meets the conditions.Lemma 6 The product of RNs with non-zero averages (RNMs) meets the three conditions. An RNM has the following form (d is a constant)."}, {"heading": "5.2 Inversion-Elimination", "text": "Removal of inversion is applicable if the set of logical variables in g is identical to the set of logical variables in e, LV (e) = LV (g). Note: The number of logical variables in g is identical to the set of logical variables in e, LV (e) = LV (g). Note that the number of logical variables in g (g) is equal. The number of logical variables in g is identical to the set of logical variables in e, LV (e) = LV (g) = LV (g)."}, {"heading": "5.3 Relational-Atom-Elimination", "text": "Relational atom elimination marginalizes atoms when inversion elimination is not applicable. It is a generalized algorithm of those represented for RN in Section 4. It marginalizes each relation atom of a parameter g after three cases: (1) variables in atom e (has relationship to an atom (i.e.). (2) variables in atom e only have relationship to each other (i.e. \"(X, X)\"); and (3) other general cases (i.e. \"other general cases\" (i.e. \"other general cases\" (Xi, X) \"). In case (1), a modified\" Pwise Constant1 \"eliminates an atom e.\" In this case, the integration of a random variable in the atom does not affect the integration of another variable in the atom e as shown in Section 4.2. That is what RV (e)."}, {"heading": "6 Experiments", "text": "For experiments, we have implemented three algorithms: (A) inference with a grounded model; (B) inference with only inversion elimination; and (C) inference with both inversion elimination and relational atom elimination. Our new algorithm (C) is significantly faster than the grounded model (A) and inversion elimination (B). Note that inversion elimination (B) is also our new algorithm for continuous variables, although comparable elimination methods for discrete variables (de Salvo Braz et al., 2005; Milch et al., 2008; Pfeffer et al., 1999) preceded our existing one. Our experimental results are shown in Figure 5 and 6In the recession model, we have presented observations for a market variable (M) and a turnover variable (R)."}, {"heading": "7 Related Work", "text": "(Poole, 2003), solves inference problems with unification, which dynamically splits and unifies a number of soil nodes. (de Salvo Braz et al., 2005; de Salvo Braz et al., 2006) provides a tractable algorithm. (Milch et al., 2008) applies the counting formula to reduce the size of probability density tables. However, these elevated inference algorithms are difficult to apply to continuous domains.6 Observations are required to make the product of RNs a probability density function. Please refer to Lemma 1 for detail.MLNs (Markov Logic Network) (Richardson & Domingos, 2006) use first-order logic sets to represent relationships across nodes in a graphical model. In this respect, MLNs are also graphic models at the relational level. (Singla & Domingos, 2008), provides an approximated inference algorithm at the discretion level."}, {"heading": "8 Conclusion and Future work", "text": "This algorithm is an evolution of the exact inference in RCMs, since all previous work is limited to discrete domains. Based on a query and observations, our algorithm calculates exactly the conditional density of the query when potentials meet certain conditions. Our current algorithm has two limitations: First, found potentials that meet the conditions in Section 5 are variants of Gaussian potentials. Therefore, one goal of our future work is to find potentials beyond Gaussian. Second, the current algorithm is designed only for continuous variables. Many real-world models require not only continuous variables, but also discrete variables. Therefore, creating an efficient inference algorithm for hybrid relational models would be a promising direction."}, {"heading": "Acknowledgements", "text": "We would like to thank Abner Guzman Rivera and the anonymous critics for their valuable comments, which are supported by NSF IIS 05-46663 and UIUC / NCSA AESIS 251024."}, {"heading": "9 Appendix", "text": "Evidence for Lemma 1 Here we prove that the product of the RNs integrates (at least integrates) into a constant. The constant becomes the normalizing factor of the probability density function.We prove this by contradiction. Suppose that the product of the RNs does not integrate into a constant, that is, it integrates into infinity (after an integration via x).According to Eq.2, the product of the RNs maintains the same form after it has integrated a random variable x (e.g. y and z).The condition for infinity is therefore only fulfilled if the marginal (after an integration via x) is a constant function of another random variable y that is not yet integration.If x has relationships to more than one variable (e.g. y and z), the condition for infinity is not fulfilled. The marginal includes a potential solution (y, z). If x has a relationship to only y, the constant is not fulfilled, the constant for RNy is not fulfilled. The condition for infinity is not fulfilled."}], "references": [{"title": "Lifted firstorder probabilistic inference. IJCAI\u201905: Proceedings of the 19th international joint conference on Artificial intelligence (pp. 1319\u20131325)", "author": ["R. de Salvo Braz", "E. Amir", "D. Roth"], "venue": null, "citeRegEx": "Braz et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Braz et al\\.", "year": 2005}, {"title": "Mpe and partial inversion in lifted probabilistic variable elimination. AAAI\u201906: proceedings of the 21st national conference on Artificial intelligence (pp. 1123\u20131130)", "author": ["R. de Salvo Braz", "E. Amir", "D. Roth"], "venue": null, "citeRegEx": "Braz et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Braz et al\\.", "year": 2006}, {"title": "Learning probabilistic relational models. IJCAI\u201999: Proceedings of the 16th international joint conference on Artificial intelligence (pp. 1300\u20131307)", "author": ["N. Friedman", "L. Getoor", "D. Koller", "A. Pfeffer"], "venue": null, "citeRegEx": "Friedman et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 1999}, {"title": "Introduction to statistical relational learning (adaptive computation and machine learning)", "author": ["L. Getoor", "B. Taskar"], "venue": null, "citeRegEx": "Getoor and Taskar,? \\Q2007\\E", "shortCiteRegEx": "Getoor and Taskar", "year": 2007}, {"title": "Real-time bayesian anomaly detection in streaming environmental data", "author": ["D.J. Hill", "B.S. Minsker", "E. Amir"], "venue": "Water Resources Research,", "citeRegEx": "Hill et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2009}, {"title": "Lifted aggregation in directed first-order probabilistic models. IJCAI\u201909", "author": ["J. Kisynski", "D. Poole"], "venue": "Proceedings of the 21st international jont conference on Artifical intelligence (pp", "citeRegEx": "Kisynski and Poole,? \\Q2009\\E", "shortCiteRegEx": "Kisynski and Poole", "year": 2009}, {"title": "Object-oriented bayesian networks", "author": ["D. Koller", "A. Pfeffer"], "venue": "Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Koller and Pfeffer,? \\Q1997\\E", "shortCiteRegEx": "Koller and Pfeffer", "year": 1997}, {"title": "Continuous multivariate distributions", "author": ["S. Kotz", "N. Balakrishnan", "N. Johnson"], "venue": null, "citeRegEx": "Kotz et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Kotz et al\\.", "year": 2000}, {"title": "Inference in hybrid networks: Theoretical limits and practical algorithms", "author": ["U. Lerner", "R. Parr"], "venue": null, "citeRegEx": "Lerner and Parr,? \\Q2001\\E", "shortCiteRegEx": "Lerner and Parr", "year": 2001}, {"title": "Relational object maps for mobile robots. IJCAI\u201905: Proceedings of the 19th international joint conference on Artificial intelligence (pp. 1471\u20131476)", "author": ["B. Limketkai", "L. Liao", "D. Fox"], "venue": null, "citeRegEx": "Limketkai et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Limketkai et al\\.", "year": 2005}, {"title": "Transfer learning from minimal target data by mapping across relational domains. IJCAI\u201909", "author": ["L. Mihalkova", "R.J. Mooney"], "venue": "Proceedings of the 21st international jont conference on Artifical intelligence (pp", "citeRegEx": "Mihalkova and Mooney,? \\Q2009\\E", "shortCiteRegEx": "Mihalkova and Mooney", "year": 2009}, {"title": "First-order probabilistic languages: Into the unknown. 10\u201324", "author": ["B. Milch", "S. Russell"], "venue": null, "citeRegEx": "Milch and Russell,? \\Q2007\\E", "shortCiteRegEx": "Milch and Russell", "year": 2007}, {"title": "Lifted probabilistic inference with counting formulas", "author": ["B. Milch", "L.S. Zettlemoyer", "K. Kersting", "M. Haimes", "L.P. Kaelbling"], "venue": "Proceedings of the 23rd national conference on Artificial intelligence (pp", "citeRegEx": "Milch et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Milch et al\\.", "year": 2008}, {"title": "Probabilistic logic programming", "author": ["R. Ng", "V.S. Subrahmanian"], "venue": "Information and Computation,", "citeRegEx": "Ng and Subrahmanian,? \\Q1992\\E", "shortCiteRegEx": "Ng and Subrahmanian", "year": 1992}, {"title": "An analytic network process model for financial-crisis forecasting", "author": ["M.P. Niemira", "T.L. Saaty"], "venue": "International Journal of Forecasting,", "citeRegEx": "Niemira and Saaty,? \\Q2004\\E", "shortCiteRegEx": "Niemira and Saaty", "year": 2004}, {"title": "Thin junction tree filters for simultaneous localization and mapping", "author": ["M.A. Paskin"], "venue": "IJCAI\u201903: Proceedings of the 18th international joint conference on Artificial intelligence (pp. 1157\u20131164). Morgan Kaufmann.", "citeRegEx": "Paskin,? 2003", "shortCiteRegEx": "Paskin", "year": 2003}, {"title": "Spook: A system for probabilistic objectoriented knowledge representation", "author": ["A. Pfeffer", "D. Koller", "B. Milch", "K. Takusagawa"], "venue": "Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Pfeffer et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Pfeffer et al\\.", "year": 1999}, {"title": "First-order probabilistic inference", "author": ["D. Poole"], "venue": "IJCAI\u201903: Proceedings of the 18th international joint conference on Artificial intelligence (pp. 985\u2013991). Morgan Kaufmann.", "citeRegEx": "Poole,? 2003", "shortCiteRegEx": "Poole", "year": 2003}, {"title": "A unifying review of linear gaussian models", "author": ["S. Roweis", "Z. Ghahramani"], "venue": "Neural Computation,", "citeRegEx": "Roweis and Ghahramani,? \\Q1999\\E", "shortCiteRegEx": "Roweis and Ghahramani", "year": 1999}, {"title": "Inference in hybrid bayesian networks using mixtures of gaussians", "author": ["P. Shenoy"], "venue": "Proceedings of the TwentySecond Conference on Uncertainty in Artificial Intelligence (UAI-06) (pp. 428\u2013436). Arlington, Virginia: AUAI Press.", "citeRegEx": "Shenoy,? 2006", "shortCiteRegEx": "Shenoy", "year": 2006}], "referenceMentions": [{"referenceID": 4, "context": "Such systems include measurements in environmental-sensors networks (Hill et al., 2009), localizations in robotics (Limketkai et al.", "startOffset": 68, "endOffset": 87}, {"referenceID": 9, "context": ", 2009), localizations in robotics (Limketkai et al., 2005), and economic forecastings in finance (Niemira & Saaty, 2004).", "startOffset": 35, "endOffset": 59}, {"referenceID": 16, "context": "To address these issues, Relational Probabilistic Languages (RPLs) (Ng & Subrahmanian, 1992; Koller & Pfeffer, 1997; Pfeffer et al., 1999; Friedman et al., 1999; Poole, 2003; de Salvo Braz et al., 2005; Richardson & Domingos, 2006; Milch & Russell, 2007; Getoor & Taskar, 2007) describe probability distributions at a relational level with the purpose of capturing larger models.", "startOffset": 67, "endOffset": 277}, {"referenceID": 2, "context": "To address these issues, Relational Probabilistic Languages (RPLs) (Ng & Subrahmanian, 1992; Koller & Pfeffer, 1997; Pfeffer et al., 1999; Friedman et al., 1999; Poole, 2003; de Salvo Braz et al., 2005; Richardson & Domingos, 2006; Milch & Russell, 2007; Getoor & Taskar, 2007) describe probability distributions at a relational level with the purpose of capturing larger models.", "startOffset": 67, "endOffset": 277}, {"referenceID": 17, "context": "To address these issues, Relational Probabilistic Languages (RPLs) (Ng & Subrahmanian, 1992; Koller & Pfeffer, 1997; Pfeffer et al., 1999; Friedman et al., 1999; Poole, 2003; de Salvo Braz et al., 2005; Richardson & Domingos, 2006; Milch & Russell, 2007; Getoor & Taskar, 2007) describe probability distributions at a relational level with the purpose of capturing larger models.", "startOffset": 67, "endOffset": 277}, {"referenceID": 17, "context": "Recently, (Poole, 2003; de Salvo Braz et al., 2005; Milch et al., 2008; Singla & Domingos, 2008) showed that such models enable more efficient inference than possible with propositional graphical models, when inference occurs directly at the relational level.", "startOffset": 10, "endOffset": 96}, {"referenceID": 12, "context": "Recently, (Poole, 2003; de Salvo Braz et al., 2005; Milch et al., 2008; Singla & Domingos, 2008) showed that such models enable more efficient inference than possible with propositional graphical models, when inference occurs directly at the relational level.", "startOffset": 10, "endOffset": 96}, {"referenceID": 17, "context": "Present exact lifted inference algorithms (Poole, 2003; de Salvo Braz et al., 2006; Milch et al., 2008) and those developed in the efforts above are suitable for discrete domains, thus can in theory be applied to continuous domains through discretization.", "startOffset": 42, "endOffset": 103}, {"referenceID": 12, "context": "Present exact lifted inference algorithms (Poole, 2003; de Salvo Braz et al., 2006; Milch et al., 2008) and those developed in the efforts above are suitable for discrete domains, thus can in theory be applied to continuous domains through discretization.", "startOffset": 42, "endOffset": 103}, {"referenceID": 17, "context": "We also adapt principles of Inversion Elimination, a method devised by (Poole, 2003), to continuous models.", "startOffset": 71, "endOffset": 84}, {"referenceID": 17, "context": "1Part of its representation and terms are based on the previous works (Poole, 2003; de Salvo Braz et al., 2005; Milch & Russell, 2007).", "startOffset": 70, "endOffset": 134}, {"referenceID": 17, "context": "First, it splits (terminology of (Poole, 2003); shattering in (de Salvo Braz et al.", "startOffset": 33, "endOffset": 46}, {"referenceID": 17, "context": ", 2005))4 relational 4Please refer (Poole, 2003; de Salvo Braz et al., 2005) for fur5 \u03c6 : Market(s1), Market(s2),.", "startOffset": 35, "endOffset": 76}, {"referenceID": 12, "context": "Note that Inversion-Elimination (B) is also our new algorithm for continuous variables, even though comparable elimination methods for discrete variables (de Salvo Braz et al., 2005; Milch et al., 2008; Pfeffer et al., 1999) existed prior to ours.", "startOffset": 154, "endOffset": 224}, {"referenceID": 16, "context": "Note that Inversion-Elimination (B) is also our new algorithm for continuous variables, even though comparable elimination methods for discrete variables (de Salvo Braz et al., 2005; Milch et al., 2008; Pfeffer et al., 1999) existed prior to ours.", "startOffset": 154, "endOffset": 224}, {"referenceID": 17, "context": "(Poole, 2003), solves inference problems with the unification which dynamically splits a set of ground nodes and unifies them.", "startOffset": 0, "endOffset": 13}, {"referenceID": 12, "context": "(Milch et al., 2008) applies the counting formula to reduce the size of probability density tables.", "startOffset": 0, "endOffset": 20}, {"referenceID": 12, "context": "Thus, most of achievements are comparable to lifted inferences (de Salvo Braz et al., 2005; Milch et al., 2008; Pfeffer et al., 1999) over discrete domain.", "startOffset": 63, "endOffset": 133}, {"referenceID": 16, "context": "Thus, most of achievements are comparable to lifted inferences (de Salvo Braz et al., 2005; Milch et al., 2008; Pfeffer et al., 1999) over discrete domain.", "startOffset": 63, "endOffset": 133}, {"referenceID": 7, "context": "In detail, calculating conditional densities of multivariate Gaussians requires matrix inversions (Kotz et al., 2000) which are intractable for high dimensions.", "startOffset": 98, "endOffset": 117}, {"referenceID": 19, "context": "(Lerner & Parr, 2001; Shenoy, 2006) builds inference algorithms for hybrid models with Gaussians.", "startOffset": 0, "endOffset": 35}, {"referenceID": 15, "context": "(Paskin, 2003) shows that efficient inference is possible for a linear Gaussian when the treewidth of the model is small.", "startOffset": 0, "endOffset": 14}], "year": 2010, "abstractText": "Relational Continuous Models (RCMs) represent joint probability densities over attributes of objects, when the attributes have continuous domains. With relational representations, they can model joint probability distributions over large numbers of variables compactly in a natural way. This paper presents a new exact lifted inference algorithm for RCMs, thus it scales up to large models of real world applications. The algorithm applies to Relational Pairwise Models which are (relational) products of potentials of arity 2. Our algorithm is unique in two ways. First, it substantially improves the efficiency of lifted inference with variables of continuous domains. When a relational model has Gaussian potentials, it takes only linear-time compared to cubic time of previous methods. Second, it is the first exact inference algorithm which handles RCMs in a lifted way. The algorithm is illustrated over an example from econometrics. Experimental results show that our algorithm outperforms both a groundlevel inference algorithm and an algorithm built with previously-known lifted methods.", "creator": "TeX"}}}