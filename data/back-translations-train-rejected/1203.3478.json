{"id": "1203.3478", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2012", "title": "Playing games against nature: optimal policies for renewable resource allocation", "abstract": "In this paper we introduce a class of Markov decision processes that arise as a natural model for many renewable resource allocation problems. Upon extending results from the inventory control literature, we prove that they admit a closed form solution and we show how to exploit this structure to speed up its computation. We consider the application of the proposed framework to several problems arising in very different domains, and as part of the ongoing effort in the emerging field of Computational Sustainability we discuss in detail its application to the Northern Pacific Halibut marine fishery. Our approach is applied to a model based on real world data, obtaining a policy with a guaranteed lower bound on the utility function that is structurally very different from the one currently employed.", "histories": [["v1", "Thu, 15 Mar 2012 11:17:56 GMT  (154kb)", "http://arxiv.org/abs/1203.3478v1", "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)", "reviews": [], "SUBJECTS": "cs.AI cs.GT", "authors": ["stefano ermon", "jon conrad", "carla p gomes", "bart selman"], "accepted": false, "id": "1203.3478"}, "pdf": {"name": "1203.3478.pdf", "metadata": {"source": "CRF", "title": "Playing games against nature: optimal policies for renewable resource allocation", "authors": ["Stefano Ermon"], "emails": ["ermonste@cs.cornell.edu", "jmc16@cornell.edu", "gomes@cs.cornell.edu", "selman@cs.cornell.edu"], "sections": [{"heading": null, "text": "In this paper, we present a class of Markov decision-making processes that emerge as a natural model for many problems of the allocation of renewable resources. By extending the results of the literature on stock control, we demonstrate that they allow for a coherent solution and show how we can use this structure to speed up its calculation. We consider the application of the proposed framework to several problems that arise in very different areas, and within the ongoing efforts in the emerging field of Computational Sustainability, we discuss in detail its application to the marine fisheries of the North Pacific halibut. Our approach is applied to a model that is based on real data and achieves a policy with a guaranteed lower limit in terms of benefit function, which is structurally very different from that currently applied."}, {"heading": "1 Introduction", "text": "This year, it has come to the point that it will only be a matter of time before it is ready, until it is ready."}, {"heading": "2 MDP Formulation", "text": "In this section, we formulate the optimization problem as discrete time, continuous space Markov decision-making process. Wherever possible, we will use a notation that matches the one used in [4]. Even if we only consider a problem of the finite horizon, the results can be extended to the infinite horizon case with limiting arguments. To make the description concrete, the model is largely described with a natural resource management problem in mind. We consider a dynamic system that develops over time after toxn + 1 = f (xn \u2212 hn, wn), (1) where xn \u00b2 R denotes the stock of a renewable resource in due time n. By using a discrete time model, we implicitly assume that replacement or birth processes take place in regular, well-defined \"breeding seasons,\" where f (\u00b7) is a reproduction function that maps the stock level at the end of a season, to the new stock level at the beginning of the next season."}, {"heading": "2.1 Resource Economics", "text": "We now look at the economic aspects of the model. We assume that the revenue generated from a harvest h is proportional to h by a fixed price p and that the harvest is costly. In particular, we assume that there is a fixed set-up costK for each harvest \u2022 Marginal harvest costs g (x) per unit harvested xIt follows that the benefit from a harvest h is derived from an initial stock x isph \u2212 xx \u2212 hg (y) dy \u2212 K, R (x) \u2212 R (x \u2212 h) \u2212 K, (3) whereas R (x) = px \u2212 x0g (y) dy.We assume that marginal harvest costs g (x) rise when the stock size x decreases. We include the time preference in the model by considering a fixed discount factor \u03b1 = 1 / (1 + \u03b4) = maxix) when the yield capacity (0 \u2264 xi \u2212 1) is taken into account."}, {"heading": "3 Main Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Minimax Dynamic Programming", "text": "A policy \u03c0 is referred to as the optimal policy of the N period when C\u03c0N (x) gains control over all permissible measures at \u03c0 for all x. We call CN (x) = sup \u03c0 \u0441\u043d\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0442N (x), the optimal value function in which \u0432 represents the totality of all permissible measures. As a consequence of the principle of optimality ([4]), the dynamic programming equation for this problem is: C0 (x) = 0, Cn (x) = max 0 \u2264 hn \u2264 x min \u2264 W R (xn) \u2212 R (xn \u2212 hn) \u2212 hn) + \u03b1Cn \u2212 1 (f \u2212 hn, wn) for all n > 0 \u2212 0. The latter equation can be applied to the remaining stock z = x \u2212 hn \u2264 W (the subsequent decision state) \u2212 R (x) hn \u2212 hn \u2212 hn \u2212 hn, if the optimal policy x (R \u2212 hn, wn) n \u2212 n, if n \u2212 n is all \u2212 we can write the remaining stock z = max \u2212 hn and the following stock x = the following state \u2212 n."}, {"heading": "3.2 Preliminaries on K-concavity", "text": "A function \u03b2 () is K1-concave and K2-concave for constants x < y < y \u03b2 \u03b2 \u03b2; z, \u03b2 (y) exceeds the secondary approximation to \u03b2 (y) obtained with points \u03b2 (x) \u2212 K and \u03b2 (z). Therefore, no slackening is allowed for K = 0 and the standard definition of concavity is restored. Formal definition 1. A real function \u03b2 (\u00b7) is K-concave if for all x, y, x < y, and for all b > 0\u03b2 (y) \u2212 \u03b2 (y) \u03b2 (y) \u2212 \u03b2 (y) b \u2264 K (7) We give some useful results in relation to the K concavity: Lemma 1. The following properties apply: \u2022 A concave function is 0-concave and hence Kconcave for all."}, {"heading": "3.3 On the Optimality of (S \u2212 s) policies", "text": "Suppose that we can prove that Pn (x) is continuous and strictly K-concave. < p (1) Then from Lemon 1 there is Sn, sn with the properties proven in the last point of the Lemon. It is therefore easy to see this condition (6) is met only if x > s, in which case the optimal value of the remaining stock z would be exactly Sn. In conclusion, if we have the continuity and K concavity of functions Pn (x), n = 1,., N, then the following feedback law known as non-stationary (S \u2212 s) policy is optimal: In the period n in which a harvest is undertaken, if and only if the current stock level is greater than sn; in this case the stock is harvested until Sn.This policy is known in the inventory control literature as non-stationary (S \u2212 s) policy, because the levels are Sn and time dependent."}, {"heading": "4 Consistency and Complexity", "text": "Even if Theorem 1 fully describes the structure of optimal politics, there is generally no closed form solution for the values of Sn and sn that must be calculated numerically. In order to use the standard approach of dynamic programming, the state, control and interference spaces must be discredited, for example, using an evenly static grid. Assuming that these spaces are limited, we obtain discredited sentences with a finite number of elements in this way. We can then write DP-like equations for these points by using an interpolation of the value function for the points that are not in the grid. The equations can then be solved recursively by obtaining the semi-optimal measures that are taken for each point of the grid, which can then be expanded by interpolation to obtain an approximate solution to the original problem. As with all discretion programs, we must discuss the consistency of the method."}, {"heading": "5 Case Study: the Pacific Halibut", "text": "Commercial exploitation of Pacific halibut on the north-west coast of North America dates back to the late 19th century and is now one of the largest and most profitable fisheries in the region. Fisheries developed so quickly that they began to show signs of overfishing at the beginning of the 20th century. Following the publication of scientific reports clearly showing a significant decline in stocks, the governments of the US and Canada signed a treaty establishing the International Pacific Halibut Commission (IPHC) for the rational management of the resource. The IPHC Commission controls the amount of fish caught annually by setting the annual Total Allowable Catch (TAC), which is precisely the decision variable in our optimisation problem."}, {"heading": "5.1 Management Problem Formulation", "text": "In order to develop a bioeconomic model of fisheries, we have obtained data 2 from the IPHC annual reports on estimated biomass costs of 15,000 euros (measured in thousands of skate soaks) for area 3A (one of the most important regulatory areas in which water is divided) for a period of 33 years from 1975 to 2007. To model population dynamics, we must assume that the population will be made available on request by the authors. (11), where sn \u2212 hn is the stock left after fishing (inhibition) in year n. This model can be regarded as discrediting the ongoing logistical equation. Here, parameters m represent a natural mortality coefficient, r0 can be interpreted as the reproduction rate. (r0 \u2212 m) / m is the sustainability of the environment."}, {"heading": "5.2 Optimal Policy", "text": "If we apply the dynamic programming approach to the problem, which is fixed with a step size of 0.25 x 106 pounds, we will calculate the optimal policy for a management horizon of N = 33 years, which is the length of our original time series. As predicted by Theorem 1, the optimal policy of S1 and s1 in the first year (the values of S1 and s1 are respectively 133 and 176.75) for the model we have constructed for area 3A is a non-stationary (S \u2212 s) policy. In words, the optimal policy dictates that in time n a harvest should be undertaken if and only if the current level of stocks is greater than sn; in this case the stock is on Sn.The orbit of the system is harvested if managed with the optimal policy is shown in Figure 2, along with the corresponding optimal harvests."}, {"heading": "6 Conclusions", "text": "In this paper, we have analyzed the optimality of (S \u2212 s) strategies for a relatively general class of stochastic discrete resource allocation problems. If a non-stationary (S \u2212 s) policy is applied, a harvest is performed in the n if and only if the current stock is larger than sn; in this case, the stock is harvested except for Sn. The framework developed is quite general and can be applied to problems occurring in very different areas, such as natural resource management, crowdsourcing, pollution management. If the assumptions of Theorem 1 are met, we have shown that there is a non-stationary (S \u2212 s) policy that maximizes the benefit in a worst-case scenario. A fundamental advantage of the game theory approach is that it completely avoids the problem of assessing the probability distribution of the random variables describing the uncertainty of these systems."}, {"heading": "7 Acknowledgments", "text": "This research is funded by the NSF Expeditions in Computing Scholarship 0832782."}], "references": [{"title": "Robust optimization\u2013 methodology and applications", "author": ["A. Ben-Tal", "A. Nemirovski"], "venue": "Mathematical Programming,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Dynamic programming and optimal control", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific Belmont, MA,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1995}, {"title": "Robust discrete optimization and network flows", "author": ["D. Bertsimas", "M. Sim"], "venue": "Mathematical Programming,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Mathematical bioeconomics: the optimal management of renewable resources", "author": ["C.W. Clark"], "venue": "Wiley New York:,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1990}, {"title": "Resource economics", "author": ["J.M. Conrad"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1999}, {"title": "Sustainability of fisheries through marine reserves: a robust modeling analysis", "author": ["L. Doyen", "C. B\u00e9n\u00e9"], "venue": "Journal of Environmental Management,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Computational Sustainability Computational Methods for a Sustainable Environment,Economy, and Society", "author": ["C. Gomes"], "venue": "The Bridge, National Academy of Engineering,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Wilen. A model of regulated open access resource use", "author": ["J.E.F.R. Homans"], "venue": "Journal of Environmental Economics and Management,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Risk-sensitive Markov decision processes", "author": ["R.A. Howard", "J.E. Matheson"], "venue": "Management Science,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1972}, {"title": "Implementing the precautionary principle in fisheries management through marine reserves", "author": ["T. Lauck", "C.W. Clark", "M. Mangel", "G.R. Munro"], "venue": "Ecological Applications,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Markov games as a framework for multi-agent reinforcement learning", "author": ["M.L. Littman"], "venue": "In Proceedings of the eleventh international conference on machine learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1994}, {"title": "Risk sensitive Markov decision processes", "author": ["S.I. Marcus", "E. Fern\u00e1ndez-Gaucherand", "D. Hern\u00e1ndez-Hernandez", "S. Coraluppi", "P. Fard"], "venue": "Systems and Control in the Twenty-First Century,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1997}, {"title": "Game theory. Third Edition", "author": ["G. Owen"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "A stochastic model for the economic management of a renewable animal resource", "author": ["W.J. Reed"], "venue": "Mathematical Biosciences,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1974}, {"title": "Optimal escapement levels in stochastic and deterministic harvesting models", "author": ["W.J. Reed"], "venue": "Journal of Environmental Economics and Management,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1979}, {"title": "The Optimality of (S, s) Policies in the Dynamic Inventory Problem. Stanford mathematical studies in the social sciences, page", "author": ["H. Scarf"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1960}], "referenceMentions": [{"referenceID": 3, "context": "While in most of the works in the literature [6, 7] these growth processes are modeled with deterministic first-order difference or differential equations, this approach often represents an oversimplification.", "startOffset": 45, "endOffset": 51}, {"referenceID": 4, "context": "While in most of the works in the literature [6, 7] these growth processes are modeled with deterministic first-order difference or differential equations, this approach often represents an oversimplification.", "startOffset": 45, "endOffset": 51}, {"referenceID": 9, "context": "In fact, even if in principle uncertainty could be reduced by collecting and analyzing more data, it is generally believed that complex and stochastic systems, such a marine environments, could never become predictable (to the point that the authors of [13] believe that \u201cpredictability of anything as complex as marine ecosystem will forever remain a chimera\u201d).", "startOffset": 253, "endOffset": 257}, {"referenceID": 5, "context": "Moreover, there are situations of \u201cradical uncertainty\u201d ([8]) or ambiguity where a stochastic description is not feasible because the probabilities are not quantifiable.", "startOffset": 57, "endOffset": 60}, {"referenceID": 8, "context": "Using tools such as risksensitive Markov decision processes ([12, 15]), it is also possible to encode into the problem the attitude towards risk of the decision maker by using an appropriate utility function.", "startOffset": 61, "endOffset": 69}, {"referenceID": 11, "context": "Using tools such as risksensitive Markov decision processes ([12, 15]), it is also possible to encode into the problem the attitude towards risk of the decision maker by using an appropriate utility function.", "startOffset": 61, "endOffset": 69}, {"referenceID": 0, "context": "This type of approach, where the problem of data uncertainty is addressed by guaranteeing the optimality of the solution for the worst realizations of the parameters, is also known in the literature as robust optimization ([3, 5]), and has been successfully applied to uncertain linear, conic quadratic and semidefinite programming.", "startOffset": 223, "endOffset": 229}, {"referenceID": 2, "context": "This type of approach, where the problem of data uncertainty is addressed by guaranteeing the optimality of the solution for the worst realizations of the parameters, is also known in the literature as robust optimization ([3, 5]), and has been successfully applied to uncertain linear, conic quadratic and semidefinite programming.", "startOffset": 223, "endOffset": 229}, {"referenceID": 10, "context": "This formulation is a particular type of Markov game [14] (sometimes called a stochastic game [16]) where there are only two agents (the manager and nature) and they have diametrically opposed goals.", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "This formulation is a particular type of Markov game [14] (sometimes called a stochastic game [16]) where there are only two agents (the manager and nature) and they have diametrically opposed goals.", "startOffset": 94, "endOffset": 98}, {"referenceID": 6, "context": "As part of the new exciting research area of Computational Sustainability ([10]), where techniques from computer science and related fields are applied to solve the pressing sustainability challenges of our time, we present an application of the proposed framework to the Northern Pacific Halibut fishery, one of the largest and most lucrative fisheries of the Northwestern coast.", "startOffset": 75, "endOffset": 79}, {"referenceID": 1, "context": "Whenever possible, we will use a notation consistent with the one used in [4].", "startOffset": 74, "endOffset": 77}, {"referenceID": 13, "context": "As opposed to the maximization of an expected utility ([17, 18]), this formulation is inherently risk averse.", "startOffset": 55, "endOffset": 63}, {"referenceID": 14, "context": "As opposed to the maximization of an expected utility ([17, 18]), this formulation is inherently risk averse.", "startOffset": 55, "endOffset": 63}, {"referenceID": 1, "context": "As a consequence of the principle of optimality([4]), the dynamic programming equation for this problem reads:", "startOffset": 48, "endOffset": 51}, {"referenceID": 1, "context": "It can be shown (see [4]) that Cn(x), the revenue function associated with an optimal policy, is the (unique) solution to equation (4).", "startOffset": 21, "endOffset": 24}, {"referenceID": 15, "context": "To examine this kind of relationship it is useful to introduce the notion of K-concavity, a natural extension of the Kconvexity property originally introduced by Scarf in [19] to study inventory control problems.", "startOffset": 171, "endOffset": 175}, {"referenceID": 1, "context": "Similar results for K-convex functions are proved in [4].", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "However in this case Theorem 1 guarantees the continuity of Cn, that in turn implies the consistency of the method, even if the policy itself is not continuous as a function of the state([4]).", "startOffset": 187, "endOffset": 190}, {"referenceID": 14, "context": "Following [18], we suppose that the system is affected by stochasticity in the form of seasonal shocks wn that influence only the new recruitment part", "startOffset": 10, "endOffset": 14}, {"referenceID": 7, "context": "Following the analysis of the historical variable and fixed costs for the halibut fishery carried on in [11], we assume K = 5, 000, 000$ for area 3A.", "startOffset": 104, "endOffset": 108}], "year": 2010, "abstractText": "In this paper we introduce a class of Markov decision processes that arise as a natural model for many renewable resource allocation problems. Upon extending results from the inventory control literature, we prove that they admit a closed form solution and we show how to exploit this structure to speed up its computation. We consider the application of the proposed framework to several problems arising in very different domains, and as part of the ongoing effort in the emerging field of Computational Sustainability we discuss in detail its application to the Northern Pacific Halibut marine fishery. Our approach is applied to a model based on real world data, obtaining a policy with a guaranteed lower bound on the utility function that is structurally very different from the one currently employed.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}