{"id": "1203.3487", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2012", "title": "BEEM : Bucket Elimination with External Memory", "abstract": "A major limitation of exact inference algorithms for probabilistic graphical models is their extensive memory usage, which often puts real-world problems out of their reach. In this paper we show how we can extend inference algorithms, particularly Bucket Elimination, a special case of cluster (join) tree decomposition, to utilize disk memory. We provide the underlying ideas and show promising empirical results of exactly solving large problems not solvable before.", "histories": [["v1", "Thu, 15 Mar 2012 11:17:56 GMT  (441kb)", "http://arxiv.org/abs/1203.3487v1", "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)", "reviews": [], "SUBJECTS": "cs.AI cs.DS", "authors": ["kalev kask", "rina dechter", "rew e gelfand"], "accepted": false, "id": "1203.3487"}, "pdf": {"name": "1203.3487.pdf", "metadata": {"source": "CRF", "title": "BEEM : Bucket Elimination with External Memory", "authors": ["Kalev Kask", "Rina Dechter"], "emails": [], "sections": [{"heading": null, "text": "A major limitation of accurate inference algorithms for probabilistic graphical models is their extensive memory usage, which often puts real-world problems out of reach. In this paper, we show how to extend inference algorithms, especially bucket elimination, a specific case of cluster (joint) tree decomposition, to hard disk storage. We provide the underlying ideas and show promising empirical results in solving major problems that were previously insolvable."}, {"heading": "1 Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "2 Background", "text": "In this section we present some necessary precautions that occur in relation to graphical models and terms. Definition 1. Graphical Model - A Graphical Model R is a 4-tuple R = < X, F, >, where: 1. X = {X1,... Xn} is a set of variables; 2. D = {D1,... Dn} is the set of their individual - nite domains of values; 3. F = {f1,... fr} is a set of real value functions de ned over a subset of variables Si X. The scope of the function \"fi,\" as it is called, is its set of arguments, Si \"fi.\""}, {"heading": "3 Bucket Elimination with External Memory", "text": "In fact, most of them will be able to play by the rules they have set themselves, and they will be able to play by the rules they have set themselves."}, {"heading": "3.1 Function Table Indexing", "text": "For example, if f (X1, X2) is a table of ternary variables, the entries are ordered as follows: < 0, 0 > (Index 0), < 0, 1 > (Index 1), < 0, 2 > (Index 2), < 1, 0 > (Index 3), etc. Thus, the order of variables in the scope of a function determines where an entry is in the function table. As we look at functions (i.e. fXp) divided into blocks because they do not get into memory, the order of variables may also affect the number of reads / writings on disk. In the following section, we will show how the order of variables within a frame can affect the performance of our algorithm. Then, we will show how some of these variables are resolved by the order of the imposed two steps to process the tree."}, {"heading": "3.1.1 Ordering Constraints due to Elimination", "text": "In fact, it is the case that most of them are able to outdo themselves and that they see themselves in a position to outdo themselves. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "3.1.2 Ordering Constraints due to Combination", "text": "To illustrate this, consider the following example: Suppose we calculate a function f (X1, X2, X3) by combining and eliminating the variable Y from function 1 (X1, X2, Y), h2 (X1, X3, Y), and we assume that the domain size of all variables 3. From the previous section, we know that Y must be the last variable in the combined function, so if we calculate f (X1 = 1, X2 = 1, X3 = 2), we must access the entries h2 (X1 = 1, X3 = 2, Y = 0, 1, 2) corresponding to indexes 15, 16, and 17 in table h2, and the next entry of f (X1 =.2, X2 = 3, corresponding to 1 = 1), with variables 1, 1 = 3 = 0 (X2) corresponding to indexes 15, 16, and 17 in table h2."}, {"heading": "3.2 Block Computation", "text": "That is, we assume that all tables of intermediate functions are handled (i.e.). That is, it is necessary that the individual functions in each block are as large as possible, but the block size is limited by several factors. First, our algorithm is operated in a shared storage system, and each thread needs memory to operate. To simplify this problem, we assume that the original functions occupy little space in memory and block the blocks of each input function. So, our goal is to divide function tables into blocks that divide unused memory resources into unused memory. To simplify this problem, we assume the following design assumptions: 1. We assume that the original functions occupy little space and are stored in memory at all times; 32. We assume that each thread uses the same amount of memory and that the memory remains allocated to a thread; 3. We assume that each function is allocated the same amount of algorithms in a thread."}, {"heading": "3.3 The BEEM Algorithm", "text": "We have developed a new algorithm called BEEM that takes up the design ideas and algorithms described in this paragraph. The basic sketch of the BEEM algorithm is in Figure 6.There is a 1-to-1 mapping between blocks and les. An le name is a concatenation of the variables of the bucket (which created the function to which the block belongs) and the block index (wrt the function table).For example, if a specific function created by Bucket BX is divided into 5 blocks, the 5 les that contain the data are called \"X-1,\" \"X-2,\" \"X-3,\" \"X-4,\" \"X-5.\" When a particular block is needed, the program searches and loads / stores a line with the appropriate name. A block is an array of double-precise calculator numbers that calculate the variables of the calculator, and the entire block / le can be stored with a single comma single step of an algorithm."}, {"heading": "4 Experimental Evaluation", "text": "To evaluate the BEEM algorithm, we compared its performance with that of two other algorithms used to calculate the probability of evidence on probabilistic networks (Bayesian and Markov). In our comparison, we used a number of problems (so-called linkage / pedigree problems) stemming from genetics, which were used in the solving contest held at the UAI-2008.4 Many of these problems were not solved in this contest, and in addition, we also consider a class of problems - type 4 linkage - with high induced width and large number of variables.The two algorithms we used for the comparison were: 1) VEC (Variable Elimination and Conditioning) [3]; and ACE [1]. Both VEC and ACE participated in the UAI2008 solving contest. In their class (exact solvers for probabilistic networks, solution of the P (e) problem) VEC / ACE were the best two UI solvers."}, {"heading": "4.1 VEC", "text": "VEC is an algorithm that uses conditioning to create partial problems with induced widths small enough to be solved by an elimination algorithm. A basic outline of VEC is: \u2022 As a pre-processing step, VEC reduces variable domains by converting all 0 probabilities to a SAT problem F and checking for each assignment X = a whether (F and X = a) is consistent. Inconsistent assignments are truncated from domain X. \u2022 Repeatedly remove conditioning variables from the problem until the remaining problem lies within 1GB of memory. \u2022 Enumerate all value combinations of conditioning variables."}, {"heading": "4.2 ACE", "text": "ACE is a software package that allows accurate inference of Bayesian networks developed in the Au-4. For a report on the results of the competition, see http: / / graphmod.ics.uci.edu / uai08 / Evaluation / Report.5 see http: / / graphmod.ics.uci.edu / group / Software for more details about the VECtomated Reasoning Group at UCLA6. ACE works by assembling a Bayesian network into an arithmetic circuit (AC) and then using that AC to execute queries. Compiling to an AC is done by first encoding the Bayesian network in conjunctive normal form (CNF) and then extracting the AC from the factored CNF [1]."}, {"heading": "4.3 Results", "text": "Preliminary results from the execution of the three algorithms on a single problem class are shown in Tables 1 and 2. In these tables, N indicates the number of variables, w? is an upper limit for the induced width (experimentally determined on the basis of several minimum orders), and K is the maximum domain size. Runtime is shown in the format hh: mm: ss and \"> 24 h\" indicates that the algorithm did not compute p (e) in 24 hours, while \"OOM\" indicates that the algorithm exceeded the allocated 1 GB RAM. Table 1, results on stem problems with a few hundred to a thousand variables. Table 2 contains results from a series of problems with several thousand variables. In both problem groups, we observe some interesting phenomena. First, if a problem is small enough for the problem to enter memory, all three algorithms calculate p (e) very quickly."}, {"heading": "5 Conclusions", "text": "We proposed an extension of the bucket elimination algorithm, which uses external storage space to store intermediate tables. Extending the BE algorithm in this way and also parallelizing the calculation is a non-trivial matter. In this paper, we identified and addressed a number of key issues, including splitting functions into suitably large blocks and processing to minimize access to hard disks. Although the performance of our algorithm is not fully optimized, it has shown very promising results on a class of large likely networks, demonstrating improved scalability and enabling accurate computa-6http: / / reasoning.cs.ucla.edu / tion of p (e) for problems that do not lie before being solved by an all-purpose algorithm. To better understand its performance, we plan to run BEEM on several additional problem classes. In addition to further improving the decomposition and calculation schemes, we also plan to update BEEM in a compatible way, and in other ways."}, {"heading": "Acknowledgements", "text": "This work was partially supported by the NSF under premium number IIS-0713118 and by the NIH scholarship R01HG004175-02."}], "references": [{"title": "Compiling bayesian networks with local structure", "author": ["M. Chavira", "A. Darwiche"], "venue": "Proc. of 19th Intl. Joint Conf. on AI, pages 1306 1312", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "Recursive conditioning", "author": ["A. Darwiche"], "venue": "Arti cial Intelligence, 126(1-2):5 41", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Bucket elimination: A unifying framework for probabilistic inference", "author": ["R. Dechter"], "venue": "pages 211 219", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "And/or search spaces for graphical models", "author": ["R. Dechter", "R. Mateescu"], "venue": "Artif. Intell., 171(2- 3):73 106", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Unifying cluster-tree decompositions for reasoning in graphical models", "author": ["K. Kask"], "venue": "Arti cial Intelligence,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Linear-time disk-based implicit graph search", "author": ["R.E. Korf"], "venue": "J. ACM, 55(6):1 40", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Minimizing disk i/o in two-bit breadthrst search", "author": ["R.E. Korf"], "venue": "Proc. of 23rd Natl. Conf. on AI, pages 317 324. AAAI Press", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Boosting search with variable elimination in constraint optimization and constraint satisfaction problems", "author": ["J. Larrosa", "R. Dechter"], "venue": "Constraints, 8(3):303 326", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": "Morgan Kaufmann", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1991}, {"title": "Global conditioning for probabilistic inference in belief networks", "author": ["R.D. Shachter", "S.K. Andersen"], "venue": "Proc. 10th Conf. on Uncert. in AI, pages 514 522", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1994}], "referenceMentions": [{"referenceID": 2, "context": "best- rst, depth- rst branch and bound) [3, 4, 5, 2].", "startOffset": 40, "endOffset": 52}, {"referenceID": 3, "context": "best- rst, depth- rst branch and bound) [3, 4, 5, 2].", "startOffset": 40, "endOffset": 52}, {"referenceID": 4, "context": "best- rst, depth- rst branch and bound) [3, 4, 5, 2].", "startOffset": 40, "endOffset": 52}, {"referenceID": 1, "context": "best- rst, depth- rst branch and bound) [3, 4, 5, 2].", "startOffset": 40, "endOffset": 52}, {"referenceID": 1, "context": "Not surprisingly, various algorithms have been proposed that can work with bounded memory at the expense of additional time [2, 8, 9, 10].", "startOffset": 124, "endOffset": 137}, {"referenceID": 7, "context": "Not surprisingly, various algorithms have been proposed that can work with bounded memory at the expense of additional time [2, 8, 9, 10].", "startOffset": 124, "endOffset": 137}, {"referenceID": 8, "context": "Not surprisingly, various algorithms have been proposed that can work with bounded memory at the expense of additional time [2, 8, 9, 10].", "startOffset": 124, "endOffset": 137}, {"referenceID": 9, "context": "Not surprisingly, various algorithms have been proposed that can work with bounded memory at the expense of additional time [2, 8, 9, 10].", "startOffset": 124, "endOffset": 137}, {"referenceID": 5, "context": "Nonetheless, it has been demonstrated in the context of (A*) heuristic search that algorithms can be designed to mitigate such e ects [6, 7], yielding powerful schemes that can be applied to previously unsolvable problems.", "startOffset": 134, "endOffset": 140}, {"referenceID": 6, "context": "Nonetheless, it has been demonstrated in the context of (A*) heuristic search that algorithms can be designed to mitigate such e ects [6, 7], yielding powerful schemes that can be applied to previously unsolvable problems.", "startOffset": 134, "endOffset": 140}, {"referenceID": 2, "context": "In the remainder of this paper, we describe how a speci c inference-based algorithm, BE [3], can be modi ed to use external memory.", "startOffset": 88, "endOffset": 91}, {"referenceID": 2, "context": "Bucket Elimination (BE) is a special case of cluster tree elimination in which the tree-structure upon which messages are passed is determined by the variable elimination order used [3].", "startOffset": 182, "endOffset": 185}, {"referenceID": 2, "context": "Figure 2: The Bucket Elimination Algorithm [3]", "startOffset": 43, "endOffset": 46}, {"referenceID": 2, "context": "The two algorithms we used for comparison were: 1) VEC (Variable Elimination and Conditioning) [3]; and ACE[1].", "startOffset": 95, "endOffset": 98}, {"referenceID": 0, "context": "The two algorithms we used for comparison were: 1) VEC (Variable Elimination and Conditioning) [3]; and ACE[1].", "startOffset": 107, "endOffset": 110}, {"referenceID": 0, "context": "Compiling into an AC occurs by rst encoding the Bayesian network into Conjunctive Normal Form (CNF) and then extracting the AC from the factored CNF [1].", "startOffset": 149, "endOffset": 152}], "year": 2010, "abstractText": "A major limitation of exact inference algorithms for probabilistic graphical models is their extensive memory usage, which often puts real-world problems out of their reach. In this paper we show how we can extend inference algorithms, particularly Bucket Elimination, a special case of cluster (join) tree decomposition, to utilize disk memory. We provide the underlying ideas and show promising empirical results of exactly solving large problems not solvable before.", "creator": "TeX"}}}