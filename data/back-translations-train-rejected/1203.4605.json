{"id": "1203.4605", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2012", "title": "Arabic Keyphrase Extraction using Linguistic knowledge and Machine Learning Techniques", "abstract": "In this paper, a supervised learning technique for extracting keyphrases of Arabic documents is presented. The extractor is supplied with linguistic knowledge to enhance its efficiency instead of relying only on statistical information such as term frequency and distance. During analysis, an annotated Arabic corpus is used to extract the required lexical features of the document words. The knowledge also includes syntactic rules based on part of speech tags and allowed word sequences to extract the candidate keyphrases. In this work, the abstract form of Arabic words is used instead of its stem form to represent the candidate terms. The Abstract form hides most of the inflections found in Arabic words. The paper introduces new features of keyphrases based on linguistic knowledge, to capture titles and subtitles of a document. A simple ANOVA test is used to evaluate the validity of selected features. Then, the learning model is built using the LDA - Linear Discriminant Analysis - and training documents. Although, the presented system is trained using documents in the IT domain, experiments carried out show that it has a significantly better performance than the existing Arabic extractor systems, where precision and recall values reach double their corresponding values in the other systems especially for lengthy and non-scientific articles.", "histories": [["v1", "Tue, 20 Mar 2012 21:52:35 GMT  (338kb)", "http://arxiv.org/abs/1203.4605v1", "Proceedings of the Second International Conference on Arabic Language Resources and Tools, 2009"]], "COMMENTS": "Proceedings of the Second International Conference on Arabic Language Resources and Tools, 2009", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tarek el-shishtawy", "abdulwahab al-sammak"], "accepted": false, "id": "1203.4605"}, "pdf": {"name": "1203.4605.pdf", "metadata": {"source": "CRF", "title": "Arabic Keyphrase Extraction using Linguistic knowledge and Machine Learning Techniques", "authors": [], "emails": ["shishtawy@hotmail.com", "sammaka@gmail.com"], "sections": [{"heading": "1. Introduction", "text": "Keyphrases are a list of phrases composed of about five to fifteen important words and phrases that express the most important topics discussed in a particular document. As the amount of electronic text content grows rapidly, keyphrases can help manage the process of dealing with these large amounts of text information. Keyphrases play an important role in digital libraries, web content and content management systems, especially in cataloging and information gathering. The limited number of documents that have assigned key phrases as metadata descriptions increases the need for a tool that can automatically extract key phrases from text. Such a tool can retrieve many different types of information and generate analysis systems. It can automate: \u2022 Metadata that provide a high-grade description of the contents of a document, providing tools for text-mining related tasks such as document and web-page retrieval purposes. \u2022 Summary of potentially high-grade documents can represent a reader."}, {"heading": "2. Related Work", "text": "This year it is so far that it will be able to erenie.n the aforementioned lcihsrcnlrVo"}, {"heading": "3. The Proposed System", "text": "In this paper, automatic keyphrase extraction is treated as a supervised machine learning task. It defines two important questions: how to define the candidate keyphrase terms and which features of these terms are considered discriminatory, i.e. how to present the data, and consequently, what is given as input to the learning algorithm. Our motivation is that adding linguistic knowledge (such as lexical features and syntactic rules) to the extraction process, rather than relying solely on statistics, can achieve better results. Therefore, the current work is based on the combination of linguistic knowledge and machine learning techniques to extract keywords from Arabic documents with appropriate accuracy. Linguistic knowledge will play an important role at various stages of our proposed system: 1. Level of analysis in which the document is tokenized into sentences and words. Each word is analyzed using a commented Arabic corpus to extract its POS category, tags and abstract form."}, {"heading": "4- Linguistic Pre-Processor", "text": "Each document must first be pre-edited to correct the spelling errors as much as possible, and then the input document is broken down into sentences and words. Each word is analyzed to extract its lexical characteristics such as a part of speech blocks, a category and an abstract form, a process described in the following subsections."}, {"heading": "4.1. Document Preprocessing", "text": "The input document is segmented on two levels: On the first level, the document is divided into its constituent parts based on the delimiters of Arabic phrases such as comma, semicolon, colon, hyphen, and period. This process is useful for calculating part of the characteristic vector of candidate terms, such as the Normalized Sentence Position (NSL), Normalized Phrase Position (NPL), Normalized Phrase Length (NPLen), and Sentence Contain Verb (SCV). On the second level, each sentence is segmented into its constituent parts based on the criteria that words are normally separated by spaces. The generated sentences and words are exported to database tables related to their parent document table."}, {"heading": "4.2. Part of Speech Analysis", "text": "The analysis process involves gathering linguistic knowledge about the input document, gender, person and the resulting conclusion. \"Complete document analysis will require morphology, syntax and semantic analysis.\" This will strain the extractor's performance due to the cumbersome nature of these analyses. \"The focus will therefore be on extracting the lexical characteristics of the document words.\" Again, this type of analysis requires the presence of the Arabic lexicon and Arabic morphological analyzer. Instead, we will use a commented Arabic word corpus to extract the required lexical characteristics of the document words. Thus, a specially designed commenting Arabic corpus is used during the analysis process to improve the speed of the proposed system. This corpus contains collections of analyzed Arabic words from different domains. The structure of the proposed corpus is defined by the word segments (prefix, root and suffix), word root, and abstract form."}, {"heading": "5. Candidate Phrases Extraction", "text": "At this stage, all possible phrases of one, two or three consecutive words that occur in a particular document are generated as n-gram terms that follow some syntactical rules. For example, the phrase \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\""}, {"heading": "6. Feature Vector Calculation", "text": "In fact, the fact is that most of us will be able to be in the position in which they are able to move, to be in the position in which they are able to be in, to be in the position in which they are able to be in, to be in the position in which they are able to be in, to be in the position in which they are able to be in, to be in the position in which they are able to be in, to be in the position in which they are able to be in, in which they are able to hide."}, {"heading": "7. Learning Experiments", "text": "In the previous section, we propose eight statistical and linguistic features to represent the meaning of each candidate phrase. Now, the effectiveness of each feature is measured in classifying candidate phrases as keyphrases or not. This goal can be achieved by using learning models and training materials with keyphrases assigned by the author. ANOVA (ANalysis Of VAriance) test is used to evaluate the validity of the selected characteristics. The learning model is then created using the LDA (Linear Discriminant Analysis) and training materials with known keyphrases. Finally, the model is used to find key phrases for new documents. In the following subsections, the size of the training data, the ANOVA test and the LDA model is checked."}, {"heading": "7.1 Training Data", "text": "A sample of 30 documents is collected, pre-edited, analysed and manually assigned to keyphrases. Training data comes from a variety of sources and areas with a focus on computing. It includes journal articles, technical reports, essays and sections from textbooks. Few of these documents have keyphrases assigned by the author. The other documents are read carefully by many professionals to assign the correct keyphrases to the document. This data is used to train the proposed system by adjusting the classification parameters to best match the assigned keyphrases. The training sample produces 6671 candidate keyphrases. The keyphrases assigned by the author, ranging from 5 to 7 phrases per document, are assigned to the Is-Key function. Any occurrence of the abstract form of these keyphrases is marked, resulting in 885 positive and 5786 negative keyphrases."}, {"heading": "7.2 ANOVA for Regression", "text": "Variance analysis (ANOVA) for regression tests can be used to measure the effects of changes in parameter values on the dependent output. In our case, the \"feature vector\" for candidate phrases represents the effective input parameters, and the \"is-key\" feature represents the dependent output. Table 2 describes the effects of the eight parameters of the feature vector (x1, x2,... x8) on the \"is-key\" output. The experiment proves that the parameter x5 (PRF) is the most effective, while the parameter x8 (IIT) is the least effective, and the parameters x3 (NPL), x7 (SCV) have no effect on the output. Table 3 also shows the cumulative effect of the input parameters on the output. It is clear that the effect on the output increases when the number of cumulated influence parameters increases."}, {"heading": "7.3 Linear Discriminant Analysis (LDA)", "text": "In the machine learning approach, the aim of the classification is to group candidate key sets that have similar characteristic values into two groups: the keys of the first group are classified as \"yes,\" while the others are classified as \"no.\" A linear classifier achieves this by making a classification decision based on the value of the linear combination of the characteristics. If the input note vector to the classifier is a real vector, then the output score is:) (). (xw j jfxwfy \u2211 = = Where, is a real vector of weights and \u043a is a function that converts the point product of the two vectors into the desired output. The weight vector is learned from a series of labeled training samples. All values above a certain threshold are assigned to the first class (keyphrase) and all other values of the second class (non-aceyphrase). The classification is based on the Bayian rule having the highest probability of the object."}, {"heading": "8. Evaluating Results", "text": "In order to evaluate the performance of the proposed system, three experiments were conducted to test the proposed system, using three sets of data for a total of 50 documents; the first experiment was aimed at measuring the level of acceptance of the extracted keyphrases; as there are no author-assigned keyphrases for these documents, a human judge was used to assess this level (Barker & Cornacchia, 2000); the judges in our experiment are university lecturers and doctoral students; in the second and third experiments, keyphrases extracted from the presented system were compared with those extracted from two Arabic keyword extraction systems: KP-Miner (web link http: / / www.claes.sci.eg / coe _ wm / kpminer) and Sakhr Keyword Extractor (web link http: / www.sakhr.com / Technology / Keyword / Default.aspx? sec = Technology & item = KeydS)."}, {"heading": "8.1 Experiment 1", "text": "In the first experiment, a data set of 10 documents containing short messages about the Egyptian Ministry of Information and Communication was used. The average length of the documents is 203 words. Each judge is given a list of twelve key sentences extracted from our system along with the original document. Judges rated each key phrase as accepted (1) or not (0). The evaluation for each key phrase was simply calculated as the sum of the results of all judges. A key phrase was accepted if it received more than 50% of the votes. Subsequently, the process was repeated for all documents in the data set to calculate the overall average of acceptance. Table 4 summarizes the experimental characteristics. Table 5 shows an example of the extracted key sentences for a document in the data set using our proposed extractor and the CP miner extractor. The accepted key sentences of a human judge are underlined and presented boldly. Results show that an average of 44% of the extracted key sentences were accepted by our system by human judges."}, {"heading": "8.2 Experiment 2", "text": "In this experiment, the keyphrases extracted by the presented system were compared with the keyphrases extracted by KP-Miner and Sakhr Extractors. The average document size is 376.1 words per document. Table 6 shows the accuracy and retrieval values for five, seven and ten extracted keyphrases of the three systems. Results show that the presented system performs slightly better than the KP-Miner, and both exceed the Sakhr system in terms of precision and callback. Table 7 shows a sample of the extracted keyphrases of the three systems, with matching author keyphrases underlined and bold."}, {"heading": "8.3 Experiment 3", "text": "In this experiment, a data set of 20 documents with an average of 675.2 words / documents containing non-scientific topics is collected from newspapers and Arabic websites. Table 8 shows the accuracy and retrieval values for five, seven and ten extracted keyphrases of the three systems. Results show that the proposed system exceeds both the KP-Miner and the Sakhr systems in non-scientific and lengthy documents. Accuracy of our system ranges from 1.9 to 1.3 those of KP-Miner and the recall ranges from 2 to 1.3 the corresponding values of KP-Miner. By comparing the results presented in Tables 6 and 8, it becomes clear that the precision of the KP-Miner system decreases from 0.48 to 0.34 (for ten extracted keyphrases) when tested on non-scientific documents, corresponding to an increase from 0.53 to 0.65 for our system. This is due to the existence of more inflated words in non-scientific writings, whose similarities our system can easily be detected from the three words."}, {"heading": "9. Conclusion and Future Work", "text": "In this paper, we have demonstrated how the extraction of keyphrases by statistical measures as well as linguistic knowledge from Arabic documents as input into a machine learning algorithm can be achieved. The main point of this paper is that adding linguistic knowledge to the presentation results in a better result. Experiments conducted in this paper show that the presented system performs significantly better than the existing Arabic extractor systems, where precision and retrieval in long and non-scientific articles reach twice as high values. One reason for this is that the use of more linguistic knowledge enables an efficient use of traditional statistical measures. In our work, for example, the use of the abstract Arabic form of a word improves all frequency-based statistical characteristics by capturing all words and phrase reflections. Second, the features \"Normalized Phrase Rule\" and \"Sentence Contain Verb\" play a major role as they capture key phrases in long documents."}], "references": [{"title": "A Keyphrase-Based Approach to Summarization: the LAKE System at DUC-2005", "author": ["E.D. Avanzo"], "venue": "Proceedings of Human Language Technology. DUC Workshop", "citeRegEx": "Avanzo,? \\Q2005\\E", "shortCiteRegEx": "Avanzo", "year": 2005}, {"title": "Using Noun Phrase Heads to Extract Document Keyphrases", "author": ["K. Barker", "N. Cornacchia"], "venue": "Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies of Intelligence: Advances in Artificial Intelligence", "citeRegEx": "Barker and Cornacchia,? \\Q2000\\E", "shortCiteRegEx": "Barker and Cornacchia", "year": 2000}, {"title": "KP-Miner: A Keyphrase Extraction System for English and Arabic Documents", "author": ["S.R. El-Beltagy", "Rafea A"], "venue": "Information systems, doi: 10.1016/j.is", "citeRegEx": "El.Beltagy and A.,? \\Q2008\\E", "shortCiteRegEx": "El.Beltagy and A.", "year": 2008}, {"title": "Domain-Specific keyphrase extraction", "author": ["E. Frank", "G.W. Paynter", "I.H. Witten", "C. Gutwin", "C.G. Nevill-Manning"], "venue": "In IJCAI,", "citeRegEx": "Frank et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Frank et al\\.", "year": 1999}, {"title": "Automatic keyphrase extraction from scientific documents using N-gram filtration technique", "author": ["N. Kumar", "K. Srinathan"], "venue": "Proceeding of the eighth ACM symposium on Document engineering. Sao Paulo,", "citeRegEx": "Kumar and Srinathan,? \\Q2008\\E", "shortCiteRegEx": "Kumar and Srinathan", "year": 2008}, {"title": "Text Classification: Forming Candidate Key-Phrases from Existing Shorter Ones", "author": ["N. Karanikolas", "C. Skourlas"], "venue": "FACTA UNIVERSITATIS (NI\u02c7S) SER.: ELEC. ENERG. vol. 19,", "citeRegEx": "Karanikolas and Skourlas,? \\Q2006\\E", "shortCiteRegEx": "Karanikolas and Skourlas", "year": 2006}, {"title": "Development of a Stemming Algorithm", "author": ["J.B. Lovins"], "venue": "Mechanical Translation and Computational Linguistics,", "citeRegEx": "Lovins,? \\Q1968\\E", "shortCiteRegEx": "Lovins", "year": 1968}, {"title": "C4.5: Programs for Machine Learning", "author": ["J.R. Quinlan"], "venue": null, "citeRegEx": "Quinlan,? \\Q1993\\E", "shortCiteRegEx": "Quinlan", "year": 1993}, {"title": "Keypharse Extraction from Single Documents in the Open Domain Exploiting Linguistic and Statistical Methods", "author": ["A.T. Schutz"], "venue": "Master Thesis in Applied Science", "citeRegEx": "Schutz,? \\Q2008\\E", "shortCiteRegEx": "Schutz", "year": 2008}, {"title": "Extraction of Keyphrases from Text: Evaluation of Four Algorithm. National Research Council, Institute for Information Technology, Canada", "author": ["P.D. Turney"], "venue": "Technical Report ERB-1051", "citeRegEx": "Turney,? \\Q1997\\E", "shortCiteRegEx": "Turney", "year": 1997}, {"title": "Learning to Extract Keyphrases from Text. National Research Council, Institute for Information Technology, Canada", "author": ["P.D. Turney"], "venue": "Technical Report ERB-1057", "citeRegEx": "Turney,? \\Q1999\\E", "shortCiteRegEx": "Turney", "year": 1999}, {"title": "Learning Algorithms for Keyphrase Extraction", "author": ["P.D. Turney"], "venue": "Information Retrieval,", "citeRegEx": "Turney,? \\Q2000\\E", "shortCiteRegEx": "Turney", "year": 2000}, {"title": "Mining the Web for Lexical Knowledge to Improve Keyphrase Extraction: Learning from labeled and Unlabeled Data", "author": ["P.D. Turney"], "venue": "National Research Council,", "citeRegEx": "Turney,? \\Q2002\\E", "shortCiteRegEx": "Turney", "year": 2002}, {"title": "KEA: Practical Automatic Keyphrase Extraction", "author": ["Witten I", "G. Paynter", "E. Frank", "C. Gutwin", "C. Nevill", "Manning"], "venue": "In Proceedings of ACM DL'99,", "citeRegEx": "I et al\\.,? \\Q1999\\E", "shortCiteRegEx": "I et al\\.", "year": 1999}, {"title": "GIST-IT: Summarizing Email Using Linguistic Knowledge and Machine Learning", "author": ["E. Tzoukarmann", "S. Muresan", "J. Klavans"], "venue": "In Proceedings of the HLT and KM workshop,", "citeRegEx": "Tzoukarmann et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Tzoukarmann et al\\.", "year": 2001}], "referenceMentions": [{"referenceID": 7, "context": "5 decision tree classifier (Quinlan, 1993), and the second is the GenEx (Genitor and Extractor) algorithm (Turney, 1997, 1999, 2000).", "startOffset": 27, "endOffset": 42}, {"referenceID": 6, "context": "phrases using the Lovins stemmer (Lovins, 1968) to learn a C4.", "startOffset": 33, "endOffset": 47}, {"referenceID": 12, "context": "After training, the best parameter values can be hard coded in extractor, and Genitor is no longer needed (Turney, 2002).", "startOffset": 106, "endOffset": 120}, {"referenceID": 3, "context": "Kea (Frank et al., 1999; Witten et al., 1999, 2000) is another remarkable effort in this area, identifies candidate keyphrases in the same manner as Extractor.", "startOffset": 4, "endOffset": 51}], "year": 2009, "abstractText": "In this paper, a supervised learning technique for extracting keyphrases of Arabic documents is presented. The extractor is supplied with linguistic knowledge to enhance its efficiency instead of relying only on statistical information such as term frequency and distance. During analysis, an annotated Arabic corpus is used to extract the required lexical features of the document words. The knowledge also includes syntactic rules based on part of speech tags and allowed word sequences to extract the candidate keyphrases. In this work, the abstract form of Arabic words is used instead of its stem form to represent the candidate terms. The Abstract form hides most of the inflections found in Arabic words. The paper introduces new features of keyphrases based on linguistic knowledge, to capture titles and subtitles of a document. A simple ANOVA test is used to evaluate the validity of selected features. Then, the learning model is built using the LDA Linear Discriminant Analysis \u2013 and training documents. Although, the presented system is trained using documents in the IT domain, experiments carried out show that it has a significantly better performance than the existing Arabic extractor systems, where precision and recall values reach double their corresponding values in the other systems especially for lengthy and non-scientific articles.", "creator": "(Acrobat PDFMaker 6.0 for Word)"}}}