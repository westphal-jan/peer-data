{"id": "1204.1277", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2012", "title": "Mouse Simulation Using Two Coloured Tapes", "abstract": "In this paper, we present a novel approach for Human Computer Interaction (HCI) where, we control cursor movement using a real-time camera. Current methods involve changing mouse parts such as adding more buttons or changing the position of the tracking ball. Instead, our method is to use a camera and computer vision technology, such as image segmentation and gesture recognition, to control mouse tasks (left and right clicking, double-clicking, and scrolling) and we show how it can perform everything as current mouse devices can. The software will be developed in JAVA language. Recognition and pose estimation in this system are user independent and robust as we will be using colour tapes on our finger to perform actions. The software can be used as an intuitive input interface to applications that require multi-dimensional control e.g. computer games etc.", "histories": [["v1", "Thu, 5 Apr 2012 17:00:47 GMT  (426kb)", "http://arxiv.org/abs/1204.1277v1", "5 pages"]], "COMMENTS": "5 pages", "reviews": [], "SUBJECTS": "cs.AI cs.CV", "authors": ["vikram kumar", "kamran niyazi", "swapnil mahe", "swapnil vyawahare"], "accepted": false, "id": "1204.1277"}, "pdf": {"name": "1204.1277.pdf", "metadata": {"source": "CRF", "title": "Mouse Simulation Using Two Coloured Tapes", "authors": ["Kamran Niyazi", "Vikram Kumar", "Swapnil Mahe", "Swapnil Vyawahare"], "emails": ["kamran.niyazi@gmail.com", "vikrambag.kumar@gmail.com", "swapnilmahe@gmail.com", "swapnilvyawahare@gmail.com"], "sections": [{"heading": null, "text": "DOI: 10.5121 / ijist.2012.2206 57In this paper, we present a novel approach to Human Computer Interaction (HCI), in which we control the movement of the cursor with a real-time camera. Current methods include changing parts of the mouse such as adding more buttons or changing the position of the tracking ball. Instead, we use camera and computer image processing technology such as image segmentation and gesture recognition to control mouse tasks (left click, right click, double click and scroll), and we show how it can do everything as current mouse devices can. The software is developed in JAVA language. Detection and pose estimation in this system are user-independent and robust, as we use ribbons on the finger to perform actions. The software can be used as an intuitive input interface for applications that require multi-dimensional control, such as computer games such as SCALKING, or SCALKING."}, {"heading": "1. INTRODUCTION", "text": "One of the most important challenges in interacting with the human computer is the development of more intuitive and natural interfaces. Computer environments nowadays are strongly tied to the availability of a high-resolution pointing device with a single, discrete two-dimensional cursor. Modern graphical user interface (GUI), which is a current standard interface on PCs, is well-defined and provides an efficient user interface to use various applications on a computer. GUIs (graphical user interfaces) in combination with devices such as mice and trackpads are extremely effective in reducing the wealth and variety of human communication to a single point. While the usefulness of such devices in today's interfaces cannot be denied, there are many users who find that the ability of GUI is rather limited when they try to accomplish some tasks through gestures. There are possibilities to apply other types of sensors and techniques to enhance the user experience of such devices."}, {"heading": "2. RELATED WORK", "text": "There is much research in the areas of Human Computer Interaction (HCI) and Robotics. Researchers have tried to control mouse movement using video equipment for HCI. However, all used different methods to control the movement of the mouse cursor and clicking events. An approach by Hojoon Park [1] used index fingers to control the movement of the mouse cursor and the angle between index finger and thumb to click events. Erdem et al. [2] also used finger tracking to control the movement of the mouse. A click of the mouse cursor was implemented by defining a screen so that a click occurred when the user's hand moved across the region. Another approach was developed by Chu-Feng Lien [3]. He used only the fingertips to control and click the mouse cursor. His click method was based on image density and required the user to click the mouse pointer in place of Paul et al for a short period of time [5]."}, {"heading": "3. SYSTEM OVERVIEW", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Hand Recognition and Colour Tape Detection", "text": "The first step of our system is to separate the potential hand pixels from the non-hand pixels, which can be done through a background subtraction scheme in which all possible foreground information is segmented from the unchanging background scene. At system startup, a pair of background images is taken to represent the static workspace from camera view. Subsequent frames then use the appropriate background image to segment moving foreground data. [4] After subtracting the background, the process of skin segmentation occurs. Here, a histogram-based skin classifier assigns either a 3D skin histogram or a non-skin histogram to each of the RGB pixels in the training set. In light of these histograms, the probability that a given RGB color belongs to the skin or non-skin class is calculated. [4] The skin segmentation process gives an image that is ready to recognize ribbons in the finger. An algorithm is then used to select a color based on the specific color needs in a particular phase of the HSV."}, {"heading": "3.2 Mouse Cursor Movement", "text": "We use the pointer finger with yellow ribbon as the cursor controller to control the mouse cursor movement. Two different approaches to the movement of the mouse pointer can be used: The first method is the positioning of the pointer finger on a camera system to a desktop screen position, but there is a problem with this method. If the resolution of the desktop window is greater than the camera resolution, the cursor position cannot be accurate, because intermediate values are lost when converting the camera resolution to the desktop window resolution. The expected ratio of the jumping pixel is up to 4 pixels. The second method is known as weighted speed control, where the difference between the finger of the current image and the previous image is found and the distance between the two is calculated. Next, the mouse pointer moves quickly when the gap between the two finger images (current and previous frame) is wide or, if the gap is narrow, then the cursor moves slowly as the middle of the image is not connected to this algorithm, because some algorithms cannot get the first one flowing faster."}, {"heading": "3.3. Click Events", "text": "The click events for the mouse are illustrated with different hand gestures. The idea focuses on the processing of the distance between the two colored ribbons in the fingers. The click events are shown in detail in the following sub-points."}, {"heading": "3.3.1 Left Click", "text": "In the very first step, the system records the distance (say D) between the yellow and red bands in the index finger and thumb respectively. The index finger and thumb must be as far apart as possible to obtain a maximum distance (Figure: 3). This distance is considered to be the threshold distance for the event. Now that the thumb is moving towards the index finger, the distance between the fingertips or, in other words, the distance between yellow and red bands decreases. In the second step, when the thumb is near the index finger, the system records the reduced distance (say D ') between them (Figure: 4). If the distance between the bands is reduced to D' or less, we consider the event to be the left click event of the mouse cursor."}, {"heading": "3.3.2 Right Click", "text": "The right click event of the cursor is simulated with the concept of waiting time. If the yellow ribbon on the index finger waits 7 seconds (say) in front of the camera pointing to the same location, then the event is recognized as the right click event of the mouse pointer. Here, the distance between the red and yellow ribbons should be between D or D. The required hand gesture is shown in Figure: 3.Thus, for right click EventD '< d \u2264 waiting time = 7 sec."}, {"heading": "3.3.3 Double Click", "text": "The double click event of the cursor is also simulated in the same way as the right click event taking into account the waiting time. The only difference is that the finger gesture used for the double click is as in Figure: 4. If both ribbons wait for the time 7 seconds (say) and the distance between the ribbons D '(reduced distance) or smaller, then the event is recognized as the double click event of the mouse pointer."}, {"heading": "4. DISCUSSIONS", "text": "In this system, we have proposed to use ribbons on the fingers, and all other functions can be performed taking into account the relative distance of the ribbons and the waiting time. This method has a greater efficiency than any other methods previously used in this regard, where bare fingertips are used. Algorithms for detecting the fingertips are not very effective, since the color of the fingertip cannot be distinguished from the color of the hand. This requires the use of complex algorithms. In order to avoid such complex algorithms and to make our system fast enough for real-time calculations, we have proposed to use ribbons on the fingertips, which completely distinguish the fingertip from the rest of the hand. This distinction makes the algorithm for color recognition [3] fairly simple and maps them for cursor movements. This reduces the complexity of the calculation and improves the overall results."}, {"heading": "5. APPLICATIONS", "text": "This technology can be used in robotics, gaming, and the development of systems that could understand human behavior by the way they interact."}, {"heading": "6. CONCLUSIONS", "text": "At present, webcam, microphone and mouse are an integral part of the computer system. Our webcam-only product would completely eliminate the mouse and this would also lead to a new era of human computer interaction (HCI), where no physical contact with the device is required."}, {"heading": "ACKNOWLEDGEMENTS", "text": "We would like to thank Prof. N. R. Talhar, our guide, who helped us to develop this concept. We would also like to thank Prof. S. V. Athawale, who helped us to create the research work. We would also like to thank the researchers who work in this field and who have supported us in one way or another in achieving our goals. We would also like to express our appreciation and gratitude to all the other researchers at A.I.S.M.S College of Engineering in Pune who have been kind enough to share their views and make suggestions to improve this idea."}], "references": [{"title": "A Method for Controlling Mouse Movement using a Real-Time Camera,2008", "author": ["Hojoon Park"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Computer vision based mouse, A", "author": ["A. Erdem", "E. Yardimci", "Y. Atalay", "V. Cetin"], "venue": "E. Acoustics, Speech, and Signal Processing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "Real-time Hand Tracking and Finger Tracking for Interaction", "author": ["Shahzad Malik"], "venue": "CSC2503F Project Report, December", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Virtual mouse vision based interface", "author": ["P. Robertson", "R. Laddaga", "M. Van Kleek"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Fast tracking of hands and fingertips in infrared images for augmented desk interface", "author": ["Y. Sato", "Y. Kobayashi", "H. Koike"], "venue": "In Proceedings of IEEE, International Conference on Automatic Face and Gesture Recognition (FG),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Shadow gestures: 3D hand pose estimation using a single camera", "author": ["J. Segen", "S. Kumar"], "venue": "In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}], "referenceMentions": [{"referenceID": 0, "context": "One approach, by Hojoon Park [1] used index finger for cursor movement and angle between index finger and thumb for clicking events.", "startOffset": 29, "endOffset": 32}, {"referenceID": 1, "context": "Also, Erdem et al [2], used finger tip tracking to control the motion of the mouse.", "startOffset": 18, "endOffset": 21}, {"referenceID": 3, "context": "Paul et al [5], used another method to click.", "startOffset": 11, "endOffset": 14}, {"referenceID": 2, "context": "S Malik [4] developed a real-time system that can track the 3D position and 2D orientation of the thumb and index finger of each hand without the use of special markers or gloves.", "startOffset": 8, "endOffset": 11}, {"referenceID": 2, "context": "[4] After background subtraction, the process of skin segmentation is done.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4] The skin segmentation process outputs an image which is ready for detection of color tapes in the finger.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1]", "startOffset": 0, "endOffset": 3}], "year": 2012, "abstractText": "In this paper, we present a novel approach for Human Computer Interaction (HCI) where, we control cursor movement using a real-time camera. Current methods involve changing mouse parts such as adding more buttons or changing the position of the tracking ball. Instead, our method is to use a camera and computer vision technology, such as image segmentation and gesture recognition, to control mouse tasks (left and right clicking, double-clicking, and scrolling) and we show how it can perform everything as current mouse devices can. The software will be developed in JAVA language. Recognition and pose estimation in this system are user independent and robust as we will be using colour tapes on our finger to perform actions. The software can be used as an intuitive input interface to applications that require multi-dimensional control e.g. computer games etc.", "creator": "PScript5.dll Version 5.2.2"}}}