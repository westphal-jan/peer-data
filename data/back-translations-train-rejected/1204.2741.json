{"id": "1204.2741", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2012", "title": "Simultaneous Object Detection, Tracking, and Event Recognition", "abstract": "The common internal structure and algorithmic organization of object detection, detection-based tracking, and event recognition facilitates a general approach to integrating these three components. This supports multidirectional information flow between these components allowing object detection to influence tracking and event recognition and event recognition to influence tracking and object detection. The performance of the combination can exceed the performance of the components in isolation. This can be done with linear asymptotic complexity.", "histories": [["v1", "Thu, 12 Apr 2012 14:47:41 GMT  (2906kb,D)", "http://arxiv.org/abs/1204.2741v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["andrei barbu", "aaron michaux", "siddharth narayanaswamy", "jeffrey mark siskind"], "accepted": false, "id": "1204.2741"}, "pdf": {"name": "1204.2741.pdf", "metadata": {"source": "CRF", "title": "Simultaneous Object Detection, Tracking, and Event Recognition", "authors": ["Andrei Barbu", "Aaron Michaux", "Siddharth Narayanaswamy", "Jeffrey Mark Siskind"], "emails": [], "sections": [{"heading": null, "text": "The common internal structure and algorithmic organization of object detection, detection-based tracking, and event detection facilitates a general approach to integrating these three components. This supports multi-directional information flow between these components, allowing object detection to affect tracking and event detection, and event detection to affect tracking and object detection. Combined performance can exceed component performance in isolation, with linear asymptotic complexity."}, {"heading": "1 Introduction", "text": "In fact, it is as if most of us are able to recognize ourselves and understand what they are doing and that they are not doing it. (...) It is not as if they were doing it. (...) It is as if they were doing it. (...) It is as if they were doing it. (...) It is as if they were doing it. (...) It is as if they were doing it. (...) It is as if they were doing it. (...) It is as if they were doing it. (...) It is as if they were doing it. (...) It is as if they were doing it. (...) It is as if they wanted it. (...) It is as if they want it. (...) It is as if they want it. (...) It is as if they want it. (...) It is as if they want it. (...) It is as if they want it. (...) It is as if they want it. (...) It is as if they want it. (...) It is as if they want it."}, {"heading": "2 Detection-based tracking", "text": "The methods described in sections 4, 5, and 6 cover a popular dynamic programming approach to detection-based tracking. We review this approach here to illustrate the concepts, terminology, and notation needed to describe the extensions. Detection-based tracking is a general framework in which an object detector is applied to each frame of a video to obtain a series of detections that are composed of tracks by selecting a single candidate from each frame that maximizes the temporal coherence of the track. This general framework can be instantiated with answers to the following questions: 1. What is the representation of a detector? 2. What is the detection source? 3. What is the measurement of temporal coherence? 4. What is the method for searching for the track with the max-immal temporal coherence? We answer questions 1 and 2 by performing a detection in order to capture a rectangle."}, {"heading": "3 Evaluation of detection-based tracking", "text": "We evaluated the detection-base tracking using the year-one (Y1) corpus produced by DARPA to identify and track these four sources. We rated the detection-base tracking using the year-one (Y1) corpus produced by DARPA for the Mind's Eye team as the only person who preferred one person at a time. [These videos are provided at 720p @ 30fps and range from 42 to 1727 frames in length, with an average of 438.84 frames, and depict people interacting with a variety of objects to realize common English promises. Four Mind's Eye teams (University at Buffalo, Corso 2011, Stanford Research Institute, Bui 2011, University of California at Berkeley, Saenko 2011, and University of Southern California, Navatia Southern California) independently produced human-annotated tracks for different portions of Y1, we evaluated the human-based tracing power we used by tracing each other through these human sources."}, {"heading": "4 Combining object detection and tracking", "text": "While detection-based tracking is resistant to low precision, it requires a perfect recall; it cannot generate a track through a frame that has no detectors and cannot generate a track through a portion of the field of view that has no detection, regardless of how good the temporal coherence of the resulting track would be. This brittleness means that any detection source that is used must significantly exceed the number of detections per frame to achieve a near-perfect recall. This has a downside. while the Viterbi algorithm has linear complexity in the number of frames, it is square in the number of detections per frame, drastically limiting the number of detections that can reasonably be processed, leading to the need to tune the thresholds at the detection sources. We have developed a novel mechanism to eliminate the need for a threshold and to track any possible detection at any position and scale in the image."}, {"heading": "5 Combining tracking and event detection", "text": "It is popular to use Hidden Markov models (HMMs) to perform event detection (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005). If we do this, the log probability of a video model is limited to an event model: logbook k1,..., kTexp T = 1 h (kt, b), which denotes the log probability of an event for the HMM for frame t (k, b), the log probability of generating an event b = 1 h (kt, b), which is in state k (k, k), denotes the log probability of transitioning from state k to k, and j (t) denotesindex of detection in frame t. This logbook can be calculated using the forward algorithms (Tree and Petrie, 1966) produced analogously to the vitality of detection index."}, {"heading": "6 Combining object detection, tracking and event detection", "text": "One can combine the methods of sections 4 and 5 to optimize a cost function: Max x1,..., xT y1,..., yT s1,..., kTT \u2211 t = 1 f (btxtytst) + h (kt, b t xtytst) + T \u2211 t = 2 g (bt \u2212 1yt \u2212 1st \u2212 1, b xtytst) + a (kt, kt \u2212 1), Eq. 6 with Eq. 8 by forming a large Viterbi grid with values that arise in practice when the above method is applied. In Eq. 12, h a function of btxtytst is the detection in the current context. This allows the HMM event model to depend on the position, shape and position."}, {"heading": "7 Experimental results", "text": "Figure 3 shows improved performance of simultaneous object detection and tracking (c) over object detection (a) and tracking (b) in isolation for a number of reasons: motion blur even on large objects can lead to poor detection results and thus to bad traces, small objects are difficult to detect and track, and integration can improve detection and tracking of deformable objects, e.g. a person who switches from an upright pose to sitting. Figure 4 shows improved performance of simultaneous tracking and event detection (c) over tracking (b) in isolation. These results have been obtained with object and event models that have been independently trained. Object and event models seem to be possible by combining Tree-Welch (Baum, 1972; Baum et al., 1970) with the training method for object models (Felzenswalb et al., 2010a)."}, {"heading": "8 Conclusion", "text": "Recognition base tracking using dynamic programming has a long history (Castanon, 1990; Wolf et al., 1989), as well as motion profile-based approaches to detecting events using HMMs (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005), as well as attempts to integrate object detection and tracking (Li and Nevatia, 2008; Pirsiavash et al., 2011), tracking and event detection (Li and Chellappa, 2002), and object detection and event detection (Gupta and Davis, 2007; Moore et al., 1999; Peursum et al., 2005). However, we are unaware of previous work integrating all three and doing so in a way that efficiently finds a global optimum to a simple uniform cost function. We have used a general framework for detecting contemporal object detection, thereby allowing many of its internal detection and tracing functions to be dismantled."}, {"heading": "Acknowledgments", "text": "This work has been supported in part by the NSF Grant CCF0438806, the Naval Research Laboratory under contract number N00173-10-1-G023, the Army Research Laboratory under cooperation agreement number W911NF-10-2-0060, and computing resources provided by Information Technology at Purdue through the Rosen Center for Advanced Computing. Any views, opinions, findings, conclusions or recommendations contained or expressed in this document or material are those of the author (s) and do not necessarily reflect the views or official guidelines of the NSF, the Naval Research Laboratory, the Office of Naval Research, the Army Research Laboratory or the U.S. Government."}], "references": [{"title": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process", "author": ["L.E. Baum"], "venue": null, "citeRegEx": "Baum.,? \\Q1972\\E", "shortCiteRegEx": "Baum.", "year": 1972}, {"title": "Statistical inference for probabilistic functions of finite state Markov chains", "author": ["L.E. Baum", "T. Petrie"], "venue": "Ann. Math. Stat,", "citeRegEx": "Baum and Petrie.,? \\Q1966\\E", "shortCiteRegEx": "Baum and Petrie.", "year": 1966}, {"title": "A maximization technique occuring in the statistical analysis of probabilistic functions of Markov chains", "author": ["L.E. Baum", "T. Petrie", "G. Soules", "N. Weiss"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Baum et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Baum et al\\.", "year": 1970}, {"title": "Efficient algorithms for finding the K best paths through a trellis", "author": ["D.A. Castanon"], "venue": "IEEE Transactions on Aerospace and Electronic Systems,", "citeRegEx": "Castanon.,? \\Q1990\\E", "shortCiteRegEx": "Castanon.", "year": 1990}, {"title": "Kernel-based object tracking", "author": ["D. Comaniciu", "V. Ramesh", "P. Meer"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Comaniciu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Comaniciu et al\\.", "year": 2003}, {"title": "URL http://www.cse.buffalo. edu/ \u0303jcorso/bigshare/mindseye_human_ annotation_may11_buffalo.tar.bz", "author": ["J. Corso"], "venue": null, "citeRegEx": "Corso,? \\Q2011\\E", "shortCiteRegEx": "Corso", "year": 2011}, {"title": "The PASCAL Visual Object Classes (VOC) challenge", "author": ["M. Everingham", "L. Van Gool", "C.K.I. Williams", "J. Winn", "A. Zisserman"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Everingham et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Everingham et al\\.", "year": 2010}, {"title": "Distance transforms of sampled functions", "author": ["P.F. Felzenszwalb", "D.P. Huttenlocher"], "venue": "Technical Report TR2004-1963, Cornell Computing and Information Science,", "citeRegEx": "Felzenszwalb and Huttenlocher.,? \\Q2004\\E", "shortCiteRegEx": "Felzenszwalb and Huttenlocher.", "year": 2004}, {"title": "Cascade object detection with deformable part models", "author": ["P.F. Felzenszwalb", "R.B. Girshick", "D. McAllester"], "venue": "In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2010}, {"title": "Object detection with discriminatively trained part based models", "author": ["P.F. Felzenszwalb", "R.B. Girshick", "D. McAllester", "D. Ramanan"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2010}, {"title": "Fast algorithms for large-state-space HMMs with applications to web usage analysis", "author": ["Pedro F. Felzenszwalb", "Daniel P. Huttenlocher", "Jon M. Kleinberg"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2003}, {"title": "Orientation histograms for hand gesture recognition", "author": ["W.T. Freeman", "M. Roth"], "venue": "In International Workshop on Automatic Face and Gesture Recognition,", "citeRegEx": "Freeman and Roth.,? \\Q1995\\E", "shortCiteRegEx": "Freeman and Roth.", "year": 1995}, {"title": "Objects in action: an approach for combining action understanding and object perception", "author": ["A. Gupta", "L.S. Davis"], "venue": "In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Gupta and Davis.,? \\Q2007\\E", "shortCiteRegEx": "Gupta and Davis.", "year": 2007}, {"title": "A generic approach to simultaneous tracking and verification in video", "author": ["Baoxin Li", "Rama Chellappa"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "Li and Chellappa.,? \\Q2002\\E", "shortCiteRegEx": "Li and Chellappa.", "year": 2002}, {"title": "Key object driven multi-category object recognition, localization, and tracking using spatiotemporal context", "author": ["Yuan Li", "Ramakant Nevatia"], "venue": "In Proceedings of the European Conference on Computer Vision,", "citeRegEx": "Li and Nevatia.,? \\Q2008\\E", "shortCiteRegEx": "Li and Nevatia.", "year": 2008}, {"title": "Exploting human actions and object context for recognition tasks", "author": ["D.J. Moore", "I.A. Essa", "M.H. Heyes"], "venue": "In Proceedings of the 7th International Conference on Computer Vision,", "citeRegEx": "Moore et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Moore et al\\.", "year": 1999}, {"title": "A threshold selection method from gray-level histograms", "author": ["N. Otsu"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "Otsu.,? \\Q1979\\E", "shortCiteRegEx": "Otsu.", "year": 1979}, {"title": "Combining image regions and human activity for indirect object recognition in indoor wide-angle views", "author": ["P. Peursum", "G. West", "S. Venkatesh"], "venue": "In Proceedings of the 10th International Conference on Computer Vision,", "citeRegEx": "Peursum et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Peursum et al\\.", "year": 2005}, {"title": "Globally-optimal greedy algorithms for tracking a variable number of objects", "author": ["H. Pirsiavash", "D. Ramanan", "C.C. Fowlkes"], "venue": "In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Pirsiavash et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pirsiavash et al\\.", "year": 2011}, {"title": "URL https://s3.amazonaws.com/ Annotations/vaticlabels_C-D1_0819.tar.gz", "author": ["K. Saenko"], "venue": null, "citeRegEx": "Saenko,? \\Q2011\\E", "shortCiteRegEx": "Saenko", "year": 2011}, {"title": "Spatiotemporal contour grouping using abstract part models", "author": ["Pablo Sala", "Diego Macrini", "Sven J. Dickinson"], "venue": "In Proceedings of the 10th Asian Conference on Computer Vision,", "citeRegEx": "Sala et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sala et al\\.", "year": 2010}, {"title": "Good features to track", "author": ["J. Shi", "C. Tomasi"], "venue": "In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Shi and Tomasi.,? \\Q1994\\E", "shortCiteRegEx": "Shi and Tomasi.", "year": 1994}, {"title": "A maximum-likelihood approach to visual event classification", "author": ["J.M. Siskind", "Q. Morris"], "venue": "In Proceedings of the Fourth European Conference on Computer Vision,", "citeRegEx": "Siskind and Morris.,? \\Q1996\\E", "shortCiteRegEx": "Siskind and Morris.", "year": 1996}, {"title": "Real-time American sign language recognition using desk and wearable computer based video", "author": ["Thad Starner", "Joshua Weaver", "Alex Pentland"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Starner et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Starner et al\\.", "year": 1998}, {"title": "Detection and tracking of point features", "author": ["C. Tomasi", "T. Kanade"], "venue": "Technical Report CMU-CS-91-132,", "citeRegEx": "Tomasi and Kanade.,? \\Q1991\\E", "shortCiteRegEx": "Tomasi and Kanade.", "year": 1991}, {"title": "Convolutional codes and their performance in communication systems", "author": ["A.J. Viterbi"], "venue": "IEEE Transactions on Communication,", "citeRegEx": "Viterbi.,? \\Q1971\\E", "shortCiteRegEx": "Viterbi.", "year": 1971}, {"title": "Event recognition with time varying hidden Markov model", "author": ["Zhaowen Wang", "Ercan E. Kuruoglu", "Xiaokang Yang", "Yi Xu", "Songyu Yu"], "venue": "In Proceedings of the International Conference on Accoustic and Speech Signal Processing,", "citeRegEx": "Wang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2009}, {"title": "Finding the best set of K paths through a trellis with application to multitarget tracking", "author": ["J.K. Wolf", "A.M. Viterbi", "G.S. Dixon"], "venue": "IEEE Transactions on Aerospace and Electronic Systems,", "citeRegEx": "Wolf et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Wolf et al\\.", "year": 1989}, {"title": "Motion based event recognition using HMM", "author": ["Gu Xu", "Yu-Fei Ma", "HongJiang Zhang", "Shiqiang Yang"], "venue": "In Proceedings of the International Conference on Pattern Recognition,", "citeRegEx": "Xu et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2002}, {"title": "An HMM-based framework for video semantic analysis", "author": ["Gu Xu", "Yu-Fei Ma", "HongJiang Zhang", "Shi-Qiang Yang"], "venue": "IEEE Trans. Circuits Syst. Video Techn.,", "citeRegEx": "Xu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2005}, {"title": "Object tracking: A survey", "author": ["A. Yilmaz", "O. Javed", "M. Shah"], "venue": "ACM Computing Surveys,", "citeRegEx": "Yilmaz et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Yilmaz et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 22, "context": "Many common approaches to event recognition (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005) classify events based on their motion profile.", "startOffset": 44, "endOffset": 134}, {"referenceID": 23, "context": "Many common approaches to event recognition (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005) classify events based on their motion profile.", "startOffset": 44, "endOffset": 134}, {"referenceID": 26, "context": "Many common approaches to event recognition (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005) classify events based on their motion profile.", "startOffset": 44, "endOffset": 134}, {"referenceID": 30, "context": "Adaptive approaches to tracking (Yilmaz et al., 2006), e.", "startOffset": 32, "endOffset": 53}, {"referenceID": 4, "context": "Kalman filtering (Comaniciu et al., 2003), suffer from three difficulties that impact their utility for event recognition.", "startOffset": 17, "endOffset": 41}, {"referenceID": 6, "context": "On the PASCAL VOC Challenge, they typically achieve average precision scores of 40% to 50% (Everingham et al., 2010).", "startOffset": 91, "endOffset": 116}, {"referenceID": 27, "context": ", 2010a,b), detection-based trackers (Wolf et al., 1989), and HMM-based approaches to event recognition (Baum and Petrie, 1966) facilitates a general approach to integrating these three components.", "startOffset": 37, "endOffset": 56}, {"referenceID": 1, "context": ", 1989), and HMM-based approaches to event recognition (Baum and Petrie, 1966) facilitates a general approach to integrating these three components.", "startOffset": 55, "endOffset": 78}, {"referenceID": 21, "context": "The forward projection internal to g can be done in a variety of ways including optical flow and the Kanade-LucasTomasi (KLT) (Shi and Tomasi, 1994; Tomasi and Kanade, 1991) feature tracker.", "startOffset": 126, "endOffset": 173}, {"referenceID": 24, "context": "The forward projection internal to g can be done in a variety of ways including optical flow and the Kanade-LucasTomasi (KLT) (Shi and Tomasi, 1994; Tomasi and Kanade, 1991) feature tracker.", "startOffset": 126, "endOffset": 173}, {"referenceID": 25, "context": "1 can be optimized in polynomial time with the Viterbi algorithm (Viterbi, 1971):", "startOffset": 65, "endOffset": 80}, {"referenceID": 7, "context": "We take g to be the negative Euclidean distance between the center of btjt and the center of bt\u22121 jt\u22121 projected forward one frame, though, as discussed below, our approach is compatible with a variety of functions discussed by Felzenszwalb and Huttenlocher (2004). The forward projection internal to g can be done in a variety of ways including optical flow and the Kanade-LucasTomasi (KLT) (Shi and Tomasi, 1994; Tomasi and Kanade, 1991) feature tracker.", "startOffset": 228, "endOffset": 265}, {"referenceID": 20, "context": "One can ameliorate this somewhat by constructing a lattice that skips frames (Sala et al., 2010).", "startOffset": 77, "endOffset": 96}, {"referenceID": 6, "context": "and recall and thus it is necessary to explore the trade-off between the two (Everingham et al., 2010).", "startOffset": 77, "endOffset": 102}, {"referenceID": 16, "context": "One can derive an offset by computing a histogram of scores of the top detection in each frame of a video and taking the offset to be the minimum of the value that maximizes the between-class variance (Otsu, 1979) when bipartitioning this histogram and the trained acceptance threshold offset by a small but fixed amount.", "startOffset": 201, "endOffset": 213}, {"referenceID": 6, "context": "A permutation mapping was preferred when it had higher average overlap score among corresponding boxes across the tracks and the frames in a video, where the overlap score was that used by the PASCAL VOC Challenge (Everingham et al., 2010), namely the ratio of the area of their intersection to the area of their union.", "startOffset": 214, "endOffset": 239}, {"referenceID": 11, "context": "detectors learn a forest of HOG (Freeman and Roth, 1995) filters for each object class along with their characteristic displacements.", "startOffset": 32, "endOffset": 56}, {"referenceID": 7, "context": "It is made tractable by the use of a generalized distance transform (Felzenszwalb and Huttenlocher, 2004) that allows it to scale linearly with the number of image pyramid positions.", "startOffset": 68, "endOffset": 105}, {"referenceID": 22, "context": "It is popular to use Hidden Markov Models (HMMs) to perform event recognition (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005).", "startOffset": 78, "endOffset": 168}, {"referenceID": 23, "context": "It is popular to use Hidden Markov Models (HMMs) to perform event recognition (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005).", "startOffset": 78, "endOffset": 168}, {"referenceID": 26, "context": "It is popular to use Hidden Markov Models (HMMs) to perform event recognition (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005).", "startOffset": 78, "endOffset": 168}, {"referenceID": 1, "context": "This log likelihood can be computed with the forward algorithm (Baum and Petrie, 1966) which is analogous to the Viterbi algorithm.", "startOffset": 63, "endOffset": 86}, {"referenceID": 10, "context": "One can make this linear inK for suitable state-transition functions a (Felzenszwalb et al., 2003).", "startOffset": 71, "endOffset": 98}, {"referenceID": 22, "context": "However, many approaches to event recognition using HMMs use temporal derivatives of such characteristics to provide object velocity and acceleration information (Siskind and Morris, 1996; Starner et al., 1998).", "startOffset": 162, "endOffset": 210}, {"referenceID": 23, "context": "However, many approaches to event recognition using HMMs use temporal derivatives of such characteristics to provide object velocity and acceleration information (Siskind and Morris, 1996; Starner et al., 1998).", "startOffset": 162, "endOffset": 210}, {"referenceID": 0, "context": "It would appear possible to co-train object and event models by combining Baum-Welch (Baum, 1972; Baum et al., 1970) with the training procedure for object models (Felzenszwalb et al.", "startOffset": 85, "endOffset": 116}, {"referenceID": 2, "context": "It would appear possible to co-train object and event models by combining Baum-Welch (Baum, 1972; Baum et al., 1970) with the training procedure for object models (Felzenszwalb et al.", "startOffset": 85, "endOffset": 116}, {"referenceID": 3, "context": "Detection-base tracking using dynamic programming has a long history (Castanon, 1990; Wolf et al., 1989), as do motion-profile-based approaches to event recognition using HMMs (Siskind and Morris, 1996; Starner et al.", "startOffset": 69, "endOffset": 104}, {"referenceID": 27, "context": "Detection-base tracking using dynamic programming has a long history (Castanon, 1990; Wolf et al., 1989), as do motion-profile-based approaches to event recognition using HMMs (Siskind and Morris, 1996; Starner et al.", "startOffset": 69, "endOffset": 104}, {"referenceID": 22, "context": ", 1989), as do motion-profile-based approaches to event recognition using HMMs (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005).", "startOffset": 79, "endOffset": 169}, {"referenceID": 23, "context": ", 1989), as do motion-profile-based approaches to event recognition using HMMs (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005).", "startOffset": 79, "endOffset": 169}, {"referenceID": 26, "context": ", 1989), as do motion-profile-based approaches to event recognition using HMMs (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005).", "startOffset": 79, "endOffset": 169}, {"referenceID": 14, "context": "Moreover, there have been attempts to integrate object detection and tracking (Li and Nevatia, 2008; Pirsiavash et al., 2011), tracking and event recognition (Li and Chellappa, 2002), and object detection and event recognition (Gupta and Davis, 2007; Moore et al.", "startOffset": 78, "endOffset": 125}, {"referenceID": 18, "context": "Moreover, there have been attempts to integrate object detection and tracking (Li and Nevatia, 2008; Pirsiavash et al., 2011), tracking and event recognition (Li and Chellappa, 2002), and object detection and event recognition (Gupta and Davis, 2007; Moore et al.", "startOffset": 78, "endOffset": 125}, {"referenceID": 13, "context": ", 2011), tracking and event recognition (Li and Chellappa, 2002), and object detection and event recognition (Gupta and Davis, 2007; Moore et al.", "startOffset": 40, "endOffset": 64}, {"referenceID": 12, "context": ", 2011), tracking and event recognition (Li and Chellappa, 2002), and object detection and event recognition (Gupta and Davis, 2007; Moore et al., 1999; Peursum et al., 2005).", "startOffset": 109, "endOffset": 174}, {"referenceID": 15, "context": ", 2011), tracking and event recognition (Li and Chellappa, 2002), and object detection and event recognition (Gupta and Davis, 2007; Moore et al., 1999; Peursum et al., 2005).", "startOffset": 109, "endOffset": 174}, {"referenceID": 17, "context": ", 2011), tracking and event recognition (Li and Chellappa, 2002), and object detection and event recognition (Gupta and Davis, 2007; Moore et al., 1999; Peursum et al., 2005).", "startOffset": 109, "endOffset": 174}], "year": 2012, "abstractText": "The common internal structure and algorithmic organization of object detection, detection-based tracking, and event recognition facilitates a general approach to integrating these three components. This supports multidirectional information flow between these components allowing object detection to influence tracking and event recognition and event recognition to influence tracking and object detection. The performance of the combination can exceed the performance of the components in isolation. This can be done with linear asymptotic complexity.", "creator": "LaTeX with hyperref package"}}}