{"id": "1204.3514", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Apr-2012", "title": "Distributed Learning, Communication Complexity and Privacy", "abstract": "We consider the problem of PAC-learning from distributed data and analyze fundamental communication complexity questions involved. In addition to providing general upper and lower bounds on the amount of communication needed for learning, we also present tight results for a number of common concept classes including conjunctions, parity functions, and decision lists. For linear separators, we show that for non-concentrated distributions, we can use a version of the Perceptron algorithm to learn with much less communication than the number of updates given by the usual margin bound. Our general results show that in addition to VC-dimension and covering number, quantities such as the teaching-dimension and mistake-bound of a class play an important role in determining communication requirements. We also show that boosting can be performed in a generic manner in the distributed setting to achieve communication with only logarithmic dependence on 1/epsilon for any concept class. We additionally present an analysis of privacy, considering both differential privacy and a notion of distributional privacy that is especially appealing in this context.", "histories": [["v1", "Mon, 16 Apr 2012 15:10:32 GMT  (24kb)", "https://arxiv.org/abs/1204.3514v1", "18 pages"], ["v2", "Tue, 17 Apr 2012 21:42:21 GMT  (24kb)", "http://arxiv.org/abs/1204.3514v2", "18 pages"], ["v3", "Fri, 25 May 2012 15:53:51 GMT  (25kb)", "http://arxiv.org/abs/1204.3514v3", "19 pages"]], "COMMENTS": "18 pages", "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["maria-florina balcan", "avrim blum", "shai fine", "yishay mansour"], "accepted": false, "id": "1204.3514"}, "pdf": {"name": "1204.3514.pdf", "metadata": {"source": "CRF", "title": "Distributed Learning, Communication Complexity and Privacy", "authors": ["Maria-Florina Balcan", "Avrim Blum", "Shai Fine", "Yishay Mansour"], "emails": ["ninamf@cc.gatech.edu.", "avrim@cs.cmu.edu.", "shai@il.ibm.com.", "mansour@tau.ac.il."], "sections": [{"heading": null, "text": "ar Xiv: 120 4.35 14v3 [cs.LG] 2 5M ay2 01"}, {"heading": "1 Introduction", "text": "Suppose you have two databases: one with the positive examples and another with the negative examples. How much communication between them is required to learn a good hypothesis? In this paper we look at this question and its generalizations, as well as related topics such as privacy. Generally, we consider a framework in which information is distributed between multiple sites, and our goal is to learn a hypothesis with little error in terms of the general distribution of data that uses as little communication as possible, and as few rounds of communication as possible. Motivating examples include: 1. Suppose research groups around the world have collected large scientific datasets, such as genomic sequence data or celestial data, and we want to perform learning about the unification of all these different datasets without too much communication."}, {"heading": "1.1 Our Contributions", "text": "We consider and analyze basic communication issues in PAC learning from distributed data by setting general upper and lower limits on the amount of communication that is necessary to learn a particular class, as well as generally applicable techniques to achieve communication-efficient learning. We also analyze a number of important specific classes that provide efficient learning algorithms with particularly good communication performance, and in some cases counterintuitive distinctions between correct and incorrect learning. Our general upper and lower limits show that in addition to the VC dimension and the coverage of numbers, quantities such as the privacy dimension and the margin of error of a class play an important role in determining communication requirements. We also show how the increase in communication can be performed in a communication-efficient manner, with communication based only logarithmically on 1 / 2 for each class, along with compromises between total communication and number of communication rounds. Furthermore, we show that if we ignore calculations of logal error, agnostic learning can be performed in a manner."}, {"heading": "1.2 Related Work", "text": "Bshouty [1997] shows that many simple classes that PAC can be learned cannot be learned efficiently in parallel with a polynomial number of processors. Long and Servedio [2011] also show a parallel algorithm for large margin classifiers that run in parallel in time O (1 / \u03b3), compared to more naive implementations where the cost of each stage is higher than the margin. They also show an impossibility result in terms of the increase, namely that the ability to call the weak learning oracle several times in parallel within a single boost stage does not reduce the total number of successive stages of increase that are required. Collins et al. [2002] give an online algorithm that uses a parallel updated method for logistic loss, and Zinkevich et al al al al al al al al al al al al al, give a detailed analysis of the parallel stochastic gradients in which each machine processes a random subset of the total data."}, {"heading": "2 Model and Objectives", "text": "This year, it will be ready to leave the country in which it is located."}, {"heading": "3 Baseline approaches and lower bounds", "text": "The simplest procedure is that each database contains a random number of examples in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the number of acquired points in relation to the acquired points in relation to the acquired acquired points in relation to the acquired acquired points in relation to the acquired points in relation to the acquired points"}, {"heading": "4 Intersection-closed classes and version-space algorithms", "text": "A simple case in which one can perform much better than the basic methods is that of the intersectional (or union-closed) classes H, in which the functions in H itself can be described compactly. For example, the class of conjunctions and the class of intervals on the real line are closed both intersections. For such classes we have the following: Theorem 3. If H has intersections, then H can be learned by means of a round and k hypotheses of total communication. Proof. Each entity i draws a sample of size O (1B (1B (1 B) + protocol (k / B)))) and calculates the smallest hypothesis that coincides with its sample, and sends hi to the center. The center then calculates the smallest hypothesis h so that h'hi is for all i. Probably at least 1 \u2212 \u043c h has at most errors on each di and therefore errors at most on dimension."}, {"heading": "5 Reliable-useful learning, parity, and lower bounds", "text": "A classical, subordinate system of communication complexity states that two entities each have a series of linear qualities over n variables, then it is necessary to find a practicable solution based on yes \"yes\" and \"prasanna.\" This, in turn, implies that proper learning of parity functions, parity functions, which can only be learned in the case of k \"n\" bits of communication, is necessary. Furthermore, the algorithm is efficient indeed a special case of the query algorithms. Interestingly, the requirement that learning must be correct can be proved to be parity. (n) Bits only the bits of communication. (n) Bits the algorithms are efficiently able to learn the following classes, which are in the reliable learning situation. (n) It is the requirement that learning must be correct. (n) Parity functions can be learned by learning only O (n) bits."}, {"heading": "6 Decision Lists", "text": "ieD eSrdtee\u00fcgn nvo edn eSrdteeu in red eSrdtee\u00fcn, n sdsa the rf\u00fc ide eSrte\u00fcgcnlhsrtee\u00fccnh hsci hsci nvo edn, \"tlrteeaS os.\" S \"ieD eSrdteeu\" n, \"tasg os os os os,\" tS os os os. \"S"}, {"heading": "7 Linear Separators", "text": "We will now consider the case of learning homogeneous linear separators in Rd. For the sake of convenience, however, for data with Margin \u03b3, all transmitted vectors can be specified with O (d log 1 / \u03b3) bits. A simple case is when D is a radially symmetrical distribution, such as the symmetrical Gaussian distribution centered at the origin or the even distribution on the sphere.In this case, it is known that Ex \u0445 D [(x) x / | | |] is a vector exactly in the direction of the target vector, where (x) is the label of x. Moreover, an average over O (d / 2) samples is sufficient to generate an estimate of the error in most cases with high probability when considering binary distributions [Servedio, 2002]. As long as each player draws a sufficiently large general sample, we can simply draw an entire error over the entire communication base, with only one Si drawing the result."}, {"heading": "7.1 Learning large-margin separators when data is well-spread", "text": "We say that the data is alpha-well distributed if we have updates for all data points xi and xj | xi \u00b7 xj | | xi | | | xj | < \u03b1. Below it is shown that if the data is actually alpha-well distributed for a small value of \u03b1, the Perceptron algorithm can be used to learn with considerably less communication than is given by simply using its error-bound algorithm directly as in Theorem 1. Theorem 6. Let us assume that the data is alpha-widely distributed and furthermore that all points have margin at least \u03b1 with the objective of w. Then we can find a consistent hypothesis with a version of the Perceptron algorithm that uses at most O (k (1 + \u03b1 / \u03b32). Each round communicates a single hypothesis. We will run the algorithm in meta rounds. Each meta round will include a round of communication between the players."}, {"heading": "7.2 Learning linear separators over non-concentrated distributions", "text": "We will now use the analysis of Section 7.1 to achieve good communication boundaries for learning linear delimiters over non-concentrated distributions. < < / p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\"."}, {"heading": "7.3 Learning linear separators without any additional assumptions", "text": "If we are prepared to have a limit that depends on the dimension d, then we can execute an error-bound algorithm for learning linear separators using theorem 1. Specifically, we can use an error-bound algorithm based on reducing the volume of the version space of consistent hypotheses (which is a polyhedron).The starting volume is 1 and the final volume is \u03b3d, where \u03b3 is the margin of the sample. In each round, each player checks if he has an example that reduces the volume by half (volume of hypotheses that agree with all the examples sent so far).However, if it is the case, he sends it (we use the lock synchronization model here).If no player has such an example, then we are done. The hypothesis we have for each x is to predict with the majority of the consistent hypotheses in unison. This results in an aggregate number of log (O) 3 examples are communicated."}, {"heading": "8 Boosting for Logarithmic Dependence on 1/\u01eb", "text": "in the USA, in Europe, in Europe, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in"}, {"heading": "9 Agnostic Learning", "text": "We can use the core of their result to agnosticate all finite class H errors, to identify all finite class H errors that apply only to the number of class-related queries in our environment, with an overall communication that is only (poly) logarithmic to 1 / 2. The key idea is that we can simulate their robust generalized halving of the algorithm by means of communication that applies only to the number of class-related queries of their algorithms. Finite class H theorem can be learned to simulate error O (opt (H)) + an overall communication of O (k log (H) that applies only to the number of class-related queries of their algorithms. Finite class H theorem can be learned."}, {"heading": "10 Privacy", "text": "In the context of distributed learning, it is also obvious to consider the issue of privacy, starting by looking at the well-studied concept of differential privacy in terms of examples, and showing how in many cases this can be achieved without increasing the cost of communication, and then looking at the case of providing additional guarantees of privacy to the players themselves. One way is to consider each player as a single (large) example, but this requires many players to achieve some non-trivial guarantees of accuracy. Therefore, we also consider a natural notion of distributed privacy, where players do not consider their distribution as sensitive, but only the sample Si obtained from it. We analyze how large a sample is to achieve accurate learning without disclosing more information about their sample than is inherent in the distribution from which it was taken."}, {"heading": "10.1 Differential privacy with respect to individual examples", "text": "In this setting, we imagine that each entity i (e.g. a hospital) is responsible for the privacy of each individual example x-Si (e.g. its patients). In particular, we assume that each entity i and the other entities or centers may have a sequence of interactions, and that privacy requires a certain level of privacy. Differential Privacy asks that for each Si and each change of entity i goes beyond an internal randomization of entity i. (See Dwork [2006, 2008, 2009] for a discussion of motivations and characteristics of differential privacy and a collection of results. In our case, a natural approach to achieving privacy requires that all interactions with each entity i be conducted in the form of statistical queries."}, {"heading": "10.2 Differential privacy with respect to the entities", "text": "One could also demand a stronger guarantee of privacy that any company can plausibly claim to have any other data set it wants; that is, e \u2212 \u03b1 \u2264 PrSi (\u03c3) / PrS \u2032 (\u03c3) \u2264 e\u03b1 for all Si and all (even unrelated) S. \"This is in fact exactly the notion of local privacy by Kasiviswanathan et al. [2008], where essentially the only possible mechanisms for maintaining privacy via randomized response.9 They show that any statistical query algorithm can be implemented in such an environment; however, since each company is now essentially considered as a single data point, k must be quite large to achieve any non-trivial accuracy."}, {"heading": "10.3 Distributional privacy", "text": "If the number of entities is small, but we still want privacy in relation to the entities themselves, then one kind of privacy we can achieve is an idea of distributed privacy. Here, we guarantee that each player will (essentially) disclose no further information about his own sample Si's, as privacy is inherent. That is, we think of Si as \"sensitive,\" but Di as \"not sensitive.\" Specifically, we say that a probable mechanism A's for answering a request q's is the satisfaction of distributed privacy ifPr S, S'mps Di's, e \u2212 \u03b1 \u2264 Pr \u2264 Pr A (S, q) / Pr A (S, q) = v) \u2264 e\u03b1 1 \u2212. In other words, with high probability we have two random samples S, S \"from Di's, we have almost the same probability to produce a response to a request q's (S, q) / Pr A (v) = v) \u2264 e\u03b1 1 \u2212."}, {"heading": "A Table of results", "text": "Class / category Communication Efficient? Conjunctions via {0, 1} n O (nk) bits yes Parity functions via {0, 1} n, k = 2 O (n) bits yes Decision lists via {0, 1} n O (nk log n) bits yes Linear separators in Rd O (d log (1 / 2))) Examples which under radial-symmetrical D O (k) examples yes under \u03b1-well-spread D O (k (1 + \u03b1 / 2)) hypotheses yes under unfocused D O (k2 \u221a d log (dk / 3) / 2) hypotheses yes general intersection-closed k hypotheses see note 1 under Boosting O (d log 1 / 2) examples, see note 2 under Agnostic learning O (k log (| H |) log (1 / 2) note: plus low-order additional bits of communication."}, {"heading": "B Additional simple cases", "text": "For example, 1 Distribution-Based AlgorithmsAn alternative basic approach in which it can be pinpointed is to send a representation of its (approximate) distribution over described data to the center for each unit i. Then, in the light of the descriptions, the center can derive an approximation of the total distribution over described data and search for a near-optimal hypothesis. This example is particularly relevant for the agnostic 1-dimensional case, e.g. a union of d intervals over X = [0, 1]. Each unit first simply sorts the points and determines d / o boundaries that define regions of the probability mass (approximately)."}, {"heading": "C Linear Separators: Margin lower bound", "text": "Evidence. (Theory 8) Suppose we have two players \u2212 \u2212 Suppose we have two players \u2212 \u2212 Suppose each player has his own examples so that the combined dataset has a linear hyphen \u2212 Suppose we perform the perceptron algorithm, in which each player updates his own dataset until it is consistent (or at least error-free) and then pass the hypothesis on to the other player, the process continuing until a player receives a hypothesis that is already error-free. In the worst-case scenario, how many rounds can this take? Below is an example showing a problematic case in which this can actually lead to a round (1 / 2). In this example, there are three dimensions \u2212 and the target vector is (0, 1, 0). Player 1 has the positive examples, with 49% of his datasets at the location (1, technique, 3G, 3G) and 49% of his datasets at the location (1) and 49% of his points at the location (1, stop)."}], "references": [{"title": "Robust interactive learning", "author": ["Maria-Florina Balcan", "Steve Hanneke"], "venue": "In Proc. 25th Annual Conference on Learning Theory (COLT),", "citeRegEx": "Balcan and Hanneke.,? \\Q2012\\E", "shortCiteRegEx": "Balcan and Hanneke.", "year": 2012}, {"title": "Practical privacy: the SuLQ framework", "author": ["Avrim Blum", "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim"], "venue": "In Proc. 24th ACM Symposium on Principles of Database Systems (PODS),", "citeRegEx": "Blum et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2005}, {"title": "A learning theory approach to non-interactive database privacy", "author": ["Avrim Blum", "Katrina Ligett", "Aaron Roth"], "venue": "In Proc. 40th Annual ACM Symp. Theory of Computing,", "citeRegEx": "Blum et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2008}, {"title": "Exact learning of formulas in parallel", "author": ["Nader H. Bshouty"], "venue": "Machine Learning,", "citeRegEx": "Bshouty.,? \\Q1997\\E", "shortCiteRegEx": "Bshouty.", "year": 1997}, {"title": "Logistic regression, adaboost and bregman distances", "author": ["Michael Collins", "Robert E. Schapire", "Yoram Singer"], "venue": "Machine Learning,", "citeRegEx": "Collins et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Collins et al\\.", "year": 2002}, {"title": "Protocols for learning classifiers on distributed data", "author": ["Hal Daume III", "Jeff Phillips", "Avishek Saha", "Suresh Venkatasubramanian"], "venue": "In International Conference on Artificial Intelligence and Statistics (AIStats),", "citeRegEx": "III et al\\.,? \\Q2012\\E", "shortCiteRegEx": "III et al\\.", "year": 2012}, {"title": "Efficient protocols for distributed classification and optimization", "author": ["Hal Daume III", "Jeff Phillips", "Avishek Saha", "Suresh Venkatasubramanian"], "venue": "CoRR, abs/1204.3523,", "citeRegEx": "III et al\\.,? \\Q2012\\E", "shortCiteRegEx": "III et al\\.", "year": 2012}, {"title": "Optimal distributed online prediction", "author": ["Ofer Dekel", "Ran Gilad-Bachrach", "Ohad Shamir", "Lin Xiao"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "Dekel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dekel et al\\.", "year": 2011}, {"title": "Differential privacy", "author": ["Cynthia Dwork"], "venue": null, "citeRegEx": "Dwork.,? \\Q2006\\E", "shortCiteRegEx": "Dwork.", "year": 2006}, {"title": "Differential privacy: A survey of results", "author": ["Cynthia Dwork"], "venue": "In TAMC, pages", "citeRegEx": "Dwork.,? \\Q2008\\E", "shortCiteRegEx": "Dwork.", "year": 2008}, {"title": "The differential privacy frontier (extended abstract)", "author": ["Cynthia Dwork"], "venue": "In TCC, pages 496\u2013502,", "citeRegEx": "Dwork.,? \\Q2009\\E", "shortCiteRegEx": "Dwork.", "year": 2009}, {"title": "Privacy-preserving datamining on vertically partitioned databases", "author": ["Cynthia Dwork", "Kobbi Nissim"], "venue": "In Proceedings of CRYPTO, Lecture Notes in Computer Science,", "citeRegEx": "Dwork and Nissim.,? \\Q2004\\E", "shortCiteRegEx": "Dwork and Nissim.", "year": 2004}, {"title": "Boosting and differential privacy", "author": ["Cynthia Dwork", "Guy N. Rothblum", "Salil P. Vadhan"], "venue": "In FOCS,", "citeRegEx": "Dwork et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2010}, {"title": "Boosting a weak learning algorithm by majority", "author": ["Yoav Freund"], "venue": "In COLT, pages 202\u2013216,", "citeRegEx": "Freund.,? \\Q1990\\E", "shortCiteRegEx": "Freund.", "year": 1990}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Yoav Freund", "Robert E. Schapire"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Freund and Schapire.,? \\Q1997\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1997}, {"title": "On the complexity of teaching", "author": ["Sally A. Goldman", "Michael J. Kearns"], "venue": "In Proceedings of COLT", "citeRegEx": "Goldman and Kearns.,? \\Q1991\\E", "shortCiteRegEx": "Goldman and Kearns.", "year": 1991}, {"title": "The art of multiprocessor programming", "author": ["Maurice Herlihy", "Nir Shavit"], "venue": null, "citeRegEx": "Herlihy and Shavit.,? \\Q2008\\E", "shortCiteRegEx": "Herlihy and Shavit.", "year": 2008}, {"title": "Information transfer in distributed computing with applications to vlsi", "author": ["Joseph J\u00e1J\u00e1", "Viktor K. Prasanna"], "venue": "J. ACM,", "citeRegEx": "J\u00e1J\u00e1 and Prasanna.,? \\Q1984\\E", "shortCiteRegEx": "J\u00e1J\u00e1 and Prasanna.", "year": 1984}, {"title": "What Can We Learn Privately", "author": ["Shiva Kasiviswanathan", "Homin Lee", "Kobbi Nissim", "Sofya Raskhodnikova", "Adam Smith"], "venue": "In Proc. 49th Annual IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Kasiviswanathan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kasiviswanathan et al\\.", "year": 2008}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["Michael Kearns"], "venue": "Journal of the ACM,", "citeRegEx": "Kearns.,? \\Q1998\\E", "shortCiteRegEx": "Kearns.", "year": 1998}, {"title": "Communication complexity", "author": ["Eyal Kushilevitz", "Noam Nisan"], "venue": null, "citeRegEx": "Kushilevitz and Nisan.,? \\Q1997\\E", "shortCiteRegEx": "Kushilevitz and Nisan.", "year": 1997}, {"title": "Algorithms and hardness results for parallel large margin learning", "author": ["Phil Long", "Rocco Servedio"], "venue": "In NIPS,", "citeRegEx": "Long and Servedio.,? \\Q2011\\E", "shortCiteRegEx": "Long and Servedio.", "year": 2011}, {"title": "Distributed computing: a locality-sensitive approach", "author": ["David Peleg"], "venue": "Society for Industrial and Applied Mathematics, Philadelphia, PA,", "citeRegEx": "Peleg.,? \\Q2000\\E", "shortCiteRegEx": "Peleg.", "year": 2000}, {"title": "Learning complicated concepts reliably and usefully", "author": ["Ronald L. Rivest", "Robert Sloan"], "venue": "In Proceedings AAAI-88,", "citeRegEx": "Rivest and Sloan.,? \\Q1988\\E", "shortCiteRegEx": "Rivest and Sloan.", "year": 1988}, {"title": "The strength of weak learnability", "author": ["Robert E. Schapire"], "venue": "Machine Learning,", "citeRegEx": "Schapire.,? \\Q1990\\E", "shortCiteRegEx": "Schapire.", "year": 1990}, {"title": "Perceptron, Winnow, and PAC learning", "author": ["Rocco Servedio"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Servedio.,? \\Q2002\\E", "shortCiteRegEx": "Servedio.", "year": 2002}, {"title": "Parallelized stochastic gradient descent", "author": ["Martin Zinkevich", "Markus Weimer", "Alexander J. Smola", "Lihong Li"], "venue": "In NIPS,", "citeRegEx": "Zinkevich et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zinkevich et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Further we show that, ignoring computation, agnostic learning can be performed to error O(opt(H)) + \u01eb with logarithmic dependence on 1/\u01eb, by adapting results of Balcan and Hanneke [2012]. In terms of specific classes, we present several tight bounds including a \u0398(d log d) bound on the communication in bits needed for learning the class of decision lists over {0, 1}d.", "startOffset": 161, "endOffset": 187}, {"referenceID": 23, "context": "This is a by-product of a general result regarding concepts learnable in the reliable-useful framework of Rivest and Sloan [1988]. For a table of results, see Appendix A.", "startOffset": 106, "endOffset": 130}, {"referenceID": 3, "context": "Bshouty [1997] shows that many simple classes that can be PAC learned can not be efficiently learned in parallel with a polynomial number of processors.", "startOffset": 0, "endOffset": 15}, {"referenceID": 3, "context": "Bshouty [1997] shows that many simple classes that can be PAC learned can not be efficiently learned in parallel with a polynomial number of processors. Long and Servedio [2011] show a parallel algorithm for large margin classifiers running in time O(1/\u03b3) compared to more naive implementations costing of \u03a9(1/\u03b32), where \u03b3 is the margin.", "startOffset": 0, "endOffset": 178}, {"referenceID": 3, "context": "Bshouty [1997] shows that many simple classes that can be PAC learned can not be efficiently learned in parallel with a polynomial number of processors. Long and Servedio [2011] show a parallel algorithm for large margin classifiers running in time O(1/\u03b3) compared to more naive implementations costing of \u03a9(1/\u03b32), where \u03b3 is the margin. They also show an impossibility result regarding boosting, namely that the ability to call the weak learner oracle multiple times in parallel within a single boosting stage does not reduce the overall number of successive stages of boosting that are required. Collins et al. [2002] give an online algorithm that uses a parallel-update method for the logistic loss, and Zinkevich et al.", "startOffset": 0, "endOffset": 620}, {"referenceID": 3, "context": "Bshouty [1997] shows that many simple classes that can be PAC learned can not be efficiently learned in parallel with a polynomial number of processors. Long and Servedio [2011] show a parallel algorithm for large margin classifiers running in time O(1/\u03b3) compared to more naive implementations costing of \u03a9(1/\u03b32), where \u03b3 is the margin. They also show an impossibility result regarding boosting, namely that the ability to call the weak learner oracle multiple times in parallel within a single boosting stage does not reduce the overall number of successive stages of boosting that are required. Collins et al. [2002] give an online algorithm that uses a parallel-update method for the logistic loss, and Zinkevich et al. [2010] give a detailed analysis of a parallel stochastic gradient descent in which each machine processes a random subset of the overall data, combining hypotheses at the very end.", "startOffset": 0, "endOffset": 731}, {"referenceID": 3, "context": "Bshouty [1997] shows that many simple classes that can be PAC learned can not be efficiently learned in parallel with a polynomial number of processors. Long and Servedio [2011] show a parallel algorithm for large margin classifiers running in time O(1/\u03b3) compared to more naive implementations costing of \u03a9(1/\u03b32), where \u03b3 is the margin. They also show an impossibility result regarding boosting, namely that the ability to call the weak learner oracle multiple times in parallel within a single boosting stage does not reduce the overall number of successive stages of boosting that are required. Collins et al. [2002] give an online algorithm that uses a parallel-update method for the logistic loss, and Zinkevich et al. [2010] give a detailed analysis of a parallel stochastic gradient descent in which each machine processes a random subset of the overall data, combining hypotheses at the very end. All of the above results are mainly interested in reducing the time required to perform learning when data can be randomly or algorithmically partitioned among processors; in contrast, our focus is on a setting in which we begin with data arbitrarily partitioned among the entities. Dekel et al. [2011] consider distributed online prediction with arbitrary partitioning of data streams, achieving strong regret bounds; however, in their setting the goal of entities is to perform well on their own sequence of data.", "startOffset": 0, "endOffset": 1208}, {"referenceID": 3, "context": "Bshouty [1997] shows that many simple classes that can be PAC learned can not be efficiently learned in parallel with a polynomial number of processors. Long and Servedio [2011] show a parallel algorithm for large margin classifiers running in time O(1/\u03b3) compared to more naive implementations costing of \u03a9(1/\u03b32), where \u03b3 is the margin. They also show an impossibility result regarding boosting, namely that the ability to call the weak learner oracle multiple times in parallel within a single boosting stage does not reduce the overall number of successive stages of boosting that are required. Collins et al. [2002] give an online algorithm that uses a parallel-update method for the logistic loss, and Zinkevich et al. [2010] give a detailed analysis of a parallel stochastic gradient descent in which each machine processes a random subset of the overall data, combining hypotheses at the very end. All of the above results are mainly interested in reducing the time required to perform learning when data can be randomly or algorithmically partitioned among processors; in contrast, our focus is on a setting in which we begin with data arbitrarily partitioned among the entities. Dekel et al. [2011] consider distributed online prediction with arbitrary partitioning of data streams, achieving strong regret bounds; however, in their setting the goal of entities is to perform well on their own sequence of data. In very recent independent work, Daume III et al. [2012a] examine a setting much like that considered here, in which parties each have an arbitrary partition of an overall dataset, and the goal is to achieve low error over the entire distribution.", "startOffset": 0, "endOffset": 1479}, {"referenceID": 3, "context": "Bshouty [1997] shows that many simple classes that can be PAC learned can not be efficiently learned in parallel with a polynomial number of processors. Long and Servedio [2011] show a parallel algorithm for large margin classifiers running in time O(1/\u03b3) compared to more naive implementations costing of \u03a9(1/\u03b32), where \u03b3 is the margin. They also show an impossibility result regarding boosting, namely that the ability to call the weak learner oracle multiple times in parallel within a single boosting stage does not reduce the overall number of successive stages of boosting that are required. Collins et al. [2002] give an online algorithm that uses a parallel-update method for the logistic loss, and Zinkevich et al. [2010] give a detailed analysis of a parallel stochastic gradient descent in which each machine processes a random subset of the overall data, combining hypotheses at the very end. All of the above results are mainly interested in reducing the time required to perform learning when data can be randomly or algorithmically partitioned among processors; in contrast, our focus is on a setting in which we begin with data arbitrarily partitioned among the entities. Dekel et al. [2011] consider distributed online prediction with arbitrary partitioning of data streams, achieving strong regret bounds; however, in their setting the goal of entities is to perform well on their own sequence of data. In very recent independent work, Daume III et al. [2012a] examine a setting much like that considered here, in which parties each have an arbitrary partition of an overall dataset, and the goal is to achieve low error over the entire distribution. They present comunication-efficient learning algorithms for axis-parallel boxes as well as for learning linear separators in R2. Daume III et al. [2012b], also independently of our work, extend this to the case of linear separators in Rd, achieving bounds similar to those obtained via our distributed boosting results.", "startOffset": 0, "endOffset": 1823}, {"referenceID": 16, "context": "Note that if we have an algorithm with T time steps and C communication bits in the lock-synchronous model, using an exponential back-off mechanism [Herlihy and Shavit, 2008] and a synchronizer [Peleg, 2000], we can convert it to an asynchronous communication with O(T log k) rounds and O((T +C) log k) communication bits.", "startOffset": 148, "endOffset": 174}, {"referenceID": 22, "context": "Note that if we have an algorithm with T time steps and C communication bits in the lock-synchronous model, using an exponential back-off mechanism [Herlihy and Shavit, 2008] and a synchronizer [Peleg, 2000], we can convert it to an asynchronous communication with O(T log k) rounds and O((T +C) log k) communication bits.", "startOffset": 194, "endOffset": 207}, {"referenceID": 19, "context": "The interested reader is referred to Kushilevitz and Nisan [1997] for an excellent exposition of communication complexity.", "startOffset": 37, "endOffset": 66}, {"referenceID": 8, "context": "See Dwork [2008] for an excellent survey of differential privacy.", "startOffset": 4, "endOffset": 17}, {"referenceID": 15, "context": "dT (H) is defined as maxf\u2208H dT (f) where dT (f) is the smallest number of examples needed to uniquely identify f within H [Goldman and Kearns, 1991].", "startOffset": 122, "endOffset": 148}, {"referenceID": 17, "context": "A classic lower bound in communication complexity states that if two entities each have a set of linear equalities over n variables, then \u03a9(n2) bits of communication are needed to determine a feasible solution, based on J\u00e1J\u00e1 and Prasanna [1984]. This in turn implies that for proper learning of parity functions, \u03a9(n2) bits of communication are required even in the case k = 2, matching the baseline upper bound given via Equivalence Query algorithms.", "startOffset": 220, "endOffset": 245}, {"referenceID": 17, "context": "A classic lower bound in communication complexity states that if two entities each have a set of linear equalities over n variables, then \u03a9(n2) bits of communication are needed to determine a feasible solution, based on J\u00e1J\u00e1 and Prasanna [1984]. This in turn implies that for proper learning of parity functions, \u03a9(n2) bits of communication are required even in the case k = 2, matching the baseline upper bound given via Equivalence Query algorithms. Interestingly, however, if one drops the requirement that learning be proper, then for k = 2, parity functions can be learned using only O(n) bits of communication. Moreover, the algorithm is efficient. This is in fact a special case of the following result for classes that are learnable in the reliable-useful learning model of Rivest and Sloan [1988].", "startOffset": 220, "endOffset": 806}, {"referenceID": 23, "context": "[Rivest and Sloan, 1988] An algorithm reliably and usefully learns a class H if given poly(n, 1/\u01eb, 1/\u03b4) time and samples, it produces a hypothesis h that on any given example outputs either a correct prediction or the statement \u201cI don\u2019t know\u201d; moreover, with probability at least 1\u2212 \u03b4 the probability mass of examples for which it answers \u201cI don\u2019t know\u201d is at most \u01eb.", "startOffset": 0, "endOffset": 24}, {"referenceID": 25, "context": "Moreover, an average over O(d/\u01eb2) samples is sufficient to produce an estimate of error at most \u01eb with high probability [Servedio, 2002].", "startOffset": 120, "endOffset": 136}, {"referenceID": 22, "context": ", Schapire [1990], Freund [1990], Freund and Schapire [1997].", "startOffset": 2, "endOffset": 18}, {"referenceID": 13, "context": ", Schapire [1990], Freund [1990], Freund and Schapire [1997].", "startOffset": 19, "endOffset": 33}, {"referenceID": 13, "context": ", Schapire [1990], Freund [1990], Freund and Schapire [1997]. (For Adaboost, we are considering the version that uses a fixed upper bound \u03b2 on the error of the weak hypotheses.", "startOffset": 19, "endOffset": 61}, {"referenceID": 14, "context": "In particular, using Adaboost [Freund and Schapire, 1997] in Lemma 9 yields the following result (plugging in \u03b2 = 1/4 or \u03b2 = \u01eb1/c respectively):", "startOffset": 30, "endOffset": 57}, {"referenceID": 0, "context": "We prove this result by simulating the robust generalized halving algorithm of Balcan and Hanneke [2012], for the case of finite hypothesis spaces, in a communication-efficient manner.", "startOffset": 79, "endOffset": 105}, {"referenceID": 0, "context": ", niN ), who draws (but keeps internally and does not send) nij examples of Sj for each The algorithm of Balcan and Hanneke [2012] for the case of infinite hypothesis spaces begins by using a large unlabeled sample to determine a small \u01eb-cover of H.", "startOffset": 105, "endOffset": 131}, {"referenceID": 19, "context": "In our case, one natural approach for achieving privacy is to require that all interaction with each entity i be in the form of statistical queries [Kearns, 1998].", "startOffset": 148, "endOffset": 162}, {"referenceID": 1, "context": "[Dwork and Nissim, 2004, Blum et al., 2005, Kasiviswanathan et al., 2008] If H is learnable using M statistical queries of tolerance \u03c4 , then H is learnable preserving differential privacy with privacy parameter \u03b1 from a sample S of size O(max[ \u03b1\u03c4 , M \u03c42 ] log(M/\u03b4)). Proof. For a single statistical query, privacy with parameter \u03b1\u2032 can be achieved by adding Laplace noise of width O( 1 \u03b1\u2032|S|) to the empirical answer of the query on S. That is because changing a single entry in S can change the empirical answer by at most 1/|S|, so by adding such noise we have that for any v, PrS(v)/PrS\u2032(v) \u2264 e\u03b1 \u2032 . Note that with probability at least 1 \u2212 \u03b4\u2032, the amount of noise added to any given answer is at most O( 1 \u03b1\u2032|S| log(1/\u03b4 \u2032)). Thus, if the overall algorithm requires M queries to be answered to tolerance \u03c4 , then setting \u03b1\u2032 = \u03b1/M, \u03b4\u2032 = \u03b4/(2M), \u03c4 = O( 1 \u03b1\u2032|S| log(1/\u03b4 \u2032)), privacy can be achieved so long as we have |S| = O(max[ \u03b1\u03c4 , M\u03c42 ] log(M/\u03b4)), where the second term of the max is the sample size needed to achieve tolerance \u03c4 for M queries even without privacy considerations. As described in Dwork et al. [2010], one can achieve a somewhat weaker privacy guarantee using \u03b1\u2032 = O(\u03b1/ \u221a M).", "startOffset": 25, "endOffset": 1122}, {"referenceID": 18, "context": "This in fact corresponds precisely to the local privacy notion of Kasiviswanathan et al. [2008],", "startOffset": 66, "endOffset": 96}, {"referenceID": 1, "context": "Blum et al. [2008] introduce a similar privacy notion,10 which they show is strictly stronger than differential privacy, but do not provide efficient algorithms.", "startOffset": 0, "endOffset": 19}, {"referenceID": 1, "context": "In the notion of Blum et al. [2008], Di is uniform over some domain and sampling is done without replacement.", "startOffset": 17, "endOffset": 36}], "year": 2012, "abstractText": "We consider the problem of PAC-learning from distributed data and analyze fundamental communication complexity questions involved. We provide general upper and lower bounds on the amount of communication needed to learn well, showing that in addition to VC-dimension and covering number, quantities such as the teaching-dimension and mistake-bound of a class play an important role. We also present tight results for a number of common concept classes including conjunctions, parity functions, and decision lists. For linear separators, we show that for non-concentrated distributions, we can use a version of the Perceptron algorithm to learn with much less communication than the number of updates given by the usual margin bound. We also show how boosting can be performed in a generic manner in the distributed setting to achieve communication with only logarithmic dependence on 1/\u01eb for any concept class, and demonstrate how recent work on agnostic learning from class-conditional queries can be used to achieve low communication in agnostic settings as well. We additionally present an analysis of privacy, considering both differential privacy and a notion of distributional privacy that is especially appealing in this context.", "creator": "LaTeX with hyperref package"}}}