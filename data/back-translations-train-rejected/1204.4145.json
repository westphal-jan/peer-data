{"id": "1204.4145", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Apr-2012", "title": "Learning From An Optimization Viewpoint", "abstract": "In this dissertation we study statistical and online learning problems from an optimization viewpoint.The dissertation is divided into two parts :", "histories": [["v1", "Wed, 18 Apr 2012 17:17:56 GMT  (592kb,D)", "http://arxiv.org/abs/1204.4145v1", "Thesis supervisor : Nati Srebro Thesis Committee : David McAllester, Arkadi Nemirovski, Alexander Razborov, Nati Srebro"]], "COMMENTS": "Thesis supervisor : Nati Srebro Thesis Committee : David McAllester, Arkadi Nemirovski, Alexander Razborov, Nati Srebro", "reviews": [], "SUBJECTS": "cs.LG cs.GT", "authors": ["karthik sridharan"], "accepted": false, "id": "1204.4145"}, "pdf": {"name": "1204.4145.pdf", "metadata": {"source": "CRF", "title": "Learning From An Optimization Viewpoint", "authors": ["Karthik Sridharan", "David McAllester", "Arkadi Nemirovski", "Alexander Razborov"], "emails": [], "sections": [{"heading": null, "text": "Learning From An Optimization ViewpointbyKarthik SridharanSubmitted to: Toyota Technological Institute at Chicago 6045 S. Kenwood Ave, Chicago, IL, 60637For the degree of Philosophy in Computer ScienceThesis Committee: Nathan Srebro (PhD supervisor), David McAllester, Arkadi Nemirovski, Alexander Razborovar Xiv: 120 4.41 45v1 [cs.LG] 1 8A pr2 012In memory of my dear father, Raghavan Sridharan.... i"}, {"heading": "Acknowledgements", "text": "I believe that the majority of people who are able to understand and understand the world, what it is all about, what they are doing to change and change the world, to change the world, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change, to change and to change."}, {"heading": "1 Introduction 1", "text": "1.1 Learning and optimisation.............................................................. 31.2.1 Part I: Statistical and online learning: learning ability and learning rates... 31.2.2 Part II: Convex problems: oracle-efficient learning / optimisation 41.3 Main contributions......................................................................................................................"}, {"heading": "I Statistical and Online Learning : Learnability and Rates 7", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Preliminary Setup and Notations 8", "text": "2.1 Structure of general learning problems................................ 82.2 Further definitions and notations.................."}, {"heading": "3 Statistical Learning/Optimization 12", "text": "Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer. Heuer."}, {"heading": "4 Online Learning/Optimization 52", "text": "The overarching question is to what extent the overarching role of the country in addressing this problem is that the overarching task is to assume the overarching role of the state. The overarching role of the state in the world is to assume the role of the state. The overarching role of the state is to assume the responsibility of the state. The overarching role of the state is to assume the responsibility of the state. The overarching role of the state is to assume the responsibility of the state."}, {"heading": "II Convex Problems : Oracle Efficient Learning/Optimization 104", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5 Convex Learning and Optimization Problem Setup 105", "text": "5.1 Convex problems.................................................................................................................................................................."}, {"heading": "6 Mirror Descent Methods 109", "text": "6.1 Mirror descent.......................................................................... 1106.3 Stochastic mirror descent..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "7 Optimality of Mirror Descent for Online Convex Learning Problem 124", "text": ". Ix7.1. Value of Line Game. Ix7.1. Line Game. Ix.7. Line Game. Ix.7. Line Game. Ix.7. Ix.7. Line Game. Ix.7. Line Game. Ix.8. Ix.8. Ix.8. Ix.8. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9. Ix.9."}, {"heading": "8 Optimality of Mirror Descent for Statistical Convex Learning Problems 151", "text": "The lower limits for the distinction between the sexes are: Smooth losses. 1548.3. Important approaches to solutions. Stochastic approaches. 1548.2. 1548.2. Optimal approaches to solutions. 1558.3.1. Rademacher approaches to solutions. 1558.3.1. Latte approaches to solutions. 1548.3. Important approaches to solutions. Optimality. Stochastic approaches to solutions. 1558.3.1. Approaches to solutions. 1558.3.1. Latte approaches to solutions."}, {"heading": "9 Optimality of Mirror Descent for Offline Convex Optimization 175", "text": "9.1 Oracle-based Offline Convex Optimization..................... 1769.2 Lower Bounding Oracle Complexity: Connections to Statistical ConvexLearning.......................................... 1789.3 Main Result: Optimality of Mirror Descent for Offline Convexe Optimization1809.4 Statistical Learning With Distributed Oracles................................................. 1839.6 Discussion........."}, {"heading": "10 Conclusion and Future Work 187", "text": "10.1 Open Problems.........................................................................................................................................................................................................................................................................................................................................."}, {"heading": "A Relating Various Complexity Measures : Statistical Learning 197", "text": "It is indeed the case that we are able to put ourselves at the top, in the way in which we have pushed ourselves to the top."}, {"heading": "1.1 Learning and Optimization", "text": "The typical approach chosen to address learning problems was to select a suitable set of models or hypotheses or predictors, to select appropriate empirical costs over the training sample, and finally to solve the optimization problem in selecting hypotheses that minimize empirical costs over the training sample. In this case, the learning algorithm itself corresponds to the optimization algorithm that solves the optimization problem in selecting these hypotheses from the set of hypotheses that minimize empirical costs over the training sample. Theoretical guarantees for learning rates are typically provided by splitting error terms into two terms. The first term that takes into account errors we would have when selecting hypotheses that minimize empirical costs over the training sample; the second term is the optimization error that minimizes the sub-optimization algorithm's sub-optimization over the costs we minimize empirical problems over the problems we ourselves."}, {"heading": "1.2 Overview of the Thesis", "text": "The dissertation can be divided into two parts; the first part focuses on the question of learning ability and learning rates for relatively general classes of learning problems in both statistical and online learning frameworks. In the second part of this dissertation, we limit ourselves to convex learning problems and show that for most reasonable problems the method of first-order mirror descent is nearly optimal for both statistical and convex learning problems. We also establish links between convex learning and (offline) convex optimization and find that for several high-dimensional (offline) convex optimization problems mirror descent is optimal in terms of efficiency for (offline) convex optimization problems. The term efficiency we use in this case is the concept of oracle complexity introduced by Nemirovski and Yudin (1978)."}, {"heading": "1.2.1 Part I : Statistical and Online Learning : Learnability and Rates", "text": "The first part of the study is the question of learning ability in the context of statistics. This chapter deals with the analysis of learning rates in the individual countries."}, {"heading": "1.2.2 Part II : Convex Problems : Oracle Efficient Learning/Optimization", "text": "The first part of the study presents the results of the study and the second part presents the results of the study."}, {"heading": "1.3 Main Contributions", "text": "1. Part I: (a) Statistical learning \u2022 Illustrating limitations of uniform convergence and ERM / SAA \u2022 Characterizing statistical learning in general through stability \u2022 Providing universal randomized learning rules (b) Online learning \u2022 Introducing analogies of various complexity measures of the hypotheses class for online learning \u2022 Providing tools for uniform convergence theory \u2022 Characterizing online learning ability for supervised learning problems \u2022 Generic algorithm for online supervised learning (b) Statistical convex learning problems \u2022 Characterizing learning ability and learning rates for various convex learning problems by introducing a martingale type \u2022 Show universality and approximate optimism of online mirror decline for online convex learning problems (b) Statistical convex learning problems \u2022 Establish lower limits for oracle complexity and learning rates for various convex learning problems within the context of rational class-exexexexexexexxplar problems)."}, {"heading": "1.4 Bibliographic Notes", "text": "The results of Chapter 4 come from joint work with Alexander Rakhlin and Ambuj Tewari and can be found in [5]. In the second part of the dissertation, some results from Chapter 6 in [6] are found. The results of Chapter 7 come from joint work with Nathan Srebro and Ambuj Tewari. The relationship between the basic concept of the martyr type and certain convex online learning problems was first carried out in [7]. In [6] the result of the universality and approximate optimism of the method of mirror descent from Chapter 7 is explained in Chapters 8 and 9."}, {"heading": "2.1 General Learning Problem Setup", "text": "rE \"s rf\u00fc eid rf\u00fc \u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the r"}, {"heading": "2.2 More Definitions and Notations", "text": "An important object we will encounter as we learn online are trees. Unless we specify it, all trees considered in this work are either rooted complete binary trees. While it is useful to have the tree image in mind when we read the paper, it is also necessary to define trees exactly as mathematical objects. We opt for the following definition 1 (trees). The root of the tree z is the constant function z1 (trees).9A Tree of infinite depth is defined exactly like an infinite sequence (zn) n of this definition, we can talk about various operations on trees. For a function f: Z 7 \u2192 U, f (z) denotes the tree defined by the mappings."}, {"heading": "3.1 The Statistical Learning Problem and Learnability", "text": "In the statistical learning problematic, we are exactly what we apply in the statistical learning environment. \"\" We must learn. \"\" We. \"\" We. \"\" We. \"\" We. \"\" We. \"\" We. \"\". \"\" We. \".\" \"We.\". \"\" We. \"\". \"\" We. \"\". \"\". \"\" We. \"\" \".\" \"\". \"\" \"\". \"\" \".\" \"\" \"..\" \"\" \"..\" \".\". \".\". \".\". \".\" \".\" \".\" \"\". \"\". \"\" \".\" \"\" \"\". \"\" \".\" \"\". \"\" \".\" \".\" \"\". \".\" \"\". \"\" \".\". \".\". \".\". \"\". \".\". \"\". \"\" \".\" \".\" \"\". \"\". \"\". \".\" \".\" \".\" \".\". \"\". \"\". \"\". \".\". \"\". \"\". \".\" \".\" \".\" \"\". \"\". \"\" \".\". \".\". \"\". \"\" \".\" \".\" \".\" \".\" \"\". \".\". \".\" \".\". \"\" \"\" \".\". \".\". \"\" \"\". \".\". \"\" \"\". \".\". \"\" \".\" \"\". \"\" \".\" \".\". \"\" \".\". \"\" \".\". \".\". \"\" \"\". \".\". \"\" \".\" \"\" \".\". \".\" \"\" \".\". \"\" \".\" \".\" \"\". \".\" \"\". \"\" \".\" \"\" \".\". \"\". \"\" \".\" \".\". \"\" \".\" \"\" \"\". \"\". \".\". \".\". \"\" \".\". \"\" \".\". \"\" \".\" \".\". \".\". \".\". \".\". \".\". \".\" \"\" \"\". \".\" \".\""}, {"heading": "3.2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1 Learnability and Uniform Convergence", "text": "As discussed in the introduction, a central term for the characterization of learning ability is unitary convergence. (...) Formally, we say that unitary convergence is necessary for a learning problem if the empirical risks of hypotheses in the hypotheses category. \"(...) It is easy to show that if unitary convergence holds a unitary convergence, then a problem with the ERM learning rule.For binary classification problems (where Z = X = 1), each hypothesis is a mapping from X to {0, 1}, and {h, y) = 1 {h (x), [13] showed that the finiteness of a simple combinatorial measure is implied."}, {"heading": "3.2.2 Various Complexity Measures and Uniform Convergence", "text": "& # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8220; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 8222; S & # 222; S & # 222; S & # 222; S & # 222; S & # 222; S & # 222; S & & # 222; S & # 222; S & & S # 222; S & # 222; S & 222; S & S & 222; S & S & 222; S & S # 222; S & S & 222; S & S # 222; S & S & 222; S & 222; S & S & 222; S & 222; S & S & 222; S & S & 222; S & 222; S & 222; S & 222; S & S & 222; S & 222; S & 222; S & 222; S & 222 & S & S & 222; S & 222; S & 222; S & 222 & S & 222; S & S & 222; S 222 & S & 222; S & 222 & S & S & 222; S & 222 & S & 222; S & S 222 & S & 2S & S & 222; S & S & 222 & 2S & S 2S & 222; S & S & 2S 2S & S & 2S & S & S & 2S & S 2S & 2S & S 2S & 2S & S 2S & S 2S & S & S 2S & S & 2S & S & S & 2S & S # 2S & S & S & 2S & S & S & 2S & S & S & S & 2S & S 2S & S & 2S & S & S & S & S"}, {"heading": "3.2.3 Learnability and Stability", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want."}, {"heading": "3.3 Failure of Uniform Convergence and ERM/SAA Approaches", "text": "In this section, we examine a specific case of the general learning environment, in which there is a real gap between learning ability and uniform convergence, in which there are non-trivial problems in which there is no uniform convergence (not even in the local sense), but which are still learnable. Furthermore, some of these problems are learnable with an exchange rate mechanism (again without uniform convergence), and some cannot be learnt with an exchange rate mechanism, but with a different mechanism. We also discuss why this particular behavior does not formally contradict Vapnik's results in terms of the equivalence of strict consistency of the exchange rate mechanism and uniform convergence, and the important role that regulation seems to play here, but in a different way than in standard theory."}, {"heading": "3.3.1 Learning without Uniform Convergence : Stochastic Convex Optimization", "text": "We will focus here on problems where H is a subset of a Hilbert space, and \"(h; x; y) is the well-known linear prediction setting, where z = (x, y) is an instance pair, each hypothesis h belongs to a subset H of a Hilbert space, and\" (h; x; y) is the usual linear prediction setting, where z = (x) y is an instance pair, each hypothesis h belongs to a subset H of a Hilbert space, and \"(h; x, y) which is a subset (x) >, y) for some features mapping and a loss function.\" R, the convex w.r.t. its first argumentation.The situation in which the stochastic dependence on h is linear, as in the preceding example, is fairly well understood."}, {"heading": "3.3.2 Learnability via Stability : Role of Regularization", "text": "At this point, we have seen an example in the stochastic optimization problem where a uniform convergence does not work and the ERM algorithm fails. Nevertheless, we have seen that the problem was learnable using the SA approach. We will now see an alternative explanation for why the problem is learnable, which mainly uses stability to explain the success. We will specifically consider an algorithm that minimizes a regularized average loss and shows that this algorithm can guarantee a similar learning rate as the stochastic gradient approach. We will show that regulation induces stability of the learning problem and this stability in turn ensures that learning ability is ensured. In the face of a stochastic convex optimization problem with an objective function. \""}, {"heading": "3.3.3 Contradiction to Vapnik?", "text": "In sub-section 3.2.1 we discussed how Vapnik has shown that a uniform convergence with the ERM is indeed necessary for learning. The solution to this apparent paradox is that our examples are not \"strictly consistent\" in the sense of Vapnik. Remember that Vapnik, in order to exclude \"trivial\" cases, defined strict consistency of empirical minimization as (in our notation):........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"}, {"heading": "3.4 Stability of Learning Rules", "text": "In the previous section, we have shown that it is possible in the general learning attitude that problems can be learned without uniform convergence, in sharp contrast to previously considered attitudes. The underlying mechanism that enabled us to learn is stability. In this section, we will examine the relationship between learning ability and stability in greater depth and show that stability can indeed characterize learning ability. We will also see how various \"general knowledge factors\" that we normally consider to be \"superior\" and based on a \"uniform convergence\" assumption do not apply in the general learning attitude, and things can be much more delicate. We will refer to attitudes in which learning ability is equivalent to a uniform convergence classification. While the supervised classification does not cover all attitudes in which this equivalence applies, most equivalence outcomes either explicitly or implicitly (by reducing to a classification profiling)."}, {"heading": "3.4.1 Comparison with Existing Literature and Other Notions of Stability", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able to achieve our goals, and that we are able to achieve our goals."}, {"heading": "3.5 Characterizing Learnability : Main Results", "text": "Our overarching goal is to characterize learnable problems (namely, problems for which there is a universally uniform learning rule (ERM = 3), as in Eq. (??) This means finding a condition that is sufficient for both learning ability and learning ability, but far from being necessary, as we have seen in the section? The most important result in this section is a condition that is necessary and sufficient for learning ability in the general learning attitude: 32Theorem 5. A learning problem is learnable if there is a uniform RO-stable, universally AERM learning rule. In particular, if there is a uniform rule (s) -universally uniform rule, then there is a rule that is stable and universal."}, {"heading": "3.6 Randomization, Convexification, and a Generic Learning Rule", "text": "In this section, we show that if randomized learning rules are taken into account, stronger results can be achieved, and we even propose a generic randomized algorithm for statistical learning problems that guarantees a non-trivial learning rate whenever the problem is learnable."}, {"heading": "3.6.1 Stronger Results with Randomized Learning Rules", "text": "The strongest result we have so far obtained for the characterization of the ability to learn is Theorem 5, which states that a problem can be learned if and only if there is a universally uniform RO-stable AERM method. In fact, this result was obtained on the assumption that Rule A is actually deterministic: in view of this relaxation rule, we will see that we can obtain a stronger version of Theorem 5 and even provide a generic learning algorithm (at least for computer-unlimited learners) that succeeds in solving any learnable problem. To simplify notation, we will skip the notations (A), L (A) and LS (S) to mean Eh."}, {"heading": "3.6.2 A Generic Learning Rule", "text": "Remember that a symmetrical learning rule A is such that A (S) = A (S) = A (S) = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "3.7 Detailed Results and Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.7.1 Detailed Proof of Main Result (Section 3.5)", "text": "In this subsection, we provide evidence for the main outcomes contained in Section 3.5. We first note that for AERMs, average RO stability and generalization are equivalent. Equivalence of stability and generalizationIt will be convenient to work with a weaker version of generalization as an intermediate step: We say that a rule A is on average generalizable with the rate oag (n) below distribution D, if for all n, | Xi \u2032 Dn [L (A (S)))) \u2212 LS (A (S)] | \u2264 oag (n). (3.7.1) It is easy to see that generalization implies an average generalization with the same rate. We show that for AERMs the reversal is also true, and also that an average generalization corresponds to average RO stability. This establishes the equivalence between generalization and average RO stability (AERMs) for average RO stability (13)."}, {"heading": "A Sufficient Condition for Consistency", "text": "It is quite easy to see that the generalization (or even generalization) of an AERM result (universal results) implies its consistency: Lemma 17 (AERM + generalization). If the generalization (or even generalization) of an AERM problem (s) is an average generalization consistent with the rate oag (n) + erm (n) under D. Proof. [L (S) \u2212 LS (S) \u2212 LS (S) \u2212 LS (S) \u2212 LS) \u2212 LS (S) \u2212 LS (S) \u2212 LS (S) \u2212 LS (S) \u2212 LS (S)]. + E [LS (S) \u2212 LS (S) \u2212 LS (S)."}, {"heading": "3.7.2 Other Proofs", "text": "To prove the theorems, we use a stability argument. DenoteF (i) (h) = 1n \"(h, z\" i) + 1 \"(h, z\" i \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h h h h h h h h h h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h h h h h h h h h h h h h h h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h \"h\" h"}, {"heading": "3.8 Discussion", "text": "In this chapter, we have begun to discuss the issue of statistical learning efficiency in the Universal Declaration of Human Rights, both in terms of the way people learn, in terms of the way they do it, and in terms of the way they do it, and in terms of the way they do it."}, {"heading": "4.1 The Online Learning Problem", "text": "The answer to the question of whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is, whether it is a question, whether it is a question, whether it is a question, whether it is, whether it is a question, whether it is a question, whether it is a question, whether it is, whether it is a question, whether it is a question, whether it is a question, whether it is, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a"}, {"heading": "4.2 Online Learnability and the Value of the Game", "text": "How can one define the ability to learn in the online learning environment? Of course, we will refer to a problem that we call online learning if there is a random online learning algorithm that guarantees a decreasing expectation against any strategy of the opponent."}, {"heading": "4.3 Sequential Rademacher Complexity", "text": "We propose the following definition of the sequential complexity of each function class F = RZ. The key difference from the classical definition is the dependence of the sequentials on the sequential-sequential-sequential-sequential-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials-sequentials"}, {"heading": "4.3.1 Structural Results", "text": "s averages [39, 38]. In particular, contraction inequality due to Ledoux and Talagrand [41,58Corollary 3.17] allows one to move from the composition of a Lipschitz function with one class to the functional class itself. This wonderful property allows simple convergence proofs for a huge array of problems. We show that the concept of sequential Rademacher complexity also enjoys many of the same properties. In the section??? the effectiveness of the results is illustrated by a number of examples."}, {"heading": "4.4 Sequential Covering Number and Combinatorial Parameters", "text": "In statistical learning theory, learning ability for binary function classes (see Section?) is characterized by VapnikChervonenki's combinatorial dimension (42). For real function classes, the corresponding terms are scale-sensitive dimensions, such as P\u03b3 [43, 44]. For online learning, the idea is to characterize learning ability for binary predictions (35). Next, we define the dimensions of the Littlestone [34, 35] and propose its scale-sensitive versions for real-rated function classes. In the sequel, these combinatorial parameters are shown to control the growth of opaque numbers on trees. In the setting of the combinatorial prediction, the combinatorial parameters for precisely characterized function classes are shown (see Section?)."}, {"heading": "4.4.1 A Combinatorial Upper Bound", "text": "For the binary case (k = 1 below), a reader might find a similarity of theorems 31 and 33 with the classical results due to Sauer [45], Shelah [46] (also evaluated by Perles and Shelah) and Vapnik and Chervonenkis [42]. There are several approaches to prove what is often referred to as the Sauer-Shelah problem. We opt for proof in inductive style (e.g. Alon and Spencer [47]). However, the definition of trees requires more work than in the case of UK. Theorem 31. Let us leave F '0,. k'Z a class of functions with fatseq2 (F) = d'ThenNseq. We, n) d \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\". \"i\" i \"i\" i \"\" i \"i\". \"i\" i \"i\". \"i\" i \".\" i \"i\" i \".\" i \".\""}, {"heading": "4.4.2 Finite Class Lemma and the Chaining Method", "text": "Lemma 34 we will discuss this case in more detail. However, as we will show next, Lemma 34 goes far beyond the boundary functions which can only be used in a limited way. (For each finite quantity V of R-rated trees of depth n, we have that E [max v-V n] q = 1 vt () 2A is a simple consequence of the above problem that if F [0, 1] Z is a finite class, then for each given tree z \u2212 n we have this result [max f-F 1 n-n] n tf (zt ()] n E [max v-F (z) n-F (z) n-Z is a finite class, then for each given tree z \u2212 n we can prove that f-F is associated with an \"expert,\" this result combined with Theorem 24 yields a bound given63by the exponential weighted average forecaster algorithm (see [52])."}, {"heading": "4.5 Martingale Uniform Convergence", "text": "The property refers to the empirical averages that can adapt to the expected value of the function (samples taken i.i.d.) and to the universal averages of the empirical convergence of the empirical averages of the empirical averages for the expected values of the function drawn i.i.d Analogous sequential counterparts of these complexity classes can be used to apply the bound rate of the average convergence of the function to the average conditional expectation of the function values for the arbitrary distribution of the random variables."}, {"heading": "4.6 Charecterizing Learnability of Supervised Learning Problem", "text": "In this section, we will examine the specific case of the online supervised learning problem. In this setting, the instance space Z is of the form Z = X \u00b7 Y, where X is any input field and Y \u00b2 R. We assume that Y (1, 1) (of course, the boundary of 1 can be changed to any value). The target hypothesis can be H for the parent learning problem, which includes a series of functions ranging from X to any predicted label in [\u2212 1, 1] that is H [\u2212 1]. H (1, 1] X can indeed hold an arbitrary superset of H and the results if H = H (ie.) The proper learning situation we consider for the form (x, y)."}, {"heading": "4.6.1 Generic Algorithm for Supervised Learning Problem", "text": "We will present a general inappropriate learning algorithm for the online monitored environment, which will cause little regret if the functional class is learnable online."}, {"heading": "4.7 Examples", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.7.1 Example: Margin Based Regret", "text": "In the classical statistical setting, margin boundaries provide guarantees for the expected zero-one loss of a classifier based on the empirical margin zero-one error. These results form the basis for the theory of the large-margin classifiers (see [53, 54]). Recently, margin bounces were shown in the online setting based on the margin concept of the Littlestone dimension [35]. We show that our machinery can easily lead to margin boundaries for the binary classification games for the general functional class F based on their sequential wheel-maker complexity. We use ideas from [54] to do this. Proposal 49. For each class H target hypothesis [\u2212 1, 1] Z there is a randomized online algorithm A, so that for each sequence z1,..., zn, in which each zt = (xt, yt) Z \u00d7 {\u00b1 1}, played by the opponent, [n \u00b2 \u03b3 = 1 \u2212 1 (1)"}, {"heading": "4.7.2 Example : Neural Networks", "text": "The model of the neural network that we are looking at below and the 70 boundaries provided by us are analogous to those considered in the batch setting under [38]. We are now looking at a k-layer-1 normalized neural network. To this end, we leave the function class F1 by F1 = x 7 \u2192 j w1jxj, w = 1 \u2264 B1 and further for each 2 \u2264 i \u2264 k defineFi = x 7 \u2192 j wijn (fj (x)), j fj [Fi \u2212 1], j wi [1 \u2264 Bi Proposition 50. Say \u03c3: R 7 \u2192 [\u2212 1, 1] is L-Lipschitz, then Rseqn (Fk) \u2264 (k [k] i = 1 2Bi) Lk \u2212 1X."}, {"heading": "4.7.3 Example: Decision Trees", "text": "We are looking at the supervised learning game, in which the opponent provides instances from input area X and binary labels \u00b1 1 corresponding to the input, and the player decides trees with a maximum depth of d with decision functions from group C with a maximum depth of d with decision functions from C. The following sentence shows that there is a randomized learning algorithm that could possibly have little remorse for the supervised (binary) learning game, which with decision trees with a maximum depth of d with decision functions from C. The sentence is analogous to that in [38], which is considered in (classical) batch processing. Sentence 51. With T, we call the class of decision trees with a maximum depth of d with decision functions in"}, {"heading": "C. There exists a randomized online learning algorithm A such that for any sequence of instances z1 =", "text": "(x1, y1),.., zn = (xn, yn) (X \u00b7 {\u00b1 1}) n, played by the opponent, E [1n n n = 1 E\u03c4t (z1: t \u2212 1) [1 {\u03c4t (xt) 6 = yt}] \u2264 inf.: T 1 n: 1 1 {5 (xt) 6 = yt} + O (\u2211 l min (C: n (l), d log 3 / 2 (n) Rseqn (H))) + (3 + 2 log (Nblatt) \u221a n), where C: n (l) indicates the number of cases that reach the hand l and are correctly classified in the decision tree t, which minimizes the number of hands in this tree. 71"}, {"heading": "4.7.4 Example: Online Transductive Learning", "text": "Let F be a class of functions from Z to R. LetN. (\u03b1, F) = min {| G |: G-RZ s.t. () It is easy to verify that the number of F-RZ (\u03b1, n) n (4.7.1) is in fact G a minimum coverage of F on the scale \u03b1, where the coverage is targeted at all of Z. It is easy to verify that the coverage of V = {vg = g (z): g-G \u00b2 of the R-value trees is a coverage of F on z. Fix any coverage of F {\u00b1 1} n and f-F, and let g-G have such coverage of F on the scale \u03b1. We assert that the coverage V = {vg = g () of the R-value trees is a coverage of F."}, {"heading": "4.7.5 Example: Isotron", "text": "These models generalize linear and logistical regression, generalized linear models, and classification by linear threshold functions. For brevity, we will only describe the idealized SIM problem from [57]. In its \"batch\" version, we assume that the data will be revealed at once as a set {(xi, yi)} nt = 1% Rd \u00b7 R, where yt = u (< w, xt >) for some unknown w = Rd of the limited norm and an unknown, not decreasing u: R 7% R with a limited Lipschitz constant. In light of this data, the goal is to find iteratively the function u (< w, xt >) for some unknown w = Rd of the limited norm and an unknown, not decreasing u: Rd of the limited Lipschitz constant."}, {"heading": "4.8 Detailed Proofs and More Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.8.1 Proofs", "text": "The first step of the proof consists in following the minimax theorems for each pair of inf and sup: Vn (H, Z) = inf q1 (H, Z) = inf q1 (H, Z) = inf qn (H, Z) = inf q1 (H, Z) = inf qn (H, Z) = inf qn (H, Z) z z z z z z z (Z, zt) \u2212 p (Z, z) \u2212 n (Z) inf qn (H) n (H, H) zht (Z) zzt (Z) zzt (Z) zzt (Z) zzt (Z) zzt (Z) zzt (Z) zzt) zzt (Z) zzt (Z) zht) zht (Z) zht) zht (Z) zht (Z) zht (Z) zht (Z) zht) zht (Z) zht (Z)."}, {"heading": "4.8.2 Exponentially Weighted Average (EWA) Algorithm on Countable Experts", "text": "We consider here a version of the exponentially weighted expert algorithms for the individual expert (possibly infinite) number of experts and provide a limit to the expected regret of the randomized algorithm. Evidence of the result closely follows the finite case (e.g. [52, theorem 2.2]).Say we are with countable experts E1, E2,. where any expert can imagine a randomized / deterministic player strategy that, given history, produces an element of F. Again, we assume that F-1 [0, 1] Z contains only non-negative functions (corresponds to loss class).Denote f it the functional performance of experts in round t given history. The EWA algorithms we consider the access to countable experts and also need an initial weighting of each expert p1, p2,."}, {"heading": "4.9 Discussion", "text": "While in this chapter we have introduced tools for analyzing rates of online learning problems, which are analogous to the different measures of complexity for the statistical learning framework, as we have seen in the previous chapter, these tools cannot characterize learning ability in general. A similar situation applies to the online learning environment as well. While these tools characterize the learning ability of online learning problems and can even be used to obtain quotas for online learning problems, in general they could not characterize learning ability in general. In the previous chapter, we then turned to the concept of online stability to characterize learning ability and even provided a generic learning algorithm. Is there a term of stability that can be used to characterize learning ability in the online learning framework? Can we provide a generic algorithm for general learning problems in the online environment? Another interesting aspect is the question of fast rates for online learning problems."}, {"heading": "5.1 Convex Problems", "text": "It is the first time that we are able to hide, and it is the second time that we are able to hide."}, {"heading": "5.2 Various Convex Learning/Optimization Problems", "text": "In the following, we present examples of various convex learning / optimization problems that we consider in this paper."}, {"heading": "5.3 Discussion", "text": "Note that the H and X sets we are looking at are arbitrarily convex centrally symmetrical sets and need not be a priori related to each other. While the special case of when H = X? is, which occurs in the majority of theoretical analysis in existing literature, H and X are not dual to each other in many applications. Here, we offer a generic theoretical analysis of the non-dual case. Note that if H = X?, ZLip (X) corresponds to the usual convex Lipschitz problem, Zsmt (X) corresponds to the usual convex class, and finally Zucvx (2) corresponds to the convex functions that have overall convex learning and optimization problems that we have introduced in this chapter, and in the remaining chapters most of the problems that are considered in previous work."}, {"heading": "6.1 The Mirror Descent Update", "text": "Considering a strictly konvexen function: B 7 \u2192 R, the mirror descent algorithm, AMD is updated by the + 1 = argmin h'c (h | ht), H + 1 = argmin h'c (h, zt), H \u2212 ht > (6.1.1) or equivalent h't + 1 = (h'c). (h \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \""}, {"heading": "6.2 Online Mirror Descent", "text": "In this section, we describe the Online Mirror Desktop Algorithm AMD: \"We are interested in the Mirror Desktop Update given in the previous section.\" That is, AMD ({}) = h1 and further for each t-N and each z1,..., zt-1, AMD (z1,...): \".\" (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.). (.).). (. (.). (.). (.). (.). (.).). (.). (.). (.). (.). (.). (.). (. (.).). (.). (. (.).). (.). (. (.). (.). (.).). (.). (. (.). (.). (.). (. (.).). (.). (.). (. (.).). (.). (.). (.). (.).). (.). (.). (.). (.). (.). (.). (.). (.). (."}, {"heading": "6.3 Stochastic Mirror Descent", "text": "In the previous section we saw that we can successfully use online learning. (D = 1) D (S = 1) D (S = 1) S (S = 1) S (S = 1) S (S = 1) S (S = 1) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S S (S) S S (S) S S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S) S (S (S) S (S) S (S) S (S) S (S (S) S (S) S (S) S (S (S) S (S (S) S (S (S) S (S (S) S (S (S (S) S (S) S (S) S (S (S) S (S (S) S (S (S) S (S (S) S (S) S (S) S (S (S) S (S (S) S (S) S (S) S (S (S) S (S (S) S (S) S (S (S) S) S (S (S) S (S (S) S (S (S) S (S) S (S) S (S) S (S) S (S) S (S (S) S) S (S (S) S) S (S (S) S (S) S (S) S (S (S (S) S (S) S (S) S ("}, {"heading": "6.4 Mirror Descent for Offline Optimization", "text": "Note that offline convex optimization can be thought of as a special case of stochastic convex optimization, where the amount of distributions we are looking at are point distributions on a single instance of instance space Z. Based on this observation, we see that AMD can be used directly for offline convex optimization problems with the same guarantee of sub-optimality. In this thesis, we consider only the instance class ZLip (X) for the problem of offline convex optimization. The following consequence is a direct consequence of Lemma 59. Episode 62. Let us know: B 7 \u2192 R is not negative and q-uniform convex w.r.t. Standard for stochastic mirror descent with this algorithm, using h1 = argmin h-H (h) and B = (suph-H-H) 1 / p, we can guarantee that we have this algorithm for each case z-Zlimin (h) (AMh-H) (D) (h-H)."}, {"heading": "6.5 Detailed Proofs", "text": "The evidence for Lemma 55 (generalized MD-guarantee). Notice that for each h?? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h? h"}, {"heading": "6.6 Discussion", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "7.1 Value of the Linear Game", "text": "In this section we will show how the value of the linear online learning game is related to the value of other online learning games and also introduce some necessary definitions to represent the main outcome of this chapter. The following problem shows how to use online linear learning algorithms for other online learning problems (problems where the sub-gradients are in X).Tagma 63. Let us be an online learning algorithm for linear learning problems set by the instance. Let us use this for each convex learning problem set by the instance. Z so that for each h-H gradient and z-gradient learning algorithm can be constructed."}, {"heading": "7.2 Value and Martingale Type", "text": "It has been shown that the definition of the Martingale type (sometimes referred to as the hair type) of a Banach space and the optimal rates for the online optimization problem in which X and H are mutually dependent is closely related. In this section, we expand the classical notion of a Banach space (see about [65]) to one that maps the constellation for the pair (H?, X). Before proceeding with the definitions we would like to introduce some necessary notations, we will present the infinite sequence of characters drawn uniformly (i.e. each i has the same probability of being + 1 or \u2212 1). So 126across (xn) n represents a B? weighted tree of infinite depth, which is a sequence of mappings where each xn: {\u00b1 1} n 7 \u2192 B?."}, {"heading": "7.3 Martingale Type and Uniform Convexity", "text": "The classical concept of the Martingale type plays a central role in the study of the geometry of Banach spaces. In [65] it was shown that a Banach space has Martingale type p (the classical notion) if and only if there are uniformly convex functions with certain properties in this space (w.r.t. the norm of this Banach space).In this section we expand this result and show how the Martingale type of a pair (H?, X) is related to the existence of certain uniformly convex functions. Specifically, the following theorem shows that the concept of the Martingale type of the pair (H?, X) is equivalent to the existence of a non-negative function of a pair (H?, X)."}, {"heading": "7.4 Main Result : Optimality of Online Mirror Descent", "text": "In the previous chapter, we argued that if we can find an appropriate uniform convex function for use with the mirror descent algorithm, we can guarantee a decreasing regret, but the open question was when to find such a function and what is the rate to assess. In the section?? we can now combine these results to show that the mirror descent algorithm is a universal online learning algorithm for convex learning problems. Specifically, we show that whenever a problem is learnable online, the mirror descent algorithm can guarantee near-optimal rates: Theorem 71. If we apply some constant V > 0 and some q algorithms (H), Vn (H, X)."}, {"heading": "7.4.1 Smooth Loss Case", "text": "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *"}, {"heading": "L\u2217 is bounded as :", "text": "Rn (AMD), z1, z1, zn), zn), zn), zn (Zlin (X), zlin (X), zlin (X), zlin (X), zlin (X), zlin (X), zlin (V), zlin (X), zlin (X), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (lin), zlin (lin), (lin), lin (lin), zlin (V), lin (lin), lin (lin), zlin (lin), zlin (V), zlin (lin), zlin (lin), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V), zlin (V (V), zlin (V), zlin (V, zlin (V), zlin (V), zlin (V (V), zlin (V), zlin (V (V), zlin (zlin), zlin (V (V, zlin), zlin (V (V), zlin (V (V), zlin), zlin (V (zlin), zlin (V (V), zlin (V (V), zlin), zlin (V (zlin), zlin (V (V), zlin), zlin (V (zlin), zlin (V (V), zlin (V (V (V), zlin), zlin ("}, {"heading": "7.4.2 Uniformly Convex Loss Case", "text": "Lemma 74: For any other solution, there is a regulation function and a step size that deplore this solution. < n > q = q = q q functions (H, Zucvx (H, q) (X)). < n \u2032 (H, Zlin (X)) p \"p\" p \"(Vn (H, Zlin (X))) p\" p \"p\" p \"p,\" where the upper hand is over all X-rated trees u of depth. For simplicity, we now assume that \u00b2 p \"p\" p \"p\" (H, Zlin (X)) p \"p\" p. \"The following theorem shows that for certain q\" p \"p\" p \"p\" optimal rate.Theorem 75: If there is V > 0 and a > 0 such solution, that: Vn (H, Zucvx) ph \"h\" ph \"))."}, {"heading": "7.5 Examples", "text": "We show our results on various online learning problems specified by H and X."}, {"heading": "7.5.1 Example : `p non-dual pairs", "text": "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "7.5.2 Example : Non-dual Schatten norm pairs in finite dimensions", "text": "Exactly the same analysis as above can be performed for shadow p standards, i.e. if H = BS (p1), X = BS (p2) are the spheres of unity of the shadow p standard (the p-standard of singular values) for the matrix of dimensions d1 \u00b7 d2. We get the same results as in the table above (as upper limits of D2), with d = min {d1, d2}. These results, in turn, follow arguments similar to \"p-case and narrow constants for strong convexity parameters of the shadow standard [67]."}, {"heading": "7.5.3 Example : Non-dual group norm pairs in finite dimensions", "text": "In applications such as multitask learning, group norms such as the norm for the columns of h, q, 1 are frequently used on matrices h, Rk, and d, where (q, 1) norm means the \"1 norm of\" q norms for the columns of h. Popular choices are q = 2, \u221e. Here, it can be quite unnatural to use the dual norm (p, \u221e) to define the space X in which the data live. For example, we could consider H = B (q, 1) and X = B (\u221e, \u221e) = B \u00b2. In such a case, we can calculate that D2 (H, X) = 1 (k1 \u2212 1 q, log (d)) with the help of B (h) = 1q + r \u2212 2, h = 2 q, r, where r = log d \u2212 1."}, {"heading": "7.5.4 Example : Max Norm", "text": "In the online version of the matrix completion problem, an element of the matrix corresponding to X as a set of all matrices is revealed at any time, with a single element being 1 and the rest 0. Since we need X convex, we can take the absolute convex body of this matrix and use X as a unit element of '1 Ball. Its dual is the set \"W\" X? = maxi, j | Wi, j |. On the other hand, a matrix W is given, whose maximum norm is the value \"W\" max \"= minU, V: W = UV > (maxi\" Ui \"2) (maxj\" Vj \"2\"). The set \"H\" is the standard sphere below the maximum norm. \"As noted in [70], the maximum norm of the sphere is equivalent, up to a factor of two.\""}, {"heading": "7.5.5 Example : Interpolation Norms", "text": "Another interesting scenario is when the quantity H is achieved by interpolation between the standard balls of two other norms, such as 5.5 q and 4.2. Specifically, unit H can be considered as a ball of two such interpolated norms, the first type of interpolation norm being given by the following examples: (1) The second type of interpolation norm that can be taken into account is given by (2) the first type of interpolation norm: (1) the first type of interpolation norm is given by (2) the second type of interpolation norm is often used to induce certain structures or properties into the regulation; for example, one might want thrift together with the grouping effect in the linear predictors for which the elastic mesh type regulation is introduced by Zou and Hastie (71) (this is captured by interpolation between '1 and' 2 norms)."}, {"heading": "7.6 Detailed Proofs", "text": "The proof of lemmas 63 (AO 1.): \"We are all able to develop a new learning algorithm.\" (< n) < n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n (1) n n (1) n (1) n n (1) n) n (1) n n (1) n n (1) n n (1) n) n (1) n n n (1) n n (1) n n (1) n n n (1) n n (1) n n (n n n) n (1) n (n) n (n) n (1) n (n) n (n) n (1) n (n) n (1) n (n n) n (n) n (1) n (n) n (1) n (n) n (1) n n (1) n n (1) n n n (1) n n n (1) n n n n n (1) n n n n (1) n n n (1) n n n n (1) n n n (1) n n n (1) n n n n (1) n n (n) n) n (1) n (1) n (n) n n (1) n) n (1) n n n (1) n (n) n (1) n (n) n (1) n (1) n (n) n (1) n n n (1) n (n (1) n n n (1) n (1) n n (n) n (1) n (n n) n (1) n (n) n (1) n (1) n (1) n n n n (1) n n (n (1) n) n n (1 n) n (1) n n (1) n n n n n (1 n (1) n n (1) n n n n n n (1) n n (1) n) n n n n"}, {"heading": "7.7 Discussion", "text": "This year it is more than ever before in the history of the city."}, {"heading": "8.1 Lower Bounds for Statistical Learning Rates", "text": "We would like to point out that the linear learning class Zlin (X) idV (X) idH (X) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D) i.D (S) i.D (S) i.D (S) i.D) i.D (S) i.D) i.D (S) i.D) i.D (S) i.D (S) i.D) i.D i.D (S) i.D i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D) i.D (S) i.D (S) i.D (S) i.D) i.D (S) i.D (S) i.D (S) i.D) i.D (S) i.D (S) i.D) i.D (S) i.D (S) i.D (S) i.D) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (S) i.D (i.D) i.D (S) i.D (S) i.D (S) i.D (S) i.D"}, {"heading": "8.1.1 Lower Bounds for Smooth Losses", "text": "The following problem lowers the learning rate for non-negative smooth convex learning problems and also captures the dependence on the expected loss of the optimal hypothesis in target class H. This result is an analogy to Lemma 72 of the previous chapter. Lemma 87. Considering H-B, X-B? and L-A (0, 3 / 4] for any learning algorithm A, there is a distribution D over instances in Zsmt (1) (X) s.t. infh-H LD (h) \u2264 L-E and ES [LD (A (S)) \u2212 infh-H LD (h)] \u2265 L-4 (RiidnL-E (Flin (H, X) \u2212 12 RiidnL-E (Flin (H, X)))."}, {"heading": "8.2 Optimal Rates and Rademacher Type", "text": "The results of this section are analogous to the results in section 7.2.Definition 33. A pair (H?, X) of subsets of a vector space B? shall be of the Rademacher type p, if there is a constant C \u00b2 1, so that for each n \u00b2 N and each x1, x2,.., xn \u00b2 B?: E [...] subsets of a vector space B? i = 1 ixi \u00b2 \u00b2 pH \u00b2 pH \u00b2 (n \u00b2 pX \u00b2 pX). It can be shown that the convergence rate of i.d. random variables in Banach spaces is determined by the above idea of Rademacher type i.p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2."}, {"heading": "8.3 Main Result : Optimality of Stochastic Mirror Descent", "text": "In this section, we will see that most of the commonly encountered learning problems are indeed true, that the methods used in relation to statistical learning problems are almost optimal, but are not learnable online. In this section, however, we will see that the large classes of convex learning problems (in fact, most of the commonly encountered learning problems are actually true, that the statistical learning problems are optimal in terms of both rates and efficiency."}, {"heading": "8.3.1 Banach Lattices", "text": "In this section we show that if the Banach space is replaced by a standard, we can only partially be replaced by a Banach grid, then we can refer to a Banach grid that specifies a constant way: 1. For each x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x."}, {"heading": "8.3.2 Decoupling Inequalities", "text": "Another way to guarantee that Cp \u2264 GC iidp is suitable for some infinite approaches is to use the so-called decoupling inequalities (see [78, 79] for more details).159Definition 36. We say that a constant space with the same qualities as a constant B > 0 is satisfactory if the constant B > 0 is satisfactory, if the constant B > 0 is satisfactory, if the constant B > 0 is satisfactory, if the constant B > 0 is satisfactory, if the constant B > 0 is satisfactory, if the constant B > 0 is satisfactory, if the constant B > 0 is satisfactory, if the constant B > 0 is satisfactory, if the constant B is satisfactory, if the constant -quality > 0 is satisfactory."}, {"heading": "8.3.3 Optimality of Mirror Descent in Terms of Efficiency", "text": "In this section, we argue that the reflection is optimal not only in terms of the learning rate, but also in terms of efficiency."}, {"heading": "8.4 Examples", "text": "First of all, we note that all the examples we considered in the previous chapter were banach grids with finite co-type and are therefore nearly optimal for all these problems according to theorems 90, 104 and 91, both in terms of speed and number of access to gradients, for convex Lipschitz problems, supervised learning problems and non-negative smooth problems. We will see below that in these examples we not only come close to optimality, but that Cp and C iidp are actually within a fixed numerical constant factor of each other. Hence, there are not even any spatially dependent hidden factors beyond the logarithmic factor."}, {"heading": "8.4.1 Example : `p non-dual pairs", "text": "In the previous chapter we have given the characterization of the constants D2 (corresponding to 1 / \u221a n rates in the online setting) for the \"p-pairs.\" Remember the setting that H is the unified sphere of the \"dp1 sphere\" and X is the double sphere of the \"dp2 standard.\" It turns out that for \"p-norms,\" if p [1, 2] has a universal constant for the 1-decoupling according to sentence 96. On the other hand, the type constant of \"p-spaces\" is in order \u221a p and so we can conclude that the table itself is essentially narrow for the statistical learning environment, because Martingale type constant (Cp) and type constant (C iidp) lie within a fixed numerical constant factor of each other."}, {"heading": "8.4.2 Example : Non-dual Schatten norm pairs in finite dimensions", "text": "As we have shown in the previous chapter, the constants Dp (Cp, Vp, etc.) for shadow norms were the same as those for \"p norms in the online learning environment. However, as we have seen in the previous section, the constants for\" p norms agree in statistical and online frameworks. However, since lower limits for \"p norms can be converted (by diagonalization) into at least the same lower limit for shadow norms, we can again conclude that the rates of mirror decline are nearly optimal in the statistical case, and that Cp and C iidp are within a fixed numerical constant factor of each other. 162"}, {"heading": "8.4.3 Example : Non-dual group norm pairs in finite dimensions", "text": "For the group norm case, which uses the decoupling of inequalities for \"p together with Proposition 95, we can again show that Cp and C iidp lie within a constant factor of each other, which guarantees a tightness of the mirror lowering for these problems in the statistical setting."}, {"heading": "8.4.4 Computational Efficiency Issues", "text": "So far, we have used the number of gradient calculations to argue that mirror descent is optimal in terms of efficiency. Note that we have shown optimality with the help of the mirror descent algorithm, which has a simple update step that uses only the previous hypothesis and the gradient of loss of the hypothesis in each round. Therefore, the time complexity of the update in each round is in the order of the effective dimension (as in the \"p case, it is linear in d\" example), so in these cases one can again translate the oracle complexity into the time complexity of the algorithm. One for \"case, one can even show that the time complexity is nearly optimal. However, this is not always the case, it could be that the complexity of the mirror descent update step (which depends on the size of the mirror) is large enough for the time complexity of the algorithm to be inflated. One for\" cases, one can even show that the time complexity is nearly optimal. However, this is not always the case, it could be that the complexity of the update step of the mirror descent is linear in d."}, {"heading": "8.5 Detailed Proofs", "text": "S. (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S). (S)."}, {"heading": "8.6 Discussion", "text": "In this context, it should be noted that this is not a purely formal matter, but a purely formal matter, which is a purely formal matter."}, {"heading": "9.1 Oracle-based Offline Convex Optimization", "text": "A typical example of this type of procedure is the way in which we inform ourselves in a certain way about the functioning of the functioning of the functioning, which generally implements the exact computational complexity of these methods and may not even be possible in full generality. In order to grasp the efficiency of the optimization processes in a general way, we consider the oracle as an optimization problem and associated oracle complexity of the problem. To this end, we first formally define an oracle. Such models have been introduced and analyzed in [1]."}, {"heading": "9.2 Lower Bounding Oracle Complexity: Connections to Statistical", "text": "(D) We agree that we can carry out the learning processes in individual classes. (D) We agree that we can carry out the learning processes in classes 1, 2, 3, 4, 5, 5, 6, 6, 6, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 11, 12, 11, 12, 11, 11, 11, 11, 12, 11, 11, 12, 11, 12, 11, 11, 12, 11, 11, 11, 11, 11, 12, 12, 11, 12, 11, 11, 12, 11, 11, 11, 11, 12, 12, 11, 11, 12, 11, 11, 12, 11, 11, 12, 11, 11, 11, 12, 11, 11, 11, 11, 11, 11, 12, 12, 11, 11, 12, 11, 11, 12, 11, 11, 12, 11, 11, 12, 11, 11, 11, 11, 12, 12, 11, 11, 12, 11, 11, 12, 11, 11, 12, 11, 11, 12, 11, 12, 11, 11, 11, 12, 11, 11, 12, 11, 11, 12, 12, 11, 12, 11, 11, 12, 11, 11, 12, 11, 11, 12, 11, 11, 11, 12, 11, 12, 11, 11, 11, 12, 11, 11, 12, 11, 11, 11, 12, 11, 11, 12, 11, 12, 11, 11, 12, 11, 12, 11, 11, 12, 11, 11, 11, 12, 11, 11, 12, 12, 11, 11, 11, 12, 12, 11, 11, 12, 11, 12, 11, 12, 11, 11, 11, 12, 11, 12, 11, 11, 12, 11, 11, 11, 12, 12, 11, 11, 12, 11, 11, 11, 12,"}, {"heading": "9.3 Main Result : Optimality of Mirror Descent for Offline Convex", "text": "The following theorem shows that we can do this for any type of problem, and that we can also do this if there is a problem that applies to all 1 < p \u2212 1). Then there is a function and step size that we use stochastic mirroring (, AMD, Z). rProof we use Theorem 102 to bound riidn (X)."}, {"heading": "9.4 Statistical Learning With Distributed Oracles", "text": "In fact, in the past, we have had a number of problems, most of which have not yet been able to reform themselves. (...) In fact, in the past, we have had a multitude of problems. (...) In the past, we have had problems. (...) In the past, we have had problems. (...) In the past, we have had problems. (...) In the past, we have had problems. (...) In the past, we have had problems. (...) We have had problems in the past. (...) We have had problems again and again. \"(...)\" We have had problems in the past. \""}, {"heading": "9.5 Detailed Proofs", "text": "The proof of Lemma 101 (x1, s1) is essentially a vdery simple modification of the one by Nemirovskiand Yudin in Section 4.4.2 of [1]. It is a way in which we must deal with the non-dual case, with a few minor changes in relation to obesity. (x1, s1) To prove the lower limit, we must first set the maximum limit of 1,. (xm). (x1, s1, s1). (x1, s1). (xxi, sxi). (xi). (xi, \u2212 si)."}, {"heading": "9.6 Discussion", "text": "The main conclusion of this chapter is that in most reasonable cases, when the dimension of vector space B is large enough, the stochastic mirror descension algorithm is nearly optimal even for offline convex optimization, e.g. for space ZLip (X). Furthermore, we show that for statistical convex learning problems via the instance space ZLip (X), even when considering learning algorithms that use distributed oracles (i.e. distributed computation of local oracle information such as gradients, etc.), the mirror descensus is still approximately optimal and parallelization is unhelpful.186Chapter 10Conclusion and future workIn this section, we outline some important questions related to the work in this dissertation. We also discuss some other research directions. Finally, we summarize and give some concluding remarks."}, {"heading": "10.1 Open Problems", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10.1.1 Online Optimization and Stability", "text": "Another direction that needs to be explored is the question of online learning ability in the general learning environment. In the statistical paradigm, we used the tool of stability and characteristics of asymptotic empirical minimization of the learning rule to determine learning ability in the general learning environment. We would like to investigate the problem of online learning ability in the general learning environment along similar lines. Question 1. Are there characteristics that are comparable to stability and AERM characteristics in the online paradigm and guarantee online learning ability in the general learning environment? Question 2. Can we provide a generic strategy for learners in the online learning environment that guarantees that repentance is diminished whenever the problem is learnable?"}, {"heading": "10.1.2 Upper Bounding Oracle Complexity in Terms of Fat-Shattering Dimension", "text": "In the second part of the dissertation, we have shown that the oracle complexity of the offline problem of convex optimization, moff (, ZLip (X)), is undercut by the fat-shaking dimension of the corresponding linear class Flin (H, X). Thus, we have shown that at least with supervised learning problems, if one can efficiently optimize the convex function corresponding to the class ZLip (X), one can also learn statistically and efficiently. In the same chapter, we have also shown that in most reasonable cases, if the dimension is large enough, the mirror descent is almost optimal even for offline optimization. On the basis of the results in the dissertation one187, one can also conclude that for these large-dimensional cases moff (, ZLip (X)) can also be limited by O (fat)."}, {"heading": "10.2 Further Directions", "text": "The thesis mainly deals with the history of learning from the perspective of optimization and answers questions about learning ability. However, there were a few results that emerged from results and techniques provided in this thesis, and we outline a few follows.We mainly considered two extreme scenarios, while looking at statistical and online learning frameworks. In the statistical framework, instances were selected iid and in the online learning framework.It is interesting to consider the intermediate scenarios in which the learner is not faced with a completely unfavorable opponent, but is also not faced with iid sampling of instances. Perhaps the opponent has some limitations regarding instances that can be selected, or selects instances in a stochastic way that is more complex than iid sampling. Such a scenario is analyzed in [88] on the basis of techniques in Chapter 4. Another orthogonal way in which the results in the chapter were expanded was it games beyond the online mirror, such as Blackwells can be used in 89?"}, {"heading": "10.3 Summary", "text": "An important question in the field of theoretical machine learning is that of learning ability and learning rates. We have examined this question for various learning processes both in the statistical and online learning frameworks. In the statistical learning frameworks, we provide the first general characterization of learning ability in the general environment, introducing various complexity measures analogous to the 188s in the statistical learning frameworks. We also offer a characterization of online learning ability for real-world verified learning problems. An integral part of machine learning is optimization, which we are able to introduce various complexity measures."}, {"heading": "Appendix A", "text": "(1). (1). (1). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2. (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2).). (2). (2). (2). (2). (2). (2).). (2). (2). (2).). (2). (2).). (2). (2).). (2). (2).). (2. (2). (2).). (2).). (2.).). (2.). (2.).). (2.). (2.).). (2.).). (2.).). (2."}], "references": [{"title": "Problem complexity and method efficiency in optimization", "author": ["A. Nemirovski", "D. Yudin"], "venue": "Nauka Publishers, Moscow,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1978}, {"title": "Stochastic convex optimization", "author": ["S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan"], "venue": "Conference on Learning Theory,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Learnability and stability in the general learning setting", "author": ["S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan"], "venue": "Proceedings of the 22nd Annual Conference on Computational Learning Theory,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Learnability, stability and uniform convergence", "author": ["Shai Shalev-Shwartz", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Online learning: Random averages, combinatorial parameters, and learnability", "author": ["A. Rakhlin", "K. Sridharan", "A. Tewari"], "venue": "Neural Information Processing Systems (NIPS),", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "On the universality of online mirror descent. Arxiv", "author": ["Nathan Srebro", "Karthik Sridharan", "Ambuj Tewari"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Convex games in Banach spaces", "author": ["K. Sridharan", "A. Tewari"], "venue": "Proceedings of the 23nd Annual Conference on Learning Theory,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "The Nature of Statistical Learning Theory", "author": ["V.N. Vapnik"], "venue": "Springer,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "Learnability and the Vapnik-Chervonenkis dimension", "author": ["Anselm Blumer", "Andrzej Ehrenfeucht", "David Haussler", "Manfred K. Warmuth"], "venue": "Journal of the Association for Computing Machinery,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1989}, {"title": "Scale-sensitive dimensions, uniform convergence, and learnability", "author": ["N. Alon", "S. Ben-David", "N. Cesa-Bianchi", "D. Haussler"], "venue": "Journal of the ACM, 44(4):615\u2013631,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1997}, {"title": "Toward efficient agnostic learning", "author": ["M.J. Kearns", "R.E. Schapire", "L.M. Sellie"], "venue": "Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, pages 341\u2013352, July", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1992}, {"title": "Decision theoretic generalizations of the PAC model for neural net and other learning applications", "author": ["D. Haussler"], "venue": "Information and Computation, 100(1):78\u2013150,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1992}, {"title": "Chervonenkis", "author": ["V.N. Vapnik", "A. Ya"], "venue": "On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and its applications, XVI(2):264\u2013280,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1971}, {"title": "Neural Network Learning: Theoretical Foundations", "author": ["Martin Anthony", "Peter Bartlet"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "Statistical Learning Theory", "author": ["V.N. Vapnik"], "venue": "Wiley,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "The sizes of compact subsets of Hilbert space and continuity of Gaussian processes", "author": ["R.M. Dudley"], "venue": "Journal of Functional Analysis, 1(3):290\u2013330,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1967}, {"title": "Sur les probl\u00e8mes aux d\u00e9riv\u00e9es partielles et leur signification physique", "author": ["J. Hadamard"], "venue": "Princeton University Bulletin, 13:49\u201352,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1902}, {"title": "On the stability of inverse problems", "author": ["A.N. Tikhonov"], "venue": "Dolk. Akad. Nauk SSSR, 39(5):195\u2013198,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1943}, {"title": "A technique for the numerical solution of certain integral equations of the first kind", "author": ["D.L. Phillips"], "venue": "Journal of the ACM, 9(1):84\u201397,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1962}, {"title": "A finite sample distribution-free performance bound for local discrimination rules", "author": ["W. Rogers", "T. Wagner"], "venue": "Annals of Statistics, 6(3):506\u2013514,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1978}, {"title": "A Probabilistic Theory of Pattern Recognition", "author": ["L. Devroye", "L. Gy\u00f6rfi", "G. Lugosi"], "venue": "Springer,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1996}, {"title": "Bias, variance, and arcing classifiers", "author": ["Leo Breiman"], "venue": "Technical Report 460,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1996}, {"title": "Algorithmic stability and sanity-check bounds for leave-one-out crossvalidation", "author": ["M. Kearns", "D. Ron"], "venue": "Neural Computation, 11(6):1427\u20131453,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1999}, {"title": "Stability and generalization", "author": ["Olivier Bousquet", "Andr\u00e9 Elisseeff"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Almost-everywhere algorithmic stability and generalization error", "author": ["S. Kutin", "P. Niyogi"], "venue": "Proceedings of the 18th Conference in Uncertainty in Artificial Intelligence, pages 275\u2013282,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "Stability results in learning theory", "author": ["S. Rakhlin", "S. Mukherjee", "T. Poggio"], "venue": "Analysis and Applications, 3(4):397\u2013419,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization", "author": ["S. Mukherjee", "P. Niyogi", "T. Poggio", "R. Rifkin"], "venue": "Advances in Computational Mathematics, 25(1-3):161\u2013193,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "Fast rates for regularized objectives", "author": ["K. Sridharan", "N. Srebro", "S. Shalev-Shwartz"], "venue": "Advances in Neural Information Processing Systems 22,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": "ICML, pages 928\u2013936,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2003}, {"title": "Learnability and stability in the general learning setting", "author": ["S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan"], "venue": "Proceedings of the 22nd Annual Conference on Computational Learning Theory,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "On the convergence rate of good-turing estimators", "author": ["D.A. McAllester", "R.E. Schapire"], "venue": "Proceedings of the Thirteenth Annual Conference on Computational Learning Theory,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2000}, {"title": "Multiclass learnability and the erm principle", "author": ["Amit Daniely", "Sivan Sabato", "Shai Ben-David", "Shai Shalev-Shwartz"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm", "author": ["N. Littlestone"], "venue": "Machine Learning, 2(4):285\u2013318, 04", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1988}, {"title": "Agnostic online learning", "author": ["S. Ben-David", "D. Pal", "S. Shalev-Shwartz"], "venue": "Proceedings of the 22th Annual Conference on Learning Theory,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "A stochastic view of optimal regret through minimax duality", "author": ["J. Abernethy", "A. Agarwal", "P. Bartlett", "A. Rakhlin"], "venue": "Proceedings of the 22nd Annual Conference on Learning Theory,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2009}, {"title": "Rademacher processes and bounding the risk of function learning", "author": ["V. Koltchinskii", "D. Panchenko"], "venue": "High Dimensional Probability II, 47:443\u2013459,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2000}, {"title": "Rademacher and gaussian complexities: risk bounds and structural results", "author": ["P.L. Bartlett", "S. Mendelson"], "venue": "J. Mach. Learn. Res., 3:463\u2013482,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2003}, {"title": "A few notes on statistical learning theory", "author": ["S. Mendelson"], "venue": "S. Mendelson and A. J. Smola, editors, Advanced Lectures in Machine Learning, LNCS 2600, Machine Learning Summer School 2002, Canberra, Australia, February 11-22, pages 1\u201340. Springer,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2003}, {"title": "Uniform Central Limit Theorems", "author": ["R.M. Dudley"], "venue": "Cambridge University Press,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1999}, {"title": "Probability in Banach Spaces", "author": ["M. Ledoux", "M. Talagrand"], "venue": "Springer-Verlag, New York,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1991}, {"title": "Chervonenkis", "author": ["V.N. Vapnik", "A. Ya"], "venue": "On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and its Applications, 16(2):264\u2013280,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1971}, {"title": "Scale-sensitive dimensions, uniform convergence, and learnability", "author": ["N. Alon", "S. Ben-David", "N. Cesa-Bianchi", "D. Haussler"], "venue": "Journal of the ACM, 44:615\u2013631,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1997}, {"title": "Fat-shattering and the learnability of real-valued functions", "author": ["P.L. Bartlett", "P.M. Long", "R.C. Williamson"], "venue": "Journal of Computer and System Sciences, 52(3):434\u2013452,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1996}, {"title": "On the density of families of sets", "author": ["N. Sauer"], "venue": "J. Combinatorial Theory, 13:145\u2013147,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1972}, {"title": "A combinatorial problem: Stability and order for models and theories in infinitary languages", "author": ["S. Shelah"], "venue": "Pac. J. Math, 4:247\u2013261,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 1972}, {"title": "The Probabilistic Method", "author": ["N. Alon", "J. Spencer"], "venue": "John Wiley & Sons, 2nd edition,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2000}, {"title": "Entropy and the combinatorial dimension", "author": ["S. Mendelson", "R. Vershynin"], "venue": "Inventiones mathematicae, 152:37\u201355,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2003}, {"title": "Some limit theorems for empirical processes", "author": ["E. Gin\u00e9", "J. Zinn"], "venue": "Annals of Probability, 12(4):929\u2013 989,", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1984}, {"title": "Empirical Processes in M-Estimation", "author": ["S.A. van de Geer"], "venue": null, "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2000}, {"title": "Some applications of concentration inequalities to statistics", "author": ["P. Massart"], "venue": "Annales de la Facult\u00e9 des Sciences de Toulouse, IX(2):245\u2013303,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2000}, {"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": "Cambridge University Press,", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2006}, {"title": "Boosting the margin: A new explanation for the effectiveness of voting methods", "author": ["R.E. Schapire", "Y. Freund", "P. Bartlett", "W.S. Lee"], "venue": "The Annals of Statistics, pages 322\u2013330,", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1997}, {"title": "Empirical margin distributions and bounding the generalization error of combined classifiers", "author": ["V. Koltchinskii", "D. Panchenko"], "venue": "Annals of Statistics, 30(1):1\u201350,", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2002}, {"title": "From batch to transductive online learning", "author": ["S.M. Kakade", "A. Kalai"], "venue": "NIPS,", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2005}, {"title": "On prediction of individual sequences", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": "Annals of Statistics, pages 1865\u20131895,", "citeRegEx": "56", "shortCiteRegEx": null, "year": 1999}, {"title": "The isotron algorithm: High-dimensional isotonic regression", "author": ["A. Tauman Kalai", "R. Sastry"], "venue": "Proceedings of the 22th Annual Conference on Learning Theory,", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2009}, {"title": "\u03b5-entropy and \u03b5-capacity of sets in function spaces", "author": ["A.N. Kolmogorov", "V.M. Tikhomirov"], "venue": "Uspekhi Matematicheskikh Nauk, 14(2):3\u201386,", "citeRegEx": "58", "shortCiteRegEx": null, "year": 1959}, {"title": "Local rademacher complexities", "author": ["P.L. Bartlett", "O. Bousquet", "S. Mendelson"], "venue": "Annals of Statistics, 33 (4):1497\u20131537,", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2005}, {"title": "Smoothness, low-noise and fast rates", "author": ["Nathan Srebro", "Karthik Sridharan", "Ambuj Tewari"], "venue": null, "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2010}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["N. Cesa-Bianchi", "A. Conconi", "C. Gentile"], "venue": "IEEE Trans. on Information Theory, 50(9):2050\u20132057, September", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2004}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["E. Hazan", "A. Kalai", "S. Kale", "A. Agarwal"], "venue": "Proceedings of the Nineteenth Annual Conference on Computational Learning Theory,", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2006}, {"title": "Logarithmic regret algorithms for strictly convex repeated games", "author": ["S. Shalev-Shwartz", "Y. Singer"], "venue": "Technical report, The Hebrew University,", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2007}, {"title": "Martingales with values in uniformly convex spaces", "author": ["G. Pisier"], "venue": "Israel Journal of Mathematics, 20(3\u20134): 326\u2013350,", "citeRegEx": "65", "shortCiteRegEx": null, "year": 1975}, {"title": "Martingales in banach spaces (in connection with type and cotype)", "author": ["G. Pisier"], "venue": "Winter School/IHP Graduate Course,", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2011}, {"title": "Sharp uniform convexity and smoothness inequalities for trace norms", "author": ["Keith Ball", "Eric A. Carlen", "Elliott H. Lieb"], "venue": "Invent. Math.,", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 1994}, {"title": "Maximum-margin matrix factorization", "author": ["Nathan Srebro", "Jason D.M. Rennie", "Tommi S. Jaakola"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2005}, {"title": "Rank, trace-norm and max-norm", "author": ["Nathan Srebro", "Adi Shraibman"], "venue": "In Proceedings of the 18th Annual Conference on Learning Theory,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 2005}, {"title": "Regularization and variable selection via the elastic net", "author": ["Hui Zou", "Trevor Hastie"], "venue": "Journal of the Royal Statistical Society, Series B,", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 2005}, {"title": "Sparse and low-rank matrix decompositions", "author": ["V. Chandrasekaran", "S. Sanghavi", "P. Parrilo", "A. Willsky"], "venue": "IFAC Symposium on System Identification,", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2009}, {"title": "A Dirty Model for Multi-task Learning", "author": ["Ali Jalali", "Pradeep Ravikumar", "Sujay Sanghavi", "Chao Ruan"], "venue": "In NIPS,", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2010}, {"title": "Type, cotype and k-convexity", "author": ["Bernard Maurey"], "venue": "VOLUME", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2003}, {"title": "Classical Banach Spaces I and II. Classics in Mathematics", "author": ["Joram Lindenstrauss", "Lior Tzafriri"], "venue": null, "citeRegEx": "75", "shortCiteRegEx": "75", "year": 1996}, {"title": "Theoremes de factorisation dans les espaces reticules", "author": ["J.L. Krivine"], "venue": "Seminaire MAurey-Schwartz 1973- 74: Exp. Nos. 22 and 23, Ecole Polytech, Paris,", "citeRegEx": "76", "shortCiteRegEx": null, "year": 1974}, {"title": "Series de variables aleatoires vectorielles independantes et proprietes geometriques des espaces de banach", "author": ["Bernard Maurey", "Gilles Pisier"], "venue": "Studia Math.,", "citeRegEx": "77", "shortCiteRegEx": "77", "year": 1976}, {"title": "Random martingale transform inequalities", "author": ["D.J.H. Garling"], "venue": "Probability in Banach spaces 6 (Sandbjerg, 1986), (20):pp. 101\u2013119,", "citeRegEx": "78", "shortCiteRegEx": null, "year": 1986}, {"title": "Vector-valued decoupling and the burkholder-davis gundy inequality", "author": ["Sonja Cox", "Mark Veraar"], "venue": "Technical Report arXiv:1107.2218,", "citeRegEx": "79", "shortCiteRegEx": "79", "year": 2011}, {"title": "Some remarks on tangent martingale difference sequences in l1-spaces", "author": ["Sonja Cox", "Mark Veraar"], "venue": "Technical Report", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 2007}, {"title": "On a domination of sums of random variables by sums of conditionally independent ones", "author": ["Pawe? Hitczenko", "Stephen J. Montgomery-Smith"], "venue": "Mathematical Proceedings of the Cambridge Philosophical Society,", "citeRegEx": "81", "shortCiteRegEx": "81", "year": 1996}, {"title": "On a domination of sums of random variables by sums of conditionally independent ones", "author": ["Pawel Hitczenko"], "venue": "The Annals of Probability,", "citeRegEx": "82", "shortCiteRegEx": "82", "year": 1994}, {"title": "Comparison of moments for tangent sequences of random variables", "author": ["Pawel Hitczenko"], "venue": "Probability Theory and Related Fields,", "citeRegEx": "83", "shortCiteRegEx": "83", "year": 1988}, {"title": "Efficient online learning via randomized rounding", "author": ["Nicol Cesa-Bianchi", "Ohad Shamir"], "venue": "Neural Information Processing System,", "citeRegEx": "84", "shortCiteRegEx": "84", "year": 2011}, {"title": "Some random series of functions", "author": ["J.-P. Kahane"], "venue": "2nd edition,", "citeRegEx": "85", "shortCiteRegEx": null, "year": 1985}, {"title": "Martingale transforms", "author": ["D.L. Burkholder"], "venue": "The Annals of Mathematical Statistics, 37(6):pp. 1494\u20131504,", "citeRegEx": "86", "shortCiteRegEx": null, "year": 1966}, {"title": "Chapter 1 basic concepts in the geometry of banach spaces. volume 1 of Handbook of the Geometry of Banach Spaces, pages 1 \u2013 84", "author": ["William B. Johnson", "Joram Lindenstrauss"], "venue": "Elsevier Science B.V.,", "citeRegEx": "87", "shortCiteRegEx": "87", "year": 2001}, {"title": "Online learning: Stochastic and constrained adversaries", "author": ["Alexander Rakhlin", "Karthik Sridharan", "Ambuj Tewari"], "venue": null, "citeRegEx": "88", "shortCiteRegEx": "88", "year": 2011}, {"title": "Complexity-based approach to calibration with checking rules", "author": ["Dean Foster", "Alexander Rakhlin", "Karthik Sridharan", "Ambuj Tewari"], "venue": null, "citeRegEx": "90", "shortCiteRegEx": "90", "year": 2011}, {"title": "Better mini-batch algorithms via accelerated gradient methods", "author": ["Andrew Cotter", "Nathan Srebro", "Ohad Shamir", "Karthik Sridharan"], "venue": null, "citeRegEx": "91", "shortCiteRegEx": "91", "year": 2011}, {"title": "Rademacher and Gaussian complexities: Risk bounds and structural results", "author": ["P.L. Bartlett", "S. Mendelson"], "venue": "JMLR, 3:463\u2013482,", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2002}, {"title": "Some applications of concentration inequalities to statistics", "author": ["P. Massart"], "venue": "Annales de la Facult\u00e9 des Sciences de Toulouse, IX(2):245\u2013303,", "citeRegEx": "93", "shortCiteRegEx": null, "year": 2000}, {"title": "Scale-sensitive dimensions, uniform convergence, and learnability", "author": ["N. Alon", "S. Ben-David", "N. Cesa-Bianchi", "D. Haussler"], "venue": "FOCS, 0:292\u2013301,", "citeRegEx": "94", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 0, "context": "Specifically in the second half of the dissertation, focusing on convex learning problems, we show that mirror descent method originally introduced for convex optimization problems by Nemirovski and Yudin [1], is always near optimal for online learning problems, near optimal for most reasonable statistical learning problems and even near optimal for several high dimensional offline convex optimization problems.", "startOffset": 205, "endOffset": 208}, {"referenceID": 0, "context": "The next chapter, Chapter 6 introduces the mirror descent methods (see [1]) for the statistical and online convex learning problems described in the previous chapter and provides upper bounds on learning rate for them.", "startOffset": 71, "endOffset": 74}, {"referenceID": 1, "context": "Early versions of the results can be found in [2, 3].", "startOffset": 46, "endOffset": 52}, {"referenceID": 2, "context": "Early versions of the results can be found in [2, 3].", "startOffset": 46, "endOffset": 52}, {"referenceID": 3, "context": "See [4] for later version which is closer to the one presented in the chapter.", "startOffset": 4, "endOffset": 7}, {"referenceID": 4, "context": "The results in Chapter 4 are from joint work with Alexander Rakhlin and Ambuj Tewari and can be found in [5].", "startOffset": 105, "endOffset": 108}, {"referenceID": 5, "context": "In the second part of the dissertation, few of the result from Chapter 6 can be found in [6].", "startOffset": 89, "endOffset": 92}, {"referenceID": 6, "context": "Relating basic concept of martingale type and certain online convex learning problems was first done in [7].", "startOffset": 104, "endOffset": 107}, {"referenceID": 5, "context": "In [6] the result of universality and near optimality of mirror descent method from Chapter 7 is provided.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "In this chapter we consider the problem of statistical learning in the general learning problems introduced by [8] where we would like to minimize a population risk functional (stochastic objective)", "startOffset": 111, "endOffset": 114}, {"referenceID": 8, "context": "2) for all h \u2208 H converge uniformly to the population risk ([9, 10]).", "startOffset": 60, "endOffset": 67}, {"referenceID": 9, "context": "2) for all h \u2208 H converge uniformly to the population risk ([9, 10]).", "startOffset": 60, "endOffset": 67}, {"referenceID": 10, "context": "It is a direct generalization of agnostic PAC-learnability ([11]) to Vapnik\u201ds General Setting of Learning as studied by [12] and others.", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "It is a direct generalization of agnostic PAC-learnability ([11]) to Vapnik\u201ds General Setting of Learning as studied by [12] and others.", "startOffset": 120, "endOffset": 124}, {"referenceID": 12, "context": "For binary classification problems (where Z = X \u00d7 {0, 1}, each hypothesis is a mapping from X to {0, 1}, and `(h; (x, y)) = 1{h(x)6=y}), [13] showed that the finiteness of a simple combinatorial measure known as the VC-dimension implies uniform convergence.", "startOffset": 137, "endOffset": 141}, {"referenceID": 9, "context": "mension at all finite scales now replaces the property of having finite VC-dimension, but the basic equivalence still holds: a problem is learnable if and only if uniform convergence holds ([10], see also [14], Chapter 19).", "startOffset": 190, "endOffset": 194}, {"referenceID": 13, "context": "mension at all finite scales now replaces the property of having finite VC-dimension, but the basic equivalence still holds: a problem is learnable if and only if uniform convergence holds ([10], see also [14], Chapter 19).", "startOffset": 205, "endOffset": 209}, {"referenceID": 14, "context": "To justify the necessity of uniform convergence even in the General Learning Setting, Vapnik attempted to show that in this setting, learnability with the ERM learning rule is equivalent to uniform convergence ([15]).", "startOffset": 211, "endOffset": 215}, {"referenceID": 15, "context": "Pollard\u2019s bound [16] and Dudley integral bound [17] can be used to bound rates of uniform convergence in terms of covering numbers.", "startOffset": 47, "endOffset": 51}, {"referenceID": 19, "context": "In the context of modern learning theory1, the use of stability can be traced back at least to the work of [21], which noted that the sensitivity of a learning algorithm with regard to small changes in the sample controls the variance of the leave-one-out estimate.", "startOffset": 107, "endOffset": 111}, {"referenceID": 20, "context": "These results were later extended to other \u201clocal\u201d learning algorithms (see [22] and references therein).", "startOffset": 76, "endOffset": 80}, {"referenceID": 21, "context": "In addition, practical methods have been developed to introduce stability into learning algorithms, in particular the Bagging technique introduced by [23].", "startOffset": 150, "endOffset": 154}, {"referenceID": 22, "context": "[24] showed that an algorithm operating on a hypothesis class with finite VC dimension is also stable (under a certain definition of stability).", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[25] introduced a strong notion of stability (denoted as uniform stability) and showed that it is a sufficient condition for learnability, satisfied by popular learning algorithms such as regularized linear classifiers and regressors in Hilbert spaces (including several variants of SVM).", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[26] introduced several weaker variants of stability, and showed how they are sufficient to obtain generalization bounds for algorithms stable in their sense.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "A more recent line of work ([27],[28]) studied stability as a necessary condition for learnability.", "startOffset": 28, "endOffset": 32}, {"referenceID": 26, "context": "A more recent line of work ([27],[28]) studied stability as a necessary condition for learnability.", "startOffset": 33, "endOffset": 37}, {"referenceID": 16, "context": "The necessity of stability for so-called inverse problems to be well posed was first recognized by [18].", "startOffset": 99, "endOffset": 103}, {"referenceID": 17, "context": "The idea of regularization (that is, introducing stability into ill-posed inverse problems) became widely known through the works of [19] and [20].", "startOffset": 133, "endOffset": 137}, {"referenceID": 18, "context": "The idea of regularization (that is, introducing stability into ill-posed inverse problems) became widely known through the works of [19] and [20].", "startOffset": 142, "endOffset": 146}, {"referenceID": 27, "context": "When the domainH and the mapping \u03c6 are bounded, we have uniform convergence, in the sense that |L(h) \u2212 L\u0302(h)| is uniformly bounded over all h \u2208 H (see [29]).", "startOffset": 151, "endOffset": 155}, {"referenceID": 0, "context": "where for now we let H to be the d-dimensional unit sphere H = { h \u2208 R : \u2016h\u2016 \u2264 1 } , we let z = (x, \u03b1) with \u03b1 \u2208 [0, 1] and x \u2208 H, and we define u \u2217 v to be an element-wise product.", "startOffset": 112, "endOffset": 118}, {"referenceID": 0, "context": "The confidences \u03b1 are now a mapping of each coordinate to [0, 1].", "startOffset": 58, "endOffset": 64}, {"referenceID": 0, "context": "That is, an infinite sequence of reals in [0, 1].", "startOffset": 42, "endOffset": 48}, {"referenceID": 28, "context": "Since the problem is convex and (1 + )-Lipschitz and sinceH is the unit ball in the Hilbert space it follows (for instance from [30] + online to batch conversion) that irrespective of which distribution D over instances we use, LD(hS)\u2212 inf h\u2208H LD(h) \u2264 \u221a 2(1 + ) n Thus we can conclude that the problem is learnable and in fact enjoys a rate of order 1 \u221a n , yet as we already say both uniform convergence and ERM (SAA approach) fails.", "startOffset": 128, "endOffset": 132}, {"referenceID": 17, "context": "In particular, adding \u2016h\u2016 is the so-called Tikhonov Regularization technique, which has been known for more than half a century (see [19]).", "startOffset": 133, "endOffset": 137}, {"referenceID": 23, "context": "To relate our stability definitions to the ones in the literature, we note that our definitions of uniform-RO stability and strongly-uniform-RO stability are somewhat similar to uniform stability ([25]), which in our 3RO is short for \u201creplace-one\u201d.", "startOffset": 197, "endOffset": 201}, {"referenceID": 24, "context": "Moreover, we show that uniform-RO stable AERM\u2019s characterize learnability, while it is well known that uniformly stable AERM\u2019s are not necessary for learnability (see [26]).", "startOffset": 167, "endOffset": 171}, {"referenceID": 25, "context": "Our definition of average-RO stable is similar to \u201caverage stability\u201d defined in [27], which in our notation is defined as ES\u223cDn,z\u2032 1 [ `(A(S); z1)\u2212 `(A(S); z1) ] .", "startOffset": 81, "endOffset": 85}, {"referenceID": 24, "context": "For an elaborate study on other stability notions and their relationships, see [26].", "startOffset": 79, "endOffset": 83}, {"referenceID": 23, "context": "For instance, the notion of \u201call-i-LOO\u201d below has been studied by several authors under different names [25, 28, 27].", "startOffset": 104, "endOffset": 116}, {"referenceID": 26, "context": "For instance, the notion of \u201call-i-LOO\u201d below has been studied by several authors under different names [25, 28, 27].", "startOffset": 104, "endOffset": 116}, {"referenceID": 25, "context": "For instance, the notion of \u201call-i-LOO\u201d below has been studied by several authors under different names [25, 28, 27].", "startOffset": 104, "endOffset": 116}, {"referenceID": 26, "context": "While this is possible in the General Learning Setting, in supervised classification every such AERM has to be LOO stable (this is essentially proven in [28]).", "startOffset": 153, "endOffset": 157}, {"referenceID": 24, "context": "This example is taken from [26].", "startOffset": 27, "endOffset": 31}, {"referenceID": 0, "context": "Let the instance space be [0, 1], the hypothesis space [0, 1] \u222a 2, and the objective function `(h, z) = 1{h=z}.", "startOffset": 26, "endOffset": 32}, {"referenceID": 0, "context": "Let the instance space be [0, 1], the hypothesis space [0, 1] \u222a 2, and the objective function `(h, z) = 1{h=z}.", "startOffset": 55, "endOffset": 61}, {"referenceID": 29, "context": "In [31], we show a version of Theorem 5, which asserts that a problem is learnable if and only if there is an on-average-LOO stable AERM.", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": ", [28] and [27]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 25, "context": ", [28] and [27]).", "startOffset": 11, "endOffset": 15}, {"referenceID": 0, "context": "In other words, randomization implicitly replaces the arbitrary hypothesis class H by the space of probability distributions overH, M = { \u03b1 : H \u2192 [0, 1] s.", "startOffset": 146, "endOffset": 152}, {"referenceID": 23, "context": "Allowing randomization allows us to obtain results with respect to the following very strong notion of stability4: 4This definition of stability is very similar to the so-called \u201cuniform stability\u201d, discussed in [25], although [25] consider deterministic learning rules.", "startOffset": 212, "endOffset": 216}, {"referenceID": 23, "context": "Allowing randomization allows us to obtain results with respect to the following very strong notion of stability4: 4This definition of stability is very similar to the so-called \u201cuniform stability\u201d, discussed in [25], although [25] consider deterministic learning rules.", "startOffset": 227, "endOffset": 231}, {"referenceID": 0, "context": "Let the instance space be [0, 1], the hypothesis space consist of all finite subsets of [0, 1], and define the objective function as `(h, z) = 1{z/ \u2208h}).", "startOffset": 26, "endOffset": 32}, {"referenceID": 0, "context": "Let the instance space be [0, 1], the hypothesis space consist of all finite subsets of [0, 1], and define the objective function as `(h, z) = 1{z/ \u2208h}).", "startOffset": 88, "endOffset": 94}, {"referenceID": 0, "context": "Let the instance space be [0, 1].", "startOffset": 26, "endOffset": 32}, {"referenceID": 0, "context": "Let the hypothesis space consist of all finite subsets of [0, 1], and the objective function be the indicator function `(h, z) = 1{z\u2208h}.", "startOffset": 58, "endOffset": 64}, {"referenceID": 0, "context": "Consider the following learning rule: given a sample S \u2286 [0, 1], the learning rule checks if there are any two identical instances in the sample.", "startOffset": 57, "endOffset": 63}, {"referenceID": 0, "context": "Consider any continuous distribution on [0, 1].", "startOffset": 40, "endOffset": 46}, {"referenceID": 0, "context": "If the underlying distribution is continuous on [0, 1], then the returned hypothesis is S, which is countable hence , L(S) = 0 = infh L(h).", "startOffset": 48, "endOffset": 54}, {"referenceID": 31, "context": "Subsequently in a very recent work [33] it was shows that for multi-class learning problems with large number of classes, problems could still be learnable while uniform convergence fails and ERM approach may not be successful (at least not all ERM\u2019s are good).", "startOffset": 35, "endOffset": 39}, {"referenceID": 32, "context": "Littlestone [34] has shown that, in the setting of prediction of binary outcomes, a certain combinatorial property of the binaryvalued function class characterizes learnability in the realizable case (that is, when the outcomes presented by the adversary are given according to some function in the class F).", "startOffset": 12, "endOffset": 16}, {"referenceID": 33, "context": "The result has been extended to the non-realizable case by Shai Ben-David, D\u00e1vid P\u00e1l and Shai Shalev-Shwartz [35] who named this combinatorial quantity the Littlestone\u2019s dimension.", "startOffset": 109, "endOffset": 113}, {"referenceID": 33, "context": "Coincident with [35], minimax analysis of online convex optimization yielded new insights into the value of the game, its minimax dual representation, as well as algorithm-independent upper and lower bounds [36, 7].", "startOffset": 16, "endOffset": 20}, {"referenceID": 34, "context": "Coincident with [35], minimax analysis of online convex optimization yielded new insights into the value of the game, its minimax dual representation, as well as algorithm-independent upper and lower bounds [36, 7].", "startOffset": 207, "endOffset": 214}, {"referenceID": 6, "context": "Coincident with [35], minimax analysis of online convex optimization yielded new insights into the value of the game, its minimax dual representation, as well as algorithm-independent upper and lower bounds [36, 7].", "startOffset": 207, "endOffset": 214}, {"referenceID": 35, "context": "A natural generalization of Rademacher complexity [37, 38, 39], the sequential analogue possesses many of the nice properties of its classical cousin.", "startOffset": 50, "endOffset": 62}, {"referenceID": 36, "context": "A natural generalization of Rademacher complexity [37, 38, 39], the sequential analogue possesses many of the nice properties of its classical cousin.", "startOffset": 50, "endOffset": 62}, {"referenceID": 37, "context": "A natural generalization of Rademacher complexity [37, 38, 39], the sequential analogue possesses many of the nice properties of its classical cousin.", "startOffset": 50, "endOffset": 62}, {"referenceID": 38, "context": "Its proof requires considerably more work than the classical symmetrization proof [40, 39] due to the non-i.", "startOffset": 82, "endOffset": 90}, {"referenceID": 37, "context": "Its proof requires considerably more work than the classical symmetrization proof [40, 39] due to the non-i.", "startOffset": 82, "endOffset": 90}, {"referenceID": 37, "context": "In statistical learning theory, such structural results are obtained through properties of Rademacher averages [39, 38].", "startOffset": 111, "endOffset": 119}, {"referenceID": 36, "context": "In statistical learning theory, such structural results are obtained through properties of Rademacher averages [39, 38].", "startOffset": 111, "endOffset": 119}, {"referenceID": 39, "context": "As a special case of the result, we get a sequential counterpart of the Ledoux-Talagrand [41] contraction inequality.", "startOffset": 89, "endOffset": 93}, {"referenceID": 39, "context": "We remark that the lemma above encompasses the case of a Lipschitz \u03c6 : R 7\u2192 R, as stated in [41, 38].", "startOffset": 92, "endOffset": 100}, {"referenceID": 36, "context": "We remark that the lemma above encompasses the case of a Lipschitz \u03c6 : R 7\u2192 R, as stated in [41, 38].", "startOffset": 92, "endOffset": 100}, {"referenceID": 37, "context": "In the next proposition, we summarize some useful properties of Sequential Rademacher complexity (see [39, 38] for the results in the i.", "startOffset": 102, "endOffset": 110}, {"referenceID": 36, "context": "In the next proposition, we summarize some useful properties of Sequential Rademacher complexity (see [39, 38] for the results in the i.", "startOffset": 102, "endOffset": 110}, {"referenceID": 40, "context": "In statistical learning theory, learnability for binary classes of functions is characterized by the VapnikChervonenkis combinatorial dimension [42].", "startOffset": 144, "endOffset": 148}, {"referenceID": 41, "context": "For real-valued function classes, the corresponding notions are the scale-sensitive dimensions, such as P\u03b3 [43, 44].", "startOffset": 107, "endOffset": 115}, {"referenceID": 42, "context": "For real-valued function classes, the corresponding notions are the scale-sensitive dimensions, such as P\u03b3 [43, 44].", "startOffset": 107, "endOffset": 115}, {"referenceID": 32, "context": "For online learning, the notion characterizing learnability for binary prediction in the realizable case has been introduced by Littlestone [34] and extended to the non-realizable case of binary prediction by Shai Ben-David, D\u00e1vid P\u00e1l and Shai Shalev-Shwartz [35].", "startOffset": 140, "endOffset": 144}, {"referenceID": 33, "context": "For online learning, the notion characterizing learnability for binary prediction in the realizable case has been introduced by Littlestone [34] and extended to the non-realizable case of binary prediction by Shai Ben-David, D\u00e1vid P\u00e1l and Shai Shalev-Shwartz [35].", "startOffset": 259, "endOffset": 263}, {"referenceID": 32, "context": "Next, we define the Littlestone\u2019s dimension [34, 35] and propose its scale-sensitive versions for real-valued function classes.", "startOffset": 44, "endOffset": 52}, {"referenceID": 33, "context": "Next, we define the Littlestone\u2019s dimension [34, 35] and propose its scale-sensitive versions for real-valued function classes.", "startOffset": 44, "endOffset": 52}, {"referenceID": 43, "context": "In the binary case (k = 1 below), a reader might notice a similarity of Theorems 31 and 33 to the classical results due to Sauer [45], Shelah [46] (also, Perles and Shelah), and Vapnik and Chervonenkis [42].", "startOffset": 129, "endOffset": 133}, {"referenceID": 44, "context": "In the binary case (k = 1 below), a reader might notice a similarity of Theorems 31 and 33 to the classical results due to Sauer [45], Shelah [46] (also, Perles and Shelah), and Vapnik and Chervonenkis [42].", "startOffset": 142, "endOffset": 146}, {"referenceID": 40, "context": "In the binary case (k = 1 below), a reader might notice a similarity of Theorems 31 and 33 to the classical results due to Sauer [45], Shelah [46] (also, Perles and Shelah), and Vapnik and Chervonenkis [42].", "startOffset": 202, "endOffset": 206}, {"referenceID": 45, "context": "Alon and Spencer [47]).", "startOffset": 17, "endOffset": 21}, {"referenceID": 41, "context": "For the classical case of a cover based on a set points, the discretization idea appears in [43, 48].", "startOffset": 92, "endOffset": 100}, {"referenceID": 46, "context": "For the classical case of a cover based on a set points, the discretization idea appears in [43, 48].", "startOffset": 92, "endOffset": 100}, {"referenceID": 46, "context": "This point can be seen in the proof of Corollary 32 (also see [48]): the discretization process can assign almost identical function values to discrete values which differ by 1.", "startOffset": 62, "endOffset": 66}, {"referenceID": 47, "context": "When bounding deviations of means from expectations uniformly over the function class, the usual approach proceeds by a symmetrization argument [49] followed by passing to a cover of the function class and a union bound (e.", "startOffset": 144, "endOffset": 148}, {"referenceID": 37, "context": "[39]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "[50]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "A simple consequence of the above lemma is that if F \u2286 [0, 1]Z is a finite class, then for any given tree z we have that E [ max f\u2208F 1 n n \u2211", "startOffset": 55, "endOffset": 61}, {"referenceID": 50, "context": "by the exponential weighted average forecaster algorithm (see [52]).", "startOffset": 62, "endOffset": 66}, {"referenceID": 15, "context": "However, as we show next, Lemma 34 goes well beyond just finite classes and can be used to get an analog of Dudley entropy bound [17] for the online setting through a chaining argument.", "startOffset": 129, "endOffset": 133}, {"referenceID": 32, "context": "[34, 35]) is the class of step functions on a bounded interval, which has a VC dimension 1, but is not learnable in the online setting.", "startOffset": 0, "endOffset": 8}, {"referenceID": 33, "context": "[34, 35]) is the class of step functions on a bounded interval, which has a VC dimension 1, but is not learnable in the online setting.", "startOffset": 0, "endOffset": 8}, {"referenceID": 33, "context": "We achieve this by generating \u201cexperts\u201d in a way similar to [35].", "startOffset": 60, "endOffset": 64}, {"referenceID": 51, "context": "These results form the basis of the theory of large margin classifiers (see [53, 54]).", "startOffset": 76, "endOffset": 84}, {"referenceID": 52, "context": "These results form the basis of the theory of large margin classifiers (see [53, 54]).", "startOffset": 76, "endOffset": 84}, {"referenceID": 33, "context": "Recently, in the online setting, margin bounds have been shown through the concept of margin via the Littlestone dimension [35].", "startOffset": 123, "endOffset": 127}, {"referenceID": 52, "context": "We use ideas from [54] to do this.", "startOffset": 18, "endOffset": 22}, {"referenceID": 36, "context": "bounds we provide are analogous to the ones considered in the batch setting in [38].", "startOffset": 79, "endOffset": 83}, {"referenceID": 36, "context": "The proposition is analogous to the one in [38] considered in the batch (classical) setting.", "startOffset": 43, "endOffset": 47}, {"referenceID": 53, "context": "In the transductive setting considered by Kakade and Kalai [55], it is assumed that m \u2264 n and F are binaryvalued.", "startOffset": 59, "endOffset": 63}, {"referenceID": 53, "context": "Using the previous argument with c = en, we obtain a bound of 4 \u221a dn log(en) for the value of the game, matching [55] up to a constant 2.", "startOffset": 113, "endOffset": 117}, {"referenceID": 54, "context": "In particular, in the case of binary prediction, Cesa-Bianchi and Lugosi [56] proved upper bounds on the value of the game in terms of the (classical) Rademacher complexity and the (classical) Dudley integral.", "startOffset": 73, "endOffset": 77}, {"referenceID": 54, "context": "The particular assumption made in [56] is that experts are static.", "startOffset": 34, "endOffset": 38}, {"referenceID": 54, "context": "We mention that the upper bound in Theorem 4 in [56] is tighter by a log n factor if a sharper bound on the `2 cover is considered.", "startOffset": 48, "endOffset": 52}, {"referenceID": 50, "context": "Finally, for the case of a finite number of experts, clearly N\u0302\u221e \u2264 N which gives the classical O( \u221a n logN) bound on the value of the game [52].", "startOffset": 139, "endOffset": 143}, {"referenceID": 55, "context": "5 Example: Isotron Recently, Kalai and Sastry [57] introduced a method called Isotron for learning Single Index Models (SIM).", "startOffset": 46, "endOffset": 50}, {"referenceID": 55, "context": "For brevity, we only describe the Idealized SIM problem from [57].", "startOffset": 61, "endOffset": 65}, {"referenceID": 55, "context": "The elegant computationally efficient method presented in [57] is motivated by Perceptron, and a natural open question posed by the authors is whether there is an online variant of Isotron.", "startOffset": 58, "endOffset": 62}, {"referenceID": 37, "context": "The other items follow similarly to Theorem 15 in [39] and we provide the proofs for completeness.", "startOffset": 50, "endOffset": 54}, {"referenceID": 37, "context": "Note that, unlike Rademacher complexity defined in [39], Sequential Rademacher complexity does not have the absolute value around the sum.", "startOffset": 51, "endOffset": 55}, {"referenceID": 33, "context": "For the lower bound, we use a construction similar to [35].", "startOffset": 54, "endOffset": 58}, {"referenceID": 0, "context": "Here we also assume that F \u2282 [0, 1]Z contains only non-negative functions (corresponds to loss class).", "startOffset": 29, "endOffset": 35}, {"referenceID": 56, "context": "First, by the classical result of Kolmogorov and Tihomirov [58], the class G of all bounded Lipschitz functions has small metric entropy: log N\u0302\u221e(\u03b1,G) = \u0398(1/\u03b1).", "startOffset": 59, "endOffset": 63}, {"referenceID": 57, "context": "In the statistical learning framework the notion of Localized Rademacher complexity introduced in [59] can often be used to obtain fast rates.", "startOffset": 98, "endOffset": 102}, {"referenceID": 0, "context": "The mirror descent algorithm [1] is a natural generalization of gradient descent method for general convex learning problems.", "startOffset": 29, "endOffset": 32}, {"referenceID": 0, "context": "\u2016 \u00b7 \u2016 if for any h,h\u2032 \u2208 B: \u2200\u03b1\u2208[0,1] \u03a8 (\u03b1h + (1\u2212 \u03b1)h\u2032) \u2264 \u03b1\u03a8(h) + (1\u2212 \u03b1)\u03a8(h\u2032)\u2212 \u03b1(1\u2212\u03b1) q \u2016h\u2212 h \u2032\u2016", "startOffset": 30, "endOffset": 35}, {"referenceID": 58, "context": "In [60] we had made the observation that any non-negative smooth convex loss satisfies this above self bounding property.", "startOffset": 3, "endOffset": 7}, {"referenceID": 58, "context": "reasoning as in[60, 61].", "startOffset": 15, "endOffset": 23}, {"referenceID": 59, "context": "Refer to [62] for more details about online to batch conversion.", "startOffset": 9, "endOffset": 13}, {"referenceID": 0, "context": "Now we upper bound the summation term by replacing each infimum over decompositions of\u2207`(ht, zt) into any arbitrary vectors ut and vt to vectors of specific form, ut = (1\u2212 \u03b1)\u2207\u03c6(ht, zt) and vt = \u03b1\u2207\u03c6(ht, zt) for some \u03b1 \u2208 [0, 1].", "startOffset": 219, "endOffset": 225}, {"referenceID": 0, "context": "\u03b1 \u2208 [0, 1],", "startOffset": 4, "endOffset": 10}, {"referenceID": 0, "context": "The mirror descent algorithm with uniformly convex \u03a8 functions were introduced by Nemirovski and Yudin in [1] for offline convex optimization.", "startOffset": 106, "endOffset": 109}, {"referenceID": 0, "context": "Specific upper bounds for offline convex optimization of ZLip dual case when H is the unit `p ball and X is the dual of H are provided in [1].", "startOffset": 138, "endOffset": 141}, {"referenceID": 28, "context": "For online convex optimization problem, online gradient descent (Euclidean case) was proposed by Zinkevich in[30].", "startOffset": 109, "endOffset": 113}, {"referenceID": 60, "context": "Faster rates when the losses are strongly convex in the Euclidean case for online gradient descent was proposed in [63].", "startOffset": 115, "endOffset": 119}, {"referenceID": 61, "context": "Mirror descent for general strongly convex objectives with log n/n rates was proposed and analyzed in [64].", "startOffset": 102, "endOffset": 106}, {"referenceID": 62, "context": "3 we extend Pisier\u2019s result [65] to show that martingale type of the problem can be used to ensure existence of an appropriate uniformly convex function.", "startOffset": 28, "endOffset": 32}, {"referenceID": 0, "context": "Owing to this, for any p \u2208 [1, 2] we define constant : Vp := inf { V \u2223\u2223\u2223 \u2200n \u2208 N,Vn(H,Zlin(X )) \u2264 V n\u2212(1\u2212 1 p )} (7.", "startOffset": 27, "endOffset": 33}, {"referenceID": 1, "context": "Owing to this, for any p \u2208 [1, 2] we define constant : Vp := inf { V \u2223\u2223\u2223 \u2200n \u2208 N,Vn(H,Zlin(X )) \u2264 V n\u2212(1\u2212 1 p )} (7.", "startOffset": 27, "endOffset": 33}, {"referenceID": 0, "context": "To this end, similar to Vp for each p \u2208 [1, 2] we can define:", "startOffset": 40, "endOffset": 46}, {"referenceID": 1, "context": "To this end, similar to Vp for each p \u2208 [1, 2] we can define:", "startOffset": 40, "endOffset": 46}, {"referenceID": 0, "context": "For any p \u2208 [1, 2]: Vp \u2264 MDp", "startOffset": 12, "endOffset": 18}, {"referenceID": 1, "context": "For any p \u2208 [1, 2]: Vp \u2264 MDp", "startOffset": 12, "endOffset": 18}, {"referenceID": 6, "context": "In [7], it was shown that the concept of the Martingale type (also sometimes called the Haar type) of a Banach space and optimal rates for online convex optimization problem, where X andH are duals of each other, are closely related.", "startOffset": 3, "endOffset": 6}, {"referenceID": 62, "context": "In this section we extend the classic notion of Martingale type of a Banach space (see for instance [65]) to one that accounts for the pair (H,X ).", "startOffset": 100, "endOffset": 104}, {"referenceID": 62, "context": "We point the reader to [65, 66] for more details.", "startOffset": 23, "endOffset": 31}, {"referenceID": 63, "context": "We point the reader to [65, 66] for more details.", "startOffset": 23, "endOffset": 31}, {"referenceID": 0, "context": "Further, for any p \u2208 [1, 2] we also define,", "startOffset": 21, "endOffset": 27}, {"referenceID": 1, "context": "Further, for any p \u2208 [1, 2] we also define,", "startOffset": 21, "endOffset": 27}, {"referenceID": 62, "context": "We then extend the result of Pisier in [65] to the \u201cnon-matching\u201d setting combining it with the above theorem to finally get : Lemma 67.", "startOffset": 39, "endOffset": 43}, {"referenceID": 0, "context": "For any p \u2208 [1, 2] and any p\u2032 < p : Cp\u2032 \u2264 1104 Vp (p\u2212p\u2032)2", "startOffset": 12, "endOffset": 18}, {"referenceID": 1, "context": "For any p \u2208 [1, 2] and any p\u2032 < p : Cp\u2032 \u2264 1104 Vp (p\u2212p\u2032)2", "startOffset": 12, "endOffset": 18}, {"referenceID": 62, "context": "In [65], it was shown that a Banach space has Martingale type p (the classical notion) if and only if uniformly convex functions with certain properties exist on that space (w.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "For any p \u2208 [1, 2], Dp \u2264 Cp.", "startOffset": 12, "endOffset": 18}, {"referenceID": 1, "context": "For any p \u2208 [1, 2], Dp \u2264 Cp.", "startOffset": 12, "endOffset": 18}, {"referenceID": 62, "context": "p\u2032 < p, Cp\u2032 \u2264 Vp \u2264 MDp \u2264 Dp \u2264 Cp Lemma 67 (extending Pisier\u2019s result [65]) Definition of Vp (Generalized MD guarantee) Lemma 55 Construction of \u03a8, Lemma 77 (extending Pisier\u2019s result [65])", "startOffset": 69, "endOffset": 73}, {"referenceID": 62, "context": "p\u2032 < p, Cp\u2032 \u2264 Vp \u2264 MDp \u2264 Dp \u2264 Cp Lemma 67 (extending Pisier\u2019s result [65]) Definition of Vp (Generalized MD guarantee) Lemma 55 Construction of \u03a8, Lemma 77 (extending Pisier\u2019s result [65])", "startOffset": 183, "endOffset": 187}, {"referenceID": 63, "context": "1) need not be such that (q\u03a8q(h)) 1/q is a norm, with a simple modification as noted in [66] we can make it a norm.", "startOffset": 88, "endOffset": 92}, {"referenceID": 64, "context": "Ball et al [67] tightly calculate the constants of strong convexity of squared `p norms, establishing the tightness ofD2 when p1 = p2.", "startOffset": 11, "endOffset": 15}, {"referenceID": 64, "context": "These results again follow using similar arguments as `p case and tight constants for strong convexity parameters of the Schatten norm from [67].", "startOffset": 140, "endOffset": 144}, {"referenceID": 65, "context": "4 Example : Max Norm Max-norm has been proposed as a convex matrix regularizer for application such as matrix completion [69].", "startOffset": 121, "endOffset": 125}, {"referenceID": 66, "context": "As noted in [70] the max-norm ball is equivalent, up to a factor two, to the convex hull of all rank one sign matrices.", "startOffset": 12, "endOffset": 16}, {"referenceID": 66, "context": "This matches the stochastic (PAC) learning guarantee [70], and is the first guarantee we are aware of for the max norm matrix completion problem in the online setting.", "startOffset": 53, "endOffset": 57}, {"referenceID": 67, "context": "For instance one might want sparsity along with grouping effect in the linear predictors for which elastic-net type regularization introduced by Zou and Hastie [71] (this is captured by interpolation of the first type between `1 and `2 norms).", "startOffset": 160, "endOffset": 164}, {"referenceID": 68, "context": "al [72] (here one can use the interpolation norm of second type to interpolate between trace norm and element wise `1 norm).", "startOffset": 3, "endOffset": 7}, {"referenceID": 69, "context": "al [73].", "startOffset": 3, "endOffset": 7}, {"referenceID": 69, "context": "Similarly for the [73] case X could be either matrices with bounded entries or some other natural assumption that suits the problem.", "startOffset": 18, "endOffset": 22}, {"referenceID": 62, "context": "techniques as in [65].", "startOffset": 17, "endOffset": 21}, {"referenceID": 63, "context": "We restate below a proposition from Pisier\u2019s note (in [66]) Proposition 82 (Proposition 8.", "startOffset": 54, "endOffset": 58}, {"referenceID": 63, "context": "53 of [66]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 4, "context": "Now before we proceed we recall from [5] that the value of the online learning game is equal to :", "startOffset": 37, "endOffset": 40}, {"referenceID": 4, "context": "Recall from [5] that the value of the online learning game is equal to :", "startOffset": 12, "endOffset": 15}, {"referenceID": 0, "context": "We first note that using mirror descent with uniformly convex function (as opposed to strongly convex) is not new and has been used in optimization setting in [1].", "startOffset": 159, "endOffset": 162}, {"referenceID": 62, "context": "While the classic definition of martingale type and the associated results are for dual pairs, in this chapter we extended results by [65] to handle non-dual scenario.", "startOffset": 134, "endOffset": 138}, {"referenceID": 0, "context": "Owing to the fact that optimal learning rates for the linear class provide lower bounds for convex lipschitz and supervised convex learning problems, we define for each p \u2208 [1, 2] the constant V iid p analogous to the definition of Vp in the previous chapter.", "startOffset": 173, "endOffset": 179}, {"referenceID": 1, "context": "Owing to the fact that optimal learning rates for the linear class provide lower bounds for convex lipschitz and supervised convex learning problems, we define for each p \u2208 [1, 2] the constant V iid p analogous to the definition of Vp in the previous chapter.", "startOffset": 173, "endOffset": 179}, {"referenceID": 36, "context": "The following proposition which is a direct consequence of results from [38] show that the learning rates for linear and supervised convex learning problems are upper bounded by the statistical Rademacher complexity.", "startOffset": 72, "endOffset": 76}, {"referenceID": 36, "context": "[38] For any set X \u2208 B if Z(X ) is one of either Zlin(X ) or Zsup(X ), then for any n \u2208 N,", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "The inequality of linear class is a direct consequence of symmetrization (see [38]).", "startOffset": 78, "endOffset": 82}, {"referenceID": 36, "context": "The inequality for the supervised learning class Zsup(X ) additionally uses the Lipschitz contraction property (Theorem 10 (4) of [38] ) since the absolute loss is 1-Lipschitz.", "startOffset": 130, "endOffset": 134}, {"referenceID": 70, "context": "In this section we extend the classic notion of Rademacher type of a Banach space (see for instance [74]) to one that accounts for the pair (H,X ).", "startOffset": 100, "endOffset": 104}, {"referenceID": 63, "context": "We point the reader to [66] for more details.", "startOffset": 23, "endOffset": 27}, {"referenceID": 0, "context": "Further, for any p \u2208 [1, 2] we also define constant C iid p , analogous to the definition of Cp in previous chapter.", "startOffset": 21, "endOffset": 27}, {"referenceID": 1, "context": "Further, for any p \u2208 [1, 2] we also define constant C iid p , analogous to the definition of Cp in previous chapter.", "startOffset": 21, "endOffset": 27}, {"referenceID": 71, "context": "Definition 34 (Banach Lattice [75]).", "startOffset": 30, "endOffset": 34}, {"referenceID": 72, "context": "The main technology behind proving results about Banach lattices arises from the so called functional calculus over banach lattices introduced by Krivine [76] (See [75]).", "startOffset": 154, "endOffset": 158}, {"referenceID": 71, "context": "The main technology behind proving results about Banach lattices arises from the so called functional calculus over banach lattices introduced by Krivine [76] (See [75]).", "startOffset": 164, "endOffset": 168}, {"referenceID": 71, "context": "1 in [75]) which roughly states that if we prove any inequality involving continuous degree 1, homogenous equations involving finite number of real valued variables, then the same inequality is true with of course appropriate changes like \u2264 replaced by and absolute value replaced by the lattice version and so on.", "startOffset": 5, "endOffset": 9}, {"referenceID": 73, "context": "This is due to the celebrated result of Maurey and Pisier [77] which (in the dual case) assures that any space with non-trivial type also has finite co-type.", "startOffset": 58, "endOffset": 62}, {"referenceID": 74, "context": "2 Decoupling Inequalities Another way to guarantee that Cp \u2264 GC iid p for some finiteG is by using the so called decoupling inequalities (see [78, 79] for more details).", "startOffset": 142, "endOffset": 150}, {"referenceID": 75, "context": "2 Decoupling Inequalities Another way to guarantee that Cp \u2264 GC iid p for some finiteG is by using the so called decoupling inequalities (see [78, 79] for more details).", "startOffset": 142, "endOffset": 150}, {"referenceID": 74, "context": "We would like to point out that the above definition is not the same as the decoupling inequalities in [78, 79] where the above needs to be true for all martingale difference sequences where as above we only consider Walsh-Paley martingales.", "startOffset": 103, "endOffset": 111}, {"referenceID": 75, "context": "We would like to point out that the above definition is not the same as the decoupling inequalities in [78, 79] where the above needs to be true for all martingale difference sequences where as above we only consider Walsh-Paley martingales.", "startOffset": 103, "endOffset": 111}, {"referenceID": 75, "context": "1 of [79]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 75, "context": "Using some of the results in [79, 80, 81, 82, 83] we can conclude that for many interesting spaces we commonly encounter, there in fact even exists a universal 1-decoupling constant, call itBR.", "startOffset": 29, "endOffset": 49}, {"referenceID": 76, "context": "Using some of the results in [79, 80, 81, 82, 83] we can conclude that for many interesting spaces we commonly encounter, there in fact even exists a universal 1-decoupling constant, call itBR.", "startOffset": 29, "endOffset": 49}, {"referenceID": 77, "context": "Using some of the results in [79, 80, 81, 82, 83] we can conclude that for many interesting spaces we commonly encounter, there in fact even exists a universal 1-decoupling constant, call itBR.", "startOffset": 29, "endOffset": 49}, {"referenceID": 78, "context": "Using some of the results in [79, 80, 81, 82, 83] we can conclude that for many interesting spaces we commonly encounter, there in fact even exists a universal 1-decoupling constant, call itBR.", "startOffset": 29, "endOffset": 49}, {"referenceID": 79, "context": "Using some of the results in [79, 80, 81, 82, 83] we can conclude that for many interesting spaces we commonly encounter, there in fact even exists a universal 1-decoupling constant, call itBR.", "startOffset": 29, "endOffset": 49}, {"referenceID": 75, "context": "(This constantBR is the one referred to asDR in [79]).", "startOffset": 48, "endOffset": 52}, {"referenceID": 75, "context": "The following proposition proved in [79] (see also [80]) is particularly useful especially to provide decoupling inequalities for group norms and interpolation norms.", "startOffset": 36, "endOffset": 40}, {"referenceID": 76, "context": "The following proposition proved in [79] (see also [80]) is particularly useful especially to provide decoupling inequalities for group norms and interpolation norms.", "startOffset": 51, "endOffset": 55}, {"referenceID": 75, "context": "6 [79]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 75, "context": "11 of [79] it has been shown that for p \u2265 log2(d), the p-decoupling constant of `\u221e spaces if bounded by 2BR.", "startOffset": 6, "endOffset": 10}, {"referenceID": 77, "context": "In [81] it has been shown that a large class of Orlicz and Rearrangement invariant function spaces satisfy 1-decoupling inequality with universal constant", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "It turns out that for `p norms, when p \u2208 [1, 2] we have a universal constant for 1-decoupling by Proposition 96.", "startOffset": 41, "endOffset": 47}, {"referenceID": 1, "context": "It turns out that for `p norms, when p \u2208 [1, 2] we have a universal constant for 1-decoupling by Proposition 96.", "startOffset": 41, "endOffset": 47}, {"referenceID": 80, "context": "In [84], in the transductive online setting for max norm it is shown that once can again use the SDP to obtain a poly-time algorithm.", "startOffset": 3, "endOffset": 7}, {"referenceID": 81, "context": "We conclude the proof by using Kahane Inequality (see [85]) which asserts that for any p \u2208 [1, 2], ( E \u2225\u2225\u2225\u2225 n \u2211", "startOffset": 54, "endOffset": 58}, {"referenceID": 0, "context": "We conclude the proof by using Kahane Inequality (see [85]) which asserts that for any p \u2208 [1, 2], ( E \u2225\u2225\u2225\u2225 n \u2211", "startOffset": 91, "endOffset": 97}, {"referenceID": 1, "context": "We conclude the proof by using Kahane Inequality (see [85]) which asserts that for any p \u2208 [1, 2], ( E \u2225\u2225\u2225\u2225 n \u2211", "startOffset": 91, "endOffset": 97}, {"referenceID": 0, "context": "For p \u2208 [1, 2] the pair (H,X ) is said to be p-convex with constantKp if for any x1, .", "startOffset": 8, "endOffset": 14}, {"referenceID": 1, "context": "For p \u2208 [1, 2] the pair (H,X ) is said to be p-convex with constantKp if for any x1, .", "startOffset": 8, "endOffset": 14}, {"referenceID": 71, "context": "1 of [75] by noting that expectation w.", "startOffset": 5, "endOffset": 9}, {"referenceID": 71, "context": "2 (iii) [75] we can conclude that", "startOffset": 8, "endOffset": 12}, {"referenceID": 82, "context": "t=1 t tat( ) \u2223\u2223\u2223\u2223 p])1/p Burkholder\u2019s Inequality [86]", "startOffset": 49, "endOffset": 53}, {"referenceID": 71, "context": "1 [75] (by expanding out the tree of depth n to its 2 \u2212 1 elements and noting that expectation w.", "startOffset": 2, "endOffset": 6}, {"referenceID": 0, "context": "To address the issue of efficiency of optimization methods for the convex optimization problems, we use the notion of oracle complexity introduced by Nemirovski and Yudin in [1].", "startOffset": 174, "endOffset": 177}, {"referenceID": 0, "context": "1 introduces the oracle based offline optimization model of Nemirovski and Yudin [1].", "startOffset": 81, "endOffset": 84}, {"referenceID": 0, "context": "Such models have been introduced and analyzed in [1].", "startOffset": 49, "endOffset": 52}, {"referenceID": 0, "context": "To address this issue we use the notion of local oracle defined by Nemirovski and Yudin [1] and whenever we use the term oracle we mean local oracle.", "startOffset": 88, "endOffset": 91}, {"referenceID": 0, "context": "The following lemma which lower bounds oracle complexity by fat-shattering dimension of the corresponding linear function class is based on the proof technique for lower bounds on oracle complexity for offline optimization of convex Lipschitz function classes in [1].", "startOffset": 263, "endOffset": 266}, {"referenceID": 83, "context": "However it turns out that at least for the dual learning problems (when H = X ) if the dimension is large enough, by the celebrated Dvoretzky-Roger\u2019s theorem (see for instance [87]), we can infer that for all \u03b2 < , fat \u03b2 (Flin(H,X )) is larger than order 1/\u03b2.", "startOffset": 176, "endOffset": 180}, {"referenceID": 83, "context": "In this case, the celebrated Dvoretzky Roger\u2019s theorem (see [87] for geometric interpretation we use here) implies that for any Banach space of dimension large enough (larger than 2), there exists set of n points, x1, .", "startOffset": 60, "endOffset": 64}, {"referenceID": 0, "context": "2 of [1].", "startOffset": 5, "endOffset": 8}, {"referenceID": 84, "context": "Such a scenario is analyzed in [88] based on techniques in Chapter 4.", "startOffset": 31, "endOffset": 35}, {"referenceID": 85, "context": "in [89, 90].", "startOffset": 3, "endOffset": 11}, {"referenceID": 86, "context": "Results in chapters ?? and ?? influenced and shaped the work in paper [91] where we showed how one can make appropriate changes to stochastic mirror descent and accelerated methods to include mini-batching (breaking sample into blocks and instead of updating in each step with single gradient update with average of the block of gradients).", "startOffset": 70, "endOffset": 74}], "year": 2012, "abstractText": "Optimization has always played a central role in machine learning and advances in the field of optimization and mathematical programming have greatly influenced machine learning models. However the connection between optimization and learning is much deeper : one can phrase statistical and online learning problems directly as corresponding optimization problems. In this dissertation I take this viewpoint and analyze learning problems in both the statistical and online learning frameworks from an optimization perspective. In doing so we develop a deeper understanding of the connections between statistical and online learning and between learning and optimization. The dissertation can roughly be divided into two parts. In the first part we consider the question of learnability and possible learning rates for general statistical and online learning problems without regard to tractability issues. In the second part we restrict ourselves to convex learning problems and address the issue of tractability for both online and statistical learning problems by considering the oracle complexity of these learning problems. I. We first consider the question of learnability and possible learning rates for statistical learning problems under the general learning setting. The notion of learnability was first introduced by Valiant (1984) for the problem of binary classification in the realizable case. Vapnik (1995) introduced the general learning setting as a unifying framework for the general problem of statistical learning from empirical data. In this framework the learner is provided with a sample of instances drawn i.i.d. from some distribution unknown to the learner. The goal of the learner is to pick a hypothesis with low expected loss based on the sample received. The question of learnability is well studied and fully characterized for binary classification using the Vapnik Chervonenkis (VC) theory and for real valued supervised learning problems using the theory of uniform convergence with tools like Rademacher complexity, covering numbers and fat-shattering dimension etc. However we show that for the general learning setting the traditional approach of using uniform convergence theory to characterize learnability fails. Specifically we phrase the learning problem as a stochastic optimization problem and construct an example of a convex problem where Stochastic Approximation (SA) approach provides successful learning guarantee but Empirical Risk Minimization (ERM) (or equivalently Sample Average Approximation (SAA) approach) fails to give any meaningful learning guarantee. This example establishes that for general learning problems the concept of uniform convergence fails to capture learnability and ERM/SAA ap-", "creator": "LaTeX with hyperref package"}}}