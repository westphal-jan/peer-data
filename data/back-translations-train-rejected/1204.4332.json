{"id": "1204.4332", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Apr-2012", "title": "Designing generalisation evaluation function through human-machine dialogue", "abstract": "Automated generalisation has known important improvements these last few years. However, an issue that still deserves more study concerns the automatic evaluation of generalised data. Indeed, many automated generalisation systems require the utilisation of an evaluation function to automatically assess generalisation outcomes. In this paper, we propose a new approach dedicated to the design of such a function. This approach allows an imperfectly defined evaluation function to be revised through a man-machine dialogue. The user gives its preferences to the system by comparing generalisation outcomes. Machine Learning techniques are then used to improve the evaluation function. An experiment carried out on buildings shows that our approach significantly improves generalisation evaluation functions defined by users.", "histories": [["v1", "Thu, 19 Apr 2012 12:10:10 GMT  (303kb)", "http://arxiv.org/abs/1204.4332v1", null]], "reviews": [], "SUBJECTS": "cs.HC cs.LG", "authors": ["patrick taillandier", "julien gaffuri"], "accepted": false, "id": "1204.4332"}, "pdf": {"name": "1204.4332.pdf", "metadata": {"source": "CRF", "title": "Designing generalisation evaluation function through human-machine dialogue", "authors": ["Patrick Taillandier", "Julien Gaffuri", "Quang Buu", "Ha Noi", "Viet Nam"], "emails": ["patrick.taillandier@gmail.com", "julien.gaffuri@ign.fr"], "sections": [{"heading": null, "text": "The development of evaluation functions for generalizations through dialogue between man and machine Patrick Taillandier1, Julien Gaffuri21IRD, UMI UMMISCO 209,32 avenue Henri Varagnat, 93143 Bondy, France Email: patrick.taillandier @ gmail.com 2IFI, MSI, UMI 209, ngo 42 Ta Quang Buu, Ha Noi, Viet Nam3 IGN - COGIT Laboratory - University of Paris-Est 73 avenue de Paris, 94165 Saint-Mand\u00e9 cedex, FranceEmail: julien.gaffuri @ ign.fr"}, {"heading": "1. Introduction", "text": "A classic approach to automated generalization is to formalize generalization as an optimization problem: the goal is to find a state of the data that maximizes an evaluation function to assess the generalization state of the data according to the needs of the user (e.g. Wilson et al., 2003). A central theme of this approach concerns the design of this evaluation function. Unfortunately, designing such a function remains a difficult task. While the end user of the generalized data can easily describe his needs in natural language, it is often much more difficult to express his expectations in a formal language that can be used by generalization systems. In this paper, we propose an approach that addresses the generalization of the evaluation function design. An evaluation function previously designed by a user is improved through a dialogue between the user and a generalization system."}, {"heading": "2. Context", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Automated evaluation of generalisation results", "text": "While many papers focus on the automation of the generalization process, few focus on the automatic evaluation of generalization outcomes. A classic approach is to evaluate the quality of generalization using a series of constraints that translate expectation toward generalization (Beard, 1991). Constraint evaluation is often represented by a numerical satisfaction value. Overall generalization is evaluated by aggregating all constraint satisfaction values. If the calculation of individual constraint satisfaction values is often well handled, the definition of the aggregation function remains complex (Bard, 2004)."}, {"heading": "2.2 Design of an evaluation function", "text": "The design of evaluation functions is a complex problem that has been studied in various areas. Many papers have been interested in defining these functions for specific problems (Wimmer et al., 2008), but few general approaches have been proposed to help users of optimization systems define this problem. A classic approach to solving this problem is the application of supervised machine learning techniques, which consist of inducing a general model from examples designated by an expert. In this context, it is possible to learn an evaluation function from examples evaluated by an expert. This approach has been applied in several papers, such as (Wimmer et al., 2008) in the field of computer vision and (Clancy et al., 2007) in the field of cognitive radio learning. The disadvantage of this approach is the complexity for experts to quantitatively evaluate the quality of a solution. In fact, it is sometimes difficult for experts to translate the quality of a solution directly by a numerical value."}, {"heading": "2.3 Formalisation of the evaluation function design", "text": "We assume that a number of constraints are defined, the evaluation of which is represented by a numerical satisfaction value. The higher the evaluation value, the more satisfied is the constraint, that is, the better the generalization. We propose to formulate the aggregation function by a weighted mean balanced by a power. Let us allow C to be considered the considered constraint, with the weight attached to a constraint i, Vali (gen), the evaluation value of the constraint i for the generalization gene and p, an integer greater or equal to 1. The evaluation function is defined as follows: p (gen) Valww = n) Quality (ge p) Ci i i i i p iCip i1) (1) (1) (1) The role of p is to control the relative weight of the most satisfied constraints vis-\u00e0-vis the less satisfied: the higher p, the more satisfied constraints are taken into account in the overall quality of the generalization."}, {"heading": "3. Proposed approach", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. General approach", "text": "We propose an approach to designing the generalization evaluation function based on the presentation of comparisons between generalizations for the user and learning a generalization function from the collected preference data, similar to the approach proposed by Hubert & Ruas, 2003, for parameterizing the generalization process; however, one difference is that the user does not simply select his preferred generalization from a group, but that the user compares these generalizations; our approach consists of three steps described in the next sections."}, {"heading": "3.2. Initialisation of the comparison set", "text": "The first step is to generate the comparisons shown to the user in order to understand his needs. A comparison is a pair of different generalizations of the same object. To create the comparison set, select some geographical objects to be generalized and then calculate two different generalizations of these objects and store them in the comparison set."}, {"heading": "3.3 Capture of the user preferences", "text": "The second step concerns the collection of user preferences: comparisons are presented successively to the user, who indicates his preferences for each of them. This sequence is repeated until the user has been presented with a certain number of comparisons. For each comparison between two generalizations A and B. The user can choose: \u2022 Generalization A / B is much better than Generalization B / A \u2022 Generalization A / B is better than Generalization B / A \u2022 Generalization A / B is slightly better than Generalization B / A \u2022 Generalization A and Generalization B are equivalent Figure 1 represents the comparison interface of the developed prototype."}, {"heading": "3.4. Evaluation function definition", "text": "The last step is to learn a rating function from the collected user preferences: the parameter values (i.e. the constraint weights wi and the power p) that best correspond to the preferences given by the user in the previous step are calculated. We propose to formulate this problem as a minimization problem. We define a global error function that represents the inadequacy between a rating function (and thus the parameter value mapping) and user preferences. Our goal is to find the parameter values that minimize the global error function. Let feval (gen) be the current rating function that evaluates the quality of a generalization gene."}, {"heading": "4. Case study: evaluation of building generalisation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Context", "text": "Our experiment uses a generalization system based on the AGENT model (Barrault et al., 2001), in which the quality of generalization is evaluated by a series of constraints. AGENT model has been at the heart of much research and is used to create maps in several mapping agencies, but the question arises of the allocation of constraints (Bard, 2004).We propose to experiment our method of building a generalization for a traditional topographic map on a scale of 1: 25,000. Five constraints are used. Input data comes from the topographic database BDTopo \u00ae, a resolution. The initial evaluation function was designed by an expert of the AGENT model. We defined two sets of 100 different comparisons each (the learning and the testing set).The learning set is used to learn the evaluation function, the tests for assessing the quality of the initial and learning evaluation functions."}, {"heading": "4.2. Results and discussion", "text": "Table 1 shows the results of the two comparison groups. It shows the global error for each evaluation function and comparison group (see Section 3.4).These results show that the learned function has enabled an improvement in the global error: for both learning and test groups, the global errors of the initial function are higher than for the learned function. However, the quality improvement after applying the method is only 11% for the test set. One explanation is the absence of limitations (e.g. an orientation restriction).For example, if a comparison consists of two building generalizations that differ only in terms of orientation, the user always prefers the one whose orientation is close to the starting point of the building. Since the evaluation function does not take into account orientation restriction, the difference between the two generalizations cannot be measured by the system, and the reason for the different evaluation by the user is not taken into account. In this context, our approach can help by examining the incompatible comparison function to identify some important and missing deficiencies."}, {"heading": "5. Conclusion", "text": "In this paper, we presented an approach dedicated to the definition of a generalization evaluation function. We proposed a method based on a human-machine dialogue and the collection of user preferences on generalization patterns. An experiment conducted in the field of cartographic generalization showed how our approach can help users define better evaluation functions. This work is still in the early stages. In the near future, we plan to conduct further experiments, in particular to study the effects of the original evaluation function on the results. Our long-term goal is to provide a method to learn user preferences for all objects and object groups in its data. The final stage of this research would be the automatic learning of a definitive evaluation method for a complete piece of map. Such a system would be able to conduct an automatic interview with the user, allowing him to specify his specific requirements for all characteristics of the map."}], "references": [{"title": "Quality Assessment of Cartographic Generalisation", "author": ["S Bard"], "venue": "Transactions in GIS,", "citeRegEx": "Bard,? \\Q2004\\E", "shortCiteRegEx": "Bard", "year": 2004}, {"title": "Integrating multi-agent, objectoriented, and algorithmic techniques for improved automated map generalization", "author": ["M Barrault", "N Regnauld", "C Duch\u00eane", "K Haire", "C Baeijs", "Y Demazeau", "P Hardy", "W Mackaness", "A Ruas", "R Weibel"], "venue": null, "citeRegEx": "Barrault et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Barrault et al\\.", "year": 2001}, {"title": "Constraints on rule formation", "author": ["K Beard"], "venue": null, "citeRegEx": "Beard,? \\Q1991\\E", "shortCiteRegEx": "Beard", "year": 1991}, {"title": "Applications of Machine Learning to Cognitive Radio Networks", "author": ["C Clancy", "J Hecker", "E Stuntebeck", "T O'Shea"], "venue": "Wireless Communications,", "citeRegEx": "Clancy et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Clancy et al\\.", "year": 2007}, {"title": "A method based on samples to capture user needs for generalisation, workshop on progress in automated map generalisation, Paris", "author": ["F Hubert", "A Ruas"], "venue": null, "citeRegEx": "Hubert and Ruas,? \\Q2003\\E", "shortCiteRegEx": "Hubert and Ruas", "year": 2003}, {"title": "Reducing graphic conflict in scale reduced maps using a genetic algorithm. Workshop on progress in automated map generalisation, Paris", "author": ["ID Wilson", "JM Ware", "JA Ware"], "venue": null, "citeRegEx": "Wilson et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Wilson et al\\.", "year": 2003}, {"title": "Learning local objective functions for robust face model fitting", "author": ["M Wimmer", "F Stulp", "S Pietzsch", "B Radig"], "venue": "IEEE Transactions on Pattern Analysis andMachine Intelligence,", "citeRegEx": "Wimmer et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wimmer et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 2, "context": "A classic approach consists in evaluating the generalisation quality by means of a set of constraints translating the expectation towards the generalisation (Beard, 1991).", "startOffset": 157, "endOffset": 170}, {"referenceID": 0, "context": "If the computation of individual constraint satisfaction values is often well-managed, the definition of the aggregating function remains complex (Bard, 2004).", "startOffset": 146, "endOffset": 158}, {"referenceID": 6, "context": "Many works were interested in the definition of these functions for specific problems (Wimmer et al., 2008) but few proposed general approaches for helping optimisation systems users to define it.", "startOffset": 86, "endOffset": 107}, {"referenceID": 6, "context": "This approach was used in several works, like (Wimmer et al., 2008) in the domain of computer vision, and (Clancy et al.", "startOffset": 46, "endOffset": 67}, {"referenceID": 3, "context": ", 2008) in the domain of computer vision, and (Clancy et al., 2007) for the learning of cognitive radio.", "startOffset": 46, "endOffset": 67}, {"referenceID": 1, "context": "Context Our experiment use a generalisation system based on the AGENT model (Barrault et al., 2001).", "startOffset": 76, "endOffset": 99}, {"referenceID": 0, "context": "However, the question of the constraint weight assignment is still asked (Bard, 2004).", "startOffset": 73, "endOffset": 85}], "year": 2012, "abstractText": null, "creator": "Word"}}}