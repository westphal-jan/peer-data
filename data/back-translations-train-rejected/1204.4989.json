{"id": "1204.4989", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Apr-2012", "title": "Using Belief Theory to Diagnose Control Knowledge Quality. Application to cartographic generalisation", "abstract": "Both humans and artificial systems frequently use trial and error methods to problem solving. In order to be effective, this type of strategy implies having high quality control knowledge to guide the quest for the optimal solution. Unfortunately, this control knowledge is rarely perfect. Moreover, in artificial systems-as in humans-self-evaluation of one's own knowledge is often difficult. Yet, this self-evaluation can be very useful to manage knowledge and to determine when to revise it. The objective of our work is to propose an automated approach to evaluate the quality of control knowledge in artificial systems based on a specific trial and error strategy, namely the informed tree search strategy. Our revision approach consists in analysing the system's execution logs, and in using the belief theory to evaluate the global quality of the knowledge. We present a real-world industrial application in the form of an experiment using this approach in the domain of cartographic generalisation. Thus far, the results of using our approach have been encouraging.", "histories": [["v1", "Mon, 23 Apr 2012 08:01:48 GMT  (528kb)", "http://arxiv.org/abs/1204.4989v1", "Best paper award, International Conference on Computing and Communication Technologies (IEEE-RIVF), Danang : Viet Nam (2009)"]], "COMMENTS": "Best paper award, International Conference on Computing and Communication Technologies (IEEE-RIVF), Danang : Viet Nam (2009)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["patrick taillandier", "c\\'ecile duch\\^ene", "alexis drogoul"], "accepted": false, "id": "1204.4989"}, "pdf": {"name": "1204.4989.pdf", "metadata": {"source": "CRF", "title": "Using Belief Theory to Diagnose Control Knowledge Quality", "authors": ["Patrick Taillandier", "Quang Buu", "C\u00e9cile Duch\u00eane", "Alexis Dogoul"], "emails": ["patrick.taillandier@gmail.com", "cecile.duchene@ign.fr", "alexis.drogoul@gmail.com"], "sections": [{"heading": null, "text": "Knowledge Quality Diagnosis; Belief Theory; Problem Solving; Informed Tree Search Strategy; Cartographic GeneralisationI. INTRODUCTION A classic problem-solving strategy is the application of a trial-and-error approach. This type of strategy is often effective. Although, when problems become really complex, the presence of relevant knowledge becomes necessary to limit the number of tests needed to find an optimal solution, it is unfortunately rare to have perfect knowledge. Moreover, translating expert knowledge into a formalism that can be used by computers is a difficult task. Eward Feigenbaum formulated this problem in 1977 as a knowledge bottleneck problem [8]. When it is difficult to acquire perfect knowledge, it is difficult for both humans and artificial systems to evaluate the quality of their knowledge themselves. In fact, the complete diagnosis of knowledge quality when multiple parts of knowledge are used to solve problems is complex."}, {"heading": "A. Description of the considered optimisation problem", "text": "In this paper, we are interested in a family of optimization problems that consist in solving the state of an entity that maximizes an evaluation function by applying measures. Let P be an optimization problem that results from: \u2022 EP: a class of entities \u2022 {Action} P: a series of actions that can be applied to a entity that belongs to EP. The result of the application of an action is supposedly unpredictable. \u2022 QP: a function that defines the state quality of a entity that belongs to EPAn instance P is defined by a unit ep of class EP that is characterized by its initial state. The solution of p is to find the state of ep that optimizes QP by comparing actions of {Action} P to the initial state of ep.Let's look at the following example: Probot is an optimization problem in which a robot considers its starting position in a labyrinth."}, {"heading": "B. Description of the considered systems", "text": "In this section, we present the generic system to which our diagnostic approach is dedicated. The system is based on a thorough in-depth examination of state trees. The transition from one state to another corresponds to the application of an action. Figure 1 is an example of state trees. To build the state tree, the system performs an action cycle. Figure 2 presents a classic action cycle. The action cycle begins with a description of the current state of the unit and its evaluation using the QP function. Then, the system checks whether the current state is good enough or whether it is necessary to continue exploring other states. If the system decides to continue exploration, it checks whether the current state is valid or not. If not, the system traces back the previous state. Otherwise, the system constructs a list of measures to be applied. If the action list is empty, the system selects the best measures and applies them."}, {"heading": "C. Control knowledge quality", "text": "The performance of systems based on an informed tree search strategy is directly related to the quality of their knowledge. System performance can be expressed in terms of efficiency and effectiveness. Effectiveness concerns the quality of the results achieved by the system, i.e. the quality of the best-found states. Efficiency concerns the time-consuming aspect of problem solving, i.e. the system speed for performing tree search. Good knowledge allows the system to be both effective and efficient, i.e. to lead the exploration directly to an optimal state without searching for useless states."}, {"heading": "D. Difficulties of the knowledge quality diagnosis", "text": "As we have defined in [25], diagnosing the quality of knowledge requires three kinds of difficulties: the first concerns the interdependence that might exist between the different parts of knowledge: sometimes it is not possible to determine whether a part of knowledge is really faulty or whether it is another part of knowledge that is faulty and influences the results of application of the first part of knowledge; the second type of difficulty concerns information that can be extracted from the study of a state tree. For example, while it is possible to extract information about the false positive errors of the validity criterion (if a state should not be considered valid), this remains impossible with regard to the false negative errors (if a state should be considered valid); in fact, if a state was deemed not valid, it is not possible to know whether it would have been possible to find a better state if the state had been considered valid (since the problem should have been considered solved by this problem)."}, {"heading": "A. General approach", "text": "Our goal is to automatically diagnose the knowledge quality of systems based on an informed tree search. We propose to apply the same general approach as in [25]. This approach is based on analyzing the execution protocols and applying a multi-criterion decision method (Figure 3). Every time an optimization problem instance is solved, the diagnostic module analyzes the successes and failures of each piece of knowledge during an analysis phase. It then checks whether the number of problem cases resolved since the last diagnosis (Nb _ instances) is high enough to make a new diagnosis. If the number of cases is high enough, the diagnostic module triggers a diagnostic phase consisting of evaluating each piece of knowledge and applying a multi-criterion decision method to evaluate the global knowledge quality."}, {"heading": "B. Analysis phase", "text": "In fact, the fact is that most of them will be able to be in a position to be in what they are in."}, {"heading": "C. Diagnosis phase", "text": "The diagnosis phase consists in the use of this information to determine the global quality of knowledge. Diagnosis is made according to different criteria: the quality of the individual parts of knowledge is represented by a marker that is defined between 0 and 1. In fact, this means that the piece of knowledge is very flawed. Marking for a piece of knowledge is represented by a marker that is defined between 0 and 1. Marking 0 means that the piece of knowledge is very flawed; a marker of 1 means that the piece of knowledge is a perfect one. Marking for a piece of knowledge K and for a solved problem Pn depends on the results that are achieved during the analysis phase. (Section IIIIIIIIII.B.1)"}, {"heading": "2\u0398 = {\u00f8, {VveryBad}, { Vbad}, ...,{VveryBad, Vbad}, \u2026 , \u0398}", "text": "Each proposition {Vi,..., Vj} represents the proposition that the solution of the problem is one of the hypotheses of this proposition. The theory of faith is based on the use of faith functions. For a given proposition, these functions assign a basic mass of faith, mj (P), which represents the degree of faith for criterion j that this proposition is true. The basic masses of faith are located between 0 and 1 and are defined as follows: 1Pm 2P j = preservation.) (b) Decision method Our method of decision, which is based on the theory of faith, derives from the one proposed by [15]. It consists of four steps (Figure 5).Step 1This first step consists in initializing the basic masses of faith. For this step we propose to use the works of [1]. He proposed to \"specialize\" the criteria for a hypothesis of the discriminatory framework."}, {"heading": "Si = {{V}i, {\u00acVi}, \u0398}", "text": "\"We have to take the quality of knowledge to another level.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \"\" \"We.\" \"\" \"We.\" \"\" \"We.\". \"\" \"We.\" \"\" We. \".\" \"\" We. \"\". \"\" We. \"\" \"We.\" \"\" We. \"\" \"We.\" \"\" \"We.\" \"\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \".\" \"\" We. \".\" \"\" We. \"\" \"We.\" \""}, {"heading": "A. Automatic cartographic generalisation", "text": "We propose to apply our diagnostic approach to the area of cartographic generalization. Cartographic generalization is a process that aims to reduce the detail of the geographical data in order to generate a map at a given scale. The aim of this process is to ensure the legibility of the map while retaining essential information of the initial data. Cartographic generalization requires the application of numerous operations such as object scaling, displacement and elimination. Figure 7 provides an example of cartographic generalization. Automation of the generalization process from vector geographical databases is an interesting industrial application context. In fact, this problem is far from being solved. Furthermore, it is of interest to cartographic agencies that want to improve their production lines for maps. Finally, the multiplication of websites that allow to create their own maps increases the needs of reliable and effective automated generalization processes."}, {"heading": "B. The generalisation system", "text": "The generalization system we use for our experiment is based on the AGENT model [2, 19] and follows the specification defined in Section II.B.2. It generalizes a geographical object or group of geographical objects by means of an informed tree search strategy. Each state represents the geometric state of the geographical objects under consideration and is evaluated by a satisfaction function. This function characterizes the respect of cartographic constraints (map specifications) by the geographical objects. For example, a cartographic constraint may be that a building is large enough to be readable. Satisfaction of a state lies between 1 and 10 (10 represents a perfect state and a value below 5, an unacceptable state)."}, {"heading": "C. Application of our diagnosis approach", "text": "We used our diagnostic approach to evaluate the knowledge quality of our generalization system.With regard to the effectiveness evaluation function, we used this function: {} 220) () (pppn pSMean () pSile () pSile () pSile (FirstQuart) ess (PEffectivenwith S (p) return the best satisfaction found for the generalization of an object p.This function makes it possible to take into account the average satisfaction of the generalized object and to balance this result with the first quartile satisfaction value. The interest of this weighting stems from the fact that it is preferable for theme agencies to get three quarters of well generalized objects and one quarter of poorly generalized objects (which can be retouched by technicians) instead of obtaining average homogeneous results (which require much more retouching).The factor 1 / 20 is used to normalize the value of this function."}, {"heading": "D. Case study", "text": "The real case study we carried out concerned the generalisation of assemblies. The generalisation of assemblies is an interesting case study because it is not yet well managed and because it is very time consuming. We have defined, with the help of cartographic experts, six limitations and five measures for generalising assemblies. We have applied our diagnostic approach with four sets of knowledge. Each of these sets of knowledge corresponds to a different scenario for using the generalisation system: \u2022 KmostEfficient: Knowledge set that does not propose any action. In fact, this knowledge ensures that only the initial state is visited and thus the best possible efficiency is achieved. However, the quality of the result (which corresponds to the initial state) is very poor. \u2022 KsmEffective: Knowledge set that applies all possible measures for all states and uses the weak validity and final criteria. For each generalised assembly, this knowledge ensures that the best possible state is achieved, taking into account the limitations and measures used."}, {"heading": "E. Results", "text": "We recall that we have defined five levels of knowledge quality: very bad, bad, average, good, very good. KmostEfficient is classified as bad knowledge with a 100% share of the vote. KmostEffective and KExpert are classified as average knowledge; the first with a 50% share of the vote and the second with a 100% share of the vote. The last knowledge, KRevised, is classified as good knowledge with a 100% share of the vote. These results are consistent with the quantities of knowledge tested. In fact, the only knowledge that is classified as bad is KmostEfficient, for which no action is taken: the cartographic results obtained are unacceptable. The only knowledge that is classified as good is KRevised, which is a revised version of KExpert and which gives good results both in terms of efficiency and effectiveness. The other two knowledge groups were classified as average."}], "references": [{"title": "Probabilit\u00e9 et incertitude en fusion de donn\u00e9es multisenseurs", "author": ["A. Appriou"], "venue": "Revue Scientifique et Technique de la D\u00e9fense 1", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1991}, {"title": "Integrating multi-agent", "author": ["M. Barrault", "N. Regnauld", "C. Duch\u00eane", "K. Haire", "C. Baejis", "Y. Demazeau", "P. Hardy", "W. Mackaness", "A. Ruas", "R. Weibel"], "venue": "object-oriented, and algorithmic techniques for improved automated map generalization. In ICC", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "J", "author": ["R. Benayoun", "O. Laritchev"], "venue": "de Mongolfier, and J. Tegny, Linear programming with multiple objective functions: STEP method (STEM). Math. Program., 1, 3", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1971}, {"title": "Introduction aux m\u00e9thiodes multicrit\u00e8res d'aide \u00e0 la d\u00e9cision", "author": ["S. Ben Mena"], "venue": "Biotechnol. Agro. Soc. Environ. 4(2)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "A review and conceptual framework of automated map generalization", "author": ["K. Brassel", "R. Weibel"], "venue": "IJGIS", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1988}, {"title": "Creative Cartography based on Dialogue", "author": ["S. Christophe"], "venue": "'In proceedings of AutoCarto', Shepherdstown, West Virginia", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Upper and lower probabilities induced by multivalued mapping", "author": ["A. Dempster"], "venue": "Annals of Mathematical Statistics 38", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1967}, {"title": "The art of artificial intelligence 1: Themes and case studies of knowledge engineering.", "author": ["E. Feigenbaum"], "venue": "Technical report,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1977}, {"title": "An interactive approach for multicriterion optimisation with an application to the operation of an academic department", "author": ["A. Geoffrion", "J. Dyer", "A. Feinberg"], "venue": "Manage. Sci., 19, 4", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1972}, {"title": "A method based on samples to capture user needs for generalisation", "author": ["F. Hubert", "A. Ruas"], "venue": "'fifth workshop on progress in automated map generalisation', Paris", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "A review of goal programming: a tool for multi objective analysis", "author": ["J.P. Ignizio"], "venue": "J. Oper. Res. Soc., 29, 11", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1978}, {"title": "Automated learning multi-criteria classifiers for FLIR ship imagery classification", "author": ["K. Jabeur", "A. Guitouni"], "venue": "10th International Conference on Information ,9 ,12", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "Assessing a set of additive utility functions for multicriteria decision making", "author": ["E. Jacquet-Lagreze", "J. Siskos"], "venue": "The UTA method. Eur. J. Oper. Res., 10, 2", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1982}, {"title": "A statistical theory of target detection by pulsed radar", "author": ["J. Marcum"], "venue": "IEEE Trans. Info. Thry.Apr", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1960}, {"title": "Data matching-a matter of belief", "author": ["A.M. Olteanu-Raimond", "S. Musti\u00e8re"], "venue": "'The International Symposium on Spatial Data Handling' (SDH), Montpellier, France", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "A new approach for impacts assessment of urban mobility", "author": ["H. Omrani", "L. Ion-Boussier", "P. Trigano"], "venue": "'WSEAS transaction on Information science and applications' 4(3)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "A missing link in OR-AD: Robustness analysis", "author": ["B. Roy"], "venue": "Foundations of Computing and Decision Science, 23, 3", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}, {"title": "The outranking approach and the foundations of ELECTRE methods", "author": ["B. Roy"], "venue": "Theory and Decision, 31", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1991}, {"title": "A Prototype Generalisation System Based on the Multi-Agent Paradigm", "author": ["A. Ruas", "C. Duch\u00eane"], "venue": "Generalisation of Geographic Information: Cartographic Modelling and Applications", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "A mathematical theory of evidence", "author": ["G. Shafer"], "venue": "Princeton University Press", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1976}, {"title": "A bibliography of outranking approaches", "author": ["J. Siskos", "G. W\u00e4scher", "H. Winkels"], "venue": "Cahiers du Lamsade, Paris Dauphine", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1983}, {"title": "Constructing the pignistic probability function in a context of uncertainty", "author": ["P. Smets"], "venue": "Uncertainty in Artificial Intelligence 5", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1990}, {"title": "The transferable belief model", "author": ["P. Smets", "R. Kennes"], "venue": "Artificial Intelligence 66(2)", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1994}, {"title": "Signal detection and recognition by human observers", "author": ["J.A. Swets"], "venue": "New York: Wiley", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1964}, {"title": "Knowledge diagnosis in systems based on an informed tree search strategy: application to cartographic generalisation", "author": ["P. Taillandier"], "venue": "'CSTST Student Workshop', Cergy-Pontoise, France", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Knowledge revision in systems based on an informed tree search strategy: application to cartographic generalisation", "author": ["P. Taillandier", "C. Duch\u00eane", "A. Drogoul"], "venue": "CSTST. Cergy-Pontoise, France", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "Aide multicrit\u00e8re \u00e0 la d\u00e9cision dans le cadre de la probl\u00e9matique du tri : Concepts, m\u00e9thodes et applications", "author": ["W. Yu"], "venue": "The\u0300se a\u0300 Universite\u0301 Paris Dauphine", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1992}], "referenceMentions": [{"referenceID": 7, "context": "Eward Feigenbaum formulated this problem in 1977 as the knowledge acquisition bottleneck problem [8].", "startOffset": 97, "endOffset": 100}, {"referenceID": 24, "context": "As we defined in [25], the knowledge quality diagnosis requires facing three types of difficulties.", "startOffset": 17, "endOffset": 21}, {"referenceID": 24, "context": "We propose to use the same general approach than the one we presented in [25].", "startOffset": 73, "endOffset": 77}, {"referenceID": 24, "context": "In order to compute the values of these measures, we propose to use the same approach than the one we proposed in [25]: this one is based on the analysis of the best paths.", "startOffset": 114, "endOffset": 118}, {"referenceID": 10, "context": "Among them, several approaches aim at aggregating all criteria in a single criterion (utility function) which is then used to make the decision [11, 13].", "startOffset": 144, "endOffset": 152}, {"referenceID": 12, "context": "Among them, several approaches aim at aggregating all criteria in a single criterion (utility function) which is then used to make the decision [11, 13].", "startOffset": 144, "endOffset": 152}, {"referenceID": 17, "context": "Another approach consists in comparing the different possible decisions per pair by the mean of outranking relations [18, 21, 27].", "startOffset": 117, "endOffset": 129}, {"referenceID": 20, "context": "Another approach consists in comparing the different possible decisions per pair by the mean of outranking relations [18, 21, 27].", "startOffset": 117, "endOffset": 129}, {"referenceID": 26, "context": "Another approach consists in comparing the different possible decisions per pair by the mean of outranking relations [18, 21, 27].", "startOffset": 117, "endOffset": 129}, {"referenceID": 2, "context": "A last approach, which is highly interactive, consists in devising a preliminary solution and in comparing it with other possible solutions to determine the best one [3, 9].", "startOffset": 166, "endOffset": 172}, {"referenceID": 8, "context": "A last approach, which is highly interactive, consists in devising a preliminary solution and in comparing it with other possible solutions to determine the best one [3, 9].", "startOffset": 166, "endOffset": 172}, {"referenceID": 24, "context": "We proposed in [25] to solve a similar problem (with only two levels of knowledge quality) by using the ELECTRE TRI method.", "startOffset": 15, "endOffset": 19}, {"referenceID": 3, "context": "This method allows to face the problem of criterion incompatibility but it lacks of clarity [4].", "startOffset": 92, "endOffset": 95}, {"referenceID": 13, "context": "In this paper, we propose to use a method inheriting from the signal detection theory [14, 24] to solve our decision making problem.", "startOffset": 86, "endOffset": 94}, {"referenceID": 23, "context": "In this paper, we propose to use a method inheriting from the signal detection theory [14, 24] to solve our decision making problem.", "startOffset": 86, "endOffset": 94}, {"referenceID": 19, "context": "Indeed, we propose to use the belief theory [20] that allows to manage the criteria incompleteness, uncertainly and imprecision and thus is particularly adapted to our problem.", "startOffset": 44, "endOffset": 48}, {"referenceID": 6, "context": "3) Application of the belief theory a) Generality on the belief theory The belief theory is based on the work of Dempster in 1967 [7] on lower and upper probability distributions.", "startOffset": 130, "endOffset": 133}, {"referenceID": 14, "context": "It was applied successfully on numerous problems [15, 16].", "startOffset": 49, "endOffset": 57}, {"referenceID": 15, "context": "It was applied successfully on numerous problems [15, 16].", "startOffset": 49, "endOffset": 57}, {"referenceID": 14, "context": "b) Decision making method Our decision making method, which is based on the belief theory, is derived from the one proposed by [15].", "startOffset": 127, "endOffset": 131}, {"referenceID": 0, "context": "For this step, we propose to use the works of [1].", "startOffset": 46, "endOffset": 49}, {"referenceID": 21, "context": "We propose to use the fusion operator introduced by [22] to compute the belief masses resulting from the combination of two criteria:", "startOffset": 52, "endOffset": 56}, {"referenceID": 6, "context": "We propose to use the Dempster operator [7] to compute the belief masses resulting from the combination of two hypotheses:", "startOffset": 40, "endOffset": 43}, {"referenceID": 22, "context": "Thus, we propose to use the pignistic probability defined by [23] to make the decision.", "startOffset": 61, "endOffset": 65}, {"referenceID": 16, "context": "a) Decision robustness analysis A key issue of decision making is the robustness of the decision [17].", "startOffset": 97, "endOffset": 101}, {"referenceID": 4, "context": "One approach to solve it is to use a local, step-by-step and knowledge-based method [5]: each vector object of the database (representing a building, a road segment, etc.", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "The generalisation system The generalisation system that we use for our experiment is based on the AGENT model [2, 19] and follows the specification defined in Section II.", "startOffset": 111, "endOffset": 118}, {"referenceID": 18, "context": "The generalisation system The generalisation system that we use for our experiment is based on the AGENT model [2, 19] and follows the specification defined in Section II.", "startOffset": 111, "endOffset": 118}, {"referenceID": 25, "context": "The knowledge set was revised off-line with the approach proposed in [26].", "startOffset": 69, "endOffset": 73}, {"referenceID": 5, "context": "Several existing works could be used as base for the development of such a method [6, 10].", "startOffset": 82, "endOffset": 89}, {"referenceID": 9, "context": "Several existing works could be used as base for the development of such a method [6, 10].", "startOffset": 82, "endOffset": 89}, {"referenceID": 11, "context": "In order to elicit these parameter values, works like [12] proposed to use machine learning techniques.", "startOffset": 54, "endOffset": 58}], "year": 2009, "abstractText": "Both humans and artificial systems frequently use trial and error methods to problem solving. In order to be effective, this type of strategy implies having high quality control knowledge to guide the quest for the optimal solution. Unfortunately, this control knowledge is rarely perfect. Moreover, in artificial systems--as in humans--self-evaluation of one\u2019s own knowledge is often difficult. Yet, this self-evaluation can be very useful to manage knowledge and to determine when to revise it. The objective of our work is to propose an automated approach to evaluate the quality of control knowledge in artificial systems based on a specific trial and error strategy, namely the informed tree search strategy. Our revision approach consists in analysing the system\u2019s execution logs, and in using the belief theory to evaluate the global quality of the knowledge. We present a real-world industrial application in the form of an experiment using this approach in the domain of cartographic generalisation. Thus far, the results of using our approach have been encouraging. Knowledge Quality Diagnosis; Belief Theory; Problem Solving; Informed Tree Search Strategy; Cartographic Generalisation", "creator": "IEEE Conference eXpress"}}}