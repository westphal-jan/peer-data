{"id": "1205.1794", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2012", "title": "A Novel Method For Speech Segmentation Based On Speakers' Characteristics", "abstract": "Speech Segmentation is the process change point detection for partitioning an input audio stream into regions each of which corresponds to only one audio source or one speaker. One application of this system is in Speaker Diarization systems. There are several methods for speaker segmentation; however, most of the Speaker Diarization Systems use BIC-based Segmentation methods. The main goal of this paper is to propose a new method for speaker segmentation with higher speed than the current methods - e.g. BIC - and acceptable accuracy. Our proposed method is based on the pitch frequency of the speech. The accuracy of this method is similar to the accuracy of common speaker segmentation methods. However, its computation cost is much less than theirs. We show that our method is about 2.4 times faster than the BIC-based method, while the average accuracy of pitch-based method is slightly higher than that of the BIC-based method.", "histories": [["v1", "Tue, 8 May 2012 19:54:13 GMT  (378kb)", "http://arxiv.org/abs/1205.1794v1", "14 pages, 8 figures"]], "COMMENTS": "14 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["behrouz abdolali", "hossein sameti"], "accepted": false, "id": "1205.1794"}, "pdf": {"name": "1205.1794.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Behrouz Abdolali", "Hossein Sameti"], "emails": ["abdolali@ce.sharif.edu", "sameti@sharif.edu"], "sections": [{"heading": null, "text": "DOI: 10.5121 / sipij.2012.3205 65Speech Segmentation is the detection of process change points to divide an input of audio streams into regions that correspond to only one audio source or one speaker. An application of this system is in Speaker Diarization Systems. There are several methods for speaker segmentation, but most Speaker Diarization Systems use BIC-based segmentation methods. The main objective of this essay is to propose a new method for speaker segmentation that operates at a higher speed than current methods - e.g. BIC - and acceptable accuracy. Our proposed method is based on the pitch frequency of the language. The accuracy of this method is similar to the common speaker segmentation method. However, its calculation costs are much lower than yours. We show that our method is about 2.4 times faster than the BICbased method, while the average segmentation accuracy of the speaker-based BICech method is slightly higher than the ORgech-based method."}, {"heading": "1. INTRODUCTION", "text": "The process of detecting loudspeaker changes from one loudspeaker to another is an important task in many speech processing applications. This task is done before audio indexing, speaker recognition, automatic transcription, information extraction, speech summary and query [1] [2] [3]. An audio stream can be divided into different homogeneous parts by recognizing the specific speech characteristics of individual loudspeakers, a process commonly known as speaker replacement detection or speaker segmentation. In recent years, there have been three broad categories of audio segmentation techniques: metric, model-based and hybrid methods. Each of these methods has its advantages and disadvantages, which will be discussed in the next section. The most common methods of loudspeaker segmentation are the metric methods used in the Bajian information criterion (BIC). Since these methods suffer from a large amount of calculations, they are very time-consuming; nevertheless, these methods are highly precise."}, {"heading": "2. A SURVEY ON SPEAKER SEGMENTATION METHODS", "text": "In fact, most of them are unable to play by the rules they have set themselves."}, {"heading": "2.1. Speaker Segmentation based on BIC measure", "text": "Since BIC-based methods are the most common segmentation methods used today, we will focus on these methods in detail. BIC is a criterion for selecting a model for a group of data represented by Schwarz [21]. Suppose we have a group of data (X) and a model to describe these data (M). The BIC criterion for this model is represented in Equation 1. (1) = log | # 2 logIn this equation, P (X | M) is the probability value of data X to model M. # M represents the number of free parameters in model M. N represents the number of samples in data X. In the other word, BIC measures the probability of the model and data and evaluates the model [22]. In the above equation, the strain factor we set to zero is. BIC changes to GLR [23]. To achieve the expected performance for a specific corpus, we could adjust the corresponding value [24]."}, {"heading": "2.1.1. Increasingsize window method for calculating", "text": "As shown in Figure 2, we consider an initial size for the window in which N enlarges its size by Ng until a modification point is found based on the BIC criterion. A higher band for the window size, Nmax, is also determined. If a modification point is detected before the window size is increased to Nmax, the point is marked and the process starts from this point with the initial window size. Otherwise, after N repetitions are achieved [23], it is noteworthy that this method requires, as required, lower power and requires more processing power. (1,) E, 4E56. / 0 1 | 3, 4 56 12 FG + 1 2 G (G + 1) H log + 1 2 d (d + 1) H log + 1 is the dimension of the cepstralis called strain factor, if set to zero, BIC changes to K 0, this means that the number of writing data is equal by two log + 1 sid (1)."}, {"heading": "2.1.2. Fixed-Size sliding window method for calculating \u2206LMN", "text": "In this method, a fixed-size window is considered and \u0394is calculated by sliding over the steam. The window size depends on the length of the current. Setting the window size and \u03bb parameters to optimum values results in higher power and accuracy. It is obvious that this method requires less computing power, but its accuracy is lower than the previous one. According to the experiment, the window size of 1 second is good for short currents of several minutes [23]. In this thesis, we have implemented the first method to compare the best accuracy achieved by BIC-based methods with our proposed method."}, {"heading": "3. THEORETICAL TOPICS ABOUT PITCH FREQUENCY", "text": "In this section, after a brief look at pitch frequency characteristics, we will consider some important methods for pitch extraction."}, {"heading": "3.1. Pitch Frequency and Its Characteristics", "text": "The tone frequency is the basic harmony of the speech signal. In other words, it is the fundamental frequency of the vibrations of the human vocal cords. More like the sinusoidal wave is the waveform of the signal, more clearly the sense of frequency and less clearly the sense of tonal value. [26] Likewise more harmonious are the frequency components, more clearly the sense of tonal value and less clearly the sense of frequency [27,28,29]."}, {"heading": "3.2. Pitch frequency extraction methods", "text": "There are several methods for estimating the fundamental frequency of f0. Nevertheless, it is difficult to propose a method that estimates f0 well without taking into account the content of the signal. Therefore, in the environment where both music and speech signals exist, pitch estimators should be precise in both range.The difficulty in detecting f0 in a wavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewavewawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawawa"}, {"heading": "3.2.1. Pitch Detection using autocorrelation function (ACF)", "text": "Our perception of pitch frequency is closely related to our perception of the periodicity of the waveform in the time domain. The method that can determine the fundamental frequency of a signal on the basis of its waveform is the autocorrelation method [31]. The autocorrelation function of a signal s [n] is shown in Equation 8, in which \u03c4 is the delay or time shift. By calculating this function and recognizing its maximum points, we can estimate the pitch frequency of the signal s [n]."}, {"heading": "3.2.2. Pitch Detection using cepstral method", "text": "Suppose a sequence of speech samples is the result of applying folding functions to the order of the glottal excitation e [n] (8) O (P) = Q R (B). TUVW R (B + P) and the discrete impulse response of the vocal tract \u03b8 [n]. In the frequency range, the folding operator changes to the multiplication operator. Using the characteristics of the algorithm function (log (A.B) = log (A) + log (B), the multiplication operator could be changed to the addition operator. Finally, the real cepstrum of a signal is expressed by the formula s [n] = e [n] * \u03b8 [n], which is in Equation 9.In the formula S (\u03c9) above: (10) X (Y) = Q R [B]\\ T] U ^ _ UVT _ Therefore, the cepstrum is the result of applying Fourier to the basic form of the transformation spectrum, if the distance between the respective signal measure corresponds to the logarithm."}, {"heading": "3.2.3. Pitch Detection using average magnitude difference function (AMDF)", "text": "The AMDF concept is very close to the ACF concept, except that in this function the amplitude difference between the frame and its delayed version is estimated instead of estimating the similarity between them. AMDF calculation is presented in Equation 11. In this equation, the time span in relation to language samples is specified, the value \u03c4, for which AMDF (\u03c4) is minimal in a certain range, is selected as the time period of pitch. In other words, the delayed version of the frame is shifted n times and the absolute value of the sum of the difference in overlapping sections is calculated to produce n AMDF value. The pitch value is the result of the division of the sampling frequency by speech sample corresponding to the first local minimum in the AMDF function."}, {"heading": "4. SPEAKER SEGMENTATION USING PROPOSED METHOD", "text": "Since distance-based loudspeaker segmentation methods, such as the BIC method, use receiver features such as the Mel Frequency Cepstral Coefficient (MFCC), however, there are other feature vectors that can be used for this purpose. In addition, prosodic features such as pitch frequency can be used to facilitate the distinction between voice and silence. Pitch change diagram is a well-suited means of detecting loudspeaker changes [32]. There are three reasons to use pitch frequency for detecting loudspeaker changes: 1 - Each loudspeaker has its own pitch frequency, which differs from others. 2- When the loudspeaker changes, the pitch frequency diagram changes rapidly. (9) c [n] = 12 b log | S (\u03c9) | efghd\u043e iTi (11) j kl (P) = Q | X (X) (X) (X) + m (P)."}, {"heading": "5. ACCURACY IMPROVEMENT OF PROPOSED METHOD", "text": "Even during a speaker's speech, it is possible to make rapid changes in pitch frequency. In these cases, the error rate of the false alarm (FA) increases. This is the result of considering every point above the threshold as the point of the speaker change. Another problem with this method is the possibility of a speaker change, while changes in pitch frequency are not very quickly above the predefined threshold. Therefore, we may be able to increase these points of speaker change and errors in the error rate of Miss Detection (MD). To solve this problem in a way, it may be to choose the threshold below the missed points. Obviously, this is not an efficient method, as many other points that are not real speaker changes are placed above the threshold and are incorrectly reported as change points. As a result, the error rate of the MD decreases at the expense of increasing pitch change."}, {"heading": "6. THE EVALUATION MEASURES FOR", "text": "It is obvious that a standard evaluation method should be introduced for each system. It is also necessary for segmentation systems. In this section, we will discuss these measures and standard evaluation methods for segmentation systems. The results of this work are based on these methods. [33] The error rate at high FA rates remains the same. ToBIC windows with a length of 0.1s.Experimental results show that the RPSS methodology SEGMENTATION METHODSThe functioning of the system for recorded sessions could be analyzed. However, valid results are those based on sessions in a language corpus. There are several corpses, some of which are important: NIST, AMI and TMIT.For the evaluation of segmentation systems, some measures are used that represent the comparison between detected change points and real change points in the corpus. The most important measures used are% FD and% FR, which change as calculated in Equations 14.15\\ k = 14 points\\ lp / qm in the system."}, {"heading": "7. EXPERIMENTAL RESULTS", "text": "In this section, with the help of diagrams resulting from the modification of important parameters involved in the calculations of the improved proposed method, we want to investigate the effects of these parameters on the accuracy and performance of the proposed method. In this post, we apply our method to four AMI sessions. These sessions are randomly selected and the names of the sessions are included in corresponding tables. Diagrams show the averages achieved in four experiments. Threshold coefficient is a parameter that determines the acceptable value of pitch changes relative to the global maximum. This means that if this factor is 0.7, changes above the 0.7 of the global maximum are considered as speaker interchanges. It is important to take into account the effects of changes in this parameter on the accuracy and performance of the proposed method. Higher evaluation of this parameter leads to less FA and more MD and vice versa. Experimental results show that the value of 0.75 is well suited for our purpose.Based on the diagrams we understand that the increase in the value of the gamma correction of the accuracy of the 0.3 is achieved, the one of the accuracy of the method concerned."}, {"heading": "8. CONCLUSION", "text": "This paper proposes a fast and precise method of loudspeaker segmentation for loudspeaker diarization applications, which is based on pitch changes and is better in terms of runtime than the BIC-based method. Its disadvantage of lower accuracy is also complemented by innovative techniques, namely the gamma correction function and the BIC-based double check of candidate points. Using the novel techniques, we achieve a performance of 2.4 times faster than the BIC-based methods and benefit from the same accuracy."}], "references": [{"title": "speaker tracking system based on speaker turn detection for NIST evaluation", "author": ["J.F.", "P. Delacourt", "C. Fredouille", "T. Merlin", "Wellekens", "C. Bonastre"], "venue": ", Istanbul, 2000, pp. 1177\u20131180.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Speaker tracking in broadcast audio material in the frame work of the THISL project", "author": ["L.", "Boite", "J.M. Couvreur"], "venue": ", 1999, pp. 84-89.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Speaker change detection and tracking in real time news broadcasting analysis", "author": ["L.", "Zhang", "H.J. Lu"], "venue": ", 2002, pp. 602-610.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Speaker indexing for news articles debates and drama in broadcasted TV programs", "author": ["Y. Ariki M. Nishida"], "venue": "Proceeding of the Speech Recognition Workshop, 1997, pp. 67\u201372.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1997}, {"title": "Speaker tracking in broadcast audio material in the frame work of the THISL project", "author": ["J.M. Boite L. Couvreur"], "venue": "Proceeding of the Workshop on accessing information in spoken audio(ESCA- ETRW99), 1999, pp. 84-89.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1999}, {"title": "Automatic audio segmentation using the Generalized Likelihood Ratio", "author": ["D. Wang", "R. Vogt", "M. Mason", "S. Sridharan"], "venue": ", Gold Coast, pp. 1-5.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 0}, {"title": "Speaker, environment and channel change detection and clustering via the Bayesian Information Criterion", "author": ["P.Gopalakrishnan. S. Chen"], "venue": ", 1998.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1998}, {"title": "Improved speaker segmentation and segments clustering using the Bayesian Information Criterion", "author": ["R. Gopinath A. Tritschler"], "venue": ", 1999.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1999}, {"title": "Unsupervised audio stream segmentation and clustering via the Bayesian Information Criterion", "author": ["John H.L. Hansen B.W. Zhou"], "venue": ", 2000.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2000}, {"title": "Hybrid speaker based segmentation system using model level clustering", "author": ["D. Elter", "T. Sikora H. Kim"], "venue": "pp. 745\u2013748, 2005.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Automatic segmentation of speech recorded in unknown noisy channel characteristics", "author": ["J.H.L. Hansen B.L. Pellom"], "venue": "vol. 25, no. 1-3, pp. 97\u2013116.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 0}, {"title": "speech/music segmentation using entropy and dynamism features in a HMM classification framework", "author": ["I. McCowan", "H. Bourland. J. Ajmera"], "venue": "vol. 40, no. 3, pp. 351\u2013363, 2003.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Speaker change detection and tracking in real time news broadcasting analysis", "author": ["H.J. Zhang L. Lu"], "venue": ", 2002, pp. 602\u2013610.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "the LIMSI broadcast news transcription system", "author": ["L. Lamel", "G. Adda J. Gauvain"], "venue": "vol. 37, pp. 89\u2013108, 2002.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "Speech discrimination based on multiscale spectro-temporal modulations", "author": ["S. Shamma", "M. Slaney S. Mesgarani"], "venue": ", 2004, pp. 601\u2013604.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Evaluation of classification techniques for audio indexing", "author": ["J. Pinquier", "R. Ande-Obrecht J.A. Arias"], "venue": ", 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Unsupervised speaker change detection using SVM misclassification rate", "author": ["J. Wang", "J. Wang", "H. Sung P. Lin"], "venue": "vol. 56.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 0}, {"title": "Speaker segmentation and clustering", "author": ["V. Moschou", "C. Kotropoulas M. Kotti"], "venue": "Signal processing, vol. 88, pp. 091\u20131124, 2007.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Hybrid Speaker based segmentation system using model level clustering", "author": ["D. Elter", "T. Sikora H. Kim"], "venue": ", 2005, pp. 745\u2013748.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "Step by step and integrated approaches in broadcast news speaker diarization", "author": ["D. Moraru", "C. Fredouille", "J.F. Bonastre", "L.Besacier S. Meignier"], "venue": "vol. 20, pp. 303-330, 2006.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "The Annals of Statistics, vol. 6, no. 2, pp. 461- 464, Mar. 1978.  Signal & Image Processing : An International Journal (SIPIJ) Vol.3, No.2, April 2012 78", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1978}, {"title": "Speaker Diarization in Meetings Domain", "author": ["Nguyen Trung Hieu"], "venue": "School of Computer Engineering, Nanyang Technological University, Proposal for admission to the Degree of Doctor of Philosophy Sept. 2009.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "BIC-Based Speaker Segmentation Using Divide-and-Conquer Strategies With Application to Speaker Diarization", "author": ["Shih-Sian Cheng", "Hsin-Min Wang", "Hsin-Chia Fu"], "venue": "IEEE Transaction on Audio, Speech, and Language Processing, vol. 18, no. 1, pp. 141 \u2013 157, Jan. 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "BIC-based audio segmentation by divide-andconquer", "author": ["Shih-Sian Cheng", "Hsin-Min Wang", "Hsin-Chia Fu"], "venue": "Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference on, Las Vegas, NV, Apr. 2008, pp. 4841 - 4844.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "DISTBIC:a speaker-based segmentation for audio data indexing", "author": ["C.J.Wellekens P.Delacourt"], "venue": "Elsevier Jornal on Speech Communication, vol. 32, no. 1-2, pp. 111-126, Sept. 2000.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2000}, {"title": "Handbook for Acoustic Ecology, 2nd ed", "author": ["Barry Truax"], "venue": "Vancouver: A.R.C. Publication,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1999}, {"title": "Auditory Scene Analysis", "author": ["Albert Bregman"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1990}, {"title": "Hearing: Handbook of Perception and Cognition, 2nd, Ed", "author": ["B.C.M. Moore"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1995}, {"title": "Pitch Extraction and Fundamental Frequency: History and Current Techniques", "author": ["David Gerhard"], "venue": "Department of Computer Science, Technical Report TR-CS 2003-06, Nov. 2003.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2003}, {"title": "A Pitch-Based Rapid Speech Segmentation for Speaker Indexing", "author": ["Y. Yang", "M. Yang"], "venue": "IEEE International Symposium on Multimedia (ISM'05), Irvine, California, 2005.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2005}, {"title": "C.Gonzalez, Digital Image Processing.", "author": ["Richard E.Woods", "Rafael"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "This task is done before audio indexing, speaker identification, automatic transcription, information extraction, speech summarization and retrieval [1][2][3].", "startOffset": 149, "endOffset": 152}, {"referenceID": 1, "context": "This task is done before audio indexing, speaker identification, automatic transcription, information extraction, speech summarization and retrieval [1][2][3].", "startOffset": 152, "endOffset": 155}, {"referenceID": 2, "context": "This task is done before audio indexing, speaker identification, automatic transcription, information extraction, speech summarization and retrieval [1][2][3].", "startOffset": 155, "endOffset": 158}, {"referenceID": 3, "context": "It is assumed that the sentences uttered by different speakers in a conversation are delimited by pauses [4].", "startOffset": 105, "endOffset": 108}, {"referenceID": 4, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 39, "endOffset": 42}, {"referenceID": 5, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 77, "endOffset": 80}, {"referenceID": 6, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 121, "endOffset": 124}, {"referenceID": 7, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 124, "endOffset": 127}, {"referenceID": 8, "context": ", the Kullback-Leibler distance(KL,KL2)[5], generalized likelihood ratio(GLR)[6] and Bayesian Information Criterion(BIC) [7][8][9].", "startOffset": 127, "endOffset": 130}, {"referenceID": 9, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 66, "endOffset": 70}, {"referenceID": 10, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 71, "endOffset": 75}, {"referenceID": 11, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 113, "endOffset": 117}, {"referenceID": 13, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 119, "endOffset": 123}, {"referenceID": 14, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 157, "endOffset": 161}, {"referenceID": 15, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 163, "endOffset": 167}, {"referenceID": 16, "context": "The models can be created by means of hidden Markov models (HMMs) [10],[11] ,[12] ,Gaussian mixture models (GMM) [13], [14] or support vector machines (SVM) [15], [16], [17].", "startOffset": 169, "endOffset": 173}, {"referenceID": 17, "context": "Hybrid based methods combine metric and model based techniques [18].", "startOffset": 63, "endOffset": 67}, {"referenceID": 18, "context": "In [19], HMMs are combined with BIC.", "startOffset": 3, "endOffset": 7}, {"referenceID": 19, "context": "Another hybrid system is introduced in [20] where two systems are combined namely LIA system, which is based on HMMs and the CLIPS system, which performs BIC based speaker segmentation followed by hierarchical clustering.", "startOffset": 39, "endOffset": 43}, {"referenceID": 20, "context": "67 proposed by Schwarz[21].", "startOffset": 22, "endOffset": 26}, {"referenceID": 21, "context": "In the other word, BIC measures the likelihood of the model and data and scores the model[22].", "startOffset": 89, "endOffset": 93}, {"referenceID": 22, "context": "If \u03bb is set to zero, BIC changes to GLR[23].", "startOffset": 39, "endOffset": 43}, {"referenceID": 23, "context": "To achieve the expected performance for a specific corpus, we could adjust \u03bb value[24].", "startOffset": 82, "endOffset": 86}, {"referenceID": 20, "context": "As described in [21], maximizing BIC results in maximizing the expected value of likelihood of model and data.", "startOffset": 16, "endOffset": 20}, {"referenceID": 20, "context": "Therefore, BIC could be used to select the best model of a group of data[21,22].", "startOffset": 72, "endOffset": 79}, {"referenceID": 21, "context": "Therefore, BIC could be used to select the best model of a group of data[21,22].", "startOffset": 72, "endOffset": 79}, {"referenceID": 23, "context": "Therefore, the problem of checking if a single speaker change point exists in the frame, could be transformed to a model selection problem[24].", "startOffset": 138, "endOffset": 142}, {"referenceID": 17, "context": "[18].", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Hypothetic models for segmentation of one speech frame[25].", "startOffset": 54, "endOffset": 58}, {"referenceID": 22, "context": "In this equation, \u03bb GLR[23].", "startOffset": 23, "endOffset": 27}, {"referenceID": 22, "context": "Otherwise, after reaching N repeats[23].", "startOffset": 35, "endOffset": 39}, {"referenceID": 22, "context": "were proposed in [23].", "startOffset": 17, "endOffset": 21}, {"referenceID": 22, "context": "According to experiment, for short streams about some of minutes, the window size of 1 second is well[23].", "startOffset": 101, "endOffset": 105}, {"referenceID": 25, "context": "[26] Likewise, more harmonic to each other are frequency components, more clearly the sense of pitch and less clearer the sense of frequency[27,28,29]", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[26] Likewise, more harmonic to each other are frequency components, more clearly the sense of pitch and less clearer the sense of frequency[27,28,29]", "startOffset": 140, "endOffset": 150}, {"referenceID": 27, "context": "[26] Likewise, more harmonic to each other are frequency components, more clearly the sense of pitch and less clearer the sense of frequency[27,28,29]", "startOffset": 140, "endOffset": 150}, {"referenceID": 28, "context": "It means that if the waveform contains less high harmonics in the frequency spectrum, or the power of higher harmonics is low, f0 will be simpler to detect[30].", "startOffset": 155, "endOffset": 159}, {"referenceID": 29, "context": "Pitch frequency changes diagram is a well-suited means for speaker change detection[32].", "startOffset": 83, "endOffset": 87}, {"referenceID": 30, "context": "[33]", "startOffset": 0, "endOffset": 4}], "year": 2012, "abstractText": "Speech Segmentation is the process change point detection for partitioning an input audio stream into regions each of which corresponds to only one audio source or one speaker. One application of this system is in Speaker Diarization systems. There are several methods for speaker segmentation; however, most of the Speaker Diarization Systems use BIC-based Segmentation methods. The main goal of this paper is to propose a new method for speaker segmentation with higher speed than the current methods e.g. BIC and acceptable accuracy. Our proposed method is based on the pitch frequency of the speech. The accuracy of this method is similar to the accuracy of common speaker segmentation methods. However, its computation cost is much less than theirs. We show that our method is about 2.4 times faster than the BICbased method, while the average accuracy of pitch-based method is slightly higher than that of the BICbased method.", "creator": "PScript5.dll Version 5.2.2"}}}