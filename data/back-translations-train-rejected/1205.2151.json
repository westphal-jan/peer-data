{"id": "1205.2151", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2012", "title": "A Converged Algorithm for Tikhonov Regularized Nonnegative Matrix Factorization with Automatic Regularization Parameters Determination", "abstract": "We present a converged algorithm for Tikhonov regularized nonnegative matrix factorization (NMF). We specially choose this regularization because it is known that Tikhonov regularized least square (LS) is the more preferable form in solving linear inverse problems than the conventional LS. Because an NMF problem can be decomposed into LS subproblems, it can be expected that Tikhonov regularized NMF will be the more appropriate approach in solving NMF problems. The algorithm is derived using additive update rules which have been shown to have convergence guarantee. We equip the algorithm with a mechanism to automatically determine the regularization parameters based on the L-curve, a well-known concept in the inverse problems community, but is rather unknown in the NMF research. The introduction of this algorithm thus solves two inherent problems in Tikhonov regularized NMF algorithm research, i.e., convergence guarantee and regularization parameters determination.", "histories": [["v1", "Thu, 10 May 2012 03:31:39 GMT  (140kb,S)", "http://arxiv.org/abs/1205.2151v1", "Preliminary result without experimental result"]], "COMMENTS": "Preliminary result without experimental result", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["andri mirzal"], "accepted": false, "id": "1205.2151"}, "pdf": {"name": "1205.2151.pdf", "metadata": {"source": "CRF", "title": "A Converged Algorithm for Tikhonov Regularized Nonnegative Matrix Factorization with Automatic Regularization Parameters Determination", "authors": ["Andri Mirzal"], "emails": ["andrimirzal@utm.my"], "sections": [{"heading": null, "text": "The conventional method in the calculation of B and J is a method that minimizes the number of factors that are usually chosen between BC and BC. The conventional method in the calculation of B and C is a method that decomposes a non-negative matrix into a pair of other non-negative matrices. The non-negative matrix A, which has NMF, which has two non-negative matrices B and C, is a method that decomposes a non-negative matrix into a pair of other non-negative matrices., The non-negative matrix A, which has non-negative matrix B, which has non-relevant matrices B and C., the non-relevant, non-relevant matrix B and C., the non-relevant, non-relevant, non-relevant, non-relevant, non-relevant matrix B and C., the non-relevant, non-relevant, non-relevant, non-relevant, non-relevant matrix B and C., the non-relevant, non-relevant, non-relevant, non-relevant matrix B and C., the non-relevant, non-relevant, non-relevant, non-relevant matrix B and C., the non-relevant, non-relevant, non-relevant, non-relevant matrix B and C., the non-relevant, non-relevant, non-relevant, non-relevant matrix B and C., the non-relevant, the non-relevant, non-relevant, non-relevant matrix B and C., the non-relevant, the non-relevant, non-relevant, non-relevant matrix B and C., the non-relevant, the non-relevant, non-relevant, non-relevant, non-relevant, the non-relevant matrix B and C."}], "references": [{"title": "Algorithms for non-negative matrix factorization", "author": ["D. Lee", "H. Seung"], "venue": "Proc. Advances in Neural Processing Information Systems, pp. 556-62, 2000.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Generalized nonnegative matrix approximation with Bregman divergences", "author": ["I.S. Dhillon", "S. Sra"], "venue": "UTCS Technical Reports, The University of Texas at Austin, 2005.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Csisz\u00e1rs divergences for nonnegative matrix factorization: Family of new algorithms", "author": ["A. Cichocki", "R. Zdunek", "S. Amari"], "venue": "Proc. 6th Int\u2019l  Conf. on Independent Component Analysis and Blind Signal Separation, 2006.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Tapper,\u201cPositive matrix factorization: A non-negative factor model with optimal utilization of error estimates of data values,", "author": ["U.P. Paatero"], "venue": "Environmetrics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1994}, {"title": "Source identification of bulk wet deposition in finland by positive matrix factorization", "author": ["P. Anttila", "P. Paatero", "U. Tapper"], "venue": "Atmospheric Environment, Vol. 29, No. 14, pp. 1705-18, 1995.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1995}, {"title": "Learning the parts of objects by non-negative matrix factorization", "author": ["D. Lee", "H. Seung"], "venue": "Nature, 401(6755), pp. 788-91, 1999.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1999}, {"title": "Non-negative matrix factorization with sparseness constraints", "author": ["P.O. Hoyer"], "venue": "The Journal of Machine Learning Research, Vol. 5, pp. 1457-69, 2004.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning spatially localized, parts-based representation", "author": ["S.Z. Li", "X.W. Hou", "H.J. Zhang", "Q.S. Cheng"], "venue": "Proc. IEEE Comp. Soc. Conf. on Computer Vision and Pattern Recognition, pp. 207-12, 2001.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Algorithms and applications for approximate nonnegative matrix factorization", "author": ["M. Berry", "M. Brown", "A. Langville", "P. Pauca", "R.J. Plemmons"], "venue": "Computational Statistics and Data Analysis, 2006.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Document clustering using nonnegative matrix factorization", "author": ["F. Shahnaz", "M.W. Berry", "V. Pauca", "R.J. Plemmons"], "venue": "Information Processing & Management, Vol. 42, No. 2, pp. 373-86, 2006.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Document clustering based on nonnegative matrix factorization", "author": ["W. Xu", "X. Liu", "Y. Gong"], "venue": "Proc. ACM SIGIR, pp. 267-73, 2003.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "Nonnegative matrix factorization for spectral data analysis", "author": ["V.P. Pauca", "J. Piper", "R.J. Plemmons"], "venue": "Linear Algebra and Its Applications, Vol. 416, No. 1, pp. 29-47, 2006.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Constrained Nonnegative Matrix factorization for hyperspectral unmixing", "author": ["S. Jia", "Y. Qian"], "venue": "IEEE Transactions on Geoscience and Remote Sensing, Vol. 47, No. 1, pp. 161-73, 2009.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Extended SMART algorithms for non-negative matrix factorization", "author": ["A. Cichocki", "S. Amari", "R. Zdunek", "R. Kompass", "G. Hori", "Z. He"], "venue": "Lecture Notes in Computer Science, Vol. 4029, pp. 548-62, 2006.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Metagenes and molecular pattern discovery using matrix factorization", "author": ["J.P. Brunet", "P. Tamayo", "T.R. Golub", "J.P. Mesirov"], "venue": "Proc. Natl Acad. Sci. USA, Vol. 101, No. 12, pp. 4164-9, 2003.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2003}, {"title": "Improving Molecular cancer class discovery through sparse non-negative matrix factorization", "author": ["Y. Gao", "G. Church"], "venue": "Bioinformatics, Vol. 21, No. 21, pp. 3970-5, 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Sparse non-negative matrix factorizations via alternating non-negativity constrained least squares for microarray data analysis", "author": ["H. Kim", "H. Park"], "venue": "Bioinformatics, Vol. 23, No. 12, pp. 1495-502, 2007.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "On the convergence of multiplicative update algorithms for nonnegative matrix factorization", "author": ["C.J. Lin"], "venue": "IEEE Transactions on Neural Networks, Vol. 18, No. 6, pp. 1589-96, 2007.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Nonnegative Matrix Factorizations for Clustering and LSI", "author": ["A. Mirzal"], "venue": "LAP Lambert Academic Publishing,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Orthogonal nonnegative matrix t-factorizations for clustering", "author": ["C. Ding", "T. Li", "W. Peng", "H. Park"], "venue": "Proc. 12th ACM SIGKDD Int\u2019l Conf. on Knowledge Discovery and Data Mining, pp. 126-35, 2006.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Orthogonal nonnegative matrix factorization: Multiplicative updates on Stiefel manifolds", "author": ["J. Yoo", "S. Choi"], "venue": "Proc. 9th Int\u2019l Conf. Intelligent Data Engineering and Automated Learning, pp. 140-7, 2008.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "Orthogonal nonnegative matrix tri-factorization for co-clustering: Multiplicative updates on Stiefel manifolds", "author": ["J. Yoo", "S. Choi"], "venue": "Information Processing & Management, Vol. 46, No. 5, pp. 559-70, 2010.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Algorithms for orthogonal nonnegative matrix factorization", "author": ["S. Choi"], "venue": "Proc. IEEE Int\u2019l Joint Conf. on Neural Networks, pp. 1828-32, 2008.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1828}, {"title": "Non-Negative Matrix Factorization with Orthogonality Constraints for Chemical Agent Detection in Raman Spectra", "author": ["H. Li", "T. Adali", "W. Wang", "D. Emge"], "venue": "Proc. IEEE Workshop on Machine Learning for Signal Processing, pp. 253-8, 2005.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Projected gradient methods for non-negative matrix factorization", "author": ["C.J. Lin"], "venue": "Technical Report ISSTECH-95-013, Department of CS, National Taiwan University, 2005.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2005}, {"title": "Accelerating the Lee-Seung algorithm for non-negative matrix factorization", "author": ["E.F. Gonzales", "Y. Zhang"], "venue": "Technical Report, Dept. Comput. Appl. Math., Rice Univ., Houston, 2005.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2005}, {"title": "Fast projection-based methods for the least squares nonnegative matrix approximation problem", "author": ["D. Kim", "S. Sra", "I.S. Dhillon"], "venue": "Stat. Anal. Data Min., Vol. 1, No. 1, pp. 38-51, 2008.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Fast newton-type methods for the least squares nonnegative matrix approximation problem", "author": ["D. Kim", "S. Sra", "I.S. Dhillon"], "venue": "Proc. SIAM Conference on Data Mining, pp. 343-54, 2007.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2007}, {"title": "Nonnegative matrix factorization based on alternating nonnegativity constrained least squares and active set method", "author": ["H. Kim", "H. Park"], "venue": "SIAM. J. Matrix Anal. & Appl., Vol. 30, No. 2, pp. 713-30, 2008.  11", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "Toward faster nonnegative matrix factorization: A new algorithm and comparisons", "author": ["J. Kim", "H. Park"], "venue": "Proc. 8th IEEE International Conference on Data Mining, pp. 353-62, 2008.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "J. Royal Statistical Society B, Vol. 58, Issue 1, pp. 267-88, 1996.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1996}, {"title": "The L-curve and its use in the numerical treatment of inverse problems, Computational Inverse Problems in Electrocardiology", "author": ["P.C. Hansen"], "venue": "WIT Press,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2000}, {"title": "A new method for regularization parameter determination in the inverse problem of electrocardiography", "author": ["P.R. Johnston", "R.M. Gulrajani"], "venue": "IEEE Transaction on Biomedical Engineering, Vol. 44, No. 1, pp. 19-39, 1997.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1997}, {"title": "A method for choosing the regularization parameter in generalized tikhonov regularized linear inverse problems", "author": ["S. Oraintara", "W.C. Karl", "D.A. Castanon", "T.Q. Nguyen"], "venue": "Proc. International Conference of Image Processing, pp. 93-96, 2000.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2000}, {"title": "Regularization methods for linear inverse problems", "author": ["S.M. Tan", "C. Fox"], "venue": "Lecture Note: PHYSICS 707 Inverse Problems, Chapter 3, pp. 1-15, 1998.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1998}, {"title": "Iterative choices of regularization parameters in linear inverse problems", "author": ["K. Kunisch", "J. Zhou"], "venue": "Inverse Problems, Vol. 14, No. 5, pp. 1247- 64, 1998.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1998}, {"title": "Simultaneous multiple regulariza-  tion parameter selection by means of the L-hypersurface with applications to linear inverse problems posed in the wavelet transform domain", "author": ["M. Belge", "E. Miller", "M. Kilmer"], "venue": "SPIE Int\u2019l Symposium on Optical Science, Engineering, and Instrumentation: Bayesian Inference for Inverse Problems, pp. 328-36, 1998.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1998}, {"title": "A regularization parameter in discrete ill-posed problems", "author": ["T. Reginska"], "venue": "SIAM Journal of Scientific Computing, Vol. 17, No. 3, pp. 740-9, 1996.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1996}, {"title": "A technique for the numerical solution of certain integral equations of the first kind", "author": ["D.L. Phillips"], "venue": "J. Association for Computing Machinery, Vol. 9, Issue 1, pp. 84-97, 1997.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1997}, {"title": "Solution of incorrectly formulated problems and the regularization method", "author": ["A.N. Tikhonov"], "venue": "Soviet Math. Dokl. 4, pp. 1035-8, 1963. English translation of Dokl. Akad. Nauk. SSSR, 151, pp. 501-4, 1963.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1963}, {"title": "A tutorial on convex optimization", "author": ["H. Hindi"], "venue": "Proc. American Control Conference, pp. 3252-65, 2004.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2004}, {"title": "Nonlinear Programming 2nd Ed", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific, 1999.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1999}, {"title": "Regular Linear Phase Perfect Reconstruction Filter Banks for Image Compression", "author": ["S. Oraintara"], "venue": "PhD Thesis, Boston University, 2000, Appendix A.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2000}, {"title": "On the convergence of the block nonlinear Gauss-Seidel method under convex constraints", "author": ["L. Grippo", "M. Sciandrone"], "venue": "Operation Research Letters, Vol. 26, pp. 127-36, 2000.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "(2) In addition, other criteria like Kullback-Leibler divergence [1], [2] and Csisz\u00e1rs \u03c6-divergence [3] can also be used.", "startOffset": 65, "endOffset": 68}, {"referenceID": 1, "context": "(2) In addition, other criteria like Kullback-Leibler divergence [1], [2] and Csisz\u00e1rs \u03c6-divergence [3] can also be used.", "startOffset": 70, "endOffset": 73}, {"referenceID": 2, "context": "(2) In addition, other criteria like Kullback-Leibler divergence [1], [2] and Csisz\u00e1rs \u03c6-divergence [3] can also be used.", "startOffset": 100, "endOffset": 103}, {"referenceID": 3, "context": "[4], [5].", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[4], [5].", "startOffset": 5, "endOffset": 8}, {"referenceID": 5, "context": "The popularity of the NMF is due to the work of Lee and Seung [6] in which they introduced a simple yet powerful NMF algorithm, and then show its applicability in image processing and text analysis.", "startOffset": 62, "endOffset": 65}, {"referenceID": 5, "context": "my In addition, the algorithm also produces sparser factors (thus requires less storage) [6]\u2013[8] and can give more intuitive results compared to other subspace approximation techniques like Principal Component Analysis (PCA) and Independent Component Analysis (ICA) [6], [7], [9].", "startOffset": 89, "endOffset": 92}, {"referenceID": 7, "context": "my In addition, the algorithm also produces sparser factors (thus requires less storage) [6]\u2013[8] and can give more intuitive results compared to other subspace approximation techniques like Principal Component Analysis (PCA) and Independent Component Analysis (ICA) [6], [7], [9].", "startOffset": 93, "endOffset": 96}, {"referenceID": 5, "context": "my In addition, the algorithm also produces sparser factors (thus requires less storage) [6]\u2013[8] and can give more intuitive results compared to other subspace approximation techniques like Principal Component Analysis (PCA) and Independent Component Analysis (ICA) [6], [7], [9].", "startOffset": 266, "endOffset": 269}, {"referenceID": 6, "context": "my In addition, the algorithm also produces sparser factors (thus requires less storage) [6]\u2013[8] and can give more intuitive results compared to other subspace approximation techniques like Principal Component Analysis (PCA) and Independent Component Analysis (ICA) [6], [7], [9].", "startOffset": 271, "endOffset": 274}, {"referenceID": 8, "context": "my In addition, the algorithm also produces sparser factors (thus requires less storage) [6]\u2013[8] and can give more intuitive results compared to other subspace approximation techniques like Principal Component Analysis (PCA) and Independent Component Analysis (ICA) [6], [7], [9].", "startOffset": 276, "endOffset": 279}, {"referenceID": 9, "context": ", document clustering [10], [11], spectral analysis [12], [13], image processing [7], [8], blind source separation [14], and cancer detection [15]\u2013[17], and showed that the NMF can give better results.", "startOffset": 22, "endOffset": 26}, {"referenceID": 10, "context": ", document clustering [10], [11], spectral analysis [12], [13], image processing [7], [8], blind source separation [14], and cancer detection [15]\u2013[17], and showed that the NMF can give better results.", "startOffset": 28, "endOffset": 32}, {"referenceID": 11, "context": ", document clustering [10], [11], spectral analysis [12], [13], image processing [7], [8], blind source separation [14], and cancer detection [15]\u2013[17], and showed that the NMF can give better results.", "startOffset": 52, "endOffset": 56}, {"referenceID": 12, "context": ", document clustering [10], [11], spectral analysis [12], [13], image processing [7], [8], blind source separation [14], and cancer detection [15]\u2013[17], and showed that the NMF can give better results.", "startOffset": 58, "endOffset": 62}, {"referenceID": 6, "context": ", document clustering [10], [11], spectral analysis [12], [13], image processing [7], [8], blind source separation [14], and cancer detection [15]\u2013[17], and showed that the NMF can give better results.", "startOffset": 81, "endOffset": 84}, {"referenceID": 7, "context": ", document clustering [10], [11], spectral analysis [12], [13], image processing [7], [8], blind source separation [14], and cancer detection [15]\u2013[17], and showed that the NMF can give better results.", "startOffset": 86, "endOffset": 89}, {"referenceID": 13, "context": ", document clustering [10], [11], spectral analysis [12], [13], image processing [7], [8], blind source separation [14], and cancer detection [15]\u2013[17], and showed that the NMF can give better results.", "startOffset": 115, "endOffset": 119}, {"referenceID": 14, "context": ", document clustering [10], [11], spectral analysis [12], [13], image processing [7], [8], blind source separation [14], and cancer detection [15]\u2013[17], and showed that the NMF can give better results.", "startOffset": 142, "endOffset": 146}, {"referenceID": 16, "context": ", document clustering [10], [11], spectral analysis [12], [13], image processing [7], [8], blind source separation [14], and cancer detection [15]\u2013[17], and showed that the NMF can give better results.", "startOffset": 147, "endOffset": 151}, {"referenceID": 6, "context": "2) to also include auxiliary constraints such as sparseness [7], [8], [16], [17], smoothness [10], [12], [13], and orthogonality [19]\u2013[24].", "startOffset": 60, "endOffset": 63}, {"referenceID": 7, "context": "2) to also include auxiliary constraints such as sparseness [7], [8], [16], [17], smoothness [10], [12], [13], and orthogonality [19]\u2013[24].", "startOffset": 65, "endOffset": 68}, {"referenceID": 15, "context": "2) to also include auxiliary constraints such as sparseness [7], [8], [16], [17], smoothness [10], [12], [13], and orthogonality [19]\u2013[24].", "startOffset": 70, "endOffset": 74}, {"referenceID": 16, "context": "2) to also include auxiliary constraints such as sparseness [7], [8], [16], [17], smoothness [10], [12], [13], and orthogonality [19]\u2013[24].", "startOffset": 76, "endOffset": 80}, {"referenceID": 9, "context": "2) to also include auxiliary constraints such as sparseness [7], [8], [16], [17], smoothness [10], [12], [13], and orthogonality [19]\u2013[24].", "startOffset": 93, "endOffset": 97}, {"referenceID": 11, "context": "2) to also include auxiliary constraints such as sparseness [7], [8], [16], [17], smoothness [10], [12], [13], and orthogonality [19]\u2013[24].", "startOffset": 99, "endOffset": 103}, {"referenceID": 12, "context": "2) to also include auxiliary constraints such as sparseness [7], [8], [16], [17], smoothness [10], [12], [13], and orthogonality [19]\u2013[24].", "startOffset": 105, "endOffset": 109}, {"referenceID": 18, "context": "2) to also include auxiliary constraints such as sparseness [7], [8], [16], [17], smoothness [10], [12], [13], and orthogonality [19]\u2013[24].", "startOffset": 129, "endOffset": 133}, {"referenceID": 23, "context": "2) to also include auxiliary constraints such as sparseness [7], [8], [16], [17], smoothness [10], [12], [13], and orthogonality [19]\u2013[24].", "startOffset": 134, "endOffset": 138}, {"referenceID": 8, "context": "However, as multiplicative update rules based NMF algorithms do not have convergence guarantee [9], [18], [19], [25], the development of converged algorithms for various NMF objectives with auxiliary constraints is an open research problem.", "startOffset": 95, "endOffset": 98}, {"referenceID": 17, "context": "However, as multiplicative update rules based NMF algorithms do not have convergence guarantee [9], [18], [19], [25], the development of converged algorithms for various NMF objectives with auxiliary constraints is an open research problem.", "startOffset": 100, "endOffset": 104}, {"referenceID": 18, "context": "However, as multiplicative update rules based NMF algorithms do not have convergence guarantee [9], [18], [19], [25], the development of converged algorithms for various NMF objectives with auxiliary constraints is an open research problem.", "startOffset": 106, "endOffset": 110}, {"referenceID": 24, "context": "However, as multiplicative update rules based NMF algorithms do not have convergence guarantee [9], [18], [19], [25], the development of converged algorithms for various NMF objectives with auxiliary constraints is an open research problem.", "startOffset": 112, "endOffset": 116}, {"referenceID": 24, "context": ", projected gradient methods [25], [27], projected quasiNewton method [28], active set method [29], and block principal pivoting method [30]) do have convergence guarantee, due to the complexity of the algorithms, it\u2019s not always clear how to incorporate those auxiliary constraints into the algorithms.", "startOffset": 29, "endOffset": 33}, {"referenceID": 26, "context": ", projected gradient methods [25], [27], projected quasiNewton method [28], active set method [29], and block principal pivoting method [30]) do have convergence guarantee, due to the complexity of the algorithms, it\u2019s not always clear how to incorporate those auxiliary constraints into the algorithms.", "startOffset": 35, "endOffset": 39}, {"referenceID": 27, "context": ", projected gradient methods [25], [27], projected quasiNewton method [28], active set method [29], and block principal pivoting method [30]) do have convergence guarantee, due to the complexity of the algorithms, it\u2019s not always clear how to incorporate those auxiliary constraints into the algorithms.", "startOffset": 70, "endOffset": 74}, {"referenceID": 28, "context": ", projected gradient methods [25], [27], projected quasiNewton method [28], active set method [29], and block principal pivoting method [30]) do have convergence guarantee, due to the complexity of the algorithms, it\u2019s not always clear how to incorporate those auxiliary constraints into the algorithms.", "startOffset": 94, "endOffset": 98}, {"referenceID": 29, "context": ", projected gradient methods [25], [27], projected quasiNewton method [28], active set method [29], and block principal pivoting method [30]) do have convergence guarantee, due to the complexity of the algorithms, it\u2019s not always clear how to incorporate those auxiliary constraints into the algorithms.", "startOffset": 136, "endOffset": 140}, {"referenceID": 0, "context": "The additive update rules based algorithm for standard NMF first appeared in the work of Lee & Seung [1], but the convergence proof was given by Lin in ref.", "startOffset": 101, "endOffset": 104}, {"referenceID": 17, "context": "[18].", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": ", text mining [10], spectral data analysis [12], [13], microarray data analysis [29], and cancer class discovery [16] (in some works, sparseness is enforced using L2 norm on the solution, i.", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": ", text mining [10], spectral data analysis [12], [13], microarray data analysis [29], and cancer class discovery [16] (in some works, sparseness is enforced using L2 norm on the solution, i.", "startOffset": 43, "endOffset": 47}, {"referenceID": 12, "context": ", text mining [10], spectral data analysis [12], [13], microarray data analysis [29], and cancer class discovery [16] (in some works, sparseness is enforced using L2 norm on the solution, i.", "startOffset": 49, "endOffset": 53}, {"referenceID": 28, "context": ", text mining [10], spectral data analysis [12], [13], microarray data analysis [29], and cancer class discovery [16] (in some works, sparseness is enforced using L2 norm on the solution, i.", "startOffset": 80, "endOffset": 84}, {"referenceID": 15, "context": ", text mining [10], spectral data analysis [12], [13], microarray data analysis [29], and cancer class discovery [16] (in some works, sparseness is enforced using L2 norm on the solution, i.", "startOffset": 113, "endOffset": 117}, {"referenceID": 30, "context": "norm\u2014the more appropriate constraint for enforcing sparseness [31]), and showed that it can offer better results compared to the results of standard NMF.", "startOffset": 62, "endOffset": 66}, {"referenceID": 8, "context": "This constraint also can reduce influence of noise and other uncertainties in the data [9], [12], [13].", "startOffset": 87, "endOffset": 90}, {"referenceID": 11, "context": "This constraint also can reduce influence of noise and other uncertainties in the data [9], [12], [13].", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": "This constraint also can reduce influence of noise and other uncertainties in the data [9], [12], [13].", "startOffset": 98, "endOffset": 102}, {"referenceID": 31, "context": "In addition, from the inverse problem study, it is known that Tikhonov regularized least square (LS) is the more preferable form in solving inverse problems because solutions of the conventional LS tend to be unstable and dominated by data and rounding errors [32]\u2013[34].", "startOffset": 260, "endOffset": 264}, {"referenceID": 33, "context": "In addition, from the inverse problem study, it is known that Tikhonov regularized least square (LS) is the more preferable form in solving inverse problems because solutions of the conventional LS tend to be unstable and dominated by data and rounding errors [32]\u2013[34].", "startOffset": 265, "endOffset": 269}, {"referenceID": 34, "context": "Moreover, in the presence of noise, frequently the conventional LS solutions are rather undesirable as it leads to amplification of noise in the direction of singular vectors with small singular values [35].", "startOffset": 202, "endOffset": 206}, {"referenceID": 35, "context": "In this paper we will utilize the L-curve since the Morozov discrepancy principles require knowledge of the error level in the data which is often inaccessible [36].", "startOffset": 160, "endOffset": 164}, {"referenceID": 31, "context": "In this curve, the proper value for the regularization parameter is the value associated with corner of the curve where both solution and approximation error have minimum norms [32], [34].", "startOffset": 177, "endOffset": 181}, {"referenceID": 33, "context": "In this curve, the proper value for the regularization parameter is the value associated with corner of the curve where both solution and approximation error have minimum norms [32], [34].", "startOffset": 183, "endOffset": 187}, {"referenceID": 31, "context": ", [32], [34], [37], [38].", "startOffset": 2, "endOffset": 6}, {"referenceID": 33, "context": ", [32], [34], [37], [38].", "startOffset": 8, "endOffset": 12}, {"referenceID": 36, "context": ", [32], [34], [37], [38].", "startOffset": 14, "endOffset": 18}, {"referenceID": 37, "context": ", [32], [34], [37], [38].", "startOffset": 20, "endOffset": 24}, {"referenceID": 33, "context": "[34] in which they defined L-corner to be the point of tangency between L-curve with positive curvature and a straight line of negative slope.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "We choose this method because it has convergence guarantee and is relatively faster to compute than the standard method; the maximum curvature approach [32].", "startOffset": 152, "endOffset": 156}, {"referenceID": 38, "context": "The method was developed independently by Phillips [39] and Tikhonov [40].", "startOffset": 51, "endOffset": 55}, {"referenceID": 39, "context": "The method was developed independently by Phillips [39] and Tikhonov [40].", "startOffset": 69, "endOffset": 73}, {"referenceID": 31, "context": "(5) To improve the solution, usually Tikhonov regularized LS is used instead [32]: x\u03bb = argmin x \u2016y \u2212Ax\u2016F + \u03bb\u2016x\u2016 2 F (6) where \u03bb denotes nonnegative regularization parameter, \u2016y \u2212 Ax\u2016F denotes approximation error, and \u2016x\u2016 2 F denotes solution size.", "startOffset": 77, "endOffset": 81}, {"referenceID": 33, "context": "In [34], Oraintara et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 33, "context": "001 in the authors\u2019 work [34].", "startOffset": 25, "endOffset": 29}, {"referenceID": 33, "context": "Note that the value of \u03b3 doesn\u2019t influence convergence property of sequence x and \u03bb, and as long as \u03bb is sufficiently small then \u03bb converges to a stationary point [34].", "startOffset": 163, "endOffset": 167}, {"referenceID": 32, "context": "[33], but the authors fixed \u03b3 value to one.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "and may have several local mimima [25].", "startOffset": 34, "endOffset": 38}, {"referenceID": 40, "context": "The common practice to deal with the nonconvexity of an optimization problem is by transforming it into convex subproblems [41].", "startOffset": 123, "endOffset": 127}, {"referenceID": 24, "context": "In the case of the NMF, this can be done by employing the alternating strategy; fixing one matrix while solving for the other [25] (apparently, all NMF algorithms utilizing alternating strategy).", "startOffset": 126, "endOffset": 130}, {"referenceID": 33, "context": "[34], \u03b3 m and \u03b3 C n are defined similarly as in algorithm 1, and \u01eb denotes small positive number.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "17 if it satisfies the KKT optimality conditions [42], i.", "startOffset": 49, "endOffset": 53}, {"referenceID": 17, "context": "As stated by Lin [18], the above multiplicative update rules based algorithm can be modified into an equivalent converged algorithm by (1) using additive update rules, and (2) replacing zero entries that do not satisfy the KKT conditions with a small positive number to escape the zero locking.", "startOffset": 17, "endOffset": 21}, {"referenceID": 41, "context": "This approach is known as the block-coordinate descent method [42].", "startOffset": 62, "endOffset": 66}, {"referenceID": 17, "context": "From convergence analysis study, the following conditions must be satisfied for sequence { B,C } to have convergence guarantee [18], [25], [44].", "startOffset": 127, "endOffset": 131}, {"referenceID": 24, "context": "From convergence analysis study, the following conditions must be satisfied for sequence { B,C } to have convergence guarantee [18], [25], [44].", "startOffset": 133, "endOffset": 137}, {"referenceID": 43, "context": "From convergence analysis study, the following conditions must be satisfied for sequence { B,C } to have convergence guarantee [18], [25], [44].", "startOffset": 139, "endOffset": 143}, {"referenceID": 0, "context": "We will utilize the auxiliary function approach introduced in [1] to prove this property.", "startOffset": 62, "endOffset": 65}, {"referenceID": 17, "context": "Proof: As stated by Lin [18], it suffices to prove that", "startOffset": 24, "endOffset": 28}, {"referenceID": 33, "context": "[34], [43].", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "[34], [43].", "startOffset": 6, "endOffset": 10}, {"referenceID": 33, "context": "[34]): The optimum \u03b2m corresponding to the L-corner must satisfy \u03b2m \u2225 bTm \u2225", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34]): The values of \u03b2 m \u2200m either strictly increase or decrease under update rule eq.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34]): If the update rule eq.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34], the followings summarize the strategy in choosing the initial values.", "startOffset": 0, "endOffset": 4}], "year": 2012, "abstractText": "We present a converged algorithm for Tikhonov regularized nonnegative matrix factorization (NMF). We specially choose this regularization because it is known that Tikhonov regularized least square (LS) is the more preferable form in solving linear inverse problems than the conventional LS. Because an NMF problem can be decomposed into LS subproblems, it can be expected that Tikhonov regularized NMF will be the more appropriate approach in solving NMF problems. The algorithm is derived using additive update rules which have been shown to have convergence guarantee. We equip the algorithm with a mechanism to automatically determine the regularization parameters based on the L-curve, a well-known concept in the inverse problems community, but is rather unknown in the NMF research. The introduction of this algorithm thus solves two inherent problems in Tikhonov regularized NMF algorithm research, i.e., convergence guarantee and regularization parameters determination.", "creator": "LaTeX with hyperref package"}}}