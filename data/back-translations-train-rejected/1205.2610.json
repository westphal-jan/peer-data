{"id": "1205.2610", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2012", "title": "Probabilistic Structured Predictors", "abstract": "We consider MAP estimators for structured prediction with exponential family models. In particular, we concentrate on the case that efficient algorithms for uniform sampling from the output space exist. We show that under this assumption (i) exact computation of the partition function remains a hard problem, and (ii) the partition function and the gradient of the log partition function can be approximated efficiently. Our main result is an approximation scheme for the partition function based on Markov Chain Monte Carlo theory. We also show that the efficient uniform sampling assumption holds in several application settings that are of importance in machine learning.", "histories": [["v1", "Wed, 9 May 2012 18:36:39 GMT  (191kb)", "http://arxiv.org/abs/1205.2610v1", "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009). arXiv admin note: substantial text overlap witharXiv:0912.4473"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009). arXiv admin note: substantial text overlap witharXiv:0912.4473", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["shankar vembu", "thomas gartner", "mario boley"], "accepted": false, "id": "1205.2610"}, "pdf": {"name": "1205.2610.pdf", "metadata": {"source": "CRF", "title": "Probabilistic Structured Predictors", "authors": ["Shankar Vembu", "Thomas G\u00e4rtner", "Mario Boley"], "emails": ["mario.boley}@iais.fraunhofer.de"], "sections": [{"heading": null, "text": "We look at MAP estimators for structured predictions with exponential family models. In particular, we focus on the case where efficient algorithms for uniform sampling exist from the output space. We show that under this assumption (i) the exact calculation of the partition function remains a hard problem and (ii) the partition function and the gradient of the log partition function can be efficiently approximated. Our main result is an approximation scheme for the partition function based on the Markov Chain Monte Carlo theory. We also show that the efficient uniform sampling applies in several application scenarios that are relevant for machine learning."}, {"heading": "1 Introduction", "text": "We look at discriminatory structured predictive models with an emphasis on predicting combinatorial structures, which are applied in machine learning problems such as multi-label classification (Elisseeff & Weston, 2001), multi-category hierarchical classification (Cesa-Bianchi et al., 2006), and label ranking (Dekel et al., 2003), let X \u00b7 Y be the domain of observations and labels, and let X = (x1, \u00b7 \u00b7, xm), Xm, Y = (y1, \u00b7, ym), Ym be the series of observations. Our goal is to estimate x the exponential families viap (y | x, \u03b8) = exp (x, y; \u03c6 (x), y, y. \""}, {"heading": "1.1 Our Contributions", "text": "We analyze discriminatory probabilistic structured predictive models based on exponential families, using the MCMC theory. In particular: \u2022 we prove a hardness result for the calculation of the partition function (Section 2); \u2022 we present an algorithm for approximating the partition function and the gradient of the log partition function with verifiable guarantees (Section 2); \u2022 we design a Markov chain that can be used to design combinatorial structures from exponential family distributions that are taken into account in this work, since there is an exact uniform sample collector, and also perform a non-asymptotic analysis of their mixing time (Section 3); \u2022 we describe several combinatorial structures that find applications in machine learning problems, including multi-brand classification, label ranking, and multi-category hierarchical classification (Section 4).Notation: We use [n] to denote the set of {1}."}, {"heading": "2 Computing the Partition Function: Hardness Result and Approximations", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Hardness of Computing the Partition Function", "text": "(Consider the output space of undirected cycles over a fixed row of corner points, i.e., Y = U-Z-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y"}, {"heading": "2.2 Approximating the Partition Function", "text": "As a first step in approximating the partition function (p), we can consider the use of concentration imbalances. If we can compute this randomly, then we can apply Hoeffding's inequality to limit the deviation of the partition function. (p) We will now introduce an algorithm that represents a fully polynomial approximation scheme for approximating the partition function. (p) We assume that the approximation to the partition function is not useful. (Definition 2.1 Suppose f: P \u2192 R + is a function that maps the problem instances to positive real numbers. (p) A randomized approximation scheme for P is a randomized algorithm that takes p as an instance. (p) P and an error parameter > 0, and produces as output a number Q of such thatPr (p) f (p). (p) A randomized approximation scheme for P is taken as an instance of an algorithmic P."}, {"heading": "2.3 Approximating the Gradient of the Log Partition Function", "text": "The optimization problem (1) is typically solved with gradient descending methods that include gradient multiplications. We will now describe how to approximate gradient vector multiplication with verifiable guarantees based on concentration inequalities. Gradient multiplication is expressed as a vector in Rn (where n also indicates the dimension of the attribute space \u03c6 (x, y) with a limited \"2 norm,\" i.e., | | \u2264 G, where G is a constant. Gradient vector multiplication is given as < < < < < < p (y, x), z >]. We use Hoeffdings inequality to limit the deviation from < < < p (y), z >."}, {"heading": "3 Sampling Techniques", "text": "These algorithms are needed (i) to calculate the partitioning function based on the machinery introduced in the previous section, and (ii) to draw conclusions, i.e. to predict structures by applying the learned model, using the optimization problem argmaxy and other methods such as simulated annealing for convex optimization (Kalai & Vempala, 2006) (note that these methods come with verifiable guarantees and are not heuristic).The main contribution of this section is a generic, meta 'approach that can be used to sample structures of interest since there is a unified sampler."}, {"heading": "4 Application Settings", "text": "We describe three combinatorial structures with their respective application settings in machine learning. For each of these structures, we show how to get exact examples uniformly randomly. Together with the \"meta\" approach presented in the previous section, it is then possible to get exact examples of these structures from exponential family distributions that are taken into account in this thesis. Therefore, we have all the necessary components to approximate the partition function. An exact sample can be obtained by generation of a sequence of lengths d, the number of bits in which each bit is determined by throwing an unbiased coincidence."}, {"heading": "5 Conclusions and Future Work", "text": "We developed algorithms to approximate the partition function and the history of the log partition function with verifiable guarantees. We also presented a simple Markov chain based on the Metropolis process, which can be used to scan for exponential family distributions. In such cases, we can design a Markov chain to obtain approximate samples from interest distributions and also limit their mixing time.This is possible with the help of coupling technology. In fact, we show how to get approximate samples, as there is an exact uniform sampler, and the analysis will be in Appendix B. We find that the coupling technology is much easier than the coupling technology."}, {"heading": "A Approximating the Partition Function using Approximate Samples", "text": "Let us now consider the case in which we have only approximate samples resulting from a truncated Markov chain. We begin with some definitions. It is measured by the total variation between the distribution at time t and the stationary distribution. The mixing time of a Markov chain is a measure of the time taken by the chain to convergence with its stationary distribution. It is measured by the total variation between the distribution at time t and the stationary distribution. Definition A.1 Let P t (u, v) denotes the t-step probability of the transition from u to v. The total variation distance at time t is not."}, {"heading": "B Mixing Time Analysis of META using Coupling", "text": "Suppose M is a countable, ergodic Markov chain. Let's allow (P, Q) a random process (the coupling). Suppose t: (0, 1] \u2192 N is a function, so that Pr () 6 = Qt () \u2264, for all (0, 1], equally over the choice of the initial state (P0, Q0). Then the mixing time of M from above is limited by t (). Theorem B.2 The mixing time of Meta is limited from above as follows: d (ln \u2212 1) / ln (1 \u2212 exp (\u2212 2BR)) \u2212 1e. The probability that we use Cauchy-Black and Triangle inequalities is as follows: d () y \u00b2 p \u00b2, y \u00b2 p \u00b2, y \u2212 exp \u2212 exp (2 \u2212 BR)."}, {"heading": "C Bounds on the Norm of the", "text": "(2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2)) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2)) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) ("}], "references": [{"title": "Random walks on finite groups and rapidly mixing markov chains", "author": ["D. Aldous"], "venue": "S\u00e9minaire de probabilit\u00e9s de Strasbourg, 17, 243\u2013297.", "citeRegEx": "Aldous,? 1983", "shortCiteRegEx": "Aldous", "year": 1983}, {"title": "An introduction to mcmc for machine learning", "author": ["C. Andrieu", "N. de Freitas", "A. Doucet", "M.I. Jordan"], "venue": "Machine Learning,", "citeRegEx": "Andrieu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2003}, {"title": "Incremental algorithms for hierarchical classification", "author": ["N. Cesa-Bianchi", "C. Gentile", "L. Zaniboni"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2006}, {"title": "Loglinear models for label ranking", "author": ["O. Dekel", "C.D. Manning", "Y. Singer"], "venue": null, "citeRegEx": "Dekel et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Dekel et al\\.", "year": 2003}, {"title": "Proximal regularization for online and batch learning", "author": ["C.B. Do", "Q.V. Le", "Foo", "C.-S"], "venue": "Proc. of ICML", "citeRegEx": "Do et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Do et al\\.", "year": 2009}, {"title": "A kernel method for multi-labelled classification", "author": ["A. Elisseeff", "J. Weston"], "venue": null, "citeRegEx": "Elisseeff and Weston,? \\Q2001\\E", "shortCiteRegEx": "Elisseeff and Weston", "year": 2001}, {"title": "Supervised clustering with support vector machines", "author": ["T. Finley", "T. Joachims"], "venue": "Proc. of ICML", "citeRegEx": "Finley and Joachims,? \\Q2005\\E", "shortCiteRegEx": "Finley and Joachims", "year": 2005}, {"title": "Supervised clustering of streaming data for email batch detection", "author": ["P. Haider", "U. Brefeld", "T. Scheffer"], "venue": "Proc. of ICML", "citeRegEx": "Haider et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Haider et al\\.", "year": 2007}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["E. Hazan", "A. Agarwal", "S. Kale"], "venue": "Machine Learning,", "citeRegEx": "Hazan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2007}, {"title": "Exact sampling and approximate counting techniques", "author": ["M. Huber"], "venue": "Proc. of STOC.", "citeRegEx": "Huber,? 1998", "shortCiteRegEx": "Huber", "year": 1998}, {"title": "The Markov chain Monte Carlo method: An approach to approximate counting and integration. In Hochbaum DS(ed) Approximation Algorithms for NP\u2013hard Problems, 482\u2013520", "author": ["M. Jerrum", "A. Sinclair"], "venue": "PWS Publishing,", "citeRegEx": "Jerrum and Sinclair,? \\Q1996\\E", "shortCiteRegEx": "Jerrum and Sinclair", "year": 1996}, {"title": "Random generation of combinatorial structures from a uniform distribution", "author": ["M.R. Jerrum", "L.G. Valiant", "V.V. Vazirani"], "venue": "Theoretical Computer Science,", "citeRegEx": "Jerrum et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Jerrum et al\\.", "year": 1986}, {"title": "Simulated annealing for convex optimization", "author": ["A.T. Kalai", "S. Vempala"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Kalai and Vempala,? \\Q2006\\E", "shortCiteRegEx": "Kalai and Vempala", "year": 2006}, {"title": "Equation of state calculation by fast computing machines", "author": ["N. Metropolis", "A. Rosenbluth", "M. Rosenbluth", "A. Teller", "E. Teller"], "venue": "Journal of Chemical Physics,", "citeRegEx": "Metropolis et al\\.,? \\Q1953\\E", "shortCiteRegEx": "Metropolis et al\\.", "year": 1953}, {"title": "Exact sampling with coupled markov chains and applications to statistical mechanics", "author": ["J.G. Propp", "D.B. Wilson"], "venue": "Random Structures and Algorithms,", "citeRegEx": "Propp and Wilson,? \\Q1996\\E", "shortCiteRegEx": "Propp and Wilson", "year": 1996}, {"title": "Mixing", "author": ["D. Randall"], "venue": "Proc. of FOCS.", "citeRegEx": "Randall,? 2003", "shortCiteRegEx": "Randall", "year": 2003}, {"title": "Kernel-based learning of hierarchical multilabel classification models", "author": ["J. Rousu", "C. Saunders", "S. Szedm\u00e1k", "J. Shawe-Taylor"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Rousu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Rousu et al\\.", "year": 2006}, {"title": "Pegasos: Primal estimated sub-gradient solver for svm", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro"], "venue": "Proc. of ICML", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2007}, {"title": "Adaptive simulated annealing: A near-optimal connection between sampling and counting", "author": ["D. Stefankovic", "S. Vempala", "E. Vigoda"], "venue": "Proc. of FOCS", "citeRegEx": "Stefankovic et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Stefankovic et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 2, "context": "These structures find applications in machine learning problems such as multi-label classification (Elisseeff & Weston, 2001), multi-category hierarchical classification (Cesa-Bianchi et al., 2006), and label ranking (Dekel et al.", "startOffset": 170, "endOffset": 197}, {"referenceID": 3, "context": ", 2006), and label ranking (Dekel et al., 2003).", "startOffset": 27, "endOffset": 47}, {"referenceID": 14, "context": "Recent developments include a set of mathematical tools for analysing the rates of convergence of Markov chains to equilibrium (see Randall (2003); Jerrum and Sinclair (1996) for surveys).", "startOffset": 132, "endOffset": 147}, {"referenceID": 10, "context": "Recent developments include a set of mathematical tools for analysing the rates of convergence of Markov chains to equilibrium (see Randall (2003); Jerrum and Sinclair (1996) for surveys).", "startOffset": 148, "endOffset": 175}, {"referenceID": 1, "context": "important research frontier (Andrieu et al., 2003) for MCMC based machine learning problems in general.", "startOffset": 28, "endOffset": 50}, {"referenceID": 11, "context": "We exploit the intimate connection between counting and sampling problems (Jerrum et al., 1986) to approximately compute the partition function using sampling algorithms.", "startOffset": 74, "endOffset": 95}, {"referenceID": 18, "context": "We use the following cooling schedule (Stefankovic et al., 2007): l = pdR||\u03b8||e; \u03b2j = j/(pR\u2016\u03b8\u2016) for all j \u2208 [[l \u2212 1]], where p is a constant integer \u2265 3, i.", "startOffset": 38, "endOffset": 64}, {"referenceID": 13, "context": "We start with the design of a Markov chain based on Metropolis process (Metropolis et al., 1953) to sample according to exponential family distributions p(y|x, \u03b8) under the assumption that there exists an exact uniform sampler for Y.", "startOffset": 71, "endOffset": 96}, {"referenceID": 9, "context": "We now analyse the mixing time of this chain using coupling from the past technique (Propp & Wilson, 1996; Huber, 1998).", "startOffset": 84, "endOffset": 119}, {"referenceID": 9, "context": "We now analyse the mixing time of this chain using coupling from the past technique (Propp & Wilson, 1996; Huber, 1998). Coupling from the past (CFTP) is a technique to obtain an exact sample from the stationary distribution of a Markov chain. The idea is to simulate Markov chains forward from times in the past, starting in all possible states, as a coupling process. If all the chains coalesce at time 0, then Propp and Wilson (1996) showed that the current sample has the stationary distribution.", "startOffset": 107, "endOffset": 437}, {"referenceID": 9, "context": "To ensure that the algorithm terminates with a probability at least (1\u2212 \u03b4), it is required to run it for an additional factor of O(ln(1/\u03b4)) time (Huber, 1998).", "startOffset": 145, "endOffset": 158}, {"referenceID": 4, "context": "We could then employ techniques similar to those described in (Do et al., 2009) to design optimisation strategies that work well in practice.", "startOffset": 62, "endOffset": 79}, {"referenceID": 4, "context": "Appendix C) could be loose in practice as observed recently by Do et al. (2009), and thus the value of R could be way below its upper bound \u221a ln |Y|/\u03bb.", "startOffset": 63, "endOffset": 80}, {"referenceID": 15, "context": "For instance, Randall (2003) analysed the mixing time of a Markov chain to sample from the vertices of a hypercube uniformly at random.", "startOffset": 14, "endOffset": 29}, {"referenceID": 5, "context": "Vertices of a hypercube: The set of vertices of a hypercube is used as the output space in multi-label classification problems (see, for example, Elisseeff and Weston (2001)).", "startOffset": 146, "endOffset": 174}, {"referenceID": 3, "context": "Permutations: The set of permutations is used as the output space in label ranking problems (see, for example, Dekel et al. (2003)).", "startOffset": 111, "endOffset": 131}, {"referenceID": 11, "context": "The second step is accomplished along the lines of a well-known reduction from uniform sampling to exact/approximate counting (Jerrum et al., 1986).", "startOffset": 126, "endOffset": 147}, {"referenceID": 2, "context": "Sampling such rooted subtrees from a rooted tree finds applications in multi-category hierarchical classification problems as considered by Cesa-Bianchi et al. (2006) and Rousu et al.", "startOffset": 140, "endOffset": 167}, {"referenceID": 2, "context": "Sampling such rooted subtrees from a rooted tree finds applications in multi-category hierarchical classification problems as considered by Cesa-Bianchi et al. (2006) and Rousu et al. (2006). We now present a technique to generate exact samples of subtrees uniformly at random.", "startOffset": 140, "endOffset": 191}, {"referenceID": 8, "context": "We therefore argue for using online convex optimisation techniques (Hazan et al., 2007; Shalev-Shwartz et al., 2007) as these would result in fast, scalable algorithms for structured prediction.", "startOffset": 67, "endOffset": 116}, {"referenceID": 17, "context": "We therefore argue for using online convex optimisation techniques (Hazan et al., 2007; Shalev-Shwartz et al., 2007) as these would result in fast, scalable algorithms for structured prediction.", "startOffset": 67, "endOffset": 116}, {"referenceID": 7, "context": "This setting has attracted a lot of attention recently in machine learning problems (Finley & Joachims, 2005; Haider et al., 2007).", "startOffset": 84, "endOffset": 130}, {"referenceID": 0, "context": "1 (Aldous, 1983) (Coupling lemma) Suppose M is a countable, ergodic Markov chain.", "startOffset": 2, "endOffset": 16}], "year": 2009, "abstractText": "We consider MAP estimators for structured prediction with exponential family models. In particular, we concentrate on the case that efficient algorithms for uniform sampling from the output space exist. We show that under this assumption (i) exact computation of the partition function remains a hard problem, and (ii) the partition function and the gradient of the log partition function can be approximated efficiently. Our main result is an approximation scheme for the partition function based on Markov Chain Monte Carlo theory. We also show that the efficient uniform sampling assumption holds in several application settings that are of importance in machine learning.", "creator": "TeX"}}}