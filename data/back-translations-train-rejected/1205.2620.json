{"id": "1205.2620", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2012", "title": "Exact Structure Discovery in Bayesian Networks with Less Space", "abstract": "The fastest known exact algorithms for scorebased structure discovery in Bayesian networks on n nodes run in time and space 2nnO(1). The usage of these algorithms is limited to networks on at most around 25 nodes mainly due to the space requirement. Here, we study space-time tradeoffs for finding an optimal network structure. When little space is available, we apply the Gurevich-Shelah recurrence-originally proposed for the Hamiltonian path problem-and obtain time 22n-snO(1) in space 2snO(1) for any s = n/2, n/4, n/8, . . .; we assume the indegree of each node is bounded by a constant. For the more practical setting with moderate amounts of space, we present a novel scheme. It yields running time 2n(3/2)pnO(1) in space 2n(3/4)pnO(1) for any p = 0, 1, . . ., n/2; these bounds hold as long as the indegrees are at most 0.238n. Furthermore, the latter scheme allows easy and efficient parallelization beyond previous algorithms. We also explore empirically the potential of the presented techniques.", "histories": [["v1", "Wed, 9 May 2012 17:30:15 GMT  (162kb)", "http://arxiv.org/abs/1205.2620v1", "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)", "reviews": [], "SUBJECTS": "cs.AI cs.DS", "authors": ["pekka parviainen", "mikko koivisto"], "accepted": false, "id": "1205.2620"}, "pdf": {"name": "1205.2620.pdf", "metadata": {"source": "CRF", "title": "Exact Structure Discovery in Bayesian Networks with Less Space", "authors": ["Pekka Parviainen"], "emails": ["mikko.koivisto}@cs.helsinki.fi"], "sections": [{"heading": null, "text": "The fastest known exact algorithms for detecting score-based structures in Bayesian networks on n nodes run in time and space 2nnO (1). The use of these algorithms is limited to a maximum of 25 nodes mainly due to the space requirements of networks. Here, we examine space-time compromises to find the optimal network structure. If space is limited, we apply the Gurevich Shelah repetition - originally proposed for the Hamiltonian path problem - and obtain time 22n \u2212 snO (1) in space 2snO (1) for each s = n / 2, n / 4, n / 8,...; we assume that the indeterminacy of each node is limited by a constant. For the more practical setting with moderate amounts of space, we present a novel scheme. It yields runtime 2n (3 / 2) pnO (1) in space 2n (3 / 4) pnO (1) for each 0, p = 1."}, {"heading": "1 INTRODUCTION", "text": "There are a number of approaches that have come up with the idea of going in search of a solution that moves towards people's needs, both people's needs and people's needs. (...) There are a variety of approaches that relate to people's needs. (...) There are a variety of approaches that are tailored to people's needs. \"(...) There are a variety of approaches that are tailored to people's needs.\" (...) There are a variety of approaches that have been tailored to people's needs. \"(...) There are a variety of approaches that relate to people's needs.\" (...) There are a variety of approaches that are tailored to people's needs. \"(...) There are a variety of approaches that have been tailored to people's needs.\" (...) There are a variety of approaches that relate to people's needs. \""}, {"heading": "2 PRELIMINARIES", "text": "In this section, we will first formulate the problem of structure discovery in Bayesian networks, then introduce one of the possible variants of existing exact algorithms, and finally adjust the problem formulation to a limited space."}, {"heading": "2.1 The Structure Discovery Problem", "text": "A Bayesian network is a multivariate probability distribution that obeys a structural representation in the form of a directed acyclic graph (DAG) and a corresponding collection of univariate conditional probability distributions. For our purposes, it is crucial to explicitly treat the DAG, i.e. the network structure, while the conditional probabilities only implicitly flow into our formalism. A DAG on a sentence N is an acyclic graph (N, A) with node N and arc A. A node u is referred to as the parent of v when the arc uv in A. We associate with Av the parent group of v. We associate the DAG with the marginal group A when there is no ambiguity about the node. Throughout the paper, we refer to the cardinality of N by n.The problem of Bayesian network structure discovery is as follows. For each node v VP-V and a possible parent group Av-N\\ v {a specific criterion corresponds to a local criterion of probability (1992)."}, {"heading": "2.2 A Dynamic Programming Algorithm", "text": "While the existing exact algorithms for the search for an optimal network structure have some variability in the details, the key terms are the same. (v) We now review one of the variants, an algorithm that calculates the maximum score - an actual score that reaches the optimal score can then be constructed using standard techniques. (V) The algorithm can be described in two phases. (V) In the first phase, it calculates the maximum score for each score v (Y) and the maximum score Y-score for each subset of Y, defined as asf (Y). = maxX Y fv (X). (1) In words, f v (Y) is the maximum score for v (Y) the maximum score for v\\ v that parents of v must select. In the second phase, the algorithm effectively goes through all the permutations of the nodes, but only tabulates intermediate results for the first sentences of the i order of the nodes."}, {"heading": "2.3 Limited Space: The Setting", "text": "To investigate the problem of structural discovery with limited space use, we need to be explicitly informed about the input of the problem. To this end, it is advisable to leave the local values fv (Av) available for each node v only for parent sentences Av belonging to a given family of possible parent sentences, which are called Fv; elsewhere, we define fv (Av). Whether the local values implicitly or explicitly affect the space requirements of the structural discovery problem: In the first case, we assume that each local value is evaluated on the basis of input data needed once in time and space; in the second case, the local values are treated as explicit input and already take up space. We will present our results under both approaches. We are particularly interested in families Fv, which are closed downwards, i.e. closed in terms of inclusion: if Y, Fv and X Y, then X Fv. Important examples of slightly downward-oriented parents b), which essentially form a closed group Y (essentially a closed group Y)."}, {"heading": "3 A DIVIDE & CONQUER SCHEME", "text": "Next, we will consider the partitioning based on \"Y\" with 0 (Y) = 0 (Y) = 0 (Y) = Y) = 0 (Y) = 0 (Y) = Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (N) = 1 (Y) = 1 (Y) = 1 = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1) = 1 (Y) = 1 = 1 = 1 (Y) = 1 (1) = 1 (Y) = 1 (1) = 1 (1) = 1 (Y) = 1 (1) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (N (Y) = 1 (N (Y) = 1 (Y) = 1 (N (Y) = 1 (N (Y) = 1 (Y) = 1 (Y) = 1 (N (Y) = 1 (N (Y) = 1 (Y) = 1 N (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 N (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y (Y) = 1 (Y (Y) = 1 (Y) = 1 (N (Y) = 1 (Y) = 1 (Y (Y) = 1 (Y (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 (Y) = 1 ("}, {"heading": "4 PARTIAL ORDERS: THE PAIRWISE SCHEME", "text": "It is the first time that we have introduced such a class. \"In what follows, we focus on partial jobs specified by the nodes of N in two sub-ranges of N in two sub-ranges of fixed magnitude.\" We have two sub-ranges of fixed magnitude described in the previous section is a simple example of such a class. \"\" We focus on partial jobs specified by P in two sub-ranges of fixed magnitude. \"\" We have two sub-ranges of fixed magnitude, with 0 sub-ranges of fixed magnitude, with 0 sub-ranges of fixed magnitude. \""}, {"heading": "5 UNBOUNDED INDEGREE", "text": "This year, it will be able to put itself at the top of the group."}, {"heading": "6 ON PARALLELIZATION", "text": "We note that the pair scheme described in the previous sections allows efficient parallelization. Obviously, any suborder of R-Cp can be handled in parallel. Furthermore, as in the Silander-Myllyma-ki implementation, the optimal local values can be calculated in parallel for each of the n nodes over given groups of possible parents in step 3 (b) of algorithm 1 - i.e., not merge with step 3 (a). Overall, this amounts to parallelization on 2pn processors (each with its own memory); this is efficient in that the runtime per processor is reduced by the same factor. Thus, if factors in n are ignored, the runtime per processor will be 2n (3 / 4) p (under the conditions of episode 17), i.e. exponentially less than 2n when p grows."}, {"heading": "7 EMPIRICAL RESULTS", "text": "We implemented the pair scheme in the C + + language. We examined the runtime for the 16 gigabyte memory limit and varied the number of nodes n from 25 to 31, setting the maximum indegree to 3 (the local values were taken as given, so their calculation is not included in the runtime estimates). First, we estimated the minimum number of node pairs p, which results in a memory requirement of 16 gigabytes at the most. Then, we executed algorithm 1 for a single suborder R-Cp; the resulting runtime was multiplied by 2p to obtain the total runtime, see Table 7. The experiments were performed on a 3.66 GHz Intel Xeon with 32 gigabytes of RAM. Table 1: The implemented pair scheme yielded 16 gigabytes of memory. Total CPU hours are reported, T, and split between 2p processors. n T / 2p"}, {"heading": "25 0 2 2.12", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "26 2 9 2.27", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "27 4 41 2.56", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "28 7 331 2.59", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "29 9 1660 3.24", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "30 12 13322 3.25", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "31 14 67748 4.14", "text": "We see that the current implementation is feasible up to about 31 nodes (4 weeks with 100 processors, 3 days with 1000 processors), but we believe that more careful implementation can reduce both time and space requirements to about a tenth, which should bring networks within reach to 34 nodes (with massive parallelization)."}, {"heading": "Acknowledgements", "text": "The authors thank Petteri Kaski, Fedor Fomin, Saket Saurabh and Yngve Villanger for useful discussions on the Gurevich-Shelah resurgence. The research was partially supported by the Finnish Academy of Sciences, Grant 125637."}, {"heading": "A. Bjo\u0308rklund and T. Husfeldt. Exact algorithms for exact", "text": "Algorithmica, 52: 226-249, 2008."}, {"heading": "H. L. Bodlaender, F. V. Fomin, A. M. C. A. Koster,", "text": "D. Kratsch, and D. M. Thilikos. On Exact Algorithms for Tree Width. In ESA, pp. 672-683, 2006."}, {"heading": "G. F. Cooper and E. Herskovits. A Bayesian method for the", "text": "Machine learning, 9: 309-347, 1992.D. Eaton and K. Murphy. Exact Bayesian structure that learns from uncertain interventions. In: Proc. of the 23rd Conference on Uncertainty in Artificial Intelligence and Statistics (AISTAT). Omnipress, 2007. Electronic only."}, {"heading": "N. Friedman and D. Koller. Being Bayesian about network structure: A Bayesian approach to structure discovery in", "text": "Bayesian Networks. Machine Learning, 50 (1-2): 95-125, 2003."}, {"heading": "Y. Gurevich and S. Shelah. Expected computation time", "text": "s Way Problem. SIAM J. Comput., 16: 486-502, 1987."}, {"heading": "D. Heckerman, D. Geiger, and D. M. Chickering. Learning Bayesian networks: The combination of knowledge and", "text": "Machine Learning, 20: 197-243, 1995."}, {"heading": "M. Held and R. Karp. A dynamic programming approach", "text": "J. Soc. Indust. Appl. Math., (10): 196-210, 1962.M. Koivisto. Advances in exact bayesian structure discovery in bayesian networks. In Proc. of the 22nd Conference on Uncertainty in Artificial Intelligence (UAI), pp. 241-248. AUAI Press, 2006.M. Koivisto and K. Sood. Exact bayesian structure discovery in bayesian networks. Journal of Machine Learning Research, 5: 549-573, 2004."}, {"heading": "E. Lawler. A comment on minimum feedback arc sets.", "text": "IEEE Trans. on Circuit Theory, pp. 296-297, 1964."}, {"heading": "S. Ott and S. Miyano. Finding optimal gene networks using", "text": "Biological Limitations. Genome Informatics, (14): 124- 133, 2003."}, {"heading": "E. Perrier, S. Imoto, and S. Miyano. Finding optimal", "text": "Bayesian network with a superstructure. Journal of Machine Learning Research, 9: 2251-2286, 2008."}, {"heading": "T. Silander and P. Myllyma\u0308ki. A simple approach for finding the globally optimal Bayesian network structure. In", "text": "Proc. of the 22nd Conference on Uncertainty in Artificial Intelligence (UAI), pp. 445-452. AUAI Press, 2006."}, {"heading": "A. Singh and A. Moore. Finding optimal Bayesian networks by dynamic programming. Technical report,", "text": "Carnegie Mellon University, June 2005."}], "references": [{"title": "Complexity of finding embeddings in a k-tree", "author": ["S. Arnborg", "D.G. Corneil", "A. Proskurowski"], "venue": "SIAM J. Alg. Disc. Meth.,", "citeRegEx": "Arnborg et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Arnborg et al\\.", "year": 1987}, {"title": "Dynamic programming treatment of the travelling salesman problem", "author": ["R. Bellman"], "venue": "J. Assoc. Comput. Mach.,", "citeRegEx": "Bellman.,? \\Q1962\\E", "shortCiteRegEx": "Bellman.", "year": 1962}, {"title": "Exact algorithms for exact satisfiability and number of perfect matchings", "author": ["A. Bj\u00f6rklund", "T. Husfeldt"], "venue": null, "citeRegEx": "Bj\u00f6rklund and Husfeldt.,? \\Q2008\\E", "shortCiteRegEx": "Bj\u00f6rklund and Husfeldt.", "year": 2008}, {"title": "On exact algorithms for treewidth", "author": ["H.L. Bodlaender", "F.V. Fomin", "A.M.C.A. Koster", "D. Kratsch", "D.M. Thilikos"], "venue": "In ESA,", "citeRegEx": "Bodlaender et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bodlaender et al\\.", "year": 2006}, {"title": "A Bayesian method for the induction of probabilistic networks from data", "author": ["G.F. Cooper", "E. Herskovits"], "venue": "Machine Learning,", "citeRegEx": "Cooper and Herskovits.,? \\Q1992\\E", "shortCiteRegEx": "Cooper and Herskovits.", "year": 1992}, {"title": "Exact Bayesian structure learning from uncertain interventions", "author": ["D. Eaton", "K. Murphy"], "venue": "In Proc. of the 23rd Conference on Uncertainty in Artificial Intelligence and Statistics (AISTAT). Omnipress,", "citeRegEx": "Eaton and Murphy.,? \\Q2007\\E", "shortCiteRegEx": "Eaton and Murphy.", "year": 2007}, {"title": "Being Bayesian about network structure: A Bayesian approach to structure discovery in Bayesian networks", "author": ["N. Friedman", "D. Koller"], "venue": "Machine Learning,", "citeRegEx": "Friedman and Koller.,? \\Q2003\\E", "shortCiteRegEx": "Friedman and Koller.", "year": 2003}, {"title": "Expected computation time for Hamiltonian path problem", "author": ["Y. Gurevich", "S. Shelah"], "venue": "SIAM J. Comput.,", "citeRegEx": "Gurevich and Shelah.,? \\Q1987\\E", "shortCiteRegEx": "Gurevich and Shelah.", "year": 1987}, {"title": "Learning Bayesian networks: The combination of knowledge and statistical data", "author": ["D. Heckerman", "D. Geiger", "D.M. Chickering"], "venue": "Machine Learning,", "citeRegEx": "Heckerman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Heckerman et al\\.", "year": 1995}, {"title": "A dynamic programming approach to sequencing problems", "author": ["M. Held", "R. Karp"], "venue": "J. Soc. Indust. Appl. Math.,", "citeRegEx": "Held and Karp.,? \\Q1962\\E", "shortCiteRegEx": "Held and Karp.", "year": 1962}, {"title": "Advances in exact Bayesian structure discovery in Bayesian networks", "author": ["M. Koivisto"], "venue": "In Proc. of the 22nd Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Koivisto.,? \\Q2006\\E", "shortCiteRegEx": "Koivisto.", "year": 2006}, {"title": "Exact Bayesian structure discovery in Bayesian networks", "author": ["M. Koivisto", "K. Sood"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Koivisto and Sood.,? \\Q2004\\E", "shortCiteRegEx": "Koivisto and Sood.", "year": 2004}, {"title": "A comment on minimum feedback arc sets", "author": ["E. Lawler"], "venue": "IEEE Trans. on Circuit Theory,", "citeRegEx": "Lawler.,? \\Q1964\\E", "shortCiteRegEx": "Lawler.", "year": 1964}, {"title": "Finding optimal gene networks using biological constraints", "author": ["S. Ott", "S. Miyano"], "venue": "Genome Informatics,", "citeRegEx": "Ott and Miyano.,? \\Q2003\\E", "shortCiteRegEx": "Ott and Miyano.", "year": 2003}, {"title": "Finding optimal Bayesian network given a super-structure", "author": ["E. Perrier", "S. Imoto", "S. Miyano"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Perrier et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Perrier et al\\.", "year": 2008}, {"title": "A simple approach for finding the globally optimal Bayesian network structure", "author": ["T. Silander", "P. Myllym\u00e4ki"], "venue": "In Proc. of the 22nd Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Silander and Myllym\u00e4ki.,? \\Q2006\\E", "shortCiteRegEx": "Silander and Myllym\u00e4ki.", "year": 2006}, {"title": "Finding optimal Bayesian networks by dynamic programming", "author": ["A. Singh", "A. Moore"], "venue": "Technical report,", "citeRegEx": "Singh and Moore.,? \\Q2005\\E", "shortCiteRegEx": "Singh and Moore.", "year": 2005}], "referenceMentions": [{"referenceID": 5, "context": "There has been relatively recent interest in devising exact algorithms for score-based structure learning in Bayesian networks (Eaton and Murphy, 2007; Koivisto and Sood, 2004; Koivisto, 2006; Perrier et al., 2008; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 127, "endOffset": 267}, {"referenceID": 11, "context": "There has been relatively recent interest in devising exact algorithms for score-based structure learning in Bayesian networks (Eaton and Murphy, 2007; Koivisto and Sood, 2004; Koivisto, 2006; Perrier et al., 2008; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 127, "endOffset": 267}, {"referenceID": 10, "context": "There has been relatively recent interest in devising exact algorithms for score-based structure learning in Bayesian networks (Eaton and Murphy, 2007; Koivisto and Sood, 2004; Koivisto, 2006; Perrier et al., 2008; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 127, "endOffset": 267}, {"referenceID": 14, "context": "There has been relatively recent interest in devising exact algorithms for score-based structure learning in Bayesian networks (Eaton and Murphy, 2007; Koivisto and Sood, 2004; Koivisto, 2006; Perrier et al., 2008; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 127, "endOffset": 267}, {"referenceID": 15, "context": "There has been relatively recent interest in devising exact algorithms for score-based structure learning in Bayesian networks (Eaton and Murphy, 2007; Koivisto and Sood, 2004; Koivisto, 2006; Perrier et al., 2008; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 127, "endOffset": 267}, {"referenceID": 16, "context": "There has been relatively recent interest in devising exact algorithms for score-based structure learning in Bayesian networks (Eaton and Murphy, 2007; Koivisto and Sood, 2004; Koivisto, 2006; Perrier et al., 2008; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 127, "endOffset": 267}, {"referenceID": 11, "context": "e, attributes or variables) compute and store intermediate results for all the possible 2 node subsets, running in time and space 2n, assuming the score obeys certain usual modularity properties (Koivisto and Sood, 2004; Ott and Miyano, 2003; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 195, "endOffset": 295}, {"referenceID": 13, "context": "e, attributes or variables) compute and store intermediate results for all the possible 2 node subsets, running in time and space 2n, assuming the score obeys certain usual modularity properties (Koivisto and Sood, 2004; Ott and Miyano, 2003; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 195, "endOffset": 295}, {"referenceID": 15, "context": "e, attributes or variables) compute and store intermediate results for all the possible 2 node subsets, running in time and space 2n, assuming the score obeys certain usual modularity properties (Koivisto and Sood, 2004; Ott and Miyano, 2003; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 195, "endOffset": 295}, {"referenceID": 16, "context": "e, attributes or variables) compute and store intermediate results for all the possible 2 node subsets, running in time and space 2n, assuming the score obeys certain usual modularity properties (Koivisto and Sood, 2004; Ott and Miyano, 2003; Silander and Myllym\u00e4ki, 2006; Singh and Moore, 2005).", "startOffset": 195, "endOffset": 295}, {"referenceID": 15, "context": "The current record of 29 nodes was achieved by the streamlined Silander\u2013Myllym\u00e4ki implementation (Silander and Myllym\u00e4ki, 2006) using nearly 100 gigabytes of hard disk.", "startOffset": 97, "endOffset": 127}, {"referenceID": 1, "context": "For a number of similar permutation problems\u2014like the Travelling Salesman problem, the Feedback Arcset problem, and Treewidth, to name a few\u2014dynamic programming algorithms running in time and space 2n have been known for decades (Bellman, 1962; Held and Karp, 1962; Lawler, 1964; Arnborg et al., 1987), with only negligible progress since; more recent work (Bodlaender et al.", "startOffset": 229, "endOffset": 301}, {"referenceID": 9, "context": "For a number of similar permutation problems\u2014like the Travelling Salesman problem, the Feedback Arcset problem, and Treewidth, to name a few\u2014dynamic programming algorithms running in time and space 2n have been known for decades (Bellman, 1962; Held and Karp, 1962; Lawler, 1964; Arnborg et al., 1987), with only negligible progress since; more recent work (Bodlaender et al.", "startOffset": 229, "endOffset": 301}, {"referenceID": 12, "context": "For a number of similar permutation problems\u2014like the Travelling Salesman problem, the Feedback Arcset problem, and Treewidth, to name a few\u2014dynamic programming algorithms running in time and space 2n have been known for decades (Bellman, 1962; Held and Karp, 1962; Lawler, 1964; Arnborg et al., 1987), with only negligible progress since; more recent work (Bodlaender et al.", "startOffset": 229, "endOffset": 301}, {"referenceID": 0, "context": "For a number of similar permutation problems\u2014like the Travelling Salesman problem, the Feedback Arcset problem, and Treewidth, to name a few\u2014dynamic programming algorithms running in time and space 2n have been known for decades (Bellman, 1962; Held and Karp, 1962; Lawler, 1964; Arnborg et al., 1987), with only negligible progress since; more recent work (Bodlaender et al.", "startOffset": 229, "endOffset": 301}, {"referenceID": 3, "context": ", 1987), with only negligible progress since; more recent work (Bodlaender et al., 2006) has shown that if only polynomial space is allowed, then many permutation problems can PARVIAINEN & KOIVISTO 436 UAI 2009", "startOffset": 63, "endOffset": 88}, {"referenceID": 7, "context": "This divide and conquer technique is known as the Gurevich\u2013Shelah recurrence, originally presented for the Hamiltonian path problem (Gurevich and Shelah, 1987) and later applied also elsewhere (Bj\u00f6rklund and Husfeldt, 2008; Bodlaender et al.", "startOffset": 132, "endOffset": 159}, {"referenceID": 2, "context": "This divide and conquer technique is known as the Gurevich\u2013Shelah recurrence, originally presented for the Hamiltonian path problem (Gurevich and Shelah, 1987) and later applied also elsewhere (Bj\u00f6rklund and Husfeldt, 2008; Bodlaender et al., 2006).", "startOffset": 193, "endOffset": 248}, {"referenceID": 3, "context": "This divide and conquer technique is known as the Gurevich\u2013Shelah recurrence, originally presented for the Hamiltonian path problem (Gurevich and Shelah, 1987) and later applied also elsewhere (Bj\u00f6rklund and Husfeldt, 2008; Bodlaender et al., 2006).", "startOffset": 193, "endOffset": 248}, {"referenceID": 15, "context": "We note that while the Silander\u2013Myllym\u00e4ki implementation is easy to run in parallel on n processors, the time requirement per processor remains 2, up to a polynomial factor (Silander and Myllym\u00e4ki, 2006).", "startOffset": 173, "endOffset": 203}, {"referenceID": 4, "context": "Given these local scores, the task is to find a DAG A that maximizes the sum of the local scores (Cooper and Herskovits, 1992; Heckerman et al., 1995),", "startOffset": 97, "endOffset": 150}, {"referenceID": 8, "context": "Given these local scores, the task is to find a DAG A that maximizes the sum of the local scores (Cooper and Herskovits, 1992; Heckerman et al., 1995),", "startOffset": 97, "endOffset": 150}, {"referenceID": 6, "context": "We note that this formulation does not directly apply to the so-called Bayesian approach to structure discovery (Friedman and Koller, 2003; Koivisto and Sood, 2004).", "startOffset": 112, "endOffset": 164}, {"referenceID": 11, "context": "We note that this formulation does not directly apply to the so-called Bayesian approach to structure discovery (Friedman and Koller, 2003; Koivisto and Sood, 2004).", "startOffset": 112, "endOffset": 164}, {"referenceID": 13, "context": "However, this can be significantly improved by dynamic programming, observed first in Ott and Miyano (2003):", "startOffset": 86, "endOffset": 108}, {"referenceID": 14, "context": "parent sets of cardinality at most k, for some fixed k, and (b) the parent sets that are contained in a given set of candidate parents (Perrier et al., 2008).", "startOffset": 135, "endOffset": 157}, {"referenceID": 13, "context": "Perhaps the most immediate attempt to do this would be dynamic programming according to the recurrence in Lemma 1; unfortunately, this seems to require space proportional to 2/ \u221a n, for each v, when proceeding level-wise (Ott and Miyano, 2003): to compute the scores f\u0302v(Y ) for sets Y of size l one needs to access the scores f\u0302v(X) of sets X of size l \u2212 1.", "startOffset": 221, "endOffset": 243}], "year": 2009, "abstractText": "The fastest known exact algorithms for scorebased structure discovery in Bayesian networks on n nodes run in time and space 2n. The usage of these algorithms is limited to networks on at most around 25 nodes mainly due to the space requirement. Here, we study space\u2013time tradeoffs for finding an optimal network structure. When little space is available, we apply the Gurevich\u2013 Shelah recurrence\u2014originally proposed for the Hamiltonian path problem\u2014and obtain time 2n in space 2n for any s = n/2, n/4, n/8, . . .; we assume the indegree of each node is bounded by a constant. For the more practical setting with moderate amounts of space, we present a novel scheme. It yields running time 2(3/2)n in space 2(3/4)n for any p = 0, 1, . . . , n/2; these bounds hold as long as the indegrees are at most 0.238n. Furthermore, the latter scheme allows easy and efficient parallelization beyond previous algorithms. We also explore empirically the potential of the presented techniques.", "creator": null}}}