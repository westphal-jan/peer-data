{"id": "1205.2635", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2012", "title": "Constraint Processing in Lifted Probabilistic Inference", "abstract": "First-order probabilistic models combine representational power of first-order logic with graphical models. There is an ongoing effort to design lifted inference algorithms for first-order probabilistic models. We analyze lifted inference from the perspective of constraint processing and, through this viewpoint, we analyze and compare existing approaches and expose their advantages and limitations. Our theoretical results show that the wrong choice of constraint processing method can lead to exponential increase in computational complexity. Our empirical tests confirm the importance of constraint processing in lifted inference. This is the first theoretical and empirical study of constraint processing in lifted inference.", "histories": [["v1", "Wed, 9 May 2012 15:41:10 GMT  (204kb)", "http://arxiv.org/abs/1205.2635v1", "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jacek kisynski", "david l poole"], "accepted": false, "id": "1205.2635"}, "pdf": {"name": "1205.2635.pdf", "metadata": {"source": "META", "title": "Constraint Processing in Lifted Probabilistic Inference", "authors": ["Jacek Kisy\u0144ski"], "emails": ["poole}@cs.ubc.ca"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we will be able, that we will be able, that we will be able, that we will be able, that we will not be able, that we will not be able, that we will be able, that we will be able."}, {"heading": "2 PRELIMINARIES", "text": "In this section we present a definition of parameterized random variables, which are essential components of first-order probability models. We also define parameters (Poole, 2003), which are data structures used during elevated inference."}, {"heading": "2.1 PARAMETERIZED RANDOM VARIABLES", "text": "If S is a set, we denote by | S | the size of the set S. A population is a group of individuals. A population corresponds to a domain in logic. A parameter corresponds to a logical variable and is typed with a population. In view of parameter X, we denote their population with D (X). In view of a set of constraints C, we denote a group of individuals from D (X) who fulfill constraints in C by D (X): C. A substitution is a substitution in the form {X1 / t1.}, Xk / tk}, where the Xi are different parameters, and each term ti is a parameter that denotes a population or a constant from a population. A substitution is a substitution in which each ti is a constant. A parameterized random variable is of the form f (t1,., tk), where f is a variable."}, {"heading": "2.2 PARAMETRIC FACTORS", "text": "A factor of random variables is a function that assumes the set returns a real number in the face of an assignment of a value to each random variable. Factors are used in the variable elimination of factors (Zhang and Poole, 1994) to store initial conditional probabilities and intermediate results of the calculation during the probability calculation."}, {"heading": "3 LIFTED INFERENCE AND CONSTRAINT PROCESSING", "text": "In this section, we give an overview of the exact elevated probability factors developed in (Poole, 2003), (de Salvo Braz et al., 2007) and (Milch et al., 2008) in the context of constraints. < For more details on other aspects of elevated inference, we refer the reader to the papers above. Let us consider a set of parameters. Let J (\u03a6) designate a factor that corresponds to the product of all factors represented by elements of mathematics. Let U be the set of all random variables represented by parameterized random variables in the parameters. Let Q designate a subset of U. The marginal of J (\u03a6) to Q, referred to as JQ (\u03a6), is defined as JQ."}, {"heading": "3.1 SPLITTING", "text": "The prerequisite for parameter multiplication can be fulfilled by dividing parameters to substitution factors.Let there be a set of parameters. Let p f = < C, V, FF > \u03a6. A division of p f to {X / t} results in two parameters: p f [X / t], which is a parameter p f with all occurrences of X by the term t, and a parameter p fr = < C \u00b2 {X 6 = t}, V, FF >. We have J (\u03a6) = J (\u03a6) {p f [X / t], which is a parameter p f with all occurrences of X by the term, and a parameter p fr = < C \u00b2 {X 6 = t, FF >."}, {"heading": "3.2 MULTIPLICATION", "text": "Once the prerequisite for parameter multiplication is met, the multiplication can be performed in an upscale manner. < g = Factors that participate in a multiplication, as well as their product represent several factors, the calculation cost of the parameter multiplication is limited to the cost of the multiplication of two factors. The only additional requirement is that the raised inference procedure must know how many factors each factor involved in the multiplication represents and how many factors will represent its product. These numbers may be different because the product parameter may include more parameters than one parameter participating in the multiplication. In such a case, a correction of the values of a factor within suitable parameters participating in the multiplication is necessary."}, {"heading": "3.3 SUMMING OUT", "text": "During the raised summation, a parameterized random variable is added from a factor < C, V, FF >, meaning that a random variable is eliminated from each factor represented by the parameter in an inference step. < X = Factor Y is added only once to the factor F. If some parameters appear only in the parameterized variable that is eliminated, the resulting parameter will represent fewer factors than the original one. As in the case of parameter multiplication, the inference procedure must compensate for this difference. It must represent the size of the set X = (D (X1) \u00b7 \u00b7 D (Xk): C, where X1,. Xk are parameters that disappear from the parameter Y. This number tells us how many times fewer factors are the result of the summing of the values from Fex to Fex."}, {"heading": "3.4 PROPOSITIONALIZATION", "text": "During inference in first-order probability models, it may occur that none of the raised operations (including operations not described in this essay) can be applied. In such a situation, the inference procedure replaces appropriate parameterized random variables with random variables represented by them, which can be achieved by splitting, as we demonstrate in a subsequent example. Afterwards, inference is performed at least partially at the statement level. As it has a negative effect on the efficiency of the inference, propositioning during inference in first-order models is avoided as far as possible. Example 8. Consider a parameter < / 0, {g (A), Fg > from Example 2. Suppose that we have to proposition g (A). Remember that D (A) = {x1,.,., xn}. Propositioning results in a series of parameters < / 0, {g (1), < F; / 0."}, {"heading": "4 #CSP SOLVER AND LIFTED", "text": "In fact, it is such that most of them are in a position to move into another world, in which they are able to move, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "5 THEORETICAL RESULTS", "text": "In this section, we discuss the consequences of different approaches to restriction processing in reversed conclusions."}, {"heading": "5.1 SPLITTING AS NEEDED VS. SHATTERING", "text": "An alternative, called random variables, was proposed by de Salvo Braz et al. (2007). They perform splitting at the beginning of the inference by performing all the splits required to ensure that all two parameterized random variables present in the parameters considered are either identical or fragmented. (2007) Fragmentation was also used in Milk et al. (2008). Fragmentation simplifies the design and implementation of raised inference procedures, especially the construction of the elimination of heuristics. Unfortunately, as we show in Theorem 1, it can lead to the creation of a large number of parameters that are not created by following the splitting according to a needy approach. Let Q be a set of parameters."}, {"heading": "5.2 NORMAL FORM PARFACTORS VS. #CSP SOLVER", "text": "We consider two interconnected form parameters to be interconnected. We were introduced by Milch et al. (2008) in the context of counting formulas. We count formulas as parameterized random variables, which compactly represent to us a special form of probability dependencies between instances of a parameterized random variable = = 6 factors. Milk et al. (2008) require all parameters to be in normal form in order to eliminate the need to use a separate constraint solver to solve # CSP. The requirement is enforced by splitting parameters that are not applied in normal form to appropriate substitutions. While parameters that count formulas must be in normal form, this is not necessary for parameters to count without formulas. It could actually be quite expensive, as we found in this section.Proposition 1. Let < C, F > be a parameter in normal form. Then each connected proposition is completely true to the constellation C, or the constellation of one component is true to two."}, {"heading": "5.2.1 Multiplication", "text": "In the following example, we will show how the requirement for the normal form could lead to many, otherwise unnecessary factors. (Example 11. Let's assume we want to multiply the parameter from Example 10 by a factor p f = < / 0, {g1 (X1)}, F1 >. First, let's consider how to do it with a # CSP solver. A # CSP solver will calculate the number of factors represented by the factor from Example 10, (| D (X0) | \u2212 1) k + 1. Next, the solver will calculate the number of factors represented by the parameter p f, which will be multiplied trivially | D (X1). A correction will be applied to values of factor F1 to compensate for the difference between these two numbers. Finally, the two parameters will be multiplied and the entire operation will include two calls to a # CSP solver, a correction, and a parameter multiplication."}, {"heading": "5.2.2 Summing Out", "text": "Examples 7 and 9 show how to sum up a parameterized variable from a parameter that is not in normal form using a # CSP solver. In the following example, we show what this operation would look like if we converted the parameter into a set of parameters in normal form that do not require a # CSP solver. Example 12. Let's assume that we convert f (X, Y) from the parameter < X 6 = Y = a, {e (X, Y), Fe f > from Example 7 we convert it into a set of parameters in normal form by splitting it into substitutions {X / a}. We get two parameters in normal form: < {Y 6 = a), f (a, Y), f > Fe >."}, {"heading": "6 EXPERIMENTS", "text": "We used Java implementations of tested upscale inference methods. We tested on an Intel Core 2 Duo 2.66 GHz processor with 1 GB of memory provided to the JVM."}, {"heading": "6.1 SPLITTING AS NEEDED VS. SHATTERING", "text": "In the first experiment, we tested to what extent the additional effort of the shattering approach can be minimized by intensive representations and immutable objects that can be divided if possible, using the following parameters: \u03a6 = {< / 0, {gQ (), g1 (a), F0 >, [0] < {X 6 = a}, {gQ (), g1 (X), F1 >, [1] < / 0, {g1 (X), g2 (X)}, F2 >, [2] < / 0, {g2 (X), g3 (X)}, F3 >, [3].. < / 0, {gk \u2212 1 (X), gk (X)}, Fk >, [k] < / 0, [k] < / 0, pk (X), g3 >, [3]."}, {"heading": "6.2 NORMAL FORM PARFACTORS VS. #CSP SOLVER", "text": "For the experiment in this section, we randomly generated sets of parameters. There were up to 5 parameterized random variables in each parameter with a bandwidth of 2 to 10. Constraints sets contained very few (and very often zero) constraints and formed sparse CSPs. Most parameters were in normal form, allowing us to consider the # CSP solver overhead. In each parameter, there were up to 10 parameters. Parameters were typed with the same population. We varied the size of this population from 5 to 1000 to verify how well # CSP solver was scaled for larger populations. In this experiment, we summed up a parameterized random variable from one factor. We compared the sum with a # CSP solver (# CSP-SUM) to achieve this by converting one parameter into a set of parameters in normal form and a sum of a random parameter # CSP variable from each SUP."}, {"heading": "7 CONCLUSIONS AND FUTURE WORK", "text": "In this paper, we analyzed the impact of constraint processing on the efficiency of upstairs inference and explained why we cannot ignore its role in upstairs inference. We showed that the choice of constraint processing strategy has a major impact on the efficiency of upstairs inference. In particular, we discovered that smashing (de Salvo Braz et al., 2007) is never better - and sometimes worse - than splitting on demand (Poole, 2003) and that converting parameters into normal form (Milch et al., 2008) is an expensive alternative to using a special # CSP solver. Although we focused on the exact upstairs inference in this paper, our results can be applied to approximating upstairs inference."}, {"heading": "Acknowledgments", "text": "The authors thank Brian Milch for discussing the CFOVE algorithm with us. Peter Carbonetto, Michael Chiang and Mark Crowley provided many helpful suggestions during the preparation of the paper. This work was supported by the NSERC grant to David Poole."}], "references": [{"title": "Construction of belief and decision networks", "author": ["J.S. Breese"], "venue": "Comput Intell,", "citeRegEx": "Breese.,? \\Q1992\\E", "shortCiteRegEx": "Breese.", "year": 1992}, {"title": "Operations for learning with graphical models", "author": ["W.L. Buntine"], "venue": "J Artif Intell Res,", "citeRegEx": "Buntine.,? \\Q1994\\E", "shortCiteRegEx": "Buntine.", "year": 1994}, {"title": "Lifted first-order probabilistic inference. In Introduction to Statistical Relational Learning", "author": ["R. de Salvo Braz", "E. Amir", "D. Roth"], "venue": null, "citeRegEx": "Braz et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Braz et al\\.", "year": 2007}, {"title": "Introduction to Statistical Relational Learning", "author": ["L. Getoor", "B. Taskar", "editors"], "venue": null, "citeRegEx": "Getoor et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Getoor et al\\.", "year": 2007}, {"title": "A dynamic approach to probabilistic inference using Bayesian networks", "author": ["M. Horsch", "D. Poole"], "venue": "In Proc. 6th UAI,", "citeRegEx": "Horsch and Poole.,? \\Q1990\\E", "shortCiteRegEx": "Horsch and Poole.", "year": 1990}, {"title": "Combinatorial Problems and Exercises", "author": ["L. Lov\u00e1sz"], "venue": "2nd ed. North-Holland,", "citeRegEx": "Lov\u00e1sz.,? \\Q1993\\E", "shortCiteRegEx": "Lov\u00e1sz.", "year": 1993}, {"title": "Lifted probabilistic inference with counting formulas", "author": ["B. Milch", "L.S. Zettlemoyer", "K. Kersting", "M. Haimes", "L.P. Kaelbling"], "venue": "In Proc. 23rd AAAI,", "citeRegEx": "Milch et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Milch et al\\.", "year": 2008}, {"title": "First-order probabilistic inference", "author": ["D. Poole"], "venue": "In Proc. 18th IJCAI,", "citeRegEx": "Poole.,? \\Q2003\\E", "shortCiteRegEx": "Poole.", "year": 2003}, {"title": "Lifted first-order belief propagation", "author": ["P. Singla", "P. Domingos"], "venue": "In Proc. 23rd AAAI,", "citeRegEx": "Singla and Domingos.,? \\Q2008\\E", "shortCiteRegEx": "Singla and Domingos.", "year": 2008}, {"title": "A simple approach to Bayesian network computations", "author": ["N.L. Zhang", "D. Poole"], "venue": "In Proc. 10th AI,", "citeRegEx": "Zhang and Poole.,? \\Q1994\\E", "shortCiteRegEx": "Zhang and Poole.", "year": 1994}], "referenceMentions": [{"referenceID": 0, "context": "Representations that mix graphical models and first-order logic\u2014called either first-order or relational probabilistic models\u2014were proposed nearly twenty years ago (Breese, 1992; Horsch and Poole, 1990) and many more have since emerged (De Raedt et al.", "startOffset": 163, "endOffset": 201}, {"referenceID": 4, "context": "Representations that mix graphical models and first-order logic\u2014called either first-order or relational probabilistic models\u2014were proposed nearly twenty years ago (Breese, 1992; Horsch and Poole, 1990) and many more have since emerged (De Raedt et al.", "startOffset": 163, "endOffset": 201}, {"referenceID": 0, "context": "Representations that mix graphical models and first-order logic\u2014called either first-order or relational probabilistic models\u2014were proposed nearly twenty years ago (Breese, 1992; Horsch and Poole, 1990) and many more have since emerged (De Raedt et al., 2008; Getoor and Taskar, 2007). In these models, random variables are parameterized by individuals belonging to a population. Even for very simple first-order models, inference at the propositional level\u2014that is, inference that explicitly considers every individual\u2014is intractable. The idea behind lifted inference is to carry out as much inference as possible without propositionalizing. An exact lifted inference procedure for first-order probabilistic directed models was originally proposed by Poole (2003). It was later extended to a broader range of problems by de Salvo Braz et al.", "startOffset": 164, "endOffset": 764}, {"referenceID": 0, "context": "Representations that mix graphical models and first-order logic\u2014called either first-order or relational probabilistic models\u2014were proposed nearly twenty years ago (Breese, 1992; Horsch and Poole, 1990) and many more have since emerged (De Raedt et al., 2008; Getoor and Taskar, 2007). In these models, random variables are parameterized by individuals belonging to a population. Even for very simple first-order models, inference at the propositional level\u2014that is, inference that explicitly considers every individual\u2014is intractable. The idea behind lifted inference is to carry out as much inference as possible without propositionalizing. An exact lifted inference procedure for first-order probabilistic directed models was originally proposed by Poole (2003). It was later extended to a broader range of problems by de Salvo Braz et al. (2007). Further work by Milch et al.", "startOffset": 164, "endOffset": 849}, {"referenceID": 0, "context": "Representations that mix graphical models and first-order logic\u2014called either first-order or relational probabilistic models\u2014were proposed nearly twenty years ago (Breese, 1992; Horsch and Poole, 1990) and many more have since emerged (De Raedt et al., 2008; Getoor and Taskar, 2007). In these models, random variables are parameterized by individuals belonging to a population. Even for very simple first-order models, inference at the propositional level\u2014that is, inference that explicitly considers every individual\u2014is intractable. The idea behind lifted inference is to carry out as much inference as possible without propositionalizing. An exact lifted inference procedure for first-order probabilistic directed models was originally proposed by Poole (2003). It was later extended to a broader range of problems by de Salvo Braz et al. (2007). Further work by Milch et al. (2008) expanded the scope of lifted inference and resulted in the C-FOVE algorithm, which is currently the state of the art in exact lifted inference.", "startOffset": 164, "endOffset": 886}, {"referenceID": 5, "context": "In Poole (2003), each constraint is processed only when necessary to continue probabilistic inference.", "startOffset": 3, "endOffset": 16}, {"referenceID": 2, "context": "Conversely, in de Salvo Braz et al. (2007) all constraints are processed at the start of the inference (this procedure is called shattering), and at every point at which a new constraint arises.", "startOffset": 24, "endOffset": 43}, {"referenceID": 2, "context": "Conversely, in de Salvo Braz et al. (2007) all constraints are processed at the start of the inference (this procedure is called shattering), and at every point at which a new constraint arises. Both approaches need to use constraint processing to count the number of solutions to constraint satisfaction problems that arise during the probabilistic inference. Milch et al. (2008) adopt the shattering procedure, and avoid the need to use a constraint solver by requiring that the constraints be written in normal form.", "startOffset": 24, "endOffset": 381}, {"referenceID": 7, "context": "We also define parfactors (Poole, 2003), which are data structures used during lifted inference.", "startOffset": 26, "endOffset": 39}, {"referenceID": 9, "context": "in the variable elimination algorithm (Zhang and Poole, 1994) to store initial conditional probabilities and intermediate results of computation during probabilistic inference in graphical models.", "startOffset": 38, "endOffset": 61}, {"referenceID": 7, "context": "In the next example, which extends Example 1, we use parameterized belief networks (PBNs) (Poole, 2003) to illustrate representational power of parfactors.", "startOffset": 90, "endOffset": 103}, {"referenceID": 2, "context": "The PBNs are a simple first-order directed probabilistic model, we could have used parameterized Markov networks instead (as did de Salvo Braz et al. (2007) and Milch et al.", "startOffset": 138, "endOffset": 157}, {"referenceID": 2, "context": "The PBNs are a simple first-order directed probabilistic model, we could have used parameterized Markov networks instead (as did de Salvo Braz et al. (2007) and Milch et al. (2008)).", "startOffset": 138, "endOffset": 181}, {"referenceID": 6, "context": "A parfactor \u3008C,V,FF\u3009 is in normal form (Milch et al., 2008) if for each inequality (X 6= Y ) \u2208 C, where X and Y are parameters, we have EC X \\{Y}= EC Y \\{X}.", "startOffset": 39, "endOffset": 59}, {"referenceID": 7, "context": "In this section we give an overview of exact lifted probabilistic inference developed in (Poole, 2003), (de Salvo Braz et al.", "startOffset": 89, "endOffset": 102}, {"referenceID": 6, "context": ", 2007), and (Milch et al., 2008) in context of constraints.", "startOffset": 13, "endOffset": 33}, {"referenceID": 2, "context": "For more information see Example 6 below and a discussion of the fusion operation in de Salvo Braz et al. (2007). For our purpose, the key point is that the lifted inference procedure needs to compute the number of factors represented by a parfactor.", "startOffset": 94, "endOffset": 113}, {"referenceID": 6, "context": "The result needs to be represented with a counting formula (Milch et al., 2008), which is outside of the scope of this paper.", "startOffset": 59, "endOffset": 79}, {"referenceID": 7, "context": "In our experiments presented in Section 6 we used a solver (Kisy\u0144ski and Poole, 2006) that addresses the above concern. It is a lifted solver based on the variable elimination algorithm for solving #CSP of Dechter (2003) and is optimized to handle problems that contain only inequality constraints.", "startOffset": 73, "endOffset": 221}, {"referenceID": 5, "context": "Bell numbers grow faster than any exponential function (see Lov\u00e1sz (2003)), but for small w\u2019s they stay much smaller than exponential functions with a moderate base (see Figure 2).", "startOffset": 60, "endOffset": 74}, {"referenceID": 2, "context": "An alternative, called shattering, was proposed by de Salvo Braz et al. (2007). They perform splitting at the beginning of the inference by doing all the splits that are required to ensure that for any two parameterized random variables present in considered parfactors the sets of random variables represented by them are either identical or disjoint.", "startOffset": 60, "endOffset": 79}, {"referenceID": 2, "context": "An alternative, called shattering, was proposed by de Salvo Braz et al. (2007). They perform splitting at the beginning of the inference by doing all the splits that are required to ensure that for any two parameterized random variables present in considered parfactors the sets of random variables represented by them are either identical or disjoint.1 Shattering was also used in Milch et al. (2008).", "startOffset": 60, "endOffset": 402}, {"referenceID": 6, "context": "Normal form parfactors were introduced by Milch et al. (2008) in the context of counting formulas.", "startOffset": 42, "endOffset": 62}, {"referenceID": 6, "context": "Normal form parfactors were introduced by Milch et al. (2008) in the context of counting formulas. Counting formulas are parameterized random variables that let us compactly represent a special form of probabilistic dependencies between instances of a parameterized random variable. Milch et al. (2008) require all parfactors to be in normal form to eliminate the need to use a separate constraint solver to solve #CSP.", "startOffset": 42, "endOffset": 303}, {"referenceID": 7, "context": "#CSP solver (Poole, 2003), or with normal form parfactors.", "startOffset": 12, "endOffset": 25}, {"referenceID": 6, "context": ", 2007) or with normal form parfactors (Milch et al., 2008).", "startOffset": 39, "endOffset": 59}, {"referenceID": 7, "context": ", 2007) is never better\u2014and sometimes worse\u2014than splitting as needed (Poole, 2003), and that the conversion of parfactors to normal form (Milch et al.", "startOffset": 69, "endOffset": 82}, {"referenceID": 6, "context": ", 2007) is never better\u2014and sometimes worse\u2014than splitting as needed (Poole, 2003), and that the conversion of parfactors to normal form (Milch et al., 2008) is an expensive alternative to using a specialized #CSP solver.", "startOffset": 137, "endOffset": 157}, {"referenceID": 8, "context": "For example, see the recent work of (Singla and Domingos, 2008) that uses shattering.", "startOffset": 36, "endOffset": 63}], "year": 2009, "abstractText": "First-order probabilistic models combine representational power of first-order logic with graphical models. There is an ongoing effort to design lifted inference algorithms for first-order probabilistic models. We analyze lifted inference from the perspective of constraint processing and, through this viewpoint, we analyze and compare existing approaches and expose their advantages and limitations. Our theoretical results show that the wrong choice of constraint processing method can lead to exponential increase in computational complexity. Our empirical tests confirm the importance of constraint processing in lifted inference. This is the first theoretical and empirical study of constraint processing in lifted inference.", "creator": "TeX"}}}