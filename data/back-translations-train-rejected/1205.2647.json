{"id": "1205.2647", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2012", "title": "Generating Optimal Plans in Highly-Dynamic Domains", "abstract": "Generating optimal plans in highly dynamic environments is challenging. Plans are predicated on an assumed initial state, but this state can change unexpectedly during plan generation, potentially invalidating the planning effort. In this paper we make three contributions: (1) We propose a novel algorithm for generating optimal plans in settings where frequent, unexpected events interfere with planning. It is able to quickly distinguish relevant from irrelevant state changes, and to update the existing planning search tree if necessary. (2) We argue for a new criterion for evaluating plan adaptation techniques: the relative running time compared to the \"size\" of changes. This is significant since during recovery more changes may occur that need to be recovered from subsequently, and in order for this process of repeated recovery to terminate, recovery time has to converge. (3) We show empirically that our approach can converge and find optimal plans in environments that would ordinarily defy planning due to their high dynamics.", "histories": [["v1", "Wed, 9 May 2012 13:51:50 GMT  (140kb)", "http://arxiv.org/abs/1205.2647v1", "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["christian fritz", "sheila mcilraith"], "accepted": false, "id": "1205.2647"}, "pdf": {"name": "1205.2647.pdf", "metadata": {"source": "CRF", "title": "Generating Optimal Plans in Highly-Dynamic Domains", "authors": ["Christian Fritz", "Sheila A. McIlraith"], "emails": ["sheila}@cs.toronto.edu"], "sections": [{"heading": null, "text": "Creating optimal plans in highly dynamic environments is a challenge. Plans are based on an assumed initial state, but this state can change unexpectedly during the planning process and potentially negate the planning effort. In this post, we propose three contributions: (1) We propose a new algorithm to create optimal plans in environments where frequent, unexpected events impede planning. It is able to quickly distinguish relevant from irrelevant state changes and update the existing planning search tree if necessary. (2) We argue for a new criterion for evaluating planning adaptation techniques: the relative duration compared to the \"size\" of changes. This is significant because during the recovery there may be other changes from which one needs to recover, and for this process of repeated recovery to end, the recovery time must approach. (3) We demonstrate empirically that our approach can converge and find optimal plans in environments that would normally be resilient due to their high dynamics."}, {"heading": "1 Introduction", "text": "It is one of the largest nodes in the world that has ever existed."}, {"heading": "2 Background", "text": "For the exposure in this work we use the formula of the situation using a standard term of arithmetic, but the approach works with any action specification language for which regression can be defined, including STRIPS and ADL.The situation calculus is a logical language for determining and reflecting on dynamic systems [Reiter, 2001].In the situation calculus, the state of the world is expressed in terms of functions and relationships called fluents, i.e. relative to a situation s, e.g. F (~ x, s). A situation is a history of primitive actions performed from a distinct starting situation. The function do (a, s) maps an action and a situation thus inducing a tree of situations root in S0. For readability, action and fluent argument are often suppressed (an, do (an \u2212 1,.do) is abbreviated to do."}, {"heading": "3 Planning with Unexpected Events", "text": "In this paper, we consider a planner based on a forward search that uses positive action costs as a metric, but the conceptual approach is accessible to a variety of other forward planning techniques and paradigms. Intuitively, our approach comments on the search tree with all the relevant information to determine the optimal plan. By reversing the goal, prerequisites and metric function across all considered action sequences, this information is expressed in terms of the current state. If unexpected events change the current state of the world, we can symbolically think about its relevance and potential impact on the current search tree and the choice of the plan - much faster than rescheduling from scratch. Thus, our football robot knows from relying on the goal that the plan [\"Drive to the goal\"] will succeed whenever \"Distance to the ball < 10cm\" establishes the relevance of the aforementioned ball shifts, and also that unexpected measures of its approach can be ignored."}, {"heading": "3.1 Regression-based A\u2217 planning", "text": "In this section, we introduce a planner who not only specifies a plan, but also the remaining open list after completion of the search, as well as a search tree that comments on any relevant regressive formulas. To perform a formal characterization, we assume that the planning domain is encoded in a basic action theory. Faced with a starting situation S, a target formula target (s), a formula cost (a, c, s) that defines the cost of the action a, and a consistent heuristic formula specified as formula hay (h, s), a sequence of actions that satisfies such a situation (~ \u03b1, S) finds the target while minimizing the accumulated costs. Starting from an open list that contains only one element representing the empty action sequence, the search continues by repeatedly removing and expanding the first element until that element meets the target, with the open list always defined by the v."}, {"heading": "3.2 Recovering from Unexpected Events", "text": "While generating a plan for an assumed starting situation S, an unexpected event e, say \"distanceTo (ball) \u2190 20,\" can occur to change the state of the world and put us in a situation do (e, S). If this happens, the above mentioned index can show us all formulas affected by this change (e.g., T (turn, driveTo (goal), finish]).P (s). After reevaluating these formulas in do (e, S) and updating their values, the search tree will be up-to-date in the sense that all contained values are to be done in relation to (e, S) rather than the originally assumed situation. After propagating these changes to the open list, the search can continue. We show that the resulting plan is optimal for the new situation. Note that the regressed formulas never change. Since often very few fluctuations are affected by unexpected events, this relevant approach will be used for a very efficient recovery."}, {"heading": "4 Empirical Results", "text": "In fact, it is not the case that we have gone in search of what drives us, but rather that we have gone in search of what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us, what drives us."}, {"heading": "5 Discussion", "text": "This year, it has reached the stage where it will be able to take the lead."}], "references": [{"title": "Symbolic dynamic programming for first-order MDPs", "author": ["C. Boutilier", "R. Reiter", "B. Price"], "venue": "Proc. IJCAI\u201901, pp. 690\u2013700", "citeRegEx": "Boutilier et al.. 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "Learning and executing generalized robot plans", "author": ["R. Fikes", "P. Hart", "N. Nilsson"], "venue": "Artificial Intelligence, 3:251\u2013288", "citeRegEx": "Fikes et al.. 1972", "shortCiteRegEx": null, "year": 1972}, {"title": "University of Toronto", "author": ["Christian Fritz. Monitoring the Generation", "Execution of Optimal Plans. PhD thesis"], "venue": "April", "citeRegEx": "Fritz. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Fast plan adaptation through planning graphs: Local and systematic search techniques", "author": ["A. Gerevini", "I. Serina"], "venue": "Proc. AIPS\u201900, pp. 112\u2013121", "citeRegEx": "Gerevini and Serina. 2000", "shortCiteRegEx": null, "year": 2000}, {"title": "A domainindependent algorithm for plan adaptation", "author": ["S. Hanks", "D.S. Weld"], "venue": "J. Artif. Intell. Res. (JAIR), 2:319\u2013360", "citeRegEx": "Hanks and Weld. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "Flucap: A heuristic search planner for first-order MDPs", "author": ["S. H\u00f6lldobler", "E. Karabaev", "O. Skvortsova"], "venue": "J. Artif. Intell. Res., 27:419\u2013439", "citeRegEx": "H\u00f6lldobler et al.. 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "A theory of plan modification", "author": ["S. Kambhampati"], "venue": "Proc. AAAI\u201990, pp. 176\u2013182", "citeRegEx": "Kambhampati. 1990", "shortCiteRegEx": null, "year": 1990}, {"title": "Heuristic search-based replanning", "author": ["S. Koenig", "D. Furcy", "C. Bauer"], "venue": "Proc. AIPS, pp. 294\u2013301", "citeRegEx": "Koenig et al.. 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Plan reuse versus plan generation: A theoretical and empirical analysis", "author": ["B. Nebel", "J. Koehler"], "venue": "Artificial Intelligence, 76(1\u20132):427\u2013454", "citeRegEx": "Nebel and Koehler. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "ADL: Exploring the middle ground between STRIPS and the situation calculus", "author": ["E.P.D. Pednault"], "venue": "Proc. KR\u201989, pp. 324\u2013332", "citeRegEx": "Pednault. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems", "author": ["Ray Reiter"], "venue": "MIT Press,", "citeRegEx": "Reiter. 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "The fringesaving A* search algorithm - a feasibility study", "author": ["X. Sun", "S. Koenig"], "venue": "Proc. IJCAI\u201907, pp. 2391\u20132397", "citeRegEx": "Sun and Koenig. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "Rationale-based monitoring for continuous planning in dynamic environments", "author": ["M.M. Veloso", "M.E. Pollack", "M.T. Cox"], "venue": "Proc. AIPS\u201998, pp. 171\u2013179", "citeRegEx": "Veloso et al.. 1998", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 10, "context": "The situation calculus is a logical language for specifying and reasoning about dynamical systems [Reiter, 2001].", "startOffset": 98, "endOffset": 112}, {"referenceID": 10, "context": "Details of the form of these axioms can be found in [Reiter, 2001].", "startOffset": 52, "endOffset": 66}, {"referenceID": 10, "context": "In the situation calculus, one step regression is defined inductively using the successor state axiom for a fluent F (~x) as above [Reiter, 2001]:", "startOffset": 131, "endOffset": 145}, {"referenceID": 10, "context": "Due to the Regression Theorem [Reiter, 2001] we have that D |= \u03c8(do(~ \u03b1, s)) \u2261 R[\u03c8(s), ~ \u03b1] for all", "startOffset": 30, "endOffset": 44}, {"referenceID": 9, "context": "Regression in ADL was defined in [Pednault, 1989].", "startOffset": 33, "endOffset": 49}, {"referenceID": 10, "context": "Due to the Regression Theorem [Reiter, 2001], this known fact about A also holds for our regression-based version.", "startOffset": 30, "endOffset": 44}, {"referenceID": 2, "context": "[Fritz, 2009]), including an approach for monitoring plan optimality during execution.", "startOffset": 0, "endOffset": 13}, {"referenceID": 7, "context": ", [Koenig et al., 2002; Hanks and Weld, 1995; Gerevini and Serina, 2000].", "startOffset": 2, "endOffset": 72}, {"referenceID": 4, "context": ", [Koenig et al., 2002; Hanks and Weld, 1995; Gerevini and Serina, 2000].", "startOffset": 2, "endOffset": 72}, {"referenceID": 3, "context": ", [Koenig et al., 2002; Hanks and Weld, 1995; Gerevini and Serina, 2000].", "startOffset": 2, "endOffset": 72}, {"referenceID": 0, "context": ", [Boutilier et al., 2001; H\u00f6lldobler et al., 2006]).", "startOffset": 2, "endOffset": 51}, {"referenceID": 5, "context": ", [Boutilier et al., 2001; H\u00f6lldobler et al., 2006]).", "startOffset": 2, "endOffset": 51}], "year": 2009, "abstractText": "Generating optimal plans in highly dynamic environments is challenging. Plans are predicated on an assumed initial state, but this state can change unexpectedly during plan generation, potentially invalidating the planning effort. In this paper we make three contributions: (1) We propose a novel algorithm for generating optimal plans in settings where frequent, unexpected events interfere with planning. It is able to quickly distinguish relevant from irrelevant state changes, and to update the existing planning search tree if necessary. (2) We argue for a new criterion for evaluating plan adaptation techniques: the relative running time compared to the \u201csize\u201d of changes. This is significant since during recovery more changes may occur that need to be recovered from subsequently, and in order for this process of repeated recovery to terminate, recovery time has to converge. (3) We show empirically that our approach can converge and find optimal plans in environments that would ordinarily defy planning due to their high dynamics.", "creator": "gnuplot 4.2 patchlevel 3 "}}}