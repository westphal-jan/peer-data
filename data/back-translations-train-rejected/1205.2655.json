{"id": "1205.2655", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2012", "title": "Mean Field Variational Approximation for Continuous-Time Bayesian Networks", "abstract": "Continuous-time Bayesian networks is a natural structured representation language for multicomponent stochastic processes that evolve continuously over time. Despite the compact representation, inference in such models is intractable even in relatively simple structured networks. Here we introduce a mean field variational approximation in which we use a product of inhomogeneous Markov processes to approximate a distribution over trajectories. This variational approach leads to a globally consistent distribution, which can be efficiently queried. Additionally, it provides a lower bound on the probability of observations, thus making it attractive for learning tasks. We provide the theoretical foundations for the approximation, an efficient implementation that exploits the wide range of highly optimized ordinary differential equations (ODE) solvers, experimentally explore characterizations of processes for which this approximation is suitable, and show applications to a large-scale realworld inference problem.", "histories": [["v1", "Wed, 9 May 2012 14:57:02 GMT  (1353kb)", "http://arxiv.org/abs/1205.2655v1", "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ido cohn", "tal el-hay", "nir friedman", "raz kupferman"], "accepted": false, "id": "1205.2655"}, "pdf": {"name": "1205.2655.pdf", "metadata": {"source": "CRF", "title": "Mean Field Variational Approximation for Continuous-Time Bayesian Networks", "authors": ["Ido Cohn"], "emails": ["cohn@cs.huji.ac.il", "tale@cs.huji.ac.il", "nir@cs.huji.ac.il", "raz@math.huji.ac.il"], "sections": [{"heading": "1 Introduction", "text": "In order to model such processes realistically, we need to think about systems that consist of several components (e.g. many servers in a server farm, several residues in a protein sequence) and evolve in continuous time. Bayesian Continuity Time Networks (CTBNs) provide a representational language for such processes that makes it possible to use economical interaction patterns to condense the dynamics of such processes [9]. Consequences from multi-component time models are a notoriously hard problem [1]. Similar to the situation in concrete time processes, inference is exponential in the number of components, even in a CTBN with sparse interactions. Thus, we must resort to safe inference methods."}, {"heading": "2 Continuous-Time Bayesian Networks", "text": "Consider a D component Markov process X (t + s) = (X (t) 1 = Q = Q (t) 2,. X (t) D) with state space S = S1 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 SD. A notational convention: vectors are denoted by bold face symbols, e.g. X, and matrices are denoted by chalk-style characters, e.g. Q. The states in S are denoted by index vectors, x = (x1,., xD). We use indexes 1 \u2264 i, j \u2264 D for enumerating components, and X (t) x x x to describe the random state of variables describing the state of the process and its i'th components at the time t. The dynamics of a time-homogeneous component qy Markov process are fully denoted by the Markov transition function, px, y (t) y (t) = y."}, {"heading": "3 Variational Principle for Continuous Time Markov Processes", "text": "We begin by defining a variational approximation principle with respect to a general continuity time Markov process (that is, without assuming any network structure).For convenience, we limit our treatment to a time interval [0, T] with endpoint proofs X (0) = e0 and X (T) = eT. We discuss more general types of proofs (below).We aim to define a lower limit on lnPQ (eT | e0), as well as to define the posterior probability PQ (\u00b7 e0, eT).Marginal density representation Variational approximations as a functional problem that approximates the log probability of evidence by introducing a set of variation parameters. Here, we define the optimization problem using a set of mean parameters [15] representing possible values of expected sufficient statistical values.As discussed above, the previous process distribution can be characterized by an independent time matrix."}, {"heading": "4 Factored Approximation", "text": "The principle of variation that we have discussed is based on a representation as complex as the original process - the number of functions \u03b3x, y (t) that we are looking at is equal to the size of the original rate matrix Q. To get a comprehensible sequence, we make additional simplistic assumptions about approximate distribution. In the face of a D component process, we look at this factor in products of independent processes. More precisely, we define Mie as the continuous Markov consistent density set over the Xi component, which is consistent with the evidence of Xi at times 0 and T. In the face of a collection of density sets, we look at this factor in products of independent processes."}, {"heading": "5 Perspective & Related Works", "text": "Our approach is motivated by the results of Opper and Sanguinetti [12], who have developed a variation principle for a related model. However, their model, which they call a Markov jump process, resembles an HMM statistic, in which the hidden chain is a continuous Markov process and there are (loud) observations at discrete points along the process. They describe a varying principle and discuss the form of the functional one when the approach is a product of independent processes. There are two main differences between the attitude of Opper and Sanguinetti and ours. First, we show how to exploit the structure of the target CTBN to reduce the complexity of the approximation. These simplifications imply that the updating of the i'th process depends only on its Markov ceiling in the CTBN, which allows us to develop efficient approximations for large models. Second, and more importantly, the structure of the evidence in our environment is a very different problem from what we assume from determining that we use."}, {"heading": "6 Experimental Evaluation", "text": "In order to gain a better understanding of the quality of our method, we performed numerical tests on models that challenge the approximation. Furthermore, we use Ising chains in which we investigate regimes defined by the degree of coupling between the components (parameter \u03b2) and the rate of transitions (parameter \u03c4). However, we evaluate the error in two ways: firstly by the difference between the actual log probability and our estimate. Secondly, by the average relative error in estimating different expected sufficient statistics that are performed depending on the actual probability and our estimate. Secondly, by applying our method to an 8-component issuing chain, for which we can still perform exact inference, we evaluated the relative error for various decisions of \u03b2 and aggregates. The evidence in this experiment is e0 =, +, +, +, +, +, +."}, {"heading": "7 Inference on Trees", "text": "The experimental results mentioned above suggest that our approximation is accurate when we think about weakly coupled components, or about time intervals that involve only a few transitions (low transition rates). Unfortunately, in many areas, we have a family tree that represents the branching process leading to current day sequences (see Fig. 5a). It is common to model the evolution of biological sequences to consider this process as a continuous process over a tree [6]. More specifically, evolution along each branch is a continuous process that is modeled by a replication after which each replication is independently along its sub-branches. Frequent applications are forced to assume that each figure in the sequence is independent."}, {"heading": "8 Discussion", "text": "In this paper, we formulate a general principle of variation for Markov processes in continuous time (by reformulating and extending the procedure proposed by Opper and Sanguinetti [12]) and use it to derive an efficient procedure for conclusions in CTBNs. In this medium field approach, we use a product of independent inhomogeneous processes to approximate the multi-components backwards. Our method enjoys the same advantages that occur in discrete temporal mean field procedures [8]: it provides a lower limit on the probability of proofs and its runtime scales linearly with the number of components. Asynchronous updates guarantee that it converges, and the approximation represents a consistent common distribution. It also suffers from expected shortcomings: there are several local maxims, and certain complex interactions within the posterior model cannot be captured. By using a time-homogeneous model, the homogenesis of the model is shifted forward."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for their helpful comments on earlier versions of the manuscript. This research was supported in part by a grant from the Israel Science Foundation. Tal El-Hay is supported by the Eshkol Scholarship of the Israeli Ministry of Science."}], "references": [{"title": "Tractable inference for complex stochastic processes", "author": ["X. Boyen", "D. Koller"], "venue": "In UAI,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Markov chains with stationary transition probabilities", "author": ["K.L. Chung"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1960}, {"title": "Continuous time markov networks", "author": ["T. El-Hay", "N. Friedman", "D. Koller", "R. Kupferman"], "venue": "In UAI,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Gibbs sampling in factorized continuous-time markov processes", "author": ["T. El-Hay", "N. Friedman", "R. Kupferman"], "venue": "In UAI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Sampling for approximate inference in continuous time Bayesian networks", "author": ["Y. Fan", "C.R. Shelton"], "venue": "In AI and Math,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Handbook of stochastic methods", "author": ["C.W. Gardiner"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "An introduction to variational approximations methods for graphical models", "author": ["M.I. Jordan", "Z. Ghahramani", "T. Jaakkola", "L.K. Saul"], "venue": "In Learning in Graphical Models", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Continuous time Bayesian networks", "author": ["U. Nodelman", "C.R. Shelton", "D. Koller"], "venue": "In UAI,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2002}, {"title": "Expectation maximization and complex duration distributions for continuous time Bayesian networks", "author": ["U. Nodelman", "C.R. Shelton", "D. Koller"], "venue": "In UAI,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Expectation propagation for continuous time Bayesian networks", "author": ["U. Nodelman", "C.R. Shelton", "D. Koller"], "venue": "In UAI,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Variational inference for Markov jump processes", "author": ["M. Opper", "G. Sanguinetti"], "venue": "In NIPS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Variational inference for Diffusion Processes", "author": ["C. Archambeau", "M. Opper", "Y. Shen", "D. Cornford", "J. Shawe-Taylor"], "venue": "In NIPS,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Reasoning at the right time granularity", "author": ["S. Saria", "U. Nodelman", "D. Koller"], "venue": "In UAI,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Graphical models, exponential families, and variational inference", "author": ["M.J. Wainwright", "M. Jordan"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Dependence among sites in RNA evolution", "author": ["J. Yu", "J. L Thorne"], "venue": "Mol. Biol. Evol.,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}], "referenceMentions": [{"referenceID": 7, "context": "Continuous-time Bayesian networks (CTBNs) provide a representation language for such processes, which allows to naturally exploit sparse patterns of interactions to compactly represent the dynamics of such processes [9].", "startOffset": 216, "endOffset": 219}, {"referenceID": 0, "context": "Inference in multi-component temporal models is a notoriously hard problem [1].", "startOffset": 75, "endOffset": 78}, {"referenceID": 7, "context": "Similar to the situation in discrete time processes, inference is exponential in the number of components, even in a CTBN with sparse interactions [9].", "startOffset": 147, "endOffset": 150}, {"referenceID": 4, "context": "These include sampling-based approaches, where Fan and Shelton [5] introduced a likelihood-weighted sampling scheme, and more recently we [4] introduced a Gibbs-sampling procedure.", "startOffset": 63, "endOffset": 66}, {"referenceID": 3, "context": "These include sampling-based approaches, where Fan and Shelton [5] introduced a likelihood-weighted sampling scheme, and more recently we [4] introduced a Gibbs-sampling procedure.", "startOffset": 138, "endOffset": 141}, {"referenceID": 9, "context": "[11] introduced an Expectation Propagation approach, which can be roughly described as a local message passing scheme, where each message describes the dynamics of a single component over an interval.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "This message passing procedure can automatically refine the number of intervals according to the complexity of the underlying system [14].", "startOffset": 133, "endOffset": 137}, {"referenceID": 6, "context": "We use the strategy of structured variational approximations in graphical models [8], and specifically by the variational approach of Opper and Sanguinetti [12] for approximate inference in Markov Jump Processes, a related class of models (see below).", "startOffset": 81, "endOffset": 84}, {"referenceID": 10, "context": "We use the strategy of structured variational approximations in graphical models [8], and specifically by the variational approach of Opper and Sanguinetti [12] for approximate inference in Markov Jump Processes, a related class of models (see below).", "startOffset": 156, "endOffset": 160}, {"referenceID": 1, "context": "Using the rate matrix Q, we can express the Markov transition function as px,y(t) = [exp(tQ)]x,y where exp(tQ) is a matrix exponential [2, 7].", "startOffset": 135, "endOffset": 141}, {"referenceID": 5, "context": "Using the rate matrix Q, we can express the Markov transition function as px,y(t) = [exp(tQ)]x,y where exp(tQ) is a matrix exponential [2, 7].", "startOffset": 135, "endOffset": 141}, {"referenceID": 7, "context": ", D} \\ {i}, which are its parents in the network [9].", "startOffset": 49, "endOffset": 52}, {"referenceID": 13, "context": "Here we define the optimization problem over a set of mean parameters [15], representing possible values of expected sufficient statistics.", "startOffset": 70, "endOffset": 74}, {"referenceID": 6, "context": "We can use the variational principle [8] on the marginal distributions PQ(XK |e) and P\u03b7(XK).", "startOffset": 37, "endOffset": 40}, {"referenceID": 10, "context": "Variational approximations for different types of continuous-time processes have been recently proposed [12, 13].", "startOffset": 104, "endOffset": 112}, {"referenceID": 11, "context": "Variational approximations for different types of continuous-time processes have been recently proposed [12, 13].", "startOffset": 104, "endOffset": 112}, {"referenceID": 10, "context": "Our approach is motivated by results of Opper and Sanguinetti [12] who developed a variational principle for a related model.", "startOffset": 62, "endOffset": 66}, {"referenceID": 13, "context": "Taking the general perspective of Wainwright and Jordan [15], the representation of the distribution uses the natural sufficient statistics.", "startOffset": 56, "endOffset": 60}, {"referenceID": 3, "context": "The scalability of the run time stands in contrast to the Gibbs sampling procedure [4], which scales roughly with the number in transitions in the sampled trajectories.", "startOffset": 83, "endOffset": 86}, {"referenceID": 2, "context": "We can convert this factor graph into a CTBN using procedures that consider the energy function as a fitness criteria in evolution [3, 16].", "startOffset": 131, "endOffset": 138}, {"referenceID": 14, "context": "We can convert this factor graph into a CTBN using procedures that consider the energy function as a fitness criteria in evolution [3, 16].", "startOffset": 131, "endOffset": 138}, {"referenceID": 14, "context": "Unfortunately, inference in such models suffers from computational blowup, and so the few studies that deal with it explicitly resort to sampling procedures [16].", "startOffset": 157, "endOffset": 161}, {"referenceID": 14, "context": "As a more demanding test, we applied our inference procedure to the model introduced by Yu and Thorne [16] for a stem of 18 interacting RNA nucleotides in 8 species in the phylogeny of Fig.", "startOffset": 102, "endOffset": 106}, {"referenceID": 10, "context": "In this paper we formulate a general variational principle for continuous-time Markov processes (by reformulating and extending the one proposed by Opper and Sanguinetti [12]), and use it to derive an efficient procedure for inference in CTBNs.", "startOffset": 170, "endOffset": 174}, {"referenceID": 6, "context": "Our procedure enjoys the same benefits encountered in discrete time mean field procedure [8]: it provides a lower-bound on the likelihood of the evidence and its run time scales linearly with the number of components.", "startOffset": 89, "endOffset": 92}, {"referenceID": 8, "context": "It can be easily combined with the EM procedure for CTBNs [10], to obtain a Variational-EM procedure for CTBNs, which monotonically increases the likelihood by alternating between steps that improve the approximation \u03b7 (the updates discussed here) and steps that improve the model parameters \u03b8.", "startOffset": 58, "endOffset": 62}], "year": 2009, "abstractText": "Continuous-time Bayesian networks is a natural structured representation language for multicomponent stochastic processes that evolve continuously over time. Despite the compact representation, inference in such models is intractable even in relatively simple structured networks. Here we introduce a mean field variational approximation in which we use a product of inhomogeneous Markov processes to approximate a distribution over trajectories. This variational approach leads to a globally consistent distribution, which can be efficiently queried. Additionally, it provides a lower bound on the probability of observations, thus making it attractive for learning tasks. We provide the theoretical foundations for the approximation, an efficient implementation that exploits the wide range of highly optimized ordinary differential equations (ODE) solvers, experimentally explore characterizations of processes for which this approximation is suitable, and show applications to a large-scale realworld inference problem.", "creator": "TeX"}}}