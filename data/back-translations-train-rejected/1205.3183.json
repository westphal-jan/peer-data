{"id": "1205.3183", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-May-2012", "title": "A Model-Driven Probabilistic Parser Generator", "abstract": "Existing probabilistic scanners and parsers impose hard constraints on the way lexical and syntactic ambiguities can be resolved. Furthermore, traditional grammar-based parsing tools are limited in the mechanisms they allow for taking context into account. In this paper, we propose a model-driven tool that allows for statistical language models with arbitrary probability estimators. Our work on model-driven probabilistic parsing is built on top of ModelCC, a model-based parser generator, and enables the probabilistic interpretation and resolution of anaphoric, cataphoric, and recursive references in the disambiguation of abstract syntax graphs. In order to prove the expression power of ModelCC, we describe the design of a general-purpose natural language parser.", "histories": [["v1", "Mon, 14 May 2012 20:12:06 GMT  (121kb)", "http://arxiv.org/abs/1205.3183v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["luis quesada", "fernando berzal", "francisco j cortijo"], "accepted": false, "id": "1205.3183"}, "pdf": {"name": "1205.3183.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["lquesada@decsai.ugr.es,", "fberzal@decsai.ugr.es,", "cb@decsai.ugr.es"], "sections": [{"heading": null, "text": "ar Xiv: 120 5.31 83v1 [cs.CL] 1 4M ay2 012"}, {"heading": "A Model-Driven Probabilistic Parser Generator", "text": "In fact, most of them are able to play by the rules that they have set themselves, and they are not able to play by the rules that they have set."}, {"heading": "II. BACKGROUND", "text": "In this section we provide a state-of-the-art analysis of probabilistic parsing and model-based language specification."}, {"heading": "A. Probabilistic Parsing", "text": "Probabilistic scanners based on Markov-like models [9] consider the existence of implicit relationships between words, symbols, or characters found near sequences, and irreversibly guess the type of lexeme based on the preceding ones. In using such techniques, a single false assumption irreversibly faults the entire analysis process, since no correct parse tree that uses a false token can be found. Probabilistic scanners based on lexicographs [7] assign probabilities to a lexeme that belongs to different word classes. Scanning a lexicon that belongs to a particular word class but never belongs to that class is the probability in the educational lexicon."}, {"heading": "B. Model-Based Language Specification", "text": "In this sense, grammar is a model of the language that defines it. The idea behind the model-based language specification is that starting from a single abstract syntax model (ASM) that represents the core concepts in a language, language developers can develop one or more concrete syntax models (CSMs) that can meet the specific needs of the desired textual or graphical representation for language sentences. ASM-CSM mapping, for example, can be performed by providing the abstract syntax model with the constraints needed to transform the elements in the abstract syntax into their concrete representation. A diagram summarizing the traditional language design process is shown in Figure 1, while the corresponding diagram for the model-based approach is shown in Figure 2. It should be noted that ASMs are not tree-based structures when language elements refer to other language elements, hence the use of the \"stabilizing syntax design process\" while the corresponding diagram is shown in Figure 2 for the model-based approach."}, {"heading": "III. PROBABILISTIC PARSING IN MODELCC", "text": "ModelCC effectively combines model-based language specification with probabilistic parsing by allowing the specification of arbitrary probabilistic language models. Section III.A introduces ModelCC support for probabilistic language models and presents the @ Probability annotation of ModelCC. Section III.B discusses the use of context information in the probabilistic parsers of ModelCC. Section III.C explains how symbol probabilities are calculated."}, {"heading": "A. Probabilistic Language Models", "text": "The @ Probability annotation of ModelCC enables the specification of probability values for language elements and language elements. Probability values can be specified for syntactic elements of languages and for lexical components. In this case, it should be noted that the lexical analyzer behaves like a part-of-speech tagger when processing natural language. Such probability values can be specified using three alternatives: a probability value as a real number between 0 and 1, a frequency as an integer number, or a custom probability evaluator that calculates the probability value from the analysis of the language element and its context. Since ModelCC supports lexical and syntactical ambiguities, and the combination of language models, one of the most important innovations of ModelCC with respect to existing techniques is that it enables the modular specification of probability languages and its context, i.e., it is able to generate parser-based language modules based on computational specifications, even if some language-based modeling conflicts are supported by CC."}, {"heading": "B. Context Information", "text": "ModelCC provides context information that allows user-defined probability evaluators and constraints to be taken into account when processing a language element. Context information includes the current syntax graph and the parsegraph symbol that corresponds to the language element to be evaluated. If the language element instance is a reference, the context instance also includes the referenced language element instance, the corresponding parsegraph symbol and the context graph that is the smallest graph that contains both the reference and the referenced object. It should be noted that from this information it is possible to derive traditional metrics such as the distance between the reference and the referenced object in the input or syntax graph, and whether the reference is anaphorical, cataphorical or recursive. However, unlike existing probabilistic parsing techniques, ModelCC also allows the specification of complex syntactical constraints, secondary constraints, and probability constraints resolved between the language elements."}, {"heading": "C. Probability Evaluation", "text": "The probability of a certain parsegraph G for a sentence w1: m of length m is defined as the product of the probabilities representing the n instances of the language elements egg in the parsegraph G: P (G | w1: m) = n-i = 1P (Ei | wsi: ei) (1) For a language element E representing a part of the language elements and a word w, the lexical analyzer functions as a POS tagger and provides P (E | w). For a language element E with M1.. Mn members in its definition, some of which are optional, the probability P (E | M1: n) is calculated as follows. If we let OPT (E) calculate the set of optional elements for E. Assuming that their appearance is statistically independent, we can estimate the probability of the E set using its observed elements O: P (E | O1: k) = P (E) = P (E) of the optional elements for a preliminary procedure."}, {"heading": "IV. MODEL-BASED SPECIFICATION OF NATURAL LANGUAGES", "text": "In this section we present a model-based specification for a probabilistic natural language parser. Section IV.A outlines the general natural language characteristics. Section IV.B provides the ModelCC ASM specification of the general natural language. Section IV.C explains how to instantiate the general natural language. Section IV.D presents an example parser for the English language."}, {"heading": "A. Natural Language Description", "text": "In fact, most of them will be able to move in the direction in which they want to move."}, {"heading": "B. ModelCC Specification of the ASM for Natural Languages", "text": "In order to implement our general language parser using ModelCC, we need to provide a specification of the language ASM. This specification is provided as a set of UML diagrams, as in Figures 3, 4, 5, 6 and 7. Adjectives supplements and adverbial supplements can be given as nominal supplements in Figure 6. As can be seen from the illustrations, the model-based specification of the general language of nature is easily derived from the requirements of the language description. As the given model is an abstract syntax model, it does not correspond to any particular model. ASM is more similar to the mental language postulated by thought language [5]. In the next subsection, we will explain how various fully functional nature language parsers can be instantiated from this model by defining additional language-specific limitations."}, {"heading": "C. Specification of the Natural Language CSMs", "text": "In order to implement a parser for a certain natural language, the ASM CSM mapping must be specified. A pattern matcher is assigned to each lexical component of the language model. To this end, the @ Pattern annotation of ModelCC allows the specification of custom pattern matchers, which may consist of regular expressions, dictionary searches or suitable heuristics. Such pattern matchers can easily be derived from the analysis of lexical icons. In addition to syntactic ambiguities, ModelCC also supports lexical ambiguities, so that the specified pattern matchers can produce different and even overlapping token sets from the analysis of the input string. After specifying the pattern matchers for the lexical components of the language, language-specific constraints are assigned to syntactical components of the language model. For this purpose, the annotation of @ Constraint annotations can be automatically explained by an analysis of a language connotation, which cannot be included in the evaluation of a language conability section."}, {"heading": "D. An Example: Parsing an English Sentence", "text": "We have implemented an English parser by specifying an ASM-CSM mapping from the general language ASM. We have defined pattern matchers that query wiktionary.org to perform the lexical analysis. We have approximated probability values from the analysis of Google n-gram records to various lexems and constructions. As an example, we have analyzed the sentence \"I saw a picture of New York.\" The lexical analyzer for this set represents 128 valid token sequences and is in Figure 8. A set of valid parse diagrams can be obtained from this lexical analysis diagram, and Figure 9 shows the correct parse tree."}, {"heading": "V. CONCLUSIONS AND FUTURE WORK", "text": "Natural languages suffer from ambiguities. A common approach to disambiguity is to perform probabilistic scanning and probabilistic parsing. Such techniques have several disadvantages: incorrect sequences of tokens can be generated, and only small amounts of context information are used. We have described the support of probabilistic language models by ModelCC. ModelCC is a model-based parser generator that supports lexical ambiguities, syntactical ambiguities, and reference resolutions. We have also demonstrated the application of ModelCC to probabilistic parsing by providing a model-based specification of a general natural language that provides an instantiation of that language in English. We plan to conduct studies on the automatic introduction of probabilistic language models, syntactical constraints, and semantic constraints of linguistic corpora. We also plan to conduct studies on the use of alternative models to present uncertainties on language parses."}], "references": [{"title": "Compilers: Principles, Techniques, and Tools", "author": ["Alfred V. Aho", "Monica S. Lam", "Ravi Sethi", "Jeffrey D. Ullman"], "venue": "Addison Wesley, 2nd edition,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Statistical parsing with a context-free grammar and word statistics", "author": ["Eugene Charniak"], "venue": "In Proc. AAAI\u201997,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Remarks on nominalization", "author": ["Noam Chomsky"], "venue": "Readings in English Transformational Grammar,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1970}, {"title": "Head-driven statistical models for natural language parsing", "author": ["Michael Collins"], "venue": "Computational Linguistics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "The Language of Thought", "author": ["Jerry A. Fodor"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1975}, {"title": "Using metadata", "author": ["Martin Fowler"], "venue": "IEEE Software,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition", "author": ["Daniel Jurafsky", "James H. Martin"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Towards the generation of a text-based IDE from a language metamodel", "author": ["Anneke Kleppe"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Dynamic Probabilistic Systems (Volume I: Markov Models)", "author": ["Andrey A. Markov"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1971}, {"title": "Conflict detection and resolution in a lexical analyzer generator", "author": ["Jerzy R. Nawrocki"], "venue": "Information Processing Letters,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1991}, {"title": "Dynamic programming parsing for context-free grammars in continuous speech recognition", "author": ["Hermann Ney"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1991}, {"title": "A language specification tool for model-based parsing", "author": ["Luis Quesada", "Fernando Berzal", "Juan-Carlos Cubero"], "venue": "In Proc. IDEAL 2011,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "A model-driven parser generator, from abstract syntax trees to abstract syntax graphs", "author": ["Luis Quesada", "Fernando Berzal", "Juan-Carlos Cubero"], "venue": "ArXiv e-prints,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}], "referenceMentions": [{"referenceID": 9, "context": "Lexical ambiguities [10] occur when a lexeme has several meanings [7].", "startOffset": 20, "endOffset": 24}, {"referenceID": 6, "context": "Lexical ambiguities [10] occur when a lexeme has several meanings [7].", "startOffset": 66, "endOffset": 69}, {"referenceID": 0, "context": "Syntactic ambiguities occur when a token sequence can be generated using more than one parse tree [1].", "startOffset": 98, "endOffset": 101}, {"referenceID": 7, "context": "Model-based language specification techniques [8] decouple language design from language processing.", "startOffset": 46, "endOffset": 49}, {"referenceID": 11, "context": "ModelCC [12, 13] is a model-based parser generator that includes support for dealing with references between language elements and, thus, instead of returning mere abstract syntax trees, ModelCC is able to obtain abstract syntax graphs and consider lexical and syntactic ambiguities.", "startOffset": 8, "endOffset": 16}, {"referenceID": 12, "context": "ModelCC [12, 13] is a model-based parser generator that includes support for dealing with references between language elements and, thus, instead of returning mere abstract syntax trees, ModelCC is able to obtain abstract syntax graphs and consider lexical and syntactic ambiguities.", "startOffset": 8, "endOffset": 16}, {"referenceID": 8, "context": "Probabilistic scanners based on Markov-like models [9] consider the existence of implicit relationships between words, symbols or characters found close in sequences, and irrevocably guess the type of a lexeme based on the preceding ones.", "startOffset": 51, "endOffset": 54}, {"referenceID": 6, "context": "Probabilistic scanners based on lexicons [7] assign probabilities to a lexeme belonging to different word classes from the statistical analysis of lexicons.", "startOffset": 41, "endOffset": 44}, {"referenceID": 10, "context": "Probabilistic parsers [11] compute the probability of different parse trees by considering token probabilities and grammar production probabilities, which are empirically obtained from the analysis of linguistic corpora.", "startOffset": 22, "endOffset": 26}, {"referenceID": 1, "context": "Probabilistic lexicalized parsers [2, 4] associate lexical heads and head tags to the grammar symbols.", "startOffset": 34, "endOffset": 40}, {"referenceID": 3, "context": "Probabilistic lexicalized parsers [2, 4] associate lexical heads and head tags to the grammar symbols.", "startOffset": 34, "endOffset": 40}, {"referenceID": 11, "context": "ModelCC [12, 13] is a parser generator that supports a model-based approach to the design of language processing systems.", "startOffset": 8, "endOffset": 16}, {"referenceID": 12, "context": "ModelCC [12, 13] is a parser generator that supports a model-based approach to the design of language processing systems.", "startOffset": 8, "endOffset": 16}, {"referenceID": 5, "context": "Once the ASM is created, constraints can be imposed over language elements and their relationships as metadata annotations [6] in order to produce the desired ASM-CSM mappings.", "startOffset": 123, "endOffset": 126}, {"referenceID": 2, "context": "Our general language model supports Chomsky\u2019s Xbar theory [3], which claims that certain human languages share structural similarities.", "startOffset": 58, "endOffset": 61}, {"referenceID": 4, "context": "The ASM is more like the Mentalese language postulated by the Language Of Thought Hypothesis [5].", "startOffset": 93, "endOffset": 96}], "year": 2013, "abstractText": "Existing probabilistic scanners and parsers impose hard constraints on the way lexical and syntactic ambiguities can be resolved. Furthermore, traditional grammar-based parsing tools are limited in the mechanisms they allow for taking context into account. In this paper, we propose a model-driven tool that allows for statistical language models with arbitrary probability estimators. Our work on model-driven probabilistic parsing is built on top of ModelCC, a modelbased parser generator, and enables the probabilistic interpretation and resolution of anaphoric, cataphoric, and recursive references in the disambiguation of abstract syntax graphs. In order to prove the expression power of ModelCC, we describe the design of a general-purpose natural language parser.", "creator": "LaTeX with hyperref package"}}}