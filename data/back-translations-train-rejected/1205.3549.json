{"id": "1205.3549", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2012", "title": "Normalized Maximum Likelihood Coding for Exponential Family with Its Applications to Optimal Clustering", "abstract": "We are concerned with the issue of how to calculate the normalized maximum likelihood~(NML) code-length. There is a problem that the normalization term of the NML code-length may diverge when it is continuous and unbounded and a straightforward computation of it is highly expensive when the data domain is finite . In previous works it has been investigated how to calculate the NML code-length for specific types of distributions. We first propose a general method for computing the NML code-length for the exponential family. Then we specifically focus on Gaussian mixture model~(GMM), and propose a new efficient method for computing the NML to them. We develop it by generalizing Rissanen's re-normalizing technique. Then we apply this method to the clustering issue, in which a clustering structure is modeled using a GMM, and the main task is to estimate the optimal number of clusters on the basis of the NML code-length. We demonstrate using artificial data sets the superiority of the NML-based clustering over other criteria such as AIC, BIC in terms of the data size required for high accuracy rate to be achieved.", "histories": [["v1", "Wed, 16 May 2012 03:54:30 GMT  (48kb)", "https://arxiv.org/abs/1205.3549v1", null], ["v2", "Thu, 17 May 2012 01:03:19 GMT  (48kb)", "http://arxiv.org/abs/1205.3549v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["so hirai", "kenji yamanishi"], "accepted": false, "id": "1205.3549"}, "pdf": {"name": "1205.3549.pdf", "metadata": {"source": "CRF", "title": "Normalized Maximum Likelihood Coding for Exponential Family with Its Applications to Optimal Clustering", "authors": ["So Hirai", "Kenji Yamanishi"], "emails": ["Hirai@mist.i.u-tokyo.ac.jp", "yamanishi@mist.i.u-tokyo.ac.jp"], "sections": [{"heading": null, "text": "ar Xiv: 120 5.35 49v2 [cs.L \u0439 Graduate School of Information Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, JAPAN Email: So Hirai @ mist.i.u-tokyo.ac.jp He is currently owned by NTT DATA Corporation. \u2020 Graduate School of Information Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, JAPAN Email: yamanishi @ mist.i.u-tokyo.ac.jp"}, {"heading": "1 Introduction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1.1 Motivation and Previous Works", "text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _"}, {"heading": "1.2 Significance of This Paper", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1) An extension of the computation of the NML code-length to the exponential family.", "text": "We extend Hirai's and Yamanishi's method [5] for calculating the NML code length for Gaussian distributions and GMMs to an exponential family, including gamma distributions, logistical distributions, etc. Then we give a method for calculating the NML code length in a general form. 2) Improving the NML code length for Gaussian distributions and GMMs using the renormalization technique. We apply crack's renormalization technique [9] to Gaussian distributions and GMMs to derive new formulas for calculating the NML code length for them. Conventional formulas in [5] depend on the parameters that constrain the data domain. The new formulas are achieved by renormalizing the probability number relative to the parameters, and are improved by being less dependent on hyperparameters than those in [5]."}, {"heading": "2 NML Code-Length for Exponential Family", "text": "In this section we present a method for calculating the NML code length for the exponential family."}, {"heading": "2.1 Exponential Family", "text": "In the following we define the exponential family.Definition 1 The probability density function belonging to the exponential family assumes the following form: f (X; \u03b8) = h (X) exp {\u03b7 (\u03b8) TT (X) \u2212 A (\u03b7 (\u03b8))}, (2) where \u03b8-RD is a real parameter vector (D is the number of parameters) and A (\u03b7) is a normalization concept.The common distribution of the data xn is given as follows: f (xn; \u03b8) = n \u0432 i = 1h (xi) exp {\u03b7 (\u03b8) TT (xi) \u2212 A (\u03b7)}. Then the maximum probability estimate (MLE) results:"}, {"heading": "2.2 NML Code-Length for Exponential Family", "text": "In the following, we will consider the calculation of the normalization concept: C (M) as in (1) for the exponential family. Suppose that the MLE can be obtained analytically from the data for any data. It is known that for the exponential family, the MLE can be calculated as a function of sufficient statistics. In the following, we will show how the MLE can be calculated by circumventing the problem that it can deviate. The function to be integrated is expanded as follows: f (xn) = h (xn), where the integral function (x) is a certain function of x. In the following, we will show how to calculate C (M) by circumventing the problem that it can deviate. The function to be integrated is expanded as follows: f (xn) = h (xn)."}, {"heading": "2.3 Examples", "text": "In the following we give examples for the calculation of the NML code length for the exponential family. For the sake of simplicity we concentrate on the normalization term C (M) as in (1)."}, {"heading": "2.3.1 Gamma Distributions", "text": "Gamma distributions belong to the exponential family. The density function of xn for a gamma distribution is defined as follows: f (xn; k, 2001) = n (k) \u00b7 \u03b8k \u00b7 xk \u2212 1i \u00b7 exp (xn) = 1 xi / (kn). The common distribution of xn results analytically. We consider the case in which k is known and fixed."}, {"heading": "2.3.2 Logistic Distributions", "text": "The density function of xn for a logistic distribution with one parameter \u03b8 is defined as asf (xn) = n + e \u2212 xi (1 + e \u2212 xi). Thus, the joint density of xn is written as asf (xn; \u03b8) = \u03b8n \u00b7 exp {\u2212 n \u00b2 i = 1xi \u2212 n (\u03b8 + 1). Thus, the joint density of xn is written as asf (xn); \u03b8), where n / ta (xn) corresponds to the gamma distribution with a shape parameter n and a scale parameter n (xn). Thus g (270) \u00b7 g (270) \u00b7 n (270), where n / ta (xn) corresponds to the gamma distribution n (n) defines the shape parameters n and a scale parameter n (xn)."}, {"heading": "3 Re-normalized Maximum Likelihood", "text": "We show how to calculate the RNML code length for a GMM. Let xn = (x1, \u00b7 \u00b7 min), xi = (xi1, \u00b7 \u00b7, xim), (i = 1, \u00b7 \u00b7 \u00b7, n) be a given sequence in which xi is distributed according to a Gaussian distribution (1, \u00b7 \u00b7 min), xi = (xi1, \u00b7 \u00b7, \u00b7 n), (2) in which the variance covariance matrix matrix Rm is distributed for a certain positive integer m with the density: f (x; \u00b5, \u03a3) = 1 (2 | 1 2exp {\u2212 12 (x \u2212 \u00b5), (x \u2212 \u00b5)}.Notice here that the normalization term in (1) is different. Hirai and Yamanishi [5] derive a formula of the NML distribution by restricting the range of the data so that the maximum probability is within a limited range."}, {"heading": "4 Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Comparison with AIC and BIC", "text": "We created a number of data sequences of size n according to the actual number of data collected (K = 1, \u00b7 \u00b7, K). In our experiment, we repeated the creation of clusters with the EM algorithm 100 times by changing the initial values of the algorithms. We compared the four criteria: RNML, NML, Akaike's Information Criterion (AIC) [1] and Bayesian Information Criterion (BIC) [11] for the choice of the number of clusters."}, {"heading": "4.2 Dependency of NML and RNML on Parameters", "text": "Fig.3 shows diagrams with the smallest data size required for accuracy rate and usefulness to reach 80% or 0.8 relative to parameter values. We define parameters \u03b8 as \u03b8 = R2 / R1 = \u03bb2 / \u03bb1 in RNML and \u03b8 = R = \u03bb (j) min \u2212 m in NML. We see that the RNML does not depend more on parameter values than the NML. It implies that the dependence of the RNML on parameter values is much less than that of the NML."}, {"heading": "5 Conclusion", "text": "We have proposed a general method of calculating the NML code length for the exponential family. We have developed it by generalizing the existing method of limiting the data domain so that the NML code length does not differ from each other. We have focused specifically on Gaussian distributions and GMMs to propose a new efficient method of calculating the RNML for them. We have developed it by extending Rissanen's renormalization technology to multiple Gaussian distributions. We have applied this method to the cluster problem by selecting the optimal number of clusters based on the RNML code length. We have shown empirically, using artificial data, that our method approaches the estimation of cluster number much faster than AIC, BIC and NML."}], "references": [{"title": "A new look at the statistical model identification", "author": ["H. Akaike"], "venue": "IEEE Trans. on Automatic Control,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1974}, {"title": "Maximum likelihood from incomplete data via the em", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": "J.Royal Staitst. Soc.B, 39:1\u201338", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1977}, {"title": "Variable selection in linear regression: Several approaches based on normalized maximum likelihood", "author": ["C.D. Giurc\u0103neanu", "S.A. Razavi", "A. Liski"], "venue": "Signal Processing,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "The Minimum Description Length Principle", "author": ["P.D. Gr\u00fcnwald"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Efficient computation of normalized maximum likelihood coding for gaussian mixtures with its applications to optimal clustering", "author": ["S. Hirai", "K. Yamanishi"], "venue": "The IEEE ISIT, pages 1031\u20131035", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "A linear time algorithm for computing the multinomial stochastic complexity", "author": ["P. Kontkanen", "P. Myllym\u00e4ki"], "venue": "Information Processing Letters, 103:227\u2013233", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "An empirical comparison of nml", "author": ["P. Kontkanen", "P. Myllym\u00e4ki"], "venue": "Proceedings of the 2008 International, pages 125\u2013131", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Fisher information and stochastic complexity", "author": ["J. Rissanen"], "venue": "IEEE Trans. on Information Theory,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1996}, {"title": "MDL denoising", "author": ["J. Rissanen"], "venue": "IEEE Trans. on Information Theory,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Information and Complexity in Statistical Modeling", "author": ["J. Rissanen"], "venue": "Springer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "Annals of Statistics 6 (2), pages 461\u2013464", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1978}, {"title": "Universal sequential coding of single messages", "author": ["M. Shtarkov Yu"], "venue": "Problems of Information Transmission,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1987}], "referenceMentions": [{"referenceID": 7, "context": "The NML code-length for x relative to M is calculated as follows: \u2212 log fNML(x ;M) = \u2212 log f(x; \u03b8\u0302(x,M)) + log C(M), It is known from [8] that the NML code-length is optimal in the sense that it achieves the minimum of Shtarkov\u2019s minimax criterion [12].", "startOffset": 134, "endOffset": 137}, {"referenceID": 11, "context": "The NML code-length for x relative to M is calculated as follows: \u2212 log fNML(x ;M) = \u2212 log f(x; \u03b8\u0302(x,M)) + log C(M), It is known from [8] that the NML code-length is optimal in the sense that it achieves the minimum of Shtarkov\u2019s minimax criterion [12].", "startOffset": 248, "endOffset": 252}, {"referenceID": 7, "context": "The NML code-length is called the stochastic complexity [8] and has been employed as a criterion for statistical model selection on the basis of the minimum description length (MDL) principle [10, 4].", "startOffset": 56, "endOffset": 59}, {"referenceID": 9, "context": "The NML code-length is called the stochastic complexity [8] and has been employed as a criterion for statistical model selection on the basis of the minimum description length (MDL) principle [10, 4].", "startOffset": 192, "endOffset": 199}, {"referenceID": 3, "context": "The NML code-length is called the stochastic complexity [8] and has been employed as a criterion for statistical model selection on the basis of the minimum description length (MDL) principle [10, 4].", "startOffset": 192, "endOffset": 199}, {"referenceID": 7, "context": "Rissanen [8] derived a formula of an asymptotic approximation of the NML code-length: \u2212 log p(x; \u03b8\u0302(x)) + k 2 log n 2\u03c0 + log \u222b", "startOffset": 9, "endOffset": 12}, {"referenceID": 5, "context": "Kontkanen and Myllym\u00e4ki proposed efficient algorithms for the NML code-length for multinomial distributions and N\u00e4ive Bayes model [6, 7].", "startOffset": 130, "endOffset": 136}, {"referenceID": 6, "context": "Kontkanen and Myllym\u00e4ki proposed efficient algorithms for the NML code-length for multinomial distributions and N\u00e4ive Bayes model [6, 7].", "startOffset": 130, "endOffset": 136}, {"referenceID": 8, "context": "Rissanen proposed a method for circumventing this problem for linear regression models by making an elliptic constraint for the data domain so that the normalization term does not diverge [9].", "startOffset": 188, "endOffset": 191}, {"referenceID": 2, "context": "method using an rhomboid constraint [3].", "startOffset": 36, "endOffset": 39}, {"referenceID": 8, "context": "Note that all of these works [9, 3] considered 1dimensional Gaussian distributions.", "startOffset": 29, "endOffset": 35}, {"referenceID": 2, "context": "Note that all of these works [9, 3] considered 1dimensional Gaussian distributions.", "startOffset": 29, "endOffset": 35}, {"referenceID": 4, "context": "Hirai and Yamanishi [5] applied Rissanen\u2019s technique to the computation of the NML code-length for multi-variate Gaussian distributions.", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "Kontkanen and Myllym\u00e4ki [7] proposed an efficient algorithm for NML-based clustering with optimal choices of mixture size for the case where the data domain was discrete.", "startOffset": 24, "endOffset": 27}, {"referenceID": 4, "context": "Hirai and Yamanishi [5] proposed an algorithm for efficiently computing the NML code-length for Gaussian mixture models (GMM) for the case where the data domain was continuous.", "startOffset": 20, "endOffset": 23}, {"referenceID": 4, "context": "We extend Hirai and Yamanishi\u2019s method [5] for computing the NML code-length for Gaussian distributions and GMMs to exponential family including Gamma distributions, logistic distributions, etc.", "startOffset": 39, "endOffset": 42}, {"referenceID": 8, "context": "We apply Rissanen\u2019s renormalizing technique [9] into Gaussian distributions and GMMs to derive new formulas for computing the NML codelengths for them.", "startOffset": 44, "endOffset": 47}, {"referenceID": 4, "context": "Conventional formulas in [5] depend on the parameters by which the data domain is restricted.", "startOffset": 25, "endOffset": 28}, {"referenceID": 4, "context": "The new formulas are obtained by renormalizing the likelihood with respect to the parameters, and are improved in that they are less dependent on hyperparameters than those in [5].", "startOffset": 176, "endOffset": 179}, {"referenceID": 8, "context": "Note that the RNML are different from Rissanen\u2019s original one [9] in that they are derived for the case where data is multi-dimensional while Rissanen considered a specific case where it was 1-dimensional.", "startOffset": 62, "endOffset": 65}, {"referenceID": 4, "context": "Hirai and Yamanishi [5] derived a formula of the NML distribution by restricting the range of data so that the maximum likelihood lies in a bounded range specified by parameters.", "startOffset": 20, "endOffset": 23}, {"referenceID": 4, "context": "The normalization term C(R, \u03bbmin) is expanded as follows [5]: C(R, \u03bbmin) = 2R m 2 \u220fm j=1 \u03bb (j) min \u2212 m 2", "startOffset": 57, "endOffset": 60}, {"referenceID": 5, "context": "As for the computation of C1(K, n), Kontkanen and Myllym\u00e4ki proved the following theorem: Theorem 3 [6] C1(K, n) satisfies the recursive formula: C1(K + 2, n) = C1(K + 1, n) + n K C1(K, n).", "startOffset": 100, "endOffset": 103}, {"referenceID": 1, "context": "For each data sequence x n generated according to the true model M, we also generated their corresponding cluster indices z using the EM algorithm [2], where zi showed which cluster xi came from (i = 1, .", "startOffset": 147, "endOffset": 150}, {"referenceID": 0, "context": "We compared the four criteria: RNML, NML, Akaike\u2019s Information Criterion (AIC) [1] and Bayesian Information Criterion (BIC) [11] for the choice of the number of clusters.", "startOffset": 79, "endOffset": 82}, {"referenceID": 10, "context": "We compared the four criteria: RNML, NML, Akaike\u2019s Information Criterion (AIC) [1] and Bayesian Information Criterion (BIC) [11] for the choice of the number of clusters.", "startOffset": 124, "endOffset": 128}, {"referenceID": 4, "context": "We calculated RNML and NML according to the method proposed in the previous sections and [5].", "startOffset": 89, "endOffset": 92}], "year": 2012, "abstractText": "We are concerned with the issue of how to calculate the normalized maximum likelihood (NML) code-length. There is a problem that the normalization term of the NML code-length may diverge when it is continuous and unbounded and a straightforward computation of it is highly expensive when the data domain is finite . In previous works it has been investigated how to calculate the NML code-length for specific types of distributions. We first propose a general method for computing the NML code-length for the exponential family. Then we specifically focus on Gaussian mixture model (GMM), and propose a new efficient method for computing the NML to them. We develop it by generalizing Rissanen\u2019s re-normalizing technique. Then we apply this method to the clustering issue, in which a clustering structure is modeled using a GMM, and the main task is to estimate the optimal number of clusters on the basis of the NML code-length. We demonstrate using artificial data sets the superiority of the NML-based clustering over other criteria such as AIC, BIC in terms of the data size required for high accuracy rate to be achieved. Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, JAPAN Email: So Hirai@mist.i.u-tokyo.ac.jp He currently belongs to NTT DATA Corporation. Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, JAPAN Email: yamanishi@mist.i.u-tokyo.ac.jp", "creator": "LaTeX with hyperref package"}}}