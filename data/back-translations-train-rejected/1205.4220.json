{"id": "1205.4220", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-May-2012", "title": "Diffusion Adaptation over Networks", "abstract": "Adaptive networks are well-suited to perform decentralized information processing and optimization tasks and to model various types of self organized and complex behavior encountered in nature. Adaptive networks consist of a collection of agents with processing and learning abilities. The agents are linked together through a connection topology, and they cooperate with each other through local interactions to solve distributed inference problems in real-time. The continuous diffusion of information across the network enables agents to adapt their performance in relation to changing data and network conditions; it also results in improved adaptation and learning performance relative to non-cooperative networks. This article provides an overview of diffusion strategies for adaptation and learning over networks. The article is divided into several sections: 1. Motivation; 2. Mean-Square-Error Estimation; 3. Distributed Optimization via Diffusion Strategies; 4. Adaptive Diffusion Strategies; 5. Performance of Steepest-Descent Diffusion Strategies; 6. Performance of Adaptive Diffusion Strategies; 7. Comparing the Performance of Cooperative Strategies; 8. Selecting the Combination Weights; 9. Diffusion with Noisy Information Exchanges; 10. Extensions and Further Considerations; Appendix A: Properties of Kronecker Products; Appendix B: Graph Laplacian and Network Connectivity; Appendix C: Stochastic Matrices; Appendix D: Block Maximum Norm; Appendix E: Comparison with Consensus Strategies; References.", "histories": [["v1", "Fri, 18 May 2012 19:09:46 GMT  (586kb)", "https://arxiv.org/abs/1205.4220v1", "114 pages, 16 figures, 9 tables, to appear in E-Reference Signal Processing, R. Chellapa and S. Theodoridis, Eds., Elsevier, 2013"], ["v2", "Sun, 5 May 2013 22:42:36 GMT  (587kb)", "http://arxiv.org/abs/1205.4220v2", "114 pages, 16 figures, 9 tables, to appear in E-Reference Signal Processing, R. Chellapa and S. Theodoridis, Eds., Elsevier, 2013"]], "COMMENTS": "114 pages, 16 figures, 9 tables, to appear in E-Reference Signal Processing, R. Chellapa and S. Theodoridis, Eds., Elsevier, 2013", "reviews": [], "SUBJECTS": "cs.MA cs.LG", "authors": ["ali h sayed"], "accepted": false, "id": "1205.4220"}, "pdf": {"name": "1205.4220.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Ali H. Sayed"], "emails": ["sayed@ee.ucla.edu."], "sections": [{"heading": null, "text": "This article provides an overview of diffusion strategies for adaptation and learning via networks. The article is divided into several sections: 1. Strategies. 2. Strategies. 2. Strategies. 4. Measurement. 3. Distribution equilibrium.4. Distribution equilibrium.5. Distribution equilibrium.7. Distribution equilibrium.7. Distribution equilibrium.8. OVER NETWORKS. Ali H. SayedElectrical Engineering Department University of California at Los AngelesAdaptive networks are well suited to perform decentralized information processing and optimization tasks and to model various types of self-organized and complex behaviors in nature.Adaptive networks consist of a collection of agents with processing and learning capabilities. Agents are linked by a connecting topology and cooperate with each other through local interactions to solve distributed optimization, estimation and inference problems in real-time."}, {"heading": "1 Motivation", "text": "Consider a collection of N agents who are interested in optimizing the same parameter vector, where, the size M x 1. The vector is the minimizer of a global cost function, referred to as Jglob (w), which the agents seek to optimize, say, where = argmin w Jglob (w) (1). We are interested in situations where the individual agents have access to incomplete information about the global cost function. In this case, cooperation between the agents becomes beneficial. For example, by working with their neighbors and by cooperating with these neighbors with their neighbors, procedures can be developed that would allow all agents in the network to approach the global optimum where through local interactions. The goal of decentralized processing is to enable spatially distributed agents to achieve a global goal by relying exclusively on local information and processing in the network. By a continuous process of cooperation and information exchange with neighbors, agents in a network can be brought to approximate to the global performance level, despite their non-localized nature."}, {"heading": "1.1 Networks and Neighborhoods", "text": "In fact, it is such that most people will be able to move into another world, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to change the world, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they are able to move, in which they are able"}, {"heading": "1.2 Cooperation Among Agents", "text": "Now, the solution vector where of (1) may allow different interpretations depending on the application. For example, the inputs from where may represent the location coordinates of a food source that the agents are trying to locate, or the location of an accident with a dangerous chemical leak. The nodes may also be interested in locating a predator and tracking its movements over time. In these localization applications, the vector where usually two- or three-dimensional. In other applications, the inputs from where may represent the parameters of a model that the network wants to learn, such as identifying the model parameters of a biological process or the occupied frequency bands in a common communication medium. There are also situations where different agents in the network may be interested in evaluating different entries from where or even different parameter vectors where at all, say that the vectors for the node k, but with a relationship between the different vectors, so that cooperation between the node strategies may still be worthwhile."}, {"heading": "1.3 Notation", "text": "In our treatment, we have to distinguish between random variables and deterministic sizes. Therefore, we use bold letters to represent random variables and normal font to represent deterministic (not random) sizes. To this end, we use CAPITAL letters to refer to matrices and lower case letters to denote both vectors and scalars; Greek letters always refer to scalars. We write R to denote a covariance matrix and w to denote a vector of parameters. We also write \u03c32v to denote the variance of a random variable. To distinguish between a vector d (lower case) and a scalar d (also a lower case), we use parameters."}, {"heading": "2 Mean-Square-Error Estimation", "text": "Readers interested in developing distributed optimization strategies and their adaptive versions may, however, go directly to paragraph 3. The purpose of the current section is to motivate the benefits of distributed network processing and provide illustrative examples related to the estimation of the middle square. Advanced readers can skip this section at a first reading. We begin our development by associating each agent k with an individual cost (or supply) function, Jk (w). Although the algorithms presented in this article apply to more general situations, we nevertheless assume in our presentation that the cost functions Jk (w) are strictly convex, so that each of them has a unique minimization function. We also assume that for all costs Jk (w) the minimum is the same value where occurs. Obviously, the choice of Jk (w) is limitless and is largely dependent on the application."}, {"heading": "2.1 Application: Autoregressive Modeling", "text": "Our first example refers to the determination of the parameters of an auto-regressive (AR) model of noise parameters (Ev = 6), so let us consider a situation where agents are distributed over a geographic region and each agent observes k realizations (1). (4) The scalars {\u03b2m} represent the model parameters that the agents want to identify, and vk (i) represents an additive zero-mean noise model with power: \u03c32v, k = E | vk (5) It is common to assume that the noise process is time-white and spatially independent, so that the noise terms across different nodes are independent of each other, and that on the same node consecutive noise patterns are also independent of each other."}, {"heading": "2.2 Application: Tapped-Delay-Line Models", "text": "Our second example to motivate MSE cost functions, Jk (w) and linear models relate to the determination of the parameters of a moving average (MA) model from noise data. MA models are also known as finite impulse sponse (FIR) or tapped delay line models. So, let's consider a situation where agents are interested in estimating the parameters of an FIR model, such as the taps of a communication channel or the parameters of a (approximate) interest model in financial or biology. Assuming that agents are able to independently examine the unknown model and observe its response to excitations in the presence of additive noise; this situation is illustrated in Figure 4, with the probing operation for one of the nodes (node 4) highlighted. The schematics within the extended diagram in Figure 4 are intended to convey that each k examines the model with an input sequence."}, {"heading": "2.3 Application: Target Localization", "text": "Our third example relates to the problem of locating a target of interest (such as the location of a food source or a chemical leak) or locating and tracking an object of interest (such as a predator or a projectile).In several such localization applications, agents in the network are allowed to move towards the target or target, in which case we could move towards the target (e.g. if it is a food source) or away from the target. In other applications, agents can remain static and simply be interested in locating or tracking a target (such as tracking a projectile)."}, {"heading": "2.4 Application: Collaborative Spectral Sensing", "text": "Our fourth and final example illustrating the role of mean square error estimation and collaboration relates to frequency sensing for cognitive radio applications (secondary radio systems).Cognitive radio systems include two types of users: primary users and secondary users. To avoid harmful interference for primary users, primary cognitive radios must detect unused frequency bands even at low signal and noise ranges (SNR).One way to perform spectrum sensing is for each secondary user to estimate the aggregate power spectrum transmitted by all active primary users and to locate unused frequency bands within the estimated spectrum.This step can be performed by secondary users with or without cooperation.Thus, we are looking at a communication environment consisting of Q primary users and N secondary users."}, {"heading": "3 Distributed Optimization via Diffusion Strategies", "text": "The examples in the previous section were intended to illustrate how MSE cost functions and linear models are useful design tools and how they frequently occur in applications. (1) We are now interested in solving optimization problems of the kind: min wN cost functions such as (39), where each Jk (w) is assumed to be differentiable and convex over w. Although the algorithms presented in this article are applied to more general situations, we will still focus on the mean square error cost functions of the form: Jk (w), where each Jk (i) -uk, iw | 2 (93), where an M-1 column is vector, and the random processes {dk (i), uk, i} are assumed to be associated with zero mean and second order."}, {"heading": "3.1 Relating the Global Cost to Neighborhood Costs", "text": "In fact, most of us are able to go in search of a suitable candidate."}, {"heading": "3.2 Steepest-Descent Iterations", "text": "iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe) iSe) iSe) iSe (iSe (iSe) iSe (iSe) iSe (iSe) iSe (iSe (iSe) iSe (iSe) iSe) iSe (iSe (iSe) iSe (iSe) iSe (iSe (iSe) iSe (iSe) iSe) iSe (iSe) iSe (iSe (iSe) iSe) iSe (iSe (iSe (iSe) iS"}, {"heading": "3.3 Adapt-then-Combine (ATC) Diffusion Strategy", "text": "In fact, it is the case that it is a matter of a way in which the individual actors move in such a way that they can be found in the individual countries in the most diverse areas: in the USA, in the USA, in the USA, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA"}, {"heading": "3.4 Combine-then-Adapt (CTA) Diffusion Strategy", "text": "Similarly, if we return to (125) and add the second term of correction, then (126) - (127). (127). (127). (127). (127). (127). (127). (127). (127). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128). (128)."}, {"heading": "3.5 Useful Properties of Diffusion Strategies", "text": "Note that the structure of the ATC and CTA diffusion strategies (134) and (142) are basically the same: the difference between the implementations lies in which variable we choose to match the updated weight estimation wk, i. In the ATC case we select the result of the combination step to be wk, i, while in the CTA case we choose the result of the adaptation step to be wk, i. To simplify the reference strategies, the steepest diffusion algorithms derived in the previous sections were listed first. Derivative of the ATC and CTA strategies (134) and (142) followed the approach proposed in [18,27]. CTA estimation schemes were first proposed in the works [35-39] and later expanded in [18,27,32,33]. Previous versions of the CTA strategies were used in [18,27] the Algorithms [37-37] with the choice C = additional 4I."}, {"heading": "4 Adaptive Diffusion Strategies", "text": "The distributed ATC and CTA strategies (134) and (142) for determining the solution (92) - (93) require knowledge of statistical information (1). - These moments are necessary in order to evaluate the gradient vectors, which in (134) and (142), namely the terms: - (1), - (1), - (1), - (1), - (1), - (147) \u2212 (147) \u2212 (147) \u2212 (147) \u2212 (147) \u2212 (147) \u2212 (147) \u2212 (147) \u2212 (147) \u2212 (-), - (1), - (148), - (148), - (148), - (147), - (147), - (147), - (147), - (147), (147), - (147, - 147, - 147, (147), (147), (147), (147), - (147), (147, -, (147), (147), (147), -, (147), (147), (147, -, (147), (147), (147), (147, -, (147), (147), (147), (147), (147), (147, -, (147), (147), (147), (147)."}, {"heading": "5 Performance of Steepest-Descent Diffusion Strategies", "text": "Before examining in detail the mean square performance of the adaptive diffusion strategies (153) - (154) and the influence of gradient noise, we will first examine the convergence behaviour of the diffusion strategies (134) and (142) that use the true gradient vectors, thus helping to introduce the necessary notation and highlight some features of the analysis in preparation for the more demanding treatment of adaptive strategies in paragraph 6."}, {"heading": "5.1 General Diffusion Model", "text": "Instead of examining the performance of the ATC and CTA parentage strategies (134) and (142) individually, it is useful to introduce a more general description that includes the ATC and CTA parentage strategies as special cases. So, let's consider a distributed implementation of the following general form of diffusion for i + 0: 0, i \u2212 1 = procedural, i \u2212 1 (163) procedural, i \u2212 1 + procedural, i \u2212 1 + procedural, Nkcu k [rdu, Ru, 1, i \u2212 1] (164) procedural, i \u2212 1 (165) procedural, i \u2212 k k, whereby the procedural method {a1, k, ck, a2) procedural, i \u2212 k, k."}, {"heading": "5.2 Error Recursions", "text": "Our aim is to examine whether, and how quickly, the weight assessment (WIR) of the distributed implementation (163) - (165) - (172) - (173) - (173) - (173) - (165) - (174) - (174) - (172) - (172) - (172) - (172) - (173) - (173) - (173) - (165) - (165) - (171) - (176) - (176) - (176) - (172) - (172) - (172) - (172) - (172) - (172) - (172) - (172 - 173) - (172 - 173) (173) (172 - 173) (173) (173) - (172 - 173) (172 - 173) (173) (172 - 173) (173) (173 - (173) - (172 - 173) (173 - (172 - 173) (173 - 173 - 173 - 173 - (173) (172 - 173 - 173) (172 - 173 - 173) (173 - 173 - 173 - 173 - 173 - 173 - 173 - 173) (173 - 173 - 173 - 173 - 173 - 173 - 173 - 173) (173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 - 173 173 - 173 - 173 - 173 - 173 173 - 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 17"}, {"heading": "5.3 Convergence Behavior", "text": "Note from the (189) that the development of the weight error vector includes block vectors and block matrices, the cost of distributed implementations, which we will consider in this article. In order to investigate the stability and convergence of recursions, which include such block sizes, it will be useful to rely on a certain block vector norm. In App. D, we describe a so-called block maximum block and identify some of its useful properties. The results of the appendix will be widely used in our exposure. It is therefore advisable for the reader to check the properties specified in this appendix. Using the result of Lemma D.6, we can establish the following useful statement about the convergence of the steepest diffusion strategy (163) - (165). The result states that all nodes converge to the optimal solution, where the nodes are positive step sizes small enough."}, {"heading": "It then holds that the magnitude of the error vector, \u2016w\u0303i\u2016, in the diffusion case decays to zero more rapidly than in the non-cooperative case. In other words, diffusion cooperation enhances convergence rate.", "text": "It is obvious that (194) we are all (191) satisfied even if C is double stochastic. In this case, any neighbourhood covariance matrix (Rk) becomes a convex combination of individual covariance matrices (Ru, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK, RK"}, {"heading": "It then holds that the magnitude of the error vector, \u2016w\u0303i\u2016, in the diffusion case decays to zero more rapidly than in the non-cooperative case. In other words, diffusion enhances convergence rate.", "text": "Since Ru, = Ru is stochastical for all and C is double stochastical, we obtain Rk = Ru and INM \u2212 MR = INM \u2212 MRu. Then we consider the case of ATC and CTA strategies (137) and (145) without information exchange corresponding to the case C = IN. The result states that these strategies always increase the convergence rate compared to the non-cooperative case, without assuming the need for uniform step variables or uniform covariance data. Theorem 5.5. (Convergence rate is improved when C = I) Let us consider the problem of optimizing global costs (92) with the individual cost functions given by (93). Let us choose stochastic matrices A1 and A2 satisfactory (166) and set C = IN. This situation covers the two ATTA strategies starting from (92), whereby the respective prescribed mode (147) and the exchange mode (145) are not two-figure."}, {"heading": "It then holds that the magnitude of the error vector, \u2016w\u0303i\u2016, in the diffusion case decays to zero more rapidly than in the non-cooperative case. In other words, diffusion cooperation enhances convergence rate.", "text": "Proof. If C = IN, we get Rk = Ru, k and therefore R = Ru and INM \u2212 MR = INM \u2212 MRu. The results of the previous theorems underline the following important facts about the role of the combination matrices {A1, A2, C} in the convergence behavior of the diffusion strategy (163) - (165): (a) Matrix C affects the stability of the network by its influence on the boundary in (191). This is because the matrices {Rk} of the entries of C. The matrices {A1, A2} have no influence on the network stability. (b) The matrices {A1, A2, C} influence the convergence rate of the network because they influence the spectral radius of the matrix (A1, A2}."}, {"heading": "6 Performance of Adaptive Diffusion Strategies", "text": "We now come to the study of the behavior of the adaptive diffusion implementations (153) - (154) - (154) and the influence of both gradient noise and measurement noise on the convergence and performance of the stationary state. Due to the random nature of the disturbances, it becomes necessary to evaluate the behavior of the algorithms on average by examining the convergence of the weight estimates in both the mean and the mean square. To do this, we will once again consider a general diffusion structure that includes the ATC and CTA strategies (153) - (154) as special cases. We will continue to resort to the bold notation to refer to the measurements and weight estimates to highlight the fact that they are now treated as random variables. Thus, the updated equations will become stochastic updates."}, {"heading": "6.1 Data Model", "text": "When we examined the performance of the steepest diffusion strategy (163) - (165) we evaluated the result (175), which indicated how the moments {rdu, k, Ru, k} that occurred in recursions related to the optimal solution relate to where. Similarly, in order to be able to analyze the performance of the adaptive diffusion strategy (201) - (203) we must know how the data {dk (i), uk, i} relate to where throughout the network. Motivated by the examples presented in Sec. 2, we assume that the data relate to a linear model of the form: dk (i) = uk, iw o + vk (i) (208), where vk (i) measurement noises relate to the variance 2 v, k: 2v, k \u00b2, k \u00b2, k \u00b2, k = E | 2 (209) and where the stochastic processes {dk (i), uk,} as a measurement noise with the variance of the {\u00b7 \u00b7 \u00b7 v \u00b7 v (i) (208), where you {\u00b7 v \u00b7 v, k = 175, k: k), k: v \u2012 i \u2012 where the results relate to (209) and where the stochastic processes {dk (i), k (i)."}, {"heading": "6.2 Performance Measures", "text": "Our goal is to analyze, whether and how quickly the weight estimates {wk, i} from the adaptive diffusion implementation (201) - (203) converge in the direction where. To do this, we again lead the M \u00b7 1 weight error vectors:????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????"}, {"heading": "6.3 Error Recursions", "text": "With the data model (208) and the effects of measurements (201) - (203) we have the data (208) and the data (202). (203) We have the data (202) and the data (202). (203) We have the data (202), we (202), we (202), we (202), we (202), we (202), we (202), we (202), we (202), we (202), we (202), we (203), the (203), the (203), the (203), the (203), the (203), the (203), the (203), the (203), the (203), the (203), the (203), the (203), the (203), the (203), the (203, the (203), the (203), the (203, the (203), the (203), the (203, the (203), the (203), the (203, the (203), the (203, the (203), the (203, the (203), the (203, the (203), the (203, the (203), the (203, the (203), the (203, the (203), the (203, the (203), the (203, the (203, 203, 203, 203, 203, the (203, 203), the (203, 203, 203, the (203, 203, 203, 203, 203, 203, the (203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203 (203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 203, 202, 203, 202,"}, {"heading": "6.4 Convergence in the Mean", "text": "Taking into account the expectations of both sides of the (246) we find that the following statements represent the results of the 5.5 million conversion. (INM \u2212 MR) A T 1 \u00b7 E 1 \u00b7 i \u2212 1, i \u2265 0 (diffusion strategy) (248) where we apply the fact that both recursions are independent of each other, in view of our previous assumptions on convergence data and noise in seconds. (6) The convergence statements from the convergence statement may be extended to the error recursion to ensure stability on average, i.e. to ensure that reE w \u2212 \u2192 0 is guaranteed as i \u2212 (249) If (249) is guaranteed, we would say that the adaptive diffusion solution is asymptounbiological."}, {"heading": "It then holds that the magnitude of the mean error vector, \u2016E w\u0303i\u2016 in the diffusion case decays to zero more rapidly than in the non-cooperative case. In other words, diffusion enhances convergence rate.", "text": "Theorem 6.4. (The mean convergence rate is increased: Uniform covariance data) Consider the same setting of theorem 6.3. Suppose the covariance data is uniform across all nodes, say, Ru, k = Ru is independent of k. Let us also assume that the nodes in both operating modes use step variables \u00b5k, which are selected to meet the required stability conditions (250) and (252), which in this case are met by: \u00b5k < 2\u03bbmax (Ru), k = 1, 2,..., N (255)."}, {"heading": "It then holds that the magnitude of the mean error vector, \u2016E w\u0303i\u2016, in the diffusion case also decays to zero more rapidly than in the non-cooperative case. In other words, diffusion enhances convergence rate.", "text": "The next explanation considers the case of ATC and CTA strategies (204) - (206) without information exchange corresponding to the choice C = IN. The result states that these strategies always increase the convergence rate compared to the uncooperative case, without having to adopt uniform increments or uniform covariance data.Theorem 6.5. (The mean convergence rate is increased when C = I) Consider the problem of optimizing global costs (92) with the individual cost functions specified by (93). Let us select the stochastic matrices A1 and A2 that are satisfactory (166) and set C = IN. This situation includes the ATC and CTA strategies (204) - (206), which do not include information exchange. Let us assume that each node in the network measures data that meet the conditions described in Sec. 6.1. Let us consider two operating modes. In a second network mode, salk in the adaptive node 206 (254) (204)."}, {"heading": "It then holds that the magnitude of the mean error vector, \u2016E w\u0303i\u2016, in the diffusion case decays to zero more rapidly than in the non-cooperative case. In other words, diffusion cooperation enhances convergence rate.", "text": "The results of the previous theorems underline once again the following important facts about the role of combination matrices {A1, A2, C} in the convergence behaviour of the adaptive diffusion strategy (201) - (203): (a) Matrix C influences the mean stability of the network by its influence on the boundary in (250), because the matrices {Rk} depend on the entries of C. Matrices {A1, A2} do not affect the stability of the network. (b) Matrices {A1, A2, C} influence the convergence rate of the mean weight error vector across the network by influencing the spectral radius of matrix AT2 (INM \u2212 MR) A T 1, which controls the thedynamics of the weight error vector in (248)."}, {"heading": "6.5 Mean-Square Stability", "text": "The error vectors that we perform in this section are particularly interested in evaluating the development of two mean errors, namely E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-E-2, E-2, E-E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-4, E-2, E-4, E-2, E-4, E-4, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E-2, E, E-2, E-2, E-2, E, E-2, E-2, E-2, E-2, E-2, E-2, E, E-2, E-2, E-2, E-2, E, E-2, E, E, E-2, E, E-2, E, E, E,"}, {"heading": "6.6 Network Mean-Square Performance", "text": "We can now use the variance relation (279) to evaluate the network performance, as well as the performance of individual nodes (283), in steady-state (283), in steady-state variance relation (1203), in which the same setting of theorem 6.6. The weight error vector, w-value vector, w-i = col {w value, i-value Nk = 1, the adaptive diffusion strategy (201) - (203), the following relation of steady-state variance relation (1203), the following relation of steady-state variance relation (283) - (283), the following relation of steady-state variance relation (283) - (283), the following relation of steady-state variance relation of theorem 6.6."}, {"heading": "6.7 Mean-Square Performance of Individual Nodes", "text": "We can also calculate the mean quadratic power of the individual knots in the network of (284).K = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = = SO = SO = SO = SO = = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO = SO ="}, {"heading": "6.8 Uniform Data Profile", "text": "We can simplify expressions (307) - (309) for {Y, G, B} in the case when the regression covariance matrices within the mesh are uniform and all nodes use the same step size, i.e. when the combination matrix C is double stochastical, so that the signal-to-noise (SNR) ratio within the mesh can still be variable.The simplified expressions will be useful in sec."}, {"heading": "6.9 Transient Mean-Square Performance", "text": "Before comparing the mean square performance of different cooperation strategies, we pause to comment that the variance relationship (279) can also be used to characterize the transient behavior of the network (279), and not just its constant state performance. To see this, iterate (279) starting from i = 0, we find that the variance relationship (279) with respect to the initial condition (279), w \u2212 w \u00b2 2 Fi + [vec (YT)], T \u00b7 i = 0F jp (325), where w \u2212 1 (326) with respect to the initial condition, w \u2212 1. If this initial condition is random w \u2212 1 = 0, then w \u2212 1 = w o. Comparative expression (325) with respect to the points of time i and i \u2212 1, we can relate E, w \u00b2 with respect to the original condition, w \u2212 1 \u00b2, w \u2212 2 with respect to the condition."}, {"heading": "7 Comparing the Performance of Cooperative Strategies", "text": "s MSD, we can compare the performance of different cooperative and non-cooperative strategies. Table 6 below summarizes the results derived in this section and the conditions under which they occur."}, {"heading": "7.1 Comparing ATC and CTA Strategies", "text": "First, we compare the performance of the adaptive ATC and CTA diffusion strategies (153) and (154) when applying a double stochastic combination matrix A. That is, we consider the two scenarios: C, A1 = A, A2 = IN (adaptive CTA strategy) (332) C, A1 = IN, A2 = A (adaptive ATC strategy) (333), where A is now assumed to be double stochastical, i.e. A1 = 1, AT1 = 1 (334) with its rows and columns adding up to one. For example, these conditions are met when A is stochastical and symmetrical, and then expressions (307) and (309): Bcta = (I \u2212 MR) A T, Ycta = MC TSCM (335) Batc = A T (I \u2212 MR), Yatc = A TMCSCMA (336), where A (37 \u00b7 J = double chastic)."}, {"heading": "7.2 Comparing Strategies with and without Information Exchange", "text": "We will now examine the impact of information exchange (C 6 = I) on the performance of adaptive ATC and CTA diffusion strategies (153) - (154) under conditions (310) - (312) for a uniform data profile. We will start with the adaptive CTA strategy (154), and consider two scenarios with and without information exchange. These scenarios correspond to the following selection criteria in the general description (345) - (203): C 6 = I, A1 = A, A2 = IN (adaptive CTA with information exchange) (344) C = I, A2 = IN (adaptive CTA without information exchange) (345) Then expressions (322) and (323): Bcta, C6 = I = A T (I \u2212 \u00b5Ru), Ycta, C6 = I = \u00b5 2 (CTRA)."}, {"heading": "7.3 Comparing Diffusion Strategies with the Non-Cooperative Strategy", "text": "We now compare the performance of the adaptive CTA strategy (154) with the non-cooperative LMS strategy (207) under the assumption of conditions (310) - (312) for a uniform data profile. These scenarios correspond to the following selection results in the general description (201) - (203): C, A1 = A, A2 = I (adaptive CTA) (360) C = I, A1 = I, A2 = I (non-cooperative LMS) (361), where A is still assumed to be double stochastically (together with C), so thatA1 = 1, AT1 = 1 (362) Then, expressions (322) and (323) result in: Bcta = A T (I \u2212 \u00b5Ru), Ycta = 2 (CTRYvC Ru) (363) Blms = I, Ylms (I \u2212 \u00b5Ru), Ylms (I), Ylms = 2 (Rv ctu)."}, {"heading": "8 Selecting the Combination Weights", "text": "The adaptive diffusion strategy (201) - (203) uses combination weights {a1, \u0435k, a2, \u0435k, c\u043ek} or, equivalent to this, combination matrices {A1, A2, C}, where A1 and A2 are left stochastic matrices and C is a right stochastic matrix. There are several ways in which these matrices can be selected. In this section we will describe constructions that lead to left stochastic or double stochastic combination matrices, A. If a right stochastic combination matrix is required, such as C, then it can be achieved by transposing the left stochastic constructions shown below."}, {"heading": "8.1 Constant Combination Weights", "text": "In the table, the nk symbol denotes the degree of the node k, which refers to the size of its neighbourhood. Likewise, the nmax symbol refers to the maximum degree within the mesh, i.e., nmax = max 1 \u2264 k \u2264 N {nk} (372) The laplac rule that appears in the second row of the table is based on the use of the laplac matrix L of the mesh and a positive scalar approach. The laplac matrix is defined by (574) in App. B. B, namely, it is a symmetrical matrix whose entries are structured as follows: [L] k = nk \u2212 1, if k = \u2212 1, if k = and node k and neighbour are 0."}, {"heading": "8.2 Optimizing the Combination Weights", "text": "We are interested in an adaptive solution that becomes part of the learning process so that the network can adjust the weight distribution in the approach strategy."}, {"heading": "8.3 Adaptive Combination Weights", "text": "In order to evaluate the deviations between the two nodes, we need to know the deviations between the two nodes that we need near the node k2 and the vicinity of the node k2, theneach of k1 and k2, in order to evaluate the deviations, we need to learn the deviations between the two nodes in an adaptive way. Note: If a particular node belongs to two neighborhoods, we say that the neighborhood of the node k2, theneach of k1 and k2 must evaluate the deviations between the two node products, we need to evaluate the deviations between the two node products."}, {"heading": "9 Diffusion with Noisy Information Exchanges", "text": "The adaptive diffusion strategy (201) - (203) is based on merging local information gathered from neighborhoods through the use of combination matrices (A1, A2, C). In the previous section, we described several constructions for selecting such combination matrices. We have also developed an adaptive scheme for the functioning of ATC (375) - (376), which calculates combination weights in a way that takes into account the variance of the variance of the variance product profile within the network. However, in addition to the measurement noise {vk (i)} at the individual nodes, we must also take into account the effects of interference that occurs during the information exchange between adjacent nodes. Noise over the communication connections may be due to various factors, including thermal noise and imperfect channel information."}, {"heading": "9.1 Noise Sources over Exchange Links", "text": "In order to reduce the impact of climate change on climate change and global warming on global warming and global warming on global warming, we need to deal with the effects of climate change and global warming on global warming. (2) We need to adapt the effects of climate change on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming. (3) We need to adapt global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming on global warming and global warming on global warming and global warming on global warming on global warming and global warming on global warming. (3) We need to adapt global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming and global warming on global warming."}, {"heading": "9.2 Error Recursion", "text": "We are able to employ the data (407) - (410) - (201) - (203) - (407) - (407) - (414) - (414) - (414) - (414) - (414) - (416) - (414) - (416) - (416) - (414) - (414) - (414) - (414) - (416) - (414) - (414) - (414) - (414) - (414) - (414) - (414) - (414) - (414) - (414) - (414) - 414 - 414 414 414 (414) (414) 414 414 414 414 (414) (414) (414) 414 (414) (414) (414) (414) (414) (414 - 414 - 414 414 414 414 (414) (414) (414) (414) (414 - (414) (414) - (414) (414 - 414 - (414) (414) - (414) - (414) - (414 - 414) - (414 - (414) (414) - (414) (414 - (414) - (414) - 414 - 414 - 414 - 414 - 414 (414) - 414 (414) (414 - 414 - 414 - 414 - 414 (414) (414) (414) (414 - 414 - 414 (414) (414 - 414) (414 - 414 - 414 - 414 - 414 - 414 (414) (414) (414) (414 - 414 - 414 - 414 - 414 - 414 - 414 - 414 (414) (414) (414 - (414) (414) (414) (414 - (414) (414) (414 - 414 - 414 - 414 -"}, {"heading": "9.3 Convergence in the Mean", "text": "Taking the expectations of both sides of (444), we find that the mean error vector develops according to the following recursion (446) (446): It is the same recursion that has already occurred in (248) during perfect data exchange. Note that if we had taken noise into account when exchanging regression data, then the zi vector in (444) would not be the mean zero and the matrix R \u2032 i would have to be used instead of Ri. In this case, the recursion for E w \u0441i would be different from (445); i.e. the presence of noise during the exchange of regression data significantly changes the dynamics of the mean error vector R \u2032 i - see [62, 63] for details on how to extend the arguments to this general case with a non-zero bias concept."}, {"heading": "9.4 Mean-Square Convergence", "text": "(264) that we can extend the statement of Theorem 7 to the current scenery. (447) that we can extend the matrix of (264), that we have introduced the matrix of (264), (444), (444), (444), (449), (444), (444), (444), (444), (444), (444), (444), (449), (444), (449), (444), (444), (444), (449), (449), (449), (449), (449), (449), (449), (449), (449), (449), (449), (448), (448), (448), (448), (444), (444), (444), (444), 444, 444, 444, 444, 444, 444, 444, 444, 447, 447, 444, 444, 444, 444, 447, 444, 444, 444, 447, 444, 444, 447, 444, 444, 444, 444, 447, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 447, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 444, 4"}, {"heading": "9.5 Adaptive Combination Weights", "text": "We can repeat the discussion from sectors 8.2 and 8.3 to develop an adaptation scheme to adjust the combination coefficients in the noise-plagued exchange situation. (1) We can design by taking into account the ATC strategy with respect to A1 = A2 = A, A = IN, so that only weight estimates are exchanged and the updated recursions are executed in the form. (2) We can make the recursions in the form of (462), in which (408): EK, i \u2212 K (461), i \u2212 K (461) wk, i \u2212 K (461) wk, i \u2212 K (461) wk, i \u2212 K (461) wk, i \u2212 K (457) becomesMSDnetworkatc, C = I, imperfect = 0Tr (Bjatc, C = IYatc, imperfectB, 457) we."}, {"heading": "10 Extensions and Further Considerations", "text": "Various enhancements and variations of diffusion strategies are possible. Among these variations, we mention strategies that provide nodes with time processing capabilities in addition to their spatial cooperation capabilities. We can also apply diffusion strategies to solve recursive least squares and statespace problems in distributed ways. In this section, we highlight selected contributions in these and related areas."}, {"heading": "10.1 Adaptive Diffusion Strategies with Smoothing Mechanisms", "text": "In the ATC and CTA adaptive diffusion strategies (153) - (154), each node in the network share information local with its neighbors through a process of spatial cooperation or combination. In this section, we briefly describe an extension that adds a time dimension to processing at the nodes. (For example, in the ATC implementation (153), instead of relying on each node k exclusively on current data, {d (i), and on current weight estimates obtained from neighbors, {, i,,, Nk), it can be allowed to store and process current and past weight estimates, say, P of them as in {d, j = i \u2212 1,., i \u2212 P + 1}. In this way, earlier weight estimates can be smoothed out and used more effectively to improve the mean square deviation."}, {"heading": "10.2 Diffusion Recursive Least-Squares", "text": "The aim of the network is to estimate together an unknown vector of length M, which is indicated by the use of a minimum square criterion: dk (i) = uk, iw o + vk (i) = uk, iw o + vk (i). In the above relation, the vector uk, i) denotes a series of regressive vectors of length M, and vk (i) denotes vector of length M, i) denotes measurement noise."}, {"heading": "10.3 Diffusion Kalman Filtering", "text": "\"We assume that, over time, the system will be based exclusively on local observations and neighbourhood interactions. Thus, we look at a network of N nodes that relate to size n.\" The objective is for each node based on the state of the system to be based exclusively on local observations and neighbourhood interactions. Thus, we look at a network of N nodes that observe the state of the vector, xi, xi n node of a linear spatial model. At any time, each node collects a measurement vector yk, i-node."}, {"heading": "10.4 Diffusion Distributed Optimization", "text": "The ATC and the CTA-Diffusion Strategies (139) and (142), which are used for optimizing the strategy, are able to reduce the costs (539) if the individual costs, Jk (540) for the predetermined parameters, k (540) for the predetermined parameters, k, k, k, k, k, k, k, k, e, n, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c,"}, {"heading": "Acknowledgements", "text": "The development of the theory and application of diffusion adjustment over networks has benefited greatly from the insights and contributions of several UCLA doctoral students and several visiting students at the UCLA Adaptive Systems Laboratory (http: / / www.ee.ucla.edu / asl).The support and contributions of all students are hereby appreciated, including Cassio G. Lopes, Federico S. Cattivelli, ShengYuan Tu, Jianshu Chen, Xiaochuan Zhao, Zaid Towfic, Chung-Kai Yu, Noriyuki Takahashi, Jae-Woo Lee, Alexander Bertrand Paolo Di Lorenzo. The author is also S.-Y. Tu, J. Chen, X. Zhao, Z. Towfic and C.-K. Yu especially grateful for their assistance in reviewing an earlier draft of this article."}, {"heading": "A Appendix: Properties of Kronecker Products", "text": "For simplicity, we collect some useful properties of Kronecker products in this appendix. All matrices assume that they are of compatible dimensions; all inverses are assumed to exist whenever necessary. Let E = [eij] n i, j = 1 and B = [bij] m i, j = 1 n \u00b7 n or m \u00b7 m matrices. Your Kronecker product is denoted by E B and is defined as the nm \u00b7 nm matrix, whose entries are given by [20]: E B = e11B e12B.... e1nB e21B e22B.... e2nB...... en1B en2B... ennB (572) In other words, each entry of E is replaced by a scaled multiple of B. Let {\u03bbi (E), i = 1,..., n} and {\u03bbj (B), j = 1,. m} the eigenvalues of E (then all known combinations of E)."}, {"heading": "B Appendix: Graph Laplacian and Network Connectivity", "text": "Consider a network consisting of N nodes and L edges that connect the nodes to each other. In the constructions below, we need only look at the edges that connect different nodes to each other; these edges do not contain self-loops that can exist in the graph and connect the nodes directly to themselves. In other words, if we point to the edges of a graph, we will exclude the self-loops from this set, but we still allow loops of at least length 2 (i.e., loops generated by paths that contain at least 2 edges).The neighborhood of any node k is denoted by Nk and it consists of all nodes with which k can share information; these are the nodes connected by edges, in addition to nodes themselves. The degree of the node k that we denote by nk is defined as the positive integer that is equal to the size of its neighborhood."}, {"heading": "C Appendix: Stochastic Matrices", "text": "Consider N \u00b7 N matrices of the stochastic matrices) Let A leave a N \u00d7 N or left or double chastic values. The matrix A = Property A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A (Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = Self-ektor A = A Self-ektor A = A Self-ektor A = A Self-ektor A = A Self-ektor A = A Self-ektor A = A-Self-ektor A = A-Self-ektor A = A-Self-ektor A = A-Self-ektor A-A = Self-ektor A-A = Self-ektor A = Self-ektor A = Self-ektor A-A = Self-ektor A = Self-ektor A = Self-Self-ektor A = Self-Self-ektor A = Self-ektor A = Self-Self-ektor A = Self-ektor A = Self-ektor A = Self-A = Self-Self-ektor A = Self-Self-ektor A = Self-A = Self-A = Self-A-Self-A = Self-A = Self-Self-Self-ektor A = A = Self-A = Self-Self-A = Self-Self-A = A = A = Self-Self-Self-Self-Self-Self-A = A = A = A = Self-Self-Self-A = A = A = Self-Self-Self-Self-Self-A = A = A = A"}, {"heading": "D Appendix: Block Maximum Norm", "text": "Leave x = col {x1, x2,."}, {"heading": "E Appendix: Comparison with Consensus Strategies", "text": "The question of whether it is a matter of a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, and in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way in which it is about a way, in which it is about a way and in which it is about a way in which it is about a way and in which it is about a way and in which it is about a way it is about a way and in which it is about a way and in which it is about a way it is about a way and in which it is about a way and in which it is about a way and in which it is about a way it is about a way and in which it is about a way and in which it is about which it is about which it is about a way and in which it is about a way and in which it is about which it is about which it is about a way and in which it is about a way and in which it is about a way and in which it is about which it is about which it is about which it is about a way and in which it is about which it is about a way and in which it is about which it is about which it is about a way and in which it is"}], "references": [{"title": "On the limiting behavior of distributed optimization strategies", "author": ["J. Chen", "A.H. Sayed"], "venue": "Proc. 50th Annual Allerton Conference on Communication, Control, and Computing, pp. 1\u20138, Allerton, IL, October 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Diffusion adaptation strategies for distributed optimization and learning over networks", "author": ["J. Chen", "A.H. Sayed"], "venue": "IEEE Trans. Signal Processing, vol. 60, no. 8, pp. 4289\u20134305, August 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed Pareto optimization via diffusion strategies", "author": ["J. Chen", "A.H. Sayed"], "venue": "IEEE J. Selected Topics in Signal Processing, vol. 7, no. 2, pp. 205\u2013220, April 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive Filter Theory", "author": ["S. Haykin"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Mobile adaptive networks", "author": ["S.-Y. Tu", "A.H. Sayed"], "venue": "IEEE J. Sel. Topics. Signal Process., vol. 5, no. 4, pp. 649\u2013664, Aug. 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Modeling bird flight formations using diffusion adaptation", "author": ["F. Cattivelli", "A.H. Sayed"], "venue": "IEEE Transactions on Signal Processing, vol. 59, no. 5, pp. 2038\u20132051, May 2011.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Modeling bee swarming behavior through diffusion adaptation with asymmetric information sharing", "author": ["J. Li", "A.H. Sayed"], "venue": "EURASIP Journal on Advances in Signal Processing, 2012:18, doi:10.1186/1687-6180-2012-18, 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Bio-inspired cooperative optimization with application to bacteria motility", "author": ["J. Chen", "A.H. Sayed"], "venue": "Proc. ICASSP, Prague, Czech Republic, pp. 5788\u20135791, May 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Diffusion adaptation over networks of particles subject to Brownian fluctuations", "author": ["A.H. Sayed", "F.A. Sayed"], "venue": "Proc. Asilomar Conference on Signals, Systems, and Computers, pp. 685\u2013690, Pacific Grove, CA, November 2011.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Cognitive radio: Making software radios more personal,\u201dIEEE", "author": ["J. Mitola", "G.Q. Maguire"], "venue": "Personal Commun.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "Cognitive radio: Brain-empowered wireless communications", "author": ["S. Haykin"], "venue": "IEEE J. Sel. Areas Commun., vol. 23, no. 2, pp. 201-220, Feb. 2005.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}, {"title": "Optimal spectral feature detection for spectrum sensing at very low SNR", "author": ["Z. Quan", "W. Zhang", "S.J. Shellhammer", "A.H. Sayed"], "venue": "IEEE Transactions on Communications, vol. 59, no. 1, pp. 201-212, January 2011.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Cooperative sensing via sequential detection", "author": ["Q. Zou", "S. Zheng", "A.H. Sayed"], "venue": "IEEE Transactions on Signal Processing, vol. 58, no. 12, pp. 6266-6283, December 2010.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Bio-inspired swarming for dynamic radio access based on diffusion adaptation", "author": ["P. Di Lorenzo", "S. Barbarossa", "A.H. Sayed"], "venue": "Proc. EUSIPCO, pp. 402-406, Barcelona, Spain, August 2011.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Diffusion LMS strategies for distributed estimation", "author": ["F.S. Cattivelli", "A.H. Sayed"], "venue": "IEEE Trans. Signal Process., vol. 58, no. 3, pp. 1035\u20131048, March 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Introductory Functional Analysis with Applications", "author": ["E. Kreyszig"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1989}, {"title": "Introduction to Optimization, Optimization", "author": ["B. Poljak"], "venue": "Software, NY,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1987}, {"title": "A new class of incremental gradient methods for least squares problems", "author": ["D.P. Bertsekas"], "venue": "SIAM J. Optim., vol. 7, no. 4, pp. 913\u2013926, 1997.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1997}, {"title": "Incremental subgradient methods for nondifferentiable optimization", "author": ["A. Nedic", "D.P. Bertsekas"], "venue": "SIAM J. Optim., vol. 12, no. 1, pp. 109\u2013138, 2001.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "Quantized incremental algorithms for distributed optimization", "author": ["M.G. Rabbat", "R.D. Nowak"], "venue": "IEEE J. Sel. Areas Commun., vol. 23, no. 4, pp. 798\u2013808, 2005.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2005}, {"title": "Incremental adaptive strategies over distributed networks", "author": ["C.G. Lopes", "A.H. Sayed"], "venue": "IEEE Trans. Signal Process., vol. 55, no. 8, pp. 4064\u20134077, Aug. 2007.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Diffusion LMS algorithms with information exchange", "author": ["F.S. Cattivelli", "A.H. Sayed"], "venue": "Proc. Asilomar Conf. Signals, Syst. Comput., Pacific Grove, CA, pp. 251\u2013255, Nov. 2008.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "A diffusion RLS scheme for distributed estimation over adaptive networks", "author": ["F.S. Cattivelli", "C.G. Lopes", "A.H. Sayed"], "venue": "Proc. IEEE Workshop on Signal Process. Advances Wireless Comm. (SPAWC), Helsinki, Finland, pp. 1\u20135, June 2007.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2007}, {"title": "Diffusion recursive least-squares for distributed estimation over adaptive networks", "author": ["F.S. Cattivelli", "C.G. Lopes", "A.H. Sayed"], "venue": "IEEE Trans. Signal Process., vol. 56, no. 5, pp. 1865\u20131877, May 2008.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1865}, {"title": "Diffusion strategies for distributed Kalman filtering: Formulation and performance analysis", "author": ["F.S. Cattivelli", "C.G. Lopes", "A.H. Sayed"], "venue": "Proc. IAPR Workshop on Cognitive Inf. Process.(CIP), Santorini, Greece, pp. 36\u201341, June 2008.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}, {"title": "Diffusion mechanisms for fixed-point distributed Kalman smoothing", "author": ["F.S. Cattivelli", "A.H. Sayed"], "venue": "Proc. EUSIPCO, Lausanne, Switzerland, pp. 1\u20134, Aug. 2008.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "Distributed adaptive learning mechanisms", "author": ["A.H. Sayed", "F. Cattivelli"], "venue": "Handbook on Array Processing and Sensor Networks, S. Haykin and K. J. Ray Liu, Eds., pp. 695\u2013722, Wiley, NJ, 2009.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "Diffusion strategies for distributed Kalman filtering and smoothing", "author": ["F. Cattivelli", "A.H. Sayed"], "venue": "IEEE Transactions on Automatic Control, vol. 55, no. 9, pp. 2069\u20132084, Sep. 2010.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Decentralized parameter estimation by consensus based stochastic approximation", "author": ["S.S. Stankovic", "M.S. Stankovic", "D.S. Stipanovic"], "venue": "IEEE Trans. on Autom. Control, vol. 56, no. 3, pp. 531\u2013543, Mar. 2011.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2011}, {"title": "Distributed processing over adaptive networks", "author": ["C.G. Lopes", "A.H. Sayed"], "venue": "Proc. Adaptive Sensor Array Processing Workshop, MIT Lincoln Laboratory, MA, pp.1\u20135, June 2006.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2006}, {"title": "Adaptive processing over distributed networks", "author": ["A.H. Sayed", "C.G. Lopes"], "venue": "IEICE Trans. Fund. of Electron., Commun. and Comput. Sci., vol. E90-A, no. 8, pp. 1504\u20131510, 2007.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2007}, {"title": "Diffusion least-mean-squares over adaptive networks", "author": ["C.G. Lopes", "A.H. Sayed"], "venue": "Proc. IEEE ICASSP, Honolulu, Hawaii, vol. 3, pp. 917-920, April 2007.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2007}, {"title": "Steady-state performance of adaptive diffusion least-mean squares", "author": ["C.G. Lopes", "A.H. Sayed"], "venue": "Proc. IEEE Workshop on Statistical Signal Processing (SSP), pp. 136-140, Madison, WI, August 2007.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2007}, {"title": "Diffusion least-mean squares over adaptive networks: Formulation and performance analysis", "author": ["C.G. Lopes", "A.H. Sayed"], "venue": "IEEE Trans. Signal Process., vol. 56, no. 7, pp. 3122\u20133136, July 2008.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2008}, {"title": "Distributed stochastic subgradient projection algorithms for convex optimization", "author": ["S.S. Ram", "A. Nedic", "V.V. Veeravalli"], "venue": "J. Optim. Theory Appl., vol. 147, no. 3, pp. 516\u2013545, 2010.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "Convergence of a distributed parameter estimator for sensor networks with local averaging of the estimates", "author": ["P. Bianchi", "G. Fort", "W. Hachem", "J. Jakubowicz"], "venue": "Proc. IEEE ICASSP, Prague, Czech, pp. 3764\u20133767, May 2011.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2011}, {"title": "Reaching a consensus", "author": ["M.H. DeGroot"], "venue": "Journal of the American Statistical Association, vol. 69, no. 345, pp. 118\u2013121, 1974.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1974}, {"title": "A necessary and sufficient condition for reaching a consensus using DeGroot\u2019s method", "author": ["R.L. Berger"], "venue": "Journal of the American Statistical Association, vol. 76, no. 374, pp. 415-418, Jun. 1981. 113", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1981}, {"title": "Convergence and asymptotic agreement in distributed decision problems", "author": ["J. Tsitsiklis", "M. Athans"], "venue": "IEEE Trans. Autom. Control, vol. 29, no. 1, pp. 42\u201350, Jan. 1984.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1984}, {"title": "Coordination of groups of mobile autonomous agents using nearest neighbor rules", "author": ["A. Jadbabaie", "J. Lin", "A.S. Morse"], "venue": "IEEE Trans. Autom. Control, vol. 48, no. 6, pp. 988\u20131001, Jun. 2003.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2003}, {"title": "Consensus problems in networks of agents with switching topology and time-delays", "author": ["R. Olfati-Saber", "R.M. Murray"], "venue": "IEEE Trans. Autom. Control, vol. 49, pp. 1520\u20131533, Sep. 2004.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2004}, {"title": "Distributed Kalman filter with embedded consensus filters", "author": ["R. Olfati-Saber"], "venue": "Proc. 44th IEEE Conf. Decision Control, pp. 8179\u20138184, Sevilla, Spain, Dec. 2005.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2005}, {"title": "Distributed Kalman filtering for sensor networks", "author": ["R. Olfati-Saber"], "venue": "Proc. 46th IEEE Conf. Decision Control, pp. 5492\u20135498, New Orleans, LA, Dec. 2007.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2007}, {"title": "Fast linear iterations for distributed averaging", "author": ["L. Xiao", "S. Boyd"], "venue": "Syst. Control Lett., vol. 53, no. 1, pp. 65\u201378, Sep. 2004.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2004}, {"title": "A scheme for robust distributed sensor fusion based on average consensus", "author": ["L. Xiao", "S. Boyd", "S. Lall"], "venue": "Proc. IPSN, 2005, pp. 63\u201370, Los Angeles, CA, April 2005.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2005}, {"title": "Distributing the Kalman filter for large-scale systems", "author": ["U.A. Khan", "J.M.F. Moura"], "venue": "IEEE Trans. Signal Processing, vol. 56, no. 10, pp. 4919\u20134935, Oct. 2008.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2008}, {"title": "Parallel and Distributed Computation: Numerical Methods, 1st edition", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": "Athena Scientific, Singapore,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 1997}, {"title": "Cooperative distributed multi-agent optimization", "author": ["A. Nedic", "A. Ozdaglar"], "venue": "Convex Optimization in Signal Processing and Communications, Y. Eldar and D. Palomar (Eds.), Cambridge University Press, pp. 340-386, 2010.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2010}, {"title": "Diffusion least-mean-squares with adaptive combiners: Formulation and performance analysis", "author": ["N. Takahashi", "I. Yamada", "A.H. Sayed"], "venue": "IEEE Trans. on Signal Processing, vol. 9, pp. 4795-4810, Sep. 2010.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2010}, {"title": "Parallel algorithms for variational inequalities over the cartesian product of the intersections of the fixed point sets of nonexpansive mappings", "author": ["N. Takahashi", "I. Yamada"], "venue": "J. Approx. Theory, vol. 153, no. 2, pp. 139\u2013160, Aug. 2008.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2008}, {"title": "Transient analysis of data-normalized adaptive filters,\u201dIEEE", "author": ["T.Y. Al-Naffouri", "A.H. Sayed"], "venue": "Transactions on Signal Processing,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2003}, {"title": "Optimal combination rules for adaptation and learning over networks", "author": ["S-Y. Tu", "A.H. Sayed"], "venue": "Proc. IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP), San Juan, Puerto Rico, pp. 317\u2013320, December 2011.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2011}, {"title": "Diffusion LMS algorithms for sensor networks over non-ideal inter-sensor wireless channels", "author": ["R. Abdolee", "B. Champagne"], "venue": "Proc. IEEE Int. Conf. Dist. Comput. Sensor Systems (DCOSS), pp. 1\u20136, Barcelona, Spain, June 2011.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2011}, {"title": "Steady state analysis of diffusion LMS adaptive networks with noisy links", "author": ["A. Khalili", "M.A. Tinati", "A. Rastegarnia", "J.A. Chambers"], "venue": "IEEE Trans. Signal Processing, vol. 60, no. 2, pp. 974\u2013979, Feb. 2012.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive networks with noisy links", "author": ["S-Y. Tu", "A.H. Sayed"], "venue": "Proc. IEEE Globecom, pp. 1\u20135, Houston, TX, December 2011.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2011}, {"title": "Diffusion adaptation over networks under imperfect information exchange and non-stationary data", "author": ["X. Zhao", "S-Y. Tu", "A.H. Sayed"], "venue": "IEEE Transactions on Signal Processing, vol. 60, no. 7, pp. 3460\u20133475, July 2012.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2012}, {"title": "Combination weights for diffusion strategies with imperfect information exchange", "author": ["X. Zhao", "A.H. Sayed"], "venue": "Proc. IEEE ICC, pp. 1\u20135, Ottawa, Canada, June 2012.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2012}, {"title": "Graphs, Algorithms and Optimization", "author": ["W. Kocay", "D.L. Kreher"], "venue": null, "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2005}, {"title": "Algebraic connectivity of graphs", "author": ["M. Fiedler"], "venue": "Czech. Math. J., vol. 23, pp. 298\u2013305, 1973. 114", "citeRegEx": "67", "shortCiteRegEx": null, "year": 1973}, {"title": "Convergence in multiagent coordination, consensus, and flocking", "author": ["V.D. Blondel", "J.M. Hendrickx", "A. Olshevsky", "J.N. Tsitsiklis"], "venue": "Proc. Joint 44th IEEE Conf. on Decision and Control and European Control Conf. (CDC-ECC), pp. 2996-3000, Seville, Spain, Dec. 2005.", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2005}, {"title": "Locally constructed algorithms for distributed computations in ad-hoc networks", "author": ["D.S. Scherber", "H.C. Papadopoulos"], "venue": "Proc. Information Processing in Sensor Networks (IPSN), pp. 11-19, Berkeley, CA, April 2004.", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2004}, {"title": "Equations of state calculations by fast computing machines", "author": ["N. Metropolis", "A.W. Rosenbluth", "M.N. Rosenbluth", "A.H. Teller", "E. Teller"], "venue": "Journal of Chemical Physics, vol. 21, no. 6, pp. 1087-1092, 1953.", "citeRegEx": "70", "shortCiteRegEx": null, "year": 1953}, {"title": "Monte Carlo sampling methods using Markov chains and their applications", "author": ["W.K. Hastings"], "venue": "Biometrika, vol. 57, no. 1, pp. 97-109, 1970.", "citeRegEx": "71", "shortCiteRegEx": null, "year": 1970}, {"title": "Distributed recursive least-squares strategies over adaptive networks", "author": ["A.H. Sayed", "C. Lopes"], "venue": "Proc. 40th Asilomar Conference on Signals, Systems and Computers, Pacific Grove, CA, pp. 233-237, October-November, 2006.", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2006}, {"title": "Spatio-temporal diffusion mechanisms for adaptation over networks", "author": ["J-W. Lee", "S-E. Kim", "W-J. Song", "A.H. Sayed"], "venue": "Proc. EUSIPCO, pp. 1040-1044, Barcelona, Spain, August-September 2011.", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2011}, {"title": "Spatio-temporal diffusion strategies for estimation and detection over networks", "author": ["J-W. Lee", "S-E. Kim", "W-J. Song", "A.H. Sayed"], "venue": "IEEE Trans. Signal Processing, vol. 60, no. 8, pp. 4017\u20134034, August 2012.", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive robust distributed learning in diffusion sensor networks", "author": ["S. Chouvardas", "K. Slavakis", "S. Theodoridis"], "venue": "IEEE Trans. on Signal Processing, vol. 59, no. 10, pp. 4692\u20134707, Oct. 2011.", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2011}, {"title": "Adaptive algorithm for sparse system identification using projections onto weighted l1 balls", "author": ["K. Slavakis", "Y. Kopsinis", "S. Theodoridis"], "venue": "Proc. IEEE ICASSP, pp. 3742\u20133745, Dallas, TX, March 2010.", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2010}, {"title": "Diffusion distributed Kalman filtering with adaptive weights", "author": ["F. Cattivelli", "A.H. Sayed"], "venue": "Proc. Asilomar Conference on Signals, Systems and Computers, pp. 908\u2013912, Pacific Grove, CA, November 2009.", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2009}, {"title": "A space-time diffusion scheme peer-to-peer least-squares-estimation", "author": ["L. Xiao", "S. Boyd", "S. Lall"], "venue": "Proc. Information Processing in Sensor Networks (IPSN), pp. 168\u2013176, Nashville, TN, April 2006.", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2006}, {"title": "Distributed subgradient methods for multi-agent optimization", "author": ["A. Nedic", "A. Ozdaglar"], "venue": "IEEE Trans. Autom. Control, vol. 54, no. 1, pp. 48\u201361, Jan. 2009.", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2009}, {"title": "Gradient convergence in gradient methods with errors", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": "SIAM J. Optim., vol. 10, no. 3, pp. 627\u2013642, 2000.", "citeRegEx": "81", "shortCiteRegEx": null, "year": 2000}, {"title": "Bio-inspired sensor network design", "author": ["S. Barbarossa", "G. Scutari"], "venue": "IEEE Signal Processing Magazine, vol. 24, no. 3, pp. 26\u201335, May 2007.", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2007}, {"title": "Kalman-consensus filter: Optimality, stability, and performance", "author": ["R. Olfati-Saber"], "venue": "Proc. IEEE CDC, pp. 7036\u2013 7042, Shangai, China, 2009.", "citeRegEx": "83", "shortCiteRegEx": null, "year": 2009}, {"title": "Distributed LMS for consensus-based in-network adaptive processing", "author": ["I.D. Schizas", "G. Mateos", "G.B. Giannakis"], "venue": "IEEE Transactions on Signal Processing, vol. 57, no. 6, pp. 2365\u20132382, June 2009.", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2009}, {"title": "Performance analysis of the consensus-based distributed LMS algorithm", "author": ["G. Mateos", "I.D. Schizas", "G.B. Giannakis"], "venue": "EURASIP J. Adv. Signal Process., pp. 1\u201319, 2009.", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2009}, {"title": "Distributed consensus algorithms in sensor networks: Link failures and channel noise", "author": ["S. Kar", "J.M.F. Moura"], "venue": "IEEE Trans. Signal Process., vol. 57, no. 1, pp. 355\u2013369, Jan. 2009.", "citeRegEx": "86", "shortCiteRegEx": null, "year": 2009}, {"title": "Convergence rate analysis of distributed gossip (linear parameter) estimation: Fundamental limits and tradeoffs", "author": ["S. Kar", "J.M.F. Moura"], "venue": "IEEE Journal on Selected Topics on Signal Processing, vol. 5, no. 4, pp. 674\u2013 690, August 2011.", "citeRegEx": "87", "shortCiteRegEx": null, "year": 2011}, {"title": "Gossip algorithms for distributed signal processing", "author": ["A.G. Dimakis", "S. Kar", "J.M.F. Moura", "M.G. Rabbat", "A. Scaglione"], "venue": "Proc. IEEE, vol. 98, no. 11, pp. 1847\u20131864, November 2010.", "citeRegEx": "88", "shortCiteRegEx": null, "year": 1847}, {"title": "Diffusion networks outperform consensus networks", "author": ["S-Y. Tu", "A.H. Sayed"], "venue": "Proc. IEEE Statistical Signal Processing Workshop, pp. 313\u2013316, Ann Arbor, Michigan, August 2012.", "citeRegEx": "89", "shortCiteRegEx": null, "year": 2012}, {"title": "Diffusion strategies outperform consensus strategies for distributed estimation over adaptive networks", "author": ["S.-Y. Tu", "A.H. Sayed"], "venue": "IEEE Trans. Signal Processing, vol. 60, no. 12, pp. 6217\u20136234, Dec. 2012. 115", "citeRegEx": "90", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "At the same time, we note that most of the arguments in this article can be extended beyond MSE optimization to more general cost functions and to situations where the minimizers of the individual costs Jk(w) need not agree with each other \u2014 as already shown in [1\u20133]; see also Sec.", "startOffset": 262, "endOffset": 267}, {"referenceID": 1, "context": "At the same time, we note that most of the arguments in this article can be extended beyond MSE optimization to more general cost functions and to situations where the minimizers of the individual costs Jk(w) need not agree with each other \u2014 as already shown in [1\u20133]; see also Sec.", "startOffset": 262, "endOffset": 267}, {"referenceID": 2, "context": "At the same time, we note that most of the arguments in this article can be extended beyond MSE optimization to more general cost functions and to situations where the minimizers of the individual costs Jk(w) need not agree with each other \u2014 as already shown in [1\u20133]; see also Sec.", "startOffset": 262, "endOffset": 267}, {"referenceID": 3, "context": "There are many adaptive algorithms that can be used to compute wk,i; some filters are more accurate than others (usually, at the cost of additional complexity) [4\u20137].", "startOffset": 160, "endOffset": 165}, {"referenceID": 3, "context": "The performance of adaptive implementations of this kind are well-understood for both cases of stationary w and changing w [4\u20137].", "startOffset": 123, "endOffset": 128}, {"referenceID": 3, "context": "It is known that the MSD and EMSE of LMS filters of the form (26)\u2013(27) can be approximated for sufficiently small-step sizes by the following expressions [4\u20137]: EMSEk \u2248 \u03bck\u03c3 2 v,kTr(Ru,k)/2 (36) MSDk \u2248 \u03bck\u03c3 2 v,kM/2 (37)", "startOffset": 154, "endOffset": 159}, {"referenceID": 4, "context": "In several such localization applications, the agents in the network are allowed to move towards the target or away from it, in which case we would end up with a mobile adaptive network [8].", "startOffset": 186, "endOffset": 189}, {"referenceID": 4, "context": "Biological networks behave in this manner such as networks representing fish schools, bird formations, bee swarms, bacteria motility, and diffusing particles [8\u201312].", "startOffset": 158, "endOffset": 164}, {"referenceID": 5, "context": "Biological networks behave in this manner such as networks representing fish schools, bird formations, bee swarms, bacteria motility, and diffusing particles [8\u201312].", "startOffset": 158, "endOffset": 164}, {"referenceID": 6, "context": "Biological networks behave in this manner such as networks representing fish schools, bird formations, bee swarms, bacteria motility, and diffusing particles [8\u201312].", "startOffset": 158, "endOffset": 164}, {"referenceID": 7, "context": "Biological networks behave in this manner such as networks representing fish schools, bird formations, bee swarms, bacteria motility, and diffusing particles [8\u201312].", "startOffset": 158, "endOffset": 164}, {"referenceID": 8, "context": "Biological networks behave in this manner such as networks representing fish schools, bird formations, bee swarms, bacteria motility, and diffusing particles [8\u201312].", "startOffset": 158, "endOffset": 164}, {"referenceID": 9, "context": "To avoid causing harmful interference to incumbent primary users, unlicensed cognitive radio devices need to detect unused frequency bands even at low signal-to-noise (SNR) conditions [13\u201316].", "startOffset": 184, "endOffset": 191}, {"referenceID": 10, "context": "To avoid causing harmful interference to incumbent primary users, unlicensed cognitive radio devices need to detect unused frequency bands even at low signal-to-noise (SNR) conditions [13\u201316].", "startOffset": 184, "endOffset": 191}, {"referenceID": 11, "context": "To avoid causing harmful interference to incumbent primary users, unlicensed cognitive radio devices need to detect unused frequency bands even at low signal-to-noise (SNR) conditions [13\u201316].", "startOffset": 184, "endOffset": 191}, {"referenceID": 12, "context": "To avoid causing harmful interference to incumbent primary users, unlicensed cognitive radio devices need to detect unused frequency bands even at low signal-to-noise (SNR) conditions [13\u201316].", "startOffset": 184, "endOffset": 191}, {"referenceID": 13, "context": "To facilitate estimation of the spectral profile by the secondary users, we assume that each Sq(e ) can be represented as a linear combination of basis functions, {fm(e)}, say, B of them [17]: Sq(e ) = B \u2211", "startOffset": 187, "endOffset": 191}, {"referenceID": 0, "context": "It is sufficient in this article to illustrate the main concepts underlying diffusion adaptation by focusing on the useful case of MSE cost functions of the form (97); still, most of the derivations and arguments in the coming sections can be extended beyond MSE optimization to more general cost functions \u2014 as already shown in [1\u20133]; see also Sec.", "startOffset": 329, "endOffset": 334}, {"referenceID": 1, "context": "It is sufficient in this article to illustrate the main concepts underlying diffusion adaptation by focusing on the useful case of MSE cost functions of the form (97); still, most of the derivations and arguments in the coming sections can be extended beyond MSE optimization to more general cost functions \u2014 as already shown in [1\u20133]; see also Sec.", "startOffset": 329, "endOffset": 334}, {"referenceID": 2, "context": "It is sufficient in this article to illustrate the main concepts underlying diffusion adaptation by focusing on the useful case of MSE cost functions of the form (97); still, most of the derivations and arguments in the coming sections can be extended beyond MSE optimization to more general cost functions \u2014 as already shown in [1\u20133]; see also Sec.", "startOffset": 329, "endOffset": 334}, {"referenceID": 0, "context": "Our strategy to optimize J (w) in a distributed manner is based on two steps, following the developments in [1, 2, 18].", "startOffset": 108, "endOffset": 118}, {"referenceID": 1, "context": "Our strategy to optimize J (w) in a distributed manner is based on two steps, following the developments in [1, 2, 18].", "startOffset": 108, "endOffset": 118}, {"referenceID": 14, "context": "Our strategy to optimize J (w) in a distributed manner is based on two steps, following the developments in [1, 2, 18].", "startOffset": 108, "endOffset": 118}, {"referenceID": 15, "context": "The above substitution amounts to having each node k approximate the {Rl} from its neighbors by multiples of the identity matrix Rl \u2248 blk IM (118) Approximation (117) is reasonable in view of the fact that all vector norms are equivalent [19\u201321]; this norm property ensures that we can bound the weighted norm \u2016w \u2212 wo\u20162Rl by some constants multiplying the un-weighted norm \u2016w \u2212 w\u2016, say, as: r1\u2016w \u2212 w \u2016 \u2264 \u2016w \u2212 wo\u20162Rl \u2264 r2\u2016w \u2212 w \u2016 (119) for some positive constants (r1, r2).", "startOffset": 238, "endOffset": 245}, {"referenceID": 16, "context": "Using the fact that the {Rl} are Hermitian positive-definite matrices, and calling upon the Rayleigh-Ritz characterization of eigenvalues [19, 20], we can be more specific and replace the above inequalities by \u03bbmin(Rl) \u00b7 \u2016w \u2212 w \u2016 \u2264 \u2016w \u2212 wo\u20162Rl \u2264 \u03bbmax(Rl) \u00b7 \u2016w \u2212 w \u2016 (120) We note that approximations similar to (118) are common in stochastic approximation theory and they mark the difference between using a Newton\u2019s iterative method or a stochastic gradient method [5, 22]; the former uses Hessian matrices as approximations for Rl and the latter uses multiples of the identity matrix.", "startOffset": 466, "endOffset": 473}, {"referenceID": 16, "context": "One choice that is common in the optimization literature [5,22,52] is to replace \u03bck in (123) by step-size sequences {\u03bc(i) \u2265 0} that satisfy the two conditions (25).", "startOffset": 57, "endOffset": 66}, {"referenceID": 46, "context": "One choice that is common in the optimization literature [5,22,52] is to replace \u03bck in (123) by step-size sequences {\u03bc(i) \u2265 0} that satisfy the two conditions (25).", "startOffset": 57, "endOffset": 66}, {"referenceID": 17, "context": "This step is reminiscent of incremental-type approaches to optimization, which have been widely studied in the literature [23\u201326].", "startOffset": 122, "endOffset": 129}, {"referenceID": 18, "context": "This step is reminiscent of incremental-type approaches to optimization, which have been widely studied in the literature [23\u201326].", "startOffset": 122, "endOffset": 129}, {"referenceID": 19, "context": "This step is reminiscent of incremental-type approaches to optimization, which have been widely studied in the literature [23\u201326].", "startOffset": 122, "endOffset": 129}, {"referenceID": 20, "context": "This step is reminiscent of incremental-type approaches to optimization, which have been widely studied in the literature [23\u201326].", "startOffset": 122, "endOffset": 129}, {"referenceID": 0, "context": "The significance of this general form is that it is applicable to optimization problems involving more general local costs Jl(w) that are not necessarily quadratic in w, as detailed in [1\u20133] \u2014 see also Sec.", "startOffset": 185, "endOffset": 190}, {"referenceID": 1, "context": "The significance of this general form is that it is applicable to optimization problems involving more general local costs Jl(w) that are not necessarily quadratic in w, as detailed in [1\u20133] \u2014 see also Sec.", "startOffset": 185, "endOffset": 190}, {"referenceID": 2, "context": "The significance of this general form is that it is applicable to optimization problems involving more general local costs Jl(w) that are not necessarily quadratic in w, as detailed in [1\u20133] \u2014 see also Sec.", "startOffset": 185, "endOffset": 190}, {"referenceID": 14, "context": "The derivation of the ATC and CTA strategies (134) and (142) followed the approach proposed in [18,27].", "startOffset": 95, "endOffset": 102}, {"referenceID": 21, "context": "The derivation of the ATC and CTA strategies (134) and (142) followed the approach proposed in [18,27].", "startOffset": 95, "endOffset": 102}, {"referenceID": 29, "context": "CTA estimation schemes were first proposed in the works [35\u201339], and later extended in [18,27,32,33].", "startOffset": 56, "endOffset": 63}, {"referenceID": 30, "context": "CTA estimation schemes were first proposed in the works [35\u201339], and later extended in [18,27,32,33].", "startOffset": 56, "endOffset": 63}, {"referenceID": 31, "context": "CTA estimation schemes were first proposed in the works [35\u201339], and later extended in [18,27,32,33].", "startOffset": 56, "endOffset": 63}, {"referenceID": 32, "context": "CTA estimation schemes were first proposed in the works [35\u201339], and later extended in [18,27,32,33].", "startOffset": 56, "endOffset": 63}, {"referenceID": 33, "context": "CTA estimation schemes were first proposed in the works [35\u201339], and later extended in [18,27,32,33].", "startOffset": 56, "endOffset": 63}, {"referenceID": 14, "context": "CTA estimation schemes were first proposed in the works [35\u201339], and later extended in [18,27,32,33].", "startOffset": 87, "endOffset": 100}, {"referenceID": 21, "context": "CTA estimation schemes were first proposed in the works [35\u201339], and later extended in [18,27,32,33].", "startOffset": 87, "endOffset": 100}, {"referenceID": 26, "context": "CTA estimation schemes were first proposed in the works [35\u201339], and later extended in [18,27,32,33].", "startOffset": 87, "endOffset": 100}, {"referenceID": 27, "context": "CTA estimation schemes were first proposed in the works [35\u201339], and later extended in [18,27,32,33].", "startOffset": 87, "endOffset": 100}, {"referenceID": 29, "context": "The earlier versions of CTA in [35\u201337] used the choice C = I.", "startOffset": 31, "endOffset": 38}, {"referenceID": 30, "context": "The earlier versions of CTA in [35\u201337] used the choice C = I.", "startOffset": 31, "endOffset": 38}, {"referenceID": 31, "context": "The earlier versions of CTA in [35\u201337] used the choice C = I.", "startOffset": 31, "endOffset": 38}, {"referenceID": 34, "context": "This form of the algorithm with C = I, and with the additional constraint that the step-sizes \u03bck should be time-dependent and decay towards zero as time progresses, was later applied by [40,41] to solve distributed optimization problems that require all nodes to reach consensus or agreement.", "startOffset": 186, "endOffset": 193}, {"referenceID": 35, "context": "This form of the algorithm with C = I, and with the additional constraint that the step-sizes \u03bck should be time-dependent and decay towards zero as time progresses, was later applied by [40,41] to solve distributed optimization problems that require all nodes to reach consensus or agreement.", "startOffset": 186, "endOffset": 193}, {"referenceID": 22, "context": "Likewise, special cases of the ATC estimation scheme (134), involving an information exchange step followed by an aggregation step, first appeared in the work [28] on diffusion leastsquares schemes and subsequently in the works [18,29\u201333] on distributed mean-square-error and state-space estimation methods.", "startOffset": 159, "endOffset": 163}, {"referenceID": 14, "context": "Likewise, special cases of the ATC estimation scheme (134), involving an information exchange step followed by an aggregation step, first appeared in the work [28] on diffusion leastsquares schemes and subsequently in the works [18,29\u201333] on distributed mean-square-error and state-space estimation methods.", "startOffset": 228, "endOffset": 238}, {"referenceID": 23, "context": "Likewise, special cases of the ATC estimation scheme (134), involving an information exchange step followed by an aggregation step, first appeared in the work [28] on diffusion leastsquares schemes and subsequently in the works [18,29\u201333] on distributed mean-square-error and state-space estimation methods.", "startOffset": 228, "endOffset": 238}, {"referenceID": 24, "context": "Likewise, special cases of the ATC estimation scheme (134), involving an information exchange step followed by an aggregation step, first appeared in the work [28] on diffusion leastsquares schemes and subsequently in the works [18,29\u201333] on distributed mean-square-error and state-space estimation methods.", "startOffset": 228, "endOffset": 238}, {"referenceID": 25, "context": "Likewise, special cases of the ATC estimation scheme (134), involving an information exchange step followed by an aggregation step, first appeared in the work [28] on diffusion leastsquares schemes and subsequently in the works [18,29\u201333] on distributed mean-square-error and state-space estimation methods.", "startOffset": 228, "endOffset": 238}, {"referenceID": 26, "context": "Likewise, special cases of the ATC estimation scheme (134), involving an information exchange step followed by an aggregation step, first appeared in the work [28] on diffusion leastsquares schemes and subsequently in the works [18,29\u201333] on distributed mean-square-error and state-space estimation methods.", "startOffset": 228, "endOffset": 238}, {"referenceID": 27, "context": "Likewise, special cases of the ATC estimation scheme (134), involving an information exchange step followed by an aggregation step, first appeared in the work [28] on diffusion leastsquares schemes and subsequently in the works [18,29\u201333] on distributed mean-square-error and state-space estimation methods.", "startOffset": 228, "endOffset": 238}, {"referenceID": 28, "context": "A special case of the ATC strategy (134) corresponding to the choice C = I with decaying step-sizes was adopted in [34] to ensure convergence towards a consensus state.", "startOffset": 115, "endOffset": 119}, {"referenceID": 34, "context": "E and [40, 42\u201344].", "startOffset": 6, "endOffset": 17}, {"referenceID": 36, "context": "E and [40, 42\u201344].", "startOffset": 6, "endOffset": 17}, {"referenceID": 37, "context": "E and [40, 42\u201344].", "startOffset": 6, "endOffset": 17}, {"referenceID": 38, "context": "E and [40, 42\u201344].", "startOffset": 6, "endOffset": 17}, {"referenceID": 34, "context": "E and [40, 45\u201351]).", "startOffset": 6, "endOffset": 17}, {"referenceID": 39, "context": "E and [40, 45\u201351]).", "startOffset": 6, "endOffset": 17}, {"referenceID": 40, "context": "E and [40, 45\u201351]).", "startOffset": 6, "endOffset": 17}, {"referenceID": 41, "context": "E and [40, 45\u201351]).", "startOffset": 6, "endOffset": 17}, {"referenceID": 42, "context": "E and [40, 45\u201351]).", "startOffset": 6, "endOffset": 17}, {"referenceID": 43, "context": "E and [40, 45\u201351]).", "startOffset": 6, "endOffset": 17}, {"referenceID": 44, "context": "E and [40, 45\u201351]).", "startOffset": 6, "endOffset": 17}, {"referenceID": 45, "context": "E and [40, 45\u201351]).", "startOffset": 6, "endOffset": 17}, {"referenceID": 4, "context": ", [8\u201310]).", "startOffset": 2, "endOffset": 8}, {"referenceID": 5, "context": ", [8\u201310]).", "startOffset": 2, "endOffset": 8}, {"referenceID": 6, "context": ", [8\u201310]).", "startOffset": 2, "endOffset": 8}, {"referenceID": 16, "context": ", [22, 40, 52, 53]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 34, "context": ", [22, 40, 52, 53]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 46, "context": ", [22, 40, 52, 53]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 47, "context": ", [22, 40, 52, 53]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 0, "context": "Sections 5 and 6 highlight the convergence properties of the diffusion strategies \u2014 see also [1\u20133] for results pertaining to more general cost functions.", "startOffset": 93, "endOffset": 98}, {"referenceID": 1, "context": "Sections 5 and 6 highlight the convergence properties of the diffusion strategies \u2014 see also [1\u20133] for results pertaining to more general cost functions.", "startOffset": 93, "endOffset": 98}, {"referenceID": 2, "context": "Sections 5 and 6 highlight the convergence properties of the diffusion strategies \u2014 see also [1\u20133] for results pertaining to more general cost functions.", "startOffset": 93, "endOffset": 98}, {"referenceID": 4, "context": "In this way, diffusion strategies allow multiple layers of adaptation: the nodes perform adaptive processing, the combination weights can be adapted, and even the topology can be adapted especially for mobile networks [8].", "startOffset": 218, "endOffset": 221}, {"referenceID": 3, "context": "Recall that, by definition, Ru,l \u2206 = Eul,iul,i, rdu,l \u2206 = Edl(i)u \u2217 l,i (149) One common stochastic approximation method is to drop the expectation operator from the definitions of {Ru,l, rdu,l} and to use the following instantaneous approximations instead [4\u20137]: Ru,l \u2248 u \u2217 l,iul,i, rdu,l \u2248 dl(i)u \u2217 l,i (150) In this case, the approximate gradient vectors become: (rdu,l \u2212Ru,l wk,i\u22121) \u2248 u \u2217 l,i [dl(i)\u2212 ul,i wk,i\u22121] (151) (rdu,l \u2212Ru,l \u03c8k,i\u22121) \u2248 u \u2217 l,i [dl(i)\u2212 ul,i \u03c8k,i\u22121] (152) Substituting into the ATC and CTA steepest-descent strategies (134) and (142), we arrive at the following adaptive implementations of the diffusion strategies for i \u2265 0:", "startOffset": 257, "endOffset": 262}, {"referenceID": 1, "context": "The significance of the alternative forms (156)\u2013(157) is that they are applicable to optimization problems involving more general local costs Jl(w) that are not necessarily quadratic, as detailed in [2, 3]; see also Sec.", "startOffset": 199, "endOffset": 205}, {"referenceID": 2, "context": "The significance of the alternative forms (156)\u2013(157) is that they are applicable to optimization problems involving more general local costs Jl(w) that are not necessarily quadratic, as detailed in [2, 3]; see also Sec.", "startOffset": 199, "endOffset": 205}, {"referenceID": 3, "context": "Furthermore, the choice A1 = A2 = C = IN corresponds to the non-cooperative mode of operation, in which case the recursions reduce to the classical (stand-alone) steepest-descent recursion [4\u20137], where each node minimizes individually its own quadratic cost Jk(w), defined earlier in (97): wk,i = wk,i\u22121 + \u03bck [rdu,k \u2212Ru,k wk,i\u22121] , i \u2265 0 (171)", "startOffset": 189, "endOffset": 194}, {"referenceID": 3, "context": "Furthermore, the choice A1 = A2 = C = IN corresponds to the non-cooperative mode of operation, where each node runs the classical (stand-alone) least-mean-squares (LMS) filter independently of the other nodes: [4\u20137]: wk,i = wk,i\u22121 + \u03bckuk,i [dk(i)\u2212 uk,i wk,i\u22121] , i \u2265 0 (207)", "startOffset": 210, "endOffset": 215}, {"referenceID": 50, "context": "The approach we follow is based on the energy conservation framework of [4, 5, 57].", "startOffset": 72, "endOffset": 82}, {"referenceID": 14, "context": "While we can continue with the analysis by taking this factor into account, as was done in [4, 5, 18, 57], it is sufficient for the exposition in this article to focus on the case of sufficiently small step-sizes where terms involving higher powers of the step-sizes can be ignored.", "startOffset": 91, "endOffset": 105}, {"referenceID": 50, "context": "While we can continue with the analysis by taking this factor into account, as was done in [4, 5, 18, 57], it is sufficient for the exposition in this article to focus on the case of sufficiently small step-sizes where terms involving higher powers of the step-sizes can be ignored.", "startOffset": 91, "endOffset": 105}, {"referenceID": 14, "context": "The relation can be transformed into a true recursion by expanding it into a convenient state-space model; this argument was pursued in [4, 5, 18, 57] and is not necessary for the exposition here, except to say that stability of the matrix F ensures the mean-square stability of the filter \u2014 this fact is also established further ahead through relation (327).", "startOffset": 136, "endOffset": 150}, {"referenceID": 50, "context": "The relation can be transformed into a true recursion by expanding it into a convenient state-space model; this argument was pursued in [4, 5, 18, 57] and is not necessary for the exposition here, except to say that stability of the matrix F ensures the mean-square stability of the filter \u2014 this fact is also established further ahead through relation (327).", "startOffset": 136, "endOffset": 150}, {"referenceID": 14, "context": "Then, expressions (307) and (309) give: Bcta = (I \u2212MR)A T , Ycta = MC SCM (335) Batc = A T (I \u2212MR), Yatc = A MCSCMA (336) where A = A\u2297 IM (337) Following [18], introduce the auxiliary nonnegative-definite matrix Hj \u2206 = [ (I \u2212MR)A ]j \u00b7MCSCM \u00b7 [ (I \u2212MR)A ]\u2217j (338)", "startOffset": 154, "endOffset": 158}, {"referenceID": 57, "context": "B, namely, it is a symmetric matrix whose entries are constructed as follows [64\u201366]:", "startOffset": 77, "endOffset": 84}, {"referenceID": 59, "context": "Averaging rule [68]:", "startOffset": 15, "endOffset": 19}, {"referenceID": 43, "context": "Laplacian rule [49,69]: A = IN \u2212 \u03b3L, \u03b3 > 0 symmetric and doubly-stochastic", "startOffset": 15, "endOffset": 22}, {"referenceID": 60, "context": "Laplacian rule [49,69]: A = IN \u2212 \u03b3L, \u03b3 > 0 symmetric and doubly-stochastic", "startOffset": 15, "endOffset": 22}, {"referenceID": 44, "context": "Laplacian rule using \u03b3 = 1/N(maximum-degree rule [50]) :", "startOffset": 49, "endOffset": 53}, {"referenceID": 43, "context": "Metropolis rule [49,70,71]:", "startOffset": 16, "endOffset": 26}, {"referenceID": 61, "context": "Metropolis rule [49,70,71]:", "startOffset": 16, "endOffset": 26}, {"referenceID": 62, "context": "Metropolis rule [49,70,71]:", "startOffset": 16, "endOffset": 26}, {"referenceID": 23, "context": "Relative-degree rule [29]:", "startOffset": 21, "endOffset": 25}, {"referenceID": 48, "context": "While such selections may be appropriate in some applications, they can nevertheless degrade the performance of adaptation over networks [54].", "startOffset": 137, "endOffset": 141}, {"referenceID": 51, "context": "For this reason, following [58, 62], we describe in the next subsection one adaptive procedure for adjusting the combination weights.", "startOffset": 27, "endOffset": 35}, {"referenceID": 55, "context": "For this reason, following [58, 62], we describe in the next subsection one adaptive procedure for adjusting the combination weights.", "startOffset": 27, "endOffset": 35}, {"referenceID": 14, "context": "In [18], the selection of the combination weights was formulated as the following optimization problem:", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "We can pursue a numerical solution to (374) in order to search for optimal combination matrices, as was done in [18].", "startOffset": 112, "endOffset": 116}, {"referenceID": 51, "context": "We illustrate an approximate approach from [58,62] that leads to one adaptive solution that performs reasonably well in practice.", "startOffset": 43, "endOffset": 50}, {"referenceID": 55, "context": "We illustrate an approximate approach from [58,62] that leads to one adaptive solution that performs reasonably well in practice.", "startOffset": 43, "endOffset": 50}, {"referenceID": 51, "context": "We refer to this combination rule as the relative-variance combination rule [58]; it leads to a left-stochastic matrix A.", "startOffset": 76, "endOffset": 80}, {"referenceID": 14, "context": "In comparison, the following relativedegree-variance rule was proposed in [18] (a typo appears in Table III in [18], where the noise variances appear written in the table instead of their inverses):", "startOffset": 74, "endOffset": 78}, {"referenceID": 14, "context": "In comparison, the following relativedegree-variance rule was proposed in [18] (a typo appears in Table III in [18], where the noise variances appear written in the table instead of their inverses):", "startOffset": 111, "endOffset": 115}, {"referenceID": 52, "context": "We may note that some studies on the effect of imperfect data exchanges on the performance of adaptive diffusion algorithms are considered in [59\u201361].", "startOffset": 142, "endOffset": 149}, {"referenceID": 53, "context": "We may note that some studies on the effect of imperfect data exchanges on the performance of adaptive diffusion algorithms are considered in [59\u201361].", "startOffset": 142, "endOffset": 149}, {"referenceID": 54, "context": "We may note that some studies on the effect of imperfect data exchanges on the performance of adaptive diffusion algorithms are considered in [59\u201361].", "startOffset": 142, "endOffset": 149}, {"referenceID": 55, "context": "Although we can continue our analysis by studying this general case in which the vectors zi do not have zero-mean (see [62,63]), we shall nevertheless limit our discussion in the sequel to the case in which there is no noise during the exchange of the regression data, i.", "startOffset": 119, "endOffset": 126}, {"referenceID": 56, "context": "Although we can continue our analysis by studying this general case in which the vectors zi do not have zero-mean (see [62,63]), we shall nevertheless limit our discussion in the sequel to the case in which there is no noise during the exchange of the regression data, i.", "startOffset": 119, "endOffset": 126}, {"referenceID": 55, "context": ", the presence of noise during the exchange of regression data alters the dynamics of the mean error vector in an important way \u2014 see [62, 63] for details on how to extend the arguments to this general case with a driving non-zero bias term.", "startOffset": 134, "endOffset": 142}, {"referenceID": 56, "context": ", the presence of noise during the exchange of regression data alters the dynamics of the mean error vector in an important way \u2014 see [62, 63] for details on how to extend the arguments to this general case with a driving non-zero bias term.", "startOffset": 134, "endOffset": 142}, {"referenceID": 51, "context": "We continue to refer to this combination rule as the relative-variance combination rule [58]; it leads to a left-stochastic matrix A.", "startOffset": 88, "endOffset": 92}, {"referenceID": 64, "context": "3 and 4 to (488) and arrive at the following version of a diffusion strategy incorporating temporal processing (or smoothing) of the intermediate weight estimates [73, 74]:", "startOffset": 163, "endOffset": 171}, {"referenceID": 65, "context": "3 and 4 to (488) and arrive at the following version of a diffusion strategy incorporating temporal processing (or smoothing) of the intermediate weight estimates [73, 74]:", "startOffset": 163, "endOffset": 171}, {"referenceID": 64, "context": "This step is carried out in [73, 74] for doubly stochastic combination matrices A", "startOffset": 28, "endOffset": 36}, {"referenceID": 65, "context": "This step is carried out in [73, 74] for doubly stochastic combination matrices A", "startOffset": 28, "endOffset": 36}, {"referenceID": 65, "context": "For instance, it is shown in [74] that whether temporal processing is performed before or after adaptation, the strategy that performs adaptation before spatial cooperation is always better.", "startOffset": 29, "endOffset": 33}, {"referenceID": 66, "context": "In related work, reference [75] started from the CTA algorithm (159) without information exchange and added a useful projection step to it between the combination step and the adaptation step; i.", "startOffset": 27, "endOffset": 31}, {"referenceID": 66, "context": "from [75] has the following form: \u03c6k,i\u22121 = \u2211 l\u2208Nk alk wl,i\u22121 (500)", "startOffset": 5, "endOffset": 9}, {"referenceID": 67, "context": "For generic values {d, u, \u01eb}, where d is a scalar and u is a row vector, the projection operator is described analytically by the following expression [76]:", "startOffset": 151, "endOffset": 155}, {"referenceID": 22, "context": "2 Diffusion Recursive Least-Squares Diffusion strategies can also be applied to recursive least-squares problems to enable distributed solutions of least-squares designs [28,29]; see also [72].", "startOffset": 170, "endOffset": 177}, {"referenceID": 23, "context": "2 Diffusion Recursive Least-Squares Diffusion strategies can also be applied to recursive least-squares problems to enable distributed solutions of least-squares designs [28,29]; see also [72].", "startOffset": 170, "endOffset": 177}, {"referenceID": 63, "context": "2 Diffusion Recursive Least-Squares Diffusion strategies can also be applied to recursive least-squares problems to enable distributed solutions of least-squares designs [28,29]; see also [72].", "startOffset": 188, "endOffset": 192}, {"referenceID": 22, "context": "In [28, 29] a diffusion strategy was developed that allows nodes to approach the global solution wi by relying solely on local interactions.", "startOffset": 3, "endOffset": 11}, {"referenceID": 23, "context": "In [28, 29] a diffusion strategy was developed that allows nodes to approach the global solution wi by relying solely on local interactions.", "startOffset": 3, "endOffset": 11}, {"referenceID": 23, "context": "The mean-square performance and convergence of the diffusion RLS strategy are studied in some detail in [29].", "startOffset": 104, "endOffset": 108}, {"referenceID": 69, "context": "Under some approximations, and for the special choices A = C and \u03bb = 1, the diffusion RLS strategy (520) can be reduced to a form given in [79] and which is described by the following equations: P k,i = \u2211", "startOffset": 139, "endOffset": 143}, {"referenceID": 69, "context": "\u03c8k,i = Pk,iqk,i (523) Algorithm (521)\u2013(523) is motivated in [79] by using consensus-type arguments.", "startOffset": 60, "endOffset": 64}, {"referenceID": 69, "context": "Comparing these equations with (521)\u2013(523), we find that algorithm (521)\u2013(523) of [79] would relate to the diffusion RLS algorithm (520) when the following approximations are justified: \u2211", "startOffset": 82, "endOffset": 86}, {"referenceID": 23, "context": "l\u2208Nk clk\u03c8l,i\u22121 (527) = P k,i\u22121wk,i\u22121 (528) It was indicated in [29] that the diffusion RLS implementation (514) or (520) leads to enhanced performance in comparison to the consensus-based update (521)\u2013(523).", "startOffset": 63, "endOffset": 67}, {"referenceID": 24, "context": "3 Diffusion Kalman Filtering Diffusion strategies can also be applied to the solution of distributed state-space filtering and smoothing problems [30, 31, 33].", "startOffset": 146, "endOffset": 158}, {"referenceID": 25, "context": "3 Diffusion Kalman Filtering Diffusion strategies can also be applied to the solution of distributed state-space filtering and smoothing problems [30, 31, 33].", "startOffset": 146, "endOffset": 158}, {"referenceID": 27, "context": "3 Diffusion Kalman Filtering Diffusion strategies can also be applied to the solution of distributed state-space filtering and smoothing problems [30, 31, 33].", "startOffset": 146, "endOffset": 158}, {"referenceID": 27, "context": "Here, we describe briefly the diffusion version of the Kalman filter; other variants and smoothing filters can be found in [33].", "startOffset": 123, "endOffset": 127}, {"referenceID": 24, "context": "The following diffusion strategy was proposed in [30, 31, 33] to evaluate approximate predicted and filtered versions of these local estimators in a distributed manner for data satisfying model (529)\u2013(532).", "startOffset": 49, "endOffset": 61}, {"referenceID": 25, "context": "The following diffusion strategy was proposed in [30, 31, 33] to evaluate approximate predicted and filtered versions of these local estimators in a distributed manner for data satisfying model (529)\u2013(532).", "startOffset": 49, "endOffset": 61}, {"referenceID": 27, "context": "The following diffusion strategy was proposed in [30, 31, 33] to evaluate approximate predicted and filtered versions of these local estimators in a distributed manner for data satisfying model (529)\u2013(532).", "startOffset": 49, "endOffset": 61}, {"referenceID": 27, "context": "It is important to note that even though the notation Pk,i|i and Pk,i|i\u22121 has been retained for these variables, as in the standard Kalman filtering notation [5,77], these matrices do not represent any longer the covariances of the state estimation errors, x\u0303k,i|i\u22121 = xi \u2212 x\u0302k,i|i\u22121, but can be related to them [33].", "startOffset": 312, "endOffset": 316}, {"referenceID": 42, "context": "The incremental update in (535) is similar to the update used in the distributed Kalman filter derived in [48].", "startOffset": 106, "endOffset": 110}, {"referenceID": 42, "context": "Reference [48] starts from a continuous-time consensus implementation and discretizes it to arrive at the following update relation: x\u0302k,i|i = \u03c8k,i + \u01eb \u2211 l\u2208Nk (\u03c8l,i \u2212\u03c8k,i) (536)", "startOffset": 10, "endOffset": 14}, {"referenceID": 27, "context": "D of [33].", "startOffset": 5, "endOffset": 9}, {"referenceID": 27, "context": "It was verified in [33] that the diffusion implementation (538) leads to enhanced performance in comparison to the consensus-based update (537).", "startOffset": 19, "endOffset": 23}, {"referenceID": 68, "context": "Moreover, the weights {alk} in (538) can also be adjusted over time in order to further enhance performance, as discussed in [78].", "startOffset": 125, "endOffset": 129}, {"referenceID": 27, "context": "The mean-square performance and convergence of the diffusion Kalman filtering implementations are studied in some detail in [33], along with other diffusion strategies for smoothing problems including fixed-point and fixed-lag smoothing.", "startOffset": 124, "endOffset": 128}, {"referenceID": 0, "context": "Nevertheless, we remarked in that section that similar diffusion strategies can be applied to more general cases involving individual cost functions, Jk(w), that are not necessarily quadratic in w [1\u20133].", "startOffset": 197, "endOffset": 202}, {"referenceID": 1, "context": "Nevertheless, we remarked in that section that similar diffusion strategies can be applied to more general cases involving individual cost functions, Jk(w), that are not necessarily quadratic in w [1\u20133].", "startOffset": 197, "endOffset": 202}, {"referenceID": 2, "context": "Nevertheless, we remarked in that section that similar diffusion strategies can be applied to more general cases involving individual cost functions, Jk(w), that are not necessarily quadratic in w [1\u20133].", "startOffset": 197, "endOffset": 202}, {"referenceID": 0, "context": "The following properties can be proven for the diffusion strategies (545)\u2013(547) [1\u20133].", "startOffset": 80, "endOffset": 85}, {"referenceID": 1, "context": "The following properties can be proven for the diffusion strategies (545)\u2013(547) [1\u20133].", "startOffset": 80, "endOffset": 85}, {"referenceID": 2, "context": "The following properties can be proven for the diffusion strategies (545)\u2013(547) [1\u20133].", "startOffset": 80, "endOffset": 85}, {"referenceID": 0, "context": "The case where the {Jk(w)} have different individual minimizers is studied in [1,3], where it is shown that the same diffusion strategies of this section are still applicable and nodes would converge instead to a Pareto-optimal solution.", "startOffset": 78, "endOffset": 83}, {"referenceID": 2, "context": "The case where the {Jk(w)} have different individual minimizers is studied in [1,3], where it is shown that the same diffusion strategies of this section are still applicable and nodes would converge instead to a Pareto-optimal solution.", "startOffset": 78, "endOffset": 83}, {"referenceID": 34, "context": ", [40, 80]), the norms of the sub-gradients are usually required to be uniformly bounded.", "startOffset": 2, "endOffset": 10}, {"referenceID": 70, "context": ", [40, 80]), the norms of the sub-gradients are usually required to be uniformly bounded.", "startOffset": 2, "endOffset": 10}, {"referenceID": 34, "context": "This condition on the noise is more general than the \u201cuniform-bounded assumption\u201d that appears in [40], which required instead:", "startOffset": 98, "endOffset": 102}, {"referenceID": 71, "context": "3) in [81], which requires the noise variance to satisfy:", "startOffset": 6, "endOffset": 10}, {"referenceID": 16, "context": "This requirement can be verified to be a combination of the \u201crelative random noise\u201d and the \u201cabsolute random noise\u201d conditions defined in [22] \u2014 see [2].", "startOffset": 138, "endOffset": 142}, {"referenceID": 1, "context": "This requirement can be verified to be a combination of the \u201crelative random noise\u201d and the \u201cabsolute random noise\u201d conditions defined in [22] \u2014 see [2].", "startOffset": 149, "endOffset": 152}, {"referenceID": 1, "context": ", w\u0303i,N} (562) where w\u0303k,i \u2206 = w \u2212wk,i (563) Then, the following result can be established [2]; it characterizes the network mean-square deviation in steady-state, which is defined as", "startOffset": 91, "endOffset": 94}, {"referenceID": 57, "context": "The matrix L is symmetric and its entries are defined as follows [64\u201366]:", "startOffset": 65, "endOffset": 72}, {"referenceID": 57, "context": "The following is a classical result from graph theory [64\u201367].", "startOffset": 54, "endOffset": 61}, {"referenceID": 58, "context": "The following is a classical result from graph theory [64\u201367].", "startOffset": 54, "endOffset": 61}, {"referenceID": 0, "context": "(d) The eigenvalues of AA or AA are real and lie inside the interval [0, 1].", "startOffset": 69, "endOffset": 75}, {"referenceID": 0, "context": "But since \u03c1(AA ) = 1, we must have \u03bb(AA ) \u2208 [0, 1].", "startOffset": 44, "endOffset": 50}, {"referenceID": 0, "context": "For part (f), since AA \u2265 0 and its eigenvalues lie within [0, 1], the matrix AA admits an eigen-decomposition of the form: AA = U\u039bU where U is orthogonal (i.", "startOffset": 58, "endOffset": 64}, {"referenceID": 0, "context": ", U = U ) and \u039b is diagonal with entries in the range [0, 1].", "startOffset": 54, "endOffset": 60}, {"referenceID": 46, "context": "Following [52, 54, 55], the block maximum norm of x is denoted by \u2016x\u2016b,\u221e and is defined as", "startOffset": 10, "endOffset": 22}, {"referenceID": 48, "context": "Following [52, 54, 55], the block maximum norm of x is denoted by \u2016x\u2016b,\u221e and is defined as", "startOffset": 10, "endOffset": 22}, {"referenceID": 49, "context": "Following [52, 54, 55], the block maximum norm of x is denoted by \u2016x\u2016b,\u221e and is defined as", "startOffset": 10, "endOffset": 22}, {"referenceID": 48, "context": "The block maximum norm inherits the unitary invariance property of the Euclidean norm, as the following result indicates [54].", "startOffset": 121, "endOffset": 125}, {"referenceID": 15, "context": "To establish part (c), we start by recalling that all norms on finite-dimensional vector spaces are equivalent [20,21].", "startOffset": 111, "endOffset": 118}, {"referenceID": 1, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 4, "endOffset": 15}, {"referenceID": 0, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 4, "endOffset": 15}, {"referenceID": 0, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 23, "endOffset": 42}, {"referenceID": 2, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 23, "endOffset": 42}, {"referenceID": 1, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 23, "endOffset": 42}, {"referenceID": 2, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 23, "endOffset": 42}, {"referenceID": 1, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 23, "endOffset": 42}, {"referenceID": 2, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 23, "endOffset": 42}, {"referenceID": 0, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 23, "endOffset": 42}, {"referenceID": 2, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 23, "endOffset": 42}, {"referenceID": 0, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 50, "endOffset": 69}, {"referenceID": 2, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 50, "endOffset": 69}, {"referenceID": 1, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 50, "endOffset": 69}, {"referenceID": 2, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 50, "endOffset": 69}, {"referenceID": 1, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 50, "endOffset": 69}, {"referenceID": 2, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 50, "endOffset": 69}, {"referenceID": 0, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 50, "endOffset": 69}, {"referenceID": 2, "context": "D = [ 2 0 0 1 ] , A1 = [ 1 3 2 3 2 3 1 3 ] , A2 = [ 1 3 2 3 2 3 1 3 ]", "startOffset": 50, "endOffset": 69}, {"referenceID": 1, "context": "A2 DA T 1 = [ 2 3 2 3 2 3 1 ]", "startOffset": 12, "endOffset": 29}, {"referenceID": 2, "context": "A2 DA T 1 = [ 2 3 2 3 2 3 1 ]", "startOffset": 12, "endOffset": 29}, {"referenceID": 1, "context": "A2 DA T 1 = [ 2 3 2 3 2 3 1 ]", "startOffset": 12, "endOffset": 29}, {"referenceID": 2, "context": "A2 DA T 1 = [ 2 3 2 3 2 3 1 ]", "startOffset": 12, "endOffset": 29}, {"referenceID": 1, "context": "A2 DA T 1 = [ 2 3 2 3 2 3 1 ]", "startOffset": 12, "endOffset": 29}, {"referenceID": 2, "context": "A2 DA T 1 = [ 2 3 2 3 2 3 1 ]", "startOffset": 12, "endOffset": 29}, {"referenceID": 0, "context": "A2 DA T 1 = [ 2 3 2 3 2 3 1 ]", "startOffset": 12, "endOffset": 29}, {"referenceID": 14, "context": "I of [18] and Lemma 2 of [33].", "startOffset": 5, "endOffset": 9}, {"referenceID": 27, "context": "I of [18] and Lemma 2 of [33].", "startOffset": 25, "endOffset": 29}, {"referenceID": 14, "context": "I of [18] and the matrix M in Lemma 2 of [33] are block diagonal, the \u2016 \u00b7 \u2016b,\u221e norm should replace the \u2016 \u00b7 \u2016\u03c1 norm used there, as in the proof that led to (606) and as already done in [54].", "startOffset": 5, "endOffset": 9}, {"referenceID": 27, "context": "I of [18] and the matrix M in Lemma 2 of [33] are block diagonal, the \u2016 \u00b7 \u2016b,\u221e norm should replace the \u2016 \u00b7 \u2016\u03c1 norm used there, as in the proof that led to (606) and as already done in [54].", "startOffset": 41, "endOffset": 45}, {"referenceID": 48, "context": "I of [18] and the matrix M in Lemma 2 of [33] are block diagonal, the \u2016 \u00b7 \u2016b,\u221e norm should replace the \u2016 \u00b7 \u2016\u03c1 norm used there, as in the proof that led to (606) and as already done in [54].", "startOffset": 184, "endOffset": 188}, {"referenceID": 36, "context": "Convergence Conditions The following result is a classical result on consensus strategies [42\u201344].", "startOffset": 90, "endOffset": 97}, {"referenceID": 37, "context": "Convergence Conditions The following result is a classical result on consensus strategies [42\u201344].", "startOffset": 90, "endOffset": 97}, {"referenceID": 38, "context": "Convergence Conditions The following result is a classical result on consensus strategies [42\u201344].", "startOffset": 90, "endOffset": 97}, {"referenceID": 46, "context": "Now, motivated by the consensus iteration (610), and based on a procedure for distributed optimization suggested in [52] (see expression (7.", "startOffset": 116, "endOffset": 120}, {"referenceID": 39, "context": ", [45, 53, 82\u201388]) considered distributed strategies that correspond to the following form for the optimization problem under consideration (see, e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 47, "context": ", [45, 53, 82\u201388]) considered distributed strategies that correspond to the following form for the optimization problem under consideration (see, e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 72, "context": ", [45, 53, 82\u201388]) considered distributed strategies that correspond to the following form for the optimization problem under consideration (see, e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 73, "context": ", [45, 53, 82\u201388]) considered distributed strategies that correspond to the following form for the optimization problem under consideration (see, e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 74, "context": ", [45, 53, 82\u201388]) considered distributed strategies that correspond to the following form for the optimization problem under consideration (see, e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 75, "context": ", [45, 53, 82\u201388]) considered distributed strategies that correspond to the following form for the optimization problem under consideration (see, e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 76, "context": ", [45, 53, 82\u201388]) considered distributed strategies that correspond to the following form for the optimization problem under consideration (see, e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 77, "context": ", [45, 53, 82\u201388]) considered distributed strategies that correspond to the following form for the optimization problem under consideration (see, e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 78, "context": ", [45, 53, 82\u201388]) considered distributed strategies that correspond to the following form for the optimization problem under consideration (see, e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 47, "context": "20) in [53] and expression (9) in [87]):", "startOffset": 7, "endOffset": 11}, {"referenceID": 77, "context": "20) in [53] and expression (9) in [87]):", "startOffset": 34, "endOffset": 38}], "year": 2013, "abstractText": "Adaptive networks are well-suited to perform decentralized information processing and optimization tasks and to model various types of self-organized and complex behavior encountered in nature. Adaptive networks consist of a collection of agents with processing and learning abilities. The agents are linked together through a connection topology, and they cooperate with each other through local interactions to solve distributed optimization, estimation, and inference problems in real-time. The continuous diffusion of information across the network enables agents to adapt their performance in relation to streaming data and network conditions; it also results in improved adaptation and learning performance relative to non-cooperative agents. This article provides an overview of diffusion strategies for adaptation and learning over networks. The article is divided into several sections: 1. Motivation. 2. Mean-Square-Error Estimation. 3. Distributed Optimization via Diffusion Strategies. 4. Adaptive Diffusion Strategies. 5. Performance of Steepest-Descent Diffusion Strategies. 6. Performance of Adaptive Diffusion Strategies. 7. Comparing the Performance of Cooperative Strategies. 8. Selecting the Combination Weights. 9. Diffusion with Noisy Information Exchanges. 10. Extensions and Further Considerations. 11. Appendix A: Properties of Kronecker Products. 12. Appendix B: Graph Laplacian and Network Connectivity. 13. Appendix C: Stochastic Matrices. 14. Appendix D: Block Maximum Norm. 15. Appendix E: Comparison with Consensus Strategies. 16. References.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}