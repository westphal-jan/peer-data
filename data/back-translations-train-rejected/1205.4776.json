{"id": "1205.4776", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2012", "title": "Visual and semantic interpretability of projections of high dimensional data for classification tasks", "abstract": "A number of visual quality measures have been introduced in visual analytics literature in order to automatically select the best views of high dimensional data from a large number of candidate data projections. These methods generally concentrate on the interpretability of the visualization and pay little attention to the interpretability of the projection axes. In this paper, we argue that interpretability of the visualizations and the feature transformation functions are both crucial for visual exploration of high dimensional labeled data. We present a two-part user study to examine these two related but orthogonal aspects of interpretability. We first study how humans judge the quality of 2D scatterplots of various datasets with varying number of classes and provide comparisons with ten automated measures, including a number of visual quality measures and related measures from various machine learning fields. We then investigate how the user perception on interpretability of mathematical expressions relate to various automated measures of complexity that can be used to characterize data projection functions. We conclude with a discussion of how automated measures of visual and semantic interpretability of data projections can be used together for exploratory analysis in classification tasks.", "histories": [["v1", "Tue, 22 May 2012 00:10:45 GMT  (736kb,D)", "http://arxiv.org/abs/1205.4776v1", "Longer version of the VAST 2011 poster.this http URL"]], "COMMENTS": "Longer version of the VAST 2011 poster.this http URL", "reviews": [], "SUBJECTS": "cs.HC cs.LG", "authors": ["ilknur icke", "andrew rosenberg"], "accepted": false, "id": "1205.4776"}, "pdf": {"name": "1205.4776.pdf", "metadata": {"source": "CRF", "title": "Visual and semantic interpretability of projections of high dimensional data for classification tasks", "authors": ["Ilknur Icke", "Andrew Rosenberg"], "emails": ["iicke@gc.cuny.edu", "andrew@cs.qc.cuny.edu"], "sections": [{"heading": null, "text": "These methods generally focus on the interpretability of visualization and pay little attention to the interpretability of the projection axes. In this paper, we argue that both the interpretability of visualizations and the functions of function transformation are critical to the visual exploration of high-dimensionally labeled data. We present a two-part user study to examine these two related but orthogonal aspects of interpretability. We first examine how humans evaluate the quality of 2D scatter plots of different datasets with different numbers of classes and offer comparisons with ten automated metrics, including a set of visual quality measurements and related metrics from different machine learning fields. We then examine how user perception relates to the interpretability of mathematical expressions in relation to various automated measures of complexity that can be used to characterize data projection functions."}, {"heading": "1 INTRODUCTION", "text": "In fact, we are able to go in search of a solution that is capable of finding a solution that meets the needs of the people."}, {"heading": "2 RELATED WORK", "text": "The task of selecting interesting and good views of datasets becomes more difficult as dimensionality increases. For sufficiently large dimensional datasets, manual exploration of the space of views is impractical. In the case of labeled data, the degree of curiosity is related to how easy it is to distinguish the classes from each other by looking at visualizations of algorithms. Searching for informative projections of datasets that are looking for described data is based on the terminology of people suggested by humans. Xiv: 120 5.47 76v1 [cs.HC] 2 212are evaluated by a nearest neighbor classifier. The authors claim that almost perfect match between human judgment and the VizRank algorithm is achieved through a user study using six datasets."}, {"heading": "3 VISUAL INTERPRETABILITY USER STUDY", "text": "We developed computer software that performed the data visualization experiment automatically and without the intervention of the examiner. In this section, we present the details of the design and execution of the study, as well as our insights into how well the automated metrics correspond to the human perception of visual interpretability."}, {"heading": "3.1 Participants", "text": "We recruited 20 participants (13 men and 7 women) who had graduated or were pursuing a degree in natural sciences such as computer science, physics, biology, engineering, accounting and psychology. At the beginning of the study, participants were asked to complete a short questionnaire asking about their course work or experience in this field. 14 of the participants reported having completed a course in statistics, data mining or machine learning."}, {"heading": "3.2 Datasets and Visual Interpretability Measures", "text": "We selected four commonly used data sets in the field of data collection and visual analysis (Table 1), which were selected because they contain different classes from 2 to 9 that enable us to study how the number and shape of classes affects the relationship between human perception and automated metrics. Segment data contain 30 measurements that characterize malignant or benign tumors. Wine data sets contain 13 attributes that relate to the chemical properties of wines from three different regions. Segment data sets contain 19 characteristics derived from images of seven types of scenes (sky, leaves, cement, window, grass)."}, {"heading": "3.3 Wrapper Methods", "text": "The aim of a supervised learning algorithm is to build a model from the observed data to correctly predict the class affiliation of an invisible data element. Classification algorithms can generally be divided into two categories: generative and discriminatory [21]. Generative methods aim to derive probability models that generate the data points for each class. These discriminatory methods aim to directly learn a mapping between the characteristics and the class names. Regardless of the method used, the common goal of a classification algorithm is to differentiate class members as accurately as possible. Selecting suitable characteristics improves the performance of classifiers. Therefore, classification performance is used to assess the usefulness of feature sets in wrapper-based feature selection schemes [16]. Wrapper-based feature selection methods can be used to assess the quality of 2D scatter plots of the designated data."}, {"heading": "3.3.1 k-Nearest Neighbors (k-NN) Algorithm", "text": "In the k-Nearest Neighbors algorithm, the class name of a data point is predicted on the basis of a tuning mechanism weighted by the distances to its nearest k neighbors. Distance is generally the Euclidean metric. The k-Nearest Neighbors algorithm was also used in Vizrank [27] to assess the quality of scatter plots. in our experiments, we chose k as \u221a N as in Vizrank, where N is the number of data points."}, {"heading": "3.3.2 Decision Tree (J48) Algorithm", "text": "The algorithm builds a tree structure in which each internal node represents a condition that divides the dataset into multiple partitions in terms of a measure of partition impurity like entropy. Due to this partitioning, the decision boundaries are orthogonal to the attribute axes (Figure 2). In our experiments, we used the Weka implementation of the decision tree algorithm known as J48 [3]."}, {"heading": "3.3.3 Naive Bayes Algorithm", "text": "The Naive Bayes Algorithm is a generative classification method that calculates the common class density for each class separately. Assuming that all attributes are conditionally independent of each other greatly simplifies the algorithm. Despite this simplicity, it is known that the Naive Bayes Algorithm outperforms more complex classification algorithms on a variety of problems [13]."}, {"heading": "3.3.4 Support Vector Machine (SMO) Algorithm", "text": "In its simplest form, the Support Vector Machine is a machine learning technique that looks for a hyperplane that separates the classes by the maximum margin for a two-class problem. In our experiments, we used the multi-level Weka implementation based on Sequential Minimal Optimization (SMO) [3]."}, {"heading": "3.4 Cluster Validity Indices", "text": "Data clustering is a well-known problem in machine learning when categorizing multidimensional data into natural groups, so that items in the same group are more similar to each other than items from other groups. To quantify the quality of the outcome of these cluster validity indices, a number of methods have been proposed. The unifying theme of these cluster validity indices is that they all aim to measure compactness and well-separation of class structures by a distance measure and they are susceptible to outliers. Detailed overview of validity indices can be found in [12, 20]. 3.4.1 C Index (IC) The C index is a cluster validation index defined in [14]: IC = SD \u2212 SDminSDmax \u2212 classes."}, {"heading": "3.5 Visual Quality Measures", "text": "In this section, we discuss three methods introduced in the visual analysis literature: Measuring class consistency and measuring the histogram's 2D density have proven to be the closest to human perception among the four measures of visual quality proposed by a user study [24]. Therefore, we included these measures in our experiments.The LDA Index (ILDA) is based on Fisher's discriminatory analysis and was introduced in [18] for exploratory projection of classification problems: ILDA = | W | W + B | B = k = i = 1 ni (V-i. \u2212 V-V..) (V-i..) \"W = k-i = 1ni-j = 1 (Vi j \u2212 V-i.) (Vi j \u2212 V-i.)\" where Vi j are data points, V-i and V-i.. are group and dataset centroids, k is the number of groups (the group value, the group value, the number of the ILi is the number of classes)."}, {"heading": "3.5.2 Class Consistency Measure (CCM)", "text": "The measurement of class consistency measurement (CCM) was proposed in [22] and is based on maintaining proximity to class centroid after a projection from the original data space into a 2D view. A data point is considered contradictory if the projection places it closer to a class other than its own centroid. CCM evaluates each view according to how many consistent points it contains: CCM = 1 \u2212 k c = 1 CC (xc) MCC = {1 if d (xc, x-c) < d (xc, x-i), 1 \u2264 i \u2264 k, i 6 = c 0, elsewhere M the total number of data points, k the number of classes, xc a point in class c and x-c, x-i projections of the center of classes c and i. The CCM returns values between 0 and 1, where smaller values show more consistent views."}, {"heading": "3.5.3 2D Histogram Density Measure (2D-HDM)", "text": "The measure of histogram density (HDM) proposed in [23] is a measure of class separation based on 2D histograms calculated on 2D scatter plots of data. A weighted sum of entropy of each garbage and its immediate neighbors (uc) is calculated as follows: 2D \u2212 HDM = 1 Z \u2211 x, y \u2211 c uc (\u2212 \u2211 c uc \u2211 c log2 uc \u2211 c uc) 1 Z = 1 log2M \u2211 x, y \u2211 c ucwhere 1Z is a normalization factor to limit values within the [0-1] range and smaller values indicate better data separation. The choice of garbage size influences how this measurement evaluates views. In our experiments, we used 100x100 containers for each dataset."}, {"heading": "3.6 Task", "text": "Before starting the study, participants were told that they would be shown a series of scatter diagrams of some data sets with multiple groups, and that their task would be to evaluate how good the view was based on the visualizations. There were no instructions for defining the \"quality\" of a view. Each scatter graph showed only the data points in different colors in relation to their class names, and no further information was provided about the data (such as the name of the data set or the names of the attributes). After reading the instructions, participants were shown a scatter graph in each case and asked to rate them on a continuous scale between 0 (very good) and 1 (very bad) using the labels shown in Table 3."}, {"heading": "3.7 Methodology", "text": "Each user rated a total of 45 scatter plots. The first five scatter plots not known to the participants were artificial views that had varying degrees of compactness and separation between classes, from very good to very bad in terms of automated metrics. These visualizations were used as calibration views to help participants get used to the user interface and build their mental models of how they would rate the quality of a view. User ratings for these calibration views were not included in the analysis of responses. The remaining 40 preselected scatter plots were displayed to each user in randomized order. To reduce the effect of outliers, we calculated the mean of user responses for each of the scatter plots and used this value for our comparisons to automated metrics."}, {"heading": "3.8 Results", "text": "Figure 3 shows the relationships between human perception and each of the automated metrics. Each graph represents the values of the corresponding automated metrics versus the median score of the participants for each scatter graph. A strong positive linear correlation means a good alignment between the human and automated metrics. Table 4 summarizes the relationships between each metric and human perception for each scatter graph. Tables 5-8 present the results for each data set. The metrics are sorted in descending order relative to the R2 values. R2 values show how well the linear regression model matches the prediction of participants \"scores based on each automated metric. Results on all scatter graphs without considering a specific data set (Table 4) show that the C index and LDA index do not correlate with the way participants typically assess the\" quality \"of a view."}, {"heading": "3.9 Combining the Automated Visual Interpretability Measures", "text": "Given the ten automated metrics and the median of human responses of all data sets, we raise a prediction problem that would result in a linear model of human responses to the automated metrics. We trained a linear regression model with leaveone-out cross-validation. The following linear combination of six of the ten metrics was found (Figure 4): PredictedHumanResponse (PHR) = \u2212 0.7772 \u0445 J48 + 0.8155 \u0445 SMO + \u2212 0.4305 \u0445 IC + \u2212 0.4588 \u0445 IDB + 0.6586 \u0445 CCM + 0.3285 \u0445 HDM \u2212 2D + 0.3606 As shown in Table 9, the combined metric matches human perception significantly better than any individual metric in Table 4. The composite metric is the clear winner for the WDBC and the segment data sets. However, in the fixation and olive oil data sets, it was not the most human perceptual metric in relation to all data sets."}, {"heading": "4 SEMANTIC INTERPRETABILITY USER STUDY", "text": "The goal of the semantic interpretation study is to understand how easily users interpret / understand mathematical expressions of variables, coefficients, and operators that would constitute a linear or nonlinear projection (transformation) function that characterizes the relationship between a set of variables and the result of the projection. We developed a software application that automatically manages the experiment and records participants \"reactions without the intervention of the testers."}, {"heading": "4.1 Participants", "text": "The same 20 participants (Section 3.1) who participated in the visualization study also participated in this experiment. Before the study began, all participants were given time to practice using the tablet pen."}, {"heading": "4.2 The expressions", "text": "We created 30 mathematical expressions consisting of five possible variables t, u, x, y, z, numerical coefficients, mathematical operators +, \u2212, \u0445, /, logarithm, square root, exponential size and power. The first five expressions were not disclosed to the participants and served as calibration expressions (Table 10). The purpose of these initial expressions was to determine a range of expressions complexity to be shown below. Participants \"responses to these expressions were not included in the analysis of the results. In our experiments, the size of the shortest expression was 2 and the longest expression 19."}, {"heading": "4.3 Task", "text": "Participants were informed that they would be shown a set of mathematical expressions from five possible variables t, u, x, y, z, numerical coefficients, mathematical operators +, \u2212, \u043a, /, logarithm, square root, exponential size and potency. They were told that each expression would be displayed for 10 seconds and that their task would be to study the expression within this time and write it back with a tablet pen after the expression was removed from the screen. They were also asked to rate how easy it was to understand / interpret the given expression on a continuous scale from 0 (very simple) to 1 (very difficult) with labels in Table 12."}, {"heading": "4.4 Methodology", "text": "After the first five calibration expressions, the remaining 25 expressions (Table 11) were then shown to each participant in a random order, and the expressions were presented to the participants in linearized form. Specifically, we decided not to present the splitting process as a fraction so as not to create a visual clue that would make it easier to interpret the expression as opposed to adding, subtracting, or multiplying. For each participant, we recorded the time they spent writing each expression and their assessment of how easy it was to understand the expression. Images of the written expressions were automatically captured and stored for manual verification (Figure 5). For this study, we looked only at the correct / wrong answer, rather than assessing the partial correctness."}, {"heading": "4.5 Results", "text": "The results of the study are summarized in Table 11. < For each expression, we report on the median value of participants \"scores, the median value of the total time it took for participants to write down and evaluate the expression and number of correct answers. < We first examined the relationship between how an expression was rated by participants and how often it was correctly written down. We suspected that the expressions, which were often incorrectly replicated, would also be judged as difficult to interpret by participants. In fact, we found that there was a strong correlation between them (Pearson's R = 0.9379, Df = 23, p < 0.05), suggesting that the ratings given by participants were consistent with their observed behavior (answers incorrect). We found no meaningful relationship between the time taken to write the expression and the subjective rating. Most likely, this is due to the fact that participants did not spend much time using these expressions."}, {"heading": "5 DISCUSSION", "text": "In this paper, we examined the relationships between human perception and automated metrics that aim to quantify interpretative ability. To visually explore high-dimensional data sets, we looked at two types of interpretative ability. Visual interpretative ability deals with how easy it is to distinguish members of different classes by looking at 2D scatter plots of data. We presented a user study of four sets of data with different numbers of classes that compared ten automated metrics with human perception. Our results showed that no single metric outperforms others on all data sets. While the Dunn Index, C Index, and LDA Index do not correlate with human perception, all other metrics seem to relate to human perception."}], "references": [{"title": "Evaluation of multimodal input for entering mathematical equations on the computer", "author": ["L. Anthony", "J. Yang", "K.R. Koedinger"], "venue": "CHI \u201905 extended abstracts on Human factors in computing systems, CHI EA \u201905, pages 1184\u20131187, New York, NY, USA", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "Complexity of mathematical expressions in adaptive multimodal multimedia system ensuring access to mathematics for visually impaired users", "author": ["A. Awde", "Y. Bellik", "C. Tadj"], "venue": "International Journal of Computer and Information Science and Engineering, 2:103\u2013115", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Adaptive Control Processes", "author": ["R. Bellman"], "venue": "Princeton Univ. Press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1961}, {"title": "Geometric methods for feature extraction and dimensional reduction", "author": ["C.J.C. Burges"], "venue": "pages 59\u201392", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "A cluster separation measure", "author": ["D.L. Davies", "D.W. Bouldin"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1979}, {"title": "Well separated clusters and optimal fuzzy-partitions", "author": ["J.C. Dunn"], "venue": "Journal of Cybernetics, 4:95\u2013104", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1974}, {"title": "A projection pursuit algorithm for exploratory data analysis", "author": ["J.H. Friedman", "J.W. Tukey"], "venue": "Computers, IEEE Transactions on, C- 23(9):881\u2013890", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1974}, {"title": "editors", "author": ["I. Guyon", "S. Gunn", "M. Nikravesh", "L. Zadeh"], "venue": "Feature Extraction, Foundations and Applications. Series Studies in Fuzziness and Soft Computing, Physica-Verlag, Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Cluster validity methods: part", "author": ["M. Halkidi", "Y. Batistakis", "M. Vazirgiannis"], "venue": "i. SIGMOD Rec.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "Idiot\u2019s Bayes\u2014Not so stupid after all? International Statistical Review", "author": ["D.J. Hand", "K. Yu"], "venue": "69(3):385\u2013398", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Quadratic assignment as a general dataanalysis strategy", "author": ["L. Hubert", "J. Schultz"], "venue": "British Journal of Mathematical and Statistical Psychologie, 29:190\u2013241", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1976}, {"title": "Andrew W", "author": ["T.L. Khalid El-Arini"], "venue": "Moore. Autonomous visualization. In European Conference on Principles and Practice of Knowledge Discovery in Databases ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Wrappers for feature subset selection", "author": ["R. Kohavi", "G.H. John"], "venue": "Artif. Intell., 97(1-2):273\u2013324", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1997}, {"title": "Vizrank: Data visualization guided by machine learning", "author": ["G. Leban", "B. Zupan", "G. Vidmar", "I. Bratko"], "venue": "Data Mining and Knowledge Discovery, 13:119\u2013136", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "Projection pursuit for exploratory supervised classification", "author": ["E.-K. Lee", "D. Cook", "S. Klinke", "T. Lumley"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Interpretable Projection Pursuit", "author": ["S.C. Morton"], "venue": "PhD thesis, Stanford University", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1989}, {"title": "A comparison of internal and external cluster validation indexes", "author": ["E. Rend\u00f3n", "I.M. Abundez", "C. Gutierrez", "S.D. Zagal", "A. Arizmendi", "E.M. Quiroz", "H.E. Arzate"], "venue": "Proceedings of the 2011 American conference on applied mathematics and the 5th WSEAS international conference on Computer engineering and applications, AMERICAN-MATH\u201911/CEA\u201911, pages 158\u2013163, Stevens Point, Wisconsin, USA", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Discriminative vs informative learning", "author": ["Y.D. Rubinstein", "T. Hastie"], "venue": "KDD, pages 49\u201353", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1997}, {"title": "Selecting good views of high-dimensional data using class consistency", "author": ["M. Sips", "B. Neubert", "J.P. Lewis", "P. Hanrahan"], "venue": "Computer Graphics Forum, 28(3):831\u2013838", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Combining automated analysis and visualization techniques for effective exploration of high-dimensional data", "author": ["A. Tatu", "G. Albuquerque", "M. Eisemann", "J. Schneidewind", "H. Theisel", "M. Magnor", "D. Keim"], "venue": "In Proceedings of the IEEE Symposium on Visual Analytics Science and Technology (IEEE VAST),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Visual quality metrics and human perception: an initial study on 2d projections of large multidimensional data", "author": ["A. Tatu", "P. Bak", "E. Bertini", "D. Keim", "J. Schneidewind"], "venue": "Proceedings of the International Conference on Advanced Visual Interfaces, AVI \u201910, pages 49\u201356, New York, NY, USA", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Dimensionality reduction: A comparative review", "author": ["L. van der Maaten", "E. Postma", "H. van den Herik"], "venue": "Technical report,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Top 10 algorithms in data mining", "author": ["X. Wu", "V. Kumar", "J. Ross Quinlan", "J. Ghosh", "Q. Yang", "H. Motoda", "G.J. McLachlan", "A. Ng", "B. Liu", "P.S. Yu", "Z.-H. Zhou", "M. Steinbach", "D.J. Hand", "D. Steinberg"], "venue": "Knowl. Inf. Syst.,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "Classification of multicomponent analytical data of olive oils using different neural networks", "author": ["J. Zupan", "M. Novic", "X. Li", "J. Gasteiger"], "venue": "Analytica Chimica Acta, 292(3):219 \u2013 234", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1994}], "referenceMentions": [{"referenceID": 2, "context": "According to the curse of dimensionality [6] theorem, the number of samples needed for a classification task increases exponentially as the number of dimensions (variables, features) increases.", "startOffset": 41, "endOffset": 44}, {"referenceID": 3, "context": "edu (MDS), manifold learning, kernel PCA, evolutionary constructive induction) techniques have been proposed for dimensionality reduction and visualization ( [7, 25, 11]).", "startOffset": 158, "endOffset": 169}, {"referenceID": 21, "context": "edu (MDS), manifold learning, kernel PCA, evolutionary constructive induction) techniques have been proposed for dimensionality reduction and visualization ( [7, 25, 11]).", "startOffset": 158, "endOffset": 169}, {"referenceID": 7, "context": "edu (MDS), manifold learning, kernel PCA, evolutionary constructive induction) techniques have been proposed for dimensionality reduction and visualization ( [7, 25, 11]).", "startOffset": 158, "endOffset": 169}, {"referenceID": 6, "context": "The task of selecting interesting [10] or good views of datasets becomes more challenging as the dimensionality increases.", "startOffset": 34, "endOffset": 38}, {"referenceID": 14, "context": "present a measure for exploratory projection pursuit of labeled data that is based on Fisher\u2019s Linear Discriminant Analysis method in [18].", "startOffset": 134, "endOffset": 138}, {"referenceID": 13, "context": "are evaluated by a k-Nearest Neighbor classifier [17].", "startOffset": 49, "endOffset": 53}, {"referenceID": 18, "context": "propose two measures based on the notion of class consistency in [22].", "startOffset": 65, "endOffset": 69}, {"referenceID": 19, "context": "propose two measures to evaluate the degree of separation on scatterplots of labeled data in [23].", "startOffset": 93, "endOffset": 97}, {"referenceID": 20, "context": "report a user study in [24] that compares four visual quality measures that have been proposed in [22] and [23].", "startOffset": 23, "endOffset": 27}, {"referenceID": 18, "context": "report a user study in [24] that compares four visual quality measures that have been proposed in [22] and [23].", "startOffset": 98, "endOffset": 102}, {"referenceID": 19, "context": "report a user study in [24] that compares four visual quality measures that have been proposed in [22] and [23].", "startOffset": 107, "endOffset": 111}, {"referenceID": 15, "context": "Morton defines the interpretability of these projection functions in terms of parsimony (simplicity) and proposes rotation and entropy based methods to simplify the coefficients of the linear projections while preserving the interesting view [19].", "startOffset": 242, "endOffset": 246}, {"referenceID": 11, "context": "present a dimensionality reduction method that searches over scatterplots generated by simple arithmetic expressions of the original features and assessed by accuracy of a Bayesian classifier [15].", "startOffset": 192, "endOffset": 196}, {"referenceID": 0, "context": "study the effects of different input methods (keyboard, handwriting, speech) with respect to the complexity of the mathematical expressions for the purpose of developing intelligent tutoring systems [4] for algebra.", "startOffset": 199, "endOffset": 202}, {"referenceID": 1, "context": "in [5] aims to find the most appropriate way to present a mathematical expression to visually impaired users.", "startOffset": 3, "endOffset": 6}, {"referenceID": 23, "context": "The Italian olive oils dataset [27] contains the amounts of eight fatty acids in olive oils that are from nine different regions of the country (downloaded from [1]).", "startOffset": 31, "endOffset": 35}, {"referenceID": 14, "context": "A number of visual quality measures have been introduced in visual analytics literature ( [18, 22, 23]).", "startOffset": 90, "endOffset": 102}, {"referenceID": 18, "context": "A number of visual quality measures have been introduced in visual analytics literature ( [18, 22, 23]).", "startOffset": 90, "endOffset": 102}, {"referenceID": 19, "context": "A number of visual quality measures have been introduced in visual analytics literature ( [18, 22, 23]).", "startOffset": 90, "endOffset": 102}, {"referenceID": 20, "context": "We included two of the proposed measures that were reported in [24] as the closest matches to the human perception through user studies (section 3.", "startOffset": 63, "endOffset": 67}, {"referenceID": 10, "context": "4 C Index (IC) [14] 3.", "startOffset": 15, "endOffset": 19}, {"referenceID": 4, "context": "1 Davies-Bouldin Index (IDB) [8] 3.", "startOffset": 29, "endOffset": 32}, {"referenceID": 5, "context": "2 Dunn Index (IDunn) [9] 3.", "startOffset": 21, "endOffset": 24}, {"referenceID": 14, "context": "3 LDA Index (ILDA) [18] 3.", "startOffset": 19, "endOffset": 23}, {"referenceID": 18, "context": "1 Class Consistency Measure (CCM) [22] 3.", "startOffset": 34, "endOffset": 38}, {"referenceID": 19, "context": "2 2D Histogram Density Measure (2D-HDM) [23] 3.", "startOffset": 40, "endOffset": 44}, {"referenceID": 17, "context": "Classification algorithms can be broadly considered in two categories: generative and discriminative [21].", "startOffset": 101, "endOffset": 105}, {"referenceID": 12, "context": "Therefore, classification performance is used to evaluate the usefulness of feature sets in wrapper based feature selection schemes [16].", "startOffset": 132, "endOffset": 136}, {"referenceID": 22, "context": "For our experiments, we chose four of the most common (according to [26]) classification algorithms which we briefly discuss here.", "startOffset": 68, "endOffset": 72}, {"referenceID": 23, "context": "The k-Nearest Neighbors algorithm has also been utilized in Vizrank [27] in order to assess the quality of scatterplots.", "startOffset": 68, "endOffset": 72}, {"referenceID": 9, "context": "Despite this simplicity, the Naive Bayes algorithm has been known to outperform more complex classification algorithms on a variety of problems [13].", "startOffset": 144, "endOffset": 148}, {"referenceID": 8, "context": "Detailed overview of validity indices can be found in [12, 20].", "startOffset": 54, "endOffset": 62}, {"referenceID": 16, "context": "Detailed overview of validity indices can be found in [12, 20].", "startOffset": 54, "endOffset": 62}, {"referenceID": 10, "context": "The C Index is a cluster validation index defined in [14]:", "startOffset": 53, "endOffset": 57}, {"referenceID": 4, "context": "The Davies-Bouldin Index is a measure of compactness and well separation of clusters and it was proposed in [8]:", "startOffset": 108, "endOffset": 111}, {"referenceID": 5, "context": "The Dunn\u2019s index is a measure of compactness and well separation of clusters and it was proposed in [9]:", "startOffset": 100, "endOffset": 103}, {"referenceID": 20, "context": "The Class Consistency Measure and the 2D Histogram Density Measure have been reported to be the closest matches to human perception amongst the four proposed visual quality measures through a user study [24].", "startOffset": 203, "endOffset": 207}, {"referenceID": 14, "context": "The LDA index is based on Fisher\u2019s discriminant analysis and has been introduced in [18] for exploratory projection pursuit for classification problems:", "startOffset": 84, "endOffset": 88}, {"referenceID": 18, "context": "The Class Consistency Measure (CCM) has been proposed in [22] and is based on the preservation of closeness to class centroid after a projection from the original data space into a 2D view.", "startOffset": 57, "endOffset": 61}, {"referenceID": 19, "context": "The Histogram Density Measure (HDM) which has been proposed in [23] is a measure of class separation based on 2D histograms computed on 2D scatterplots of data.", "startOffset": 63, "endOffset": 67}], "year": 2012, "abstractText": "A number of visual quality measures have been introduced in visual analytics literature in order to automatically select the best views of high dimensional data from a large number of candidate data projections. These methods generally concentrate on the interpretability of the visualization and pay little attention to the interpretability of the projection axes. In this paper, we argue that interpretability of the visualizations and the feature transformation functions are both crucial for visual exploration of high dimensional labeled data. We present a two-part user study to examine these two related but orthogonal aspects of interpretability. We first study how humans judge the quality of 2D scatterplots of various datasets with varying number of classes and provide comparisons with ten automated measures, including a number of visual quality measures and related measures from various machine learning fields. We then investigate how the user perception on interpretability of mathematical expressions relate to various automated measures of complexity that can be used to characterize data projection functions. We conclude with a discussion of how automated measures of visual and semantic interpretability of data projections can be used together for exploratory analysis in classification tasks.", "creator": "LaTeX with hyperref package"}}}