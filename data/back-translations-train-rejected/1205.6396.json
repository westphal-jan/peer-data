{"id": "1205.6396", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2012", "title": "Effective Listings of Function Stop words for Twitter", "abstract": "Many words in documents recur very frequently but are essentially meaningless as they are used to join words together in a sentence. It is commonly understood that stop words do not contribute to the context or content of textual documents. Due to their high frequency of occurrence, their presence in text mining presents an obstacle to the understanding of the content in the documents. To eliminate the bias effects, most text mining software or approaches make use of stop words list to identify and remove those words. However, the development of such top words list is difficult and inconsistent between textual sources. This problem is further aggravated by sources such as Twitter which are highly repetitive or similar in nature. In this paper, we will be examining the original work using term frequency, inverse document frequency and term adjacency for developing a stop words list for the Twitter data source. We propose a new technique using combinatorial values as an alternative measure to effectively list out stop words.", "histories": [["v1", "Tue, 29 May 2012 15:37:46 GMT  (234kb)", "http://arxiv.org/abs/1205.6396v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["murphy choy"], "accepted": false, "id": "1205.6396"}, "pdf": {"name": "1205.6396.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "Many words in documents repeat themselves very frequently, but are essentially meaningless as they are used to combine words into a sentence. It is generally understood that stop words do not contribute to the context or content of text documents. Due to their high frequency of occurrence, their presence in text mining poses an obstacle to understanding the content in the documents. To eliminate the distortion effects, most text mining software or approaches use stop word lists to identify and remove these words. However, developing such a top word list is difficult and contradictory between text sources, and this problem is exacerbated by sources such as Twitter, which are highly repetitive or similar in nature. In this essay, we will examine the original work based on term frequency, inverse document frequency, and adjacency for developing a stop word list for the Twitter data source. We propose a new technique that uses combinatory values as an alternative measure to effective stop listing verbatim."}, {"heading": "Introduction", "text": "Text Mining involves a series of tasks that include selecting the approach, setting parameters, and creating a stop word list (Keogh et al., 2004; Xu and Wunsch, 2005). Drawing up a stop word list is often considered an essential component of text mining, which requires manual labor and research to produce. However, stop word lists are rarely studied and validated against the results of the mining process or mining algorithm. Lack of research related to the creation of stop word lists has led to extensive use of existing stop word lists, which may not be appropriate given the differences in the context of the text sources. Studies in this area have identified the weaknesses of the standardized stop word list (Chakrabarti et al., 1997; Chakrabarti et al., 1998; Silva and Ribeiro, 2003).With the spread of social media platforms and the introduction of such technologies in business and everyday life, social media platforms have established themselves as the most important forms of communication for companies."}, {"heading": "Current approaches", "text": "In fact, most people are able to understand themselves and what they are doing. (...) Most people in the world do not know what they are doing. (...) Most people in the world do not know what they are doing. (...) Most people in the world do not know what they are doing. (...) Most people in the world do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not know what they are doing. (...) They do not do it. (...) They do not. \"(...) They do not do it.\""}, {"heading": "Experimental setup", "text": "For all the experiments we conducted, we selected 9 3-day periods that included tweets with the keyword search for an earthquake. \"Each of these periods starts 24 hours before the start of an earthquake and lasts until 48 hours after the occurrence of the earthquake. The reason for selecting 9 different periods and earthquakes is that the experiments will be as unbiased as possible. The use of query techniques based tweets is to ensure that we have some form of central topics that provide some kind of comparison for the words that are not useful or meaningful. These two conditions allow us to estimate the overall performance for the effectively and impartially tested techniques. The control factor for this experiment is the Fox and Manus Stopword List. Choosing two stopword lists we have to double validate the techniques, as both stopword lists are commonly used for text mining purposes."}, {"heading": "Conclusion", "text": "The approach is based on the combinatorial nature of the words in speeches. We investigated the effectiveness and robustness of the approach by testing it against 9 sets of tweets from different periods of time. It is also compared with existing approaches using TD * IDF and variants. Results showed that the new approach is comparable to existing approaches, if not better in certain cases. The direct nature of the combinatorial approach is not normalized and additional research is needed to produce the normalized metric. Other newer approaches such as the page rank approach also require more research to understand effectiveness. Future research will also have to stop words."}], "references": [{"title": "Message Classification in the Call Center, Proceedings of the Sixth conference on Applied Natural Language Processing, 158\u2013165", "author": ["S. Busemann", "S. Schmeier", "R.G. Arens"], "venue": "Blake, C. 2010. Text Mining, ARIST, Vol 45 (To appear) Chakrabarti, S., Dom, B., Agrawal, R. and Raghavan, P. 1997. Using Taxonomy, Discriminants, and Signatures for Navigating in Text Databases, Proceedings of the 23rd International", "citeRegEx": "Busemann et al\\.,? 2000", "shortCiteRegEx": "Busemann et al\\.", "year": 2000}, {"title": "Scalabe Feature Selection, Classification and Signature Generation for Organizing Large Text Databases into Hierarchical Topic Taxonomies", "author": ["S. Chakrabarti", "B. Dom", "R. Agrawal", "P. Raghavan"], "venue": "Conference on Very Large Databases,", "citeRegEx": "Chakrabarti et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Chakrabarti et al\\.", "year": 1998}, {"title": "Grounded Theory Research: Procedures, Canons, and Evaluative Criteria, Qualitative Sociology", "author": ["J. Corbin", "A. Strauss"], "venue": "Web Browsing Patterns, Knowledge Information System,", "citeRegEx": "Corbin and Strauss,? \\Q1990\\E", "shortCiteRegEx": "Corbin and Strauss", "year": 1990}, {"title": "Mining E-Mail Content for Author Identification Forensics", "author": ["O. de Vel", "M. Corney", "G. Mohay"], "venue": "Earthquake Twitter. Nature Geoscience,", "citeRegEx": "Vel et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Vel et al\\.", "year": 2001}, {"title": "The Discovery of Grounded Theory, Chicago: Aldine Publishing Company", "author": ["B. Glaser", "A. Strauss"], "venue": "Jothi,P. et al. 2011. \"Analysis of social networking sites: A study on effective communication strategy in developing brand communication\", Journal of Media and Communication Studies Vol. 3(7), pp. 234-242, July 2011", "citeRegEx": "Glaser and Strauss,? 1967", "shortCiteRegEx": "Glaser and Strauss", "year": 1967}, {"title": "An Investigation of the Impact of Data Quality on Decision Performance", "author": ["W. Jung"], "venue": "Proceedings of the 2004 International Symposium on Information and Communication Technology (ISICT", "citeRegEx": "Jung,? \\Q2004\\E", "shortCiteRegEx": "Jung", "year": 2004}, {"title": "Towards Parameter-Free Data Mining, Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 206-215", "author": ["E. Keogh", "S. Lonardi", "C.A. Ratanamahatana"], "venue": "Konchady, Manu. 2007, Text Mining Application programming. Charles River Media Publishing.", "citeRegEx": "Keogh et al\\.,? 2004", "shortCiteRegEx": "Keogh et al\\.", "year": 2004}, {"title": "Learning to Classify Email", "author": ["I Koprinska", "J. Poon", "J. Clark", "J. Chan"], "venue": "Information Science,", "citeRegEx": "Koprinska et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koprinska et al\\.", "year": 2007}, {"title": "Knowledge Management Technology, IBM Systems Journal", "author": ["A.D. MIT Press. Marwick"], "venue": "Moreale, E. and Watt, S. 2002. Organisational Information Management and Knowledge Discovery in Email within Mailing Lists, In H. Yin et al. (Eds.), Intelligent Data Engineering and Automated Learning, Lecture Notes in Computer Science, 2412/2002, 217-224, Berlin /", "citeRegEx": "Marwick,? 2001", "shortCiteRegEx": "Marwick", "year": 2001}, {"title": "Moldova\u2018s \u0333Twitter Revolution.\u2018", "author": ["Alina", "Munteanu", "Igor"], "venue": "Journal of Democracy", "citeRegEx": "Mungui.Pippidi et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Mungui.Pippidi et al\\.", "year": 1998}, {"title": "The SMART Retrieval System\u2014Experiments in Automatic Document Processing, Upper Saddle River, NJ, USA: Prentice-Hall, Inc", "author": ["G. Salton"], "venue": "The Importance of Stop Word Removal on Recall Values in Text Categorization, Proceedings of the International Joint Conference on Neural Networks,", "citeRegEx": "Salton,? \\Q1971\\E", "shortCiteRegEx": "Salton", "year": 1971}, {"title": "Evolving Better Stoplists for Document Clustering and Web Intelligence, Proceedings of the 3rd Hybrid Intelligent Systems Conference, Australia, IOS Press", "author": ["M.P. Sinka", "Come D.W."], "venue": "T. Sakaki, M. Okazaki, and Y. Matsuo. Earthquake shakes twitter users: real-time event detection by social sensors. In WWW \u201810: Proc. of the 19th international Conf. on World wide", "citeRegEx": "Sinka and W.,? 2003", "shortCiteRegEx": "Sinka and W.", "year": 2003}, {"title": "Email Data Cleaning", "author": ["J. ACM. Tang", "H. Li", "Y. Cao", "Z. Tang"], "venue": "Proceedings of the eleventh ACM SIGKDD international conference on Knowledge Discovery in Data Mining, Chicago, Illinois,", "citeRegEx": "Tang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2010}, {"title": "Examining Data Quality, Communications of the ACM, ACM Press, 41(2), 54\u201357", "author": ["G.K. Tayi", "D.P. Ballou"], "venue": "Tumasjan, A.; Sprenger, T. O.; Sandner, P. G.; and Welpe, I. M. 2010. Predicting Elections with Twitter: What 140 Characters Reveal about Political Sentiment. In Proc. 4Th Intl. AAAI Conf. on Weblogs and Social Media (ICWSM).", "citeRegEx": "Tayi and Ballou,? 1998", "shortCiteRegEx": "Tayi and Ballou", "year": 1998}, {"title": "Automatic keyword extraction from individual documents", "author": ["S. Rose", "D. Engel", "N. Cramer", "W. Cowley."], "venue": "M. W. Berry and J. Kogan (Eds.), Text Mining: Applications and Theory. John Wiley and Sons, Ltd. Van Rijsbergen, C. J. 1979. Information Retrieval, Newton, MA: Butterworth- Heinemann. Xu, R. and Wunsch, D. 2005. Survey of Clustering Algorithms, IEEE Transactions on Neural", "citeRegEx": "Rose et al\\.,? 2010", "shortCiteRegEx": "Rose et al\\.", "year": 2010}, {"title": "Information Enhancement for Data Mining", "author": ["S. Zhang", "C. Zhang", "Q. Yang"], "venue": "IEEE Intelligent Systems, March-April,", "citeRegEx": "Zhang et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 6, "context": "Text mining comprises of a series of tasks that includes selection of approach, parameter setting and the creation of a stop word list (Keogh et al., 2004; Xu and Wunsch, 2005).", "startOffset": 135, "endOffset": 176}, {"referenceID": 1, "context": "Research in the area has identified the weaknesses of standardized stop words list (Chakrabarti et al., 1997; Chakrabarti et al., 1998; Silva and Ribeiro, 2003).", "startOffset": 83, "endOffset": 160}, {"referenceID": 5, "context": "huge amount of data collected, the data quality has to be of a very high level of quality in order to be effective (Cooley et al., 1999; Redman, 1998; Jung, 2004; Tayi and Ballou, 1998; Zhang et al., 2004).", "startOffset": 115, "endOffset": 205}, {"referenceID": 13, "context": "huge amount of data collected, the data quality has to be of a very high level of quality in order to be effective (Cooley et al., 1999; Redman, 1998; Jung, 2004; Tayi and Ballou, 1998; Zhang et al., 2004).", "startOffset": 115, "endOffset": 205}, {"referenceID": 15, "context": "huge amount of data collected, the data quality has to be of a very high level of quality in order to be effective (Cooley et al., 1999; Redman, 1998; Jung, 2004; Tayi and Ballou, 1998; Zhang et al., 2004).", "startOffset": 115, "endOffset": 205}, {"referenceID": 7, "context": "Other authors held the opinion that any words that appear too rarely or were longer than a certain length should be removed (Koprinska et al., 2007).", "startOffset": 124, "endOffset": 148}], "year": 2012, "abstractText": "Many words in documents recur very frequently but are essentially meaningless as they are used to join words together in a sentence. It is commonly understood that stop words do not contribute to the context or content of textual documents. Due to their high frequency of occurrence, their presence in text mining presents an obstacle to the understanding of the content in the documents. To eliminate the bias effects, most text mining software or approaches make use of stop words list to identify and remove those words. However, the development of such top words list is difficult and inconsistent between textual sources. This problem is further aggravated by sources such as Twitter which are highly repetitive or similar in nature. In this paper, we will be examining the original work using term frequency, inverse document frequency and term adjacency for developing a stop words list for the Twitter data source. We propose a new technique using combinatorial values as an alternative measure to effectively list out stop words.", "creator": "Microsoft\u00ae Office Word 2007"}}}