{"id": "1206.0918", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2012", "title": "Fuzzy Knowledge Representation Based on Possibilistic and Necessary Bayesian Networks", "abstract": "Within the framework proposed in this paper, we address the issue of extending the certain networks to a fuzzy certain networks in order to cope with a vagueness and limitations of existing models for decision under imprecise and uncertain knowledge. This paper proposes a framework that combines two disciplines to exploit their own advantages in uncertain and imprecise knowledge representation problems. The framework proposed is a possibilistic logic based one in which Bayesian nodes and their properties are represented by local necessity-valued knowledge base. Data in properties are interpreted as set of valuated formulas. In our contribution possibilistic Bayesian networks have a qualitative part and a quantitative part, represented by local knowledge bases. The general idea is to study how a fusion of these two formalisms would permit representing compact way to solve efficiently problems for knowledge representation. We show how to apply possibility and necessity measures to the problem of knowledge representation with large scale data. On the other hand fuzzification of crisp certainty degrees to fuzzy variables improves the quality of the network and tends to bring smoothness and robustness in the network performance. The general aim is to provide a new approach for decision under uncertainty that combines three methodologies: Bayesian networks certainty distribution and fuzzy logic.", "histories": [["v1", "Tue, 5 Jun 2012 13:13:21 GMT  (645kb)", "http://arxiv.org/abs/1206.0918v1", "ISSN: 1790-0832"]], "COMMENTS": "ISSN: 1790-0832", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["abdelkader heni", "mohamed nazih omri", "adel alimi"], "accepted": false, "id": "1206.0918"}, "pdf": {"name": "1206.0918.pdf", "metadata": {"source": "CRF", "title": "Fuzzy Knowledge Representation Based on Possibilistic and Necessary Bayesian Networks", "authors": ["ABDELKADER HENI"], "emails": ["abdelkader.heni@edunet.tn,", "nazih.omri@ipeim.rnu.tn,", "adel.alimi@enis.rnu.tn"], "sections": [{"heading": null, "text": "This paper proposes a framework that combines two disciplines to exploit their own advantages in uncertain and imprecise knowledge presentation problems. The proposed framework is a framework based on possible logic, in which Bayesian nodes and their properties are represented by local, necessarily valued knowledge base. Data in properties are interpreted as a set of evaluated formulas. In our paper we show how possible and necessary measures can be applied to the problem of knowledge presentation with large-scale data. On the other hand, the general idea is to investigate how a merging of these two formalities would allow to present compact solutions to knowledge presentation problems. We show how to apply possibilities and necessities to the problem of knowledge presentation with large-scale data."}, {"heading": "1 Introduction", "text": "In fact, most of them are able to survive on their own if they do not see themselves able to achieve their goals, most of them are able to achieve their goals, and most of them are able to achieve their goals, most of them are able to achieve their goals, most of them are able to achieve their goals, and most of them are not able to achieve their goals, and most of them are able to achieve their goals."}, {"heading": "2.1 Possibilistic logic", "text": "Let L be a finite statement language. p; q; r;.. denote q formulas (and b) denote tautologies and contradictions. D denotes the classical synactivity relationship. D is the set of classical statement techniques q of L, and [p] is the set of classical models of p (i.e. interpretations where p is true) [13].2.1.1 Possibility necessity distributions and possibility necessity measurements. The basic element of possibility theory is the possibility distribution, which represents an assignment from p to interpretation [0 1]. The degree p represents the compatibility of p with the available information (or beliefs) about the real world. D = 0 means by convention that this statement method is p: interpretation is impossible, and D = 1 means that nothing prevents the real world from being p."}, {"heading": "2.1.2 Fuzzy knowledge base", "text": "A blurred formula is a tripley, which is a classical closed formula of the first order and (\u03b1, \u03b2) is a positive number of the range (0,1). This formula expresses that it is possible at least to the degree, and at least to the degree, to which it is certain, i.e. to the degree, to which it is possible, i.e. to the degree, to which it is possible and necessary. The right part of a possible formula, i.e. to the degree, to which it is possible and necessary, is weighted as possibility and necessity. A blurred knowledge base is defined as a set of weighted formulas [18]. More formally, it is expressed as follows: (\u03b9, \u03b1i, \u03b2 i), i = 1.... m} where it is a meaningful formula and \u03b2I is the higher limit of possibility and \u03b2I the lower limit of necessity attributable to this formula (certainty)."}, {"heading": "3 Fuzzy Bayesian networks", "text": "A standard possibilistic network is a decomposition of a multivariate possibility distribution according to: \u03c0 (A1,....., An) = mini = 1.. n \u03c0 (Ai | parents (Ai)) (5) where parents (Ai) is the set of parents of variable Ai, which is made as small as possible (WSEAS TRANS. on INFORMATION SCIENCE & APPLICATIONS Issue 2, Volume 3, February 2006 ISSN: 1790-0832 226In our work on average fuzzy bayesian networks is considered as a graphical representation of uncertain information. It provides an alternative to probabilistic causal network when numerical data are not causable.Let V = {A1, A2,.. An} a program of attribution is that is a graphically represented information."}, {"heading": "Where:", "text": "- A (A1,., An) is the common average distribution. - min (\u03c0 (Ai | U (Ai)) is the lower limit of the possibilities associated with (Ai | U (Ai). - min (N (Ai | U (Ai))) is the lower limit of the necessities associated with (Ai | U (Ai). Example: Let the earlier possibilities necessities and the conditional possibilities necessities be as described in Table 1: By applying the chain rule defined by Equation (8), we obtain the average distribution associated with the above-quoted average blurred Bajesian network as described in the table."}, {"heading": "A B C D min\u03a0 minN A", "text": "a) a) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c) c (1) c) c) c) c) c) c) c) c (1) c) c) c) c) c) c c) c) c) c) c) c (1) c) c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c (1) c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c) c) c) c) c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c"}, {"heading": "To note here that in [15] the authors prove the possibility to recover conditional possibilities from \u2211A where \u2211A is a possibilistic knowledge base.", "text": "c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c. c"}, {"heading": "Example:", "text": "From the average knowledge base associated with node A, and through the use of equations 11 and 12 \u2211 AA = {(a, 0.5, 0.9)} = {(a, 0.45)} We can derive the conditional average table for node A by using equations 11 and 12\u03c0 N Aa 1 0.6 0.6 \u00ac a 0.5 0.1 0.05 For the rest of the nodes we can derive the rest of the conditional averages associated with other nodes, and thus we can restore the average distribution represented in Table 2.7 Fuzzy Bayesian networks on the basis of an unclear distribution of needs. Logical formulas with a weight strictly greater than agile levels (lower limits of necessity degree) are immune to inconsistency and can certainly be used in deductive reasoning. [19] However, in order to make arguments for inaccurate and uncertain distribution of necessity, two important questions should be addressed: First, any improvement should be achieved from an unclear arrangement of possibilities."}, {"heading": "Example:", "text": "Let our particular network be as described in the representation of a Bayesian network in metastatic cancer.Figure 2. A Bayesian network in metastatic cancer [20] Figure 2 shows a Bayesian network that represents the above-mentioned cause-and-effect relationships. Table 3 lists the causal influences in relation to blurred distributions of certainty. Each variable is characterized by an unknown degree of necessity due to the condition of its parents. For example:"}, {"heading": "C \u2208 [0, 1] represents the dichotomy between having a brain tumor and not having one, c denotes the assertion", "text": "C = 1 or \"brain tumor present,\" and \u00ac c is the relation of c, namely C = 0. The root node A, which has no parent, is characterized by its previous blurred distribution of certainty."}, {"heading": "Example", "text": "The conditional fuzzy necessities associated with the graph shown in Figure 2 are as in Table 3. For simplicity reasons, we have here retained only four nodes as shown in Figure 1. For example, N (d | b, \u00ac c) cannot be 0.1 as described in Table 1, but rather is a fuzzy number, say [\u03b21] [\u03b2D | BC1, \u03b2D | BC2], where \u03c71 = (d | b, \u00ac c) is the fuzzy necessity associated with the fuzzy formula (d | b, \u00ac c) and associated with a membership function \u00b5 (\u03c71) that is supposed to be a triangular function (resp. \u00b5 can be betapezoidal or some other type of function)."}, {"heading": "Where:", "text": "- \u03b1, k1 and k2 are two defined constants.. - | * | is the absolute value of the term * The above expression and the figure mean that the interval [\u03b2D | BC1, \u03b2D | BC2] [\u03b2D | BC1, \u03b2D | BC1] is the most likely situation. If \u03c71 \u2265 \u03b2D | BC2 or \u04211 \u2264 \u03b2D | BC1 is \u00b5 (\u03c71) = 0, the possible manifestation of a change between FBN and unclear knowledge bases is considered analogously if the given demand level is a blur of numbers as described in Section 5, the demand distribution N (X) associated with a node X is defined as a blurred distribution defined by a membership function \u00b5: [\u03b21, \u03b22] [0 1] (14). Example: Consider the diagram of Figure 2."}, {"heading": "Let the different membership be as follow:", "text": "\u00b5i (gnis) = ki1 x (\u03b2ij1) - ki2 x (\u03b2ij2 | \u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043d\u043dnenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenene"}, {"heading": "Where:", "text": "- \u00b5i is the membership function associated with the fuzzy variable that should be triangular. - ki1 and ki2 are the constant used in each membership function that should be triangular. - \u03b2ij1 and \u03b2ij2 are the two minutes and the maximum limit of a requirement level. Finally, by maximizing each membership function, we can derive an optimal value for the level of security associated with each fuzzy variable (i.e. proposition)."}, {"heading": "By replacing \u03bb by 1 (the maximization of \u00b5( \u03c7 )), the", "text": "Similarly, the definition of fuzzy joint neurotransformation is achieved by applying the fuzzy chain rule: \"(A1,..., An) = min (\u03c7i),\" \"\u03c7i\" = \"(Ai | U (Ai).\" From a semantic point of view, a specific knowledge base in which each \u03b1i is a crisp need value is understood as the demand distribution representing the blurred model theorems of \u2211: \"N\" (\u03c9) = min max \"(GDP),\" 1-\u03b1, \"in which [Pi] denotes the set of models of Pi, so that:\" \u00b5 [Pi] = \u03b1, if \"Pi\u00b5\" [Pi] (\u03c9) = (17) 0 otherFrom (21) we can clearly deduce that \"N\" is clearly a crisp \"function and\" Pi \"is a crisp one.\""}, {"heading": "9 Conclusion", "text": "The main advantages of this representation for the user are that both the explanation of knowledge and the possible conclusions are modular. Individual knowledge databases should be compiled separately and complete. Again, this representation defines an organized structure for determining the graph structure. We have defined only the transformation process for knowledge bases. Certain Bayesian networks with a fuzzy knowledge data approach naturally give us the substance of the evidence for each logical formula. Although the methodology proposed in this paper aims at and illustrates some typical examples, the techniques developed require experimental results. Future work will consist in extending this representation to define efficient algorithms for local conclusions."}, {"heading": "Quantitative Approches to Rreasoning and Uncertainty,", "text": "[11] S. Benferhat, S. Smaoui. Hybrid possibilistic networks. in proceeding of the Twentieth National Conference on Artificial Intelligence (AAAI-05), AAI Press. Pittsburgh, 2005. [13] S. Benferhat, D. Dubois, L. Garcia, H. Prade. On the transformation between possibilistic logic bases and possibilistic causal networks. International Journal of Approximate Reasoning, Vol. 29, N. 21, 35-173, 2002. [14] J. Gebhardt and R. Kruse. The Context Model an Integration View of Vagueness and possibilistic causal networks."}], "references": [{"title": "Bayesian networks : a model of selfactivated memory for evidential reasoning", "author": ["Pearl Judea"], "venue": "Cognitive Science Society, UC Irvine,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1985}, {"title": "A constraint-propagation approach to probabilistic reasoning", "author": ["Pearl Judea"], "venue": "Uncertainty in Artificial Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1986}, {"title": "Fusion, propagation and structuring in belief networks. UCLA Computer Science Department Technical Report", "author": ["Pearl Judea"], "venue": "Artificial Intelligence,,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1986}, {"title": "Graphoids : a graph-based logic for reasoning about relevance relations", "author": ["Pearl Judea", "A. Paz"], "venue": "UCLA Computer Science Department Technical Report 850038;", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1987}, {"title": "Influence diagrams and d-separation", "author": ["Pearl Judea", "T. Verma"], "venue": "UCLA Cognitive Systems Laboratory, Technical Report 880052,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1988}, {"title": "A semantics for possibility theory based on likelihoods", "author": ["D. Dubois", "S. Moral", "H. Prade"], "venue": "J. Math. Anal. Appl", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1997}, {"title": "Fuzzy Sets and Systems: Theory and Applications", "author": ["D. Dubois", "H. Prade"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1980}, {"title": "Qualitative possibilistic graphical models from independance to propagation algorithms", "author": ["N.Ben Amor"], "venue": "The\u0300se de doctorat,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2002}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference.Morgan", "author": ["J. Pearl"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1988}, {"title": "Hybrid possibilistic networks. in proceeding of the Twentieth", "author": ["S. Benferhat", "S. Smaoui"], "venue": "National Conference on Artificial Intelligence (AAAI-05),AAAI Press. Pittsburgh,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "On the transformation between possibilistic logic bases and possibilistic causal networks", "author": ["S. Benferhat", "D. Dubois", "L. Garcia", "H. Prade"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "The context model an integrating view of vagueness and uncertainty Int", "author": ["J. Gebhardt", "R. Kruse"], "venue": "Journal of Approximate Reasoning", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1993}, {"title": "Possibilistic networks with locally weighted knowledge bases", "author": ["Salem Benferhat", "Salma Smaoui"], "venue": "4th International Symposium on Imprecise Probabilities and Their Applications, Pittsburgh, Pennsylvania,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Fuzzy sets as a basis for a theory of possibility", "author": ["L.A. Zadeh"], "venue": "Fuzzy Sets and Systems", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1978}, {"title": "Fuzzy Sets and Systems: Theory and applications", "author": ["D. Dubois", "H. Prade"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1980}, {"title": "Belief structures, possibility theory and decomposable confidence", "author": ["D. Dubois"], "venue": "measure. on finite sets. Computers and Artificial Intelligence,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1986}, {"title": "Possibilistic logic : a retrospective and prospective view", "author": ["Dubois", "Prade"], "venue": "Fuzzy Sets and Systems", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "Constrained abductive reasoning with fuzzy parameters in Bayesian networks", "author": ["Han-Lin Li", "Han-Ying Kao"], "venue": "Computers & Operations Research", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 170, "endOffset": 173}, {"referenceID": 1, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 174, "endOffset": 177}, {"referenceID": 2, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 178, "endOffset": 181}, {"referenceID": 3, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 182, "endOffset": 185}, {"referenceID": 4, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 186, "endOffset": 189}, {"referenceID": 8, "context": "These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11].", "startOffset": 194, "endOffset": 198}, {"referenceID": 5, "context": "The goal of this paper is to develop a qualitative framework where the uncertainty is represented in possibility theory; an ordinal theory for uncertainty developed since more than ten years [6], [7], and [8].", "startOffset": 191, "endOffset": 194}, {"referenceID": 6, "context": "The goal of this paper is to develop a qualitative framework where the uncertainty is represented in possibility theory; an ordinal theory for uncertainty developed since more than ten years [6], [7], and [8].", "startOffset": 196, "endOffset": 199}, {"referenceID": 9, "context": "The language defined in [12] [13] and in [15] has been modified to enhance usability and to support a more powerful system.", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": "The language defined in [12] [13] and in [15] has been modified to enhance usability and to support a more powerful system.", "startOffset": 29, "endOffset": 33}, {"referenceID": 12, "context": "The language defined in [12] [13] and in [15] has been modified to enhance usability and to support a more powerful system.", "startOffset": 41, "endOffset": 45}, {"referenceID": 11, "context": "In this paper we consider a type of possibilistic network that is based on the context model interpretation of a degree of possibility and focused on imprecision [14].", "startOffset": 162, "endOffset": 166}, {"referenceID": 10, "context": "e, interpretations where p is true {\u03c9 | \u03c9 p}) [13].", "startOffset": 46, "endOffset": 50}, {"referenceID": 0, "context": "1 Possibility-necessity distributions and possibility-necessity measures The basic element of possibility theory is the possibility distribution \u220f which is a mapping from \u03a9 to the interval [0 1].", "startOffset": 189, "endOffset": 194}, {"referenceID": 10, "context": "By convention, \u03c0(\u03c9)= 0 means that the interpretation \u03c9 is impossible, and \u03c0(\u03c9) = 1 means that nothing prevents \u03c9 from being the real world [13].", "startOffset": 139, "endOffset": 143}, {"referenceID": 13, "context": "\u220f(p) = max ( \u03c0 (\u03c9) : \u03c9 \u2208 [p]) (1) Which evaluates the extent to which p is consistent with the available beliefs expressed by p [16].", "startOffset": 128, "endOffset": 132}, {"referenceID": 14, "context": "We have [17]: \u2200p, \u2200q N (p\u2227q) = max (N(p), N (q)) (4)", "startOffset": 8, "endOffset": 12}, {"referenceID": 0, "context": "2 Fuzzy knowledge base A fuzzy formula is a tripley (\u03c6, \u03b1,\u03b2) where \u03c6 is a classical first-order closed formula and (\u03b1,\u03b2 )\u2208 [0,1] are a positive numbers.", "startOffset": 123, "endOffset": 128}, {"referenceID": 15, "context": "A fuzzy knowledge base \u2211 is defined as the set of weighted formulae [18].", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "where parents(Ai) is the set of parents of variable Ai, which is made as small as possible by exploiting conditional independencies of the type indicated above [9] and [10].", "startOffset": 160, "endOffset": 163}, {"referenceID": 9, "context": "We give next some definitions inspired from [12] and [13].", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "We give next some definitions inspired from [12] and [13].", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "To note here that in [15] the authors prove the possibility to recover conditional possibilities from \u2211A where \u2211A is a possibilistic knowledge base.", "startOffset": 21, "endOffset": 25}, {"referenceID": 12, "context": "Based o the results obtained in [15] , we can check in our case that it is possible to recover both conditional", "startOffset": 32, "endOffset": 36}, {"referenceID": 12, "context": "6 From Average valued knowledge base to average fuzzy Bayesian network In [15] the authors describe a process permitting to deduce a possibilistic network from a possibilistic knowledge base.", "startOffset": 74, "endOffset": 78}, {"referenceID": 16, "context": "7 Fuzzy Bayesian networks based on fuzzy necessity distribution Logical formulae with a weight strictly greater than a given levels (lower bounds of necessity degrees) are immune to inconsistency and can be safely used in deductive reasoning [19].", "startOffset": 242, "endOffset": 246}, {"referenceID": 17, "context": "A Bayesian network for metastatic cancer[20]", "startOffset": 40, "endOffset": 44}, {"referenceID": 0, "context": "For instance: C \u2208 [0, 1] represents the dichotomy between having a brain tumor and not having one, c denotes the assertion C = 1 or \u201cBrain tumor is present\u201d, and \u00acc is the", "startOffset": 18, "endOffset": 24}, {"referenceID": 0, "context": "\u03bc : [\u03b21, \u03b22] [0 1] (14) \u03c7 \u03bc (\u03c7)", "startOffset": 13, "endOffset": 18}], "year": 2006, "abstractText": "Within the framework proposed in this paper, we address the issue of extending the certain networks to a fuzzy certain networks in order to cope with a vagueness and limitations of existing models for decision under imprecise and uncertain knowledge. This paper proposes a framework that combines two disciplines to exploit their own advantages in uncertain and imprecise knowledge representation problems. The framework proposed is a possibilistic logic based one in which Bayesian nodes and their properties are represented by local necessity-valued knowledge base. Data in properties are interpreted as set of valuated formulas. In our contribution possibilistic Bayesian networks have a qualitative part and a quantitative part, represented by local knowledge bases. The general idea is to study how a fusion of these two formalisms would permit representing compact way to solve efficiently problems for knowledge representation. We show how to apply possibility and necessity measures to the problem of knowledge representation with large scale data. On the other hand fuzzification of crisp certainty degrees to fuzzy variables improves the quality of the network and tends to bring smoothness and robustness in the network performance. The general aim is to provide a new approach for decision under uncertainty that combines three methodologies: Bayesian networks certainty distribution and fuzzy logic . Key-Words: Possibilistic logic, Bayesian networks, Certain Bayesian networks, Local knowledge bases", "creator": "PDFCREATOR Version 0.8.0"}}}