{"id": "1206.1074", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2012", "title": "Memetic Artificial Bee Colony Algorithm for Large-Scale Global Optimization", "abstract": "Memetic computation (MC) has emerged recently as a new paradigm of efficient algorithms for solving the hardest optimization problems. On the other hand, artificial bees colony (ABC) algorithms demonstrate good performances when solving continuous and combinatorial optimization problems. This study tries to use these technologies under the same roof. As a result, a memetic ABC (MABC) algorithm has been developed that is hybridized with two local search heuristics: the Nelder-Mead algorithm (NMA) and the random walk with direction exploitation (RWDE). The former is attended more towards exploration, while the latter more towards exploitation of the search space. The stochastic adaptation rule was employed in order to control the balancing between exploration and exploitation. This MABC algorithm was applied to a Special suite on Large Scale Continuous Global Optimization at the 2012 IEEE Congress on Evolutionary Computation. The obtained results the MABC are comparable with the results of DECC-G, DECC-G*, and MLCC.", "histories": [["v1", "Tue, 5 Jun 2012 21:04:10 GMT  (187kb,D)", "http://arxiv.org/abs/1206.1074v1", "CONFERENCE: IEEE Congress on Evolutionary Computation, Brisbane, Australia, 2012"]], "COMMENTS": "CONFERENCE: IEEE Congress on Evolutionary Computation, Brisbane, Australia, 2012", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["iztok fister", "iztok fister jr", "janez brest", "viljem \\v{z}umer"], "accepted": false, "id": "1206.1074"}, "pdf": {"name": "1206.1074.pdf", "metadata": {"source": "CRF", "title": "Memetic Artificial Bee Colony Algorithm for Large-Scale Global Optimization", "authors": ["Iztok Fister", "Iztok Fister Jr.", "Janez Brest", "Viljem \u017dumer"], "emails": ["iztok.fister@uni-mb.si", "iztok.fister@guest.arnes.si", "janez.brest@uni-mb.si", "zumer@uni-mb.si"], "sections": [{"heading": null, "text": "In fact, most people are able to understand themselves and understand what it is all about: how to behave, how to behave, how to behave, how to behave, how to behave, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, how to do it, to do it, to do it, to do it, to do it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, to do what it, what it, to do what it, to do what it, what it, what it, to do, what it, what it, what it, what it, to do, what it, what it, what it, what it, what it, what it, what it is to do, what it, what it, what it, what it, what it is to do, what it, what it, what it, what it is to do, what it is to do, what it, what it, what it is, what it, what it is, what it is, what it is, what it is to do, what it is, what it is, what it is, what it is, what it is, what it is to do, what it is, what it is, what it is, what it is, what it is, what it is, what it is, what it is, what it is, what it is"}, {"heading": "II. MEMETIC ARTIFICIAL BEES COLONY ALGORITHM FOR LARGE-SCALE", "text": "GLOBAL OPTIMIZATION In the original ABC algorithm, the food process is carried out by three groups of bees: busy bees, observers and scouts. Each food source is discovered by only one busy bee. Based on information obtained from the employed foresters, the show bees make a decision about which food source to visit. When the food source is exhausted, the corresponding unemployed foresters become scouts. In order to make a super-fit individual who indicates the direction in which the search space of the bee colony needs to be explored, an additional step is added to the original ABC algorithms, i.e., they improve the best bees. As a result, the final scheme for the MABC algorithm is achieved as follows: Algorithm 1 pseudo-code of the MABC algorithms 1: Init (); 2: while! TerminationConditionMeet () 3: Send;"}, {"heading": "A. Stochastic long-distance exploration", "text": "In order to obtain an experimental solution, three operators are applied to the solution of each candidate, i.e. mutation, crossover and selection. The mutation operator in MABC implements a \u2032 rand / 1 / bin \u2032 similar DE mutation strategy, according to Equation (2): v (t) i = x (t) r1 + (x (t) r2 \u2212 x (t) r3), (2) where r1, r2, r3 are randomly selected candidate solutions and t is the generation number. This operator differs slightly from the original ABC modification operator. Conversely to DE, the constant scale parameter F is not used in the equation. (2) Instead of the original ABC expression for creating a new food position, which modifies only the single dimension of the experimental solution, the new expression is developed in MABC, which is able to modify several dimensions in the experimental solution. The number of modifications is controlled by parj-j =:"}, {"heading": "B. Stochastic moderate-distance exploration", "text": "The property q that the i-th viewer should visit the nectar quantity is expressed as follows: qi = fi \u2212 fworst fbest \u2212 fworst, (5) where fi, fworst and fbest denote the nectar quantities of the i-th, worst and best food sources. Stochastic exploration over medium distances is similar to long-distance exploration, i.e. an experimental solution is subject to the actions of the three operators: mutation, crossover and selection. In this case, MABC implements a \u2032 currenttobest / 1 / bin \u2032 like DE strategy as a mutation operator, expressed as: v (t) i = x (t) i + (t) best \u2212 x (t) i) r2."}, {"heading": "C. Deterministic short-distance exploration", "text": "Deterministic short-distance exploration attempts to make full use of promising search directions, the goal of which is to bring a candidate solution to the local optimum. In MABC, short-distance exploration is about maintaining a diversity of population.In population-based algorithms, diversity plays a critical role in the success of optimization. [29] A population's diversity is a measure of the different solutions available. [14] This measure can be expressed as the number of different existing fitness values, the number of different existing phenotypes, or the number of different existing genotypes. (In this study, the fitness diversity metric is expressed as [30]: 1 \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fbest \u2212 fis most pronounced, where the number of existing phenotypes or the number of different genotype diversity is expressed with metric-30)."}, {"heading": "D. Random long-distance exploration", "text": "In nature, when the food source is exhausted, the hunters become scouts. These scouts look for new food sources within the environment. In the MABC, scouts are simulated by a new randomly generated food source, which the scouts should detect in the remaining cycles of this algorithm. The food is exhausted when the predefined number of cycles (also known as the scout limit) has expired, in which no further improvement in nectar quantities is detected. Scouts are generated according to the equivalent (1). Note that this exploration is treated as remote sensing because the new food sources are scanned throughout the decision room S. On the other hand, the exploration is blind without any historical information having been explored so far."}, {"heading": "E. MABC framework", "text": "These memes interact with each other to solve problems. In the original ABC framework, the MC paradigm as a whole is not used, i.e. the memes are executed sequentially within each generation. Let's emphasize that the stochastic long distance (function SendEmployesBees ()) and stochastic medium distance (function SendOnlookerBees ()) explorations are carried out unconditionally, i.e. in each generation. On the other hand, the performances of the deterministic short distance (function LocalImproveBestBee ()) and the random long distance explorations (function SendScouts () are limited by the parameters local search ratio and scouts. The first parameter regulates the relationship between global and local search, while the second determines when to start exploring new regions of the continuous search space."}, {"heading": "III. EXPERIMENTS", "text": "One goal of the experiments was to apply MABC to the specific test suite proposed in the Special Session on Continuous Large-Scale Global Optimization at the IEEE Congress on Evolutionary Calculation 2012, to obtain results and then compare them with the results of DECC-G *, DECC-G and MLCC, as proposed by the Organizing Committee, to see how many competitive results were obtained."}, {"heading": "A. Test suite", "text": "The test suite consists of five problem classes, i.e. different high-dimensional problems (D = 1, 000): 1. Separable functions: \u2022 F1: Shifted Elliptic Function. \u2022 F2: Shifted Rastrigin's Function.2. Single-group m-nonseparable functions (m = 50): \u2022 F4: Single-group Shifted and m-rotated Elliptic Function. \u2022 F5: Single-group Shifted and m-rotated Rastrigin's Function.2. Single-group m-nonseparable functions (m = 50): \u2022 F4: Single-group Shifted and m-rotated Elliptic Function. \u2022 F5: Single-group Shifted and m-rotated Rastrigin's Function.F6: Single-group m-rotated and m-rotated Ackley's Function."}, {"heading": "B. Experimental setup", "text": "Table I shows the characteristics of the MABC algorithm used in the experiments. Note that all values of the algorithm parameters shown in this table were the best found in extensive experiments.The number of independent runs of the MABC algorithm was set at 25. The maximum number of function evaluations of FEs was set at 3 million. In addition to the final result, the error values of FEs = 120 000 and FEs = 600 000 were recorded.All of these values were prescribed by the organizing committee of this contests. Population size was set to 20. MABC with higher population sizes slowly converged, while the same algorithm with smaller population sizes remained in local optimum.The crossover probability CR was set to 0.01. That is, each crossover modified 10 dimensions of the experimental solution. The higher values of this parameter drastically reduced the results of MABC, while the number of exploiting the results had a detrimental effect on the results."}, {"heading": "C. PC configuration", "text": "All runs were performed on HP Compaq with the following configurations: 1. Processor - Intel Core i7-2600 3.4 (3.8) GHz"}, {"heading": "2. RAM - 4GB DDR3", "text": "3. Operating System - Linux Mint 12MABC was implemented within the Eclipse Indigo CDT Framework."}, {"heading": "IV. RESULTS", "text": "The results are analyzed from different angles and summarized in the following subsections: \u2022 Convergence diagrams, \u2022 Summary of results and \u2022 Comparison with other algorithms. The obtained results are presented in detail in the memory of this work."}, {"heading": "A. Convergence Plots", "text": "If a convergence of results is analyzed by solving different functions, four characteristic curves can be achieved: The characteristic diagrams, e.g. the functions F2, F11, F15 and F16, are in Figures 1-4. Note that the average results over 25 gradients are taken into account in all diagrams."}, {"heading": "B. Summary of Results", "text": "From this the following conclusions can be derived: \u2022 Divisible functions F1 \u2212 F3 are the easiest to solve for MABC; \u2022 Partially separable elliptical functions (F4, F9, F14) are the most difficult nut to crack for MABC; \u2022 On average, the functions of the D 2m group are shifted and m-rotated easier to solve than those of the D m group shifted and m-rotated, but the single-group shifted and m-rotated functions are the most difficult to solve.Although it should be true that completely non-divisible functions are the most difficult to solve, this truth cannot be derived from the results of the experiments."}, {"heading": "C. Comparison with other algorithms", "text": "In this experiment, the results of the following algorithms are compared with the results of the MABC (Table III): \u2022 DECC-G, \u2022 DECC-G * and \u2022 MLCC.Description, characteristics and results of the aforementioned algorithms are published on the conference pages [31].The comparison was carried out in a similar way to the rules laid down by the competition organising committee at LSGO CEC '2011. That is, the results for each algorithm are divided into three categories determined by the limits of FEs 1.2e5, 6.0e5 and 3.0e6, i.e. in the 1 25, 1 5 and the final evaluation figures. In the absence of results from the first two categories, only the final results were dealt with. Afterwards, the algorithms in the experiment are rewarded with the ranks of 1-4 according to their decreasing averages. Finally, rank 1 is rewarded with 25, rank 2 with 18, rank 3 with 15 and rank 4 with 12 points."}, {"heading": "V. CONCLUSION", "text": "This study presented an MABC algorithm that hybridizes the original ABC using two local search heuristics, namely NMA and RWDE. The first algorithm is more dedicated to exploration, while the second is more dedicated to the exploitation of the search space. An adaptive stochastic function was used to balance the process of exploration / exploitation. MABC's results were performed in the Special Suite on LSGO at IEEE CEC 2012 and compared with the results of the DECC-G, DECC-G * and MLCC algorithms, which were very competitive compared to the other algorithms. Furthermore, this algorithm was analyzed in the spirit of the MC, where four exploration stages are identified: stochastic long distances, stochastic medium distances, deterministic short distances and random long-distance explorations. Each of these stages should correspond to the respective meme. However, the interaction between the memory type should leave the additional options open for the development of this alphantom."}, {"heading": "Acknowledgment", "text": "The authors would acknowledge the efforts of the organizers of this session and the availability of the source code of benchmark functions. Furthermore, we thank Prof. Fatih Tasgetiren for his help in seeking the new directions in the development of the ABC algorithm. [1] E. Aarts and J.K. Lenstra. Local Search in Combinatorial Optimization. Princeton University Press, Inc., Princeton and Oxford, 1997. [3] T. Ba \ufffd ck. Evolutionary Algorithms in Theory and Practice: Evolutionary Computation. Computa-tional Intelligence Library. Oxford University Press, Inc., Bristol, UK, 1997. [4] T. Ba \ufffd ck. Evolutionary Strategies in Theory and Practice: Evolutionary Programming, Genetic Algorithms. Oxford University Press, Inc., New York, USA, 1996. [4] C. Blum and D. Merkle."}], "references": [{"title": "Local search in combinatorial optimization", "author": ["E. Aarts", "J.K. Lenstra"], "venue": "Princeton University Press, Princeton and Oxford,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1997}, {"title": "Handbook of Evolutionary Computation", "author": ["F. B\u00e4ck", "D.B. Fogel", "Z. Michalewicz"], "venue": "Computational Intelligence Library. Oxford University Press, Inc., Bristol, UK,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms", "author": ["T. B\u00e4ck"], "venue": "Oxford University Press, Inc., New York, USA,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "Swarm intelligence: introduction and applications", "author": ["C. Blum", "D. Merkle"], "venue": "Natural computing series. Springer-Verlag, Berlin, Germany,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Self-adapting control parameters in differential evolution: A comparative study on numerical benchmark problems", "author": ["J. Brest", "S. Greiner", "B. Boskovic", "M. Mernik", "V. Zumer"], "venue": "IEEE Trans. 16  Evolutionary Computation, 10(6):646\u2013657,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Self-adaptive differential evolution algorithm using population size reduction and three strategies", "author": ["J. Brest", "M.S. Mau\u010dec"], "venue": "Soft Computing - A Fusion of Foundations, Methodologies and Applications, 15(11):2157\u20132174,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Particle Swarm Optimization", "author": ["M. Clerc"], "venue": "ISTE Publishing Company, London, UK,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Evolutionary Algorithms for Solving Multi-Objective Problems, volume 5 of Genetic Algorithms and Evolutionary Computation", "author": ["C.A.C. Coello", "G.B. Lamont", "D.A. van Veldhuizen", "editors"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Memetic Algorithms in Continuous Optimization, pages 153\u2013165", "author": ["C. Cotta", "F. Neri"], "venue": "Handbook of Memetic Algorithms. Springer-Verlag, Berlin, Germany,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Differential evolution: A survey of the state-of-the-art", "author": ["S. Das", "P.N. Suganthan"], "venue": "IEEE Transaction on Evolutionary Computation, 15(1):4\u201331,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "The ant system: Optimization by a colony of cooperating agents", "author": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics, 26(1):29\u201341,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1996}, {"title": "Ant colony optimization", "author": ["M. Dorigo", "T. St\u00fctzle"], "venue": "MIT Press,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "A new optimizer using particle swarm theory", "author": ["R.C. Eberhart", "J. Kennedy"], "venue": "Proceedings of the Sixth International Symposium on Micro Machine and Human Science (MHS\u201995), pages 39\u201343, Piscataway, NJ, USA, October", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1995}, {"title": "Introduction to evolutionary computing", "author": ["A.E. Eiben", "J.E. Smith"], "venue": "Springer-Verlag, Berlin,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "A hybrid artificial bee colony for graph 3-coloring", "author": ["I. Fister Jr.", "I. Fister", "J. Brest"], "venue": "Artificial Intelligence and Soft Computing \u2013ICAISC 2012,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "A study on the use of non-parametric tests for analyzing the evolutionary algorithms\u2019 behaviour: a case study on the cec\u20192005 special session on real parameter optimization", "author": ["S. Garcia", "D. Molina", "M. Lozano", "F. Herrera"], "venue": "Journal of Heuristics, 15:617\u2013644,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Handbook of metaheuristics, volume 57 of International series in operations research & management science", "author": ["F. Glover", "G.A. Kochenberger"], "venue": "Kluwer Academic Publishers, Dordrecht, Netherlands,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Ockham\u2019s razor in memetic computing: Three stage optimal memetic exploration", "author": ["G. Iacca", "F. Neri", "E. Mininno", "Y.-S. Ong", "M.-H. Lim"], "venue": "Information Sciences, 188:17\u201343,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "A survey: algorithms simulating bee swarm intelligence", "author": ["D. Karaboga", "B. Bahriye"], "venue": "Artifficial Intelligence Review, 31(1\u20134):61\u201385,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "A powerful and efficient algorithm for numerical function optimization: artificial bee colony (abc) algorithm", "author": ["D. Karaboga", "B. Basturk"], "venue": "Journal of Global Optimization, 39(3):459\u2013 471,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Optimization by simulated annealing", "author": ["S. Kirkpatrick", "C.D. Gelatt", "Jr.", "M.P. Vecchi"], "venue": "Science Magazine,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1983}, {"title": "The Art of Computer Programming, Volume II: Seminumerical Algorithms", "author": ["D.E. Knuth"], "venue": "2nd Edition Addison-Wesley, Reading Massachusetts,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1981}, {"title": "Editorial scalability of evolutionary algorithms and other metaheuristics for large-scale continuous optimization problems", "author": ["T. Lozano", "D. Molina", "F. Herrera"], "venue": "Soft Computing - A Fusion of Foundations, Methodologies and Applications, 15(11):2085\u20132087,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Memetic Algorithms for Combinatorial Problems: Fitness Landscapes and Effective Search Strategy", "author": ["P. Merz"], "venue": "PhD thesis, Gesamthochschule Siegen, University of Siegen, Germany,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "Genetic Algorithms + Data Structures = Evolutionary Programs", "author": ["Z. Michalewicz"], "venue": "Springer- Verlag, Berlin,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1996}, {"title": "How to Solve It: Modern Heuristics", "author": ["Z. Michalewicz", "D.B. Fogel"], "venue": "Springer-Verlag, Berlin,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "On evolutionary search, optimization, genetic algorithms and martial arts: Toward memetic algorithms", "author": ["P. Moscato"], "venue": "Technical Report Caltech Concurrent Computation Program Report 826, Caltech, Pasadena, California,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1989}, {"title": "A simplex method for function optimization", "author": ["A. Nelder", "R. Mead"], "venue": "Computation Journal, 7:308\u2013313,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1965}, {"title": "Diversity Management in Memetic Algorithms, pages 153\u2013165", "author": ["F. Neri"], "venue": "Handbook of Memetic Algorithms. Springer-Verlag, Berlin, Germany,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "An adaptive multimeme algorithm for designing HIV multidrug therapies", "author": ["F. Neri", "J. Toivanen", "G.L. Cascella", "Y.-S. Ong"], "venue": "IEEE/ACM Transactions on Computational Biology and Bioinformatics, 4(2):264\u2013278,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "A note on the finite time behaviour of dimulated annealing", "author": ["A. Nolte", "R. Schrader"], "venue": "Mathematics of Operations Research, 25(3):476\u2013484,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2000}, {"title": "Memetic computation - past, present & future [research frontier", "author": ["Y.-S. Ong", "M.-H. Lim", "X. Chen"], "venue": "IEEE Computational Intelligence Magazine, 5(2):24\u201331,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Differential Evolution: A Practical Approach to Global Optimization", "author": ["K. Price", "R.M. Storn", "J.A. Lampinen"], "venue": "Springer-Verlag, New York, NY, USA,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2005}, {"title": "Engineering optimization: theory and practice", "author": ["S.S. Rao"], "venue": "John Willey & Sons, New Jersey, US,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "Benchmark Functions for the CEC 2010 Special Session and Competition on Large Scale Global Optimization", "author": ["K. Tang", "Xiaodong Li", "P.N. Suganthan", "Z. Yang", "T. Weise"], "venue": "Technical report, Nature Inspired Computation and Applications Laboratory, USTC, China,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2009}, {"title": "A discrete artificial bee colony algorithm for the total flowtime minimization in permutation flow shops", "author": ["M.F. Tasgetiren", "Q.-K. Pan", "P.N. Suganthan", "A.H.-L. Chen"], "venue": "Information Sciences, 181(16):3459\u20133475, 2011. Updated 4 June", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 24, "context": "The domain of function optimization serves as a \u2019test-bed\u2019 for many new comparisons and new features of various algorithms [25].", "startOffset": 123, "endOffset": 127}, {"referenceID": 16, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 79, "endOffset": 87}, {"referenceID": 25, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 79, "endOffset": 87}, {"referenceID": 20, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 172, "endOffset": 180}, {"referenceID": 30, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 172, "endOffset": 180}, {"referenceID": 1, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 212, "endOffset": 225}, {"referenceID": 2, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 212, "endOffset": 225}, {"referenceID": 7, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 212, "endOffset": 225}, {"referenceID": 22, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 212, "endOffset": 225}, {"referenceID": 4, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 255, "endOffset": 269}, {"referenceID": 5, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 255, "endOffset": 269}, {"referenceID": 9, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 255, "endOffset": 269}, {"referenceID": 32, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 255, "endOffset": 269}, {"referenceID": 6, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 305, "endOffset": 312}, {"referenceID": 12, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 305, "endOffset": 312}, {"referenceID": 10, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 347, "endOffset": 355}, {"referenceID": 11, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 347, "endOffset": 355}, {"referenceID": 0, "context": "EAs hybridized with local search algorithms [1] have been successful within this domain.", "startOffset": 44, "endOffset": 47}, {"referenceID": 23, "context": "These kinds of EAs are often named as memetic algorithms (MAs) [24, 27].", "startOffset": 63, "endOffset": 71}, {"referenceID": 26, "context": "These kinds of EAs are often named as memetic algorithms (MAs) [24, 27].", "startOffset": 63, "endOffset": 71}, {"referenceID": 31, "context": "Memetic computation (MC) [33] has emerged recently as a widening of MAs.", "startOffset": 25, "endOffset": 29}, {"referenceID": 3, "context": "As analog to EA, swarm intelligence (SI) [4] has been inspired by nature.", "startOffset": 41, "endOffset": 44}, {"referenceID": 18, "context": "This concept has been exploited also by the Artificial Bees Colony (ABC) algorithm proposed by Karaboga and Basturk [19] and achieved excellent results when solving continuous optimization problems [20] as well as combinatorial optimization problems [15, 37].", "startOffset": 116, "endOffset": 120}, {"referenceID": 19, "context": "This concept has been exploited also by the Artificial Bees Colony (ABC) algorithm proposed by Karaboga and Basturk [19] and achieved excellent results when solving continuous optimization problems [20] as well as combinatorial optimization problems [15, 37].", "startOffset": 198, "endOffset": 202}, {"referenceID": 14, "context": "This concept has been exploited also by the Artificial Bees Colony (ABC) algorithm proposed by Karaboga and Basturk [19] and achieved excellent results when solving continuous optimization problems [20] as well as combinatorial optimization problems [15, 37].", "startOffset": 250, "endOffset": 258}, {"referenceID": 35, "context": "This concept has been exploited also by the Artificial Bees Colony (ABC) algorithm proposed by Karaboga and Basturk [19] and achieved excellent results when solving continuous optimization problems [20] as well as combinatorial optimization problems [15, 37].", "startOffset": 250, "endOffset": 258}, {"referenceID": 17, "context": "[18] assert that an optimal memetic exploration of the search space is composed of three", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "Two local search methods were applied within the proposed memetic ABC (MABC) algorithm: the Nelder/Mead (NM) simplex method [35] and the random walk method with direction exploitation (RWDE) [35].", "startOffset": 124, "endOffset": 128}, {"referenceID": 33, "context": "Two local search methods were applied within the proposed memetic ABC (MABC) algorithm: the Nelder/Mead (NM) simplex method [35] and the random walk method with direction exploitation (RWDE) [35].", "startOffset": 191, "endOffset": 195}, {"referenceID": 8, "context": "The stochastic adaptive rule as specified by Neri [9] was applied for balancing the exploration and exploitation.", "startOffset": 50, "endOffset": 53}, {"referenceID": 8, "context": "In order to make a super-fit individual [9] that guides the direction in which the search space needs to be explored by the bee colony, an additional step is added to the original ABC algorithm, i.", "startOffset": 40, "endOffset": 43}, {"referenceID": 17, "context": "In the sense of MC analysis due to [18], each of these four functions perform certain exploration task, as follows:", "startOffset": 35, "endOffset": 39}, {"referenceID": 32, "context": "The stochastic long-distance exploration is performed in the DE fashion [34] as follows.", "startOffset": 72, "endOffset": 76}, {"referenceID": 28, "context": "In population-based algorithms, diversity plays a crucial role in the success of the optimization [29].", "startOffset": 98, "endOffset": 102}, {"referenceID": 13, "context": "The diversity of a population is a measure of the different solutions present [14].", "startOffset": 78, "endOffset": 82}, {"referenceID": 29, "context": "In this study, the fitness diversity metric is expressed as [30]:", "startOffset": 60, "endOffset": 64}, {"referenceID": 28, "context": "It is very sensible to small variations and thus, especially suitable for fitness landscapes containing plateaus and low gradient areas [29].", "startOffset": 136, "endOffset": 140}, {"referenceID": 27, "context": "The first is the Nelder-Mead Algorithm (NMA) [28] with exploration features and the second the Random Walk with Direction Exploitation (RWDE) [35] with exploitation features.", "startOffset": 45, "endOffset": 49}, {"referenceID": 33, "context": "The first is the Nelder-Mead Algorithm (NMA) [28] with exploration features and the second the Random Walk with Direction Exploitation (RWDE) [35] with exploitation features.", "startOffset": 142, "endOffset": 146}, {"referenceID": 21, "context": "Both values \u03bcp and \u03c3p are calculated incrementally in each generation according to the Knuth\u2019s algorithm [22].", "startOffset": 105, "endOffset": 109}, {"referenceID": 34, "context": "In contrast, the fully-nonseparable functions are usually the more difficult to solve [36].", "startOffset": 86, "endOffset": 90}, {"referenceID": 15, "context": "In order to check how significant these results are, the Friedman nonparametric test as proposed in [16] was performed with significant level \u03b1 = 0.", "startOffset": 100, "endOffset": 104}, {"referenceID": 0, "context": "[1] E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] F.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] T.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[32] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[33] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[34] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[35] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[36] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[37] M.", "startOffset": 0, "endOffset": 4}], "year": 2012, "abstractText": "Large-Scale Global Optimization Iztok Fister,\u2217 Iztok Fister Jr.,\u2020 Janez Brest,\u2021 and Viljem \u017dumer\u00a7 Abstract Memetic computation (MC) has emerged recently as a new paradigm of efficient algorithms for solving the hardest optimization problems. On the other hand, artificial bees colony (ABC) algorithms demonstrate good performances when solving continuous and combinatorial optimization problems. This study tries to use these technologies under the same roof. As a result, a memetic ABC (MABC) algorithm has been developed that is hybridized with two local search heuristics: the Nelder-Mead algorithm (NMA) and the random walk with direction exploitation (RWDE). The former is attended more towards exploration, while the latter more towards exploitation of the search space. The stochastic adaptation rule was employed in order to control the balancing between exploration and exploitation. This MABC algorithm was applied to a Special suite on Large Scale Continuous Global Optimization at the 2012 IEEE Congress on Evolutionary Computation. The obtained results the MABC are comparable with the results of DECC-G, DECC-G*, and MLCC. To cite paper as follows: I. Fister, I. Fister Jr., J. Brest, V. Zumer, Memetic Artificial Bee Colony Algorithm for Large-Scale Global Optimization, in Proc. IEEE Congress on Evolutionary Computation, Brisbane, Australia, 2012", "creator": "LaTeX with hyperref package"}}}