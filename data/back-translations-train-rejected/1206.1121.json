{"id": "1206.1121", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2012", "title": "Comparison of the C4.5 and a Naive Bayes Classifier for the Prediction of Lung Cancer Survivability", "abstract": "Numerous data mining techniques have been developed to extract information and identify patterns and predict trends from large data sets. In this study, two classification techniques, the J48 implementation of the C4.5 algorithm and a Naive Bayes classifier are applied to predict lung cancer survivability from an extensive data set with fifteen years of patient records. The purpose of the project is to verify the predictive effectiveness of the two techniques on real, historical data. Besides the performance outcome that renders J48 marginally better than the Naive Bayes technique, there is a detailed description of the data and the required pre-processing activities. The performance results confirm expectations while some of the issues that appeared during experimentation, underscore the value of having domain-specific understanding to leverage any domain-specific characteristics inherent in the data.", "histories": [["v1", "Wed, 6 Jun 2012 04:56:47 GMT  (597kb)", "http://arxiv.org/abs/1206.1121v1", "9 pages, 3 figures, 9 tables"], ["v2", "Sat, 1 Sep 2012 07:40:47 GMT  (603kb)", "http://arxiv.org/abs/1206.1121v2", "9 pages, 3 figures, 9 tables"]], "COMMENTS": "9 pages, 3 figures, 9 tables", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["george dimitoglou", "james a adams", "carol m jim"], "accepted": false, "id": "1206.1121"}, "pdf": {"name": "1206.1121.pdf", "metadata": {"source": "CRF", "title": "Comparison of the C4.5 and a Naive Bayes Classifier for the Prediction of Lung Cancer Survivability", "authors": ["George Dimitoglou", "James A. Adams", "Carol M. Jim"], "emails": ["dimitoglou@cs.hood.edu"], "sections": [{"heading": null, "text": "Index terms - Data Mining, Mining methods and algorithms, Text Mining - - - - - - - - - - - - - - -"}, {"heading": "1 INTRODUCTION", "text": "The proliferation of computer technologies in all areas of modern life has significantly increased the amount of data collected and stored."}, {"heading": "2 ALGORITHMS AND PREDICTION MODELS", "text": "In order to develop a predictive model, classifiers are the data mining algorithm of choice. The basic premise is to treat as input a collection of cases, each belonging to a small number of classes described by a fixed set of attributes [17]. The output of the classifier is the prediction of the class to which a new case belongs. Accuracy of the prediction depends on the classifier and the types of attributes and classes in the dataset. Classification can be viewed as an illustration of a set of attributes of a particular class [17]. Two classification techniques were used for data analysis, the Naive Bayes and the open source version of the statistical classifier C4.5."}, {"heading": "2.1 Naive Bayes", "text": "The Naive Bayes Algorithm is a simple probabilistic classifier that calculates a series of probabilities by calculating the frequency and combinations of values in a given dataset. The probability of a specific feature in the data appears as a member of a set of probabilities and is derived by calculating the frequency of each characteristic value within a class of a training dataset. The training dataset is a subset used to train a classifier algorithm by using known values to predict future unknown values. The algorithm uses the Bayes theorem [15] and assumes that all attributes are independent, since the value of the class variables is given. [18] This conditional assumption of independence rarely applies to real applications, hence characterization as naive, but the algorithm tends to be good per form and to learn quickly in various controlled classification problems. [18] This \"naivety\" allows the algorithm to construct data from large data schematics without allowing the algorithm to erect."}, {"heading": "2.2 J48", "text": "J48 is an implementation of C4.5 [20], which is the successor of the ID3 algorithm. [19] ID3 is based on methods of inductive logic programming, constructs a decision tree based on a training set of data and uses an entropy measurement variable to determine what characteristics of training cases are important to populate the leaves of the tree. First, the algorithm identifies the dominant attribute of the training set and uses it as the root of the tree. Second, it creates a leaf for every possible value the root can take. Then, it repeats the process using the training data classified by this leaf. [18] The core function of the algorithm is to determine the most appropriate attributes for dividing the data into different classes. The ID3 algorithm uses entropy and information gain [29] to measure the impurity of the data elements."}, {"heading": "3 DATA", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.4 Data Description", "text": "We used version 3.4.10 of the open source Weka to Environment for Knowledge Analysis (WEKA) toolkit [13] to determine the accuracy of two algorithms for predicting lung cancer survival. Data used in the experiments came from the RESPIR incidence files contained in three SEER records (Table 1).DIMITOGLOU: COMPARISON OF THE C4.5 AND NAIVE BAYES CLASSIFIERS FOR THE PREDICTION OF LUNG CANCER SURVIVABILITY 3There are a total of 481,432 records in the record. It contains records of patients who were diagnosed between 19732004 and NAIVE BAYES CLASSIFIERS FOR THE PREDICTION OF LUNG CANCER SURVIVABILITY 3. Due to the modification and addition of data fields, however, such records were removed from our 1988 data sets only."}, {"heading": "2.5 Preprocessing\u00a0Activities", "text": "It is not only a matter of time, but also of the way in which people in individual countries deal with the most diverse views and views, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved, how they behaved in the world, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to have behaved, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to have behaved, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they behaved, how they seem to the world, how they seem to the world, how they seem to the world, how they behaved, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they behaved, how they seem to the world, how they seem to the world, how they behaved, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they seem to the world, how they behaved, how they seem to the world, how they appear to the world, how they appear to the world, how they behaved, how they appear to the world, how they seem to the world, how they appear to the world, how they appear to the world, how they behaved, how they appear to the world, how they appear to the world, how they appear to the world, how they appear to the world, how they appear to the world, how they behaved, how they appear to the world, how they appear to the world, how they appear to the world, how they appear to the way they appear to the world, how they appear to the"}, {"heading": "2.8 Preliminary\u00a0Statistical\u00a0Analysis\u00a0Results", "text": "At this stage, a series of statistical measurements and counts are used to determine whether there are any interesting patterns simply by measuring the frequency of occurrence of elements and events in the data. Early results for the keyword tumor size indicate a trend, patient records with this attribute being less than 40 mm.Another interesting observation can be made via the Site Specific Surgery Code, which describes the body and organ locations that would have been operated on. The majority (95%) of the records are identified as lungs and bronchus and the remainder as pleura and windpipe, mediastinum and other respiratory organs. On the treatment page, the keyword Radiation, indic describes the method of radiotherapy performed during the initial treatment. While there are almost ten possible categories, 92% of the records in the data sets are in catalog categories under the diagnosis autopsy and radiotherapy."}, {"heading": "3 SURVIVABILITY", "text": "Survival rates and statistics indicate the percentage of patients who manage to develop cancer for a specified period of time, typically five years (60 months). Survival must be determined as causal survival, which is lung cancer survival, not any other cause. The designation of the ICD10 Death Code plays an important role in this determination, as patient records showing that it is impossible to survive due to causes other than lung cancer must be eliminated, assuming that the data contain a single, precise disease-specific death code. It is often difficult to be dependent on such variables, especially in cancer patients, as the cause of death can often be traced back to another location due to metastasis and not to the primary location. Moreover, survival rates are often vague when indicating whether a patient is still in treatment and whether the patient has achieved full or partial survival."}, {"heading": "2.9 Survival\u00a0Time", "text": "There is an interesting pattern in the data when comparing the mean survival time (MST) in months from year to year. The MST is very stable from year to year, gradu ally increasing as expected. However, there is a dramatic decrease between the years 1999 and 2000. 2. Survival time (in months) per year. The mean survival time in the 16-year range is constant for the first seven years, gradually in the wrinkles between years eight and twelve, and then dramaturgically every year by about 33% until the end of the data collection (Figure 2). The increase in the survival rate, which goes against the data in Figure 2, could be justified by the introduction of revolutionary treatment and very early prediction after the year 2000. Most likely, this decrease is due to a large increase in the number of patient records (Table 4)."}, {"heading": "4 EXPERIMENTATION", "text": "The aim of this study is to test the accuracy of two learning algorithms (Naive Bayes and J48) in predicting the survival of patients with lung cancer. After pre-processing, the data is ready to be processed by the two algorithms."}, {"heading": "19881992\u00a0 5 1993", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "19921998\u00a0 7 1999", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "19881997\u00a0 10 1998", "text": "Three experiments were carried out, each according to a common scenario: Using a variable number of consecutive years as a training data set, attempts were made to predict the accuracy of lung cancer incidence for a subsequent year (target year). In order to then determine the degree of accuracy for each algorithm, the predicted results are compared with the target data. Several data sets are used, which are identified by the number of training years and target data (Table 6)."}, {"heading": "2.10 Execution", "text": "The Naive Bayes algorithm was performed over each individual, five, seven, and ten year period, producing correctly classified instances ranging from 88.27% to 92.38% (Table 7); for each experiment, we obtained the Correctly Classified Instances (CCI), the Incorrect Classified In Instances (ICI), the Kappa Statistics (\u03ba), and the Rootmean Squareerror (RMSE); the CCI is the sampling accuracy without any random corrections; and it is expressed as a perDIMITOGLOU: COMPARISON OF THE C4.5 AND NAIVE BAYES CLASSIFIERS FOR THE PREDICTION OF LUNG SURVIVABILITY 7centage of correctly classified instances; the Kappa Statistics is a chance-corrected measure and NAE, and NAIVE BAYES CLASSIFIERS FOR THE PREDICTION CENTED INstances correctly classified."}, {"heading": "5 DISCUSSION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Classification Results", "text": "The aim of the experiments was to compare the strength of the two techniques in predicting the survival of patients with lung cancer. While overall classification accuracy is around 90%, there is an unexpected result.For both the Naive Bayes and the J48 algorithms, the 5-year training dataset delivers greater accuracy than the 7-year and 10-year training datasets. It would be expected that the 5-year training dataset would have higher prediction accuracy with more training data, but this is not the case. Two possible factors play a role: Firstly, the difference in the number of patient records between the three datasets is not proportional; the 5-year training dataset contains 15,780 lung cancer patient records and the 7-year training dataset contains 17,192. This is a difference of 1,412 (an increase of 8.94%) of patient records between the three datasets."}, {"heading": "7 CONCLUSION & FUTURE WORK", "text": "This study examines the ability of data mining and machine learning methods to accurately predict the survival of patients with lung cancer. Survival ability is defined as someone who lives beyond a period of 5 years. Generally, we achieve approximate predictive accuracy of about 90% by using either the Naive Bayes or the J48 algorithm. As a result of this study, a treating physician can theoretically collect a handful of medical metrics such as tumor size and location, treatment options, patient background, etc., and predict with a relatively high degree of accuracy whether the patient is likely to live for five years or more. Given the high mortality rate (> 90%) of patients in the study, it seems reasonable and useful to examine the survival ability of patients over a shorter period of time, for example, between twelve and eighteen months. Given the results and observations of the study, tree survival will focus on examining regional trends and the impact of the location on survival."}, {"heading": "ACKNOWLEDGMENT", "text": "The authors thank SEER and the National Cancer In Institute for the data. REFERENCES [1] American Cancer Society, Cancer Facts & Figures. American Cancer Society, Atlanta, GA, 2010, URL: http: / / www.cancer.org / research /. [2] American Cancer Society, Cancer Facts & Figures. [3] Biesalski, H and Bueno de Mesquita, B and Chesson, Chytil and Grimble, R and Hermus, R and Kohrle, J and Lotan, R and Norpoth, K and Pastorino, U and Thurnham, D, European Consesus Statement on Lung Cancer: risk factors and prevention."}], "references": [{"title": "Predicting Breast Cancer Survivability using Data Mining Techniques, Ninth Workshop on Mining Scientific and Engineering Datasets in conjunction with the Sixth SIAM International Conference on Data Mining (SDM", "author": ["A. Bellaachia", "E. Guven"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Lung cancer attributable to indoor radon exposure in France: impact of the risk models and uncertainty analysis", "author": ["Catelinois", "Olivier", "Rogel", "Agnes", "Laurier", "Dominique", "Bil\u00ad lon", "Solenne", "Hemon", "Denis", "Verger", "Pierre", "Tirmarche", "Margot"], "venue": "Environ\u00ad mental Health Perspectives,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Estimating the number of asbestos\u00adrelated lung cancer deaths in Great Britain", "author": ["Darnton", "Andrew J", "McElvenny", "Damien M", "Hodgson", "John T"], "venue": "The Annals of occupational hy\u00ad giene,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "A Clustering Approach in De\u00ad veloping Prognostic Systems of Cancer Patients", "author": ["Dechang Chen", "Kai Xing", "Donald Henson", "Li Sheng", "Arnold M. Schwartz", "Xiuzhen Cheng"], "venue": "In Proceedings of the 2008 Seventh International Conference on Machine Learning and Ap\u00ad plications (ICMLA \u201908)", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Knowledge Extraction from Prostate Cancer Data", "author": ["Dursun Delen", "Nainish Patil"], "venue": "In Proceedings of the 39th Annual Hawaii In\u00ad ternational Conference on System Sciences (HICSS \u201906),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Classification Algorithms in Comparing Classifier Categories to Predict the Accuracy of the Net\u00ad work Intrusion Detection \u00ad A Machine Learning Approach", "author": ["G M Gandhi", "S.K. Srivatsa"], "venue": "Advances  in Computational Sciences and Technology,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "An Empirical Study of the Behavior of Classifiers on Imbalanced and Overlapped Data Sets\", Lecture Notes in Computer Science, Volume 4756, Progress in Pattern Recognition, Image Analysis and Applications, Pages 397\u00ad406", "author": ["V. Garc\u00eda", "J. Sanchez", "R. Mollinenda"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "The accumulated evidence on lung cancer and environmental tobacco smoke", "author": ["AK Hackshaw", "MR Law", "Wald", "NJ"], "venue": "British Medical Journal,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "The WEKA Data Mining Software: An Up\u00ad", "author": ["M Hall", "F Eibe", "G Holmes", "B Pfahringer", "P Reutemann", "H. Witten I"], "venue": "date; SIGKDD Explorations,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Acute Cystitis and Acute Nephritis Prediction Using Machine Learning Techniques", "author": ["Kowsalya", "G R. Sasikala", "Sangeetha Priya J"], "venue": "Global Journal of Computer Science and Technology,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "A multidimensional measure function for classifier performance", "author": ["Lavesson", "Niklas", "Davidson", "Paul"], "venue": "In Proceedings of the 2nd IEEE International Conference on Intelligent Systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Asbestos\u00adrelated lung disease", "author": ["O\u2019Reilly", "Katherine M A", "Mclaughlin", "Anne Marie", "Beckett", "William S", "Sime", "Patricia J"], "venue": "American Family Physician,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "A Comparative Study of Data Min\u00ad ing Algorithms for Network Intrusion Detection", "author": ["M Panda", "R. Patra M"], "venue": "In Proceedings of the 2008 First International Conference on Emerging Trends in En\u00ad gineering and Technology (ICETET \u201908)", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Network Intrusion Detection using Naive Bayes, International journal of Computer Science and Network Security, Dec\u02c6AZ30\u00ad2007, pp.258\u00ad263", "author": ["M Panda", "R. Patra M"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Model\u00ad ing intrusion detection system using hybrid intelligent systems", "author": ["S. Peddabachigari", "A. Abraham", "G. Grosan", "Thomas"], "venue": "J. Netw. Comput. Appl. 30,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Decision Trees and Decision Making", "author": ["J. Quinlan R"], "venue": "IEEE Trans\u00ad action on System Man Cyber,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1990}, {"title": "Improved use of continuous attributes in C4.5", "author": ["J. Quinlan R"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1996}, {"title": "Cigarette smoking and lung cancer in New Mexico. The Amer\u00ad ican Review of Respiratory Disease", "author": ["M Samet J", "L Wiggins C", "G Humble C", "R. Pathak D"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}, {"title": "Classification of Arrhythmia Using Machine Learning Techniques", "author": ["T. Soman", "P.O. Bobbie"], "venue": "WSEAS Transactions on Computers,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "Combination Data Mining Methods with New Medical Data to Predicting Outcome of Coronary Heart Disease", "author": ["Yanwei Xing", "Jie Wang", "Zhihong Zhao", "Yonghong Gao"], "venue": "In Proceedings of the 2007 International Conference on Convergence Information Tech\u00ad nology (ICCIT \u201907)", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "A Comparative Study for Email Classi\u00ad fication", "author": ["S. Youn", "D. McLeod"], "venue": "Proceedings of International Joint Conferences on Computer,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "Data Mining: Practical Machine Learning Tools and Techniques", "author": ["Witten Ian H", "Frank Eibe"], "venue": "James A. Adams is Sr. Systems Analyst with Marriott International. He holds a M.S. in computer science from Hood College where he received the 2008 Departmental Scholar Award. Carol A. Jim is a doctoral student in computer science at The George Washington University. She holds a B.S. in mathematics and computer science and a M.S. in computer science from Hood College where she received the 2010 Departmental Scholar Award", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "This type of analysis is not unique, in fact it was inspired by a similar analysis on breast cancer survivab\u00ad ility techniques [2].", "startOffset": 127, "endOffset": 130}, {"referenceID": 8, "context": "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes\u00ad tos [6, 16] and radon gas [5] have also been linked with the in\u00ad cidence of the disease.", "startOffset": 68, "endOffset": 79}, {"referenceID": 17, "context": "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes\u00ad tos [6, 16] and radon gas [5] have also been linked with the in\u00ad cidence of the disease.", "startOffset": 68, "endOffset": 79}, {"referenceID": 3, "context": "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes\u00ad tos [6, 16] and radon gas [5] have also been linked with the in\u00ad cidence of the disease.", "startOffset": 107, "endOffset": 114}, {"referenceID": 12, "context": "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes\u00ad tos [6, 16] and radon gas [5] have also been linked with the in\u00ad cidence of the disease.", "startOffset": 107, "endOffset": 114}, {"referenceID": 2, "context": "Smoking  has  been  identified  as  the greatest contributing cause [3, 12, 22] but exposure to asbes\u00ad tos [6, 16] and radon gas [5] have also been linked with the in\u00ad cidence of the disease.", "startOffset": 129, "endOffset": 132}, {"referenceID": 4, "context": "As  a   result,  methods  and  tech\u00ad niques   from the  computing sciences   related  to  knowledge discovery   and   data  mining   have   become   very   useful   in identifying patterns and analyzing relationships in the data that may lead to better disease outcome prediction [7, 8, 23, 26].", "startOffset": 280, "endOffset": 294}, {"referenceID": 18, "context": "As  a   result,  methods  and  tech\u00ad niques   from the  computing sciences   related  to  knowledge discovery   and   data  mining   have   become   very   useful   in identifying patterns and analyzing relationships in the data that may lead to better disease outcome prediction [7, 8, 23, 26].", "startOffset": 280, "endOffset": 294}, {"referenceID": 19, "context": "As  a   result,  methods  and  tech\u00ad niques   from the  computing sciences   related  to  knowledge discovery   and   data  mining   have   become   very   useful   in identifying patterns and analyzing relationships in the data that may lead to better disease outcome prediction [7, 8, 23, 26].", "startOffset": 280, "endOffset": 294}, {"referenceID": 13, "context": "The basic premise is based on treating a collection of cases as input, each belonging to a small number of classes described by a fixed set of attributes [17].", "startOffset": 154, "endOffset": 158}, {"referenceID": 13, "context": "Classification may be viewed as mapping from a set of attributes to a particular class [17].", "startOffset": 87, "endOffset": 91}, {"referenceID": 11, "context": "The algorithm uses Bayes theorem [15] and assumes all attributes to be independent   given the value of  the class variable.", "startOffset": 33, "endOffset": 37}, {"referenceID": 14, "context": "This  conditional  independence  assumption rarely  holds  true  in  real\u00adworld   applications,  hence  the characterization as Naive yet  the algorithm  tends  to per\u00ad form well and  learn rapidly in various supervised classi\u00ad fication problems [18].", "startOffset": 246, "endOffset": 250}, {"referenceID": 15, "context": "5  [20]  which  is  the  suc\u00ad cessor of the ID3 algorithm [19].", "startOffset": 58, "endOffset": 62}, {"referenceID": 14, "context": "Then, for each of the leaves it repeats the process using the training set data classified by this leaf [18].", "startOffset": 104, "endOffset": 108}, {"referenceID": 16, "context": "The ID3 algorithm [21] uses entropy and information gain [29],   bor\u00ad rowed from information theory,  to measure  the  impurity of the data items.", "startOffset": 18, "endOffset": 22}, {"referenceID": 21, "context": "The ID3 algorithm [21] uses entropy and information gain [29],   bor\u00ad rowed from information theory,  to measure  the  impurity of the data items.", "startOffset": 57, "endOffset": 61}, {"referenceID": 21, "context": "Informa\u00ad tion gain [29] measures the decrease of the weighted average entropy of  the  attributes  compared with  the  entropy of  the complete  dataset.", "startOffset": 19, "endOffset": 23}, {"referenceID": 6, "context": "For example,  in the  context  of  intrusion  detection  systems,  one  study  [10] found  J48 performing better than another similar study [16], while studies in the prediction of acute cystitis and  nephritis [14]  and  the  classification  of  arrhythmia  data  [23]  the  per\u00ad formance of Naive Bayes was superior.", "startOffset": 79, "endOffset": 83}, {"referenceID": 12, "context": "For example,  in the  context  of  intrusion  detection  systems,  one  study  [10] found  J48 performing better than another similar study [16], while studies in the prediction of acute cystitis and  nephritis [14]  and  the  classification  of  arrhythmia  data  [23]  the  per\u00ad formance of Naive Bayes was superior.", "startOffset": 140, "endOffset": 144}, {"referenceID": 10, "context": "For example,  in the  context  of  intrusion  detection  systems,  one  study  [10] found  J48 performing better than another similar study [16], while studies in the prediction of acute cystitis and  nephritis [14]  and  the  classification  of  arrhythmia  data  [23]  the  per\u00ad formance of Naive Bayes was superior.", "startOffset": 211, "endOffset": 215}, {"referenceID": 18, "context": "For example,  in the  context  of  intrusion  detection  systems,  one  study  [10] found  J48 performing better than another similar study [16], while studies in the prediction of acute cystitis and  nephritis [14]  and  the  classification  of  arrhythmia  data  [23]  the  per\u00ad formance of Naive Bayes was superior.", "startOffset": 265, "endOffset": 269}, {"referenceID": 20, "context": "Similarly, in the con\u00ad text of spam e\u00admail identification [27], J48   performed better in  terms  of  accuracy  of  overall  classification  despite  the widespread use of Bayesian\u00adbased span filtering techniques.", "startOffset": 58, "endOffset": 62}, {"referenceID": 9, "context": "10  of  the  open  source toolkit  Weka  to  Environment  for  Knowledge  Analysis (WEKA) [13] to determine the accuracy of two algorithms in predicting lung cancer survivability.", "startOffset": 90, "endOffset": 94}, {"referenceID": 5, "context": "Tumor location in the body, as classi\u00ad fied by the International Classification of Diseases for On\u00ad cology (ICD\u00adO\u00ad3) [9] for topography codes.", "startOffset": 117, "endOffset": 120}, {"referenceID": 11, "context": "From the results, the Naive Bayes technique remained true to its reputation and its portrayal in the literature: it is robust, easy to interpret, it often does surprisingly well but may not be the best classifier in any particular application [15].", "startOffset": 243, "endOffset": 247}], "year": 2012, "abstractText": "Numerous data mining techniques have been developed to extract information and identify patterns and predict trends from large data sets. In this study, two classification techniques, the J48 implementation of the C4.5 algorithm and a Naive Bayes classifier are applied to predict lung cancer survivability from an extensive data set with fifteen years of patient records. The purpose of the project is to verify the predictive effectiveness of the two techniques on real, historical data. Besides the performance outcome that renders J48 marginally better than the Naive Bayes technique, there is a detailed description of the data and the required pre-processing activities. The performance results confirm expectations while some of the issues that appeared during experimentation, underscore the value of having domain-specific understanding to leverage any domain-specific characteristics inherent in the data.", "creator": "Writer"}}}