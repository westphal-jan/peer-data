{"id": "1206.2691", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2012", "title": "IDS: An Incremental Learning Algorithm for Finite Automata", "abstract": "We present a new algorithm IDS for incremental learning of deterministic finite automata (DFA). This algorithm is based on the concept of distinguishing sequences introduced in (Angluin81). We give a rigorous proof that two versions of this learning algorithm correctly learn in the limit. Finally we present an empirical performance analysis that compares these two algorithms, focussing on learning times and different types of learning queries. We conclude that IDS is an efficient algorithm for software engineering applications of automata learning, such as testing and model inference.", "histories": [["v1", "Wed, 13 Jun 2012 00:27:36 GMT  (143kb,D)", "http://arxiv.org/abs/1206.2691v1", "8 pages, 5 figures"]], "COMMENTS": "8 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.LG cs.DS cs.FL", "authors": ["muddassar a sindhu", "karl meinke"], "accepted": false, "id": "1206.2691"}, "pdf": {"name": "1206.2691.pdf", "metadata": {"source": "CRF", "title": "IDS: An Incremental Learning Algorithm for Finite Automata", "authors": ["Muddassar A. Sindhu", "Karl Meinke"], "emails": [], "sections": [{"heading": null, "text": "This year it has come to the point where we are going to be able to assert ourselves, that we are able to assert ourselves in the world, and that we are able to assert ourselves, that we are able to assert ourselves in the world, that we are able to assert ourselves, that we are able to assert ourselves, that we are able to stay in the world, \"he said."}, {"heading": "A. Related Work", "text": "The ID algorithm is not incremental because only one hypothesis is automated. Later, an incremental version of this algorithm was presented in [11]. Like the IID algorithm, our IDS algorithm is also incremental. However, unlike IID, the IDS algorithm and its verification of correctness are much simpler, and some technical errors in [11] are also overcome. Distinguishing sequences can be compared to the completely uniform tabular approach to partition construction as represented by the well-known online learning algorithm L * of [9]. Distinguishing sequences in Xiv: 120 6.26 91v1 [cs.LG] 1 3Ju n20 122 is an equivalence oracle in the learning phase. In contrast to L *, the differentiation of sequences in Xiv is disposed: 120 6.2 [s.LG] 1 3Ju n20 12x2 a learning equivalent in the learning phase."}, {"heading": "II. PRELIMINARIES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Notations and concepts for DFA", "text": "The length of a set of symbols is denoted by | \u03b1 | and | \u03bb | = 0. We leave pref (\u03b1) the prefix closure of \u03b1, i.e. the set of all prefix prefixes of \u03b1, i.e. the set of all prefix prefixes of \u03b1, i.e. the set of all prefix prefixes of \u03b1. We can also apply prefix closure points to any set of strings. The set difference operation between two sets U and V, which is denoted by U \u2212 V, is the set of elements of U that are not members of V. The symmetrical difference operation, which is defined by pairs of sets, is defined by U-V-U. (V \u2212 U) The set of difference machines (DFA) is a set of elements of U that are not members of V. The symmetrical difference operation, which is defined by pairs of sets."}, {"heading": "B. The ID Algorithm", "text": "Our IDS algorithm is an incremental version of the ID learning algorithm introduced in [1] and [2]. The ID algorithm is an online learning algorithm for complete learning of a DFA, based on a given, complete set of P's itself. It is useful to check the ID algorithm here and generate new queries until a participation in the state space can be constructed. As this algorithm has been discussed extensively in [1], our own presentation can be brief. Detailed proof of the accuracy of the ID and an analysis of its complexity can be found in [1]. A finite set of P's of input strings is said to exist a complete element for a DFA state if there is a string."}, {"heading": "C. Behavioural differences between IID and IDS", "text": "However, the following points of behaviour of IID and IDS are worth mentioning: 1) IID begins with a zero DFA hypothesis, while IDS, on the other hand, constructs the initial hypothesis with all negative and positive examples after building a starting hypothesis that makes it more useful for practical software engineering applications identified in Section I. 3) IID in some cases builds hypotheses that have a partially defined transition function, rather than showing them with an example in the next section. IDS fixes this problem based on lines 10-13 of algorithms 4 are described in this paper. 4) Unlike IDS, there is no prefixed free version of IID.5) In addition to the above, it is easily detectable that two of the IDS solutions are not satisfactory."}, {"heading": "IV. EMPIRICAL PERFORMANCE ANALYSIS", "text": "This question can be answered experimentally by randomly selecting a large number of DFA with a certain statespace size and randomly generating a sequence of query strings for each such DFA. From the point of view of software engineering applications such as tests and model conclusions, we have found that it is important to distinguish between the two types of target automation queries used by IDS during the learning process. On the one hand, the algorithm uses internally generated queries (we call these accounting sources) and on the other hand, it uses queries supplied externally from the input file."}, {"heading": "A. Results and Interpretation", "text": "The graph in Figures 4 and 5 illustrates the outcome of our experiments to measure the average time and complexity of queries from both IDS algorithms, as shown in Section IV. Figure 4 shows the results of estimating the average learning time for the prefix free and prefix closed IDS algorithms as a function of the state spatial size of the target DFA. Nevertheless, there is enough data to identify some clear trends. The average learning time for the prefix free IDS learning is substantially greater than the time for prefix closed IDS size. Therefore, the two data curves are not smooth for large state spatial sizes."}, {"heading": "V. CONCLUSIONS", "text": "We have presented two versions of the IDS algorithm, an incremental algorithm for learning DFA in polynomic time. We have provided rigorous proof that both algorithms are learning within the limit correctly. Finally, we have presented the results of an empirical study on the average time and query complexity of IDS. These empirical results suggest that the IDS algorithm is well suited for software engineering applications where an incremental approach is required to enable externally generated online queries. This conclusion is also supported by [6], where we have evaluated the IDS algorithm for learning-based testing of reactive systems and have shown that it leads to error detection up to 4000 times faster than non-incremental learning. We thank the financial support for this research by the University Commission (HEC) of Pakistan, the Swedish Research Council (VR) and the EU within the project HATS FP7-2320."}], "references": [{"title": "A note on the number of queries needed to identify regular languages", "author": ["D. Angluin"], "venue": "Information and Control, vol. 51, no. 1, pp. 76\u201387, October 1981.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1981}, {"title": "Black-box checking", "author": ["D. Peled", "M. Vardi", "M. Yannakakis"], "venue": "Formal Methods for Protocol Engineering and Distributed Systems FORTE/PSTV. Kluwer, 1999, pp. 225\u2013240.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Sat-based abstraction refinement using ilp and machine learning", "author": ["E. Clarke", "A. Gupta", "J. Kukula", "O. Strichman"], "venue": "Proc. 21st International Conference On Computer Aided Verification (CAV\u201902), 2002.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning meets verification", "author": ["M. Luecker"], "venue": "FMCO, ser. Lecture Notes in Computer Science, F. S. de Boer et al., Ed., vol. 4709. Springer, 2006, pp. 127\u2013151.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Dynamic testing via automata learning", "author": ["H. Raffelt", "B. Steffen", "T. Margaria"], "venue": "Hardware and Software: Verification and Testing, ser. LNCS, no. 4899. Springer, 2008, pp. 136\u2013152.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Incremental learning-based testing for reactive systems", "author": ["K. Meinke", "M.A. Sindhu"], "venue": "Tests and Proofs, ser. Lecture Notes in Computer Science, M. Gogolla and B. Wolff, Eds., vol. 6706. Springer, 2011, pp. 134\u2013151.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Regular inference for communication protocol entities", "author": ["T. Bohlin", "B. Jonsson"], "venue": "Dept. of Information Technology, Uppsala University, Technical Report 2008-024, 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Language identification in the limit", "author": ["E.M. Gold"], "venue": "Information and Control, vol. 10, pp. 447\u2013474, 1967.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1967}, {"title": "Learning regular sets from queries and counterexamples", "author": ["D. Angluin"], "venue": "Information and Computation, vol. 75, no. 1, pp. 87\u2013106, November 1987.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1987}, {"title": "Incremental regular inference", "author": ["P. Dupont"], "venue": "Proceedings of the Third ICGI-96, ser. LNAI, no. 1147, 1996.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "A polynomial time incremental algorithm for regular grammar inference", "author": ["R. Parekh", "C. Nichitiu", "V. Honavar"], "venue": "Proc. Fourth Int. Colloq. on Grammatical Inference (ICGI 98), ser. LNAI. Springer, 1998.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1998}, {"title": "Learning automata from ordered examples", "author": ["S. Porat", "J.A. Feldman"], "venue": "Mach. Learn., vol. 7, pp. 109\u2013138, September 1991. [Online]. Available: http://portal.acm.org/citation.cfm?id=125342.125343", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1991}, {"title": "Automated black-box testing of functional correctness using function approximation", "author": ["K. Meinke"], "venue": "ISSTA \u201904: Proceedings of the 2004 ACM SIGSOFT international symposium on Software testing and analysis. New York, NY, USA: ACM, 2004, pp. 143\u2013153.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "A learning-based approach to unit testing of numerical software", "author": ["K. Meinke", "F. Niu"], "venue": "Proc. Twenty Second IFIP Int. Conf. on Testing Software and Systems (ICTSS 2010), ser. LNCS, no. 6435. Springer, 2010, pp. 221\u2013235.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Inferring regular languages in polynomial update time", "author": ["P. Oncina", "Garc\u00eda"], "venue": "World Scientific Publishing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1991}, {"title": "Random dfa\u2019s can be approximately learned from sparse uniform examples", "author": ["K.J. Lang"], "venue": "Proceedings of the fifth annual workshop on Computational learning theory, ser. COLT \u201992. New York, NY, USA: ACM, 1992, pp. 45\u201352. [Online]. Available: http://doi.acm.org/10.1145/130385.130390", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1992}, {"title": "A linear algorithm for testing equivalence of finite automata", "author": ["J.E. Hopcroft", "R.M. Karp"], "venue": "Cornell University, Tech. Rep. TR 71-114, 1971. [Online]. Available: http://hdl.handle.net/1813/5958", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1971}], "referenceMentions": [{"referenceID": 0, "context": "This algorithm is based on the concept of distinguishing sequences introduced in [1].", "startOffset": 81, "endOffset": 84}, {"referenceID": 1, "context": "[2],[3], [4] ) software testing (e.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[2],[3], [4] ) software testing (e.", "startOffset": 4, "endOffset": 7}, {"referenceID": 3, "context": "[2],[3], [4] ) software testing (e.", "startOffset": 9, "endOffset": 12}, {"referenceID": 4, "context": "[5],[6] ) and model inference (e.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[5],[6] ) and model inference (e.", "startOffset": 4, "endOffset": 7}, {"referenceID": 6, "context": "[7]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "The notion of convergence in the limit, as a model of correct incremental learning originates in [8].", "startOffset": 97, "endOffset": 100}, {"referenceID": 0, "context": "Other approaches, such as [1] and [9] have considered online learning,", "startOffset": 26, "endOffset": 29}, {"referenceID": 8, "context": "Other approaches, such as [1] and [9] have considered online learning,", "startOffset": 34, "endOffset": 37}, {"referenceID": 9, "context": "the RPNI2 algorithm of [10], the IID algorithm of [11] and the algorithm of [12].", "startOffset": 23, "endOffset": 27}, {"referenceID": 10, "context": "the RPNI2 algorithm of [10], the IID algorithm of [11] and the algorithm of [12].", "startOffset": 50, "endOffset": 54}, {"referenceID": 11, "context": "the RPNI2 algorithm of [10], the IID algorithm of [11] and the algorithm of [12].", "startOffset": 76, "endOffset": 80}, {"referenceID": 12, "context": "[13], [14], [6]) has led us to investigate the use of distinguishing sequences to design incremental learning algorithms for DFA.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[13], [14], [6]) has led us to investigate the use of distinguishing sequences to design incremental learning algorithms for DFA.", "startOffset": 6, "endOffset": 10}, {"referenceID": 5, "context": "[13], [14], [6]) has led us to investigate the use of distinguishing sequences to design incremental learning algorithms for DFA.", "startOffset": 12, "endOffset": 15}, {"referenceID": 0, "context": "Distinguishing sequences were first applied to derive the ID online learning algorithm for DFA in [1].", "startOffset": 98, "endOffset": 101}, {"referenceID": 5, "context": "In [6] this algorithm has been successfully applied to learning based testing of reactive systems with demonstrated error discovery rates up to 4000 times faster than using non-incremental learning.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "Distinguishing sequences were first applied to derive the ID online learning algorithm for DFA in [1].", "startOffset": 98, "endOffset": 101}, {"referenceID": 10, "context": "Later an incremental version IID of this algorithm was presented in [11].", "startOffset": 68, "endOffset": 72}, {"referenceID": 10, "context": "the IDS algorithm, and its proof of correctness are much simpler, and some technical errors in [11] are also overcome.", "startOffset": 95, "endOffset": 99}, {"referenceID": 8, "context": "Distinguishing sequences can be contrasted with the complete consistent table approach to partition construction as represented by the well known online learning algorithm L* of [9].", "startOffset": 178, "endOffset": 181}, {"referenceID": 9, "context": "In [10], an incremental version RPNI2 of the RPNI offline learning algorithm of [15] and [16] is presented.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "In [10], an incremental version RPNI2 of the RPNI offline learning algorithm of [15] and [16] is presented.", "startOffset": 80, "endOffset": 84}, {"referenceID": 15, "context": "In [10], an incremental version RPNI2 of the RPNI offline learning algorithm of [15] and [16] is presented.", "startOffset": 89, "endOffset": 93}, {"referenceID": 11, "context": "The incremental learning algorithm introduced in [12] requires a lexicographic ordering on the presentation of online queries, which is less flexible than IDS, and indeed inappropriate for software engineering applications.", "startOffset": 49, "endOffset": 53}, {"referenceID": 0, "context": "Our IDS algorithm is an incremental version of the ID learning algorithm introduced in [1].", "startOffset": 87, "endOffset": 90}, {"referenceID": 0, "context": "Since this algorithm has been discussed at length in [1], our own presentation can be brief.", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "A detailed proof of correctness of ID and an analysis of its complexity can be found in [1].", "startOffset": 88, "endOffset": 91}, {"referenceID": 10, "context": "The IID algorithm of [11] also presents a simulation method", "startOffset": 21, "endOffset": 25}, {"referenceID": 0, "context": "Proof: (i) See [1] Theorem 3.", "startOffset": 15, "endOffset": 18}, {"referenceID": 10, "context": "This difference means that the automaton construction algorithm (Algorithm 1, lines 28-37) used for ID can no longer be used for IID, (as asserted in [11]) as we show below.", "startOffset": 150, "endOffset": 154}, {"referenceID": 10, "context": "to start learning A using the IID algorithm of [11], we have P0 = Pref(b) = {b, \u03bb} and P \u2032 0 = {b, \u03bb} \u222a {d0} = {b, \u03bb, d0}.", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "Therefore the IID algorithm of [11] does not always generate a hypothesis automaton", "startOffset": 31, "endOffset": 35}, {"referenceID": 8, "context": "The notion of closed and consistent observation table is given in [9] for L* algorithm.", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "If Ei(\u03b1) 6= Ei(\u03b2) as in the above example where E1(bb) = {\u03bb} is not equal to any of E1(d0) = \u2205, E1(\u03bb) = {b} or E1(b) = {\u03bb, b} then the solution in [9] is to move \u03b2 \u2208 T \\ P \u2032 to set P \u2032 and ask more queries to rebuild the congruence that might have been affected by this last addition to set P \u2032.", "startOffset": 147, "endOffset": 150}, {"referenceID": 7, "context": "of [8].", "startOffset": 3, "endOffset": 6}, {"referenceID": 16, "context": "We chose an algorithm with nearly linear time performance described in [17].", "startOffset": 71, "endOffset": 75}, {"referenceID": 5, "context": "This conclusion is further supported in [6] where we have evaluated the IDS algorithm for learning based testing of reactive systems, and shown that it leads to error discovery up to 4000 times faster than using non-incremental", "startOffset": 40, "endOffset": 43}], "year": 2012, "abstractText": "We present a new algorithm IDS for incremental learning of deterministic finite automata (DFA). This algorithm is based on the concept of distinguishing sequences introduced in [1]. We give a rigorous proof that two versions of this learning algorithm correctly learn in the limit. Finally we present an empirical performance analysis that compares these two algorithms, focussing on learning times and different types of learning queries. We conclude that IDS is an efficient algorithm for software engineering applications of automata learning, such as formal software testing and model inference.", "creator": "LaTeX with hyperref package"}}}