{"id": "1206.3111", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2012", "title": "The third open Answer Set Programming competition", "abstract": "Answer Set Programming (ASP) is a well-established paradigm of declarative programming in close relationship with other declarative formalisms such as SAT Modulo Theories, Constraint Handling Rules, FO(.), PDDL and many others. Since its first informal editions, ASP systems have been compared in the now well-established ASP Competition. The Third (Open) ASP Competition, as the sequel to the ASP Competitions Series held at the University of Potsdam in Germany (2006-2007) and at the University of Leuven in Belgium in 2009, took place at the University of Calabria (Italy) in the first half of 2011. Participants competed on a pre-selected collection of benchmark problems, taken from a variety of domains as well as real world applications. The Competition ran on two tracks: the Model and Solve (M&amp;S) Track, based on an open problem encoding, and open language, and open to any kind of system based on a declarative specification paradigm; and the System Track, run on the basis of fixed, public problem encodings, written in a standard ASP language. This paper discusses the format of the Competition and the rationale behind it, then reports the results for both tracks. Comparison with the second ASP competition and state-of-the-art solutions for some of the benchmark domains is eventually discussed.", "histories": [["v1", "Thu, 14 Jun 2012 14:03:28 GMT  (8002kb,A)", "http://arxiv.org/abs/1206.3111v1", "37 pages, 12 figures, 1 table - To appear in Theory and Practice of Logic Programming (TPLP)"]], "COMMENTS": "37 pages, 12 figures, 1 table - To appear in Theory and Practice of Logic Programming (TPLP)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["francesco calimeri", "giovambattista ianni", "francesco ricca"], "accepted": false, "id": "1206.3111"}, "pdf": {"name": "1206.3111.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["calimeri@mat.unical.it)", "ianni@mat.unical.it)", "ricca@mat.unical.it)"], "sections": [{"heading": null, "text": "ar Xiv: 120 6.31 11v1 [cs.AI] 1The competition ran on two tracks: the Model and Solve (M & S) track, based on open problem encoding and open language and open to all types of systems based on a declarative specification paradigm; and the System Track, based on fixed, public problem encoding, written in a standard ASP language. This paper discusses the format of the competition and its underlying principles and then reports the results for both tracks. Finally, the comparison with the second ASP competition and state-of-the-art solutions for some of the benchmark areas is discussed. KEYWORDS: Answer Set Programming, Logic Programming, Declarative Languages, Artificial Intelligence Competitions"}, {"heading": "1 Introduction", "text": "In fact, it is such that most of them will be able to move to another world, in which they will be able to integrate themselves, and in which they will be able to integrate themselves. (...) Most of them are able to move to another world. (...) Most of them are able to move to another world. (...) Most of them are able to live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live in which they live, in which they live in which they live in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live in"}, {"heading": "2 Competition Format", "text": "This year it has come to the point where it is a purely reactionary project, which is a reactionary project, which is a reactionary project."}, {"heading": "3 Participants", "text": "In this section, we present the participants of the competition, categorized according to the applied modeling paradigms and their evaluation techniques. [3] During the competition activities, we also developed a more comprehensive language proposal called ASP-RfC (Request for Comments), which includes aggregates and other widely used but not yet standardized language features."}, {"heading": "3.1 System Track", "text": "The traditional approach to ASP program evaluation follows an instance that consists of a grounding module that generates a propositional theory coupled with a subsequent propositional solution module. There have been other attempts that deviate from this usual approach (Dal Palu).In order to deal with invariable programs, all approaches are ultimately applied to the grounder Gringo programs (Gebser et al. 2007).In detail, the System Track eleven has official participants and five non-competing systems, which can be classified according to the assessment strategy used: Native ASP: using user-defined search techniques based on backtracking algorithms tailored to handle logical programs."}, {"heading": "3.2 M&S Track", "text": "Participants adopted several different declarative paradigms, for example, belonging to the following language families: ASP-based, based on ASP (Gelfond and Lifschitz 1991) (and variants) as problem solutions that model a sophisticated language (Jaffar and Lassez 1987); and, planning-based, based on PDDL (Planning Definition Language) as a modeling language (PDDL 3.1 2008). Specifically, six teams participated in the M & S-Bahn: Potassco: The Potassco team from the University of Potsdam, Germany (Gebser et al 2007) submitted a heterogeneous ASP-based solution."}, {"heading": "4 Competition Settings", "text": "A detailed description of the general settings, rating criteria and selected benchmark suites can be found in Appendices B, C and D. The scoring framework is a refinement of the scoring framework used in the first and second ASP contest. In these previous editions, the scoring rules were mainly based on a weighted sum of instances solved within a given timeframe. In this edition, the scoring framework was expanded by awarding additional points to systems that performed well in terms of rating time. For search and query problems, each system was rated on benchmark problem P with the rating S (P) = Ssolve (P) + Stime (P). Ssolve and Stime could range from 0 to 50: while Ssolve depending on the number of instances solved in the given time, Xnitude Benchmark Benchmark Benchmark Benchmark Systems."}, {"heading": "5 Results and Discussion", "text": "The final results of the competition are shown in Figures 1 and 2 for System and M & S Track respectively, the detailed results for each benchmark problem considered, and cactus charts showing the number of cases resolved and the corresponding time per participant, are listed in Appendix F. (Note: Timing out cases are not drawn) Full competition figures, detailed per case, as well as executable packages and declarative specifications submitted by the participants, are available on the competition website (Calimeri et al. 2010)."}, {"heading": "5.1 System Track Results", "text": "In fact, most of them will be able to play by the rules they have established over the last five years, and they will be able to play by the rules."}, {"heading": "5.2 M&S Track Results", "text": "The winner in the category (see Figure 2) is the Potassco team. It is worth noting that the second-placed BPsolvers, which present solutions based on predicate tables for this category, are the absolute winners in three out of seven problem areas."}, {"heading": "6 Further Analysis", "text": "This year, it is at an all-time high in the history of the European Union."}, {"heading": "7 Concluding remarks", "text": "Much effort has been expended by the ASP community over the last 20 years, and excellent results have been achieved since the first groundbreaking work; ASP and ASP system can now be used profitably in many areas of application, not only thanks to the declarative and expressive power of formalism, but also thanks to the continuous improvement of performance. Even a two-year horizon indicates that things are getting better. Furthermore, it is interesting to note that despite the difference between the specifically tailored solutions and the one with8 in the sense that there are no parameters that will tune the technology.factory settings being significant, the current state-of-the-art ASP implementations offer a good experience for application developers, given the nice declarative approach of formalism and the mature, robust and currently well-functioning systems available. Nevertheless, there is still much scope for improvement. For example, the comparison with some ad-hoc solutions from the university has confirmed that the performance of court-out is no longer a weak point, but the other one could solve some problems."}, {"heading": "Appendix B Detailed Competition Settings", "text": "In fact, most of them are able to survive themselves if they do not survive themselves."}, {"heading": "Appendix C Detailed scoring regulations", "text": "The most important factors taken into account in the scoring framework are generally presented in terms of system performance: 1. Benchmarks with many instances should not dominate the overall score of the category. Thus, the total score for a given problem P was standardized in terms of the number of instances selected for P. 2. Unfounded approaches and coding were greatly discouraged. 3. A system that manages a given problem presents a clear gap compared to all systems that are unable to do so. Thus, a flat reward for each instance I of a problem was given to a System S that I correctly solved within the allotted time. 4. In terms of time performance, human beings are generally more receptive to the changes in a value than to the changes themselves."}, {"heading": "Appendix D Benchmark Suite", "text": "In fact, it is such that most of them will be able to move into a different world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "Appendix E System Versions", "text": "As described in Section 3, entrants submitted original systems and bundles of solutions that may relate to different (sub) systems. In some cases, systems were provided as bespoke versions that were intentionally compiled for the competition; in other cases, the executables came from official release sources but were built on the competition engines and may therefore differ from those officially distributed. We explicitly report here on the exact versions whenever these are explicitly stated by entrants; it is worth remembering that all systems and bundles, along with codes, instances, scriptions and anything else required for the actual realignment of the competition, are available on the competition website (Calimeri et al. 2010), where further details of systems and teams can be found, as well as codes, instances, scriptions and everything else needed for the actual realignment of the competition (Gringo)."}, {"heading": "Appendix F Detailed result tables for Section 5", "text": "This year it has come to the point that it will be able to retaliate, \"he said in an interview with the German Press Agency.\" We are very satisfied with the development, \"he said.\" We are very satisfied, \"he said.\" We are very satisfied, \"he said,\" but we are not yet able to achieve our goals. \""}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": "Answer Set Programming (ASP) is a well-established paradigm of declarative program-<lb>ming in close relationship with other declarative formalisms such as SAT Modulo Theories,<lb>Constraint Handling Rules, FO(.), PDDL and many others. Since its first informal edi-<lb>tions, ASP systems have been compared in the now well-established ASP Competition.<lb>The Third (Open) ASP Competition, as the sequel to the ASP Competitions Series held<lb>at the University of Potsdam in Germany (2006-2007) and at the University of Leuven in<lb>Belgium in 2009, took place at the University of Calabria (Italy) in the first half of 2011.<lb>Participants competed on a pre-selected collection of benchmark problems, taken from a<lb>variety of domains as well as real world applications.<lb>The Competition ran on two tracks: the Model and Solve (M&S) Track, based on an<lb>open problem encoding, and open language, and open to any kind of system based on a<lb>declarative specification paradigm; and the System Track, run on the basis of fixed, public<lb>problem encodings, written in a standard ASP language. This paper discusses the format<lb>of the Competition and the rationale behind it, then reports the results for both tracks.<lb>Comparison with the second ASP competition and state-of-the-art solutions for some of<lb>the benchmark domains is eventually discussed.", "creator": "gnuplot 4.4 patchlevel 0"}}}