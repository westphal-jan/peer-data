{"id": "1206.3233", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2012", "title": "Speeding Up Planning in Markov Decision Processes via Automatically Constructed Abstractions", "abstract": "In this paper, we consider planning in stochastic shortest path (SSP) problems, a subclass of Markov Decision Problems (MDP). We focus on medium-size problems whose state space can be fully enumerated. This problem has numerous important applications, such as navigation and planning under uncertainty. We propose a new approach for constructing a multi-level hierarchy of progressively simpler abstractions of the original problem. Once computed, the hierarchy can be used to speed up planning by first finding a policy for the most abstract level and then recursively refining it into a solution to the original problem. This approach is fully automated and delivers a speed-up of two orders of magnitude over a state-of-the-art MDP solver on sample problems while returning near-optimal solutions. We also prove theoretical bounds on the loss of solution optimality resulting from the use of abstractions.", "histories": [["v1", "Wed, 13 Jun 2012 12:34:35 GMT  (829kb)", "http://arxiv.org/abs/1206.3233v1", "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["alejandro isaza", "csaba szepesvari", "vadim bulitko", "russell greiner"], "accepted": false, "id": "1206.3233"}, "pdf": {"name": "1206.3233.pdf", "metadata": {"source": "CRF", "title": "Speeding Up Planning in Markov Decision Processes via Automatically Constructed Abstractions", "authors": ["Alejandro Isaza"], "emails": ["isaza@cs.ualberta.ca", "szepesva@cs.ualberta.ca", "bulitko@cs.ualberta.ca", "greiner@cs.ualberta.ca"], "sections": [{"heading": null, "text": "In this paper, we look at planning in stochastic shortpath problems (SSP), a subclass of the Markov Decision Problems (MDP). We focus on medium-sized problems whose state space can be fully enumerated, and this problem has numerous important applications, such as navigation and planning under uncertainty. We propose a new approach to constructing a multi-level hierarchy of progressively simpler abstractions of the original problem. Once calculated, the hierarchy can be used to speed up planning by first finding a strategy for the most abstract level and then refining it recursively to a solution to the original problem. This approach is fully automated and provides an acceleration of two orders of magnitude compared to a state-of-the-art MDP solver for example problems, while returning to near optimal solutions."}, {"heading": "1 Introduction and Motivation", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2 Problem Formulation and Theory", "text": "It also represents a theoretical result that characterizes the relationship between the performance of abstract politics and the politics of the original problem. (Definition 1 A Markov Decision Process (MDP) is defined by a finite state space corresponding to the probability that the next state is an act applied in the state x; direct costs c (x, y) for each state x X; transition probabilities p (y, a) corresponding to the probability that the next state is an act applied in the state x; direct costs c (x, y) for all x, y), y)."}, {"heading": "3 Abstracting an SSP", "text": "The process consists of four main steps (Figure 1): (1) Cluster suggests candidates for abstract states; (2) GenerateLinkCandidates suggests candidates for abstract actions (or \"links\"); (3) Repair validates and, if necessary, repairs the links to satisfy the so-called \"attachment properties\" (the formal definition will be given later); and Prune rejects excessive links. Once an abstraction is built, we use a special planning procedure (described in Section 4) to resolve specific SSPs; the rest of this section describes the four steps of our BuildAbstraction algorithm in detail.Step 1: Cluster."}, {"heading": "4 Planning with an Abstraction", "text": "After building an abstraction, we can use it to solve certain SSP problems. If we set a new goal, our abstraction planner, AbsPlanner, then creates a goal-approach region in the abstract MDP that encompasses the goal and is large enough to include all the states of the target cluster that includes the goal. After building the region, AbsPlanner produces an SSP by adding states and transitions at a latitude-first to a certain depth, progressing backwards along the transitions and only stopping after adding all the states of the target cluster. After building the region, AbsPlanner produces an SSP. The domain of this SSP includes the states found in the latitude-first search, and also a new terminal state that becomes the destination of the transition that leaves the region - i.e. these transitions are rerouted to this new terminal, with high transition costs x. All other costs and transitions of this SSP are inherited from the ground-level MDP."}, {"heading": "5 Empirical Evaluation", "text": "\"This section summarizes our empirical evaluation of this approach in terms of the quality (sub-optimality) of solutions and solution times. Here, we report on the compromises of using different levels of abstraction and the dependence on the\" stochasticity \"of transitions. (Note: Stochasticity makes it difficult to build abstractions.) We have also tested the performance of the algorithm for more practical problems. In addition to the results presented here, we have conducted extensive experiments that examine the trade between solution quality and solution time as a function of the various parameters of our algorithm (e.g. the values of p, k, or the number of abstraction levels).The scale behavior of our algorithm in terms of its resource use, the quality of solutions, and the solution time. These results, which appear in (Isaza et al., 2008), confirm that the algorithm is robust to the decisions of its parameters and scales as expected."}, {"heading": "5.1 Abstraction level trade-offs", "text": "We used a 100 x 100 grid world to analyze the trade-offs between different levels of abstraction, with several different parameter configurations. We say that a configuration is \"dominant\" if it is a Pareto optimum - i.e., if no other configuration is both temporal and suboptimal. Figure 2 shows properties of the dominant configurations3See (Isaza et al., 2008) for more details, including relevant illustrations. 4We performed all experiments with a 2GHz AMD Opteron (tm) processor with 4GB of RAM running Linux with kernel 2.6.18 for different levels of abstraction. We see that using a smaller number of abstractions takes more time, but produces better solutions (i.e. lower suboptimality), and higher levels of abstraction require less solving time, but produced inferior solutions (i.e. increased suboptimality). Note that using a smaller number of abstractions requires more time, but produces better solutions (i.e., lower suboptimality), and higher levels of abstraction require less time, but produces inferior solutions (i.e., increased suboptimality). Note that we get a lower level of abstraction (i.e. we get a lower level of abstraction from 5.000 to 5.000)."}, {"heading": "5.2 Sensitivity to Stochasticity of the Dynamics", "text": "This section quantifies how the solution quality and construction time relate to noise in dynamics. In general, we consider an action to be \"successful\" when the agent moves in the appropriate direction; our Gridworld model sets the probability of success to P = 0.7, so that we move with a probability of (1 \u2212 P) / 3 in each of the other three directions. Figure 3 shows the suboptimality and acceleration of solution finding using our method compared to IPS for different values of P. We see that our method loses optimism as the dynamic becomes noisier (i.e., when P becomes smaller). Figure 3 shows the suboptimality and acceleration of solution finding using our method compared to IPS for different values of P. We see that our method loses optimism as the dynamic becomes noisier (i.e., when P becomes smaller)."}, {"heading": "5.3 Congested Game Maps", "text": "To test the performance of our approach in a more practical application, we used maps modeled after game environments from commercial video games. We first created simplified grid worlds resembling some layers of opulent role-playing and real-time strategy games, and then converted the grid worlds into overloaded maps as described above, resulting in maps with state room sizes of 6176 (BG1), 5672 (BG2), 5852 (BG3), 20249 (WC1), and 9848 (WC2). Figure 5 provides such a map in which the color of each state indicates the associated constipation: warmer / redder colors indicate high constipation (i.e. low probability of success P), while colder / bluer colors indicate low constipation (i.e. high value of P). Very dark blue maps indicate unresistant obstacles."}, {"heading": "6 Related Work", "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "7 Discussion and Future Directions", "text": "Another way to use an abstract solution to an abstract problem would be to use the abstract value function to guide the local search starting from the current state. These ideas have proven successful in pattern database research, where the cost of an optimal solution to an abstract problem is used as a powerful heuristic for the original problem. Such a method has the potential to improve the quality of the solution while keeping the cost of the planning steps associated with execution low. Another idea is to use abstraction to select the amount of such local problems (i.e. the depth of rollouts); these ideas have proven successful in deterministic environments (Bulitko, Bjo Brnsson, Lus trek, Schaeffer, & Sigmundarson, 2007; Bulitko, Lus trek, Schaeffer, Lus trek, Schaeffer, Lus trek, Schaeffer, Bjo rnsson, & Sigmundarson, 2008).Currently, our abstractions are ministerial."}, {"heading": "8 Conclusions", "text": "This paper explores ways to accelerate the planning of SSP problems by abstracting state and action independently of target. We strengthen existing theoretical results and then automatically provide an algorithm for building abstraction hierarchies. Finally, we demonstrate empirically the benefits of this approach by showing that it works effectively for SSPs of varying sizes and difficulty."}, {"heading": "Acknowledgements", "text": "We thank the reviewers for their insightful comments. This research was partially funded by the National Science and Engineering Research Council (NSERC), iCore and the Alberta Ingenuity Fund."}], "references": [{"title": "State space reduction for hierarchical reinforcement learning", "author": ["M. Asadi", "M. Huber"], "venue": "In FLAIRS, pp", "citeRegEx": "Asadi and Huber,? \\Q2004\\E", "shortCiteRegEx": "Asadi and Huber", "year": 2004}, {"title": "Effective control knowledge transfer through learning skill and representation hierarchies", "author": ["M. Asadi", "M. Huber"], "venue": "In IJCAI,", "citeRegEx": "Asadi and Huber,? \\Q2007\\E", "shortCiteRegEx": "Asadi and Huber", "year": 2007}, {"title": "Baldur\u2019s Gate", "author": ["BioWare Corp."], "venue": "November 30, 1998.", "citeRegEx": "Corp.,? 1998", "shortCiteRegEx": "Corp.", "year": 1998}, {"title": "Warcraft III: Reign of Chaos", "author": ["Blizzard Entertainment"], "venue": "July 3, 2002.", "citeRegEx": "Entertainment,? 2002", "shortCiteRegEx": "Entertainment", "year": 2002}, {"title": "Dynamic Control in Path-Planning with Real-Time Heuristic Search", "author": ["V. Bulitko", "Y. Bj\u00f6rnsson", "M. Lu\u0161trek", "J. Schaeffer", "S. Sigmundarson"], "venue": "In ICAPS,", "citeRegEx": "Bulitko et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bulitko et al\\.", "year": 2007}, {"title": "Dynamic Control in Real-Time Heuristic Search. JAIR", "author": ["V. Bulitko", "M. Lu\u0161trek", "J. Schaeffer", "Y. Bj\u00f6rnsson", "S. Sigmundarson"], "venue": null, "citeRegEx": "Bulitko et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bulitko et al\\.", "year": 2008}, {"title": "Model reduction techniques for computing approximately optimal solutions for Markov decision processes", "author": ["T. Dean", "R. Givan", "S. Leach"], "venue": "In UAI,", "citeRegEx": "Dean et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Dean et al\\.", "year": 1997}, {"title": "Hierarchical solution of Markov decision processes using macro-actions", "author": ["M. Hauskrecht", "N. Meuleau", "L.P. Kaelbling", "T. Dean", "C. Boutilier"], "venue": "In UAI, pp", "citeRegEx": "Hauskrecht et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Hauskrecht et al\\.", "year": 1998}, {"title": "Speeding up planning in Markov decision processes via automatically constructed abstraction", "author": ["A. Isaza", "C. Szepesv\u00e1ri", "V. Bulitko", "R. Greiner"], "venue": "Tech. rep., Computing Science, U. Alberta. http://www.cs. ualberta.ca/ \u0303szepesva/RESEARCH/PRMDP", "citeRegEx": "Isaza et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Isaza et al\\.", "year": 2008}, {"title": "Solving factored MDPs using non-homogeneous partitions", "author": ["K. Kim", "T. Dean"], "venue": "Artificial Intelligence,", "citeRegEx": "Kim and Dean,? \\Q2003\\E", "shortCiteRegEx": "Kim and Dean", "year": 2003}, {"title": "Fast exact planning in Markov decision processes", "author": ["H.B. McMahan", "G.J. Gordon"], "venue": "In ICAPS,", "citeRegEx": "McMahan and Gordon,? \\Q2005\\E", "shortCiteRegEx": "McMahan and Gordon", "year": 2005}, {"title": "Memory-efficient abstractions for pathfinding", "author": ["N. Sturtevant"], "venue": "AIIDE, pp. 31\u201336.", "citeRegEx": "Sturtevant,? 2007", "shortCiteRegEx": "Sturtevant", "year": 2007}, {"title": "Between MDPs and semi-MDPs: a framework for temporal abstraction in reinforcement learning", "author": ["R.S. Sutton", "D. Precup", "S. Singh"], "venue": "Artificial Intelligence,", "citeRegEx": "Sutton et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1999}], "referenceMentions": [{"referenceID": 12, "context": "We adopt the notion of options from Sutton et al. (1999):", "startOffset": 36, "endOffset": 57}, {"referenceID": 9, "context": "To our knowledge, such options-based abstractions have not been analyzed previously; the closest results are probably Theorem 2 of Kim and Dean (2003) and Theorem 4 of Dean, Givan, and Leach (1997).", "startOffset": 131, "endOffset": 151}, {"referenceID": 9, "context": "To our knowledge, such options-based abstractions have not been analyzed previously; the closest results are probably Theorem 2 of Kim and Dean (2003) and Theorem 4 of Dean, Givan, and Leach (1997). The proof is rather technical and is given", "startOffset": 131, "endOffset": 198}, {"referenceID": 8, "context": "Isaza et al. (2008) provides further details.", "startOffset": 0, "endOffset": 20}, {"referenceID": 10, "context": "The optimal solution to S is obtained by using the Improved Prioritized Sweeping (IPS) algorithm of McMahan and Gordon (2005), (line 14).", "startOffset": 100, "endOffset": 126}, {"referenceID": 8, "context": "These results, appearing in (Isaza et al., 2008), confirm that the algorithm is robust to the choices of its parameters and scales as expected by increasing problem sizes.", "startOffset": 28, "endOffset": 48}, {"referenceID": 8, "context": "See (Isaza et al., 2008) for more details, including relevant pictures.", "startOffset": 4, "endOffset": 24}, {"referenceID": 4, "context": "Dean et al. (1997) introduced the notion of \u03b5-homogeneous partitions and analyzed its properties, but without giving explicit loss bounds.", "startOffset": 0, "endOffset": 19}, {"referenceID": 4, "context": "Dean et al. (1997) introduced the notion of \u03b5-homogeneous partitions and analyzed its properties, but without giving explicit loss bounds. Kim and Dean (2003) developed some loss bounds.", "startOffset": 0, "endOffset": 159}, {"referenceID": 0, "context": "While Asadi and Huber (2004) also considered such optionsbased abstractions, they assume that the abstract actions (options) are given externally (possibly by specifying goal states for each of them) and they do not develop bounds.", "startOffset": 6, "endOffset": 29}, {"referenceID": 0, "context": "While Asadi and Huber (2004) also considered such optionsbased abstractions, they assume that the abstract actions (options) are given externally (possibly by specifying goal states for each of them) and they do not develop bounds. In a number of subsequent papers, the authors refined their methods. In particular, they became increasingly focussed on learning problems. For example, in the recent follow-up work, Asadi and Huber (2007) provide a method to learn an abstract hierarchical representation that uses state aggregation and options.", "startOffset": 6, "endOffset": 438}, {"referenceID": 7, "context": "Further, we deal with undiscounted SSPs, while Hauskrecht et al. (1998) dealt with discounted MDPs (but this difference is probably not crucial).", "startOffset": 47, "endOffset": 72}], "year": 2008, "abstractText": "In this paper, we consider planning in stochastic shortest path (SSP) problems, a subclass of Markov Decision Problems (MDP). We focus on medium-size problems whose state space can be fully enumerated. This problem has numerous important applications, such as navigation and planning under uncertainty. We propose a new approach for constructing a multi-level hierarchy of progressively simpler abstractions of the original problem. Once computed, the hierarchy can be used to speed up planning by first finding a policy for the most abstract level and then recursively refining it into a solution to the original problem. This approach is fully automated and delivers a speed-up of two orders of magnitude over a state-of-the-art MDP solver on sample problems while returning near-optimal solutions. We also prove theoretical bounds on the loss of solution optimality resulting from the use of abstractions.", "creator": "gnuplot 4.2 patchlevel 0"}}}