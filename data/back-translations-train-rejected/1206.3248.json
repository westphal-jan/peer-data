{"id": "1206.3248", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2012", "title": "Knowledge Combination in Graphical Multiagent Model", "abstract": "A graphical multiagent model (GMM) represents a joint distribution over the behavior of a set of agents. One source of knowledge about agents' behavior may come from gametheoretic analysis, as captured by several graphical game representations developed in recent years. GMMs generalize this approach to express arbitrary distributions, based on game descriptions or other sources of knowledge bearing on beliefs about agent behavior. To illustrate the flexibility of GMMs, we exhibit game-derived models that allow probabilistic deviation from equilibrium, as well as models based on heuristic action choice. We investigate three different methods of integrating these models into a single model representing the combined knowledge sources. To evaluate the predictive performance of the combined model, we treat as actual outcome the behavior produced by a reinforcement learning process. We find that combining the two knowledge sources, using any of the methods, provides better predictions than either source alone. Among the combination methods, mixing data outperforms the opinion pool and direct update methods investigated in this empirical trial.", "histories": [["v1", "Wed, 13 Jun 2012 15:09:25 GMT  (327kb)", "http://arxiv.org/abs/1206.3248v1", "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["quang duong", "michael p wellman", "satinder singh"], "accepted": false, "id": "1206.3248"}, "pdf": {"name": "1206.3248.pdf", "metadata": {"source": "CRF", "title": "Knowledge Combination in Graphical Multiagent Models", "authors": ["Quang Duong", "Michael P. Wellman", "Satinder Singh"], "emails": ["qduong@umich.edu", "wellman@umich.edu", "baveja@umich.edu"], "sections": [{"heading": null, "text": "A graphical multi-agent model (GMM) represents a common distribution of the behavior of a group of agents. A source of knowledge about the behavior of agents could come from game theory analysis, which is captured by several graphical game representations developed in recent years. GMMs generalize this approach to express arbitrary distributions based on game descriptions or other knowledge sources based on beliefs about the behavior of agents. To illustrate the exibility of GMMs, we show playful models that allow probable deviations from the equilibrium, as well as models based on heuristic action selection. We examine three different methods for integrating these models into a single model that represents the combined sources of knowledge. To evaluate the predictive performance of the combined model, we treat the behavior caused by an enhanced learning process as an actual result."}, {"heading": "1 INTRODUCTION", "text": "In fact, we are able to go in search of a solution that is capable of finding a solution, that is capable of finding a solution that is capable of finding a solution, that is capable of finding a solution, and that is able to find a solution that is capable of finding a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution."}, {"heading": "2 GRAPHICAL MULTIAGENT MODELS", "text": "Consider a multi-agent scenario with n players, in which each player has a higher potential than a description of the result. The result is a common action or strategy per le, s, which regrets the strategy choice of all players. A GMM G for this scenario is a graphical model, G = (V, E, S, \u03c0), with indentations V = {v1,..., vn}, which corresponds to the agents (we refer to vi and i interchangeable), and edges (i, j), which indicate a local interaction between i and j. The graph de nes for each agent is a neighborhood, Ni = {j}, which corresponds to the agents (we refer to vi and i interchangeable), and edges (i, j), which indicate a local interaction between i and j. The graph de nes for each agent is a neighborhood, Ni = (i, j)."}, {"heading": "3 EXAMPLE: INTERNET INDUSTRY PARTNERSHIPS", "text": "We illustrate the GMM framework and motivate the problem of combining knowledge sources using an exemplary multi-agent scenario. In the partnership area of the Internet industry, 1 companies must decide whether to maintain (s = 1) or update (s = 2) their current technology. Payo functions in G can be mapped in various ways to G's potential functions. Payo for each strategy depends on the decisions of other companies to which they are related through a kind of partnership with their neighbors in the interaction diagram."}, {"heading": "3.1 GAME DEFINITION", "text": "We construct our example scenario based on a fragment of the partnership network consisting of 10 representative companies as illustrated in Figure 1. Each node represents a company that we characterize using three parameters: (1) size class, z; (2) sector, t: either commerce, infrastructure or content; and (3) change coe cient, ch (0, 1), which represents the intrinsic adaptability of business technology. Cancer's study (2002) provides sector and a rough order of magnitude; we assign the change coe arbitrarily (3). Although somewhat invented, the scenario speculation serves our purpose of demonstrating some capabilities of the GMM approach. Payo's function, u, de nes the value of maintaining or improving technology, is transformation given the actions of neighboring companies and the parameters that describe these companies. (Qualitatively, Payo is enhanced by agreement with neighbors, where larger neighbors from the same sector are relatively important."}, {"heading": "3.2 GMM CONSTRUCTIONS", "text": "Given the Payo function and the aforementioned game-de-nition, we can easily create a Repentance Potential function (2), parameterized by temperature. This potential function, in turn, de nes Reue GMM, reG. Our heuristic rules-based model, hM, on the other hand, is specified without direct reference to the Payo function. In this model, each company independently applies a local heuristics to stochastically choose its action. The more partners (| Ni | \u2212 1) a company has and the larger its size zi, the less likely it is that it will change. Given the pChange values, it is easy to determine a potential function for the GMM hG, so that the predictive partnership is the same as it is generated by applying the rule."}, {"heading": "3.3 SIMULATION MODEL", "text": "The role of our simulation model is to generate game data from a plausible agent interaction process. In this study, we treat this data as the actual result and use it to evaluate the GMMs above as well as combined models.The simulation is based on the idea that the agent's actual behavior is induced by repeated interaction through a reinforcement learning process (RL).In the model, each actor is an independent learner who applies an RL process designed for partially observable environments.The environment for the company i includes i and its partners (i.e. its neighbors N \u2212 i), and any coordination of partner strategies sN \u2212 i is a potential state.The actor tries to learn a stochastic game policy: i (si | sN \u2212 i), which denotes the likelihood of acting si in state sN \u2212 i."}, {"heading": "4 METHODS FOR COMBINING KNOWLEDGE SOURCES", "text": "How can we integrate them into a single GMM in the face of two complementary sources of knowledge? We formulate the problem if one source of knowledge is explicitly expressed as GMM, G1, and the other in the form of some data D = {s1,..., sm} of common plays in the context of the multi-agent scenario.2 Note that D may not accurately reflect the actual distribution of the game, e.g. because it is small or has been observed in a particular multi-agent setting. In this section we answer these questions abstractly, and in the next section show how we can do this for our specifically reG model and the data derived from hM."}, {"heading": "4.1 DIRECT UPDATE", "text": "The direct update method combines the two sources of knowledge G1 and D into a new GMM, directG, derived by adjusting the \u03bbG1 parameters of G1 to maximize the predictive power of the data.2Since we can generate such a dataset from a GMM or induce a GMM from data, the combination methods can be applied to more general settings where the predictive reliability of the data is either formal.We measure the predictive results using the logarithmic scoring rule (Gneiting and Raftery, 2007): Score (G | D) = 1 log PrG (s k), which assesses the predictive reliability of the datas.Our problem is to adjust the parameters of the GMM to maximize this score (Caps and Rodr\u00edguez, 1997)."}, {"heading": "4.2 OPINION POOL", "text": "Unlike direct updating, which depends on the availability of both game result data and the parameterized form of the potential function, the next two methods, opinion pool and data mixing, lead the problem of the knowledge combination towards potentially greater independence from the forms of the input knowledge sources. The option pool method begins by initially using half of the given data D to learn a GMM G2 by adjusting its parameters to maximize the probability of the data, as with the method of direct updating described above. The combined model OPG is then an aggregation of G1 and G2 in a single probability distribution: PrOPG (s) = f (PrG1 (s), PrG2 (s))."}, {"heading": "4.3 MIXING DATA", "text": "We combine D1 and D to form a data set mD by scanning both sources evenly, although one source could easily be weighted more than another by adjusting the sampling ratio. We then set up a new GMM for a given parameterized form by adjusting the parameter \u03bb, as described in the direct update approach (Section 4.1), to determine the probability of new data mD. Below is the sketch of the mixed data method produced by the combined GMM-MixG. Note that we omit step 4 in our implementation. 1. Create a sampling of the game results D1 from G1.2. Create a mixed data set of D1 and D with the sampling ratio \u03c9 = 0,5,3. Create MixG with slightly more than with direct updating using the data mD.4. (optional) tune in the part determined below sampling level G until the results are maximized in a few steps."}, {"heading": "5 EMPIRICAL STUDY", "text": "We evaluate our combination approaches experimentally using our simplified version of the partnership domain of the Internet industry. We mainly focus on Example 1, the scenario shown in Figure 1. In the first experiment, we also examine Example 2, which uses a smaller graph that only includes the four leading companies."}, {"heading": "5.1 EXPERIMENT SETTINGS", "text": "In our experiments, we use the above components: (i) the regret GMM reG with the randomly generated temperature parameters (except in one case explicitly specified below), (ii) a data set D of common games generated by the use of the heuristic rule-based model hM, (iii) the heuristic model hM and the associated GMM hG, and (iv) a test data set D * derived from the RL-based model simM. We compare our combination approaches based on their ability to predict the test data set using the score function Score (G | D *). In particular, we compare the performance of a model combining knowledge sources related to the performance of a base model baseG using a ratio of scores, R = Score (baseG | D *) Score (baseG | D *) Score (combined) and noble G."}, {"heading": "5.2 RESULTS AND ANALYSIS", "text": "First, in Figure 2 and Figure 3, we present an overview of our combination methods \"e > ectiveness.\" For both models, reG and D are used to derive the model directG with the direct update method, the model OPG with the opinion pool method, and the model mixG with the mixed data method. Figure 2 shows better results than individual input models, suggesting that the combination of two knowledge sources is independent of which of the proposed methods is adopted. Figure 3 shows the performance of different models derived from the same gold standard source is relatively better than individual input models, suggesting that the combination of two knowledge sources is independent of which of the proposed methods is adopted."}, {"heading": "6 CONCLUSIONS", "text": "GMMs provide an exible representational framework for graphically structured multi-agent scenarios that supports the specification of probability distributions based on game theory models as well as heuristic or other qualitative characterizations of agent behavior. We have explored the possibility of exploiting this flexibility by using multiple knowledge sources for prediction, as demonstrated for the task of predicting the outcome of an amplification learning process.Our fundamental finding is that combining two knowledge sources in this scenario improves predictive power across both input sources alone. We have also identified the most effective combination method among those who have attempted to mix data, and the presence of a threshold for data availability that can help increase efficiency. Furthermore, we have found that our knowledge combination approaches, especially the blending of data, can ecologically harmonize the performance of modelling the amplification learning process."}], "references": [{"title": "Computing pure Nash equilibria in graphical games via Markov random elds", "author": ["C. Daskalakis", "C.H. Papadimitriou"], "venue": "Seventh ACM conference on Electronic Commerce, pages 91 99, Ann Arbor.", "citeRegEx": "Daskalakis and Papadimitriou,? 2006", "shortCiteRegEx": "Daskalakis and Papadimitriou", "year": 2006}, {"title": "Networks of in uence diagrams: A formalism for reasoning about agents' decision-making processes", "author": ["Y. Gal", "A. Pfe er"], "venue": "Journal of Arti cial Intelligence Research.", "citeRegEx": "Gal and er,? 2008", "shortCiteRegEx": "Gal and er", "year": 2008}, {"title": "Strictly proper scoring rules, prediction and estimation", "author": ["T. Gneiting", "A.E. Raftery"], "venue": "Journal of the American Statistical Association, 102(477):359 378.", "citeRegEx": "Gneiting and Raftery,? 2007", "shortCiteRegEx": "Gneiting and Raftery", "year": 2007}, {"title": "Reinforcement learning algorithm for partially observable Markov decision problems", "author": ["T. Jaakkola", "S. Singh", "M.I. Jordan"], "venue": "Advances in Neural Information Processing Systems 7, pages 345 352.", "citeRegEx": "Jaakkola et al\\.,? 1995", "shortCiteRegEx": "Jaakkola et al\\.", "year": 1995}, {"title": "Mean eld approach to learning in Boltzmann machines", "author": ["H.J. Kappen", "F.B. Rodr\u00edguez"], "venue": "Pattern Recognition Letters, 18:1317 1322.", "citeRegEx": "Kappen and Rodr\u00edguez,? 1997", "shortCiteRegEx": "Kappen and Rodr\u00edguez", "year": 1997}, {"title": "Computational game theory: A tutorial", "author": ["M. Kearns"], "venue": "http://www.cis.upenn.edu/~mkearns/ nips02tutorial/nips.pdf. Presented at the Neural Information Processing Systems conference.", "citeRegEx": "Kearns,? 2002", "shortCiteRegEx": "Kearns", "year": 2002}, {"title": "Graphical games", "author": ["M. Kearns"], "venue": "Nisan, N., Roughgarden, T., Tardos, E., and Vazirani, V. V., editors, Algorithmic Game Theory, pages 159 180. Cambridge University Press.", "citeRegEx": "Kearns,? 2007", "shortCiteRegEx": "Kearns", "year": 2007}, {"title": "Graphical models for game theory", "author": ["M. Kearns", "M.L. Littman", "S. Singh"], "venue": "Seventeenth Conference on Uncertainty in Arti cial Intelligence, pages 253 260, Seattle.", "citeRegEx": "Kearns et al\\.,? 2001", "shortCiteRegEx": "Kearns et al\\.", "year": 2001}, {"title": "Multi-agent in uence diagrams for representing and solving games", "author": ["D. Koller", "B. Milch"], "venue": "Games and Economic Behavior, 45:181 221.", "citeRegEx": "Koller and Milch,? 2003", "shortCiteRegEx": "Koller and Milch", "year": 2003}, {"title": "Internet industry partnerships", "author": ["V. Krebs"], "venue": "http: //www.orgnet.com/netindustry.html.", "citeRegEx": "Krebs,? 2002", "shortCiteRegEx": "Krebs", "year": 2002}, {"title": "Graphical models for groups: Belief aggregation and risk sharing", "author": ["D.M. Pennock", "M.P. Wellman"], "venue": "Decision Analysis, 2:148 164.", "citeRegEx": "Pennock and Wellman,? 2005", "shortCiteRegEx": "Pennock and Wellman", "year": 2005}, {"title": "Mechanism design based on beliefs about responsive play (position paper)", "author": ["Y. Vorobeychik", "M.P. Wellman"], "venue": "ACM EC-06 Workshop on Alternative Solution Concepts for Mechanism Design, Ann Arbor, MI.", "citeRegEx": "Vorobeychik and Wellman,? 2006", "shortCiteRegEx": "Vorobeychik and Wellman", "year": 2006}, {"title": "Information theory: The bridge connecting bounded rational game theory and statistical physics", "author": ["D.H. Wolpert"], "venue": "Complex Engineered Systems. Springer.", "citeRegEx": "Wolpert,? 2006", "shortCiteRegEx": "Wolpert", "year": 2006}, {"title": "Generalized belief propagation", "author": ["J.S. Yedidia", "W.T. Freeman", "Y. Weiss"], "venue": "Advances in Neural Information Processing Systems, 13:689 695.", "citeRegEx": "Yedidia et al\\.,? 2001", "shortCiteRegEx": "Yedidia et al\\.", "year": 2001}], "referenceMentions": [{"referenceID": 6, "context": "(2001), and subsequently examined and extended in several research e orts (Kearns, 2007).", "startOffset": 74, "endOffset": 88}, {"referenceID": 5, "context": "The idea of exploiting conditional independence among the e ects of agents' decisions was central to the multiagent in uence diagram (MAID) framework developed by Koller and Milch (2003). This observation was also a driving motivation for graphical game models, rst introduced by Kearns et al.", "startOffset": 163, "endOffset": 187}, {"referenceID": 5, "context": "This observation was also a driving motivation for graphical game models, rst introduced by Kearns et al. (2001), and subsequently examined and extended in several research e orts (Kearns, 2007).", "startOffset": 92, "endOffset": 113}, {"referenceID": 0, "context": "Daskalakis and Papadimitriou (2006) demonstrated how to map a graphical game to a Markov random eld (MRF), assigning high potential to congurations where an agent plays a best response to its neighbors.", "startOffset": 0, "endOffset": 36}, {"referenceID": 11, "context": "When reasoning about strategies to play, or designing a mechanism (which induces a game for other agents), we may wish to adopt alternative bases for forming beliefs about the agents' play (Vorobeychik and Wellman, 2006).", "startOffset": 189, "endOffset": 220}, {"referenceID": 12, "context": "It also aligns with the goal of Wolpert's information-theoretic framework for modeling bounded rationality in game play (Wolpert, 2006).", "startOffset": 120, "endOffset": 135}, {"referenceID": 0, "context": "For example, Daskalakis and Papadimitriou (2006) de ned a binary potential function, associating a high value for con gurations where each agent's strategy choice is a best response to its neighbors (i.", "startOffset": 13, "endOffset": 49}, {"referenceID": 9, "context": "The study by Krebs (2002) provides sector and a rough order of size;", "startOffset": 13, "endOffset": 26}, {"referenceID": 7, "context": "The example is inspired by the network model of Krebs (2002), cited by Kearns (2002).", "startOffset": 48, "endOffset": 61}, {"referenceID": 5, "context": "The example is inspired by the network model of Krebs (2002), cited by Kearns (2002). Figure 1: Part of the Internet industry partnership network, from Krebs (2002).", "startOffset": 71, "endOffset": 85}, {"referenceID": 5, "context": "The example is inspired by the network model of Krebs (2002), cited by Kearns (2002). Figure 1: Part of the Internet industry partnership network, from Krebs (2002).", "startOffset": 71, "endOffset": 165}, {"referenceID": 3, "context": "In the model, each agent is an independent learner, employing an RL procedure designed for partially observable environments (Jaakkola et al., 1995).", "startOffset": 125, "endOffset": 148}, {"referenceID": 3, "context": "To learn the policy \u03c3i, we apply the RL procedure of Jaakkola et al. (1995).", "startOffset": 53, "endOffset": 76}, {"referenceID": 2, "context": "We measure predictive performance using the logarithmic scoring rule (Gneiting and Raftery, 2007): Score(G | D) = \u2211|D| k=1 log PrG(s ), which assesses the log-likelihood of the data.", "startOffset": 69, "endOffset": 97}, {"referenceID": 4, "context": "We take as our problem to tune the GMM's parameters \u03bb in order to maximize this score (Kappen and Rodr\u00edguez, 1997),", "startOffset": 86, "endOffset": 114}, {"referenceID": 13, "context": "Our pilot study of generalized belief propagation approximations in GMMs (Yedidia et al., 2001) has indeed yielded positive results, and will be incorporated in future reports.", "startOffset": 73, "endOffset": 95}, {"referenceID": 10, "context": "The logOP is the only pool known to preserve independence structure in graphical models (Pennock and Wellman, 2005), which is an important property in our context.", "startOffset": 88, "endOffset": 115}], "year": 2008, "abstractText": "A graphical multiagent model (GMM) represents a joint distribution over the behavior of a set of agents. One source of knowledge about agents' behavior may come from gametheoretic analysis, as captured by several graphical game representations developed in recent years. GMMs generalize this approach to express arbitrary distributions, based on game descriptions or other sources of knowledge bearing on beliefs about agent behavior. To illustrate the exibility of GMMs, we exhibit game-derived models that allow probabilistic deviation from equilibrium, as well as models based on heuristic action choice. We investigate three di erent methods of integrating these models into a single model representing the combined knowledge sources. To evaluate the predictive performance of the combined model, we treat as actual outcome the behavior produced by a reinforcement learning process. We nd that combining the two knowledge sources, using any of the methods, provides better predictions than either source alone. Among the combination methods, mixing data outperforms the opinion pool and direct update methods investigated in this empirical trial.", "creator": "TeX"}}}