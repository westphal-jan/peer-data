{"id": "1206.3253", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2012", "title": "Learning and Solving Many-Player Games through a Cluster-Based Representation", "abstract": "In addressing the challenge of exponential scaling with the number of agents we adopt a cluster-based representation to approximately solve asymmetric games of very many players. A cluster groups together agents with a similar \"strategic view\" of the game. We learn the clustered approximation from data consisting of strategy profiles and payoffs, which may be obtained from observations of play or access to a simulator. Using our clustering we construct a reduced \"twins\" game in which each cluster is associated with two players of the reduced game. This allows our representation to be individually- responsive because we align the interests of every individual agent with the strategy of its cluster. Our approach provides agents with higher payoffs and lower regret on average than model-free methods as well as previous cluster-based methods, and requires only few observations for learning to be successful. The \"twins\" approach is shown to be an important component of providing these low regret approximations.", "histories": [["v1", "Wed, 13 Jun 2012 15:12:21 GMT  (174kb)", "http://arxiv.org/abs/1206.3253v1", "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)", "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["sevan g ficici", "david c parkes", "avi pfeffer"], "accepted": false, "id": "1206.3253"}, "pdf": {"name": "1206.3253.pdf", "metadata": {"source": "CRF", "title": "Learning and Solving Many-Player Games through a Cluster-Based Representation", "authors": ["Sevan G. Ficici", "David C. Parkes"], "emails": ["sevan@eecs.harvard.edu", "parkes@eecs.harvard.edu", "avi@eecs.harvard.edu"], "sections": [{"heading": null, "text": "In solving the challenge of exponential scaling with the number of agents, we use cluster-based representation to approximate asymmetrical games of many players. A cluster groups agents with a similar \"strategic view\" of the game. We learn the cluster approximation from data that consists of strategy profiles and payouts that can be obtained from game observations or access to a simulator. Using our cluster, we construct a reduced \"twin game,\" in which each cluster is associated with two players in the reduced game. This allows our representation to respond individually by aligning the interests of each agent with the strategy of their cluster. Our approach offers agents on average higher payouts and less remorse than model-free methods and previous cluster-based methods, and requires only a few observations to succeed. The \"twin approach\" proves to be an important component in delivering these low remorse approximations."}, {"heading": "1 Introduction", "text": "This year, it has come to the point where it can only take a year for a solution to be found and a solution to be found."}, {"heading": "2 The Vendor Game", "text": "One example of a game that fits our approach is a vendor game. Here, we have a large number of vendors who each sell a different product, and the products belong to categories. For example, some vendors can sell drinks, while others sell sandwiches. Naturally, within each category, the products are further differentiated. For example, a vendor can sell beer while another vendor sells lemonade. Each vendor must occupy one of a small number of locations from which to operate his sales services; a sales location can influence more than one vendor. What a vendor's decision requires strategic thinking is the fact that certain vendor services are natural complements to each other, while other services are substituted when a sandwich vendor and beverage retailer decide to operate in the same location, the two vendors will benefit positively from their complementary relationship."}, {"heading": "3 The Cluster-Based Model", "text": "Our approach to the compact representation and tractable solution of asymmetric N-player games is to use (generally) lossy compression. We group a large number of agents into a much smaller number of clusters. The basic assumptions made by our approach are that 1) agents who are bundled in the same cluster receive similar rewards when they take the same action; 2) agents who are bundled in the same cluster have similar influences on other agents in the same and different clusters; and 3) within each cluster, the actions of individual agents are combined linearly on. Therefore, the combinatory effects of strategic interaction at the cluster level are captured, thereby realizing our computerized savings. In this section, we introduce cluster-based representation and explain how the model (both cluster structure and payouts) is learned from data. Before proceeding, we want to note that our play is currently asymmetrical (that we are currently asking for each to share)."}, {"heading": "3.1 Defining the Model", "text": "LetK is the number of clusters we want to generate; this parameter allows us to express a trade-off between fidelity to the original game and computing efficiency. Let C be a clustering of N agents in K clusters, where Ci-C is the ith cluster of agents. (A cluster is referred to as a \"player\" in the reduced game induced by clustering. (We reserve the term \"agent\" for an agent of the original N player game.For each combination of a cluster and a pure strategy (i.e., each element in the cross-product C-S), we construct a linear equation with | S-K + 1 terms. Each of these linear equations is a regressor that estimates the payout of an agent in the cluster Ci, if it plays pure strategy sx, we get the payouts of agents."}, {"heading": "3.2 Model Learning", "text": "This year, the time has come for us to be able to look for a solution that will put us in the position where we are able to find a solution."}, {"heading": "4 The Twins Game", "text": "Considering that we have profiled K-player strategies, an obvious reduction would be to construct a K-player normal-form game = twin game. We would then each solve this smaller K-player game and then assign to each agent within a cluster the strategy (pure or mixed) used in Nash Equilibrium. This would follow the approach of Wellman et al. [11], albeit slightly extended to an asymmetrical mindset. But one problem with this approach is that the i-th player in the K-player game has no incentive to unilaterally deviate from the equilibrium, cluster i cannot be treated as a real \"player\" because it is not a monolithic decision-maker. Each cluster of agents consists of independent decision-makers whose individual incentives may not be aligned with the cluster level of the Kplayer game."}, {"heading": "4.1 Example", "text": "Let's continue with our example from Section 3.1. We have two clusters of agents, A and B, and will therefore build a four-player game. Let's name players \u03b2, A, B and B, where A and A correspond to the twin players for cluster A, and similarly for players for cluster B. Table 1 shows how we convert our regressors into a twin game. (Each row of the table corresponds to a four-player pure strategy profile. Soon, we will show only 1 / 4 of the profiles where A L and A play. (The leftmost column indicates a four-player pure strategy profile; for example, the third row indicates a profile in which player A, A, B and B play pure strategies L, R, R and L. The remaining columns each show the rewards each player receives for each pure strategy profile.) We calculate player rewards as described in the previous section. The pure strategy that a player uses in a profile."}, {"heading": "5 Experimental Results", "text": "When generating our observation set for the purpose of experimentation, we build N-agents to play the game for a certain number of interactions. We provide agents with a uniform distribution of their pure strategies to generate an observation set with good support in the space of possible common strategy profiles in our twin game. From these observations, and with a given number of K-clusters, we learn our cluster-based approach, which includes clustering and linear regression. We then construct the 2K-player twin game. For comparison, we also construct a K-player game with one player per cluster and thus without individual responsiveness. With Gambit [8] we find all the Nash balances of these reduced normal-form games. For each TSNE of the 2K-player game and each NE of the K-player game, we assign the balance strategies to the agents and let them operate freely for 100 iterations."}, {"heading": "5.1 Vendor Game", "text": "We initialize the type interaction matrix T as follows. Each product type is treated as a substitute for itself, so the diagonal of T is negative. From the diagonal, we randomly select between interaction types (Pr (neutral) = 0.1, Pr (substitute) = 0.45), but require that T contains at least one complementary interaction. Substitution agents are evenly selected between [\u2212 3.0, 0.0], additions of [0.0, 3.0] and neutral interactions have an average of zeros. In one experiment, we use 100 agents, two agent types, two locations (L and R), \u03c32 = 1.5 and 15 observations per study over ten studies. We group agents into two groups (A and B), and neutral interactions have an average of zeros. Table 2 summarizes our experiment and shows that average agent payouts and regrets are the same. The model-free learning methods clearly perform the poorest, and always give the worst agents (and highest)."}, {"heading": "5.2 Santa Fe Bar", "text": "The second game on which we test our approach is a slight variation of the Santa Fe Bar problem (also known as the El Farol Bar problem). In this game, each of the N agents must decide independently whether or not to visit the El Farol bar. However, there are three possible outcomes for an agent: 1) the agent decides to visit the bar, but the bar is full (designated v \u2022), 2) the agent decides to visit the bar, and the bar has room (designated v), 3) the agent decides to stay at home (denotes h). Each agent prefers these outcomes as a result: v \u2022, v \u00b2 h, and h \u2022. Once all N agents make their choice to visit the bar or stay at home."}, {"heading": "6 Conclusions", "text": "We present a method of approaching the structure of asymmetric N-player games for large N-players. This approach uses a clustering approach to compress the original N-player game into a much smaller and more tractable 2K-player game, where K is the number of groups into which we group the N-agents. Each of the K-groups of agents is associated with two players in the 2K-player game; we refer to these pairs of players as \"twins.\" Nash balances, in which twins use the same strategy, are \"twin-symmetrical\" NE. We treat these NE as K-player strategy profiles that we assign to our agent groups; all agents within a group play the same strategy. The K-players NE have the characteristic that the incentives of all agents within a cluster are aligned to the strategy that we align with the strategy assigned to that cluster."}, {"heading": "Acknowledgments", "text": "The authors would like to thank the anonymous reviewers for their helpful comments. The research reported in this article was partly supported by the AFOSR grant FA9550-05-10321 and the NSF grant DMS 0631636."}], "references": [{"title": "Inductive reasoning and bounded rationality", "author": ["W.B. Arthur"], "venue": "Amer. Econ. Review, 84(2):406\u2013411", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1994}, {"title": "Computing Nash equilibria of action-graph games", "author": ["N. Bhat", "K. Leyton-Brown"], "venue": "UAI", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Progress in approximate nash equilibria", "author": ["C. Daskalakis", "A. Mehta", "C.H. Papadimitriou"], "venue": "8th ACM Conf. on Electronic Commerce", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Computing equilibria in anonymous games", "author": ["C. Daskalakis", "C.H. Papadimitriou"], "venue": "FOCS", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Analogy-based expectation equilibrium", "author": ["P. Jehiel"], "venue": "Journal of Economic Theory, 123:81\u2013104", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Graphical models for game theory", "author": ["M. Kearns", "M. Littman", "S. Singh"], "venue": "UAI", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Efficient nash computation in large population games with bounded influence", "author": ["M. Kearns", "Y. Mansour"], "venue": "UAI", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "Gambit: Software tools for game theory", "author": ["R.D. McKelvey", "A.M. McLennan", "T.L. Turocy"], "venue": "version 0.2007.01.30. http://gambit.sourceforge.net", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Noncooperative games", "author": ["J.F. Nash"], "venue": "Annals of Mathematics, 54:189\u2013295", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1951}, {"title": "Learning payoff functions in infinite games", "author": ["Y. Vorobeychik", "M.P. Wellman", "S. Singh"], "venue": "Machine Learning, 67:145\u2013168", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Approximate strategic reasoning through hierarchical reduction of large symmetric games", "author": ["M.P. Wellman", "D.M. Reeves", "K.M. Lochner", "S.-F. Cheng", "R. Suri"], "venue": "AAAI", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 5, "context": ", graphical games [6] and action-graph games [2].", "startOffset": 18, "endOffset": 21}, {"referenceID": 1, "context": ", graphical games [6] and action-graph games [2].", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "[3] for a recent survey), but our focus is on effective, heuristic methods rather than on achieving worst-case approximation bounds.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[11] propose and study an approximate representation that is suitable for symmetric games.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] apply regression learning techniques to model payoffs for continuous games.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "The work on graphical games [6] assumes locality of interaction, while we make no such assumptions, and graphical games with many agents remain hard to solve.", "startOffset": 28, "endOffset": 31}, {"referenceID": 1, "context": "In comparing with action graph games [2], we note for example that our vendor game could be viewed as an action graph game if the cluster-based approximation is in fact exact.", "startOffset": 37, "endOffset": 40}, {"referenceID": 3, "context": "Daskalakis and Papadimitriou [4] consider anonymous games, a special case of action graph games in which the strategic considerations depend only on the number of agents that adopt each strategy but not their identity.", "startOffset": 29, "endOffset": 32}, {"referenceID": 6, "context": "Kearns and Mansour [7] present summarization games, a compact representation for games with many players.", "startOffset": 19, "endOffset": 22}, {"referenceID": 0, "context": "Their approach has two components: a summarization function, which maps the space of N -player strategy profiles onto the interval [0, 1], and a set of payoff functions, one for each player.", "startOffset": 131, "endOffset": 137}, {"referenceID": 4, "context": "Jehiel [5] advances the idea of an analogy-based expectation equilibrium in which agents are clustered into \u201canalogy classes\u201d and each agent plays a best-response against the average strategy in each cluster.", "startOffset": 7, "endOffset": 10}, {"referenceID": 10, "context": "[11], albeit slightly extended to an asymmetric setting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "A TSNE is guaranteed to exist, because there is always a twin symmetric best response to a twin symmetric strategy profile, so we can use the same argument as in Nash\u2019s proof of the existence of Nash equilibrium [9].", "startOffset": 212, "endOffset": 215}, {"referenceID": 7, "context": "Using Gambit [8], we find all Nash equilibria of these reduced normal-form games.", "startOffset": 13, "endOffset": 16}, {"referenceID": 0, "context": "The second game on which we test our approach is a slight variation of the Santa Fe bar problem (also known as the El Farol bar problem) [1].", "startOffset": 137, "endOffset": 140}, {"referenceID": 10, "context": ", [11] (WEL) to approximate a solution.", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "[11] when using the same number of agent clusters.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11]; for example, we can divide the clusters of the twins game into subclusters to allow for asymmetric equilibria, even in symmetric games and even if learned with just one cluster.", "startOffset": 0, "endOffset": 4}], "year": 2008, "abstractText": "In addressing the challenge of exponential scaling with the number of agents we adopt a cluster-based representation to approximately solve asymmetric games of very many players. A cluster groups together agents with a similar \u201cstrategic view\u201d of the game. We learn the clustered approximation from data consisting of strategy profiles and payoffs, which may be obtained from observations of play or access to a simulator. Using our clustering we construct a reduced \u201ctwins\u201d game in which each cluster is associated with two players of the reduced game. This allows our representation to be individuallyresponsive because we align the interests of every individual agent with the strategy of its cluster. Our approach provides agents with higher payoffs and lower regret on average than model-free methods as well as previous cluster-based methods, and requires only few observations for learning to be successful. The \u201ctwins\u201d approach is shown to be an important component of providing these low regret approximations.", "creator": "dvips(k) 5.96 Copyright 2005 Radical Eye Software"}}}