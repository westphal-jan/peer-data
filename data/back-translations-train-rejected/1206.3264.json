{"id": "1206.3264", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2012", "title": "Sampling First Order Logical Particles", "abstract": "Approximate inference in dynamic systems is the problem of estimating the state of the system given a sequence of actions and partial observations. High precision estimation is fundamental in many applications like diagnosis, natural language processing, tracking, planning, and robotics. In this paper we present an algorithm that samples possible deterministic executions of a probabilistic sequence. The algorithm takes advantage of a compact representation (using first order logic) for actions and world states to improve the precision of its estimation. Theoretical and empirical results show that the algorithm's expected error is smaller than propositional sampling and Sequential Monte Carlo (SMC) sampling techniques.", "histories": [["v1", "Wed, 13 Jun 2012 15:35:12 GMT  (2161kb)", "http://arxiv.org/abs/1206.3264v1", "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["hannaneh hajishirzi", "eyal amir"], "accepted": false, "id": "1206.3264"}, "pdf": {"name": "1206.3264.pdf", "metadata": {"source": "CRF", "title": "Sampling First Order Logical Particles", "authors": ["Hannaneh Hajishirzi"], "emails": ["eyal}@uiuc.edu"], "sections": [{"heading": null, "text": "Approximate conclusions in dynamic systems are the problem of estimating the state of the system based on a sequence of actions and partial observations. High precision is essential in many applications such as diagnosis, processing of natural language, tracking, planning and robotics. In this paper, we present an algorithm that examines possible deterministic execution of a probabilistic sequence. The algorithm uses a compact representation (with first order logic) of actions and world states to improve the precision of its estimation. Theoretical and empirical results show that the expected error of the algorithm is smaller than propositional scanning and sequential scanning procedures in Monte Carlo (SMC)."}, {"heading": "1 Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2 Probabilistic Relational Action Models", "text": "In this section, we present our framework, called the Probabilistic Relational Action Model (PRAM), for the representation of the dynamic system. The system is dynamic in the sense that its state changes through the execution of actions. Actions have probabilistic effects, which are represented by a probability distribution about possible deterministic executions. In what follows is the definition of the basic building blocks of a PRAM. We first define the language L of a PRAM to represent the probability distributions. [PRAM language] The language L of a PRAM is a tuple (F, C, DA) consisting of: \u2022 F a finite series of predictive variables (called fluents), the values of which change over time."}, {"heading": "3 Filtering Algorithm", "text": "In this section, we present our filter algorithm for calculating the probability of a query T against a sequence of probabilistic actions a1: T = < a1,.., aT > and observations o0: T = < o0,.., oT > in a PRAM. The algorithm approaches this probability by generating samples under possible deterministic execution of the given probabilistic action sequence. It then places these samples instead of enumerating deterministic execution and marginalizes them from these samples. The following equation shows the exact computational accuracy. P (T | a1: T, o0: T) = (2) \u2211 i P (T | ~ DAi) P (~ DAi | a1: T, o1: T), oT: D (oT: T, oT: D) and T: D (T) is a possible execution of the sequence a1: T."}, {"heading": "3.1 Probability of a FOL Formula at time t", "text": "In this section we show how to calculate the probability P (t | ~ DA, o0: t) of the formula t by applying a FO particle ~ DA and observations o0: t. Running the FO particle ~ DA with observations o0: t updates the current state of the system. The current state results from the application of an FO progression subroutine (described below) at each time step. Subsequently, the method PFOF (Figure 3) calculates the probability of the query taking into account the current system state for each FO particle. Its first step applies an FO regression subroutine to the query and the current state formula and returns FOL formulas output at time 0. This can be done because the actions are deterministic. The second step of the algorithm calculates the previous probability of regression of the query based on the current state formula regressed by the FO particle."}, {"heading": "3.1.1 Progress Current State Formula", "text": "In this section, we will introduce the Progress algorithm, which updates the current state formula, which contains a deterministic action and an observation. In general, the progression of an FOL formula for a deterministic action results in a series of FOL formulas (p1: n) where p1,.., pn are atomic subformulas of \"and\" precondda. \"(Succp1, da,.., Succpn, da) (see [19] for more details) Also filtering an FOL formula with an observation o is the FOL formula. Overall, generating all FOL formulas (Succp1, da,.., Succpn, da) is impossible because there are infinite numbers of such formulas (see [19] for more details)."}, {"heading": "3.1.2 Regressing a FOL Formula", "text": "The fact is that we are able to hold our own, that we are able to hold our own, that we are able to put ourselves in the lead."}, {"heading": "3.1.3 Prior Probability of a FOL Formula", "text": "In this section we describe the method Prior-FOF to calculate the probability of an FOL formula at time 0. We assume that the previous distribution P 0 over the world states of a PRAM with language L = (F, C, V, A, DA) is represented by a Markov logic network (MLN) [18]. We choose to represent our previous probabilistic logic with an MLN (called previous MLN) because it represents the expressive power of a FOL for a fixed domain. Our previous MLN consists of a series of weighted FOL formulas over the fluent language L of PRAM. The semantics of the MLN is that of a Markov network MLN [9], whose cliques coincide with the fundamentals of the formulas that make up the universe of C-L. The potential solution of a Clique Cl is defined as the exponential weighting of the corresponding formula."}, {"heading": "3.2 Sampling Algorithms", "text": "In this section, we describe the procedures S / R-Actions (Figure 5) and S-Actions (Figure 6), which each have a sequence of probable actions and observations. (Figure 1) Both algorithms incrementally generate each FO particle by triggering a deterrent action at a given time. (Figure 1) Both S / R-Actions and S / Actions generate an FO particle ~ DA = < da1,. daT > given a sequence a1: T and observations o0: T of the distribution P (~ DA: T). We calculate this probability distribution iteratively: P (~ DA | a1: T, o0: T)."}, {"heading": "3.3 Correctness, Complexity, and Accuracy", "text": "The following theorem shows how FOFA uses S-Actions and S / R-Actions to calculate the approximate posterior distribution P-Actions (FA). (FA) The approximate posterior distribution P-Actions (FA). (FA) The approximate posterior distribution P-Actions (FA). (FA) The approximate distribution P-API (FA). (FA) The approximate distribution P-API (FA). (FA) The approximate distribution. (FA) The approximate distribution. (FA) The approximate distribution. (FA) The approximate distribution. (FA) The approximate distribution. (FA) The approximate distribution. (FA) The approximate distribution. (FA) The approximate distribution. (FA) The approximate distribution. (FA). (FA). (FA). (FOP). (FOP)."}, {"heading": "4 Empirical Results", "text": "We have implemented our FOFA algorithm (Figure 2) with both S / R actions (Figure 5) and S actions (Figure 6), and our algorithms use a different structure from that available in DBNs. Therefore, we focus on planning domains: briefcases and repositories taken from the international planning competition for AIPS-98 and AIPS-02. 2 We have random deterministic designs and a probability distribution over them for each action. For example, we look at two versions of PutInSucc and PutInFail with probabilities of 0.9 and 0.1. Note that DBN representations (transitions between states) for the above frameworks are not compact, because the assumptions of independence among state variables are not known. We have compared the accuracy of our FOFA (S / R actions) and FOFA (S actions) with SCAI [8] and SMC algorithms."}, {"heading": "5 Conclusions and Future Work", "text": "Our algorithm uses a compact representation and achieves a higher accuracy than SMC scanning and earlier propositional scanning techniques. There are several directions in which we can continue this work: (1) Apply scanning in FO Markov Decision Processes (MDP) s [2] (2) Learn the transition model in PRAM. (3) Apply the algorithm in text comprehension. (4) Generalize the representation to continuous ranges (e.g. by discretizing the real value variables or by combining it with Rao-Blackwellised particle filtering [6])."}, {"heading": "Acknowledgements", "text": "We thank the anonymous reviewers for their helpful comments. This work was supported by DARPA SRI 27-001253 (PLATO project), NSF CAREER 05-46663 and UIUC / NCSA AESIS 251024."}], "references": [{"title": "Reasoning about noisy sensors and effectors in the situation", "author": ["F. Bacchus", "J.Y. Halpern", "H.J. Levesque"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1999}, {"title": "Symbolic dynamic programming for first-order MDPs", "author": ["C. Boutilier", "R. Reiter", "B. Price"], "venue": "In IJCAI,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Clp(bn): Constraint logic programming for probabilistic knowledge", "author": ["V.S. Costa", "D. Page", "M. Qazi", "J. Cussens"], "venue": "In UAI,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Probabilistic temporal reasoning", "author": ["T. Dean", "K. Kanazawa"], "venue": "In AAAI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1988}, {"title": "Sequential Monte Carlo", "author": ["A. Doucet", "N. de Freitas", "N. Gordon"], "venue": "Methods in Practice. Springer,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Raoblackwellised particle filtering for dynamic bayesian networks", "author": ["A. Doucet", "N. de Freitas", "K. Murphy", "S. Russell"], "venue": "In UAI,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "Learning probabilistic relational models", "author": ["N. Friedman", "L. Getoor", "D. Koller", "A. Pfeffer"], "venue": "In IJCAI,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1999}, {"title": "Stochastic filtering in a probabilistic action model", "author": ["H. Hajishirzi", "E. Amir"], "venue": "In AAAI\u201907,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Introduction to probabilistic graphical models", "author": ["Michael Jordan"], "venue": "Forthcoming", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Logical hidden markov models", "author": ["K. Kersting", "L.D. Raedt", "T. Raiko"], "venue": "Artificial Intelligence Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "A computational scheme for reasoning in dynamic probabilistic networks", "author": ["U. Kjaerulff"], "venue": "In UAI,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1992}, {"title": "Stochastic logic programs", "author": ["S. Muggleton"], "venue": "In Workshop on ILP,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "Dynamic Bayesian Networks: Representation, Inference and Learning", "author": ["Kevin Murphy"], "venue": "PhD thesis,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "Reasoning about partially observed actions", "author": ["M. Nance", "A. Vogel", "E. Amir"], "venue": "In AAAI,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Probabilistic horn abduction and bayesian networks", "author": ["D. Pool"], "venue": "Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1993}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition", "author": ["L.R. Rabiner"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1989}, {"title": "Knowledge In Action", "author": ["R. Reiter"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2001}, {"title": "First order logical filtering", "author": ["A. Shirazi", "E. Amir"], "venue": "In IJ- CAI,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Discriminative probabilistic models for relational data", "author": ["B. Taskar", "P. Abbeel", "D. Koller"], "venue": "In UAI\u201902,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "Infinite state bayesian networks", "author": ["M. Welling", "I. Porteous", "E. Bart"], "venue": "In NIPS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Logical particle filtering", "author": ["L.S. Zettlemoyer", "H.M. Pasula", "L.P. Kaelbling"], "venue": "In Dagstuhl Seminar on Probabilistic, Logical, and Relational Learning,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}], "referenceMentions": [{"referenceID": 3, "context": "This is because domain features become correlated after some steps, even if the domain has much conditional-independence structure [4].", "startOffset": 131, "endOffset": 134}, {"referenceID": 4, "context": "One of the most commonly used classes of techniques for approximate reasoning is SMC sampling [5].", "startOffset": 94, "endOffset": 97}, {"referenceID": 7, "context": "Recently, [8] introduced a new sampling approach which achieves higher precision than SMC techniques given a fixed number of samples.", "startOffset": 10, "endOffset": 13}, {"referenceID": 16, "context": ", [17]) and first order logical filtering [19; 14].", "startOffset": 2, "endOffset": 6}, {"referenceID": 16, "context": "We model a PRAM (Section 2) using probabilistic situation calculus [17], extended with a first order probabilistic prior that combines FOL and probabilities in a single framework (e.", "startOffset": 67, "endOffset": 71}, {"referenceID": 4, "context": "This algorithm achieves superior precision with fewer samples than SMC sampling techniques [5].", "startOffset": 91, "endOffset": 94}, {"referenceID": 12, "context": ", [13]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 7, "context": "The closest work to ours is [8] which also samples deterministic executions of the given probabilistic sequence.", "startOffset": 28, "endOffset": 31}, {"referenceID": 16, "context": "In PRAM each deterministic action da(~x) \u2208 DA is specified by precondition and successor state axioms [17].", "startOffset": 102, "endOffset": 106}, {"referenceID": 15, "context": "this is different from HMMs [16], where a sensor model is given).", "startOffset": 28, "endOffset": 32}, {"referenceID": 4, "context": "Finally, the algorithm uses generated samples in place of ~ DAi in Equation (2) and computes P\u0303N (\u03c6 |a , o ) as an approximation for the posterior probability of the query \u03c6 given the sequence a and the observations o by using the Monte Carlo integration [5]:", "startOffset": 255, "endOffset": 258}, {"referenceID": 17, "context": ", Succpn,da) (see [19] for more details).", "startOffset": 18, "endOffset": 22}, {"referenceID": 16, "context": "The algorithm for regression Regress(\u03c6, da) of formula \u03c6 with deterministic action da works as follows (see [17]).", "startOffset": 108, "endOffset": 112}, {"referenceID": 8, "context": "The semantics of the MLN is that of a Markov network MMLN [9] whose cliques correspond to groundings of the formulas given the universe of objects C \u2208 L.", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": ", [9]) in P (\u03c6) \u221d \u2211 f\u2208M \u220f", "startOffset": 2, "endOffset": 5}, {"referenceID": 19, "context": ", [21]) for representing prior distribution over infinite states.", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": "An estimation (see [5]) for measuring high variance among the weights is estimating the effective number of particles as N\u0302eff = 1 \u2211N i=1 wi .", "startOffset": 19, "endOffset": 22}, {"referenceID": 7, "context": "3 in [8].", "startOffset": 5, "endOffset": 8}, {"referenceID": 7, "context": "We compared the accuracy of our FOFA(S/R-Actions) and FOFA(S-Actions) with SCAI [8] and SMC algorithms.", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": "There are several directions that we can continue this work: (1) Apply sampling in FO Markov Decision Processes(MDP)s [2](2) Learn the transition model in PRAM.", "startOffset": 118, "endOffset": 121}, {"referenceID": 5, "context": ", by discretizing the real value variables or by combining with Rao-Blackwellised Particle Filtering [6]).", "startOffset": 101, "endOffset": 104}], "year": 2008, "abstractText": "Approximate inference in dynamic systems is the problem of estimating the state of the system given a sequence of actions and partial observations. High precision estimation is fundamental in many applications like diagnosis, natural language processing, tracking, planning, and robotics. In this paper we present an algorithm that samples possible deterministic executions of a probabilistic sequence. The algorithm takes advantage of a compact representation (using first order logic) for actions and world states to improve the precision of its estimation. Theoretical and empirical results show that the algorithm\u2019s expected error is smaller than propositional sampling and Sequential Monte Carlo (SMC) sampling techniques.", "creator": "TeX"}}}