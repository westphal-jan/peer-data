{"id": "1206.3266", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2012", "title": "Partitioned Linear Programming Approximations for MDPs", "abstract": "Approximate linear programming (ALP) is an efficient approach to solving large factored Markov decision processes (MDPs). The main idea of the method is to approximate the optimal value function by a set of basis functions and optimize their weights by linear programming (LP). This paper proposes a new ALP approximation. Comparing to the standard ALP formulation, we decompose the constraint space into a set of low-dimensional spaces. This structure allows for solving the new LP efficiently. In particular, the constraints of the LP can be satisfied in a compact form without an exponential dependence on the treewidth of ALP constraints. We study both practical and theoretical aspects of the proposed approach. Moreover, we demonstrate its scale-up potential on an MDP with more than 2^100 states.", "histories": [["v1", "Wed, 13 Jun 2012 15:36:14 GMT  (426kb)", "http://arxiv.org/abs/1206.3266v1", "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["branislav kveton", "milos hauskrecht"], "accepted": false, "id": "1206.3266"}, "pdf": {"name": "1206.3266.pdf", "metadata": {"source": "META", "title": "Partitioned Linear Programming Approximations for MDPs", "authors": ["Branislav Kveton", "Milos Hauskrecht"], "emails": ["branislav.kveton@intel.com", "milos@cs.pitt.edu"], "sections": [{"heading": null, "text": "Approximate Linear Programming (ALP) is an efficient approach to solving large factored Markov decision-making processes (MDPs). The basic idea of the method is to approximate the optimal value function through a series of basic functions and to optimize their weighting through linear programming (LP). In this paper, a new ALP approximation is proposed. Compared to the standard ALP formulation, we split the containment space into a series of low-dimensional spaces. This structure enables an efficient solution of the new LP. In particular, the constraints of the LP can be met in a compact form without exponential dependence on the tree width of the ALP constraints. We examine both practical and theoretical aspects of the proposed approach. In addition, we demonstrate its scaling potential on an MDP with more than 2100 states."}, {"heading": "1 Introduction", "text": "Markov Decision Processes (MDPs) [19] are an established framework for solving sequential decision problems under uncertainty. Unfortunately, traditional methods of solving MDPs, such as value and policy iteration, are not suitable for solving real problems. These problems are generally structured, and their state and scope of action are represented by state and action variables. The main idea of this method is to approximate the optimal value function through a series of basic functions and to optimize their weighting by linear programming (ALP). Optimization can be performed in a structured way to solve these problems efficiently [6, 12, 15]."}, {"heading": "2 Factored MDPs", "text": "Many real-world decision-making problems are, of course, described in factored form. Factored MDPs [5] allow a compact representation of this structure. A factored MDP [5] is a quadruple counted M = (X, A, P, R), where X = {X1,.., Xn} is a state space represented by a set of state variables, A = {a1,., am} is a finite set of measures 1, P (X, X, A, A) is a transitional function representing the dynamics of the MDP, andR is a reward function that assigns immediate payouts to state action configurations. The state of the system is fully monitored and given by a vector of value assignments x = (x1,.,. xn). 1For the simplicity of exposure, we adopt an MDP model with a single action variable."}, {"heading": "3 Solving factored MDPs", "text": "Markov decision-making processes can be solved by exact methods of dynamic programming (DP) in polynomial time in the size of their state space [19]. Unfortunately, the spaceX of factored MDPs is exponential in the number of state variables. Therefore, the DP methods are not suitable for solving these problems. Since a factored representation of an MDP does not guarantee a structure in its solution [13], we resort to value function approximations. In this work, we focus on the approximation of the linear value function [2, 22]: V w (x) = \u2211 iwifi (x). (4) The approximation limits the form of the value function to the linear combination of the basic functions fi (x), where w is a vector of optimized weights. The basic functions fi (x) are arbitrary functions, which are generally limited to small subsets of state variables Xi [2, 13]."}, {"heading": "4 Approximate linear programming", "text": "Various techniques for optimising the approximation of linear value function have been investigated and analysed [3]. We focus on approximate linear programming (ALP) [21], in which this problem is reproduced as a linear program: minimizew \u2211 iwi\u03b1i (5) under the condition: \u2211 iwiFi (x, a) \u2212 R (x, a) \u2265 0 nixX, a nearest variable in the LP, \u03b1i is a basic function relevance: \u03b1i = e\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6\u00f6n (x), (7) more often than the difference between the basic function fi (x) and its discounted retrospective function, \u03b1i is (a), fi (and) \u2212 is defined."}, {"heading": "4.1 Solving ALP formulations", "text": "This problem is difficult because the number of constraints is exponential in the number of state variables. Fortunately, the constraints have a certain structure, the structure being the result of the combination of linear value function approximations (Equation 4) with factored reward and transition models (Equations 1 and 2), so ALPMC constraints can be met in a structured form and without a complete enumeration.Based on these observations, Guestrin et al. [10] proposed a variable elimination method [9] that condenses the constraint space. Schuurmans and Patrascu [20] solved the satisfaction problem of constraint by the cutting plane method [4]. The approach iteratively searches for the most violated constraint: argmin x, a [exposed iw (t) i-Fi (x, a)."}, {"heading": "4.2 Theoretical analysis", "text": "The quality of the ALP formulation has been studied by de Farias and Van Roy [6]. Based on their work, we come to the conclusion that ALP minimizes the error of the L1 standard, the error that Farias and Van Roy made. Theorem 1 (de Farias and Van Roy [6]) draws a parallel between the optimization of this goal and the error of the maximum standard, the error of the V standard, V standard, V standard. Theorem 1 (de Farias and Van Roy [5]). Let us be a solution for the ALP formulation (5). Then, the expected error of the value function V standard, V standard can be limited as follows: D standard V standard, D standard, D standard, D standard V standard, D standard, the error, the relevance density function of the state, weighted and D standard, is the maximum standard. De Farias and Van Roy [6] also proved to be a tighter version of the standard, the error, the standard V, the standard V, weighted and the standard V."}, {"heading": "5 Partitioned ALP", "text": "In this section, we propose a novel, approximately linear programming formulation. Compared to the standard ALP (5), the proposed formulation has an additional structure in its limited space, which allows to control the complexity of the solution of the new LP. The LP solves a more restrictive problem than the standard ALP. Consequently, the formulation can be seen as an internal approach to the feasible region of the ALP (Figure 1), which distinguishes our work from existing ALP approaches [7, 14]. These approaches are based on constraint sampling and as a result they approach the feasible region of the ALP from the outside."}, {"heading": "5.1 An illustrative example", "text": "Let us first consider an optimization problem: minimizew, h w1\u03b11 + w2\u03b12 + h (10) subject to: w1F1 (x1) + w2F2 (x2) + h \u2265 0-x1-x2-X2; where w = (w1, w2) denotes the most important optimized variables, and h is an auxiliary variable that guarantees the feasibility of the LP. This problem affects | X1 \u00d7 X2 | = | X1 | | X2 | Restrictions. If the number of limitations is large, a suboptimal but feasible solution of the problem can be achieved by solving a new linear program: minimizew, h w1\u03b11 + w2\u03b12 + h (11) subject to: h1 + h2 = hw1F1 (x1) + h1 \u2265 0-x2F2 + h2."}, {"heading": "5.2 Partitioned ALP formulation", "text": "Similar to Section 5.1, we can resolve the constraint space in the ALP formulation (5). Formally, the partitioned ALP (PALP) formulation with K constraint spaces is given by a linear program: minimizew \u2211 iwi\u03b1i (12) is subject to: DMw (x, a) T \u2265 0 \u0445 x X, a) A; where: Mw (x, a) = (w1F1 (x, a),.., \u2212 R1 (x1, a). (13) is a vector whose i-th element corresponds to the i-th formulation in the ALP constraint, and the partition matrix: D = d1.1 d1.2 d1.3 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 d2.1 d2.2 d2.3 \u00b7 d3.1 \u00b7 d3.2 d3.3 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7... (14) corresponds to the ALP constraint."}, {"heading": "5.3 Partitioning matrix", "text": "The partition matrix allows trading in the quality and complexity of PALP solutions (Figure 2). In order to achieve high-quality and traceable approximations, the matrix rows should reflect tree decompositions corresponding to the ALP constraints (Figure 2).The breadth of decompositions should be small, since the complexity of satisfying a single constraint space is exponential in its tree width [10].How to generate the best PALP approach within a certain complexity limit is an open question. In the experimental section, we build the matrix D on the basis of heuristics. Heuristics creates a constraint space for each expectation term Fk (x, a) in equation 9. This constraint space consists of the TermwkFk (x, a) and its cost network neighbors."}, {"heading": "5.4 Solving PALP formulations", "text": "The PALP formulation (12) is similar to the ALP formulation (5) and can therefore be solved in a similar way. In the experimental section, we have implemented the cutting plane method for solving linear programs (Figure 3). In principle, any method for solving ALPs (Section 4.1) can be adapted to PALPs."}, {"heading": "5.5 Theoretical analysis", "text": "In this section, we discuss the quality of the PALP formulation (12). First, we prove that its solution is an upper limit for the optimal value function (12)."}, {"heading": "6 Experiments", "text": "The aim of the experimental section is to demonstrate the quality and scale-up potential of PALP approximations, which will be investigated with a view to ALP, a state-of-the-art approach to solving large-scale factor-based MDPs. Our experiments will be conducted on various forms of network administration problems [10], which is a standard benchmark for testing the scalability of MDP algorithms."}, {"heading": "6.1 Experimental setup", "text": "The problem of network administration concerns a network of randomly crashed computers. If a computer crashes, it increases the likelihood that its neighbors will crash. The goal is to reboot crashed computers to restore their functionality and prevent their failures from spreading further into the network. Examples of three network topologies are shown in Figure 4. Each network consists of a server and several workstations. The difference between the two types of computers is the reward for keeping them running. The reward for maintaining the server is 1. The problem of network administration is challenging because of the size of its state space. Especially since the state of the network is a product of individual computer states, it is exponential in the number of computers. Therefore, only small instances of the problem can be solved exactly. In the rest of the section, we focus on large-scale problems and try to solve them by linear approximations (Equation 4)."}, {"heading": "6.2 Experimental results", "text": "Our main experimental results are summarized in Figure 5. Based on these results, we conclude that PALP strategies are almost as good as ALP strategies. To explain our results, we have tried to examine the similarity of the basic functions achieved by ALP and PALP. As shown in Figure 6, the orders of magnitude of weights can be very different, but the weights show similar trends. Conversely, value functional approximations that correspond to weights must have similar shapes, and their greedy policies are similar to a result.Figure 5 suggests that PALP strategies can be calculated much faster than ALP strategies. These quick results from working with sparse decomposition mechanisms (Figure 7) of the original containment space than the space itself."}, {"heading": "7 Conclusions", "text": "The development of scalable algorithms to solve real MDPs is a challenging task. In this work, we investigated a novel approach to approximate linear programming. Compared to the standard ALP formulation, we split the containment space into a series of low-dimensional spaces. This structure allows a more efficient solution of the new LP. In particular, its constraints can be met in a compact form, without exponential dependence on the tree width of the original constraint space. Our experiments demonstrate the superiority of the new approach compared to existing exact and approximate solutions for ALP. The results of this paper can be extended in several ways. First, we have not addressed the issue of good subdivision of matrices D. This issue is similar in many aspects to the problem of efficient inference in Bayesian networks. In this context, Meila [17] proposed using a mixture of trees to find an arbitrary common probability distribution defined by a Bayesian network."}, {"heading": "Acknowledgment", "text": "We thank anonymous reviewers for helpful comments that have led to the improvement of this work, and Carlos Guestrin for encouraging and positioning this work in a broader context."}], "references": [{"title": "Dynamic Programming", "author": ["Richard Bellman"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1957}, {"title": "Polynomial approximation \u2013 a new computational technique in dynamic programming: Allocation processes", "author": ["Richard Bellman", "Robert Kalaba", "Bella Kotkin"], "venue": "Mathematics of Computation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1963}, {"title": "Neuro-Dynamic Programming", "author": ["Dimitri Bertsekas", "John Tsitsiklis"], "venue": "Athena Scientific,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1996}, {"title": "Introduction to Linear Optimization", "author": ["Dimitris Bertsimas", "John Tsitsiklis"], "venue": "Athena Scientific,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "Exploiting structure in policy construction", "author": ["Craig Boutilier", "Richard Dearden", "Mois\u00e9s Goldszmidt"], "venue": "In Proceedings of the 14th International Joint Conference on Artificial Intelligence,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1995}, {"title": "The linear programming approach to approximate dynamic programming", "author": ["Daniela Pucci de Farias", "Benjamin Van Roy"], "venue": "Operations Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "On constraint sampling for the linear programming approach to approximate dynamic programming", "author": ["Daniela Pucci de Farias", "Benjamin Van Roy"], "venue": "Mathematics of Operations Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "A model for reasoning about persistence and causation", "author": ["Thomas Dean", "Keiji Kanazawa"], "venue": "Computational Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1989}, {"title": "Bucket elimination: A unifying framework for probabilistic inference", "author": ["Rina Dechter"], "venue": "In Proceedings of the 12th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1996}, {"title": "Maxnorm projections for factored MDPs", "author": ["Carlos Guestrin", "Daphne Koller", "Ronald Parr"], "venue": "In Proceedings of the 17th International Joint Conference on Artificial Intelligence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Multiagent planning with factored MDPs", "author": ["Carlos Guestrin", "Daphne Koller", "Ronald Parr"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Efficient solution algorithms for factored MDPs", "author": ["Carlos Guestrin", "Daphne Koller", "Ronald Parr", "Shobha Venkataraman"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Computing factored value functions for policies in structured MDPs", "author": ["Daphne Koller", "Ronald Parr"], "venue": "In Proceedings of the 16th International Joint Conference on Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "An MCMC approach to solving hybrid factored MDPs", "author": ["Branislav Kveton", "Milos Hauskrecht"], "venue": "In Proceedings of the 19th International Joint Conference on Artificial Intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Solving factored MDPs with hybrid state and action variables", "author": ["Branislav Kveton", "Milos Hauskrecht", "Carlos Guestrin"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Samuel meets Amarel: Automating value function approximation using global state space analysis", "author": ["Sridhar Mahadevan"], "venue": "In Proceedings of the 20th National Conference on Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "Learning with Mixtures of Trees", "author": ["Marina Meila"], "venue": "PhD thesis, Massachusetts Institute of Technology,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1999}, {"title": "Greedy linear valueapproximation for factored Markov decision processes", "author": ["Relu Patrascu", "Pascal Poupart", "Dale Schuurmans", "Craig Boutilier", "Carlos Guestrin"], "venue": "In Proceedings of the 18th National Conference on Artificial Intelligence,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2002}, {"title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming", "author": ["Martin Puterman"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1994}, {"title": "Direct valueapproximation for factored MDPs", "author": ["Dale Schuurmans", "Relu Patrascu"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "Generalized polynomial approximations in Markovian decision processes", "author": ["Paul Schweitzer", "Abraham Seidmann"], "venue": "Journal of Mathematical Analysis and Applications,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1985}, {"title": "Planning Under Uncertainty in Complex Structured Environments", "author": ["Benjamin Van Roy"], "venue": "PhD thesis, Massachusetts Institute of Technology,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}], "referenceMentions": [{"referenceID": 18, "context": "Markov decision processes (MDPs) [19] are an established framework for solving sequential decision problems under uncertainty.", "startOffset": 33, "endOffset": 37}, {"referenceID": 20, "context": "Approximate linear programming (ALP) [21] has emerged as a promising approach to solving these problems efficiently [6, 12, 15].", "startOffset": 37, "endOffset": 41}, {"referenceID": 5, "context": "Approximate linear programming (ALP) [21] has emerged as a promising approach to solving these problems efficiently [6, 12, 15].", "startOffset": 116, "endOffset": 127}, {"referenceID": 11, "context": "Approximate linear programming (ALP) [21] has emerged as a promising approach to solving these problems efficiently [6, 12, 15].", "startOffset": 116, "endOffset": 127}, {"referenceID": 14, "context": "Approximate linear programming (ALP) [21] has emerged as a promising approach to solving these problems efficiently [6, 12, 15].", "startOffset": 116, "endOffset": 127}, {"referenceID": 9, "context": "The optimization can be performed in a structured manner [10, 20].", "startOffset": 57, "endOffset": 65}, {"referenceID": 19, "context": "The optimization can be performed in a structured manner [10, 20].", "startOffset": 57, "endOffset": 65}, {"referenceID": 9, "context": "The complexity of computing exact ALP solutions [10, 20] is exponential in the treewidth of the dependency graph that represents the constraint space in ALP.", "startOffset": 48, "endOffset": 56}, {"referenceID": 19, "context": "The complexity of computing exact ALP solutions [10, 20] is exponential in the treewidth of the dependency graph that represents the constraint space in ALP.", "startOffset": 48, "endOffset": 56}, {"referenceID": 6, "context": "This type of problems can be still solved approximately using Monte Carlo constraint sampling [7, 14].", "startOffset": 94, "endOffset": 101}, {"referenceID": 13, "context": "This type of problems can be still solved approximately using Monte Carlo constraint sampling [7, 14].", "startOffset": 94, "endOffset": 101}, {"referenceID": 4, "context": "First, we review factored MDPs [5] and linear value function approximations [2, 22].", "startOffset": 31, "endOffset": 34}, {"referenceID": 1, "context": "First, we review factored MDPs [5] and linear value function approximations [2, 22].", "startOffset": 76, "endOffset": 83}, {"referenceID": 21, "context": "First, we review factored MDPs [5] and linear value function approximations [2, 22].", "startOffset": 76, "endOffset": 83}, {"referenceID": 4, "context": "Factored MDPs [5] allow for a compact representation of this structure.", "startOffset": 14, "endOffset": 17}, {"referenceID": 4, "context": "A factored MDP [5] is a 4-tuple M = (X,A, P,R), where X = {X1, .", "startOffset": 15, "endOffset": 18}, {"referenceID": 10, "context": "Our ideas straightforwardly generalize to MDPs with factored action spaces [11].", "startOffset": 75, "endOffset": 79}, {"referenceID": 7, "context": "and is described compactly by a dynamic Bayesian network (DBN) [8].", "startOffset": 63, "endOffset": 66}, {"referenceID": 18, "context": "In such a setting, there always exists an optimal policy \u03c0 which is stationary and deterministic [19].", "startOffset": 97, "endOffset": 101}, {"referenceID": 0, "context": "The policy is greedy with respect to the optimal value function V , which is a fixed point of the Bellman equation [1]:", "startOffset": 115, "endOffset": 118}, {"referenceID": 18, "context": "Markov decision processes can be solved by exact dynamic programming (DP) methods in polynomial time in the size of their state space [19].", "startOffset": 134, "endOffset": 138}, {"referenceID": 12, "context": "Since a factored representation of an MDP does not guarantee a structure in its solution [13], we resort to value function approximations.", "startOffset": 89, "endOffset": 93}, {"referenceID": 1, "context": "In this work, we focus on the linear value function approximation [2, 22]:", "startOffset": 66, "endOffset": 73}, {"referenceID": 21, "context": "In this work, we focus on the linear value function approximation [2, 22]:", "startOffset": 66, "endOffset": 73}, {"referenceID": 1, "context": "The basis functions fi(x) are arbitrary functions, which are usually restricted to small subsets of state variablesXi [2, 13].", "startOffset": 118, "endOffset": 125}, {"referenceID": 12, "context": "The basis functions fi(x) are arbitrary functions, which are usually restricted to small subsets of state variablesXi [2, 13].", "startOffset": 118, "endOffset": 125}, {"referenceID": 17, "context": "They are usually provided by domain experts but can also be discovered automatically [18, 16].", "startOffset": 85, "endOffset": 93}, {"referenceID": 15, "context": "They are usually provided by domain experts but can also be discovered automatically [18, 16].", "startOffset": 85, "endOffset": 93}, {"referenceID": 2, "context": "Various techniques for optimizing the linear value function approximation have been studied and analyzed [3].", "startOffset": 105, "endOffset": 108}, {"referenceID": 20, "context": "We focus on approximate linear programming (ALP) [21], which restates this problem as a linear program:", "startOffset": 49, "endOffset": 53}, {"referenceID": 9, "context": "Since our basis functions fi(x) are often restricted to small subsets of state variables, expectation terms in the ALP formulation (5) can be computed efficiently [10].", "startOffset": 163, "endOffset": 167}, {"referenceID": 9, "context": "[10] proposed a variable elimination method [9] that rewrites the constraint space compactly.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[10] proposed a variable elimination method [9] that rewrites the constraint space compactly.", "startOffset": 44, "endOffset": 47}, {"referenceID": 19, "context": "Schuurmans and Patrascu [20] solved the constraint satisfaction problem by the cutting plane method [4].", "startOffset": 24, "endOffset": 28}, {"referenceID": 3, "context": "Schuurmans and Patrascu [20] solved the constraint satisfaction problem by the cutting plane method [4].", "startOffset": 100, "endOffset": 103}, {"referenceID": 9, "context": "The space complexity of both constraint satisfaction methods [10, 20] is exponential in the treewidth of the constraint space.", "startOffset": 61, "endOffset": 69}, {"referenceID": 19, "context": "The space complexity of both constraint satisfaction methods [10, 20] is exponential in the treewidth of the constraint space.", "startOffset": 61, "endOffset": 69}, {"referenceID": 6, "context": "For instance, de Farias and Van Roy [7] proposed Monte Carlo approximations of the constraint space.", "startOffset": 36, "endOffset": 39}, {"referenceID": 13, "context": "Kveton and Hauskrecht [14] showed how to search for the most violated constraint (Equation 9) using Markov chain Monte Carlo (MCMC) sampling.", "startOffset": 22, "endOffset": 26}, {"referenceID": 5, "context": "The quality of the ALP formulation has been studied by de Farias and Van Roy [6].", "startOffset": 77, "endOffset": 80}, {"referenceID": 5, "context": "Theorem 1 (de Farias and Van Roy [6]).", "startOffset": 33, "endOffset": 36}, {"referenceID": 5, "context": "De Farias and Van Roy [6] also proved a tighter version of Theorem 1, which reweights the error \u2016V \u2217 \u2212 V w\u2016\u221e.", "startOffset": 22, "endOffset": 25}, {"referenceID": 6, "context": "This differentiates our work from existing ALP approximations [7, 14].", "startOffset": 62, "endOffset": 69}, {"referenceID": 13, "context": "This differentiates our work from existing ALP approximations [7, 14].", "startOffset": 62, "endOffset": 69}, {"referenceID": 9, "context": "The width of the decompositions should be small since the complexity of satisfying a single constraint space is exponential in its treewidth [10].", "startOffset": 141, "endOffset": 145}, {"referenceID": 5, "context": "Proof: Our proof is similar to the proof of Theorem 2 by de Farias and Van Roy [6].", "startOffset": 79, "endOffset": 82}, {"referenceID": 5, "context": "holds [6].", "startOffset": 6, "endOffset": 9}, {"referenceID": 9, "context": "Our experiments are performed on various forms of the network administration problem [10].", "startOffset": 85, "endOffset": 89}, {"referenceID": 6, "context": "In addition, we experiment with ALP formulations, which are solved approximately by Monte Carlo constraint sampling [7].", "startOffset": 116, "endOffset": 119}, {"referenceID": 16, "context": "In this context, Meila [17] proposed using a mixture of trees to approximate an arbitrary joint probability distribution defined by a Bayesian network.", "startOffset": 23, "endOffset": 27}], "year": 2008, "abstractText": "Approximate linear programming (ALP) is an efficient approach to solving large factored Markov decision processes (MDPs). The main idea of the method is to approximate the optimal value function by a set of basis functions and optimize their weights by linear programming (LP). This paper proposes a new ALP approximation. Comparing to the standard ALP formulation, we decompose the constraint space into a set of low-dimensional spaces. This structure allows for solving the new LP efficiently. In particular, the constraints of the LP can be satisfied in a compact form without an exponential dependence on the treewidth of ALP constraints. We study both practical and theoretical aspects of the proposed approach. Moreover, we demonstrate its scale-up potential on an MDP with more than 2 states.", "creator": "dvips(k) 5.96 Copyright 2007 Radical Eye Software"}}}