{"id": "1206.3284", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2012", "title": "Bounding Search Space Size via (Hyper)tree Decompositions", "abstract": "This paper develops a measure for bounding the performance of AND/OR search algorithms for solving a variety of queries over graphical models. We show how drawing a connection to the recent notion of hypertree decompositions allows to exploit determinism in the problem specification and produce tighter bounds. We demonstrate on a variety of practical problem instances that we are often able to improve upon existing bounds by several orders of magnitude.", "histories": [["v1", "Wed, 13 Jun 2012 15:44:34 GMT  (199kb)", "http://arxiv.org/abs/1206.3284v1", "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["lars otten", "rina dechter"], "accepted": false, "id": "1206.3284"}, "pdf": {"name": "1206.3284.pdf", "metadata": {"source": "CRF", "title": "Bounding Search Space Size via (Hyper)tree Decompositions", "authors": ["Lars Otten"], "emails": ["lotten@ics.uci.edu", "dechter@ics.uci.edu"], "sections": [{"heading": null, "text": "This paper develops a measure of the performance of AND / OR search algorithms to solve a variety of queries via graphical models. We show how the connection to the recent introduction of hypertree decomposition enables us to exploit determinism in problem specification and draw narrower boundaries. We show from a variety of practical problem cases that we are often able to improve existing boundaries by several orders of magnitude."}, {"heading": "1 INTRODUCTION", "text": "This year, it has come to the point where it is only a matter of time before a solution is found, in which a solution is found."}, {"heading": "2 PRELIMINARIES AND DEFINITIONS", "text": "In the following, we will adopt a graphical model that is a set of variables X = {x1,.., xn}, their finite domains D = {D1,.., Dn}, a set of functions F = {f1,.., fm}, each defined by a subset X, and a combination operator (typically sum, product, or link) across all functions. Along with a marginalization operator such as minX and maxX, we will get an argument problem. The particular cases of reasoning tasks we have in mind are belief networks, (weighted) constraint networks, or mixed networks that combine both. The primary tasks in belief networks are updating and finding the most likely explanation. They are often specified by conditional probability functions defined on each variable and its parents in a particular acyclic graph (see Figure 1 (a)), and use multiplication and summation or maximization as combination and eralization."}, {"heading": "2.1 EXPRESSING STRUCTURE", "text": "In fact, it is that it is a matter of a way in which people are able to determine for themselves what they want and what they want. (...) In fact, it is a matter of people being able to decide what they want. (...) In fact, it is a matter of people being able to decide. (...) It is a matter of people being able to decide what they want. (...) It is a matter of people being able to decide what they want. (...) It is as if they are able to behave. (...) It is as if they are able. (...) It is as if they are able to behave. (...) It is as if they are able. (...) It is as if they are able. (...) It is as if they are able. (...) It is as if they are in a situation. (...) It is as if they are in a situation. (...) It is as if they are in a situation. (...) It is as if they are in a situation."}, {"heading": "2.2 SOLVING REASONING PROBLEMS", "text": "There are two main methods for solving thought problems: search (e.g., searching for the first branch and the first branch, searching for the best first branch) and conclusion (e.g., removing variables, clustering connecting trees), both of which can be detected as exponential in time and space in the tree width of the problem site [Lauritzen und Spiegelhalter, 1988, Dechter and Pearl, 1989, Kask et al., 2005, Dechter and Mateescu, 2007], with the dominant factor being kW, where k denotes the maximum domain of the problem variables."}, {"heading": "2.2.1 Search", "text": "The search for the origin of the disease begins with the origin of the disease and ends with the origin of the disease. The origin of the disease begins with the origin of the disease. The origin of the disease begins with the origin of the disease. The origin of the disease begins with the origin of the disease. The origin of the disease begins with the origin of the disease. The origin of the disease begins with the origin of the disease. The origin of the disease begins with the origin of the disease. The origin of the disease begins with the origin of the origin of the disease. The origin of the disease begins with the origin of the origin of the disease. The origin of the disease begins with the origin of the origin of the disease."}, {"heading": "2.3 EXPLOITING DETERMINISM", "text": "In practice, however, problem cases in many areas will exhibit a significant degree of determinism (e.g. improper tuples in constraint problems, zero probability entries in faith networks); search algorithms detect the resulting inconsistencies early in the search process and prune the relevant part of the search space, which can result in significant runtime savings, but is not reflected in the standard worst-case limits described above; in order to exploit determinism in the context of variable elimination, the concept of (generalized) hypertree decomposition for constraint networks was used in [Gottlob et al, 2000]. As a subclass of tree decomposition, it was shown that there is a stronger indicator of tractability than tree width. DEFINITION 2.4 Let's leave T = < T >, where T = (V, E) a tree decomposition of a rational problem with X."}, {"heading": "3 HYPERTREE WIDTH BOUNDS FOR INFERENCE", "text": "In this section, we briefly examine whether the limits based on tree width can provide a practical improvement over the tree width limits described above. To this end, we recently looked at a selection of over 140 problem cases from different areas [Dechter et al., 2008]. We used the code developed for [Dermaku et al., 2005], which is available online. It generates a tree decomposition along a minfill order and extends it to a (generalized) hypertree decomposition by applying a greedy heuristics. We used the lowest tree width w and hypertree width hw of 20 passes as the basis for our investigation: For each example of problems, we calculate the dominant factors of the two worst-case complexity limits, i.e. where k indicates the maximum domain size and t the maximum functional density of hypertree instances, hypertree decomposition in the problem instance is not relevant."}, {"heading": "4 SEARCH SPACE ESTIMATION", "text": "Although the results in [Dechter et al., 2008] suggest that complexity limits based on the width of a hypertree are often not competitive in practice, the idea of exploiting determinism remains promising. Furthermore, although all considerations in Section 3 are aimed at inference algorithms, we are particularly interested in estimating how determinism in a problem affects the size of the search space discussed in Section 2.2.1, since search is a widely used method in practice. To this end, we will endeavor to expand the size of the minimal AND / OR context search graph explored by an AND / OR search with caching, as described in Section 2."}, {"heading": "4.1 TREE DECOMPOSITION CORRESPONDENCE", "text": "Suppose a variable orders d = x1,.., xn is fixed and the search instantiates variables first to last (while the conclusion would be last to first). We note that the way the search space is broken down by AND / OR caching search can be represented by the decomposition of the bucket tree along the same sequence. For details, refer to [Mateescu and Dechter, 2005] to illustrate that we are repeating our previous example: Example 4.1 Consider the decomposition of the bucket tree in Figure 1 (c) and the AND / OR search graph in Figure 3. It is easy to see that the decomposition clusters can be related to the \"layers\" of the search graph, i.e. the nodes associated with a variable and their values, as shown in Figure 4."}, {"heading": "4.2 BOUNDING CLUSTER SIZE", "text": "It is not as if it were a matter of a manner and manner, which would deal with the question of the manner and manner, how they are in the manner and manner, how they are in the manner and manner, how they are in the manner and manner, how they are in the manner and manner, how they are in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language of the language, in the language, in the language, in the language, in the language of the language, in the language, in the language, in the language of the language, in the language, in the language of the language, in the language, in the language, in the language of the language, in the language, in the language, in the language of the language, in the language, in the language of the language, in the language, in the language of the language, in the language, in the language of the language, in the language of the language, in the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language of the language, in the language, in the language of the language of the language, in the language of the language, in the language of the language, in the language of the language of the language, in the language of the language, in the language of the language of the language, in the language of the language, in the language of the language of the language, in the language, in the language of the language of the language of the language, in"}, {"heading": "5 EXPERIMENTAL RESULTS", "text": "For empirical evaluation, we return to the problem cases described in [Dechter et al., 2008] (see also Section 3), which include 112 faith networks from areas such as encoding networks, dynamic Bayesian networks, genetic linkage instances, and CPCS medical diagnostic networks. We also evaluated 30 weighted constraint network instances. All problem instances are available online. For each instance, we enter the number of variables n, the maximum variable domain size k, the maximum functional type r, and the average density ratio tr (defined as the average percentage of relevant tuples in a full functional table). For each problem instance, we perform our Bounding Method along 100 different minfill orderings (with random binding break) and record the lowest limit, with w as the tree width of the bucket tree decomposition (defined as the average percentage of relevant Cympel for each functional space size) being 1."}, {"heading": "5.1 BOUND IMPROVEMENTS", "text": "If we compare the values for n \u00b7 kw + 1 and twb, we can see that the problem improves by at least one order of magnitude for each instance of problem, but often by more than that (remember that table log10 shows the limits).For example, for most genetic linkages of the family tree, the decrease is ten orders of magnitude or more. Similar results apply to the dynamic Bayesian networks we tested, with many orders of magnitude. It seems that problems with a higher number of variables benefit most from the fine-grained analysis, which makes sense considering the fact that the worst-case bound greatly overestimates the size of almost all clusters, since tree decomposition in practice contains very few clusters full of tree widths. If we try to exploit determinism by going from the twb to the hwb limit, there is only an indication of the problem parameters, which are not an obvious indicator of when the bound conditions will improve."}, {"heading": "5.2 BOUND EVALUATION", "text": "Most problem cases are too large to calculate the exact size of the minimum AND / OR search space, which would be tantamount to solving the problem (for solution counting or calculating P (e)), but for some of the smaller cases this is actually feasible, which gives us the opportunity to test how narrow our limit is. Table 2 shows the upper limits nkW + 1, twb, and hwb (not in their log10 this time), as well as the exact number of AND nodes in the actual context-minimum search curve. The values in each line were determined in the same minfill order (not necessarily the one used for Table 1). For smaller instances, the limit we calculate is quite narrow (note that CPCS instances have no determinism at all, and thus twb and hwb exactly correspond to the size of the search space)."}, {"heading": "6 CONCLUSIONS & FUTURE WORK", "text": "While asymptotic limits for search algorithms can give an approximate idea of the severity of the problem, it is often desirable to obtain a narrower, finer-grained limit. However, as has already been shown, this can be achieved by looking at a suitable tree decomposition of the underlying graph structure of the problem and the domains of variables in the decomposition clusters. However, this is blind to the determinism that can severely prune the search space in practice. The contribution of this paper is to introduce ideas from the framework of hypertree decomposition into the limits of the search space, which allows us to exploit determinism in the functional specification, but only if it is advantageous for the overall complexity. We have shown in a number of 112 faith networks and 30 weighted constraint networks that the proposed scheme is indeed capable of further improving bound search complexity, in some cases by several orders of magnitude."}, {"heading": "Acknowledgments", "text": "This work was partially supported by NSF funding IIS0713118 and NIH funding R01-HG004175-02."}], "references": [{"title": "Pearl: Tree Clustering for Constraint Networks", "author": ["Dechter", "Pearl", "J. 1989] R. Dechter"], "venue": "Artificial Intelligence", "citeRegEx": "Dechter et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Dechter et al\\.", "year": 1989}, {"title": "AND/OR search spaces for graphical models", "author": ["Dechter", "Mateescu", "2007] R. Dechter", "R. Mateescu"], "venue": "In Artificial Intelligence", "citeRegEx": "Dechter et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dechter et al\\.", "year": 2007}, {"title": "On the Practical Significance of Hypertree vs. Tree Width", "author": ["Dechter et al", "2008] R. Dechter", "L. Otten", "R. Marinescu"], "venue": "In Proceedings of ECAI\u201908", "citeRegEx": "al. et al\\.,? \\Q2008\\E", "shortCiteRegEx": "al. et al\\.", "year": 2008}, {"title": "Heuristic Methods for Hypertree Decompositions", "author": ["Dermaku et al", "2005] A. Dermaku", "T. Ganzow", "G. Gottlob", "B. McMahan", "N. Musliu", "M. Samer"], "venue": "Technical Report DBAI-TR-2005-53, Vienna University of Technology,", "citeRegEx": "al. et al\\.,? \\Q2005\\E", "shortCiteRegEx": "al. et al\\.", "year": 2005}, {"title": "Maximum Likelihood Haplotyping for General Pedigrees", "author": ["Fishelson et al", "2005] M. Fishelson", "N. Dovgolevsky N", "D. Geiger"], "venue": "Human Heredity", "citeRegEx": "al. et al\\.,? \\Q2005\\E", "shortCiteRegEx": "al. et al\\.", "year": 2005}, {"title": "A comparison of structural CSP decomposition methods", "author": ["Gottlob et al", "2000] G. Gottlob", "N. Leone", "F. Scarcello"], "venue": "Artificial Intelligence", "citeRegEx": "al. et al\\.,? \\Q2000\\E", "shortCiteRegEx": "al. et al\\.", "year": 2000}, {"title": "Unifying tree decompositions for reasoning in graphical models", "author": ["Kask et al", "2005] K. Kask", "R. Dechter", "J. Larrosa", "A. Dechter"], "venue": "Artificial Intelligence", "citeRegEx": "al. et al\\.,? \\Q2005\\E", "shortCiteRegEx": "al. et al\\.", "year": 2005}, {"title": "Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems", "author": ["Lauritzen", "Spiegelhalter", "1988] S.L. Lauritzen", "D.J. Spiegelhalter"], "venue": "Journal of the Royal Statistical Society. Series B", "citeRegEx": "Lauritzen et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Lauritzen et al\\.", "year": 1988}, {"title": "The Relationship Between AND/OR Search Spaces and Variable Elimination", "author": ["Mateescu", "Dechter", "2005] R. Mateescu", "R. Dechter"], "venue": "In Proceedings of", "citeRegEx": "Mateescu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Mateescu et al\\.", "year": 2005}, {"title": "Online system for faster linkage analysis via parallel execution on thousands of personal computers", "author": ["Silberstein et al", "2006] M. Silberstein", "A. Tzemach", "N. Dovgolevskiy", "M. Fishelson", "A. Schuster", "D. Geiger"], "venue": "American Journal of Human Genetics,", "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "Bounding Complexity in the Presence of Functional Dependencies", "author": ["Zabiyaka", "Darwiche", "2006] Y. Zabiyaka", "A. Darwiche"], "venue": "In Proceedings of", "citeRegEx": "Zabiyaka et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zabiyaka et al\\.", "year": 2006}], "referenceMentions": [], "year": 2008, "abstractText": "This paper develops a measure for bounding the performance of AND/OR search algorithms for solving a variety of queries over graphical models. We show how drawing a connection to the recent notion of hypertree decompositions allows to exploit determinism in the problem specification and produce tighter bounds. We demonstrate on a variety of practical problem instances that we are often able to improve upon existing bounds by several orders of magnitude.", "creator": null}}}