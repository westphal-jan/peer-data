{"id": "1206.3286", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2012", "title": "New Techniques for Algorithm Portfolio Design", "abstract": "We present and evaluate new techniques for designing algorithm portfolios. In our view, the problem has both a scheduling aspect and a machine learning aspect. Prior work has largely addressed one of the two aspects in isolation. Building on recent work on the scheduling aspect of the problem, we present a technique that addresses both aspects simultaneously and has attractive theoretical guarantees. Experimentally, we show that this technique can be used to improve the performance of state-of-the-art algorithms for Boolean satisfiability, zero-one integer programming, and A.I. planning.", "histories": [["v1", "Wed, 13 Jun 2012 15:45:20 GMT  (295kb)", "http://arxiv.org/abs/1206.3286v1", "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence (UAI2008)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["matthew streeter", "stephen f smith"], "accepted": false, "id": "1206.3286"}, "pdf": {"name": "1206.3286.pdf", "metadata": {"source": "CRF", "title": "New Techniques for Algorithm Portfolio Design", "authors": ["Matthew Streeter", "Stephen F. Smith"], "emails": ["sfs}@cs.cmu.edu"], "sections": [{"heading": null, "text": "We present and evaluate new techniques for designing algorithm portfolios. In our view, the problem has both a scheduling aspect and an aspect of machine learning. Preparatory work has largely dealt with one of the two aspects in isolation. Building on current work on the scheduling aspect of the problem, we present a technique that addresses both aspects simultaneously and provides attractive theoretical guarantees. Experimentally, we show that this technique can be used to improve the performance of modern algorithms for Boolean satisfaction, zero-one integer programming and A.I. planning."}, {"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to assert themselves, that they are able to survive on their own."}, {"heading": "1.1 Formal setup", "text": "We are given as input a set of H of heuristics (i.e., algorithms with potentially large run-time pairs are temporarily executed) to solve a arithmetic problem. Heuristic h, when executed on problem case x, runs for T (h, x) units of time before solving the problem. If h is randomly estimated, then T (h, x) is a random variable whose result depends on the sequence of random bits that are input to h.We will be interested in executing heuristics according to the schemes of the following form.Definition (schema). A scheme S = < (h1, perc1), (h2, perc2), is a sequence of pairs (h, bar). H \u00d7 R > 0, where each pair (h, bar) represents a running heuristic h for the time. If we interpret a schedule, we let each heuristic method be equal in one model of two (the choice of styles does not have to be all)."}, {"heading": "1.2 Summary of results", "text": "In \u00a7 2, we review the most recent results using a purely planning approach to the design problem of the Portfolio algorithm. In offline setting, the main result is a greedy algorithm that delivers a 4 approximation to the optimal schedule; achieving a 4 approximation for each > 0 is NP-hard. In offline setting, the main result is an online appointment selection algorithm whose worst-case performance converges with that of the offline greedy approximation algorithm, asymptotic as the number of instances increases. Note that the latter do not require statistical assumptions about the sequence of problem instances. In \u00a7 3, we discuss how the online algorithm discussed in \u00a7 2 can be combined with algorithms to solve this so-called sleeping expert problem, in order to use the Boolean features of an instance in selecting a problem instance. This approach leads to an online algorithm that simultaneously delivers for each characteristic of a given time (i.e., an optimum performance)."}, {"heading": "2 Background", "text": "In this section we discuss current results of a pure planning approach to the design of algorithm portfolios. These results form the basis for the algorithms and experimental results presented in the rest of the article."}, {"heading": "2.1 Offline greedy approximation algorithm", "text": "Suppose we collect a set of training cases X and want to calculate the schedule that runs optimally through the training instances (i.e. the plan S, which minimizes the number x x E [T (S, x)]. We assume that the distribution of T (h, x) for each heuristic h-sum set cover problem [3], Streeter et al. [16, 17] has developed a greedy approximation algorithm for this offline problem (in practice we would have to estimate it by performing a finite number of runs). Suppose f (S) denotes the sum of all instances x x X, the probability that the execution of plan S results in a solution for instance x. Plan G = < g1, g2,... > results from the greedy approximation algorithm x."}, {"heading": "2.2 Online greedy algorithm", "text": "In the online setting, a sequence < x1, x2,.., xn > of the problem cases arrives individually, and one has to solve each instance xi according to a schedule (let's call it Si) before moving on to instance xi + 1. Selecting Si means one has no knowledge of xi itself. After solving xi, one only learns the results of the runs that were actually performed in the execution of Si. As in the offline setting, the goal is to minimize the average CPU time required to solve each instance in the sequence. Recently, Streeter and Golovin [15] developed an online algorithm for an abstract appointment problem that includes this online problem as a special case. To apply the results of [15], we have to make some additional assumptions. First, we assume that T (h, xi) is an integer for all heuristics h and instances xi."}, {"heading": "O (r |X |) values of \u03c4 per heuristic, where r is the maximum number of runs used to estimate the distribution of", "text": "T (h, x).For further details see [14].Theorem 2 (Streeter and Golovin, 2007).The algorithm OG [15], which is executed with exploration probability \u03b3 = \u0443 (n \u2212 1 4), has the following guarantee: Leave Ti = min {B, T (Si, xi)}, for something B > 0. Then n \u2211 i = 1 E [Ti] \u2264 4 \u00d7 min S \u0432S {n \u2211 i = 1 E [T (S, x)]} + O (n 3 4)."}, {"heading": "3 Exploiting Features", "text": "The algorithms mentioned in theories 1 and 2 do not provide mechanisms for adapting to the particular problem to be solved. (In practice, there can be quickly calculable characteristics that distinguish one instance from the other and suggest the use of different heuristics.) In this section, we describe how existing techniques for solving the so-called expert sleeping problem can be used to exploit such characteristics in an attractive way. (The expert sleeping problem is defined as follows: one has access to a number of M experts on any day in which a particular expert is either awake, in which case the expert disposes of a piece of sleeping expert, or the expert is asleep. At the beginning of the day, one must select an awake expert whose advice must be followed. (0, 1) At the end of the day, the value of loss i (0, 1) ij is used for loss."}, {"heading": "4 Experimental Evaluation", "text": "In this section, we evaluate the algorithms presented in the previous section experimentally using data from recent solver contests."}, {"heading": "4.1 Solver competitions", "text": "In these contests, each approach submitted is traced back to a sequence of problem cases that depend on the following three approaches."}, {"heading": "4.2 Number of training instances required in practice", "text": "In this section, we examine how the number of available training instances affects the quality of a plan calculated using these training instances. To do this, we chose the following procedure: In view of a series of n instances, we randomly select m < n training instances and then use the greedy algorithm from \u00a7 2.1 to calculate a roughly optimal plan principle for the training instances. Using this plan principle, we solve each of the 3In all solution contests, the number of heuristics was large enough that the calculation of an optimal plan using dynamic programming was impractical. n \u2212 m remaining instances and capture the average CPU time required for this. We examined all m values that were potencies of 2 less than n. For each m value, we repeated the experiment 100 times and obtained the results. PB '07, opt. small integersFigure 2 shows the results for optimization problems from the \"small integer\" B \"competition."}, {"heading": "4.3 Exploiting features", "text": "We will now examine the usefulness of using Boolean characteristics to decide what timetable we will use to solve a particular problem instance. We will present the results for two instance sets: the random category of the SAT 2007 competition and the optimal planning track of IPC-5. For the SAT instances, we will designate each instance with Boolean characteristics based on the size of the formula, the ratio of clauses to variables and the number of letters per clause. For the planning instances, we will use characteristics based on the planning domain, the number of targets, and the number of predicates in the initial conditions. To evaluate the effect of the characteristics, we will use a procedure similar to that used in the experiments summarized in Figure 2. In the light of a data set, we will randomly test training instances and examine how average performance (on test instances) varies as a function of m. For each value of m, we will repeat the experiment 100 times and average the results."}, {"heading": "5 Combining Anytime Algorithms", "text": "In this case, we want to construct a timetable that delivers almost optimal solutions, in addition to the proven optimal solutions. An easy way to do this is as follows. Let's define for each instance a set of objectives to be achieved (e.g., finding a solution with the most time points that are optimal, in addition to the proven optimal solutions); let's define for each instance a set of objectives to be achieved (e.g., finding a solution with the most time points that are optimal to stand up for each instance, 1,5, 1,01)."}, {"heading": "6 Related Work", "text": "Previous work on the design of algorithm portfolios has almost always focused on a single aspect of the problem. In particular, almost all previous theoretical work has focused on the timing aspect of the problem, while much of the experimental work has focused on the aspect of machine learning the problem. We will now discuss earlier work on each of these two aspects of the problem in more detail."}, {"heading": "6.1 Scheduling approaches", "text": "The earliest work on this problem measures the performance of a schedule in terms of its competitiveness (i.e. the time required to solve a particular problem using the schedule divided by the time required by the optimal schedule for that instance).The results of this work include the universal schedule for restarting Luby et al. [11] and the schedule of Kao et al. [9] for mapping time between multiple deterministic algorithms subject to memory limitations. Subsequent work focused on developing schedules tailored to a specific class of problems. Gomes et al. [7] demonstrated that (at the time) state-of-the-art heuristics for Boolean satisfaction and satisfaction limitation could be dramatically improved by not presenting heuristics and randomized heuristics with a suitable restart4We."}, {"heading": "6.2 Machine learning approaches", "text": "Another approach to designing algorithm portfolios is to use instances characteristics to predict which algorithm will execute the fastest in a given instance, and then simply execute that algorithm exclusively. As an example of this approach, Leyton-Brown et al. [10] use the least squares regression to estimate the runtime of each algorithm based on rapidly calculable instance characteristics, and then execute the algorithm with the smallest predicted runtime. Xu et al. [18] presented an improved version of this approach, using a two-step prediction scheme in which the response to a decision problem is predicted using a binary classifier, and the runtimes are then estimated based on the classifier's prediction."}, {"heading": "6.3 Integrated approaches", "text": "In addition to the work just described, there are previous papers that deal with both the planning and machine learning aspects of the algorithm portfolio problem at the same time. For example, Gagliolo and Schmidhuber [4] have presented an approach to allocating CPU time among heuristics in an online environment based on statistical models of heuristic behavior. Although their approach does not offer rigorous performance guarantees and would not perform well in the worst-case online environment considered in this paper, it would be interesting to compare their approach to ours experimentally."}, {"heading": "7 Conclusions", "text": "Our main experimental results can be summarized as follows: 1. In a number of well-studied problem areas, existing state-of-the-art heuristics can be combined into new and faster heuristics by simply collecting a few dozen training instances and using them to calculate a timetable for executing existing heuristics. 2. Advanced algorithms for solving optimization problems can be combined into an algorithm with better performance at any time via a timetable. 3. Instance-specific features can be used to create an individual timetable for a particular problem, and using this approach can lead to better performance than either a pure schedule approach or a purely function-based approach. As proposed in \u00a7 1, our experimental results could potentially be improved in at least two ways. First, we could try to predict the remaining problems based on the current timetable."}, {"heading": "Acknowledgements", "text": "Many thanks to Avrim Blum for proposing to use a sleeping expert algorithm in our problem. This research was partially supported by DARPA under contract number FA8750-05-C-0033 and by the CMU Robotics Institute."}], "references": [{"title": "Generic ILP versus specialized 0-1 ILP: An update", "author": ["Fadi A. Aloul", "Arathi Ramani", "Igor L. Markov", "Karem A. Sakallah"], "venue": "In ICCAD,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "From external to internal regret", "author": ["Avrim Blum", "Yishay Mansour"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Approximating min sum set", "author": ["Uriel Feige", "L\u00e1szl\u00f3 Lov\u00e1sz", "Prasad Tetali"], "venue": "cover. Algorithmica,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Dynamic algorithm portfolios", "author": ["Matteo Gagliolo", "J\u00fcrgen Schmidhuber"], "venue": "In AIMATH,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Algorithm portfolio design: Theory vs. practice", "author": ["Carla P. Gomes", "Bart Selman"], "venue": "In UAI,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1997}, {"title": "Boosting combinatorial search through randomization", "author": ["Carla P. Gomes", "Bart Selman", "Henry Kautz"], "venue": "In AAAI,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1998}, {"title": "An economics approach to hard computational problems", "author": ["Bernardo A. Huberman", "Rajan M. Lukose", "Tad Hogg"], "venue": "Science, 275:51\u201354,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "Optimal constructions of hybrid algorithms", "author": ["Ming-Yang Kao", "Yuan Ma", "Michael Sipser", "Yiqun Yin"], "venue": "In SODA,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "Boosting as a metaphor for algorithm design", "author": ["Kevin Leyton-Brown", "Eugene Nudelman", "Galen Andrew", "James McFadden", "Yoav Shoham"], "venue": "In CP,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Optimal speedup of Las Vegas algorithms", "author": ["Michael Luby", "Alistair Sinclair", "David Zuckerman"], "venue": "Information Processing Letters,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1993}, {"title": "Learning parallel portfolios of algorithms", "author": ["Marek Petrik", "Shlomo Zilberstein"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Combining multiple heuristics", "author": ["Tzur Sayag", "Shai Fine", "Yishay Mansour"], "venue": "In STACS, pages 242\u2013253,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Using Online Algorithms to Solve NP-Hard Problems More Efficiently in Practice", "author": ["Matthew Streeter"], "venue": "PhD thesis,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "An online algorithm for maximizing submodular functions", "author": ["Matthew Streeter", "Daniel Golovin"], "venue": "Technical Report CMU-CS-07-171,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Combining multiple heuristics online", "author": ["Matthew Streeter", "Daniel Golovin", "Stephen F. Smith"], "venue": "In AAAI,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Restart schedules for ensembles of problem instances", "author": ["Matthew Streeter", "Daniel Golovin", "Stephen F. Smith"], "venue": "In AAAI,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "SATzilla07: The design and analysis of an algorithm portfolio for SAT", "author": ["Lin Xu", "Frank Hutter", "Holger H. Hoos", "Kevin Leyton-Brown"], "venue": "In CP,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}], "referenceMentions": [{"referenceID": 4, "context": "We refer to the general problem of determining how to solve a problem instance in this setting as algorithm portfolio design [5, 6].", "startOffset": 125, "endOffset": 131}, {"referenceID": 6, "context": ", [6, 8, 10]) has largely addressed one of the two aspects in isolation (we discuss previous work in detail in \u00a76).", "startOffset": 2, "endOffset": 12}, {"referenceID": 8, "context": ", [6, 8, 10]) has largely addressed one of the two aspects in isolation (we discuss previous work in detail in \u00a76).", "startOffset": 2, "endOffset": 12}, {"referenceID": 9, "context": "This class of schedules is quite flexible, and includes restart-schedules [11] and task-switching schedules [13] as special cases.", "startOffset": 74, "endOffset": 78}, {"referenceID": 11, "context": "This class of schedules is quite flexible, and includes restart-schedules [11] and task-switching schedules [13] as special cases.", "startOffset": 108, "endOffset": 112}, {"referenceID": 2, "context": "Building on previous work on the Min-Sum Set Cover problem [3], Streeter et al.", "startOffset": 59, "endOffset": 62}, {"referenceID": 14, "context": "[16, 17] developed a greedy approximation algorithm for this offline problem.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[16, 17] developed a greedy approximation algorithm for this offline problem.", "startOffset": 0, "endOffset": 8}, {"referenceID": 13, "context": "Recently, Streeter and Golovin [15] developed an online algorithm for an abstract scheduling problem that includes this online problem as a special case.", "startOffset": 31, "endOffset": 35}, {"referenceID": 13, "context": "For the results of [15] to apply, we must make some additional assumptions.", "startOffset": 19, "endOffset": 23}, {"referenceID": 13, "context": "The algorithm presented in [15] is called OG, for \u201conline greedy\u201d, and can be viewed as an online version of the greedy approximation algorithm described in \u00a72.", "startOffset": 27, "endOffset": 31}, {"referenceID": 12, "context": "For more details, see [14].", "startOffset": 22, "endOffset": 26}, {"referenceID": 13, "context": "Algorithm OG [15], run with exploration probability \u03b3 =", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "Following the advice of expert j on day i incurs a loss `j \u2208 [0, 1].", "startOffset": 61, "endOffset": 67}, {"referenceID": 13, "context": "Due to space constraints, the pseudo-code refers to [15, 17]", "startOffset": 52, "endOffset": 60}, {"referenceID": 15, "context": "Due to space constraints, the pseudo-code refers to [15, 17]", "startOffset": 52, "endOffset": 60}, {"referenceID": 1, "context": "See [2] for a description of such an algorithm.", "startOffset": 4, "endOffset": 7}, {"referenceID": 1, "context": "Initialization: let E be a copy of the sleeping experts algorithm of [2]; and for each feature j, let Aj be a copy of OG [15].", "startOffset": 69, "endOffset": 72}, {"referenceID": 13, "context": "Initialization: let E be a copy of the sleeping experts algorithm of [2]; and for each feature j, let Aj be a copy of OG [15].", "startOffset": 121, "endOffset": 125}, {"referenceID": 15, "context": "Using the procedure of [17], run each heuristic for time O (B logB) in order to obtain a function f\u0302 such that for any schedule S, E [ f\u0302(S) ] =", "startOffset": 23, "endOffset": 27}, {"referenceID": 13, "context": "Feed f\u0302 back to each Aj , as described in [15].", "startOffset": 42, "endOffset": 46}, {"referenceID": 0, "context": "On many benchmarks, pseudo-Boolean optimizers (which are usually based on SAT solvers) outperform general integer programming packages such as CPLEX [1].", "startOffset": 149, "endOffset": 152}, {"referenceID": 14, "context": ", [16]) gave learningtheoretic bounds on the number of training instances required to learn a near-optimal schedule; however, these worst-case upper bounds are quite pessimistic relative to our experimental results.", "startOffset": 2, "endOffset": 6}, {"referenceID": 1, "context": "The second approach, which we refer to as \u201cFeatures only\u201d below, is similar except that it uses the sleeping experts algorithm of [2] to select a single heuristic (rather than a schedule), and runs that heuristic until it obtains a solution.", "startOffset": 130, "endOffset": 133}, {"referenceID": 9, "context": "[11] and the schedule of Kao et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[9] for allocating time among multiple deterministic algorithms subject to memory constraints.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] demonstrated that (then) state-of-the-art heuristics for Boolean satisfiability and constraint satisfaction could be dramatically improved by randomizing the heuristic\u2019s decision-making heuristics and running the randomized heuristic with an appropriate restart", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8] and Gomes et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "Independently, Petrik and Zilberstein [12] and Sayag et al.", "startOffset": 38, "endOffset": 42}, {"referenceID": 11, "context": "[13] addressed this problem for two classes of schedules: taskswitching schedules and resource-sharing schedules.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] presented a polynomial-time 4 approximation algorithm for computing task-switching schedules, as reviewed in \u00a72.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[10] use least squares regression to estimate the running time of each algorithm based on quickly-computable instance features, and then run the algorithm with the smallest predicted running time.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] presented an improved version of this approach that used a two-step prediction scheme in which the answer to a decision problem is predicted using a binary classifier, and run times are then estimated conditioned on the classifier\u2019s prediction.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "For example, Gagliolo and Schmidhuber [4] presented an approach for allocating CPU time among heuristics in an online setting, based on statistical models of the behavior of the heuristics.", "startOffset": 38, "endOffset": 41}], "year": 2008, "abstractText": "We present and evaluate new techniques for designing algorithm portfolios. In our view, the problem has both a scheduling aspect and a machine learning aspect. Prior work has largely addressed one of the two aspects in isolation. Building on recent work on the scheduling aspect of the problem, we present a technique that addresses both aspects simultaneously and has attractive theoretical guarantees. Experimentally, we show that this technique can be used to improve the performance of state-of-the-art algorithms for Boolean satisfiability, zero-one integer programming, and A.I. planning.", "creator": "LaTeX with hyperref package"}}}