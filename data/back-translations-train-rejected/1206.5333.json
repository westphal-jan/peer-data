{"id": "1206.5333", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jun-2012", "title": "TempEval-3: Evaluating Events, Time Expressions, and Temporal Relations", "abstract": "We describe the TempEval-3 task which is currently in preparation for the SemEval-2013 evaluation exercise. The aim of TempEval is to advance research on temporal information processing. TempEval-3 follows on from previous TempEval events, incorporating: a three-part task structure covering event, temporal expression and temporal relation extraction; a larger dataset; and single overall task quality scores.", "histories": [["v1", "Fri, 22 Jun 2012 22:30:44 GMT  (12kb)", "https://arxiv.org/abs/1206.5333v1", null], ["v2", "Sun, 25 May 2014 19:10:12 GMT  (12kb)", "http://arxiv.org/abs/1206.5333v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["naushad uzzaman", "hector llorens", "james allen", "leon derczynski", "marc verhagen", "james pustejovsky"], "accepted": false, "id": "1206.5333"}, "pdf": {"name": "1206.5333.pdf", "metadata": {"source": "CRF", "title": "TempEval-3: Evaluating Events, Time Expressions, and Temporal Relations", "authors": ["Naushad UzZaman", "Hector Llorens", "James Allen", "Leon Derczynski", "Marc Verhagen", "James Pustejovsky"], "emails": ["naushad@cs.rochester.edu", "james@cs.rochester.edu", "hllorens@dlsi.ua.es", "leon@dcs.shef.ac.uk", "jamesp@cs.brandeis.edu", "marc@cs.brandeis.edu"], "sections": [{"heading": null, "text": "ar Xiv: 120 6.53 33v2 [cs.CIn this proposal, we describe the upcoming TempEval 3 task, which is currently in preparation for the SemEval 2013 evaluation exercise. TempEval's goal is to advance research on time information processing. TempEval-3 builds on earlier TempEval events and includes: a three-part task structure covering event, time expression and time relation extraction; a larger dataset; and the evaluation of the overall quality of individual tasks."}, {"heading": "1 Introduction", "text": "The TempEval task has been added as a new task in SemEval-2007 (Verhagen et al., 2009), with the emphasis on the identification of temporal relations; the automatic identification of all temporal references, events and temporal relations within a text is the ultimate goal of research in this area; the area is too broad to be addressed fully in a first evaluation challenge, and instead a staged approach has been chosen. TempEval (henceforth TempEval-1) was an initial evaluation exercise based on three defined tasks (the links between: events and time periods in the same sentence; events and documentation time DCT; major events in successive sentences), which were considered realistic both from the perspective of assembling resources for development and testing as well as from the perspective of developing systems capable of tackling the tasks. TempEval-2 (Verhagen et al., 2010) is an extended-time task based on a multi-lingual and three-task."}, {"heading": "2 TempEval changes", "text": "As suggested, TempEval-3 is a follow-up to TempEval-1 and 2. TempEval-3 differs from its ancestors in the following ways: (i) size of the corpus: The data set used includes about 500K tokens of silver standard data and about 100K tokens of gold standard data for education, compared to the corpus of about 50K tokens corpus used in TempEval 1 and 2; (iii) time relation task: The temporal relation tasks must be performed from raw text, i.e. participants must first extract events and temporal expressions to determine which ones should be linked and then obtain the relation types; (iii) tasks not independently: Participants must comment on temporal expressions and events to complete the relation task; (iv) time relation types: The complete set of temporal interval relationships in TimeML (Pusteal was used in 2005, instead of Esteal used in earlier systems)."}, {"heading": "3 Tasks", "text": "The tasks proposed for TempEval-3 are:"}, {"heading": "3.1 Task A: Temporal expression extraction and normalization", "text": "Specify the range of time expressions in a text as defined by the TimeML TIMEX3 tag. In addition, specify the value of the TYPE and VAL properties. The possible values of TYPE are time, date, duration and set; the value of VAL is a normalized value as defined by the TIMEX3 standard."}, {"heading": "3.2 Task B: Event extraction", "text": "As in TempEval-2, participants determine the magnitude of the events in a text defined by the TimeML EVENT tag. In addition, systems can determine the value of the features CLASS, TENSE, ASPECT, POLARITY, MODALITY and also recognize whether the event is a major event or not."}, {"heading": "3.3 Task C: Annotating temporal relations", "text": "Identify the pairs of temporal entities (events or temporal expressions) that have a temporal connection and classify the temporal relationship between them as TLINK. Possible pairs of entities that can have a temporal connection are: (i) event and temporal expressions in the same sentence, (ii) event and document creation time, (iii) major events of consecutive sentences, and (iv) event pairs in the same sentence. For this task, we now require that the participating systems determine which entities need to be linked. Relationship names will be the same as in TimeML, i.e.: before, after, include, enclose, while, simultaneously, immediately after, immediately before, identity begins, ends, begins and ends."}, {"heading": "3.4 Task selection", "text": "Participants can choose whether to complete Paper A, B or C. Selection of Paper C (relation annotation) includes Papers A and B. However, a participant may only complete Paper C by using existing tools to perform Papers A and B. This is the TempEval 3 proposal, not the main lecture included in the SemEval 2013 Proceedings."}, {"heading": "4 Dataset creation", "text": "In TempEval-3 we publish new data as well as a significant review and modification of existing corpora."}, {"heading": "4.1 Reviewing Existing Corpora", "text": "We consider the existing TimeBank (Pustejovsky et al., 2003), TempEval = > Aspect = > PASS = > PASS-2 and AQUAINT1 data for review in TempEval-3. TimeBank v1.2, TempEval-1 and TempEval-2 had the same documents but different relationship types and sometimes different sets of events & & & & & < MASS, \"so TimeML schema ltltltltltT.\" < MASS, \"so TimeBank-1.\" & ltS, \"so TimeMASS.,\" so. \"& ltS,\" so TimeBank \"& ltS,\" so TimeS, \"so TimeS,\" so TimeBank, \"so TimeBank.,\" so. & ltS, \"so.,\" so. & ltS., \"so,\" so. & ltS., \"so. & ltS.,\" so. & ltS., \"so,\" so. & ltS, \"so. & ltS.,\" so. & ltS., \"so,\" so. & ltS, \"so. & ltS,\" so. & lt; so, \"so. & lt; so,\" so, \"so. & ltS,\" so, so. & ltS., \"so. & ltS, so. & ltS, so. & ltS., so. & ltS., so. & ltS., so. & ltS, so. & ltS., so. & ltS, so. & ltS. & ltS., so. & ltS, so. & ltS, so. & ltS, so. & ltS, so. & ltS., so. & ltS, so., so. & ltS., so. & ltS., so., so. & ltS. & ltS, so. & so., so. & so. & ltS. & so. & ltS, so., so. & so., so. & so. & so. & so. & so., so., so. & ltS. & so. & so., so. & so"}, {"heading": "4.2 Automatically Creating New Large Corpora", "text": "Much of the TempEval 3 data is automatically generated using a temporal merge system. We collected half a million token text corpus from Gigaword2. These systems were automatically commented on with TIPSem, TIPSem-B (Llorens et al., 2010) and TRIOS (UzZaman and Allen, 2010), which were retrained on TimeBank and the AQUAINT corpus using the TimeML time relationship set. We then merged these three state-of-the-art system editions using our merge algorithm (UzZaman et al., 2012). In our merge configuration, all units and relationships suggested by the best system (TIPSem) are added to the merge output."}, {"heading": "5 Evaluation", "text": "Assessment of Papers A and B will be a standard F score (including precision and recall metrics) in terms of extent and F score / kappa in terms of attributes of response extensions that overlap with key dimensions. Assessment of Paper C will be taken over by our proposed graph-based assessment metric (see UzZaman and Allen (2011) for details).This metric uses a timeframe to reward relationship annotations that are equivalent but unambiguous, and then finds precision and retrieval. Our TempEval 3 Proposal is a combined measure of a system's performance 2http: / / www.ldc.upenn.edu / Catalog / catalogEntry.jsp? catalogId = LDC2011T07This is the TempEval 3 proposal, not the main document located in the SemEval 2013 Proceedings (i.e., a system that evaluates both time and expressions)."}, {"heading": "6 Conclusion", "text": "We have described the task, the data set and the evaluation style of TempEval-3. The event will be part of SemEval-2013. Training will begin in autumn 2012 and the evaluation period will end in January 2013. More information can be found on the task website3 and on the TempEval grouplist4."}], "references": [{"title": "TIPSem (English and Spanish): Evaluating CRFs and Semantic Roles in TempEval-2.", "author": ["H. Llorens", "E. Saquete", "B. Navarro"], "venue": "In Proceedings of the 5th International Workshop on Semantic Evaluation,", "citeRegEx": "Llorens et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Llorens et al\\.", "year": 2010}, {"title": "The TimeBank corpus.", "author": ["J. Pustejovsky", "P. Hanks", "R. Sauri", "A. See", "R. Gaizauskas", "A. Setzer", "D. Radev", "B. Sundheim", "D. Day", "L. Ferro"], "venue": "In Corpus Linguistics,", "citeRegEx": "Pustejovsky et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Pustejovsky et al\\.", "year": 2003}, {"title": "The specification language TimeML.", "author": ["J. Pustejovsky", "B. Ingria", "R. Sauri", "J. Castano", "J. Littman", "R. Gaizauskas", "A. Setzer", "G. Katz", "I. Mani"], "venue": "The Language of Time: A reader,", "citeRegEx": "Pustejovsky et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pustejovsky et al\\.", "year": 2005}, {"title": "TRIPS and TRIOS system for TempEval2: Extracting temporal information from text.", "author": ["N. UzZaman", "J.F"], "venue": "In Proceedings of the 5th International Workshop on Semantic Evaluation,", "citeRegEx": "UzZaman and J.F.,? \\Q2010\\E", "shortCiteRegEx": "UzZaman and J.F.", "year": 2010}, {"title": "Temporal Evaluation.", "author": ["N. UzZaman", "J.F"], "venue": null, "citeRegEx": "UzZaman and J.F.,? \\Q2011\\E", "shortCiteRegEx": "UzZaman and J.F.", "year": 2011}, {"title": "Merging Temporal Annotations.", "author": ["N. UzZaman", "H. Llorens", "J.F"], "venue": "In Proceedings of the TIME Conference", "citeRegEx": "UzZaman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "UzZaman et al\\.", "year": 2012}, {"title": "The TempEval challenge: identifying temporal relations in text.", "author": ["M. Verhagen", "R. Gaizauskas", "F. Schilder", "M. Hepple", "J. Moszkowicz", "J. Pustejovsky"], "venue": "Language Resources and Evaluation,", "citeRegEx": "Verhagen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Verhagen et al\\.", "year": 2009}, {"title": "SemEval-2010 task 13: TempEval-2.", "author": ["M. Verhagen", "R. Sauri", "T. Caselli", "J. Pustejovsky"], "venue": "In Proceedings of the 5th International Workshop on Semantic Evaluation,", "citeRegEx": "Verhagen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Verhagen et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 6, "context": "The TempEval task was added as a new task in SemEval-2007 (Verhagen et al., 2009), focusing on the identification of temporal relations.", "startOffset": 58, "endOffset": 81}, {"referenceID": 7, "context": "TempEval-2 (Verhagen et al., 2010) extended TempEval-1, growing into a multilingual task, and consisting of six subtasks rather than three.", "startOffset": 11, "endOffset": 34}, {"referenceID": 2, "context": "(iv) temporal relation types: the full set of temporal interval relations in TimeML (Pustejovsky et al., 2005) is used, rather than the reduced set used in earlier TempEvals;", "startOffset": 84, "endOffset": 110}, {"referenceID": 1, "context": "1 Reviewing Existing Corpora We considered the existing TimeBank (Pustejovsky et al., 2003), TempEval-1, TempEval-2 and AQUAINT data for review in TempEval-3.", "startOffset": 65, "endOffset": 91}, {"referenceID": 0, "context": "We automatically annotated this corpus using TIPSem, TIPSem-B (Llorens et al., 2010) and TRIOS (UzZaman and Allen, 2010).", "startOffset": 62, "endOffset": 84}, {"referenceID": 5, "context": "We then merged these three state-of-the-art system outputs using our merging algorithm (UzZaman et al., 2012).", "startOffset": 87, "endOffset": 109}], "year": 2014, "abstractText": "In this proposal, we describe the forthcoming TempEval-3 task which is currently in preparation for the SemEval-2013 evaluation exercise. The aim of TempEval is to advance research on temporal information processing. TempEval-3 follows on from previous TempEval events, incorporating: a three-part task structure covering event, temporal expression and temporal relation extraction; a larger dataset; and single overall task quality scores.", "creator": "LaTeX with hyperref package"}}}