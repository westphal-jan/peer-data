{"id": "1206.6827", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Linear Algebra Approach to Separable Bayesian Networks", "abstract": "Separable Bayesian Networks, or the Influence Model, are dynamic Bayesian Networks in which the conditional probability distribution can be separated into a function of only the marginal distribution of a node's neighbors, instead of the joint distributions. In terms of modeling, separable networks has rendered possible siginificant reduction in complexity, as the state space is only linear in the number of variables on the network, in contrast to a typical state space which is exponential. In this work, We describe the connection between an arbitrary Conditional Probability Table (CPT) and separable systems using linear algebra. We give an alternate proof on the equivalence of sufficiency and separability. We present a computational method for testing whether a given CPT is separable.", "histories": [["v1", "Wed, 27 Jun 2012 15:41:47 GMT  (127kb)", "http://arxiv.org/abs/1206.6827v1", "Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["chalee asavathiratham"], "accepted": false, "id": "1206.6827"}, "pdf": {"name": "1206.6827.pdf", "metadata": {"source": "CRF", "title": "Linear Algebra Approach to Separable Bayesian Networks", "authors": ["Chalee Asavathiratham"], "emails": ["chalee@alum.mit.edu"], "sections": [{"heading": null, "text": "Separable Bayesian Networks or the Influence Model are dynamic Bayesian Networks in which the conditional probability distribution can be divided into a function of only the marginal distribution of the parents of a node, rather than the common distributions. We describe the connection between any conditional probability table (CPT) and divisible systems using linear algebra. We give [Pfeffer00] an alternative proof of the equivalence of sufficiency and separability. We present a calculation method to test whether a given CPT is separable."}, {"heading": "1 Introduction", "text": "Separable Bayesian Networks or the Influence Model are dynamic Bayesian Networks in which the conditional probability distribution can be divided into a function of only the marginal distribution of the neighbors of a node, rather than the common distributions. In terms of modeling, divisible networks have allowed for a significant reduction in complexity, since the state space is only linear in the number of variables in the network, as opposed to a typical state space that is exponential. We describe the connection between any conditional probability table (CPT) and divisible systems using linear algebra. We give [Pfeffer00] an alternative proof of the equivalence of sufficiency and separability. We present a calculation method to test whether a given CPT is separable."}, {"heading": "2 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Probability Mass Functions", "text": "Suppose X, Y, and Z are three random variables and let the size of their sample spaces be some finite integers mx, my, and my, respectively. Similar to [Pfeffer00], we designate the space of probability mass functions (PMF) over the common random variable (X, Y) as \"XY,\" i.e. \"XY\" = \"q\" = \"q\" Rmxmy | q \"\u2265 0,\" q \"1mxmy = 1,\" where \"1mxmy\" is the complete column vector of length (mxmy), and \"q\" 0 \"means that each entry of the column vector q is not negative. If there is no ambiguity, we drop the subscript from 1."}, {"heading": "2.2 Event Matrix", "text": "Let ei = [0 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 0] is the vector in which the single 1 entry appears in the position. For random variable X, we can represent its result as ei-Rmx. Stacking these vectors into a matrix, we get the event matrix BX - in this case, the mx identity matrix appears. If the matrix is a random variable, then the matrix of the event matrix BX is the vector in which the single 1 entry appears in the position."}, {"heading": "2.3 Sufficiency", "text": "For a given conditional PMF P (Z | XY), we leave CP (Z | XY) = q q q q q q (or simply C) its conditional probability table (CPT). That is, C is a (mxmy) -by-mz matrix, so that each row of C corresponds to a result of (X, Y) sorted in the order defined by B. It then follows that C has nonnegative entries and C1mz = 1mxmy. In [Pepper00], the function P: XY \u2192 Z is defined as absolute equality (q) = q (X, Y). It then follows that C has nonnegative entries and C1mz = 1mxmy."}, {"heading": "2.4 Separability", "text": "First, we would expand the definition of separability in the order O (mxmymz + mzzzm) of my reduction by a multiple, as expressed in [Pfeffer00].Definition 2 P (Z | XY). (Z | XY) is separable if there are condition distributions PX (Z | X). (Z | XY) is separable if there is a condition for reducing complexity. To see this, for example, we must list the task of listing P (Z | XY) for all possible values of X, Y and Z. In general, we need a table whose number of entries is in the order O (mxmymz). By separability, we must list the conditional probabilities P (Z | X) and P (Z | Y) separately and calculate P (Z | XY) as needed, which would result in a table in the order O (mzmzmzmzm)."}, {"heading": "2.5 Extension to Multiple Variables", "text": "The above results can be extended to the multiple case, as P (Z | X1 \u00b7 Xn) = 11... Let's m1,.. mn the size of the sample spaces of X1,.., Xn respectively. We construct a sequence of matrices {Bi} from i = 1 to i = n by a recursive procedure as follows: B1 = Im1Bi = [Bi \u2212 1 1 1 1 Imi] (11) in which the matrices of i = 1 mj. The event matrix and, is shown by B = 1 2. Some properties of B are rerepresented for the general case.Theorem 6 For 1 \u2264 i \u2264 n (Bi) = (i k = 1 mk) \u2212 i + 1Proof: See theorem 5.8 in [Asavathiratham00].Theorem 7N (B) = {v"}, {"heading": "2.6 Test for Separability", "text": "Given a CPT matrix C, we can test whether it is separable by simply checking that it is located in the subspace of B. One way to do this is to test whether the orthogonal projection C on R (B) is self-compatible. If C-R (B), then the projection would be only the least square approximation. To achieve this, we would need a basis for R (B). Unfortunately, B itself does not have a complete column rank2For example, a large algorithm according to Theorem 6 would work and therefore cannot be used directly to create an orthogonal projection."}, {"heading": "2.7 Connection to the Influence Model", "text": "The influence model was first introduced in [Asavathiratham00] and briefly described in [Asavathiratham01]. Originally intended to be cascads3Can we find another basis that is both orthonormal and recursive? Phenomena in power systems, the model was applied in applications such as social interaction, viral marketing networks, information diffusion, and distributed control. Remember that an influence model is defined by an n-by-n stochastic matrix D, called the influence matrix, and a set of matrices {Aij} for all i, j = 1,., n such that each Aij \u2265 0 and Aij1 = 1. Each location i (node i) at a time k has a status represented by si [k] = [0 \u00b7 1 \u00b7 \u00b7 0]."}, {"heading": "3 Open Issues", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Approximating General DBN with a Separable System", "text": "So far, we have focused only on the CPT of a given variable Z, but the idea can be extended to a network of random variables. That is, if we get a Bayesian Dynamic Network in which each node has any CPT based on the common distribution of its neighbors (possibly even itself), we can approach it with a divisible version, so what would be the optimal way to achieve this? One possible approach is to work with the CPT of each node separately, that is, to approach the CPT table of each node with a divisible version that is optimal in a certain sense. Once we have a divisible CPT, we can factorize it into smaller CPT tables according to (12). What should be the optimality criterion in the approximation? Although P (C) is optimal in the smallest quadratic sense, i.e. P (C) = arg X (B) (function) could be approximate to X | 2 | C (although the distance between the other might be similar to 18 | C)."}, {"heading": "3.2 Learning and Inference on Separable Systems", "text": "Since the number of parameters for such systems is usually much smaller than for a general DBN, learning parameters should require much less data and behave much more stable; this advantage was the key to the application described in [Basu01]. For a general DBN, the task of updating the rear distribution still requires an exponential calculation of the number of variables in the system, e.g. the forward-backward algorithm. Given that dividable BNs are defined in such a way that the boundary distributions are sufficient to predict themselves in the future, it seems plausible that there is any method for the reduced-calculation sequence tasks."}, {"heading": "Acknowledgements", "text": "The author thanks Prof. Benjamin Van Roy (Stanford), Prof. George C. Verghese (MIT) and Prof. Sandip Roy (Washington State) for many helpful conversations."}], "references": [{"title": "Influence Model: A Tractable Representations for the Dynamics of Networked Markov Chains, Ph.D", "author": ["C. Asavathiratham"], "venue": null, "citeRegEx": "Asavathiratham.,? \\Q2000\\E", "shortCiteRegEx": "Asavathiratham.", "year": 2000}, {"title": "The Influence Model, IEEE Control Systems", "author": ["C. Asavathiratham", "S. Roy", "B.C. Lesieutre", "G.C. Verghese"], "venue": null, "citeRegEx": "Asavathiratham et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Asavathiratham et al\\.", "year": 2001}, {"title": "Towards Measuring Human Interactions in Conversational Settings", "author": ["S. Basu", "T. Choudhury", "B. Clarkson", "A. Pentland"], "venue": "Proceedings of the IEEE Int\u2019l Workshop on Cues in Communication (CUES", "citeRegEx": "Basu et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Basu et al\\.", "year": 2001}, {"title": "Sufficiency, Separability, and Temporal Probabilistic Models. Uncertainty in Artificial Intelligence", "author": ["A. Pfeffer"], "venue": null, "citeRegEx": "Pfeffer,? \\Q2001\\E", "shortCiteRegEx": "Pfeffer", "year": 2001}], "referenceMentions": [], "year": 2006, "abstractText": "Separable Bayesian Networks, or the Influence Model, are dynamic Bayesian Networks in which the conditional probability distribution can be separated into a function of only the marginal distribution of a node\u2019s parents, instead of the joint distributions. We describe the connection between an arbitrary Conditional Probability Table (CPT) and separable systems using linear algebra. We give an alternate proof to [Pfeffer00] on the equivalence of sufficiency and separability. We present a computational method for testing whether a given CPT is separable.", "creator": "dvips(k) 5.94a Copyright 2003 Radical Eye Software"}}}