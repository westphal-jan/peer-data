{"id": "1206.6854", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Belief Update in CLG Bayesian Networks With Lazy Propagation", "abstract": "In recent years Bayesian networks (BNs) with a mixture of continuous and discrete variables have received an increasing level of attention. We present an architecture for exact belief update in Conditional Linear Gaussian BNs (CLG BNs). The architecture is an extension of lazy propagation using operations of Lauritzen &amp; Jensen [6] and Cowell [2]. By decomposing clique and separator potentials into sets of factors, the proposed architecture takes advantage of independence and irrelevance properties induced by the structure of the graph and the evidence. The resulting benefits are illustrated by examples. Results of a preliminary empirical performance evaluation indicate a significant potential of the proposed architecture.", "histories": [["v1", "Wed, 27 Jun 2012 16:25:42 GMT  (153kb)", "http://arxiv.org/abs/1206.6854v1", "Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["anders l madsen"], "accepted": false, "id": "1206.6854"}, "pdf": {"name": "1206.6854.pdf", "metadata": {"source": "CRF", "title": "Belief Update in CLG Bayesian Networks With Lazy Propagation", "authors": ["Anders L Madsen"], "emails": ["Anders.L.Madsen@hugin.com"], "sections": [{"heading": null, "text": "In recent years, Bayesian networks (BNs) with a mixture of continuous and discrete variables have gained increasing attention. We present an architecture for the exact actualization of beliefs in conditional linear Gaussian BNs (CLG BNs). The architecture is an extension of the rotten propagation by operations of Lauritzen & Jensen [6] and Cowell [2]. By breaking down clique and separation potentials into groups of factors, the proposed architecture exploits the properties of independence and irrelevance induced by the structure of the diagram and the evidence, the resulting benefits are illustrated by examples. Results of a preliminary empirical performance evaluation indicate a significant potential of the proposed architecture."}, {"heading": "1 INTRODUCTION", "text": "In this context, it should be noted that this is a very complex and complex matter."}, {"heading": "2 PRELIMINARIES AND NOTATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 CLG BAYESIAN NETWORK", "text": "A CLG BN = (X, G, P, F) via variable X consists of an acyclic directional graph (DAG) G = (V, E), a series of conditional probability distributions P = {P (X | \u03c0 (X)): X \u00b2) and a series of CLG density functions F = {f (Y | \u03c0 (Y): Y value is the set of discrete variables. The vertices V of G correspond one to one of the variables of X."}, {"heading": "2.2 THE EXCHANGE OPERATION", "text": "Leave Y, Z and Z1. The distribution of Y to Z1 is: Y and Z1. The distribution of Y is: Y and Z2. The distribution of Y to Z2. The distribution of Y is: Y and Z2. The distribution of Y to X2. The distribution of Y to X2. The distribution of Y is: Y and Z2. The distribution of Y to X2. The distribution of Y to X2. The distribution of Y is: Y and Z2. The distribution of Y is: Y and Z2. The distribution of Y to X2. The distribution of Y is: Y and Z2. The distribution of Y to X2."}, {"heading": "2.3 THE STRONG JUNCTION TREE", "text": "Faith updating is done by passing the message in a strong intersection tree T = (C, S) with cliques C, separator S and strong root R \u0441C. T has the property that for all adjacent cliques A and B with A is closer to R than B is S = A B or B\\ A B. Let A and B be adjacent cliques with A closer to R than B and so that S = A \u00b2 B is then designated as the parent clique of B (with B) and S as the parent clique of B (with B). A clique C \u00b2 C is designated as the border clique when C \u00b2 6 = \u2205 and either B \u00b2 or B \u00b2 is evidenced by evidence where B = C (C) is. Let bd (C) designate the group of border cliques."}, {"heading": "3 LAZY PROPAGATION", "text": "A node tree for a discrete BN is broad enough in construction to support the calculation of any rear marginal set taking into account any subset of evidence, but the node tree is often too broad to exploit the evidence-induced properties of independence. Lazy dissemination aims to exploit the independence and irrelevance properties induced by evidence in a Shenoy-Shafer transmission scheme [10]."}, {"heading": "3.1 POTENTIALS AND OPERATIONS", "text": "Definition 3.1 [Potential] A potential on W'X is a potential on W'W = (P, F), where P is a series of (discrete) probability potentials on subsets of W'W and F is a series of probability density functions on subsets of W'W. Elements of P are called factors and elements of F are called density functions (or density functions). Furthermore, we designate a potential as empty if it is the potential onW1 \"W2\" given by the potential W1 \"W2.\" The insignificant potential is called \u03c0. Definition 3.2 [Combination] The combination of two potentials \u03c0W1 = (P1, F1) and \u03c0W2 = (P2, F2) denotes the potential onW2. \"If W1\" \u03c0W2 \"(P1\" \u03c0W2, \"\u03c0W2 = (P2, F1\" F2) is the potential density of \"P2\" function. \"[Contraction] W on a contraction."}, {"heading": "3.2 INITIALIZATION", "text": "The first step in initializing T = (C, S) is to assign \u03c0 for each clique C = C. Next, for each clique we assign P (X | \u03c0 (X), to the clique C = (P, F) closest to R, so fa (X) C, where fa (X) = \u03c0 (X) \u00b2. Likewise, for each clique we assign a potential \u03c0C = (P, F). The contraction of the common potential \u03c0X to T = (C, S) is therefore: \u03c0X = (C, C\u03c0C = (X, X) \u00b2 for each clique C = (X, X) for each potential clique C = (Y, Y, Y) for each clique T = (Y, Y)."}, {"heading": "3.3 PROPAGATION", "text": "The distribution of information in T is done by message delivery using the separators S. The separator S = A = B between two adjacent cliques A and B stores the messages passed between A and B, see Figure 2. Messages are forwarded from leaf cliques to R by each clique A recursively passing a message to its parent clique B whenever A receives a message from each C-adj (A)\\ {B} (COLLECT). Messages are then forwarded in the opposite direction (DISTRIBUTE)."}, {"heading": "3.4 MESSAGES", "text": "Absorption from A to B involves the elimination of the variable A\\ B from the combination of the potential associated with A and the messages passed to A by each neighbor, with the exception of B. The message \u03c0A \u2192 B is calculated as follows: \u03c0A \u2192 B = (\u03c0A (C-adj (A)\\ {B} \u03c0C \u2192 A)) \u2193 B, where \u03c0C \u2192 A is the message passed from C to A and \u2193 is the projection based on exchange operations and barren variable distances."}, {"heading": "3.5 THE PUSH OPERATION", "text": "If the connecting tree is not wide enough to support a calculation, then the PUSH operation is used [6]. The boundary density of a variable Y function is generally a mixture of Gaussian distributions. To calculate the boundary mix of Y, it may be necessary to (temporarily) rearrange the contents of clicks and separators of T. The PUSH operation is applied to rearrange T in such a way that Y becomes part of a boundary clique. This is achieved by extending cliques and separators to Y and Y towards R. Suppose A is the clique closest to R, so that Y-A, A-6-bd (C), B-4-C (A), and S-4-S (A), the figure Y is eliminated in relation to variable S (until the variable S is excluded)."}, {"heading": "3.6 INSERTION OF CONTINUOUS EVIDENCE", "text": "Imagine, Y \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2, if at all, that is, I = \u03c0 (Y). The insertion of evidence that Y brings forth a factor p (y | I), so that p (y | I = i) = exp (\u2212 y \u2212 Y (i)) 2 / (2\u03c32 (i))) \u00b2 \u00b2, \u00b2 \u00b2 \u00b2 \u00b2, \u00b2 \u00b2 \u00b2 \u00b2, \u00b2 \u00b2 \u00b2 \u00b2, \u00b2 \u00b2 \u00b2, \u00b2 \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, \u00b2, and \u00b2, \u00b2, \u00b2, \u00b2."}, {"heading": "3.7 PROPAGATION OF CONTINUOUS EVIDENCE", "text": "In Section 3.3, the propagation scheme used in the propagation of messages from each C-adj (A)\\ {\u03c0C (A)} is described. Once each delimiting clique has received A-bd (C) messages from each C-adj (A)\\ {\u03c0C (A)}, continuous evidence is inserted by means of the PUSH operation. Let T = (C, S) be a strong representation of the intersection tree and allow the evidence for propagation. The evidence is propagated in T by performing the following sequence of steps: 1. Initialization including insertion of evidence. 2. Run a COLLECT operation on each A-bd (C) COLLECT of each B-adj (A)\\ {\u03c0C (A)}. 3. Insert evidence by using the PUSH operation. 4. Perform a COLLECT operation and a DISTRIBUTE operation on R. During the COLLET operation, only two clicks will run between the two clicks."}, {"heading": "3.8 POSTERIOR MARGINALS", "text": "The back limits P (X) for X (X) and P (X) can be calculated from any clique or delimiter containing X. (X) If X (X) C, then P (X) is calculated as: P (X), where C (PC, FC) is the clique potential for C (X). If S, on the other hand, is a delimiter containing X (X) and X (X), then P (X) is calculated as: P (X) for the reduction of C (X) and PCp, where C (PC, FC) is the clique potential for C. If S is a delimiter containing X (X), then P (X) is calculated for the reduction of C (X) and X (X) for the reduction of components Y."}, {"heading": "4 COMPARISON", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 COWELL", "text": "Cowell [2] presents a belief actualization algorithm in which message delivery takes place on an elimination tree rather than on a (strong) transition tree, creating a local propagation scheme in which all calculations are performed using continuous variables by manipulating univariate regressions (avoiding matrix operations), eliminating continuous variables using Exchange operations. The three main differences between the current propagation scheme and Cowell [2] are: use of a strong transition tree as opposed to an elimination tree, use of Exchange to eliminate both continuous and discrete variables, and a single round of message delivery."}, {"heading": "4.2 LAURITZEN AND JENSEN", "text": "A CG potential consists of a probability potential through discrete variables and a probability density function through continuous variables that depend on discrete variables; each clique and separator has a CG potential through their variables; this implies that complex matrix operations are required during faith updating; initialization plays an important role in the Lauritzen & Jensen [6] architecture; it produces a Lauritzen & Mirror Holder-like representation of crossing trees [7], where cliquepotentials are conditioned to the parent's continuous variables; this ensures that a variable Y structure is propagated only when there is evidence on Y or when the mix marginal structure is compressed to Y.In addition, a complex recursive combination operator may be required to combine Lauritzen potentials."}, {"heading": "4.3 MADSEN", "text": "The current architecture differs significantly from the architecture proposed by Madsen [9], which represents an extension of Madsen & Jensen [11] to the case of CLG BNs based on the distribution scheme of Lauritzen & Jensen [6], which implies a number of differences compared to the current scheme: firstly, the architecture is based exclusively on the operations of Lauritzen & Jensen [6], while the current scheme is based on the operations of Lauritzen & Jensen [6] and Cowell [2]; secondly, a Lauritzen & mirror-like representation of cross trees is achieved as a result of initialization, i.e. during the original COLLECT operation, the transmitter clique is conditioned on the continuous variables of the parent separator; and finally, in the current scheme, variable eliminations are performed through interchangeable operations and infertile variable distances."}, {"heading": "5 PERFORMANCE ANALYSIS", "text": "In fact, most of them will be able to feel as if they are able to survive on their own."}, {"heading": "6 CONCLUSION", "text": "The proposed architecture is based on enhanced versions of the operations introduced by Lauritzen & Jensen [6] and Cowell [2].Despite a significant difference in efficiency of the table operations, the proposed architecture is - in some cases - more efficient than a commercial implementation of the Lauritzen & Jensen [6] architecture.The results of the performance evaluation indicate a significant potential of the proposed architecture."}], "references": [{"title": "Symbolic probabilistic inference with both discrete and continuous  variables", "author": ["K.C. Chang", "R. Fung"], "venue": "IEEE Transactions on Systems, Man. and Cybernetics, 25(6):910\u2013916", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1995}, {"title": "Local Propagation In Conditional Gaussian Bayesian Networks", "author": ["R.G. Cowell"], "venue": "Journal of Machine Learning Research, 6:1517\u20131550", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Probabilistic Networks and Expert Systems", "author": ["R.G. Cowell", "A.P. Dawid", "S.L. Lauritzen", "D.J. Spiegelhalter"], "venue": "Springer-Verlag", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1999}, {"title": "Bayesian Networks and Decision Graphs", "author": ["F.V. Jensen"], "venue": "Springer-Verlag", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Propagation of probabilities", "author": ["S.L. Lauritzen"], "venue": "means and variances in mixed graphical association models. Journal of the American Statistical Association, 87(420):1098\u20131108", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1992}, {"title": "Stable Local Computation with Mixed Gaussian Distributions", "author": ["S.L. Lauritzen", "F. Jensen"], "venue": "Statistics and Computing, 11(2):191\u2013203", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Local computations with probabilities on graphical structures and their application to expert systems", "author": ["S.L. Lauritzen", "D.J. Spiegelhalter"], "venue": "Journal of the Royal Statistical Society, B., 50(2):157\u2013224", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1988}, {"title": "Graphical models for associations between variables", "author": ["S.L. Lauritzen", "N. Wermuth"], "venue": "some of which are qualitative and some quantitative. The Annals of Statistics, 17:31\u201357", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1989}, {"title": "All Good Things Come to Those Who Are Lazy - Efficient Inference in Bayesian Networks and Influence Diagrams Based on Lazy Evaluation", "author": ["A.L. Madsen"], "venue": "PhD thesis, Department of Computer Science, Aalborg University", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1999}, {"title": "Variations Over the Message Computation Algorithm of Lazy Propagation", "author": ["A.L. Madsen"], "venue": "IEEE Transactions on Systems, Man. and Cybernetics Part B", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Lazy propagation: A junction tree inference algorithm based on lazy evaluation", "author": ["A.L. Madsen", "F.V. Jensen"], "venue": "Artificial Intelligence, 113(1- 2):203\u2013245", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "Probabilistic Reasoning in Intelligence Systems", "author": ["J. Pearl"], "venue": "Morgan Kaufmann Publishers", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1988}, {"title": "B", "author": ["R. Shachter"], "venue": "D\u2019Ambrosio, and B. DelFavero. Symbolic probabilistic inference in belief networks. In Proceedings Eighth National Conference on AI, pages 126\u2013131", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1990}, {"title": "Gaussian influence diagrams", "author": ["R.D. Shachter", "C.R. Kenley"], "venue": "Management Science, 35(5):527\u2013 549", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1989}], "referenceMentions": [{"referenceID": 5, "context": "The architecture is an extension of lazy propagation using operations of Lauritzen & Jensen [6] and Cowell [2].", "startOffset": 92, "endOffset": 95}, {"referenceID": 1, "context": "The architecture is an extension of lazy propagation using operations of Lauritzen & Jensen [6] and Cowell [2].", "startOffset": 107, "endOffset": 110}, {"referenceID": 11, "context": "The framework of BNs is an efficient knowledge representation for reasoning under uncertainty [12, 3, 4].", "startOffset": 94, "endOffset": 104}, {"referenceID": 2, "context": "The framework of BNs is an efficient knowledge representation for reasoning under uncertainty [12, 3, 4].", "startOffset": 94, "endOffset": 104}, {"referenceID": 3, "context": "The framework of BNs is an efficient knowledge representation for reasoning under uncertainty [12, 3, 4].", "startOffset": 94, "endOffset": 104}, {"referenceID": 11, "context": "The work by Pearl [12] on BNs containing continuous variables imposed three constraints on the variables in the network.", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "Later, Shachter & Kenley [14] described how to solve Gaussian influence diagrams under similar constraints, but allowing multiple connected causal networks.", "startOffset": 25, "endOffset": 29}, {"referenceID": 4, "context": "Lauritzen [5] presents a scheme for modeling and exact belief update in CLG BNs.", "startOffset": 10, "endOffset": 13}, {"referenceID": 0, "context": "Using a similar approach Chang & Fung [1] extend the SPI algorithm [13] to solve arbitrary queries against CLG BNs.", "startOffset": 38, "endOffset": 41}, {"referenceID": 12, "context": "Using a similar approach Chang & Fung [1] extend the SPI algorithm [13] to solve arbitrary queries against CLG BNs.", "startOffset": 67, "endOffset": 71}, {"referenceID": 4, "context": "The Lauritzen [5] architecture is known to suffer from problems causing numerical instability.", "startOffset": 14, "endOffset": 17}, {"referenceID": 5, "context": "For this reason the architecture was later revised by Lauritzen & Jensen [6] in order to improve the numerical stability of belief update.", "startOffset": 73, "endOffset": 76}, {"referenceID": 1, "context": "Recently, Cowell [2] introduced an alternative architecture for belief update based on message passing in an elimination tree using the arcreversal operation of Shachter & Kenley [14] (referred to as the EXCHANGE operation).", "startOffset": 17, "endOffset": 20}, {"referenceID": 13, "context": "Recently, Cowell [2] introduced an alternative architecture for belief update based on message passing in an elimination tree using the arcreversal operation of Shachter & Kenley [14] (referred to as the EXCHANGE operation).", "startOffset": 179, "endOffset": 183}, {"referenceID": 9, "context": "The architecture is an extension of lazy propagation [10] based on operations introduced by Lauritzen & Jensen [6] and Cowell [2].", "startOffset": 53, "endOffset": 57}, {"referenceID": 5, "context": "The architecture is an extension of lazy propagation [10] based on operations introduced by Lauritzen & Jensen [6] and Cowell [2].", "startOffset": 111, "endOffset": 114}, {"referenceID": 1, "context": "The architecture is an extension of lazy propagation [10] based on operations introduced by Lauritzen & Jensen [6] and Cowell [2].", "startOffset": 126, "endOffset": 129}, {"referenceID": 5, "context": "Posterior marginal distributions are computed using EXCHANGE and PUSH [6] operations.", "startOffset": 70, "endOffset": 73}, {"referenceID": 5, "context": "number of randomly generated CLG BNs with the performance of the Lauritzen & Jensen [6] architecture as implemented in the HUGIN Decision Engine, i.", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "It converts the above pair of distributions such that Y becomes a parent of Z in the domain graph spanned by the two distributions maintaining the same joint probability density function of the original pair [2].", "startOffset": 208, "endOffset": 211}, {"referenceID": 1, "context": "while the distribution of Z is (Cowell [2] considers three different cases depending on the values of \u03c32Y and \u03c32Z that are mathematical limits of this case):", "startOffset": 39, "endOffset": 42}, {"referenceID": 9, "context": "Lazy propagation aims at taking advantage of independence and irrelevance properties induced by evidence in a Shenoy-Shafer message passing scheme [10].", "startOffset": 147, "endOffset": 151}, {"referenceID": 5, "context": "This is contrary to both the Lauritzen & Jensen [6] and Cowell [2] architectures where each clique has a probability potential over all discrete variables in the clique.", "startOffset": 48, "endOffset": 51}, {"referenceID": 1, "context": "This is contrary to both the Lauritzen & Jensen [6] and Cowell [2] architectures where each clique has a probability potential over all discrete variables in the clique.", "startOffset": 63, "endOffset": 66}, {"referenceID": 5, "context": "If the junction tree is not wide-enough to support a calculation, then the PUSH operation is used [6].", "startOffset": 98, "endOffset": 101}, {"referenceID": 5, "context": "where we assume \u03c32Y(i) > 0 for all i [6, 2].", "startOffset": 37, "endOffset": 43}, {"referenceID": 1, "context": "where we assume \u03c32Y(i) > 0 for all i [6, 2].", "startOffset": 37, "endOffset": 43}, {"referenceID": 1, "context": "If \u03c3(i) = 0, insertion of evidence may be undefined, see [2] who cites [6].", "startOffset": 57, "endOffset": 60}, {"referenceID": 5, "context": "If \u03c3(i) = 0, insertion of evidence may be undefined, see [2] who cites [6].", "startOffset": 71, "endOffset": 74}, {"referenceID": 1, "context": "The architectures described in [2], [6], and [9] each does a full propagation over all the nodes of the computation tree prior to inserting \u01eb whereas we do only a partial COLLECT prior to inserting \u01eb\u2206.", "startOffset": 31, "endOffset": 34}, {"referenceID": 5, "context": "The architectures described in [2], [6], and [9] each does a full propagation over all the nodes of the computation tree prior to inserting \u01eb whereas we do only a partial COLLECT prior to inserting \u01eb\u2206.", "startOffset": 36, "endOffset": 39}, {"referenceID": 8, "context": "The architectures described in [2], [6], and [9] each does a full propagation over all the nodes of the computation tree prior to inserting \u01eb whereas we do only a partial COLLECT prior to inserting \u01eb\u2206.", "startOffset": 45, "endOffset": 48}, {"referenceID": 1, "context": "Cowell [2] presents an algorithm for belief update where message passing proceeds on an elimination tree rather than a (strong) junction tree.", "startOffset": 7, "endOffset": 10}, {"referenceID": 1, "context": "The three main differences between the present propagation scheme and Cowell [2] are: use of a strong junction tree as opposed to an elimination tree, use of EXCHANGE to eliminate both continuous and discrete variables and a single round of message passing.", "startOffset": 77, "endOffset": 80}, {"referenceID": 5, "context": "The architecture of Lauritzen & Jensen [6] performs belief update by message passing in a strong junction tree architecture.", "startOffset": 39, "endOffset": 42}, {"referenceID": 7, "context": "A CG potential [8] is associated with each clique and separator.", "startOffset": 15, "endOffset": 18}, {"referenceID": 5, "context": "Initialization plays an important role in the Lauritzen & Jensen [6] architecture.", "startOffset": 65, "endOffset": 68}, {"referenceID": 6, "context": "It produces a Lauritzen & Spiegelhalter-like junction tree representation [7] where clique potentials are conditioned on the continuous variables of the parent separator.", "startOffset": 74, "endOffset": 77}, {"referenceID": 1, "context": "The need for conditioning, recursive combination, and complex matrix operations is eliminated in both the Cowell [2] and the present architectures.", "startOffset": 113, "endOffset": 116}, {"referenceID": 5, "context": "In the Lauritzen & Jensen [6] architecture initialization of T requires a recursive combination operation.", "startOffset": 26, "endOffset": 29}, {"referenceID": 5, "context": "The Lauritzen & Jensen [6] architecture calculates weak marginals during DISTRIBUTE.", "startOffset": 23, "endOffset": 26}, {"referenceID": 1, "context": "This is not the case for the Cowell [2] nor the present architecture.", "startOffset": 36, "endOffset": 39}, {"referenceID": 8, "context": "The present architecture is quite different from the architecture proposed by Madsen [9].", "startOffset": 85, "endOffset": 88}, {"referenceID": 10, "context": "The latter architecture is an extension of Madsen & Jensen [11] to the case of CLG BNs based on the propagation scheme of Lauritzen & Jensen [6].", "startOffset": 59, "endOffset": 63}, {"referenceID": 5, "context": "The latter architecture is an extension of Madsen & Jensen [11] to the case of CLG BNs based on the propagation scheme of Lauritzen & Jensen [6].", "startOffset": 141, "endOffset": 144}, {"referenceID": 5, "context": "First, the architecture is based solely on the operations of Lauritzen & Jensen [6] whereas the present scheme is based on operations of both Lauritzen & Jensen [6]", "startOffset": 80, "endOffset": 83}, {"referenceID": 5, "context": "First, the architecture is based solely on the operations of Lauritzen & Jensen [6] whereas the present scheme is based on operations of both Lauritzen & Jensen [6]", "startOffset": 161, "endOffset": 164}, {"referenceID": 1, "context": "and Cowell [2].", "startOffset": 11, "endOffset": 14}, {"referenceID": 5, "context": "We compared the performance of the present architecture with the performance of the commercial implementation of the Lauritzen & Jensen [6] architecture in the HUGIN Decision Engine.", "startOffset": 136, "endOffset": 139}, {"referenceID": 5, "context": "This insight is supported by the experimental analysis, which indicates that the Lauritzen & Jensen [6] implementation runs out of memory on most networks with 75 or more variables for a large fraction of the evidence sets whereas the present architecture runs out of memory on a much smaller fraction of the evidence 0 1 2 3 4 5 6", "startOffset": 100, "endOffset": 103}, {"referenceID": 5, "context": "On most of the networks considered in the test \u2014 where belief update is feasible \u2014 the commercial implementation of Lauritzen & Jensen [6] is most efficient (typically networks with less than 75 variables).", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "The architecture is based on extended versions of operations introduced by Lauritzen & Jensen [6] and Cowell [2].", "startOffset": 94, "endOffset": 97}, {"referenceID": 1, "context": "The architecture is based on extended versions of operations introduced by Lauritzen & Jensen [6] and Cowell [2].", "startOffset": 109, "endOffset": 112}, {"referenceID": 5, "context": "Despite a significant difference in the efficiency of table operations the proposed architecture is \u2014 in some cases \u2014 more efficient than a commercial implementation of the Lauritzen & Jensen [6] architecture.", "startOffset": 192, "endOffset": 195}], "year": 2006, "abstractText": "In recent years Bayesian networks (BNs) with a mixture of continuous and discrete variables have received an increasing level of attention. We present an architecture for exact belief update in Conditional Linear Gaussian BNs (CLG BNs). The architecture is an extension of lazy propagation using operations of Lauritzen & Jensen [6] and Cowell [2]. By decomposing clique and separator potentials into sets of factors, the proposed architecture takes advantage of independence and irrelevance properties induced by the structure of the graph and the evidence. The resulting benefits are illustrated by examples. Results of a preliminary empirical performance evaluation indicate a significant potential of the proposed architecture.", "creator": "dvips(k) 5.95a Copyright 2005 Radical Eye Software"}}}