{"id": "1206.6869", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Recognizing Activities and Spatial Context Using Wearable Sensors", "abstract": "We introduce a new dynamic model with the capability of recognizing both activities that an individual is performing as well as where that ndividual is located. Our model is novel in that it utilizes a dynamic graphical model to jointly estimate both activity and spatial context over time based on the simultaneous use of asynchronous observations consisting of GPS measurements, and measurements from a small mountable sensor board. Joint inference is quite desirable as it has the ability to improve accuracy of the model. A key goal, however, in designing our overall system is to be able to perform accurate inference decisions while minimizing the amount of hardware an individual must wear. This minimization leads to greater comfort and flexibility, decreased power requirements and therefore increased battery life, and reduced cost. We show results indicating that our joint measurement model outperforms measurements from either the sensor board or GPS alone, using two types of probabilistic inference procedures, namely particle filtering and pruned exact inference.", "histories": [["v1", "Wed, 27 Jun 2012 16:29:30 GMT  (931kb)", "http://arxiv.org/abs/1206.6869v1", "Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["amarnag subramanya", "alvin raj", "jeff a bilmes", "dieter fox"], "accepted": false, "id": "1206.6869"}, "pdf": {"name": "1206.6869.pdf", "metadata": {"source": "CRF", "title": "Recognizing Activities and Spatial Context Using Wearable Sensors", "authors": ["Amarnag Subramanya", "Alvin Raj"], "emails": [], "sections": [{"heading": null, "text": "We are introducing a new dynamic model, with the ability to detect both activities that a person performs and the location of that person. Our approach is novel in that it uses a dynamic graphical model to jointly estimate both the activity and the spatial context over time, based on the simultaneous use of asynchronous observations, consisting of GPS measurements and a small mountable sensor board. Common conclusions are highly desirable as they can improve the accuracy of the model and the consistency of location and activity estimates. The parameters of our model are trained on partially labeled data. We apply virtual evidence to improve data commentary, giving the user high flexibility in labeling training data. We present results that show the performance gains achieved by virtual evidence for data comments and the shared conclusion carried out by our system."}, {"heading": "1 Introduction", "text": "These technologies make it possible to track a person's activities over a longer period of time. We focus on providing accurate information about a person's activities and their context in an everyday environment. Specifically, we want to estimate a person's movements (such as walking, running or driving) and whether a person is outdoors or in an everyday environment."}, {"heading": "2 Wearable Sensor System", "text": "Our customized portable sensor system consists of a multi-sensor board, a Holux GPS unit with SIRF III chipset, and an iPAQ PDA for data storage. The sensor board shown in Figure 1 is extremely compact, cost-effective, and uses standard electronic components. It weighs only 121g, including battery and processing hardware. Sensors include a 3-axis accelerometer, two microphones for recording speech and ambient sound, photo transistors for measuring light conditions, and temperature and barometric pressure sensors. The total cost per sensor board is approximately $400. The time-stamped data collected on this device is transmitted to an iPAQ handheld computer via USB connection. GPS data is transmitted from the receiver to the PDA via Bluetooth. The entire system can operate for more than 8 hours."}, {"heading": "3 Activity Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Overview", "text": "The full DBN for our activity model is shown in Figure 2 with some of the implementation details shown in Figure 3. Variables presented in the model include GPS measurements (gk, hk), sensor board measurements that are capable of the person, lk, velocity of motion vk, the type of motion they perform, and their environment ek. We first describe the individual components and their relationships that begin at the sensor level of the model. GPS measurements are divided into longitude / latitude information, g.xk, g.yk}, and horizontal dilution of precision (hdop), hdop provides information on the accuracy of location information that largely depends on the visibility and position of the satellites. The node ok models GPS outliers typically occur when the person is in a building or near trees."}, {"heading": "3.2 Inference", "text": "Our DBN-based probabilistic inference system uses a combination of a triangulation [4] (to create a dynamic connection tree) and search-based methods within each clique. This allows us to apply a form of approximate inference method that is similar to sampling but has some differences. As each clique is constructed, we use only a subset of the states of the incoming separators, and the subset is indirectly selected using a cutting strategy - specifically for each separator, its previous clique has been removed to the top scoring k clique states, resulting in a reduced separator size and thus a reduced intra-clique construction method. As a result, our inference system adaptively cuts the state space. As the cutting threshold is selected based on the probability of the most likely state, the number of states being tracked depends on the uncertainty of the posterior state; the higher the uncertainty, the less is used."}, {"heading": "3.3 Semi-supervised Learning With Virtual Evidence", "text": "This is a typical approach to learning such models is to collect long sequences of training data and manually mark them with the activities performed. Unfortunately, such an approach is extremely tedious and error-prone. However, annotation errors are typically due to confusion between different activities and the wrong timing of transitions between activities. The second type of error is particularly difficult to overcome, as it is often unclear or not well defined when a transition actually takes place, or what a transition means. For example, the exact point in time at which a person enters the driving vehicle state can be chosen in various ways, for example, when the person enters the car when they turn on the engine, or when the car begins to move. An obvious solution to this problem would be uncontrolled training of model parameters. Unfortunately, such an approach typically generates models that do not correspond directly with the amount of activities that one wants to detect."}, {"heading": "3.4 Feature Extraction", "text": "Our system uses GPS measurements and sensor board measurements to infer a person's activities. Specifically, the sensor board produces a variety of discrete signals that exhibit different characteristics, such as inherently different sampling rates and spectral contents - for example, raw audio has a much higher sampling rate than the barometric pressure sensor. To include such heterogeneous sensor data, we use the feature extraction process developed by Lester and colleagues so that information is not lost. Next, we provide only a high-level description of this process, more information can be found in [12]. First, signal sample rates are normalized to an appropriate rate through low-pass filtering and / or up / down sampling, so that information is not lost. Next, each signal is windowed with a window of appropriate length at 4 Hz, and a feature vector is inhibited in each window, resulting in a feature vector of high dimensionality."}, {"heading": "4 Related Work", "text": "Recently, the estimation of the activities of wearable sensors has attracted considerable attention, especially in the ubiquitous computing communities and artificial intelligence communities. Virtually all existing approaches involve either position sensors such as GPS or location-independent sensors such as accelerometers and microphones, but not opposite.Bao and Intille [2] use multiple accelerometers placed on a person's body to estimate activities such as standing, walking, or walking. Kern and colleagues [11, 10] and Lukowicz et al. [15] have added a microphone to a similar set of accelerometers to extract additional context information, which typically relies on Gaussian observation models and dimension reduction techniques such as PCA and LDA to generate observation models from the low sensor extract functions (e.g. FFT) to extract additional conformations."}, {"heading": "5 Experiments", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country."}, {"heading": "6 Conclusions", "text": "We have presented an approach to estimate a person's low-level activities and spatial context from data collected from a small portable sensor device. Our approach uses a dynamic Bayesian network to model dependencies between different parts of the system, allowing us to draw efficient conclusions and learn from the model. In experiments, we show that the detection accuracy of our system is significantly higher than the accuracy achieved by existing techniques that do not make common arguments about a person's activities and the spatial context. In addition, our approach can correct GPS errors, resulting in a more consistent assessment of a person's location and environment. We also show how virtual evidence (VE) can be used to model partially labeled data. Experiments show that VE can deliver better results than standard EM on fully labeled data, which we are initially able to model uncertainty in the transition period between activities."}, {"heading": "Acknowledgments", "text": "The authors thank Tanzeem Choudhury, Jonathan Lester and Gaetano Borriello for many useful discussions and for providing their feature extraction and learning code. Further thanks go to the Intel Research Lab in Seattle for providing the sensor boards used in this research. This work was supported in part by DARPA's ASSIST and CALO programs (contract numbers: NBCH-C-05-0137, SRI subcontract 27-000968) and by the NSF Human and Social Dynamics (HSD) program under contract number IIS-0433637."}], "references": [{"title": "Using GPS to learn significant locations and predict movement across multiple users", "author": ["D. Ashbrook", "T. Starner"], "venue": "Personal and Ubiquitous Computing, 7(5)", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2003}, {"title": "Activity recognition from userannotated acceleration data", "author": ["L. Bao", "S Intille"], "venue": "Proc. of the International Conference on Pervasive Computing and Communications", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "On soft evidence in bayesian networks", "author": ["J. Bilmes"], "venue": "Technical Report UWEETR-2004-0016, University of Washington, Dept. of EE", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "On triangulating dynamic graphical models", "author": ["J. Bilmes", "C. Bartels"], "venue": "Uncertainty in Artificial Intelligence: Pro-  ceedings of the Nineteenth Conference ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Combining labeled and unlabeled data with co-training", "author": ["A. Blum", "T. Mitchell"], "venue": "COLT: Proceedings of the Workshop on Computational Learning Theory", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1998}, {"title": "editors", "author": ["O. Chapelle", "A. Zien", "B. Sch\u00f6lkopf"], "venue": "Semisupervised learning. MIT Press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Probabilistic temporal reasoning", "author": ["T. Dean", "K. Kanazawa"], "venue": "Proc. of the National Conference on Artificial Intelligence (AAAI)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1988}, {"title": "Constraint Processing", "author": ["R. Dechter"], "venue": "Morgan Kaufmann", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Using context-aware computing to reduce the perceived burden of interruptions from mobile devices", "author": ["J. Ho", "S. Intille"], "venue": "Proc. of the Conference on Human Factors in Computing Systems (CHI)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "Wearable sensing to annotate meeting recordings", "author": ["N. Kern", "B. Schiele", "H. Junker", "P. Lukowicz", "G. Trster"], "venue": "In The 6th International Symposium on Wearable Computers (ISWC)", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2002}, {"title": "Recognizing context for annotating a live life recording", "author": ["N. Kern", "B. Schiele", "A. Schmidt"], "venue": "Personal and Ubiquituous Computingd", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "A hybrid discriminative-generative approach for modeling human activities", "author": ["J. Lester", "T. Choudhury", "N. Kern", "G. Borriello", "B. Hannaford"], "venue": "Proc. of the International Joint Conference on Artificial Intelligence (IJCAI)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning and inferring transportation routines", "author": ["L. Liao", "D. Fox", "H. Kautz"], "venue": "Proc. of the National Conference on Artificial Intelligence (AAAI)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Location-based activity recognition", "author": ["L. Liao", "D. Fox", "H. Kautz"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}, {"title": "Recognizing workshop activity using body worn microphones and accelerometers", "author": ["P. Lukowicz", "J. Ward", "H. Junker", "M. St\u00e4ger", "G. Tr\u00f6ster", "A. Atrash", "T. Starner"], "venue": "Proc. of Pervasive Computing", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Opportunity Knocks: a system to provide cognitive assistance with transportation services", "author": ["D. Patterson", "L. Liao", "K. Gajos", "M. Collier", "N. Livic", "K. Olson", "S. Wang", "D. Fox", "H. Kautz"], "venue": "International Conference on Ubiquitous Computing (UbiComp)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": "Morgan Kaufmann Publishers, Inc.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1988}, {"title": "Rao- Blackwellized particle filters for recognizing activities and spatial context from wearable sensors", "author": ["A. Raj", "A. Subramanya", "J. Bilmes", "D. Fox"], "venue": "Experimental Robotics: The 10th International Symposium, Springer Tracts in Advanced Robotics (STAR). Springer Verlag", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Unsupervised word sense disambiguation rivaling supervised methods", "author": ["D. Yarowsky"], "venue": "Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1995}], "referenceMentions": [{"referenceID": 11, "context": "Recent advances in wearable sensing and computing devices and in fast probabilistic inference techniques make possible the fine-grained estimation of a person\u2019s activities over extended periods of time [12].", "startOffset": 202, "endOffset": 206}, {"referenceID": 8, "context": "Such technologies enable applications ranging from context aware computing [9] to support for cognitively impaired people [16] to long-term health and fitness monitoring to automatic after action reporting of military missions.", "startOffset": 75, "endOffset": 78}, {"referenceID": 15, "context": "Such technologies enable applications ranging from context aware computing [9] to support for cognitively impaired people [16] to long-term health and fitness monitoring to automatic after action reporting of military missions.", "startOffset": 122, "endOffset": 126}, {"referenceID": 10, "context": "There are in fact a variety of systems that utilize multiple sensors and measurements taken all over the body [11, 15].", "startOffset": 110, "endOffset": 118}, {"referenceID": 14, "context": "There are in fact a variety of systems that utilize multiple sensors and measurements taken all over the body [11, 15].", "startOffset": 110, "endOffset": 118}, {"referenceID": 6, "context": "Our statistical model, moreover, utilizes a dynamic Bayesian network (DBN) [7] for expressing the underlying dependencies between various types of information represented in our system, and performs efficient probabilistic inference based on a discretization of 2-D space.", "startOffset": 75, "endOffset": 78}, {"referenceID": 7, "context": "Map There are many ways of expressing constraints in Bayesian networks [8], each of which can be implemented using a variety of algorithms.", "startOffset": 71, "endOffset": 74}, {"referenceID": 17, "context": "In [18], we show how to apply RaoBlackwellized particle filters in order to perform approximate inference using a sample-based representation of the state space.", "startOffset": 3, "endOffset": 7}, {"referenceID": 3, "context": "Our DBN-based probabilistic inference system uses a combination of a triangulation [4] (to produce a dynamic junction tree) and search-based methods within each clique.", "startOffset": 83, "endOffset": 86}, {"referenceID": 3, "context": "All DBN inference and incorporation of dynamic virtual evidence (see below) utilizes the graphical modeling toolkit (GMTK) system [4].", "startOffset": 130, "endOffset": 133}, {"referenceID": 18, "context": ", semi-supervised) learning [19, 5, 6], where parts of the data are labeled and other parts are left unlabeled.", "startOffset": 28, "endOffset": 38}, {"referenceID": 4, "context": ", semi-supervised) learning [19, 5, 6], where parts of the data are labeled and other parts are left unlabeled.", "startOffset": 28, "endOffset": 38}, {"referenceID": 5, "context": ", semi-supervised) learning [19, 5, 6], where parts of the data are labeled and other parts are left unlabeled.", "startOffset": 28, "endOffset": 38}, {"referenceID": 16, "context": "Virtual evidence was first defined in [17] as a way to depict evidence in a Bayesian network using the mechanism of hidden variables.", "startOffset": 38, "endOffset": 42}, {"referenceID": 2, "context": "Virtual evidence can be used to incorporate soft evidence when computing posterior distributions over the most probable values of random variables (filtering, Viterbi, or MPE), and during EM training [3].", "startOffset": 200, "endOffset": 203}, {"referenceID": 11, "context": "To incorporate such heterogeneous sensor data, we employ the feature extraction process developed by Lester and colleagues [12].", "startOffset": 123, "endOffset": 127}, {"referenceID": 11, "context": "Here, we only provide a high-level description of this process, more information can be found in [12].", "startOffset": 97, "endOffset": 101}, {"referenceID": 11, "context": "We utilize the approach taken in [12] as our starting feature extraction procedure.", "startOffset": 33, "endOffset": 37}, {"referenceID": 0, "context": "Considering these margins together, we can obtain an average distance to the decision boundary, which is then passed through a sigmoid function to produce a [0, 1]valued probability.", "startOffset": 157, "endOffset": 163}, {"referenceID": 1, "context": "Bao and Intille [2] use multiple accelerometers placed on a person\u2019s body to estimate activities such as standing, walking, or running.", "startOffset": 16, "endOffset": 19}, {"referenceID": 10, "context": "Kern and colleagues [11, 10] and Lukowicz et al.", "startOffset": 20, "endOffset": 28}, {"referenceID": 9, "context": "Kern and colleagues [11, 10] and Lukowicz et al.", "startOffset": 20, "endOffset": 28}, {"referenceID": 14, "context": "[15] added a microphone to a similar set of accelerometers in order to extract additional context information.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] showed how to apply boosting in order to learn activity classifiers based on the sensor data collected by the same sensor board we use in our research.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "These existing approaches feed the sensor data or features into static classifiers [2, 9], a bank of temporally independent HMMs [12], or multi-state HMMs [10, 11] in order to perform temporal smoothing.", "startOffset": 83, "endOffset": 89}, {"referenceID": 8, "context": "These existing approaches feed the sensor data or features into static classifiers [2, 9], a bank of temporally independent HMMs [12], or multi-state HMMs [10, 11] in order to perform temporal smoothing.", "startOffset": 83, "endOffset": 89}, {"referenceID": 11, "context": "These existing approaches feed the sensor data or features into static classifiers [2, 9], a bank of temporally independent HMMs [12], or multi-state HMMs [10, 11] in order to perform temporal smoothing.", "startOffset": 129, "endOffset": 133}, {"referenceID": 9, "context": "These existing approaches feed the sensor data or features into static classifiers [2, 9], a bank of temporally independent HMMs [12], or multi-state HMMs [10, 11] in order to perform temporal smoothing.", "startOffset": 155, "endOffset": 163}, {"referenceID": 10, "context": "These existing approaches feed the sensor data or features into static classifiers [2, 9], a bank of temporally independent HMMs [12], or multi-state HMMs [10, 11] in order to perform temporal smoothing.", "startOffset": 155, "endOffset": 163}, {"referenceID": 0, "context": "For instance, Ashbrook and Starner [1] detect a person\u2019s significant places based on the time spent at a location.", "startOffset": 35, "endOffset": 38}, {"referenceID": 12, "context": "In [13], Liao and colleagues showed how to learn a person\u2019s outdoor transportation routines from GPS data.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "More recently, the same authors presented a technique for jointly determining a person\u2019s activities and her significant places [14].", "startOffset": 127, "endOffset": 131}, {"referenceID": 11, "context": "This system is similar to the technique used to infer activities in [12].", "startOffset": 68, "endOffset": 72}, {"referenceID": 17, "context": "We are also investigating the use of Rao-Blackwellised particle filters in order better represent a person\u2019s location in continuous space [18].", "startOffset": 138, "endOffset": 142}], "year": 2006, "abstractText": "We introduce a new dynamic model with the capability of recognizing both activities that an individual is performing as well as where that individual is located. Our approach is novel in that it utilizes a dynamic graphical model to jointly estimate both activity and spatial context over time based on the simultaneous use of asynchronous observations consisting of GPS measurements, and a small mountable sensor board. Joint inference is quite desirable as it has the ability to improve accuracy of the model and consistency of the location and activity estimates. The parameters of our model are trained on partially labeled data. We apply virtual evidence to improve data annotation, giving the user high flexibility when labeling training data. We present results indicating the performance gains achieved by virtual evidence for data annotation and the joint inference performed by our system.", "creator": "TeX"}}}