{"id": "1211.2290", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2012", "title": "Dating Texts without Explicit Temporal Cues", "abstract": "This paper tackles temporal resolution of documents, such as determining when a document is about or when it was written, based only on its text. We apply techniques from information retrieval that predict dates via language models over a discretized timeline. Unlike most previous works, we rely {\\it solely} on temporal cues implicit in the text. We consider both document-likelihood and divergence based techniques and several smoothing methods for both of them. Our best model predicts the mid-point of individuals' lives with a median of 22 and mean error of 36 years for Wikipedia biographies from 3800 B.C. to the present day. We also show that this approach works well when training on such biographies and predicting dates both for non-biographical Wikipedia pages about specific years (500 B.C. to 2010 A.D.) and for publication dates of short stories (1798 to 2008). Together, our work shows that, even in absence of temporal extraction resources, it is possible to achieve remarkable temporal locality across a diverse set of texts.", "histories": [["v1", "Sat, 10 Nov 2012 05:12:31 GMT  (178kb,D)", "http://arxiv.org/abs/1211.2290v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["abhimanu kumar", "jason baldridge", "matthew lease", "joydeep ghosh"], "accepted": false, "id": "1211.2290"}, "pdf": {"name": "1211.2290.pdf", "metadata": {"source": "CRF", "title": "Dating Texts without Explicit Temporal Cues", "authors": ["Abhimanu Kumar", "Jason Baldridge", "Joydeep Ghosh"], "emails": ["abhimank@cs.cmu.edu", "jbaldrid@mail.utexas.edu", "ml@ischool.utexas.edu", "ghosh@ece.utexas.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is such that most of them will be able to go into another world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "2 Related Work", "text": "In recent years, the number of those who are able to reform has multiplied. (...) In recent years, the number of those who are able to reform and to reform has multiplied. (...) In recent years, the number of those who are able to reform and to reform has multiplied. (...) In recent years, the number of those who are able to reform has increased. (...) In recent years, the number of those who are able to reform has increased. (...) In recent years, the number of those who are able to reform has increased. (...) In recent years, the number of those who are able to reform has increased. (...) In recent years, the number of those who are able to reform has increased. \""}, {"heading": "3 Document Collections", "text": "Our models are trained and evaluated on three sets of data 6Wikipedia biographies (wiki-bio). The Wikipedia dump of English on September 4, 2010 is used 7 to obtain biographies of people who lived between the years 3800 B.C. and 2010 A.D. We extract the lifespan of each individual via the date of birth and the date of death of each article. We exclude biographies that do not specify any of the fields or that lie outside the year under consideration. If the date of birth is missing, we describe it as 100 years before the date of death (similarly, and vice versa if the date of death is missing). We do this only to estimate the word distributions in education. All such documents are discarded for validation and testing. We treat the lifespan of each individual as the described period of time of the article."}, {"heading": "4 Model", "text": "Similar to previous works, we represent continuous time through discrete units. Our formalization follows most closely that of Alonso et al. (2009). The period 8http: / / en.wikipedia.org / wiki / List _ of _ years9For example, the events \"Proto-Greek invasions of Greece.,\" \"Minoan Old Palace (Protopalatial) period starts in Crete.\" etc. are present in the text for both 1878 and 1880 BC, which occurred around 1880 BC, but their exact date of occurrence is unknown."}, {"heading": "4.1 Estimation", "text": "Let a span of several, contiguous years have a certain interval = [ys, ye], with ys and ye referring respectively to the beginning and end years. As mentioned in \u00a7 3, we also know the year range covered by each collection of documents, and accordingly limit our general timeline to the span \u03c4o = [y0, yY), which in total covers yY \u2212 y0 = years. A chronon is an atomic interval x, on which a discrete timeline is constructed (Alonso et al., 2009). In this paper, a chronon consists of years in which it is a tunable parameter. Considering this, the timeline is divided into a sequence of n contiguous, non-intersecting chronons x = x1: n, in which n = a dilemma arises. A \"pseudo-document\" dx \"is created for each chronon x, as the concatenation of all educational documents whose labelled span overlaps x."}, {"heading": "4.2 Estimation", "text": "We calculate the affinity between each chronon x and a document d by using the discrete distribution P (x / d) anpr (x / d) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anpr (x) anx (anr) ane (anr) anx (anr) anx (anr) anx (x) ane (x) (x) anpr (x) anr (x) anx (x) anr (x) ane (x) anpr (x) anr (x) anr (x (x) anr (x) anr (x) ane (x (anr) anr (x) anr (x) anr (x (x) anr (x) anr (x) anr (x (x) anr (x) anr (x) anr (x (x) anr (x) anr (x (x) anr (x) anr (x) anr (x (x) anr) anr (x (x) anr (x) anr (x (x) anr) anr (x (x) anr) anr (x (x) anr (x (x) anr) anr (x (x (x) anr) anr) (x (x (x (x) anr) anr) anr (x (x (x) anr) anr (x (x (x (x) anr) anr) (x (x (x (x) anr) anr) anr) (x (x (x (x (x (x) anr) anr) anr (x (x (x) anr) anr)"}, {"heading": "5 Experimental Setup", "text": "In fact, it is as if most of us will be able to abide by the rules that they have established in the past. (...) In fact, it is as if they are able to assert themselves in the present. (...) It is as if they were able to stay in the present. (...) It is as if they were able to stay in the future. (...) It is as if they want to go into the future. (...) It is as if they want to go into the future. (...) It is as if they want to go into the future. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...).). (...). (...).). (...).). (...).). (...). (...).).). (...). (...).). (...).). (...).). (...).). (...).). (...).). (...).). (...).). (...).).). (...). (...).).).). (...). (...).). (...).). (...). (...).). (...).).). (...). (...).).). (...). (...).). (...). (...)..).).)..). (...). (...). (...).). (...). (...).).).).). (...). (...).). (...).).).).). (...). (...).). (...).."}, {"heading": "6 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Parameter tuning", "text": "We start with the annual prediction experiments on the development sets to tune the parameters \u03b4, \u0442 or \u00b5. We parameterise \u00b5 as a function of the average chronon size in the training set: \u00b5 = d\u03c1c-e (8) c-i is a constant whose value depends on the model and the task. The value of \u03c1 is adjusted by the validation set. Figure 4: Tuning for the smoothing parameters (as well as) by wiki bio and wiki year data sets for the KL model. Choice of the chronon size and smoothing parameter.We tune the chronon size by the validation savings and tune the smoothing parameters. \u2212 Sich-i-i-i for the best preserved type of smoothing. For the tuning we assign the chronon size and smoothing parameter an optimal model."}, {"heading": "6.2 Test results.", "text": "Table 2 shows the results for the different models on the test sets for all three datasets, using parameters matched to the corresponding development groups.Wiki-bio The models beat both baselines slightly. Note that baseline-ht is quite strong for a large number of documents: it results in an average error of zero, since more than half of the documents have birth and death dates than their first datasets. Nevertheless, it is completely out for many documents and evidently has limited applicability. The models all reduce the error by half compared to baseline-1915. The best model (DL + JM smoothing) achieves an average error of 37.4 years, which is quite strong since the prediction range is 5810 years. The mean and mean error for the best model is 2.5 years. The mean and mean error was 36.6 and 22.0 years for the best performing model (DL + JM smoothing) on the development set.Wiki years beat the baseline model is 2.5 years, the average error for the best model is 755 and 32.5 means that 355 documents are relatively comfortable."}, {"heading": "6.3 Output analysis", "text": "This year, it has come to the point where it only takes one year to get to the next round."}, {"heading": "7 Conclusion", "text": "Using words alone, it is possible to determine the period of time a document is about (the Wikipedia records) or the period in which it was written (the Gutenberg records). In the former case, the presence of designated entities dominates the texts, and their names provide strong evidence for certain historical periods. In the latter case, the texts are freely invented (including science fiction), and they rarely mention historical entities. In these, generic terms indicating a certain period of time dominate the prediction. Interestingly, the models used (successfully) for this later task are trained on Wikipedia biographies of historical individuals written over the last decade. The predictions of our models are a natural counterpart to other time-sensitive models of word choice, such as Dynamic Topic Models (DTMs) (Lead and Lafferty, 2006)."}, {"heading": "Acknowledgments", "text": "This work was supported in part by a grant from the Morris Memorial Trust Fund of the New York Community Trust and a Temple Fellowship."}], "references": [{"title": "Maintaining knowledge about temporal intervals", "author": ["James F. Allen."], "venue": "Commun. ACM, 26(11):832\u2013843, November.", "citeRegEx": "Allen.,? 1983", "shortCiteRegEx": "Allen.", "year": 1983}, {"title": "Clustering and exploring search results using timeline constructions", "author": ["Omar Alonso", "Michael Gertz", "Ricardo Baeza-Yates."], "venue": "Proceedings of the 18th ACM conference on Information and knowledge management, CIKM \u201909, pages 97\u2013106, New York, NY,", "citeRegEx": "Alonso et al\\.,? 2009", "shortCiteRegEx": "Alonso et al\\.", "year": 2009}, {"title": "Dynamic topic models", "author": ["David M. Blei", "John D. Lafferty."], "venue": "Proceedings of the 23rd international conference on Machine learning, ICML \u201906, pages 113\u2013120, New York, NY, USA. ACM.", "citeRegEx": "Blei and Lafferty.,? 2006", "shortCiteRegEx": "Blei and Lafferty.", "year": 2006}, {"title": "Jointly combining implicit constraints improves temporal ordering", "author": ["Nathanael Chambers", "Daniel Jurafsky."], "venue": "EMNLP, pages 698\u2013706. ACL.", "citeRegEx": "Chambers and Jurafsky.,? 2008", "shortCiteRegEx": "Chambers and Jurafsky.", "year": 2008}, {"title": "Labeling documents with timestamps: Learning from their time expressions", "author": ["Nathanael Chambers."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 98\u2013106, Jeju Island, Korea, July. Asso-", "citeRegEx": "Chambers.,? 2012", "shortCiteRegEx": "Chambers.", "year": 2012}, {"title": "Structural and temporal analysis of the blogosphere through community factorization", "author": ["Yun Chi", "Shenghuo Zhu", "Xiaodan Song", "Junichi Tatemura", "Belle L. Tseng."], "venue": "Proceedings of the 13th ACM SIGKDD international conference on Knowledge dis-", "citeRegEx": "Chi et al\\.,? 2007", "shortCiteRegEx": "Chi et al\\.", "year": 2007}, {"title": "Finding wormholes with flickr geotags", "author": ["Maarten Clements", "Pavel Serdyukov", "Arjen P. de Vries", "Marcel J.T. Reinders."], "venue": "Proceedings of the 32nd European conference on Advances in Information Retrieval, ECIR\u20192010, pages 658\u2013661, Berlin, Heidel-", "citeRegEx": "Clements et al\\.,? 2010", "shortCiteRegEx": "Clements et al\\.", "year": 2010}, {"title": "Answering general time sensitive queries", "author": ["Wisam Dakka", "Luis Gravano", "Panagiotis G. Ipeirotis."], "venue": "Proceedings of the 17th ACM conference on Information and knowledge management, CIKM \u201908, pages 1437\u20131438, New York, NY, USA. ACM.", "citeRegEx": "Dakka et al\\.,? 2008", "shortCiteRegEx": "Dakka et al\\.", "year": 2008}, {"title": "Temporal Language Models for the Disclosure of Historical Text", "author": ["Franciska de Jong", "Henning Rode", "Djoerd Hiemstra."], "venue": "Humanities, computers and cultural heritage: Proceedings of the XVIth International Conference of the Association for History and Com-", "citeRegEx": "Jong et al\\.,? 2005", "shortCiteRegEx": "Jong et al\\.", "year": 2005}, {"title": "A latent variable model for geographic lexical variation", "author": ["Jacob Eisenstein", "Brendan O\u2019Connor", "Noah A. Smith", "Eric P. Xing"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Eisenstein et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Eisenstein et al\\.", "year": 2010}, {"title": "Real-time event extraction for infectious disease outbreaks", "author": ["Ralph Grishman", "Silja Huttunen", "Roman Yangarber."], "venue": "Proceedings of the second international conference on Human Language Technology Research, pages 366\u2013369, San Diego, California. Mor-", "citeRegEx": "Grishman et al\\.,? 2002", "shortCiteRegEx": "Grishman et al\\.", "year": 2002}, {"title": "Studying the history of ideas using topic models", "author": ["David Hall", "Daniel Jurafsky", "Christopher D. Manning."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP \u201908, pages 363\u2013371, Stroudsburg, PA, USA.", "citeRegEx": "Hall et al\\.,? 2008", "shortCiteRegEx": "Hall et al\\.", "year": 2008}, {"title": "Improving temporal language models for determining time of non-timestamped documents", "author": ["Nattiya Kanhabua", "Kjetil N\u00f8rv\u00e5g."], "venue": "Proceedings of the 12th European conference on Research and Advanced Technology for Digital Libraries, ECDL \u201908, pages", "citeRegEx": "Kanhabua and N\u00f8rv\u00e5g.,? 2008", "shortCiteRegEx": "Kanhabua and N\u00f8rv\u00e5g.", "year": 2008}, {"title": "Understanding temporal query dynamics", "author": ["Anagha Kulkarni", "Jaime Teevan", "Krysta M. Svore", "Susan T. Dumais."], "venue": "Proceedings of the fourth ACM international conference on Web search and data mining, WSDM \u201911, pages 167\u2013176, New York, NY,", "citeRegEx": "Kulkarni et al\\.,? 2011", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2011}, {"title": "Supervised language modeling for temporal resolution of texts", "author": ["Abhimanu Kumar", "Matthew Lease", "Jason Baldridge."], "venue": "Proceeding of the 20th ACM Conference on Information and Knowledge Management (CIKM), pages 2069\u20132072.", "citeRegEx": "Kumar et al\\.,? 2011", "shortCiteRegEx": "Kumar et al\\.", "year": 2011}, {"title": "Document language models, query models, and risk minimization for information retrieval", "author": ["J. Lafferty", "C. Zhai."], "venue": "Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 111\u2013119.", "citeRegEx": "Lafferty and Zhai.,? 2001a", "shortCiteRegEx": "Lafferty and Zhai.", "year": 2001}, {"title": "Document language models, query models, and risk minimization for information retrieval", "author": ["John Lafferty", "Chengxiang Zhai."], "venue": "Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, SI-", "citeRegEx": "Lafferty and Zhai.,? 2001b", "shortCiteRegEx": "Lafferty and Zhai.", "year": 2001}, {"title": "Time-based language models", "author": ["Xiaoyan Li", "W. Bruce Croft."], "venue": "Proceedings of the twelfth international conference on Information and knowledge management, CIKM \u201903, pages 469\u2013475, New York, NY, USA. ACM.", "citeRegEx": "Li and Croft.,? 2003", "shortCiteRegEx": "Li and Croft.", "year": 2003}, {"title": "Learning to resolve geographical and temporal references in text", "author": ["Vitor Loureiro", "Ivo Anastcio", "Bruno Martins."], "venue": "Isabel F. Cruz, Divyakant Agrawal, Christian S. Jensen, Eyal Ofek, and Egemen Tanin, editors, GIS, pages 349\u2013352. ACM.", "citeRegEx": "Loureiro et al\\.,? 2011", "shortCiteRegEx": "Loureiro et al\\.", "year": 2011}, {"title": "WikiWars: A new corpus for research on temporal expressions", "author": ["Pawel Mazur", "Robert Dale."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 913\u2013922, Cambridge, MA, October. Association for Computa-", "citeRegEx": "Mazur and Dale.,? 2010", "shortCiteRegEx": "Mazur and Dale.", "year": 2010}, {"title": "Identifying relevant temporal expressions for realworld events", "author": ["Sara Romano Nattiya Kanhabua", "Avar Stewart."], "venue": "Proceedings of The SIGIR 2012 Workshop on Time-aware Information Access, Portland, Oregon.", "citeRegEx": "Kanhabua and Stewart.,? 2012", "shortCiteRegEx": "Kanhabua and Stewart.", "year": 2012}, {"title": "A language modeling approach to information retrieval", "author": ["Jay M. Ponte", "W. Bruce Croft."], "venue": "Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR \u201998, pages 275\u2013281, New York,", "citeRegEx": "Ponte and Croft.,? 1998", "shortCiteRegEx": "Ponte and Croft.", "year": 1998}, {"title": "The TimeBank corpus", "author": ["James Pustejovsky", "Patrick Hanks", "Roser Sauri", "Andrew See", "David Day", "Lisa Ferro", "Robert Gaizauskas", "Marcia Lazo", "Andrea Setzer", "Beth Sundheim."], "venue": "Corpus Linguistics, pages 647\u2013656.", "citeRegEx": "Pustejovsky et al\\.,? 2003", "shortCiteRegEx": "Pustejovsky et al\\.", "year": 2003}, {"title": "Heideltime: High quality rule-based extraction and normalization of temporal expressions", "author": ["Jannik Str\u00f6tgen", "Michael Gertz."], "venue": "Proceedings of the 5th International Workshop on Semantic Evaluation, SemEval \u201910, pages 321\u2013324, Stroudsburg, PA, USA.", "citeRegEx": "Str\u00f6tgen and Gertz.,? 2010", "shortCiteRegEx": "Str\u00f6tgen and Gertz.", "year": 2010}, {"title": "A system for reasoning about time", "author": ["Marc B. Vilain."], "venue": "David L. Waltz, editor, AAAI, pages 197\u2013201. AAAI Press.", "citeRegEx": "Vilain.,? 1982", "shortCiteRegEx": "Vilain.", "year": 1982}, {"title": "Topics over time: a non-markov continuous-time model of topical trends", "author": ["Xuerui Wang", "Andrew McCallum."], "venue": "Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD \u201906, pages 424\u2013433, New York,", "citeRegEx": "Wang and McCallum.,? 2006", "shortCiteRegEx": "Wang and McCallum.", "year": 2006}, {"title": "Continuous time dynamic topic models", "author": ["Chong Wang", "David M. Blei", "David Heckerman."], "venue": "David A. McAllester and Petri Myllymki, editors, UAI, pages 579\u2013586. AUAI Press.", "citeRegEx": "Wang et al\\.,? 2008", "shortCiteRegEx": "Wang et al\\.", "year": 2008}, {"title": "Simple supervised document geolocation with geodesic grids", "author": ["Benjamin Wing", "Jason Baldridge."], "venue": "Dekang Lin, Yuji Matsumoto, and Rada Mihalcea, editors, ACL, pages 955\u2013964. The Association for Computer Linguistics.", "citeRegEx": "Wing and Baldridge.,? 2011", "shortCiteRegEx": "Wing and Baldridge.", "year": 2011}, {"title": "A study of smoothing methods for language models applied to information retrieval", "author": ["Chengxiang Zhai", "John Lafferty."], "venue": "ACM Trans. Inf. Syst., 22(2):179\u2013 214.", "citeRegEx": "Zhai and Lafferty.,? 2004", "shortCiteRegEx": "Zhai and Lafferty.", "year": 2004}, {"title": "Evolutionary hierarchical dirichlet processes for multiple correlated time-varying corpora", "author": ["Jianwen Zhang", "Yangqiu Song", "Changshui Zhang", "Shixia Liu."], "venue": "Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data", "citeRegEx": "Zhang et al\\.,? 2010", "shortCiteRegEx": "Zhang et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "In early computational linguistics research it was primarily concerned with the fine-grained ordering of temporal events (Allen, 1983; Vilain, 1982).", "startOffset": 121, "endOffset": 148}, {"referenceID": 24, "context": "In early computational linguistics research it was primarily concerned with the fine-grained ordering of temporal events (Allen, 1983; Vilain, 1982).", "startOffset": 121, "endOffset": 148}, {"referenceID": 7, "context": "Information retrieval research has focused largely on timesensitive document ranking (Dakka et al., 2008; Li and Croft, 2003), temporal organization of search results (Alonso et al.", "startOffset": 85, "endOffset": 125}, {"referenceID": 17, "context": "Information retrieval research has focused largely on timesensitive document ranking (Dakka et al., 2008; Li and Croft, 2003), temporal organization of search results (Alonso et al.", "startOffset": 85, "endOffset": 125}, {"referenceID": 1, "context": ", 2008; Li and Croft, 2003), temporal organization of search results (Alonso et al., 2009), and how queries and documents change over time (Kulkarni et al.", "startOffset": 69, "endOffset": 90}, {"referenceID": 13, "context": ", 2009), and how queries and documents change over time (Kulkarni et al., 2011).", "startOffset": 56, "endOffset": 79}, {"referenceID": 1, "context": "poral expressions (Alonso et al., 2009), we investigate the feasibility of using text alone to assign timestamps to documents.", "startOffset": 18, "endOffset": 39}, {"referenceID": 12, "context": "Following previous document dating work (de Jong et al., 2005; Kanhabua and N\u00f8rv\u00e5g, 2008; Kumar et al., 2011), we construct supervised language models that capture the tempo-", "startOffset": 40, "endOffset": 109}, {"referenceID": 14, "context": "Following previous document dating work (de Jong et al., 2005; Kanhabua and N\u00f8rv\u00e5g, 2008; Kumar et al., 2011), we construct supervised language models that capture the tempo-", "startOffset": 40, "endOffset": 109}, {"referenceID": 12, "context": "This provides a ranking over chronons for the document, representing the document\u2019s likelihood of being similar to the time periods covered by each chronon (de Jong et al., 2005; Kanhabua and N\u00f8rv\u00e5g, 2008).", "startOffset": 156, "endOffset": 205}, {"referenceID": 23, "context": "Note that we use a robust temporal expression identifier for English, Heidel-Time (Str\u00f6tgen and Gertz, 2010), to identify and remove dates from all texts for both training and testing.", "startOffset": 82, "endOffset": 108}, {"referenceID": 4, "context": "While one could exploit a resource such as Heidel-Time to perform rule-based document dating (possibly in combination with our methods and others such as (Chambers, 2012)), this work demonstrates that text-based techniques can be used effectively for languages for which such temporal extraction resources are not available (Heidel-", "startOffset": 154, "endOffset": 170}, {"referenceID": 22, "context": "TimeBank (Pustejovsky et al., 2003) and Wikiwars (Mazur and Dale, 2010) were created to provide a common set of corpora for evaluating time-sensitive models.", "startOffset": 9, "endOffset": 35}, {"referenceID": 19, "context": ", 2003) and Wikiwars (Mazur and Dale, 2010) were created to provide a common set of corpora for evaluating time-sensitive models.", "startOffset": 21, "endOffset": 43}, {"referenceID": 19, "context": ", 2003) and Wikiwars (Mazur and Dale, 2010) were created to provide a common set of corpora for evaluating time-sensitive models. (2011) use the", "startOffset": 22, "endOffset": 137}, {"referenceID": 10, "context": "(Grishman et al., 2002) use semantic properties of web-data to create and automatically update a database on infectious disease outbreaks.", "startOffset": 0, "endOffset": 23}, {"referenceID": 29, "context": "and market sentiment (Zhang et al., 2010).", "startOffset": 21, "endOffset": 41}, {"referenceID": 2, "context": "Dynamic Topic Models (Blei and Lafferty, 2006) are used to analyze the evolution of topics over time in a large document collection (Wang et al.", "startOffset": 21, "endOffset": 46}, {"referenceID": 26, "context": "Dynamic Topic Models (Blei and Lafferty, 2006) are used to analyze the evolution of topics over time in a large document collection (Wang et al., 2008).", "startOffset": 132, "endOffset": 151}, {"referenceID": 29, "context": "(Zhang et al., 2010) provide clustering techniques for time varying text corpora through hierarchical Dirichlet processes for model-", "startOffset": 0, "endOffset": 20}, {"referenceID": 2, "context": "Dynamic Topic Models (Blei and Lafferty, 2006) are used to analyze the evolution of topics over time in a large document collection (Wang et al., 2008). (2006) analyse variations in topic occurrences over a large corpora for a fixed time period.", "startOffset": 22, "endOffset": 160}, {"referenceID": 2, "context": "Dynamic Topic Models (Blei and Lafferty, 2006) are used to analyze the evolution of topics over time in a large document collection (Wang et al., 2008). (2006) analyse variations in topic occurrences over a large corpora for a fixed time period. (2008) investigate the history of ideas in a research field though latent variable approaches.", "startOffset": 22, "endOffset": 253}, {"referenceID": 2, "context": "Dynamic Topic Models (Blei and Lafferty, 2006) are used to analyze the evolution of topics over time in a large document collection (Wang et al., 2008). (2006) analyse variations in topic occurrences over a large corpora for a fixed time period. (2008) investigate the history of ideas in a research field though latent variable approaches. (2007) use graphical models for temporal analysis of blogs and Zhang et al.", "startOffset": 22, "endOffset": 348}, {"referenceID": 17, "context": "time-sensitive query interpretation (Li and Croft, 2003; Dakka et al., 2008), time-based presentation of search results (Alonso et al.", "startOffset": 36, "endOffset": 76}, {"referenceID": 7, "context": "time-sensitive query interpretation (Li and Croft, 2003; Dakka et al., 2008), time-based presentation of search results (Alonso et al.", "startOffset": 36, "endOffset": 76}, {"referenceID": 1, "context": ", 2008), time-based presentation of search results (Alonso et al., 2009), and modelling query and document changes over time (Kulkarni et al.", "startOffset": 51, "endOffset": 72}, {"referenceID": 13, "context": ", 2009), and modelling query and document changes over time (Kulkarni et al., 2011).", "startOffset": 60, "endOffset": 83}, {"referenceID": 17, "context": "(Li and Croft, 2003), one of the early temporal language models, use explicit document dates to estimate a more informative document prior.", "startOffset": 0, "endOffset": 20}, {"referenceID": 17, "context": "(Li and Croft, 2003), one of the early temporal language models, use explicit document dates to estimate a more informative document prior. More recently, (2008) propose models for identifying important time intervals likely to be of interest for a", "startOffset": 1, "endOffset": 162}, {"referenceID": 12, "context": "These approaches (de Jong et al., 2005; Kanhabua and N\u00f8rv\u00e5g, 2008) normalize the evidence for each", "startOffset": 17, "endOffset": 66}, {"referenceID": 1, "context": "Our formalization most closely follows that of Alonso et al. (2009). The", "startOffset": 47, "endOffset": 68}, {"referenceID": 1, "context": "A chronon is an atomic interval x upon which a discrete timeline is constructed (Alonso et al., 2009).", "startOffset": 80, "endOffset": 101}, {"referenceID": 28, "context": "(Zhai and Lafferty, 2004), b) Dirichlet smoothing (Zhai and Lafferty, 2004), and c) chronon-specific smoothing (CS) (Kumar et al.", "startOffset": 0, "endOffset": 25}, {"referenceID": 28, "context": "(Zhai and Lafferty, 2004), b) Dirichlet smoothing (Zhai and Lafferty, 2004), and c) chronon-specific smoothing (CS) (Kumar et al.", "startOffset": 50, "endOffset": 75}, {"referenceID": 14, "context": "(Zhai and Lafferty, 2004), b) Dirichlet smoothing (Zhai and Lafferty, 2004), and c) chronon-specific smoothing (CS) (Kumar et al., 2011).", "startOffset": 116, "endOffset": 136}, {"referenceID": 15, "context": "The second approach ranks chronons based on the divergence between latent unigram distributions P (w|d) and P (w|x) (Lafferty and Zhai, 2001a).", "startOffset": 116, "endOffset": 142}, {"referenceID": 21, "context": "Ranking by document likelihood The language modeling approach for information retrieval was originally formulated as query-likelihood (Ponte and Croft, 1998).", "startOffset": 134, "endOffset": 157}, {"referenceID": 27, "context": "Ranking by model comparison Zhai and Lafferty (2001b) propose ranking via KL-divergence between a query and each collection document.", "startOffset": 28, "endOffset": 54}, {"referenceID": 14, "context": "Kumar et al. (2011) use this approach to compute P (x|d), which is estimated by computing the inverse KL-divergence of x and d and normalizing this value with the sum of inverse divergences with all chronons x1:n:", "startOffset": 0, "endOffset": 20}, {"referenceID": 12, "context": "rank equivalent to standard model comparison ranking with negative KL-divergence (de Jong et al., 2005; Kanhabua and N\u00f8rv\u00e5g, 2008):", "startOffset": 81, "endOffset": 130}, {"referenceID": 16, "context": "query-likelihood) assuming a uniform document prior and the query model being estimated by relative frequency (Lafferty and Zhai, 2001b).", "startOffset": 110, "endOffset": 136}, {"referenceID": 23, "context": "expressions identified in each document using the Heidel-Time temporal tagger (Str\u00f6tgen and Gertz, 2010) are removed.", "startOffset": 78, "endOffset": 104}, {"referenceID": 12, "context": "As in prior work (de Jong et al., 2005; Kanhabua and N\u00f8rv\u00e5g, 2008; Kumar et al., 2011), we smooth chronon pseudo-document language models (for all models as well as smoothing techniques) but not document models.", "startOffset": 17, "endOffset": 86}, {"referenceID": 14, "context": "As in prior work (de Jong et al., 2005; Kanhabua and N\u00f8rv\u00e5g, 2008; Kumar et al., 2011), we smooth chronon pseudo-document language models (for all models as well as smoothing techniques) but not document models.", "startOffset": 17, "endOffset": 86}, {"referenceID": 9, "context": "Similar distance error measures have also been used with document geolocation (Eisenstein et al., 2010; Wing and Baldridge, 2011).", "startOffset": 78, "endOffset": 129}, {"referenceID": 27, "context": "Similar distance error measures have also been used with document geolocation (Eisenstein et al., 2010; Wing and Baldridge, 2011).", "startOffset": 78, "endOffset": 129}, {"referenceID": 23, "context": "Baselines For Wikipedia biographies the first baseline (baseline-ht) is the mid-point of the first two temporal-dates extracted by HeidelTime (Str\u00f6tgen and Gertz, 2010).", "startOffset": 142, "endOffset": 168}, {"referenceID": 2, "context": "The predictions made by our models provide a natural counterpart to other temporally sensitive models of word choice, such as Dynamic Topic Models (DTMs) (Blei and Lafferty, 2006).", "startOffset": 154, "endOffset": 179}], "year": 2012, "abstractText": "This paper tackles temporal resolution of documents, such as determining when a document is about or when it was written, based only on its text. We apply techniques from information retrieval that predict dates via language models over a discretized timeline. Unlike most previous works, we rely solely on temporal cues implicit in the text. We consider both document-likelihood and divergence based techniques and several smoothing methods for both of them. Our best model predicts the mid-point of individuals\u2019 lives with a median of 22 and mean error of 36 years for Wikipedia biographies from 3800 B.C. to the present day. We also show that this approach works well when training on such biographies and predicting dates both for nonbiographical Wikipedia pages about specific years (500 B.C. to 2010 A.D.) and for publication dates of short stories (1798 to 2008). Together, our work shows that, even in absence of temporal extraction resources, it is possible to achieve remarkable temporal locality across a diverse set of texts.", "creator": "TeX"}}}