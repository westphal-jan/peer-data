{"id": "1211.2741", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2012", "title": "A Hindi Speech Actuated Computer Interface for Web Search", "abstract": "Aiming at increasing system simplicity and flexibility, an audio evoked based system was developed by integrating simplified headphone and user-friendly software design. This paper describes a Hindi Speech Actuated Computer Interface for Web search (HSACIWS), which accepts spoken queries in Hindi language and provides the search result on the screen. This system recognizes spoken queries by large vocabulary continuous speech recognition (LVCSR), retrieves relevant document by text retrieval, and provides the search result on the Web by the integration of the Web and the voice systems. The LVCSR in this system showed enough performance levels for speech with acoustic and language models derived from a query corpus with target contents.", "histories": [["v1", "Mon, 12 Nov 2012 19:17:34 GMT  (284kb)", "http://arxiv.org/abs/1211.2741v1", "7 pages"]], "COMMENTS": "7 pages", "reviews": [], "SUBJECTS": "cs.CL cs.HC cs.IR", "authors": ["kamlesh sharma", "s v a v prasad", "t v prasad"], "accepted": false, "id": "1211.2741"}, "pdf": {"name": "1211.2741.pdf", "metadata": {"source": "META", "title": "A Hindi Speech Actuated Computer Interface for Web Search", "authors": ["Kamlesh Sharma"], "emails": [], "sections": [{"heading": null, "text": "In fact, it is such that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is"}, {"heading": "A. Training Module", "text": "The audio signal was processed and features extracted, and the signal was smoothed by using various filters to form feature vectors that were periodically calculated, say every 10 to 20 milliseconds. Many feature types were used, including time and frequency masking, tasking of inverse Fourier transformations, resulting in a mathematical series whose coefficient was maintained as a feature vector. Characteristics were mathematically treated as vectors to simplify training and recognition calculation. Figure 4 describes an approach to building the system for reading the spoken words in a lexicon and a phonetic word model using the HMM derived from lexicon and phonetic notation. These HMM word models were iteratively compared with the training language. Training language was generated by these HMM word models, and grammar was created with the lexicon for individual phonetics."}, {"heading": "B. Speech Recognition Module", "text": "Recognition of an unknown language begins with extracting a feature and generating a feature vector for a particular language by using different vectors to create techniques discussed in the Training Module. Output of the feature vector was passed to the recognition component, as in Fig. 5. The recognition component of used HMM model sequences, which are allowed by grammar, was searched to find the word sequence in the word model with the highest probability of generating that particular sequence of feature vectors."}, {"heading": "C. Morphological Analyzer", "text": "In fact, it is a purely mental game, in which it is a question of finding a path to follow in order to walk it, to walk it, to walk it, to walk it, to walk it."}, {"heading": "A. Training and Testing Data Scenario for Experiments", "text": "In order to compare the effectiveness of the HSACIWS system against a scenario of really limited data pairs, a collection of training and test data was created for the HSACIWS system, which contained extremely limited amounts of data; the training and test data were extracted from urban and semi-urban areas of India, which were collected through questionnaires, templates and face-to-face conversations; the large amount of data was collected through questionnaires, in which users were asked about various questions for which the system could train and test; the limited data consisted of the following resources: a. Data Corpus: The database contains 478 verbatim phrases and sentences of the user in urban and semi151 | P a g ewww.ijacsa.thesai.orgurban areas. This data collection includes both the training and test phrases as well as sentences. b Small Hindi phrases of the Hindi lexicon: The database contains 2390 Hindi-translation from the Spediology Database to the English version of the Hindi dictionary. \""}, {"heading": "B. Experimental Testing", "text": "The HMM Toolkit was not used in this experiment. A set of 100 sets were randomly selected from the set of 478 training sets to retrieve the result accordingly and show the user. Users were not trained or provided any information. Initially, the experiment is performed on advance queries. HSACIWS performance was calculated by using the percentage performance formula Accuracy, which is defined as Accuracy =, and the user is calculated the total number of sets in the test sets, the number of substitution errors, and deletion errors in the interaction with the system."}], "references": [{"title": "Speech Interface for search Engine\u201d.United state patent, Jun", "author": ["Michael D. Goller", "Stuart E Goller"], "venue": "shett", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Automated set up of webbased", "author": ["Frederick J. Damerau", "David E. Johnson"], "venue": "Naturel Language Interface, U S Patent, Jun", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Grammar Representation Requirements for voice markup Langauge", "author": ["M.K. Brown"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "A Brain Actuated Human Computer Interface for Google Search", "author": ["Honglai Xu", "Tianyi Qian", "Bo Hong", "Xiaorong Gao", "Shangkai Gao"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Kubesch, Speech Recognition Method for Activating a hyperlink of an Internet page, US patent 3 Aug", "author": ["Matrin Holley", "Dieter"], "venue": "International Journal of Advanced Computer Science and Applications,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Voice Operated Guidance Systems for Vision Impaired People: Investigating a User- Centered Open Source Model in International", "author": ["Bruce Moulton", "Gauri Pradhan", "Zenon Chaczko"], "venue": "Journal of Digital Content Technology and its Applications,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Speech at the Interface", "author": ["Cameron", "Hugh"], "venue": "Proceedings of the Cost249 Workshop on Speech in Telephone Networks,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "BrailleSurf: An HTML Browser for visually handicapped people", "author": ["Hadjadj", "Djamel", "Dominique Burger"], "venue": "In Proc. of 14th conference on \"Technology and Persons with Disabilities\u201d, Los Angeles,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Homer \u2013 A Small Self Voicing Web Browser for Blind People Laboratory of Artificial Perception, Systems and Cybernetics", "author": ["Mihelic", "France", "Nikola Pavesic", "Simon Dobrisek", "Jerneja Gros", "Bostjan Vesnicer", "Janez Zibert"], "venue": "Faculty of Electrical Engineering,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Considerations in Producing a Commercial Voice Browser", "author": ["Robin", "Michael B", "Charles T. Hemphill"], "venue": "W3C WS on \u201cVoice Browsers\u201d. Massachusetts,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "[2]", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[3]", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "It is used in many fields like automatic speech recognition directory, military, defense, medical science, bio-informatics, home automation systems, word processing system, dictation system, embedded systems, query processing and many more systems developed for handicapped persons [7].", "startOffset": 282, "endOffset": 285}, {"referenceID": 6, "context": "[9]", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "HMM [5] was used for representing speech units.", "startOffset": 4, "endOffset": 7}, {"referenceID": 4, "context": "Initialisation of emission probability densities of HMM states using a segmented and labelled speech database [6] should lead to better models.", "startOffset": 110, "endOffset": 113}, {"referenceID": 7, "context": "3 or (b) employing a data filtering algorithm to get the actual results [10].", "startOffset": 72, "endOffset": 76}, {"referenceID": 5, "context": "The user can activate the hyperlink number module by providing visual number to the module [7].", "startOffset": 91, "endOffset": 94}, {"referenceID": 2, "context": "[4]", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[11]", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[12]", "startOffset": 0, "endOffset": 4}], "year": 2012, "abstractText": "Aiming at increasing system simplicity and flexibility, an audio evoked based system was developed by integrating simplified headphone and user-friendly software design. This paper describes a Hindi Speech Actuated Computer Interface for Web search (HSACIWS), which accepts spoken queries in Hindi language and provides the search result on the screen. This system recognizes spoken queries by large vocabulary continuous speech recognition (LVCSR), retrieves relevant document by text retrieval, and provides the search result on the Web by the integration of the Web and the voice systems. The LVCSR in this system showed enough performance levels for speech with acoustic and language models derived from a query corpus with target contents. KeywordsWeb search; Hindi speech; HSACIWS; computer interface; human computer interaction.", "creator": "Microsoft\u00ae Office Word 2007"}}}