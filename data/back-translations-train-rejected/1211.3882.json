{"id": "1211.3882", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Nov-2012", "title": "Gliders2012: Development and Competition Results", "abstract": "The RoboCup 2D Simulation League incorporates several challenging features, setting a benchmark for Artificial Intelligence (AI). In this paper we describe some of the ideas and tools around the development of our team, Gliders2012. In our description, we focus on the evaluation function as one of our central mechanisms for action selection. We also point to a new framework for watching log files in a web browser that we release for use and further development by the RoboCup community. Finally, we also summarize results of the group and final matches we played during RoboCup 2012, with Gliders2012 finishing 4th out of 19 teams.", "histories": [["v1", "Fri, 16 Nov 2012 13:20:59 GMT  (121kb,D)", "https://arxiv.org/abs/1211.3882v1", null], ["v2", "Wed, 21 Nov 2012 04:03:21 GMT  (121kb,D)", "http://arxiv.org/abs/1211.3882v2", "10 pages"]], "reviews": [], "SUBJECTS": "cs.AI cs.MA cs.RO", "authors": ["edward moore", "oliver obst", "mikhail prokopenko", "peter wang", "jason held"], "accepted": false, "id": "1211.3882"}, "pdf": {"name": "1211.3882.pdf", "metadata": {"source": "CRF", "title": "Gliders2012: Development and Competition Results", "authors": ["Edward Moore", "Oliver Obst", "Mikhail Prokopenko", "Peter Wang", "Jason Held"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, it is as if most of them are able to play by the rules that they have imposed on themselves. (...) In fact, it is as if they are able to outdo themselves. (...) In fact, it is as if they are able to outdo themselves. (...) It is as if they are able to outdo themselves. (...) It is as if they are able to outdo themselves. (...) It is as if they are able to outdo themselves. (...). (...) It is as if they are able to outdo themselves. (...). (...) It is as if they are able to outdo themselves. (...) It is as if they are able. (...) It is as if they are. (...). (...) It is as if they are in. (...) It is as if they are in. (...)."}, {"heading": "2 Motivation and approach", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Chess analogy", "text": "As Larame \u0301 e argues, in chess \"the evaluation function is unique in a very real sense: while search techniques are fairly universal and move generation can be derived from the rules of the game and no longer, the evaluation requires a deep and thorough analysis of the strategy.\" [11] He lists several evaluation criteria for the main board: material balance (an account in which pieces are on the board for each side), agility (a measure of how many move options are available, especially for powerful chess pieces), board control (one side controls a square when it has more pieces attacking it than the opponent), development (smaller pieces should be brought into play as quickly as possible), pawn formations, royal security and trope (a measure of how easy it is for a character to attack the opposing king; normally measured at a distance). Some parallels can be drawn with the RoboCup simulation, with goal safety and distances to the opposing gate analogous to safety and trope."}, {"heading": "2.2 Basic evaluation", "text": "The evaluation function of agent2D, however, is quite simple. On the basis of the chess analogy, it merely implements tropism and is intended to get the basic client to play goal-oriented. For a player controlling the ball, it takes into account two features of each possible resulting state: its X coordinate (the greater, the better) and the distance from it to the opponent's target (the smaller, the better). That is, the opponent's target is the ultimately desirable resulting state S, and each action a is evaluated using a single distance metric Dr (a) = D (s = result (a), S). (1) The selected action is simply the one that minimizes the distance between resulting and desirable states, i.e. it minimizes this measurement: a = arg min a r (a). (2) For players who are not controlling the ball and tactically active, the evaluation function is not explicitly specified, i.e. this measurement is a = min arg a (a) (a)."}, {"heading": "2.3 Multiple desirable states: tactics", "text": "This means that not only do we want the state to be able to change from one cycle to another, but we also want a player to have several desirable states at a given time (cycle), this variety is caused by different tactics, and another player can consider a desirable state if he goes to the left (action a1), each of which is evaluated against the corresponding desirable state that is led to the right (action a2). In other words, there are a number of tactics represented by a number of desirable states: {action a3)."}, {"heading": "2.4 Mobility and field control", "text": "The functional tactic implements the mobility aspect of the evaluation by diversifying the options of the player who controls the ball in order to continue the game. Other teammates can also use this function to select a desirable state for their positioning, i.e. a player who chooses a position on the field does not need to have a single best point given the current state. He can consider several points, each of which again depends on the action. For example, the player can consider the state (point) S1 when moving to the left wing with the action a1, and the state (point) S2 when blocking a next opponent with the action a2. Each of the resulting states s1 = result (a1) and s2 = result (a2) are compared with the corresponding desirable states suggested by the tactic S1 and S2, and the action that achieves the best proximity to the metric D. The diversification of the key points of the positioning is achieved by allowing both the mobility (and the mobility)."}, {"heading": "2.5 Example", "text": "Figure 1 illustrates the concept of action-based evaluation. The player controlling the ball (left team, number 11) has several options: he can dribble in a general forward-facing left direction, pass to teammates 7 and 10 (in various ways, including direct and lead passes), etc. We will consider three options (represented by arrows): dribble forward-left, pass to left to teammate 7 and pass to right to teammate 10. Instead, the new evaluation function of agent2d identifies two desirable states, represented by a small rectangle to the left of player 11, and a small circle to the right. The rectangle defines the tactical approach to develop an attack to the left and through the middle, and the circle corresponds to the tactical approach, with the dribbling to the right of player 11 and the small circle to the right of the group (the first pass to the second and the second to the tactical approach)."}, {"heading": "3 Development and Results", "text": "The proposed approach was implemented in Gliders2012 - a new team based on agent2d [1]. We conducted several iterative experiments, some of the most important tools for development being a set of scripts to automate running tournaments, and the average results of such a tournament are a useful indicator of whether a proposed change in the team is really helpful or potentially impairs performance. Often, it is helpful to briefly observe some of the games stored on the simulation server. To make these games available for viewing via the web browser, the current solution is to convert them to Flash format (SWF), even though the source code for this program is available [9], a required library to create SWF files that are no longer distributed."}, {"heading": "3.1 Results at RoboCup 2012", "text": "The tournament was played over several rounds, in which Gliders2012 reached the semifinals, resulting in a 4th place. Our detailed results are as follows: seeding round (round 0) A seeding round was played, with the 18 participating teams spread over 4 groups of 4 or 5 teams. The results of these groups were used to make all teams fairer for the following round 1.Gliders2012 were assigned to Group C with 4 other teams: GPR-2D (Brazil), MarIik (Iran), AUT 2D (Iran), and Riton (also Iran). Gliders2012 ended the seeding table with a tie against MarIik, and all other games won (Table 1).Round 1 All teams were played in Round 1."}, {"heading": "4 Conclusion", "text": "We have described a novel mechanism that uses action-based evaluation functions after applying it in the RoboCup 2D simulation, a mechanism that can be compared to some well-known constructive models used by belief revision and belief updating. [14] The approach also allowed us to draw parallels with the evaluation functions used by chess computers in terms of mobility, field control, tropism, etc. The evaluation function, which varies desirable states depending on considered actions, is applicable in both ball control and positioning scenarios. Tactics that correspond to several desirable states are not imposed from top to bottom, but contribute to the evaluation of these desirable states. Our proposed approach and its implementation have proven successful both in many experiments and during the competitions. The authors are Valentina Cupac, Andrew Curline, Tim D'Adam, Ivan Nong, and Tom Stewart grateful for their contribution."}], "references": [{"title": "Multi-agent positioning mechanism in the dynamic environment", "author": ["Hidehisa Akiyama", "Itsuki Noda"], "venue": "RoboCup 2007: Robot Soccer World Cup XI,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Helios2010 team description", "author": ["Hidehisa Akiyama", "Hiroki Shimora"], "venue": "In RoboCup 2010: Robot Soccer World Cup XIV,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "RoboCup: Today and tomorrow \u2013 What we have have learned", "author": ["Minoru Asada", "Hiroaki Kitano", "Itsuki Noda", "Manuela Veloso"], "venue": "Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "Wrighteagle and ut austin villa: Robocup 2011 simulation league champions", "author": ["Aijun Bai", "Xiaoping Chen", "Patrick MacAlpine", "Daniel Urieli", "Samuel Barrett", "Peter Stone"], "venue": "In RoboCup 2011: Robot Soccer World Cup XV, Lecture Notes in Artificial Intelligence. Springer,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Flexible synchronisation within RoboCup environment: A comparative analysis", "author": ["Marc Butler", "Mikhail Prokopenko", "Thomas Howard"], "venue": "In RoboCup 2000: Robot Soccer World Cup IV,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Users Manual: RoboCup Soccer Server \u2014 for Soccer Server Version 7.07 and Later", "author": ["Mao Chen", "Klaus Dorer", "Ehsan Foroughi", "Fredrick Heintz", "ZhanXiang Huang", "Spiros Kapetanakis", "Kostas Kostiadis", "Johan Kummeneje", "Jan Murray", "Itsuki Noda", "Oliver Obst", "Pat Riley", "Timo Steffens", "Yi Wang", "Xiang Yin"], "venue": "The RoboCup Federation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Computers in Sport, chapter Approaching a Formal Soccer Theory from the Behavior Specification in Robotic Soccer, pages 161\u2013186", "author": ["Frank Dylla", "Alexander Ferrein", "Gerhard Lakemeyer", "Jan Murray", "Oliver Obst", "Thomas R\u00f6fer", "Stefan Schiffer", "Frieder Stolzenburg", "Ubbo Visser", "Thomas Wagner"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "robocup2flash version 0.3", "author": ["Thilo Girmann", "Oliver Obst"], "venue": "http://robolog.cvs. sourceforge.net/viewvc/robolog/robocup2flash/,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "The RoboCup Synthetic Agent Challenge 97", "author": ["Hiroaki Kitano", "Milind Tambe", "Peter Stone", "Manuela M. Veloso", "Silvia Coradeschi", "Eiichi Osawa", "Hitoshi Matsubara", "Itsuki Noda", "Minoru Asada"], "venue": "Robot Soccer World Cup I,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Chess Programming Part VI: Evaluation Functions", "author": ["Fran\u00e7ois Dominic Laram\u00e9e"], "venue": "http://www.gamedev.net/page/resources/_/technical/artificial-intelligence/ chess-programming-part-vi-evaluation-functions-r1208,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "The RoboCup Soccer Server and CMUnited Clients: Implemented Infrastructure for MAS Research", "author": ["Itsuki Noda", "Peter Stone"], "venue": "Autonomous Agents and Multi-Agent Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Flexible coordination of multiagent team behavior using HTN planning", "author": ["Oliver Obst", "Joschka Boedecker"], "venue": "RoboCup 2005: Robot Soccer World Cup IX, Lecture Notes in Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Revision vs. update: Taking a closer look", "author": ["Pavlos Peppas", "Abhaya C. Nayak", "Maurice Pagnucco", "Norman Y. Foo", "Rex Bing Hung Kwok", "Mikhail Prokopenko"], "venue": "12th European Conference on Artificial Intelligence, Budapest,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1996}, {"title": "Gliders2012: Tactics with action-dependent evaluation functions", "author": ["Mikhail Prokopenko", "Oliver Obst", "Peter Wang", "Jason Held"], "venue": "In RoboCup 2012:", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Relating the entropy of joint beliefs to multi-agent coordination", "author": ["Mikhail Prokopenko", "Peter Wang"], "venue": "RoboCup 2002: Robot Soccer World Cup VI,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2003}, {"title": "Evaluating team performance at the edge of chaos", "author": ["Mikhail Prokopenko", "Peter Wang"], "venue": "RoboCup 2003: Robot Soccer World Cup VII,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "Situation based strategic positioning for coordinating a team of homogeneous agents", "author": ["L\u00fa\u0131s Paulo Reis", "Nuno Lau", "Eugenio Oliveira"], "venue": "Workshop and additional contributions),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2000}, {"title": "Layered disclosure: Revealing agents\u2019 internals", "author": ["Patrick Riley", "Peter Stone", "Manuela Veloso"], "venue": "International Workshop,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2000}, {"title": "Defining and using ideal teammate and opponent models", "author": ["Peter Stone", "Patrick Riley", "Manuela Veloso"], "venue": "In Proceedings of the Twelfth Annual Conference on Innovative Applications of Artificial Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2000}, {"title": "Task decomposition, dynamic role assignment, and lowbandwidth communication for real-time strategic teamwork", "author": ["Peter Stone", "Manuela Veloso"], "venue": "Artificial Intelligence,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1999}, {"title": "Team-partitioned, opaque-transition reinforced learning", "author": ["Peter Stone", "Manuela M. Veloso"], "venue": "Robot Soccer World Cup II,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1999}], "referenceMentions": [{"referenceID": 8, "context": "The RoboCup Simulation League [10] incorporates several challenging features, setting a benchmark for Artificial Intelligence (AI).", "startOffset": 30, "endOffset": 34}, {"referenceID": 10, "context": "\u2013 distributed client/server system running on a network, leading to fragmented, localized and imprecise (noisy and latent) information about the environment (field) [12]; \u2013 concurrent communication with a medium-sized number of agents [21]; \u2013 heterogeneous sensory data (visual, auditory, kinetic) and limited range of basic commands/effectors (turn, kick, dash, .", "startOffset": 165, "endOffset": 169}, {"referenceID": 19, "context": "\u2013 distributed client/server system running on a network, leading to fragmented, localized and imprecise (noisy and latent) information about the environment (field) [12]; \u2013 concurrent communication with a medium-sized number of agents [21]; \u2013 heterogeneous sensory data (visual, auditory, kinetic) and limited range of basic commands/effectors (turn, kick, dash, .", "startOffset": 235, "endOffset": 239}, {"referenceID": 17, "context": ") [19]; \u2013 asynchronous perception-action activity and limited window of opportunity to perform an action [6]; \u2013 autonomous decision-making under constraints enforced by teamwork (collaboration) and opponent (competition) [20]; \u2013 conflicts between reactivity and deliberation [18]; \u2013 no centralized controllers and centralized world model (no global vision, etc.", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": ") [19]; \u2013 asynchronous perception-action activity and limited window of opportunity to perform an action [6]; \u2013 autonomous decision-making under constraints enforced by teamwork (collaboration) and opponent (competition) [20]; \u2013 conflicts between reactivity and deliberation [18]; \u2013 no centralized controllers and centralized world model (no global vision, etc.", "startOffset": 105, "endOffset": 108}, {"referenceID": 18, "context": ") [19]; \u2013 asynchronous perception-action activity and limited window of opportunity to perform an action [6]; \u2013 autonomous decision-making under constraints enforced by teamwork (collaboration) and opponent (competition) [20]; \u2013 conflicts between reactivity and deliberation [18]; \u2013 no centralized controllers and centralized world model (no global vision, etc.", "startOffset": 221, "endOffset": 225}, {"referenceID": 16, "context": ") [19]; \u2013 asynchronous perception-action activity and limited window of opportunity to perform an action [6]; \u2013 autonomous decision-making under constraints enforced by teamwork (collaboration) and opponent (competition) [20]; \u2013 conflicts between reactivity and deliberation [18]; \u2013 no centralized controllers and centralized world model (no global vision, etc.", "startOffset": 275, "endOffset": 279}, {"referenceID": 14, "context": ") [16,17].", "startOffset": 2, "endOffset": 9}, {"referenceID": 15, "context": ") [16,17].", "startOffset": 2, "endOffset": 9}, {"referenceID": 2, "context": "[4], chess and RoboCup differ in a few key elements: environment (static vs dynamic), state change (turn-taking vs real-time), information accessibility (complete vs incomplete), sensor readings (symbolic vs non-symbolic), and control (central vs distributed).", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "One may argue that superior performance of recent world champions in the RoboCup 2D Simulation League [3,5] may be attributed, at least partially, to sophisticated evaluation functions employed by these teams.", "startOffset": 102, "endOffset": 107}, {"referenceID": 3, "context": "One may argue that superior performance of recent world champions in the RoboCup 2D Simulation League [3,5] may be attributed, at least partially, to sophisticated evaluation functions employed by these teams.", "startOffset": 102, "endOffset": 107}, {"referenceID": 12, "context": "In this short paper we describe a novel mechanism utilizing action-dependent evaluation functions, comparing it to some well known constructive models used by belief revision and belief update [14].", "startOffset": 193, "endOffset": 197}, {"referenceID": 5, "context": "The experiments are carried out using a new simulated soccer team for the RoboCup soccer 2D simulator [7], Gliders2012.", "startOffset": 102, "endOffset": 105}, {"referenceID": 9, "context": "As argued by Laram\u00e9e, in chess \u201cthe evaluation function, is unique in a very real sense: while search techniques are pretty much universal and move generation can be deducted from a game\u2019s rules and no more, evaluation requires a deep and thorough analysis of strategy\u201d [11].", "startOffset": 270, "endOffset": 274}, {"referenceID": 13, "context": "Moreover, we suggested [15] not only that the most desirable state can change from one cycle to another, but also that a player may entertain multiple desirable states at any given time (cycle).", "startOffset": 23, "endOffset": 27}, {"referenceID": 20, "context": ", with actiondependent features generalizing state space proposed by Stone and Veloso [22].", "startOffset": 86, "endOffset": 90}, {"referenceID": 12, "context": "Another interesting point is the analogy between multiple desirable states unified by the proposed evaluation function and the constructive model for belief update and belief revision [14].", "startOffset": 184, "endOffset": 188}, {"referenceID": 12, "context": "[14] have shown that the model for belief update uses multiple systems of spheres (one for each possible world), finds in parallel the spheres consistent with the new data that are nearest to their respective central possible worlds, and collects possible worlds within these spheres.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "They suggested to use Voronoi diagrams: a Voronoi diagram is the partitioning of a plane with n points into n convex polygons such that each polygon contains exactly one point and every point in the given polygon is closer to its central point than any other [8].", "startOffset": 259, "endOffset": 262}, {"referenceID": 0, "context": "who used a dual representation of Voronoi diagrams \u2014 the Delaunay triangulation [2,3].", "startOffset": 80, "endOffset": 85}, {"referenceID": 1, "context": "who used a dual representation of Voronoi diagrams \u2014 the Delaunay triangulation [2,3].", "startOffset": 80, "endOffset": 85}, {"referenceID": 7, "context": "Even though source code for this program is available [9], a required library to create SWF files is proprietary and not anymore distributed.", "startOffset": 54, "endOffset": 57}, {"referenceID": 12, "context": "The mechanism can be contrasted with some well known constructive models used by belief revision and belief update [14].", "startOffset": 115, "endOffset": 119}, {"referenceID": 15, "context": ", [17,13]) is not used in Gliders2012.", "startOffset": 2, "endOffset": 9}, {"referenceID": 11, "context": ", [17,13]) is not used in Gliders2012.", "startOffset": 2, "endOffset": 9}], "year": 2012, "abstractText": "The RoboCup 2D Simulation League incorporates several challenging features, setting a benchmark for Artificial Intelligence (AI). In this paper we describe some of the ideas and tools around the development of our team, Gliders2012. In our description, we focus on the evaluation function as one of our central mechanisms for action selection. We also point to a new framework for watching log files in a web browser that we release for use and further development by the RoboCup community. Finally, we also summarize results of the group and final matches we played during RoboCup 2012, with Gliders2012 finishing 4th out of 19 teams.", "creator": "LaTeX with hyperref package"}}}