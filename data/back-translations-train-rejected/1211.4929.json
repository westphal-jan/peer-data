{"id": "1211.4929", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Nov-2012", "title": "Summarizing Reviews with Variable-length Syntactic Patterns and Topic Models", "abstract": "We present a novel summarization framework for reviews of products and services by selecting informative and concise text segments from the reviews. Our method consists of two major steps. First, we identify five frequently occurring variable-length syntactic patterns and use them to extract candidate segments. Then we use the output of a joint generative sentiment topic model to filter out the non-informative segments. We verify the proposed method with quantitative and qualitative experiments. In a quantitative study, our approach outperforms previous methods in producing informative segments and summaries that capture aspects of products and services as expressed in the user-generated pros and cons lists. Our user study with ninety users resonates with this result: individual segments extracted and filtered by our method are rated as more useful by users compared to previous approaches by users.", "histories": [["v1", "Wed, 21 Nov 2012 03:59:06 GMT  (266kb,D)", "http://arxiv.org/abs/1211.4929v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["trung v nguyen", "alice h oh"], "accepted": false, "id": "1211.4929"}, "pdf": {"name": "1211.4929.pdf", "metadata": {"source": "CRF", "title": "Summarizing Reviews with Variable-length Syntactic Patterns and Topic Models", "authors": ["Trung Nguyen", "Alice Oh"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "It is only a matter of time before we will be able to find a solution to this problem; it is only a matter of time before it is resolved."}, {"heading": "2 Related work", "text": "We see how excerpts of texts are applied in existing literature. Previous studies have produced an associative summary of products and services, using subjective excerpts of texts relating to each individual aspect. Different forms of excerpts contain a sentence [8] that is limited to a single sentence."}, {"heading": "3 A Topic Model for Learning Polarity of Sentiment Lexicons", "text": "Our central modelling assumption for reviews is that a sentence through its sentiment component expresses an opinion on an aspect. In the sentence \"The service was excellent,\" for example, only the word \"excellent\" carries the positive sentiment. This is not a new assumption, since adjectives and adverbs are commonly considered the most important source of sentiment in a sentence in the existing literature. Our model uses this kind of knowledge to locate sentiment words in a sentence with relatively high certainty."}, {"heading": "3.1 Generative Process", "text": "The formal generation process of our graphical representation model in Fig. 1 is as follows (see Table 1 for the list of notations): - Draw for each aspect k a distribution of non-sentiment words, \u03c6k \u0445 Dir (\u03b2), and two distributions of sentiment words, \u03c6 \u2032 jk (\u03b2 \u2032 jk), where j = 0 denotes positive polarity and j = 1 negative polarity. - Draw for each report d, draw a sentiment distribution of sentiment words \u03c0d \u0445 Dir (\u03b3) Draw for each sentence c in document d, - Choose a topic z = k \u0445 Mult (\u03c0d) and a sentiment s = j \u0445 Mult (\u03c0d) - Choose words to discuss aspect and sentiment words."}, {"heading": "3.2 Inference", "text": "The sampler assigns values for the latent variables: the themes and sensations of the sentences. Using a collapsed Gibbs sampler [7], new values for the topic and sensation of a sentence c in document d are drawn from the conditional probability number (zdc = k, sdc = j | rest) in document A (dc) (n TW\\ ki + \u03b2) in document A (dc)."}, {"heading": "3.3 Aspect and Sentiment Classification Using Output of the Model", "text": "As explained in the introduction, we try to use the results of this model to improve the selection of informative segments for summary. We define the subject classifier of any segment of n words G = (w1, w2,..., wn) asarg max k p (k | G) = arg max k wn \u2211 i = w1 (log? ki + Java log? jki). (6) To classify the mood of a segment G, we use the mood value yji learned from the model. We define the polarity of G aspolarity (G): = \u2211 mood word i-G polarity (i) = \u2211 mood word i-G y0i \u2212 y1i. (7) G is classified as positive if polarity (G) > = 0 and negative if polarity (G) < 0."}, {"heading": "4 Summarization Using Syntactic Patterns and Topic Models", "text": "In this section, we present our framework for the segment-based summary of variable-length reviews. First, we describe the five common syntatic patterns in reviews that extract text segments from candidates. Then, we discuss the use of topic models in selecting meaningful segments from the group of extracted candidates. In addition, we present an independent framework to evaluate the summaries that comprise segments regardless of approaches."}, {"heading": "4.1 Extraction Patterns", "text": "We use sentence syntax to guide the extraction process by defining patterns of lexical classes for matching with text segments. The purpose is to extract semantically significant text units in a sentence that can be understood without additional context. In the particular task of summarizing product and service ratings, we want to capture units that contain perceptions of aspects. This type of segment is important because it expresses and formulates opinions about the object under test. Based on the above observation, we identify five most common extraction patterns to capture a variety of text segments in product and service ratings as follows. First, we use POS taggers to highlight all the advantages and disadvantages available in our datasets of restaurant and coffee machine ratings (see Section 5.1). The advantages and disadvantages are relatively short and significant, and therefore cannot be suitable representatives of the text segments we want to include in the summaries of the categories we generate most frequently from their occurring sequences."}, {"heading": "4.2 Selecting Informative Segments using Topic Models", "text": "For example, \"closing thoughts\" and \"several hours\" are cases of pattern 5, but they do not disclose interesting information. In addition, the sheer number of text segments that match the patterns requires us to be selective in searching for segments that are included in summaries. We observe that informative segments often contain words that convey opinions about aspects of units. As the aspect-sentiment intimacy context is modeled and learned through our common sentimental topic model, we suggest the following filters to edit less informative segments, with the results not filtered, i.e., all matching segments are mapped. AW Eliminate a segment if it does not contain one of the most likely words in the segment. SW Eliminate Eliminate a segment that makes a segment less informative."}, {"heading": "4.3 A Framework for Segment-based Summary Evaluation", "text": "We are now introducing a framework for automatic evaluation of extraction patterns at segment and unit levels (a specific product or service). (This framework is independent of the way segments are generated and can therefore be applied to any method that uses segment as a unit of the summary. Each company E has a candidate overview EC = {Y | Y corresponds to one of the samples} and a reference overview ER = {X | X} X is in the gold standard summary of E}. (For Y-EC and X-ER, we measure the similarity of their content using precision and RecallP (X, Y): = skip2 (X, Y) (X, Y), R (X, Y): = skip2 (X, Y): = skip2 (X, Y) (X, Y) (X, Y) is the number of Skip Bigram matches between X and Y (denotes ROUGE-SU in [12])."}, {"heading": "5 Experiments", "text": "We experimented with evaluations of coffee machines as representative of the product domain and evaluations of restaurants as representative of the service domain. We describe our data sets and experimental setups in 5.1. In 5.2 we give an example of the topics and sentiment words learned through the model. We analyze the effectiveness of extraction patterns in 5.3 and compare the performance of different sentiment classifiers and segment filters in 5.4."}, {"heading": "5.1 Data Sets and Experimental Set-ups", "text": "For each review, we collected their free-format text content and their pros and cons, if available. - RESTAURANTS 50,000 reviews of 5,532 restaurants collected by Citysearch New York. These data are provided by Ganu, et al. [6]. - COFFEEMAKERS 23,411 reviews of 534 coffee machines collected by epinions.com. Our first step is to adapt the common sentiment theme model to each data set. As in other standard topic models, the data is pre-processed in which sentences are marked by punctuations: \",!\" and \"?.\" Hyperparameters are set as \u03b1 = 0.1, \u03b2 = 0.1 for both positive and negative feelings. The number of aspects is 7 for both companies. We integrated prior sentiment information into the model with Sentiments in Analogy 9."}, {"heading": "5.2 Topics and Polarities of Sentiment Words Learned by the Model", "text": "Each topic has three distributions, with one distribution (first column) consisting of descriptive words about the aspect and two distributions (remaining columns) consisting of evaluating words that guide the aspect. Apart from the usual sentiment words such as good, big, bad, wrong, which are associated with most aspects due to their frequent use, positive and negative sentiment lexicographs strongly relate to their respective aspects. For example, the model shows that people are more likely to reject food with tasty, best, fresh and tasty praise and dry, tasteless, cold or soggy food. Such results can be very helpful for the research purpose of understanding which aspects the reviewers care and comment on. Table 4 shows the effectiveness of our model in learning the polarities of domain-specific sentiment lexicographs (the seeds used for bootstrapping can be very helpful)."}, {"heading": "5.3 Evaluation of Extraction Patterns", "text": "We are now analyzing how different extraction patterns behave when applied to the service domain and the product domain (Tables 5 and 6). We are using the AW + SEN + SW method because it has yielded the best result of all methods. Patterns 3 and 5 are the most productive in restaurant reviews with superior average accuracy and recall at both the segment and entity levels compared to the rest. They account for more than half of the pros and cons of an entity. It is noteworthy that the extraction of sentences such as \"the service was good\" in restaurant reviews may affect the quality of the summary, as the values for pattern 2 and 4 are overwhelmingly low, where adjectives and nouns are commonly used to detect feelings and aspects in service reviews. It is noteworthy that extraction of anything other than adjective-noun pairs may affect the quality of the summary, as the values for pattern 2 and 4 are overwhelmingly low, but the behavior of extraction patterns at both the 6th level of the product pattern is not the highest in a large pattern domain."}, {"heading": "5.4 Evaluation of Sentiment Classifiers and Segment Filters", "text": "The results in the previous section suggest using different syntactical patterns to summarize the service and product domains. We used patterns 1, 3 and 5 for services and all patterns for products in all of our experiments in this paragraph.The results are shown in Tables 7 and 8. The good overall performance of the Baseline + SWN process in both areas indicates that the proposed patterns extract good segments for the summary. Comparing AW + SWN and AW + SEN, we see that SEN is better at sentiment classification than SWN. This result is consistent with the previous section and reaffirms the effectiveness of our model in terms of learning domain-specific lexicographics."}, {"heading": "6 Qualitative Evaluation", "text": "In this section, we supplement our results in the previous section by qualitatively evaluating the quality of the extracted segments with a user study and presenting examples of summaries generated by our approach."}, {"heading": "6.1 Quality of Extracted Segments", "text": "We conducted a user study with 130 employees of the Amazon Mechanical Turk service. We randomly selected 123 short passages, each containing 4 to 6 sentences from coffee maker ratings. The user's task is to read a passage and rate each passage as \"very useful,\" \"useful,\" \"reasonably useful\" or \"useless\" in terms of the passage. We added two types of elements for each passage: segments extracted through our approach using the AW filter, and adjective-noun phrases extracted using markers and term frequency, as in [23]. Each user performs 6 tasks, half of which are repetitions of others, allowing us to recognize users who give inconsistent ratings."}, {"heading": "6.2 Example Summaries", "text": "Below we show examples of a restaurant review and a coffee machine review along with the segments that were extracted as summaries. Restaurant review: The room is small but cozy, and the staff is friendly and knowledgeable. Some great music was played that made me feel like I was on vacation somewhere far away from Astoria. There are a lot of really great vegetarian options as well as several authentic Turkish dishes, really great vegetarian options. Coffee machine review: I bought this machine about a week ago and went straight to Mundo. Your stomach could already be filled with tons of delicacies. Summary: The staff is friendly, the room is small, some great music is playing, several authentic Turkish dishes, really great vegetarian options. Coffee machine review: I didn't know which machine to get in store, but the saleswoman helped me make the decision to buy this segment. It's incredibly easy to handle and the coffee machine is so perfect."}, {"heading": "7 Conclusions", "text": "In this paper, we describe a framework for extracting and selecting informative segments to summarize products and services. We extract candidate segments by matching them with syntactic patterns of varying lengths, and select the segments that contain top sentimental and aspect words learned through theme models. We proposed a new common sentiment theme model that learns the polarity of aspect-dependent sentiment lexicographs. Qualitative and quantitative experiments confirm that our model surpasses previous approaches to improving the quality of extracted segments as well as the summaries generated."}], "references": [{"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "J. Mach. Learn. Res., 3:993\u20131022, Mar.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Old wine or warm beer: Target-specific sentiment analysis of adjectives", "author": ["A. Fahrni", "M. Klenner"], "venue": "Computational Linguistics, 2(3):60\u201363,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Beyond the stars: Improving rating predictions using review text content", "author": ["G. Ganu", "N. Elhadad", "A. Marian"], "venue": "In WebDB,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Finding scientific topics", "author": ["T.L. Griffiths", "M. Steyvers"], "venue": "PNAS, 101(suppl. 1):5228\u2013 5235,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Sentiment analysis and subjectivity", "author": ["B. Liu"], "venue": "In Handbook of Natural Language Processing, Second Edition. CRC Press,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "On the limited memory bfgs method for large scale optimization", "author": ["D.C. Liu", "J. Nocedal", "D.C. Liu", "J. Nocedal"], "venue": "Mathematical Programming, 45:503\u2013528,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1989}, {"title": "Rated aspect summarization of short comments", "author": ["Y. Lu", "C. Zhai", "N. Sundaresan"], "venue": "In WWW\u201909, pages 131\u2013140,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 4, "context": "Many automatic systems were built to address this challenge including generating aspect-based sentiment summarization of reviews [1,8,19] and comparing and ranking products with regard to their aspects [13].", "startOffset": 202, "endOffset": 206}, {"referenceID": 6, "context": "Different forms of the excerpts include sentence [8], concise phrase composing of a modifier and a header term [16], adjective-noun pair extracted based on POS tagging and the term-frequency of the pair [23], and phrase generated by rules [15].", "startOffset": 111, "endOffset": 115}, {"referenceID": 1, "context": "This is an important property of polarity of sentiment words as pointed out in [5,11,13,18], and recently several joint topic models have been proposed to unify the treatment of sentiment and topic (aspect) [9,11,17,21].", "startOffset": 79, "endOffset": 91}, {"referenceID": 4, "context": "This is an important property of polarity of sentiment words as pointed out in [5,11,13,18], and recently several joint topic models have been proposed to unify the treatment of sentiment and topic (aspect) [9,11,17,21].", "startOffset": 79, "endOffset": 91}, {"referenceID": 0, "context": "TSM is based on pLSI whereas more recent work ([9,11,20]) uses or extends Latent Dirichlet Allocation (LDA) [2].", "startOffset": 108, "endOffset": 111}, {"referenceID": 3, "context": "Using a collapsed Gibbs sampler [7], new values for the topic and sentiment of a sentence c in document d are drawn from the conditional probability", "startOffset": 32, "endOffset": 35}, {"referenceID": 5, "context": "We use the L-BFGS optimizer [14] to minimize the objective function L\u03b2\u2032\u2212 log p(\u03b2\u2032) by taking its partial derivatives with respect to yki and yji.", "startOffset": 28, "endOffset": 32}, {"referenceID": 1, "context": "In addition to our model-based sentiment classifier, we introduce another sentiment classifier based on SentiWordNet (SWN) [4], a popular lexical resource for opinion mining, using the same approach as in [5].", "startOffset": 205, "endOffset": 208}, {"referenceID": 2, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "We used a set of 929 positive and 236 negative noun phrases obtained from an external set of restaurant reviews in [5].", "startOffset": 115, "endOffset": 118}], "year": 2012, "abstractText": "We present a novel summarization framework for reviews of products and services by selecting informative and concise text segments from the reviews. Our method consists of two major steps. First, we identify five frequently occurring variable-length syntactic patterns and use them to extract candidate segments. Then we use the output of a joint generative sentiment topic model to filter out the non-informative segments. We verify the proposed method with quantitative and qualitative experiments. In a quantitative study, our approach outperforms previous methods in producing informative segments and summaries that capture aspects of products and services as expressed in the user-generated pros and cons lists. Our user study with ninety users resonates with this result: individual segments extracted and filtered by our method are rated as more useful by users compared to previous approaches by users.", "creator": "LaTeX with hyperref package"}}}