{"id": "1211.5766", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Nov-2012", "title": "Visualization and clustering by 3D cellular automata: Application to unstructured data", "abstract": "Given the limited performance of 2D cellular automata in terms of space when the number of documents increases and in terms of visualization clusters, our motivation was to experiment these cellular automata by increasing the size to view the impact of size on quality of results. The representation of textual data was carried out by a vector model whose components are derived from the overall balancing of the used corpus, Term Frequency Inverse Document Frequency (TF-IDF). The WorldNet thesaurus has been used to address the problem of the lemmatization of the words because the representation used in this study is that of the bags of words. Another independent method of the language was used to represent textual records is that of the n-grams. Several measures of similarity have been tested. To validate the classification we have used two measures of assessment based on the recall and precision (f-measure and entropy). The results are promising and confirm the idea to increase the dimension to the problem of the spatiality of the classes. The results obtained in terms of purity class (i.e. the minimum value of entropy) shows that the number of documents over longer believes the results are better for 3D cellular automata, which was not obvious to the 2D dimension. In terms of spatial navigation, cellular automata provide very good 3D performance visualization than 2D cellular automata.", "histories": [["v1", "Sun, 25 Nov 2012 14:24:01 GMT  (797kb)", "http://arxiv.org/abs/1211.5766v1", "10 pages, 8 figures"]], "COMMENTS": "10 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.AI cs.IR", "authors": ["reda mohamed hamou", "abdelmalek amine", "ahmed chaouki lokbani", "michel simonet"], "accepted": false, "id": "1211.5766"}, "pdf": {"name": "1211.5766.pdf", "metadata": {"source": "CRF", "title": "Visualization and clustering by 3D cellular automata: Application to unstructured data", "authors": ["Reda Mohamed HAMOU", "Abdelmalek AMINE", "Ahmed Chaouki LOKBANI", "Michel SIMONET"], "emails": [], "sections": [{"heading": null, "text": "In fact, most of the people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance"}, {"heading": "A. Problematic", "text": "The supervised classification problems are: \u2022 Supervised classification requires a lot of human resources. \u2022 When the number of documents increases, the initial classification needs to be reviewed, which leads to the creation of new classes and changes in the criteria of choice. \u2022 Little consistent classifications Given the problems that the supervised classification breaks down and after [6] where about 80% of documents are in text format. This huge volume of unstructured or structured semi results in an act to make relevant information more difficult to obtain, the generation of a problem known as the problem of information overload [4]. The techniques and tools of knowledge discovery in text (KDT) [7] or simply text mining [6] are designed to deal with this problem. One of these techniques is clustering, a technique that is used to associate similar documents to a particular collection by helping to understand their contents [8, 9]."}, {"heading": "B. State of the art", "text": "This year is the highest in the history of the country."}, {"heading": "II. THE REPRESENTATION OF DATA", "text": "In fact, it is so that it will be able to erenie.n the aforementioned cerebral vessels cerebrVo cnlrVo"}, {"heading": "Maximum distance", "text": "The maximum distance is also called the \"sub\" distance. It is defined as the maximum value of the distances of the attributes, two data points x and y in d-dimensional space and is defined as follows: Average DistanceAs mentioned by Legendre [32], the Euclidean distance has the following disadvantage: Two data points without values of attributes in common space can have less than one more pair of data points with the same attribute values. To overcome this disadvantage, the average distance to change the Euclidean distance [32] was assumed. The average distance is defined by: Mahalanobis DistanceMahalanobis distance can reduce the distance of the distortion caused by linear combinations of attributes. It is defined by: Where is the covariance matrix of the data defined above."}, {"heading": "Tchebychev distance", "text": "The Chebychev distance between two points is the maximum distance between the points in a single dimension. The distance between the points X = (X1, X2, etc.) and Y = (Y1, Y2, etc.) is calculated using the formula: Maxi | Xi - Yi |, where Xi and Yi are the values of the ith variables at points X and Y, respectively."}, {"heading": "III. MODELLING", "text": "Before modelling our cluster algorithm, we describe our source of the data used, which represents the Reuters benchmark and a medical corpus."}, {"heading": "A. Reuters 21,758", "text": "In our experiments, we used the Reuters-21578 corpus, which is a database of 21578 text documents of news information in English. Documents from the Reuters-21578 collection appeared in the Reuters newsroom in 1987. Documents were compiled by Reuters employees and indexed by categories. In 1990, the documents from Reuters and CGI were provided for research purposes to the Information Retrieval Laboratory (W. Bruce Croft, Director) of the Department of Computer and Information Sciences at the University of Massachusetts at Amherst. Formatting the documents and producing the related data files was done in 1990 by David D. Lewis and Stephen Harding at the Information Retrieval Laboratory. The Reuters-21578 collection is divided into 22 files. Each of the first 21 files (reut2-000.sgm by reut2-020.sgm) contains 1,000 documents, while the last one (reut2-021.sgm) contains 578 documents."}, {"heading": "B. medical Corpus", "text": "This body consists of the OHSUMED Collection, which was extracted to create the MEDLINE Database. It consists of extracts from medical journals dated from 1987 to 1991. Generally, these texts contain a title and a summary, but some of them may have only one title. In addition to the manual annotations, these texts contain manual categories called Medical Subject Headings MeSH."}, {"heading": "C. The cellular automaton 3D for Clustering", "text": "We have already experienced the 2D cell automaton [Hamou & al] and we have achieved satisfactory results, but we encountered a few problems with the spatial representation of classes (clusters) space. Therefore, we have designed this problem by experimenting with 3D cell automata, and we had reasonable reasons that they provide a better representation of space and consume months of space. Examples to make the clustering of 1000 documents and represent different classes are a need for a cell automaton of size 2D 35 x 35, for the same number of documents required for a cell automaton of size 11 x 11 (i.e.: a cube of dimension 11 cells) and its very expressive visual appearance. From a formal point of view, a cell automaton is defined by the quadruplet (U, V, E, F)."}, {"heading": "Transition function [1,2,3]", "text": "Almost the same 2D cell automaton transition functions are used for 3D cell automata, the only difference is in the neighborhood, which contains a much larger number than the 2D cell automata, namely: The cell automata proposed by us is a network of cells in a 3D room and belongs to the family (k, r), where k is the number of possible states of a cell, i.e. the cardinal of all states and r is the surroundings of the cell, i.e. r is the radius of the neighborhood. This automaton has 4 possible states (k = 4) and the theradius of the neighborhood is a single cell (r = 1). Thus, one cell of the automaton is dead, alive and alone, or contains data that all states of the automaton are (dead, alive, isolated, active). A dead cell contains the value 0, a living cell contains the value -1, an isolated cell contains the value -2, and an active cell contains data (number of the document corpus).We used these values, and in particular, the cell contains the 1."}, {"heading": "The neighbourhood", "text": "27 blue cells (26 cells + the cell itself) are adjacent cells of the green cell near 3D moors. (Figure 1).When the cell Ci, j, k dies, when then the cell Ci, j, k dataNeighbourhood Ci, j, k becomes aliveIf cell Ci, j, k becomes isolated EndIf a cell is then unchanged (isolated remains) Figure 1. 3D moors neighborhood7 Blue cells (6 cells + the cell itself) are adjacent cells of the green cell near 3D from scratch (Figure 2).The neighborhood that is used in our 3D cell is cluster clusters, so that the spatial representation of classes Crope documents are: IV nippata near 3D from scratch (Figure 2)."}, {"heading": "A. Results", "text": "Figure 2. 3D Von Neumann Neighborhood Ck Ci Cik"}, {"heading": "Interpretation", "text": "This year, it is only a matter of time before agreement is reached."}, {"heading": "V. CONCLUSION AND PERSPECTIVES", "text": "In this paper, a 3D cell automaton is proposed as a solution to the problem of unattended classification (clustering) of text and space problems in 2D cell automates.The transition function used in our cell automateshas evolved into a group (cluster) resembling a certain threshold field.The experimental results are positive and confirm the idea of increasing the dimension of the automates.In view of the results, our approach based on a biomimetic approach (3D cell automatescan) can help solve one of the problems of data mining and visualization of text data based on evaluation criteria based on the notion of memory and precision, the f-measure and entropy. In view of the results, our approach based on a biomimetic approach (3D cell automatescan help solve one of the problems of data mining and visualization of text data.In the future, we will try to explore other biomimetic methods, since nature does not yet reveal all the secrets of the combinatorial problems still present in the field."}], "references": [{"title": "A concept space approach to addressing the vocabulary problem in scientific information retrieval: An experiment on the worm community system", "author": ["H. Chen"], "venue": "Journal of the American Society for Information Science,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1996}, {"title": "The vocabulary problem in collaboration [Special Issue on CSCW", "author": ["H. Chen"], "venue": "IEEE Computer Society,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1994}, {"title": "Text mining: The state of the art and the challenges", "author": ["Tan", "A.-H"], "venue": "In Workshop on Knowledge Discovery From Advanced Databases -", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "Knowledge discovery in textual databases (KDT)", "author": ["R. Feldman", "I. Dagan"], "venue": "In International Conference on Knowledge Discovery (pp. 112-117)", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1995}, {"title": "Data clustering: A review", "author": ["A.K. Jain", "M.N. Murty", "P.J. Flynn"], "venue": "ACM Computing Surveys,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "Recent trends in hierarchic document clustering: A critical review", "author": ["P. Willet"], "venue": "Information Processing & Management,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1988}, {"title": "Information retrieval. London: Butterworths", "author": ["Rijsbergen", "C. v"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1979}, {"title": "Data clustering and learning", "author": ["J. Buhmann"], "venue": "The Handbook of Brain Theory and Neural Networks,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "A comparative study of clustering methods", "author": ["M. Zait", "H. Messatfa"], "venue": "Future Generation Computer Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1997}, {"title": "Clustering Algorithms", "author": ["J. Hartigan"], "venue": "JohnWiley & Sons. Toronto. Canada", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1975}, {"title": "A survey of recent advances in hierarchical clustering algorithms", "author": ["F. Murtagh"], "venue": "The Computer Journal,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1983}, {"title": "Optimization by Simulated Annealing", "author": ["S. Kirkpatrick", "C.D. Gelatt", "Vecchi", "M.P"], "venue": "Science", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1983}, {"title": "Evolution Strategies: A Comprehensive Introduction", "author": ["Beyer", "H.-G", "Schwefel", "H.P"], "venue": "Journal Natural Computing", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "The Theory of Evolution Strategies", "author": ["Beyer", "H.-G"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2001}, {"title": "Dynamic partitional clustering using evolution strategies", "author": ["Lee", "C.-Y", "Antonsson", "E.K"], "venue": "Proceedings of the Third Asia Pacific Conference on Simulated Evolution and Learning", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2000}, {"title": "Genetic Programming: On the Programming of Computers by Means of Natural Evolution", "author": ["Koza", "J.R"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1992}, {"title": "A Learning System Based on Genetic Adaptive Algorithms, PhD dissertation (University of Pittsburgh)", "author": ["Smith", "S.F"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1980}, {"title": "A representation for the adaptive generation of simple sequential programs", "author": ["N.L. Cramer"], "venue": "In:John, J. (ed.) Proceedings of an International Conference on Genetic Algorithms and the Applications,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1985}, {"title": "A clustering algorithm using an evolutionary programmingbased approach", "author": ["M. Sarkar", "B. Yegnanarayana", "Khemani"], "venue": "Pattern Recognition Letters", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1997}, {"title": "Ant Colony Optimization", "author": ["M. Dorigo", "T. St\u00fctzle"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "Particle swarm optimization", "author": ["J. Kennedy", "R. Eberhart"], "venue": "In Proceedings of IEEE International Conference on Neural Networks,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1995}, {"title": "Image classification using particle swarm optimization", "author": ["M. Omran", "A. Salman", "Engelbrecht", "A.P"], "venue": "In: Conference on Simulated Evolution and Learning,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Particle swarm optimization method for image clustering", "author": ["M. Omran", "A.P. Engelbrecht", "Salman"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "The SMART Retrieval System.Prentice-Hall, Englewood Cliffs, NJ", "author": ["G. Salton"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1971}, {"title": "Introduction to Modern Information Retrieval.McGraw", "author": ["M.J.G. Salton"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1983}, {"title": "Using linear algebra for intelligent information retrieval", "author": ["M. Berry", "S. Dumais", "G. O\u2019Brien"], "venue": "SIAM Review,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1995}, {"title": "Machine learning in automated text categorization", "author": ["F. Sebastiani"], "venue": "ACM Computing Surveys", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2002}, {"title": "Cluster analysis, 3rd edition", "author": ["B. Everitt"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1993}], "referenceMentions": [{"referenceID": 2, "context": "\u2022 Little consistent classifications Given the problems that the supervised classification pauses and according to [6] where about 80% of the documents are in text format.", "startOffset": 114, "endOffset": 117}, {"referenceID": 0, "context": "This huge volume of unstructured or structured semi gives rise to an act to find relevant information more difficult to achieve, generating a problem known as the problem of information overload [4].", "startOffset": 195, "endOffset": 198}, {"referenceID": 3, "context": "The techniques and tools of knowledge discovery in text (KDT) [7] or simply text mining [6] are being developed to deal with this problem.", "startOffset": 62, "endOffset": 65}, {"referenceID": 2, "context": "The techniques and tools of knowledge discovery in text (KDT) [7] or simply text mining [6] are being developed to deal with this problem.", "startOffset": 88, "endOffset": 91}, {"referenceID": 4, "context": "One of these techniques is the clustering, a technique used to group similar documents of a given collection by assisting in the understanding of its content [8, 9].", "startOffset": 158, "endOffset": 164}, {"referenceID": 5, "context": "One of these techniques is the clustering, a technique used to group similar documents of a given collection by assisting in the understanding of its content [8, 9].", "startOffset": 158, "endOffset": 164}, {"referenceID": 6, "context": "This hypothesis is known as the hypothesis of cluster described in [10].", "startOffset": 67, "endOffset": 71}, {"referenceID": 5, "context": "Both activities have different purposes and are different in essence: the process of grouping or clustering produces clusters without prior on the content of the document knowledge or which exist classes, while the classification (or categorization) is a process that begins with a predefined set of categories and tries to identify to which category a document belongs [9].", "startOffset": 370, "endOffset": 373}, {"referenceID": 7, "context": "generally the four phases of design: the representation of the data, modelling, optimization, and validation [11].", "startOffset": 109, "endOffset": 113}, {"referenceID": 8, "context": "For large data sets, the hierarchical methods become impractical unless other techniques are integrated, because usually prioritised methods are of complexity O (n2) for space memory and O (n3) for time CPU [12, 13, 14], where n is the number of data in the dataset.", "startOffset": 207, "endOffset": 219}, {"referenceID": 9, "context": "For large data sets, the hierarchical methods become impractical unless other techniques are integrated, because usually prioritised methods are of complexity O (n2) for space memory and O (n3) for time CPU [12, 13, 14], where n is the number of data in the dataset.", "startOffset": 207, "endOffset": 219}, {"referenceID": 10, "context": "For large data sets, the hierarchical methods become impractical unless other techniques are integrated, because usually prioritised methods are of complexity O (n2) for space memory and O (n3) for time CPU [12, 13, 14], where n is the number of data in the dataset.", "startOffset": 207, "endOffset": 219}, {"referenceID": 11, "context": "simulated annealing [15], allows refining a single candidate solution and shows a weakness to deal with a local optimum.", "startOffset": 20, "endOffset": 24}, {"referenceID": 12, "context": "Evolutionary or evolution strategies (ES) [16, 17] are optimization techniques based on ideas of adaptation and evolution.", "startOffset": 42, "endOffset": 50}, {"referenceID": 13, "context": "Evolutionary or evolution strategies (ES) [16, 17] are optimization techniques based on ideas of adaptation and evolution.", "startOffset": 42, "endOffset": 50}, {"referenceID": 14, "context": "In the case of the clustering, Lee and Antonsson [18] used an evolution strategy (ES) to a set of data without any prior knowledge of the number of clusters.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "The first results on the GP methodology was developed by Smith [20] and Cramer [21].", "startOffset": 63, "endOffset": 67}, {"referenceID": 17, "context": "The first results on the GP methodology was developed by Smith [20] and Cramer [21].", "startOffset": 79, "endOffset": 83}, {"referenceID": 15, "context": "Koza, however remains the main initiator of the GP and paved the way for the application of genetic programming in complex optimization and various problems of research [19].", "startOffset": 169, "endOffset": 173}, {"referenceID": 18, "context": "[22] highlight an approach for classifying data dynamically using evolutionary programming (PE) where two fitness functions are optimized simultaneously.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "The main fields of applications of the COA are the problems of combinatorial optimization NP hard [23].", "startOffset": 98, "endOffset": 102}, {"referenceID": 20, "context": "The particle swarm optimization (PSO) was introduced by Kennedy and Eberhart in 1995 [24].", "startOffset": 85, "endOffset": 89}, {"referenceID": 21, "context": "[25].", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[25, 26] Results show that the PSO-based method carries out the k-means, the FCM and a few other algorithms of classification on the State of the art.", "startOffset": 0, "endOffset": 8}, {"referenceID": 22, "context": "[25, 26] Results show that the PSO-based method carries out the k-means, the FCM and a few other algorithms of classification on the State of the art.", "startOffset": 0, "endOffset": 8}, {"referenceID": 23, "context": "The vector space of information search system, launched by Gerard Salton [27], [28], represents the documents as vectors in a vector space.", "startOffset": 73, "endOffset": 77}, {"referenceID": 24, "context": "The vector space of information search system, launched by Gerard Salton [27], [28], represents the documents as vectors in a vector space.", "startOffset": 79, "endOffset": 83}, {"referenceID": 25, "context": "A major advantage of this representation is that the algebraic structure vector space can be exploited [29].", "startOffset": 103, "endOffset": 107}, {"referenceID": 26, "context": "The most widely used weighting is called TF - IDF weighting and is used in our study [30].", "startOffset": 85, "endOffset": 89}, {"referenceID": 27, "context": "The similarity coefficient indicates the strength of the relationship between two data points [31].", "startOffset": 94, "endOffset": 98}], "year": 2012, "abstractText": "Given the limited performance of 2D cellular automata in terms of space when the number of documents increases and in terms of visualization clusters, our motivation was to experiment these cellular automata by increasing the size to view the impact of size on quality of results. The representation of textual data was carried out by a vector model whose components are derived from the overall balancing of the used corpus Term Frequency \u2013 Inverse Document Frequency (TF IDF).The WorldNet thesaurus has been used to address the problem of the lemmatization of the words because the representation used in this study is that of the bags of words. Another independent method of the language was used to represent textual records is that of the n-grams. Several measures of similarity have been tested. To validate the classification we have used two measures of assessment based on the recall and precision (f-measure and entropy). The results are promising and confirm the idea to increase the dimension to the problem of the spatiality of the classes. The results obtained in terms of purity class (ie the minimum value of entropy) shows that the number of documents over longer believes the results are better for 3D cellular automata, which was not obvious to 2D the dimension. In terms of spatial navigation, cellular automata provide very good 3D performance visualization than 2D cellular automata.", "creator": "Microsoft\u00ae Word Starter 2010"}}}