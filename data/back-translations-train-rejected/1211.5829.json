{"id": "1211.5829", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Nov-2012", "title": "An Automatic Algorithm for Object Recognition and Detection Based on ASIFT Keypoints", "abstract": "Object recognition is an important task in image processing and computer vision. This paper presents a perfect method for object recognition with full boundary detection by combining affine scale invariant feature transform (ASIFT) and a region merging algorithm. ASIFT is a fully affine invariant algorithm that means features are invariant to six affine parameters namely translation (2 parameters), zoom, rotation and two camera axis orientations. The features are very reliable and give us strong keypoints that can be used for matching between different images of an object. We trained an object in several images with different aspects for finding best keypoints of it. Then, a robust region merging algorithm is used to recognize and detect the object with full boundary in the other images based on ASIFT keypoints and a similarity measure for merging regions in the image. Experimental results show that the presented method is very efficient and powerful to recognize the object and detect it with high accuracy.", "histories": [["v1", "Mon, 26 Nov 2012 01:10:15 GMT  (1420kb)", "http://arxiv.org/abs/1211.5829v1", "11 pages - 8 figures. arXiv admin note: substantial text overlap witharXiv:1210.7038"]], "COMMENTS": "11 pages - 8 figures. arXiv admin note: substantial text overlap witharXiv:1210.7038", "reviews": [], "SUBJECTS": "cs.AI cs.CV", "authors": ["reza oji"], "accepted": false, "id": "1211.5829"}, "pdf": {"name": "1211.5829.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["ASIFT KEYPOINTS", "Reza Oji"], "emails": ["oji.reza@gmail.com"], "sections": [{"heading": null, "text": "DOI: 10.5121 / sipij.2012.3503 29Object recognition is an important task in image processing and computer vision. This work represents a perfect method for object recognition with complete boundary recognition by combining affine scale invariant functional transformation (ASIFT) and an algorithm for merging regions. ASIFT is a fully sophisticated invariant algorithm, which means that properties are invariant to six affine parameters, namely translation (2 parameters), zoom, rotation and orientation of two camera axes. The properties are very reliable and provide us with strong key points that can be used for matching between different images of an object. We trained an object in multiple images with different aspects to find the best key points for it. Afterwards, a robust region merge algorithm is used to detect and detect the object with full boundary in the other images, based on ASIFT key points and an image of similarity to show it to the accuracy of the merged region and to show the FT is very efficient."}, {"heading": "1. INTRODUCTION", "text": "These points have many applications in image processing such as object detection, object and shape detection, image registration and object tracking. By extracting the key points, we can use them to find objects in the other images. We can detect and recognize the object using the key points and a segmentation algorithm is very accurate, because if the key points are correctly identified, they will get the best information from the image. ASIFT is a fully affine invariant method in terms of six parameters of affinity transformation [1,2], whereas the previous method SIFT was invariant in terms of four parameters, namely translation, rotation and change in scale (zoom). ASIFT covers two other parameters, namely length and elevation angle, which are relevant to the orientation of the camera. It means that ASIFT is more effective for our goal and more robust in the changes in images.Many object detection and segment detection are 4,5]."}, {"heading": "2. THE ASIFT ALGORITHM", "text": "ASIFT is an improved algorithm of SIFT. SIFT was introduced by Lowe (1994), where SIFT is invariant on four of the six parameters of affine transformation. ASIFT simulates all image views obtained by length and latency angles (variation of the two orientation parameters of the camera axis) and then applies the other parameters using the SIFT algorithm. There is a new idea called Transition Tilt, which was developed to quantify the height of inclination between two such images. Below, the most important steps of the algorithm are described."}, {"heading": "2.1. The Affine Camera Model", "text": "The image distortions resulting from the change in the viewing angle can be modelled by affine planar transformations. Each affine card A is defined: \u2212 \u2212 = Affine card A is the discovery of A, Ri is the discovery of rotations, \u03c6 [0,180), and Tt is an inclination, namely a diagonal matrix with the first eigenvalue t > 1 and the second equal to 1. Figure 1 shows a camera motion interpretation of (1). The optical axis Tt corresponds to the zoom and a third angle of the camera parameterizes the rotation motion. According to the preamble, each image should be transformed by simulating all possible affine distortions caused by the changes in the optical axis of the camera."}, {"heading": "2.2. Scale Space Extremum Detection", "text": "The next step is to extract key points that are invariant to scale changes. We must look for stable properties in all possible changes. Previous research has shown that the Gaussian function is the only possible scale nucleus for this task. A function, L (x, y, \u03c3), is the scale space of an image obtained from the folding of an input image, I (x, y), with a Gaussian function with variable scale space, G (x, y, \u03c3). To efficiently detect stable key point positions, Lowe suggested using the scale space extremity in difference from Gaussian function (DOG), D (x, y, \u03c3). Extremely calculated by the difference of two adjacent scales separated by a constant factor K (2):, (2) This process repeats itself in several octaves x. In each octave, the initial image is repeated with Gaussian space to generate the scalx images."}, {"heading": "2.3. Accurate Keypoint Localization", "text": "For each candidate, the interpolation of nearby data is used to accurately determine its position, eliminating many key points that are unstable and sensitive to noise, such as the low contrast dots and the dots on the edge. (Figure 4)"}, {"heading": "2.4. Assigning an Orientation", "text": "The next step is to assign an orientation for each keypoint. In this step, the keypoint descriptor [10] can be displayed relative to this orientation, thus obtaining invariance to the image rotation. For each Gaussian image sample, points are selected in regions around the keypoint and size, m and orientations of the gradient are calculated (3): (3) A weighted histogram (magnitude + Gaussian) of local gradient directions is then created on a selected scale. (Figure 5) 22))) 1, () 1, () 1 () 1 (), 1 (), (), (), (\u2212 \u2212 \u2212 LyxLyxLyxxtan), (1) (+), (x1) (\u2212 xtan) (\u2212) (\u2212 x1)"}, {"heading": "2.5. Keypoint Descriptor", "text": "The remaining objectives are to define a keypoint descriptor [11] for the local image regions and to reduce the effects of illumination changes. The descriptor is based on 16 \u00d7 16 samples, of which the keypoint is in the middle. Samples are divided into 4 \u00d7 4 sub-regions in 8 directions around the keypoint. The size of each point is weighted and gives gradients that are far away from the keypoint less weight. Therefore, the feature vector is dimensional 128 (4 x 4 x 8). Finally, vector normalization is applied in 8 directions around the keypoint. A modification of the image contrast, in which each pixel value is multiplied by a constant, multiplies the gradients of the world by the same constant. The contrast change is reversed by vector normalization and brightness change, in which a constant is added to each image."}, {"heading": "3. PROPOSED OBJECT RECOGNITION AND DETECTION METHOD", "text": "For each object, we train it by ASIFT algorithm in multiple images with different scales and viewing angles to find the best key points to detect the desired object in the other images. Then, the object is detected by using these key points and a region merge algorithm. A maximum similarity of the region merge algorithm was suggested by Ning. This algorithm is based on a region merge method with initial segmentation of center shift [12] and user markers. User marks a part of the object and background to help the process of merging by maximum similarity. The non-marking background regions are automatically merged, while the non-marking object regions are identified and preserved from merging with the background. It can extract the object from complex scenes, but there is a weakness that the algorithm needs user markers, so the algorithm is not automatic to use the ASIFT by combining this algorithm with our algorithm, but we use this region automatically."}, {"heading": "3.1. Region Merging Based on Maximal Similarity", "text": "We use the mean shift segmentation software, namely the EDISON system [13] for initial segmentation, because it can maintain boundaries well and has high velocity. Any other low-level segmentation such as superpixels and watershed can also be used. For more information on the middle shift segmentation, see [14,15]. There are many small regions after initial segmentation. These regions represent the use of a color histogram, which is an effective descriptor because different regions of the same object often show a great similarity in color, while there are differences in other aspects such as size and shape. The color histogram, which is calculated by the RGB color space. We quantify each color histogram uniformly in 8 levels. Therefore, the attribute space 8 x 8 x 8 x 8 = 512 and the histogram of each region is calculated in 512 folders. Now, the normalized keyboard histogram of a region X is composed by the histodensed regions, so that we want the histodensity X to be the object."}, {"heading": "3.2. The Merging Process", "text": "In the merge process, we have three regions in the image with different labels: the object regions designated by RO, identified by key points from the ASIFT algorithm; the regions around the images, which are not normally inclusive objects, so we cover all images as initial background regions to help and start the merge process; and the third regions, the unsigned regions designated by N. The merge rule is defined in Continue (5). Let Y be a neighboring region of X and SY is the merge of the neighboring region Y, that X is one of them. The similarity between Y and SY stops, i.e. (Y, SY), is calculated. We will merge X and Y if and only if the similarity between them is the maximum of all similarities. (Y, SY).Merge X and Y = max."}, {"heading": "4. EXPERIMENTAL RESULTS", "text": "Our results show that the proposed method is very powerful and robust for object detection and detection. We trained three objects (rack, bottle and calendar) from an online dataset [16] in multiple views with different scales and illuminations to verify our method. Using ASIFT key points in the region, which are based on maximum similarity, helped us achieve significant results. These key points are very accurate and come from a strong algorithm (ASIFT) with a statistical basis. In addition, the key points provide us with the best information about objects that are very useful for merging processes.Figure 7 shows ASIFT key points on the images with initial mean displacement and detected objects with their limitations. The first line (a) is relevant to the rack dataset, the second line (b) is the bottle and the third line, (c) is the calendar number. The accuracy rate (6) of the full limit detection is calculated for each object and table."}, {"heading": "5. CONCLUSIONS", "text": "This paper presented an algorithm for object detection and detection, which is achieved by combining ASIFT and a regional merging algorithm based on a measure of similarity. We train different objects separately in multiple images with multiple aspects and camera perspectives to find the best key points for their detection in the other images. These key points are applied to the regional merging algorithm. The merging process is initiated by using key points and depicted similarity measurements (Euclidean distance), the regions are merged based on the merging role and finally, the object is well recognized, with its boundary. A final conclusion is that the more key points are achieved and the more precise they are, the results will be better and more acceptable. We are currently working on developing an approach to shape detection of objects in images. We hope to present a robust shape detection algorithm by using the extracted boundaries of objects based on the algorithm proposed in this paper."}], "references": [], "referenceMentions": [], "year": 2012, "abstractText": "Object recognition is an important task in image processing and computer vision. This paper presents a<lb>perfect method for object recognition with full boundary detection by combining affine scale invariant<lb>feature transform (ASIFT) and a region merging algorithm. ASIFT is a fully affine invariant algorithm that<lb>means features are invariant to six affine parameters namely translation (2 parameters), zoom, rotation<lb>and two camera axis orientations. The features are very reliable and give us strong keypoints that can be<lb>used for matching between different images of an object. We trained an object in several images with<lb>different aspects for finding best keypoints of it. Then, a robust region merging algorithm is used to<lb>recognize and detect the object with full boundary in the other images based on ASIFT keypoints and a<lb>similarity measure for merging regions in the image. Experimental results show that the presented method<lb>is very efficient and powerful to recognize the object and detect it with high accuracy.", "creator": "PScript5.dll Version 5.2.2"}}}