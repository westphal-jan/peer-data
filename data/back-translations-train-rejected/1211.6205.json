{"id": "1211.6205", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Nov-2012", "title": "Neuro-Fuzzy Computing System with the Capacity of Implementation on Memristor-Crossbar and Optimization-Free Hardware Training", "abstract": "In this paper, first we present a new explanation for the relation between logical circuits and artificial neural networks, logical circuits and fuzzy logic, and artificial neural networks and fuzzy inference systems. Then, based on these results, we propose a new neuro-fuzzy computing system which can effectively be implemented on the memristor-crossbar structure. One important feature of the proposed system is that its hardware can directly be trained using the Hebbian learning rule and without the need to any optimization. The system also has a very good capability to deal with huge number of input-out training data without facing problems like overtraining.", "histories": [["v1", "Tue, 27 Nov 2012 03:51:44 GMT  (1903kb)", "http://arxiv.org/abs/1211.6205v1", "16 pages, 11 images, submitted to IEEE Trans. on Fuzzy systems"]], "COMMENTS": "16 pages, 11 images, submitted to IEEE Trans. on Fuzzy systems", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["farnood merrikh-bayat", "farshad merrikh-bayat", "saeed bagheri shouraki"], "accepted": false, "id": "1211.6205"}, "pdf": {"name": "1211.6205.pdf", "metadata": {"source": "CRF", "title": "Neuro-Fuzzy Computing System with the Capacity of Implementation on Memristor-Crossbar and Optimization-Free Hardware Training", "authors": ["Farnood Merrikh-Bayat", "Farshad Merrikh-Bayat", "Saeed Bagheri Shouraki"], "emails": ["merrikhbayat@ee.sharif.edu,", "bagheri-s@sharif.edu.", "f.bayat@znu.ac.ir."], "sections": [{"heading": null, "text": "In fact, most of them are able to survive on their own."}, {"heading": "II. THE RELATIONS BETWEEN DIGITAL LOGIC, FUZZY LOGIC AND NEURAL NETWORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Similarities and dissimilarities between logical circuits and artificial neural networks", "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times. \""}, {"heading": "B. The relation between logical circuits and fuzzy logic", "text": "A major question that arises at this point is: \"Can we extend the multi-layered logical circuits represented in Figure 1?\" The method used to express a binary function in the form of a sum of products is very similar to the method of constructing a continuous function based on fuzzy rules. Below, we will discuss this topic with more detail. First, we will consider a multi-layered input-single-output system whose input-output relationship can be regarded as the mathematical chart X."}, {"heading": "III. REALIZATION, TRAINING AND APPLICATION OF THE PROPOSED NEURO-FUZZY SYSTEM", "text": "In this section we will explain the hardware implementation, training and some applications of our proposed nuero-fuzzy system, which has significant differences from existing methods. It is also shown that the proposed structure has the advantage that it can be effectively designed to deal with massive input-output data. The overall structure of the proposed neuro-fuzzy computing system is the same as the one in Figure 3, which can also be considered as a two-layer network. In this figure it is assumed that x and y are scalar inputs and z-output. Note: This system is actually a dynamic structure that is incomplete at the beginning and is more and more completed by training with the new data. It means that the hidden layer has no neurons before training and the neurons become input-output-output data immediately after subjecting the system."}, {"heading": "A. Response of the proposed neuro-fuzzy computing system to the given input", "text": "In this section, we assume that the proposed neuro-fuzzy computing system is designed and fully trained, and we only discuss various aspects of calculating its output for the given input. The training method is then discussed in Section III-B. Note: As it will be shown later, the proposed system can be trained in another section during its ordinary work and the only reason for presenting the training method. In Fig. 3, it is assumed that the value of the signal input into the variable y group is input into the variable x group, the concept of ith neurons assigned to the ith neurons of this group is the value of the input signal of the ith neurons of the variable y, yi is the concept assigned to the ith neurons of this group, nx is the number of neurons used to cover the universal set of the unclear variable y."}, {"heading": "B. Training the proposed neuro-fuzzy computing system", "text": "In the previous section, we showed that the work procedure of all parts of the proposed neuro-fuzzy computing system, except for the activation function of neurons at the hidden level, is similar to the classical ANN system. However, what makes the proposed system significantly different and more efficient is the way in which it is trained. Specifically, the proposed system is trained on the basis of the specified inputputputputputputputputputputputdata, and as will be shown later, the output of synaptic weights or other parameters of the system can be carried out without the need for an optimization method. Without any loss of generality, we will look again at the neuro-fuzzy computing system shown in the figure. 3 and assume that the system has already been subjected to the input data and is subject to other parameters of the system. In the following, we will discuss the method of training the system when it is subjected to a new training file."}, {"heading": "IV. HARDWARE IMPLEMENTATION OF THE PROPOSED NEURO-FUZZY COMPUTING SYSTEM", "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far."}, {"heading": "V. SIMULATION RESULTS", "text": "In this section we show the high potential of the proposed neuro-fuzzy computing system for solving various technical problems in the field of modeling and classification. An important ability of the proposed system is to model multivariable mathematical functions. To show this, we consider the functions: g1 (x, y) = 10,391 (x \u2212 0.4) (x \u2212 0.6) + 0.36), (19) g2 (x, y) = 24,234 (r2 (0.75 \u2212 r2)), r2 (x \u2212 0.5) 2, (y \u2212 0.5) 2, (20) g3 (x, y) = 42,659 (0.1 + x), (0.05 + x)."}, {"heading": "VI. CONCLUSION", "text": "A novelty of this paper is the new explanation of the relationship between logical circuits and ANNs, logical circuits and fuzzy logic, as well as ANNs and fuzzy inference systems. This explanation led to the introduction of fuzzy min terms and a special two-layer ANN with the ability to work with fuzzy input output data. This neurofuzzy computing system has at least four main advantages over many other classic designs: First, it can be effectively implemented on the nano-scale memristor crossbar structure; second, the hardware of the system can be trained simply by applying the Hebrew learning method and without the need for optimization; third, the proposed structure can work effectively with a huge amount of training data from the input output (fuzzy type) without having problems such as over-training; and finally, it has strong biological support that makes it a powerful structure to mimic the function of the human brain."}], "references": [{"title": "Hardware implementation of an artificial neural network using field programmable gate arrays (FPGA\u2019s)", "author": ["N.M. Botros", "M. Abdul-Aziz"], "venue": "IEEE Transactions on Industrial Electronics, Vol. 41, No. 6, pp. 665\u2013667, December 1994.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1994}, {"title": "Direct Neural-Network Hardware-Implementation Algorithm", "author": ["A. Dinu", "M.N. Cristea", "S.E. Cristea"], "venue": "IEEE Transactions on Industrial Electronics, Vol. 57, No. 5, pp. 1845\u20131848, May 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1845}, {"title": "A fuzzy neural network model and its hardware implementation", "author": ["Y.H. Kuo", "C.I. Kao", "J.J. Chen"], "venue": "IEEE Transactions on Fuzzy Systems, Vol. 1, No. 3, pp. 171\u2013183, 1993.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1993}, {"title": "The missing memristor found", "author": ["D.B. Strukov", "G.S. Snider", "D.R. Stewart", "R.S. Williams"], "venue": "Nature, Vol. 453, pp. 80\u201383, 1 May 2008.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Memristor - the missing circuit element", "author": ["L.O. Chua"], "venue": "IEEE Trans. on Circuit Theory, Vol. CT-18, No. 5, pp. 507\u2013519, 1971.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1971}, {"title": "From synapses to circuitry: Using memristive memory to explore the electronic brain", "author": ["G. Snider", "R. Amerson", "D. Carter", "H. Abdalla", "M.S. Qureshi", "J. Leveille", "M. Versace", "H. Ames", "S. Patrick", "B. Chandler", "A. Gorchetchnikov", "E. Mingolla"], "venue": "Computer, Vol. 44, No. 2, pp. 21\u201328, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Nanoscale Memristor Device as Synapse in Neuromorphic Systems", "author": ["S.H. Jo", "T. Chang", "I. Ebong", "B.B. Bhadviya", "P. Mazumder", "W. Lu"], "venue": "Nano Letter, Vol. 10, No. 4, pp. 1297\u20131301, March 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Short-Term Memory to Long-Term Memory Transition in a Nanoscale Memristor", "author": ["T. Chang", "S.-H. Jo", "W. Lu"], "venue": "ACS Nano, Vol. 5, No. 9, pp. 7669\u20137676, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Memristor Crossbar-Based Hardware Implementation of the IDS Method", "author": ["F. Merrikh-Bayat", "S. Bagheri Shouraki", "A. Rohani"], "venue": "IEEE Transactions on Fuzzy Systems, Vol. 19, No. 6, pp. 1083\u20131096, December 2011.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Memristive Neuro- Fuzzy System", "author": ["F. Merrikh-Bayat", "S. Bagheri Shouraki"], "venue": "To appear in IEEE Transactions on Systems, Man and Cybernetics, Part B: Cybernetics, 2012.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive Resonance Theory Design in Mixed Memristive-Fuzzy Hardware", "author": ["M. Versace", "R.T. Kozma", "D.C. Wunsch"], "venue": "Advances in Neuromorphic Memristor Science and Applications, Vol. 4, pp. 133\u2013153, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "A neuronal learning rule for sub-millisecond temporal coding", "author": ["W. Gerstner", "R. Kempter", "J.L. Hemmen", "H. Wagner"], "venue": "Nature, Vol. 383, pp. 76\u201378, 1996.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1996}, {"title": "Neural Synaptic Weighting With a Pulse-Based Memristor Circuit", "author": ["H. Kim", "M. Sah", "Y. Changju", "T. Roska", "L.O. Chua"], "venue": "IEEE Transactions on Circuits and Systems I: Regular papers, Vol. 59, No. 1, pp. 148\u2013158, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Hebbian Learning in Spiking Neural Networks With Nanocrystalline Silicon TFTs and Memristive Synapses", "author": ["K.D. Cantley", "A. Subramaniam", "H.J. Stiegler", "R.A. Chapman", "E.M. Vogel"], "venue": "IEEE Transactions on Nanotechnology, Vol. 10, No. 5, pp. 1066\u20131073, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Implementation of biologically plausible spiking neural network models on the memristor crossbar-based CMOS/nano circuits", "author": ["A. Afifi", "A. Ayatollahi", "F. Raissi"], "venue": "European Conference on circuit theory and design, pp. 563\u2013566, 2009.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Memristor Bridge Synapse-Based Neural Network and Its Learning", "author": ["S.P. Adhikari", "C. Yang", "H. Kim", "L.O. Chua"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, Vol. 23, No. 9, pp. 1426\u20131435, September 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "The organization of behavior", "author": ["D.O. Hebb"], "venue": "New York Wiley and Sons, 1949.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1949}, {"title": "Digital Logic Circuit Analysis and Design", "author": ["V.P. Nelson", "H.T. Nagle", "B.D. Carroll"], "venue": "Prentice Hall, 1995.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1995}, {"title": "Fundamentals of Neural Networks: Architectures, Algorithms and Applications", "author": ["L.V. Fausett"], "venue": "Pearson Education Publisher, 2006.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Flexible Neuro-Fuzzy Systems: Structures, Learning and Performance Evaluation", "author": ["L. Rutkowski"], "venue": "Kluwer Academic Publishers, 2004.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "Reconfigurable nano-crossbar architectures", "author": ["D.B. Strukov", "K.K. Likharev"], "venue": "in: Nanoelectronics, R. Waser Eds., 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Memristive devices and systems", "author": ["L.O. Chua", "S.M. Kang"], "venue": "Proceedings of the IEEE, Vol. 64, No. 2, pp. 209\u2013223, 1976.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1976}, {"title": "High-precision tuning of state for memristive devices by adaptable variation-tolerant algorithm", "author": ["F. Alibart", "L. Gao", "B. Hoskins", "D.B. Strukov"], "venue": "Nanotechnology 23, art. 075201, 2012.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Time-dependency of the threshold voltage in memristive devices", "author": ["E. Lehtonen", "J. Poikonen", "M. Laiho", "W. Lu"], "venue": "IEEE International Symposium on Circuits and Systems (ISCAS), pp. 2245\u20132248, 15-18 May 2011.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Regression modeling in back-propagation and projection pursuit learning", "author": ["J.N. Hwang", "S.R. Lay", "M. Maechler", "R.D. Martin", "J. Schimert"], "venue": "IEEE Transactions on Neural Networks, Vol. 5, No. 3, pp. 342\u2013353, 1994.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1994}, {"title": "Objective functions for training new hidden units in constructive neural networks", "author": ["T.Y. Kwok", "D.Y. Yeung"], "venue": "IEEE Transactions on Neural Networks, Vol. 8, No. 5, pp. 1131\u20131148, 1997.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1997}, {"title": "Constructive feedforward neural networks using Hermite polynomial activation functions", "author": ["L. Ma", "K. Khorasani"], "venue": "IEEE Transactions on Neural Networks, Vol. 16, No. 4, pp. 821\u2013833, 2005.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2005}, {"title": "A study on the modeling ability of the IDS method: A soft computing technique using pattern-based information processing", "author": ["M. Murakami", "N. Honda"], "venue": "International Journal of Approximate Reasoning, Vol. 45, pp. 470\u2013487, 2007.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "ANFIS:Adaptive-Network-based Fuzzy Inference Systems", "author": ["J.S.R. Jang"], "venue": "IEEE Transactions on Systems, Man and Cybernetics, Vol. 23, pp. 665\u2013685, 1993.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 0, "context": "As a result, most of the analog hardwares proposed so far are somehow inefficient and area consuming designs (see, for example [1], [2], [3]).", "startOffset": 127, "endOffset": 130}, {"referenceID": 1, "context": "As a result, most of the analog hardwares proposed so far are somehow inefficient and area consuming designs (see, for example [1], [2], [3]).", "startOffset": 132, "endOffset": 135}, {"referenceID": 2, "context": "As a result, most of the analog hardwares proposed so far are somehow inefficient and area consuming designs (see, for example [1], [2], [3]).", "startOffset": 137, "endOffset": 140}, {"referenceID": 3, "context": "In 2008 and after the physical realization of first memristive device or memristor [4] (used interchangeably in the rest of paper) which was also predicted by Leon Chua in 1971 [5], the field of brain emulation has been revived.", "startOffset": 83, "endOffset": 86}, {"referenceID": 4, "context": "In 2008 and after the physical realization of first memristive device or memristor [4] (used interchangeably in the rest of paper) which was also predicted by Leon Chua in 1971 [5], the field of brain emulation has been revived.", "startOffset": 177, "endOffset": 180}, {"referenceID": 5, "context": "This is mainly because of the existence of some similarities between the physical behavior of memristor and synapses in brain [6], [7].", "startOffset": 126, "endOffset": 129}, {"referenceID": 6, "context": "This is mainly because of the existence of some similarities between the physical behavior of memristor and synapses in brain [6], [7].", "startOffset": 131, "endOffset": 134}, {"referenceID": 7, "context": "Fortunately, unlike capacitor, memristor can retain its memristance for a long period of time in the absence of the voltage or current applied to it [8].", "startOffset": 149, "endOffset": 152}, {"referenceID": 8, "context": "The first category belongs to the works trying to implement fuzzy inference methods by using memristive hardwares [9], [10], [11].", "startOffset": 114, "endOffset": 117}, {"referenceID": 9, "context": "The first category belongs to the works trying to implement fuzzy inference methods by using memristive hardwares [9], [10], [11].", "startOffset": 119, "endOffset": 123}, {"referenceID": 10, "context": "The first category belongs to the works trying to implement fuzzy inference methods by using memristive hardwares [9], [10], [11].", "startOffset": 125, "endOffset": 129}, {"referenceID": 9, "context": "For example, in [10] we showed that fuzzy relations (describing the relation between input and output fuzzy concepts or variables in an imprecise manner) can efficiently be formed on memristor crossbar structures by using Hebbian learning method.", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "The second category consists of the studies concentrated on hardware implementation of spiking neural networks and their learning methods such as Spike TimingDependent Plasticity (STDP) [12] using memristor crossbar structures [13], [14], [15], [16], [17].", "startOffset": 186, "endOffset": 190}, {"referenceID": 12, "context": "The second category consists of the studies concentrated on hardware implementation of spiking neural networks and their learning methods such as Spike TimingDependent Plasticity (STDP) [12] using memristor crossbar structures [13], [14], [15], [16], [17].", "startOffset": 227, "endOffset": 231}, {"referenceID": 13, "context": "The second category consists of the studies concentrated on hardware implementation of spiking neural networks and their learning methods such as Spike TimingDependent Plasticity (STDP) [12] using memristor crossbar structures [13], [14], [15], [16], [17].", "startOffset": 233, "endOffset": 237}, {"referenceID": 14, "context": "The second category consists of the studies concentrated on hardware implementation of spiking neural networks and their learning methods such as Spike TimingDependent Plasticity (STDP) [12] using memristor crossbar structures [13], [14], [15], [16], [17].", "startOffset": 239, "endOffset": 243}, {"referenceID": 15, "context": "The second category consists of the studies concentrated on hardware implementation of spiking neural networks and their learning methods such as Spike TimingDependent Plasticity (STDP) [12] using memristor crossbar structures [13], [14], [15], [16], [17].", "startOffset": 251, "endOffset": 255}, {"referenceID": 16, "context": "For example, it will be demonstrated that logical circuits can be considered as networks whose connections can partly be tuned by using Hebbian learning rule [18].", "startOffset": 158, "endOffset": 162}, {"referenceID": 17, "context": "To show this, first note that any binary function can be written in the standard form of sum of products (min-terms) [19].", "startOffset": 117, "endOffset": 121}, {"referenceID": 18, "context": "Clearly, similar to conventional ANNs [20], in the structure shown in Fig.", "startOffset": 38, "endOffset": 42}, {"referenceID": 16, "context": "However, interesting point is that these weights can be adjusted following the Hebbian learning rule [18] used in ANNs.", "startOffset": 101, "endOffset": 105}, {"referenceID": 9, "context": "In other words, similar to fuzzy logic [10], here it seems that we are considering one input terminal per each distinct value of input variable and the input that we apply to any of these terminals somehow is the representative of our confidence degree about the occurrence of its corresponding concept.", "startOffset": 39, "endOffset": 43}, {"referenceID": 19, "context": "Moreover, assume that the output of this fuzzy inference system is obtained by aggregation of the output of N fuzzy rules in the form of [21]:", "startOffset": 137, "endOffset": 141}, {"referenceID": 19, "context": "Various methods are available to determine the amount of activation of the antecedent part of a fuzzy rule for the given fuzzy input data [21].", "startOffset": 138, "endOffset": 142}, {"referenceID": 9, "context": "Interestingly, in [10] we showed that this process is also equivalent with the creation of fuzzy relation [21] between min-terms and output concepts.", "startOffset": 18, "endOffset": 22}, {"referenceID": 19, "context": "Interestingly, in [10] we showed that this process is also equivalent with the creation of fuzzy relation [21] between min-terms and output concepts.", "startOffset": 106, "endOffset": 110}, {"referenceID": 20, "context": "This circuit consists of a simple memristor crossbar [22] where each of its rows is connected to the virtually grounded terminal of an operational amplifier that plays the role of a neuron with identity activation function.", "startOffset": 53, "endOffset": 57}, {"referenceID": 3, "context": "6 this semiconductor element is a memristive device [4], [23].", "startOffset": 52, "endOffset": 55}, {"referenceID": 21, "context": "6 this semiconductor element is a memristive device [4], [23].", "startOffset": 57, "endOffset": 61}, {"referenceID": 22, "context": "Memristive device is a nonlinear element whose resistance (known as memristance) can be tuned by applying a suitable voltage to the device [24].", "startOffset": 139, "endOffset": 143}, {"referenceID": 23, "context": "Since there is a threshold in the physical model of the device, amplitude of the applied voltage should be larger than this threshold to be able to change the state (and consequently, the memristance) of the device [25].", "startOffset": 215, "endOffset": 219}, {"referenceID": 20, "context": "Note that several methods have been proposed so far to change the memristance of specified memristors in a crossbar without altering the memristance of other semi-selected memristors [22].", "startOffset": 183, "endOffset": 187}, {"referenceID": 3, "context": "In this simulation the HP model [4] is used to simulate memristor and voltages are applied to memristor for about 0.", "startOffset": 32, "endOffset": 35}, {"referenceID": 24, "context": "[26] to study the learning and modeling capability of systems (in all of the above functions it is assumed that x, y \u2208 [0, 1]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[26] to study the learning and modeling capability of systems (in all of the above functions it is assumed that x, y \u2208 [0, 1]).", "startOffset": 119, "endOffset": 125}, {"referenceID": 24, "context": "The Fraction of Variance Unexplained (FVU) performance index defined as follows [26]", "startOffset": 80, "endOffset": 84}, {"referenceID": 25, "context": "The second group of the results presented in Table II corresponds to the method proposed by Kwok and Yeung [27] for training the coefficients of the new hidden units added to a dynamical network based on using different cost functions (i.", "startOffset": 107, "endOffset": 111}, {"referenceID": 25, "context": ", S1, \u221a S1, S2, \u221a S2, S3, \u221a S3, Scascor, Sfujita, and Ssqr as defined in [27]).", "startOffset": 73, "endOffset": 77}, {"referenceID": 26, "context": "The third group of results in Table II is obtained by using the method proposed by Ma and Khorasani [28], which is similar to the previous method with the difference that instead of using different cost functions for training, different Hermite polynomial activation functions are applied to the neurons of hidden layer.", "startOffset": 100, "endOffset": 104}, {"referenceID": 27, "context": "Murakami and Honda [29] studied the modeling ability of the Active Learning Method (ALM) and used it for pattern-based information processing.", "startOffset": 19, "endOffset": 23}, {"referenceID": 28, "context": "Finally, the last group of results in Table II corresponds to the modeling of functions using the ANFIS method [30].", "startOffset": 111, "endOffset": 115}, {"referenceID": 27, "context": "TABLE II COMPARING THE ACCURACIES OF THE MODELS OPTIMIZED USING DIFFERENT ALGORITHMS BASED ON FVU CRITERION [29].", "startOffset": 108, "endOffset": 112}, {"referenceID": 24, "context": "g1 g2 g3 g4 g5 [26] BPL based on Gauss-Newton method (5 hidden units) 0.", "startOffset": 15, "endOffset": 19}, {"referenceID": 25, "context": "[27] CFNN with S1 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[28] Standard CFNN with sigmoidal activation functions (10 hidden units) 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[29] ALM with 6 partitions 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[30] ANFIS with 9 rules 0.", "startOffset": 0, "endOffset": 4}], "year": 2012, "abstractText": "In this paper, first we present a new explanation for the relation between logical circuits and artificial neural networks, logical circuits and fuzzy logic, and artificial neural networks and fuzzy inference systems. Then, based on these results, we propose a new neuro-fuzzy computing system which can effectively be implemented on the memristor-crossbar structure. One important feature of the proposed system is that its hardware can directly be trained using the Hebbian learning rule and without the need to any optimization. The system also has a very good capability to deal with huge number of input-out training data without facing problems like overtraining.", "creator": "LaTeX with hyperref package"}}}