{"id": "1211.6887", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Nov-2012", "title": "Automating rule generation for grammar checkers", "abstract": "In this paper, I describe several approaches to automatic or semi-automatic development of symbolic rules for grammar checkers from the information contained in corpora. The rules obtained this way are an important addition to manually-created rules that seem to dominate in rule-based checkers. However, the manual process of creation of rules is costly, time-consuming and error-prone. It seems therefore advisable to use machine-learning algorithms to create the rules automatically or semi-automatically. The results obtained seem to corroborate my initial hypothesis that symbolic machine learning algorithms can be useful for acquiring new rules for grammar checking. It turns out, however, that for practical uses, error corpora cannot be the sole source of information used in grammar checking. I suggest therefore that only by using different approaches, grammar-checkers, or more generally, computer-aided proofreading tools, will be able to cover most frequent and severe mistakes and avoid false alarms that seem to distract users.", "histories": [["v1", "Thu, 29 Nov 2012 11:35:25 GMT  (117kb)", "http://arxiv.org/abs/1211.6887v1", "Draft of the chapter published In: Explorations Across Languages and Corpora. PALC 2009, ed. by S. Go\\'zd\\'z-Roszkowski, Peter Lang, 2011, p. 123-133"]], "COMMENTS": "Draft of the chapter published In: Explorations Across Languages and Corpora. PALC 2009, ed. by S. Go\\'zd\\'z-Roszkowski, Peter Lang, 2011, p. 123-133", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["marcin mi{\\l}kowski"], "accepted": false, "id": "1211.6887"}, "pdf": {"name": "1211.6887.pdf", "metadata": {"source": "CRF", "title": "Automating rule generation for grammar checkers", "authors": ["Marcin Mi\u0142kowski"], "emails": [], "sections": [{"heading": null, "text": "Automation of rule generation for grammar examiners Marcin Mi\u0142kowskiPolish Academy of Sciences"}, {"heading": "1. Introduction", "text": "In this essay, I describe several approaches to the automatic or semi-automatic development of symbolic rules for grammar examiners from the information contained in corpora. The rules obtained in this way are an important complement to the manually created rules that seem to prevail in rule-based examiners. However, the manual process of rule-making is costly, time-consuming and error-prone. Therefore, it seems advisable to use machine learning to create the rules automatically or semi-automatically. Therefore, the results obtained seem to confirm our original hypothesis that symbolic machine learning algorithms can be useful to learn new rules for grammar testing. However, it turns out that error corpora cannot be the only source of information used in grammar testing for practical purposes. We therefore suggest that only by using different approaches grammar examiners or general computer-based correction tools will it be possible to learn how to cover the most common and most common algorithms before they are applied."}, {"heading": "2. Three approaches to rule-based grammar checking", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "3. Machine learning of rules", "text": "In fact, it is the case that most people are able to put themselves in a different world, in which they are able to live in, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live."}, {"heading": "4. Approaches to learning from the error corpus", "text": "In fact, it is as if it is a reactionary project, in which it is only an attempt."}, {"heading": "5. Adapting the rules to LanguageTool and future work", "text": "The rules of TBL, as noted, can easily be translated into the notation of declarative symbolic rules used in LanguageTool (the exact description of the notation is outside the scope of this paper). Rules are specified in XML files as patterns of tokens, but tokens can be automatically tested for multiple attributes (such as POS tags, lemmas and surface shapes) and relationships (including linking, negation, exceptions, conditional skipping of tokens forward, and unification of attributes). Attributes can be specified as regular expressions. Therefore, the rules can be much more general than the rules created by TBL. So, although it may be possible to automatically convert transformation rules to LT notation, to transform human intervention, it is still advisable to make them more general than the rules created by TBL."}], "references": [{"title": "Transformation-Based Error-Driven Learning and Natural Language. A Case Study in Part of Speech Tagging.", "author": ["E. Brill"], "venue": "Computational Linguistics,", "citeRegEx": "Brill,? \\Q1995\\E", "shortCiteRegEx": "Brill", "year": 1995}, {"title": "Transformation-based correction of rule-based MT.", "author": ["J. Elming"], "venue": "Proceedings of EAMT", "citeRegEx": "Elming,? \\Q2008\\E", "shortCiteRegEx": "Elming", "year": 2008}, {"title": "Random House Unabridged Dictionary", "author": ["B. Flexner S"], "venue": null, "citeRegEx": "S.,? \\Q1983\\E", "shortCiteRegEx": "S.", "year": 1983}, {"title": "Using Contextual Speller Techniques and Language Modeling for ESL Error Correction", "author": ["M. Gamon", "J. Gao", "Brockett", "Ch", "A. Klementiev", "W. Dolan", "D. Belenko", "L. Vanderwende"], "venue": "Proceedings of IJCNLP", "citeRegEx": "Gamon et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Gamon et al\\.", "year": 2008}, {"title": "Transformation-Based Learning of Danish Grammar Correction.", "author": ["D. Hardt"], "venue": "Proceedings of RANLP", "citeRegEx": "Hardt,? \\Q2001\\E", "shortCiteRegEx": "Hardt", "year": 2001}, {"title": "S\u0142ownictwo wsp\u00f3\u0142czesnego j\u0119zyka polskiego", "author": ["I. Kurcz", "A. Lewicki", "J. Sambor", "J. Woronczak"], "venue": "Listy frekwencyjne. Tom I. Teksty popularnonaukowe. Warszawa: Uniwersytet Warszawski", "citeRegEx": "Kurcz et al\\.,? \\Q1974\\E", "shortCiteRegEx": "Kurcz et al\\.", "year": 1974}, {"title": "S\u0142ownictwo wsp\u00f3\u0142czesnego j\u0119zyka polskiego", "author": ["A. Lewicki", "J. Sambor", "J. Woronczak"], "venue": "Listy frekwencyjne. Tom IV. Proza artystyczna. Warszawa: Uniwersytet Warszawski", "citeRegEx": "Kurcz et al\\.,? \\Q1976\\E", "shortCiteRegEx": "Kurcz et al\\.", "year": 1976}, {"title": "S\u0142ownictwo wsp\u00f3\u0142czesnego j\u0119zyka polskiego", "author": ["I. Kurcz", "A. Lewicki", "J. Sambor", "J. Woronczak"], "venue": "Listy frekwencyjne. Tom V. Dramat artystyczny. Warszawa: Uniwersytet Warszawski. Lager, T", "citeRegEx": "Kurcz et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Kurcz et al\\.", "year": 1977}, {"title": "S\u0142ownictwo wsp\u00f3\u0142czesnego j\u0119zyka polskiego", "author": ["A. Bergen. Lewicki", "W. Mas\u0142owski", "J. Sambor", "J. Woronczak"], "venue": "Workshop on Computational Natural Language Learning", "citeRegEx": "Lewicki et al\\.,? \\Q1975\\E", "shortCiteRegEx": "Lewicki et al\\.", "year": 1975}, {"title": "A Rule-Based Style and Grammar Checker, Diplomarbeit, Bielefeld: Universit\u00e4t Bielefeld", "author": ["Naber Daniel"], "venue": "Available at: http://www.danielnaber.de/languagetool/download/style_and_grammar_chec", "citeRegEx": "Daniel,? \\Q2003\\E", "shortCiteRegEx": "Daniel", "year": 2003}, {"title": "Rule-based Translation With Statistical Phrase-based Post-editing.", "author": ["Lane\u201d. In"], "venue": "Proceedings of the Second Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),", "citeRegEx": "In,? \\Q2007\\E", "shortCiteRegEx": "In", "year": 2007}, {"title": "Faking errors to avoid making errors: Very weakly supervised learning for error detection in writing", "author": ["J. Sj\u00f6bergh", "O. Knutsson"], "venue": "Computational Linguistics,", "citeRegEx": "Sj\u00f6bergh and Knutsson.,? \\Q2005\\E", "shortCiteRegEx": "Sj\u00f6bergh and Knutsson.", "year": 2005}], "referenceMentions": [{"referenceID": 3, "context": "It might be used for ESL grammar checking (Gamon et al. 2008).", "startOffset": 42, "endOffset": 61}, {"referenceID": 0, "context": "TBL is most well-known for its application in the Brill tagger (Brill 1995), however, it may be used in a wide variety of NLP tasks that involve classification.", "startOffset": 63, "endOffset": 75}, {"referenceID": 4, "context": "Such approach has been taken in transformationbased learning for punctuation correction in Danish (Hardt 2001).", "startOffset": 98, "endOffset": 110}, {"referenceID": 1, "context": "They have been used to learn transformation rules that automatically correct machine-translated text and improve its quality (Elming 2008).", "startOffset": 125, "endOffset": 138}], "year": 2011, "abstractText": "In this paper, I describe several approaches to automatic or semiautomatic development of symbolic rules for grammar checkers from the information contained in corpora. The rules obtained this way are an important addition to manually-created rules that seem to dominate in rulebased checkers. However, the manual process of creation of rules is costly, time-consuming and error-prone. It seems therefore advisable to use machine-learning algorithms to create the rules automatically or semiautomatically. The results obtained seem to corroborate our initial hypothesis that symbolic machine learning algorithms can be useful for acquiring new rules for grammar checking. It turns out, however, that for practical uses, error corpora cannot be the sole source of information used in grammar checking. We suggest therefore that only by using different approaches, grammar-checkers, or more generally, computer-aided proofreading tools, will be able to cover most frequent and severe mistakes and avoid false alarms that seem to distract users. In what follows, I will show how Transformation-Based Learning (TBL) algorithms may be used to acquire rules. Before doing that, I will discuss the pros and cons of three approaches to creating rules and show the need to make use of them all in a successful grammar-checking tool. The results obtained seem to suggest that the machine-learning approach is actually fruitful, and I will point to some future work related to the reported research.", "creator": "Writer"}}}