{"id": "1212.2414", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Dec-2012", "title": "Mining Techniques in Network Security to Enhance Intrusion Detection Systems", "abstract": "In intrusion detection systems, classifiers still suffer from several drawbacks such as data dimensionality and dominance, different network feature types, and data impact on the classification. In this paper two significant enhancements are presented to solve these drawbacks. The first enhancement is an improved feature selection using sequential backward search and information gain. This, in turn, extracts valuable features that enhance positively the detection rate and reduce the false positive rate. The second enhancement is transferring nominal network features to numeric ones by exploiting the discrete random variable and the probability mass function to solve the problem of different feature types, the problem of data dominance, and data impact on the classification. The latter is combined to known normalization methods to achieve a significant hybrid normalization approach. Finally, an intensive and comparative study approves the efficiency of these enhancements and shows better performance comparing to other proposed methods.", "histories": [["v1", "Tue, 11 Dec 2012 13:14:42 GMT  (595kb)", "http://arxiv.org/abs/1212.2414v1", "16 pages, 7 figures"]], "COMMENTS": "16 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.CR cs.LG", "authors": ["maher salem", "ulrich buehler"], "accepted": false, "id": "1212.2414"}, "pdf": {"name": "1212.2414.pdf", "metadata": {"source": "CRF", "title": "MININGTECHNIQUES INNETWORK SECURITYTO ENHANCE INTRUSIONDETECTION SYSTEMS", "authors": ["Maher Salem", "Ulrich Buehler"], "emails": ["maher.salem@informatik.hs-fulda.de,", "u.buehler@informatik.hs-fulda.de"], "sections": [{"heading": null, "text": "DOI: 10.5121 / ijnsa.2012.4604 51KEYWORDS Sequential reverse search, information gain, normalization, probability mass function, discrete random variable."}, {"heading": "1. INTRODUCTION", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2. RELATED WORKS", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times, \"in which he said the role of the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" New York Times, \"the\" the \"New York Times,\" the \"the\" New York Times, \"the\" the \"the\" New York Times, \"the\" the \"New York Times,\" the \"the\" the \"New York Times,\" the \"the\" the \"New York Times,\" the \"the\" the \"New York Times,\" the \"the\" the \"New York Times,\" the \"the\" the \"the\" New York Times, \"the\" the \"the\" the \"the\" New York Times, \"the\" the \"the\" the \"the\" New York Times, \"the\" the \"the\" the \"New York Times,\" the \"the\" the \"the\" the \"the\" New York Times, \"the\" the \"the\" the \"the\" the \"New York Times,\" the \"the\" the \"the\" the \"New York Times,\" the \"the\" the \"the\" the \"New York Times,\" the \"the\" the \"the\" the \"New York Times,\" the \"the\" the \"the\" the \"New York Times,\" the \"the\" the \"the\" New York Times, \"the\" the \"the\" the \"New York Times, the\" the \"the\" the \"the\" New York Times, \"the\" the \"the\" the \"New York Times,\" the \"the\" the \"the\" New York Times, \"the\" the \"the\" the \"New York Times,\" the \"the\" the \"the\" the \"the\" New York Times, \"the\" the \"the\" the \"the\" New York Times, the \"the\" the \"the\" the \""}, {"heading": "3. PROPOSED ENHANCEMENTS", "text": "The proposed improvements in this research focus on two main phases of IDS, namely feature selection and normalization. Improvement of feature selection (or the first improvement) is improved by an improved method that filters out the most valuable features for IDS. On the other hand, normalization of nominal features (or the second improvement) solved the problem of different feature types, data dominance, and effects on classification, which is modified to be a hybrid approach. These improvements greatly enhance the performance of the classifier. Figure 1 shows a general overview of the proposed improvements. More details on these improvements are explained in the following subsections."}, {"heading": "3.1. Improved Feature Selection", "text": "To find the most valuable characteristics, we propose the first improvement, which is an improved method for selecting characteristics. To evaluate this improvement, we initialize a dataset with all 41 features of the NSL-KDD [23] dataset and classify it using multiple classifiers; these are Multilayer Perceptron, Na\u00efve Bayes, Random Tree and Decision Tree [13]. The following steps explain the modified SBS method: 1. Initialize D as a complete dataset with F characteristics and I instances. 2. Leave Fplus for selected characteristics and Fminus for remote characteristics 3. Initialize Fplus = PA and Fminus = 4. Select different classifiers to evaluate the detection rate and false positive rate 5. Look around."}, {"heading": "6. Repeat until D is empty", "text": "7. Fplus has the selected characteristics, which have a positive effect on the detection rate and the false positive rate. 8. Fplus has the characteristics, which do not affect the detection rate and the false positive rate. The above modified SBS characteristics suggest a threshold range, which is based on the mean and the standard deviation of the detection rate and the false positive rate of each mentioned classifier. Considering the mean value is \u03bc and the standard deviation is \u03c3, then the threshold range is defined as TM = [\u03bc-\u03c3, \u03bc + \u03c3], then \u2211 = = Ni ixN 1 and 1) (12 \u2212 \u2212 \u2212 = \u2211 = Nx Ni i i (1), where x is the input vector and N is the number of samples in a vector x. Extracted characteristics from SBS are then evaluated using the IG method. However, the information gathering method only treats discrete values. Therefore, the transmission of continuous values into discrete values is indispensable to achieve values."}, {"heading": "3.2. Hybrid Normalization", "text": "These characteristics can be considered as numerical or nominal values = = isolated values [11], which together form a data set used to train the classifier and to detect abnormal traffic flows. However, most classifiers, in particular Self Organizing Map (SOM), handle only numerical data types and operate correctly with numerical values [17]. Furthermore, nominal characteristics such as protocol type or service type will be very important for classification methods, especially through neural networks. These classifiers build a model only from numerical data types. Thus, if symbolic values are not transferred to real values, the classifier ignores them. Consequently, this will affect the performance of the classification and may lead to an increase in abnormality. In this paper, the second proposed improvement will scale the nominal values using the fact that a symbolic feature describing network traffic can be considered a discrete deviation."}, {"heading": "4. RESULTS AND DISCUSSION", "text": "The second proposed improvement in this paper depends on the first improvement, i.e. the results of the first improvement are used in the second improvement. Therefore, in this section, a mapping of the results for each improvement is presented separately. In addition, we clarify the steps of preparing and pre-processing the training and test data sets for the evaluation step. Test data sets are completely separated from the training data sets. Consequently, we have created these training and test data sets with only two class names; that is, normal and anomalous."}, {"heading": "4.1. Significant Feature Sets", "text": "This year, the number of newcomers to the US is many times higher than the number of newcomers to the US."}, {"heading": "4.2. Dataset Types for Evaluation", "text": "In the last subsections, we have specified exactly which characteristics are selected and which normalization methods are taken into account in this work. Therefore, in this subsection, we specify various data sets, which are then selected to evaluate the hybrid approach and initiate an intensive and comparative study. So, we have developed a Matlab program \"GENDA\" to generate several data sets from the MVF and MVRF (see Table 2), normalize them using the hybrid normalization method, which converts the nominal characteristics into numerical, and the other three normalization methods. This means that GENDA will generate 4 training data sets and 4 test data sets, which are normalized by the above-mentioned normalization methods for the MVRF and the same for the MVRF. Figure 4 shows record generation minus normalization rate and abbreviations listed in Table 3, where L stands for learning data sets (Training Data Set, we suggest normalization characters) for the PMF, the normalization data set proposed for PMF."}, {"heading": "4.3. Comparative and Evaluative Study", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "5. CONCLUSION", "text": "The enormous scale of network traffic and the diversity of characteristic types impair the performance of the IDS. Moreover, different scales of characteristic values negatively affect performance. Therefore, this paper proposes two major improvements to eliminate these drawbacks: The first improvement is an improved method of attribute selection, which includes a modified sequential backward search and a ranking of information gains; the second improvement is a hybrid approach, which consists of transferring nominal values of network characteristics to numerical characteristics, using a concept based on the idea of discrete random variables and probability mass function, and then combining this improvement with a known normalization method, such as decimal, statistics, or minimum maximum normalization. Multiple tools such as WEKA and Matlab are used to develop specific programs or evaluate the proposed improvements. WEKA, however, selects several classifiers for evaluation that are monitored and not monitored; the results show that the first improvement we achieve in detection rate or hybridity improves."}, {"heading": "ACKNOWLEDGMENTS", "text": "This research project \"SecMonet\" is funded by the Federal Ministry of Education and Research (BMBF 17062X10) under the funding line \"ProfUnt.\""}], "references": [{"title": "A Comparative Study of Anomaly Detection Schemes in Network Intrusion Detection", "author": ["A. Lazarevic", "L. Ertoz", "V. Kumar", "A. Ozgur", "J. Srivastava"], "venue": "Proceedings of the Third SIAM International Conference in Data Mining, 2003.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2003}, {"title": "Online Streaming Feature Selection,", "author": ["X. Wu", "K. Yu", "H. Wang", "W. Ding"], "venue": "Proceddings of the 27 International Conference on Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Attack Classification Based on Data Mining Technique and Its Application for Reliable Medical Sensor Communication", "author": ["H. Oh", "I. Doh", "K. Chae"], "venue": "International Journal of Computer Science and Applications, Vol.6, No.3, pp 20\u201332, 2009.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "A new data normalization method for unsupervised anomaly intrusion detection", "author": ["L. Chai", "J. Chem", "Y. KE", "T. Chen", "Z. Li"], "venue": "Journal of Zhejiang University-SCIENCE C (Computers & Electronics), Volume 11, Number 10, pp. 778-784, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Research on Data Normalization Methods in Multi- Attribute Evaluation", "author": ["Yu Liping", "Pan Yuntao", "Wu Yishan"], "venue": "Computational Intelligence and Software Engineering(CiSE), pp.1-5, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "A Novel Normalization Technique for Unsupervised Learning in ANN", "author": ["G. Chakraborty", "B. Chakraborty"], "venue": "IEEE TRANSACTIONS ON NEURAL NETWORKS, VOL. 11, NO. 1, pp. 253- 257,2000.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2000}, {"title": "Intrusion Detection and Attack Classifier Based on Three Techniques: A Comparative Study", "author": ["A. Brifcani", "A. Issa"], "venue": "Eng. & Tech. Journal, Vol.29, No.2, pp. 368-412, 2011.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "An Adaptive Growing Hierarchical Self Organizing Map for Network Intrusion Detection", "author": ["D. Ippoliti", "X. Zhou"], "venue": "Proceedings of 19th International Conference IEEE Computer Communications and Networks (ICCCN), pp. 2-5, 2010.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Data Preprocessing for Distance-based Unsupervised Intrusion Detection,", "author": ["D. Said", "L. Stirlingy", "P. Federolfy", "K. Barker"], "venue": "Ninth Annual International Conference on Privacy, Security and Trust,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Attribute Normalization in Network Intrusion Detection", "author": ["W. Wang", "X. Zhang", "S. Gombault", "S.J. Knapskog"], "venue": "10 International Symposium on Pervasive Systems, Algorithms, and Networks (ISPAN), pp.448-453, 2009.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Mining Audit Data to Build Intrusion Detection Models", "author": ["W. Lee", "S.J. Stolfo", "K.W. Mok"], "venue": "Proceedings of the 4thInternational Conference on Knowledge Discovery and Data Mining. pp. 66-72, AAAI Press, 1998.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1998}, {"title": "A Data Mining Framework for Building Intrusion Detection Models", "author": ["W. Lee", "S.J. Stolfo", "K.W. Mok"], "venue": "IEEE Symposium on Security and Privacy. pp. 120-132., 1999.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1999}, {"title": "Improved Feature Selection Method using SBS-IG-Plus", "author": ["M. Salem", "U. Buehler", "S. Reissman"], "venue": "ISSE 2011 Securing Electronic Business Processes, pp. 352-361, Vieweg+Teubner, 2011.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Data Mining Approaches for Intrusion Detection,", "author": ["W. Lee", "S.J. Stolfo"], "venue": "Proceedings of the 7th USENIX security symposium,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "Lilakiatsakun, \u201dComputer Network Security Based On Support Vector Machine Approach,", "author": ["W.P. Somwang"], "venue": "The 11th International Conference on Control, Automation and Systems", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Specification-based Intrusion Detection for Advanced Metering Infrastructures,", "author": ["R. Berthier", "W.H. Sanders"], "venue": "IEEE Pacific Rim International Symposium on Dependable Computing", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "The self-organizing map", "author": ["T. Kohonen"], "venue": "Proceedings of the IEEE, vol.78, no.9, pp.1464-1480, 1990.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1990}, {"title": "The WEKA Data Mining Software: An Update,", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "SIGKD D Explorations,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Empirical Comparison Of Forward And Backward Search Strategies In L-GEM Based Feature Selection With RBFNN", "author": ["Yao-Hong Chan"], "venue": "In Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "A Lightweight Intrusion Detection Model Based on Feature Selection and Maximum Entropy Model", "author": ["Yang Li"], "venue": "In Communication Technology, ICCT '06. International Conference,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Approximate Equal Frequency Discretization Method", "author": ["Sheng-yi Jiang"], "venue": "In Intelligent Systems, GCIS '09. WRI Global Congress, p", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Obviously, this kind of IDS unable to detect unknown attacks [1].", "startOffset": 61, "endOffset": 64}, {"referenceID": 13, "context": "Therefore, anomaly-based IDS investigated this problem and showed promising results that can detect unknown abnormal activities on the network, but it suffers from the high false alarm rate [14] [15].", "startOffset": 190, "endOffset": 194}, {"referenceID": 14, "context": "Therefore, anomaly-based IDS investigated this problem and showed promising results that can detect unknown abnormal activities on the network, but it suffers from the high false alarm rate [14] [15].", "startOffset": 195, "endOffset": 199}, {"referenceID": 15, "context": "The third IDS category is specification-based IDS, which defines a system specification (model) and detects when behavior differ from expected [16].", "startOffset": 143, "endOffset": 147}, {"referenceID": 18, "context": "[19] utilized the searching methods Sequential Backward Search (SBS) and sequential forward search with the Localized Generalization Error (L-GEM) as threshold criteria and Radial Basis Function Neural Network (RBFNN) as classifier.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] exploited Chi-Square with information gain.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "Therefore, a discretization approach in [21] is examined in the first enhancement.", "startOffset": 40, "endOffset": 44}, {"referenceID": 2, "context": "in [3] presented an unsupervised method to detect attacks using SOM.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "The proposed transferring method in this paper is comparied with the proposed method in [3] and results are discussed in section 4.", "startOffset": 88, "endOffset": 91}, {"referenceID": 3, "context": "[4] proposed a unified normalization distance framework for numeric and nominal records.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] have evaluated several normalization methods in multi-attributes and they concluded that different evaluation purposes require different data normalization methods.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "In [6] Chakraborty G.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "A comparative study is presented in [7], but the nominal features have been investigated in supervised learning using decision tree and interactive dichotomizer 3.", "startOffset": 36, "endOffset": 39}, {"referenceID": 7, "context": "Ippoliti and Zhou in [8] have presented a modified normalization method using minimum maximum approach that adapts the input process of the Growing Hierarchical Self Organizing Map (GHSOM).", "startOffset": 21, "endOffset": 24}, {"referenceID": 8, "context": "[9].", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] have proposed a study about normalizing network attributes; they have presented four normalization methods and evaluated them with four classifiers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "To evaluate this enhancement, we initialize a dataset with all 41 features from NSL-KDD [23] dataset and classify it using several classifiers; these are Multilayer Perceptron, Na\u00efve Bayes, Random Tree, and Decision Tree [13].", "startOffset": 221, "endOffset": 225}, {"referenceID": 20, "context": "In this regard, an equal frequency discretizer [21] is considered.", "startOffset": 47, "endOffset": 51}, {"referenceID": 10, "context": "These features can be numeric or nominal values [11], [12], those together form a dataset, which will be utilized to train the classifier and to detect abnormal traffic.", "startOffset": 48, "endOffset": 52}, {"referenceID": 11, "context": "These features can be numeric or nominal values [11], [12], those together form a dataset, which will be utilized to train the classifier and to detect abnormal traffic.", "startOffset": 54, "endOffset": 58}, {"referenceID": 16, "context": "But most classifiers, particularly Self Organizing Map (SOM), handle only numeric data type and operate properly with the numerical values [17].", "startOffset": 139, "endOffset": 143}, {"referenceID": 0, "context": "Using these relative frequencies we define a mapping pmf:\u03a9j\u2192[0,1] that transfers each nominal feature xkj\u2208\u03a9j into a real number (xkj) = fkj.", "startOffset": 60, "endOffset": 65}, {"referenceID": 0, "context": "Based on this enhancement we could scale the nominal features into real ones into the range [0,1], which is normalized in nature.", "startOffset": 92, "endOffset": 97}, {"referenceID": 0, "context": "Therefore scaling all features into one scale such as between [0, 1] is a necessary step to handle each feature exactly like others.", "startOffset": 62, "endOffset": 68}, {"referenceID": 0, "context": "Generally, every dataset consists of nominal and numeric features, the second enhancement handles only the nominal features and scale them directly into the range [0,1], but for the numeric features we", "startOffset": 163, "endOffset": 168}, {"referenceID": 0, "context": "Let f: \u2192[0,1] be the normalization function and v\u2208 the numerical value of a feature in the feature sets.", "startOffset": 8, "endOffset": 13}, {"referenceID": 0, "context": "where e is the minimum number of positions such that maximum value drop into [0,1].", "startOffset": 77, "endOffset": 82}, {"referenceID": 1, "context": "In this regard, [2] proposed an online streaming feature selection that presents a novel framework based on feature relevance.", "startOffset": 16, "endOffset": 19}, {"referenceID": 17, "context": "[18].", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "features values must be between [0,1].", "startOffset": 32, "endOffset": 37}, {"referenceID": 2, "context": "In addition to the generated datasets in table 3 we have generated another dataset based on the assumption in [3] to compare it to our results.", "startOffset": 110, "endOffset": 113}, {"referenceID": 17, "context": "61 The results of the performance parameters have been evaluated in WEKA tool [18], which is a data mining tool that consists of several implemented classifiers from different fields.", "startOffset": 78, "endOffset": 82}, {"referenceID": 2, "context": "SOM6: detection rate results of self organizing map for the normalized dataset by the normalization method proposed in [3].", "startOffset": 119, "endOffset": 122}, {"referenceID": 2, "context": "In contrast to the proposed normalization method in [3] the hybrid approach achieved more accuracy and preciseness with low false positive and smallest testing time.", "startOffset": 52, "endOffset": 55}], "year": 2012, "abstractText": "In intrusion detection systems, classifiers still suffer from several drawbacks such as data dimensionality and dominance, different network feature types, and data impact on the classification. In this paper two significant enhancements are presented to solve these drawbacks. The first enhancement is an improved feature selection using sequential backward search and information gain. This, in turn, extracts valuable features that enhance positively the detection rate and reduce the false positive rate. The second enhancement is transferring nominal network features to numeric ones by exploiting the discrete random variable and the probability mass function to solve the problem of different feature types, the problem of data dominance, and data impact on the classification. The latter is combined to known normalization methods to achieve a significant hybrid normalization approach. Finally, an intensive and comparative study approves the efficiency of these enhancements and shows better performance comparing to other proposed methods.", "creator": "Microsoft Word"}}}