{"id": "1212.3634", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Dec-2012", "title": "A comparative study of root-based and stem-based approaches for measuring the similarity between arabic words for arabic text mining applications", "abstract": "Representation of semantic information contained in the words is needed for any Arabic Text Mining applications. More precisely, the purpose is to better take into account the semantic dependencies between words expressed by the co-occurrence frequencies of these words. There have been many proposals to compute similarities between words based on their distributions in contexts. In this paper, we compare and contrast the effect of two preprocessing techniques applied to Arabic corpus: Rootbased (Stemming), and Stem-based (Light Stemming) approaches for measuring the similarity between Arabic words with the well known abstractive model -Latent Semantic Analysis (LSA)- with a wide variety of distance functions and similarity measures, such as the Euclidean Distance, Cosine Similarity, Jaccard Coefficient, and the Pearson Correlation Coefficient. The obtained results show that, on the one hand, the variety of the corpus produces more accurate results; on the other hand, the Stem-based approach outperformed the Root-based one because this latter affects the words meanings.", "histories": [["v1", "Fri, 14 Dec 2012 23:34:07 GMT  (250kb)", "http://arxiv.org/abs/1212.3634v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["hanane froud", "abdelmonaim lachkar", "said alaoui ouatik"], "accepted": false, "id": "1212.3634"}, "pdf": {"name": "1212.3634.pdf", "metadata": {"source": "CRF", "title": "TEXT MINING APPLICATIONS", "authors": ["Hanane FROUD", "Abdelmonaim LACHKAR", "Said ALAOUI OUATIK", "Sidi Mohamed", "Ben Abdellah (USMBA", "Fez"], "emails": ["hanane_froud@yahoo.fr,", "abdelmonaime_lachkar@yahoo.fr", "s_ouatik@yahoo.com"], "sections": [{"heading": null, "text": "Key concepts Arabic language; latent semantic analysis (LSA); similarity measurements; root and light controllers."}, {"heading": "1. INTRODUCTION", "text": "In fact, it is the case that most of them are able to move around without being able to move around."}, {"heading": "2. LATENT SEMANTIC ANALYSIS (LSA)", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able to put ourselves in the lead."}, {"heading": "3. ARABIC TEXT PREPROCESSING", "text": "In fact, it is the case that most of them are able to abide by the rules that they have given themselves, that they have taken care of. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is the case that they are able to abide by the rules. (...) It is not the case that they are able to abide by the rules. (...) It is the case that they are able to determine for themselves what they are doing. (...) It is as if they are able to determine for themselves. (...)"}, {"heading": "4. SIMILARITY MEASURES", "text": "In this section we discuss the four measures of similarity tested in [12] and we include these four measures in our thesis: b = b = effectiveness of the measures of semantics between Arabic words.4.1. MetricNot every distance measurement is a metric. To qualify as a metric, a measure d must meet the following four conditions: let x and y be two objects in a set and (,) d x y be the distance between two points need not be negative, that is, (,) 0d x y \u2265. 2. The distance between two objects must be zero if and only if the two objects are identical, that is, (,) d x y = if and only if x y = 3. Distance must be symmetrical, that is, distance from x to y is the same as the distance from y to x, i.e. (,) d x y y y =.4."}, {"heading": "5. EXPERIMENTS RESULTS AND DISCUSSION", "text": "Subsequently, two Arabic test datasets will be used and two schemes of similarity will be applied. (Figure 4): the Larkey's Stemmer developed by [11], and the Khoja's Correlation Coefficient (Figure 4).5.1. DatasetWe have experimented with two test datasets, both from the website: http: / / www.spa.gov.sa / for the Saudi Press Agency: the first one is a heterogeneous dataset; it's composed of different documents from different categories, Politics, and Sports).The second contains 257 documents belonging to one category (Politics).The full features of the corpus used will be presented in Table.2. Below, for each dataset, we will experiment with the above four similarities."}, {"heading": "6. CONCLUSION", "text": "In this paper, we proposed comparing and comparing the effect of two pre-processing approaches: Khojas Stemmer (root-based) and Larkey's Stemmer (stem-based) to measure similarity between Arabic words using latent semantic analysis (LSA). We experimented with different similarity measures. The root-based approach finds the three-letter roots for Arabic words without dependence on root or pattern files. The light-stemming approach removes the usual suffixes and prefixes from the words. The results come to three conclusions: 1. The Larkey's Stemmer exceeds the Khoja's Stemmer because this later influences the meaning of the words.2. The Jaccard measurement performs poorly compared to the other measurements. 3. Cosin and Pearson correlation measures and the euclidean distance are quite similar to the measurement of similarity between the Arabic words. We believe that the research presented in this paper may have a very important advantage in the second study, as it may be used in the comparative study."}], "references": [{"title": "Clustering by means of Unsupervised Decision Trees or Hierarchical and K-Means-like Algorithm", "author": ["P. Bellot", "M. El-B\u00e8ze"], "venue": "Proc. of RIAO", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Projections for Efficient Document Clustering", "author": ["H.Schutze", "C. Silverstein"], "venue": "In Proceedings of SIGIR\u201997,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "A Solution to Plato\u2019s Problem: The Latent Semantic Analysis Theory of the Acquisition, Induction, and Representation of Knowledge", "author": ["S.T. LANDAUER"], "venue": "DUMAIS", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Improving Stemming for Arabic Information Retrieval: Light Stemming and Co-occurrence Analysis", "author": ["L.S.Larkey", "L.Ballesteros", "M.E.Connell"], "venue": "The 25th Annual International Conference on Research and Development in Information Retrieval (SIGIR", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Neto.\u201dModern Information Retrieval", "author": ["R.B. Yates"], "venue": "ADDISON-WESLEY, New York,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "Fast and Effective Text Mining using Linear-time Document Clustering", "author": ["B. Larsen", "C. Aone"], "venue": "In Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "Stemming for Arabic Words Similarity Measures based on Latent Semantic Analysis Model. The 3rd International Conference on Multimedia Computing and Systems (ICMCS'12), May 10-12", "author": ["H.Froud", "A.Lachkar", "S.Ouatik"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Stemming Versus Light Stemming as Feature Selection Techniques for Arabic Text Categorization", "author": ["R. Duwairi", "M. Al-Refai", "N. Khasawneh"], "venue": "Innovations in Information Technology,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "A new algorithm to generate Arabic root-pattern forms", "author": ["Al-Fedaghi S", "F. Al-Anzi"], "venue": "In proceedings of the 11th national Computer Conference and Exhibition", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1989}, {"title": "A computational morphology system for Arabic", "author": ["Al-Shalabi R", "M. Evens"], "venue": "In Workshop on Computational Approaches to Semitic Languages,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1998}, {"title": "On Arabic search: improving the retrieval effectiveness via a light temming approach", "author": ["Aljlayl M", "O. Frieder"], "venue": "In ACM CIKM 2002 International Conference on Information and Knowledge Management,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Arabic information retrieval at UMass in TREC-10", "author": ["Larkey L", "M.E. Connell"], "venue": "Proceedings of TREC", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2001}, {"title": "Building an Arabic Stemmer for Information Retrieval", "author": ["Chen A", "F. Gey"], "venue": "In Proceedings of the 11th Text Retrieval Conference (TREC", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2002}, {"title": "The Qur'An: An Introduction", "author": ["Abu-Hamdiyyah", "Mohammad"], "venue": "Authors Miss. Hanane Froud Phd Student in Laboratory of Information Science and Systems, ECOLE NATIONALE DES SCIENCES APPLIQUE\u0301ES,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "Generally, Arabic Text Mining applications usually represent documents as \u2018Bags-of-Words\u2019 or Vector Space Model (VSM) [1][2][3], in which text documents are represented as a set of points in a high dimensional vector space.", "startOffset": 118, "endOffset": 121}, {"referenceID": 6, "context": "In the other hand, the Arabic Documents Representation may also be impacting by the use of different text pre-processing approaches, which affect any Text Mining tasks as we have already concluded in our previous works [7][15].", "startOffset": 222, "endOffset": 226}, {"referenceID": 6, "context": "The main goal of this paper is to compare and contrast the effect of two preprocessing techniques, that affect the document's semantics, applied to Arabic corpus: Root-based (Stemming), and Stem-based (Light Stemming) approaches for measuring the semantic between Arabic words with the well known abstractive model -Latent Semantic Analysis (LSA)- with different distance functions and similarity measures [15], to overcome the above problems for Arabic Documents Representation.", "startOffset": 406, "endOffset": 410}, {"referenceID": 1, "context": "We used SVD technique to reduce the dimensionality of the vector space [4] [5], and to build the word representative matrix.", "startOffset": 71, "endOffset": 74}, {"referenceID": 2, "context": "Latent Semantic Analysis (LSA) model is the automatic procedure proposed by [9] to construct a vector space.", "startOffset": 76, "endOffset": 79}, {"referenceID": 13, "context": "Modern Standard Arabic has a rich morphology, based on consonantal roots, which depends on vowel changes and in some cases consonantal insertions and deletions to create inflections and derivations which make morphological analysis a very complex task [22].", "startOffset": 252, "endOffset": 256}, {"referenceID": 3, "context": "Root-based versus Stem-based approaches Arabic stemming algorithms can be classified, according to the desired level of analysis, as root-based approach (Khoja [10]); stem-based approach (Larkey [11]).", "startOffset": 195, "endOffset": 199}, {"referenceID": 8, "context": "Al-Fedaghi and Al-Anzi algorithm tries to find the root of the word by matching the word with all possible patterns with all possible affixes attached to it [17].", "startOffset": 157, "endOffset": 161}, {"referenceID": 9, "context": "AlShalabi morphology system uses different algorithms to find the roots and patterns [18].", "startOffset": 85, "endOffset": 89}, {"referenceID": 10, "context": "Light stemmer is mentioned by some authors [19,20,11,21], but till now there is almost no standard algorithm for Arabic light stemming, all trials in this field were a set of rules to strip off a small set of suffixes and prefixes, also there is no definite list of these strippable affixes.", "startOffset": 43, "endOffset": 56}, {"referenceID": 11, "context": "Light stemmer is mentioned by some authors [19,20,11,21], but till now there is almost no standard algorithm for Arabic light stemming, all trials in this field were a set of rules to strip off a small set of suffixes and prefixes, also there is no definite list of these strippable affixes.", "startOffset": 43, "endOffset": 56}, {"referenceID": 3, "context": "Light stemmer is mentioned by some authors [19,20,11,21], but till now there is almost no standard algorithm for Arabic light stemming, all trials in this field were a set of rules to strip off a small set of suffixes and prefixes, also there is no definite list of these strippable affixes.", "startOffset": 43, "endOffset": 56}, {"referenceID": 12, "context": "Light stemmer is mentioned by some authors [19,20,11,21], but till now there is almost no standard algorithm for Arabic light stemming, all trials in this field were a set of rules to strip off a small set of suffixes and prefixes, also there is no definite list of these strippable affixes.", "startOffset": 43, "endOffset": 56}, {"referenceID": 3, "context": "In order to test the effect of the two stemming approaches above on the similarity measures with the LSA model, we selected tow famous Stemming algorithms: the Morphological Analyzer from Khoja and Garside [10], and the Light Stemmer developed by Larkey [11].", "startOffset": 254, "endOffset": 258}, {"referenceID": 4, "context": "Cosine Similarity Cosine similarity is one of the most popular similarity measure applied to text documents, such as in numerous information retrieval applications [13] and clustering too [14].", "startOffset": 164, "endOffset": 168}, {"referenceID": 5, "context": "Cosine Similarity Cosine similarity is one of the most popular similarity measure applied to text documents, such as in numerous information retrieval applications [13] and clustering too [14].", "startOffset": 188, "endOffset": 192}, {"referenceID": 3, "context": "EXPERIMENTS RESULTS AND DISCUSSION Experiments are applied by using two Arabic testing datasets and by applying two schemes of stemming (Figure 4) : the Larkey's Stemmer developed by [11], and the Khoja's Stemmer [10].", "startOffset": 183, "endOffset": 187}, {"referenceID": 6, "context": "The above results show that the obtained results using Larkey\u2019s Stemmer outperformed those obtained using Khoja\u2019s Stemmer, because this latter affects negatively the obtained results with LSA Model [15], when we try to measure the similarity between two different Arabic words that have the same root like: (\u0629\u0631 : \u0627, : \u0627), or different root like: (%\u0631 ' ()\u0627\u0648, *+$\u0631), (\u0639 83 , 5 \u0627\u0648).", "startOffset": 198, "endOffset": 202}, {"referenceID": 7, "context": "The Larkey\u2019s Stemmer doesn\u2019t produce the root and therefore doesn't affect the semantics of words; but it maps several words, which have the same meaning to a common syntactical form, our observation broadly agreed with [16].", "startOffset": 220, "endOffset": 224}], "year": 2012, "abstractText": "Representation of semantic information contained in the words is needed for any Arabic Text Mining applications. More precisely, the purpose is to better take into account the semantic dependencies between words expressed by the co-occurrence frequencies of these words. There have been many proposals to compute similarities between words based on their distributions in contexts. In this paper, we compare and contrast the effect of two preprocessing techniques applied to Arabic corpus: Rootbased (Stemming), and Stem-based (Light Stemming) approaches for measuring the similarity between Arabic words with the well known abstractive model -Latent Semantic Analysis (LSA)with a wide variety of distance functions and similarity measures, such as the Euclidean Distance, Cosine Similarity, Jaccard Coefficient, and the Pearson Correlation Coefficient. The obtained results show that, on the one hand, the variety of the corpus produces more accurate results; on the other hand, the Stem-based approach outperformed the Root-based one because this latter affects the words meanings.", "creator": "PDFCreator Version 1.2.3"}}}