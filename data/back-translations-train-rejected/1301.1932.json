{"id": "1301.1932", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jan-2013", "title": "An Approach for Classification of Dysfluent and Fluent Speech Using K-NN And SVM", "abstract": "This paper presents a new approach for classification of dysfluent and fluent speech using Mel-Frequency Cepstral Coefficient (MFCC). The speech is fluent when person's speech flows easily and smoothly. Sounds combine into syllable, syllables mix together into words and words link into sentences with little effort. When someone's speech is dysfluent, it is irregular and does not flow effortlessly. Therefore, a dysfluency is a break in the smooth, meaningful flow of speech. Stuttering is one such disorder in which the fluent flow of speech is disrupted by occurrences of dysfluencies such as repetitions, prolongations, interjections and so on. In this work we have considered three types of dysfluencies such as repetition, prolongation and interjection to characterize dysfluent speech. After obtaining dysfluent and fluent speech, the speech signals are analyzed in order to extract MFCC features. The k-Nearest Neighbor (k-NN) and Support Vector Machine (SVM) classifiers are used to classify the speech as dysfluent and fluent speech. The 80% of the data is used for training and 20% for testing. The average accuracy of 86.67% and 93.34% is obtained for dysfluent and fluent speech respectively.", "histories": [["v1", "Wed, 9 Jan 2013 17:42:59 GMT  (186kb)", "http://arxiv.org/abs/1301.1932v1", "10 pages,4 figures; International Journal of Computer Science, Engineering and Applications (IJCSEA) Vol.2, No.6, December 2012"]], "COMMENTS": "10 pages,4 figures; International Journal of Computer Science, Engineering and Applications (IJCSEA) Vol.2, No.6, December 2012", "reviews": [], "SUBJECTS": "cs.SD cs.AI", "authors": ["p mahesha", "d s vinod"], "accepted": false, "id": "1301.1932"}, "pdf": {"name": "1301.1932.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["maheshsjce@yahoo.com", "dsvinod@daad-alumni.de"], "sections": [{"heading": null, "text": "DOI: 10.5121 / ijcsea.2012.2603 23This paper introduces a new approach to classifying erroneous and fluid language using the Mel Frequency Cepstral Coefficient (MFCC). Speech is fluent when speech flows smoothly and smoothly. Louds combine to form syllables, syllables blend easily into words and words into sentences. If language is fluent, it is irregular and does not flow effortlessly. Therefore, a disturbance of smooth, meaningful speech flow is a disturbance. Stuttering is one such disturbance where the fluid flow of speech is disturbed by the occurrence of disturbances such as repetitions, extensions, interjections, etc. In this paper, we have considered three types of disturbances such as repetition, prolongation, and interjection to characterize faulty speech."}, {"heading": "1. INTRODUCTION", "text": "Stuttering is also known as dysphemia and stuttering is a disorder of language flow that affects speech flow. It is one of the most serious problems in speech pathology and a poorly understood disorder. Approximately 1% of the population suffers from this disorder and has found that four times as many men as women are affected [11, 5, 16, 3]. Stuttering is the subject of interest by researchers from various fields such as speech physiology, pathology, psychology, acoustics and signal analysis. Therefore, this area is a multidisciplinary field of research in the sciences. Speech fluency can be defined in terms of continuity, rate, co-articulation and effort. Continuity refers to the degree to which syllables and words are logically sequenced and also the presence or absence of pauses. When semantic units follow each other in a continuous and logical flow of information, language is interpreted as fluent."}, {"heading": "2. SPEECH DATA", "text": "The speech samples are taken from the University College London Archive of Stuttered Speech (UCLASS) [15 14], which consists of the recording of monologues, readings and conversations. 40 different speakers contribute 107 readings to the database. In this thesis, speech samples are taken from the standard reading of 25 different speakers aged between 10 and 20 years. Samples are selected to cover a wide range of age and stutter frequency. Repetition, extension and filled pause dysfluences are manually segmented by listening to the speech signal. Segmented samples are subjected to feature extraction, the same standard English passages used in the UCLASS database are used to prepare the fluent database. Twenty fluent speakers with an average age group of 25 years were made to read the passage and record it using cool edit version 2.1."}, {"heading": "3. METHODOLOGY", "text": "The overall process of fluent and fluent language classification is divided into 4 steps as shown in Figure 1."}, {"heading": "3.1. Pre-emphasis", "text": "The voice signal s (n) is sent to the high-pass filter: 2 () () (1) s n s n a s = \u2212 \u043a \u2212 (1) where s2 (n) is the output signal and the recommended value of a is usually between 0.9 and 1.0 [10] The z-transformation of the filter is 1 () 1H z a z \u2212 = \u2212 \u043c (2) The aim of this stage is to increase the amount of energy in the high frequencies."}, {"heading": "3.2. Segmentation", "text": "In this thesis, we look at three types of disturbances in the stuttered language, such as repetitions, extensions, and interjections; these were identified by listening to the recorded speech samples and segmented manually. Segmented samples are subjected to feature extraction."}, {"heading": "3.3. Feature Extraction (MFCC)", "text": "The feature extraction is used to convert an observed speech signal into a kind of parametric representation for further investigation and processing, using several feature extraction algorithms such as Linear Predictive Coefficient (LPC), Linear Predictive Cepstral Coefficient (LPCC), Mel Frequency Cepstral Coefficient (MFCC) and Perceptual Linear Prediction (PLP).The MFCC feature extraction is one of the best known and most widely used features for speech recognition, generating a multi-dimensional feature vector for each language image. In this study, we considered 12MFCCs. The method is based on human hearing perceptions that cannot perceive frequencies above 1KHz. In other words, MFCC is based on Known2 () 0.54 0.46cos, 0 11n w n n NN = \u2212 \u2264 \u2264 \u2212 \u2212 -variation of the critical bandwidth of the human ear frequency with the following [M7] short for the block."}, {"heading": "3.3.1. Step 1: Framing", "text": "In framing, we split the signal into several frames before the emphasis, so that we analyze each frame in a short time instead of analyzing the entire signal at once [9]. A hammering window is applied to each frame, resulting in information loss at the beginning and end of frames. To overcome this overlap, information is applied to re-insert the information into extracted feature frames. Frame length is set to 25 frames and there is 10ms overlap between two adjacent frames to ensure stationary overlap between frames."}, {"heading": "3.3.2. Step 2: Windowing", "text": "Windows are a point-by-point multiplication between the framed signal and the window function. Whereas in the frequency range the combination becomes the folding between the short-term spectrum and the transmission function of the window, a good window function has a narrow main lobes and low side lobes in its transmission function [9]. The purpose of using the hammering window is to minimize spectral distortion and signal discontinuities. The hammering window function is represented in the following equation: (3) If the window is defined as w (n), the window signal results in () () () () Y n X n W n = x (4) Where, N = number of samples in each frame, Y (n) = output signal, X (n) = input signal and W (n) = hammering window."}, {"heading": "3.3.3. Step 3: Fast Fourier Transform (FFT)", "text": "The purpose of FFT is to convert the signal from the time domain into the frequency domain, which prepares for the next stage (Mel frequency conversion). The basis of the Fourier transformation is the conversion of the folding of the integral impulse and the impulse response of the vocal tract in the time domain into multiplication in the frequency domain [2]. The equation results from: [] () () () Y w FFT h t X t H w X w = \u0445 (5) If X (w), H (w) and Y (w) are the Fourier transformation of X (t), H (t) and Y (t), respectively."}, {"heading": "3.3.4. Step 4: Mel Filter Bank Processing", "text": "The Mel frequency scale is linear to 1000 Hz and logarithmic thereafter [1]. A series of overlapping Mel filters is designed so that their center frequencies are equally distant from each other on the Mel scale. Filter banks can be implemented in both the time domain and the frequency domain. For the purposes of MFCC processing, filter banks are implemented in the frequency domain. The Mel scale filter bank is shown in Figure 3. Figure 3 shows a series of triangular filters used to calculate a weighted sum of filter spectral components, and the output of the process is roughly equivalent to a Mel scale. The size frequency response of each filter is triangular and corresponds to the unit at the center frequency. It also decreases linearly to zero at the center frequency of two adjacent filters. The output of each filter is the sum of its filtered spectral components corresponds to the unit at the center frequency and then at the triangular unit."}, {"heading": "3.3.5. Step 5: Discrete Cosine Transform (DCT)", "text": "In this step, the log-Mel spectrum is converted back into the time domain using DCT. The result of the conversion is called MFCCs. Since the speech signal is a folding between slowly varying stimulus response (filter) and rapidly varying glottal pulse (source), the speech spectrum consists of the spectral shell (low frequency) and the spectral details (radio frequency). Now, we have to separate the spectral shell and spectral details from the spectrum. Logarithm has the effect of changing the multiplication in addition. Therefore, we can simply convert the multiplication of the size of the Fourier into addition by taking the DCT of the logarithm of the magnitude spectrum. We can calculate the Mel frequency conception from the result of the last step with equation 7 [13].1 (log) cos, 1, 2, 3,... 21 K cepkk kk = Kk = MK."}, {"heading": "3.4. Classification", "text": "The k-Nearest Neighbor (k-NN) and SVM are used as classification techniques in the proposed approach."}, {"heading": "3.4.1. k - Nearest Neighbor (k-NN)", "text": "k-NN classifies new instance queries based on the next training examples in the Feature Space. Each query object (test speech signal) is compared with each training object (training speech signal), and then the object is classified with a majority of its neighbors, assigning the object to the class that is most common among its closest neighbors (k is a positive integer, typically small). If k = 1, the object is simply assigned to the class of its closest neighbor [8]. In this study, the minimum distance from the test speech signal to each of the training signals in the training set is calculated. This classifies test language sample that belongs to the same class as the closest or closest sample point in the training set. A Euclidean distance measurement is used to determine the proximity between the individual training data and the test data. Euclidean language sample that belongs to the same class is considered the second or second most frequent measurement (cerebral)."}, {"heading": "3.4.2 Support Vector Machines (SVM)", "text": "An SVM is a classification technique based on the statistical learning theory [17, 18]. It is a supervised learning technique that uses a labeled data set for training and tries to find a decision function that best classifies the training data. The purpose of the algorithm is to find a hyperplane to define decision boundaries between data points of different classes. The SVM classifier finds the optimal hyperplance that correctly separates (classifies) most of the data points while the distance of one or other class from the hyperplane is maximized. The hyperplane equation is given by Tw x b + (9), with w weight vector and b bias.In view of the data set labeled with the training {} 1, N i i i \u2212 y = with ix as input vector and {} 1, 1."}, {"heading": "4. RESULTS AND DISCUSSIONS", "text": "The database is divided into two subgroups: training set and test set based on the 80: 20 ratio. Table 2 shows the distribution of language segments for training and testing. To analyze language samples, we first extract the MFCC function, then two training databases for dysfluent and fluent language samples. Once the system is trained, the test set is used to estimate the performance of classifiers. The experiment was repeated three times, each time different training and test sets were randomly constructed. The results of training and tests for dysfluent and fluent language are shown in Table 3. Figure 4 shows the average classification result."}, {"heading": "5. CONCLUSIONS", "text": "The voice signal can be used as a reliable indicator of speech anomalies. We have proposed an approach to distinguish between fluent and non-fluent language based on MFCC feature analysis. Two classifiers, such as k-NN and SVM, were applied to MFCC characteristics to classify fluent and non-fluent language. Using k-NN classifiers, we have achieved an average accuracy of 86.67% and 93.34% for non-fluent language, respectively. SVM classifiers returned an accuracy of 90% and 96.67% for non-fluent and non-fluent language, respectively. In this work, we have considered three types of dysfunction that are important for classifying non-fluent language. In the future, the number of training data can be increased to improve the accuracy of test data and various functional extraction algorithms can be used to improve performance."}], "references": [{"title": "What causes stuttering?", "author": ["C C.Buchel", "M Sommer"], "venue": "PLoS Biol 2(2):", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Voice recognition algorithms using Mel Frequency Cepstral Coefficients (MFCC) and Dynamic Time Warping (DTW) techniques", "author": ["Lindasalwa"], "venue": "Journal of Computing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Three-dimensional model analysis and processing", "author": ["Hao Luo Faxin Yu", "Zheming Lu", "Pinghui Wang"], "venue": "Advanced topics in science and technology,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "A frequency spectral feature modelling for Hidden Markov Model based automated speech recognition", "author": ["Ibrahim Patel", "Y Srivinasa Rao"], "venue": "The second International conference on Networks and Communications", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "An introduction to support vector machines and other kernel-based learning methods", "author": ["Nello Cristianini", "John Shawe-Taylor"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2000}, {"title": "A tutorial on support vector machine-based methods for classification problems in chemometrics", "author": ["J Luts", "F Ojeda", "R Van de Plas", "B De Moor", "S Van Huel", "JA Suykens"], "venue": "Analytica Chimica Acta", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "If semantic units follow one another in a continual and logical flow of information, the speech is interpreted as fluent [4].", "startOffset": 121, "endOffset": 124}, {"referenceID": 1, "context": "46cos ,0 1 1 n w n n N N \uf070 \uf8eb \uf8f6 = \u2212 \u2264 \u2264 \u2212 \uf8ec \uf8f7 \u2212 \uf8ed \uf8f8 variation of the human ear\u2019s critical bandwidth with frequency [7].", "startOffset": 114, "endOffset": 117}, {"referenceID": 3, "context": "We can calculate the Mel frequency cepstrum from the result of the last step using equation 7[13].", "startOffset": 93, "endOffset": 97}, {"referenceID": 2, "context": "If k = 1, then the object is simply assigned to the class of its nearest neighbor [8].", "startOffset": 82, "endOffset": 85}, {"referenceID": 4, "context": "2 Support Vector Machines (SVM) A SVM is a classification technique based on the statistical learning theory [17, 18].", "startOffset": 109, "endOffset": 117}, {"referenceID": 5, "context": "i y \u2208 \u2212 + Where xi is input vector and yi is its corresponding label [19].", "startOffset": 69, "endOffset": 73}], "year": 2013, "abstractText": "This paper presents a new approach for classification of dysfluent and fluent speech using Mel-Frequency Cepstral Coefficient (MFCC). The speech is fluent when person\u2019s speech flows easily and smoothly. Sounds combine into syllable, syllables mix together into words and words link into sentences with little effort. When someone\u2019s speech is dyfluent, it is irregular and does not flow effortlessly. Therefore, a dysfluency is a break in the smooth, meaningful flow of speech. Stuttering is one such disorder in which the fluent flow of speech is disrupted by occurrences of dysfluencies such as repetitions, prolongations, interjections and so on. In this work we have considered three types of dysfluencies such as repetition, prolongation and interjection to characterize dysfluent speech. After obtaining dysfluent and fluent speech, the speech signals are analyzed in order to extract MFCC features. The k-Nearest Neighbour (k-NN) and Support Vector Machine (SVM) classifiers are used to classify the speech as dysfluent and fluent speech. The 80% of the data is used for training and 20% for testing. The average accuracy of 86.67% and 93.34% is obtained for dysfluent and fluent speech respectively.", "creator": "Microsoft Office Word"}}}