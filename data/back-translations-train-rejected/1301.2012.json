{"id": "1301.2012", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Error Correction in Learning using SVMs", "abstract": "This paper is concerned with learning binary classifiers under adversarial label-noise. We introduce the problem of error-correction in learning where the goal is to recover the original clean data from a label-manipulated version of it, given (i) no constraints on the adversary other than an upper-bound on the number of errors, and (ii) some regularity properties for the original data. We present a simple and practical error-correction algorithm called SubSVMs that learns individual SVMs on several small-size (log-size), class-balanced, random subsets of the data and then reclassifies the training points using a majority vote. Our analysis reveals the need for the two main ingredients of SubSVMs, namely class-balanced sampling and subsampled bagging. Experimental results on synthetic as well as benchmark UCI data demonstrate the effectiveness of our approach. In addition to noise-tolerance, log-size subsampled bagging also yields significant run-time benefits over standard SVMs.", "histories": [["v1", "Thu, 10 Jan 2013 00:47:21 GMT  (608kb,D)", "http://arxiv.org/abs/1301.2012v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["srivatsan laxman", "sushil mittal", "ramarathnam venkatesan"], "accepted": false, "id": "1301.2012"}, "pdf": {"name": "1301.2012.pdf", "metadata": {"source": "CRF", "title": "Error Correction in Learning using SVMs", "authors": ["Srivatsan Laxman", "Sushil Mittal", "Ramarathnam Venkatesan"], "emails": ["slaxman@microsoft.com", "mittal@stat.columbia.edu", "venkie@microsoft.com"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them will be able to move to another world, in which they can move to another world, in which they will be able to integrate."}, {"heading": "2. Error correction problem in learning", "text": "We assume that D is suitable for the given placement task. D, however, is not available to train the learning algorithms. Instead, the learner only has access to D = {xi, y, i): i = 1,., \"that is a label.,\" that is a label that is suitable for the given placement task., \"\" that is a label., \"that is a label-manipulated version of D2.The opponent is allowed to give examples in D where there is no more than one label."}, {"heading": "3.1 Error correction analysis", "text": "Our analysis is based on the margin-based generalization bound for SVMs regarding a sampling distribution over the original (clean) data D = 22% and then adjusts the boundary to take into account the number of label errors in the corrupt Settings-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Setting-Settings. (This is the most important quantity of interest in the Error-Setting-Setting-Setting-Setting-Setting-Setting-Setings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Settings-Sett"}, {"heading": "3.2 Importance of Class-balanced Sampling", "text": "The boundary in (4) is known to two groups of parameters. In the first group, we have r, \u03b2 and \u03b8, which are fixed by the regularity properties of D. In the second group, we have s and \u03b7, both of which are determined by our sampling strategy. Since \u03b7 depends on the sampling bias p, we will now discuss how p and s are to be fixed for optimal error correction performance. From (4) it is clear that in order to maximize the number of errors that can be tolerated, we must minimize the quantity in square brackets. The first term within the brackets is minimized if there is a minimum error correction. Figure 1 provides a graphical representation of the data corruption process. The optimal value of the sampling typically depends on the direction attack parameters, error parameters, and the true size of the minority class in D. However, none of these learners is known."}, {"heading": "4. Experiments", "text": "We present experimental results of subSVMs on simulated, linearly separable data as well as LIBSVM extracts of some UCI datasets 5. SVMs are known to play the role of clean data in our experiments. Our data corruption process follows Fig. 1. We give \"clean\" training data of size D with a minority class of size \u03b2 ', 0 < \u03b2 \u2264 0.5, the parameters \u03c1 and \u03b1 control corruption. We randomly select points for corruption, of which an \u03b1 fraction is uniformly selected under 5. http: / / www.csie.ntu.edu.tw / \u0445 cjlin / libsvmtools / datasetsrandom from the minority class and (1 \u2212 \u03b1) fractions from the other. By varying the direction of attack \u03b1, we have produced a wide range of corrupt data with varying degrees of difficulty for binary classification."}, {"heading": "4.1 Synthetic Data Experiments", "text": "In the first experiment, we created \"clean\" datasets D with 1000 d-dimensional data points from a mixture of two Gaussian distributions, each with a covariance of 0.1Id and a distance of two units between the mean values. Three d-values were used: 2, 16 and 30. A constant margin of 0.2 units was forced and incorrectly classified points were removed manually. \u03b2 varied between [0.05, 0.5] in steps of 0.05, \u03c1 = 0.75 and \u03b1 was varied between [0.0, 1.0] in steps of 0.25. We investigated the significance of a class-balanced sample in algorithm 1 (SubSVMs) by comparing two versions of it - one with a class-balanced sample (p = 1 / 2) and the other with a uniform sample (p = \u03b2). For each d, the data corresponding to each [\u03b2, \u03b1] pair was evaluated using 10 random corruptions."}, {"heading": "4.2 UCI Data Experiments", "text": "There can be two ways to test this, either the error-corrected training data can be used to retrain a fresh standard SVM. Table 1 shows the data characteristics of the 13 data sets used. The fraction of the minority class, \u03b2 ranges from 0.03 to 0.48 in the training sets and from 0.03 to 0.50 in the test sets. Functionality dimensions also vary from 4 to 300. Note that these data sets are not linearly separable, they are still called \"clean\" before being subjected to label manipulation. For generalizing different types of attacks, a difference between [0.0, 1.0] in increments of 0.25 has been specified."}, {"heading": "5. Conclusions", "text": "We present a simple algorithm (SubSVMs) for learning binary classifiers under hostile label noise. SubSVMs can efficiently correct a limited number of hostile label errors contained in linearly separable data. Attribute noise and multi-class settings enhancements are important guidelines for future work. It would also be interesting to examine the applicability of SubSVMs to solving large, loud, real-world problems where SVMs typically perform poor.9. See Appendix D for more detailed runtime."}, {"heading": "Appendix A. Error-rate of \u03a8S\u0302 w.r.t. samples drawn uniformly from D\u0302", "text": "In the absence of knowledge (whether 2 is associated with the minority class or the majority class), the overall error rate of the two classes is so high that the samples collected by D pD are measured by = max (p 1 + (1 \u2212 p) 2, (1 \u2212 p) 2, (1 \u2212 p) 2, (1 \u2212 p) 2, (1 \u2212 p) 2, (7), therefore, if = p 1 + (1 \u2212 p) 2, then2 = \u2212 p 1 \u2212 p (8) and if (1 \u2212 p) 1, (1 \u2212 p) 2, then2 = (1 \u2212 p) 1p) 1, p) 2 < max (1 \u2212 p) 2, p) = p (10), where p \u00b2 p \u00b2 p \u00b2 p \u00b2, 1 \u2212 p \u00b2)."}, {"heading": "Appendix C. Details of performance metrics", "text": "The use of Balanced Accuracy (BAC) for class imbalanced datasets is prescribed by Brodersen et al. (2010) and can simply be calculated as BAC = Sensitivity + Specificity2. (37) Sensitivity and specificity are defined as follow sensitivity = tptp + fn (38) specificity = tntp + fn (39), where tp and fp indicate the number of true and false positives, while tn and fn indicate the number of true and false negatives. Similarly, the conventional F score for unbalanced datasets can be trivially maximized by using compromising reminders for high precision. Therefore, SIF Flat (2003) serves as an alternative to the F score for unbalanced datasets and is given by SIF = 2tprtpr + 1 (40)."}, {"heading": "Appendix D. Additional Results", "text": "Tables 4, 5 and 6 show additional results to UCI data sets with L-2 loss using skew-insensitive F-Score (SIF), Area Under the Curve (AUC) or Accuracy (Accuracy)."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "This paper is concerned with learning binary classifiers under adversarial label-noise. We introduce the problem of error-correction in learning where the goal is to recover the original clean data from a label-manipulated version of it, given (i) no constraints on the adversary other than an upper-bound on the number of errors, and (ii) some regularity properties for the original data. We present a simple and practical error-correction algorithm called SubSVMs that learns individual SVMs on several small-size (log-size), class-balanced, random subsets of the data and then reclassifies the training points using a majority vote. Our analysis reveals the need for the two main ingredients of SubSVMs, namely class-balanced sampling and subsampled bagging. Experimental results on synthetic as well as benchmark UCI data demonstrate the effectiveness of our approach. In addition to noise-tolerance, log-size subsampled bagging also yields significant run-time benefits over standard SVMs.", "creator": "LaTeX with hyperref package"}}}