{"id": "1301.3193", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2013", "title": "Learning Graphical Model Parameters with Approximate Marginal Inference", "abstract": "Likelihood based-learning of graphical models faces challenges of computational-complexity and robustness to model mis-specification. This paper studies methods that fit parameters directly to maximize a measure of the accuracy of predicted marginals, taking into account both model and inference approximations at training time. Experiments on imaging problems suggest marginalization-based learning performs better than likelihood-based approximations on difficult problems where the model being fit is approximate in nature.", "histories": [["v1", "Tue, 15 Jan 2013 01:07:14 GMT  (8070kb)", "http://arxiv.org/abs/1301.3193v1", "To Appear, IEEE Transactions on Pattern Analysis and Machine Intelligence"]], "COMMENTS": "To Appear, IEEE Transactions on Pattern Analysis and Machine Intelligence", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["justin domke"], "accepted": false, "id": "1301.3193"}, "pdf": {"name": "1301.3193.pdf", "metadata": {"source": "CRF", "title": "Learning Graphical Model Parameters with Approximate Marginal Inference", "authors": ["Justin Domke"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 130 1.31 93v1 [cs.LG] 1 5Ja n20 13Index Terms - Graphical models, Conditional random fields, Machine learning, Inference, Segmentation."}, {"heading": "1 INTRODUCTION", "text": "G RAPHICAL models are a standard tool in the fields of image processing, computer vision and many other areas. Exact conclusions and conclusions are often insoluble due to the large tree width of the graph. Many previous papers include approximations of probability. (Section 4.) In this paper, we propose that parameter learning can instead be done using \"marginalization-based\" loss functions, which directly quantify the quality of predictions of a given marginal inference algorithm. This has two major advantages: First, approximation errors in the inference algorithm are taken into account in learning; second, this is robust to model misspecifications. The contributions in this paper are firstly, the general framework of marginal-based adjustment as implicit differentiation; and secondly, we show that the parameter gradient can be calculated by \"disruption\" - that is, performing the approximate algorithm twice with the parameters that are slightly based on the current loss; and third, we perform the adjustment strategy based on most of the results."}, {"heading": "2 SETUP", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Markov Random Fields", "text": "Markov random fields are probability distributions that can be written as asp (x) = 1Z (xc) and xi (xi). (1) This is defined by a graph, with a node for each random variable. The first product in Equation 1 is above the set of cliques c in the graph, while the second is above all individual variables. For example, the graph x2x3 x4x5 x6 corresponds to the distribution curve (x) = 1Z. Every function curve (x2, x3, x5) is positive (x3, x4). The factor Z ensures normalization. The motivation for these types of models is the Hammersley-Clifford curve (x6). Each function curve (xc) or any other (xi) is positive, but otherwise arbitrary."}, {"heading": "2.2 Conditional Random Fields", "text": "Frequently, one is interested in modelling the conditional probability of x, because observations y are available. Of course, for such problems it is natural to define a conditional random field [2] p (x | y) = 1Z (y) \u0441\u0430\u0441\u043a\u043e (xc, y) \u0442 i\u043a (xi, y).2 In this case \u0443 (xc, y) indicates that the value for a certain configuration xc depends on the input y. In practice, the form of this dependency is application-dependent."}, {"heading": "2.3 Inference Problems", "text": "Suppose we have some distribution p (x | y), we are given some input y = general x function, and we have to guess a single output vector x *. What is the best guess? The answer clearly depends on the meaning of \"best.\" One framework for answering this question is the idea of a Bayes estimator [3]. You have to specify some Utilityx function U (x, x \") to quantify how\" happy \"you are to guess x if the actual output is x. You then choose x\" to maximize the expected Utilityx problems = argmax x \"p\" (x, x \"). A natural Utilityx function is an indicator function that yields one for the exact value x, and zero otherwise. It is easy to show that the optimal estimate for this Utilityx component is the popular Maximum Posteriori (MAP), the ability is (\" MPorx, \"if the MPorx is high)."}, {"heading": "2.4 Exponential Family", "text": "The exponential family is defined by p (x; \u03b8) = exp (\u03b8 \u00b7 f (x) \u2212 A (\u03b8)), where \u03b8 is a vector of parameters, f (x) is a vector of sufficient statistics, and the log partition functionA (\u03b8) = log \u2211 xexp\u03b8 \u00b7 f (x). (3) provides normalization. Different sufficient statistics f (x) define different distributions. The exponential family is well understood in statistics. Accordingly, it is useful to note that a Markov random field (eq. 1) is a member of the exponential family, with sufficient statistics consisting of indicator functions for each possible configuration of each clip and each variable [8], namely f (X) = {I [Xc = xc] | both are indicator functions."}, {"heading": "2.5 Learning", "text": "The focus of this paper is on learning model parameters from data. (The automatic determination of the graph structure remains an active area of research, but is not taken into account here.) Specifically, we assume the goal of learning to minimize empirical risk. (3) The summation is above all examples in the data set, and the loss function L (3) quantifies how well the distribution defined by the parameter vector corresponds to the example x. Several loss functions will be adjusted in Section 4. We assume that the empirical risk is adjusted by means of a gradient-based optimization. Therefore, the most important technical questions in learning are which loss function to use and how to calculate the gradient dLdledge. In practice, we will normally be interested in adjusting the conditional distributions. On the basis of the notation from Eq. 5, we can ignore these asR (3) = compatible (y, x) distribution problems."}, {"heading": "3 VARIATIONAL INFERENCE", "text": "In Section 3.1, the exact principle of variation shows that the (insoluble) problem of calculating the log partition function can be transformed into a (still insoluble) optimization problem. To derive a comprehensible marginalization algorithm, we approach this optimization and yield an approximate log partitioning function A. The approximate margins are then taken as the exact gradient of A elements. We define the reverse mapping to return a parameter vector that leads to marginalization. While this will generally not be unique [8, paragraph 3.5.2], two vectors that generate the same parameter (\u00b5) and generate the same marginal distribution (\u00b5) will be so unambiguous."}, {"heading": "3.1 Exact Variational Principle", "text": "Theorem (Exact principle of variation). The log partition function can also be represented as A (\u03b8) = max. \u00b5-M \u03b8 \u00b7 \u00b5 + H (\u00b5), (8), where M = {\u00b5 \u2032: \u03b8, \u00b5 \u2032 = \u00b5 (\u03b8)} is the marginal polytopic, andH (\u00b5) = \u2212 \u2211 xp (x; \u03b8 (\u00b5)) log p (x; \u03b8 (\u00b5))) is the entropy. In tree-like graphs, this optimization can be efficiently solved. In general, however, it is insoluble in two respects: firstly, the marginal polytopic M is difficult to characterize. Secondly, entropy is insoluble."}, {"heading": "3.2 Mean Field", "text": "The idea of the center field is to approximate the exact principle of variation by replacing M with a certain square subset F-M, so that F is easy to characterize, and for each vector \u00b5-F we can calculate entropy exactly. To generate such a set F, instead of looking at the set of center vectors available from each parameter vector (which characterizes M), we look at a subset of tractable parameter vectors. The easiest way to achieve this is to restrict the observation to parameter vectors \u03b8 (xc) = 0 for all factors that c.F = {\u00b5 \u2032: we perceive square, p = \u00b5-square, p-square (xc-square). It is not difficult to see that this corresponds to the set of fully factored distributions \u03b8 (xc) = 0. Also note that this (in non-treelike quadratic quadratic quadratic graphs) has the same as M, but it is not an exhibited set."}, {"heading": "3.3 Tree-Reweighted Belief Propagation", "text": "While the center field replaces the marginal polytopic with a subset (14), the local polytopy (16) replaces the reweighted faith propagation (TRW) with a superset (TRW), which can clearly only increase the value of the approximate log partition function if further approximation is required, since entropy remains intolerable for any mean vector function. (It is not even defined for the approximate log partition function. (TRW further approaches entropy with a tractable upper limit.) Together, these two approximations result in a tractable upper limit for the log partition function. (TRW is based on the optimization of Problem A) = max."}, {"heading": "4 LOSS FUNCTIONS", "text": "In the field of space, only a representative sample of previous work can be cited. A recent review [10] is more thorough. Although, technically speaking, a \"loss\" should be minimized, we continue to use this terminology for probability and its approximations where one wants to maximize. For simplicity, let us refer to the generative setting: the use of the same loss functions for the formation of a conditional model is simple (Section 2.5)."}, {"heading": "4.1 The Likelihood and Approximations", "text": "The classical loss function would be the probability of using L (\u03b8, x) = log p (x; \u03b8) = \u03b8 \u00b7 f (x) \u2212 A (\u03b8). (19) This has the gradient dL d\u03b8 = f (x) \u2212 \u00b5 (\u03b8). (20) One argument for the probability is that it is efficient; with a correct model, they converge at an asymptotically optimal rate with true parameters [11]. Some previous work has used tree-structured diagrams in which marginals can be calculated accurately [12]. Of course, the probability and gradient in diagrams with high tree widths are not precisely calculated due to the presence of the protocol distribution function A (\u03b8) and marginals \u00b5 (\u03b8), which has motivated a variety of approximations, the first being to approximate the marginal values with Markov chain in Monte Carlo [13] [14], [14] which can lead to high computing costs (especially if the problem runs below the marginal chains, where only the indicative chains can be approached)."}, {"heading": "4.1.1 Surrogate Likelihood", "text": "A seemingly heuristic approach would be to replace the marginals in Eq.20 with those of an approximate inference method, which may well be a matter of principle if, instead of approximating the log partition function, one thinks of the probability itself (Eq.19), the corresponding approximate marginals will crystallize as the exact gradient of this surrogate loss. This \"surrogate probability\" [17] appears to be the most commonly used loss in educational problems, with marginals approaching either the center [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25]. However, the terminology of \"surrogate probability\" is not widely used and in most cases only the gradient is calculated, which means that optimization cannot use line searches."}, {"heading": "4.1.2 Expectation Maximization", "text": "In many applications, only a subset of variables can be observed. Suppose that we want to model x = (z, h) where z is observed but h is hidden. A natural loss function here is the expected maximization (EM) lossL (\u03b8, z) = log p (z; \u03b8) = log \u2211 hp (z, h; \u03b8). It is easy to prove that this is equivalent to L (\u03b8, z) = A (\u03b8, z) \u2212 A (\u03b8, z), (21) where A (\u03b8, z) = log \u2211 h exp\u03b8 \u00b7 f (z, h) the log partition function with z is \"jammed\" to the observed values. If all variables are observed, A (\u03b8, z) is reduced to \u03b8 \u00b7 f (z). On the other hand, if a variational approximation for A (\u03b8, z) is replaced, a \"variable EM\" algorithm [8, Sec 6.2.2] can be reestablished, the relationship between the parameters and the sorter is changed to the one here."}, {"heading": "4.1.3 Saddle-Point Approximation", "text": "A third approximation of the probability is the search for a \"saddle point.\" Here, the gradient in Equation 20 is approached by running a (presumably approximate) MAP inference algorithm and then imagining that the marginals set the uniformity probability to the approximate MAP solution and to zero elsewhere [27], [28], [21]. This is a heuristic method, but it can be expected to work well if the estimated MAP solution is close to the true MAP and the conditional distribution p (x | y) has a strong \"peak.\""}, {"heading": "4.1.4 Pseudolikelihood", "text": "Finally, there are two classes of probability approximations that do not require any conclusions: The first is the classic pseudo-probability [29], in which L (\u03b8, x) = \u2211 ilog p (xi | x \u2212 i; \u03b8) is used. It can be calculated efficiently, even in diagrams with high tree width, since conditional probabilities are easy to calculate. Besag [29] showed that under certain conditions they converge with the true parameter vector when the amount of data becomes infinite. Pseudo-probability has been used in many applications [30], [31].6 Instead of the probability of individual variables given to all others, one can take the probability of patches of variables, sometimes referred to as \"patch\" pseudo-probability [32]."}, {"heading": "4.1.5 Piecewise Likelihood", "text": "More recently, Sutton and McCallum [33] suggested the probability of a piece. The idea is to approximate the log partition function as the sum of the log partition functions of the different \"parts\" of the chart. There is flexibility in determining which parts to use. In this essay, we will use pieces that consist of each clique and each variable, which has worked better in practice than some alternatives. Then, you have the replacement partition function A-1-2-2-3. In practice, sometimes it is best to make some heuristic adjustments to the parameters after learning to improve test time performance [34], [35]."}, {"heading": "4.2 Marginal-based Loss Functions", "text": "In the light of the discussion in Section 4.1, one might conclude that probability, although difficult to optimize, is an ideal loss function, since it will approach the true parameters in the face of a well-specified model with asymptotically efficient rates. However, this conclusion is complicated by two problems: firstly, the maximum probability solution is mathematically insoluble, which motivates the above-mentioned approximations; secondly, the question of missing the model is too simplistic; for many types of complex phenomena, we will wish to adapt a model that is approximate in nature; this may be true because the conditional independence asserted in the diagram is not accurate, or because the parameterization of factors is too simplistic; these approximations may arise from ignorance, due to a lack of knowledge of the domain to be studied, or intentionally, because the true model may have too many degrees of freedom to conform with available data."}, {"heading": "4.2.1 Univariate Logistic Loss", "text": "Univariate logistical loss [39] is defined by L (\u03b8, x) = \u2212 \u2211 ilog \u00b5 (xi; \u03b8), whereby we use the notation \u00b5 to indicate that the loss is implicitly defined in relation to the marginal forecasts of some (possibly approximate) algorithms and not to the true marginal. This measures the mean accuracy of all univariate margins, not to the common distribution. This loss can be regarded as empirical risk minimization of the KL divergence between the true marginal and the predicted, since \u2211 iKL (qi | | \u00b5i) = \u2211 i-xiq (xi) log q (xi) \u00b5 (xi; \u03b8) = konst. \u2212 E q-ilog\u00b5 (xi; \u03b8). If it is defined in exact marginal, it is a kind of composite probability [40]."}, {"heading": "4.2.2 Smoothed Univariate Classification Error", "text": "Perhaps the most natural loss in the conditional context would be the univariate classification error, L (\u03b8, x) = \u2211 iS (max x \u2032 i 6 = xi\u00b5 (xi; \u03b8) \u2212 \u00b5 (xi; \u03b8))), where S (\u00b7) is the step function. This measures exactly the number of components of x that would be predicted incorrectly using the MPM inference. Of course, this loss is neither differentiable nor continuous, which makes optimization using gradient-based methods impractical. Instead, Gross et al. [5] suggest approaching with a sigmoid function S (t) = (1 + exp (\u2212 \u03b1t) \u2212 1, where \u03b1 controls the approximation quality. There is evidence [36], [5] that the smoothed classification loss can produce parameters with lower univariable classification errors under MPM inference. However, our experience is that it is also more prone to getting stuck in local minimums, which makes interpretation more difficult."}, {"heading": "4.2.3 Clique Losses", "text": "Each of the above univariate losses can instead be taken on the basis of cliques. For example, the logistical loss of the clique isL (\u03b8, x) = \u2212 \u2211 clog\u00b5 (xc; \u03b8), 7 10 0 10 1 10 2 10 30 0,1 0,2 0,3 # training date ean test error or shift of 010 010 110 210 3 # training datashift of 310 010 110 210 3 # training datashift of 10probability clique logistic univariate logistics Figure 1: Mean test error of different with exact consequence of trained loss functions. In the case of a well-specified model (shift of zero) the probability is essentially identical to the marginal loss functions. However, if an incorrect specification is introduced, completely different estimates arise. These can be regarded as empirical risk minimization of the mean KL divergence of the true clique margins. An advantage of this with an exact model is consistency. Simple examples of perfect cases, although the joint conditions must be corrected exactly in spite of the need to be distributed."}, {"heading": "4.2.4 Hidden variables", "text": "Marginal loss functions can accommodate hidden variables simply by using the loss sum over the observed variables. A similar approach can be applied with pseudo-probability or piecemeal probability."}, {"heading": "4.3 Comparison with Exact Inference", "text": "To compare the effects of different loss functions in the event of a misspecification of the model, this section contains a simple example where the graphical model assumes the following \"chain structure\":.... x1 x2 x3 x4 xny1 y2 y3 y4 ynHere, an exact inference is possible so that the comparison is not complicated by approximate inference. All variables are binary; the parameters are generated from the interval [\u2212 1, + 1] for all i and xi by random assumption of \u03b8 (xi) (xj) (xj) = t if xi = xj) = \u2212 t, if xi 6 = xj, where t is randomly selected from the interval [\u2212 1, + 1] for all (i, j). Interaction parameters are taken as \u03b8 (yi, yj) = t if xi = xj, and \u03b8 (xi, xj) = t if xi = 6, where xi = 6, j = xi, where [vi] all are selected."}, {"heading": "4.4 MAP-Based Training", "text": "Another class of methods explicitly optimizes the performance of MAP inference [42], [43], [44], [45], [25]. This paper focuses on applications that use marginal inference and may need to consider hidden variables, and therefore focuses on probability and marginal losses."}, {"heading": "5 IMPLICIT FITTING", "text": "s not difficult to predict the value of the loss for one of the marginal loss functions. However, you can simply run the inference algorithm and put the resulting marginal loss into the loss. However, we also need the gradient dLd\u03b8. Our first result is that the loss gradient can be achieved by solving a sparse linear system. Here, it is useful to introduce a notation to distinguish the loss L, defined in terms of the parameters of dimarginal Q, directly in terms of the marginal defined \u2212 climarginal p. (Note that the notation suggests the application to marginal losses, this is a generic result.) Theoretically, it is reasonable in theory to define the loss that defines L in terms of \u2212 marginal loss \u2212 in terms of L, this is a generic result."}, {"heading": "6 PERTURBATION", "text": "This section notes that variation methods have a special structure that makes it possible to calculate derivatives without explicit formation or inversion of a linear system. (23) However, a classic trick in scientific calculation is to efficiently calculate Jacobian vector products by finite differences. The basic result is that for any arbitrary vector v, d\u00b5d\u03b8T v = lim r \u2192 01r (\u00b5) \u2212 \u00b5 (\u00b5) \u2212 Normal trick in scientific calculation is that essentially only the definition of derived products by finite differences in the direction of v. Now this does not seem to be immediately helpful, since Eq. 23 requires d\u00b5 Tdhabi, not dp."}, {"heading": "7 TRUNCATED FITTING", "text": "Previous methods for calculating loss gradients are derived from the assumption that inference optimization is precisely defined. Of course, in an implementation, a certain convergence threshold must be used. Various convergence thresholds can be used in the learning phase and in the testing phase. In practice, we have observed that a too loose threshold in the learning phase can lead to a poor estimated risk gradient, and learning ends with a poor search direction. Meanwhile, a loose threshold can often be used at test times with few consequences. Normally, a difference of 10 \u2212 3 in estimated margins has little practical impact, but this may still be enough to discourage learning from success."}, {"heading": "7.1 Back Mean Field", "text": "The idea behind this is as follows: Suppose we start with uniform marginal values, perform N-iterations of the center field and then - regardless of whether the center field has converged or not - take predicate marginal values and insert them into one of the marginal loss functions. Since each step in this process is differentiable, this specifies the loss as a differentiable function of model parameters. We want the exact course of this function. Theorem. After the execution of the rear center field can (xi) = dLd\u03b8 (xi) \u2212 and thus the loss as a differentiable function of model parameters. A proof sketch can be found in Appendix C. In rough terms, the proof takes the form of a mechanical differentiation of the individual steps c: c: each step of the inference process c: 10Algorithm 2: Back Mean Field 1)."}, {"heading": "7.2 Back TRW", "text": "Next, we consider the truncated fit to the TRW inference. As described above, we assume that a fixed number N of inference iterations has been performed, and we want to define and differentiate a loss defined on the basis of the currently predicted margins. Alg. 3 shows the method. Theory. after executing back TRW, \u2190 \u2212 \u03b8 (xi) = dLd\u03b8 (xi) and \u2190 \u2212 \u03b8 (xc) = dLd\u03b8 (xc). Again, a sketch of evidence is in Appendix C. Using only paired factors, uniform probabilities of appearance of \u03c1 = 1, all references to the stack are removed and instead of a fixed number of iterations, a convergence threshold is essentially obtained, Eaton and Ghahramani's back faith propagation [53, extended version, fig. 5]. Here, we refer to the general strategy of using the full (untruncated) inference as a \"backagation\" with either LBP or LBP."}, {"heading": "7.3 Truncated Likelihood & Truncated EM", "text": "The reason for this is that these losses (Eqs. 19 and 21) are similarly put on a stack. b) mc (xi). (xc). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c). (c) (c). (c). (c). (c). (c) (c)."}, {"heading": "8 EXPERIMENTS", "text": "These experiments take into account three different sets of data with different complexity. In all cases, we try to keep the characteristics used relatively simple, which means some sacrifices in performance compared to the use of complex characteristics, which are more carefully matched to the different problem areas. However, since our goal is to measure the relative performance of the different algorithms, we use simple characteristics for the sake of experimental transparency. We compare marginal learning methods with surrogate probability / EM, pseudo-probability and piecemeal probability. These comparisons were chosen because, firstly, they are most popular in the literature (paragraph 4). Secondly, surrogate probability also requires marginal conclusions, i.e. a comparison of \"apples against apples\" with the same consequence method. Thirdly, these methods can all deal with hidden variables that appear in our third data set. In each experiment, an \"independent\" model with universal characteristics was trained only with logical loss in order to initialize others."}, {"heading": "8.1 Setup", "text": "Learning uses the LBFGS optimization algorithm. Values \u03b8 are parameterized linearly with respect to unit and edge characteristics. Formally, we fit two matrices, F and G, which determine all unit characteristics and edge characteristics, respectively. These can be expressed most elegantly by introducing a bit more notation. Similarly, let us designate the set of parameter values \u03b8 (xi) for all values xi. If u (y, i) designates the vector of unit characteristics for variable i in the input image y, then \u03b8i = Fu (y, i). Similarly, let us designate the set of parameter values \u03b8 (xi, xj) for all xi, xj. If v (y, i, j) is the vector of unit characteristics for variable i in the input image y, then let us designate the vector of parameter values \u03b8 (xi, xj) for all xi, xj."}, {"heading": "8.2 Binary Denoising Data", "text": "In a first experiment, we create a binary denocialization problem using the Berkeley segmentation dataset. The noise input values are then generated as yi = xi (1 \u2212 tni) + (1 \u2212 xi) t n i, where xi is the true binary designation and ti [0, 1] is random. In this case, it is the noise level at which lower values correspond to more noise. Thirty-two images were used for training, and 100 for the test. This is something of a 12toy problem, but the ability to systematically vary the noise level is illustrative. As non-standard features u (y, i), we only use two features where the noise levels are the same: a constant of 1, and the noise input value at that pixel."}, {"heading": "8.3 Horses", "text": "Second, we use the Weizman horse dataset, consisting of 328 images of horses in different resolutions. We use 200 for training and 128 for testing. The amount of possible labels xi is again binary - either the pixel is part of a horse or not. For unary characteristics u (y, i), we start by calculating the RGB intensities of each pixel, along with the normalized vertical and horizontal positions. We expand these 5 initial characteristics into a larger set with sinusoidal expansion. [54] Specifically, we name the five original characteristics by s. Then we count the characteristics sin (c \u00b7 s) and cos (c \u00b7 s) for all binary vectors c of the corresponding length. This results in an extended set of 64 characteristics. To these we add (a) input (b) True labels (c) surr. How. TRW (d) UTRW (e) class = 50 TRW."}, {"heading": "8.4 Stanford Backgrounds Data", "text": "Our latest experiments consider the Stanford Backgrounds dataset. This consists of 715 images of the resolution 13 (a) Input Image (b) True Labelstion approx. 240 x 320. Most pixels are labeled as one of eight classes, with some unlabeled. The simple features u (y, i) that we use here are identical to those for the horses dataset. In preliminary experiments, we tried to perform training models with different resolutions. We found that reducing the resolution to 20% of the original after calculating characteristics, then upsampling the predicted marginals yielded significantly better results than with the original resolution. Therefore, this is done for all the following experiments: Edge characteristics are identical to those for the horses dataset, except on the difference of the RGB intensities, which means 22 total marginal characteristics v (y, j). In an initial experiment, we compare the performance of truncated adjustment, perturbation and back propagation, using 100 images from this dataset we learn for the speed."}, {"heading": "9 CONCLUSIONS", "text": "In this paper, we focus on three: the error specification of the model, the need for approximate inference, and computational complexity. The main technical contribution of this paper consists of several training methods based on the margins predicted by a given approximate inference algorithm. These methods take model error specifications and inference approximations into account. To combat computational complexity, we introduce \"truncated\" learning, in which the inference algorithm only needs to be run for a fixed number of iterations. Truncation can also be applied, somewhat heuristically, to surrogate probability. Among earlier methods, we experimentally find the surrogate probability to exceed pseudo-probability or piecewise learning. By more accurately reflecting the test criterion of hammering loss, marginal loss functions perform even better, especially with harder problems (although the probability of separation is generally smaller than the probability of separation function and the probability of being less)."}, {"heading": "10 BIOGRAPHY", "text": "Justin Domke received his doctorate in computer science from the University of Maryland, College Park in 2009. From 2009 to 2012, he was an assistant professor at the Rochester Institute of Technology. Since 2012, he has been a member of the machine learning working group at NICTA.15."}, {"heading": "11 APPENDIX A: VARIATIONAL INFERENCE", "text": "The log partition function can also be represented as \"A\" (\"q\") = max \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m\" m \"m"}, {"heading": "12 APPENDIX B: IMPLICIT DIFFERENTIATION", "text": "Theorem. Let us assume that \u00b5 (cipitated): = argmax \u00b5 = B\u00b5 = d is cipitated. \u00b7 \u00b5 + H (cipitated). Let us define L (cipitated, x) = Q (cipitated), x. Then let us leave D = d 2Hd\u00b5d\u00b5T, dL d\u03b8 = (D \u2212 1BT (BD \u2212 1BT) \u2212 1BD \u2212 1 \u2212 D \u2212 1) dQ d\u00b5.Proof: Let us first remember the implicit differentiation theorem. \u00b7 \u00b5 + H (cipitated) + Block T (B\u00b5 \u2212 d), our implicit function results from the block-implicated terms T (a, b) = 0, bendbTfda = \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "13 APPENDIX C: TRUNCATED FITTING", "text": "A first case in which we have a \"product of powers\" is this: \"This product of powers.\" Suppose the following problem is useful in dealing with such operations. Suppose that both terms and TRW contain steps in which we first take a product of a set of terms and then normalize it. The following problem is useful in dealing with such operations. Suppose that bi = j aij and ci = bi / j aij. Then we find it useful that dci dajk = (Ii = j \u2212 ci).Corollaryate is useful in dealing with such operations. Under the same conditions, dLdajk = cj ajk = cj ajk = idL dci ci ci ci ci ci ci ci ci ci ci).Accordingly, we find it useful that the operator backnorm (g) = c (g \u2212 g \u00b7 g \u00b7 c."}], "references": [{"title": "Spatial interaction and the statistical analysis of lattice systems", "author": ["J. Besag"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological), vol. 36, no. 2, pp. 192\u2013236, 1974.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1974}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F. Pereira"], "venue": "ICML, 2001.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Model distortions in bayesian MAP reconstruction", "author": ["M. Nikolova"], "venue": "Inverse Problems and Imaging, vol. 1, no. 2, pp. 399\u2013422, 2007.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Probabilistic solution of ill-posed problems in computational vision", "author": ["J. Marroquin", "S. Mitter", "T. Poggio"], "venue": "Journal of the American Statistical Association, vol. 82, no. 397, pp. 76\u201389, 1987.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1987}, {"title": "Training conditional random fields for maximum labelwise accuracy", "author": ["S.S. Gross", "O. Russakovsky", "C.B. Do", "S. Batzoglou"], "venue": "NIPS, 2007.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Exploiting inference for approximate parameter learning in discriminative fields: An empirical study", "author": ["S. Kumar", "J. August", "M. Hebert"], "venue": "EMMCVPR, 2005.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Measuring uncertainty in graph cut solutions", "author": ["P. Kohli", "P. Torr"], "venue": "Computer Vision and Image Understanding, vol. 112, no. 1, pp. 30\u201338, 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Graphical models, exponential families, and variational inference", "author": ["M. Wainwright", "M. Jordan"], "venue": "Found. Trends Mach. Learn., vol. 1, no. 1-2, pp. 1\u2013305, 2008.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Convergent message passing algorithms - a unifying view", "author": ["T. Meltzer", "A. Globerson", "Y. Weiss"], "venue": "UAI, 2009.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Structured learning and prediction in computer vision", "author": ["S. Nowozin", "C.H. Lampert"], "venue": "Foundations and Trends in Computer Graphics and Vision, vol. 6, pp. 185\u2013365, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "On parameter learning in CRF-based approaches to object class image segmentation", "author": ["S. Nowozin", "P.V. Gehler", "C.H. Lampert"], "venue": "ECCV, 2010.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning flexible features for conditional random fields", "author": ["L. Stewart", "X. He", "R.S. Zemel"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 8, pp. 1415\u20131426, 2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Markov chain monte carlo maximum likelihood", "author": ["C. Geyer"], "venue": "Symposium on the Interface, 1991.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1991}, {"title": "On contrastive divergence learning", "author": ["M. Carreira-Perpinan", "G. Hinton"], "venue": "AISTATS, 2005.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "Fields of experts", "author": ["S. Roth", "M.J. Black"], "venue": "International Journal of Computer Vision, vol. 82, no. 2, pp. 205\u2013229, 2009.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Estimating the \u201cwrong\u201d graphical model: benefits in the computation-limited setting", "author": ["M.J. Wainwright"], "venue": "Journal of Machine Learning Research, vol. 7, pp. 1829\u20131859, 2006.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1829}, {"title": "Efficiently learning random fields for stereo vision with sparse message passing", "author": ["J.J. Weinman", "L.C. Tran", "C.J. Pal"], "venue": "ECCV, 2008, pp. 617\u2013630.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Random field model for integration of local information and global information", "author": ["T. Toyoda", "O. Hasegawa"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 8, pp. 1483\u20131489, 2008.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning to combine bottom-up and top-down segmentation", "author": ["A. Levin", "Y. Weiss"], "venue": "International Journal of Computer Vision, vol. 81, no. 1, pp. 105\u2013118, 2009.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Exploiting inference for approximate parameter learning in discriminative fields: An empirical study", "author": ["S. Kumar", "J. August", "M. Hebert"], "venue": "EMMCVPR, 2005.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "Figure/ground assignment in natural images", "author": ["X. Ren", "C. Fowlkes", "J. Malik"], "venue": "ECCV, 2006.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Accelerated training of conditional random fields with stochastic gradient methods", "author": ["S.V.N. Vishwanathan", "N.N. Schraudolph", "M.W. Schmidt", "K.P. Murphy"], "venue": "ICML, 2006.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning probabilistic models for contour completion in natural images", "author": ["X. Ren", "C. Fowlkes", "J. Malik"], "venue": "International Journal of Computer Vision, vol. 77, no. 1-3, pp. 47\u201363, 2008.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "Scene understanding with discriminative structured prediction", "author": ["J. Yuan", "J. Li", "B. Zhang"], "venue": "CVPR, 2008.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Scene segmentation with crfs learned from partially labeled images", "author": ["J.J. Verbeek", "B. Triggs"], "venue": "NIPS, 2007.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning conditional random fields for stereo", "author": ["D. Scharstein", "C. Pal"], "venue": "CVPR, 2007.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Using combination of statistical models and multilevel structural information for detecting urban areas from a single gray-level image", "author": ["P. Zhong", "R. Wang"], "venue": "IEEE T. Geoscience and Remote Sensing, vol. 45, no. 5-2, pp. 1469\u20131482, 2007.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2007}, {"title": "Statistical analysis of non-lattice data", "author": ["J. Besag"], "venue": "Journal of the Royal Statistical Society. Series D (The Statistician), vol. 24, no. 3, pp. 179\u2013195, 1975.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1975}, {"title": "Multiscale conditional random fields for image labeling", "author": ["X. He", "R.S. Zemel", "M.\u00c1. Carreira-Perpi\u00f1\u00e1n"], "venue": "CVPR, 2004.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2004}, {"title": "Discriminative random fields", "author": ["S. Kumar", "M. Hebert"], "venue": "International Journal of Computer Vision, vol. 68, no. 2, pp. 179\u2013201, 2006.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning in gibbsian fields: How accurate and how fast can it be?", "author": ["S.C. Zhu", "X. Liu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2002}, {"title": "Piecewise training for undirected models", "author": ["C. Sutton", "A. McCallum"], "venue": "UAI, 2005.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "Robust model-based scene interpretation by multilayered context information", "author": ["S. Kim", "I.-S. Kweon"], "venue": "Computer Vision and Image Understanding, vol. 105, no. 3, pp. 167\u2013187, 2007.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2007}, {"title": "Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture, layout, and context", "author": ["J. Shotton", "J.M. Winn", "C. Rother", "A. Criminisi"], "venue": "Int. J. of Comput. Vision, vol. 81, no. 1, pp. 2\u201323, 2009.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "Empirical risk minimization of graphical model parameters given approximate inference, decoding, and model structure", "author": ["V. Stoyanov", "A. Ropson", "J. Eisner"], "venue": "AISTATS, 2011.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning convex inference of marginals", "author": ["J. Domke"], "venue": "UAI, 2008.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "A new algorithm for the estimation of hidden markov model parameters", "author": ["L.R. Bahl", "P.F. Bron", "P.V. de Souza", "R.L. Mercer"], "venue": "ICASSP, 1988.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1988}, {"title": "An alternate objective function for Markovian fields", "author": ["S. Kakade", "Y.W. Teh", "S. Roweis"], "venue": "ICML, 2002.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2002}, {"title": "Composite likelihood methods", "author": ["B.G. Lindsay"], "venue": "Contemporary Mathematics, vol. 80, pp. 221\u2013239, 1988.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1988}, {"title": "Learning convex inference of marginals", "author": ["J. Domke"], "venue": "UAI, 2008.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2008}, {"title": "Discriminative models for multi-class object layout", "author": ["C. Desai", "D. Ramanan", "C.C. Fowlkes"], "venue": "International Journal of Computer Vision, vol. 95, no. 1, pp. 1\u201312, 2011.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning CRFs using graph cuts", "author": ["M. Szummer", "P. Kohli", "D. Hoiem"], "venue": "ECCV, 2008.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2008}, {"title": "Hierarchical image-region labeling via structured learning", "author": ["J.J. McAuley", "T.E. de Campos", "G. Csurka", "F. Perronnin"], "venue": "BMVC, 2009.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2009}, {"title": "Scene segmentation via low-dimensional semantic representation and conditional random field", "author": ["W. Yang", "B. Triggs", "D. Dai", "G.-S. Xia"], "venue": "HAL, Tech. Rep., 2009.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2009}, {"title": "Implicit differentiation by perturbation", "author": ["J. Domke"], "venue": "NIPS, 2010.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2010}, {"title": "Approximate Solution Methods in Engineering Mechanics", "author": ["A. Boresi", "K. Chong"], "venue": "Elsevier Science Inc.,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 1991}, {"title": "Accelerated conjugate gradient algorithm with finite difference hessian/vector product approximation for unconstrained optimization", "author": ["N. Andrei"], "venue": "J. Comput. Appl. Math., vol. 230, no. 2, pp. 570\u2013582, 2009.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2009}, {"title": "Linear response algorithms for approximate inference in graphical models", "author": ["M. Welling", "Y.W. Teh"], "venue": "Neural Computation, vol. 16, pp. 197\u2013221, 2004.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2004}, {"title": "Parameter learning with truncated message-passing", "author": ["J. Domke"], "venue": "CVPR, 2011.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2011}, {"title": "Minimum-risk training of approximate CRF-based NLP systems", "author": ["V. Stoyanov", "J. Eisner"], "venue": "Proceedings of NAACL-HLT.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 0}, {"title": "Choosing a variable to clamp", "author": ["F. Eaton", "Z. Ghahramani"], "venue": "AISTATS, 2009.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2009}, {"title": "Value function approximation in reinforcement leanring using the fourier basis", "author": ["G. Konidaris", "S. Osentoski", "P. Thomas"], "venue": "AAAI, 2011.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "The motivation for these types of models is the Hammersley\u2013Clifford theorem [1], which gives specific conditions under which a distribution can be written as in Eq.", "startOffset": 76, "endOffset": 79}, {"referenceID": 1, "context": "For such problems, it is natural to define a Conditional Random Field [2] p(x|y) = 1 Z(y) \u220f", "startOffset": 70, "endOffset": 73}, {"referenceID": 2, "context": "One framework for answering this question is the idea of a Bayes estimator [3].", "startOffset": 75, "endOffset": 78}, {"referenceID": 3, "context": "(2) This appears to have been originally called Maximum Posterior Marginal (MPM) inference [4], though it has been reinvented under other names [5].", "startOffset": 91, "endOffset": 94}, {"referenceID": 4, "context": "(2) This appears to have been originally called Maximum Posterior Marginal (MPM) inference [4], though it has been reinvented under other names [5].", "startOffset": 144, "endOffset": 147}, {"referenceID": 5, "context": "A few papers have experimentally compared MAP and MPM inference [6], [7].", "startOffset": 64, "endOffset": 67}, {"referenceID": 6, "context": "A few papers have experimentally compared MAP and MPM inference [6], [7].", "startOffset": 69, "endOffset": 72}, {"referenceID": 7, "context": "1) is a member of the exponential family, with sufficient statistics consisting of indicator functions for each possible configuration of each clique and each variable [8], namely,", "startOffset": 168, "endOffset": 171}, {"referenceID": 7, "context": "3 VARIATIONAL INFERENCE This section reviews approximate methods for computing marginals, with notation based on Wainwright and Jordan [8].", "startOffset": 135, "endOffset": 138}, {"referenceID": 8, "context": "show [9] that on certain graphs made up of monotonic chains, an appropriate ordering of messages does assure convergence.", "startOffset": 5, "endOffset": 8}, {"referenceID": 9, "context": "A recent review [10] is more thorough.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "Some previous work uses tree structured graphs where marginals may be computed exactly [12].", "startOffset": 87, "endOffset": 91}, {"referenceID": 11, "context": "The first is to approximate the marginals \u03bc using Markov chain Monte Carlo [13], [14].", "startOffset": 75, "endOffset": 79}, {"referenceID": 12, "context": "The first is to approximate the marginals \u03bc using Markov chain Monte Carlo [13], [14].", "startOffset": 81, "endOffset": 85}, {"referenceID": 13, "context": "Contrastive Divergence [15] further approximates these samples by running the Markov chain for only a few steps, but started at the data points [16].", "startOffset": 23, "endOffset": 27}, {"referenceID": 14, "context": "Contrastive Divergence [15] further approximates these samples by running the Markov chain for only a few steps, but started at the data points [16].", "startOffset": 144, "endOffset": 148}, {"referenceID": 15, "context": "This \u201csurrogate likelihood\u201d [17] approximation appears to be the most widely used loss in imaging problems, with marginals approximated by either mean field [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25].", "startOffset": 28, "endOffset": 32}, {"referenceID": 16, "context": "This \u201csurrogate likelihood\u201d [17] approximation appears to be the most widely used loss in imaging problems, with marginals approximated by either mean field [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25].", "startOffset": 157, "endOffset": 161}, {"referenceID": 17, "context": "This \u201csurrogate likelihood\u201d [17] approximation appears to be the most widely used loss in imaging problems, with marginals approximated by either mean field [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25].", "startOffset": 163, "endOffset": 167}, {"referenceID": 18, "context": "This \u201csurrogate likelihood\u201d [17] approximation appears to be the most widely used loss in imaging problems, with marginals approximated by either mean field [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25].", "startOffset": 173, "endOffset": 177}, {"referenceID": 19, "context": "This \u201csurrogate likelihood\u201d [17] approximation appears to be the most widely used loss in imaging problems, with marginals approximated by either mean field [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25].", "startOffset": 185, "endOffset": 189}, {"referenceID": 20, "context": "This \u201csurrogate likelihood\u201d [17] approximation appears to be the most widely used loss in imaging problems, with marginals approximated by either mean field [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25].", "startOffset": 191, "endOffset": 195}, {"referenceID": 21, "context": "This \u201csurrogate likelihood\u201d [17] approximation appears to be the most widely used loss in imaging problems, with marginals approximated by either mean field [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25].", "startOffset": 197, "endOffset": 201}, {"referenceID": 22, "context": "This \u201csurrogate likelihood\u201d [17] approximation appears to be the most widely used loss in imaging problems, with marginals approximated by either mean field [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25].", "startOffset": 203, "endOffset": 207}, {"referenceID": 23, "context": "This \u201csurrogate likelihood\u201d [17] approximation appears to be the most widely used loss in imaging problems, with marginals approximated by either mean field [18], [19], TRW [20] or LBP [21], [22], [23], [24], [25].", "startOffset": 209, "endOffset": 213}, {"referenceID": 24, "context": "However, using the same approximation for both A(\u03b8) and A(\u03b8, z) appears to work well in practice [26].", "startOffset": 97, "endOffset": 101}, {"referenceID": 25, "context": "20 by running a (presumably approximate) MAP inference algorithm, and then imagining that the marginals put unit probability at the approximate MAP solution, and zero elsewhere [27], [28], [21].", "startOffset": 177, "endOffset": 181}, {"referenceID": 26, "context": "20 by running a (presumably approximate) MAP inference algorithm, and then imagining that the marginals put unit probability at the approximate MAP solution, and zero elsewhere [27], [28], [21].", "startOffset": 183, "endOffset": 187}, {"referenceID": 19, "context": "20 by running a (presumably approximate) MAP inference algorithm, and then imagining that the marginals put unit probability at the approximate MAP solution, and zero elsewhere [27], [28], [21].", "startOffset": 189, "endOffset": 193}, {"referenceID": 27, "context": "The first is the classic pseudolikelihood [29], where one uses L(\u03b8,x) = \u2211", "startOffset": 42, "endOffset": 46}, {"referenceID": 27, "context": "Besag [29] showed that, under certain conditions, this will converge to the true parameter vector as the amount of data becomes infinite.", "startOffset": 6, "endOffset": 10}, {"referenceID": 28, "context": "The pseudolikelihood has been used in many applications [30], [31].", "startOffset": 56, "endOffset": 60}, {"referenceID": 29, "context": "The pseudolikelihood has been used in many applications [30], [31].", "startOffset": 62, "endOffset": 66}, {"referenceID": 30, "context": "Instead of the probability of individual variables given all others, one can take the probability of patches of variables given all others, sometimes called the \u201cpatch\u201d pseudolikelihood [32].", "startOffset": 186, "endOffset": 190}, {"referenceID": 31, "context": "5 Piecewise Likelihood More recently, Sutton and McCallum [33] suggested the piecewise likelihood.", "startOffset": 58, "endOffset": 62}, {"referenceID": 32, "context": "In practice, it is sometimes best to make some heuristic adjustments to the parameters after learning to improve test-time performance [34], [35].", "startOffset": 135, "endOffset": 139}, {"referenceID": 33, "context": "In practice, it is sometimes best to make some heuristic adjustments to the parameters after learning to improve test-time performance [34], [35].", "startOffset": 141, "endOffset": 145}, {"referenceID": 34, "context": "This essentially fits into the paradigm of empirical risk minimization [36], [37].", "startOffset": 71, "endOffset": 75}, {"referenceID": 35, "context": "This essentially fits into the paradigm of empirical risk minimization [36], [37].", "startOffset": 77, "endOffset": 81}, {"referenceID": 36, "context": "in the late 1980s [38].", "startOffset": 18, "endOffset": 22}, {"referenceID": 37, "context": "1 Univariate Logistic Loss The univariate logistic loss [39] is defined by L(\u03b8,x) = \u2212 \u2211", "startOffset": 56, "endOffset": 60}, {"referenceID": 38, "context": "If defined on exact marginals, this is a type of composite likelihood [40].", "startOffset": 70, "endOffset": 74}, {"referenceID": 4, "context": "[5] suggest approximating with a sigmoid function S(t) = (1 + exp(\u2212\u03b1t)), where \u03b1 controls approximation quality.", "startOffset": 0, "endOffset": 3}, {"referenceID": 34, "context": "There is evidence [36], [5] that the smoothed classification loss can yield parameters with lower univariate classification error under MPM inference.", "startOffset": 18, "endOffset": 22}, {"referenceID": 4, "context": "There is evidence [36], [5] that the smoothed classification loss can yield parameters with lower univariate classification error under MPM inference.", "startOffset": 24, "endOffset": 27}, {"referenceID": 39, "context": "Our experience with the univariate quadratic loss [41] is similar.", "startOffset": 50, "endOffset": 54}, {"referenceID": 7, "context": "However, if all clique marginals are correct, the joint must be correct, by the standard moment matching conditions for the exponential family [8].", "startOffset": 143, "endOffset": 146}, {"referenceID": 40, "context": "4 MAP-Based Training Another class of methods explicitly optimize the performance of MAP inference [42], [43], [44], [45], [25].", "startOffset": 99, "endOffset": 103}, {"referenceID": 41, "context": "4 MAP-Based Training Another class of methods explicitly optimize the performance of MAP inference [42], [43], [44], [45], [25].", "startOffset": 105, "endOffset": 109}, {"referenceID": 42, "context": "4 MAP-Based Training Another class of methods explicitly optimize the performance of MAP inference [42], [43], [44], [45], [25].", "startOffset": 111, "endOffset": 115}, {"referenceID": 43, "context": "4 MAP-Based Training Another class of methods explicitly optimize the performance of MAP inference [42], [43], [44], [45], [25].", "startOffset": 117, "endOffset": 121}, {"referenceID": 23, "context": "4 MAP-Based Training Another class of methods explicitly optimize the performance of MAP inference [42], [43], [44], [45], [25].", "startOffset": 123, "endOffset": 127}, {"referenceID": 44, "context": "Domke [46] lists conditions for various classes of entropies that guarantee that A will be differentiable.", "startOffset": 6, "endOffset": 10}, {"referenceID": 45, "context": ", which is accurate to order o(r) [47].", "startOffset": 34, "endOffset": 38}, {"referenceID": 46, "context": "In all cases, the step size is, following Andrei [48], taken to be r = m\u01eb 1 3 (", "startOffset": 49, "endOffset": 53}, {"referenceID": 47, "context": "Welling and Teh used sensitivity of approximate beliefs to parameters to approximate joint probabilities of non-neighboring variables [50].", "startOffset": 134, "endOffset": 138}, {"referenceID": 48, "context": "Usually, a difference of 10 in estimated marginals has little practical impact, but this can still be enough to prevent learning from succeeding [51].", "startOffset": 145, "endOffset": 149}, {"referenceID": 34, "context": "[36], [52].", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "[36], [52].", "startOffset": 6, "endOffset": 10}, {"referenceID": 0, "context": "The noisy input values are then generated as yi = xi(1\u2212ti ) + (1\u2212xi)t n i , where xi is the true binary label, and ti \u2208 [0, 1] is random.", "startOffset": 120, "endOffset": 126}, {"referenceID": 51, "context": "We expand these 5 initial features into a larger set using sinusoidal expansion [54].", "startOffset": 80, "endOffset": 84}], "year": 2013, "abstractText": "Likelihood based-learning of graphical models faces challenges of computational-complexity and robustness to model misspecification. This paper studies methods that fit parameters directly to maximize a measure of the accuracy of predicted marginals, taking into account both model and inference approximations at training time. Experiments on imaging problems suggest marginalization-based learning performs better than likelihood-based approximations on difficult problems where the model being fit is approximate in nature.", "creator": "LaTeX with hyperref package"}}}