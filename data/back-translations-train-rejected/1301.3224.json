{"id": "1301.3224", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2013", "title": "Efficient Learning of Domain-invariant Image Representations", "abstract": "We present an algorithm that learns representations which explicitly compensate for domain mismatch and which can be efficiently realized as linear classifiers. Specifically, we form a linear transformation that maps features from the target (test) domain to the source (training) domain as part of training the classifier. We optimize both the transformation and classifier parameters jointly, and introduce an efficient cost function based on misclassification loss. Our method combines several features previously unavailable in a single algorithm: multi-class adaptation through representation learning, ability to map across heterogeneous feature spaces, and scalability to large datasets. We present experiments on several image datasets that demonstrate improved accuracy and computational advantages compared to previous approaches.", "histories": [["v1", "Tue, 15 Jan 2013 04:39:32 GMT  (177kb,D)", "https://arxiv.org/abs/1301.3224v1", null], ["v2", "Thu, 17 Jan 2013 01:36:31 GMT  (179kb,D)", "http://arxiv.org/abs/1301.3224v2", null], ["v3", "Mon, 11 Mar 2013 05:09:12 GMT  (179kb,D)", "http://arxiv.org/abs/1301.3224v3", null], ["v4", "Sun, 17 Mar 2013 19:39:37 GMT  (179kb,D)", "http://arxiv.org/abs/1301.3224v4", null], ["v5", "Tue, 9 Apr 2013 01:10:49 GMT  (179kb,D)", "http://arxiv.org/abs/1301.3224v5", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["judy hoffman", "erik rodner", "jeff donahue", "trevor darrell", "kate saenko"], "accepted": false, "id": "1301.3224"}, "pdf": {"name": "1301.3224.pdf", "metadata": {"source": "CRF", "title": "Efficient Learning of Domain-invariant Image Representations", "authors": ["Judy Hoffman", "Erik Rodner", "Jeff Donahue"], "emails": ["jhoffman@eecs.berkeley.edu", "erik.rodner@gmail.com", "jdonahue@eecs.berkeley.edu", "trevor@eecs.berkeley.edu", "saenko@cs.uml.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to move to another world in which they are able to find themselves."}, {"heading": "2 Related Work", "text": "Domain adaptation, or covariate shift, is a fundamental problem in machine learning, and has attracted a lot of attention in the machine learning and natural language community, e.g. [16, 17, 18, 19] (see [20] for a comprehensive overview). It is related to multi-task learning, but differs in the following ways: in domain adaptation problems, distribution varies across domains through the characteristics p (X), while output labels Y remain the same; in multi-task learning or knowledge transfer, p (X) remains the same (single domain), while output labels are different (see [20] for more details. In this paper, we perform multi-task learning across domains, i.e. both p (X) and output labels Y may change between domains. Domain adaptation is gaining considerable attention in the vision community. Several SVM-based approaches have been proposed for multi-task learning across domains, i.e. both p (X) and output labels Y may change between domains. Domain adaptation is gaining considerable attention in the vision community. SVM-based approaches have been applied to the SVM image-based function, including a SVM adaptive domain adaptation function."}, {"heading": "3 Max-Margin Domain Transforms", "text": "We propose a novel method for the multi-task domain to jointly learn that the individual categories of the hypercategories are separate from each other. Let's call the standard for the affine hyperplane associated with the k'th binary SVM, since it cannot solve the problem of linear SVMs by learning a target trait. Let's intuitively note that we want to learn a new target trait that is shared across several categories. We propose to do this by considering a transformation W of the input functions or, equally, a transformation WT of the source hyperlevel as parameters. Let's let xs1,. x s nS denote the training points in the source domain (DS), with labels ys1, ysnS. Let's leave x t 1., x t nT the labeledpoints in the target domain (DT), with labels ytnT."}, {"heading": "4 Experiments on Image Datasets", "text": "The idea is that it is a way of interweaving the different types of data that can be found in different parts of the world. \"The way we use it,\" the author continues, \"is very different.\" \"The way we use it is very different.\" \"The way we use it is very different.\" \"The way we use it is very different.\" \"The way we use it is very different.\" \"The way we use it is very different.\" \"The way we use it is very different.\" \"The way we use it is very different.\" \"The way we use it is very different.\" \"The way we use it is very different.\" \"The way we use it is very different.\""}, {"heading": "5 Conclusion", "text": "In this paper, we introduced a feature-learning technique for domain fitting that combines the ability of feature-transform-based methods to perform multi-task adjustments with the performance benefits of directly adjusting classification parameters. We validated the computational efficiency and effectiveness of our method using two standard benchmarks used for image domain adjustment. Our experiments show that 1) our method is a competitive domain adjustment algorithm that is capable of outperforming previous methods, 2) successfully generalizing to new target categories at test time, and 3) learning asymmetric transformations. In addition, these benefits are offered by a framework that is scalable to larger datasets and achieves a higher classification accuracy than previous approaches. So far, we have focused on linear transformations due to its speed and scalability, but our method can also include non-linear transformations in a non-linear way."}], "references": [{"title": "Adapting visual category models to new domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "In Proc. ECCV,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Learning to recognize activities from the wrong view point", "author": ["A. Farhadi", "M.K. Tabrizi"], "venue": "In Proc. ECCV,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Domain transfer svm for video concept detection", "author": ["L. Duan", "I.W. Tsang", "D. Xu", "S.J. Maybank"], "venue": "In CVPR,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Visual event recognition in videos by learning from web data", "author": ["L. Duan", "D. Xu", "I. Tsang", "J. Luo"], "venue": "In Proc. CVPR,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Unbiased look at dataset bias", "author": ["A. Torralba", "A. Efros"], "venue": "In Proc. CVPR,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Object detection with discriminatively trained part based models", "author": ["D. McAllester P. Felzenszwalb", "R. Girshick", "D. Ramanan"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Poselets: Body part detectors trained using 3d human pose annotations", "author": ["Lubomir Bourdev", "Jitendra Malik"], "venue": "In Proc. ICCV,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Adapting svm classifiers to data with shifted distributions", "author": ["J. Yang", "R. Yan", "A. Hauptmann"], "venue": "In ICDM Workshops,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Regularized adaptation: Theory, algorithms and applications", "author": ["X. Li"], "venue": "In PhD thesis,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Tabula rasa: Model transfer for object category detection", "author": ["Y. Aytar", "A. Zisserman"], "venue": "In Proc. ICCV,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Learning with augmented features for heterogeneous domain adaptation", "author": ["Lixin Duan", "Dong Xu", "Ivor W. Tsang"], "venue": "In Proc. ICML,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "What you saw is not what you get: Domain adaptation using asymmetric kernel transforms", "author": ["B. Kulis", "K. Saenko", "T. Darrell"], "venue": "In Proc. CVPR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Domain adaptation for object recognition: An unsupervised approach", "author": ["R. Gopalan", "R. Li", "R. Chellappa"], "venue": "In Proc. ICCV,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Translated learning: Transfer learning across different feature spaces", "author": ["W. Dai", "Y. Chen", "G. Xue", "Q. Yang", "Y. Yu"], "venue": "In Proc. NIPS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "In Proc. CVPR,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification", "author": ["J. Blitzer", "M. Dredze", "F. Pereira"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Frustratingly easy domain adaptation", "author": ["H. Daume III"], "venue": "In Proc. ACL,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Analysis of representations for domain adaptation", "author": ["S. Ben-david", "J. Blitzer", "K. Crammer", "O. Pereira"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Instance weighting for domain adaptation in nlp", "author": ["J. Jiang", "C.X. Zhai"], "venue": "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach", "author": ["A. Bergamo", "L. Torresani"], "venue": "In Proc. NIPS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Cross-domain learning methods for high-level visual concept classification", "author": ["W. Jiang", "E. Zavesky", "S. Chang", "A. Loui"], "venue": "In ICIP,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Deep learning of representations for unsupervised and transfer learning", "author": ["Yoshua Bengio"], "venue": "Journal of Machine Learning Research - Proceedings Track,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Domain adaptation with structural correspondence learning", "author": ["John Blitzer", "Ryan McDonald", "Fernando Pereira"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "Caltech-256 object category dataset", "author": ["G. Griffin", "A. Holub", "P. Perona"], "venue": "Technical Report 7694, California Institute of Technology,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 208, "endOffset": 211}, {"referenceID": 1, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 226, "endOffset": 229}, {"referenceID": 2, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 273, "endOffset": 279}, {"referenceID": 3, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 273, "endOffset": 279}, {"referenceID": 4, "context": "Recent studies have demonstrated a significant degradation in the performance of state-of-the-art image classifiers when input feature distributions change due to different image sensors and noise conditions [1], pose changes [2], a shift from commercial to consumer video [3, 4], and, more generally, training datasets biased by the way in which they were collected [5].", "startOffset": 367, "endOffset": 370}, {"referenceID": 5, "context": "Learning adaptive representations for linear classifiers is particularly interesting as they are efficient and prevalent in vision applications, with fast linear SVMs forming the core of some of the most popular object detection methods [6, 7].", "startOffset": 237, "endOffset": 243}, {"referenceID": 6, "context": "Learning adaptive representations for linear classifiers is particularly interesting as they are efficient and prevalent in vision applications, with fast linear SVMs forming the core of some of the most popular object detection methods [6, 7].", "startOffset": 237, "endOffset": 243}, {"referenceID": 7, "context": "Previous work proposed to adapt linear SVMs [8, 9, 10], learning a perturbation of the source hyperplane by minimizing the classification error on labeled target examples for each binary task.", "startOffset": 44, "endOffset": 54}, {"referenceID": 8, "context": "Previous work proposed to adapt linear SVMs [8, 9, 10], learning a perturbation of the source hyperplane by minimizing the classification error on labeled target examples for each binary task.", "startOffset": 44, "endOffset": 54}, {"referenceID": 9, "context": "Previous work proposed to adapt linear SVMs [8, 9, 10], learning a perturbation of the source hyperplane by minimizing the classification error on labeled target examples for each binary task.", "startOffset": 44, "endOffset": 54}, {"referenceID": 10, "context": "The recent HFA method [11] learns both the perturbed classifier and a latent domain-invariant feature representation, allowing domains to have heterogeneous features with different dimensionalities.", "startOffset": 22, "endOffset": 26}, {"referenceID": 0, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 1, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 11, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 12, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 13, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 14, "context": "Recently proposed feature adaptation methods [1, 2, 12, 13, 14, 15] offer a solution by learning a category-independent feature transform that maps target features into the source, pooling all training labels across categories.", "startOffset": 45, "endOffset": 67}, {"referenceID": 11, "context": "An additional advantage of the asymmetric transform method ARC-t [12] over metric learning [1] or the recently proposed Geodesic Flow Kernel (GFK) [15], is that, like HFA [11], ARC-t can map between heterogeneous feature spaces.", "startOffset": 65, "endOffset": 69}, {"referenceID": 0, "context": "An additional advantage of the asymmetric transform method ARC-t [12] over metric learning [1] or the recently proposed Geodesic Flow Kernel (GFK) [15], is that, like HFA [11], ARC-t can map between heterogeneous feature spaces.", "startOffset": 91, "endOffset": 94}, {"referenceID": 14, "context": "An additional advantage of the asymmetric transform method ARC-t [12] over metric learning [1] or the recently proposed Geodesic Flow Kernel (GFK) [15], is that, like HFA [11], ARC-t can map between heterogeneous feature spaces.", "startOffset": 147, "endOffset": 151}, {"referenceID": 10, "context": "An additional advantage of the asymmetric transform method ARC-t [12] over metric learning [1] or the recently proposed Geodesic Flow Kernel (GFK) [15], is that, like HFA [11], ARC-t can map between heterogeneous feature spaces.", "startOffset": 171, "endOffset": 175}, {"referenceID": 11, "context": "ARC-t [12] HFA [11] GFK [15] MMDT (ours) multi-class yes no yes yes large datasets no no yes yes heterogeneous features yes yes no yes optimize max-margin objective no yes no yes", "startOffset": 6, "endOffset": 10}, {"referenceID": 10, "context": "ARC-t [12] HFA [11] GFK [15] MMDT (ours) multi-class yes no yes yes large datasets no no yes yes heterogeneous features yes yes no yes optimize max-margin objective no yes no yes", "startOffset": 15, "endOffset": 19}, {"referenceID": 14, "context": "ARC-t [12] HFA [11] GFK [15] MMDT (ours) multi-class yes no yes yes large datasets no no yes yes heterogeneous features yes yes no yes optimize max-margin objective no yes no yes", "startOffset": 24, "endOffset": 28}, {"referenceID": 15, "context": "[16, 17, 18, 19] (see [20] for a comprehensive overview).", "startOffset": 0, "endOffset": 16}, {"referenceID": 16, "context": "[16, 17, 18, 19] (see [20] for a comprehensive overview).", "startOffset": 0, "endOffset": 16}, {"referenceID": 17, "context": "[16, 17, 18, 19] (see [20] for a comprehensive overview).", "startOffset": 0, "endOffset": 16}, {"referenceID": 18, "context": "[16, 17, 18, 19] (see [20] for a comprehensive overview).", "startOffset": 0, "endOffset": 16}, {"referenceID": 19, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 181, "endOffset": 185}, {"referenceID": 16, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 221, "endOffset": 225}, {"referenceID": 7, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 240, "endOffset": 246}, {"referenceID": 8, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 240, "endOffset": 246}, {"referenceID": 9, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 355, "endOffset": 359}, {"referenceID": 2, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 381, "endOffset": 384}, {"referenceID": 3, "context": "Several SVMbased approaches have been proposed for image domain adaptation, including: weighted combination of source and target SVMs and transductive SVMs applied to adaptation in [21]; the feature replication method of [17]; Adaptive SVM [8, 9], where the source model parameters are adapted by adding a perturbation function, and its successor PMT-SVM [10]; Domain Transfer SVM [3], which learns a target decision function while reducing the mismatch in the domain distributions; and a related method [4] based on multiple kernel learning.", "startOffset": 504, "endOffset": 507}, {"referenceID": 16, "context": "In the linear case, feature replication [17] can be shown to decompose the learned parameter into \u03b8 = \u03b8\u0302 + \u03b8\u2032, where \u03b8\u0302 is shared by all domains [22], in a similar fashion to adaptive SVMs.", "startOffset": 40, "endOffset": 44}, {"referenceID": 20, "context": "In the linear case, feature replication [17] can be shown to decompose the learned parameter into \u03b8 = \u03b8\u0302 + \u03b8\u2032, where \u03b8\u0302 is shared by all domains [22], in a similar fashion to adaptive SVMs.", "startOffset": 145, "endOffset": 149}, {"referenceID": 21, "context": "Several authors considered learning feature representations for unsupervised and transfer learning [23], and for domain adaptation [18, 24].", "startOffset": 99, "endOffset": 103}, {"referenceID": 17, "context": "Several authors considered learning feature representations for unsupervised and transfer learning [23], and for domain adaptation [18, 24].", "startOffset": 131, "endOffset": 139}, {"referenceID": 22, "context": "Several authors considered learning feature representations for unsupervised and transfer learning [23], and for domain adaptation [18, 24].", "startOffset": 131, "endOffset": 139}, {"referenceID": 0, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 11, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 12, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 1, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 13, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 10, "context": "For visual domain adaptation, transform-based adaptation methods [1, 12, 13, 2, 14, 11] have recently been proposed.", "startOffset": 65, "endOffset": 87}, {"referenceID": 11, "context": "The most closely related are the ARC-t method [12], which learns a transformation that maximizes similarity constraints between points in the source and those projected from the target domain, and the recent HFA method [11], which learns a transformation both from the source and target into a common latent space, as well as the classifier parameters.", "startOffset": 46, "endOffset": 50}, {"referenceID": 10, "context": "The most closely related are the ARC-t method [12], which learns a transformation that maximizes similarity constraints between points in the source and those projected from the target domain, and the recent HFA method [11], which learns a transformation both from the source and target into a common latent space, as well as the classifier parameters.", "startOffset": 219, "endOffset": 223}, {"referenceID": 14, "context": "Another related method is the recently proposed GFK [15], which computes a symmetric kernel between source and target points based on geodesic flow along a latent manifold.", "startOffset": 52, "endOffset": 56}, {"referenceID": 11, "context": "Relation to existing work: We now analyze the proposed algorithm in the context of the previous feature transform methods ARC-t [12], HFA [11] and GFK [15].", "startOffset": 128, "endOffset": 132}, {"referenceID": 10, "context": "Relation to existing work: We now analyze the proposed algorithm in the context of the previous feature transform methods ARC-t [12], HFA [11] and GFK [15].", "startOffset": 138, "endOffset": 142}, {"referenceID": 14, "context": "Relation to existing work: We now analyze the proposed algorithm in the context of the previous feature transform methods ARC-t [12], HFA [11] and GFK [15].", "startOffset": 151, "endOffset": 155}, {"referenceID": 14, "context": "Finally, GFK [15] formulates a kernelized representation of the data that is equivalent to computing the dot product in infinitely many subspaces along the geodesic flow between the source and target domain subspaces.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "We now present experiments using the Office [1], Caltech256 [25] and Bing [21] datasets to evaluate our algorithm according to the following four criteria.", "startOffset": 44, "endOffset": 47}, {"referenceID": 23, "context": "We now present experiments using the Office [1], Caltech256 [25] and Bing [21] datasets to evaluate our algorithm according to the following four criteria.", "startOffset": 60, "endOffset": 64}, {"referenceID": 19, "context": "We now present experiments using the Office [1], Caltech256 [25] and Bing [21] datasets to evaluate our algorithm according to the following four criteria.", "startOffset": 74, "endOffset": 78}, {"referenceID": 11, "context": "svms svmt arct [12] hfa [11] gfk[15] mmdt (ours) a\u2192 w 33.", "startOffset": 15, "endOffset": 19}, {"referenceID": 10, "context": "svms svmt arct [12] hfa [11] gfk[15] mmdt (ours) a\u2192 w 33.", "startOffset": 24, "endOffset": 28}, {"referenceID": 14, "context": "svms svmt arct [12] hfa [11] gfk[15] mmdt (ours) a\u2192 w 33.", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": ") We use the SURF-BoW image features provided by the authors [1].", "startOffset": 61, "endOffset": 64}, {"referenceID": 0, "context": "More details on how these features were computed can be found in [1].", "startOffset": 65, "endOffset": 68}, {"referenceID": 14, "context": "To better compare to previously reported performance, we use the features provided by [15], which are also SURF-BoW 800 dimensional features.", "startOffset": 86, "endOffset": 90}, {"referenceID": 19, "context": "Bing Dataset To demonstrate the effect that constraint set size has on run-time performance, we use the Bing dataset from [21], which has a larger number of images in each domain than Office.", "startOffset": 122, "endOffset": 126}, {"referenceID": 19, "context": "We use the train/test split from [21] and then vary the number of labeled target examples available from 5 to 25.", "startOffset": 33, "endOffset": 37}, {"referenceID": 11, "context": "\u2022 arc-t: A category general feature transform method proposed by [12].", "startOffset": 65, "endOffset": 69}, {"referenceID": 10, "context": "\u2022 hfa: A max-margin transform approach that learns a latent common space between source and target as well as a classifier that can be applied to points in that common space [11].", "startOffset": 174, "endOffset": 178}, {"referenceID": 14, "context": "\u2022 gfk: The geodesic flow kernel [15] applied to all source and target data (including test data).", "startOffset": 32, "endOffset": 36}, {"referenceID": 14, "context": "Following [15], we use a 1-nearest neighbor classifier with the kernel.", "startOffset": 10, "endOffset": 14}, {"referenceID": 24, "context": "We used the LIBSVM package [26] for kernelized methods and Liblinear [27] package for linear methods.", "startOffset": 27, "endOffset": 31}, {"referenceID": 25, "context": "We used the LIBSVM package [26] for kernelized methods and Liblinear [27] package for linear methods.", "startOffset": 69, "endOffset": 73}, {"referenceID": 11, "context": "Following the experimental setup of [12].", "startOffset": 36, "endOffset": 40}, {"referenceID": 9, "context": "We compare against pmt-svm [10] and ARC-t [12] using both knn and svm classification.", "startOffset": 27, "endOffset": 31}, {"referenceID": 11, "context": "We compare against pmt-svm [10] and ARC-t [12] using both knn and svm classification.", "startOffset": 42, "endOffset": 46}, {"referenceID": 0, "context": "We follow the setup of [1] and [15]: 20 training examples for amazon source (8 for all other domains as source) and 3 labeled examples per category for the target domain.", "startOffset": 23, "endOffset": 26}, {"referenceID": 14, "context": "We follow the setup of [1] and [15]: 20 training examples for amazon source (8 for all other domains as source) and 3 labeled examples per category for the target domain.", "startOffset": 31, "endOffset": 35}, {"referenceID": 10, "context": "Recall that this is a setting that many category specific adaptation methods cannot generalize to, including hfa [11].", "startOffset": 113, "endOffset": 117}, {"referenceID": 11, "context": "Therefore, we compare our results for this setting to the arc-t [12] method which learns a category independent feature transform and the gfk [15] method which learns a category independent kernel to compare the domains.", "startOffset": 64, "endOffset": 68}, {"referenceID": 14, "context": "Therefore, we compare our results for this setting to the arc-t [12] method which learns a category independent feature transform and the gfk [15] method which learns a category independent kernel to compare the domains.", "startOffset": 142, "endOffset": 146}, {"referenceID": 11, "context": "Following the experimental setup of [12], we use the full Office dataset and allow 20 labeled examples per category in the source for amazon and 10 labeled examples for the first 15 object categories in the target (dslr).", "startOffset": 36, "endOffset": 40}, {"referenceID": 19, "context": "To demonstrate the effect that constraint set size has on run-time performance, we use the Bing [21] dataset, which has a larger number of images in each domain than Office.", "startOffset": 96, "endOffset": 100}, {"referenceID": 19, "context": "We use the train/test split from [21] and then vary the number of labeled target examples available from 5 to 20.", "startOffset": 33, "endOffset": 37}], "year": 2013, "abstractText": "We present an algorithm that learns representations which explicitly compensate for domain mismatch and which can be efficiently realized as linear classifiers. Specifically, we form a linear transformation that maps features from the target (test) domain to the source (training) domain as part of training the classifier. We optimize both the transformation and classifier parameters jointly, and introduce an efficient cost function based on misclassification loss. Our method combines several features previously unavailable in a single algorithm: multi-class adaptation through representation learning, ability to map across heterogeneous feature spaces, and scalability to large datasets. We present experiments on several image datasets that demonstrate improved accuracy and computational advantages compared to previous approaches.", "creator": "LaTeX with hyperref package"}}}