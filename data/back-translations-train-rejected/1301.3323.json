{"id": "1301.3323", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2013", "title": "Auto-pooling: Learning to Improve Invariance of Image Features from Image Sequences", "abstract": "Learning invariant representations from images is one of the hardest challenges facing computer vision. Spatial pooling is widely used to create invariance to spatial shifting, but it is restricted to convolutional models. In this paper, we propose a novel pooling method that can learn soft clustering of features from image sequences. It is trained to improve the temporal coherence of features, while keeping the information loss at minimum. Our method does not use spatial information, so it can be used with non-convolutional models too. Experiments on images extracted from natural videos showed that our method can cluster similar features together. When trained by convolutional features, auto-pooling outperformed traditional spatial pooling on an image classification task, even though it does not use the spatial topology of features.", "histories": [["v1", "Tue, 15 Jan 2013 12:47:39 GMT  (856kb)", "https://arxiv.org/abs/1301.3323v1", "9 pages, 10 figures"], ["v2", "Wed, 16 Jan 2013 06:05:10 GMT  (856kb)", "http://arxiv.org/abs/1301.3323v2", "9 pages, 10 figures"], ["v3", "Wed, 23 Jan 2013 16:39:30 GMT  (860kb)", "http://arxiv.org/abs/1301.3323v3", "9 pages, 10 figures. Submission for ICLR 2013"], ["v4", "Mon, 18 Mar 2013 07:19:31 GMT  (1034kb)", "http://arxiv.org/abs/1301.3323v4", "9 pages, 10 figures. Submission for ICLR 2013"]], "COMMENTS": "9 pages, 10 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["sainbayar sukhbaatar", "takaki makino", "kazuyuki aihara"], "accepted": false, "id": "1301.3323"}, "pdf": {"name": "1301.3323.pdf", "metadata": {"source": "CRF", "title": "Auto-pooling: Learning to Improve Invariance of Image Features from Image Sequences", "authors": ["Sainbayar Sukhbaatar"], "emails": ["sainaa@sat.t.u-tokyo.ac.jp", "mak@sat.t.u-tokyo.ac.jp", "aihara@sat.t.u-tokyo.ac.jp"], "sections": [{"heading": null, "text": "ar Xiv: 130 1.33 23v4 [cs.CV] 1 8Learning invariant representations from images is one of the most difficult challenges faced by computer vision. Spatial pooling is widely used to generate invariance against spatial displacement, but is limited to revolutionary models. In this paper, we propose a novel pooling method that can learn soft clustering of features from image sequences. It is designed to improve the temporal coherence of features while minimizing information loss. Our method does not use spatial information, so it can also be used with non-revolutionary models. Experiments on images extracted from natural video showed that our method can bundle similar features. When trained by convolutionary features, auto-pooling surpasses traditional spatial pooling in an image classification task, although it does not use the spatial topology of features."}, {"heading": "1 Introduction", "text": "This year, there is only one notable aversion in which such aversion occurs: \"It is as if it is an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion to an aversion.\""}, {"heading": "2 Auto-pooling", "text": "The first property is that two images show the same object, then their pooled representations should be the same. Auto-pooling attempts to minimize the distance between the pooled representations. It is trained by image sequences in an unattended manner to make features more immutable. The goal of the training is to link similar features so that small transformations would not affect pooled representations. In addition, image sequences for animals and humans are available as early as their birth, so it is biologically plausible to use them when learning complex cell types as invariant. We believe that there are two desirable properties in good pooling methods. The first property is that two images show the same object, then their pooled representations should be the same. Auto-pooling attempts to minimize the distance between the pooled representations."}, {"heading": "2.1 Invariance Score", "text": "To evaluate our pooling model, we define a score for measuring the invariance of features (a similar score is also introduced in [5]).A simple measurement of the invariance of features is the average activation change between two adjacent frames, G = 1NN * n = 1% g (xn) \u2212 g (x \u2032 n) * 2.This should be G (x): = f (x) when measuring the invariance of raw features, and g (x): = Pf (x) when measuring the inventory of pooled representations. In the case of invariant features, G should be small. However, features can cheat by simply making their activation constant to reduce G, which is obviously not useful. An ideal invariant feature should assume the same value only if the stimuli come from consecutive frames. In the case of frames selected from random timings, an invariant feature should have different activities, because it is likely that the objects contain different inputs."}, {"heading": "3 Experiments", "text": "The effectiveness of our method is demonstrated by two types of experiments: In the first experiment, we train an auto-pooling model with non-revolutionary characteristics. The aim of this experiment is to see if similar characteristics are merged. In addition, we measured the inventory value of the characteristics before and after pooling. In the second experiment, we compared our method with traditional spatial pooling on an image classification task."}, {"heading": "3.1 Clustering of Image Features", "text": "We prepared a dataset of 16 x 16 grayscale patch pairs from natural videos1. Patch pairs are extracted from random positions of consecutive frames. Some of the patch pairs are shown in Figure 3.We used a sparse auto-encoder to learn 400 features from patches. Then, we trained an auto-pooling model on these features. However, since auto-pooling does soft clustering, it is difficult to visualize the cluster result. For simplicity, we used a small threshold to show some of the learned clusters in Figure 4, where each column represents a single cluster. For the i-th cluster, we showed features with Pij > \u03b5. It is obvious that similar features are bundled together. You can see that the size of a cluster is different depending on the nature of its features."}, {"heading": "3.2 Image Classification", "text": "This year it is more than ever before in the history of the city."}, {"heading": "4 Conclusions", "text": "In this paper, we introduced auto-pooling, a novel pooling method that can generalize traditional spatial pooling to transformations other than spatial displacements. Auto-pooling attempts to make features more temporally coherent by exhibiting slow activation with continued image sequence. Loss of information from pooling is kept to a minimum with the same cost function as auto-encoders. The main advantage of our method is that it learns to cluster features from data rather than relying on manual heuristic spatial subdivisions. Therefore, auto-pooling is a biologically more plausible model for complex cells. If it is trained by image pairs extracted from natural videos, auto-pooling successfully bundles similar features together. We have shown that such clustering could significantly improve the inventory of features. In addition, our pooling model was more effective than conventional spatial pooling when it was used in a real-world pooling task that was mainly limited to automated spatial features."}, {"heading": "Acknowledgments", "text": "This research is supported by the Aihara Innovative Mathematical Modelling Project (JSPS) through the \"Funding Program for World-Leading Innovative R & D on Science and Technology (FIRST Program)\" initiated by the Council for Science and Technology Policy (CSTP)."}], "references": [{"title": "Slow feature analysis yields a rich repertoire of complex cell properties", "author": ["P. Berkes", "L. Wiskott"], "venue": "Journal of Vision,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Learning transformational invariants from natural movies", "author": ["C. Cadieu", "B. Olshausen"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Selecting receptive fields in deep networks", "author": ["A. Coates", "A. Ng"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position", "author": ["K. Fukushima"], "venue": "Biological Cybernetics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1980}, {"title": "Measuring invariances in deep networks", "author": ["I. Goodfellow", "Q. Le", "A. Saxe", "H. Lee", "A. Ng"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Emergence of complex-like cells in a temporal product network with local receptive fields", "author": ["K. Gregor", "Y. LeCun"], "venue": "arXiv preprint arXiv:1006.0448,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Receptive fields, binocular interaction and functional architecture in the cat\u2019s visual cortex", "author": ["D. Hubel", "T. Wiesel"], "venue": "The Journal of Physiology,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1962}, {"title": "Topographic independent component analysis", "author": ["A. Hyv\u00e4rinen", "P. Hoyer", "M. Inki"], "venue": "Neural Computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Beyond spatial pyramids: Receptive field learning for pooled image features", "author": ["Y. Jia", "C. Huang", "T. Darrell"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Learning invariant features through topographic filter maps", "author": ["K. Kavukcuoglu", "M. Ranzato", "R. Fergus", "Y. LeCun"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G. Hinton"], "venue": "Master\u2019s thesis,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "CUDAMat: a CUDA-based matrix class for Python", "author": ["V. Mnih"], "venue": "Technical report, Department of Computer Science, University of Toronto,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Deep learning from temporal coherence in video", "author": ["H. Mobahi", "R. Collobert", "J. Weston"], "venue": "In Proceedings of the 26th International Conference on Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Topographic product models applied to natural scene statistics", "author": ["S. Osindero", "M. Welling", "G. Hinton"], "venue": "Neural Computation,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Efficient learning of sparse representations with an energy-based model", "author": ["M. Ranzato", "S. Chopra", "Y. LeCun"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["P. Vincent", "H. Larochelle", "Y. Bengio", "P.A. Manzagol"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}], "referenceMentions": [{"referenceID": 6, "context": "The concept of invariant features dates back to Hubel and Wiesel\u2019s seminal work [7], in which cells in a cat\u2019s visual cortex are studied.", "startOffset": 80, "endOffset": 83}, {"referenceID": 3, "context": "Inspired by simple and complex cells, the spatial pooling step is introduced to computer vision architectures along with the convolution step [4, 12, 13].", "startOffset": 142, "endOffset": 153}, {"referenceID": 11, "context": "Inspired by simple and complex cells, the spatial pooling step is introduced to computer vision architectures along with the convolution step [4, 12, 13].", "startOffset": 142, "endOffset": 153}, {"referenceID": 12, "context": "Inspired by simple and complex cells, the spatial pooling step is introduced to computer vision architectures along with the convolution step [4, 12, 13].", "startOffset": 142, "endOffset": 153}, {"referenceID": 8, "context": "[9] showed that it is possible to learn custom pooling regions specialized for a given classification task.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Another method that improves spatial pooling is proposed by Coates and Ng [3], in which local features are clustered by their similarity.", "startOffset": 74, "endOffset": 77}, {"referenceID": 7, "context": "Beside from spatial pooling, there are methods [8, 10, 16] that create invariance by placing features on a two-dimensional topographic map.", "startOffset": 47, "endOffset": 58}, {"referenceID": 9, "context": "Beside from spatial pooling, there are methods [8, 10, 16] that create invariance by placing features on a two-dimensional topographic map.", "startOffset": 47, "endOffset": 58}, {"referenceID": 15, "context": "Beside from spatial pooling, there are methods [8, 10, 16] that create invariance by placing features on a two-dimensional topographic map.", "startOffset": 47, "endOffset": 58}, {"referenceID": 0, "context": "Slowness has been used in many methods as a criterion for invariant features [1, 15, 2, 6].", "startOffset": 77, "endOffset": 90}, {"referenceID": 14, "context": "Slowness has been used in many methods as a criterion for invariant features [1, 15, 2, 6].", "startOffset": 77, "endOffset": 90}, {"referenceID": 1, "context": "Slowness has been used in many methods as a criterion for invariant features [1, 15, 2, 6].", "startOffset": 77, "endOffset": 90}, {"referenceID": 5, "context": "Slowness has been used in many methods as a criterion for invariant features [1, 15, 2, 6].", "startOffset": 77, "endOffset": 90}, {"referenceID": 14, "context": "[15] incorporated unsupervised slowness learning with supervised back-propagation learning, which improved the classification rate.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "This is done by minimizing the reconstruction error in the same way as auto-encoders [17, 18].", "startOffset": 85, "endOffset": 93}, {"referenceID": 17, "context": "This is done by minimizing the reconstruction error in the same way as auto-encoders [17, 18].", "startOffset": 85, "endOffset": 93}, {"referenceID": 4, "context": "For evaluating our pooling model, we define a score for measuring invariance of features (a similar score is also introduced in [5]).", "startOffset": 128, "endOffset": 131}, {"referenceID": 10, "context": "For image classification, we used CIFAR10 dataset [11], which contains 50 thousand labeled images from ten categories.", "startOffset": 50, "endOffset": 54}, {"referenceID": 13, "context": "Luckily, the training took only few hours because we implemented our algorithm on a graphic card (Tesla K20c) using CUDAMat library [14].", "startOffset": 132, "endOffset": 136}, {"referenceID": 11, "context": "However, it is possible to use multiple spatial pooling at once [12] to produce better results.", "startOffset": 64, "endOffset": 68}], "year": 2013, "abstractText": "Learning invariant representations from images is one of the hardest challenges facing computer vision. Spatial pooling is widely used to create invariance to spatial shifting, but it is restricted to convolutional models. In this paper, we propose a novel pooling method that can learn soft clustering of features from image sequences. It is trained to improve the temporal coherence of features, while keeping the information loss at minimum. Our method does not use spatial information, so it can be used with non-convolutional models too. Experiments on images extracted from natural videos showed that our method can cluster similar features together. When trained by convolutional features, auto-pooling outperformed traditional spatial pooling on an image classification task, even though it does not use the spatial topology of features.", "creator": "LaTeX with hyperref package"}}}