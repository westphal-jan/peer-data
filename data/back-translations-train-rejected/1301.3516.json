{"id": "1301.3516", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2013", "title": "Learnable Pooling Regions for Image Classification", "abstract": "From the early HMAX model to Spatial Pyramid Matching, pooling has played an important role in visual recognition pipelines. Spatial pooling, by grouping of local codes, equips these methods with a certain degree of robustness to translation and deformation yet preserving important spatial information. Despite the predominance of this approach in current recognition systems, we have seen little progress to fully adapt the pooling strategy to the task at hand. This paper proposes a model for learning task dependent pooling scheme -- including previously proposed hand-crafted pooling schemes as a particular instantiation. In our work, we investigate the role of different regularization terms used in the proposed model together with an efficient method to train them. Our experiments show improved performance over hand-crafted pooling schemes on the CIFAR-10 and CIFAR-100 datasets -- in particular improving the state-of-the-art to 56.29% on the latter.", "histories": [["v1", "Tue, 15 Jan 2013 22:15:06 GMT  (282kb,D)", "http://arxiv.org/abs/1301.3516v1", null], ["v2", "Tue, 6 Aug 2013 13:51:04 GMT  (266kb,D)", "http://arxiv.org/abs/1301.3516v2", null], ["v3", "Tue, 5 May 2015 18:12:46 GMT  (65kb,D)", "http://arxiv.org/abs/1301.3516v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["mateusz malinowski", "mario fritz"], "accepted": false, "id": "1301.3516"}, "pdf": {"name": "1301.3516.pdf", "metadata": {"source": "CRF", "title": "Learnable Pooling Regions for Image Classification", "authors": ["Mateusz Malinowski"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "This year it has come to the point where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in a time where we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we in which we are in which we are in which we are in which we are in which we are in which we are in which we in which we are in which we are in which we are in which we in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we in which we are in which we are in which we are in which are in which we are in which we are in which are in which we are in which we are in which are in which we in which we are in which are in which we are in which are in which we are in which are in which we are in which are in which we are in which are in which we are in which we are in which we are in which are in which we are in which are in which we are in which we are in which are in which we are in which are in which we are in which we are in which are in which are in which we in which are in which are in which are in which are in which we are in which are in which are in which are in which are in which"}, {"heading": "2 Method", "text": "In contrast to the methods that use fixed spatial pooling regions in the object classification task [Lazebnik et al., 2006, Yang et al., 2009], our method jointly optimizes both the classifier and the pooling regions. In this way, the learning signal present in the classifier can contribute to shaping the pooling regions in such a way that better pooled characteristics emerge."}, {"heading": "2.1 Parameterized pooling operator", "text": "The simplest form of spatial pooling is the calculation of the histogram over the entire image. This can be expressed as \u03a3 (U): = \u2211 M j = 1 uj, where uj-RK is a code (from M such codes) and an index j refers to the spatial location from which the code originates. A code is an encrypted patch that is extracted from the image. The proposed method is agnostic towards the patch extraction method and the encoding scheme. As the pooling approach loses spatial information of the codes, Lazebnik et al. [2006] is proposed to first divide the image into subsections and then generate pooled features by concatenating histograms that are compiled over each subregion. There are two problems with such an approach: First, the division is largely arbitrary and in particular independent of the data."}, {"heading": "2.2 Learnable pooling regions", "text": "In the SPM architectures, the pooling weights w are designed by hand, here we aim for common learning units w = j = j-l together with the parameters of the classifier. Intuitively, during the training, the classifier has access to the classes to which the images belong, and can therefore form the pooling regions. On the other hand, the method aggregates the statistics of the codes across such learned regions and passes them to the classifier, which allows greater accuracy. However, such joint training of the classifier and the pooling regions can be interpreted as tightly connected multi-layered perceptrons by adapting the backpropagation algorithm [Bishop, 1999, LeCun et al., 1998], [Collobert and Bengio, 2004].Consider a sampling scheme and a coding method that produces M-codes of each dimensional code. Each coordinate of the code is a layer for the multi-layered percon."}, {"heading": "2.3 Regularization terms", "text": "For the classification and pooling parameters W, we introduce the learning process that can select such parameter vectors in the following section. 3Deployment of the codes U (i) and a (i) l (i) l: = wl (U (i))), then a (i): = a (i) l. 4The algorithm developed by Mark Schmidt can be downloaded from the following website: http: / / www.di.ens.fr / mschmidt / Software / minFunc.htmla Simple L2 regulation terms: | | 2l2 and | W k | | 2l2. We improve the interpretability of the pooling weight as well as the transferability between models by adding a projection onto a unit."}, {"heading": "2.4 Approximation of the model", "text": "That is, the number of pool parameters grows as K \u00b7 M \u00b7 L, where K is the dimensionality of the codes, M is the number of patches taken from the image, and L is the number of pooling units. Therefore, we propose two approaches to our method that make the whole approach more scalable, and then we emphasize that the learned regions have very little when comparing the default spatial divisions at test times. The first approach makes a fine-grained spatial partition of the image, and then pools the codes across such sub-regions. We call this operation a pre-pooling step, reducing the number of recorded spatial divisions in the subjects."}, {"heading": "3 Experimental Results", "text": "We evaluate our methodology using the CIFAR-10 and CIFAR-100 datasets [Krizhevsky and Hinton, 2010], provide insights into the learned pooling strategies, and examine the transfer between datasets. In this section, we describe our experimental setup and present our results for both datasets."}, {"heading": "3.1 CIFAR-10 and CIFAR-100 datasets", "text": "The CIFAR-10 and CIFAR-100 datasets contain 50,000 training color images and 10,000 test color images from 10 and 100 categories, respectively, with 6000 and 600 images per class. All images have the same size: 32 x 32 pixels and were sampled from the 80 million tiny dataset [Torralba et al., 2008]."}, {"heading": "3.2 Evaluation pipeline", "text": "In this work, we follow the Coates and Ng [2011] pipeline, extracting normalized and consecrated 6-6 patches from images that have a dense, endowed grid with a unit of spacing. As a next step, we use K-mean mapping and linear encryption. Optionally, we use two approximations described in Section 2.4. Since we want to be comparable to Coates et al, we classify images with logistic regression or linear SVM in the case of transferred pooling regions. Optionally, we use two approximations described in Section 2.4."}, {"heading": "3.3 Evaluation of our method on small dictionaries", "text": "Figure 1 (a) shows the classification accuracy of our complete method over the baseline [Coates and Ng, 2011]. Because we train the pooling regions without approximations in this set of experiments, the results are limited to dictionary sizes up to 800. Our method outperforms Coates \"approach for dictionary size 16 by 10% (our method achieves accuracy 57.07%, while the baseline is only 46.93%).This improvement is consistent across the larger dictionaries, although the margin is narrowing. Our method is about 2.5% and 1.88% better than the baseline for 400 and 800 dictionary elements, respectively."}, {"heading": "3.4 Scaling up to sizable dictionaries", "text": "In the following experiments we use batches5The reader can find details of such an approach in subsection 2.4.with 40 coordinates extracted from the original code, as they fit comfortably into the memory of a single standard machine (about 5 Gbytes for the main data) and can all be trained in parallels. Besides reducing memory requirements, the batches have shown several practical advantages due to smaller parameters, we need fewer calculations per iteration, as well as faster convergence. Figure 1 (b) shows the classification performance for larger dictionaries, in which we examined the full model [Coates], random pooling regions (described in subsection 3.5), bags of functions, and two possible approximations."}, {"heading": "3.5 Random pooling regions", "text": "Our study also includes results based on random pooling regions, where the weights for the parameterized operator (equation 2) differ from the normal distribution with mean 0.5 and standard deviation 0.1, i.e. wlj \u0445 N (0.5, 0.1) for all l. This notion of random pooling differs from the Jia et al. [2012], where random selection of rectangles is used. Experiments show that the random pooling regions can still retain some spatial information, especially in the regime of larger dictionaries, where the difference is only 1.09%. Results suggest that artisanal partitioning of the image into sub-areas is questionable and requires a learning-based approach."}, {"heading": "3.6 Investigation of the regularization terms", "text": "Our model (Eq.5) contains two regularization terms that are linked to the pooling weights and impose different assumptions on the pooling regions. Therefore, it is interesting to examine their role in the classification task taking into account all possible subsets of {l2, smooth}, with \"l2\" and \"smooth\" referring to | | W | | 2l2 and (| x xW | | 2l2 + | 2 l2). Table 3 shows our results on CIFAR-10. For these experiments, we select a dictionary size of 200 so that we can evaluate different regularization terms without approximations. We come to the conclusion that the concept of spatial regularization of smoothness is crucial in order to achieve a good predictive effect of our method, while the concept of the l2 standard can be omitted and thus the number of hyperparameters can be reduced. Based on the cross-validation results (second column of this 3), we choose for this additional setting."}, {"heading": "3.7 Experiments on the CIFAR-100 dataset", "text": "Although most of the work is carried out on the CIFAR-10 dataset, we are also investigating how the model behaves and generalises on the much more sophisticated CIFAR-100 dataset with 100 classes. Our model using the term spatial smoothing on 40-dimensional batches achieves an accuracy of 56.29%. To the best of our knowledge, this result consists of the state-of-the-art performance on this dataset, which exceeds Jia and Huang [2011] by 1.41% and the baseline by 4.63%."}, {"heading": "3.8 Transfer of the pooling regions between datasets", "text": "In this scenario, the pooling regions are first trained on the source dataset and then used on the target dataset to train a new classifier. We use a dictionary of 1600 with 40-dimensional batches. Our results in Table 5 suggest that the learned pooling regions are actually transferable between the two datasets. While we observe a performance decline in learning the pooling strategy on the less diverse CIFAR-10 dataset, we see improvements in learning on the richer CIFAR-100 dataset. We arrive at a test accuracy of 80.35%, which is an additional 0.75% or 0.18% improvement over our best result (batch-based approximation) or Jia and Huang [2011]."}, {"heading": "3.9 Visualization and analysis of pooling strategies", "text": "The first line shows the widespread rectangular spatial division of the image. The second line shows the results on CIFAR-10 using the term \"l2\" regularization. Pooling is most different from the other results because it learns highly localized weights. This pooling strategy also performed worst in our study (Table 3). \"Smooth\" pooling performs best. The visualization shows that weights are localized but evenly distributed over the image. The weights reveal a propensity for initialization shown in the first line. All methods of spatial smoothing control tend to focus on similar parts of the image, but \"l2 & smooth\" is more conservative in the distribution of weights. The last two lines show a propensity for initialization achieved by our approach to the respective plane."}, {"heading": "4 Conclusion", "text": "In this paper, we propose flexible parameterization of the pool operator, which can be trained together with the classifier. In this way, we investigate the impact of different regulators on the pool regions and the overall system. In order to train the large set of parameters, we propose approaches to our model that allow efficient and parallel training without loss of accuracy. Our experiments show that there is room to improve classification accuracy by advancing the spatial pooling phase. The presented method exceeds a popular, handmade pooling-based method and previous approaches to learning pooling strategies. While our improvements are consistent across the range of dictionary sizes we studied, the margin is most impressive for small codes, where we observe improvements of up to 10% compared to the baseline of the coates. Finally, our method achieves an accuracy of 529% of the new CAR based on the knowledge of the IAR."}], "references": [{"title": "Hierarchical models of object recognition in cortex", "author": ["M. Riesenhuber", "T. Poggio"], "venue": "Nature Neuroscience,", "citeRegEx": "Riesenhuber and Poggio.,? \\Q2009\\E", "shortCiteRegEx": "Riesenhuber and Poggio.", "year": 2009}, {"title": "The structure of locally orderless images", "author": ["J.J. Koenderink", "A.J. Van Doorn"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Koenderink and Doorn.,? \\Q1999\\E", "shortCiteRegEx": "Koenderink and Doorn.", "year": 1999}, {"title": "Distinctive image features from scale-invariant keypoints", "author": ["D.G. Lowe"], "venue": null, "citeRegEx": "Lowe.,? \\Q2004\\E", "shortCiteRegEx": "Lowe.", "year": 2004}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "In CVPR,", "citeRegEx": "Dalal and Triggs.,? \\Q2005\\E", "shortCiteRegEx": "Dalal and Triggs.", "year": 2005}, {"title": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "In CVPR,", "citeRegEx": "Lazebnik et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lazebnik et al\\.", "year": 2006}, {"title": "Linear spatial pyramid matching using sparse coding for image classification", "author": ["J. Yang", "K. Yu", "Y. Gong", "T. Huang"], "venue": "In CVPR,", "citeRegEx": "Yang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2009}, {"title": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", "author": ["M.A. Ranzato", "F.J. Huang", "Y. Boureau", "Y. LeCun"], "venue": "In CVPR,", "citeRegEx": "Ranzato et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2007}, {"title": "Building high-level features using large scale unsupervised learning", "author": ["Q.V. Le", "M.A. Ranzato", "R. Monga", "M. Devin", "K. Chen", "G.S. Corrado", "J. Dean", "A.Y. Ng"], "venue": "In ICML,", "citeRegEx": "Le et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Le et al\\.", "year": 2012}, {"title": "Beyond spatial pyramids: Receptive field learning for pooled image features", "author": ["Y. Jia", "C. Huang"], "venue": "In NIPS Workshop on Deep Learning,", "citeRegEx": "Jia and Huang.,? \\Q2011\\E", "shortCiteRegEx": "Jia and Huang.", "year": 2011}, {"title": "Beyond spatial pyramids: Receptive field learning for pooled image features", "author": ["Y. Jia", "C. Huang", "T. Darrell"], "venue": "In CVPR,", "citeRegEx": "Jia et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2012}, {"title": "Geometric lp-norm feature pooling for image classification", "author": ["J. Feng", "B. Ni", "Q. Tian", "S. Yan"], "venue": "In CVPR,", "citeRegEx": "Feng et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2011}, {"title": "Modeling pixel means and covariances using factorized third-order boltzmann machines", "author": ["M.A. Ranzato", "G.E. Hinton"], "venue": "In CVPR,", "citeRegEx": "Ranzato and Hinton.,? \\Q2010\\E", "shortCiteRegEx": "Ranzato and Hinton.", "year": 2010}, {"title": "Neural Network for Pattern Recognition", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "Bishop.,? \\Q1999\\E", "shortCiteRegEx": "Bishop.", "year": 1999}, {"title": "Efficient backprop", "author": ["Y. LeCun", "L. Bottou", "G. Orr", "K. M\u00fcller"], "venue": "Neural networks: Tricks of the trade,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Links between perceptrons, mlps and svms", "author": ["R. Collobert", "S. Bengio"], "venue": "In ICML,", "citeRegEx": "Collobert and Bengio.,? \\Q2004\\E", "shortCiteRegEx": "Collobert and Bengio.", "year": 2004}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["A. Coates", "H. Lee", "A.Y. Ng"], "venue": "In AISTATS,", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "Building high-level features using large scale unsupervised learning", "author": ["Q.V. Le", "R. Monga", "M. Devin", "G. Corrado", "K. Chen", "M.A. Ranzato", "J. Dean", "A.Y. Ng"], "venue": null, "citeRegEx": "Le et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Le et al\\.", "year": 2012}, {"title": "Convolutional deep belief networks on cifar-10", "author": ["A. Krizhevsky", "G. Hinton"], "venue": "Technical report,", "citeRegEx": "Krizhevsky and Hinton.,? \\Q2010\\E", "shortCiteRegEx": "Krizhevsky and Hinton.", "year": 2010}, {"title": "Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition", "author": ["A. Torralba", "R. Fergus", "W.T"], "venue": null, "citeRegEx": "Torralba et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Torralba et al\\.", "year": 2008}, {"title": "The importance of encoding versus training with sparse coding and vector quantization", "author": ["A. Coates", "A.Y. Ng"], "venue": "In ICML,", "citeRegEx": "Coates and Ng.,? \\Q2011\\E", "shortCiteRegEx": "Coates and Ng.", "year": 2011}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "In CVPR,", "citeRegEx": "Ciresan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ciresan et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Motivated from biology [Riesenhuber and Poggio, 2009] and statistics of locally orderless images [Koenderink and Van Doorn, 1999], the spatial pooling approach has been found useful as an intermediate step of many today\u2019s computer vision methods.", "startOffset": 23, "endOffset": 53}, {"referenceID": 2, "context": "For instance, the most popular visual descriptors such as SIFT [Lowe, 2004] and HOG [Dalal and Triggs, 2005], which compute local histograms of gradients, can be in fact seen as a special version of the spatial pooling strategy.", "startOffset": 63, "endOffset": 75}, {"referenceID": 3, "context": "For instance, the most popular visual descriptors such as SIFT [Lowe, 2004] and HOG [Dalal and Triggs, 2005], which compute local histograms of gradients, can be in fact seen as a special version of the spatial pooling strategy.", "startOffset": 84, "endOffset": 108}, {"referenceID": 4, "context": "Recent progress has been made in learning pooling regions in the context of image classification using the Spatial Pyramid Matching (SPM) pipeline [Lazebnik et al., 2006, Yang et al., 2009]. Jia and Huang [2011], Jia et al.", "startOffset": 148, "endOffset": 212}, {"referenceID": 4, "context": "Recent progress has been made in learning pooling regions in the context of image classification using the Spatial Pyramid Matching (SPM) pipeline [Lazebnik et al., 2006, Yang et al., 2009]. Jia and Huang [2011], Jia et al. [2012] and Feng et al.", "startOffset": 148, "endOffset": 231}, {"referenceID": 4, "context": "Recent progress has been made in learning pooling regions in the context of image classification using the Spatial Pyramid Matching (SPM) pipeline [Lazebnik et al., 2006, Yang et al., 2009]. Jia and Huang [2011], Jia et al. [2012] and Feng et al. [2011] have investigated how to further liberate the recognition from preconceptions of the hand crafted recognition pipelines, and include the", "startOffset": 148, "endOffset": 254}, {"referenceID": 8, "context": "For instance Jia and Huang [2011] optimizes binary pooling strategies that are given by the superposition of rectangular basis functions, and Feng et al.", "startOffset": 13, "endOffset": 34}, {"referenceID": 8, "context": "For instance Jia and Huang [2011] optimizes binary pooling strategies that are given by the superposition of rectangular basis functions, and Feng et al. [2011] finds pooling regions by applying a linear discriminant analysis for individual pooling strategies and training a classifier afterwards.", "startOffset": 13, "endOffset": 161}, {"referenceID": 8, "context": "For instance Jia and Huang [2011] optimizes binary pooling strategies that are given by the superposition of rectangular basis functions, and Feng et al. [2011] finds pooling regions by applying a linear discriminant analysis for individual pooling strategies and training a classifier afterwards. Also as opposed to Ranzato and Hinton [2010], we aim for discriminative pooling over large neighborhoods in the SPM fashion where the information about the image class membership is available during training.", "startOffset": 13, "endOffset": 343}, {"referenceID": 4, "context": "Since the pooling approach looses spatial information of the codes, Lazebnik et al. [2006] proposed to first divide the image into subregions, and afterwards to create pooled features by concatenating histograms computed over each subregion.", "startOffset": 68, "endOffset": 91}, {"referenceID": 15, "context": "Although our method is independent of the choice of a dictionary and an encoding scheme, in this work we use K-means with triangle coding fk(x) := max {0, \u03bc(z)\u2212 zk} [Coates et al., 2011].", "startOffset": 165, "endOffset": 186}, {"referenceID": 7, "context": "As opposed to Le et al. [2012b] our training is fully independent and doesn\u2019t need communication between different machines.", "startOffset": 14, "endOffset": 32}, {"referenceID": 17, "context": "We evaluate our method on the CIFAR-10 and CIFAR-100 datasets [Krizhevsky and Hinton, 2010].", "startOffset": 62, "endOffset": 91}, {"referenceID": 18, "context": "All images have the same size: 32 \u00d7 32 pixels, and were sampled from the 80 million tiny images dataset [Torralba et al., 2008].", "startOffset": 104, "endOffset": 127}, {"referenceID": 18, "context": "In this work, we follow the Coates and Ng [2011] pipeline.", "startOffset": 28, "endOffset": 49}, {"referenceID": 15, "context": "As the next step, we employ the K-means assignment and triangle encoding [Coates and Ng, 2011, Coates et al., 2011] to compute codes \u2013 a K-dimensional representation of the patch. We classify images using either a logistic regression, or a linear SVM in the case of transferred pooling regions. Optionally we use two approximations described in subsection 2.4. As we want to be comparable to Coates et al. [2011], who use a spatial division into 2-by-2 subregions which results in 4 \u00b7K pooled features, we use 4 pooling units.", "startOffset": 95, "endOffset": 413}, {"referenceID": 19, "context": "Figure 1(a) shows the classification accuracy of our full method against the baseline [Coates and Ng, 2011].", "startOffset": 86, "endOffset": 107}, {"referenceID": 8, "context": "Our method performs comparable to the pooling strategy of Jia and Huang [2011] which uses more restrictive assumptions on the pooling regions and employs feature selection algorithm.", "startOffset": 58, "endOffset": 79}, {"referenceID": 19, "context": "Table 1: Comparison of our methods against the baseline [Coates and Ng, 2011] and Jia and Huang [2011] with respect to the dictionary size, number of features and the test accuracy on CIFAR-10.", "startOffset": 56, "endOffset": 77}, {"referenceID": 8, "context": "Table 1: Comparison of our methods against the baseline [Coates and Ng, 2011] and Jia and Huang [2011] with respect to the dictionary size, number of features and the test accuracy on CIFAR-10.", "startOffset": 82, "endOffset": 103}, {"referenceID": 20, "context": "To the best of our knowledge Ciresan et al. [2012] achieves the best results on the CIFAR-10 dataset with an accuracy 88.", "startOffset": 29, "endOffset": 51}, {"referenceID": 9, "context": "This notion of the random pooling differs from the Jia et al. [2012] where random selection of rectangles is used.", "startOffset": 51, "endOffset": 69}, {"referenceID": 8, "context": "To our best knowledge, this result consitutes the state-of-the-art performance on this dataset, outperforming Jia and Huang [2011] by 1.", "startOffset": 110, "endOffset": 131}, {"referenceID": 18, "context": "Table 4: The classification accuracy on CIFAR-100, where our method is compared against the Coates and Ng [2011] (we downloaded the framework from https://sites.", "startOffset": 92, "endOffset": 113}, {"referenceID": 8, "context": "com/site/kmeanslearning, we also use 5fold cross-validation to choose hyper-parameter C) and Jia and Huang [2011] (here we refer to the NIPS 2011 workshop paper).", "startOffset": 93, "endOffset": 114}, {"referenceID": 8, "context": "18% over our best result (batch-based approximation) and Jia and Huang [2011] respectively.", "startOffset": 57, "endOffset": 78}], "year": 2017, "abstractText": "From the early HMAX model to Spatial Pyramid Matching, pooling has played an important role in visual recognition pipelines. Spatial pooling, by grouping of local codes, equips these methods with a certain degree of robustness to translation and deformation yet preserving important spatial information. Despite the predominance of this approach in current recognition systems, we have seen little progress to fully adapt the pooling strategy to the task at hand. This paper proposes a model for learning task dependent pooling scheme \u2013 including previously proposed hand-crafted pooling schemes as a particular instantiation. In our work, we investigate the role of different regularization terms used in the proposed model together with an efficient method to train them. Our experiments show improved performance over hand-crafted pooling schemes on the CIFAR-10 and CIFAR100 datasets \u2013 in particular improving the state-of-the-art to 56.29% on the latter.", "creator": "LaTeX with hyperref package"}}}