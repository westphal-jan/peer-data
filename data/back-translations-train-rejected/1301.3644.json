{"id": "1301.3644", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Regularized Discriminant Embedding for Visual Descriptor Learning", "abstract": "Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.", "histories": [["v1", "Wed, 16 Jan 2013 10:12:37 GMT  (614kb,D)", "http://arxiv.org/abs/1301.3644v1", "3 pages + 1 additional page containing only cited references; The full version of this manuscript is currently under review in an international journal"]], "COMMENTS": "3 pages + 1 additional page containing only cited references; The full version of this manuscript is currently under review in an international journal", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["kye-hyeon kim", "rui cai", "lei zhang", "seungjin choi"], "accepted": false, "id": "1301.3644"}, "pdf": {"name": "1301.3644.pdf", "metadata": {"source": "CRF", "title": "Regularized Discriminant Embedding for Visual Descriptor Learning", "authors": ["Kye-Hyeon Kim", "Rui Cai", "Lei Zhang", "Seungjin Choia"], "emails": ["fenrir@postech.ac.kr,", "leizhang}@microsoft.com,", "seungjin@postech.ac.kr"], "sections": [{"heading": "1 Introduction", "text": "A local descriptor is a feature vector that represents the properties of an interesting local part of an image. Scale Invariant Feature Transformation (SIFT) [2] is popularly used to extract interesting parts and their local descriptors from an image. Comparing two images is done by aggregating pairs between each local descriptor in an image and its next local descriptor in another image whose paired distances are below a certain threshold. The assumption behind this method is that local descriptors corresponding to the same local part (\"matching descriptors\") are usually close enough in the feature space, while local descriptors belonging to different local parts (\"non-matching descriptors\") are far apart. However, this assumption does not apply if there are significant changes in environmental conditions (e.g. viewing point, noise and resolution) between two images."}, {"heading": "2 Proposed Method", "text": "\"We are not in a position to compare the different levels of education.\" \"We are not in a position to compare the different levels of education.\" \"We are not in a position to compare the different levels of education.\" \"We are not in a position to compare the different levels of education.\" \"We are not in a position to compare the different levels of education.\" \"We are not in a position to compare the different levels of education.\" \"We are not in a position to compare the different levels of education.\" \"We divide the levels of education of the local levels into four subsets, Relevant-Near, Relevant-Near-Relevant-Relevant-Relevant-Relevant-Relevant-Relevant-Relevant-Relevant-Relevant-Relevant-Relevant-Relevant.\""}], "references": [{"title": "Discriminant embedding for local image descriptors", "author": ["G. Hua", "M. Brown", "S. Winder"], "venue": "Proceedings of the International Conference on Computer Vision (ICCV), 2007, pp. 1\u20138.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Object recognition from local scale-invariant features", "author": ["D.G. Lowe"], "venue": "Proceedings of the International Conference on Computer Vision (ICCV), 1999, pp. 1150\u20131157.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Descriptor learning for efficient retrieval", "author": ["J. Philbin", "M. Isard", "J. Sivic", "A. Zisserman"], "venue": "Proceedings of the European Conference on Computer Vision (ECCV), 2010, pp. 677\u2013691.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Dimensionality reduction of multimodal labeled data by local Fisher discriminant analysis", "author": ["M. Sugiyama"], "venue": "Journal of Machine Learning Research, vol. 5, pp. 1027\u20131061, 2007. 4", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 1, "context": "Scale-invariant feature transform (SIFT) [2] is popularly used for extracting interesting parts and their local descriptors from an image.", "startOffset": 41, "endOffset": 44}, {"referenceID": 0, "context": "Using linear discriminant embedding (LDE) [1], non-matching pairs are still closer than matching pairs in the first three examples.", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "In descriptor learning [1, 3], a projection is obtained from training pairs of matching and nonmatching descriptors in order to map given local descriptors (e.", "startOffset": 23, "endOffset": 29}, {"referenceID": 2, "context": "In descriptor learning [1, 3], a projection is obtained from training pairs of matching and nonmatching descriptors in order to map given local descriptors (e.", "startOffset": 23, "endOffset": 29}, {"referenceID": 3, "context": "Traditional techniques for supervised dimensionality reduction, including linear discriminant analysis (LDA) and local Fisher discriminant analysis (LFDA) [4], can be applied to descriptor learning after a slight modification.", "startOffset": 155, "endOffset": 158}, {"referenceID": 0, "context": "For example, linear discriminant embedding (LDE) [1] is come from LDA with a simple modification for handling pairwise training data.", "startOffset": 49, "endOffset": 52}], "year": 2013, "abstractText": "Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.", "creator": "LaTeX with hyperref package"}}}