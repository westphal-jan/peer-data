{"id": "1301.3836", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "The Complexity of Decentralized Control of Markov Decision Processes", "abstract": "Planning for distributed agents with partial state information is considered from a decision- theoretic perspective. We describe generalizations of both the MDP and POMDP models that allow for decentralized control. For even a small number of agents, the finite-horizon problems corresponding to both of our models are complete for nondeterministic exponential time. These complexity results illustrate a fundamental difference between centralized and decentralized control of Markov processes. In contrast to the MDP and POMDP problems, the problems we consider provably do not admit polynomial-time algorithms and most likely require doubly exponential time to solve in the worst case. We have thus provided mathematical evidence corresponding to the intuition that decentralized planning problems cannot easily be reduced to centralized problems and solved exactly using established techniques.", "histories": [["v1", "Wed, 16 Jan 2013 15:48:55 GMT  (209kb)", "http://arxiv.org/abs/1301.3836v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["daniel s bernstein", "shlomo zilberstein", "neil immerman"], "accepted": false, "id": "1301.3836"}, "pdf": {"name": "1301.3836.pdf", "metadata": {"source": "CRF", "title": "The Complexity of Decentralized Control of Markov Decision Processes", "authors": ["Daniel S. Bernstein", "Shlomo Zilberstein", "Neil Immerman"], "emails": ["@cs.umass.edu"], "sections": [{"heading": null, "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, a country, a city and a country."}], "references": [{"title": "Decentral\u00ad ized optimal control of Markov chains with a common past information set", "author": ["M. Aicardi", "D. Franco", "R. Minciardi"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "Aicardi et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Aicardi et al\\.", "year": 1987}, {"title": "Non\u00ad deterministic exponential time has two-prover interactive protocols", "author": ["L. Babai", "L. Fortnow", "C. Lund"], "venue": "Computational Complexity,", "citeRegEx": "Babai et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Babai et al\\.", "year": 1991}, {"title": "Multiagent systems: Challenges and opportunities for decision-theoretic planning", "author": ["C. Boutilier"], "venue": "AI Magazine, 20(4), 35-43.", "citeRegEx": "Boutilier,? 1999", "shortCiteRegEx": "Boutilier", "year": 1999}, {"title": "In\u00ad cremental pruning: A simple, fast, exact method for par\u00ad tially observable Markov decision processes", "author": ["A. Cassandra", "M.L. Littman", "N.L. Zhang"], "venue": "In Proceed\u00ad ings of the T hirteenth Annual Conference on Uncertainty in Artificial Intelligence (pp", "citeRegEx": "Cassandra et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Cassandra et al\\.", "year": 1997}, {"title": "A survey of research in distributed, continual planning", "author": ["M.E. desJardins", "E.H. Durfee", "C.L. Ortiz", "M.J. Wolverton"], "venue": "AI Magazine,", "citeRegEx": "desJardins et al\\.,? \\Q1999\\E", "shortCiteRegEx": "desJardins et al\\.", "year": 1999}, {"title": "Distributed problem solving and planning", "author": ["E.H. Durfee"], "venue": "Multiagent Systems (pp. 121-164). Cam\u00ad bridge, MA: The MIT Press.", "citeRegEx": "Durfee,? 1999", "shortCiteRegEx": "Durfee", "year": 1999}, {"title": "An integrated system for mulit-rover scientific exploration", "author": ["T. Estlin", "A. Gray", "T. Mann", "G. Rabideau", "R. Castano", "S. Chien", "E. Mjolsness"], "venue": "In Proceedings of the Sixteenth National Conference on Artificial Intelligence (pp. 541-548)", "citeRegEx": "Estlin et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Estlin et al\\.", "year": 1999}, {"title": "Collaborative plans for com\u00ad plex group action", "author": ["B. Grosz", "S. Kraus"], "venue": "Artificial Intelligence,", "citeRegEx": "Grosz and Kraus,? \\Q1996\\E", "shortCiteRegEx": "Grosz and Kraus", "year": 1996}, {"title": "Solving POMDPs by searching in pol\u00ad icy space", "author": ["E. Hansen"], "venue": "Proceedings of the Fourteenth Annual Con\u00ad ference on Uncertainty in Artificial Intelligence (pp. 211219).", "citeRegEx": "Hansen,? 1998", "shortCiteRegEx": "Hansen", "year": 1998}, {"title": "Reinforce\u00ad ment learning algorithm for partially observable Markov decision problems", "author": ["T. Jaakkola", "S.P. Singh", "M.I. Jordan"], "venue": "In Proceedings of Advances in Neural Information Processing Systems", "citeRegEx": "Jaakkola et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Jaakkola et al\\.", "year": 1995}, {"title": "Planning and actiong in partially observable stochastic do\u00ad mains", "author": ["L.P. Kaelbling", "M.L. Littman", "A.R. Cassandra"], "venue": "Artificial Intelligence,", "citeRegEx": "Kaelbling et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kaelbling et al\\.", "year": 1998}, {"title": "Reflections on the nature of multi\u00ad agent coordination and its implications for an agent archi\u00ad tecture", "author": ["V.R. Lesser"], "venue": "Autonomous Agents and Multi-Agent Systems, 1, 89-111.", "citeRegEx": "Lesser,? 1998", "shortCiteRegEx": "Lesser", "year": 1998}, {"title": "On the un\u00ad decidability of probabilistic planning and infinite-horizon partially observable Markov decision process problems", "author": ["Madani", "S. Hanks", "A. Condon"], "venue": null, "citeRegEx": "Madani et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Madani et al\\.", "year": 1999}, {"title": "Using communication to reduce lo\u00ad", "author": ["M.J. Mataric"], "venue": null, "citeRegEx": "Mataric,? \\Q1998\\E", "shortCiteRegEx": "Mataric", "year": 1998}, {"title": "Decentralized con\u00ad trol of a multiple access broadcast channel: Performance bounds", "author": ["J.M. Ooi", "G.W. Wornell"], "venue": "In Proceedings of the 35th Conference on Deci\u00ad sion and Control (pp. 293-298)", "citeRegEx": "Ooi and Wornell,? \\Q1996\\E", "shortCiteRegEx": "Ooi and Wornell", "year": 1996}, {"title": "Computational Complexity", "author": ["C.H. Papadimitriou"], "venue": "Reading, MA: Addison-Wesley. Papadimitriou, C. H. & Tsitsiklis, J. N. (1987). The com\u00ad plexity of Markov decision processes. Mathematics of Op\u00ad erations Research, 12(3), 441-450.", "citeRegEx": "Papadimitriou,? 1994", "shortCiteRegEx": "Papadimitriou", "year": 1994}, {"title": "Learning to cooperate via policy search", "author": ["L. Peshkin", "Kim", "K.-E", "N. Meuleau", "L.P. Kaelbling"], "venue": "In Pro\u00ad ceedings of the Sixteenth International Conference on Un\u00ad certainty in Artificial Intelligence. Peterson,", "citeRegEx": "Peshkin et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Peshkin et al\\.", "year": 2000}, {"title": "Task decomposition, dy\u00ad namic role assignment, and low-bandwidth communication for real-time strategic teamwork", "author": ["ternation"], "venue": "Annual Symposium on Foundations of Computer Science (pp. 348-363)", "citeRegEx": "ternation.,? \\Q1999\\E", "shortCiteRegEx": "ternation.", "year": 1999}, {"title": "On the complexity of decentralized decision making and detection problems", "author": ["J.N. Tsitsiklis", "M. Athans"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "Tsitsiklis and Athans,? \\Q1985\\E", "shortCiteRegEx": "Tsitsiklis and Athans", "year": 1985}, {"title": "Markov Decision Processes", "author": ["D.J. White"], "venue": "West Sussex, England: John Wiley & Sons.", "citeRegEx": "White,? 1993", "shortCiteRegEx": "White", "year": 1993}], "referenceMentions": [{"referenceID": 11, "context": "growing interest in problems with multiple distributed agents working to achieve a common goal (Grosz & Kraus, 1996; Lesser, 1998; desJardins et al., 1999; Durfee, 1999; Stone & Veloso, 1999).", "startOffset": 95, "endOffset": 191}, {"referenceID": 4, "context": "growing interest in problems with multiple distributed agents working to achieve a common goal (Grosz & Kraus, 1996; Lesser, 1998; desJardins et al., 1999; Durfee, 1999; Stone & Veloso, 1999).", "startOffset": 95, "endOffset": 191}, {"referenceID": 5, "context": "growing interest in problems with multiple distributed agents working to achieve a common goal (Grosz & Kraus, 1996; Lesser, 1998; desJardins et al., 1999; Durfee, 1999; Stone & Veloso, 1999).", "startOffset": 95, "endOffset": 191}, {"referenceID": 13, "context": "For instance, consider two robots cooperating to push a box (Mataric, 1998).", "startOffset": 60, "endOffset": 75}, {"referenceID": 6, "context": "Other problems of planning for distributed agents with limited communication include maximizing the throughput of a multiple access broadcast channel (Ooi & Womell, 1996) and coordinating multiple spacecraft on a mission together (Estlin et al., 1999).", "startOffset": 230, "endOffset": 251}, {"referenceID": 19, "context": "A partially observable Markov decision process (POMDP) is a generalization of an MDP in which an agent must base its decisions on incomplete information about the state of the environment (White, 1993).", "startOffset": 188, "endOffset": 201}, {"referenceID": 2, "context": "Boutilier (1999) studies multi-agent Markov decision processes (MMDPs), but in this model, the agents all have access to the same in\u00ad formation.", "startOffset": 0, "endOffset": 17}, {"referenceID": 2, "context": "Boutilier (1999) studies multi-agent Markov decision processes (MMDPs), but in this model, the agents all have access to the same in\u00ad formation. In the framework we describe, this assumption is not made. Peshkin et al. (2000) use essentially the DEC\u00ad POMDP model (although they refer to it as a partially ob\u00ad servable identical payoff stochastic game (POIPSG)) and discuss algorithms for obtaining approximate solutions to the corresponding optimization problem.", "startOffset": 0, "endOffset": 226}, {"referenceID": 15, "context": "We prove that for all m 2: 2, DEC-POMDP m is NEXP-complete, and for all m 2: 3, DEC-MDP m is NEXP-complete, where NEXP = NTIME (2n ) (Papadimitriou, 1994).", "startOffset": 133, "endOffset": 154}, {"referenceID": 10, "context": "The transition probabilities and expected rewards for the corresponding \"belief MDP\" can be computed in exponential time (Kaelbling et al., 1998).", "startOffset": 121, "endOffset": 145}, {"referenceID": 1, "context": "Second, we have drawn a connection be\u00ad tween work on Markov decision processes and the body of work in complexity theory that deals with the exponen\u00ad tial jump in complexity due to decentralization (Peterson & Reif, 1979; Babai et al., 1991).", "startOffset": 198, "endOffset": 241}, {"referenceID": 3, "context": "Consider the growing body of work on algorithms for ob\u00ad taining exact or approximate solutions for POMDPs (e.g., Jaakkola et al., 1995; Cassandra et al., 1997; Hansen, 1998).", "startOffset": 106, "endOffset": 173}, {"referenceID": 8, "context": "Consider the growing body of work on algorithms for ob\u00ad taining exact or approximate solutions for POMDPs (e.g., Jaakkola et al., 1995; Cassandra et al., 1997; Hansen, 1998).", "startOffset": 106, "endOffset": 173}, {"referenceID": 12, "context": "It has recently been shown that the infinite-horizon POMDP problem is undecidable (Madani et al., 1999) under several different optimality criteria.", "startOffset": 82, "endOffset": 103}], "year": 2011, "abstractText": "Planning for distributed agents with partial state information is considered from a decision\u00ad theoretic perspective. We describe generaliza\u00ad tions of both the MDP and POMDP models that allow for decentralized control. For even a small number of agents, the finite-horizon prob\u00ad lems corresponding to both of our models are complete for nondeterministic exponential time. These complexity results illustrate a fundamen\u00ad tal difference between centralized and decentral\u00ad ized control of Markov processes. In contrast to the MDP and POMDP problems, the problems we consider provably do not admit polynomial\u00ad time algorithms and most likely require doubly exponential time to solve in the worst case. We have thus provided mathematical evidence corre\u00ad sponding to the intuition that decentralized plan\u00ad ning problems cannot easily be reduced to cen\u00ad tralized problems and solved exactly using estab\u00ad lished techniques.", "creator": "pdftk 1.41 - www.pdftk.com"}}}