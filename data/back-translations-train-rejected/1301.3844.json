{"id": "1301.3844", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "A Bayesian Method for Causal Modeling and Discovery Under Selection", "abstract": "This paper describes a Bayesian method for learning causal networks using samples that were selected in a non-random manner from a population of interest. Examples of data obtained by non-random sampling include convenience samples and case-control data in which a fixed number of samples with and without some condition is collected; such data are not uncommon. The paper describes a method for combining data under selection with prior beliefs in order to derive a posterior probability for a model of the causal processes that are generating the data in the population of interest. The priors include beliefs about the nature of the non-random sampling procedure. Although exact application of the method would be computationally intractable for most realistic datasets, efficient special-case and approximation methods are discussed. Finally, the paper describes how to combine learning under selection with previous methods for learning from observational and experimental data that are obtained on random samples of the population of interest. The net result is a Bayesian methodology that supports causal modeling and discovery from a rich mixture of different types of data.", "histories": [["v1", "Wed, 16 Jan 2013 15:49:26 GMT  (271kb)", "http://arxiv.org/abs/1301.3844v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["gregory f cooper"], "accepted": false, "id": "1301.3844"}, "pdf": {"name": "1301.3844.pdf", "metadata": {"source": "CRF", "title": "A Bayesian Method for Causal Modeling and Discovery Under Selection", "authors": [], "emails": ["gfc@cbmi.upmc.edu"], "sections": [{"heading": null, "text": "In fact, it is the case that most people who are able to survive themselves are not able to survive themselves. (...) Most people who are able to survive themselves are able to survive themselves. (...) Most people who are able to survive themselves are not able to survive themselves. (...) Most people who are able to survive themselves are able to survive themselves. (...) Most people who are able to survive themselves are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}], "references": [{"title": "Learning Bayesian networks is NP-complete", "author": ["M. Chickering"], "venue": null, "citeRegEx": "Chickering,? \\Q1996\\E", "shortCiteRegEx": "Chickering", "year": 1996}, {"title": "The computational complexity", "author": ["G.F. Cooper"], "venue": null, "citeRegEx": "Cooper,? \\Q1990\\E", "shortCiteRegEx": "Cooper", "year": 1990}, {"title": "Causal discovery from data in the presence of selection bias", "author": ["G.F. Cooper"], "venue": "Proceedings of the Workshop on Artificial Intelligence and Statistics", "citeRegEx": "Cooper,? \\Q1995\\E", "shortCiteRegEx": "Cooper", "year": 1995}, {"title": "Probabilistic temporal reasoning, In: Proceedings of AAAI 524-528", "author": ["T. Dean", "K. Kanazawa"], "venue": null, "citeRegEx": "Dean and Kanazawa,? \\Q1988\\E", "shortCiteRegEx": "Dean and Kanazawa", "year": 1988}, {"title": "Probabilistic Reasoning in Intelligent Systems", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Evidence absorption and propagation through evidence reversals", "author": ["R.D. Shachter"], "venue": "Proceedings of the Workshop on Uncertainty in Artificial Intelligence", "citeRegEx": "Shachter,? \\Q1989\\E", "shortCiteRegEx": "Shachter", "year": 1989}, {"title": "Causation, Prediction, and Search", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": null, "citeRegEx": "Spirtes et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Spirtes et al\\.", "year": 1993}, {"title": "Explanations for multivariate structures derived from univariate recursive regressions, Report", "author": ["N. Wermuth", "D.R. Cox", "J. Pearl"], "venue": null, "citeRegEx": "Wermuth et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Wermuth et al\\.", "year": 1994}], "referenceMentions": [{"referenceID": 2, "context": "In (Cooper 1995), numerous conditions under which causal structure and parameters can (and cannot) be learned from conditional-independence tests are described, when there is selection; a special-case Bayesian analysis of causal modeling under selection also is proposed.", "startOffset": 3, "endOffset": 16}, {"referenceID": 4, "context": "A causal Bayesian network (or causal network for short) is a Bayesian network in which each arc is interpreted as a direct causal influence between a parent node (variable) and a child node, relative to the other nodes in the network (Pearl 1988).", "startOffset": 234, "endOffset": 246}, {"referenceID": 4, "context": "The causal Markov condition permits the joint distribution of the n variables in a causal network to be factored as follows (Pearl 1988):", "startOffset": 124, "endOffset": 136}, {"referenceID": 2, "context": "To represent selection, we introduce a variable called S into model M that has states T and F, which designate whether a given case was sampled (7) or not (F) (Cooper 1995).", "startOffset": 159, "endOffset": 172}, {"referenceID": 4, "context": "be dependent, because they are d-connected (Pearl 1988).", "startOffset": 43, "endOffset": 55}, {"referenceID": 1, "context": "Proof In (Cooper 1990), 3-SAT is reduced to causal network inference by using a network structure that includes a single node that has parents but no children.", "startOffset": 9, "endOffset": 22}, {"referenceID": 0, "context": "Proof In the absence of selection, (Chickering 1996) showed that finding a network structure M that maximizes P(D I M, K) is NP-hard.", "startOffset": 35, "endOffset": 52}, {"referenceID": 1, "context": "A proof parallel to the one in Theorem 2 can be used to reduce Bayesian network inference in the absence of selection (Cooper 1990) to Bayesian network inference under selection.", "startOffset": 118, "endOffset": 131}, {"referenceID": 5, "context": "We can apply Bayes rule to the prior parameters on B in order to reverse all arcs away from S (Shachter 1989), yielding a tree with the same connectivity, but no arcs into S.", "startOffset": 94, "endOffset": 109}, {"referenceID": 5, "context": "If S and its ancestors do not form a tree, heuristically we could reverse arcs (Shachter 1989) away from S anyway, thereby creating a network in which S is a root node.", "startOffset": 79, "endOffset": 94}, {"referenceID": 3, "context": "By using temporal causal networks (Dean and Kanazawa 1988) we can represent more complex types of data mixtures in which selection and experimentation occur over time.", "startOffset": 34, "endOffset": 58}], "year": 2011, "abstractText": "This paper describes a Bayesian method for learning causal networks using samples that were selected in a non-random manner from a population of interest. Examples of data obtained by non-random sampling include convenience samples and case-control data in which a fixed number of samples with and without some condition is collected; such data are not uncommon. The paper describes a method for combining data under selection with prior beliefs in order to derive a posterior probability for a model of the causal processes that are generating the data in the population of interest. The priors include beliefs about the nature of the non-random sampling procedure. Although exact application of the method would be computationally intractable for most realistic datasets, efficient special-case and approximation methods are discussed. Finally, the paper describes how to combine learning under selection with previous methods for learning from observational and experimental data that are obtained on random samples of the population of interest. The net result is a Bayesian methodology that supports causal modeling and discovery from a rich mixture of different types of data.", "creator": "pdftk 1.41 - www.pdftk.com"}}}