{"id": "1301.3855", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Likelihood Computations Using Value Abstractions", "abstract": "In this paper, we use evidence-specific value abstraction for speeding Bayesian networks inference. This is done by grouping variable values and treating the combined values as a single entity. As we show, such abstractions can exploit regularities in conditional probability distributions and also the specific values of observed variables. To formally justify value abstraction, we define the notion of safe value abstraction and devise inference algorithms that use it to reduce the cost of inference. Our procedure is particularly useful for learning complex networks with many hidden variables. In such cases, repeated likelihood computations are required for EM or other parameter optimization techniques. Since these computations are repeated with respect to the same evidence set, our methods can provide significant speedup to the learning procedure. We demonstrate the algorithm on genetic linkage problems where the use of value abstraction sometimes differentiates between a feasible and non-feasible solution.", "histories": [["v1", "Wed, 16 Jan 2013 15:50:10 GMT  (346kb)", "http://arxiv.org/abs/1301.3855v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nir friedman", "dan geiger", "noam lotner"], "accepted": false, "id": "1301.3855"}, "pdf": {"name": "1301.3855.pdf", "metadata": {"source": "CRF", "title": "Likelihood Computations Using Value Abstraction", "authors": ["Nir Friedman", "Dan Geiger"], "emails": [], "sections": [{"heading": null, "text": "This year, it is closer than ever before in the history of the country."}], "references": [{"title": "Bucket elimination: A unifying frame\u00ad work for probabilistic inference", "author": ["R. Dechter"], "venue": "UAI 1 9 96. [ 5] R. C. Elston and J. Stewart. A general model for the analysis of pedigree data. Human Heredity, 21: 523- 542, 1 971. [  6] C. Harbron and A. Thomas. Alternative graphical rep\u00ad resentations of genotypes in a pedigree. IMA Jour\u00ad nal of Mathematics Applied in Medicine and Biology, 11:217-228, 1 9 94. [7] F. V. Jensen, S. L. Lauritzen, and K. G. Olesen. Bayesian updating in causal probabilistic networks by  local computations. Computational Statistics Quar\u00ad terly, 5 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2367}], "referenceMentions": [{"referenceID": 0, "context": "It is easy to see that this procedure is closely related to variable elimination algorithms [3, 4, 16], except that", "startOffset": 92, "endOffset": 102}], "year": 2011, "abstractText": "In this paper, we use evidence-specific value ab\u00ad straction for speeding Bayesian networks infer\u00ad ence. This is done by grouping variable val\u00ad ues and treating the combined values as a sin\u00ad gle entity. As we show, such abstractions can ex\u00ad ploit regularities in conditional probability distri\u00ad butions and also the specific values of observed variables. To formally justify value abstraction, we defi ne the notion of safe value abstraction and devise inference algorithms that use it to re\u00ad duce the cost of inference. Our procedure is par\u00ad ticularly useful for learning complex networks with many hidden variables. In such cases, re\u00ad peated likelihood computations are required for E M or other parameter optimization techniques. Since these computations are repeated with re\u00ad spect to the same evidence set, our methods can provide signifi cant speedup to the learning pro\u00ad cedure. We demonstrate the algorithm on genetic linkage problems where the use of value abstrac\u00ad tion sometimes differentiates between a feasible and non-feasible solution.", "creator": "pdftk 1.41 - www.pdftk.com"}}}