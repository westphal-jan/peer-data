{"id": "1301.3861", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Inference for Belief Networks Using Coupling From the Past", "abstract": "Inference for belief networks using Gibbs sampling produces a distribution for unobserved variables that differs from the correct distribution by a (usually) unknown error, since convergence to the right distribution occurs only asymptotically. The method of \"coupling from the past\" samples from exactly the correct distribution by (conceptually) running dependent Gibbs sampling simulations from every possible starting state from a time far enough in the past that all runs reach the same state at time t=0. Explicitly considering every possible state is intractable for large networks, however. We propose a method for layered noisy-or networks that uses a compact, but often imprecise, summary of a set of states. This method samples from exactly the correct distribution, and requires only about twice the time per step as ordinary Gibbs sampling, but it may require more simulation steps than would be needed if chains were tracked exactly.", "histories": [["v1", "Wed, 16 Jan 2013 15:50:34 GMT  (240kb)", "http://arxiv.org/abs/1301.3861v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["michael harvey", "radford m neal"], "accepted": false, "id": "1301.3861"}, "pdf": {"name": "1301.3861.pdf", "metadata": {"source": "CRF", "title": "Inference for Belief Networks Using Coupling From the Past", "authors": ["Michael Harvey", "Radford M. Neal"], "emails": ["mikeh@cs.", "radford@cs."], "sections": [{"heading": null, "text": "This method of \"coupling from the past\" is tractable in any possible state for large networks, however, we propose a method for layered sampling simulations from any possible initial state that uses a compact, but often impregnated, summary summary summary of a set of states. This method only requires about twice the time per step as ordinary Gibbs sampling, but it may require more simulation steps than would be necessary if it requires exact simulation steps. It requires more simulation steps than it takes to perform exact simulation steps in large networks. We propose a method for layered sampling or net work that uses a compact but often implicit summary of a set of states. This method only requires about twice the time per step as ordinary Gibbs sampling, but it requires more simulation steps than would be necessary if chains are exact steps."}], "references": [{"title": "On exact simulation of Markov random fields using coupling from the past", "author": ["Haggstrom", "K. Nelander"], "venue": "Scandinavian Journal of Statistics,", "citeRegEx": "Haggstrom et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Haggstrom et al\\.", "year": 1999}, {"title": "Monte Carlo Inference for Belief Networks Using Coupling From the Past, MSc The\u00ad", "author": ["M. Harvey"], "venue": null, "citeRegEx": "Harvey,? \\Q1999\\E", "shortCiteRegEx": "Harvey", "year": 1999}, {"title": "Exact sampling and approximate counting techniques", "author": ["M. Huber"], "venue": "Proceedings of the 30th ACM Symposium on the Theory of Computing,", "citeRegEx": "Huber,? \\Q1998\\E", "shortCiteRegEx": "Huber", "year": 1998}, {"title": "Exact Sam\u00ad pling with Coupled Markov Chains and Applications to Statistical Mechanics", "author": ["J.G. Propp", "D.B. Wilson"], "venue": "Random Structures and Algorithms,", "citeRegEx": "Propp and Wilson,? \\Q1996\\E", "shortCiteRegEx": "Propp and Wilson", "year": 1996}, {"title": "Evidential Reasoning Using Stochas\u00ad tic Simulation of Causal Models", "author": ["J. Pearl"], "venue": "Artificial Intelli\u00ad gence,", "citeRegEx": "Pearl,? \\Q1987\\E", "shortCiteRegEx": "Pearl", "year": 1987}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Convergence rates of Markov chains", "author": ["J.S. Rosenthal"], "venue": "SIAM Review,", "citeRegEx": "Rosenthal,? \\Q1995\\E", "shortCiteRegEx": "Rosenthal", "year": 1995}], "referenceMentions": [{"referenceID": 3, "context": "To overcome this problem of initialization bias, Propp and Wilson (1997) introduced exact sampling, also known as perfect simulation, using the method of \"cou\u00ad pling from the past\" to obtain states from exactly the desired distribution.", "startOffset": 49, "endOffset": 73}, {"referenceID": 6, "context": "(See Rosenthal (1995) for further discussion.", "startOffset": 5, "endOffset": 22}, {"referenceID": 3, "context": "Propp and Wilson (1997) show that this scheme is not far from optimal, requiring no more than four times the total number of simulation steps", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "Propp and Wilson (1997) show that coupling from the past can be implemented efficiently when states can be given a partial order that is preserved through Markov chain transitions, by simulating just two chains, started from the minimal and maximal states.", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "Similar techniques, applied to simulation of Markov random fields, have been independently developed by Huber (1998) and by Haggstrom and Nelander (1999).", "startOffset": 104, "endOffset": 117}, {"referenceID": 2, "context": "Similar techniques, applied to simulation of Markov random fields, have been independently developed by Huber (1998) and by Haggstrom and Nelander (1999).", "startOffset": 104, "endOffset": 154}, {"referenceID": 1, "context": "The rules for selecting the appropriate states are summarized below, and justified in detail by Harvey (1999).", "startOffset": 96, "endOffset": 110}, {"referenceID": 3, "context": ", Propp and Wilson (1997) show that the expected total number of time steps simulated is around 2.", "startOffset": 2, "endOffset": 26}, {"referenceID": 1, "context": "tests are described in detail by Harvey (1999).", "startOffset": 33, "endOffset": 47}], "year": 2011, "abstractText": "Inference for belief networks using Gibbs sampling produces a distribution for unob\u00ad served variables that differs from the correct distribution by a (usually) unknown error, since convergence to the right distribution occurs only asymptotically. The method of \"coupling from the past\" samples from ex\u00ad actly the correct distribution by ( conceptu\u00ad ally) running dependent Gibbs sampling sim\u00ad ulations from every possible starting state from a time far enough in the past that all runs reach the same state at time t = 0. Ex\u00ad plicitly considering every possible state is in\u00ad tractable for large networks, however. We propose a method for layered noisy-or net\u00ad works that uses a compact, but often impre\u00ad cise, summary of a set of states. This method samples from exactly the correct distribution, and requires only about twice the time per step as ordinary Gibbs sampling, but it may require more simulation steps than would be needed if chains were tracked exactly.", "creator": "pdftk 1.41 - www.pdftk.com"}}}