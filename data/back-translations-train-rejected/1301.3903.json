{"id": "1301.3903", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Exploiting Qualitative Knowledge in the Learning of Conditional Probabilities of Bayesian Networks", "abstract": "Algorithms for learning the conditional probabilities of Bayesian networks with hidden variables typically operate within a high-dimensional search space and yield only locally optimal solutions. One way of limiting the search space and avoiding local optima is to impose qualitative constraints that are based on background knowledge concerning the domain. We present a method for integrating formal statements of qualitative constraints into two learning algorithms, APN and EM. In our experiments with synthetic data, this method yielded networks that satisfied the constraints almost perfectly. The accuracy of the learned networks was consistently superior to that of corresponding networks learned without constraints. The exploitation of qualitative constraints therefore appears to be a promising way to increase both the interpretability and the accuracy of learned Bayesian networks with known structure.", "histories": [["v1", "Wed, 16 Jan 2013 15:53:24 GMT  (378kb)", "http://arxiv.org/abs/1301.3903v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["frank wittig", "anthony jameson"], "accepted": false, "id": "1301.3903"}, "pdf": {"name": "1301.3903.pdf", "metadata": {"source": "CRF", "title": "Exploiting Qualitative Knowledge in the Learning of Conditional Probabilities of Bayesian Networks", "authors": ["Frank Wittig", "Anthony Jameson"], "emails": ["jameson}@cs.uni-sb.de"], "sections": [{"heading": null, "text": "Algorithms for learning the conditional possibilities of Bayesian networks with hidden variables typically operate within a high-dimensional search space and provide only locally optimal solutions. One way to limit the search space and avoid local optima is to impose qualitative constraints based on domain background knowledge. We present a method for integrating formal statements of agonizing constraints into two learning algorithms, APN and EM. In our experiments with synthetic data, this method provided networks that met the constraints almost perfectly, and the accuracy of the learned networks was consistently superior to those of corresponding networks that were learned without constraints. Thus, exploiting qualitative constraints seems to be a promising way to increase both the interpretability and the acceptance of learned Bayesian networks with known structures."}, {"heading": "If you don 't know where you're going, you might", "text": "This year, the time has come for us to be able to go in search of a solution that is capable, that we are able, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution."}], "references": [{"title": "Update rules for pa\u00ad rameter estimation in Bayesian networks", "author": ["D. Koller", "Y. Singer"], "venue": "Uncertainty in Artificial Intelligence: Proceedings of the Thirteenth Conference (pp. 3-13)", "citeRegEx": "Koller and Singer,? \\Q1997\\E", "shortCiteRegEx": "Koller and Singer", "year": 1997}, {"title": "Adap\u00ad tive probabilistic networks with hidden variables", "author": [], "venue": "Machine Learning,", "citeRegEx": "K.,? \\Q1997\\E", "shortCiteRegEx": "K.", "year": 1997}, {"title": "Expert sys\u00ad tems and probabilistic network models", "author": ["E. Castillo", "J.M. Gutierrez", "A.S. Hadi"], "venue": null, "citeRegEx": "Castillo et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Castillo et al\\.", "year": 1997}, {"title": "Max\u00ad imum likelihood from incomplete data via the EM algo\u00ad rithm", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": "Journal of the Royal Statistical Society,", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "Learn\u00ad ing Bayesian nets that perform well", "author": ["R. Greiner", "A.J. Grove", "D. Schuurmans"], "venue": "Uncertainty in Artificial Intelligence: Pro\u00ad ceedings of the Thirteenth Conference (pp. 198-207)", "citeRegEx": "Greiner et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Greiner et al\\.", "year": 1997}, {"title": "A tutorial on learning with Bayesian networks", "author": ["D. Beckerman"], "venue": null, "citeRegEx": "Beckerman,? \\Q1998\\E", "shortCiteRegEx": "Beckerman", "year": 1998}, {"title": "Creating an empirical basis for adaptation deci\u00ad sions", "author": ["A. Jameson", "B. GroBmann-Hutter", "L. March", "R. Rummer"], "venue": "In H. Lieberman (Ed.), IU/2000: International Con\u00ad ference on Intelligent User Interfaces (pp. 149-156)", "citeRegEx": "Jameson et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Jameson et al\\.", "year": 2000}, {"title": "Rethinking the learning of belief network probabilities", "author": ["R. Musick"], "venue": "Proceedings of the Second International Confer\u00ad ence on Knowledge Discovery and Data Mining (pp. 120125)", "citeRegEx": "Musick,? \\Q1996\\E", "shortCiteRegEx": "Musick", "year": 1996}, {"title": "Accelerating EM: An empirical study", "author": ["L.E. Ortiz", "L.P. Kaelbling"], "venue": null, "citeRegEx": "Ortiz and Kaelbling,? \\Q1999\\E", "shortCiteRegEx": "Ortiz and Kaelbling", "year": 1999}, {"title": "Probabilistic reasoning in intelligent systems: Networks of plausible iJiference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Local learning in probabilistic networks with hidden variables", "author": [], "venue": "Proceedings of the Fourteenth In\u00ad ternational Joint Conference on Artificial Intelligence (pp", "citeRegEx": "K.,? \\Q1995\\E", "shortCiteRegEx": "K.", "year": 1995}, {"title": "Fundamental concepts of qualitative probabilistic networks", "author": ["M.P. Wellman"], "venue": "Artificial Intelligence,", "citeRegEx": "Wellman,? \\Q1990\\E", "shortCiteRegEx": "Wellman", "year": 1990}], "referenceMentions": [{"referenceID": 11, "context": "Within the framework of qualitative probabilistic networks (Wellman, 1990), Druzdzel and van der Gaag ( 1995) give formal probabilistic definitions of several types of quali\u00ad tative relationships that can hold between nodes in a BN.", "startOffset": 59, "endOffset": 74}], "year": 2011, "abstractText": "Algorithms for learning the conditional proba\u00ad bilities of Bayesian networks with hidden vari\u00ad ables typically operate within a high-dimensional search space and yield only locally optimal so\u00ad lutions. One way of limiting the search space and avoiding local optima is to impose quali\u00ad tative constraints that are based on background knowledge concerning the domain. We present a method for integrating formal statements of qual\u00ad itative constraints into two learning algorithms, APN and EM. In our experiments with synthetic data, this method yielded networks that satisfied the constraints almost perfectly. The accuracy of the learned networks was consistently superior to that of corresponding networks learned without constraints. The exploitation of qualitative con\u00ad straints therefore appears to be a promising way to increase both the interpretability and the accu\u00ad racy of learned Bayesian networks with known structure. If you don 't know where you're going, you might wind up someplace else. -Yogi Berra", "creator": "pdftk 1.41 - www.pdftk.com"}}}