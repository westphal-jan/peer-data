{"id": "1301.4351", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2013", "title": "Applying machine learning techniques to improve user acceptance on ubiquitous environement", "abstract": "Ubiquitous information access becomes more and more important nowadays and research is aimed at making it adapted to users. Our work consists in applying machine learning techniques in order to adapt the information access provided by ubiquitous systems to users when the system only knows the user social group, without knowing anything about the user interest. The adaptation procedures associate actions to perceived situations of the user. Associations are based on feedback given by the user as a reaction to the behavior of the system. Our method brings a solution to some of the problems concerning the acceptance of the system by users when applying machine learning techniques to systems at the beginning of the interaction between the system and the user.", "histories": [["v1", "Fri, 18 Jan 2013 11:26:54 GMT  (572kb)", "http://arxiv.org/abs/1301.4351v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.AI", "authors": ["djallel bouneffouf"], "accepted": false, "id": "1301.4351"}, "pdf": {"name": "1301.4351.pdf", "metadata": {"source": "CRF", "title": "Applying machine learning techniques to improve user acceptance on ubiquitous environment", "authors": ["Djallel Bouneffouf"], "emails": ["Djallel.bouneffouf@it-sudparis.eu"], "sections": [{"heading": null, "text": "Our work consists in the application of machine learning techniques to adapt the information access of ubiquitous systems to users when the system only knows the social group of the user without knowing anything about the user's interests. Adaptation procedures associate actions with perceived situations of the user. Associations are based on feedback given by the user in response to the behavior of the system. Our method provides a solution to some of the problems that affect the acceptance of the system by the user when machine learning techniques are applied to systems at the beginning of the interaction between the system and the user. Keywords: context awareness, machine learning, user acceptance."}, {"heading": "1 Introduction", "text": "There has been a huge technological revolution in recent years with the emergence of mobile devices (e.g. computers, mobile computers, mobile phones, pocket PCs, PDAs) and mobile networks (GSM, 3G +, wireless networks, Bluetooth, etc.) with which information processing has been thoroughly integrated into everyday activities, leading to a new paradigm called ubiquitous computing to provide them with relevant outcomes. The need to adapt an information system to the user context has been conditioned by access to the right information at the right time and place. In view of this, it is important to take into account the needs of users and their contextual situation when accessing information to provide them with relevant outcomes."}, {"heading": "2 Research problem", "text": "Our work relates to research in the following two areas: - The evolution of the user's interests according to the context: A major difficulty in applying machine learning techniques to adapt a system to the user is the development of his interests. The user's interest may change over time and the system must be continuously adapted to this dynamic change, using the user's context information to provide the relevant recommendations. - User Acceptance: The system must respect some criteria that must be accepted by the user, such as comprehensibility, non-intrusive and avoiding the cold start problem. As part of our work, we try to avoid the cold start problem: the system should start with background knowledge, because in the initial state, when the system behaviour is incoherent, the user quickly rejects it. In this research context, our goal is to create an ubiquitous recommendation system based on information about the user's context."}, {"heading": "3 State of the art", "text": "In [10], for example, the authors use linear classifiers that are trained only on rating information for recommendations. In [2], the authors propose a hybrid recommendation framework to recommend movies to users. In the content-based filtering of this hybrid recommender, they receive additional information about movies from the website as a text document. A Naive Bayes classifier is used to create user and article profiles that handle vectors of dictionaries. These approaches have good results if they begin with a certain degree of user experience. However, none of them have attempted to work without background knowledge of the user at the beginning. Reinforcement Learning (RL) is an algorithm that does not require prior experience to begin work. In [9], RL is applied to a recommendation system for automatically acquiring the context model in a ubiquitous environment."}, {"heading": "4 Proposition", "text": "Our analysis of the state of the art allows us to say that the process of selecting relevant information for users following their interest development can be modelled as an RL process. Furthermore, Collaborative Filtering (CF) has been very successful [7] to avoid the problem of cold start using demographic information. Our main idea is to start with an initial default behavior defined by the social group to which the user who uses CF belongs. This behavior is normally acceptable to all users of the social network, and then this behavior is personalized by the RL learning process."}, {"heading": "4.1 Collaborative filtering", "text": "CF is based on the assumption that the best way to find interesting content is to find other people who have similar interests and then recommend articles that appeal to those similar users. [1] A CF referral system works like this: In a group of transactions D, where each transaction is T in the form < id, item, rating >, a recommendation model M is produced. Each object is represented by a categorical value, while the rating is a numerical value on a certain scale (for example, each object is a movie rated from 1 to 5 stars). Such a model M can generate a list of Top-N recommended articles and corresponding predicted ratings from a certain group of known ratings [4]. In many situations, ratings are not explicit. For example, if we want to recommend websites to a website visitor, we can use the set of pages he or she has visited and assign these pages an implicit rate of one and zero from all other sites."}, {"heading": "4.2 Reinforcement learning and the q-learning algorithm", "text": "RL is a computational approach to machine learning in which an agent attempts to maximize the total reward he receives in interaction with a complex and uncertain environment [8]. A learning effect is modelled as a Markov decision-making process defined by (S, A, R, P), where S and A are finite relationships of states and actions, or R: S \u00b7 A \u2192 R is the immediate reward function, and P: S \u00b7 A \u00b7 S \u2192 [0, 1] is the stochastic Markovian transition function. The agent constructs an optimal Markovian policy \u03c0: S \u2192 A that maximizes the expected sum of future discounted rewards over an endless horizon. We define Q * (s, a), the value of actions within a state within the framework of a policy. The Q learning algorithm enables the calculation of an approximation of Q *, regardless of the policies pursued when R and P are known."}, {"heading": "4.3 The combination of collaborative filtering and reinforcement learning", "text": "The first step of the Q-learning algorithm, called \"action selection,\" is a compromise between the use of knowledge (we choose the action that maximizes reward) and the exploration of the state space by selecting an action a priori less interesting in terms of reward. In the Q-learning algorithm, it is said that for each state the action a = Q (s) is selected according to the current policy. Policy choice of action must ensure a balance between exploration and exploitation. Exploitation consists in choosing the best action for the current state, i.e. taking advantage of the knowledge of the system at the moment of recommendation. Exploration consists in choosing an action other than the best one in order to test it, observe its consequences and expand the knowledge of the recommendation system.It is useful to promote exploration at the outset in order to quickly cover a large part of the state space, then by reducing the exploration capacity obtained and maximizing the exploitation of the reward."}, {"heading": "5 Preliminary ideas", "text": "Fig. 1 summarizes the global mechanism of the receiver system. In order to recognize the context of the user, the receiver system receives events from the sensor module (e.g. the user's phone), which constitute the input of the receiver system and start the learning algorithm of the receiver system, which allows the selection of an action to be performed in the environment. We consider the environment, which consists of all the context dimensions described in [5], namely cognitive, temporal, geographical, material, social, source documents, qualitative, psychological and demographic. For the actual state of our work, the environment is replaced by a context simulator, which executes scenarios by telling the receiver system simulated events, as real sensors would do. And the sensor module can only recognize the time, social and cognitive dimension of the context in the following way: - Time is recognized by the user's mobile phone and the calendar of his company - The social group is defined by its cognitive system / dimension."}, {"heading": "6 Preliminary results", "text": "We use an experimental platform to test our algorithms, developed in C #. For this test, we used a very simple scenario: given a company nomalys, the marketers can access the most relevant data of their company via their mobile phone. Paul is a new sales representative of the company; he integrates a team of ten marketers. As for Paul's agenda, he has a midday meeting with a customer in Paris. At his meeting, the system must recommend the customer's complaint register to him. To achieve this goal, the system only knows the habits of Paul's ten colleagues. In our experiments, the system is controlled by each of the previously presented algorithms: CF, Q-Learning and CF-QL. The experiment consists of testing 100 attempts for each algorithm, which begin when the user connects to the system. During the trials, the system recommends resources for the user. We assume that if the user chooses one of the recommended resources (e.g. reads a document, opens a folder, etc.), the results are classified as well."}, {"heading": "7 Conclusion", "text": "The aim of this doctoral thesis is to investigate the adaptation and acceptance of a recommendation system by the user when the system initially does not know anything about the user and his habits. The recommendation system defines the observable situations and which actions should be performed in each situation in order to provide the user with useful information.To achieve this goal, we first use the RL algorithm to solve the problem of the system that starts without much experience (cold start), and the CF algorithm to initiate the learning process. As a future work, we intend to improve the adaptation of the recommendation system by integrating another context dimension as a spatial and cognitive dimension and to carry out tests with real users."}, {"heading": "7. M. Vozalis and K. Margaritis, \u201cOn the enhancement of collaborative filtering by", "text": ", Web Intelligence and Agent Systems, Volume 4, No. 2, pp. 117-138, 2006."}, {"heading": "8. C.J. Watkins, C.H. \u201cLearning from Delayed Rewards\u201d PhD thesis, University of", "text": "Cambridge, 1989."}, {"heading": "9. S. Zaidenberg, P. Reignier, and J. Crowley L.\u201dAn architecture for ubiquitous applications,\u201d", "text": "In IWUC, 2007.10. T. Zhang and V. Iyengar, \"Recommended Systems with Linear Classifiers,\" The Journal of Machine Learning Research, Volume 2, p. 334, 2002."}], "references": [{"title": "Empirical Analysis of Predictive Algorithms for Collaborative Filtering,", "author": ["J.S. Breese", "D. Heckerman", "C. Kadie"], "venue": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, Madison, WI,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Content-boosted collaborative filtering for improved recommendations,", "author": ["P. Melville", "R.J. Mooney", "R. Nagarajan"], "venue": "in in Eighteenth National Conference on Artificial Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "Item-based Collaborative Filtering Recommendation Algorithms", "author": ["B. Sarwar", "G. Karypis", "J. Konstan", "J. Reid"], "venue": "Appears in WWW10,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2001}, {"title": "Evaluation of contextual information retrieval : overview of issues and research", "author": ["L. Tamine", "M. Boughanem", "M. Daoud"], "venue": "Knowl Inf Syst (Kais), in press,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Dynamic service composition in ambient intelligence environments: a multi-agent approach", "author": ["M. Vall\u00e9e", "F. Ramparany", "L. Vercouter"], "venue": "In Proceeding of the First European Young Researcher Workshop on Service-Oriented Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "On the enhancement of collaborative filtering by demographic data,", "author": ["M. Vozalis", "K. Margaritis"], "venue": "Web Intelligence and Agent Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Learning from Delayed Rewards", "author": ["C.H.C.J. Watkins"], "venue": "PhD thesis,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1989}, {"title": "L.\u201dAn architecture for ubiquitous applications,", "author": ["S. Zaidenberg", "P. Reignier", "J. Crowley"], "venue": "In IWUC,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Recommender systems using linear classifiers,", "author": ["T. Zhang", "V. Iyengar"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}], "referenceMentions": [{"referenceID": 4, "context": "Most of current work on ubiquitous recommendation pre-defines services and fires them in the suitable situation [6, 3].", "startOffset": 112, "endOffset": 118}, {"referenceID": 8, "context": "For example, in [10] the authors use linear classifiers trained only on rating information for recommendation.", "startOffset": 16, "endOffset": 20}, {"referenceID": 1, "context": "In [2], the authors propose a hybrid recommender framework to recommend movies to users.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "In [9], RL is applied to a recommendation system for the automatic acquisition of the context model in a ubiquitous environment.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "In [7] the authors also use demographic information about users and items for providing more accurate prediction for users, but their system does not follow the user interest evolution.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "Moreover, Collaborative Filtering (CF) has been very successful [7] to avoid the problem of the cold-start using demographic information.", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "CF is built on the assumption that the best way to find interesting content is to find other people who have similar interests and then recommend items that those similar users like [1].", "startOffset": 182, "endOffset": 185}, {"referenceID": 2, "context": "Such a model M can produce a list of top-N recommended items, and corresponding predicted ratings, from a given set of known ratings [4].", "startOffset": 133, "endOffset": 136}, {"referenceID": 0, "context": "In terms of CF, three major classes of algorithms exist (Memory-based, Model-based Hybrid-based) [1, 4].", "startOffset": 97, "endOffset": 103}, {"referenceID": 2, "context": "In terms of CF, three major classes of algorithms exist (Memory-based, Model-based Hybrid-based) [1, 4].", "startOffset": 97, "endOffset": 103}, {"referenceID": 6, "context": "RL is a computational approach of Machine Learning where an agent tries to maximize the total amount of reward it receives when interacting with a complex and uncertain environment [8].", "startOffset": 181, "endOffset": 184}, {"referenceID": 0, "context": "; R : S \u00d7 A \u2192 R is the immediate reward function and P : S \u00d7 A \u00d7 S \u2192 [0, 1] is the stochastic Markovian transition function.", "startOffset": 69, "endOffset": 75}, {"referenceID": 3, "context": "We consider the environment being composed of all context dimensions described in [5], namely cognitive, time, geographic, material, social, source document, qualitative, psychological, and demographic.", "startOffset": 82, "endOffset": 85}], "year": 2011, "abstractText": "Ubiquitous information access becomes more and more important nowadays and research is aimed at making it adapted to users. Our work consists in applying machine learning techniques in order to adapt the information access provided by ubiquitous systems to users when the system only knows the user social group, without knowing anything about the user\u2019s interest. The adaptation procedures associate actions to perceived situations of the user. Associations are based on feedback given by the user as a reaction to the behavior of the system. Our method brings a solution to some of the problems concerning the acceptance of the system by users when applying machine learning techniques to systems at the beginning of the interaction between the system and the user.", "creator": "Microsoft\u00ae Office Word 2007"}}}