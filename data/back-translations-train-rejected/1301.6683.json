{"id": "1301.6683", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2013", "title": "Discovering the Hidden Structure of Complex Dynamic Systems", "abstract": "Dynamic Bayesian networks provide a compact and natural representation for complex dynamic systems. However, in many cases, there is no expert available from whom a model can be elicited. Learning provides an alternative approach for constructing models of dynamic systems. In this paper, we address some of the crucial computational aspects of learning the structure of dynamic systems, particularly those where some relevant variables are partially observed or even entirely unknown. Our approach is based on the Structural Expectation Maximization (SEM) algorithm. The main computational cost of the SEM algorithm is the gathering of expected sufficient statistics. We propose a novel approximation scheme that allows these sufficient statistics to be computed efficiently. We also investigate the fundamental problem of discovering the existence of hidden variables without exhaustive and expensive search. Our approach is based on the observation that, in dynamic systems, ignoring a hidden variable typically results in a violation of the Markov property. Thus, our algorithm searches for such violations in the data, and introduces hidden variables to explain them. We provide empirical results showing that the algorithm is able to learn the dynamics of complex systems in a computationally tractable way.", "histories": [["v1", "Wed, 23 Jan 2013 15:57:10 GMT  (349kb)", "http://arxiv.org/abs/1301.6683v1", "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)"]], "COMMENTS": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["xavier boyen", "nir friedman", "daphne koller"], "accepted": false, "id": "1301.6683"}, "pdf": {"name": "1301.6683.pdf", "metadata": {"source": "CRF", "title": "Discovering the Hidden Structure of Complex Dynamic Systems", "authors": ["Xavier Boyen", "Nir Friedman", "Daphne Koller"], "emails": ["xb@cs.stanford.", "nir@cs.huji.", "koller@cs."], "sections": [{"heading": null, "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a"}], "references": [{"title": "Theory refinement on Bayesian net\u00ad", "author": ["W. Buntine"], "venue": null, "citeRegEx": "Buntine,? \\Q1991\\E", "shortCiteRegEx": "Buntine", "year": 1991}, {"title": "Forecasting sleep ap\u00ad", "author": ["P. Dagum", "A. Galper"], "venue": null, "citeRegEx": "Dagum and Galper,? \\Q1993\\E", "shortCiteRegEx": "Dagum and Galper", "year": 1993}, {"title": "Learning belief networks", "author": ["N. Friedman"], "venue": null, "citeRegEx": "Friedman,? \\Q1997\\E", "shortCiteRegEx": "Friedman", "year": 1997}, {"title": "The Bayesian structural EM algo\u00ad", "author": ["N. Friedman"], "venue": null, "citeRegEx": "Friedman,? \\Q1998\\E", "shortCiteRegEx": "Friedman", "year": 1998}, {"title": "A tutorial on learning with", "author": ["D. Heckerman"], "venue": null, "citeRegEx": "Heckerman,? \\Q1999\\E", "shortCiteRegEx": "Heckerman", "year": 1999}, {"title": "The EM algorithm for graphi\u00ad", "author": ["S.L. Lauritzen"], "venue": null, "citeRegEx": "Lauritzen,? \\Q1995\\E", "shortCiteRegEx": "Lauritzen", "year": 1995}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "Annals of Statistics", "citeRegEx": "Schwarz,? \\Q1978\\E", "shortCiteRegEx": "Schwarz", "year": 1978}], "referenceMentions": [{"referenceID": 4, "context": "Recent work has made significant progress on the prob\u00ad lem of learning Bayesian networks from data (see, for example, [Heckerman 1999].", "startOffset": 118, "endOffset": 134}, {"referenceID": 2, "context": "1998], using the Structurol EM (SEM) algo\u00ad rithm [Friedman 1997].", "startOffset": 49, "endOffset": 64}, {"referenceID": 6, "context": "The most frequently used are the Bayesian Information Criterion {BIG) [Schwarz 1978] and the Bayesian scores, such as the BOe score of [Heckerman et a!.", "startOffset": 70, "endOffset": 84}, {"referenceID": 0, "context": "Thus, we usually resort to greedy local search procedures [Buntine 1991; Heck\u00ad erman et al. 1995] that gradually improve a candidate structure by applying local structural transformation: adding, deleting, or reversing an edge.", "startOffset": 58, "endOffset": 97}, {"referenceID": 5, "context": "The most common solution to the missing data problem is the Expectation-Maximization (EM) algo\u00ad rithm [Dempster et a!. 1977; Lauritzen 1995).", "startOffset": 102, "endOffset": 140}, {"referenceID": 2, "context": "Friedman's Structural EM (SEM) algorithm [1997) ex\u00ad tends it to the structure learning task.", "startOffset": 0, "endOffset": 48}, {"referenceID": 2, "context": "Friedman [1998) shows that, for a large family of scor\u00ad ing rules, the network resulting from this inner loop must have a higher score than the original.", "startOffset": 0, "endOffset": 16}, {"referenceID": 2, "context": "Unfortunately, probabilistic inference for DBNs is no\u00ad toriously expensive, as Friedman et al. [1998) clearly point out in their paper on learning DBNs.", "startOffset": 79, "endOffset": 102}, {"referenceID": 2, "context": "2 The second approach, which was used by Friedman et a!. [1998], is to compute suf\u00ad ficient statistics \"on demand\", i.", "startOffset": 41, "endOffset": 64}, {"referenceID": 2, "context": "Friedman et al. [1999] present an intermediate solution which we also adopt.", "startOffset": 0, "endOffset": 23}, {"referenceID": 1, "context": "Following the suggestion of Dagum and Galper [1993], each variable was discretized into seven buck\u00ad ets.", "startOffset": 28, "endOffset": 52}, {"referenceID": 2, "context": "The first deals with search techniques for learning in the presence of hidden variables [Friedman 1997; Fried\u00ad man et al. 1998].", "startOffset": 88, "endOffset": 127}, {"referenceID": 2, "context": "The first deals with search techniques for learning in the presence of hidden variables [Friedman 1997; Fried\u00ad man et al. 1998]. The second deals with fast approxi\u00ad mate inference in complex networks [Boyen and Koller 1998b; Boyen and Koller 1999]. While approximate DBN inference has been playing a major role in para\u00ad metric learning [Boyen and Koller 1998a; Ghahramani and Jordan 1996a], this is the first paper to deal with the issues involved in applying it to structure search. In particular, we had to deal with the computation of a large number of different statistics and to introduce methods for discovering hidden variables. Although we based our solution on the Boyen-Koller approxi\u00ad mation, many of these ideas can be applied to other approximate inference methods, including the varia\u00ad tional methods of Ghahramani and Jordan [1996a].", "startOffset": 89, "endOffset": 848}], "year": 2011, "abstractText": "Dynamic Bayesian networks provide a compact and natural representation for complex dynamic systems. However, in many cases, there is no ex\u00ad pert available from whom a model can be elicited. Learning provides an alternative approach for constructing models of dynamic systems. In this paper, we address some of the crucial compu\u00ad tational aspects of learning the structure of dy\u00ad namic systems, particularly those where some relevant variables are partially observed or even entirely unknown. Our approach is based on the Structural Expectation Maximization (SEM) al\u00ad gorithm. The main computational cost of the SEM algorithm is the gathering of expected suf\u00ad ficient statistics. We propose a novel approxima\u00ad tion scheme that allows these sufficient statistics to be computed efficiently. We also investigate the fundamental problem of discovering the exis\u00ad tence of hidden variables without exhaustive and expensive search. Our approach is based on the observation that, in dynamic systems, ignoring a hidden variable typically results in a violation of the Markov property. Thus, our algorithm searches for such violations in the data, and in\u00ad troduces hidden variables to explain them. We provide empirical results showing that the algo\u00ad rithm is able to learn the dynamics of complex systems in a computationally tractable way.", "creator": "pdftk 1.41 - www.pdftk.com"}}}