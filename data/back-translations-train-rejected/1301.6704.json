{"id": "1301.6704", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2013", "title": "SPUDD: Stochastic Planning using Decision Diagrams", "abstract": "Markov decisions processes (MDPs) are becoming increasing popular as models of decision theoretic planning. While traditional dynamic programming methods perform well for problems with small state spaces, structured methods are needed for large problems. We propose and examine a value iteration algorithm for MDPs that uses algebraic decision diagrams(ADDs) to represent value functions and policies. An MDP is represented using Bayesian networks and ADDs and dynamic programming is applied directly to these ADDs. We demonstrate our method on large MDPs (up to 63 million states) and show that significant gains can be had when compared to tree-structured representations (with up to a thirty-fold reduction in the number of nodes required to represent optimal value functions).", "histories": [["v1", "Wed, 23 Jan 2013 15:58:38 GMT  (570kb)", "http://arxiv.org/abs/1301.6704v1", "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)"]], "COMMENTS": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jesse hoey", "robert st-aubin", "alan hu", "craig boutilier"], "accepted": false, "id": "1301.6704"}, "pdf": {"name": "1301.6704.pdf", "metadata": {"source": "CRF", "title": "SPUDD: Stochastic Planning using Decision Diagrams", "authors": ["Jesse Hoey", "Robert St-Aubin", "AlanHu Craig Boutilier"], "emails": ["@cs.ubc.ca"], "sections": [{"heading": null, "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "Pf\ufffd1t ( C, PL, APU, BPU, ADR, BDR, BO) = [C + C[(PL \u00b7 APU + PL) \u00b7 ADR \u00b7 BDR", "text": "eiD rf\u00fc ide rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the"}], "references": [{"title": "Adaptive aggregation for infinite horizon dynamic programming", "author": ["D.P. Bertsekas", "D.A. Castanon"], "venue": "IEEE Trans. Aut. Cont.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1989}, {"title": "Decision theoretic plan\u00ad ning: Structural assumptions and computational leverage", "author": ["C. Boutilier", "T. Dean", "S. Hanks"], "venue": "J. Artif. Intel. Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1999}, {"title": "Approximating value trees in structured dynamic programming", "author": ["C. Boutilier", "R. Dearden"], "venue": "Proc. Inti. Conf Machine Learning,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1996}, {"title": "Exploiting structure in policy construction", "author": ["C. Boutilier", "R. Dearden", "M. Goldszmidt"], "venue": "Proc. IJCAI-95, pp.II04l l l l , Montreal,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1995}, {"title": "Stochas\u00ad tic dynamic programming with factored representations", "author": ["C. Boutilier", "R. Dearden", "M. Goldszmidt"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "Graph-based algorithms for boolean function manipulation", "author": ["R.E. Bryant"], "venue": "IEEE Trans. Comp.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1986}, {"title": "Automatic obdd\u00ad based generation of universal plans in non-deterministic do\u00ad mains", "author": ["P. Traverso"], "venue": "Proc. AAAJ-98,", "citeRegEx": "Traverso.,? \\Q1998\\E", "shortCiteRegEx": "Traverso.", "year": 1998}, {"title": "Model minimization in Markov de\u00ad cision processes", "author": ["T. Dean", "R. Givan"], "venue": "Proc. AAAI-97,", "citeRegEx": "Dean and Givan.,? \\Q1997\\E", "shortCiteRegEx": "Dean and Givan.", "year": 1997}, {"title": "A modelfor reasoningabout per\u00ad sistence and causation", "author": ["T. Dean", "K. Kanazawa"], "venue": "Comp. Intel.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1989}, {"title": "Abstraction and approximate decision theoretic planning", "author": ["R. Dearden", "C. Boutilier"], "venue": "Artif. Intel.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1997}, {"title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming", "author": ["L. Puterman"], "venue": null, "citeRegEx": "Puterman.,? \\Q1994\\E", "shortCiteRegEx": "Puterman.", "year": 1994}, {"title": "CUDD: CU decision diagram package. Avail\u00ad able from ftp: I /vlsi .colorado", "author": ["F. Somenzi"], "venue": "edu/pub/,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}], "referenceMentions": [], "year": 2011, "abstractText": "Recently, structured methods for solving factored Markov decisions processes (MDPs) with large state spaces have been proposed recently to al\u00ad low dynamic programming to be applied with\u00ad out the need for complete state enumeration. We propose and examine a new value iteration algo\u00ad rithm for MDPs that uses algebraic decision di\u00ad agrams (ADDs) to represent value functions and policies, assuming an ADD input representation of the MDP. Dynamic programming is imple\u00ad mented via ADD manipulation. We demonstrate our method on a class of large MDPs (up to 63 million states) and show that significant gains can be had when compared to tree-structured repre\u00ad sentations (with up to a thirty-fold reduction in the number of nodes required to represent optimal value functions).", "creator": "pdftk 1.41 - www.pdftk.com"}}}