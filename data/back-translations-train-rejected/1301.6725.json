{"id": "1301.6725", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2013", "title": "Loopy Belief Propagation for Approximate Inference: An Empirical Study", "abstract": "Recently, researchers have demonstrated that loopy belief propagation - the use of Pearls polytree algorithm IN a Bayesian network WITH loops OF error- correcting codes.The most dramatic instance OF this IS the near Shannon - limit performance OF Turbo Codes codes whose decoding algorithm IS equivalent TO loopy belief propagation IN a chain - structured Bayesian network. IN this paper we ask : IS there something special about the error - correcting code context, OR does loopy propagation WORK AS an approximate inference schemeIN a more general setting? We compare the marginals computed using loopy propagation TO the exact ones IN four Bayesian network architectures, including two real - world networks : ALARM AND QMR.We find that the loopy beliefs often converge AND WHEN they do, they give a good approximation TO the correct marginals.However,ON the QMR network, the loopy beliefs oscillated AND had no obvious relationship TO the correct posteriors. We present SOME initial investigations INTO the cause OF these oscillations, AND show that SOME simple methods OF preventing them lead TO the wrong results.", "histories": [["v1", "Wed, 23 Jan 2013 16:00:02 GMT  (344kb)", "http://arxiv.org/abs/1301.6725v1", "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)"]], "COMMENTS": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["kevin murphy", "yair weiss", "michael i jordan"], "accepted": false, "id": "1301.6725"}, "pdf": {"name": "1301.6725.pdf", "metadata": {"source": "CRF", "title": "Loopy Belief Propagation for Approximate Inference: An Empirical Study", "authors": ["Kevin P. Murphy"], "emails": ["}@cs.berkeley.edu"], "sections": [{"heading": null, "text": "In fact, it is such that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is in which there is a process in which there is a process in which"}], "references": [{"title": "The structure of Bayes networks for visual recognition", "author": ["J.M. Agosta"], "venue": "UAI, volume 4, pages 397-405,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1990}, {"title": "On the convergence of iterative decoding on graphs with a single cycle", "author": ["S.M. Aji", "G.B. Horn", "R.J. McEliece"], "venue": "Proc. 1998 !SIT,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "The alarm monitoring system: A case study with two probabilistic inference tech\u00ad niques for belief networks", "author": ["I. Beinlich", "G. Suermondt", "R. Chavez", "G. Cooper"], "venue": "Proc. 2 'nd European Conf. on AI and Medicine,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1989}, {"title": "Near Shannon limit error-correcting coding and decoding: Turbo codes", "author": ["C. Berrou", "A. Glavieux", "P. Thitimajshima"], "venue": "Proc. IEEE Interna\u00ad tional Communications Conference '93,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1993}, {"title": "The computational complexity of probabilistic inference using Bayesian belief net\u00ad works", "author": ["G. Cooper"], "venue": "Artificial Intelligence, 42:393-405,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1990}, {"title": "Aproximate probabilis\u00ad tic inference in Bayesian networks in NP hard", "author": ["P. Dagum", "M. Luby"], "venue": "Artificial Intelligence, 60:141-153,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1993}, {"title": "A tractable inference algorithm for diagnosing multiple diseases", "author": ["D. Heckerman"], "venue": "Proc. Fifth Conf. on Uncertainty in AI,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1989}, {"title": "Variational prob\u00ad abilistic inference and the QMR-DT", "author": ["T.S. Jaakkola", "M.l. Jordan"], "venue": "network. lAIR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "Iterative de\u00ad coding of compound codes by probability prop\u00ad agation in graphical models", "author": ["F.R. Kschischang", "B.J. Frey"], "venue": "IEEE Journal on Selected Areas in Communication, 16(2) :219-230,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Turbo decoding as as an instance of Pearl's 'be\u00ad lief propagation' algorithm", "author": ["R.J. McEliece", "D.J.C. MacKay", "J.F. Cheng"], "venue": "IEEE Journal on Selected Areas in Communication, 16(2):140-152,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1998}, {"title": "The Turbo decision algorithm", "author": ["R.J. McEliece", "E. Rodemich", "J.F. Cheng"], "venue": "Proc. 33rd Aller\u00ad ton Conference on Communications, Control and Computing, pages 366-379, Monticello, 11,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1995}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["Judea Pearl"], "venue": "Mor\u00ad gan Kaufmann,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1988}, {"title": "Fusion and prop\u00ad agation with multiple observations in belief net\u00ad works", "author": ["M.A. Peot", "R.D. Shachter"], "venue": "Artificial Intelligence, 48:299-318,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1991}, {"title": "The geometry of turbo\u00ad decoding dynamics", "author": ["Thomas Richardson"], "venue": "IEEE Trans. on Info. Theory,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "Mean field theory for sigmoid belief networks. lAIR", "author": ["L.K. Saul", "T. Jaakkola", "M.l. Jordan"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1996}, {"title": "Simulation ap\u00ad proaches to general probabilistic inference on be\u00ad lief networks", "author": ["R.D. Shachter", "M.A. Peat"], "venue": "Uncertainty in AI, volume 5,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1990}, {"title": "An empirical analysis of likelihood-weighting simulation on a large, multi\u00ad ply connected medical belief network", "author": ["M. Shwe", "G. Cooper"], "venue": "Computers and Biomedical Research, 24:453-475,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1991}, {"title": "Belief propagation and revision in net\u00ad works with loops", "author": ["Y. Weiss"], "venue": "Technical Report 1616, MIT AI lab,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "Correctness of local probability prop\u00ad agation in graphical models with loops", "author": ["Y. Weiss"], "venue": "Neural Computation, to appear,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}], "referenceMentions": [{"referenceID": 4, "context": "The task of calculating posterior marginals on nodes in an arbitrary Bayesian network is known to be NP\u00ad hard [5].", "startOffset": 110, "endOffset": 113}, {"referenceID": 5, "context": "This is true even for the seemingly easier task of calculating approximate posteriors [6].", "startOffset": 86, "endOffset": 89}, {"referenceID": 11, "context": "This refers to using the well-known Pearl polytree algorithm [12] on a Bayesian network with loops (undirected cycles).", "startOffset": 61, "endOffset": 65}, {"referenceID": 11, "context": "7 in [12] investigates the quality of the ap\u00ad proximation when it is applied to a particular loopy belief network.", "startOffset": 5, "endOffset": 9}, {"referenceID": 3, "context": "Perhaps the most dramatic instance of this performance is in an error correcting code scheme known as \"Turbo Codes\" [4].", "startOffset": 116, "endOffset": 119}, {"referenceID": 10, "context": "years\" [11] and have recently been shown [9, 10] to uti\u00ad lize an algorithm equivalent to belief propagation in a network with loops.", "startOffset": 7, "endOffset": 11}, {"referenceID": 8, "context": "years\" [11] and have recently been shown [9, 10] to uti\u00ad lize an algorithm equivalent to belief propagation in a network with loops.", "startOffset": 41, "endOffset": 48}, {"referenceID": 9, "context": "years\" [11] and have recently been shown [9, 10] to uti\u00ad lize an algorithm equivalent to belief propagation in a network with loops.", "startOffset": 41, "endOffset": 48}, {"referenceID": 10, "context": "Although there is widespread agreement in the coding community that these codes \"represent a genuine, and perhaps historic, break\u00ad through\" [11], a theoretical understanding of their per\u00ad formance has yet to be achieved.", "startOffset": 140, "endOffset": 144}, {"referenceID": 9, "context": "These theo\u00ad rems, which may have nothing directly to do with coding or decoding will show that in some sense belief propagation \"converges with high probability to a near-optimum value\" of the desired belief on a class of loopy DAGs [10].", "startOffset": 233, "endOffset": 237}, {"referenceID": 17, "context": "Progress in the analysis of loopy belief propagation has been made for the case of networks with a single loop [18, 19, 2, 1].", "startOffset": 111, "endOffset": 125}, {"referenceID": 18, "context": "Progress in the analysis of loopy belief propagation has been made for the case of networks with a single loop [18, 19, 2, 1].", "startOffset": 111, "endOffset": 125}, {"referenceID": 1, "context": "Progress in the analysis of loopy belief propagation has been made for the case of networks with a single loop [18, 19, 2, 1].", "startOffset": 111, "endOffset": 125}, {"referenceID": 0, "context": "Progress in the analysis of loopy belief propagation has been made for the case of networks with a single loop [18, 19, 2, 1].", "startOffset": 111, "endOffset": 125}, {"referenceID": 18, "context": "In the max-product (or \"belief revision\") version, Weiss [19] showed that ( 1) belief propagation may con\u00ad verge to a stable value or oscillate in a limit cycle and (2) if it converges then it is guaranteed to give the cor\u00ad rect assignment of values to the hidden nodes.", "startOffset": 57, "endOffset": 61}, {"referenceID": 13, "context": "For the case of networks with multiple loops, Richard\u00ad son [14] has analyzed the special case of Turbo codes.", "startOffset": 59, "endOffset": 63}, {"referenceID": 12, "context": "(Following Peot and Shachter [13], we incorporate ev\u00ad idence by letting a node send a message to itself, .", "startOffset": 29, "endOffset": 33}, {"referenceID": 11, "context": "For noisy-or links between parents and children, there exists an analytic expression for 1r( x) and Ax ( u;) that avoids the exhaustive enumeration over parent config\u00ad urations [12].", "startOffset": 177, "endOffset": 181}, {"referenceID": 11, "context": "As Pearl [12] pointed out, normalizing the messages makes no difference to the final beliefs but avoids numerical underflow.", "startOffset": 9, "endOffset": 13}, {"referenceID": 16, "context": "For comparison, we also implemented likelihood weighting [17], which is a simple form of importance sampling.", "startOffset": 57, "endOffset": 61}, {"referenceID": 6, "context": "We used the fixed structure and calculated posteriors for the four cases for which posteriors have been cal\u00ad culated exactly by Heckerman [7].", "startOffset": 138, "endOffset": 141}, {"referenceID": 0, "context": "Would low priors cause oscillations in the toyQMR case? To answer this question we repeated the ex\u00ad periments reported in the previous section but rather than having the prior probability of each node be ran\u00ad domly selected in the range [0, 1] we selected the prior uniformly in the range [0, U] and varied U.", "startOffset": 237, "endOffset": 243}, {"referenceID": 0, "context": "If indeed small priors are responsible for the oscilla\u00ad tion, then we would expect the real QMR network to converge if the priors were sampled randomly in the range [0, 1].", "startOffset": 165, "endOffset": 171}, {"referenceID": 0, "context": "To check this, we reran loopy propaga\u00ad tion on the full QMR network with the four tractable cases but changed the priors to be randomly sampled in the range [0, 1].", "startOffset": 157, "endOffset": 163}], "year": 2011, "abstractText": "Recently, researchers have demonstrated that \"loopy belief propagation\" the use of Pearl's polytree algorithm in a Bayesian network with loops can perform well in the context of error-correcting codes. The most dramatic instance of this is the near Shannon-limit performance of \"Turbo Codes\" codes whose decoding algorithm is equivalent to loopy belief propagation in a chain-structured Bayesian network. In this paper we ask: is there something spe\u00ad cial about the error-correcting code context, or does loopy propagation work as an ap\u00ad proximate inference scheme in a more gen\u00ad eral setting? We compare the marginals com\u00ad puted using loopy propagation to the exact ones in four Bayesian network architectures, including two real-world networks: ALARM and QMR. We find that the loopy beliefs of\u00ad ten converge and when they do, they give a good approximation to the correct marginals. However, on the QMR network, the loopy be\u00ad liefs oscillated and had no obvious relation\u00ad ship to the correct posteriors. We present some initial investigations into the cause of these oscillations, and show that some sim\u00ad ple methods of preventing them lead to the wrong results.", "creator": "pdftk 1.41 - www.pdftk.com"}}}