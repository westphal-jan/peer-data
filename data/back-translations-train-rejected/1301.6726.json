{"id": "1301.6726", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2013", "title": "Learning Bayesian Networks from Incomplete Data with Stochastic Search Algorithms", "abstract": "This paper describes stochastic search approaches, including a new stochastic algorithm and an adaptive mutation operator, for learning Bayesian networks from incomplete data. This problem is characterized by a huge solution space with a highly multimodal landscape. State-of-the-art approaches all involve using deterministic approaches such as the expectation-maximization algorithm. These approaches are guaranteed to find local maxima, but do not explore the landscape for other modes. Our approach evolves structure and the missing data. We compare our stochastic algorithms and show they all produce accurate results.", "histories": [["v1", "Wed, 23 Jan 2013 16:00:06 GMT  (455kb)", "http://arxiv.org/abs/1301.6726v1", "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)"]], "COMMENTS": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["james w myers", "kathryn blackmond laskey", "tod s levitt"], "accepted": false, "id": "1301.6726"}, "pdf": {"name": "1301.6726.pdf", "metadata": {"source": "CRF", "title": "Learning Bayesian Networks from Incomplete Data with Stochastic Search Algorithms", "authors": ["James W. Myers", "George Mason", "Kathryn Blackmond Laskey", "Tod Levitt"], "emails": ["tlevitt@iet.com"], "sections": [{"heading": null, "text": "This year is the highest in the history of the country."}, {"heading": "Z = 'Lexp{-11logP(s)+Z]} (3)", "text": "It is clear that P (s) is the Holtzman distribution of the system with energy values E (s) and temperature T. Note that if T is set to I, then E (s) = -logP (s).Consider a generic problem, the posterior distribution of a parameter e from a series of observations x1, \u2022 Xc, where the observations are considered independent samples from the distribution P (xl9).The posterior distribution can be defined in relation to a Holtzman distribution asStochastic algorithms 4791 P (Bix1, \u2022 Xc) x, x, x, x, x, x. (4) The representation of (4) for a general statistical inference means that algorithms from statistical physics can be applied to general problems in statistical inference. Applying methods from statistical physics to complex problems in statistical inference is an arbitrary class."}], "references": [{"title": "A Bayesian Method for the Induction", "author": ["G.F. Cooper", "E. Herskovits"], "venue": null, "citeRegEx": "Cooper and Herskovits,? \\Q1992\\E", "shortCiteRegEx": "Cooper and Herskovits", "year": 1992}, {"title": "An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms", "author": ["K.A. DeJong", "W.M. Spears"], "venue": "Proceedings of the First International Conference on Parallel Problem Solving from", "citeRegEx": "DeJong and Spears,? 1990", "shortCiteRegEx": "DeJong and Spears", "year": 1990}, {"title": "Maximum Likelihood Estimation from Incomplete Data via the EM Algorithm.", "author": ["A.P. Dempster", "N.M. Laird"], "venue": "Journal of the Royal Statistical Society", "citeRegEx": "Dempster and Laird,? \\Q1977\\E", "shortCiteRegEx": "Dempster and Laird", "year": 1977}, {"title": "An Introduction to Probability Theory and Its Appl", "author": ["W. Feller"], "venue": null, "citeRegEx": "Feller,? \\Q1968\\E", "shortCiteRegEx": "Feller", "year": 1968}, {"title": "The Bayesian Structural EM Algorithm", "author": ["N. Friedman"], "venue": "Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, Madison, WI, Morgan Kaufmann Publishers.", "citeRegEx": "Friedman,? 1998", "shortCiteRegEx": "Friedman", "year": 1998}, {"title": "Inference from Iterative Simulation using Multiple Sequences.", "author": ["A. Gelman", "D.B. Rubin"], "venue": "Statistical Science", "citeRegEx": "Gelman and Rubin,? \\Q1992\\E", "shortCiteRegEx": "Gelman and Rubin", "year": 1992}, {"title": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images.", "author": ["S. Geman", "D. Geman"], "venue": "IEEE Transaction on Pattern Analysis and Machine Intelligence", "citeRegEx": "Geman and Geman,? \\Q1984\\E", "shortCiteRegEx": "Geman and Geman", "year": 1984}, {"title": "Monte Carlo Sampling Methods using Markov Chains and their Applications.", "author": ["W.K. Hastings"], "venue": null, "citeRegEx": "Hastings,? \\Q1970\\E", "shortCiteRegEx": "Hastings", "year": 1970}, {"title": "Learning Bayesian Networks: The Combination of Knowledge and Statistical Data.", "author": ["D. Heckerman", "D. Geiger"], "venue": "Machine Learning", "citeRegEx": "Heckerman and Geiger,? \\Q1995\\E", "shortCiteRegEx": "Heckerman and Geiger", "year": 1995}, {"title": "Parallel Markov Chain Monte Carlo Sampling: An Evolutionary Based Approach", "author": ["C.C. Holmes", "B.K. Mallick"], "venue": "London, Imperial College.", "citeRegEx": "Holmes and Mallick,? 1998", "shortCiteRegEx": "Holmes and Mallick", "year": 1998}, {"title": "The EM algorithm for graphical association models with missing data.", "author": ["S.L. Lauritzen"], "venue": "Computational Statistics & Data Analysis", "citeRegEx": "Lauritzen,? \\Q1995\\E", "shortCiteRegEx": "Lauritzen", "year": 1995}, {"title": "Statistical Analysis with Missing Data", "author": ["R. Little", "D. Rubin"], "venue": "New York, John Wiley & Sons.", "citeRegEx": "Little and Rubin,? 1987", "shortCiteRegEx": "Little and Rubin", "year": 1987}, {"title": "Equations of State Calculation by Fast Computing Machines.", "author": ["N. Metropolis", "A.W. Rosenbluth"], "venue": "Journal of Chemical Physics", "citeRegEx": "Metropolis and Rosenbluth,? \\Q1953\\E", "shortCiteRegEx": "Metropolis and Rosenbluth", "year": 1953}, {"title": "Stochastic Algorithms for Learning with Incomplete Data: An Application to Bayesian Networks", "author": ["J.W. Myers"], "venue": "Systems Engineering. Fairfax, VA, GeorgeMason University: 189.", "citeRegEx": "Myers,? 1999", "shortCiteRegEx": "Myers", "year": 1999}, {"title": "Learning Bayesian Networks from Incomplete Data using Evoluationary Algorithms", "author": ["J.W. Myers", "K.B. Laskey"], "venue": null, "citeRegEx": "Myers and Laskey,? \\Q1999\\E", "shortCiteRegEx": "Myers and Laskey", "year": 1999}, {"title": "Uniform Crossover in Genetic Algorithms", "author": ["Toronto", "G. University of Toronto. Syswerda"], "venue": "Proceedi", "citeRegEx": "Toronto and Syswerda,? 1989", "shortCiteRegEx": "Toronto and Syswerda", "year": 1989}], "referenceMentions": [{"referenceID": 10, "context": "The first attempts at treating incomplete data involved learning the parameters of a fixed network structure [Lauritzen 1995].", "startOffset": 109, "endOffset": 125}, {"referenceID": 4, "context": "1977], [Friedman 1998].", "startOffset": 7, "endOffset": 22}, {"referenceID": 11, "context": "The EM algorithm is a proven approach for dealing with incomplete information when building statistical models [Little and Rubin 1987].", "startOffset": 111, "endOffset": 134}, {"referenceID": 4, "context": "However, it has been noted [Friedman 1998] that the search space is large and multimodal.", "startOffset": 27, "endOffset": 42}, {"referenceID": 1, "context": "[Syswerda 1989], [DeJong and Spears 1990].", "startOffset": 17, "endOffset": 41}, {"referenceID": 6, "context": "[Geman and Geman 1984).", "startOffset": 0, "endOffset": 22}, {"referenceID": 3, "context": "x' If a Markov chain satisfies certain regularity conditions [Feller 1968], then it converges to a ooique stationary distribution.", "startOffset": 61, "endOffset": 74}, {"referenceID": 3, "context": "Additional conditions are required on the transition probabilities to ensure that the chain converges to the distribution 7t(S) from any initial distribution [Feller 1968].", "startOffset": 158, "endOffset": 171}, {"referenceID": 7, "context": "1953], [Hastings 1970).", "startOffset": 7, "endOffset": 22}, {"referenceID": 13, "context": "Our approach to learning Bayesian networks from incomplete data is to set up two sets of Markov chains for sampling from the incomplete data and the network structures [Myers 1999].", "startOffset": 168, "endOffset": 180}, {"referenceID": 9, "context": "See Holmes and Mallick for a similar approach [Holmes and Mallick 1998].", "startOffset": 46, "endOffset": 71}, {"referenceID": 5, "context": "We use the convergence metric developed by Gelman and Rubin for measuring convergence of multiple chains [Gelman and Rubin 1992].", "startOffset": 105, "endOffset": 128}], "year": 2011, "abstractText": "This paper describes stochastic search approaches, including a new stochastic algorithm and an adaptive mutation operator, for learning Bayesian networks from incomplete data. This problem is characterized by a huge solution space with a highly multimodal landscape. State-of-the-art approaches all involve using deterministic approaches such as the e:\ufffd.-pectation-maximization algorithm. These approaches are guaranteed to find local maxima, but do not explore the landscape for other modes. Our approach evolves structure and the missing data. We compare our stochastic algorithms and show they all produce accurate results.", "creator": "pdftk 1.41 - www.pdftk.com"}}}