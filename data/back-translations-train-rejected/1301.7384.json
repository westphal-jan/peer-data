{"id": "1301.7384", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "An Anytime Algorithm for Decision Making under Uncertainty", "abstract": "We present an anytime algorithm which computes policies for decision problems represented as multi-stage influence diagrams. Our algorithm constructs policies incrementally, starting from a policy which makes no use of the available information. The incremental process constructs policies which includes more of the information available to the decision maker at each step. While the process converges to the optimal policy, our approach is designed for situations in which computing the optimal policy is infeasible. We provide examples of the process on several large decision problems, showing that, for these examples, the process constructs valuable (but sub-optimal) policies before the optimal policy would be available by traditional methods.", "histories": [["v1", "Wed, 30 Jan 2013 15:04:31 GMT  (327kb)", "http://arxiv.org/abs/1301.7384v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["michael c horsch", "david l poole"], "accepted": false, "id": "1301.7384"}, "pdf": {"name": "1301.7384.pdf", "metadata": {"source": "CRF", "title": "An Anytime Algorithm for Decision Making under Uncertainty", "authors": ["Michael C. Horsch", "David Poole"], "emails": ["horsch@cs.ubc.ca", "poole@cs.ubc.ca"], "sections": [{"heading": null, "text": "We have a policy that starts from a policy that does not allow the use of the available information. While the incremental processes that involve the decision makers at each step are converted by the policy makers, our approach is designed for situations where the optimal policy is practicable. We offer examples of the process that is valuable to the decision makers (but suboptimal measures) before the optimal policy is provided by traditional methods. INTRODUCTIONThe representative tools developed by decision analysts and AI practitioners can represent major decision problems. The costs of compilation are not taken into account, optimal strategies can be determined by the use of methods."}], "references": [{"title": "Input genelarization in delayed re\u00ad", "author": ["L.P. bling"], "venue": null, "citeRegEx": "bling,? \\Q1991\\E", "shortCiteRegEx": "bling", "year": 1991}, {"title": "M", "author": ["Druzdzel"], "venue": "J.", "citeRegEx": "Druzdzel. 1994", "shortCiteRegEx": null, "year": 1994}, {"title": "E", "author": ["D.E. Heckerman", "J.S. Breese", "Horvitz"], "venue": "J.", "citeRegEx": "Heckerman. Breese. . Horvitz. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "M", "author": ["Horsch"], "venue": "C.", "citeRegEx": "Horsch. 1998", "shortCiteRegEx": null, "year": 1998}, {"title": "and Matheson", "author": ["R. Howard"], "venue": "J., eds.", "citeRegEx": "Howard . Matheson. 1984", "shortCiteRegEx": null, "year": 1984}, {"title": "and Sadigh", "author": ["P.E. Lehner"], "venue": "A.", "citeRegEx": "Lehner . Sadigh. 1993", "shortCiteRegEx": null, "year": 1993}, {"title": "L", "author": ["M.L. Littman", "A.R. Cassandra", "Kaelbling"], "venue": "P.", "citeRegEx": "Littman. Cassandra. . Kaelbling. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "Reasoning about the value of decision-model refine\u00ad ment: Methods and application", "author": ["Poh", "Horvitz", "K.L. 1993) Poh", "E.J. Horvitz"], "venue": "In Proceedings of the Ninth Conference on Uncertainty in Artificial Intelli\u00ad gence,", "citeRegEx": "Poh et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Poh et al\\.", "year": 1993}, {"title": "and Poole", "author": ["R. Qi"], "venue": "D.", "citeRegEx": "Qi . Poole. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "Decision making using probabilistic inference methods", "author": ["Shachter", "Peot", "R. 1992) Shachter", "M. Peot"], "venue": "In Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Shachter et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Shachter et al\\.", "year": 1992}, {"title": "Structur\u00ad ing conditional relationships in influence diagrams. Operations Research 41:280-297", "author": ["Holtzman Smith", "Matheson", "1993) Smith", "J. E", "S. Holtzman", "J.E. Matheson"], "venue": null, "citeRegEx": "Smith et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Smith et al\\.", "year": 1993}, {"title": "and Boerlage", "author": ["N.L. Zhang"], "venue": "B.", "citeRegEx": "Zhang . Boerlage. 1995", "shortCiteRegEx": null, "year": 1995}], "referenceMentions": [{"referenceID": 4, "context": "W hen costs of computation are not taken into account, optimal policies can be determined using dy\u00ad namic programming [Howard & Matheson, 1984; Shachter, 1986].", "startOffset": 118, "endOffset": 159}, {"referenceID": 8, "context": "Due to space constraints, none of the numerical data required to complete the specification of this problem is shown; this information can be found in [Qi & Poole, 1995; Smith, Holtzman, & Matheson, 1993].", "startOffset": 151, "endOffset": 204}, {"referenceID": 2, "context": "The algorithm has been described in more detail in [Horsch & Poole, 1996], and is similar to algorithms de\u00ad scribed in [Heckerman, Breese, & Horvitz, 1989; Lehner & Sadigh, 1993].", "startOffset": 119, "endOffset": 178}, {"referenceID": 5, "context": "The algorithm has been described in more detail in [Horsch & Poole, 1996], and is similar to algorithms de\u00ad scribed in [Heckerman, Breese, & Horvitz, 1989; Lehner & Sadigh, 1993].", "startOffset": 119, "endOffset": 178}, {"referenceID": 3, "context": "These strate\u00ad gies and heuristics are discussed in more detail in [Horsch, 1998].", "startOffset": 66, "endOffset": 80}], "year": 2011, "abstractText": "We present an anytime algorithm which com\u00ad putes policies for decision problems represented as multi-stage influence diagrams. Our algo\u00ad rithm constructs policies incrementally, starting from a policy which makes no use of the avail\u00ad able information. The incremental process con\u00ad structs policies which includes more of the infor\u00ad mation available to the decision maker at each step. While the process converges to the opti\u00ad mal policy, our approach is designed for situa\u00ad tions in which computing the optimal policy is in\u00ad feasible. We provide examples of the process on several large decision problems, showing that, for these examples, the process constructs valuable (but sub-optimal) policies before the optimal pol\u00ad icy would be available by traditional methods.", "creator": "pdftk 1.41 - www.pdftk.com"}}}