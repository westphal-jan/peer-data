{"id": "1301.7417", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "Planning with Partially Observable Markov Decision Processes: Advances in Exact Solution Method", "abstract": "There is much interest in using partially observable Markov decision processes (POMDPs) as a formal model for planning in stochastic domains. This paper is concerned with finding optimal policies for POMDPs. We propose several improvements to incremental pruning, presently the most efficient exact algorithm for solving POMDPs.", "histories": [["v1", "Wed, 30 Jan 2013 15:07:12 GMT  (320kb)", "http://arxiv.org/abs/1301.7417v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nevin lianwen zhang", "stephen s lee"], "accepted": false, "id": "1301.7417"}, "pdf": {"name": "1301.7417.pdf", "metadata": {"source": "CRF", "title": "Planning with Partially Observable Markov Decision Processes: Advances in Exact Solution Method", "authors": ["Nevin L. Zhang", "Stephen S. Lee"], "emails": [], "sections": [{"heading": null, "text": "In fact, it is the case that it will be able to retaliate until it is able to retaliate."}], "references": [{"title": "Optimal polices for partially observable Markov decision processes", "author": ["A.R. Cassandra"], "venue": "TR CS-94-14,", "citeRegEx": "Cassandra,? \\Q1994\\E", "shortCiteRegEx": "Cassandra", "year": 1994}, {"title": "Incremental pruning: A simple, fast, ex\u00ad act method for partially observable Markov deci\u00ad sion processes", "author": ["A.R. Cassandra", "M.L. Littman", "N.L. Zhang"], "venue": "In Proceedings of Thirteenth Con\u00ad ference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Cassandra et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Cassandra et al\\.", "year": 1997}, {"title": "Algorithms for partially ob\u00ad servable Markov decision processes", "author": ["H.T. Cheng"], "venue": "PhD thesis,", "citeRegEx": "Cheng,? \\Q1988\\E", "shortCiteRegEx": "Cheng", "year": 1988}, {"title": "Efficient dynamic-programming up\u00ad dates in partially observable Markov decision pro\u00ad cesses", "author": ["M.L. Littman", "A.R. Cassandra", "L.P. Kaelbling"], "venue": "TR CS-95-19,", "citeRegEx": "Littman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Littman et al\\.", "year": 1995}, {"title": "A survey of partially observ\u00ad able Markov decision processes: theory, models, and algorithms", "author": ["G.E. Monahan"], "venue": "Management Science,", "citeRegEx": "Monahan,? \\Q1982\\E", "shortCiteRegEx": "Monahan", "year": 1982}, {"title": "The optimal control of partially observable Markov processes", "author": ["E.J. Sondik"], "venue": "PhD thesis, Stan\u00ad ford University,", "citeRegEx": "Sondik,? \\Q1971\\E", "shortCiteRegEx": "Sondik", "year": 1971}, {"title": "Partially observed Markov decision processes: A survey", "author": ["III C.C. White"], "venue": "Annals of Opera\u00ad tions Research,", "citeRegEx": "White,? \\Q1991\\E", "shortCiteRegEx": "White", "year": 1991}, {"title": "A model approxima\u00ad tion scheme for planning in stochastic domains", "author": ["N.L. Zhang", "W. Liu"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Zhang and Liu,? \\Q1997\\E", "shortCiteRegEx": "Zhang and Liu", "year": 1997}], "referenceMentions": [{"referenceID": 5, "context": "Sondik (1971) has shown that if there exists a finite set Vt of func\u00ad tions of s, henceforth called vectors, that represents 1't* in the sense that for all belief states b", "startOffset": 0, "endOffset": 14}, {"referenceID": 4, "context": "exhaustive (Monahan 1982) , Lark (White 1991) , linear support (Cheng 1988) , witness (Littman et al 1995) , and incremental pruning (Zhang and Liu 1997) .", "startOffset": 11, "endOffset": 25}, {"referenceID": 6, "context": "exhaustive (Monahan 1982) , Lark (White 1991) , linear support (Cheng 1988) , witness (Littman et al 1995) , and incremental pruning (Zhang and Liu 1997) .", "startOffset": 33, "endOffset": 45}, {"referenceID": 2, "context": "exhaustive (Monahan 1982) , Lark (White 1991) , linear support (Cheng 1988) , witness (Littman et al 1995) , and incremental pruning (Zhang and Liu 1997) .", "startOffset": 63, "endOffset": 75}, {"referenceID": 7, "context": "exhaustive (Monahan 1982) , Lark (White 1991) , linear support (Cheng 1988) , witness (Littman et al 1995) , and incremental pruning (Zhang and Liu 1997) .", "startOffset": 133, "endOffset": 153}, {"referenceID": 6, "context": "A popular choice is Lark's algorithm1 (White 1991) .", "startOffset": 38, "endOffset": 50}, {"referenceID": 7, "context": "The issue of exploiting informative observations is studied in detail in Zhang and Liu (1997). The LP\u00ad reduction techniques can be incorporated into the method.", "startOffset": 73, "endOffset": 94}, {"referenceID": 0, "context": "Cassandra et al (1997) have shown that the restricted region variation of incremental pruning is significantly more efficient than plain incremental pruning.", "startOffset": 0, "endOffset": 23}, {"referenceID": 0, "context": "The tiger problem (Cassandra 1994) was used in the experiments.", "startOffset": 18, "endOffset": 34}, {"referenceID": 7, "context": "The techniques introduced in this paper can be easily incorporated into the ap\u00ad proximate method proposed by Zhang and Liu (1997).", "startOffset": 109, "endOffset": 130}], "year": 2011, "abstractText": "There is much interest in using par\u00ad tially observable Markov decision processes (POMDPs) as a formal model for planning in stochastic domains. This paper is concerned with finding optimal policies for POMDPs. We propose several improvements to incre\u00ad mental pruning, presently the most efficient exact algorithm for solving POMDPs.", "creator": "pdftk 1.41 - www.pdftk.com"}}}