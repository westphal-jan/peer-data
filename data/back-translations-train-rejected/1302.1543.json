{"id": "1302.1543", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Probability Update: Conditioning vs. Cross-Entropy", "abstract": "Conditioning is the generally agreed-upon method for updating probability distributions when one learns that an event is certainly true. But it has been argued that we need other rules, in particular the rule of cross-entropy minimization, to handle updates that involve uncertain information. In this paper we re-examine such a case: van Fraassen's Judy Benjamin problem, which in essence asks how one might update given the value of a conditional probability. We argue that -- contrary to the suggestions in the literature -- it is possible to use simple conditionalization in this case, and thereby obtain answers that agree fully with intuition. This contrasts with proposals such as cross-entropy, which are easier to apply but can give unsatisfactory answers. Based on the lessons from this example, we speculate on some general philosophical issues concerning probability update.", "histories": [["v1", "Wed, 6 Feb 2013 15:55:49 GMT  (971kb)", "http://arxiv.org/abs/1302.1543v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["adam j grove", "joseph y halpern"], "accepted": false, "id": "1302.1543"}, "pdf": {"name": "1302.1543.pdf", "metadata": {"source": "CRF", "title": "Probability Update: Conditioning vs. Cross-Entropy", "authors": ["Adam J. Grove", "Joseph Y. Halpern"], "emails": ["grove@research.nj.nec.com", "halpern@cs.cornell.edu"], "sections": [{"heading": null, "text": "In this case, we simply have an answer to the question of how we engage with the distribution of people in the real world who have so far given a largely adequate answer to the problem of updating. But, many people have argued that conditioning is not a philosophically adequate answer (Jeffrey 1983 in particular). Once we try to build a truly intelligent agent that interacts with a rich world, conditioning can be a practically inadequate answer to the problem of updating. The problem is that some of the information we receive is not of the form \"Tis (definitely) true\" forany T. What would be expected with a restriction like \"Pr (T) = 2 / 3\" or \"is that some of the information we receive is not of the form\" Tis \"true.\""}], "references": [{"title": "Generating new be\u00ad liefs from old", "author": ["J.Y. Halpern", "D. Koller"], "venue": "Proc. Tenth Annual Confer\u00ad ence on Uncertainty Artificial Intelligence, pp. 37-45. Available by anonymous ftp from lo\u00ad", "citeRegEx": "Halpern and Koller,? 1994", "shortCiteRegEx": "Halpern and Koller", "year": 1994}, {"title": "Updating sub\u00ad jective probability", "author": ["P. Diaconis", "S.L. Zabell"], "venue": "Journal of the American Sta\u00ad tistical Society 77(380), 822-830.", "citeRegEx": "Diaconis and Zabell,? 1982", "shortCiteRegEx": "Diaconis and Zabell", "year": 1982}, {"title": "Scientific Rea\u00ad soning: The Bayesian Approach", "author": ["C. Howson", "P. Urbach"], "venue": "La Salle, Illi\u00ad nois: Open Court.", "citeRegEx": "Howson and Urbach,? 1989", "shortCiteRegEx": "Howson and Urbach", "year": 1989}, {"title": "Papers on Probability, Statis\u00ad tics, and Statistical Physics", "author": ["Jaynes", "E . T."], "venue": "Dordrecht, Nether\u00ad lands: Riedel. Edited by R. Rosenkrantz.", "citeRegEx": "Jaynes and T.,? 1983", "shortCiteRegEx": "Jaynes and T.", "year": 1983}, {"title": "The Logic of Decision", "author": ["R.C. Jeffrey"], "venue": "Chicago: University of Chicago Press. First Edi\u00ad tion Published 1965.", "citeRegEx": "Jeffrey,? 1983", "shortCiteRegEx": "Jeffrey", "year": 1983}, {"title": "On infor\u00ad mation and sufficiency", "author": ["S. Kullback", "R.A. Leibler"], "venue": "Annals of Mathematical Statistics 22, 76-86.", "citeRegEx": "Kullback and Leibler,? 1951", "shortCiteRegEx": "Kullback and Leibler", "year": 1951}, {"title": "Probability, Random Variables, and Stochastic Processes", "author": ["A. Papoulis"], "venue": "Chicago: McGraw\u00ad Hill.", "citeRegEx": "Papoulis,? 1984", "shortCiteRegEx": "Papoulis", "year": 1984}, {"title": "A method for updating justifying minimum cross entropy", "author": ["J.B. Paris", "A. Vencovska"], "venue": "International Journal of Approximate Reason\u00ad ing 7, 1-18.", "citeRegEx": "Paris and Vencovska,? 1992", "shortCiteRegEx": "Paris and Vencovska", "year": 1992}, {"title": "Entropy and uncertainty", "author": ["T. Seidenfeld"], "venue": "I. B. MacNeill and G. J. Umphrey (Eds.), Foun\u00ad dations of Statistical Inference, pp. 259-287. Rei\u00ad del. An earlier version appeared in Philosophy of Science, vol. 53, pp. 467-491.", "citeRegEx": "Seidenfeld,? 1987", "shortCiteRegEx": "Seidenfeld", "year": 1987}, {"title": "Axiomatic derivation of the principle of maximum entropy and the principle of minimimum cross-entropy", "author": ["J.E. Shore", "R.W. Johnson"], "venue": "IEEE Transactions on Information Theory IT26(1), 26-37.", "citeRegEx": "Shore and Johnson,? 1980", "shortCiteRegEx": "Shore and Johnson", "year": 1980}, {"title": "Can the maximum entropy prin\u00ad ciple be explained as a consistency requirement? Stud", "author": ["J. Uffink"], "venue": "Hist. Phil. Mod. Phys. 26(3), 223-261.", "citeRegEx": "Uffink,? 1995", "shortCiteRegEx": "Uffink", "year": 1995}, {"title": "The constraint rule of the max\u00ad imum entropy principle", "author": ["J. Uffink"], "venue": "Stud. Hist. Phil. Mod. Phys. 27(1), 47-79.", "citeRegEx": "Uffink,? 1996", "shortCiteRegEx": "Uffink", "year": 1996}, {"title": "Rational belief and prob\u00ad ability kinematics", "author": ["B.C. van Fraassen"], "venue": "Philosophy of Science", "citeRegEx": "Fraassen,? \\Q1980\\E", "shortCiteRegEx": "Fraassen", "year": 1980}, {"title": "A problem for relative information minimizers", "author": ["B.C. van Fraassen"], "venue": "British Journal for the Philosophy of Science", "citeRegEx": "Fraassen,? \\Q1981\\E", "shortCiteRegEx": "Fraassen", "year": 1981}, {"title": "Symmetries of personal probability kinematics", "author": ["B.C. van Fraassen"], "venue": "In N. Rescher (Ed.), Sci\u00ad entific Enquiry in Philsophical Perspective,", "citeRegEx": "Fraassen,? \\Q1987\\E", "shortCiteRegEx": "Fraassen", "year": 1987}], "referenceMentions": [{"referenceID": 12, "context": "In this paper we re-examine such a case: van Fraassen's Judy Benjamin problem [1987], which in essence asks how one might update given the value of a conditional probability.", "startOffset": 45, "endOffset": 85}, {"referenceID": 4, "context": "But many people have argued that conditioning is not a philosophically adequate answer (in particular, [Jeffrey 1983]).", "startOffset": 103, "endOffset": 117}, {"referenceID": 1, "context": ", see [Bacchus, Grove, Halpern, and Koller 1994; Diaconis and Zabell 1982; Jeffrey 1983; Jaynes 1983; Paris and Vencovska 1992; Uffink 1995]).", "startOffset": 6, "endOffset": 140}, {"referenceID": 4, "context": ", see [Bacchus, Grove, Halpern, and Koller 1994; Diaconis and Zabell 1982; Jeffrey 1983; Jaynes 1983; Paris and Vencovska 1992; Uffink 1995]).", "startOffset": 6, "endOffset": 140}, {"referenceID": 7, "context": ", see [Bacchus, Grove, Halpern, and Koller 1994; Diaconis and Zabell 1982; Jeffrey 1983; Jaynes 1983; Paris and Vencovska 1992; Uffink 1995]).", "startOffset": 6, "endOffset": 140}, {"referenceID": 10, "context": ", see [Bacchus, Grove, Halpern, and Koller 1994; Diaconis and Zabell 1982; Jeffrey 1983; Jaynes 1983; Paris and Vencovska 1992; Uffink 1995]).", "startOffset": 6, "endOffset": 140}, {"referenceID": 5, "context": "Certainly the best known and most studied of these proposals is to use the rule of minimizing cross-entropy [Kullback and Leibler 1951] as a way of updating with general probabilistic information.", "startOffset": 108, "endOffset": 135}, {"referenceID": 4, "context": "This rule can also be shown to generalize Jeffrey's rule [Jeffrey 1983], which in turn generalizes conditioning.", "startOffset": 57, "endOffset": 71}, {"referenceID": 9, "context": "But is cross-entropy ( CE) really such a good rule? The traditional justifications of CE are that it satisfies vari\u00ad ous sets of criteria (such as those of [Shore and Johnson 1980]) which, while plausible, are certainly not com\u00ad pelling [Uffink 1995].", "startOffset": 156, "endOffset": 180}, {"referenceID": 10, "context": "But is cross-entropy ( CE) really such a good rule? The traditional justifications of CE are that it satisfies vari\u00ad ous sets of criteria (such as those of [Shore and Johnson 1980]) which, while plausible, are certainly not com\u00ad pelling [Uffink 1995].", "startOffset": 237, "endOffset": 250}, {"referenceID": 9, "context": "But is cross-entropy ( CE) really such a good rule? The traditional justifications of CE are that it satisfies vari\u00ad ous sets of criteria (such as those of [Shore and Johnson 1980]) which, while plausible, are certainly not com\u00ad pelling [Uffink 1995]. Van Fraassen, in a paper entitled \"A problem for relative information [CE] minimizers in probability kinematics\" [1981] instead approached the question in a different way: he looked at how CE behaves on a simple specific example.", "startOffset": 157, "endOffset": 372}, {"referenceID": 12, "context": "Van Fraassen explains the JB problem as follows [1987]:", "startOffset": 4, "endOffset": 55}, {"referenceID": 12, "context": "Van Fraassen [1987] notes that", "startOffset": 4, "endOffset": 20}, {"referenceID": 12, "context": "in Blue territory even before hearing the message? As van Fraassen [1981] says, as part of an extended dis\u00ad cussion of this phenomenon:", "startOffset": 58, "endOffset": 74}, {"referenceID": 12, "context": "But if o: = 0 then, to quote van Fraassen [1987], \"he would have told her, in effect, 'You are not in Red", "startOffset": 33, "endOffset": 49}, {"referenceID": 8, "context": "cussed and criticized in a more general setting [Seidenfeld 1987].", "startOffset": 48, "endOffset": 65}, {"referenceID": 10, "context": "Even families of rules, such as van Fraassen proposes, are not so bad: after one has chosen a rule (usually by selecting a single real-valued parameter [Uffink 1995]), the rest is again mechanical, general, and determinate.", "startOffset": 152, "endOffset": 165}, {"referenceID": 2, "context": "mi\u00ad form in a continuous space [Howson and Urbach 1989].", "startOffset": 31, "endOffset": 55}, {"referenceID": 6, "context": "Further details can be found in any standard text on probability (for instance [Papoulis 1984]).", "startOffset": 79, "endOffset": 94}], "year": 2011, "abstractText": "Conditioning is the generally agreed-upon method for updating probability distribu\u00ad tions when one learns that an event is cer\u00ad tainly true. But it has been argued that we need other rules, in particular the rule of cross-entropy minimization, to handle up\u00ad dates that involve uncertain information. In this paper we re-examine such a case: van Fraassen's Judy Benjamin problem [1987], which in essence asks how one might update given the value of a conditional probability. We argue that-contrary to the suggestions in the literature-it is possible to use simple conditionalization in this case, and thereby obtain answers that agree fully with intu\u00ad ition. This contrasts with proposals such as cross-entropy, which are easier to apply but can give unsatisfactory answers. Based on the lessons from this example, we speculate on some general philosophical issues concern\u00ad ing probability update.", "creator": "pdftk 1.41 - www.pdftk.com"}}}