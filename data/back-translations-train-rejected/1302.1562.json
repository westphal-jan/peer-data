{"id": "1302.1562", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Support and Plausibility Degrees in Generalized Functional Models", "abstract": "By discussing several examples, the theory of generalized functional models is shown to be very natural for modeling some situations of reasoning under uncertainty. A generalized functional model is a pair (f, P) where f is a function describing the interactions between a parameter variable, an observation variable and a random source, and P is a probability distribution for the random source. Unlike traditional functional models, generalized functional models do not require that there is only one value of the parameter variable that is compatible with an observation and a realization of the random source. As a consequence, the results of the analysis of a generalized functional model are not expressed in terms of probability distributions but rather by support and plausibility functions. The analysis of a generalized functional model is very logical and is inspired from ideas already put forward by R.A. Fisher in his theory of fiducial probability.", "histories": [["v1", "Wed, 6 Feb 2013 15:58:30 GMT  (770kb)", "http://arxiv.org/abs/1302.1562v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["paul-andre monney"], "accepted": false, "id": "1302.1562"}, "pdf": {"name": "1302.1562.pdf", "metadata": {"source": "CRF", "title": "Support and Plausibility Degrees in Generalized Functional Models", "authors": ["Paul-Andre Monney"], "emails": ["paul-andre.monney@unifr"], "sections": [{"heading": null, "text": "The theories of Bayes and FisherJessica is a young woman pregnant = result pregnant = pregnant. In order to find out about her status, she decides to go to the local pharmacy and buys a pregnancy test. The test result indicates that she is not pregnant, but she knows that such tests are not completely trustworthy. The question is then how to assess the chance that she is pregnant despite the negative test result. (Of course, one possibility means that she is not pregnant and + 1 means that she is pregnant in order to analyze the situation. Let 8 denote the variable that indicates her true pregnancy status. The amount of possible values of B is e = {-1, + 1} where the probability of B is correct means that she is not pregnant and + 1 means that she is pregnant. The variable indicates a test result. The amount of possible values of X = {- 1, + 1} where Suppcate is a negative test result and + 1 is a positive test result."}], "references": [{"title": "Statistical inference: fiducial and struc\u00ad tural vs", "author": ["H. Bunke"], "venue": "likelihood. Math. Opemtionsforsch. u. Statist.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1975}, {"title": "The functional-model basis of fiducial inference", "author": ["A.P. Dawid", "M. Stone"], "venue": "The Annals of Statistics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1982}, {"title": "The structure of inference", "author": ["D.A.S. Fraser"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1968}, {"title": "A Mathematical The\u00ad ory of Hints. An Approach to the Dempster-Shafer Theory of Evidence, volume", "author": ["J. Kohlas", "P.A. Manney"], "venue": "Lecture Notes in Economics and Mathematical Systems. Springer,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1995}, {"title": "On the validation of fiducial techniques", "author": ["A. Plante"], "venue": "Can. J. Statist.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1979}, {"title": "A Mathematical Theory of Evidence", "author": ["G. Shafer"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1976}, {"title": "Belief functions and parametric models", "author": ["G. Shafer"], "venue": "J. R. Statist. Soc. B,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1982}], "referenceMentions": [{"referenceID": 2, "context": "Classical, non-generalized, functional models have been studied by Fraser [3], Bunke [1], Plante [5] and Dawid, Stone [2].", "startOffset": 74, "endOffset": 77}, {"referenceID": 0, "context": "Classical, non-generalized, functional models have been studied by Fraser [3], Bunke [1], Plante [5] and Dawid, Stone [2].", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "Classical, non-generalized, functional models have been studied by Fraser [3], Bunke [1], Plante [5] and Dawid, Stone [2].", "startOffset": 97, "endOffset": 100}, {"referenceID": 1, "context": "Classical, non-generalized, functional models have been studied by Fraser [3], Bunke [1], Plante [5] and Dawid, Stone [2].", "startOffset": 118, "endOffset": 121}, {"referenceID": 6, "context": "See also Shafer [7].", "startOffset": 16, "endOffset": 19}, {"referenceID": 3, "context": "The goal of this section is to show how the knowledge about e generated by the observations in a general\u00ad ized functional model can be expressed with the the\u00ad ory of hints, which is a theory strongly related to the Dempster-Shafer theory of evidence [4], [6].", "startOffset": 250, "endOffset": 253}, {"referenceID": 5, "context": "The goal of this section is to show how the knowledge about e generated by the observations in a general\u00ad ized functional model can be expressed with the the\u00ad ory of hints, which is a theory strongly related to the Dempster-Shafer theory of evidence [4], [6].", "startOffset": 255, "endOffset": 258}, {"referenceID": 0, "context": "The corresponding function sp: 28 -+ [0, 1] is called a support function.", "startOffset": 37, "endOffset": 43}, {"referenceID": 0, "context": "This can be done for all subsets H \ufffd 9 and the cor\u00ad responding function pl : 26 -+ [0, 1] is called a plausi\u00ad bility function.", "startOffset": 83, "endOffset": 89}, {"referenceID": 5, "context": "Support functions are known as belief functions in the Dempster-Shafer theory of evidence [6].", "startOffset": 90, "endOffset": 93}, {"referenceID": 0, "context": "Bel : 28 -+ [0, 1] (20)", "startOffset": 12, "endOffset": 18}, {"referenceID": 0, "context": "is a belief function if there exists a function m : 28 -+ [0, 1] satisfying", "startOffset": 58, "endOffset": 64}, {"referenceID": 3, "context": "Note that the actual computation of such degrees of support and plausibility can be facil\u00ad itated by using special computational procedures in\u00ad volving the so-called commonality functions (for more information on this topic, see [4] or [6]).", "startOffset": 229, "endOffset": 232}, {"referenceID": 5, "context": "Note that the actual computation of such degrees of support and plausibility can be facil\u00ad itated by using special computational procedures in\u00ad volving the so-called commonality functions (for more information on this topic, see [4] or [6]).", "startOffset": 236, "endOffset": 239}], "year": 2011, "abstractText": "By discussing several examples, the theory of generalized functional models is shown to be very natural for modeling some situations of reasoning under uncertainty. A general\u00ad ized functional model is a pair (f, P) where f is a function describing the interactions between a parameter variable, an observa\u00ad tion variable and a random source, and P is a probability distribution for the random source. Unlike traditional functional mod\u00ad els, generalized functional models do not re\u00ad quire that there is only one value of the pa\u00ad rameter variable that is compatible with an observation and a realization of the random source. As a consequence, the results of the analysis of a generalized functional model are not expressed in terms of probability distri\u00ad butions but rather by support and plausi\u00ad bility functions. The analysis of a general\u00ad ized functional model is very logical and is inspired from ideas already put forward by R.A. Fisher in his theory of fiducial proba\u00ad bility. 1 The Theories of Bayes and Fisher Jessica is a young woman suspecting that she might be pregnant. To find out about her status she decides to go to the local pharmacy and buys a pregnancy test. The test result indicates that she is not pregnant, but she knows that such tests are not fully trustworthy. The question is then how to evaluate the chance that she is pregnant in spite of the negative test result. Of course, one possibility is to use the Bayesian the\u00ad ory to analyze the situation. The Bayesian model is as follows. Let 8 denote the variable indicating her true pregnancy status. The set of possible values of B is e = { -1, +1} where -1 means that she is not pregnant and +1 means that she is pregnant. Simi\u00ad larly, Jet \ufffd denote the variable indicating a test result. The set of possible values of\ufffd is X = { 1 , + 1} where -1 represents a negative test result and + 1 a positive test result. The reliability of the test can be expressed by two numbers, namely the chance p that the test will indicate a negative result when a woman in not pregnant, and the chance p' that the test will indi\u00ad cate a positive result when a woman is pregnant. It is reasonable to assume that both p and p' are rather high. This information is represented by the condi\u00ad tional probabilities P(\ufffd =liB = -1) = p, P(\ufffd = liB = 1} = p'. (1) Suppose that Jessica's prior about her status is given by the probabilities P(B = -1) = y, P(B = +1) = 1y. (2) Then by Bayes theorem the posterior probability that Jessica is not pregnant is P'(B = -1) = yp . (3) yp+ (1y)(lp') According to the Bayesian theory, this represents Jes\u00ad sica's degree of confidence in the fact that she is not pregnant. Now assume that the probability of getting a correct negative result is the same as getting a correct positive result, i.e. p = p'. This means that the test reveals the true pregnancy status with probability p. This probability is an indicator of the confidence in the test result. Then by formula (3) the posterior probability that .Jessica is not pregnant is P'(B = 1) = yp (4) yp+ (1 y)( l p) This is the Bayesian solution to Jessica's pregnancy test problem. However, .Jessica is unable to give the prior probability of her being pregnant because she is not comfortable with the idea of giving a precise number to estimate this chance. As can be seen in for\u00ad mula ( 4), without a prior it is impossible to find the posterior probability of her not being pregnant. The Bayesian theory requires prior probabilities to com\u00ad pute posterior probabilities. But Jessica is still in\u00ad terested in finding a numerical value expressing the chance of her not being pregnant considering the neg\u00ad ative test result. How can we find such a numerical value? In 1930, R.A. Fisher identified a class of prob\u00ad lems in which it appeared to him that inductive prob\u00ad ability statements could legitimately be made without prior probabilities being used. It turns out that Jes\u00ad sica's problem when p = p' is one of them. In this example, Fisher's reasoning would go as follows. First define the variable", "creator": "pdftk 1.41 - www.pdftk.com"}}}