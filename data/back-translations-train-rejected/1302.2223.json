{"id": "1302.2223", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Feb-2013", "title": "WNtags: A Web-Based Tool For Image Labeling And Retrieval With Lexical Ontologies", "abstract": "Ever growing number of image documents available on the Internet continuously motivates research in better annotation models and more efficient retrieval methods. Formal knowledge representation of objects and events in pictures, their interaction as well as context complexity becomes no longer an option for a quality image repository, but a necessity. We present an ontology-based online image annotation tool WNtags and demonstrate its usefulness in several typical multimedia retrieval tasks using International Affective Picture System emotionally annotated image database. WNtags is built around WordNet lexical ontology but considers Suggested Upper Merged Ontology as the preferred labeling formalism. WNtags uses sets of weighted WordNet synsets as high-level image semantic descriptors and query matching is performed with word stemming and node distance metrics. We also elaborate our near future plans to expand image content description with induced affect as in stimuli for research of human emotion and attention.", "histories": [["v1", "Sat, 9 Feb 2013 11:49:19 GMT  (469kb)", "http://arxiv.org/abs/1302.2223v1", "10 pages, 3 figures, published in 16th International Conference on Knowledge-Based and Intelligent Information &amp; Engineering Systems, 10-12 Sep 2012, San Sebastian, Spain"]], "COMMENTS": "10 pages, 3 figures, published in 16th International Conference on Knowledge-Based and Intelligent Information &amp; Engineering Systems, 10-12 Sep 2012, San Sebastian, Spain", "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.MM", "authors": ["marko horvat", "anton grbin", "gordan gledec"], "accepted": false, "id": "1302.2223"}, "pdf": {"name": "1302.2223.pdf", "metadata": {"source": "CRF", "title": "WNtags: A Web-Based Tool For Image Labeling And Retrieval With Lexical Ontologies", "authors": ["Marko Horvat", "Anton Grbin", "Gordan Gledec"], "emails": ["Gordan.Gledec}@fer.hr"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2 The WNtags collaborative web-based annotation tool", "text": "This year, we will be able to try to find a solution that is capable of finding a solution, that is capable of finding a solution, that is capable of finding a solution."}, {"heading": "3 Formal image annotation", "text": "This year, it is more than ever before in the history of the city."}, {"heading": "4 Image retrieval", "text": ", \"\", \",\", \",\", \",\", \",\", \",\",,,,,,, \",,\",, \",,\",, \",\",, \",\", \",\", \",\", \",,\", \",,\", \",,\",,,,,,,,,, \",\", \",\", \",,,\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\",, \",\", \",\", \",\","}, {"heading": "4.1 Discussion", "text": "This year it is more than ever before."}, {"heading": "5 Conclusion", "text": "Due to the user-friendly user interface of the tool, new images can be easily added to the document store and labeled with semantic concepts. WNtags was developed as a flexible and modular research tool in areas of annotation and retrieval of emotionally annotated images from real life, but the problems outlined in the previous chapter vividly illustrate the difficulties of using WordNet as a knowledge base for image description. Only a large ontology without lexical dependencies is able to formally reflect the basic truth meaning of image contents. That's why we plan to add SUMO to the knowledge base WNtags."}, {"heading": "Acknowledgements", "text": "This research was partially supported by the Ministry of Science, Education and Sport of the Republic of Croatia, grant number 036-0000000-2029. WNtags was developed by the student team: Anton Grbin (project leader), Aleksandar Dukovski, Anton Grbin, Jerko Jurin, Dino Mila\u010di\u0107, Matija Stepani\u0107, Hrvoje \u0160imi\u0107 and Dominik Trup\u010devi\u0107 as part of their programming project course at the University of Zagreb, Faculty of Electrical Engineering and Computer Science."}], "references": [{"title": "Emotion representation and physiology assignments in digital systems", "author": ["C. Peter", "A. Herbon"], "venue": "Interacting with Computers, Vol. 18. Elsevier", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Ontology-based photo annotation", "author": ["Schreiber", "A. Th.", "B. Dubbeldam", "Wielemaker", "B.J.J. Wielinga"], "venue": "IEEE Intelligent Systems, 16(3)", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Development and application of a metric on semantic nets", "author": ["R. Rada", "H. Mili", "E. Bicknell", "M. Blettner"], "venue": "IEEE Transations on Systems, Man, and Cybernetics, 19(1)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1989}, {"title": "LabelMe: a database and webbased tool for image annotation", "author": ["B.C. Russell", "A. Torralba", "K.P. Murphy", "W.T. Freeman"], "venue": "Technical report, MIT", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "ImageNet: a large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "Li", "L.-J.", "K. Li", "L. Fei-Fei"], "venue": "Proc. CVPR.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "International affective picture system (IAPS): Affective ratings of pictures and instruction manual (Technical Report A-8)", "author": ["P.J. Lang", "M.M. Bradley", "B.N. Cuthbert"], "venue": "University of Florida, Gainesville, FL", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Tagging multimedia stimuli with ontologies", "author": ["M. Horvat", "S. Popovi\u0107", "N. Bogunovi\u0107", "K. \u0106osi\u0107"], "venue": "Proceedings of the 32nd International Convention MIPRO 2009, Croatian Society for Information and Communication Technology, Electronics and Microelectronics \u2013 MIPRO, Opatija, Croatia", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "WordNet: An Electronic Lexical Database", "author": ["C. Fellbaum"], "venue": "MIT Press", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1998}, {"title": "Ontology: A Practical Guide", "author": ["A. Pease"], "venue": "Articulate Software Press, Angwin, CA", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Semantic Web for the Working Ontologist: Effective Modeling in RDFS and OWL", "author": ["D. Allemang", "J. Hendler"], "venue": "Elsevier", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "International affective digitized sounds (IADS): Stimuli, instruction manual and affective ratings (Tech", "author": ["P.J. Lang", "M.M. Bradley", "B.N. Cuthbert"], "venue": "Rep. No. B-2). The Center for Research in Psychophysiology, University of Florida, U.S.A.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "Towards Modeling of Readers\u2019 Emotional State Response for the Automated Annotation of Documents", "author": ["D. Tsonos", "K. Ikospentaki", "G. Kouroupetrolgou"], "venue": "IEEE World Congress on Computational Intelligence (WCCI 2008)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Facial expressions and complex IAPS pictures", "author": ["J.C. Britton", "S.F. Taylor", "K.D. Sudheimer", "I. Liberzo"], "venue": "Common and differential networks. NeuroImage,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Ontology-based reasoning techniques for multimedia interpretation and retrieval", "author": ["B. Neumann", "R. M\u04e7ller"], "venue": "In Semantic Multimedia and Ontologies: Theory and Applications, Springer", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Towards a standard upper ontology", "author": ["Niles I", "A. Pease"], "venue": "Proceedings of the international conference on Formal Ontology in Information Systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "Physiology-driven adaptive virtual reality stimulation for prevention and treatment of stress related disorders", "author": ["K. \u0106osi\u0107", "S. Popovi\u0107", "D. Kukolja", "M. Horvat", "B. Dropulji\u0107"], "venue": "CyberPsychology, Behavior, and Social Networking, Vol. 13:1", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "WordNet::Similarity - Measuring the Relatedness of Concepts", "author": ["T. Pedersen", "S. Patwardhan", "J. Michelizzi"], "venue": "Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-04), San Jose, CA (Intelligent Systems Demonstration)", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2004}, {"title": "Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language", "author": ["P. Resnik"], "venue": "Journal Of Artificial Intelligence Research, Vol. 11", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "Linking lexicons and ontologies: Mapping wordnet to the suggested upper merged ontology", "author": ["Niles I.", "A. Pease"], "venue": "In Proc. of the 2003 Int. Conf. on Information and Knowledge Engineering", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "This is accomplished using circumplex model of emotions [1], ontology-based image labels [2], corpus independent graph-", "startOffset": 56, "endOffset": 59}, {"referenceID": 1, "context": "This is accomplished using circumplex model of emotions [1], ontology-based image labels [2], corpus independent graph-", "startOffset": 89, "endOffset": 92}, {"referenceID": 2, "context": "based distance metrics [3] which, as the entire tool, has modular implementation and can be optimized or replaced independently from other parts of the system.", "startOffset": 23, "endOffset": 26}, {"referenceID": 3, "context": "WNtags tool is different from other similar tools for manual image annotation (per example see [4][5]) in several respects.", "startOffset": 95, "endOffset": 98}, {"referenceID": 4, "context": "WNtags tool is different from other similar tools for manual image annotation (per example see [4][5]) in several respects.", "startOffset": 98, "endOffset": 101}, {"referenceID": 5, "context": "Firstly, WNtags uses International Affective Picture System (IAPS) dataset with semantically and emotionally described photographs that induce negative, neutral or positive affective reactions in stimulated persons [6].", "startOffset": 215, "endOffset": 218}, {"referenceID": 6, "context": "IAPS pictures are annotated sparsely and inadequately using free-text keywords [7].", "startOffset": 79, "endOffset": 82}, {"referenceID": 7, "context": "Thirdly, WNtags uses WordNet [8] for description of image content and in the future envisages applying Suggested Upper Merged Ontology (SUMO) [9] to formally schematize image concepts.", "startOffset": 29, "endOffset": 32}, {"referenceID": 8, "context": "Thirdly, WNtags uses WordNet [8] for description of image content and in the future envisages applying Suggested Upper Merged Ontology (SUMO) [9] to formally schematize image concepts.", "startOffset": 142, "endOffset": 145}, {"referenceID": 3, "context": "Representation of picture segments and objects is currently not in our focus as with some other image annotation tools [4] [5].", "startOffset": 119, "endOffset": 122}, {"referenceID": 4, "context": "Representation of picture segments and objects is currently not in our focus as with some other image annotation tools [4] [5].", "startOffset": 123, "endOffset": 126}, {"referenceID": 9, "context": "With formal logical systems based on Description Logic (DL) [10] these annotation may constitute a knowledge database of an intelligent expert system.", "startOffset": 60, "endOffset": 64}, {"referenceID": 5, "context": "Finally, WNtags could also be interpreted as a step towards improvement of emotionally annotated databases such as IAPS [6], International Affective Digitized Sounds (IADS) [11] or Geneva Affective Picture Database (GAPED) [12].", "startOffset": 120, "endOffset": 123}, {"referenceID": 10, "context": "Finally, WNtags could also be interpreted as a step towards improvement of emotionally annotated databases such as IAPS [6], International Affective Digitized Sounds (IADS) [11] or Geneva Affective Picture Database (GAPED) [12].", "startOffset": 173, "endOffset": 177}, {"referenceID": 5, "context": "These databases of multimedia stimuli are important for research of human emotion and attention [6], but also find their uses in a wide range of research (examples [13][14]).", "startOffset": 96, "endOffset": 99}, {"referenceID": 11, "context": "These databases of multimedia stimuli are important for research of human emotion and attention [6], but also find their uses in a wide range of research (examples [13][14]).", "startOffset": 164, "endOffset": 168}, {"referenceID": 12, "context": "These databases of multimedia stimuli are important for research of human emotion and attention [6], but also find their uses in a wide range of research (examples [13][14]).", "startOffset": 168, "endOffset": 172}, {"referenceID": 6, "context": "As mentioned before, their description schemes of multimedia semantics are currently quite rudimentary and limiting making image retrieval difficult and operator intensive [7].", "startOffset": 172, "endOffset": 175}, {"referenceID": 13, "context": "We believe that only a knowledge database based on a large upper ontology and extended with appropriate domain ontologies can encapsulate semantics present in an image repository [15].", "startOffset": 179, "endOffset": 183}, {"referenceID": 7, "context": "WordNet is a lexical database of English language [8] which may also be interpreted as an informal and lexical ontology [16].", "startOffset": 50, "endOffset": 53}, {"referenceID": 14, "context": "WordNet is a lexical database of English language [8] which may also be interpreted as an informal and lexical ontology [16].", "startOffset": 120, "endOffset": 124}, {"referenceID": 6, "context": "In spite of these shortcomings, WordNet is still far superior in image annotation than existing IAPS keywords, which are inconsistent, ambiguous and non-contiguous [7][17].", "startOffset": 164, "endOffset": 167}, {"referenceID": 15, "context": "In spite of these shortcomings, WordNet is still far superior in image annotation than existing IAPS keywords, which are inconsistent, ambiguous and non-contiguous [7][17].", "startOffset": 167, "endOffset": 171}, {"referenceID": 0, "context": "Every sense i s is weighted in a range [0,1] i w \u2208", "startOffset": 39, "endOffset": 44}, {"referenceID": 0, "context": "circumplex model of affect to annotate stimuli emotion values [1][6].", "startOffset": 62, "endOffset": 65}, {"referenceID": 5, "context": "circumplex model of affect to annotate stimuli emotion values [1][6].", "startOffset": 65, "endOffset": 68}, {"referenceID": 0, "context": "Values of all axis are numerical and normalized in interval [1, 9].", "startOffset": 60, "endOffset": 66}, {"referenceID": 8, "context": "Values of all axis are numerical and normalized in interval [1, 9].", "startOffset": 60, "endOffset": 66}, {"referenceID": 16, "context": "WNtags has modular architecture and in the current version, to save processing time, semantic similarity is loaded from the freely available WordNet::Similarity dataset with prepared similarity and relatedness pairs [18].", "startOffset": 216, "endOffset": 220}, {"referenceID": 17, "context": "Thirdly, the structure of WordNet\u2019s semantic network may be contrary to intuition and too complex [19].", "startOffset": 98, "endOffset": 102}, {"referenceID": 18, "context": "In doing this we would like to retain existing WordNet image labels and map them to SUMO concepts [20].", "startOffset": 98, "endOffset": 102}], "year": 2012, "abstractText": "Ever growing number of image documents available on the Internet continuously motivates research in better annotation models and more efficient retrieval methods. Formal knowledge representation of objects and events in pictures, their interaction as well as context complexity becomes no longer an option for a quality image repository, but a necessity. We present an ontologybased online image annotation tool WNtags and demonstrate its usefulness in several typical multimedia retrieval tasks using International Affective Picture System emotionally annotated image database. WNtags is built around WordNet lexical ontology but considers Suggested Upper Merged Ontology as the preferred labeling formalism. WNtags uses sets of weighted WordNet synsets as high-level image semantic descriptors and query matching is performed with word stemming and node distance metrics. We also elaborate our near future plans to expand image content description with induced affect as in stimuli for research of human emotion and attention.", "creator": "PScript5.dll Version 5.2.2"}}}