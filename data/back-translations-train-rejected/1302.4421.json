{"id": "1302.4421", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2013", "title": "Towards a theory of good SAT representations", "abstract": "We aim at providing a foundation of a theory of \"good\" SAT representations F of boolean functions f. We argue that the hierarchy UC_k of unit-refutation complete clause-sets of level k, introduced by the authors, provides the most basic target classes, that is, F in UC_k is to be achieved for k as small as feasible. If F does not contain new variables, i.e., F is equivalent (as a CNF) to f, then F in UC_1 is similar to \"achieving (generalised) arc consistency\" known from the literature (it is somewhat weaker, but theoretically much nicer to handle). We show that for polysize representations of boolean functions in this sense, the hierarchy UC_k is strict. The boolean functions for these separations are \"doped\" minimally unsatisfiable clause-sets of deficiency 1; these functions have been introduced in [Sloan, Soerenyi, Turan, 2007], and we generalise their construction and show a correspondence to a strengthened notion of irredundant sub-clause-sets. Turning from lower bounds to upper bounds, we believe that many common CNF representations fit into the UC_k scheme, and we give some basic tools to construct representations in UC_1 with new variables, based on the Tseitin translation. Note that regarding new variables the UC_1-representations are stronger than mere \"arc consistency\", since the new variables are not excluded from consideration.", "histories": [["v1", "Mon, 18 Feb 2013 20:40:06 GMT  (46kb)", "https://arxiv.org/abs/1302.4421v1", "43 pages"], ["v2", "Tue, 5 Mar 2013 00:04:46 GMT  (48kb)", "http://arxiv.org/abs/1302.4421v2", "45 pages; second version with some extended discussions and editorial corrections"], ["v3", "Thu, 21 Mar 2013 00:46:37 GMT  (51kb)", "http://arxiv.org/abs/1302.4421v3", "43 pages; second version with some extended discussions and editorial corrections, third version with extended introduction, more examples and explanations, and some editorial improvements"], ["v4", "Fri, 10 May 2013 17:45:54 GMT  (74kb)", "http://arxiv.org/abs/1302.4421v4", "59 pages; second version with some extended discussions and editorial corrections, third version with extended introduction, more examples and explanations, and some editorial improvements, fourth version with further examples, explanations and discussions, and with added computational experiments"]], "COMMENTS": "43 pages", "reviews": [], "SUBJECTS": "cs.AI cs.LO", "authors": ["matthew gwynne", "oliver kullmann"], "accepted": false, "id": "1302.4421"}, "pdf": {"name": "1302.4421.pdf", "metadata": {"source": "CRF", "title": "Towards a theory of good SAT representations", "authors": ["Matthew Gwynne"], "emails": [], "sections": [{"heading": null, "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to fight, to fight, to fight, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "1 Introduction 3", "text": "1.1. General framework: Hierarchies and units of measurement..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "2 Preliminaries 12", "text": ".............................................. 12 2.2 CNF versus DNF...................... 13. 2.3 On \"good\" equivalent rates..............................."}, {"heading": "3 Measuring \u201cSAT representation complexity\u201d 14", "text": "3.1 Hardness and UCk................................ 15 3.2 W hardness and WCk............................ 17"}, {"heading": "4 Minimal premise sets and doped clause-sets 18", "text": "4.1 Minimum premises........................................................................................................................................................................................................................................................................................................................................................................................................................................................"}, {"heading": "5 Doping tree clause-sets 22", "text": "............................................................................................................................."}, {"heading": "6 Lower bounds 28", "text": "6.1 Trigger hypergraphs......................................................................................................................."}, {"heading": "7 Analysing the Tseitin translation 35", "text": "......................................................................"}, {"heading": "8 Hardness under union 43", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9 Basic experiments 44", "text": "9.1 Instances......................................................................."}, {"heading": "10 Conclusion and open problems 49", "text": "10.1 Strict hierarchies................................................................................................................................................................................."}, {"heading": "1 Introduction", "text": "In fact, most of them are able to go in search of a solution that has its origins in the past."}, {"heading": "1.1 A general framework: hierarchies and measurement", "text": "\"This is the only solution that we cover in the limitation of these hierarchies, with the levels of the hierarchy that offers the possibility of trading with the inference method. (rk) The existing results we show in Lemma 6,5 of [37, 38] that different poly-time solvable SAT classes are contained in the levels of the KLA hierarchy. (This is the HO hierarchy of the KLA hierarchy in the levels of the KLA hierarchy. (This is the HO hierarchy of the KLA hierarchy.) This is the HO hierarchy of the KLA hierarchy. (This is the HO hierarchy of the KLA hierarchy.) In which we contain different SAT classes. (This is the HO hierarchy of the KLA hierarchy.) This is the HO hierarchy of the KLA hierarchy. (This is the HO hierarchy of the HO hierarchy.)"}, {"heading": "1.2 Representation of boolean functions", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able, that we are able to assert ourselves, that we are able, that we are able, that we are able, and that we are able to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in a position, to put ourselves in the position we are in."}, {"heading": "1.3 Strictness of hierarchies", "text": "A fundamental question is the severity of these hierarchies PCk, UCk, and WCk in each of these two remaining dimensions. That is, whether each level offers new possibilities for polysizing (sequences of) Boolean functions within the boundaries of the specified dimensions, i.e. relative versus absolute and without versus with new variables. With the basic choice of the absolute condition, we have six correct hierarchies (3 presumed, 3 proven), namely PCk, UCk, and WCk for representations without (theorem 6.14) and with new variables (conjecture 7.3). However, if we use representations based on the relative condition (and use new variables), then all of these hierarchies collapse to their first level: two collapses are similar to the existing results, while the collapse for WCk should also follow this way, and is considered as consistency of the consistency 7.5.Considered, under the relative condition UC0-UC0-UCK-UCK-W1, where everything can be reduced to WC0-UCK-UCK with WCysik classes 1."}, {"heading": "1.4 Understanding the combinatorial structure of satisfiable clause-sets", "text": "In order to demonstrate properties over all equivalent representations of any clause set F, we need to be able to understand its combinatorial structure in relation to the set of all its prime numbers (see [52, 66]). To understand the structure of satisfactory sentences (MU) and their associated Boolean functions, we now consider the concept of \"minimal premises\" (MPS) introduced in [62]. The notion of MPS generalizes that of MU by looking at clause sets F, which are minimal. R.T implies a clause C and not just the implicit clause C. And accordingly, we look at the minimum premise set (MPSS) of a clause set F (MPSS) of an exact clause set F. Each implicit clause F has an associated MPSS clause (consider only the minimal clause set F implicit clause), which implies a minimum premise set F."}, {"heading": "1.5 The UC hierarchy is strict regarding equivalence", "text": "It is not as if it were a matter of a kind of concepts, which differ in the manner and manner in which we interpret them in the manner and manner in which we interpret them in the manner and manner in which they occur in the manner and manner in which they occur in the language, as they do in the language, as they do in the language, as they do in the language, as they do in the language, as they do in the language, as they do in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language, as in the language in the language, as in the language, as in the language in the language, as in the language, as in the language in the language, as in the language in the language, as in the language, as in the language, as in the language, as in the language"}, {"heading": "1.6 Relevance of these hierarchies for SAT solving", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able to hide ourselves, and that we are able, we will be able to be able, \"he said."}, {"heading": "1.7 Tools for good representations", "text": "In fact, it is true that most of us are able to survive on our own and that they are able to survive on their own. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "1.8 Experimental results", "text": "In Section 9, we consider the use of the class of Boolean functions f used for the lower limit to be a constraint in a general SAT problem. We have equivalent clauses in UCk for the optimal k, as well as short orthogonal DNF representations that allow us to apply the canonical translation in the same way as the reduced canonical translation. We supplement these three constraints in a fixed manner to obtain an unsatisfactory set of clauses. Experiments show that the optimal UCk representation for all solver types performs much better in terms of runtime. This provides some evidence for our claim that equivalent representations in UCk even for higher k (in our experiments, we considered k \u2264 5) may exceed the representations obtained by introducing new variables, as they (possibly) use much fewer variables and clauses."}, {"heading": "1.9 Remarks on the term \u201chardness\u201d", "text": "In general, one speaks of the \"hardness measurement\" hd: CLS \u2192 N0 (definition 3.3) in the context of other measures, then one should call it specific tree hardness (\"t-hardness\"), which is called by thd (F), because of its close relationship to treeresolution (and its spatial complexity). Thus, we have three basic types of hardness measurements, namely, hardness thd (F), the minimum k with F-UCk, the minimum k with F-PCk, and the minimum k hardness, the minimum k with F-WCk. In this article, since thd (F) is most important, we call it H-UCk, p-hardness phd (F), the minimum the hardness with F-PCk, and w-hardness, the minimum the minimum hardness, the minimum the minimum the minimum assignment."}, {"heading": "1.10 Overview on results", "text": "In Section 4, we examine minimum premise sets and doping in general, while in Section 5, we apply these terms to our source of hard examples. In Section 6, we are then able to show the separation result. In Section 7, we discuss our basic experiments and analyze the Tseitin translation. To examine the severity of a specific case, we present some tools for determining (W) hardness in Section 8. Section 9, we discuss our basic experiments. Finally, in Section 10, we find many open problems. The most important results on minimum premise sets and doping are: 1 Theorem 4.18 shows the correlation between prime numbers and minimum premise sets and minimum premise sets."}, {"heading": "2 Preliminaries", "text": "We follow the general notations and definitions as described in [52]. We use N = {1, 2,...}, N0 = N = 0 {0} and P (M) for the set of subsets of set M."}, {"heading": "2.1 Clause-sets", "text": "Unless we have a complete solution to the question whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question, whether there is a complete solution to the question after the question, whether there is a complete answer to the question after the question after the question after the question after the question, whether there is a complete answer to the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the answer after the question after the question after the question after the question after the question after the question after the question after the answer after the question after the question after the question after the question after the question after the question after the answer after the question after the question after the question after the answer after the question after the question after the question after the answer after the question after the question after the question after the answer after the question after the question after the question after the question after the answer after the question after the question after the question after the question after the answer after the question after the question after the question after the question after the answer after the question after the question after the question after the question after the question after the question after the question after the question after the question after the answer after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question after the question"}, {"heading": "2.2 CNF versus DNF", "text": "In fact, it is as if it is a matter of a way in which people are able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they were able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves. (...) It is as if they are able to survive themselves."}, {"heading": "2.3 On \u201cgood\u201d equivalent clause-sets", "text": "A basic problem that is considered in this article is that a particular F-CLS finds a \"good\" equivalent F-CLS. How \"good\" F-CLS is depends in our context on two factors that need to be weighed against each other: \u2022 the size of F-CLS: we measure c (F-CLS), and the smaller the better; \u2022 the inference force of F-CLS: Conclusions from F-CLS should be \"as simple as possible,\" and we consider two measures in this article, the (tree) hardness in subsection 3.1 and the width hardness in subsection 3.2; the smaller these measures, the easier it is to deduce w.r.t. Tree resolution or (generalized) width-limited resolution. The basic size lower limit for F-CLS is implied by the essential prime number, which is that C-Prc0 (F) that Prc0 (F)\\ {C} variables are not equivalent in F-CLS."}, {"heading": "3 Measuring \u201cSAT representation complexity\u201d", "text": "(D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D) D (D) D (D) D) D (D) D (D) D) D (D) D (D) D (D) D (D) D (D) D (D) D (D) D) D (D) D (D) D) D (D) D) D (D) D (D) D) D (D) D (D) D) D (D) D (D) D) D (D) D (D) D) D (D) D (D) D (D) D) D (D) D (D) D) D (D) D) D (D) (D) D) D (D) (D) D) D (D) (D) D) D (D) (D) D) (D) D) (D) D) D (D) D) D (D) (D) (D) (D) D) D) D (D) (D) D) (D) D) D (D) (D) D) D (D) (D) D) (D) D) (D) D) D (D) (D) (D) (D) D) (D) (D) (D) D) (D) (D) (D) (D) D) (D) D) (D) (D) (D) (D) (D) (D) D) (D) (D) (D) D) (D) (D) (D) (D) (D) D) (D) (D) (D) (D) D) (D) (D) (D) (D) D) (D) (D) D) (D) (D) D) (D) (D"}, {"heading": "4 Minimal premise sets and doped clause-sets", "text": "In this section, we will examine \"minimal premises,\" or mps for short, introduced in [62], along with the properties of \"doped\" clauses that generalize a construction used in [75]. Mps \"are generalizations of minimally unsatisfactory clauses that are stronger than irredundant clauses, while doping refers to primary implications and sub-mps. Remember that a clause F is minimally unsatisfactory if F-USAT, while F is more powerful than irredundant clauses F- {C-SAT} for all C-F clauses. Now, a mps is a set of minimally unsatisfactory clauses that is MU-CLS; see [52] for more information. In other words, for F-CLS, we have F-MU if and only if F-F clauses are minimally related to this conditional relationship. Now, a clause F-clause set is the minimum clause that implies clause F-F, that is any clause-F-clause."}, {"heading": "4.1 Minimal premise sets", "text": "In fact, most people are able to recognize themselves and understand what they are doing. (...) In fact, most of us are able to identify ourselves. (...) It is as if they were able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...) It is as if they were able to put themselves in the center. (...) It is as if they are able to put themselves in the center. (...)"}, {"heading": "4.2 Doping clause-sets", "text": "\"For F (F) we have n (F) = n (F).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c (F).c).c (F).c (F).c (F).c).c (F).c (F).c (F).c (F).c (F).c (F).c).c (F).c (.c).c (F).c).c (.c).c (F).c (.c).c).c (F.c).c (F).c (.c).c (F).c (F).c (.c).c (F).c (F).c (.c).c (F).c (.c).c (F).c (.c).c (F).c (.c).c (.c (F).c (.c).c (F).c (.c).c (.c).c (.c).c (.c (F).c (.c).c (.c).c (.c).c (.c (.c).c (.c (.c).c).c (.c (.c).c (.c (.c).c (.c).c (.c (.c).c (.c (.c).c (.c).c (.c (.c).c (.c (.c (.c).c).c (.c (.c).c (.c).c (.c (.c).c (.c).c (.c (.c).c (.c).c ("}, {"heading": "4.3 Hardness of doped clause-sets", "text": "The hardness of a doped clause set is the maximum hardness of a sub-clause set of the original clause set: Lemma 4,20 For F-CLS we have HD (D (F) = maxF (F).Proof: We have HD (F) \u2264 HD (D (F))) for all F-F, as we obtain F-F by applying an appropriate partial allotment by setting the doping variables in F \"to false and the rest to true. And, if we consider an arbitrary partial allotment with D (F) and USAT, then w.l.o.g. All doping variables are set (we can set the unused doping variables in F\" to true, \"as these variables are all pure), and then we have a partial allotment that makes F\" unsatisfactory \"for these F (F)."}, {"heading": "5 Doping tree clause-sets", "text": "As explained in Section 1.5, we want to construct Boolean functions (given by propositions) with a large number of primes, and where we have strong control over these primes. To this end, we dope \"minimally unsatisfactory propositions of deficiency 1,\" i.e. the elements of SMU\u03b4 = 1. First, we check the background in Section 5.1 (see [52] for more information). In Section 5.2, we show that these propositions form the core of \"totally minimum propositions,\" which have as many minimum propositions as possible. In Theorem 5.12, we show that F-SMU\u03b4 = 1 are exactly the unsatisfactory propositions, so that each non-empty subset is an mps. Then, in Section 5.3, we look at the dosing of these special propositions, and in Theorem 5.22, we determine basic properties of D (F)."}, {"heading": "5.1 Preliminaries on minimal unsatisfiability", "text": "Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root Root"}, {"heading": "5.2 Total minimal premise sets", "text": "vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvu vvvvvvvvvvvvvvvvvvvvvvvvvu vvvvvvvvvvvvvvvvu vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvu"}, {"heading": "5.3 Doping SMU\u03b4=1", "text": "We now turn to a closer understanding of the primes (T1 (F), which we regard as non-empty subset. (F) We begin with their identification with non-empty subset (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F)........ (F). (F). (F)."}, {"heading": "6 Lower bounds", "text": "This section proves the main result of this article, Theorem 6.14, which for each k \u2265 0 sequence (F kh) h \u0394N has small set sets of hardness k + 1, with each equivalent set of hardness k (actually the w hardness k) being exponentially large. In this way, we show that the UCk hierarchy is useful, i.e., equivalent set sets of higher hardness can be substantially shorter. These F kh are doped versions of set sets of SMU\u03b4 = 1 (sentence 5.22) that are \"extreme,\" i.e. their underlying trees T1 (F kh) are as large as possible for the given Horton emitter number k + 1 and height h. Organization of this section is as follows: In Section 6.1, the main instrument for displaying size-lower sets of equivalent set sets of a given (w-) hardness shows the lower limit in Theorem 6.4."}, {"heading": "6.1 Trigger hypergraphs", "text": "'It is very important that we all F & # 8222; s & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 222; f # 222; f # 222; f # 222; f # 8222; f & # 8222; f # 8222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 22; f # 22; f # 22; f # 22; f # 22; f # 22; f # 22; f # 22; f # 22; f # 222; f # 22; f # 22; f # 222; f # 222; f # 22; f # 22; f # 222; f # 22; f # 222; f # 222; f # 222; f # 22; f # 22; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 222; f # 822; f # 222; f # 222; f #"}, {"heading": "6.2 Extremal trees", "text": "For a given hardness k = 0 we must build trees that are as large as possible; this is achieved by specifying the height and using trees that are completely filled in for the given parameter values: definition (k, h), tree number k and height h if1. hs (T) = k (T), ht (T) = h; 2. for all trees with a allowed parameter pair (K, h), a complete tree T is called the extreme tree of the Horton emitter number k and height h if1. hs (T) = k, ht (T) = h; 2. for all trees with a allowed parameter pair (T), k and ht (T) that we have nds (T). We denote the set of all extreme trees with Horton emitter number k and height h of HS (k, h).Note that we use for allowed parameter pairs (k, h), h = 0."}, {"heading": "6.3 The exponential lower bound", "text": "The task is to find many irreconcilable hyperedges in Tk (F k h), where F k h: = D (F 1) for T (K + 1, h). Our method for this is to show that there are many \"incomparable\" subsets of leaves in T in the following sense: The depth of a node w in a rooted tree T, which from the length of the path from the root of T to the depth of B is not comparable iff A 6, B 6 and B 6 (A). Furthermore, we call two sets A, B and C incomparable if the sets C and B are incomparable. Definition 6.11 Consider a complete binary tree T, where each leaf has depth at least k + 1."}, {"heading": "7 Analysing the Tseitin translation", "text": "In Section 7.1 we discuss the general concept of \"CNF representation.\" In Section 7.2 we discuss the translation of the DNF into the CNF, which we regard as a map from CLS to CLS and which we call \"canonical translation.\" Lemma 7.11 shows that the hardness of the canonical translation results can be arbitrarily high. On the other hand, Lemma 7.12 shows that for the meeting of the DNF the canonical translation result is in UC, and Theorem 7.14 applies this to our subordinate examples, as opposed to Theorem 6.14 (so that we see that new variables help here)."}, {"heading": "7.1 CNF-representations", "text": "In this case, it is not the case that the F & # 252; for the F & # 252; for the F & # 252; for the F & # 252; for the F & # 252; for the F & # 252; for the F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & & # 160; F & # 160; F & # 160; F & 160; F & 160; F & # 160; F & # 160; F & & & & & & 160; F & 160; F & 160; F & 160; F"}, {"heading": "7.2 The canonical translation", "text": "In fact, it is as if it is a kind of cncnlhSe that is able to move in a position, in which it is able to be in a position, in which it is able to be in a position, in which it is able to be in a position, in which it is able to be in a position, in which it is able to be in a position, in which it is able to be in a position, in which it is in a position, in which it is in a position, in which it is in a position, in which it is in a position, in which it is in a position, in which it is in a position, in which it is in a position, in which it is in a position, in which it is in a position, in which it is in a position, in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it is in which it in which it is in which it is in which it is in which it in which it is in which it in which it is in which it is in which it in which it is in which it is in which it in which it is in which it is in which it in which it is in which it is in which it is in which it is which it in which it is in which it is which it is in which it is which it is which it is which it in which it is which it is which it is which it in which it in which it is which it is which it is which it is which it is which it is in which it is which it is which it is which it is which it is which it is which it is which it is in which it is which it is which it is which it is which it is which it is in which it is which it is which it is which it which it is which it is which it is in which it is which it is which it is in which it is which it is which it which it is which it is which it is which it which it is which it is which it is which it which it is which it is which it is which it is"}, {"heading": "7.3 XOR-clauses", "text": "For n-bit parity function x1, x2, x2, x2, x2, x2, x2, x2, x2, x2, 2, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 7, 6, 7, 7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11"}, {"heading": "8 Hardness under union", "text": "If we apply a system of linear equations (with different auxiliary variables for each individual equation) (with different auxiliary variables for each individual equation), the translation of Lemma 7.19 will not lead to a higher resolution, as we show in Theorem 8.5. To facilitate the exact calculation of the hardness of two such XOR clauses, we will show two general tools for the upper limit of hardness and one for the lower limit. Let P be the series of partial aspects with var (var) = V clauses. Then hd (F) clauses will be applicable for the upper limit of hardness and one for the lower limit. Proof: Consider a partial aspect with Lemma US clauses; we must show that we have a partial aspect with var (var) clauses."}, {"heading": "9 Basic experiments", "text": "In this section, we will conduct some experiments to use the three different mechanisms for displaying Boolean functions f that have been examined in this article: 1. sentence sentences F equivalent to f with F-UCk, where k is as low as possible; 2. the canonical translation ct (G) for a DNF sentence set G equivalent to f; 3. and the reduced canonical translation ct- (G). The instances are described in Section 9.1, while the experimental results are discussed in Section 9.2. Our focus is on a better understanding of the interaction between solver behavior and problem presentation, and thus we will consider various representative complete SAT solvers."}, {"heading": "9.1 The instances", "text": "For the \"completion,\" according to Fk, \"we can consider the watering of the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering, the watering of the watering of the watering, the watering of the watering of the"}, {"heading": "9.2 Solver performances", "text": "This year, it has reached the point where it will be able to climb to the top of the leaderboard that lists all the other candidates."}, {"heading": "10 Conclusion and open problems", "text": "We have discussed the three hierarchies PCk, UCk and WCk of the target classes for \"good\" SAT representations. We have shown that each level of UCk + 1 contains clauses without equivalent short clauses in WCk. And we have outlined the conditions under which the Tseitin translation produces translations into UC."}, {"heading": "10.1 Strictness of hierarchies", "text": "A fundamental question is the severity of the hierarchies PCk, UCk and WCk in each of the dimensions. In Theorem 6.14 we have shown that the hierarchies UCk and WCk are strict. It follows that for PCk at least every other level brings progress in terms of logical equivalence (and polysization), which proves that these hierarchies are useful, e.g. by using failed literal reduction, the use of exponentially smaller SAT translations can be possible. Open are the questions of severity for the hierarchies that allow new variables. In summary, the most important assumptions are: 1. Guess 6.15 strengthens Theorem 6.14 by taking into account the PC hierarchy. 2. Guess 7.3 roughly states that all PCk, UCk and WCk are strict (similar to Theorem 6.14) when new variables are allowed under the absolute condition.3. Guess that CW1 breaks down relative to KWK (7.5)."}, {"heading": "10.2 Separating the different hierarchies", "text": "For our three most important guesses in relation to the three hierarchies we use the following terms: \"A\" (F \"n) n\" n \"n\" n. \"(F\" n) n \"n\" n \"n\" n. \"(F) n\" n \"n\" n \"n.\" (F) n \"n\" n \"n\" n \"n.\" (F) n \"n\" n \"n\" n. \"(F) n\" n \"n\" n \"n\" n. \"(F) n\" n \"n\" n \"n\" n. \"(F) n\" n \"n\" n \"n\" n. \"(F) n\" n \"n\" n. \"(F) n\" n. \"n.\" (F) n \"n.\" n. \"(F) n\" n. \"n.\" (F) n \"n.\" n. \"(F) n\" n \"n.\" n. \"n.\" (F) n \"n\" n (F) n \"n.\" n (F \"n\" n \"n.\" n. \"n.\" n. \"n.\" (F) n (F \"n\" n \"n\" n \"n.\" n. \"n.\" n. (F \"n.\" n \"n\" n \"n.\" n. (F) n \"n. (F\" n \"n\" n \"n.\" n. (F) n \"n\" n. (F) n \"n\" n \"n. (F\" n \"n\" n. \"n\" n. \"n.\" n. (F) n \"n\" n \"n. (F) n\" n. (F) n \"n\" n \"n\" n. (F) n \"n\" n \"n\" n. (F \"n\" n \"n.\" n \"n\" n. (F) n \"n\" n \"n\" n. (F) n \"n\" n \"n\" n. (F \"n\" n \"n. (F) n\" n \"n\" n \"n\" n \"n. (F) n\" n \"n\" n \"n. (F\" n \"n\" n \"n\" n. \"n. (F) n\" n \"n"}, {"heading": "10.3 Compilation procedures", "text": ", which is an F-UCk equivalent to f, with F-prc0 (f) and where no clause can be removed without increasing the hardness or destroying the equivalence. It is shown that if f is given as 2-CNF, then a smallest k base is calculable in polynomial time, but even for f with a given prc0 (f), where prc0 (f) is set a horn clause that determines whether a k base of a described size exists for a fixed k-1, NP is complete. There are interesting applications where prc0 (f) is given (or can be compressed) a first phase, and where a small equivalent F-UCk is found."}, {"heading": "10.4 Exploring w-hardness", "text": "It is to be expected that the w-hardness can behave very differently from the hardness. For example, as expressed in conjecture 10.1, its second stage should already contain short sentences that cannot be represented in any KLA. Nevertheless, we do not have tools at hand to deal with the w-hardness (we do not even have a presumed example of such a separation).A first task is to investigate which of the hardness results from this article and from [38] can be adapted to the w-hardness. In [9] we will present some basic methods for w-hardness limits. Can the classes WCk go beyond monotonous circuits that are strongly related to the expressiveness of arc-consistent CNF representations in [8] (see the following subsection for some further comments)? Assumption 7.5 would show the opposite, namely that in the (unlimited) presence of new variables, the consistency is also limited, modulo-time polycompressions would be greater than that of the PCK (that consistency is greater)."}, {"heading": "10.5 Hard boolean functions handled by oracles", "text": "Finally, we turn to specific (sequences) Boolean functions, which are currently beyond the reach of good representations, and where the use of oracles is therefore necessary. Presumably, here we have another example of the limitations of arc-consistent representations as shown in [8]. To overcome these (presumed) limitations, the theory of the use of oracles as discussed in [53, 59] and further, as the limitations of arc-consistent representations as shown in [8], must be generalized. To overcome these (presumed) limitations, the theory of the use of oracles as discussed in [53, 59] and further, as the limitations of arc-consistent representations as shown in [8] must be generalized. In order to overcome these (presumed) limitations, the theory of the use of oracles as discussed in [53, 59] and further in Subsection 9.4 of [37, 38]. The point of these oracles, which are adjusted only to unsatisfactory limitations, is that the theory is stable using partial areas, is necessary that it is difficult to detect."}], "references": [{"title": "Measuring the hardness of SAT instances", "author": ["Carlos Ans\u00f3tegui", "Ma\u0155\u0131a Luisa Bonet", "Jordi Levy", "Felip Many\u00e0"], "venue": "Proceedings of the 23th AAAI Conference on Artificial Intelligence", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Predicting learnt clauses quality in modern SAT solvers", "author": ["Gilles Audemard", "Laurent Simon"], "venue": "Proceedings of the 21st International Joint Conference on Artificial intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Efficient CNF encoding of boolean cardinality constraints", "author": ["Olivier Bailleux", "Yacine Boufkhad"], "venue": "In Principles and Practice of Constraint Programming \u2013 CP 2003,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "On hierarchies over the SLUR class", "author": ["Tom\u00e1\u0161 Balyo", "\u0160tefan Gursk\u00fd", "Petr Ku\u010dera", "V\u00e1clav Vl\u010dek"], "venue": "In Twelfth International Symposium on Artificial Intelligence and Mathematics (ISAIM", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Short proofs are narrow \u2014 resolution made simple", "author": ["Eli Ben-Sasson", "Avi Wigderson"], "venue": "In Proceedings of the 31th Annual ACM Symposium on Theory of Computing", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1999}, {"title": "Circuit complexity and decompositions of global constraints", "author": ["Christian Bessiere", "George Katsirelos", "Nina Narodytska", "Toby Walsh"], "venue": "In Proceedings of the Twenty-First International Joint Conference on Artificial Intelligence (IJCAI-", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Hardness measures and resolution lower bounds, with applications to Pigeonhole principles", "author": ["Olaf Beyersdorff", "Matthew Gwynne", "Oliver Kullmann"], "venue": "In preparation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Picosat essentials", "author": ["Armin Biere"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Lingeling, Plingeling, PicoSAT and PrecoSAT at SAT Race", "author": ["Armin Biere"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Lingeling and friends entering the SAT Challenge", "author": ["Armin Biere"], "venue": "Proceedings of SAT Challenge 2012: Solver and Benchmark Descriptions,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Handbook of Satisfiability, volume 185 of Frontiers in Artificial Intelligence and Applications", "author": ["Armin Biere", "Marijn J.H. Heule", "Hans van Maaren", "Toby Walsh", "editors"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Knowledge compilation with empowerment", "author": ["Lucas Bordeaux", "Joao Marques-Silva"], "venue": "SOFSEM 2012: Theory and Practice of Computer Science,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "The complexity of read-once resolution", "author": ["Hans Kleine B\u00fcning", "Xishun Zhao"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "On resolution with short clauses", "author": ["Michael Buro", "Hans Kleine B\u00fcning"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1996}, {"title": "A survey of knowledge compilation", "author": ["Marco Cadoli", "Francesco M. Donini"], "venue": "AI Communications,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1997}, {"title": "Properties of SLUR formulae", "author": ["Ond\u0159ej \u010cepek", "Petr Ku\u010dera", "V\u00e1clav Vl\u010dek"], "venue": "SOFSEM 2012: Theory and Practice of Computer Science,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "An exponential example for analytic tableaux", "author": ["Stephen A. Cook"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1973}, {"title": "Boolean Functions: Theory, Algorithms, and Applications, volume 142 of Encyclopedia of Mathematics and Its Applications", "author": ["Yves Crama", "Peter L. Hammer"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Complexity of Constraints: An Overview of Current Research Themes, volume 5250 of Lecture Notes in Computer", "author": ["Nadia Creignou", "Phokion Kolaitis", "Heribert Vollmer", "editors"], "venue": "Science (LNCS). Springer,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "A knowledge compilation map", "author": ["Adnan Darwiche", "Pierre Marquis"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Tractable databases: How to make propositional unit resolution complete through compilation", "author": ["Alvaro del Val"], "venue": "In Proceedings of the 4th International Conference on Principles of Knowledge Representation and Reasoning", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1994}, {"title": "On some tractable classes in deduction and abduction", "author": ["Alvaro del Val"], "venue": "Artificial Intelligence,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2000}, {"title": "Translating pseudo-boolean constraints into SAT", "author": ["Niklas E\u00e9n", "Niklas S\u00f6rensson"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2006}, {"title": "Extending the knowledge compilation map: Krom, Horn, Affine and beyond", "author": ["H\u00e9l\u00e8ne Fargier", "Piere Marquis"], "venue": "ECAI 2008,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Polynomial\u2013time recognition of minimal unsatisfiable formulas with fixed clause\u2013variable difference", "author": ["Herbert Fleischner", "Oliver Kullmann", "Stefan Szeider"], "venue": "Theoretical Computer Science,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2002}, {"title": "A perspective on certain polynomial-time solvable classes of satisfiability", "author": ["John Franco", "Allen Van Gelder"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2003}, {"title": "Arc consistency in SAT", "author": ["Ian P. Gent"], "venue": "Proceedings of the 15th European Conference on Artificial Intelligence (ECAI", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2002}, {"title": "The propositional formula checker HeerHugo", "author": ["Jan Friso Groote", "Joost P. Warners"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2000}, {"title": "Towards a better understanding of hardness", "author": ["Matthew Gwynne", "Oliver Kullmann"], "venue": "In The Seventeenth International Conference on Principles and Practice of Constraint Programming (CP 2011): Doctoral Program Proceedings,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "Towards a better understanding of SAT translations", "author": ["Matthew Gwynne", "Oliver Kullmann"], "venue": "Logic and Computational Complexity (LCC\u201911),", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2011}, {"title": "Generalising and unifying SLUR and unit-refutation completeness", "author": ["Matthew Gwynne", "Oliver Kullmann"], "venue": "SOFSEM 2013: Theory and Practice of Computer Science,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}, {"title": "Generalising unit-refutation completeness and SLUR via nested input resolution", "author": ["Matthew Gwynne", "Oliver Kullmann"], "venue": "Technical Report arXiv:1204.6529v5 [cs.LO],", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2013}, {"title": "Generalising unit-refutation completeness and SLUR via nested input resolution", "author": ["Matthew Gwynne", "Oliver Kullmann"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2013}, {"title": "When boolean satisfiability meets Gaussian elimination in a Simplex way", "author": ["Cheng-Shen Han", "Jie-Hong Roland Jiang"], "venue": "Computer Aided Verification,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2012}, {"title": "St\u030aalmarck\u2019s algorithm as a HOL derived rule. In Theorem proving in higher order logics: 9th International Conference, TPHOLs\u201996", "author": ["John Harrison"], "venue": "Lecture Notes in Computer Science", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1996}, {"title": "Marcheq: Implementing additional reasoning into an efficient look-ahead SAT solver", "author": ["Marijn Heule", "Mark Dufour", "Joris van Zwieten", "Hans van Maaren"], "venue": "In Hoos and Mitchell", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2034}, {"title": "Limitations of restricted branching in clause", "author": ["Matti J\u00e4rvisalo", "Tommi Junttila"], "venue": "learning. Constraints,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2009}, {"title": "\u017divn\u00fd. Relating proof complexity measures and practical hardness of SAT", "author": ["Matti J\u00e4rvisalo", "Arie Matsliah", "Jakob Nordstr\u00f6m", "Stanislav"], "venue": "Principles and Practice of Constraint Programming - CP 2012,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2012}, {"title": "The effect of structural branching on the efficiency of clause learning SAT solving: An experimental study", "author": ["Matti J\u00e4rvisalo", "Ilkka Niemel\u00e4"], "venue": "Journal of Algorithms,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2008}, {"title": "Algebraic attacks using SAT-solvers", "author": ["Philipp Jovanovic", "Martin Kreuzer"], "venue": "Groups-Complexity-Cryptology,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2010}, {"title": "Two encodings of DNNF theories, July 2008. Presented at ECAI\u201908 Workshop on Inference methods based on Graphical Structures of Knowledge", "author": ["Jean Christoph Jung", "Pedro Barahoma", "George Katsirelos", "Toby Walsh"], "venue": "Proceedings at http://www.irit.fr/LC/", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2008}, {"title": "An incremental method for generating prime implicants/implicates", "author": ["Alex Kean", "George Tsiknis"], "venue": "Journal of Symbolic Computation,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1990}, {"title": "On generalized Horn formulas and k-resolution", "author": ["Hans Kleine B\u00fcning"], "venue": "Theoretical Computer Science,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1993}, {"title": "Investigating a general hierarchy of polynomially decidable classes of CNF\u2019s based on short tree-like resolution proofs", "author": ["Oliver Kullmann"], "venue": "Technical Report TR99-041, Electronic Colloquium on Computational Complexity (ECCC), October", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 1999}, {"title": "New methods for 3-SAT decision and worst-case analysis", "author": ["Oliver Kullmann"], "venue": "Theoretical Computer Science,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 1999}, {"title": "On a generalization of extended resolution", "author": ["Oliver Kullmann"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1999}, {"title": "An application of matroid theory to the SAT problem", "author": ["Oliver Kullmann"], "venue": "In Fifteenth Annual IEEE Conference on Computational Complexity", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2000}, {"title": "Investigating the behaviour of a SAT solver on random formulas", "author": ["Oliver Kullmann"], "venue": "Technical Report CSR 23-2002,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2002}, {"title": "The combinatorics of conflicts between clauses", "author": ["Oliver Kullmann"], "venue": "In Enrico Giunchiglia and Armando Tacchella, editors, Theory and Applications of Satisfiability Testing 2003,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2004}, {"title": "Upper and lower bounds on the complexity of generalised resolution and generalised constraint satisfaction problems", "author": ["Oliver Kullmann"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2004}, {"title": "Theory and Applications of Satisfiability Testing - SAT 2009, volume 5584 of Lecture", "author": ["Oliver Kullmann", "editor"], "venue": "Notes in Computer Science. Springer,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2009}, {"title": "Constraint satisfaction problems in clausal form II: Minimal unsatisfiability and conflict structure", "author": ["Oliver Kullmann"], "venue": "Fundamenta Informaticae,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2011}, {"title": "On Davis-Putnam reductions for minimally unsatisfiable clause-sets", "author": ["Oliver Kullmann", "Xishun Zhao"], "venue": "Technical Report arXiv:1202.2600v5 [cs.DM],", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2012}, {"title": "Conflict-driven XOR-clause learning", "author": ["Tero Laitinen", "Tommi Junttila", "Ilkka Niemel\u00e4"], "venue": "Theory and Applications of Satisfiability Testing SAT 2012, volume LNCS 7317 of Lecture Notes in Computer Science,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2012}, {"title": "Heuristics based on unit propagation for satisfiability problems", "author": ["Chu Min Li", "Anbulagan"], "venue": "In Proceedings of 15th International Joint Conference on Artificial Intelligence", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 1997}, {"title": "Computing minimally unsatisfiable subformulas: State of the art and future directions", "author": ["Joao Marques-Silva"], "venue": "Journal of Multiple-Valued Logic and Soft Computing,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2012}, {"title": "On the power of clause-learning SAT solvers with restarts", "author": ["Knot Pipatsrisawat", "Adnan Darwiche"], "venue": "Principles and Practice of Constraint Programming - CP 2009,", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2009}, {"title": "On the power of clause-learning SAT solvers as resolution engines", "author": ["Knot Pipatsrisawat", "Adnan Darwiche"], "venue": "Artificial Intelligence,", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2011}, {"title": "A structure-preserving clause form translation", "author": ["David A. Plaisted", "Steven Greenbaum"], "venue": "Journal of Symbolic Computation,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 1986}, {"title": "Hierarchies of polynomially solvable satisfiability problems", "author": ["Daniele Pretolani"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 1996}, {"title": "A tutorial on St\u030aalmarck\u2019s proof procedure for propositional logic", "author": ["Mary Sheeran", "Gunnar St\u030aalmarck"], "venue": "In FMCAD\u201998,", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 1998}, {"title": "Towards an optimal CNF encoding of boolean cardinality constraints", "author": ["Carsten Sinz"], "venue": "In Principles and Practice of Constraint Programming \u2013 CP 2005,", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2005}, {"title": "On k-term DNF with the largest number of prime implicants", "author": ["Robert H. Sloan", "Bal\u00e1zs S\u00f6r\u00e9nyi", "Gy\u00f6rgy Tur\u00e1n"], "venue": "SIAM Journal on Discrete Mathematics,", "citeRegEx": "75", "shortCiteRegEx": "75", "year": 2007}, {"title": "Cryptominisat 2.5.0", "author": ["Mate Soos"], "venue": "http://baldur.iti.uka.de/ sat-race-2010/descriptions/solver_13.pdf,", "citeRegEx": "76", "shortCiteRegEx": "76", "year": 2010}, {"title": "Enhanced Gaussian elimination in DPLL-based SAT solvers", "author": ["Mate Soos"], "venue": "Pragmatics of SAT,", "citeRegEx": "77", "shortCiteRegEx": "77", "year": 2010}, {"title": "Ein Satz \u00fcber Untermengen einer endlichen Menge", "author": ["Emanuel Sperner"], "venue": "Mathematische Zeitschrift,", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 1928}, {"title": "Modeling and verifying systems and software in propositional logic", "author": ["Gunnar St\u030aalmarck", "M. S\u00e4flund"], "venue": "Safety of Computer Control Systems", "citeRegEx": "81", "shortCiteRegEx": "81", "year": 1990}, {"title": "Compiling finite linear CSP into SAT", "author": ["Naoyuki Tamura", "Akiko Taga", "Satoshi Kitagawa", "Mutsunori Banbara"], "venue": null, "citeRegEx": "82", "shortCiteRegEx": "82", "year": 2009}, {"title": "A compact and efficient SAT-encoding of finite domain CSP", "author": ["Tomoya Tanjo", "Naoyuki Tamura", "Mutsunori Banbara"], "venue": "Theory and Applications of Satisfiability Testing - SAT 2011, volume LNCS 6695 of Lecture Notes in Computer Science,", "citeRegEx": "83", "shortCiteRegEx": "83", "year": 2011}, {"title": "The complexity of propositional proofs", "author": ["Alasdair Urquhart"], "venue": "The Bulletin of Symbolic Logic,", "citeRegEx": "84", "shortCiteRegEx": "84", "year": 1995}, {"title": "A short note on some tractable cases of the satisfiability problem", "author": ["Hans van Maaren"], "venue": "Information and Computation,", "citeRegEx": "85", "shortCiteRegEx": "85", "year": 2000}, {"title": "Classes of boolean formulae with effectively solvable SAT", "author": ["V. Vl\u010dek"], "venue": "In Jana Safrankova and Jiri Pavlu, editors, Proceedings of the 19th Annual Conference of Doctoral Students - WDS 2010,", "citeRegEx": "86", "shortCiteRegEx": "86", "year": 2010}], "referenceMentions": [{"referenceID": 30, "context": "The hierarchy UCk of unit-refutation complete clause-sets of level k, introduced in [36, 37, 38], provides the most basic target classes, that is, F \u2208 UCk is to be achieved for k as small as feasible.", "startOffset": 84, "endOffset": 96}, {"referenceID": 31, "context": "The hierarchy UCk of unit-refutation complete clause-sets of level k, introduced in [36, 37, 38], provides the most basic target classes, that is, F \u2208 UCk is to be achieved for k as small as feasible.", "startOffset": 84, "endOffset": 96}, {"referenceID": 32, "context": "The hierarchy UCk of unit-refutation complete clause-sets of level k, introduced in [36, 37, 38], provides the most basic target classes, that is, F \u2208 UCk is to be achieved for k as small as feasible.", "startOffset": 84, "endOffset": 96}, {"referenceID": 20, "context": "Here UC1 = UC has been introduced in [26] for the purpose of knowledge compilation.", "startOffset": 37, "endOffset": 41}, {"referenceID": 11, "context": "We also touch upon the hierarchy PCk of propagation complete clause-sets of level k, where PC1 = PC has been introduced in [15].", "startOffset": 123, "endOffset": 127}, {"referenceID": 2, "context": "See for example [4, 74, 28] for work on cardinality constraints, [82, 83] for work on general constraint translations, and [48, 35] for investigations into different translations in cryptography.", "startOffset": 16, "endOffset": 27}, {"referenceID": 61, "context": "See for example [4, 74, 28] for work on cardinality constraints, [82, 83] for work on general constraint translations, and [48, 35] for investigations into different translations in cryptography.", "startOffset": 16, "endOffset": 27}, {"referenceID": 22, "context": "See for example [4, 74, 28] for work on cardinality constraints, [82, 83] for work on general constraint translations, and [48, 35] for investigations into different translations in cryptography.", "startOffset": 16, "endOffset": 27}, {"referenceID": 67, "context": "See for example [4, 74, 28] for work on cardinality constraints, [82, 83] for work on general constraint translations, and [48, 35] for investigations into different translations in cryptography.", "startOffset": 65, "endOffset": 73}, {"referenceID": 68, "context": "See for example [4, 74, 28] for work on cardinality constraints, [82, 83] for work on general constraint translations, and [48, 35] for investigations into different translations in cryptography.", "startOffset": 65, "endOffset": 73}, {"referenceID": 39, "context": "See for example [4, 74, 28] for work on cardinality constraints, [82, 83] for work on general constraint translations, and [48, 35] for investigations into different translations in cryptography.", "startOffset": 123, "endOffset": 131}, {"referenceID": 29, "context": "See for example [4, 74, 28] for work on cardinality constraints, [82, 83] for work on general constraint translations, and [48, 35] for investigations into different translations in cryptography.", "startOffset": 123, "endOffset": 131}, {"referenceID": 26, "context": "7 in [72], while various casestudies can be found in [32, 4, 74, 28, 49, 5].", "startOffset": 53, "endOffset": 75}, {"referenceID": 2, "context": "7 in [72], while various casestudies can be found in [32, 4, 74, 28, 49, 5].", "startOffset": 53, "endOffset": 75}, {"referenceID": 61, "context": "7 in [72], while various casestudies can be found in [32, 4, 74, 28, 49, 5].", "startOffset": 53, "endOffset": 75}, {"referenceID": 22, "context": "7 in [72], while various casestudies can be found in [32, 4, 74, 28, 49, 5].", "startOffset": 53, "endOffset": 75}, {"referenceID": 40, "context": "7 in [72], while various casestudies can be found in [32, 4, 74, 28, 49, 5].", "startOffset": 53, "endOffset": 75}, {"referenceID": 11, "context": "In a similar vein, there is the class PC of propagation-complete clause-sets (see [15]), containing all clause-sets for which unit-clause propagation is sufficient to detect all forced assignments.", "startOffset": 82, "endOffset": 86}, {"referenceID": 36, "context": "In [45] it is shown that conflict-driven solvers with branching restricted to input variables have only superpolynomial run-time on EPHPn, an Extended Resolution", "startOffset": 3, "endOffset": 7}, {"referenceID": 38, "context": "Also experimentally it is demonstrated in [47] that input-restricted branching can have a detrimental effect on solver times and proof sizes for modern CDCL solvers.", "startOffset": 42, "endOffset": 46}, {"referenceID": 30, "context": "Motivated by the absolute condition, in [36, 37, 38] we considered the somewhat more fundamental class UC of refutation complete clause-sets, introduced in [26] as a method for propositional knowledge compilation, and studied its properties.", "startOffset": 40, "endOffset": 52}, {"referenceID": 31, "context": "Motivated by the absolute condition, in [36, 37, 38] we considered the somewhat more fundamental class UC of refutation complete clause-sets, introduced in [26] as a method for propositional knowledge compilation, and studied its properties.", "startOffset": 40, "endOffset": 52}, {"referenceID": 32, "context": "Motivated by the absolute condition, in [36, 37, 38] we considered the somewhat more fundamental class UC of refutation complete clause-sets, introduced in [26] as a method for propositional knowledge compilation, and studied its properties.", "startOffset": 40, "endOffset": 52}, {"referenceID": 20, "context": "Motivated by the absolute condition, in [36, 37, 38] we considered the somewhat more fundamental class UC of refutation complete clause-sets, introduced in [26] as a method for propositional knowledge compilation, and studied its properties.", "startOffset": 156, "endOffset": 160}, {"referenceID": 30, "context": "In [36, 37, 38], using generalised unit-clause propagation rk (with r1 being UCP) introduced in [53, 59], we developed a hierarchy UCk (with UC1 = UC) of clause-sets of \u201chardness\u201d at most k, that is, refutation is (always) possible via rk.", "startOffset": 3, "endOffset": 15}, {"referenceID": 31, "context": "In [36, 37, 38], using generalised unit-clause propagation rk (with r1 being UCP) introduced in [53, 59], we developed a hierarchy UCk (with UC1 = UC) of clause-sets of \u201chardness\u201d at most k, that is, refutation is (always) possible via rk.", "startOffset": 3, "endOffset": 15}, {"referenceID": 32, "context": "In [36, 37, 38], using generalised unit-clause propagation rk (with r1 being UCP) introduced in [53, 59], we developed a hierarchy UCk (with UC1 = UC) of clause-sets of \u201chardness\u201d at most k, that is, refutation is (always) possible via rk.", "startOffset": 3, "endOffset": 15}, {"referenceID": 43, "context": "In [36, 37, 38], using generalised unit-clause propagation rk (with r1 being UCP) introduced in [53, 59], we developed a hierarchy UCk (with UC1 = UC) of clause-sets of \u201chardness\u201d at most k, that is, refutation is (always) possible via rk.", "startOffset": 96, "endOffset": 104}, {"referenceID": 49, "context": "In [36, 37, 38], using generalised unit-clause propagation rk (with r1 being UCP) introduced in [53, 59], we developed a hierarchy UCk (with UC1 = UC) of clause-sets of \u201chardness\u201d at most k, that is, refutation is (always) possible via rk.", "startOffset": 96, "endOffset": 104}, {"referenceID": 31, "context": "5 of [37, 38] that various poly-time solvable SAT classes are contained within levels of the UCk hierarchy.", "startOffset": 5, "endOffset": 13}, {"referenceID": 32, "context": "5 of [37, 38] that various poly-time solvable SAT classes are contained within levels of the UCk hierarchy.", "startOffset": 5, "endOffset": 13}, {"referenceID": 17, "context": "2 in [22] and [85]) and HOk \u2282 UCk (generalised Horn clause-sets, see [51]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 70, "context": "2 in [22] and [85]) and HOk \u2282 UCk (generalised Horn clause-sets, see [51]).", "startOffset": 14, "endOffset": 18}, {"referenceID": 42, "context": "2 in [22] and [85]) and HOk \u2282 UCk (generalised Horn clause-sets, see [51]).", "startOffset": 69, "endOffset": 73}, {"referenceID": 37, "context": "In [46] the argument is made that tree-resolution complexity can not provide a good measure of hardness of instances for SAT solving, citing the ability of CDCL solvers to simulate exponentially more powerful full resolution (see [2] for evidence that CDCL solvers can simulate full resolution).", "startOffset": 3, "endOffset": 7}, {"referenceID": 31, "context": "On the other hand, for tighter target classes in the case of full resolution, we also consider the notion of width-hardness as introduced in [37, 38], based on the", "startOffset": 141, "endOffset": 149}, {"referenceID": 32, "context": "On the other hand, for tighter target classes in the case of full resolution, we also consider the notion of width-hardness as introduced in [37, 38], based on the", "startOffset": 141, "endOffset": 149}, {"referenceID": 43, "context": "width-based hierarchies of unsatisfiable clause-sets in [53, 59].", "startOffset": 56, "endOffset": 64}, {"referenceID": 49, "context": "width-based hierarchies of unsatisfiable clause-sets in [53, 59].", "startOffset": 56, "endOffset": 64}, {"referenceID": 42, "context": "That is, a clause-set is in WCk, the hierarchy of clause-sets of width-hardness k, iff under any partial assignment resulting in an unsatisfiable clause-set there is a \u201ck-resolution\u201d refutation as introduced in [51].", "startOffset": 211, "endOffset": 215}, {"referenceID": 21, "context": "A precursor A generalisation of UC was already discussed in [27].", "startOffset": 60, "endOffset": 64}, {"referenceID": 21, "context": "[27] continues by considering the (generic) hierarchy (\u03a0k)k\u2208N0 from [71], a precursor of [53].", "startOffset": 0, "endOffset": 4}, {"referenceID": 59, "context": "[27] continues by considering the (generic) hierarchy (\u03a0k)k\u2208N0 from [71], a precursor of [53].", "startOffset": 68, "endOffset": 72}, {"referenceID": 43, "context": "[27] continues by considering the (generic) hierarchy (\u03a0k)k\u2208N0 from [71], a precursor of [53].", "startOffset": 89, "endOffset": 93}, {"referenceID": 59, "context": "However this choice for \u03a00 was never considered for that hierarchy from [71], which might have two reasons: Implicit preference is given to classes \u03a00 closed under sub-clause-set formation (see Section 6.", "startOffset": 72, "endOffset": 76}, {"referenceID": 32, "context": "3 in [38] for more discussions on this issue).", "startOffset": 5, "endOffset": 9}, {"referenceID": 59, "context": "And furthermore SAT and UNSAT is not distinguished in [71] and in subsequent work directly relying on it; see Subsection 1.", "startOffset": 54, "endOffset": 58}, {"referenceID": 43, "context": "2 in [53] for a discussion of this.", "startOffset": 5, "endOffset": 9}, {"referenceID": 21, "context": "So the four choices for \u03a00 considered in [27] are HO, 2\u2013CLS, RHO and QHO.", "startOffset": 41, "endOffset": 45}, {"referenceID": 21, "context": "Due to these weaknesses, [27] does not consider a hierarchy generalising UC.", "startOffset": 25, "endOffset": 29}, {"referenceID": 32, "context": "3 in [38] for results in this direction.", "startOffset": 5, "endOffset": 9}, {"referenceID": 21, "context": "1)[27] actually favours adding unit-clauses to F , but we consider applying partial assignments as more fundamental.", "startOffset": 2, "endOffset": 6}, {"referenceID": 14, "context": "[18] gives an overview of the CNF-based target languages (prime implicates, UC, 2\u2013CLS, Horn clause-sets).", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[29] consider disjunctions of simple CNF classes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[25] provides an overview of target compilation languages based on \u201cnested\u201d (graph-based) classes, namely variants of NNF, DNNF and BDDs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "All of the CNF classes studied in [18, 25, 29] are included at the first three levels of the hierarchy UCk, namely, sets of prime implicates in UC0, (renamable) Horn clausesets in UC1 = UC, and 2\u2013CLS in UC2.", "startOffset": 34, "endOffset": 46}, {"referenceID": 19, "context": "All of the CNF classes studied in [18, 25, 29] are included at the first three levels of the hierarchy UCk, namely, sets of prime implicates in UC0, (renamable) Horn clausesets in UC1 = UC, and 2\u2013CLS in UC2.", "startOffset": 34, "endOffset": 46}, {"referenceID": 23, "context": "All of the CNF classes studied in [18, 25, 29] are included at the first three levels of the hierarchy UCk, namely, sets of prime implicates in UC0, (renamable) Horn clausesets in UC1 = UC, and 2\u2013CLS in UC2.", "startOffset": 34, "endOffset": 46}, {"referenceID": 40, "context": "And see [49] for a basic negative result, characterising what can be represented under the relative condition (i.", "startOffset": 8, "endOffset": 12}, {"referenceID": 55, "context": "The notion of minimal unsatisfiability (MU) and minimally unsatisfiable subsets (MUS) is important in understanding the combinatorics of unsatisfiable clause-sets (see [52, 66]).", "startOffset": 168, "endOffset": 176}, {"referenceID": 51, "context": "To understand the structure of satisfiable clause-sets and their associated boolean functions, we now consider the concept of \u201cminimal premise sets\u201d (MPS) introduced in [62].", "startOffset": 169, "endOffset": 173}, {"referenceID": 62, "context": "[75] introduced a special type of boolean functions, called Non-repeating Unate Decision trees (NUD) there, by adding new variables to each clause of clause-sets in SMU\u03b4=1, which is the class of unsatisfiable hitting clause-sets of deficiency \u03b4 = 1.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "In [26] (Example 2) a separation was already shown between UC0 (clause-sets containing all of their prime implicates) and UC1 = UC, and the question was raised of the worst-case growth when compiling from an arbitrary CNF clause-set F to some equivalent F \u2032 \u2208 UC.", "startOffset": 3, "endOffset": 7}, {"referenceID": 5, "context": "This question was partly answered in [8] (although the connection was not made), where the authors provide examples of poly-size clausesets with only super-polynomial size representations in UC, even when allowing new variables (see Subsections 7.", "startOffset": 37, "endOffset": 40}, {"referenceID": 6, "context": "5, and [9] for more on the connection between [8] and UCk).", "startOffset": 7, "endOffset": 10}, {"referenceID": 5, "context": "5, and [9] for more on the connection between [8] and UCk).", "startOffset": 46, "endOffset": 49}, {"referenceID": 20, "context": "Our separation result now answers the question of worst-case growth from [26] in full generality with the hierarchy UCk.", "startOffset": 73, "endOffset": 77}, {"referenceID": 20, "context": "This separation, between UCk+1 and UCk for arbitrary k, is more involved than the simple separation in [26], due to the parameterised use of more advanced polynomial-time methods than r1 (UCP).", "startOffset": 103, "endOffset": 107}, {"referenceID": 47, "context": "Especially r2, which is (complete) failed-literal elimination, is used in look-ahead SAT solvers (see [42] for an overview) such as OKsolver ([57]), march ([41]) and Satz ([65]).", "startOffset": 142, "endOffset": 146}, {"referenceID": 35, "context": "Especially r2, which is (complete) failed-literal elimination, is used in look-ahead SAT solvers (see [42] for an overview) such as OKsolver ([57]), march ([41]) and Satz ([65]).", "startOffset": 156, "endOffset": 160}, {"referenceID": 54, "context": "Especially r2, which is (complete) failed-literal elimination, is used in look-ahead SAT solvers (see [42] for an overview) such as OKsolver ([57]), march ([41]) and Satz ([65]).", "startOffset": 172, "endOffset": 176}, {"referenceID": 63, "context": "Also conflict-driven solvers such as CryptoMiniSat ([76]) and PicoSAT ([10, 12]) integrate r2 during search, and solvers such as Lingeling ([12, 13]) use r2 as a preprocessing technique.", "startOffset": 52, "endOffset": 56}, {"referenceID": 7, "context": "Also conflict-driven solvers such as CryptoMiniSat ([76]) and PicoSAT ([10, 12]) integrate r2 during search, and solvers such as Lingeling ([12, 13]) use r2 as a preprocessing technique.", "startOffset": 71, "endOffset": 79}, {"referenceID": 8, "context": "Also conflict-driven solvers such as CryptoMiniSat ([76]) and PicoSAT ([10, 12]) integrate r2 during search, and solvers such as Lingeling ([12, 13]) use r2 as a preprocessing technique.", "startOffset": 71, "endOffset": 79}, {"referenceID": 8, "context": "Also conflict-driven solvers such as CryptoMiniSat ([76]) and PicoSAT ([10, 12]) integrate r2 during search, and solvers such as Lingeling ([12, 13]) use r2 as a preprocessing technique.", "startOffset": 140, "endOffset": 148}, {"referenceID": 9, "context": "Also conflict-driven solvers such as CryptoMiniSat ([76]) and PicoSAT ([10, 12]) integrate r2 during search, and solvers such as Lingeling ([12, 13]) use r2 as a preprocessing technique.", "startOffset": 140, "endOffset": 148}, {"referenceID": 66, "context": "Furthermore, in general rk is used, in even stronger versions, in the St\u030aalmarck-solver (see [81, 40, 73], and see Section 3.", "startOffset": 93, "endOffset": 105}, {"referenceID": 34, "context": "Furthermore, in general rk is used, in even stronger versions, in the St\u030aalmarck-solver (see [81, 40, 73], and see Section 3.", "startOffset": 93, "endOffset": 105}, {"referenceID": 60, "context": "Furthermore, in general rk is used, in even stronger versions, in the St\u030aalmarck-solver (see [81, 40, 73], and see Section 3.", "startOffset": 93, "endOffset": 105}, {"referenceID": 43, "context": "5 of [53] for a discussion of the connections to rk), and via breadth-first \u201cbranch/merge\u201d rules in HeerHugo (see [33]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 27, "context": "5 of [53] for a discussion of the connections to rk), and via breadth-first \u201cbranch/merge\u201d rules in HeerHugo (see [33]).", "startOffset": 114, "endOffset": 118}, {"referenceID": 56, "context": "In [68, 69] it is argued that modern SAT solvers can simulate full resolution \u2014 and this is considered to be a good property of SAT solvers.", "startOffset": 3, "endOffset": 11}, {"referenceID": 57, "context": "In [68, 69] it is argued that modern SAT solvers can simulate full resolution \u2014 and this is considered to be a good property of SAT solvers.", "startOffset": 3, "endOffset": 11}, {"referenceID": 58, "context": "It has been noted in the literature at several places (see [70, 44, 28]), that one might use only one of the two directions of the equivalences in the Tseitintranslation.", "startOffset": 59, "endOffset": 71}, {"referenceID": 22, "context": "It has been noted in the literature at several places (see [70, 44, 28]), that one might use only one of the two directions of the equivalences in the Tseitintranslation.", "startOffset": 59, "endOffset": 71}, {"referenceID": 31, "context": "5 of [37, 38] discusses the translation of the so-called \u201cSchaefer classes\u201d into the UCk hierarchy; see Section 12.", "startOffset": 5, "endOffset": 13}, {"referenceID": 32, "context": "5 of [37, 38] discusses the translation of the so-called \u201cSchaefer classes\u201d into the UCk hierarchy; see Section 12.", "startOffset": 5, "endOffset": 13}, {"referenceID": 18, "context": "2 in [24] for an introduction, and see [23] for an in-depth overview on recent developments.", "startOffset": 39, "endOffset": 43}, {"referenceID": 43, "context": "In what respect is the terminology \u201chardness\u201d appropriate? The hardness measure hd(F ) has been introduced in [53, 59], based on quasi-automatisation of tree-resolution, that is, on a specific algorithmic approach (close to St\u030aalmarcks approach).", "startOffset": 110, "endOffset": 118}, {"referenceID": 49, "context": "In what respect is the terminology \u201chardness\u201d appropriate? The hardness measure hd(F ) has been introduced in [53, 59], based on quasi-automatisation of tree-resolution, that is, on a specific algorithmic approach (close to St\u030aalmarcks approach).", "startOffset": 110, "endOffset": 118}, {"referenceID": 0, "context": "In [1], hd(F ) for unsatisfiable F was proposed as measure of SAT-solverhardness in general.", "startOffset": 3, "endOffset": 6}, {"referenceID": 37, "context": "This was criticised in [46] by the argument, that conflict-driven SAT solvers would be closer to dag-resolution (full resolution) than tree-resolution.", "startOffset": 23, "endOffset": 27}, {"referenceID": 43, "context": "The main results on size lower bounds for the hardness are: 4)Using the simplest oracle, on unsatisfiable instances the measure from [53, 59] yields hd(F ).", "startOffset": 133, "endOffset": 141}, {"referenceID": 49, "context": "The main results on size lower bounds for the hardness are: 4)Using the simplest oracle, on unsatisfiable instances the measure from [53, 59] yields hd(F ).", "startOffset": 133, "endOffset": 141}, {"referenceID": 43, "context": "But on satisfiable instances the approach of [53, 59] is very different, namely an algorithmic polynomial-time approach is taken, extending the breadth-first search for tree-resolution refutations in a natural way.", "startOffset": 45, "endOffset": 53}, {"referenceID": 49, "context": "But on satisfiable instances the approach of [53, 59] is very different, namely an algorithmic polynomial-time approach is taken, extending the breadth-first search for tree-resolution refutations in a natural way.", "startOffset": 45, "endOffset": 53}, {"referenceID": 17, "context": "Note that by the de Morgan rules from the CNF-formula we obtain the DNFformula via negating the whole formula together with negating the literals (in other words, the underlying boolean function of a CNF-clause-set F is the \u201cdual\u201d of the underlying boolean function of the DNF-clause-set F ; see [22]).", "startOffset": 296, "endOffset": 300}, {"referenceID": 17, "context": "1 The clause-set F = {{v}} has the equivalent DNF-clause-set F = {{v}} (the underlying boolean function is \u201cself-dual\u201d; see [22]), while the negation is {{v}}.", "startOffset": 124, "endOffset": 128}, {"referenceID": 43, "context": "It is mostly of an expository nature, explaining what we need from [53, 59, 36, 37, 38], with some additional remarks.", "startOffset": 67, "endOffset": 87}, {"referenceID": 49, "context": "It is mostly of an expository nature, explaining what we need from [53, 59, 36, 37, 38], with some additional remarks.", "startOffset": 67, "endOffset": 87}, {"referenceID": 30, "context": "It is mostly of an expository nature, explaining what we need from [53, 59, 36, 37, 38], with some additional remarks.", "startOffset": 67, "endOffset": 87}, {"referenceID": 31, "context": "It is mostly of an expository nature, explaining what we need from [53, 59, 36, 37, 38], with some additional remarks.", "startOffset": 67, "endOffset": 87}, {"referenceID": 32, "context": "It is mostly of an expository nature, explaining what we need from [53, 59, 36, 37, 38], with some additional remarks.", "startOffset": 67, "endOffset": 87}, {"referenceID": 43, "context": "Hardness for unsatisfiable clause-sets was introduced in [53, 59], while this generalisation to arbitrary clause-sets was first mentioned in [1], and systematically studied in [36, 37, 38].", "startOffset": 57, "endOffset": 65}, {"referenceID": 49, "context": "Hardness for unsatisfiable clause-sets was introduced in [53, 59], while this generalisation to arbitrary clause-sets was first mentioned in [1], and systematically studied in [36, 37, 38].", "startOffset": 57, "endOffset": 65}, {"referenceID": 0, "context": "Hardness for unsatisfiable clause-sets was introduced in [53, 59], while this generalisation to arbitrary clause-sets was first mentioned in [1], and systematically studied in [36, 37, 38].", "startOffset": 141, "endOffset": 144}, {"referenceID": 30, "context": "Hardness for unsatisfiable clause-sets was introduced in [53, 59], while this generalisation to arbitrary clause-sets was first mentioned in [1], and systematically studied in [36, 37, 38].", "startOffset": 176, "endOffset": 188}, {"referenceID": 31, "context": "Hardness for unsatisfiable clause-sets was introduced in [53, 59], while this generalisation to arbitrary clause-sets was first mentioned in [1], and systematically studied in [36, 37, 38].", "startOffset": 176, "endOffset": 188}, {"referenceID": 32, "context": "Hardness for unsatisfiable clause-sets was introduced in [53, 59], while this generalisation to arbitrary clause-sets was first mentioned in [1], and systematically studied in [36, 37, 38].", "startOffset": 176, "endOffset": 188}, {"referenceID": 30, "context": "3 defines hardness proof-theoretically; importantly, it can also be characterised algorithmically via necessary levels of generalised unit-clause propagation (see [36, 37, 38] for the details):", "startOffset": 163, "endOffset": 175}, {"referenceID": 31, "context": "3 defines hardness proof-theoretically; importantly, it can also be characterised algorithmically via necessary levels of generalised unit-clause propagation (see [36, 37, 38] for the details):", "startOffset": 163, "endOffset": 175}, {"referenceID": 32, "context": "3 defines hardness proof-theoretically; importantly, it can also be characterised algorithmically via necessary levels of generalised unit-clause propagation (see [36, 37, 38] for the details):", "startOffset": 163, "endOffset": 175}, {"referenceID": 43, "context": "4 Consider the reductions rk : CLS \u2192 CLS for k \u2208 N0 as introduced in [53]; it is r1 unit-clause propagation, while r2 is (full, iterated) failed-literal elimination.", "startOffset": 69, "endOffset": 73}, {"referenceID": 20, "context": "UC1 = UC is the class of unit-refutation complete clause-sets, as introduced in [26].", "startOffset": 80, "endOffset": 84}, {"referenceID": 30, "context": "In [36, 37, 38] we show that UC = SLUR, where SLUR is the class of clause-sets solvable via Single Lookahead Unit Resolution (see [31]).", "startOffset": 3, "endOffset": 15}, {"referenceID": 31, "context": "In [36, 37, 38] we show that UC = SLUR, where SLUR is the class of clause-sets solvable via Single Lookahead Unit Resolution (see [31]).", "startOffset": 3, "endOffset": 15}, {"referenceID": 32, "context": "In [36, 37, 38] we show that UC = SLUR, where SLUR is the class of clause-sets solvable via Single Lookahead Unit Resolution (see [31]).", "startOffset": 3, "endOffset": 15}, {"referenceID": 25, "context": "In [36, 37, 38] we show that UC = SLUR, where SLUR is the class of clause-sets solvable via Single Lookahead Unit Resolution (see [31]).", "startOffset": 130, "endOffset": 134}, {"referenceID": 15, "context": "Using [19] we then obtain ([36, 37, 38]) that membership decision for UCk (= SLURk) is coNP-complete for k \u2265 1.", "startOffset": 6, "endOffset": 10}, {"referenceID": 30, "context": "Using [19] we then obtain ([36, 37, 38]) that membership decision for UCk (= SLURk) is coNP-complete for k \u2265 1.", "startOffset": 27, "endOffset": 39}, {"referenceID": 31, "context": "Using [19] we then obtain ([36, 37, 38]) that membership decision for UCk (= SLURk) is coNP-complete for k \u2265 1.", "startOffset": 27, "endOffset": 39}, {"referenceID": 32, "context": "Using [19] we then obtain ([36, 37, 38]) that membership decision for UCk (= SLURk) is coNP-complete for k \u2265 1.", "startOffset": 27, "endOffset": 39}, {"referenceID": 43, "context": "2 of [53].", "startOffset": 5, "endOffset": 9}, {"referenceID": 43, "context": "17 from [53], sufficient for our purposes, is as follows (with a technical correction, as explained in Example 3.", "startOffset": 8, "endOffset": 12}, {"referenceID": 43, "context": "17 in [53] doesn\u2019t state the condition (i) from Lemma 3.", "startOffset": 6, "endOffset": 10}, {"referenceID": 43, "context": "The following example shows that this condition actually needs to be stated (that is, if we just have (ii) and (iii), then h doesn\u2019t need to be a lower bound for hd); fortunately in all applications in [53] this (natural) condition is fulfilled.", "startOffset": 202, "endOffset": 206}, {"referenceID": 57, "context": "Complementary to \u201cunit-refutation completeness\u201d, there is the notion of \u201cpropagation-completeness\u201d as investigated in [69, 15], yielding the class PC \u2282 UC.", "startOffset": 118, "endOffset": 126}, {"referenceID": 11, "context": "Complementary to \u201cunit-refutation completeness\u201d, there is the notion of \u201cpropagation-completeness\u201d as investigated in [69, 15], yielding the class PC \u2282 UC.", "startOffset": 118, "endOffset": 126}, {"referenceID": 31, "context": "This was captured and generalised by a measure phd : CLS \u2192 N0 of \u201cpropagationhardness\u201d along with the associated hierarchy, defined in [37, 38] as follows:", "startOffset": 135, "endOffset": 143}, {"referenceID": 32, "context": "This was captured and generalised by a measure phd : CLS \u2192 N0 of \u201cpropagationhardness\u201d along with the associated hierarchy, defined in [37, 38] as follows:", "startOffset": 135, "endOffset": 143}, {"referenceID": 43, "context": "8 For F \u2208 CLS we define the propagation-hardness (for short \u201cp-hardness\u201d) phd(F ) \u2208 N0 as the minimal k \u2208 N0 such that for all partial assignments \u03c6 \u2208 PASS we have rk(\u03c6 \u2217 F ) = r\u221e(\u03c6 \u2217 F ), where rk : CLS \u2192 CLS is generalised UCP ([53, 59]), and r\u221e : CLS \u2192 CLS applies all forced assignments, and can be defined by r\u221e(F ) := rn(F )(F ).", "startOffset": 230, "endOffset": 238}, {"referenceID": 49, "context": "8 For F \u2208 CLS we define the propagation-hardness (for short \u201cp-hardness\u201d) phd(F ) \u2208 N0 as the minimal k \u2208 N0 such that for all partial assignments \u03c6 \u2208 PASS we have rk(\u03c6 \u2217 F ) = r\u221e(\u03c6 \u2217 F ), where rk : CLS \u2192 CLS is generalised UCP ([53, 59]), and r\u221e : CLS \u2192 CLS applies all forced assignments, and can be defined by r\u221e(F ) := rn(F )(F ).", "startOffset": 230, "endOffset": 238}, {"referenceID": 4, "context": "A basic weakness of the standard notion of width-restricted resolution, which demands that both parent clauses must have length at most k for some fixed k \u2208 N0 (the \u201cwidth\u201d; see [7]), is that even Horn clause-sets require unbounded width in this sense.", "startOffset": 178, "endOffset": 181}, {"referenceID": 43, "context": "The correct solution, as investigated and discussed in [53, 59], is to use the notion of \u201ck-resolution\u201d as introduced in [51], where only one parent clause needs to have length at most k (thus properly generalising unit-resolution).", "startOffset": 55, "endOffset": 63}, {"referenceID": 49, "context": "The correct solution, as investigated and discussed in [53, 59], is to use the notion of \u201ck-resolution\u201d as introduced in [51], where only one parent clause needs to have length at most k (thus properly generalising unit-resolution).", "startOffset": 55, "endOffset": 63}, {"referenceID": 42, "context": "The correct solution, as investigated and discussed in [53, 59], is to use the notion of \u201ck-resolution\u201d as introduced in [51], where only one parent clause needs to have length at most k (thus properly generalising unit-resolution).", "startOffset": 121, "endOffset": 125}, {"referenceID": 43, "context": "Nested input-resolution ([53, 59]) is the proof-theoretic basis of hardness, and approximates tree-resolution.", "startOffset": 25, "endOffset": 33}, {"referenceID": 49, "context": "Nested input-resolution ([53, 59]) is the proof-theoretic basis of hardness, and approximates tree-resolution.", "startOffset": 25, "endOffset": 33}, {"referenceID": 49, "context": "12 in [59]):", "startOffset": 6, "endOffset": 10}, {"referenceID": 43, "context": "2 in [53], and is a special case of widU introduced in Subsection 6.", "startOffset": 5, "endOffset": 9}, {"referenceID": 49, "context": "1 of [59]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 49, "context": "8 in [59] for unsatisfiable clause-sets, which extends to satisfiable clausesets by definition).", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "For unsatisfiable F , whether whd(F ) = k holds for k \u2208 {0, 1, 2} can be decided in polynomial time; this is non-trivial for k = 2 ([17]) and unknown for k > 2.", "startOffset": 132, "endOffset": 136}, {"referenceID": 49, "context": "5 of [59], by actually using a slight strengthening of k-resolution, which combines width-bounded resolution and input resolution.", "startOffset": 5, "endOffset": 9}, {"referenceID": 49, "context": "12 in [59] we obtain for F \u2208 USAT , n(F ) 6= 0, the following general lower bound on resolution complexity:", "startOffset": 6, "endOffset": 10}, {"referenceID": 30, "context": "Similar to Theorem 14 in [36] resp.", "startOffset": 25, "endOffset": 29}, {"referenceID": 31, "context": "7 in [37, 38] we thus obtain:", "startOffset": 5, "endOffset": 13}, {"referenceID": 32, "context": "7 in [37, 38] we thus obtain:", "startOffset": 5, "endOffset": 13}, {"referenceID": 51, "context": "In this section we study \u201cminimal premise sets\u201d, \u201cmps\u2019s\u201d for short, introduced in [62], together with the properties of \u201cdoped\u201d clause-sets, generalising a construction used in [75].", "startOffset": 82, "endOffset": 86}, {"referenceID": 62, "context": "In this section we study \u201cminimal premise sets\u201d, \u201cmps\u2019s\u201d for short, introduced in [62], together with the properties of \u201cdoped\u201d clause-sets, generalising a construction used in [75].", "startOffset": 177, "endOffset": 181}, {"referenceID": 51, "context": "1 in [62] basic properties of minimal premise sets are considered:", "startOffset": 5, "endOffset": 9}, {"referenceID": 51, "context": "5 in [62] we see that no clause-set can minimally entail more than one clause:", "startOffset": 5, "endOffset": 9}, {"referenceID": 51, "context": "4 in [62] we get the main characterisation of mps\u2019s, namely that after elimination of pure literals they must be minimally unsatisfiable:", "startOffset": 5, "endOffset": 9}, {"referenceID": 55, "context": "For unsatisfiable clause-sets the set of minimally unsatisfiable sub-clause-sets has been studied extensively in the literature; see [66] for a recent overview.", "startOffset": 133, "endOffset": 137}, {"referenceID": 51, "context": "6 of [62], misplacing the \u201c\u22121\u201d into the exponent.", "startOffset": 5, "endOffset": 9}, {"referenceID": 31, "context": "5 in [37, 38], all UCk are closed under partial assignments, so for \u03c6 := \u3008u\u22a5 \u2192 1\u3009\u222a\u3008uC \u2192 0 | C \u2208 F \u2032\u3009 we have hd(D(F )) \u2265 hd(\u03c6 \u2217D(F )) = hd(F \u2032) > hd(F ) = 0.", "startOffset": 5, "endOffset": 13}, {"referenceID": 32, "context": "5 in [37, 38], all UCk are closed under partial assignments, so for \u03c6 := \u3008u\u22a5 \u2192 1\u3009\u222a\u3008uC \u2192 0 | C \u2208 F \u2032\u3009 we have hd(D(F )) \u2265 hd(\u03c6 \u2217D(F )) = hd(F \u2032) > hd(F ) = 0.", "startOffset": 5, "endOffset": 13}, {"referenceID": 46, "context": "In [56] (generalised in [62]) it is shown that the elements of SMU\u03b4=1 are exactly the clause-sets introduced in [21].", "startOffset": 3, "endOffset": 7}, {"referenceID": 51, "context": "In [56] (generalised in [62]) it is shown that the elements of SMU\u03b4=1 are exactly the clause-sets introduced in [21].", "startOffset": 24, "endOffset": 28}, {"referenceID": 16, "context": "In [56] (generalised in [62]) it is shown that the elements of SMU\u03b4=1 are exactly the clause-sets introduced in [21].", "startOffset": 112, "endOffset": 116}, {"referenceID": 46, "context": "5 in [56]:", "startOffset": 5, "endOffset": 9}, {"referenceID": 52, "context": "It is well-known that UHIT \u2282 SMU holds (for a proof see Lemma 2 in [63]).", "startOffset": 67, "endOffset": 71}, {"referenceID": 48, "context": "In [58], Corollary 34, it was shown that that an unsatisfiable clause-sets F has precisely one clash between any pair of different clause-sets iff F \u2208 SMU\u03b4=1 holds (an alternative proof was found in [75]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 62, "context": "In [58], Corollary 34, it was shown that that an unsatisfiable clause-sets F has precisely one clash between any pair of different clause-sets iff F \u2208 SMU\u03b4=1 holds (an alternative proof was found in [75]).", "startOffset": 199, "endOffset": 203}, {"referenceID": 48, "context": "Now assume F \u2208 SMU\u03b4=1, and we have to show that F 6)In [58] the notation \u201cUHIT \u201d was used to denote \u201cuniform hitting clause-sets\u201d, which is now more appropriately called \u201c(conflict-)regular hitting clause-sets\u201d, while \u201cU\u201d now stands for \u201cunsatisfiable\u201d.", "startOffset": 55, "endOffset": 59}, {"referenceID": 51, "context": "14 That every 2-element sub-clause-set of F \u2208 CLS is an mps, that is, every two (different) clauses of F clash in precisely one literal, says that F is 1-regular hitting in the terminology of [62], Section 6.", "startOffset": 192, "endOffset": 196}, {"referenceID": 48, "context": "For an interesting example with deficiency 1 see Section 5 in [58].", "startOffset": 62, "endOffset": 66}, {"referenceID": 62, "context": "We arrive at a simple and perspicuous proof of the main result of [75], that the clause-sets F with |prc0(F )| = 2 ) \u2212 1 are precisely the clause-sets D(F ) for F \u2208 SMU\u03b4=1 when allowing to replace the single doping variable of a clause by any non-empty set of new (pure) literals:", "startOffset": 66, "endOffset": 70}, {"referenceID": 31, "context": "2 of [37, 38] we have prc0(F ) = F .", "startOffset": 5, "endOffset": 13}, {"referenceID": 32, "context": "2 of [37, 38] we have prc0(F ) = F .", "startOffset": 5, "endOffset": 13}, {"referenceID": 31, "context": "2 of [37, 38].", "startOffset": 5, "endOffset": 13}, {"referenceID": 32, "context": "2 of [37, 38].", "startOffset": 5, "endOffset": 13}, {"referenceID": 49, "context": "1 in [59].", "startOffset": 5, "endOffset": 9}, {"referenceID": 20, "context": "A simple example demonstrates the separation between UC0 and UC1 (similar to [26], Example 2, which uses Example 6.", "startOffset": 77, "endOffset": 81}, {"referenceID": 41, "context": "1 from [50]):", "startOffset": 7, "endOffset": 11}, {"referenceID": 41, "context": "1 from [50]:", "startOffset": 7, "endOffset": 11}, {"referenceID": 65, "context": "By Sperner\u2019s Theorem ([80]) holds |S0| \u2264 M , and this upper bound M is realised, just observing the antichain-condition, by choosing for S0 the set ( lvs(T0) m\u2032 ) of subsets of lvs(T0) of size m \u2032.", "startOffset": 22, "endOffset": 26}, {"referenceID": 31, "context": "1 from [37, 38] that UCk, and indeed also WCk, is a proper hierarchy of boolean functions regarding polysize representations without new variables (see Subsection 7.", "startOffset": 7, "endOffset": 15}, {"referenceID": 32, "context": "1 from [37, 38] that UCk, and indeed also WCk, is a proper hierarchy of boolean functions regarding polysize representations without new variables (see Subsection 7.", "startOffset": 7, "endOffset": 15}, {"referenceID": 31, "context": "2 of [37, 38] we discussed representations of boolean functions in general.", "startOffset": 5, "endOffset": 13}, {"referenceID": 32, "context": "2 of [37, 38] we discussed representations of boolean functions in general.", "startOffset": 5, "endOffset": 13}, {"referenceID": 31, "context": "We have conjectured in [37, 38] (Conjecture 9.", "startOffset": 23, "endOffset": 31}, {"referenceID": 32, "context": "We have conjectured in [37, 38] (Conjecture 9.", "startOffset": 23, "endOffset": 31}, {"referenceID": 5, "context": "Such an encoding is an extension of Theorem 1 in [8], using similar techniques.", "startOffset": 49, "endOffset": 52}, {"referenceID": 40, "context": "In [49] a more general version of Lemma 7.", "startOffset": 3, "endOffset": 7}, {"referenceID": 40, "context": "9 only establishes the 7)There is a mistake in [49] in that it claims that the Tseitin translation of all DNNFs maintain arc-consistency via UCP, however this is shown only for smooth DNNFs as confirmed by George Katirelos via e-mail in January 2012.", "startOffset": 47, "endOffset": 51}, {"referenceID": 17, "context": "6 and Chapter 7 in [22]), which are as clause-sets precisely the hitting clause-sets, then we obtain absolute hardness 1:", "startOffset": 19, "endOffset": 23}, {"referenceID": 44, "context": "And also note that in case of \u22a5 / \u2208 F the additional clauses of ct(F ), that is, the C \u2208 ct(F ) \\ ct(F ), are all blocked for ct(F ) (see [54, 55]), since C can not be resolved on the vct-variable in it.", "startOffset": 138, "endOffset": 146}, {"referenceID": 45, "context": "And also note that in case of \u22a5 / \u2208 F the additional clauses of ct(F ), that is, the C \u2208 ct(F ) \\ ct(F ), are all blocked for ct(F ) (see [54, 55]), since C can not be resolved on the vct-variable in it.", "startOffset": 138, "endOffset": 146}, {"referenceID": 5, "context": "Basic results for showing such a lower bound are obtained in [8].", "startOffset": 61, "endOffset": 64}, {"referenceID": 43, "context": "Thus at each leaf we can attach a splitting tree of Horton-Strahler number of hardness at most max\u03c8\u2208P hd(\u03c8\u2217F ), and from that (via the well-known correspondence of splitting trees and resolution trees; see [53, 59] for details) we obtain a resolution tree fulfilling the desired hardness bound.", "startOffset": 206, "endOffset": 214}, {"referenceID": 49, "context": "Thus at each leaf we can attach a splitting tree of Horton-Strahler number of hardness at most max\u03c8\u2208P hd(\u03c8\u2217F ), and from that (via the well-known correspondence of splitting trees and resolution trees; see [53, 59] for details) we obtain a resolution tree fulfilling the desired hardness bound.", "startOffset": 206, "endOffset": 214}, {"referenceID": 30, "context": "1 with F := F1\u222aF2 and V := var(F1)\u2229var(F2), and apply the general upper bound hd(F1 \u222a F2) \u2264 max(hd(F1), hd(F2)) for variable-disjoint F1, F2 (Lemma 15 in [36]).", "startOffset": 154, "endOffset": 158}, {"referenceID": 49, "context": "1, part 1, in [59]).", "startOffset": 14, "endOffset": 18}, {"referenceID": 30, "context": "By Lemma 19 in [36] we have hd(\u03c8 \u2217 F ) \u2264 2, and thus hd(F ) \u2264 (n \u2212 2) + 2 = n.", "startOffset": 15, "endOffset": 19}, {"referenceID": 43, "context": "18 in [53], since then F would be simply the clause-set with all 2 clauses of length n.", "startOffset": 6, "endOffset": 10}, {"referenceID": 32, "context": "7 in [38].", "startOffset": 5, "endOffset": 9}, {"referenceID": 47, "context": "OKsolver ([57]): a look-ahead solver, used as a \u201ctheoretical\u201d solver.", "startOffset": 10, "endOffset": 14}, {"referenceID": 63, "context": "6 (see [76]).", "startOffset": 7, "endOffset": 11}, {"referenceID": 1, "context": "0 (see [3]).", "startOffset": 7, "endOffset": 10}, {"referenceID": 7, "context": "(a) PicoSAT, version 913 (see[10, 12]).", "startOffset": 29, "endOffset": 37}, {"referenceID": 8, "context": "(a) PicoSAT, version 913 (see[10, 12]).", "startOffset": 29, "endOffset": 37}, {"referenceID": 8, "context": "(c) Lingeling, version ala-b02aa1a-121013 (see [12, 13]).", "startOffset": 47, "endOffset": 55}, {"referenceID": 9, "context": "(c) Lingeling, version ala-b02aa1a-121013 (see [12, 13]).", "startOffset": 47, "endOffset": 55}, {"referenceID": 71, "context": "We conclude our considerations on hierarchies by considering the three hierarchies SLUR(k) introduced in [86], SLUR\u2217(k) introduced in [19], and CANON(k) introduced in [6], which we have compared to the UC-hierarchy in [36, 37, 38].", "startOffset": 105, "endOffset": 109}, {"referenceID": 15, "context": "We conclude our considerations on hierarchies by considering the three hierarchies SLUR(k) introduced in [86], SLUR\u2217(k) introduced in [19], and CANON(k) introduced in [6], which we have compared to the UC-hierarchy in [36, 37, 38].", "startOffset": 134, "endOffset": 138}, {"referenceID": 3, "context": "We conclude our considerations on hierarchies by considering the three hierarchies SLUR(k) introduced in [86], SLUR\u2217(k) introduced in [19], and CANON(k) introduced in [6], which we have compared to the UC-hierarchy in [36, 37, 38].", "startOffset": 167, "endOffset": 170}, {"referenceID": 30, "context": "We conclude our considerations on hierarchies by considering the three hierarchies SLUR(k) introduced in [86], SLUR\u2217(k) introduced in [19], and CANON(k) introduced in [6], which we have compared to the UC-hierarchy in [36, 37, 38].", "startOffset": 218, "endOffset": 230}, {"referenceID": 31, "context": "We conclude our considerations on hierarchies by considering the three hierarchies SLUR(k) introduced in [86], SLUR\u2217(k) introduced in [19], and CANON(k) introduced in [6], which we have compared to the UC-hierarchy in [36, 37, 38].", "startOffset": 218, "endOffset": 230}, {"referenceID": 32, "context": "We conclude our considerations on hierarchies by considering the three hierarchies SLUR(k) introduced in [86], SLUR\u2217(k) introduced in [19], and CANON(k) introduced in [6], which we have compared to the UC-hierarchy in [36, 37, 38].", "startOffset": 218, "endOffset": 230}, {"referenceID": 32, "context": "3 Compilation procedures For a given boolean function f and k \u2208 N0, how do we find algorithmically a \u201csmall\u201d equivalent F \u2208 UCk ? In [38], Section 8, the notion of a \u201ck-base for f\u201d is introduced, which is an F \u2208 UCk equivalent to f , with F \u2286 prc0(f) and where no clause can be removed without increasing the hardness or destroying equivalence.", "startOffset": 133, "endOffset": 137}, {"referenceID": 29, "context": "The most basic approach filters out unneeded prime implicates; see [35, 34] for some initial applications to cryptanalysis.", "startOffset": 67, "endOffset": 75}, {"referenceID": 28, "context": "The most basic approach filters out unneeded prime implicates; see [35, 34] for some initial applications to cryptanalysis.", "startOffset": 67, "endOffset": 75}, {"referenceID": 29, "context": "A simple filtering heuristic, used in [35, 34], is to favour (keeping) short-clauses.", "startOffset": 38, "endOffset": 46}, {"referenceID": 28, "context": "A simple filtering heuristic, used in [35, 34], is to favour (keeping) short-clauses.", "startOffset": 38, "endOffset": 46}, {"referenceID": 11, "context": "Essentially the same heuristic is considered in [15] (called \u201clength-increasing iterative empowerment\u201d) when generating representations in PC.", "startOffset": 48, "endOffset": 52}, {"referenceID": 20, "context": "For the case that f is given by a CNF F0, in [26] one finds refinements of the resolution procedure applied to F0, which would normally compute prc0(f), i.", "startOffset": 45, "endOffset": 49}, {"referenceID": 32, "context": "A first task is to investigate which of the results on hardness from this article and from [38] can be adapted to w-hardness.", "startOffset": 91, "endOffset": 95}, {"referenceID": 6, "context": "In [9] we will present some basic methods for w-hardness bounds.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "Can the classes WCk go beyond monotone circuits, which were shown in [8] to be strongly related to the expressive power of arc-consistent CNF representations (see the following subsection for some further remarks)? Conjecture 7.", "startOffset": 69, "endOffset": 72}, {"referenceID": 5, "context": "So the conjecture is that here we have another example for the limitations of arc-consistent representations as shown in [8].", "startOffset": 121, "endOffset": 124}, {"referenceID": 43, "context": "To overcome these (conjectured) limitations, the theory started here has to be generalised via the use of oracles as developed in [53, 59], and further discussed in Subsection 9.", "startOffset": 130, "endOffset": 138}, {"referenceID": 49, "context": "To overcome these (conjectured) limitations, the theory started here has to be generalised via the use of oracles as developed in [53, 59], and further discussed in Subsection 9.", "startOffset": 130, "endOffset": 138}, {"referenceID": 31, "context": "4 of [37, 38].", "startOffset": 5, "endOffset": 13}, {"referenceID": 32, "context": "4 of [37, 38].", "startOffset": 5, "endOffset": 13}, {"referenceID": 64, "context": "Thus they are conceptually simpler than the current integration of SAT solvers and methods from linear algebra (see [78, 20, 77, 39, 64]).", "startOffset": 116, "endOffset": 136}, {"referenceID": 33, "context": "Thus they are conceptually simpler than the current integration of SAT solvers and methods from linear algebra (see [78, 20, 77, 39, 64]).", "startOffset": 116, "endOffset": 136}, {"referenceID": 53, "context": "Thus they are conceptually simpler than the current integration of SAT solvers and methods from linear algebra (see [78, 20, 77, 39, 64]).", "startOffset": 116, "endOffset": 136}, {"referenceID": 24, "context": "And for some oracles, like detection of minimally unsatisfiable clause-sets of a given deficiency, the problems would turn from polytime to NP-hard in this way ([30, 16]).", "startOffset": 161, "endOffset": 169}, {"referenceID": 12, "context": "And for some oracles, like detection of minimally unsatisfiable clause-sets of a given deficiency, the problems would turn from polytime to NP-hard in this way ([30, 16]).", "startOffset": 161, "endOffset": 169}, {"referenceID": 6, "context": "In [9] we show hd(PHPmm) = whd(PHP m m) = m \u2212 1, and so the (standard representation) PHPmm \u2208 CLS itself is not a good representation (it is small, but has high w-hardness).", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "Actually, as explained in [9], from [8] it follows that PHPmm has no polysize arc-consistent representation at all! So again, here oracles are needed; see Subsection 9.", "startOffset": 26, "endOffset": 29}, {"referenceID": 5, "context": "Actually, as explained in [9], from [8] it follows that PHPmm has no polysize arc-consistent representation at all! So again, here oracles are needed; see Subsection 9.", "startOffset": 36, "endOffset": 39}, {"referenceID": 31, "context": "4 of [37, 38] for a proposal of an interesting oracle (with potentially good stability properties).", "startOffset": 5, "endOffset": 13}, {"referenceID": 32, "context": "4 of [37, 38] for a proposal of an interesting oracle (with potentially good stability properties).", "startOffset": 5, "endOffset": 13}], "year": 2013, "abstractText": "We consider the fundamental task of representing a boolean function f by a conjunctive normal form (clause-set) F for the purpose of SAT solving. The boolean function f here acts as a kind of constraint, like a cardinality constraint or an S-box in a cryptosystem, while F is a subset of the whole SAT problem to be solved. The traditional approach towards \u201cgood\u201d properties of F considers \u201carc consistency\u201d, which demands that for every partial instantiation of f , all forced assignments can be recovered from the corresponding partial assignment to F via unit-clause propagation (UCP). We propose to consider a more refined framework: First, instead of considering the above relative condition, a relation between f and F , we consider an absolute condition, namely that goodness of F is guaranteed by F being element of a suitable target class. And second, instead of just considering UCP, we consider hierarchies of target classes, which allow for different mechanisms than UCP and allow for size/complexity trade-offs. The hierarchy UCk of unit-refutation complete clause-sets of level k, introduced in [36, 37, 38], provides the most basic target classes, that is, F \u2208 UCk is to be achieved for k as small as feasible. Here UC1 = UC has been introduced in [26] for the purpose of knowledge compilation. In general, UCk is the set of clause-sets F such that unsatisfiable instantiations (by partial assignments) are recognisable by k-times nested unit-clause propagation. We also touch upon the hierarchy PCk of propagation complete clause-sets of level k, where PC1 = PC has been introduced in [15]. The hierarchy PCk refines the hierarchy UCk by providing intermediate layers. In order to make use of full resolution, we consider the hierarchy WCk of width-refutation complete clauses-sets of level k, employing an improved notion of width (so that we always have UCk \u2286 WCk). Via the absolute condition, the quality of the representation F is fully captured by the target class, and the only relation between f and F is that F must \u201crepresent\u201d f . If F does not contain new variables, then this means that F is equivalent to f , while with new variables the satisfying assignments of F projected to the variables of f must be precisely the satisfying assignments of f . Without new variables, the relative and absolute condition coincide, but with new variables, the absolute condition is stronger. As we remark in this article, for the relative condition and new variables at least the hierarchies UCk and PCk collapse, and we also conjecture that the WCk hierarchy collapses. The main result of this article is that without new variables, none of these hierarchies collapses. That means that there are boolean functions with only exponential-size equivalent clause-sets at level k, but with poly-size equivalent clause-sets at level k + 1.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}