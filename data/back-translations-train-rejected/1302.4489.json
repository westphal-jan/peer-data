{"id": "1302.4489", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Feb-2013", "title": "Termhood-based Comparability Metrics of Comparable Corpus in Special Domain", "abstract": "Cross-Language Information Retrieval (CLIR) and machine translation (MT) resources, such as dictionaries and parallel corpora, are scarce and hard to come by for special domains. Besides, these resources are just limited to a few languages, such as English, French, and Spanish and so on. So, obtaining comparable corpora automatically for such domains could be an answer to this problem effectively. Comparable corpora, that the subcorpora are not translations of each other, can be easily obtained from web. Therefore, building and using comparable corpora is often a more feasible option in multilingual information processing. Comparability metrics is one of key issues in the field of building and using comparable corpus. Currently, there is no widely accepted definition or metrics method of corpus comparability. In fact, Different definitions or metrics methods of comparability might be given to suit various tasks about natural language processing. A new comparability, namely, termhood-based metrics, oriented to the task of bilingual terminology extraction, is proposed in this paper. In this method, words are ranked by termhood not frequency, and then the cosine similarities, calculated based on the ranking lists of word termhood, is used as comparability. Experiments results show that termhood-based metrics performs better than traditional frequency-based metrics.", "histories": [["v1", "Tue, 19 Feb 2013 00:30:57 GMT  (171kb)", "http://arxiv.org/abs/1302.4489v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sa liu", "chengzhi zhang"], "accepted": false, "id": "1302.4489"}, "pdf": {"name": "1302.4489.pdf", "metadata": {"source": "CRF", "title": "Termhood-based Comparability Metrics of Comparable Corpus in Special Domain", "authors": ["Sa Liu", "Chengzhi Zhang"], "emails": ["liusa321@163.com,", "zhangchz@istic.ac.cn"], "sections": [{"heading": null, "text": "At present, there is no widely accepted definition or metric for comparability of corpus. In fact, different definitions or metrics for comparability could be given to meet different tasks of processing natural language. A new comparability, namely termhood-based metrics based on the task of bilingual terminology extraction, is proposed in this paper. In this method, words are classified by termhood and not by frequency, and then the cosine similarities calculated on the basis of termhood rankings are used as comparability. Experimental results show that termhood-based metrics perform better than traditional frequency-based metrics. Keywords: Termhood-based comparability, Comparable Corpus, Frequency-based Metrics, Terminology Extraction"}, {"heading": "1 Introduction", "text": "Parallel Corpus, which contains source documents and their translations, plays an important role in the multilingual information service [1], such as Cross-Language Information Retrieval (CLIR), and Machine Translation (MT). However, parallel Corpus is scarce resources and not easy to obtain in some underfunded languages or specialized domains. Due to these shortcomings, building and using comparable corpora is often a more viable option. It is obviously easier to find document collections with similar themes in multiple languages than parallel Corpus [2]. The Web, with its enormous amounts of data, provides a natural source for this. For example, bilingual website and online Wikipedia, are very good resources for collecting and obtaining comparable data. Meanwhile, comparable data can be updated from these resources, with the increase in source data, and then more Corpus can be easily and precisely extracted."}, {"heading": "2 Related Works", "text": "In this section, we discuss related work relevant to our research, including a brief overview of the structure of comparable corpus and comparability indicators of comparable corpus."}, {"heading": "2.1 Building comparable corpus", "text": "Talvensaari et al. created comparable corpus based on focused crawling [6]. Leturia et al. (2009) used search engine queries to capture comparable corpus from the Internet [7]. Otero and L'opez used Wikipedia to capture domain-like corpus using categories as subject constraints [8]. In our previous experiments, we used three different Internet data sources to capture comparable corpus: query bilingual domain keywords in search engines, use of the online encyclopedia Wikipedia, and search in academic databases. Finally, we select data from academic databases as an experimental corpus based on their appropriate size and quality."}, {"heading": "2.2 Comparability metrics of comparable corpus", "text": "The most commonly used metrics of comparable corpus are chi-square statistics and word similarity. Leturia et al. used these two methods to measure the comparability of the domain-specific comparable corpus from the Internet. [2] One method is the calculation of the cosinal value between the vectors that contain all the keywords of each corpus; the other is the calculation of chi-square statistics for the most common N-keywords (Top-N-Keywords). The ACCURAT (Analysis and Evaluation of Comparable Corpora for Under Resourced Areas of Machine Translation) project uses asymmetric chi-square statistics for the most common N-keywords."}, {"heading": "3 Termhood-based comparability metrics of comparable corpus", "text": "As for terminology extraction based on a comparable corpus, comparability should concern the distribution and quality of terminology. Termology is defined as the degree of terminology to be used in a particular area. Termology can be measured by terms and word distribution by word weighting rankings. Therefore, we proposed termhood-based comparability metrics. In this method, words are classified by term and not by frequency, and then the cosine similarities are calculated based on the ranking of word weighting. The obtained similarity is used as the comparability of a comparable corpus."}, {"heading": "3.1 The Basic Idea", "text": "In order to calculate term-based comparability, the entire process we have used is described as follows: (1) Sino-English domain comparable corpus collecting: comparable corpus, which we evaluate in the experiment from two online academic databases (Chinese corpus from CNKI [12], English corpus from EBSCO [13]); (2) Pre-processing: Chinese corpus is pre-processing and word lists from keywords (from the aforementioned academic databases) and full-text words (from the full-text of a document) are both obtained; (3) Translating and processing: English corpus is translated into Chinese by Google Translate [14]. Then the translated corpus is segmented by ICTClAS [15], and finally word lists from keywords and full-text words are acquired; (4) Termhood measure: Termhood comparison of words is compiled by the method of acquiring the corpus-similarity to the corpus (5)."}, {"heading": "3.2 Key technology in the proposed method", "text": "In this section, the key technology used in our proposed method is described in detail, including termhood measurement and comparability of termhood-based metrics. (1) Termhood measurement by corpus comparison It is observed that a true term is more prominent (or peculiar) for its own specialized domain than for a general domain or other field. Kit and Liu proposed a measurement of mono-word terminology in the terminology of this peculiarity and quantify it in terms of the difference in rank of a word in a domain and a background corpus [16]. We use this method to measure the terms of terminology. We use People's Daily Corpus from 1998 to June as the background corpus and Library and Information (LIS) Corpus as the domain corpus. In light of a domain corpus D (with a vocabulary VD) and a background corpulary B (with a vocabulary Vabulary V) the domain vocabulary of a vocabulary is defined."}, {"heading": "4 Experiments and Result Analysis", "text": "In this section, we first present the data of the experiments used for comparability measurements, then describe in detail two different methods of data processing, and finally present and analyze the results of the experiments."}, {"heading": "4.1 Data", "text": "In the experiments, we select three types of comparable corpus with different comparability, i.e. parallel corpus, comparable corpus and non-comparable corpus. It is assumed that the comparability of comparable corpus is between parallel and non-comparable corpus. In our experiments, the area of the parallel corpus is the library and information science (LIS) derived from abstracts of records from the CNKI database; comparable corpus is also the LIS area collected from two aforementioned academic databases."}, {"heading": "4.2 Data processing", "text": "In order to verify the effectiveness of the proposed method, we calculate the comparability of three types of comparable corpus, i.e. parallel corpus, comparable corpus or non-comparable corpus. In the experiments, the comparability of each type of comparable corpus is calculated on the basis of time-based or traditional frequency-based metrics. (1) Frequency-based metrics Word was classified on the basis of their frequency in the corpus, and then the comparability was calculated using cosine values between two vectors represented by words and their frequency. In the experiment, word frequency is normalized because there is a difference between the size of Chinese corpus and the English corpus. Experiments were conducted for six different corpus sizes, i.e. Top100, Top200, Top500, Top1000, Top2000 and Top5000."}, {"heading": "4.3 Experiments and Results", "text": "Note that both methods reflect the fact that the comparability of the parallel corpus > the comparability of the comparable corpus > the comparability of the non-comparable corpus > the comparability of the non-comparable corpus. In comparison, it is assumed that the comparability of the comparable corpus should be in the middle of the two; parallel, comparable, not comparable, the comparability of three types of corpus should have an even decreasing trend. In comparison, the approach of the comparable corpus reflects a more obvious point. The performance of the frequency-based method for all words is shown in Figure.3. Overall, it reflects the fact that the comparability of the parallel corpus > the comparability of the non-comparable corpus > the comparability of the comparable corpus. This contradicts our hypothesis. Furthermore, this result is not consistent with the frequency-based method of the comparable corpus."}, {"heading": "5 Evaluation", "text": "In addition, we verify the validity of the comparability measure of termingonal metrics by performing bilingual term extraction. In this section, we need to learn whether comparable corpus with high comparability can produce bilingual terminology with high quality. Therefore, our experiment is designed to extract bilingual terminology from three corpus with different comparability, which are parallel corpus, comparable corpus or non-comparable corpus. Again, the comparability of comparable corpus is assumed to be between parallel and non-comparable corpus. We expect the higher corpus comparability to be the higher the quality bilingual terminology we can obtain."}, {"heading": "5.1 Methods of Bilingual Term Extraction and Evaluation", "text": "The method of terminology extraction in our experiment is one of the most popular methods, namely the context vector-based method [18], which involves the following steps: 1) pre-processing. For the Chinese corpus: segmentation and part of the language. For English: stammering and part of the language; 2) generation of candidate monolingual terminology; 3) generation of a context vector of monolingual terminology based on coexistence statistics; 4) translation of Chinese context vectors into English by bilingual dictionary from the LDC [19]; 5) calculation of the similarity of the context vector in the singular space of the English language. 6) extraction of terminology pairs whose similarity is greater than the specified threshold. 7) evaluation of the terminology quality. We use the Top @ N method to evaluate the result of bilingual terminology extraction. That is, for any English top @ terminology coupled with terminology translation, if there is a correct N."}, {"heading": "5.2 Results and Analysis", "text": "We use two indicators for the overall analysis, the general similarity of the terminology pairs and the general degree of agreement. Table 2 is the result of the evaluation. Note that the general similarity of the terminology pairs increases with the growth of comparability. According to Table 2, the overall degree of agreement achieved by machine discrimination does not always increase with the growth of comparability. In fact, machine discrimination is carried out using the LDC dictionary. As far as we know, the LDC dictionary is a general dictionary comprising only about 80,000 pairs of bilingual lexicographs, but the corpus in our experiments is corpus in a specific area. Therefore, it is inevitable that there will be a deviation due to the limited size of the bilingual dictionary. Therefore, the human evaluation is very necessary. Note that the overall degree of agreement achieved by human evaluation is related to the growth of comparability."}, {"heading": "6 Conclusions and Future Works", "text": "In this paper, we have proposed a method based on terms to measure the comparability of comparable corpus. Experiments have shown that this method performs better than the traditional frequency-based method. It is likely that the applicant terms are rated more sensibly due to the limitation of terms. It is possible that this method is less affected by common words and takes into account the quality of terms in a specific area, so that their performance is more stable and better in the task of terminology extraction. Experiments also show that the results of comparability are more reliable when keywords are used that are not full-text in the frequency-based method. This, in turn, shows that when using full-text data after preprocessing, there are so many common words that they affect the rankings and cause further inaccurate results. Regardless of keywords or full-text data, the results in the term-based method are consistent. This shows that the term method has better stability for our current work than some directions of frequency."}, {"heading": "Acknowledgement", "text": "This work is supported by the National Natural Science Foundation of China under grant number 70903032."}], "references": [{"title": "Parallel and comparable corpora: What are they up to", "author": ["A.M. McEnery", "R.Z. Xiao"], "venue": "Proceedings of Incorporating Corpora: Translation and the Linguist Translating Europe Multilingual Matters, Clevedon, UK.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Creating and Exploiting a Comparable Corpus in Cross - Language Information Retrieval", "author": ["T. Talvensaari", "Laurikkala J", "K. J\u00e4rvelin", "M. Juhola", "H. Keskustalo"], "venue": "J.ACM Transactions on Information Systems (TOIS)", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Bilingual terminology extraction: an approach based on multilingual thesaurus applicable to comparable corpora", "author": ["H. Dejean", "E. Gaussier", "F. Sadat"], "venue": "Proceedings of COLING2002,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2002}, {"title": "Using word frequency lists to measure corpus homogeneity and similarity between corpora", "author": ["A. Kilgarriff"], "venue": "Proceedings of the Fifth Workshop on Very Large Corpora,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1997}, {"title": "Focused web crawling in the acquisition of comparable corpora", "author": ["T. Talvensaari", "A. Pirkola", "K. J\u00e4rvelin", "M. Juhola", "J. Laurikkala"], "venue": "J.Information Retrieval. 11(5), 427-445", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Search engine based approaches for collecting domain-specific Basque-English comparable corpora from the Internet", "author": ["I. Leturia", "I.S. Vicente", "X. Saralegi"], "venue": "In Proceedings of the Fifth Web as Corpus Workshop (WAC5), pp.53-61.Basque Country, Spain", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "\u0301opez, I.G.: Wikipedia as Multilingual Source of Comparable Corpora", "author": ["P.G. Otero"], "venue": "In Proceedings of the 3rd Workshop on Building and Using Comparable Corpora, LREC2010,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "ACCURAT: Metrics for the evaluation of comparability of multilingual corpora", "author": ["A. Vasi\u013cjevs"], "venue": "Proceedings of the Workshop on Methods for the Automatic Acquisition of Language Resources and their Evaluation Methods, LREC2010.Malta", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving Corpus Comparability for Bilingual Lexicon Extraction from Comparable Corpora", "author": ["B. Li", "E. Gaussier"], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Measuring mono-word termhood by rank difference via corpus comparison", "author": ["C.Y. Kit", "X.Y. Liu"], "venue": "J. Terminology", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "A Vector Space Model for Automatic Indexing", "author": ["G. Salton", "A. Wong", "C.S. Yang"], "venue": "Communications of the ACM. Malta", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1975}, {"title": "A Statistical view on Bilingual lexicon extraction: From Parallel Corpora to nonparallel corpora", "author": ["P. Fung"], "venue": "Proceedings of Jean Veronis. Parallel Text", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2000}, {"title": "Cognates Can Improve Statistical Translation Models", "author": ["G. Kondrak", "D. Marcu", "K. Knight"], "venue": "In Proceedings of HLT-NAACL 2003: Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Parallel corpus which contains source documents and their translations plays an important role in multilingual information service [1], such as Cross-Language Information Retrieval (CLIR), and machine translation (MT).", "startOffset": 131, "endOffset": 134}, {"referenceID": 1, "context": "It is obviously easier to find document collections with similar topics in multiple languages than to find parallel corpus [2].", "startOffset": 123, "endOffset": 126}, {"referenceID": 2, "context": "In multilingual terminology extraction, comparability is focused on distribution and quality of the vocabulary of translated forms [4].", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "So far, method of based word frequency list has been always used to measure corpus homogeneity and similarity between corpora [5].", "startOffset": 126, "endOffset": 129}, {"referenceID": 1, "context": "Generally, comparable corpus is generated from news agencies or by crawling certain sites [2].", "startOffset": 90, "endOffset": 93}, {"referenceID": 4, "context": "built comparable corpora based on focused crawling [6].", "startOffset": 51, "endOffset": 54}, {"referenceID": 5, "context": "(2009) used search engine queries for collecting comparable corpora from the Internet [7].", "startOffset": 86, "endOffset": 89}, {"referenceID": 6, "context": "Otero and L \u0301opez exploited Wikipedia for collecting domain comparable corpora by using categories as topic restrictions [8].", "startOffset": 121, "endOffset": 124}, {"referenceID": 1, "context": "used these two methods to measure the comparability of domain-specific comparable corpora obtained from the Internet by using search engine [2].", "startOffset": 140, "endOffset": 143}, {"referenceID": 7, "context": "The ACCURAT (Analysis and evaluation of Comparable Corpora for Under Resourced Areas of Machine Translation) project used asymmetric Chi-square statistics to measure comparability [9].", "startOffset": 180, "endOffset": 183}, {"referenceID": 8, "context": "Li and Gaussier purposed a metrics of comparable corpus for bilingual lexicon extraction [11].", "startOffset": 89, "endOffset": 93}, {"referenceID": 8, "context": "It is in this point that our method is different to Li et al [11], which is oriented to bilingual lexicon.", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "Kit and Liu proposed a measure for mono-word termhood in terminology of such peculiarity and quantify it in terms of a word\u2019s ranking difference in a domain and background corpus [16].", "startOffset": 179, "endOffset": 183}, {"referenceID": 10, "context": "Then we calculate similarity of the new word list by vector space model [17].", "startOffset": 72, "endOffset": 76}, {"referenceID": 11, "context": "The method of terminology extraction in our experiment is one of the most popular methods, namely, context vector-based method [18], which includes the following steps.", "startOffset": 127, "endOffset": 131}, {"referenceID": 12, "context": "In the evaluation criteria of human judgments, if translation relation is completely correct, the score of matching will be 1; partly correct, score will be calculated by dice coefficient [20]; completely incorrect, score will be zero.", "startOffset": 188, "endOffset": 192}], "year": 2012, "abstractText": "Cross-Language Information Retrieval (CLIR) and machine translation (MT) resources, such as dictionaries and parallel corpora, are scarce and hard to come by for special domains. Besides, these resources are just limited to a few languages, such as English, French, and Spanish and so on. So, obtaining comparable corpora automatically for such domains could be an answer to this problem effectively. Comparable corpora, that the subcorpora are not translations of each other, can be easily obtained from web. Therefore, building and using comparable corpora is often a more feasible option in multilingual information processing. Comparability metrics is one of key issues in the field of building and using comparable corpus. Currently, there is no widely accepted definition or metrics method of corpus comparability. In fact, Different definitions or metrics methods of comparability might be given to suit various tasks about natural language processing. A new comparability, namely, termhood-based metrics, oriented to the task of bilingual terminology extraction, is proposed in this paper. In this method, words are ranked by termhood not frequency, and then the cosine similarities, calculated based on the ranking lists of word termhood, is used as comparability. Experiments results show that termhood-based metrics performs better than traditional frequency-based metrics.", "creator": "PScript5.dll Version 5.2"}}}