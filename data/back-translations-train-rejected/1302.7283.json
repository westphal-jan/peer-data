{"id": "1302.7283", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2013", "title": "Source Separation using Regularized NMF with MMSE Estimates under GMM Priors with Online Learning for The Uncertainties", "abstract": "We propose a new method to enforce priors on the solution of the nonnegative matrix factorization (NMF). The proposed algorithm can be used for denoising or single-channel source separation (SCSS) applications. The NMF solution is guided to follow the Minimum Mean Square Error (MMSE) estimates under Gaussian mixture prior models (GMM) for the source signal. In SCSS applications, the spectra of the observed mixed signal are decomposed as a weighted linear combination of trained basis vectors for each source using NMF. In this work, the NMF decomposition weight matrices are treated as a distorted image by a distortion operator, which is learned directly from the observed signals. The MMSE estimate of the weights matrix under GMM prior and log-normal distribution for the distortion is then found to improve the NMF decomposition results. The MMSE estimate is embedded within the optimization objective to form a novel regularized NMF cost function. The corresponding update rules for the new objectives are derived in this paper. Experimental results show that, the proposed regularized NMF algorithm improves the source separation performance compared with using NMF without prior or with other prior models.", "histories": [["v1", "Thu, 28 Feb 2013 18:56:56 GMT  (164kb,D)", "http://arxiv.org/abs/1302.7283v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NA", "authors": ["emad m grais", "hakan erdogan"], "accepted": false, "id": "1302.7283"}, "pdf": {"name": "1302.7283.pdf", "metadata": {"source": "CRF", "title": "Source Separation using Regularized NMF with MMSE Estimates under GMM Priors with Online Learning for The Uncertainties", "authors": ["Emad M. Grais", "Hakan Erdogan"], "emails": ["haerdogan}@sabanciuniv.edu"], "sections": [{"heading": null, "text": "We propose a new method to commit priors to solving non-negative matrix factorization (NMF); the proposed algorithm can be used for denocialization or single-channel source separation (SCSS) applications; the NMF solution is based on the estimates of the Minimum Mean Square Error (MMSE) using previous Gaussian Mixture Models (GMM) for the source signal; in SCSS applications, the spectra of the observed mixed signal are decomposed using weighted linear combination of trained base vectors for each source using NMF. In this thesis, the NMF decomposition weight matrices are treated by a distortion operator as a distorted image learned directly from the observed signals; the MMSE estimation of the weight matrix using GMM before and protocol normal distribution for the distortion are then determined to improve the NMF decomposition results within the MSE-type MF estimation, which is a new MF optimization function."}, {"heading": "1. Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2. Nonnegative matrix factorization", "text": "Non-negative matrix factorization is used to divide each non-negative matrix V into a multiplication of a non-negative base matrix B and a non-negative gain or weight matrix G as follows: V \u2248 BG. (1) The columns of matrix B contain non-negative base or dictionary vectors optimized to approximate the data in V as a non-negative linear combination of their constituent vectors. Each column in the gain / weight matrix G contains the set of weight combinations that the base vectors have in the base matrix. To solve the data in the V matrix B and G, various NMF cost functions can be used. For audio source separation applications, the Itakura-Saito (IS-NMF) divergence cost function (Fevotte et), BIS multiplication function (Fevotte et), BIS-m."}, {"heading": "3. Problem formulation for SCSS", "text": "For single-channel source separation (SCSS), the goal is to find estimates of source signals mixed on a single observation channel y (t), which is usually solved in the short time in which the Fourier transformation (STFT) takes place. Let Y (t, f) be the STFT of y (t), where t represents the image index and f is the frequency index. Due to the linearity of the STFT, we have: Y (t, f) = S1 (t, f) + S2 (t, f), (5) where S1 (t, f) and S2 (t, f) are the unknown STFT of the first and second sources in the mixed signal. Assuming the independence of the sources, we can describe the power spectrum density (PSD) of the measured signal sum of the source signals PSD as follows: \u03c32y (t, f) = dose 2 (t, f), (6) of the measured signal as dose of the gram (SY) and (SY) (S1) grams."}, {"heading": "4. Conventional NMF for SCSS", "text": "In conventional single-channel source separation using NMF without regulation (Grais et al., 2012), there are two main stages to find estimates for S1 and S2 in Equation (7). The first stage is the training stage and the second stage is the separation / test stage. In the training stage, the spectrogram Strain is calculated for each source by calculating the squared size of the STFT of each source training signal. NMF is used to decompose the spectrogram into base and gains matrices as follows: Strain1 \u2248 B1Gtrain1, Strain2 \u2248 B2Gtrain2, (8) the multiplicative update rules in Equations (3) and (4) are used to resolve the B1, B2, G train 1 and G train 2 for both sources. Within each iteration, the columns of B1 and B2 are normalized the B2 matrices and the matrices of B1 and B2 are compensated accordingly."}, {"heading": "5. Motivation for regularized NMF", "text": "The solution of the problem, which has occurred in the last two years in the last two years in the United States, is not yet complete, since it is not yet so far that it will be as far in the next two years in the United States as in the last three years. (...) The solution of the problem is not yet complete. (...) The solution of the problem is not yet complete. (...) The solution of the problem is not yet complete. (...) The solution of the problem is not yet complete. (...) The solution of the problem is not yet complete. (...) The solution of the problem is not yet complete. (...) The solution of the problem is not yet complete. (...) The solution of the problem is not yet complete. (...) The solution of the problem is not yet complete. (...) The solution is not yet complete. (...) The solution is not yet complete. (...) The solution is not yet complete. (... The solution is not yet complete. (...) The solution is not yet complete. (... The solution is not yet complete. (...) The solution is not yet complete. (... The solution is not yet complete.) The solution is not yet complete. (... The solution of the problem is not yet complete."}, {"heading": "6. Motivation for the proposed regularized NMF", "text": "This year it is more than ever before in the history of the city."}, {"heading": "7. Training the GMM prior models", "text": "We use the winning matrices Gtrain1 and G Train 2 in Equation (8) to train previous models for the expected / valid weight patterns in the winning matrix for each source. For each matrix Gtrain1 and G Train 2, we normalize their columns and then calculate their logarithm. The normalization in this work is done using the Euclidean norm. The log-normalized columns are then used to train a gain before GMM for each source. The GMM for a random variable x is defined as: p (x) = K \u2211 k = 1\u03c0k (2\u03c0) d / 2 | 1 / 2 exp {\u2212 12 (x \u2212 \u00b5k) T \u03a3 \u2212 1k (x \u2212 k)}}, (13) where K is the number of Gaussian mixture components, \u03c0k is the mixed weight, d is the vector dimension, \u00b5k is the mean vector dimension of the model matrix and the sensitivity diagram is the GMM."}, {"heading": "8. The proposed regularized NMF", "text": "This year it is more than ever before in the history of the city."}, {"heading": "9. The proposed regularized NMF for SCSS", "text": "In this section we are back to the individual source sharing problems to find a better solution to the equation (9). Figure 1 shows the flow chart that summarizes all stages of the application of our proposed regulated NMF method to SCSS problems. \u2212 Figure 1 shows the flow chart that summarizes all stages of application of our proposed regulated NMF cost function in Section 8 to find a better solution to the gain submatrices in equation (9). The base matrix Btrain = [B1, B2] is still fixed here, we just need to update the profit matrix G in Section 9. Normalized columns of the G1 and G2 submatrices in Equation (9) can be considered deformed images as in Equation (23) and their restored images need to be estimated."}, {"heading": "10. Source signals reconstruction", "text": "Once the suitable solution for the gain matrix G in section 9 has been found, the initially estimated spectrograms S-1 and S-2 can be calculated on the basis of (10) and then used to form spectral masks as follows: H1 = S-1S-1 + S-2, H2 = S-2S-1 + S-2, (41), the divisions being performed on an elementary basis. The final estimate of each source STFT is as follows: S-1 (t, f) = H1 (t, f) Y (t, f), S-2 (t, f) = H2 (t, f) Y (t, f), (42), where Y (t, f) is the STFT of the observed mixed signal equation (5), H1 (t, f) and H2 (t, f) are the entries in row f and column t of the spectral masks H1 and H2."}, {"heading": "11. Experiments and Discussion", "text": "Our main goal was to obtain a clean voice signal from a mixture of voice and piano signals. We simulated our algorithm based on a collection of voice and piano data at a sampling rate of 16kHz. For voice data, we used the training and test data from the TIMIT database. For music data, we downloaded piano music data from the Piano Society website (URL, 2009a). We used 12 pieces with approximate 50 minutes of total duration from different composers, but from a single artist for training, and skipped one piece for testing. PSD for the voice and music data were calculated using the STFT window with 480 points length and 60% overlap and the FFT points were taken at 512 points, the first 257 FFT points were only used since the conjugation of the remaining 255 points."}, {"heading": "12. CONCLUSION", "text": "In this thesis, we have introduced a new regulated NMF algorithm. The NMF solution for the gain matrix was guided by the MMSE estimation under a GMM, in which the uncertainty of the observed mixed signal was determined online from the observed data. The proposed algorithm can be expanded to better measure the distortion in the observed signal by embedding more parameters in Equation (14) that can be learned online from the observed signal."}, {"heading": "13. Acknowledgements", "text": "This research is partly supported by Turk Telekom Group Research and Development, project entitled \"Single Channel Source Separation,\" grant number 3014-06, funding year 2012."}, {"heading": "APPENDIX A", "text": "In this appendix we show the MMSE estimate and the parameter \u0442 k = K = K = K = K = K = K = K = K = K (2001), Ghahramani and Hinton (1997), and Rosti and Gales (2004). Suppose we have a noisy observation y as shown in the graphic model (Figure 4, which can be formulated as follows: y = x + e, (47) where e is the noise term, and x is the unknown underlying correct signal to estimate under a GMM prior distribution: p (x) = K \u00b2 k = 1 \u03c0kN (x \u00b2 K), (48) the error term e has a Gaussian distribution with the mean and diagonal covariance matrix: p (e) = N (e | 0, 0). (49) The conditional distribution of y is a Gaussian with the mean x and diagonal covariance matrix: p (x)."}, {"heading": "APPENDIX B", "text": "In this appendix we show the curves of the penalty term in the regularized NMF cost function in section 2.1. To calculate the update rule for the profit matrix G, the curves in the curves in the NMF cost function C (G) = DIS (V | BG) + GL (G), (78), whence L (G) = N (N), n (G), n (G), n (G), n (G), n (G), n (G), n (G), n (G), n (G), n (G), n (G), n (G), n (G), n (G), n (G), n (G), x), x (G), x (G), x (G), x (G), x (G), x (G)."}], "references": [{"title": "Fast Bayesian NMF algorithms enforcing harmonicity and temporal continuity in polyphonic music transcription, in: IEEE workshop on applications of signal processing to audio and acoustics", "author": ["N. Bertin", "R. Badeau", "E. Vincent"], "venue": null, "citeRegEx": "Bertin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bertin et al\\.", "year": 2009}, {"title": "Enforcing harmonicity and smoothness in bayesian nonnegative matrix factorization applied to polyphonic music transcription", "author": ["N. Bertin", "R. Badeau", "E. Vincent"], "venue": "IEEE Transactions,", "citeRegEx": "Bertin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bertin et al\\.", "year": 2010}, {"title": "GaP: a factor model for discrete data", "author": ["J. Canny"], "venue": "in: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval", "citeRegEx": "Canny,? \\Q2004\\E", "shortCiteRegEx": "Canny", "year": 2004}, {"title": "Conjugate Gamma Markov random fields for modelling nonstationary sources, in: International Conference on Independent Component Analysis and Signal Separation", "author": ["A.T. Cemgil", "O. Dikmen"], "venue": null, "citeRegEx": "Cemgil and Dikmen,? \\Q2007\\E", "shortCiteRegEx": "Cemgil and Dikmen", "year": 2007}, {"title": "Constrained non-negative matrix factorization method for EEG analysis in early detection of alzheimers disease", "author": ["Z. Chen", "A. Cichocki", "T.M. Rutkowski"], "venue": "in: IEEE International Conference on Acoustics,", "citeRegEx": "Chen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2006}, {"title": "New algorithms for nonnegative matrix factorization in applications to blind source separation", "author": ["A. Cichocki", "R. Zdunek", "S. Amari"], "venue": "in: IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)", "citeRegEx": "Cichocki et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cichocki et al\\.", "year": 2006}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": "Journal of the Royal Statistical Society", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "Nonnegative matrix factorization with the itakura-saito divergence. With application to music analysis", "author": ["C. Fevotte", "N. Bertin", "J.L. Durrieu"], "venue": "Neural Computation", "citeRegEx": "Fevotte et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Fevotte et al\\.", "year": 2009}, {"title": "The EM algorithm for mixtures of factor analyzers", "author": ["Z. Ghahramani", "G.E. Hinton"], "venue": "Technical Report. CRG-TR-96-1,", "citeRegEx": "Ghahramani and Hinton,? \\Q1997\\E", "shortCiteRegEx": "Ghahramani and Hinton", "year": 1997}, {"title": "Adaptation of speaker-specific bases in non-negative matrix factorization for single channel speech-music separation, in: Annual Conference of the International Speech Communication Association (INTERSPEECH)", "author": ["E.M. Grais", "H. Erdogan"], "venue": null, "citeRegEx": "Grais and Erdogan,? \\Q2011\\E", "shortCiteRegEx": "Grais and Erdogan", "year": 2011}, {"title": "Single channel speech music separation using nonnegative matrix factorization and spectral masks", "author": ["E.M. Grais", "H. Erdogan"], "venue": "in: International Conference on Digital Signal Processing", "citeRegEx": "Grais and Erdogan,? \\Q2011\\E", "shortCiteRegEx": "Grais and Erdogan", "year": 2011}, {"title": "2011c. Single channel speech music separation using nonnegative matrix factorization with sliding window and spectral masks, in: Annual Conference of the International Speech Communication Association (INTERSPEECH)", "author": ["E.M. Grais", "H. Erdogan"], "venue": null, "citeRegEx": "Grais and Erdogan,? \\Q2011\\E", "shortCiteRegEx": "Grais and Erdogan", "year": 2011}, {"title": "Gaussian mixture gain priors for regularized nonnegative matrix factorization in single-channel source separation, in: Annual Conference of the International Speech Communication Association (INTERSPEECH)", "author": ["E.M. Grais", "H. Erdogan"], "venue": null, "citeRegEx": "Grais and Erdogan,? \\Q2012\\E", "shortCiteRegEx": "Grais and Erdogan", "year": 2012}, {"title": "Regularized nonnegative matrix factorization using gaussian mixture priors for supervised single channel source separation. Computer Speech and Language http://dx.doi.org/10.1016/j.csl.2012.09.002", "author": ["E.M. Grais", "H. Erdogan"], "venue": null, "citeRegEx": "Grais and Erdogan,? \\Q2012\\E", "shortCiteRegEx": "Grais and Erdogan", "year": 2012}, {"title": "Spectro-temporal post-smoothing in NMF based single-channel source separation", "author": ["E.M. Grais", "H. Erdogan"], "venue": "in: European Signal Processing Conference (EUSIPCO)", "citeRegEx": "Grais and Erdogan,? \\Q2012\\E", "shortCiteRegEx": "Grais and Erdogan", "year": 2012}, {"title": "Audio-Visual speech recognition with background music using single-channel source separation", "author": ["E.M. Grais", "I.S. Topkaya", "H. Erdogan"], "venue": "in: IEEE Conference on Signal Processing and Communications Applications (SIU)", "citeRegEx": "Grais et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Grais et al\\.", "year": 2012}, {"title": "Adaptation of source-specific dictionaries in non-negative matrix factorization for source separation", "author": ["X. Jaureguiberry", "P. Leveau", "S. Maller", "J.J. Burred"], "venue": "in: IEEE International Conference Acoustics, Speech and Signal Processing (ICASSP)", "citeRegEx": "Jaureguiberry et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jaureguiberry et al\\.", "year": 2011}, {"title": "Nonparametric shape priors for active contour-based image segmentation", "author": ["J. Kim", "M. cetin", "A.S. Willsky"], "venue": "Signal Processing", "citeRegEx": "Kim et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2007}, {"title": "Algorithms for non-negative matrix factorization", "author": ["D.D. Lee", "H.S. Seung"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Lee and Seung,? \\Q2001\\E", "shortCiteRegEx": "Lee and Seung", "year": 2001}, {"title": "Probability and random processing for electrical engineering", "author": ["A. Leon-Garcia"], "venue": null, "citeRegEx": "Leon.Garcia,? \\Q1994\\E", "shortCiteRegEx": "Leon.Garcia", "year": 1994}, {"title": "Fundamentals of speech recognition", "author": ["L. Rabiner", "B.H. Juang"], "venue": null, "citeRegEx": "Rabiner and Juang,? \\Q1993\\E", "shortCiteRegEx": "Rabiner and Juang", "year": 1993}, {"title": "Generalised linear Gaussian models", "author": ["A.V. Rosti", "M. Gales"], "venue": "Technical Report", "citeRegEx": "Rosti and Gales,? \\Q2001\\E", "shortCiteRegEx": "Rosti and Gales", "year": 2001}, {"title": "Factor analysed hidden markov models for speech recognition", "author": ["A.V.I. Rosti", "M.J.F. Gales"], "venue": "Computer Speech and Language, Issue", "citeRegEx": "Rosti and Gales,? \\Q2004\\E", "shortCiteRegEx": "Rosti and Gales", "year": 2004}, {"title": "Single-channel speech separation using sparse non-negative matrix factorization", "author": ["M.N. Schmidt", "R.K. Olsson"], "venue": "in: International Conference on Spoken Language Processing (INTERSPEECH)", "citeRegEx": "Schmidt and Olsson,? \\Q2006\\E", "shortCiteRegEx": "Schmidt and Olsson", "year": 2006}, {"title": "Performance measurement in blind audio source separation", "author": ["E. Vincent", "R. Gribonval", "C. Fevotte"], "venue": "IEEE Transactions, Audio, speech, and language processing", "citeRegEx": "Vincent et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2006}, {"title": "Monaural sound source separation by non-negative matrix factorization with temporal continuity and sparseness criteria", "author": ["T. Virtanen"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing", "citeRegEx": "Virtanen,? \\Q2007\\E", "shortCiteRegEx": "Virtanen", "year": 2007}, {"title": "Mixtures of gamma priors for non-negative matrix factorization based speech separation, in: International Conference on Independent Component Analysis and Blind Signal Separation", "author": ["T. Virtanen", "A.T. Cemgil"], "venue": null, "citeRegEx": "Virtanen and Cemgil,? \\Q2009\\E", "shortCiteRegEx": "Virtanen and Cemgil", "year": 2009}, {"title": "Bayesian extensions to nonnegative matrix factorization for audio signal modeling, in: IEEE International Conference Acoustics, Speech and Signal Processing (ICASSP)", "author": ["T. Virtanen", "A.T. Cemgil", "S. Godsill"], "venue": null, "citeRegEx": "Virtanen et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Virtanen et al\\.", "year": 2008}, {"title": "Using posterior word probabilities for improved speech recognition, in: IEEE International Conference Acoustics, Speech and Signal Processing (ICASSP)", "author": ["F. Wessel", "R. Schluter", "H. Ney"], "venue": null, "citeRegEx": "Wessel et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Wessel et al\\.", "year": 2000}, {"title": "Regularized non-negative matrix factorization with temporal dependencies for speech denoising", "author": ["K.W. Wilson", "B. Raj", "P. Smaragdis"], "venue": null, "citeRegEx": "Wilson et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wilson et al\\.", "year": 2008}, {"title": "The MMSE estimate of x can be found by calculating the conditional expectation of x given the observation y. Given the Gaussian component k, the joint distribution of x and y is a multivariate Gaussian distribution with conditional expectation and conditional variance as follows (Rosti and", "author": ["Jordan", "Bishop"], "venue": null, "citeRegEx": "Jordan and Bishop..,? \\Q2004\\E", "shortCiteRegEx": "Jordan and Bishop..", "year": 2004}, {"title": "E (x|y, k) = \u03bck + \u03a3kxy\u03a3", "author": ["Gales"], "venue": null, "citeRegEx": "Gales,? \\Q1994\\E", "shortCiteRegEx": "Gales", "year": 1994}], "referenceMentions": [{"referenceID": 18, "context": "Introduction Nonnegative matrix factorization (Lee and Seung, 2001) is an important tool for source separation applications, especially when only one observation of the mixed signal is available.", "startOffset": 46, "endOffset": 67}, {"referenceID": 25, "context": "For audio source separation applications, the continuity and sparsity priors were enforced in the NMF decomposition weights (Virtanen, 2007).", "startOffset": 124, "endOffset": 140}, {"referenceID": 0, "context": "In Bertin et al. (2009), and Bertin et al.", "startOffset": 3, "endOffset": 24}, {"referenceID": 0, "context": "In Bertin et al. (2009), and Bertin et al. (2010), smoothness and harmonicity priors were enforced on the NMF solution in Bayesian framework and applied to music transcription.", "startOffset": 3, "endOffset": 50}, {"referenceID": 0, "context": "In Bertin et al. (2009), and Bertin et al. (2010), smoothness and harmonicity priors were enforced on the NMF solution in Bayesian framework and applied to music transcription. In Wilson et al. (2008b), and Wilson et al.", "startOffset": 3, "endOffset": 202}, {"referenceID": 0, "context": "In Bertin et al. (2009), and Bertin et al. (2010), smoothness and harmonicity priors were enforced on the NMF solution in Bayesian framework and applied to music transcription. In Wilson et al. (2008b), and Wilson et al. (2008a) the regularized NMF was used to increase the NMF decomposition", "startOffset": 3, "endOffset": 229}, {"referenceID": 3, "context": "The Gamma distribution and the Gamma Markov chain (Cemgil and Dikmen, 2007) were used as priors for the basis and weights/gains matrices respectively in Virtanen et al.", "startOffset": 50, "endOffset": 75}, {"referenceID": 23, "context": "In supervised single channel source separation (SCSS), NMF is used in two main stages, the training stage and the separation stage (Schmidt and Olsson, 2006; Grais and Erdogan, 2011a,b,c; Grais et al., 2012; Grais and Erdogan, 2012c).", "startOffset": 131, "endOffset": 233}, {"referenceID": 15, "context": "In supervised single channel source separation (SCSS), NMF is used in two main stages, the training stage and the separation stage (Schmidt and Olsson, 2006; Grais and Erdogan, 2011a,b,c; Grais et al., 2012; Grais and Erdogan, 2012c).", "startOffset": 131, "endOffset": 233}, {"referenceID": 4, "context": "In Fevotte et al. (2009), Markov chain prior model for smoothness was used within a Bayesian framework in regularized NMF with Itakura-Saito (IS-NMF) divergence.", "startOffset": 3, "endOffset": 25}, {"referenceID": 4, "context": "In Fevotte et al. (2009), Markov chain prior model for smoothness was used within a Bayesian framework in regularized NMF with Itakura-Saito (IS-NMF) divergence. In Virtanen et al. (2008), the conjugate prior distributions on the NMF weights and basis matrices solutions with the Poisson observation model within Bayesian framework was introduced.", "startOffset": 3, "endOffset": 188}, {"referenceID": 3, "context": "The Gamma distribution and the Gamma Markov chain (Cemgil and Dikmen, 2007) were used as priors for the basis and weights/gains matrices respectively in Virtanen et al. (2008). A mixture of Gamma prior model was used as a prior for the basis matrix in Virtanen and Cemgil (2009).", "startOffset": 51, "endOffset": 176}, {"referenceID": 3, "context": "The Gamma distribution and the Gamma Markov chain (Cemgil and Dikmen, 2007) were used as priors for the basis and weights/gains matrices respectively in Virtanen et al. (2008). A mixture of Gamma prior model was used as a prior for the basis matrix in Virtanen and Cemgil (2009). The regularized NMF with smoothness and spatial decorrelation constraints was used in Chen et al.", "startOffset": 51, "endOffset": 279}, {"referenceID": 3, "context": "The Gamma distribution and the Gamma Markov chain (Cemgil and Dikmen, 2007) were used as priors for the basis and weights/gains matrices respectively in Virtanen et al. (2008). A mixture of Gamma prior model was used as a prior for the basis matrix in Virtanen and Cemgil (2009). The regularized NMF with smoothness and spatial decorrelation constraints was used in Chen et al. (2006) for EEG applications.", "startOffset": 51, "endOffset": 385}, {"referenceID": 3, "context": "The Gamma distribution and the Gamma Markov chain (Cemgil and Dikmen, 2007) were used as priors for the basis and weights/gains matrices respectively in Virtanen et al. (2008). A mixture of Gamma prior model was used as a prior for the basis matrix in Virtanen and Cemgil (2009). The regularized NMF with smoothness and spatial decorrelation constraints was used in Chen et al. (2006) for EEG applications. In Cichocki et al. (2006), and Chen et al.", "startOffset": 51, "endOffset": 433}, {"referenceID": 3, "context": "The Gamma distribution and the Gamma Markov chain (Cemgil and Dikmen, 2007) were used as priors for the basis and weights/gains matrices respectively in Virtanen et al. (2008). A mixture of Gamma prior model was used as a prior for the basis matrix in Virtanen and Cemgil (2009). The regularized NMF with smoothness and spatial decorrelation constraints was used in Chen et al. (2006) for EEG applications. In Cichocki et al. (2006), and Chen et al. (2006), a variety of constrained NMF algorithms were used for different applications.", "startOffset": 51, "endOffset": 457}, {"referenceID": 20, "context": "GMMs are used to model the multi-modal nature in speech feature vectors due to phonetic differences, speaking styles, gender, accents (Rabiner and Juang, 1993).", "startOffset": 134, "endOffset": 159}, {"referenceID": 9, "context": "In Grais and Erdogan (2012b), the prior GMM that models the valid weight combinations for each source is used to guide the NMF solution for the gains matrix during the separation stage.", "startOffset": 3, "endOffset": 29}, {"referenceID": 9, "context": "In Grais and Erdogan (2012b), the prior GMM that models the valid weight combinations for each source is used to guide the NMF solution for the gains matrix during the separation stage. The priors in Grais and Erdogan (2012b) are enforced by maximizing the log-likelihood of the NMF solution with the trained prior GMMs.", "startOffset": 3, "endOffset": 226}, {"referenceID": 9, "context": "In Grais and Erdogan (2012b), the prior GMM that models the valid weight combinations for each source is used to guide the NMF solution for the gains matrix during the separation stage. The priors in Grais and Erdogan (2012b) are enforced by maximizing the log-likelihood of the NMF solution with the trained prior GMMs. The priors in Grais and Erdogan (2012b) are enforced without evaluating how good the NMF solution is without using the", "startOffset": 3, "endOffset": 361}, {"referenceID": 2, "context": "This is the main advantage of the proposed regularized NMF compared to the regularization using the loglikelihood of the GMM prior or other prior distributions (Grais and Erdogan, 2012a,b; Canny, 2004).", "startOffset": 160, "endOffset": 201}, {"referenceID": 7, "context": "For audio source separation applications, the Itakura-Saito (IS-NMF) divergence cost function (Fevotte et al., 2009) is usually used.", "startOffset": 94, "endOffset": 116}, {"referenceID": 7, "context": "This cost function is found to be a good measurement for the perceptual differences between different audio signals (Fevotte et al., 2009; Jaureguiberry et al., 2011).", "startOffset": 116, "endOffset": 166}, {"referenceID": 16, "context": "This cost function is found to be a good measurement for the perceptual differences between different audio signals (Fevotte et al., 2009; Jaureguiberry et al., 2011).", "startOffset": 116, "endOffset": 166}, {"referenceID": 7, "context": "The IS-NMF solutions for equation (2) can be computed by alternating multiplicative updates of B and G (Fevotte et al., 2009; Jaureguiberry et al., 2011) as:", "startOffset": 103, "endOffset": 153}, {"referenceID": 16, "context": "The IS-NMF solutions for equation (2) can be computed by alternating multiplicative updates of B and G (Fevotte et al., 2009; Jaureguiberry et al., 2011) as:", "startOffset": 103, "endOffset": 153}, {"referenceID": 7, "context": "used with matrices of power spectral densities of the source signals (Fevotte et al., 2009; Jaureguiberry et al., 2011).", "startOffset": 69, "endOffset": 119}, {"referenceID": 16, "context": "used with matrices of power spectral densities of the source signals (Fevotte et al., 2009; Jaureguiberry et al., 2011).", "startOffset": 69, "endOffset": 119}, {"referenceID": 15, "context": "In conventional single channel source separation using NMF without regularization (Grais et al., 2012), there are two main stages to find estimates for S1 and S2 in equation (7).", "startOffset": 82, "endOffset": 102}, {"referenceID": 9, "context": "The regularization parameter in Grais and Erdogan (2012b) was playing two important roles.", "startOffset": 32, "endOffset": 58}, {"referenceID": 9, "context": "The regularization parameter in Grais and Erdogan (2012b) was playing two important roles. The first role was to match the scale of the IS-NMF divergence term with the scale of the log-likelihood prior term. The second role was to decide how much the regularized NMF cost function needs to rely on the prior term. The results in Grais and Erdogan (2012b) show that, when the source i has higher energy level than 12", "startOffset": 32, "endOffset": 355}, {"referenceID": 27, "context": "In the cases when the conjugate prior models of the NMF solutions were used (Virtanen et al., 2008; Canny, 2004), the hyperparameters of the prior models were also chosen manually.", "startOffset": 76, "endOffset": 112}, {"referenceID": 2, "context": "In the cases when the conjugate prior models of the NMF solutions were used (Virtanen et al., 2008; Canny, 2004), the hyperparameters of the prior models were also chosen manually.", "startOffset": 76, "endOffset": 112}, {"referenceID": 7, "context": "The conjugate prior models usually enforced on NMF solutions using a Bayesian framework (Fevotte et al., 2009; Virtanen et al., 2008; Canny, 2004).", "startOffset": 88, "endOffset": 146}, {"referenceID": 27, "context": "The conjugate prior models usually enforced on NMF solutions using a Bayesian framework (Fevotte et al., 2009; Virtanen et al., 2008; Canny, 2004).", "startOffset": 88, "endOffset": 146}, {"referenceID": 2, "context": "The conjugate prior models usually enforced on NMF solutions using a Bayesian framework (Fevotte et al., 2009; Virtanen et al., 2008; Canny, 2004).", "startOffset": 88, "endOffset": 146}, {"referenceID": 7, "context": "The values of the regularization parameters in Grais and Erdogan (2012b) was chosen manually for every energy level for each source.", "startOffset": 47, "endOffset": 73}, {"referenceID": 2, "context": ", 2008; Canny, 2004), the hyperparameters of the prior models were also chosen manually. The conjugate prior models usually enforced on NMF solutions using a Bayesian framework (Fevotte et al., 2009; Virtanen et al., 2008; Canny, 2004). In Grais and Erdogan (2012b), it was also shown that, the hyper-parameter choices for the conjugate prior models can also depend on the energy level differences of the source signals in the mixed signal.", "startOffset": 8, "endOffset": 266}, {"referenceID": 9, "context": "Motivation for the proposed regularized NMF In this work, we try to use prior GMMs to guide the solution of the gains matrix during the separation stage using regularized NMF as in Grais and Erdogan (2012b) but following a totally different regularization strategy.", "startOffset": 181, "endOffset": 207}, {"referenceID": 9, "context": "Motivation for the proposed regularized NMF In this work, we try to use prior GMMs to guide the solution of the gains matrix during the separation stage using regularized NMF as in Grais and Erdogan (2012b) but following a totally different regularization strategy. We also try to find a way to estimate how much the solution of the regularized NMF needs to rely on the prior GMMs automatically not manually as in Grais and Erdogan (2012b). The way of finding how much the regularized NMF solution of the gains matrix needs to rely on the prior GMM is by measuring how far the statistics of the solution of the gains matrix Gi in (9) is from the statistics of the solution of the valid gains matrix solution", "startOffset": 181, "endOffset": 440}, {"referenceID": 9, "context": "The matrix G i in (8) is used to train a prior GMM for the expected (valid) weight combinations that can exist in the gains matrix for source i as in Grais and Erdogan (2012b). The solution of the gains submatrix Gi in (9) can be seen as a deformed observation that needs to be restored using MMSE estimate under its corresponding GMM prior for source i.", "startOffset": 150, "endOffset": 176}, {"referenceID": 6, "context": "In training GMM, the expectation maximization (EM) algorithm (Dempster et al., 1977) is used to learn the GMM parameters (\u03c0k,\u03bck,\u03a3k, \u2200k = {1, 2, .", "startOffset": 61, "endOffset": 84}, {"referenceID": 28, "context": "We use the logarithm because it has been shown that the logarithm of a variable taking values between 0 and 1 can be modeled well by a GMM (Wessel et al., 2000).", "startOffset": 139, "endOffset": 160}, {"referenceID": 17, "context": "Even, Parzen density priors (Kim et al., 2007) can be seen under the same framework.", "startOffset": 28, "endOffset": 46}, {"referenceID": 9, "context": "In Grais and Erdogan (2012b), a GMM was used as the prior model for the gains matrix, and the solution of the gains matrix was encouraged to increase its log-likelihood with the prior model using this regularized NMF cost function.", "startOffset": 3, "endOffset": 29}, {"referenceID": 9, "context": "In Grais and Erdogan (2012b), a GMM was used as the prior model for the gains matrix, and the solution of the gains matrix was encouraged to increase its log-likelihood with the prior model using this regularized NMF cost function. The regularization parameters in Grais and Erdogan (2012b) were the only tools to control how much the regularized NMF relies on the prior models based on the energy differences of the sources in the mixed signal.", "startOffset": 3, "endOffset": 291}, {"referenceID": 9, "context": "By deciding automatically how much the regularized NMF needs to rely on the prior we conjecture that, we do not need to manually change the values for the regularization parameter based on the energy differences of the sources in the mixed signal 1 to improve the performance of NMF as in Grais and Erdogan (2012b). We use the following way of measuring how far the conventional NMF solution is from the prior templates: We can see the solution of the conventional NMF as distorted observations of a true/valid template.", "startOffset": 289, "endOffset": 315}, {"referenceID": 8, "context": "Given the prior GMM parameters which are considered fixed here, the update of \u03a8 is found based on the sufficient statistics \u1e91n and R\u0302n as follows (Rosti and Gales, 2001, 2004; Ghahramani and Hinton, 1997) [Appendix A]:", "startOffset": 146, "endOffset": 204}, {"referenceID": 8, "context": "Given the GMM prior parameters and the uncertainty measurement \u03a8, the MMSE estimate of each pattern xn given its observation qn under the observation model in equation (14) can be found similar to Rosti and Gales (2001, 2004), and Ghahramani and Hinton (1997) as in Appendix A as follows: f (qn) = K \u2211", "startOffset": 231, "endOffset": 260}, {"referenceID": 17, "context": "The multiplicative update rule for G can be found by following the same procedures as in Virtanen (2007); Bertin et al.", "startOffset": 89, "endOffset": 105}, {"referenceID": 0, "context": "The multiplicative update rule for G can be found by following the same procedures as in Virtanen (2007); Bertin et al. (2010); Grais and Erdogan", "startOffset": 106, "endOffset": 127}, {"referenceID": 25, "context": "The cost function is shown to be nonincreasing under the update rule (Virtanen, 2007; Bertin et al., 2010): G\u2190 G\u2297 \u2207 \u2212 GC \u2207+GC , (29)", "startOffset": 69, "endOffset": 106}, {"referenceID": 1, "context": "The cost function is shown to be nonincreasing under the update rule (Virtanen, 2007; Bertin et al., 2010): G\u2190 G\u2297 \u2207 \u2212 GC \u2207+GC , (29)", "startOffset": 69, "endOffset": 106}, {"referenceID": 9, "context": "There is no need to change the values of the regularization parameters according to the energy differences of the source signals in the mixed signal as in Grais and Erdogan (2012b). Reasonable values for the regularization parameters are chosen manually and kept fixed in this work.", "startOffset": 155, "endOffset": 181}, {"referenceID": 9, "context": "There is no need to change the values of the regularization parameters according to the energy differences of the source signals in the mixed signal as in Grais and Erdogan (2012b). Reasonable values for the regularization parameters are chosen manually and kept fixed in this work. Another main difference between the regularized NMF in Grais and Erdogan (2012b) that is shown in equation (11) and the proposed regularized NMF in this paper is related to the training procedures for the source models.", "startOffset": 155, "endOffset": 364}, {"referenceID": 9, "context": "There is no need to change the values of the regularization parameters according to the energy differences of the source signals in the mixed signal as in Grais and Erdogan (2012b). Reasonable values for the regularization parameters are chosen manually and kept fixed in this work. Another main difference between the regularized NMF in Grais and Erdogan (2012b) that is shown in equation (11) and the proposed regularized NMF in this paper is related to the training procedures for the source models. In both works, the main aim of the training stage is to train the basis matrices and the gains prior GMMs for the source signals. In Grais and Erdogan (2012b), to match between the way the trained models were used during training with the way they were used during separation, the basis matrices and the prior GMM parameters were learned jointly using the regularized NMF cost function in (11).", "startOffset": 155, "endOffset": 662}, {"referenceID": 9, "context": "There is no need to change the values of the regularization parameters according to the energy differences of the source signals in the mixed signal as in Grais and Erdogan (2012b). Reasonable values for the regularization parameters are chosen manually and kept fixed in this work. Another main difference between the regularized NMF in Grais and Erdogan (2012b) that is shown in equation (11) and the proposed regularized NMF in this paper is related to the training procedures for the source models. In both works, the main aim of the training stage is to train the basis matrices and the gains prior GMMs for the source signals. In Grais and Erdogan (2012b), to match between the way the trained models were used during training with the way they were used during separation, the basis matrices and the prior GMM parameters were learned jointly using the regularized NMF cost function in (11). The joint training for the source models was introduced in Grais and Erdogan (2012b) to improve the separation performance.", "startOffset": 155, "endOffset": 983}, {"referenceID": 9, "context": "Since, we needed to update (retrain) the GMM parameters at each NMF iteration, joint training slowed down the training of the source models in Grais and Erdogan (2012b). Another problem of using joint training is that, we had other regularization parameters during the training stage that needed to be chosen.", "startOffset": 143, "endOffset": 169}, {"referenceID": 9, "context": "Since, we needed to update (retrain) the GMM parameters at each NMF iteration, joint training slowed down the training of the source models in Grais and Erdogan (2012b). Another problem of using joint training is that, we had other regularization parameters during the training stage that needed to be chosen. Using joint training duplicates the number of the regularization parameters that need to be chosen. Choosing the regularization parameters in Grais and Erdogan (2012b) was done using validation data.", "startOffset": 143, "endOffset": 478}, {"referenceID": 9, "context": "Since, we needed to update (retrain) the GMM parameters at each NMF iteration, joint training slowed down the training of the source models in Grais and Erdogan (2012b). Another problem of using joint training is that, we had other regularization parameters during the training stage that needed to be chosen. Using joint training duplicates the number of the regularization parameters that need to be chosen. Choosing the regularization parameters in Grais and Erdogan (2012b) was done using validation data. That means, in Grais and Erdogan (2012b) we had to train many source models (basis matrix and prior GMM) for different regularization parameter values.", "startOffset": 143, "endOffset": 551}, {"referenceID": 9, "context": "Since, we needed to update (retrain) the GMM parameters at each NMF iteration, joint training slowed down the training of the source models in Grais and Erdogan (2012b). Another problem of using joint training is that, we had other regularization parameters during the training stage that needed to be chosen. Using joint training duplicates the number of the regularization parameters that need to be chosen. Choosing the regularization parameters in Grais and Erdogan (2012b) was done using validation data. That means, in Grais and Erdogan (2012b) we had to train many source models (basis matrix and prior GMM) for different regularization parameter values. Then, we chose the best combination for the regularization parameter values in training and separation stages that gave the best results during the separation stage. In the case of using MMSE estimate regularization for NMF, we do not need to use joint training. In this paper, we do not need to consider solving the regularized NMF in (27) during the training stage to solve (8). In the training stage, the training data for each source is assumed to be clean data. Since the spectrogram of each source training data represents clean source data, the NMF solution for the gains matrix can not be seen as a distorted image. Therefore, the deformation measurement parameter \u03a8 is a matrix of zeros. When \u03a8 = 0, the MMSE estimates prior term in (27) will disappear because \u2211K k=1 \u03b3kn = 1. Then, the regularized NMF (27) becomes just NMF. That means, we do not need to use the regularized NMF during the training stage which is not the case in Grais and Erdogan (2012b). Here in the training stage, we just need to use IS-NMF to decompose the spectrogram of the training data into trained basis and gains matrices.", "startOffset": 143, "endOffset": 1628}, {"referenceID": 7, "context": "The spectral masks can be seen as the Wiener filter as in Fevotte et al. (2009). The estimated source signals \u015d1(t) and \u015d2(t) can be found by using inverse STFT of their corresponding STFTs \u015c1(t, f) and \u015c2(t, f).", "startOffset": 58, "endOffset": 80}, {"referenceID": 24, "context": "(SIR), which is defined as the ratio of the target energy to the interference error due to the music signal only (Vincent et al., 2006).", "startOffset": 113, "endOffset": 135}, {"referenceID": 26, "context": "In the sparsity prior, the NMF solution of the gains matrix was enforced to be sparse (Virtanen and Cemgil, 2009; Schmidt and Olsson, 2006).", "startOffset": 86, "endOffset": 139}, {"referenceID": 23, "context": "In the sparsity prior, the NMF solution of the gains matrix was enforced to be sparse (Virtanen and Cemgil, 2009; Schmidt and Olsson, 2006).", "startOffset": 86, "endOffset": 139}, {"referenceID": 26, "context": "Enforcing sparsity on the NMF solution of the gains matrix is equivalent to model the prior of the gains matrix using exponential distribution with parameter \u03bb (Virtanen and Cemgil, 2009).", "startOffset": 160, "endOffset": 187}, {"referenceID": 9, "context": "In regularized NMF with GMM based log-likelihood prior we trained the NMF bases and the prior GMM parameters jointly as shown in Grais and Erdogan (2012b). In the sparse NMF case, we got best results when \u03bb = 0.", "startOffset": 129, "endOffset": 155}, {"referenceID": 26, "context": "Comparing the relative improvements in dB that we got in this paper with the achieved improvements in other works (Wilson et al., 2008b,a; Virtanen and Cemgil, 2009; Virtanen, 2007) we can see that the, improvements in this", "startOffset": 114, "endOffset": 181}, {"referenceID": 25, "context": "Comparing the relative improvements in dB that we got in this paper with the achieved improvements in other works (Wilson et al., 2008b,a; Virtanen and Cemgil, 2009; Virtanen, 2007) we can see that the, improvements in this", "startOffset": 114, "endOffset": 181}], "year": 2013, "abstractText": "We propose a new method to enforce priors on the solution of the nonnegative matrix factorization (NMF). The proposed algorithm can be used for denoising or single-channel source separation (SCSS) applications. The NMF solution is guided to follow the Minimum Mean Square Error (MMSE) estimates under Gaussian mixture prior models (GMM) for the source signal. In SCSS applications, the spectra of the observed mixed signal are decomposed as a weighted linear combination of trained basis vectors for each source using NMF. In this work, the NMF decomposition weight matrices are treated as a distorted image by a distortion operator, which is learned directly from the observed signals. The MMSE estimate of the weights matrix under GMM prior and log-normal distribution for the distortion is then found to improve the NMF decomposition results. The MMSE estimate is embedded within the optimization objective to form a novel regularized NMF cost function. The corresponding update rules for the new objectives are derived in this paper. Experimental results show that, the proposed regularized NMF alPreprint submitted to Elsevier March 1, 2013 ar X iv :1 30 2. 72 83 v1 [ cs .L G ] 2 8 Fe b 20 13 gorithm improves the source separation performance compared with using NMF without prior or with other prior models.", "creator": "LaTeX with hyperref package"}}}