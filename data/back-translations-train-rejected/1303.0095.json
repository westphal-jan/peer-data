{"id": "1303.0095", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2013", "title": "Label-dependent Feature Extraction in Social Networks for Node Classification", "abstract": "A new method of feature extraction in the social network for within-network classification is proposed in the paper. The method provides new features calculated by combination of both: network structure information and class labels assigned to nodes. The influence of various features on classification performance has also been studied. The experiments on real-world data have shown that features created owing to the proposed method can lead to significant improvement of classification accuracy.", "histories": [["v1", "Fri, 1 Mar 2013 06:31:02 GMT  (527kb)", "http://arxiv.org/abs/1303.0095v1", "feature extraction, label-dependent features, classification, social network analysis, AMD social network"]], "COMMENTS": "feature extraction, label-dependent features, classification, social network analysis, AMD social network", "reviews": [], "SUBJECTS": "cs.SI cs.LG", "authors": ["tomasz kajdanowicz", "przemyslaw kazienko", "piotr doskocz"], "accepted": false, "id": "1303.0095"}, "pdf": {"name": "1303.0095.pdf", "metadata": {"source": "CRF", "title": "Label-dependent Feature Extraction in Social Networks for Node Classification", "authors": ["Tomasz Kajdanowicz", "Przemys\u0142aw Kazienko", "Piotr Doskocz"], "emails": ["kazienko@pwr.wroc.pl", "piotr.doskocz@pwr.wroc.pl"], "sections": [{"heading": null, "text": "Keywords: feature extraction, label-dependent features, classification, social network analysis, AMD social network"}, {"heading": "1 Introduction", "text": "These relationships describe each object independently of each other, which means that no direct correlations between objects are taken into account in the classification phase. An exception may be additional input characteristics that contain information about the entire group to which a particular object belongs. However, it requires a clustering process that needs to be initiated beforehand. There are some applications and research methods, especially related to social networks, that are able to produce data with dependencies between the labels of interconnected objects, which are called relational autocorrelation. [16] Based on these connections, additional input information should be inserted into the classification process. If the objects under consideration are human and the classification is based on their profiles, the social network can be extracted from complementary data (unlike human profiles)."}, {"heading": "2 Related Work", "text": "In recent years, a large number of papers have appeared describing models and techniques for classifying network data. Similar to the classical problems of machine learning, the classification of network data requires special solutions for feature extraction, high performance and unattended learning algorithms, sparse data processing, etc. Usually, network classification problems are solved with two main approaches: within a network and cross-network inferences. Within the network classification, for which training institutes are directly connected to entities, they remain in contrast to network classifications in which the models of other similar networks are applied. [11] Overall, the networked data have several unique characteristics that simultaneously complicate the leverage of learning and classification."}, {"heading": "3 Features Extraction from the Social Network", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 General Terms", "text": "Suppose that a social network is a graph G = (V, E, X, L, Y, W) in which V is a set of nodes (objects, social units); E is a set of edges (connections) eij between two nodes vi and vj, E = {eij: vi, vjV, i \u0445 j}; X is a set of attribute vectors xi, a separate one for each node vi (a profile of vi), X = {xi: viVxiX}; L is the set of different labels (classes) that can be assigned to nodes; Y is a list of actual labels that can be assigned to nodes, Y = {< vi, yi >: viV yiL}; W is a set of edge weights, wijW wij \u2265 0 and wij indicates the strength of edges eij. After we know the values of yi for a given subset of nodes VKV, the classification process can be described as a step of classifying Vecu in the first attributes of the Vecu."}, {"heading": "3.2 Features Extraction", "text": "Character extraction from social networks is a generic term for methods of constructing variables from the connectivity graph that express the position and meaning of each node in relation to the others. As mentioned in Section 1, the generated characteristics may be label independent or label dependent. To provide clarity, the work in describing label dependent characteristics assumes that the feature extraction is based only on a correlation between the label of the object and the observed labels of other objects in its neighborhood, see Fig. 1.Three examples of basic label independent and three label dependent characteristics are presented in the following subsections, as well as a generalization for label dependent feature extraction."}, {"heading": "3.2.1 Label-independent Features", "text": "Betweennes Centrality Betweenness Centrality of Node vi dvuted to what extent vi is between other nodes. Nodes with high intermediate nodes are very important in the network, as other nodes are connected mainly by them. Betweenness Centrality B (G, vi) of Node vi in diagram G can be calculated according to the following equation: ikjVGvv kj ikj i ikj i ikj i vvvGP vGB); (,,, (1) where: P (G, vi, vj) - a function return the number of shorest path between vi i ikj i ikj vvGP vGB); P (G, vj, vk, vi) - a function that returns the number of shortest path between vi and vj, which pass through vi in diagram G. Obviously equation 1 is calculated only for pairs vj, vk, for which there is a path from vj vvk, vi)."}, {"heading": "3.2.2 Label-dependent Features", "text": "It means that a sub-network for a particular label l consists only of those nodes that share a label (class) l with all the edges that connect those selected nodes. To this end, a new selection operator O (G, l) is defined for each label. There is a sub-network Gl with l: Gl = (Vl, El, Xl, {l}, Yl, Wl) so that Vl = {vi, Wl) a new selection operator O (G, l) is defined for each label L. There is a sub-network Gl with l: Gl = l}, El = {eij: vi, vjVleijE}, Xl = {xl: vlVlVlVlxlX}.Afterwards, for each sub-network Gl), new features are compiled."}, {"heading": "3.2.3 General Method for Label-dependent Features Extraction", "text": "In the field of social network analysis (SNA), a number of measures have been introduced that characterize network nodes, the majority of which are label-independent and it is possible to define many methods that extract label-dependent characteristics based on these characteristics. A general concept of creating a label-dependent attribute Ml (G, l, vi) for label and node vi in social network G applies label-independent attribute M to the corresponding label-dependent subnetwork Gl = O (G, l) as follows: Ml (G, l, vi) = M (Gl, vi), (6) where: Ml (Gl, vi) - means any structural network measure for the node vi that is applied to the subnetwork Gl = O (G, l), e.g. degree, between path or cluster coefficient; obviously, Ml (G, l, vi) is calculated separately for each label using the corresponding subnetwork Gl = Cardvl = Eq (other version of Eq), 6)."}, {"heading": "4 Experimental Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Data Set", "text": "The dataset used for experiments, Attendee Meta-Data (AMD), was downloaded from the UCI Network Data Repository (http: / / networkdata.ics.uci.edu / data.php? d = amdhope).The AMD dataset was the result of a project using RFID (Radio Frequency Identification) technology to connect conference attendees at the \"The Last HOPE\" conference in July 2008 in New York City. All attendees were given an RFID badge that uniquely identifies them and tracked them across the conference room.The dataset contains descriptions of attendees, their interactions via instant messages, as well as their location during the conference.Conference attendees were asked to mark themselves based on a diverse interest."}, {"heading": "4.2 Extracted features", "text": "In accordance with the methodology presented in Section 3, 17 attributes were calculated in the experiments, see Table 1. The extracted attributes were grouped into 4 groups, the first containing raw data attributes, the second introducing brand-independent network-based attributes, the third introducing brand-specific attributes derived from the proposed method, the last, fourth adding all previously presented attributes, and finally, the 20 datasets obtained in the experiment can be downloaded in arff format from http: / / www.zsi.pwr.wroc.pl / ~ kazienko / datasets / amd / amd.zip to predict an interest assigned to a specific person."}, {"heading": "4.3 Classification", "text": "The experiments were conducted for 20 datasets with three classification algorithms, AdaBoost, Multilayered Perceptron, SVM, with the settings in Table 2 being the same for each of the four feature groups (Table 1), classified in 10% - 90% of the marked or unmarked nodes using 10-fold validation."}, {"heading": "5 Results", "text": "The results obtained have shown that the average accuracy of classification using different sets of features really differs. As shown in Fig. 6, the average accuracy of features 3 and 4 is about 23% higher than that of features 1 and 2. At the same time, F-measurement and precision are improved by the use of feature-dependent sets (Fig. 3 and 4) by 33% and 35%, respectively, see Table 3. Regardless of the feature set used, all classification algorithms used seem to be more stable than features 1 and 2. In particular, the standard deviation corresponds to the accuracy of 20 sets of data in the first case and 12% in the second. Furthermore, experiments have shown that classification based on feature sets 3 and 4 appears to be more stable than in features 1 and 2. The standard deviation of the accuracy of 20 sets corresponds to 1% in the first case and 12% in the second."}, {"heading": "6 Conclusions and Future Work", "text": "The main principle behind the method is based on selective definitions of sub-diagrams for which new characteristics are defined and calculated. These new characteristics provide additional quantitative information about the network context of the case to be classified. According to the experimental evidence gathered, the proposed brand-specific trait extraction appears to be much more effective and greatly improves classification performance. Indeed, the results achieved so good were surprising to the authors. These results have shown that the new approach to classification, which is extended by traits derived from the social network, has very satisfactory and promising outcomes. It may even happen that the regular characteristics should only reduce the classification indicators and be removed from the input trace. This phenomenon probably stems from the general background of both trait sources. Human profiles are actually the voluntarily collected data, whereas social networks are built on real human activities. There is a crucial difference between a statement of \"I am interested in mountains\" and \"information about real life.\""}], "references": [{"title": "Within-network classification using local structure similarity. European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases ECML PKKD", "author": ["C. Desrosiers", "G. Karypis"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Learning probabilistic relational models", "author": ["N. Friedman", "L. Getoor", "D. Koller", "A. Pfeffer"], "venue": "In proceedings of the International Joint Conference on Artificial Intelligence IJCAI-99,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Graph Drawing by Force-directed Placement", "author": ["T. Fruchterman", "E. Reingold"], "venue": "Software \u2013 Practice and Experience 21,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1991}, {"title": "Leveraging Label-Independent Features for Classification in Sparsely Labeled Networks: An Empirical Study", "author": ["B. Gallagher", "T. Eliassi-Rad"], "venue": "In proceedings of the Second ACM SIGKDD Workshop on Social Network Mining and Analysis (SNA-KDD'08),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Using ghost edges for classification in sparsely labeled networks", "author": ["B. Gallagher", "H. Tong", "T. Eliassi-Rad", "C. Faloutsos"], "venue": "In proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Learning probabilistic models of link structure", "author": ["L. Getoor", "N. Friedman", "D. Koller", "B. Taskar"], "venue": "Journal of Machine Learning Research 3,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Why collective inference improves relational classification", "author": ["D. Jensen", "J. Neville", "B. Gallagher"], "venue": "In the proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Boosting Algorithm with Sequenceloss Cost Function for Structured Prediction", "author": ["T. Kajdanowicz", "P. Kazienko", "J. Kraszewski"], "venue": "The 5th International Conference on Hybrid Artificial Intelligence Systems, HAIS 2010, San Sebastia\u0301n,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Profile of the Social Network in Photo Sharing Systems", "author": ["P. Kazienko", "K. Musia\u0142", "T. Kajdanowicz"], "venue": "14th Americas Conference on Information Systems,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Link-based classification", "author": ["Q. Lu", "L. Getoor"], "venue": "In proceedings of the 20th International Conference on Machine Learning ICML 2003,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "A brief survey of machine learning methods for classification in networked data and an application to suspicion scoring", "author": ["S. Macskassy", "F. Provost"], "venue": "Workshop on Statistical Network Learning at 23rd International Conference on Machine Learning ICML 2006,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Classification in networked data: A toolkit and a univariate case study", "author": ["S. Macskassy", "F. Provost"], "venue": "Journal of Machine Learning Research", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Birds of a feather: Homophily in social networks", "author": ["M. McPherson", "L. Smith-Lovin", "J. Cook"], "venue": "Annual Review of Sociology 27,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2001}, {"title": "Relational dependency networks", "author": ["J. Neville", "D. Jensen"], "venue": "Journal of Machine Learning Research 8,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Collective classification in network data", "author": ["P. Sen", "G. Namata", "M. Bilgic", "L. Getoor", "B. Gallagher", "T. Eliassi-Rad"], "venue": "Artificial Intelligence Magazine 29(3),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Social network analysis: Methods and applications", "author": ["S. Wasserman", "K. Faust"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1994}], "referenceMentions": [{"referenceID": 13, "context": "There are some applications and research methods, especially related to social networks, which are able to produce data with dependencies between labels of interconnected objects, referred as relational autocorrelation [16].", "startOffset": 219, "endOffset": 223}, {"referenceID": 8, "context": "If the considered objects are humans and the classification is utilized on their profiles then the social network can be extracted from complementary data (different from people\u2019s profiles) about common activities and mutual communication [9, 10, 15].", "startOffset": 239, "endOffset": 250}, {"referenceID": 15, "context": "Overall, a social network is a set of nodes (human entities, objects) and node-node relationship between pairs of nodes [18].", "startOffset": 120, "endOffset": 124}, {"referenceID": 14, "context": "According to [17], all network objects may be described by three distinct types of information that can be easily used in label classification: correlation between the object\u2019s label (class) and its attributes, correlation between the object\u2019s label and the observed (known) labels of other objects in its neighborhood and, consequently, correlation between the object\u2019s label and unobserved (unknown) labels of other objects in its neighborhood.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "Basic task of within-network classification [1, 12] is to assign the correct labels to the unlabeled nodes from a set of the possible class labels.", "startOffset": 44, "endOffset": 51}, {"referenceID": 10, "context": "Basic task of within-network classification [1, 12] is to assign the correct labels to the unlabeled nodes from a set of the possible class labels.", "startOffset": 44, "endOffset": 51}, {"referenceID": 9, "context": "Within-network classification, for which training entities are connected directly to entities, whose labels are to be classified, stays in contrast to across-network classification, where models learnt from one network are applied to another similar network [11].", "startOffset": 258, "endOffset": 262}, {"referenceID": 6, "context": "More generally, network data allow the use of the features of the node\u2019s neighbors to label them, although it must be performed with care to avoid increase of variance estimation [7].", "startOffset": 179, "endOffset": 182}, {"referenceID": 1, "context": "Among others, statistical relational learning (SRL) techniques were introduced, including probabilistic relational models, relational Markov networks, and probabilistic entity-relationship models [2, 6, 13, 16].", "startOffset": 196, "endOffset": 210}, {"referenceID": 5, "context": "Among others, statistical relational learning (SRL) techniques were introduced, including probabilistic relational models, relational Markov networks, and probabilistic entity-relationship models [2, 6, 13, 16].", "startOffset": 196, "endOffset": 210}, {"referenceID": 11, "context": "Among others, statistical relational learning (SRL) techniques were introduced, including probabilistic relational models, relational Markov networks, and probabilistic entity-relationship models [2, 6, 13, 16].", "startOffset": 196, "endOffset": 210}, {"referenceID": 13, "context": "Among others, statistical relational learning (SRL) techniques were introduced, including probabilistic relational models, relational Markov networks, and probabilistic entity-relationship models [2, 6, 13, 16].", "startOffset": 196, "endOffset": 210}, {"referenceID": 14, "context": "The most known implementations of the first approach are iterative classification (ICA) and Gibbs sampling algorithm (GS), whereas example of the latter are loopy belief propagation (LBP) and mean-field relaxation labeling (MF) [17].", "startOffset": 228, "endOffset": 232}, {"referenceID": 4, "context": "especially logForest, a logistic model based on links, wvRN, a relational neighbor model, SSL Gaussian random field model, ghostEdge, combination of statistical relational learning and semi-supervised learning for sparse networks and theirs collective classification supplements [5].", "startOffset": 279, "endOffset": 282}, {"referenceID": 3, "context": "According to [4] the derived features are divided into two categories: label-dependent (LD) and label-independent (LI).", "startOffset": 13, "endOffset": 16}, {"referenceID": 3, "context": "This problem is known as classification in sparsely labeled networks [4, 5].", "startOffset": 69, "endOffset": 75}, {"referenceID": 4, "context": "This problem is known as classification in sparsely labeled networks [4, 5].", "startOffset": 69, "endOffset": 75}, {"referenceID": 3, "context": "Social networks, being a network representation of interactions between people is a subject of research in terms of classification in networks as well [4].", "startOffset": 151, "endOffset": 154}, {"referenceID": 2, "context": "Visualization of the social network for the activism interest data set based on the class \u20180\u2019 neighborhood using Force-Directed Placement Algorithm [3].", "startOffset": 148, "endOffset": 151}, {"referenceID": 2, "context": "Visualization of the social network for the activism interest data set based on the class \u20181\u2019 neighborhood using Force-Directed Placement Algorithm [3].", "startOffset": 148, "endOffset": 151}, {"referenceID": 7, "context": "development of new ensemble algorithms, which would have network measures already incorporated, especially based on boosting concept [8].", "startOffset": 133, "endOffset": 136}], "year": 2010, "abstractText": "A new method of feature extraction in the social network for withinnetwork classification is proposed in the paper. The method provides new features calculated by combination of both: network structure information and class labels assigned to nodes. The influence of various features on classification performance has also been studied. The experiments on realworld data have shown that features created owing to the proposed method can lead to significant improvement of classification accuracy.", "creator": "PScript5.dll Version 5.2.2"}}}