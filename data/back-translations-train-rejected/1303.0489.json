{"id": "1303.0489", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2013", "title": "A Semantic approach for effective document clustering using WordNet", "abstract": "Now a days, the text document is spontaneously increasing over the internet, e-mail and web pages and they are stored in the electronic database format. To arrange and browse the document it becomes difficult. To overcome such problem the document preprocessing, term selection, attribute reduction and maintaining the relationship between the important terms using background knowledge, WordNet, becomes an important parameters in data mining. In these paper the different stages are formed, firstly the document preprocessing is done by removing stop words, stemming is performed using porter stemmer algorithm, word net thesaurus is applied for maintaining relationship between the important terms, global unique words, and frequent word sets get generated, Secondly, data matrix is formed, and thirdly terms are extracted from the documents by using term selection approaches tf-idf, tf-df, and tf2 based on their minimum threshold value. Further each and every document terms gets preprocessed, where the frequency of each term within the document is counted for representation. The purpose of this approach is to reduce the attributes and find the effective term selection method using WordNet for better clustering accuracy. Experiments are evaluated on Reuters Transcription Subsets, wheat, trade, money grain, and ship, Reuters 21578, Classic 30, 20 News group (atheism), 20 News group (Hardware), 20 News group (Computer Graphics) etc.", "histories": [["v1", "Sun, 3 Mar 2013 12:19:18 GMT  (219kb)", "http://arxiv.org/abs/1303.0489v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["leena h patil", "mohammed atique"], "accepted": false, "id": "1303.0489"}, "pdf": {"name": "1303.0489.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["harshleena23@rediffmail.com).", "atique_shaikh1@rediffmail.com)."], "sections": [{"heading": null, "text": "In fact, most of them are able to go in search of new paths that they want to take in order to understand the world. Most of them are able to go in search of new paths that they want to go in. Most of them are able to go in search of new paths that they want to go in. Most of them are able to go in search of new paths that they want to go in. Most of them are not able to go in search of new paths that they want to go in. Most of them are able to explore themselves."}, {"heading": "II. DOCUMENT PREPROCESSING", "text": "It describes the necessary processing of documents in order to obtain the underlying representation of documents. [7] Thousands of words are contained in a document that contains the terms that must be omitted in order to remove the terms that have a special meaning for the terminology. [8] The terms are divided into the following stages: 1, 2, 4, 5, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,"}, {"heading": "III. FEATURE SELECTION", "text": "In our approach, three different selection methods are used: tf-idf, tf-df, and tf2 to selectrepresentative terms of each document that is defined as the following threshold:. (1) tf-idf (terms).tf-idf (terms): It is referred to as tfi-dfij and used to define the meaning of the term tj within the document di.tfidfij = X logWhere is the frequency of the term in the document, andthe denominator is the frequency of all terms in the document, andtf is the frequency of all terms in the document."}, {"heading": "IV. EXPERIMENTAL RESULTS", "text": "In this section we evaluate experimentally the performance of the proposed algorithms. All experiments were performed on an Intel I5 processor, Windows 7 OS machine with 8 GB of storage space."}, {"heading": "13. Lingling Meng and Junzhong Gu, \u201cA New Method for Calculating Word Sense Similarity in WordNet\u201d,", "text": "International Journal of Signal Processing, Image Processing and Pattern Recognition Vol. 5, No. 3, September 2012.Data sets Number of terms Number of keytermsTf2Percentage of terms removedReuters - 21578 462 55 88.10Classic 30 309807 8974 97.1020 News Group (athesim) 185684 1004 99.4620 News Group (Computer Graphics) 164667 1005 99.3820 News Group (Hardware) 138843 1000 99.27Reuters Transcription Subset (Wheat) 1940 310 84.02Reuters Transcription Subset (Trade) 3394 215 93.66Reuters Transcription Subset (Ship) 1397 167 88.04Reuters Transcription Subset (Money) 2755 166 93.97Reuters Transcription Subset (Grain) 2102 290 86.20Reuters Transcription Subset (Corn) 2331 437 81.25"}], "references": [{"title": "Reuters-21578 text categorization test collection,\u201d1999.[Online", "author": ["D.D. Lewis"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "A comparison of document clustering techniques", "author": ["M. Steinbach", "G. Karypis", "V. Kumar"], "venue": "Proc. of the 6th ACM SIGKDD int'l conf. on Knowledge Discovery and Data Mining ,KDD,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "Hierarchical document clustering using frequent itemsets", "author": ["B. Fung", "K. Wang", "M. Ester"], "venue": "Proc. of SIAM Int'l Conf. on Data Mining, SDM'", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "A new unsupervised method for document clustering by using WordNet lexical and conceptual relations", "author": ["D.R. Recupero"], "venue": "Information Retrieval", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Frequent term-based text clustering", "author": ["F. Beil", "M. Ester", "X. Xu"], "venue": "Proc. of Int'l Conf. on knowledge Discovery and Data Mining, KDD'", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "An integration of fuzzy association rules and WordNet for document clustering", "author": ["C.L.Chen", "F.S.C. Tseng", "T. Liang"], "venue": "Proc. of the 13th Paci.c-Asia Conference on Knowledge Discovery and Data Mining, pp", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "An integration of WordNet and fuzzy association rule mining for multi-label document clustering, Data", "author": ["Chun-Ling Chen a", "Frank S.C. Tseng b", "Tyne Liang"], "venue": "Knowledge Engineering", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}], "referenceMentions": [{"referenceID": 6, "context": "[9][10]Because of this, text mining techniques are useful in processing these documents.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7]Thousands of words are present in a document set, the aim of this is to reduce dimensionality for having the better accuracy for classification.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[9]One major property is that there are extremely common words present and the explanation of the sentences still held after these stop-words are removed.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4][5]In this representation, the term frequency for each word is normalized by the inverse document frequency, or IDF.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4][5]In this representation, the term frequency for each word is normalized by the inverse document frequency, or IDF.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "Re0 includes 1504 documents with 13 classes [2].", "startOffset": 44, "endOffset": 47}], "year": 2013, "abstractText": "Abstract\u2014 Now a days, the text document is spontaneously increasing over the internet, e-mail and web pages and they are stored in the electronic database format. To arrange and browse the document it becomes difficult. To overcome such problem the document preprocessing, term selection, attribute reduction and maintaining the relationship between the important terms using background knowledge, WordNet, becomes an important parameters in data mining. In these paper the different stages are formed, firstly the document preprocessing is done by removing stop words, stemming is performed using porter stemmer algorithm, word net thesaurus is applied for maintaining relationship between the important terms, global unique words, and frequent word sets get generated, Secondly, data matrix is formed, and thirdly terms are extracted from the documents by using term selection approaches tf-idf, tf-df, and tf2 based on their minimum threshold value. Further each and every document terms gets preprocessed, where the frequency of each term within the document is counted for representation. The purpose of this approach is to reduce the attributes and find the effective term selection method using WordNet for better clustering accuracy. Experiments are evaluated on Reuters Transcription Subsets, wheat, trade, money grain, and ship, Reuters 21578, Classic 30, 20 News group (atheism), 20 News group (Hardware), 20 News group (Computer Graphics) etc.", "creator": "Microsoft\u00ae Office Word 2007"}}}