{"id": "1303.3754", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2013", "title": "A Last-Step Regression Algorithm for Non-Stationary Online Learning", "abstract": "The goal of a learner in standard online learning is to maintain an average loss close to the loss of the best-performing single function in some class. In many real-world problems, such as rating or ranking items, there is no single best target function during the runtime of the algorithm, instead the best (local) target function is drifting over time. We develop a novel last-step minmax optimal algorithm in context of a drift. We analyze the algorithm in the worst-case regret framework and show that it maintains an average loss close to that of the best slowly changing sequence of linear functions, as long as the total of drift is sublinear. In some situations, our bound improves over existing bounds, and additionally the algorithm suffers logarithmic regret when there is no drift. We also build on the H_infinity filter and its bound, and develop and analyze a second algorithm for drifting setting. Synthetic simulations demonstrate the advantages of our algorithms in a worst-case constant drift setting.", "histories": [["v1", "Fri, 15 Mar 2013 12:20:53 GMT  (443kb,D)", "http://arxiv.org/abs/1303.3754v1", "arXiv admin note: substantial text overlap witharXiv:1303.0140"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1303.0140", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["edward moroshko", "koby crammer"], "accepted": false, "id": "1303.3754"}, "pdf": {"name": "1303.3754.pdf", "metadata": {"source": "CRF", "title": "A Last-Step Regression Algorithm for Non-Stationary Online Learning", "authors": ["Edward Moroshko", "Koby Crammer"], "emails": [], "sections": [{"heading": null, "text": "The goal of a learner in standard online learning is to maintain an average loss close to the loss of the most powerful single function in a class. In many real-world problems, such as evaluations or rankings, there is not a single optimal target function during the lifetime of the algorithm, instead, the best (local) target function drifts over time. We develop a novel sub-optimal algorithm in the context of a drift. We analyze the algorithm in the worst-case regret framework and show that it maintains an average loss close to the best slow-changing sequence of linear functions as long as the total number of drifts is sublinear. In some situations, our limit improves beyond existing limits, and in addition, the algorithm suffers from logarithmic regret when there is no drift. We also build on the H filter and its limit and develop and analyze a second drift adjustment algorithm. Synthetic simulations demonstrate the benefits of our constant algorithm in the worst case."}, {"heading": "1 Introduction", "text": "We look at online learning problems, in which a learning algorithm predicts real numbers that are determined in a sequence of experiments. An example of such a problem is the prediction of a share price that, in contrast to the current state of the stock market, is predicted only slowly and slowly. In general, the aim of the algorithm is to achieve an average loss that is not much greater than the loss one suffers when it is always chosen to predict the best possible single function of any functional class. In the past half century, many algorithms have been proposed (a review can be found in a comprehensive book presented in the proceedings of the 16th International Conference on Artificial Intelligence and Statistics (AISTATS) 2013, Scottsdale, AZ, USA. Volume XX of JMLR: W & CP XX. Copyright 2013 by the authors. The topic [10] for this problem, some of which are able to achieve an average loss close to the best function in retrospect."}, {"heading": "2 Problem Setting", "text": "Our algorithms are designed for online adjustment and work in iterations (or rounds). In each round, an online algorithm receives an input vector xt-Rd and predicts a real value y-t-R. Then, the algorithm receives a target label yt-R associated with xt, uses it to update its prediction rule, and then proceeds to the next round. In each round, the performance of the algorithm is evaluated on the basis of the squared loss, \"t (alg) =\" (yt, y-t) = (y-t) = (y-yt) 2. The goal of the algorithm is to have low cumulative losses compared to predictors from any class."}, {"heading": "3 Algorithm", "text": "We define the last step minmax predictor y T to be1, arg min y T max yT (T = > 1) max yT (T = 1) max. (T = 1) max. (T = 1) max. (T = 1) max. (T = 1) max. (T = 1) max. (T = 1) max. (T = 1) max. (T \u2212 1) max. (T \u2212 1) max. (T \u2212 1) max. (T \u2212 1) max. (T \u2212 1) max. (T = 1) max. (T = 1) max. (T = 1) max. (T = 1)."}, {"heading": "4 Analysis", "text": "We now analyze the performance of the algorithm in the worst case scenario, starting with the following technical dilemma 3. For all: D't \u2212 1D \u2212 1 t xtx > t D \u2212 1 t D \u2032 t \u2212 1 \u2212 D \u2212 1t \u2212 1 + D \u2032 t \u2212 1 (D \u2212 1t D \u2032 t \u2212 1 + c \u2212 1I) 0where D \u2032 t \u2212 1 = (I + c \u2212 1Dt \u2212 1) \u2212 1. The evidence appears in App. B.3. Next, we tied the cumulative loss of the algorithm, Theorem 4. Suppose that the labels are limited for a few years supt | yt | \u2264 Y."}, {"heading": "Parameters: 0 < b < c", "text": "Initialize: Set D0 = (bc) / (c \u2212 b) I, (D \u2212 1t \u2212 1 + c \u2212 1I) \u2212 1 + xtx > t (7) () \u2212 1 instance xt get \u2022 Calculate Dt = (D \u2212 1t \u2212 1 + c \u2212 1I) \u2212 1 + xtx > t (7) \u2212 1"}, {"heading": "Output: eT , DT", "text": "LT (LASER) \u2264 min u1 \u2032,... \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212"}, {"heading": "Output: wT , PT", "text": "Figure 2: One H algorithm is based on the use of variance-like matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matrix matri"}, {"heading": "Furthermore, set b = \u03b5c for some 0 < \u03b5 < 1.", "text": "In this case, the algorithm is reduced to reduction. (b + X2) In this case, the algorithm is reduced to reduction. (b + X2) In this case, the algorithm is reduced to reduction. (b + X2) In this case, the algorithm is reduced to reduction. (b + X2) In this case, the algorithm is limited to reduction. (b) In this case, the algorithm is limited to reduction. (b) In this case, the algorithm is limited to reduction. (b) In this case, the algorithm is limited to reduction. (b) In this case, the algorithm is limited to reduction. (b) In this case, the algorithm is limited to reduction. (b) In this case, the algorithm is limited to reduction. (b + X2) In this case, the algorithm is limited to definition. (b) In this case, we are limited to reduction. (b) In this case, the algorithm is limited to reduction."}, {"heading": "5 An H\u221e Algorithm for Online Regression", "text": "The goal of an algorithm is to make predictions, and the predictions are compared with the predictions of some functions of a known class. Formally, it is equivalent to online learning. On each iteration, the filter receives an input and predicts a corresponding output y-t. It then receives the true desired output yt and updates its internal model. Many adaptive filter algorithms deal with square loss, that is, it is known as the least square (LMS) algorithm in the adaptive filter literature. [31] A possible difference between adaptive filtering and online learning can be considered in the interpretation of algorithms and as a result of their analysis. In online learning, the goal of an algorithm is to make predictions, and the predictions are compared with the predictions of some functions of a known class."}, {"heading": "6 Simulations", "text": "We evaluate the LASER and H \u221e algorithms on four synthetic datasets. We set T = 2000 and d = 20. For all datasets, the inputs xt-R20 were generated in such a way that the first ten coordinates were grouped into five groups of size two. Each such pair was generated from a 45 \u00b0 rotated Gaussian distribution with standard deviations of 10 and 1. The remaining 10 coordinates were drawn from independent Gaussian distributions N (0, 2). The first synthetic dataset was generated using a sequence of vectors ut-R20 for which the only non-zero coordinates are the first two, where their values are the coordinates of a unit vector rotating at a constant rate (linear drift). Specifically, we have a value of 1 and the instantaneous drift-R20 we are constant. The second synthetic dataset was generated using a sequence of vectors R20."}, {"heading": "7 Related Work", "text": "It is. It is. It is. It is. It is. It is. It is. It is. It is. It is. It is. It is. It is. It is. Most people who stand up for the rights of women and men speak up for the equality of man and woman. (...) It is not. It is not that they stand for the equality of man and woman. (...) It is as if they stand for the equality of woman. (...) It is as if they stand for the equality of man and woman. (...) It is as if they stand for the equality of man and woman. (...) It is. \"(...) It is. (...) It is. It is. (...) It is. It is. It is. (...) It is. It is. (...) It is. It is. (...) It is. It is. (...) It is. It is. It is. (...) It is. It is. It is. It is. It is. (...) It is. It is. It is. It is. It is. It is. (...) It is. It is. It is. It is. It is. (...) It is. It is. It is. It is. It is. It is. It is. It is. (... It is. It is. It is. It is. It is. It is. It is. It is. It is. It is. It is. It is. It is. It is."}, {"heading": "8 Summary and Conclusions", "text": "We proposed a novel algorithm for non-stationary online regression, which was designed and analyzed with the square loss. It was developed from the last step of the minmax predictor for non-stationary problems, and we showed an exact recursive form of its solution. We also described an algorithm based on the H \u221e filter, which is also motivated by a min-max approach, but whose regrets are limited. Simulations showed its superior performance in a worst-case drift (near one constant per iteration). An interesting future direction is the extension of the algorithm for general loss functions instead of the square loss. To implement the algorithm, we need to perform either a matrix inversion or a eigenvector decomposition, we want to design a more efficient version of the algorithm."}, {"heading": "A Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1 Proof of Corollary 8", "text": "The proof that plugging Lem. 5 in Thm. 4 for all (u1.. uT), LT (LASER) \u2264 b-1Tr (Dt \u2212 1), Lem. 7 the RHS and getLT (LASER) \u2264 b-1bDT + c-1Y 2 T-1Tr (Dt \u2212 1).With Lem. 7 we have the RHS and getLT (LASER) \u2264 b-2Tdmax {3X2 + 4X2c2, b + XY} and the term c-2Tr (D0) because c-1Y 2Tr (D0) = 1Y 2Tr (D0) + cV + c-1Y 2Tdmax {3X2 + 4X2c2, b + XY} and the term c-2Tr (D0), because c-1Y 2Tr (D0) = 1Y 2Tr (D0) + cV + c-1Y 2Tdmax {3X2 + 4X2c2, b + XY} and the term c + X2}, because c-2T (DT), because c-2T, 2T 2T, 2T 2T 2T, 2T 2T 2T, 2T 2T 2T, 2T 2T 2T 2T 2T, 2T 2T 2T 2T, 2T 2T 2T 2T, 2T 2T 2T 2T, 2T 2T 2T 2T, 2T 2T 2T 2T, 2T 2T 2T 2T 2T 2T, 2T 2T 2T 2T, 2T-2T 2T 2T 2T 2T, 2T 2T 2T 2T 2T, 2T 2T 2T 2T, 2T 2T 2T 2T-2T 2T, 2T 2T 2T 2T 2T, 2T 2T 2T 2T 2T, 2T 2T 2T, 2T 2T 2T 2T 2T 2T 2T 2T 2T"}, {"heading": "SUPPLEMENTARY MATERIAL", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.1 Proof of Lem. 1", "text": "Proof: We calculate Pt (ut) = min u1,..., ut \u2212 1 (b-u1, 2 + ct \u2212 1 x s = 1 x us + 1 x s = 1 (ys \u2212 u > s xs) 2) = min ut \u2212 1 x u1,..., ut \u2212 2 (b-u1, 2 + ct \u2212 2 x s = 1 x us + 1 x us 2 + t \u2212 1 x s = 1 (ys \u2212 u > s xs) 2 + c-ut \u2212 1 x 2 + (yt \u2212 u > t xt) 2) = min ut \u2212 1 (Pt \u2212 1 (ut \u2212 1) + c-ut \u2212 1 x \u2212 2 + (yt \u2212 u > t xt) 2)"}, {"heading": "B.2 Proof of Lem. 2", "text": "Proof. P1 (u1) = Q1 (u1) \u2212 \u2212 t \u2212 t \u2212 t t t t t t t t \u2212 t t t t t t t t t t t t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t. P1 (u1) = Q1 (u1) \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212"}, {"heading": "B.3 Proof of Lem. 3", "text": "For proof, we first use the Woodbury equation to get the following two parallels: D \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 1 = > 1x > D = 1x > (D \u2212 1t > 1x > 1I) xtx > t (D \u2212 1t \u2212 1t (D \u2212 1t \u2212 1) xtx (D \u2212 1t \u2212 1I) xtx (D \u2212 1t \u2212 1I) xtand (I + c \u2212 1Dt \u2212 1Dt \u2212 1t) xtand (I + t \u2212 1Dt \u2212 1) xt \u2212 t (D \u2212 1) x \u2212 t \u2212 t \u2212 \u2212 \u2212 t \u2212 t (I + c \u2212 1Dt \u2212 1Dt \u2212 1) D \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t (D \u2212 t) (D \u2212 1) \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t (D \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t \u2212 t"}, {"heading": "B.4 Derivations for Thm. 4", "text": "(yt \u2212 y \u2212 t) 2 + min \u2212 \u2212 \u2212 t, ut \u2212 1 Qt \u2212 b > b > b = (u1,.., ut \u2212 1) \u2212 min u1,..., ut Qt (u1,. \u2212 t) = (yt \u2212 y \u2212 t) 2 \u2212 e > t \u2212 1D \u2212 1t \u2212 1t \u2212 1et (cI + Dt \u2212 1) \u2212 1 et \u2212 y2t + ((I + c \u2212 1 \u2212 y2t) \u2212 1 t \u2212 1 et \u2212 1D \u2212 1t \u2212 1 et > t \u2212 1 (cI + Dt \u2212 1) he (cI + Dt \u2212 1) \u2212 1 et \u2212 y2t ((I + c \u2212 y2t) \u2212 1 et (8), c \u2212 2 \u2212 yt (I + c \u2212 2t), c \u2212 2 \u2212 X \u2212 t \u2212 1 \u2212 t) > D \u2212 1t (I + c \u2212 1Dt \u2212 Y \u2212 1 et) \u2212 1 et (1 + ytxt) (1c) (1c)."}, {"heading": "B.6 Proof of Lem. 6", "text": "Proof. The second property results from the symmetry between \u03b2 and \u03bb. To prove the third property, we break down the function as follows: f (\u03bb) = \u03bb\u03b2 / (\u03bb + \u03b2) + x2 \u2264 + \u03b2 + x 2. Therefore, the function becomes by its argument f (\u03bb) \u2264, if, and only if, \u2212 \u03bb + \u03b2 + x 2 \u2264 0.Since we assume x2 \u2264 2, the last imbalance applies when, \u2212 \u03bb2 + \u03b32\u03bb + \u03b32\u03b2 \u2264 0, which applies to \u03bb \u00b2. In summary: If \u03bb 2 + \u04454 + 4\u04452\u03b22 applies, then f (\u03bb) \u2264. Otherwise, in the second property, we have f (\u03bb) \u2264 + \u04452 \u04452 + \u04452 + \u041a2\u03b22 + \u04452 + \u04212 + \u04212 \u04212 \u04212 \u04214 \u04214 \u04214 \u04214 \u04214 \u04214 \u04214 \u04212."}], "references": [{"title": "Tracking the best disjunction", "author": ["P. Auer", "M. Warmuth"], "venue": "Electronic Colloquium on Computational Complexity (ECCC),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Relative loss bounds for on-line density estimation with the exponential family of distributions", "author": ["K. Azoury", "M. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Analysis of the normalized lms algorithm with gaussian inputs", "author": ["N.J. Bershad"], "venue": "IEEE Transactions on Acoustics, Speech, and Signal Processing,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1986}, {"title": "Performance of adaptive estimation algorithms in dependent random environments", "author": ["R.R. Bitmead", "B.D.O. Anderson"], "venue": "IEEE Trans. on Automatic Control,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1980}, {"title": "Online regression competitive with changing predictors", "author": ["S. Busuttil", "Y. Kalnishkan"], "venue": "In ALT,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Tracking the best hyperplane with a simple budget perceptron", "author": ["G. Cavallanti", "N. Cesa-Bianchi", "C. Gentile"], "venue": "Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Worst case quadratic loss bounds for on-line prediction of linear functions by gradient descent", "author": ["N. Ceas-Bianchi", "P.M. Long", "M.K. Warmuth"], "venue": "IEEE Tran. on NN,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1996}, {"title": "A second-order perceptron algorithm", "author": ["N. Cesa-Bianchi", "A. Conconi", "C. Gentile"], "venue": "Siam Journal of Commutation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Application of the least squares algorithm to the observer design for linear time-varying systems", "author": ["M.-S. Chen", "J.-Y. Yen"], "venue": "Automatic Control, IEEE Tran. on,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "Confidenceweighted linear classification for text categorization", "author": ["K. Crammer", "M. Dredze", "F. Pereira"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Online classification on a budget", "author": ["K. Crammer", "J. Kandola", "Y. Singer"], "venue": "In NIPS,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "Adaptive regularization of weighted vectors", "author": ["K. Crammer", "A. Kulesza", "M. Dredze"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "The forgetron: A kernel-based perceptron on a fixed budget", "author": ["O. Dekel", "S. Shalev-shwartz", "Y. Singer"], "venue": "In NIPS", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "In COLT,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "On relative loss bounds in generalized linear regression", "author": ["J. Forster"], "venue": "In Fundamentals of Computation Theory (FCT),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1999}, {"title": "Prediction in the worst case", "author": ["D. Foster"], "venue": "The Annals of Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1991}, {"title": "Logical covariance matrix reset in self-tuning control", "author": ["S. Goodhart", "K. Burnham", "D. James"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1991}, {"title": "Aggregating strategies", "author": ["V.G.Vovk"], "venue": "Proceedings of the Third Annual Workshop on Computational Learning Theory,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1990}, {"title": "Recursive least squares", "author": ["M. Hayes"], "venue": "In Statistical Digital Signal Processing and Modeling,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1996}, {"title": "Tracking the best linear predictor", "author": ["M. Herbster", "M. Warmuth"], "venue": "JMLR, 1:281\u2013309,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2001}, {"title": "A new approach to linear filtering and prediction problems", "author": ["R.E. Kalman"], "venue": "Transactions of the ASME\u2013 Journal of Basic Engineering,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1960}, {"title": "Exponential gradient versus gradient descent for linear predictors", "author": ["J. Kivinen", "M.K.Warmuth"], "venue": "Information and Computation,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1997}, {"title": "Online learning with kernels", "author": ["J. Kivinen", "A. Smola", "R. Williamson"], "venue": "In NIPS,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2001}, {"title": "The pnorm generalization of the lms algorithm for adaptive filtering", "author": ["J. Kivinen", "M.K. Warmuth", "B. Hassibi"], "venue": "In Proc. 13th IFAC Symposium on System Identification,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2003}, {"title": "The weighted majority algorithm", "author": ["N. Littlestone", "M.K. Warmuth"], "venue": "Inf. Comput.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1994}, {"title": "Adaptive bound optimization for online convex optimization", "author": ["H.B. McMahan", "M.J. Streeter"], "venue": "In COLT,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Weighted last-step min-max algorithm with improved sub-logarithmic regret", "author": ["E. Moroshko", "K. Crammer"], "venue": "In The 23nd International Conference on Algorithmic Learning Theory, ALT", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Modified least squares algorithm incorporating exponential resetting and forgetting", "author": ["M. Salgado", "G. Goodwin", "R. Middleton"], "venue": "International J. of Control,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1988}, {"title": "Adaptive Filters", "author": ["A.H. Sayed"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2008}, {"title": "A game theory approach to constrained minimax state estimation", "author": ["D. Simon"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2006}, {"title": "Optimal State Estimation: Kalman, H Infinity, and Nonlinear Approaches", "author": ["D. Simon"], "venue": "Wiley- Interscience,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2006}, {"title": "The last-step minimax algorithm", "author": ["E. Takimoto", "M. Warmuth"], "venue": "In ALT,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2000}, {"title": "Re-adapting the regularization of weights for non-stationary regression", "author": ["N. Vaits", "K. Crammer"], "venue": "In ALT,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2011}, {"title": "Competitive on-line statistics", "author": ["V. Vovk"], "venue": "International Statistical Review,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2001}, {"title": "Adaptive switching circuits. In Institute of Radio Engineers, Western Electronic Show and Convention", "author": ["B. Widrow", "M.E. Hoff"], "venue": "Convention Record, Part", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1960}], "referenceMentions": [{"referenceID": 8, "context": "the topic [10]) for this problem, some of which are able to achieve an average loss arbitrarily close to that of the best function in retrospect.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 25, "endOffset": 40}, {"referenceID": 0, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 25, "endOffset": 40}, {"referenceID": 20, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 25, "endOffset": 40}, {"referenceID": 23, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 25, "endOffset": 40}, {"referenceID": 23, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 199, "endOffset": 203}, {"referenceID": 5, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 247, "endOffset": 250}, {"referenceID": 15, "context": "We take a different route and derive an algorithm based on the last-step min-max approach proposed by Forster [17] and later used [34] for online density estimation.", "startOffset": 110, "endOffset": 114}, {"referenceID": 32, "context": "We take a different route and derive an algorithm based on the last-step min-max approach proposed by Forster [17] and later used [34] for online density estimation.", "startOffset": 130, "endOffset": 134}, {"referenceID": 33, "context": "stantaneous drift is close to constant, this improves over a previous bound of Vaits and Crammer [35] of an algorithm named ARCOR that showed a bound of T\u03bd log(T ).", "startOffset": 97, "endOffset": 101}, {"referenceID": 15, "context": "Additionally, when no drift is introduced (stationary setting) our algorithm suffers logarithmic regret, as for the algorithm of Forster [17].", "startOffset": 137, "endOffset": 141}, {"referenceID": 15, "context": "To solve it, we follow an approach used by Forster in a different context [17].", "startOffset": 74, "endOffset": 78}, {"referenceID": 15, "context": "This problem is of a similar form to the one discussed by Forster [17], from which we get the optimal solution, \u0177T = clip ( xTD \u22121 T ( I + cDT\u22121 )\u22121 eT\u22121, Y ) , where for y > 0 we define clip(x, y) = sign(x) min{|x|, y}.", "startOffset": 66, "endOffset": 70}, {"referenceID": 34, "context": "Clearly, for c = \u221e the LASER algorithm reduces to the AAR algorithm of Vovk [36], or the last-step min-max algorithm of Forster [17].", "startOffset": 76, "endOffset": 80}, {"referenceID": 15, "context": "Clearly, for c = \u221e the LASER algorithm reduces to the AAR algorithm of Vovk [36], or the last-step min-max algorithm of Forster [17].", "startOffset": 128, "endOffset": 132}, {"referenceID": 1, "context": "See also the work of Azoury and Warmuth [2].", "startOffset": 40, "endOffset": 43}, {"referenceID": 1, "context": "This algorithm can be seen also as a forward algorithm [2]: The predictor of (14) can be seen as the optimal linear model obtained over the same prefix of length T \u2212 1 and the new input xT with fictional-label yT = 0.", "startOffset": 55, "endOffset": 58}, {"referenceID": 15, "context": "Similar to the derivation of Forster [17] (details omitted due to lack of space),", "startOffset": 37, "endOffset": 41}, {"referenceID": 34, "context": "First, when the total drift V = 0 goes to zero, we set c = \u221e and thus we have Dt = bI + \u2211t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].", "startOffset": 129, "endOffset": 144}, {"referenceID": 15, "context": "First, when the total drift V = 0 goes to zero, we set c = \u221e and thus we have Dt = bI + \u2211t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].", "startOffset": 129, "endOffset": 144}, {"referenceID": 19, "context": "First, when the total drift V = 0 goes to zero, we set c = \u221e and thus we have Dt = bI + \u2211t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].", "startOffset": 129, "endOffset": 144}, {"referenceID": 7, "context": "First, when the total drift V = 0 goes to zero, we set c = \u221e and thus we have Dt = bI + \u2211t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].", "startOffset": 129, "endOffset": 144}, {"referenceID": 15, "context": "In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]).", "startOffset": 63, "endOffset": 67}, {"referenceID": 34, "context": "In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]).", "startOffset": 132, "endOffset": 136}, {"referenceID": 15, "context": "In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]).", "startOffset": 258, "endOffset": 262}, {"referenceID": 1, "context": "See also the work of Azoury and Warmuth [2].", "startOffset": 40, "endOffset": 43}, {"referenceID": 33, "context": "Third, Vaits and Crammer [35] recently proposed an algorithm, called ARCOR, for the same setting.", "startOffset": 25, "endOffset": 29}, {"referenceID": 33, "context": "Therefore, in this case the bound of ARCOR [35] is \u03bdT log(T ) which is worse than our bound, both since it has an additional log(T ) factor (as opposed to our additive log term) and since \u03bd = o(1).", "startOffset": 43, "endOffset": 47}, {"referenceID": 33, "context": "Therefore we expect that our algorithm will perform better than ARCOR [35] when the instantaneous drift is approximately constant.", "startOffset": 70, "endOffset": 74}, {"referenceID": 20, "context": "Fourth, Herbster and Warmuth [22] developed shifting bounds for general gradient descent algorithms with projection of the weight-vector using the Bregman divergence.", "startOffset": 29, "endOffset": 33}, {"referenceID": 4, "context": "Busuttil and Kalnishkan [6] developed a variant of the Aggregating Algorithm [20] for the non-stationary setting.", "startOffset": 24, "endOffset": 27}, {"referenceID": 18, "context": "Busuttil and Kalnishkan [6] developed a variant of the Aggregating Algorithm [20] for the non-stationary setting.", "startOffset": 77, "endOffset": 81}, {"referenceID": 35, "context": "For example, a well known online learning algorithm [37] for regression, which is basically a gradient-descent algorithm with the squared-loss, is known as the least mean-square (LMS) algorithm in the adaptive filtering literature [31].", "startOffset": 52, "endOffset": 56}, {"referenceID": 29, "context": "For example, a well known online learning algorithm [37] for regression, which is basically a gradient-descent algorithm with the squared-loss, is known as the least mean-square (LMS) algorithm in the adaptive filtering literature [31].", "startOffset": 231, "endOffset": 235}, {"referenceID": 31, "context": "papers by Simon [33, 32]) are a family of (robust) linear filters developed based on a min-max approach, like LASER, and analyzed in the worst case setting.", "startOffset": 16, "endOffset": 24}, {"referenceID": 30, "context": "papers by Simon [33, 32]) are a family of (robust) linear filters developed based on a min-max approach, like LASER, and analyzed in the worst case setting.", "startOffset": 16, "endOffset": 24}, {"referenceID": 21, "context": "These filters are reminiscent of the celebrated Kalman filter [23], which was motivated and analyzed in a stochastic setting with Gaussian noise.", "startOffset": 62, "endOffset": 66}, {"referenceID": 24, "context": "[26] proposed another approach for filtering with a bound depending on \u2211 t \u2016ut\u2212ut\u22121\u2016 and not the sum of squares as we have both for LASER and the H\u221e-based algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 64, "endOffset": 70}, {"referenceID": 3, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 64, "endOffset": 70}, {"referenceID": 12, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 150, "endOffset": 154}, {"referenceID": 33, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 162, "endOffset": 166}, {"referenceID": 9, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 175, "endOffset": 183}, {"referenceID": 28, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 175, "endOffset": 183}, {"referenceID": 35, "context": "We already mentioned the work of Widrow and Hoff [37] who studied a gradient descent algorithm for the squared loss.", "startOffset": 49, "endOffset": 53}, {"referenceID": 3, "context": "A notable example is the normalized least mean squares algorithm (NLMS) [5, 3] that adapts to the input\u2019s scale.", "startOffset": 72, "endOffset": 78}, {"referenceID": 2, "context": "A notable example is the normalized least mean squares algorithm (NLMS) [5, 3] that adapts to the input\u2019s scale.", "startOffset": 72, "endOffset": 78}, {"referenceID": 8, "context": "We refer the reader to a encyclopedic book in the subject [10].", "startOffset": 58, "endOffset": 62}, {"referenceID": 6, "context": "[8] about two decades ago.", "startOffset": 0, "endOffset": 3}, {"referenceID": 22, "context": "These algorithms were generalized and extended by Kivinen and Warmuth [24] using additional regularization functions.", "startOffset": 70, "endOffset": 74}, {"referenceID": 16, "context": "An online version of the ridge regression algorithm in the worst-case setting was proposed and analyzed by Foster [18].", "startOffset": 114, "endOffset": 118}, {"referenceID": 18, "context": "A related algorithm called Aggregating Algorithm (AA) was studied by Vovk [20], and later applied to the problem of linear regression with square loss [36].", "startOffset": 74, "endOffset": 78}, {"referenceID": 34, "context": "A related algorithm called Aggregating Algorithm (AA) was studied by Vovk [20], and later applied to the problem of linear regression with square loss [36].", "startOffset": 151, "endOffset": 155}, {"referenceID": 19, "context": "The recursive least squares (RLS) [21] is a similar algorithm proposed for adaptive filtering.", "startOffset": 34, "endOffset": 38}, {"referenceID": 15, "context": "The derivation of our algorithm shares similarities with the work of Forster [17] and the work of Moroshko and Crammer [29].", "startOffset": 77, "endOffset": 81}, {"referenceID": 27, "context": "The derivation of our algorithm shares similarities with the work of Forster [17] and the work of Moroshko and Crammer [29].", "startOffset": 119, "endOffset": 123}, {"referenceID": 15, "context": "While the algorithms of Forster [17] and Moroshko and Crammer [29] are designed for the stationary setting, our work is primarily designed for the nonstationary setting.", "startOffset": 32, "endOffset": 36}, {"referenceID": 27, "context": "While the algorithms of Forster [17] and Moroshko and Crammer [29] are designed for the stationary setting, our work is primarily designed for the nonstationary setting.", "startOffset": 62, "endOffset": 66}, {"referenceID": 27, "context": "Moroshko and Crammer [29] also discussed a weak variant of the non-stationary setting, where the complexity is measured by the total distance from a reference vector \u016b, rather than the total distance of consecutive vectors (as in this paper), which is more relevant to non-stationary problems.", "startOffset": 21, "endOffset": 25}, {"referenceID": 27, "context": "Note also that Moroshko and Crammer [29] did not derive algorithms for the nonstationary setting, but just show a bound of the weighted min-max algorithm (designed for the stationary setting) in the weak non-stationary setting.", "startOffset": 36, "endOffset": 40}, {"referenceID": 33, "context": "Our work is mostly close to a recent algorithm [35] called ARCOR.", "startOffset": 47, "endOffset": 51}, {"referenceID": 9, "context": "The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively.", "startOffset": 44, "endOffset": 56}, {"referenceID": 28, "context": "The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively.", "startOffset": 44, "endOffset": 56}, {"referenceID": 17, "context": "The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively.", "startOffset": 44, "endOffset": 56}, {"referenceID": 21, "context": "The Kalman filter [23] and the H\u221e algorithm (e.", "startOffset": 18, "endOffset": 22}, {"referenceID": 31, "context": "[33]) designed for filtering take a similar approach, yet the exact algebraic form is different (Fig.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "ARCOR also controls explicitly the norm of the weight vector, which is used for its analysis, by projecting it into a bounded set, as was also proposed by Herbster and Warmuth [22].", "startOffset": 176, "endOffset": 180}, {"referenceID": 23, "context": "Other approaches to control its norm are to shrink it multiplicatively [25] or by removing old examples [7].", "startOffset": 71, "endOffset": 75}, {"referenceID": 5, "context": "Other approaches to control its norm are to shrink it multiplicatively [25] or by removing old examples [7].", "startOffset": 104, "endOffset": 107}, {"referenceID": 11, "context": "[13, 15]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 13, "context": "[13, 15]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 7, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 103, "endOffset": 114}, {"referenceID": 12, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 103, "endOffset": 114}, {"referenceID": 10, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 103, "endOffset": 114}, {"referenceID": 14, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 169, "endOffset": 177}, {"referenceID": 26, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 169, "endOffset": 177}], "year": 2013, "abstractText": "The goal of a learner in standard online learning is to maintain an average loss close to the loss of the best-performing single function in some class. In many real-world problems, such as rating or ranking items, there is no single best target function during the runtime of the algorithm, instead the best (local) target function is drifting over time. We develop a novel last-step minmax optimal algorithm in context of a drift. We analyze the algorithm in the worst-case regret framework and show that it maintains an average loss close to that of the best slowly changing sequence of linear functions, as long as the total of drift is sublinear. In some situations, our bound improves over existing bounds, and additionally the algorithm suffers logarithmic regret when there is no drift. We also build on the H\u221e filter and its bound, and develop and analyze a second algorithm for drifting setting. Synthetic simulations demonstrate the advantages of our algorithms in a worst-case constant drift setting.", "creator": "LaTeX with hyperref package"}}}