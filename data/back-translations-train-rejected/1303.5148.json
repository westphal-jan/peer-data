{"id": "1303.5148", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Mar-2013", "title": "Estimating Confusions in the ASR Channel for Improved Topic-based Language Model Adaptation", "abstract": "Human language is a combination of elemental languages/domains/styles that change across and sometimes within discourses. Language models, which play a crucial role in speech recognizers and machine translation systems, are particularly sensitive to such changes, unless some form of adaptation takes place. One approach to speech language model adaptation is self-training, in which a language model's parameters are tuned based on automatically transcribed audio. However, transcription errors can misguide self-training, particularly in challenging settings such as conversational speech. In this work, we propose a model that considers the confusions (errors) of the ASR channel. By modeling the likely confusions in the ASR output instead of using just the 1-best, we improve self-training efficacy by obtaining a more reliable reference transcription estimate. We demonstrate improved topic-based language modeling adaptation results over both 1-best and lattice self-training using our ASR channel confusion estimates on telephone conversations.", "histories": [["v1", "Thu, 21 Mar 2013 02:56:43 GMT  (70kb,D)", "http://arxiv.org/abs/1303.5148v1", "Technical Report 8, Human Language Technology Center of Excellence, Johns Hopkins University"]], "COMMENTS": "Technical Report 8, Human Language Technology Center of Excellence, Johns Hopkins University", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["damianos karakos", "mark dredze", "sanjeev khudanpur"], "accepted": false, "id": "1303.5148"}, "pdf": {"name": "1303.5148.pdf", "metadata": {"source": "CRF", "title": "Estimating Confusions in the ASR Channel for Improved Topic-based Language Model Adaptation", "authors": ["Damianos Karakos", "Mark Dredze", "Sanjeev Khudanpur"], "emails": ["dkarakos@bbn.com", "mdredze@jhu.edu", "khudanpur@jhu.edu"], "sections": [{"heading": null, "text": "THE JOHNS HOPKINS UNIVERSITYEstimating Confusions in the ASR Channel for Improved Topic Model AdaptationDamianos Karakos, Mark Dredze, Sanjeev KhudanpurTECHNICAL REPORT 8 MARCH 22, 2013ar Xiv: 130 3.51 48v1 [cs.CL] 2 1M ar2 013c \u00a9 HLTCOE, 2013Acknowledgements This work is supported in part by the Human Language Technology Center of Excellence. All opinions, results and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsor. HLTCOE 810 Wyman Park Drive Baltimore, Maryland 21211 http: / / hltcoe.jhu.eduEstimating Confusions in the ASR Channel for Improved Topic-based Language Model AdaptationDamidanos Kardanakhuelos Human Abhudos @ BBN @ TechnologyBBN @ 12bbN"}, {"heading": "1 Introduction", "text": "In fact, it is such that most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to move, to fight, to fight, to fight, to fight, to move, to move, to move, to fight, to fight, to fight, to fight, to move, to fight, to fight, to fight, to fight, to move, to fight, to fight, to move, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "2 Language Model Adaptation", "text": "We receive a trained speech recognizer, a theme-based speech model, and a large collection of audio utterances q (many conversations) q for a new domain, i.e. a topic change, but not manually transcribed text required for language model training. Our goal is to adapt the language model by learning new topic distributions using the available audio. We consider self-training, which distributes the topic based on automatically transcribed audio. A conversation model C consists of N topics represented by N lattices (confusion networks) - with words and posterior probabilities commented on - produced by the speech recognition mechanism. 1 Each confusion network consists of a sequence of text containers, each topic being hypothesized by the recognition mechanism at a given time. The i-te bin is denoted by Bi and contains words {wi, j} | j = 1, with V being the vocabulary."}, {"heading": "3 Learning \u03bb from ASR Output", "text": "We start with the following approaches to self-evaluation, where model parameters based on q = q = q = q = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v = v v = v = v = v = v v v v = v v = v v = v = v v = v v v = v = v = v = v v v = v v v v v v v = v v"}, {"heading": "3.1 Learning \u03bb from Expected Counts", "text": "Following Novotney et al. (2009), we next consider the use of the entire paper in self-training by maximizing the expected protocol probability of the ASR output: L \u2032 (1) = E [M \u2211 i = 1 log q (Wi)], (7) whereWi is a random variable that takes the value w \u0445 bi with the probability equal to the confidence (posterior probability) si (w) of the detector; the maximum probability of the estimation problem is derived from: \u043d = argmax; L \u2032 (1) (8) = argmax; M \u2211 i = 1 \u2211 w = bi si (w) log (\u2211 t) = argmax; w; V tf (w) log (w); where tf (w) = p (w) = p (w) = i si (w) (w) = 1 \u2211; w (w) denotes the expected number of the word w in conversation given by the sum of the re-complicators of w in all the confusion of the conversation."}, {"heading": "3.2 Maximum-Aposteriori Estimation of \u03bb", "text": "In addition to a maximum probability estimate, we consider a maximum aposteriori (MAP) estimate by placing a dirichlet before \u03bb (Bacchiani and Roark, 2003), where dir (\u03bb; \u03b1) is the pdf of the dirichlet distribution with the parameter \u03b1: \u03bb \u0445 = argmax \u03bb L + \u03b2 log (Dir (\u03bb; \u03b1). This results in an additional component in the optimization. It is easy to prove that the updated equation for \u03bb (j + 1) t is: \u03bb (j + 1) t = [\u2211 M i = 1 r (j) (t | w-i) + \u03b2 (t). (12) In the case where only the ASR 1-is best used, and vice versa (j \u2212 1) M i = 1 r (j-w) (t) (t \u00b2 w) (t \u00b2 w) (p \u00b2) (p \u00b2) (p \u00b2))."}, {"heading": "4 Confusion Estimation in ASR Output", "text": "The ASR channel confusion model is represented by a conditional probability distribution PC (v | w), V, W, V, which indicates the probability that the most likely word in the recognition output (i.e. the \"1-best\" word) is v, since the true (reference) word is w. Of course, this conditional distribution is only an approximation like many other phenomena - coarticulation, instability of the language, channel variations, lexical choice in context, etc. - cause this probability to vary. We assume that PC (v | w) is an \"average\" of conditional probabilities under different conditions. We will use the following simple method to estimate the ASR channel last probability."}, {"heading": "4.1 Learning \u03bb with ASR Confusion Estimates", "text": "It could be argued that the ASR channel confusion distribution (w) is less likely than an improbable distribution (w). (15) It could be argued that the ASR channel confusion distribution (w) is less likely than an improbable mixing (w). (17) It could be argued that the ASR channel confusion distribution (w) is improbable mixing (w). (17) However, it could be argued that the ASR channel confusion distribution (w) should exclude improbable mixing (w) as there are no specific, improbable words in a specific way that we could not obtain if they are probable. (17) It could be argued that the ASR channel confusion distribution (w) should exclude improbable mixing (w)."}, {"heading": "4.2 Learning \u03bb from Expected Counts", "text": "As before, we consider the maximization of the expected log probability of the ASR output: L \u00b2 (2) = E [M \u00b2 i = 1 Log p (Wi)], (33) where Wi takes the value w \u00b2 bi with the probability corresponding to the trust (posterior probability) si (w) of the recognizer. The modified maximum probability problem now becomes: \u03bb = argmax \u00b2 l \u00b2 (2) = argmax \u00b2 m \u00b2 (2) = w \u00b2 bi si (w) log pi (w) = argmax \u00b2 m \u00b2 i = 1 \u00b2 w \u00b2 t \u00b2 bi si (w) \u00b7 log \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t \u00b2 t (j \u00b2 t \u00b2 t), t \u00b2 t \u00b2 t \u00b2 t \u00b2 t t (t \u00b2 t), t \u00b2 t \u00b2 t (t), t \u00b2 t \u00b2 t (t), j \u00b2 t \u00b2 t (t), j \u00b2 t (t), j \u00b2 t (t), j \u00b2 t (t), j \u00b2 t (t), j \u00b2 t (t)."}, {"heading": "4.3 Maximum-Aposteriori Estimation of \u03bb", "text": "Finally, we consider an MAP estimate of \u03bb with the confusion model. The optimization contains the term q = q = q = q = q = q (44) and the Q difference (20) is: Q (q (j), \u00b5 (j) + \u03b4) \u2212 Q (q (j), \u00b5 (j), + \u03b2 log (Dir (e\u00b5 (j) + \u03b4 / Z1) \u2212 \u03b2 log (Dir (j) / Z0 \u2032)) (37) \u2212 log (Dir (e\u00b5), Z1), where Z1 are the corresponding normalizing constants. To get a lower limit on the difference in the second line of (37), we consider the following chain of qualities: log (e\u00b5 (j) + zi / Z1) \u2212 log (Dir (e\u00b5) (Z0) / Z0), = (Z0), the lower limit on the difference in the second line of (37), we consider the following chain of qualities: log (Ze\u00b5) + zi / Z1) \u2212 log (Dir) (Ze\u00b5) (corresponding to Ze\u00b5 / Z0)."}, {"heading": "5 Experimental Results", "text": "We compare ourselves, as described in Section 3, with our confusing approach, as described in Section 4, based on thematic-based language model adaptation. We compare the self-training, as described in Section 3, with the confusing approach, as described in Section 4, based on thematic-based language model adaptation. We chose a small training to simulate a high WHO state (about 56%), as we are primarily interested in low resource settings. While speaking is a demanding task, even with many hours of training data, we are interested in settings with a tiny amount of training data, such as new domains, languages, or noise states. Set A2, a superset of A1, contains 5.5 mil words of manual confusion that are used to train the topic-based distribution."}, {"heading": "6 Conclusion", "text": "We have introduced a new model that captures the confusions (errors) of the ASR channel. When combined with the adaptation of a theme-based language model, we see improvements in the modeling of words that improve readability and downstream applications. Our improvements are consistent across a number of settings, including 1-best and grid self-training for conversational language. Beyond improvements in speech modeling, we believe that our confusion model can support other language tasks, such as the classification of topics. We plan to explore other tasks and better confusion models in the future."}], "references": [{"title": "Unsupervised language model adaptation", "author": ["Bacchiani", "Roark2003] M. Bacchiani", "B. Roark"], "venue": "In Proceedings of ICASSP-2003,", "citeRegEx": "Bacchiani et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bacchiani et al\\.", "year": 2003}, {"title": "Language model adaptation with MAP estimation and the perceptron algorithm", "author": ["B. Roark", "M. Saraclar"], "venue": "In Proceedings of HLT-2004,", "citeRegEx": "Bacchiani et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bacchiani et al\\.", "year": 2004}, {"title": "An overview of statistical language model adaptation", "author": ["J.R. Bellegarda"], "venue": "In Proceedings of ISCA Tutorial and Research Workshop (ITRW),", "citeRegEx": "Bellegarda.,? \\Q2001\\E", "shortCiteRegEx": "Bellegarda.", "year": 2001}, {"title": "An empirical study of smoothing techniques for language modeling", "author": ["Chen", "Goodman1996] S.F. Chen", "J. Goodman"], "venue": "In Proceedings of the 34th Annual Meeting of the ACL,", "citeRegEx": "Chen et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Chen et al\\.", "year": 1996}, {"title": "Elements of Information Theory", "author": ["Cover", "Thomas1996] T.M. Cover", "J.A. Thomas"], "venue": null, "citeRegEx": "Cover et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Cover et al\\.", "year": 1996}, {"title": "A hybrid svm/mce training approach for vector space topic identification of spoken audio recordings", "author": ["Hazen", "Richardson2008] T.J. Hazen", "F. Richardson"], "venue": "In Proceedings of Interspeech-2008,", "citeRegEx": "Hazen et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hazen et al\\.", "year": 2008}, {"title": "Unsupervised learning by probabilistic latent semantic analysis", "author": ["T. Hofmann"], "venue": "Machine Learning,", "citeRegEx": "Hofmann.,? \\Q2001\\E", "shortCiteRegEx": "Hofmann.", "year": 2001}, {"title": "Style & topic language model adaptation using HMM-LDA", "author": ["Hsu", "Glass2006] B-J. Hsu", "J. Glass"], "venue": "In Proceedings of EMNLP-2006", "citeRegEx": "Hsu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2006}, {"title": "Statistical Methods for Speech Recognition", "author": ["F. Jelinek"], "venue": null, "citeRegEx": "Jelinek.,? \\Q1997\\E", "shortCiteRegEx": "Jelinek.", "year": 1997}, {"title": "Estimating document frequencies in a speech corpus", "author": ["Karakos et al.2011] D. Karakos", "M. Dredze", "K. Church", "A. Jansen", "S. Khudanpur"], "venue": "In Proceedings of ASRU-2011", "citeRegEx": "Karakos et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Karakos et al\\.", "year": 2011}, {"title": "Finding consensus among words: Latticebased word error minimization", "author": ["Mangu et al.1999] L. Mangu", "E. Brill", "A. Stolcke"], "venue": "In Proceedings of Eurospeech-1999", "citeRegEx": "Mangu et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Mangu et al\\.", "year": 1999}, {"title": "Unsupervised acoustic and language model training with small amounts of labelled data", "author": ["Novotney et al.2009] S. Novotney", "R. Schwartz", "J. Ma"], "venue": "In Proceedings of ICASSP-2009", "citeRegEx": "Novotney et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Novotney et al\\.", "year": 2009}, {"title": "Using story topics for language model adaptation", "author": ["Seymore", "Rosenfeld1997] K. Seymore", "R. Rosenfeld"], "venue": "In Proceedings of Eurospeech-1997", "citeRegEx": "Seymore et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Seymore et al\\.", "year": 1997}, {"title": "Dynamic language model adaptation using variational Bayes inference", "author": ["Tam", "Schultz2005] Y-C. Tam", "T. Schultz"], "venue": "In Proceedings of Eurospeech-2005", "citeRegEx": "Tam et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Tam et al\\.", "year": 2005}, {"title": "Integrating MAP, marginals, and unsupervised language model adaptation", "author": ["Wang", "Stolcke2007] W. Wang", "A. Stolcke"], "venue": "In Proceedings of Interspeech-2007,", "citeRegEx": "Wang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2007}, {"title": "Maximum entropy techniques for exploiting syntactic, semantic and collocational dependencies in language modeling", "author": ["Wu", "Khudanpur2000] J. Wu", "S. Khudanpur"], "venue": "Computer Speech and Language,", "citeRegEx": "Wu et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2000}, {"title": "Self-supervised discriminative training of statistical language models", "author": ["Xu et al.2009] P. Xu", "D. Karakos", "S. Khudanpur"], "venue": "In Proceedings of ASRU-2009", "citeRegEx": "Xu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 2, "context": "Reliance on (static) training data makes language models brittle (Bellegarda, 2001) to changes in domain.", "startOffset": 65, "endOffset": 83}, {"referenceID": 11, "context": "One common approach to language model adaptation is self-training (Novotney et al., 2009), in which the language model is retrained on the output from the ASR system run on the new audio.", "startOffset": 66, "endOffset": 89}, {"referenceID": 0, "context": "Note that Bacchiani et al. (2004) also consider the problem of language model adaptation as an error correction problem, but with supervised methods.", "startOffset": 10, "endOffset": 34}, {"referenceID": 6, "context": "Such models have been used in a variety of ways, such as in PLSA (Hofmann, 2001) and LDA (Blei et al.", "startOffset": 65, "endOffset": 80}, {"referenceID": 11, "context": "1 Learning \u03bb from Expected Counts Following Novotney et al. (2009) we next consider using the entire bin in self-training by maximizing the expected log-likelihood of the ASR output:", "startOffset": 44, "endOffset": 67}, {"referenceID": 9, "context": "t \u03bbtq(w|t) ) where tf(w) = \u2211 i si(w) denotes the expected count of word w in the conversation, given by the sum of the posteriors of w in all the confusion network bins of the conversation (Karakos et al., 2011) (note that for text documents, it is equivalent to termfrequency).", "startOffset": 189, "endOffset": 211}, {"referenceID": 16, "context": "We use the following simple procedure for estimating the ASR channel, similar to that of (Xu et al., 2009) for computing cohort sets:", "startOffset": 89, "endOffset": 106}, {"referenceID": 10, "context": "\u2022 Create confusion networks (Mangu et al., 1999) with the available audio.", "startOffset": 28, "endOffset": 48}, {"referenceID": 8, "context": "Perplexity (Jelinek, 1997) is measured on the manual transcripts of both dev and test data based on the formula PPL(p) ,", "startOffset": 11, "endOffset": 26}], "year": 2013, "abstractText": "Human language is a combination of elemental languages/domains/styles that change across and sometimes within discourses. Language models, which play a crucial role in speech recognizers and machine translation systems, are particularly sensitive to such changes, unless some form of adaptation takes place. One approach to speech language model adaptation is self-training, in which a language model\u2019s parameters are tuned based on automatically transcribed audio. However, transcription errors can misguide self-training, particularly in challenging settings such as conversational speech. In this work, we propose a model that considers the confusions (errors) of the ASR channel. By modeling the likely confusions in the ASR output instead of using just the 1-best, we improve self-training efficacy by obtaining a more reliable reference transcription estimate. We demonstrate improved topic-based language modeling adaptation results over both 1-best and lattice selftraining using our ASR channel confusion estimates on telephone conversations.", "creator": "LaTeX with hyperref package"}}}