{"id": "1305.0625", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-May-2013", "title": "CONATION: English Command Input/Output System for Computers", "abstract": "In this information technology age, a convenient and user friendly interface is required to operate the computer system on very fast rate. In the human being, speech being a natural mode of communication has potential to being a fast and convenient mode of interaction with computer. Speech recognition will play an important role in taking technology to them. It is the need of this era to access the information within seconds. This paper describes the design and development of speaker independent and English command interpreted system for computers. HMM model is used to represent the phoneme like speech commands. Experiments have been done on real world data and system has been trained in normal condition for real world subject.", "histories": [["v1", "Fri, 3 May 2013 06:25:18 GMT  (73kb)", "http://arxiv.org/abs/1305.0625v1", "6 pages, 3 tables"]], "COMMENTS": "6 pages, 3 tables", "reviews": [], "SUBJECTS": "cs.HC cs.CL", "authors": ["kamlesh sharma", "dr t v prasad"], "accepted": false, "id": "1305.0625"}, "pdf": {"name": "1305.0625.pdf", "metadata": {"source": "CRF", "title": "CONATION: English Command Input/Output System for Computers", "authors": ["Kamlesh Sharma"], "emails": ["kamlesh0581@gmail.com,", "tvprasad2002@yahoo.com"], "sections": [{"heading": null, "text": "CONATION: English Command Input / Output System for ComputersKamlesh Sharma * and Dr. T. V. Prasad * * * Research Scholar, * * Professor & Head Dept. of Comp. Sc. & Engg., Lingaya's University, Faridabad, IndiaEmail: kamlesh0581 @ gmail.com, tvprasad2002 @ yahoo.com Abstract - In this age of information technology, a convenient and user-friendly user interface is required to operate the computer system at very high speeds. In humans, language has the potential to be a fast and convenient way of interacting with the computer. Speech recognition will play an important role in bringing the technology to them."}, {"heading": "1. INTRODUCTION", "text": "The primarily human interaction is done by keyboard and mouse as pointing device work as input and monitor and printer work as output. Keyboard, although a popular medium is not very convenient as it requires a certain degree of skill for effective use. A mouse on the other hand requires good hand-eye coordination. It is also cumbersome for entering non-trivial amount of text data and therefore requires the use of additional media such as keyboard. Physically handicapped people find computers hard to use. Partly, people find reading from a screen difficult. With the integration of computers and telecommunications, the way of accessing information becomes an important problem. The designs of the dominant human machine interfaces are more suitable for the interpretation of information than by humans. The concept of the machine is able to interact with people in a mode that is natural and convenient for people."}, {"heading": "2. RELATED WORK", "text": "Dragon Dictate is the only discrete speech system that is still commercially available. In recent years, most systems have used continuous language that allows the user to speak in a more natural way. The most important continuous speech systems currently available for the PC are Dragon Naturally Speaking and IBM Via Voice. Microsoft has integrated its own speech recognition system into the latest versions of Windows. There is now a version of IBM Via Voice for the current Apple MAC computer. Voice recognition is aimed at recognizing the speaker, while speech recognition is associated with speech recognition. Speech recognition has been a research goal for more than four decades. [6] [7]"}, {"heading": "3. COMMANDS RECOGNITION USING HMM", "text": "The output of the above module is a list of features recorded every 10 msec. These features are then passed on to the Detection Module. The feature vectors generated by the feature vector generator module act as an observation list for the Detection Module. The probability of generating the observation given to a model, P (O | \u03bb), is calculated for each model using a Finding Probability Function. The word corresponding to the HMM, which indicates the highest probability and above the threshold, is considered to be spoken. The forward variable variable was used to determine the probability of occurrence of a model using a Finding Probability Function. For a model with N states, P (O / \u03bb) is defined as the probability of observation, in the sense of the Forward Variable, to determine the probability of occurrence of an HMM."}, {"heading": "Occurrence Probability", "text": "For the forward variable to function, we must find bi (Ot). This is the probability of a given occurrence for a given state. This value can be calculated by the formula of the multivariate normal distribution. Probability of observation X occurring in state i is given as follows: (1 / (2\u03c0) D / 2 | Vi |) exp (- (1 / 2) * (Ot-\u00b5i) TV-1 (Ot-\u00b5i)), where D represents the dimension of the vector, \u00b5i is the matrix, Vi is the covariance matrix, | Vi | is the determinant of matrix Vi, V-1 is the inversion of matrix V. The mean value vector \u00b5i is given as: \u00b5i = (1 / N) * \u2211 Ot Oti"}, {"heading": "Covariance Matrix Vi can be obtained by:", "text": "This operation yields a N x N in which N is the dimension of the system. [2] 4. TRAINED THE SYSTETo train the system, we needed three parameters: \u2022 None of the states that the HMM model should have. \u2022 The size of the characteristic vector D. \u2022 One or more filenames, each containing a training set. [4] To generate an initial HMM, we take the N equally placed observations (characteristic vector) from the first training set. Each is used to train a separate state. After the training, the states have an average vector that is of size D. And a variance matrix of size D X D that contains all zeros. Then, for each of the remaining observations, we find the Euklian distances that are intended for observation."}, {"heading": "5. IMPLEMENTATION OF COMMAND INPUT/OUTPUT SYSTEM", "text": "The implementation of the Input / Output System command is carried out by CHMM. The continuous HMM library, which supports vector as observations, has been implemented in the project. The library uses probability distribution functions, which is described in Section 3. The system has a model for each word that the system can recognize. The word list can be considered a language model, while the system needs to know where the model for each word can be found and which word corresponds to the model. This information is stored in a flat file, which is called models in a directory called HMMs. The difference in the case of HMM is that the symbol does not uniquely identify a state. The new state is determined by the symbol and the chances of transition from the current state to a candidate state. The system is trained before a word is mentioned in Section 4. When a sound is given to the system to recognize, it compares each model with the word and finds out the model that closest corresponds to it."}, {"heading": "6. EXPERIMENTAL RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Training", "text": "For the training of the system we used 20 users. Each user trained the system. The training of the system took place in a quiet and peaceful environment, so the detection accuracy can be higher. When users trained the system, a separate profile is created for each user."}, {"heading": "Recognition", "text": "Detection was tried on two types of sounds. \u2022 Known user: The user whose voice we used for training. \u2022 Unknown user: The user whose voice we did not use for training. \u2022 The result of the experiment as shown in the table: Table 1: Detection resultType of user Number of sounds Correct detection of unknown user 20 18 2 Unknown user 10 6 0Table 2 shows the probability of detection of commands and the graphical representation shows in Figure 2 on the last page."}, {"heading": "Commands Number of", "text": "The system is tested for 10 users and the corresponding percentage detection result is obtained from a diagram. This experiment tried to find out how many users are correctly detected. Results are shown in Table 3 and Graph 3."}, {"heading": "User Recognition Percentage", "text": "1 Accuracy of the experiments depends on the training time, if the training time of the system is increased, then the accuracy automatically increases. Time is directly proportional to accuracy, if the training time is increased, then the accuracy of the system increases if we trained the system in a very quiet environment and provided the same environment at the time of the system use. 3 Accuracy of the system increases if high-quality input hardware such as microphone is used 4 A graphical representation shows how time plays an important role in accuracy. A table showing the number of users and the time the user uses to train the system is given in Table 4 and Graph 4."}, {"heading": "8. CONCLUSIONS AND FUTURE WORK", "text": "The key factor in the development of such a system is the target audience. For example, physically handicapped people should be able to wear a headset and have their hands and eyes free to operate the system. Today, while this question is being considered and applied where these technologies are needed and desired, there are a number of scenarios in which speech recognition will either be delivered, developed, researched or seriously discussed, such as computer and video games, precision surgery, household applications, portable computers, etc. There are several challenges that the system will have to face in the future: firstly, the overall robustness of the system needs to be improved to facilitate implementation in real-world applications involving telephone and computer systems; secondly, the system needs to be able to reject irrelevant language that does not contain valid words or commands, etc. Thirdly, the recognition process needs to be designed so that commands can be set in continuous language; and finally, the language systems need to be able to operate on low-cost processors."}], "references": [{"title": "A feature-based hierarchical speech recognition system for Hindi", "author": ["K Samudravijaya", "R Ahuja", "N Bondale", "T Jose", "S Krishnan", "P Poddar", "S Rao P V", "R Raveendran"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "[8]", "startOffset": 0, "endOffset": 3}], "year": 2012, "abstractText": "In this information technology age, a convenient and user friendly interface is required to operate the computer system on very fast rate. In human being, speech being a natural mode of communication has potential to being a fast and convenient mode of interaction with computer. Speech recognition will play an important role in taking technology to them. It is the need of this era to access the information with in seconds. This paper describes the design and development of speaker independent and English command interpreted system for computer. HMM model is used to represent the phoneme like speech commands. Experiments have been done on real world data and system has been trained in normal condition for real world subject.", "creator": "PDFCreator Version 0.9.8"}}}