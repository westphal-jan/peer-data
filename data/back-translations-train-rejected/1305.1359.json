{"id": "1305.1359", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2013", "title": "A Differential Equations Approach to Optimizing Regret Trade-offs", "abstract": "We consider the classical question of predicting binary sequences and study the {\\em optimal} algorithms for obtaining the best possible regret and payoff functions for this problem. The question turns out to be also equivalent to the problem of optimal trade-offs between the regrets of two experts in an \"experts problem\", studied before by \\cite{kearns-regret}. While, say, a regret of $\\Theta(\\sqrt{T})$ is known, we argue that it important to ask what is the provably optimal algorithm for this problem --- both because it leads to natural algorithms, as well as because regret is in fact often comparable in magnitude to the final payoffs and hence is a non-negligible term.", "histories": [["v1", "Tue, 7 May 2013 00:02:51 GMT  (151kb,D)", "http://arxiv.org/abs/1305.1359v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alexandr", "oni", "rina panigrahy"], "accepted": false, "id": "1305.1359"}, "pdf": {"name": "1305.1359.pdf", "metadata": {"source": "CRF", "title": "A Differential Equations Approach to Optimizing Regret Trade-offs", "authors": ["Alexandr Andoni", "Rina Panigrahy"], "emails": [], "sections": [{"heading": null, "text": "\u221a T), we argue that it is important to ask which is the demonstrably optimal algorithm for this problem - both because it leads to natural algorithms, and because regret is often actually comparable in magnitude to final payouts, and therefore is not a negligible term. In the basic setting, the result is essentially a classic result of hedging '65. Instead, we focus on another default setting, the time-discounted payouts, where the final \"hold time\" is not specified. We show an explicit characterization of the optimal regret for this setting. To obtain our main result, we show that the optimal payout functions must meet the hermitic differential equation, and therefore are given by the solutions of this equation. It turns out that the characterization of the payout function differs qualitatively from the classical (non-discounted) setting, and that there is essentially a unique optimal solution."}, {"heading": "1 Introduction", "text": "Consider the following classic game of predicting a binary \u00b1 1 sequence. The player (predictor) sees a binary sequence {bt} t \u2265 1, one bit at a time, and tries to predict the next bit bt from the past history b1,.. the payout (score) of the algorithm is then the number of correct guesses minus the number of false guesses, which is formally defined as: for a certain time T > 0, and where b = t is the prediction at the time t: AT = 1 \u2264 Tbtb. One can consider this game as an idealized \"share prediction\" as follows: Every day, the share price rises or falls by exactly one dollar, and the player bets on this event. If the bet is correct, the player wins one dollar, and otherwise he loses one dollar. In general, it is impossible to guarantee a positive payout for all possible scenarios (sequences), even for randomized algorithms."}, {"heading": "1.1 Statement of Results", "text": "In general, we study the optimal regret curves, because we measure the payout and regret as a function of the \"height\" of the sequence (the sum of the bits of the sequence as defined above; one can also take a discounted sum). Note that the comparison against the amount amounts to a comparison of the performance of our algorithm with that of two static experts: one who always predicts + 1 (\"long the stock\"), and another who always predicts a payout of -1 (\"short the stock\"). The former receives a payout that corresponds to the amount and the latter receives a payout that is equal to the negative amount. We use the notion of a payout function - which assigns a real function f that assigns the payout of algorithms f (x) for each height x. In particular, for fixed algorithms and a height x, we leave the minimum payout over all sequences with the height x at the time T. For a certain function fT, we will say that f( x) is feasible if there is one."}, {"heading": "1.2 Related Work", "text": "Numerous papers, including [12, 9], have examined the optimal degree of remorse that can be achieved in relation to several experts (Chapter 8 in [10]). Recent papers, including [1, 2, 23], have extended this analysis to other constellations. Measures other than the standard remorse measure have been examined in [25]. Similarly, the Normal Hedge Algorithm [11] is similar, although it differs in both configuration and precise algorithm. Normal Hedge considers undiscounted payouts and receives strong remorse guarantees for the Epsilon quantier of the best experts. We look at two expert cases (where Epsilon quantity is not applicable) and try to obtain a demonstrably optimal regret."}, {"heading": "2 Time-Independent Prediction Algorithms", "text": "In this section, we will examine the optimal regret and the algorithms for the time-independent strategies and regret curves. We will consider the time-discounted setting, which allows us to theorem 1.2.As mentioned in the introduction, we consider a payout f feasible if there is a prediction algorithm that achieves a payout of at least f (x) for the discounted amount x at any time. We will argue that the payout function that achieves it is also time-independent. If f is feasible (in constant state), then there is a time-independent betting strategy b (x) that always dominates the function f (x). Observe that for a time-independent betting function, the payout function that achieves it is also time-independent. Claim 2.1 If f is feasible, then there is a time-independent betting strategy b that achieves payout function f."}, {"heading": "A Prediction Algorithms for Fixed Stopping Time", "text": "In this section we will discuss the optimal repentance and the corresponding betting algorithms for a fixed stop time T, which leads to strategies that depend on the current time t and the stop time T. We will consider the classic, non-discounted setting (Theorem 1.1) and the time-discounted setting (Theorem A.3), both of which depend on fixed stop time T. We will consider the admittedly more interesting case - the time-independent strategies - in the next section.A.1 Non-discounted setting [12] gave a precise characterization of the possible payout curves that are achievable. First, it showed that if we denote g (b =) for a sequence b = 1} T, we denote the payoff / score that will be achieved for sequence b."}, {"heading": "B Trade-off with two experts", "text": "This year, the number of people registered in the USA has increased to more than 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000, in Europe to 1,000 in Europe to 1,000, in Europe to 1,000 in Europe to 1,000, in Europe to 1,000 in Europe to 1,000, in Europe to 1,000 in Europe to 1,000, in Europe to 1,000 in Europe to 1,000 in Europe to 1,000, in Europe to 1,000 in Europe to 1,000 in Europe to 1,000, in Europe to 1,000 in Europe to 1,000 in Europe to 1,000, in Europe to 1,000 in Europe to 1,000 in Europe to 1,000, in Europe to 1,000 in Europe to 1,000 in Europe to 1,000, in Europe to 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, in Europe to 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, in Europe to 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, 1,000 in Europe to 1,000 in Europe, 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, 1,000 in Europe in Europe to 1,000 in Europe to 1,000 in Europe to 1,000 in Europe, 1,000 in Europe to 1,000 in Europe to 1,000 in Europe"}, {"heading": "C Multi-scale Optimal Regret", "text": "We show how the framework can be extended to the multiple time scales. The sequence can have trends in an unknown time frame and therefore it is important that the algorithm has a slight regret not only on a time scale, but at the same time on many time scales. We will now prove that (with unlimited bets) there are (normalized) payoff functions (x1, x2) and g2 (x1, x2) in time scales \u2212 if and only if he meets the conditions in Theorem 1.4.Proof of Theorem 1.4. If b (x1, x2) is the betting function (x1, x2), then as before the introduction of 1 (x1, x2) + bb-2-2-3-4-4-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-5-x1-5-"}], "references": [{"title": "Continuous experts and the binning algorithm", "author": ["J. Abernethy", "J. Langford", "M. Warmuth"], "venue": "Learning Theory pp", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Optimal strategies from random walks", "author": ["J. Abernethy", "M. Warmuth", "J. Yellin"], "venue": "Proceedings of The 21st Annual Conference on Learning Theory", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Algorithms for portfolio management based on the newton method", "author": ["A. Agarwal", "E. Hazan", "S. Kale", "R. Schapire"], "venue": "Proceedings of the 23rd international conference on Machine learning", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Minimax policies for adversarial and stochastic bandits", "author": ["J.Y. Audibert", "S. Bubeck"], "venue": "COLT", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "The nonstochastic multi-armed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R. Schapire"], "venue": "SIAM J. Comput", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Estimating the fractal dimension of the S&P500 index using wavelet analysis. International joirnal of theoretical and applied finance", "author": ["E. Bayraktar", "H. Poor", "K. Sircar"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Empirical support for winnow and weighted-majority algorithms: Results on a calendar scheduling domain", "author": ["A. Blum"], "venue": "Machine Learning 26(1),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1997}, {"title": "From external to internal regret", "author": ["A. Blum", "Y. Mansour"], "venue": "Journal of Machine Learning Research pp", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "How to use expert advice", "author": ["N. Cesa-Bianchi", "Y. Freund", "D. Haussler", "D. Helmbold", "R. Schapire", "M. Warmuth"], "venue": "Journal of the ACM (JACM) 44(3),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Prediction, Learning and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "A parameter free hedging algorithm", "author": ["K. Chaudhuri", "Y. Freund", "D. Hsu"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Behaviour of sequential predictors of binary sequences. Transactions of the Fourth Prague Conference on Information Theory, Statistical Decision Functions, Random Processes", "author": ["T. Cover"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1965}, {"title": "Universal portfolios", "author": ["T. Cover"], "venue": "Mathematical Finance", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1991}, {"title": "Regret to the best vs. regret to the average", "author": ["E. Even-Dar", "M. Kearns", "Y. Mansour", "J. Wortman"], "venue": "Machine Learning", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Predicting a binary sequence almost as well as the optimal biased coin", "author": ["Y. Freund"], "venue": "COLT", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1996}, {"title": "Using and combining predictors that specialize", "author": ["Y. Freund", "R.E. Schapire", "Y. Singer", "M.K. Warmuth"], "venue": "STOC pp", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1997}, {"title": "Multi-armed Bandit Allocation Indices", "author": ["J.C. Gittins"], "venue": "John Wiley", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1989}, {"title": "Efficient learning algorithms for changing environments", "author": ["E. Hazan", "C. Seshadhri"], "venue": "ICML pp", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "On-line portfolio selection using multiplicative updates", "author": ["D. Helmbold", "R. Schapire", "Y. Singer", "M. Warmuth"], "venue": "Mathematical Finance 8(4),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "A deterministic-control-based approach to fully nonlinear parabolic and elliptic equations", "author": ["R. Kohn", "S. Serfaty"], "venue": "Comm. Pure Appl. Math. 63(10),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "The weighted majority", "author": ["N. Littlestone", "M. Warmuth"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1989}, {"title": "Learning with continuous experts using drifting games", "author": ["I. Mukherjee", "R. Schapire"], "venue": "Algorithmic Learning Theory", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Normal approximation with Steins method", "author": ["M. Rai\u010d"], "venue": "Proceedings of the Seventh Young Statisticians Meeting", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Online learning: Beyond regret", "author": ["A. Rakhlin", "K. Sridharan", "A. Tewari"], "venue": "COLT", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Fractional brownian motion, random walks and binary market models", "author": ["T. Sottinen"], "venue": "Finance and Stochastics 5(3),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2001}, {"title": "A short proof of the gittins index theorem", "author": ["J. Tsitsiklis"], "venue": "Annals of Applied Probability", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1994}, {"title": "A game of prediction with expert advice", "author": ["V. Vovk"], "venue": "Journal of Computer and System Sciences", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1998}], "referenceMentions": [{"referenceID": 13, "context": "The question turns out to be also equivalent to the problem of optimal trade-offs between the regrets of two experts in an \u201cexperts problem\u201d, studied before by [14].", "startOffset": 160, "endOffset": 164}, {"referenceID": 11, "context": "Regret has been studied in a number of papers, including [12, 22, 13, 5, 4].", "startOffset": 57, "endOffset": 75}, {"referenceID": 20, "context": "Regret has been studied in a number of papers, including [12, 22, 13, 5, 4].", "startOffset": 57, "endOffset": 75}, {"referenceID": 12, "context": "Regret has been studied in a number of papers, including [12, 22, 13, 5, 4].", "startOffset": 57, "endOffset": 75}, {"referenceID": 4, "context": "Regret has been studied in a number of papers, including [12, 22, 13, 5, 4].", "startOffset": 57, "endOffset": 75}, {"referenceID": 3, "context": "Regret has been studied in a number of papers, including [12, 22, 13, 5, 4].", "startOffset": 57, "endOffset": 75}, {"referenceID": 20, "context": "A classical result says that one can obtain a regret of \u0398( \u221a T ) for a sequence of length T , via, say, the weighted majority algorithm of [22].", "startOffset": 139, "endOffset": 143}, {"referenceID": 9, "context": "the payoff per time step btb\u0303t is essentially equivalent to the well known absolute loss function |bt \u2212 b\u0303t| (see for example [10], chapter 8).", "startOffset": 126, "endOffset": 130}, {"referenceID": 13, "context": "The latter problem has been previously studied by [14], and later by [20], to address, say, an investment scenario where there may be two experts one risk taking and another conservative and one may be willing to take different regrets with respect to these two experts.", "startOffset": 50, "endOffset": 54}, {"referenceID": 5, "context": "For example, in several investment scenarios it is known that the payoffs of the experts (or stocks) in time T is barely more than O( \u221a T ) (see, for example, the Hurst coefficient measurements of financial markets in [6, 26]).", "startOffset": 218, "endOffset": 225}, {"referenceID": 24, "context": "For example, in several investment scenarios it is known that the payoffs of the experts (or stocks) in time T is barely more than O( \u221a T ) (see, for example, the Hurst coefficient measurements of financial markets in [6, 26]).", "startOffset": 218, "endOffset": 225}, {"referenceID": 11, "context": "We note that, in the vanilla setting, when there is a time bound T , the solution already follows from the results of [12] (see also [9, 10]), who gave a characterization of all possible payoffs back in 1965.", "startOffset": 118, "endOffset": 122}, {"referenceID": 8, "context": "We note that, in the vanilla setting, when there is a time bound T , the solution already follows from the results of [12] (see also [9, 10]), who gave a characterization of all possible payoffs back in 1965.", "startOffset": 133, "endOffset": 140}, {"referenceID": 9, "context": "We note that, in the vanilla setting, when there is a time bound T , the solution already follows from the results of [12] (see also [9, 10]), who gave a characterization of all possible payoffs back in 1965.", "startOffset": 133, "endOffset": 140}, {"referenceID": 19, "context": "One can also obtain the optimal algorithm by computing a certain dynamic programming, similar to an approach from [21].", "startOffset": 114, "endOffset": 118}, {"referenceID": 16, "context": "To understand the time-independent strategies, we are led to consider the another classic setting of time-discounted payoffs (see [17, 27]).", "startOffset": 130, "endOffset": 138}, {"referenceID": 25, "context": "To understand the time-independent strategies, we are led to consider the another classic setting of time-discounted payoffs (see [17, 27]).", "startOffset": 130, "endOffset": 138}, {"referenceID": 11, "context": "For starters, we remind the result for the vanilla, non-discounted, fixed stopping time setting, which follows from [12], and is related to Rademacher complexity of the predictions of the two experts (see [9, 10]).", "startOffset": 116, "endOffset": 120}, {"referenceID": 8, "context": "For starters, we remind the result for the vanilla, non-discounted, fixed stopping time setting, which follows from [12], and is related to Rademacher complexity of the predictions of the two experts (see [9, 10]).", "startOffset": 205, "endOffset": 212}, {"referenceID": 9, "context": "For starters, we remind the result for the vanilla, non-discounted, fixed stopping time setting, which follows from [12], and is related to Rademacher complexity of the predictions of the two experts (see [9, 10]).", "startOffset": 205, "endOffset": 212}, {"referenceID": 19, "context": "Such an approach has been previously undertaken by [21] to show that many differential equations can be realized as two-person games, as is also the case in our scenario.", "startOffset": 51, "endOffset": 55}, {"referenceID": 0, "context": "Here, in each round, each expert has a payoff in the range [0, 1] that is unknown to the algorithm.", "startOffset": 59, "endOffset": 65}, {"referenceID": 0, "context": "The algorithm pulls each arm (expert) with probability b\u03031,t, b\u03032,t \u2208 [0, 1] respectively where b\u03031,t + b\u03032,t = 1.", "startOffset": 70, "endOffset": 76}, {"referenceID": 13, "context": "We note that this was first studied in [14].", "startOffset": 39, "endOffset": 43}, {"referenceID": 7, "context": "Several earlier papers considered regrets at different time scales; see [8, 16, 18, 29, 20].", "startOffset": 72, "endOffset": 91}, {"referenceID": 15, "context": "Several earlier papers considered regrets at different time scales; see [8, 16, 18, 29, 20].", "startOffset": 72, "endOffset": 91}, {"referenceID": 17, "context": "Several earlier papers considered regrets at different time scales; see [8, 16, 18, 29, 20].", "startOffset": 72, "endOffset": 91}, {"referenceID": 11, "context": "Numerous works including [12, 9] have examined the optimal amount of regret achievable with respect to multiple experts.", "startOffset": 25, "endOffset": 32}, {"referenceID": 8, "context": "Numerous works including [12, 9] have examined the optimal amount of regret achievable with respect to multiple experts.", "startOffset": 25, "endOffset": 32}, {"referenceID": 9, "context": "Many of the results in this body of work can be found in [10].", "startOffset": 57, "endOffset": 61}, {"referenceID": 9, "context": "It is well known that in the case of static experts, the optimal regret is exactly equal to the Rademacher complexity of the predictions of the experts (chapter 8 in [10]).", "startOffset": 166, "endOffset": 170}, {"referenceID": 0, "context": "Recent works, including [1, 2, 23], have extended this analysis to other settings.", "startOffset": 24, "endOffset": 34}, {"referenceID": 1, "context": "Recent works, including [1, 2, 23], have extended this analysis to other settings.", "startOffset": 24, "endOffset": 34}, {"referenceID": 21, "context": "Recent works, including [1, 2, 23], have extended this analysis to other settings.", "startOffset": 24, "endOffset": 34}, {"referenceID": 23, "context": "Measures other than the standard regret measure have been studied in [25].", "startOffset": 69, "endOffset": 73}, {"referenceID": 10, "context": "Also related is the NormalHedge algorithm [11], though it differs in both the setting and the precise algorithm.", "startOffset": 42, "endOffset": 46}, {"referenceID": 7, "context": "Algorithms with performance guarantees within each interval have been studied in [8, 16, 29] and, more recently, in [18, 20].", "startOffset": 81, "endOffset": 92}, {"referenceID": 15, "context": "Algorithms with performance guarantees within each interval have been studied in [8, 16, 29] and, more recently, in [18, 20].", "startOffset": 81, "endOffset": 92}, {"referenceID": 17, "context": "Algorithms with performance guarantees within each interval have been studied in [8, 16, 29] and, more recently, in [18, 20].", "startOffset": 116, "endOffset": 124}, {"referenceID": 13, "context": "The question of what can be achieved if one would like to have a significantly better guarantee with respect to a fixed arm or a distribution on arms was asked before in [14, 20].", "startOffset": 170, "endOffset": 178}, {"referenceID": 26, "context": "Tradeoffs between regret and loss were also examined in [28], where the author studied the set of values of a, b for which an algorithm can have payoff aOPT + b logN , where OPT is the payoff of the best arm and a, b are constants.", "startOffset": 56, "endOffset": 60}, {"referenceID": 14, "context": "The problem of bit prediction was also considered in [15], where several loss functions are considered.", "startOffset": 53, "endOffset": 57}, {"referenceID": 6, "context": "Numerous papers ([7, 19, 3]) have implemented algorithms inspired from regret syle analysis and applied it on financial and other types of data.", "startOffset": 17, "endOffset": 27}, {"referenceID": 18, "context": "Numerous papers ([7, 19, 3]) have implemented algorithms inspired from regret syle analysis and applied it on financial and other types of data.", "startOffset": 17, "endOffset": 27}, {"referenceID": 2, "context": "Numerous papers ([7, 19, 3]) have implemented algorithms inspired from regret syle analysis and applied it on financial and other types of data.", "startOffset": 17, "endOffset": 27}], "year": 2013, "abstractText": "We consider the classical question of predicting binary sequences and study the optimal algorithms for obtaining the best possible regret and payoff functions for this problem. The question turns out to be also equivalent to the problem of optimal trade-offs between the regrets of two experts in an \u201cexperts problem\u201d, studied before by [14]. While, say, a regret of \u0398( \u221a T ) is known, we argue that it important to ask what is the provably optimal algorithm for this problem \u2014 both because it leads to natural algorithms, as well as because regret is in fact often comparable in magnitude to the final payoffs and hence is a non-negligible term. In the basic setting, the result essentially follows from a classical result of Cover from \u201965. Here instead, we focus on another standard setting, of time-discounted payoffs, where the final \u201cstopping time\u201d is not specified. We exhibit an explicit characterization of the optimal regret for this setting. To obtain our main result, we show that the optimal payoff functions have to satisfy the Hermite differential equation, and hence are given by the solutions to this equation. It turns out that characterization of the payoff function is qualitatively different from the classical (non-discounted) setting, and, namely, there\u2019s essentially a unique optimal solution.", "creator": "LaTeX with hyperref package"}}}