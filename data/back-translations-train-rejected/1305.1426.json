{"id": "1305.1426", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2013", "title": "Speech Enhancement Modeling Towards Robust Speech Recognition System", "abstract": "Form about four decades human beings have been dreaming of an intelligent machine which can master the natural speech. In its simplest form, this machine should consist of two subsystems, namely automatic speech recognition (ASR) and speech understanding (SU). The goal of ASR is to transcribe natural speech while SU is to understand the meaning of the transcription. Recognizing and understanding a spoken sentence is obviously a knowledge-intensive process, which must take into account all variable information about the speech communication process, from acoustics to semantics and pragmatics. While developing an Automatic Speech Recognition System, it is observed that some adverse conditions degrade the performance of the Speech Recognition System. In this contribution, speech enhancement system is introduced for enhancing speech signals corrupted by additive noise and improving the performance of Automatic Speech Recognizers in noisy conditions. Automatic speech recognition experiments show that replacing noisy speech signals by the corresponding enhanced speech signals leads to an improvement in the recognition accuracies. The amount of improvement varies with the type of the corrupting noise.", "histories": [["v1", "Tue, 7 May 2013 07:21:06 GMT  (30kb)", "http://arxiv.org/abs/1305.1426v1", "Pages: 04; Conference Proceedings International Conference on Advance Computing (ICAC-2008), India"]], "COMMENTS": "Pages: 04; Conference Proceedings International Conference on Advance Computing (ICAC-2008), India", "reviews": [], "SUBJECTS": "cs.SD cs.CL", "authors": ["urmila shrawankar", "v m thakare"], "accepted": false, "id": "1305.1426"}, "pdf": {"name": "1305.1426.pdf", "metadata": {"source": "CRF", "title": "Speech Enhancement Modeling Towards Robust Speech Recognition System", "authors": ["Urmila N. Shrawankar", "G H Raisoni", "V. M. Thakare"], "emails": ["urmilas@rediffmail.com"], "sections": [{"heading": null, "text": "While we are developing an automatic speech recognition system, some adverse conditions are observed to worsen the performance of the speech recognition system.This paper introduces a speech enhancement system to improve speech corrupted by additive noise and improve the performance of automatic speech recognition devices under loud conditions.Automatic speech recognition experiments show that replacing noisy speech signals with corresponding improved speech signals leads to improved recognition accuracy.The extent of the improvement varies depending on the type of corrupting noise. Categories and subject descriptions Human-Computer Interaction Interface (SUI): Human-Computer Interaction is not simply a human-human interaction. Human-human interaction is mainly based on speech, emotion and gesture, with human-computer interaction being based on either a text interface or a graphical interface (GUI)."}, {"heading": "1 INTRODUCTION", "text": "Much effort has been put into the efficient transmission and storage of voice signals in recent decades. As technology advances, the user interface (SUI) is being made a success of. The freedom and flexibility offered by SUI brings new challenges. While these technologies perform impressively in controlled, noise-free environments, performance quickly degrades under practical conditions. Noise reduction is also becoming an increasingly important feature, such as in offices, canteens, railway stations, etc., in order to improve the performance of voice recognition systems."}, {"heading": "2. NOISE ESTIMATION AND SPEECH ENHANCEMENT MODELS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Wiener Filtering:", "text": "With the Viennese filter approach, the optimal estimator is designed in such a way that the mean square error is minimized."}, {"heading": "2.2 Spectral Subtraction:", "text": "Spectral subtraction is a language enhancement scheme based on a direct estimate of the short-term spectral magnitude of clean language. It combines the estimated magnitude with the noisy phase."}, {"heading": "2.3 Subspace Based Models:", "text": "The Viennese filter does not distinguish between the two types of distortion. An alternative approach, motivated by perceptual considerations, consists in a trade-off between noise reduction and signal distortion and was introduced as a subspace method."}, {"heading": "2.4 Kalman Filter", "text": "Viennese filtering, spectral subtraction, and the subspace methods described above can generally be classified as non-parametric methods in that they do not use a parametric model to describe the signal, in contrast to parametric methods that use models such as the auto-regressive (AR) or the sine wave model to describe the signal. We are discussing a specific approach, the Kalman filter, which provides a framework that can exploit information about the human language production process using the AR model."}, {"heading": "2.5 Statistical Models", "text": "In the above mentioned models, we considered linear estimation techniques for the signal. Linear estimation is optimal (in the sense of the mean square MSE) for the case when x and y are Gaussian in common. In this case, the Viennese filter represents the optimal solution. In this section, we will consider methods that use distributions other than Gaussian and derive optimal nonlinear solutions. First, we will consider methods that maintain the Gaussian assumption about the speech and noise processes in the frequency domain, i.e., the respective Discrete Fourier Transform - DFT coefficients are assumed to be normally distributed. They differ from the Viennese solution in that they attempt to obtain MMSE estimates of the spectral amplitude, which then follows a Rayleigh distribution. Here, we will also discuss methods that proceed from super-Gaussian (gamma, laplace, etc.) models."}, {"heading": "2.5.1 Gaussian Models", "text": "In the Viennese Filter Approach to Speech Improvement, an optimal estimate (under Gaussian assumption and in the mean square sense of error) of the pure speech spectral component is obtained from the noisy language. Spectral amplitude is perceptibly more relevant than the phase, and therefore performance could be improved by an optimal estimate of the amplitude. Amplitude estimation by the Viennese filter (obtained as a module of the optimally estimated spectral component) is not optimal under the assumed model; only the estimation of the spectral component is optimal. By using the same statistical model, an optimal estimate of the spectral amplitude with loud language can be obtained. Fourier expansion coefficients of the speech and noise processes are assumed as independent zero-mean Gaussian variables with temporally varying variances, resulting in a Rayleigh distribution of the amplitudes of the amplitudes of the Fourier amplitudes."}, {"heading": "2.5.2 Super-Gaussian Models", "text": "The methods discussed in the previous section assume that the DFT coefficients follow a Gaussian distribution. In this section we will discuss methods that presuppose a Super Gaussian distribution. Super Gaussian variables, also called leptocourses, have a better distribution of gamma (probability density function) than Gaussian random variables and have heavier tails, e.g. laplace and gamma distributions. DFT coefficients are better modelled by a gamma distribution. Under the Gaussian assumption for speech and noise, the estimator is linear (Vienna filter)."}, {"heading": "2.6 Trained Statistical Models", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.6.1 HMM Based Methods", "text": "s MMSE and MAP maximum aposteriori estimates of the speech signal. HMMs consist of several states with a mixture of Gaussian pdfs in each state. A state transition matrix regulates the transition from one state to another. The covariance matrix of each Gaussian pdf is parameterized by the AR parameters of the signal. AR parameters are the linear prediction coefficients and the variance of the excitation signal. In the MAP approach, an estimate of the speech signal is achieved by maximizing the rear pdf of the speech signal taking into account the noisy observations. As the corresponding gradient equations are non-linear, a local maximization of the speech signal is performed using the expectation filter."}, {"heading": "2.6.2 Codebook Based Approach", "text": "The codebook-based approaches attempt to overcome the disadvantage of the Hidden Markov Model (HMM) in non-stationary noise. In a context of language decomposition, an instantaneous frame-by-frame gain computing approach was also considered. Trained codebooks containing only the LP coefficients of speech and noise are used to calculate the gain terms for each short timeframe based on the LP coefficients and loud observation, and the codebooks are trained on representative language and noise databases."}, {"heading": "2.7 Comparison between HMM and Codebook Approaches", "text": "The main difference between the HMM methods and the codebook approaches lies in the way they deal with the non-stationary noise signals, which in turn are related to the modelling and calculation of the excitation variants. Since the HMM method models both the LP coefficients and the excitation variance as prior information, an adjustment of the gain for the speech and sound models is required to compensate for differences in the level of excitation variance between training and operation. Gain adaptation factor is calculated using the observed noise gain and an estimate of the noise statistics obtained with the help of, for example, the minimal statistical approach. Conventional noise estimation techniques are buffer-based techniques in which an estimate is achieved on a buffer of several past frames. Therefore, such a scheme cannot react quickly to non-stationary noise. In the codebook-AR approach, the MD and LP coefficient models are optimally calculated."}, {"heading": "3. CONCLUSION", "text": "In fact, it is such that most people are able to survive themselves when they go to another world, in which they go to another world. In the other world it is such that they go to another world. In the third world it is such that they go to another world. In the third world it is such that they go to another world. In the third world it is such that they go to another world. In the third world it is such that they go to another world. In the third world it is such that they go to another world. In the third world it is such that they go to another world. In the third world it is such that they go to another world. In the third world it is so, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in the third world, in"}], "references": [{"title": "Suppression of acoustic noise in speech using spectral subtraction,", "author": ["S.F. Boll"], "venue": "IEEE Trans. Acoustics, Speech, Signal Processing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1979}, {"title": "MMSE estimation of magnitude-squared DFT coefficients with supergaussian priors,", "author": ["C. Breithaupt", "R. Martin"], "venue": "Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "A minimum mean square error approach for speech enhancement,", "author": ["Y. Ephraim"], "venue": "Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1990}, {"title": "Employing Laplacian-Gaussian densities for speech enhancement,", "author": ["S. Gazor"], "venue": "Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Speech enhancement employing Laplacian Gaussian mixture,", "author": ["S. Gazor", "W. Zhang"], "venue": "IEEE Trans. Speech Audio Processing,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "Estimation of the excitation variances of speech and noise AR-models for enhanced speech", "author": ["M. Kuropatwinski", "W.B. Kleijn"], "venue": "coding,\" in Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Speech enhancement in the DFT domain using Laplacian speech priors.", "author": ["R. Martin", "C. Breithaupt"], "venue": "in Proc. Int. Workshop Acoustic Echo and Noise Control,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "New speech enhancement techniques for low bit rate speech", "author": ["R. Martin", "R.V. Cox"], "venue": "coding,\" in Proc. IEEE Speech Coding Workshop,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "A speech enhancement method based on Kalman \u0304 ltering,", "author": ["K.K. Paliwal", "A. Basu"], "venue": "in Proc. IEEE Int. Conf. Acoustics, Speech, Signal Pro-cessing,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1987}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition,", "author": ["L.R. Rabiner"], "venue": "Proc. IEEE,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1989}, {"title": "Fundamentals of speech", "author": ["L.R. Rabiner", "B.H. Juang"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1993}, {"title": "HMM-based strategies for enhancement of speech signals embedded in nonstationary noise,", "author": ["H. Sameti", "H. Sheikhzadeh", "L. Deng"], "venue": "IEEE Trans. Speech Audio Processing,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "Model based voice decomposition method,", "author": ["M. Sugiyama"], "venue": "Proc. ICSLP,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2000}, {"title": "On noise gain estimation for HMM based speech enhancement,", "author": ["D. Zhao", "W.B. Kleijn"], "venue": "in Proc. Interspeech 2005 - Eurospeech,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}], "referenceMentions": [], "year": 2008, "abstractText": "For about four decades human beings have been dreaming of an intelligent machine which can master the natural speech. In its simplest form, this machine should consist of two subsystems, namely automatic speech recognition (ASR) and speech understanding (SU). The goal of ASR is to transcribe natural speech while SU is to understand the meaning of the transcription. Recognizing and understanding a spoken sentence is obviously a knowledge-intensive process, which must take into account all variable information about the speech communication process, from acoustics to semantics and pragmatics. While developing an Automatic Speech Recognition System, it is observed that some adverse conditions degrade the performance of the Speech Recognition System. In this contribution, speech enhancement system is introduced for enhancing speech signals corrupted by additive noise and improving the performance of Automatic Speech Recognizers in noisy conditions. Automatic speech recognition experiments show that replacing noisy speech signals by the corresponding enhanced speech signals leads to an improvement in the recognition accuracies. The amount of improvement varies with the type of the corrupting noise.", "creator": "deskPDF 2.5"}}}