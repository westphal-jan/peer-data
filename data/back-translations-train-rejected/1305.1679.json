{"id": "1305.1679", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2013", "title": "High Level Pattern Classification via Tourist Walks in Networks", "abstract": "Complex networks refer to large-scale graphs with nontrivial connection patterns. The salient and interesting features that the complex network study offer in comparison to graph theory are the emphasis on the dynamical properties of the networks and the ability of inherently uncovering pattern formation of the vertices. In this paper, we present a hybrid data classification technique combining a low level and a high level classifier. The low level term can be equipped with any traditional classification techniques, which realize the classification task considering only physical features (e.g., geometrical or statistical features) of the input data. On the other hand, the high level term has the ability of detecting data patterns with semantic meanings. In this way, the classification is realized by means of the extraction of the underlying network's features constructed from the input data. As a result, the high level classification process measures the compliance of the test instances with the pattern formation of the training data. Out of various high level perspectives that can be utilized to capture semantic meaning, we utilize the dynamical features that are generated from a tourist walker in a networked environment. Specifically, a weighted combination of transient and cycle lengths generated by the tourist walk is employed for that end. Interestingly, our study shows that the proposed technique is able to further improve the already optimized performance of traditional classification techniques.", "histories": [["v1", "Tue, 7 May 2013 23:40:08 GMT  (1727kb,D)", "http://arxiv.org/abs/1305.1679v1", "Submitted to the IEEE Transactions on Neural Networks and Learning Systems"]], "COMMENTS": "Submitted to the IEEE Transactions on Neural Networks and Learning Systems", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["thiago christiano silva", "liang zhao"], "accepted": false, "id": "1305.1679"}, "pdf": {"name": "1305.1679.pdf", "metadata": {"source": "CRF", "title": "High Level Pattern Classification via Tourist Walks in Networks", "authors": ["Thiago Christiano Silva"], "emails": ["zhao}@icmc.usp.br."], "sections": [{"heading": null, "text": "This year, it is only a matter of time before agreement is reached."}, {"heading": "II. RELEVANT BACKGROUND: TOURIST WALKS", "text": "In each individual step of time, the tourist follows a simple deterministic rule: he visits the next page that was not visited in the previous \u00b5 steps. In other words, the hiker partially performs self-avoiding deterministic walks over the data set, in which the self-avoiding factor is limited to the memory window. \u2212 1. This amount can be understood as a repulsive force emanating from the locations in this memory window that prevents the walker from visiting it at that interval (refractory time). Therefore, it is forbidden for a trajectory to intersect within this memory window. Although it is a simple rule, it has been shown that this movement dynamically exhibits complex behavior when \u00b5 > 1 [24].The behavior of the tourist depends greatly on the configuration of the data set and the starting point."}, {"heading": "III. MODEL DESCRIPTION", "text": "This section presents a number of useful notations, together with the assumptions of the underlying hybrid classification framework. Next, we give a quick overview of the peculiarities of the original hybrid classification framework [4]. Finally, the high-level classification based on tourist walks is formally introduced, as well as an overview of its algorithm."}, {"heading": "A. Notations and Premises", "text": "Some mathematical notations and assumptions are discussed below. Consider that Xtraining = {(x1, y1),.., (xl, yl), (xl, yl)}, which consists of training instances designated as l. Each training instance, xi-X, receives its own label or target yi-L. In addition, each training instance is described by a d-dimensional vector, i.e. xi = (f1,.., fd), each entry symbolizing a feature or descriptor of this point. The aim is to construct a hypothesis in such a way that the classifier x 7 \u2192 y is depicted. Usually, the constructed classifier is checked for its predictive power by subjecting it to a test set Xtest = {xl + 1,.., xl + u} in which the labels are not provided."}, {"heading": "B. Overview of the Hybrid Classification Framework", "text": "In this context, we must also mention the fact that each country is a country in which it is not a country, but a country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which it is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which is a country, in which"}, {"heading": "C. Deriving the High Level Classification Technique Using Tourist Walks", "text": "Equation (1) provides a general framework for the hybrid classification process in the sense that various supervised data classification techniques can be brought into play. (1) The first term of (1) is relatively easy to implement, as it can be any traditional classification technology. However, the literature offers a myriad of supervised data classification techniques, some of which include graph-based methods, decision trees, SVM and their variations, neural networks, Bayesian learning terms, among many others. However, little has been done in the field of classification techniques that takes into account the patterns or organizational features inherent in the relationships between the data elements. Thus, we now proceed to a detailed analysis of the proposed high-level classification term H.Motivated by the intrinsic ability to describe topological structures among the data elements, we propose a network-based (graph-based) technique for the high-level classifier."}, {"heading": "D. Algorithm", "text": "For didactic purposes, Algorithm 1 lists the sequence of steps required to perform a high-level classification of a single test instance in accordance with the rules we have described in this paragraph.1 Algorithm 1: An overview of the high-level classification procedure used on tourist walks for a single test instance.1) Construct a set of network components G = {G1,..., GL} for each class from the vector-based training set using the combined k-NN and rules from the training phase; 2) Calculate the average transition and cycle lengths for the component of each network representing a class of training data; 3) Insert a test instance xi into the graphs formed using the k-NN and rules from the classification phase; 4) Calculate the new average transition and cycle lengths for the component of each network that has a connection of at least one test distance of the transition distance (and help with calculating the high); 4) Calculate the transition length (and high)."}, {"heading": "E. Linking the High Level Classifier based on Tourist Walks and the General Framework introduced in [4]", "text": "One may wonder how the high-level classifier based on (3) = > u = high (1) is in the general framework for high-level classification (introduced in [4]. The following proposal links both approaches. Proposal 1. The high-level classifier based on tourist walks whose decision equations are: H (j) i = high (p). (1 \u2212 T (j). (1 \u2212 T) i (1 \u2212 C (j). (1 \u2212 C) i (p))."}, {"heading": "IV. COMPUTER SIMULATIONS", "text": "In this section we present the results of the computer simulation to evaluate the effectiveness of the proposed hybrid classification model based on tourist walks. Error estimation method in these simulations will be the stratified 10-fold cross-validation."}, {"heading": "A. Motivating and Illustrative Examples", "text": "In this section, we offer simple examples with the aim of showing the mechanisms of the proposed hybrid classification technology. To this end, we simplify the parameter selection procedures as follows: The weights given for the transients and cycle lengths are the same, i.e., it would merely form a real pattern of the real classification technology = 0.5; and the critical tourist run length is defined as the size of the smallest class in the problem. Here, we design certain situations in which the use of the high order of learning is welcome, since reliability at the mere physical level would probably deceive a low classification. As an introductory example, we consider the synthetic data supplied in Fig. 1 in the introductory section Section Section Section. Our goal is to classify the two triangular data elements (Xtest). The elements in Xtest will be one with an insert of 0.05 and one of each network component = 2, before the network construction."}, {"heading": "B. Parameter Sensitivity Analysis", "text": "In this section, we run several simulations to gain a better understanding of the influence of each parameter in the model.1) Influence of the compliance term on different high-level classifiers: In this section, we examine the impact of the compliance term \u03bb on three different types of high-level classifiers, as follows: (i) you construct only the cycle length of the component; (ii) you construct only the transient length of the component; and (iii) the best-weighted combination of these two measurements. The optimization process is performed by finding the precision of each measurement variable. (0, 0.1,.). (search space), which results in the highest accuracy rate of the model. Here, we show that, in general, the transient and cycle lengths are not correlated."}, {"heading": "C. Simulations on Real-World Data Sets", "text": "In this section, we will apply the proposed framework to several known UCI datasets. The most relevant metadata of each dataset are in Table II. For a detailed description, refer to [34]. In terms of numerical attributes, the reciprocal technique of Euclidean distance is used. However, for categorical examples, the overlap similarity measurement [35] is used. All datasets are submitted to a standardization pre-processing table. Here, the high-level classifier is composed of the best weighted combination of transient and cycle lengths. The optimization process is performed by encountering different types of memory. [0, 0.1, 1, 2, 2, 3. (search space), subject to + 1, the highest accuracy rate of the model. The critical memory length is set to \u00b5c = 0.3nmax, where nmax indicates the size of the largest component."}, {"heading": "V. APPLICATION: HANDWRITTEN DIGITS RECOGNITION", "text": "In this section, we provide an application of the proposed technique to handwritten number recognition. Specifically, we have been classified in Subsect 3 = 11. V, we detail the experimental results obtained from the modified NIST database, because a data set consisting of tens of thousands of real handwritten numbers is already specific today. Nevertheless, in this section, we present two simple examples to show how the proposed technique can be used for invariant pattern recognition. The data set in which we will conduct our studies is referred to as the modified NIST set [40]. This data set provides a training set of 60,000 samples and a test set of 10,000 samples. Each image has 28 x 28 pixels. In terms of high-level classification, the network is constructed at the training stage using k = 3 and = 0.01."}, {"heading": "VI. CONCLUSIONS", "text": "In this paper, we have proposed an alternative and novel method of data classification that combines both low and high properties of the data: the former classifies data instances by their physical properties, and the latter measures the consistency of the test instance with the pattern formation of the input data. To this end, tourist walks have been used to capture the complex topological properties of the network created from the input data. A very interesting feature of the proposed technique is that the influence of the generic term must be increased in order to obtain a correct classification, as the complexity of the class configuration increases. This means that the generic term is particularly useful in complex classification situations. Furthermore, it is worth noting that the application of the dynamics of tourist migrations in the context of the high classifier is also a novel approach in the literature. We have shown that although such a path is constructed under very simple rules, it is nevertheless able to capture topological characteristics of the underlying network on a global basis to local basis."}, {"heading": "ACKNOWLEDGMENT", "text": "This work is supported by the Sa'o Paulo State Research Foundation (FAPESP) and the Brazilian National Research Council (CNPq)."}], "references": [{"title": "Pattern Classification, 2nd ed", "author": ["R.O. Duda", "P.E. Hart", "D.G. Stork"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Network-based high level data classification", "author": ["T.C. Silva", "L. Zhao"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 23, no. 6, pp. 954\u2013970, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Combining labeled and unlabeled data with co-training", "author": ["A. Blum", "T. Mitchell"], "venue": "COLT: Proceedings of the Workshop on Computational Learning Theory, 1998, pp. 92\u2013100.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1998}, {"title": "Tri-training: exploiting unlabeled data using three classifiers", "author": ["Z.-H. Zhou", "M. Li"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 17, no. 11, pp. 1529\u20131541, 2005.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "The semantic web", "author": ["T. Berners-Lee", "J. Hendler", "O. Lassila"], "venue": "Scientific American, vol. 284, no. 5, pp. 34\u201343, 2001.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "The semantic web revisited", "author": ["N. Shadbolt", "W. Hall", "T. Berners-Lee"], "venue": "IEEE Intelligent Systems, vol. 6, pp. 96\u2013101, 2006.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "The semantic web in action", "author": ["L. Feigenbaum", "I. Herman", "T. Hongsermeier", "E. Neumann", "S. Stephens"], "venue": "Scientific American, vol. 297, no. 6, pp. 90\u201397, 2007.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Linear prediction models with graph regularization for web-page categorization.", "author": ["T. Zhang", "A. Popescul", "B. Dom"], "venue": "in KDD. ACM,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Classification in networked data: A toolkit and a univariate case study", "author": ["S.A. Macskassy", "F. Provost"], "venue": "J. Mach. Learn. Res., vol. 8, pp. 935\u2013983, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Combining content and link for classification using matrix factorization.", "author": ["S. Zhu", "K. Yu", "Y. Chi", "Y. Gong"], "venue": "in SIGIR. ACM,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Using ghost edges for classification in sparsely labeled networks", "author": ["B. Gallagher", "H. Tong", "T. Eliassi-rad", "C. Faloutsos"], "venue": "Knowledge Discovery and Data Mining, 2008, pp. 256\u2013264.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Classifying networked entities with modularity kernels", "author": ["D. Zhang", "R. Mao"], "venue": "International Conference on Information and Knowledge Management, 2008, pp. 113\u2013122.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Semi-supervised learning literature survey", "author": ["X. Zhu"], "venue": "Computer Sciences, University of Wisconsin-Madison, Tech. Rep. 1530, 2005.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "Use of contextual constraints in recognition of contour-traced handprinted characters", "author": ["R.W. Donaldson", "G.T. Toussaint"], "venue": "IEEE Trans. Computers, pp. 1096\u20131099, 1970.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1970}, {"title": "A cognitive pyramid for contextual classification of remote sensing images", "author": ["E. Binaghi", "I. Gallo", "M. Pepe"], "venue": "IEEE Trans. Geoscience and Remote Sensing, vol. 41, no. 12, pp. 2906\u20132922, 2003.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning relevant image features with multiple-kernel classification", "author": ["D. Tuia", "G. Camps-Valls", "G. Matasci", "M. Kanevski"], "venue": "IEEE Trans. Geoscience and Remote Sensing, vol. 48, no. 10, pp. 3780\u20133791, 2010.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning contextual dependency network models for link-based classification", "author": ["Y. Tian", "Q. Yang", "T. Huang", "C.X. Ling", "W. Gao"], "venue": "IEEE Trans. Data and Knowledge Engineering, vol. 18, no. 11, pp. 1482\u20131496, 2006.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "survey of image classification methods and techniques for improving classification performance", "author": ["D. Lu", "Q. Weng"], "venue": "International Journal of Remote Sensing, vol. 28, no. 5, pp. 823\u2013870, 2007.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "On classification with incomplete data", "author": ["D. Williams", "X. Liao", "Y. Xue", "L. Carin", "B. Krishnapuram"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 29, no. 3, pp. 427\u2013436, 2007.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Neural network for graphs: A contextual constructive approach", "author": ["A. Micheli"], "venue": "IEEE Trans. Neural Networks, vol. 20, no. 3, pp. 498\u2013511, 2009.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Deterministic walks in random media", "author": ["G.F. Lima", "A.S. Martinez", "O. Kinouchi"], "venue": "Phy. Rev. Lett., vol. 87, p. 010603, 2001.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "Deterministic walks as an algorithm of pattern recognition", "author": ["M.G. Campiteli", "P.D. Batista", "O. Kinouchi", "A.S. Martinez"], "venue": "Physical Review E, vol. 74, p. 026703, 2006.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}, {"title": "Texture analysisandclassificationusingdeterministictouristwalk", "author": ["A.R. Backes", "W.N. Gon\u00e7alves", "A.S. Martinez", "O.M. Bruno"], "venue": "Pattern Recognition, vol. 43, pp. 685\u2013694, 2010.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "Rotation invariant kernels and their application to shape analysis", "author": ["O.C. Hamsici", "A.M. Martinez"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 31, no. 11, pp. 1985\u20131999, 2009.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1985}, {"title": "Age-invariant face recognition", "author": ["U. Park", "Y. Tong", "A.K. Jain"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 32, no. 5, pp. 947\u2013954, 2010.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Robust object recognition with cortex-like mechanisms", "author": ["T. Serre", "L. Wolf", "S. Bileschi", "M. Riesenhuber", "T. Poggio"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 29, no. 3, pp. 411\u2013426, 2007.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "Statistical physics - the salesman and the tourist", "author": ["H.E. Stanley", "S.V. Buldyrev"], "venue": "Nature, vol. 413, pp. 373\u2013374, 2001.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2001}, {"title": "Deterministic walks in random networks: an application to thesaurus graphs", "author": ["O. Kinouchi", "A.S. Martinez", "G.F. Lima", "G.M. Louren\u00e7o", "S. Risau- Gusman"], "venue": "Physica A, vol. 315, pp. 665\u2013676, 2002.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2002}, {"title": "Fuzzy support vector machines", "author": ["C.-F. Lin", "S.-D. Wang"], "venue": "IEEE Transactions on Neural Networks, vol. 13, pp. 464\u2013471, 2002.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2002}, {"title": "A comparison of methods for multi-class support vector machines", "author": ["C.-W. Hsu", "C.-J. Lin"], "venue": "IEEE Transactions on Neural Networks, vol. 13, pp. 415\u2013425, 2002.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2002}, {"title": "UCI machine learning repository", "author": ["A. Frank", "A. Asuncion"], "venue": "2010.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Similarity measures for categorical data: A comparative evaluation", "author": ["S. Boriah", "V. Chandola", "V. Kumar"], "venue": "SIAM Data Mining Conference, 2008, pp. 243\u2013254.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2008}, {"title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction, second edition ed", "author": ["T. Hastie", "R. Tibshirani", "J. Friedman"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Learning internal representations by error propagation", "author": ["D.E. Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1988}, {"title": "Fuzzy support vector machines for multiclass problems", "author": ["S. Abe", "T. Inoue"], "venue": "in European Symposium on Artificial Neural Networks, 2002, 2002, pp. 113\u2013118.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2002}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, vol. 86, no. 11, pp. 2278\u20132324, 1998.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 1, "context": "These techniques that predict class labels using only physical features are called low level classification techniques [4].", "startOffset": 119, "endOffset": 122}, {"referenceID": 1, "context": "Supervised data classification by considering not only physical attributes but also pattern formation is referred to as high level classification [4].", "startOffset": 146, "endOffset": 149}, {"referenceID": 2, "context": "In this sense, strongly related techniques are co-training [5] and tritraining [6], which attempt to consider the cooperation of various classification techniques (ensemble), each focusing on a theoretically different \u201cvision\u201d of the data.", "startOffset": 59, "endOffset": 62}, {"referenceID": 3, "context": "In this sense, strongly related techniques are co-training [5] and tritraining [6], which attempt to consider the cooperation of various classification techniques (ensemble), each focusing on a theoretically different \u201cvision\u201d of the data.", "startOffset": 79, "endOffset": 82}, {"referenceID": 4, "context": "Following the literature stream on such matter, there are several kinds of works related to high level classification, such as the Semantic Web [7]\u2013[9], which uses ontologies to describe the semantics of the data, statistical relational learning, which realizes collective inference [10]\u2013[14] or graph-based semisupervised learning [15], [16], and contextual classification techniques [17]\u2013[23], which consider the spatial relationships between the individual pixels and the local and global configurations of neighboring pixels in an image for assigning classes.", "startOffset": 144, "endOffset": 147}, {"referenceID": 6, "context": "Following the literature stream on such matter, there are several kinds of works related to high level classification, such as the Semantic Web [7]\u2013[9], which uses ontologies to describe the semantics of the data, statistical relational learning, which realizes collective inference [10]\u2013[14] or graph-based semisupervised learning [15], [16], and contextual classification techniques [17]\u2013[23], which consider the spatial relationships between the individual pixels and the local and global configurations of neighboring pixels in an image for assigning classes.", "startOffset": 148, "endOffset": 151}, {"referenceID": 7, "context": "Following the literature stream on such matter, there are several kinds of works related to high level classification, such as the Semantic Web [7]\u2013[9], which uses ontologies to describe the semantics of the data, statistical relational learning, which realizes collective inference [10]\u2013[14] or graph-based semisupervised learning [15], [16], and contextual classification techniques [17]\u2013[23], which consider the spatial relationships between the individual pixels and the local and global configurations of neighboring pixels in an image for assigning classes.", "startOffset": 283, "endOffset": 287}, {"referenceID": 11, "context": "Following the literature stream on such matter, there are several kinds of works related to high level classification, such as the Semantic Web [7]\u2013[9], which uses ontologies to describe the semantics of the data, statistical relational learning, which realizes collective inference [10]\u2013[14] or graph-based semisupervised learning [15], [16], and contextual classification techniques [17]\u2013[23], which consider the spatial relationships between the individual pixels and the local and global configurations of neighboring pixels in an image for assigning classes.", "startOffset": 288, "endOffset": 292}, {"referenceID": 12, "context": "Following the literature stream on such matter, there are several kinds of works related to high level classification, such as the Semantic Web [7]\u2013[9], which uses ontologies to describe the semantics of the data, statistical relational learning, which realizes collective inference [10]\u2013[14] or graph-based semisupervised learning [15], [16], and contextual classification techniques [17]\u2013[23], which consider the spatial relationships between the individual pixels and the local and global configurations of neighboring pixels in an image for assigning classes.", "startOffset": 332, "endOffset": 336}, {"referenceID": 13, "context": "Following the literature stream on such matter, there are several kinds of works related to high level classification, such as the Semantic Web [7]\u2013[9], which uses ontologies to describe the semantics of the data, statistical relational learning, which realizes collective inference [10]\u2013[14] or graph-based semisupervised learning [15], [16], and contextual classification techniques [17]\u2013[23], which consider the spatial relationships between the individual pixels and the local and global configurations of neighboring pixels in an image for assigning classes.", "startOffset": 385, "endOffset": 389}, {"referenceID": 19, "context": "Following the literature stream on such matter, there are several kinds of works related to high level classification, such as the Semantic Web [7]\u2013[9], which uses ontologies to describe the semantics of the data, statistical relational learning, which realizes collective inference [10]\u2013[14] or graph-based semisupervised learning [15], [16], and contextual classification techniques [17]\u2013[23], which consider the spatial relationships between the individual pixels and the local and global configurations of neighboring pixels in an image for assigning classes.", "startOffset": 390, "endOffset": 394}, {"referenceID": 20, "context": "A tourist walk can be defined as follows: Given a set of cities, each time the tourist (walker) goes to the nearest city that has not been visited in the past \u03bc time steps [24].", "startOffset": 172, "endOffset": 176}, {"referenceID": 21, "context": "It has been shown that tourist walk is useful for data clustering [25] and image processing [26].", "startOffset": 66, "endOffset": 70}, {"referenceID": 22, "context": "It has been shown that tourist walk is useful for data clustering [25] and image processing [26].", "startOffset": 92, "endOffset": 96}, {"referenceID": 1, "context": "The idea of this paper is built upon the general framework proposed by [4].", "startOffset": 71, "endOffset": 74}, {"referenceID": 1, "context": "In the original work introduced in [4], the high level classification problem is treated using three existing network measures in a combined way (assortativity, clustering coefficient, and average degree).", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "In this occasion, the global topological and organizational features of the network are said to be completely characterized in the sense of tourist walks; \u2022 In view of the intuitive dynamical properties displayed by a tourist walk, one can avoid the weight assignment among various network measures, which is a problem when static network measures are used, as occurs in [4].", "startOffset": 371, "endOffset": 374}, {"referenceID": 23, "context": "Still in this paper, we show how the proposed technique can be used to solve general invariant pattern recognition problems [27]\u2013[29], particularly when the pattern variances are nonlinear and there is not a closed form to describe the invariance.", "startOffset": 124, "endOffset": 128}, {"referenceID": 25, "context": "Still in this paper, we show how the proposed technique can be used to solve general invariant pattern recognition problems [27]\u2013[29], particularly when the pattern variances are nonlinear and there is not a closed form to describe the invariance.", "startOffset": 129, "endOffset": 133}, {"referenceID": 20, "context": "In spite of being a simple rule, it has been shown that this movement dynamic possesses complex behavior when \u03bc > 1 [24].", "startOffset": 116, "endOffset": 120}, {"referenceID": 20, "context": "A note that is worth pointing out is that, in the majority of the works related to these walks [24], [30], [31], the tourist may visit any other site other than the ones contained in its memory window.", "startOffset": 95, "endOffset": 99}, {"referenceID": 26, "context": "A note that is worth pointing out is that, in the majority of the works related to these walks [24], [30], [31], the tourist may visit any other site other than the ones contained in its memory window.", "startOffset": 101, "endOffset": 105}, {"referenceID": 27, "context": "A note that is worth pointing out is that, in the majority of the works related to these walks [24], [30], [31], the tourist may visit any other site other than the ones contained in its memory window.", "startOffset": 107, "endOffset": 111}, {"referenceID": 1, "context": "Next, we give a quick overview on the particularities of the original hybrid classification framework [4].", "startOffset": 102, "endOffset": 105}, {"referenceID": 1, "context": "In this section, we review the hybrid classification framework [4].", "startOffset": 63, "endOffset": 66}, {"referenceID": 1, "context": "and the General Framework introduced in [4]", "startOffset": 40, "endOffset": 43}, {"referenceID": 1, "context": "One may wonder how the high level classifier based on tourist walks given by (3) is plugged into the general framework for high level classification introduced in [4].", "startOffset": 163, "endOffset": 166}, {"referenceID": 28, "context": "With respect to the low level classifier, a fuzzy SVM classifier is utilized [32], which is equipped with optimization method criterion defined as the Karush-Kuhn-Tucker violation fixed at 10\u22123 (the same condition suggested by [33]).", "startOffset": 77, "endOffset": 81}, {"referenceID": 29, "context": "With respect to the low level classifier, a fuzzy SVM classifier is utilized [32], which is equipped with optimization method criterion defined as the Karush-Kuhn-Tucker violation fixed at 10\u22123 (the same condition suggested by [33]).", "startOffset": 227, "endOffset": 231}, {"referenceID": 30, "context": "Continuing our exploration of this interesting phenomenon, we now turn our attention to two well-known data sets from the UCI Machine Learning Repository [34]: Iris (balanced classes) and Wine (unbalanced classes).", "startOffset": 154, "endOffset": 158}, {"referenceID": 30, "context": "For a detailed description, refer to [34].", "startOffset": 37, "endOffset": 41}, {"referenceID": 31, "context": "For categorical examples, the overlap similarity measure [35] is utilized.", "startOffset": 57, "endOffset": 61}, {"referenceID": 32, "context": "For comparison purposes, we evaluate the performance of the framework against different low level classifiers: Bayesian networks [36], Weighted k-nearest neighbors [37], Multi-layer perceptrons (MLP) [38], Multi-class SVM (M-SVM) [32], [39].", "startOffset": 164, "endOffset": 168}, {"referenceID": 33, "context": "For comparison purposes, we evaluate the performance of the framework against different low level classifiers: Bayesian networks [36], Weighted k-nearest neighbors [37], Multi-layer perceptrons (MLP) [38], Multi-class SVM (M-SVM) [32], [39].", "startOffset": 200, "endOffset": 204}, {"referenceID": 28, "context": "For comparison purposes, we evaluate the performance of the framework against different low level classifiers: Bayesian networks [36], Weighted k-nearest neighbors [37], Multi-layer perceptrons (MLP) [38], Multi-class SVM (M-SVM) [32], [39].", "startOffset": 230, "endOffset": 234}, {"referenceID": 34, "context": "For comparison purposes, we evaluate the performance of the framework against different low level classifiers: Bayesian networks [36], Weighted k-nearest neighbors [37], Multi-layer perceptrons (MLP) [38], Multi-class SVM (M-SVM) [32], [39].", "startOffset": 236, "endOffset": 240}, {"referenceID": 35, "context": "The data set in which we will conduct our studies hereon is named Modified NIST set [40].", "startOffset": 84, "endOffset": 88}, {"referenceID": 35, "context": "We use the same experimental setup given in [40]; \u2022 A k-nearest neighbor classifier with an Euclidean distance measure between input images (k = 3); \u2022 A k-nearest neighbor classifier with the similarity function given by a set of weighted eigenvalue measures [4].", "startOffset": 44, "endOffset": 48}, {"referenceID": 1, "context": "We use the same experimental setup given in [40]; \u2022 A k-nearest neighbor classifier with an Euclidean distance measure between input images (k = 3); \u2022 A k-nearest neighbor classifier with the similarity function given by a set of weighted eigenvalue measures [4].", "startOffset": 259, "endOffset": 262}], "year": 2013, "abstractText": "Complex networks refer to large-scale graphs with nontrivial connection patterns. The salient and interesting features that the complex network study offer in comparison to graph theory are the emphasis on the dynamical properties of the networks and the ability of inherently uncovering pattern formation of the vertices. In this paper, we present a hybrid data classification technique combining a low level and a high level classifier. The low level term can be equipped with any traditional classification techniques, which realize the classification task considering only physical features (e.g., geometrical or statistical features) of the input data. On the other hand, the high level term has the ability of detecting data patterns with semantic meanings. In this way, the classification is realized by means of the extraction of the underlying network\u2019s features constructed from the input data. As a result, the high level classification process measures the compliance of the test instances with the pattern formation of the training data. Out of various high level perspectives that can be utilized to capture semantic meaning, we utilize the dynamical features that are generated from a tourist walker in a networked environment. Specifically, a weighted combination of transient and cycle lengths generated by the tourist walk is employed for that end. Furthermore, we show that the proposed technique is able to capture the organizational and complex features of the class component from a local to global fashion in a natural and intuitive way by altering the memory size of the tourist walk. Still in this work, we uncover the existence of a critical memory length, we say complex saturation, where any values larger than this critical point make no change in the transient and cycle lengths of the network component. Interestingly, our study shows that the proposed technique is able to further improve the already optimized performance of traditional classification techniques. Finally, we apply the proposed technique to the recognition of handwritten digit images and promising results have been obtained.", "creator": "LaTeX with hyperref package"}}}