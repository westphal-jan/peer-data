{"id": "1305.2352", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2013", "title": "Speech Enhancement Using Pitch Detection Approach For Noisy Environment", "abstract": "Acoustical mismatch among training and testing phases degrades outstandingly speech recognition results. This problem has limited the development of real-world nonspecific applications, as testing conditions are highly variant or even unpredictable during the training process. Therefore the background noise has to be removed from the noisy speech signal to increase the signal intelligibility and to reduce the listener fatigue. Enhancement techniques applied, as pre-processing stages; to the systems remarkably improve recognition results. In this paper, a novel approach is used to enhance the perceived quality of the speech signal when the additive noise cannot be directly controlled. Instead of controlling the background noise, we propose to reinforce the speech signal so that it can be heard more clearly in noisy environments. The subjective evaluation shows that the proposed method improves perceptual quality of speech in various noisy environments. As in some cases speaking may be more convenient than typing, even for rapid typists: many mathematical symbols are missing from the keyboard but can be easily spoken and recognized. Therefore, the proposed system can be used in an application designed for mathematical symbol recognition (especially symbols not available on the keyboard) in schools.", "histories": [["v1", "Thu, 9 May 2013 08:39:11 GMT  (433kb)", "http://arxiv.org/abs/1305.2352v1", "Pages: 06 Figures : 05"]], "COMMENTS": "Pages: 06 Figures : 05", "reviews": [], "SUBJECTS": "cs.SD cs.CL", "authors": ["rashmi makhijani", "urmila shrawankar", "v m thakare"], "accepted": false, "id": "1305.2352"}, "pdf": {"name": "1305.2352.pdf", "metadata": {"source": "CRF", "title": "SPEECH ENHANCEMENT USING PITCH DETECTION APPROACH FOR NOISY ENVIRONMENT", "authors": ["RASHMI MAKHIJANI", "URMILA SHRAWANKAR"], "emails": ["rashmi.makhijani2002@gmail.com", "urmila@ieee.org"], "sections": [{"heading": null, "text": "Keywords: pitch; cepstrum analysis; speech recognition;"}, {"heading": "1. Introduction", "text": "The quality of perception of language, defined as the general quality of perception measured in terms of intelligibility, clarity and naturalness, is seriously affected by ambient noise. Many methods for improving the quality of perception of speech in a noisy environment have been proposed and are used. Each method proposes improving perception-related speech characteristics such as signal-to-noise ratio (SNR), volume and high-bandwidth components [1] - [4]. This paper proposes a new method for solving the problem of unpredictable performance of conventional methods. The proposed method is used to detect mathematical symbols in a school environment [5]. ISSN: 0975-5462 Vol. 3 No. 2 Feb 2011 1764"}, {"heading": "2. Methodology", "text": "Speech recognition, in its most general form, is a transformation from an acoustic waveform into a written equivalent of message information. To process the speech signal digitally, it is necessary to make the analog waveform discrete in both time (sample) and amplitude (quantization). The speech recognition process consists of various steps such as speech capture, speech preprocessing, feature extraction, training and recognition. The main focus in this paper is on the second step, i.e. speech preprocessing. During the first step, i.e. speech capture, speech samples are collected from the speaker in real time and stored in memory for pre-processing. Pre-processing is a critical process carried out on speech input in order to develop a robust and efficient system [6]. It is mainly performed in some steps such as A / D conversion, the endpoint being pre-speech and speech improvement."}, {"heading": "3. Pitch Detection via Cepstral Method", "text": "Subsequently, the linkage of the logbook function with the logbook A + log B is converted into an additive relationship. In the real linkage of a signal (1), the linkage with the cephalome becomes a multiplication relationship. In other words, the cephalome is a Fourier analysis of the logbook function A + log B, and the logbook spectrum can be converted into an additive relationship. In the real linkage with a signal (1), the cephalome becomes a Fourier analysis of the logarithm spectrum."}, {"heading": "4. Voice features extraction", "text": "The voice function MFCC is one of the most widely used and popular methods of voice extraction. Function extraction converts the digital voice signal into sets of numerical descriptors, known as feature vectors, containing key features of the voice signal. Assessing the various types of features extracted from the voice to determine their suitability for recognition is the third step for this paper. Current most popular and well-known features used are the Linear Prediction Coefficients (LPC), Linear Prediction CepstralISSN: 0975-5462 Vol. 2 Feb 2011 1766 Coefficients (LFCC) and frequencies used to perform the Cepstral coefficients (MFCC). Thus, in this paper the MFCC is used for accurate functional extraction.4.1. Mel frequency coefficients Cepstraqul coefficients (MFCC) are the coefficient (MFCC)."}, {"heading": "5. Speaker Modeling", "text": "The next step after trait extraction is to create pattern models for the quantification of traits. In training or recognition mode, language models are created using the specific language features extracted from the current language samples. In recognition mode, the language model is used for comparison with the current samples for identification or verification purposes. There are three main types of modeling techniques available, namely: template matching, stochastic modeling, neural networks. Various concepts have been introduced as part of these techniques, such as pattern matching (dynamic time warping), which performs direct template matching between trainee and tester. However, direct template matching is time-consuming when the number of trait vectors increases. Clustering is a method of reducing the number of trait vectors by using a codebook to quantify (quantify) the centers of trait vectors."}], "references": [{"title": "Near end listening enhancement: Speech intelligibility improvement in noisy environments", "author": ["B. Sauert", "P. Vary"], "venue": "in Proc. ICASSP,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Perceptual reinforcement of speech signal based on partial specific loudness,", "author": ["J. Shin", "N. Kim"], "venue": "IEEE Signal Process.Lett, vol. 14,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Speech intelligibility enhancement using tunable equalization filter", "author": ["P. Shankar", "S. Park"], "venue": "Proc. ICASSP, 2007, pp. 613\u2013616.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "On Preprocessing of Speech Signals", "author": ["Ayaz Keerio", "Bhargav Kumar Mitra", "Philip Birch", "Rupert Young", "Chris Chatwin"], "venue": "International Journal of Signal Processing", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "An overview of modeling technology of speech recognition", "author": ["Zhonghua", "Fu", "Zhao Rongchun"], "venue": ". Neural Networks and Signal Processing, 2003. Proceedings of the 2003 International Conference on , vol.2, no., pp. 887-891 Vol.2, 14-17 Dec. 2003.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Effect of temporal envelope smearing on speech reception", "author": ["R. Drullman", "J. Festen", "R. Plomp"], "venue": "J. Acoust. Soc. Amer., vol. 95, no. 2, pp. 1053\u20131064, Feb. 1994.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1994}, {"title": "Thakare,\u201cFeature Extraction for a speech recognition system in a noisy environment:a study", "author": ["Urmila Shrawankar", "Dr. V.M"], "venue": "ICCEA 2010,Indonesia,March", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Speaker Identification using Mel Frequency cepstral coefficients", "author": ["Md. Rashidul Hasan", "Mustafa Jamil", "Md. Golam Rabbani", "Md. Saifur Rahman"], "venue": "3rd International Conference on Electrical & Computer Engineering ICECE 2004,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "An algorithm for robust signal modelling in speech recognition", "author": ["R. Vergin"], "venue": ". Acoustics, Speech and Signal Processing, 1998. Proceedings of the 1998 IEEE International Conference on , vol.2, no., pp.969-972 vol.2, 12-15 May 1998.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1998}, {"title": "Generalized mel frequency cepstral coefficients for large-vocabulary speakerindependent continuous-speech recognition", "author": ["R. Vergin", "D. O'Shaughnessy", "A. Farhat"], "venue": ". Speech and Audio Processing, IEEE Transactions on , vol.7, no.5, pp.525-532, Sep 1999.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "Text independent speaker recognition using the Mel frequency cepstral coefficients and a neural network classifier", "author": ["H. Seddik", "A. Rahmouni", "M. Sayadi"], "venue": "Communications and Signal Processing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2004}, {"title": "Computing Mel-frequency cepstral coefficients on the power spectrum", "author": ["S Molau"], "venue": ". Acoustics, Speech, and Signal Processing, 2001. Proceedings. (ICASSP '01). 2001 IEEE International Conference on , vol.1, no., pp.73-76 vol.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Experimental evaluation of features for robust speaker identification", "author": ["D.A. Reynolds"], "venue": ". Speech and Audio Processing, IEEE Transactions on , vol.2, no.4, pp.639-643, Oct 1994.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1994}, {"title": "Suving: Automaticsilence/unvoiced/voiced classification of speech,", "author": ["Kinghorn", "A.M. Greenwood"], "venue": "Departmentof Computer Science, The University ofSheffield,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}], "referenceMentions": [{"referenceID": 0, "context": "Each method suggests the enhancement of perception-related speech features such as signal-to-noise ratio (SNR), loudness, and highband components [1]\u2013[4].", "startOffset": 146, "endOffset": 149}, {"referenceID": 3, "context": "Each method suggests the enhancement of perception-related speech features such as signal-to-noise ratio (SNR), loudness, and highband components [1]\u2013[4].", "startOffset": 150, "endOffset": 153}, {"referenceID": 4, "context": "Pre-processing is a critical process performed on speech input in order to develop a robust and efficient system [6].", "startOffset": 113, "endOffset": 116}, {"referenceID": 5, "context": "After pre-emphasis stage, speech enhancement techniques [7] are used based on Pitch detection .", "startOffset": 56, "endOffset": 59}, {"referenceID": 6, "context": "Coefficients (LPCC) & Mel-Frequency Cepstral Coefficients (MFCC)[8].", "startOffset": 64, "endOffset": 67}, {"referenceID": 7, "context": "The difference between the MFC and cepstral analysis is that the MFC maps frequency components using a Mel scale modeled based on the human ear perception of sound instead of a linear scale [9].", "startOffset": 190, "endOffset": 193}, {"referenceID": 8, "context": "Vergin [10] mentioned that MFCC as frequency domain parameters are much more consistent and accurate than time domain features.", "startOffset": 7, "endOffset": 11}, {"referenceID": 8, "context": "Vergin [10] listed the steps leading to extraction of MFCCs: Fast Fourier Transform, filtering and cosine transform of the log energy vector.", "startOffset": 7, "endOffset": 11}, {"referenceID": 9, "context": "According to Vergin [11], MFCCs can be obtained by the mapping of an acoustic frequency to a perceptual frequency scale called the Mel scale.", "startOffset": 20, "endOffset": 24}, {"referenceID": 10, "context": "Seddik [12] mentioned that MFCC are computed by applying discrete cosine transform to the log of the Mel-filter bank.", "startOffset": 7, "endOffset": 11}, {"referenceID": 11, "context": "The main advantage of MFCC is the robustness towards noise and spectral estimation errors under various conditions [13].", "startOffset": 115, "endOffset": 119}, {"referenceID": 12, "context": "Reynolds did a study on the comparison of different features and found that the MFCC provides better performance than other features [14].", "startOffset": 133, "endOffset": 137}, {"referenceID": 13, "context": "The LBG (Linde, Buzo and Gray) algorithm [15] and the k-means algorithm are some of the most well known algorithms for Vector Quantization (VQ).", "startOffset": 41, "endOffset": 45}], "year": 2011, "abstractText": "Acoustical mismatch among training and testing phases degrades outstandingly speech recognition results. This problem has limited the development of real-world nonspecific applications, as testing conditions are highly variant or even unpredictable during the training process. Therefore the background noise has to be removed from the noisy speech signal to increase the signal intelligibility and to reduce the listener fatigue. Enhancement techniques applied, as pre-processing stages; to the systems remarkably improve recognition results. In this paper, a novel approach is used to enhance the perceived quality of the speech signal when the additive noise cannot be directly controlled. Instead of controlling the background noise, we propose to reinforce the speech signal so that it can be heard more clearly in noisy environments.The subjective evaluation shows that the proposed method improves perceptual quality of speech in various noisy environments. As in some cases speaking may be more convenient than typing, even for rapid typists: many mathematical symbols are missing from the keyboard but can be easily spoken and recognized. Therefore, the proposed system can be used in an application designed for mathematical symbol recognition (especially symbols not available on the keyboard) in schools.", "creator": "PScript5.dll Version 5.2.2"}}}