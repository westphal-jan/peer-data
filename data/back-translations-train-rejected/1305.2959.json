{"id": "1305.2959", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2013", "title": "Automatic Speech Recognition Using Template Model for Man-Machine Interface", "abstract": "Speech is a natural form of communication for human beings, and computers with the ability to understand speech and speak with a human voice are expected to contribute to the development of more natural man-machine interfaces. Computers with this kind of ability are gradually becoming a reality, through the evolution of speech recognition technologies. Speech is being an important mode of interaction with computers. In this paper Feature extraction is implemented using well-known Mel-Frequency Cepstral Coefficients (MFCC).Pattern matching is done using Dynamic time warping (DTW) algorithm.", "histories": [["v1", "Thu, 9 May 2013 08:47:47 GMT  (62kb)", "http://arxiv.org/abs/1305.2959v1", "Pages: 05 Figures : 01 Tables : 03 Proceedings of the International Conference ICAET 2010, Chennai, India. arXiv admin note: text overlap witharXiv:1305.2847"]], "COMMENTS": "Pages: 05 Figures : 01 Tables : 03 Proceedings of the International Conference ICAET 2010, Chennai, India. arXiv admin note: text overlap witharXiv:1305.2847", "reviews": [], "SUBJECTS": "cs.SD cs.CL", "authors": ["neema mishra", "urmila shrawankar", "v m thakare"], "accepted": false, "id": "1305.2959"}, "pdf": {"name": "1305.2959.pdf", "metadata": {"source": "CRF", "title": "Automatic Speech Recognition Using Template Model for Man-Machine Interface", "authors": ["Neema Mishra", "Urmila Shrawankar"], "emails": ["neema.mishra@gmail.com", "urmila@ieee.org"], "sections": [{"heading": "1. Introduction", "text": "We need more and more people to get things done. A convenient and user-friendly user interface for human interaction is an important technological problem. The predominant computer interface is via keyboard or pointing device for input and a visual display unit or printer for output. Spoken languages dominate communication between people and therefore people expect a language interface with the computer. Automatic speech recognition (ASR) can be divided into two categories."}, {"heading": "2. Feature Extraction", "text": "The usual step in functional extraction is frequency or spectral analysis. Signal processing techniques aim to extract features related to the identification of characteristics [10]. The aim of functional extraction is to find a number of properties of an expression that have acoustic correlations in the speech spectrum, i.e. parameters that some can estimate such as the processing of signal waves. Such parameters are referred to as features [11]. Several distinct features of the extraction algorithm exist, namely: \u2022 Linear Predictive Cepstral Coefficients (LPCC) \u2022 Perceptual Linear Prediction (PLP) Cepstra frequency Cepstral Coefficients (MFCC) LPCC calculates spectra Spectract Spectract Spectract Spectract Spectract Spectract Spectraction prior to conversion into Cepstral coefficients. The LPCC derivative Ceptrace-critical frequencies are critical areas of the LPCP."}, {"heading": "3. Pattern Recognition", "text": "Dynamic time distortion is a technique for determining the optimal nonlinear distortion of test patterns in order to achieve a good match with a reference pattern (model) with an appropriate computational load. DTW is an algorithm for measuring the similarity between two sequences that are very time- or speed-dependent.DTW is a method that allows a computer to find an optimal match between two predefined sequences with a certain limitation. In speech recognition technology, the test data is converted into templates. The recognition process then consists of the match of the incoming speech pattern with stored templates. The template with the lowest distance measurement from the input pattern is the recognized word. The optimal match (lowest distance measurement) is based on dynamic programming. This is called dynamic time distortion (DTW) [1]. Read D (j), the cumulative distance from the word to the optimal path."}, {"heading": "4.2 Experiment Details", "text": "We conducted three different experiments that looked at different aspects of the speech recognition system for better accuracy and practical implementation. To match the test template with the reference template of the same speaker, we recorded voices from speakers, converted them into sequence vectors of the Mel receiver coefficient, and stored them as reference templates in a binary file. To match the saved reference template with the test template, we used the DTW algorithm. Experiment 1: Matching test and reference template of the same speaker. In this experiment, 10 words are used as reference template and then 3 repetitions of the words as test template. The 30 (3 * 10) template were matched with the DTW algorithm implemented in the Matte Laboratory. Accuracy for other speakers in a similar manner was:"}, {"heading": "SPEAKER ACCURACY", "text": "Experiment 2: Matching reference template of one speaker with test template of another speaker. In this experiment, the first repetition of 10 names of one speaker was used as reference template and all templates of all other speakers were matched with them as test template. Thus, for example, using the third speaker as reference speaker and the second speaker as test, 35 out of 40 templates were matched. Therefore, the accuracy is calculated as 35 / 40 * 100 = 87.5%. These are different speakers, the accuracy decreased as expected. In case of gender discrepancy, the accuracy decreased further (speaker 1 is female, while the rest is male.) All possible combinations were tested and the few results are tabulated as follows:"}, {"heading": "REFERNCE TEST ACCURACY", "text": "The average accuracy when comparing test and reference templates of different loudspeakers was 70.6%."}, {"heading": "5. CONCLUSION AND FUTURE DIRECTION", "text": "Automatic recognition of machine language has been a research goal for more than five decades [15]. This work proposed an approach to implementing an ASR with MFCC feature extraction and pattern matching DTW, which matches test and reference template for the same speaker to an accuracy of 97.5%. In the other experiment to maintain the matching reference template of a speaker with the test template of another speaker, the accuracy is 70.6%. Until now, we have used rectangular windows because they are easy to understand. One could use pounding windows to increase the accuracy rate. Scope for future work would focus on incorporating features ranging from limited database size to large, depending on the speaker to the speaker independently. In addition, we can (HIDDEN MARKOV MODEL) use HMM to find the most likely word from the database if no corresponding template is stored in the database."}, {"heading": "6. REFERNCES", "text": "[1] Holmes, J.N. (1988).Speech Synthesis And Recognition, Van Nostrand Reinfold (UK) Co, Ltd, pp. 102-113. [2] Bimbot et al., \"A Tutorial on Text-Independent Speaker Verification,\" Eurasip J.Appl. Speech Proc.4 (2004). [3] D.Reynolds et al., \"Speaker Verification using adapted GMM,\" Digital Signal Processing, 10 (1- 3), 2000. [4] F.K.Soong et al., \"A vector quantization approach to speaker recognition,\" AT & T Tech.J., Vol 66 (1987). [5] A.Das & P.Ghosh, \"Audio-Video Biometric Recognition by Vector Quantization,\" Proc.IEEE SLT-06. [6] T.Kinnunen, E.Karpov, and P.Franti, \"Realtime Speaker Identification and Identification.\""}, {"heading": "Verification\u201d,IEEE Trans.On Audio, Speech and", "text": "Language Processing, V14-1, Jan. 2006. [7] T.Matsui and S.Furui, \"Concatenated phoneme models for text-variable speaker recognition,\" Proc.ICASSP-93. [8] D.Falavigna, \"Comparison of Different HMM Based Methods for Speaker Verification,\" Proc.Eurospeech-95. [9] Higgins et al., \"Speaker Verification using randomized phrase prompting,\" Digital Signal Processing, 1 (2): (1991). [10] Sandipan Chakroborthy and Goutam Saha, \"Improved Text-Independent Speaker Identification Using Fused MFCC & IMFCC Feature Sets Based on Gaussian Filter,\" International Journal of Signal Processing, Vol.5, no.1, Vnanoborthy and Goutam Saha, \"Improved Text-Independent Speaker Identification using Fused MFCC & IMFCC Feature Sets Based on Gaussian Filter,\" Improved Text-Independent Speaker Identification Based on Gaussian Filter, \"Vnanech, Vnanoborthy and Goutam Saha,\" Vnanoborthy and Goutam Saha, \"Improved Text-Independent Speaker Identification using Fused MFCC & IMFCC Feature Sets Based on Gaussian Filter,\" International Journal of Signal Processing, Vnanovch, VNV, V.8, \"Indian Signal,\" VgnioFace, \"VII,\" Indian Signal Processing."}], "references": [{"title": "Synthesis And Recognition, Van Nostrand Reinfold (UK) Co, Ltd, pp.102-113", "author": ["J.N. Holmes"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1988}, {"title": "A Tutorial on Text-Independent Speaker Verification", "author": ["Bimbot"], "venue": "Eurasip J.Appl. Speech", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "A vector quantization approach to speaker recognition", "author": ["F.K.Soong"], "venue": "AT&T Tech.J.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1987}, {"title": "Speaker Verification using randomized phrase prompting", "author": ["Higgins"], "venue": "Digital Signal Processing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1991}, {"title": "Improved Text-Independent Speaker Identification Using Fused MFCC & IMFCC Feature Sets Based on Gaussian Filter", "author": ["Sandipan Chakroborthy", "Goutam Saha"], "venue": "International Journal of Signal Processing, vol.5, no.1, pp.11-19, 2009.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Implementing a Speech Recognition System Interface for Indian Languages", "author": ["R.K. Aggarwal", "Mayank Dave"], "venue": "IJCNLP-08 Workshop on NLP for Less Privileged, IIIT, Hyderabad,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Fundamental of Speech Recognition,\u201dPTRPrentice", "author": ["L.Rabiner", "B.H. Juang"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1993}, {"title": "Combining Evidence from Residual Phase and MFCC features for Speaker Recognition", "author": ["Murty", "Yegna"], "venue": "IEEE Signal Processing Letters,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Dynamic Programming Algorithms Optimization for Spoken Word Recognition\u201d,IEEE Trans on acoustic, speech and signal processing,vol.ASSP", "author": ["Hiroaki Sakoe", "Seibi Chiba"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1978}], "referenceMentions": [{"referenceID": 0, "context": "Spoken languages dominate communication among human being and hence people expect speech interface with computers [1].", "startOffset": 114, "endOffset": 117}, {"referenceID": 1, "context": "Text-independent methods [2-6] assume that passwords users are uttering can be anything.", "startOffset": 25, "endOffset": 30}, {"referenceID": 2, "context": "Text-independent methods [2-6] assume that passwords users are uttering can be anything.", "startOffset": 25, "endOffset": 30}, {"referenceID": 3, "context": "Text-dependant speaker recognition methods [7-9] exploits the feature dynamic to capture the identity of the speaker\u2019s methods compare the features vectors sequence of the test utterance with the \u201cfeature-dynamicsmodel\u201d of all the speakers.", "startOffset": 43, "endOffset": 48}, {"referenceID": 4, "context": "The signal processing techniques aim to extract features that are related to identify the characteristics [10].", "startOffset": 106, "endOffset": 110}, {"referenceID": 5, "context": "Such parameters are termed as features [11].", "startOffset": 39, "endOffset": 43}, {"referenceID": 6, "context": "In speech recognition, tasks 12 coefficients are retained which represent the slow variation of the spectrum of the signal, which characterizes the vocal tract shape of the uttered words [12].", "startOffset": 187, "endOffset": 191}, {"referenceID": 7, "context": "speech recognition and for the speaker recognition task as well [13].", "startOffset": 64, "endOffset": 68}, {"referenceID": 8, "context": "Pattern Recognition The dynamic time warping is a technique of finding optimal non-linear warping of test patterns so as to obtained good match with a reference pattern(model) with a reasonable computational load [14].", "startOffset": 213, "endOffset": 217}, {"referenceID": 0, "context": "This is called a Dynamic Time Warping (DTW) [1].", "startOffset": 44, "endOffset": 47}, {"referenceID": 0, "context": "[1] Holmes, J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Bimbot et al, \u201cA Tutorial on Text-Independent Speaker Verification\u201d, Eurasip J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4] F.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[9] Higgins et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[10] Sandipan Chakroborthy and Goutam Saha, \u201cImproved Text-Independent Speaker Identification Using Fused MFCC & IMFCC Feature Sets Based on Gaussian Filter,\u201d International Journal of Signal Processing, vol.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[11] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[12] L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[13] Murty & Yegna, \u201cCombining Evidence from Residual Phase and MFCC features for Speaker Recognition, IEEE Signal Processing Letters, V13-1, (2006).", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[14] Hiroaki Sakoe and Seibi Chiba, \u201cDynamic Programming Algorithms Optimization for Spoken Word Recognition\u201d,IEEE Trans on acoustic, speech and signal processing,vol.", "startOffset": 0, "endOffset": 4}], "year": 2013, "abstractText": "Speech is a natural form of communication for human beings, and computers with the ability to understand speech and speak with a human voice are expected to contribute to the development of more natural man-machine interfaces. Computers with this kind of ability are gradually becoming a reality, through the evolution of speech recognition technologies. Speech being an important mode of interaction with computers. In this paper Feature extraction is implemented using well-known Mel-Frequency Cepstral Coefficients (MFCC).Pattern matching is done using Dynamic time warping (DTW) algorithm.", "creator": "PScript5.dll Version 5.2"}}}