{"id": "1305.3981", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2013", "title": "Binary Tree based Chinese Word Segmentation", "abstract": "Chinese word segmentation is a fundamental task for Chinese language processing. The granularity mismatch problem is the main cause of the errors. This paper showed that the binary tree representation can store outputs with different granularity. A binary tree based framework is also designed to overcome the granularity mismatch problem. There are two steps in this framework, namely tree building and tree pruning. The tree pruning step is specially designed to focus on the granularity problem. Previous work for Chinese word segmentation such as the sequence tagging can be easily employed in this framework. This framework can also provide quantitative error analysis methods. The experiments showed that after using a more sophisticated tree pruning function for a state-of-the-art conditional random field based baseline, the error reduction can be up to 20%.", "histories": [["v1", "Fri, 17 May 2013 05:14:43 GMT  (894kb)", "http://arxiv.org/abs/1305.3981v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kaixu zhang", "can wang", "maosong sun"], "accepted": false, "id": "1305.3981"}, "pdf": {"name": "1305.3981.pdf", "metadata": {"source": "CRF", "title": "Binary Tree based Chinese Word Segmentation", "authors": [], "emails": ["sunmaosong@gmail.com"], "sections": [{"heading": null, "text": "The answer to this question is: \"What is the answer to this question?\" \"What is the answer to this question?\" \"What is the answer to this question?\" \"What is the answer to this question?\" \"What is the answer to this question?\" \"What is the answer to this question?\" \"What is the answer to this question?\" \"What is the answer to this question?\" \"What is the answer to this question?\" \"\" What is the answer to this question? \"\" The answer to this question \"The answer to\" What is the answer to this question? \"The answer to\" What is the answer to \"What is the answer to\" What is the answer to this question? \"The answer to this question\" The answer to \"The answer to this question\" The answer to \"The answer to this question\" The answer to the answer to the question \"The answer to the answer to the question\" The answer to the answer to the question \"The answer to the answer to the question\" The answer to the answer to the question \"The answer to the answer to the question\" The answer to this question \"The answer to the answer to the question\" The answer to the answer to the question \"The answer to the answer to the question\" The answer to this question \"The answer to the answer to the question\" The answer to this question \"The answer to the answer to the answer to the question\" The answer to the answer to the question \"The answer to the answer to this question\" The answer to the answer to the question \"The answer to the answer to this question\" The answer to the answer to this question is the answer to the answer to the answer to the question is the answer to the answer to the answer to the question \"the answer to the answer to the question\" the answer to this question is the answer to the answer to the answer to the answer to the question \"the answer to the answer to this question is the answer to the answer to the answer to the answer to the answer to the question."}, {"heading": "1 Related Work", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "2 Method", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Tree Building", "text": "The first step of our framework is to build a binary tree for an input set 1. The process can simply be based on a single function (), which gives certainty that there is a word boundary between and c + 1. The function () could be derived from various previous work. In the case of a PMI-based method, which is an association method, we can define the function PMI () as follows: PMI () = Log (+ 1) () (+ 1) In the CRF-based method, we define this function CRF () as the marginal probability that: CRF () = () = S = E | The algorithm for building the binary tree based on this function is described as the pseudo-codiology."}, {"heading": "2.2 Tree Pruning", "text": "The second step is to prune the binary tree, which focuses on granularity. The leaves of the pruned tree form the segmentation output. The example of a pruned binary tree is shown in Fig.\\ ref {fig: pruned tree}. The pruning can also be applied by a single function (,,,, + 1...), where and + 1... are the roots of two sub-trees of the node tree. The function of the binary function can be based on a threshold and the same () function of the tree:,,,,,,,,,,,,,,"}, {"heading": "2.3 A Granularity Based Explanation", "text": "For previous work like the CRF-based methods without the binary tree-based frame, the output words can be determined directly by the function () and a threshold value: The -words of an input sentence 1... are arbitrary substrings like..., so that there is a word boundary between (1), () > max (), (\u2212 1) definition: The inequalities in this definition mean that there is a word boundary between and + 1 if and only if () () >. Note that different results can be obtained with different thresholds. \u2212 The larger the threshold, the coarser the segmentation result is, which means that there is a smaller number of words in the output (the threshold can be considered a parameter to control output granularity)."}, {"heading": "3 Binary Tree Based Error Analysis", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want."}, {"heading": "4 An SVM-based Tree Pruning Function", "text": "In fact, it is a very good idea that is able to establish itself and establish itself in the region."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Datasets and the Baseline", "text": "We use these four corpora of the SIGHAN bake-off 2005 ~\\ cite {emerson _ second _ 2005} for our evaluation. They are free of charge and are widely used by most previous work for the evaluation. The metrics used for the evaluation are the accuracy, the = (# of the words in the output) (# of the words in the output) (the recall that = (# of the words in the gold standard) (# of the words in the gold standard) (and the F _ measure = 2 / (+)). In addition, the OOV rate for the analysis is calculated. We use a state-of-the-art CRF-based method as the starting point and define the tree-building function (). The error analysis is also based on this. The CRF-based model is trained with the Pocket CRF 3 toolkit. The feature templates used for the character are:"}, {"heading": "5.2 Binary Tree Based Error Analysis", "text": "The errors are divided not only into IV errors and OOV errors, but also into the binary trees as we discussed in the previous paragraph.The results are in the\\ ref {tab: error _ types} table. We can also see that there are more IV words for the overlapping errors, while there are OOV words for the less truncated errors. This is due to the phenomenon that most of the OOV words consist of IV words, but not vice versa."}, {"heading": "5.3 SVM-based Tree Pruning", "text": "In order to compare the previous work based on the same training sets in SIGHAN bake-off 2005 and avoid the use of other resources, we have divided the original training set into two parts. Nine-tenths of these are used as a training set $\\ mathcal {S} _ textup {b} $to train the CRF model for tree pruning, while the remainder is used as a training set $\\ mathcal {S} _ textup {p} $to train the SVM model for tree pruning. We use LibSVM 4 for training and testing for the SVM model, and all use default4 http: / www.csie.ntu.edu.edu.tw / ~ cjlin / libsvm / parameters. Features are described in Section\\ ref {Section: SVM}. The results can be found in Table\\ ref {tab: svm}. The first and second rows show the F-ring rate of the original training measures, each with a base rate of 90% svM, to lower the base rate of the SVM method."}, {"heading": "6 Conclusions", "text": "We proposed a binary tree representation for the structures of the unclear part between Chinese morphology and syntax. We also proposed a simple two-step tree representation for CWS, namely tree formation and pruning. Previous models for CWS can be used within this framework. Binary tree representation provides a quantitative error analysis method for CWS, which allows us to see that the granularity problem is the main cause of the errors for CWS and Cross-Corpus CWS. We also illustrated with an SVM-based tree pruning model for step 2, reducing the error rate up to 20\\% from a state-of-the-art CRF-based baseline. The definition of the Chinese word is not clear even for linguists\\ cite {xue _ defining _ 2001}. The inconsistencies of the segment standard between different corpora, such as the inconsistency between MSR and PKU Corpus, also have a granularity."}], "references": [{"title": "The second international Chinese word segmentation bakeoff", "author": ["T Emerson"], "venue": "Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing. Jeju Island,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Chinese word segmentation and named entity recognition: A pragmatic approach", "author": ["Gao Jianfeng", "Li Mu", "Huang Chang-Ning", "Wu Andi"], "venue": "Computational Linguistics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Word lattice reranking for Chinese word segmentation and Part-of-Speech tagging", "author": ["Jiang Wenbin", "Mi Haitao", "Liu Qun"], "venue": "Proceedings of the 22 International Conference on Computational Linguistics Volume 1. Association for Computational Linguistics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "An Error-Driven  Word-Character hybrid model for joint Chinese word segmentation and POS tagging", "author": ["C Kruengkrai", "K Uchimoto", "J Kazama", "Yiou Wang", "K Torisawa", "Hitoshi Isahara"], "venue": "Proc. of ACL-IJCNLP", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Punctuation as implicit annotations for Chinese word segmentation", "author": ["Li Zhongguo", "Sun Maosong"], "venue": "Computational Linguistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Information retrieval oriented word segmentation based on character associative strength ranking", "author": ["Y Liu", "B Wang", "F Ding", "S Xu"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Chinese segmentation and new word detection using conditional random fields", "author": ["Peng Fuchun", "Feng Fangfang", "McCallum A"], "venue": "Proceedings of the 20th international conference on Computational Linguistics. Association for Computational Linguistics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Chinese word segmentation without using lexicon and hand-crafted training data, In: Proceedings of the 17th international conference on Computational linguistics-Volume", "author": ["Sun Maosong", "Shen Dayang", "Tsou Benjamin K"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Defining and automatically identifying words in Chinese: Ph.D", "author": ["Xue Nianwen"], "venue": "Dissertation, University of Delaware,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "Chinese word segmentation as character tagging", "author": ["Xue Nianwen"], "venue": "Computational Linguistics and Chinese Language Processing,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Character-Level dependencies in Chinese: Usefulness and learning, In: Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics", "author": ["Zhao Hai"], "venue": "Association for Computational Linguistics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}], "referenceMentions": [{"referenceID": 4, "context": "Without such problem, the performance is claimed to be increased by Li and Sun [5] .", "startOffset": 79, "endOffset": 82}], "year": 2011, "abstractText": "Chinese word segmentation is a fundamental task for Chinese language processing. The granularity mismatch problem is the main cause of the errors. This paper showed that the binary tree representation can store outputs with different granularity. A binary tree based framework is also designed to overcome the granularity mismatch problem. There are two steps in this framework, namely tree building and tree pruning. The tree pruning step is specially designed to focus on the granularity problem. Previous work for Chinese word segmentation such as the sequence tagging can be easily employed in this framework. This framework can also provide quantitative error analysis methods. The experiments showed that after using a more sophisticated tree pruning function for a state-of-the-art conditional random field based baseline, the error reduction can be up to 20%.", "creator": "Microsoft\u00ae Word 2010"}}}