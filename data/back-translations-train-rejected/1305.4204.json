{"id": "1305.4204", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2013", "title": "Machine learning on images using a string-distance", "abstract": "We present a new method for image feature-extraction which is based on representing an image by a finite-dimensional vector of distances that measure how different the image is from a set of image prototypes. We use the recently introduced Universal Image Distance (UID) \\cite{RatsabyChesterIEEE2012} to compare the similarity between an image and a prototype image. The advantage in using the UID is the fact that no domain knowledge nor any image analysis need to be done. Each image is represented by a finite dimensional feature vector whose components are the UID values between the image and a finite set of image prototypes from each of the feature categories. The method is automatic since once the user selects the prototype images, the feature vectors are automatically calculated without the need to do any image analysis. The prototype images can be of different size, in particular, different than the image size. Based on a collection of such cases any supervised or unsupervised learning algorithm can be used to train and produce an image classifier or image cluster analysis. In this paper we present the image feature-extraction method and use it on several supervised and unsupervised learning experiments for satellite image data.", "histories": [["v1", "Fri, 17 May 2013 22:40:14 GMT  (7360kb,D)", "http://arxiv.org/abs/1305.4204v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["uzi chester", "joel ratsaby"], "accepted": false, "id": "1305.4204"}, "pdf": {"name": "1305.4204.pdf", "metadata": {"source": "CRF", "title": "Machine learning on images using a string-distance", "authors": ["Uzi Chester", "Joel Ratsaby"], "emails": ["uzichester@gmail.com,", "ratsaby@ariel.ac.il,"], "sections": [{"heading": "1 Introduction", "text": "In fact, the fact is that most of them will be able to move to a different world in which they are able than in another world in which they are able to live and live, in which they are able, and in which they are able to change the world."}, {"heading": "2 LZ-complexity and string distances", "text": "The UID distance function [1] is based on the LZ complexity of a string (hi = j components). The definition of this complexity results from [5]: let S, Q, and R are strings of characters defined by the alphabet A. (S) The definition of this complexity follows (5): let S, Q, and R are strings of S that consist of characters of S between position i and j. An extension R = SQ of S is reproducible by S (referred to as S \u2192 R) if there is an integer p \u2264 l (S), so that Q (k) = R (p + k \u2212 1) for characters of S between position i and j., l (S) is reproducible by S (referred to as S \u2192 R) if there is an integer p \u2264 l (S)."}, {"heading": "3 Universal Image Distance", "text": "The idea is to convert each of the two images I and J into strings X (I) and X (J) of characters from a finite alphabet of symbols. Once in string format, we use d * (X (I), X (J))) as the spacing between I and J. The details of this process are described in the following algorithm 1. Algorithm 1 UID measures the spacing 1. Input: two color images I, J in JPEG format (RGB representation) 2. Transform the RGB matrices into grayscale by forming a weighted sum of R, G and B components according to the following formula: Grayscale V-Alue: = 0.2989R + 0.5870G + 0.1140B, (used in Matlab \u00a9). Each pixel is now a single numerical value in the range 0 to 255. We refer to this set of values as the alphabet and call it J from J."}, {"heading": "4 Prototype selection", "text": "In this section we describe the algorithm for selecting image prototypes from each of the attribute categories. This process runs only once before the stage of converting the images into finite dimensional vectors, that is, it does not run once per image, but once for all the images. For an image we get from P-I a sub-image P of I, in which P can be any rectangular image, by putting a window over the image that I select completely from I.Algorithm 2 prototypes 1. Input: M-image denotes categories, and a corpus CN of N, in which there can be unlabeled colored images {Ij} Nj = 1.2. for (i: = 1 to M) do (a) Based on each of the images Ij in CN, let the user select Li prototype images (i). Li k = 1 and set them as attribute category i."}, {"heading": "5 Image feature-representation", "text": "In the previous section, we described algorithm 2, which manually selects the prototypes, and this algorithm is now used to create a function vector representation of an image. It is described below as algorithm 3 (in [1] we have used a similar algorithm UIC to softly classify an image, while here we are using it to create only a function vector representation of an image, which later serves as a single case for the formation of any supervised learning algorithm or a single unlabeled case. Algorithm 3 function vector generation 1. Input: an image that I represent on the following attribute categories 1 \u2264 i \u2264 M and with a set of PL: = {P (i) k} Li k = 1} M i = 1 labeled prototype images (obtainedvon algorithm 2). 2. Initialize the number of variables ci: 0, 1 \u2264 i \u2264 M 3. Let a Sub angle of type W equal to the size I."}, {"heading": "6 Supervised and unsupervised learning on images", "text": "Given a corpus of C images and a set of PL labeled prototypes, we use algorithm 3 to generate the feature vectors v (I) that correspond to each image I in C. At this point, we have a database D of the size | C | that consists of feature vectors of all images in C. This database can be used, for example, for unattended learning to discover interesting image clusters. It can also be used for supervised learning, provided that each of the cases can be labeled according to a value of a variable of the target class, which may generally differ from the feature categories. By using T, let us designate the class target variable and the database DT, which consists of feature vectors of D with the corresponding target class values. The following algorithm 4 Image Classification Learn 1. Input: (1) a target class variable T that contains values in a finite group of class categories, (2) a database DT based on M-dimensional characteristics."}, {"heading": "7 Experimental setup and results", "text": "We created a corpus C of 60 images of the size 670 x 1364 pixels from GoogleEarth \u00a9 of different types of areas (Figure 2 shows a few scaled-down examples of such images).From these images, we let a user define four characteristics: sea, city, dry roads and select three relatively small image prototypes of the size 45 x 17 pixels from each feature category, that is, we ran algorithm 2 with M = 4 and Li = 3 for all 1 \u2264 0. We then ran algorithm 3 to generate the feature vectors for each image in the corpus and obtained a database D.We allowed the user name through a target group of variable humidity with possible values 0 or 1."}, {"heading": "8 Conclusion", "text": "We have introduced a method for automatically defining and measuring features of colored images based on a universal image distance, which is measured by calculating the complexity of the string representation of the two images and their concatenation. An image is represented by a feature vector consisting of the distances from the image to a fixed set of small image prototypes once defined by the user. There is no need for sophisticated mathematical image analysis or pre-processing, as the universal image distance considers the image as a string containing all relevant information of the image. The simplicity of our method makes it very attractive for quick and scalable implementation, for example on a special hardware acceleration chip. We have applied our method to monitored and unattended machine learning on satellite images. Results show that standard machine learning algorithms based on our feature vector representation of images work well."}], "references": [{"title": "Universal distance measure for images", "author": ["U.A. Chester", "J. Ratsaby"], "venue": "In Electrical Electronics Engineers in Israel (IEEEI),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Image Analysis, Classification and Change Detection in Remote Sensing: With Algorithms for Envi/Idl", "author": ["M.J. Canty"], "venue": "CRC/Taylor & Francis,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Remote sensing and image interpretation", "author": ["T.M. Lillesand", "R.W. Kiefer", "J.W. Chipman"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "A new sequence distance measure for phylogenetic tree", "author": ["K. Sayood", "H.H. Otu"], "venue": "construction. Bioinformatics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "On the complexity of finite sequences", "author": ["J. Ziv", "A. Lempel"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1976}, {"title": "Fpga-based data compressor based on prediction by partial matching", "author": ["J. Ratsaby", "V. Sirota"], "venue": "In Electrical Electronics Engineers in Israel (IEEEI),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "An fpga-based pattern classifier using data compression", "author": ["J. Ratsaby", "D. Zavielov"], "venue": "In Proc. of 26 IEEE Convention of Electrical and Electronics Engineers in Israel, Eilat,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Parallel processing algorithm for bayesian network inference", "author": ["G. Kaspi", "J. Ratsaby"], "venue": "In Electrical Electronics Engineers in Israel (IEEEI),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Clustering by compression", "author": ["R. Cilibrasi", "P. Vitanyi"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Encyclopedia of Distances", "author": ["M. Deza", "E. Deza"], "venue": "Computer Science. Springer-Verlag,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "We use the recently introduced Universal Image Distance (UID) [1] to compare the similarity between an image and a prototype image.", "startOffset": 62, "endOffset": 65}, {"referenceID": 1, "context": "This process may involve extracting relevant features and segmenting images into sub-components based on some prior knowledge about their context [2,3].", "startOffset": 146, "endOffset": 151}, {"referenceID": 2, "context": "This process may involve extracting relevant features and segmenting images into sub-components based on some prior knowledge about their context [2,3].", "startOffset": 146, "endOffset": 151}, {"referenceID": 0, "context": "In [1] we introduced a new distance function, called Universal Image Distance (UID), for measuring the distance between two images.", "startOffset": 3, "endOffset": 6}, {"referenceID": 3, "context": "The UID first transforms each of the two images into a string of characters from a finite alphabet and then uses the string distance of [4] to give the distance value between the images.", "startOffset": 136, "endOffset": 139}, {"referenceID": 3, "context": "According to [4] the distance between two strings x and y is a normalized difference between the complexity of the concatenation xy of the strings", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "By complexity of a string x we mean the Lempel-Ziv complexity [5].", "startOffset": 62, "endOffset": 65}, {"referenceID": 5, "context": "It is therefore scalable and can be implemented using parallel processing techniques, such as on system-on-chip and FPGA hardware implementation [6,7,8].", "startOffset": 145, "endOffset": 152}, {"referenceID": 6, "context": "It is therefore scalable and can be implemented using parallel processing techniques, such as on system-on-chip and FPGA hardware implementation [6,7,8].", "startOffset": 145, "endOffset": 152}, {"referenceID": 7, "context": "It is therefore scalable and can be implemented using parallel processing techniques, such as on system-on-chip and FPGA hardware implementation [6,7,8].", "startOffset": 145, "endOffset": 152}, {"referenceID": 1, "context": "Our method extracts image features that are unbiased in the sense that they do not employ any heuristics in contrast to other common image-processing techniques[2].", "startOffset": 160, "endOffset": 163}, {"referenceID": 0, "context": "The UID distance function [1] is based on the LZ- complexity of a string.", "startOffset": 26, "endOffset": 29}, {"referenceID": 4, "context": "The definition of this complexity follows [5]: let S,Q and R be strings of characters that are defined over the alphabet A.", "startOffset": 42, "endOffset": 45}, {"referenceID": 4, "context": "Moreover, every string S has a unique exhaustive history [5].", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "A distance for strings based on the LZ-complexity was introduced in [4] and is defined as follows: given two strings X and Y , denote by XY their concatenation then define", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "As in [1] we use the following normalized distance function", "startOffset": 6, "endOffset": 9}, {"referenceID": 8, "context": "We note in passing that (1) resembles the normalized compression distance of [9] except that here we do not use a compressor but rather the LZ-complexity c of a string.", "startOffset": 77, "endOffset": 80}, {"referenceID": 9, "context": ", edit-distances [10].", "startOffset": 17, "endOffset": 21}, {"referenceID": 0, "context": "It is described as Algorithm 3 below (in [1] we used a similar algorithm UIC to soft-classify an image whilst here we use it to only produce a feature vector representation of an image which later serves as a single labeled case for training any supervised learning algorithm or a single unlabeled case for training an unsupervised algorithm).", "startOffset": 41, "endOffset": 44}, {"referenceID": 0, "context": "Train and test algorithm A and produce a classifier C which maps the feature space [0, 1] into T 4.", "startOffset": 83, "endOffset": 89}], "year": 2013, "abstractText": "We present a new method for image feature-extraction which is based on representing an image by a finite-dimensional vector of distances that measure how different the image is from a set of image prototypes. We use the recently introduced Universal Image Distance (UID) [1] to compare the similarity between an image and a prototype image. The advantage in using the UID is the fact that no domain knowledge nor any image analysis need to be done. Each image is represented by a finite dimensional feature vector whose components are the UID values between the image and a finite set of image prototypes from each of the feature categories. The method is automatic since once the user selects the prototype images, the feature vectors are automatically calculated without the need to do any image analysis. The prototype images can be of different size, in particular, different than the image size. Based on a collection of such cases any supervised or unsupervised learning algorithm can be used to train and produce an image classifier or image cluster analysis. In this paper we present the image feature-extraction method and use it on several supervised and unsupervised learning experiments for satellite image data.", "creator": "LaTeX with hyperref package"}}}