{"id": "1305.5030", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2013", "title": "Towards Rational Deployment of Multiple Heuristics in A*", "abstract": "The obvious way to use several admissible heuristics in A* is to take their maximum. In this paper we aim to reduce the time spent on computing heuristics. We discuss Lazy A*, a variant of A* where heuristics are evaluated lazily: only when they are essential to a decision to be made in the A* search process. We present a new rational meta-reasoning based scheme, rational lazy A*, which decides whether to compute the more expensive heuristics at all, based on a myopic value of information estimate. Both methods are examined theoretically. Empirical evaluation on several domains supports the theoretical results, and shows that lazy A* and rational lazy A* are state-of-the-art heuristic combination methods.", "histories": [["v1", "Wed, 22 May 2013 06:41:00 GMT  (522kb,D)", "http://arxiv.org/abs/1305.5030v1", "7 pages, IJCAI 2013, to appear"]], "COMMENTS": "7 pages, IJCAI 2013, to appear", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["david tolpin", "tal beja", "solomon eyal shimony", "ariel felner", "erez karpas"], "accepted": false, "id": "1305.5030"}, "pdf": {"name": "1305.5030.pdf", "metadata": {"source": "CRF", "title": "Towards Rational Deployment of Multiple Heuristics in A*", "authors": ["David Tolpin", "Tal Beja", "Solomon Eyal Shimony", "Ariel Felner"], "emails": ["tolpin@cs.bgu.ac.il", "bejat@cs.bgu.ac.il", "shimony@cs.bgu.ac.il", "felner@bgu.ac.il", "karpase@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "The A-shaped algorithms [Hart et al., 1968] are the best first heuristic search algorithms used by the cost function f (n) = g (n) + h (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) (n) n (n) (n) (n) n (n) (n) (n) (n) (n) n (n) (n) (n) n (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) ((n) (n) ((n) (n) (n) (n) ((n) (n) (n) (n) ((n) ((n) (n) ((n) (n) ((n) (n) ((n) (n) (n) ((n) (() ((n) () () ((((n) (n) (() () (n) (n) (n) ((("}, {"heading": "2 Lazy A\u2217", "text": "It is not as if we are able to reduce the cost when we see ourselves able to h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h3-3-3-h3-3-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2-h2 h"}, {"heading": "3 Enhancements to Lazy A\u2217", "text": "Various improvements can improve the basic LA (algorithm 1), which is particularly effective when t1 and not negligible."}, {"heading": "3.1 OPEN bypassing", "text": "Suppose the node n has just been created, and let fbest denote the currently best f value in OPEN. LA \u0445 evaluates h1 (n) and then inserts n into OPEN. However, if f1 (n) \u2264 fbest, n will immediately reach the peak of OPEN and h2 will be calculated. In such cases, we can choose to calculate h2 (n) immediately (according to line 12 in algorithm 1), which saves the overhead of inserting n in OPEN and springs up again at the next step (= 2 \u00d7 to). For such nodes, LA \u0445 is identical to A \u0445 MAX, since both heuristics are calculated before the node is added to OPEN. This improvement is called OPEN bypassing (OB), reminiscent of the instant expansion technology applied to generated nodes of the instant expansion technology applied to generated nodes [Stern et al., 2010; Sun et al., 2009]. The same technique can be applied if n is expanded again by EN, > 2 when hopped only > n is best."}, {"heading": "3.2 Heuristic bypassing", "text": "Heuristic bypass (HBP) is a technique that allows A \u043d MAX to omit the evaluation of one of the two heuristics. HBP is probably used by many implementers, although to the best of our knowledge it has never appeared in the literature. HBP works for a node n under the following two conditions: (1) the operator between n and its parent p is bidirectional, and (2) both heuristics are consistent [Felner et al., 2011]. Let C be the cost of the operator. However, since heuristics is consistent, we know that | h (p) \u2212 h (n) \u2212 h (n) | \u2264 C. Therefore, h (p) provides the following upper and lower limits to h (n) \u2212 C \u2264 h (n) \u2264 h (p) + C. So we denote h (p) \u2212 C and hhhc (n) \u2212 hhhc and hhhc (n) = hc."}, {"heading": "4 Rational Lazy A\u2217", "text": "We have a very strong guarantee that we will expand the same set of nodes as A \u043c MAX. However, we would prefer to expand more states if it means reducing the search time. We now present each algorithm problem in such a way that it should be treated as an action in a sequential decision-making process as to whether the measures should be chosen in such a way as to achieve the minimum expected search time. However, the appropriate general meta-reasoning is extremely difficult to precisely define and optimally solve. Therefore, we focus on just one decision type that is made in the context of LA when n re-emeres of OPEN (line 7). We have two options: (1) evaluate the second heuristic h2 (n) and add the nodes back to OPEN (line 7)."}, {"heading": "5 Empirical evaluation", "text": "We now present our empirical assessment of LA * and RLA *, variants of the 15 puzzle and planning areas."}, {"heading": "5.1 Weighted 15 puzzle", "text": "We first provide evaluations of the weighted 15-puzzle variant [Thayer and Ruml, 2011], where the cost of moving each tile is equal to the number on the tile. We used a subset of 36 problem cases (from the 100 instances of Korf (1985)), which could be solved with less disk space and 15 minutes timeout, using weighted Manhattan heuristics (WMD) for h1. Since the expensive and informative heuristic column h2 we use a heuristic problem based on lookaheads [Stern et al., 2010]. Given a bound d, we applied and traced a limited depth search of a node n when we reached leaf node l, for which g (l) + WMD (n) + WMD (n) + WMD (n) + f values from sheets were propagated to n.Table 3. Current results are averaged on all solved instances."}, {"heading": "5.2 Planning domains", "text": "We compared the performance of LA and LA, which we did in the heuristic evaluation. We experimented with all planning effects without conditional effects and derivative predicates (which we do not support) from previous CIPs. We compared the performance of LA and LA, which we did in the heuristic evaluation. We experimented with all planning effects without conditional effects and derivative predicates (which we do not support) from previous CIPs. We compared the performance of LA and LA, which we did in the heuristic evaluation. We experimented with all planning effects without conditional effects and derivative predicates (which we do not support) from previous CIPs. We compared the performance of LA and LA, which we did in the heuristic evaluation. We experimented with all planning effects without conditional effects and derivative predicates."}, {"heading": "5.3 Limitations of LA\u2217: 15 puzzle example", "text": "Some domains and heuristic attitudes will not be temporal acceleration with LA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA BA"}, {"heading": "6 Conclusion", "text": "We discussed two schemes for shortening heuristic evaluation times. LA \u043a is very easy to implement and is as informative as A \u0445 MAX. LA \u043a can significantly speed up the search, especially if t2 dominates the other time costs, as seen in weighted 15 puzzle and planning areas. Rational LA \u043a allows additional cuts in h2 evaluations at the cost of less information than A \u0445 MAX. However, due to a rational trade-off, this enables additional acceleration, and Rational LA \u0445 achieves the best overall performance in our areas. RLA \u043c is easier to implement than its direct competitor Sel-MAX, but its decision may be more informed. If RLA itself has to decide whether h2 should be calculated for some nodes n, it already knows that f1 (n) \u2264 C \u0441. In contrast, although SelMAX applies a much more complicated decision rule, it makes its decision when n is generated first, and does not know whether h1 will be sufficient to generate rational rationality."}, {"heading": "7 Acknowledgments", "text": "The research was supported by the Israeli Science Foundation (ISF) under grant number 305 / 09 to Ariel Felner and Eyal Shimony, as well as by the Lynne and William Frankel Center for Computer Science."}], "references": [{"title": "Generalized best-first search strategies and the optimality of A", "author": ["R. Dechter", "J. Pearl"], "venue": "Journal of the ACM, 32(3):505\u2013536", "citeRegEx": "Dechter and Pearl. 1985", "shortCiteRegEx": null, "year": 1985}, {"title": "JAIR", "author": ["Carmel Domshlak", "Erez Karpas", "Shaul Markovitch. Online speedup learning for optimal planning"], "venue": "44:709\u2013755,", "citeRegEx": "Domshlak et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Inconsistent heuristics in theory and practice", "author": ["A. Felner", "U. Zahavi", "R. Holte", "J. Schaeffer", "N. Sturtevant", "Z. Zhang"], "venue": "Artificial Intelligence, 175(910):1570\u20131603", "citeRegEx": "Felner et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "and Holte R", "author": ["A. Felner", "M. Goldenberg", "G. Sharon", "R. Stern", "T. Beja", "N.R. Sturtevant", "J. Schaeffer"], "venue": "Partial-expansion a* with selective node generation. In AAAI, pages 471\u2013477", "citeRegEx": "Felner et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "A formal basis for the heuristic determination of minimum cost paths", "author": ["P.E. Hart", "N.J. Nilsson", "B. Raphael"], "venue": "IEEE Transactions on Systems Science and Cybernetics, SCC-4(2):100\u2013107", "citeRegEx": "Hart et al.. 1968", "shortCiteRegEx": null, "year": 1968}, {"title": "Selecting computations: Theory and applications", "author": ["Nicholas Hay", "Stuart Russell", "David Tolpin", "Solomon Eyal Shimony"], "venue": "Nando de Freitas and Kevin P. Murphy, editors, UAI, pages 346\u2013355. AUAI Press,", "citeRegEx": "Hay et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "critical paths and abstractions: What\u2019s the difference anyway? In ICAPS", "author": ["Malte Helmert", "Carmel Domshlak. Landmarks"], "venue": "pages 162\u2013169,", "citeRegEx": "Helmert and Domshlak. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "JAIR", "author": ["Malte Helmert. The Fast Downward planning system"], "venue": "26:191\u2013246,", "citeRegEx": "Helmert. 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "In IJCAI", "author": ["Erez Karpas", "Carmel Domshlak. Cost-optimal planning with landmarks"], "venue": "pages 1728\u20131733,", "citeRegEx": "Karpas and Domshlak. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Disjoint pattern database heuristics", "author": ["R.E. Korf", "A. Felner"], "venue": "Artificial Intelligence, 134(12):9\u201322", "citeRegEx": "Korf and Felner. 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Depth-first iterative-deepening: An optimal admissible tree search", "author": ["R.E. Korf"], "venue": "Artificial Intelligence, 27(1):97\u2013109", "citeRegEx": "Korf. 1985", "shortCiteRegEx": null, "year": 1985}, {"title": "Artificial Intelligence", "author": ["Stuart Russell", "Eric Wefald. Principles of metereasoning"], "venue": "49:361\u2013395,", "citeRegEx": "Russell and Wefald. 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "In AAAI", "author": ["Roni Stern", "Tamar Kulberis", "Ariel Felner", "Robert Holte. Using lookaheads with optimal bestfirst search"], "venue": "pages 185\u2013190,", "citeRegEx": "Stern et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Simple optimization techniques for A*-based search", "author": ["X. Sun", "W. Yeoh", "P. Chen", "S. Koenig"], "venue": "AAMAS, pages 931\u2013936", "citeRegEx": "Sun et al.. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Bounded suboptimal search: A direct approach using inadmissible estimates", "author": ["Jordan T. Thayer", "Wheeler Ruml"], "venue": "Proceedings of the Twentysecond International Joint Conference on Artificial Intelligence (IJCAI-11),", "citeRegEx": "Thayer and Ruml. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "editor", "author": ["David Tolpin", "Solomon Eyal Shimony. Rational deployment of CSP heuristics. In Toby Walsh"], "venue": "IJCAI, pages 680\u2013686. IJCAI/AAAI,", "citeRegEx": "Tolpin and Shimony. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Maxsat heuristics for cost optimal planning", "author": ["Lei Zhang", "Fahiem Bacchus"], "venue": "AAAI,", "citeRegEx": "Zhang and Bacchus. 2012", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 4, "context": "1 Introduction The A\u2217 algorithm [Hart et al., 1968] is a best-first heuristic search algorithm guided by the cost function f(n) = g(n) + h(n).", "startOffset": 32, "endOffset": 51}, {"referenceID": 0, "context": "If the heuristic h(n) is admissible (never overestimates the real cost to the goal) then the set of nodes expanded by A\u2217 is both necessary and sufficient to find the optimal path to the goal [Dechter and Pearl, 1985].", "startOffset": 191, "endOffset": 216}, {"referenceID": 3, "context": "These nodes, called surplus nodes [Felner et al., 2012], are in OPEN when we expand the goal node with f = C\u2217.", "startOffset": 34, "endOffset": 55}, {"referenceID": 12, "context": "It is a reminiscent of the immediate expand technique applied to generated nodes [Stern et al., 2010; Sun et al., 2009].", "startOffset": 81, "endOffset": 119}, {"referenceID": 13, "context": "It is a reminiscent of the immediate expand technique applied to generated nodes [Stern et al., 2010; Sun et al., 2009].", "startOffset": 81, "endOffset": 119}, {"referenceID": 2, "context": "HBP works for a node n under the following two preconditions: (1) the operator between n and its parent p is bidirectional, and (2) both heuristics are consistent [Felner et al., 2011].", "startOffset": 163, "endOffset": 184}, {"referenceID": 11, "context": "Using principles of rational meta-reasoning [Russell and Wefald, 1991], theoretically every algorithm action (heuristic function evaluation, node expansion, open list operation) should be treated as an action in a sequential decision-making meta-level problem: actions should be chosen so as to achieve the minimal expected search time.", "startOffset": 44, "endOffset": 70}, {"referenceID": 14, "context": "We first provide evaluations on the weighted 15-puzzle variant [Thayer and Ruml, 2011], where the cost of moving each tile is equal to the number on the tile.", "startOffset": 63, "endOffset": 86}, {"referenceID": 12, "context": "As the expensive and informative heuristic h2 we use a heuristic based on lookaheads [Stern et al., 2010].", "startOffset": 85, "endOffset": 105}, {"referenceID": 7, "context": "2 Planning domains We implemented LA\u2217 and RLA\u2217 on top of the Fast Downward planning system [Helmert, 2006], and experimented with two state of the art heuristics: the admissible landmarks heuristic hLA (used as h1) [Karpas and Domshlak, 2009], and the landmark cut heuristic hLMCUT [Helmert and Domshlak, 2009] (used as h2).", "startOffset": 91, "endOffset": 106}, {"referenceID": 8, "context": "2 Planning domains We implemented LA\u2217 and RLA\u2217 on top of the Fast Downward planning system [Helmert, 2006], and experimented with two state of the art heuristics: the admissible landmarks heuristic hLA (used as h1) [Karpas and Domshlak, 2009], and the landmark cut heuristic hLMCUT [Helmert and Domshlak, 2009] (used as h2).", "startOffset": 215, "endOffset": 242}, {"referenceID": 6, "context": "2 Planning domains We implemented LA\u2217 and RLA\u2217 on top of the Fast Downward planning system [Helmert, 2006], and experimented with two state of the art heuristics: the admissible landmarks heuristic hLA (used as h1) [Karpas and Domshlak, 2009], and the landmark cut heuristic hLMCUT [Helmert and Domshlak, 2009] (used as h2).", "startOffset": 282, "endOffset": 310}, {"referenceID": 1, "context": "of the heuristics individually, as well as to their max-based combination, and their combination using selective-max (SelMAX) [Domshlak et al., 2012].", "startOffset": 126, "endOffset": 149}, {"referenceID": 9, "context": "The next experiment is with MD as h1 and a variant of the additive 7-8 PDBs [Korf and Felner, 2002], as h2.", "startOffset": 76, "endOffset": 99}, {"referenceID": 11, "context": "RLA\u2217 and its analysis can be seen as an instance of the rational meta-reasoning framework [Russell and Wefald, 1991].", "startOffset": 90, "endOffset": 116}, {"referenceID": 15, "context": "Recent work exists on meta-reasoning in DFS algorithms for CSP) [Tolpin and Shimony, 2011] and in Monte-Carlo tree search [Hay et al.", "startOffset": 64, "endOffset": 90}, {"referenceID": 5, "context": "Recent work exists on meta-reasoning in DFS algorithms for CSP) [Tolpin and Shimony, 2011] and in Monte-Carlo tree search [Hay et al., 2012].", "startOffset": 122, "endOffset": 140}], "year": 2013, "abstractText": "The obvious way to use several admissible heuristics in A\u2217 is to take their maximum. In this paper we aim to reduce the time spent on computing heuristics. We discuss Lazy A\u2217, a variant of A\u2217 where heuristics are evaluated lazily: only when they are essential to a decision to be made in the A\u2217 search process. We present a new rational meta-reasoning based scheme, rational lazy A\u2217, which decides whether to compute the more expensive heuristics at all, based on a myopic value of information estimate. Both methods are examined theoretically. Empirical evaluation on several domains supports the theoretical results, and shows that lazy A\u2217 and rational lazy A\u2217 are state-of-the-art heuristic combination methods.", "creator": "LaTeX with hyperref package"}}}