{"id": "1305.6046", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2013", "title": "Supervised Feature Selection for Diagnosis of Coronary Artery Disease Based on Genetic Algorithm", "abstract": "Feature Selection (FS) has become the focus of much research on decision support systems areas for which data sets with tremendous number of variables are analyzed. In this paper we present a new method for the diagnosis of Coronary Artery Diseases (CAD) founded on Genetic Algorithm (GA) wrapped Bayes Naive (BN) based FS. Basically, CAD dataset contains two classes defined with 13 features. In GA BN algorithm, GA generates in each iteration a subset of attributes that will be evaluated using the BN in the second step of the selection procedure. The final set of attribute contains the most relevant feature model that increases the accuracy. The algorithm in this case produces 85.50% classification accuracy in the diagnosis of CAD. Thus, the asset of the Algorithm is then compared with the use of Support Vector Machine (SVM), MultiLayer Perceptron (MLP) and C4.5 decision tree Algorithm. The result of classification accuracy for those algorithms are respectively 83.5%, 83.16% and 80.85%. Consequently, the GA wrapped BN Algorithm is correspondingly compared with other FS algorithms. The Obtained results have shown very promising outcomes for the diagnosis of CAD.", "histories": [["v1", "Sun, 26 May 2013 18:16:52 GMT  (199kb)", "http://arxiv.org/abs/1305.6046v1", "First International Conference on Computational Science and Engineering (CSE-2013), May 18 ~ 19, 2013, Dubai, UAE. Volume Editors: Sundarapandian Vaidyanathan, Dhinaharan Nagamalai"]], "COMMENTS": "First International Conference on Computational Science and Engineering (CSE-2013), May 18 ~ 19, 2013, Dubai, UAE. Volume Editors: Sundarapandian Vaidyanathan, Dhinaharan Nagamalai", "reviews": [], "SUBJECTS": "cs.LG cs.CE", "authors": ["sidahmed mokeddem", "baghdad atmani", "mostefa mokaddem"], "accepted": false, "id": "1305.6046"}, "pdf": {"name": "1305.6046.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Sidahmed Mokeddem", "Baghdad Atmani", "Most\u00e9fa Mokaddem"], "emails": ["sid_wise@hotmail.com", "atmani.baghdad@gmail.com", "mmemus@gmail.com"], "sections": [{"heading": null, "text": "Sundarapandian et al. (Eds): CSE, CICS, DBDM, AIFL, SCOM - 2013 pp. 41-51, 2013. \u00a9 CS & IT-CSCP 2013 DOI: 10.5121 / csit.2013.3305Feature Selection (FS) has become the focus of much research on decision support systems for which data sets are analyzed with a huge number of variables. In this paper, we present a new method for diagnosing coronary artery disease (CAD) based on the Genetic Algorithm (GA) that envelops Bayes Na\u00efve (BN). Essentially, the CAD dataset contains two classes defined by 13 characteristics. In the GA-BN algorithm, GAin each iteration generates a subset of attributes that are evaluated by the BN in the second step of the selection process."}, {"heading": "1. INTRODUCTION", "text": "It is estimated that 45% of deaths in Algeria are caused by cardiovascular disease."}, {"heading": "2. RELATED WORKS", "text": "A large number of studies have been proposed in connection with the Fuzzy Logic Rule, which is based on the diagnosis of CAD. In [8] a system for detecting the risk of heart disease has been proposed. This system consists of two phases, the first is the generation of fuzzy rules, and the second is the construction of a rule inference machine based on rules. Tsipouras et al. [9] have proposed a four-phase system for decision support based on fuzzy rules: 1) building a decision tree from the data, 2) extracting rules from the rough form to Fuzzy One and 4) and modelling optimisation. They have achieved a classification accuracy of 65%. Further work in this context [10] has developed a fuzzy system. They have extracted the rules using an extraction method based on rough set theory [11]. The rules are then selected and merged, after which the rules have been weighted with the information of support."}, {"heading": "3. CORONARY ARTERY DISEASE", "text": "CAD covers a variety of diseases related to the cardiovascular system. Cardiovascular diseases are the most common coronary heart diseases that affect the arteries of the heart and include, among others, angina, heart failure, heart attack and stroke (stroke), which occur when the brain is not adequately supplied with blood. As in all medical fields and for the prevention of cardiovascular disease, one of the possible solutions is to educate people in advance about their CAD risks and take preventive measures accordingly. Experts say that early detection of CAD at the stage of angina can prevent death if the right drugs are given through the following measures. In this area, it is important to develop a system for diagnosing CAD to assist physicians in preventing such pathology. Studies that have been conducted to investigate risk factors for CAD [15, 16] other studies that attempt to evaluate the 12-BAD-Lead-18 and [EKG-18]."}, {"heading": "4. FEATURE SELECTION APPROACH", "text": "FS is an active area of research and development in various applications (indexing and retrieval of images, genomic analysis, document analysis...) A large number of algorithms have been proposed in the literature for unattended, supervised, and semi-supervised FS. According to Dash et al. [20], a selection process of attributes usually consists of four steps, illustrated in Figure 1. The generation process allows to generate a subset of attributes in each iteration, which are evaluated in the second step of the selection process. This process of generating attributes can begin either with an empty set of attributes, or with the totality of all attributes, or with a subset of randomly selected attributes. In the first two cases, attributes are added iteratively (forward selection) or removed (reverse selection) [21]. Some other algorithms hybrid both concepts are used as sequential forward-projection techniques, which are advanced after each step forward."}, {"heading": "4.1. The proposed Methodology", "text": "Random generation methods randomly examine all 2n subset candidates, where n is the number of characteristics in the database. Therefore, a subset is not the result of an increase or decrease in the characteristics from the previous subset. This cannot stop the search if the evaluation function of a subset has reached a local optimum. However, the 2n subset candidates are not all evaluated. Therefore, a maximum number of iterations is imposed to ensure that the computation time remains reasonable. In our proposed methodology, we use GA for the generation process Figure 2. GA is an adaptive heuristic search algorithm based on the evolutionary ideas of natural selection and genetics. In our use of genetic algorithms, a subset of characteristics is coded as a chromosome. This group of chromosomes, i.e. the basic totality, is the search space of the algorithm. The fitness function that is used to evaluate the performance of each chromosome (a subset of its proximity to its characteristics) is always used to measure the proximity of the individual chromosome (a subset of its characteristics)."}, {"heading": "17 end for", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "16 Calculate accuracy for k", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "14 Train BN", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "13 End for", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "12 Replace chromosomes with lowest fitness of 7 by best chromosomes with highest fitness of 11", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10 Apply Binary Mutation with probability of 0.09", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9 Apply Binary Crossover with probability of 0.2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7 Generate randomly a population of 20 chromosomes", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6 Encode features as binary chromosomes", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5 for number_generation=1 to 40", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3 Test_DATA_all =(1 fold for BN", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 For k=1 to 10", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 Split Dataset into 10 folds", "text": "In our model, we have characteristics such as binary strings of 1 and 0. In this pattern, 1 means selection of a characteristic and 0 means non-selection. The number of genetic factors in the chromosome equals 14, which is the size of the characteristics of the CAD dataset. The population consists of the number of chromosomes in the search space, and we have chosen 20 as the population size. Therefore, the first population (parent) is randomly generated. We use BNevaluator as a fitness function, usually a fitness function that evaluates the relevance of the chromosomes. Accordingly, the relevance of the chromosomes is represented by the classification accuracy of the BNevaluator, so that the suitability of a chromosome must be collected to determine the relevance of the chromosomes."}, {"heading": "4.2. Feature Selection Techniques used in this study", "text": "In order to evaluate the effectiveness of our proposed GN-packaged BN technique, we compare our methodology with two other FS-packaged methods. The two methods are based on the BN algorithm. The first method uses the Best First Search (BFS) as the generation technology. BFS is a search algorithm that researches a graph by extending the most promising node with the best score that is evaluated based on the packaged BN [29]. In the second method, we generate the subset of characteristics using the Sequential Floating Forward Search (SFFS). This technique derives from the sequential forward generation techniques. The principle of such techniques is to add one or more attributes step by step. However, since they do not examine all possible subsets of attributes and cannot trace them during the search, they are therefore suboptimal. SFFS applies backward steps after each step, while the corresponding subset improves the packaged effectiveness of the BN [30]."}, {"heading": "4.3. Machine Learning techniques used in our study", "text": "Our proposed methodology selects the most relevant features from the CAD dataset and delivers promising diagnostic accuracy. Nevertheless, in order to examine the effectiveness of the selected features with other ML algorithms. In this section, we present these algorithms in general."}, {"heading": "4.3.1. Na\u00efve Bayes", "text": "One of the Bayesian approaches is NB. All Bayesian approaches use the Bayes formula (1). The main hypothesis of this type of method is the independence of attributes. Thus, if attributes are interdependent, this algorithm leads to low classification accuracy [31]. (1)"}, {"heading": "4.3.2. C4.5 Tree Algorithm", "text": "One of the important decision tree algorithms is C4.5 [32]. This algorithm can handle all types of data. It uses cutting techniques to increase the accuracy and gain ratio in the selection of attributes. For example, C4.5 can use a trimming algorithm, such as reducing error pruning, and it increases the accuracy of the algorithm. One of its parameters is M, the minimum number of instances a leaf should have."}, {"heading": "4.3.3. Support Vector Machine", "text": "SVM method is a controlled ML method used for classification, widely used to build a predictive model. SVM predicts for each given test input which of two possible classes forms the input, making it a non-probable binary linear classifier [33]. In the case of training of instance markup pairs, i = 1,......, r, where and. SVM contains the solution to the problem given by (2) In (2) are training vectors and they are mapped by the function into a higher dimensional space. C is the decision parameter for the error term. SVM finds a linear separating hyperplane with the highest margin in dimensional space. Accordingly, the solution of (2) only allows a linear separation solution. Conversely, the use of a core allows a non-linear separation by means of a core function (linear, polynomic, radial base and sigmoids)."}, {"heading": "4.3.4. Multi-Layer Perceptron", "text": "MLP is a feed-forward neural network trained with the standard back propagation algorithm [34]. These are monitored networks, so that it learns from input data to obtain a desired response, so that they are widely used for pattern classification. MLP contain one or two hidden layers. Obviously, the structure of MLP consists of an input and output layer with one or more hidden layers. In addition, each node in one layer with each node in the following layer weighs a weight of. In the MLP, the learning task takes place while the weights of the nodes are updated with the application of the back propagation method and the error set in the output compared to the desired result. Specifically, the error in the output node j in the ninth data point is represented by (3). In the equation d is the desired value and y is the value generated by the MLP."}, {"heading": "5. EXPERIMENTS AND RESULTS", "text": "In the test phase, the test data set is given to the system for determining the risk prognosis of heart patients and the results obtained are evaluated with the metric accuracy of the evaluation [35]. Accuracy is the typical measure for evaluating the effectiveness of the ML method; it is used to calculate how worthy and consistent the test was. To calculate this measurement, we first calculate some of the terms such as True Positives, True Negatives, False Negatives and False Positives based on Table 1, with TP being the True Positive, TN the True Negative, FN the False Negative and FP the False Positive. The experiments are approved and used for each of the proposed wrappers. First, we calculate the average accuracy of the wrapper algorithms coupled with the BN classifier. In addition, each wrapper strategy produces features and we have used the results to measure the effectiveness of these methods with the MAD 3 measurement."}, {"heading": "BN SVM MLP C4.5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Discussion", "text": "The proposed algorithm is believed to have the highest classification accuracy in the literature. This study presents a GA-wrapped BN classification model for the diagnosis of CAD. Experimental results clearly demonstrate the efficiency of the characteristic model selected by GA coating. To prove this, the proposed GA coating BN was compared with some other clinical systems in the literature, and the algorithm was also compared with two wrap-FS methods (BFS and SFFS). Classification accuracy shows the effectiveness of the characteristics selected by GA."}, {"heading": "6. CONCLUSIONS", "text": "The proposed algorithm for CAD patients comprises two steps: (1) generation of a subset of features and (2) evaluation of the system using BN-ML technology. Experimental results show the strength of the proposed BN algorithm in GA packaging to select the most relevant features for the efficient diagnosis of CAD diseases. In general, problems in automated disease diagnosis need to be reduced to achieve high accuracy. Consequently, the proposed algorithm is applied to CAD diseases."}], "references": [{"title": "Clinical decision support systems: a discussion on different methodologies used in health care", "author": ["M.M. Abbasi", "S. Kashiyarndi"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Total endoscopic coronary artery bypass grafting", "author": ["F. Volkmar", "T.A. Diegeler", "Walther"], "venue": "Eur J CardiothoracSurg,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2000}, {"title": "Medical diagnostic decision support systems\u2014past, present, and future: a threaded bibliography and brief commentary", "author": ["Miller RA"], "venue": "J Am Med Inform Assoc 1(1):8-27", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1994}, {"title": "on the relationship between feature selection and classification accuracy", "author": ["W.N. Gansterer", "G.F. Ecker"], "venue": "Work", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "The effect to diagnostic accuracy of decision tree classifier of fuzzy and k-NN based weighted pre-processing methods to diagnosis of erythemato-squamous diseases", "author": ["K. Polat", "S. G\u00fcnes"], "venue": "Digital Signal Process", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Using support vector machines with a novel hybrid feature selection method for diagnosis of erythemato-squamous diseases", "author": ["J. Xie", "C. Wang"], "venue": "Expert Syst. Appl", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Automated diagnosis of coronary artery disease based on data mining and fuzzy modeling", "author": ["M.G. Tsipouras", "T.P. Exarchos", "D.I. Fotiadis", "A.P. Kotsia", "K.V. Vakalis", "K.K. Naka", "L.K. Michalis"], "venue": "IEEE Transactions on Information Technology in Biomedicine", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Diagnosis of coronary artery disease using artificial intelligence based decision support system", "author": ["N.A. Setiawan", "P.A. Venkatachalam", "A.F.M. Hani"], "venue": "Proceedings of the International Conference on Man-Machine Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Intelligent and effective heart attack predic-tion system using data mining and artificial neural network", "author": ["S.B. Patil", "Y.S. Kumaraswamy"], "venue": "European Journal of Scientific Research", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Acute Coronary Syndrome prediction Using Data Mining Techniques- an Application", "author": ["Tahseen A. Jilani", "Huda Yasin", "MadihaYasin", "Cemal Ardil"], "venue": "World Academy of Science, Engineering and Technology,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Comparison of 18-lead ECG and selected body surface potential mapping leads in determining maximally deviated ST lead and efficacy in detecting acute myocardial ischemia during coronary occlusion", "author": ["S.F. Wung", "B. Drew"], "venue": "Journal of Electro-cardiology", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "The angiotensin converting en-zyme D allele is an independent risk factor for early onset coronary artery disease", "author": ["A.V. Raygani", "H. Ghaneialvar", "Z. Rahimi", "H. Nomani", "M. Saidi", "F. Bahrehmand", "A. Vaisi-Raygani", "T.H. Tavilani"], "venue": "Pourmotabbed,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Multifractal analysis of human synchronous 12-lead ECG signals using multiple scale factors", "author": ["X. Yang", "X. Ning", "J. Wang"], "venue": "Physica A: Statistical Mechanics and its Applications", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2007}, {"title": "Designing prehospital ECG systems for acute coronary syndromes. Lessons learned from clinical trials involving 12-lead ST-segment monitoring", "author": ["B.J. Drew", "M.M. Pelter", "E. Lee", "J. Zegre", "D. Schindler", "K.E. Fleischmann"], "venue": "Journal of Electro-cardiology", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "UCI repository of machine learning databases", "author": ["D.J. Newman", "S. Hettich", "C.L. Blake", "C.J. Merz"], "venue": "Department of Information and Computer Science,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "Consistency based feature selection", "author": ["M. Dash", "H. Liu", "H. Motoda"], "venue": "In Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining \u2019ICKDDM00\u2019,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2000}, {"title": "An introduction to variable and feature selection", "author": ["GUYON", "Isabelle et ELISSEEFF", "Andr\u00e9"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "Floating search methods in feature selection", "author": ["PUDIL", "Pavel", "NOVOVI\u010cOV\u00c1", "Jana", "et KITTLER", "Josef"], "venue": "Pattern recognition letters,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1994}, {"title": "Adaptation in natural and artificial systems", "author": ["J.H. Holland"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1975}, {"title": "Genetic algorithms in search, optimization, and machine learning", "author": ["D. Goldberg"], "venue": "Addison- Wisley Editions", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1989}, {"title": "Wrappers for feature subset selection", "author": ["R.Kohavi", "G. John"], "venue": "Artificial Intelligence,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1997}, {"title": "Laplacian score for feature selection", "author": ["X. He", "D. Cai", "P. Niyogi"], "venue": "In Proceedings of the Advances in Neural Information Processing Systems \u2019NIPS", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "Feature selection as a preprocessing step for hierarchical clustering", "author": ["L. Talavera"], "venue": "In Proceedings of the 16th International Conference on Machine Learning \u2019ICML", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1999}, {"title": "Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm", "author": ["H. Yan", "J. Zheng", "Y. Jiang", "C. Peng", "S. Xiao"], "venue": "Appl. Soft Comput", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2008}, {"title": "Generalized best-first search strategies and the optimality of A*", "author": ["DECHTER", "Rinaet PEARL", "Judea"], "venue": "Journal of the ACM (JACM), vol. 32,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1985}, {"title": "Floating search methods in feature selection", "author": ["PUDIL", "Pavel", "NOVOVI\u010cOV\u00c1", "Jana", "et KITTLER", "Josef"], "venue": "Pattern recognition letters,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1994}, {"title": "Naive (Bayes) at forty: The independence assumption in information retrieval", "author": ["LEWIS", "David D"], "venue": "Machine learning:", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1998}, {"title": "Neural network: A comprehensive foundation", "author": ["S. Haykin"], "venue": "Upper Saddle River,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1999}, {"title": "Sensitivity, specificity, accuracy, associated confidence interval and roc analysis with practical SAS implementations", "author": ["W. Zhu", "N. Zeng", "N. Wang"], "venue": "NESUG Proceedings: Health Care and Life Sciences,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2010}, {"title": "Use of fuzzy neural network to predict coronary heart disease in a Malaysian sample", "author": ["ABIDIN", "DOM Basir", "Rosma Mohd", "RAHMAN", "A. Rashid A"], "venue": "WSEAS International Conference. Proceedings. Mathematics and Computers in Science and Engineering. World Scientific and Engineering Academy and Society", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2009}, {"title": "Fuzzy expert system approach for coronary artery disease screening using clinical parameters", "author": ["PAL", "Debabrata", "K.M. MANDANA", "Sarbajit"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2012}, {"title": "Genetic algorithm wrapped Bayesian network feature selection applied to differential diagnosis of erythemato-squamous diseases", "author": ["\u00d6Z\u00c7IFT", "Ak\u0131n et G\u00dcLTEN", "Arif"], "venue": "Digital Signal Processing. Authors Sidahmed MOKEDDEM was born in Mostaganem, Algeria,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Subsequently, they are trained to learn decision characteristics of a physician for an explicit disease and then they can be used to support physician decision making to diagnose future patients of the same disease [1, 2].", "startOffset": 215, "endOffset": 221}, {"referenceID": 1, "context": "Subsequently, they are trained to learn decision characteristics of a physician for an explicit disease and then they can be used to support physician decision making to diagnose future patients of the same disease [1, 2].", "startOffset": 215, "endOffset": 221}, {"referenceID": 2, "context": "Inappropriately, there is no common model that can be adjusted for the diagnosis of all kinds of diseases [3].", "startOffset": 106, "endOffset": 109}, {"referenceID": 3, "context": "This can increase the risk of taking into account correlated or redundant attributes which can lead to lower classification accuracy [4, 5, 6].", "startOffset": 133, "endOffset": 142}, {"referenceID": 4, "context": "This can increase the risk of taking into account correlated or redundant attributes which can lead to lower classification accuracy [4, 5, 6].", "startOffset": 133, "endOffset": 142}, {"referenceID": 5, "context": "This can increase the risk of taking into account correlated or redundant attributes which can lead to lower classification accuracy [4, 5, 6].", "startOffset": 133, "endOffset": 142}, {"referenceID": 6, "context": "[9] have proposed a four stage system for decision support based on fuzzy rules: 1) construction of a decision tree from the data, 2) the extraction of rules from the tree, 3) the transformation rules from the rough form to fuzzy one and 4 ) and the model optimization.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Another work in this context [10] have developed a fuzzy system.", "startOffset": 29, "endOffset": 33}, {"referenceID": 8, "context": "[12] have proposed an intelligent system for predicting heart attacks; in order to make the data ready to be analyzed they integrate them into a data warehouse.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "In this study [13], the authors have used", "startOffset": 14, "endOffset": 18}, {"referenceID": 10, "context": "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].", "startOffset": 62, "endOffset": 70}, {"referenceID": 11, "context": "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].", "startOffset": 62, "endOffset": 70}, {"referenceID": 12, "context": "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].", "startOffset": 122, "endOffset": 130}, {"referenceID": 13, "context": "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].", "startOffset": 122, "endOffset": 130}, {"referenceID": 10, "context": "Studies that have been made to study risk factors for the CAD [15, 16], other studies that try to analyze the 12-lead ECG [17, 18] and 18-lead ECG [15].", "startOffset": 147, "endOffset": 151}, {"referenceID": 14, "context": "The data set is taken from the Data Mining Repository of the University of California, Irvine (UCI) [19].", "startOffset": 100, "endOffset": 104}, {"referenceID": 15, "context": ", [20] a selection process of attributes is usually composed of four steps illustrated in Figure 1.", "startOffset": 2, "endOffset": 6}, {"referenceID": 16, "context": "In the first two cases, attributes are added iteratively (forward selection) or removed (Backward selection) [21].", "startOffset": 109, "endOffset": 113}, {"referenceID": 17, "context": "Some other algorithms hybrid both concepts as Sequential Forward Floating Selection technique that apply, after each step Forward, Backward steps while the selected subset improves the evaluation function [22].", "startOffset": 205, "endOffset": 209}, {"referenceID": 18, "context": "Genetic algorithms, introduced by Holland in 1975 [23] are the most common methods used for random generation [24].", "startOffset": 50, "endOffset": 54}, {"referenceID": 19, "context": "Genetic algorithms, introduced by Holland in 1975 [23] are the most common methods used for random generation [24].", "startOffset": 110, "endOffset": 114}, {"referenceID": 20, "context": "Wrapper Approaches use the classification accuracy rate as evaluation criteria [25].", "startOffset": 79, "endOffset": 83}, {"referenceID": 21, "context": "Filter Approaches use an evaluation function based on the characteristics of the dataset, regardless of any classification algorithm, to select certain attributes or a subset of attributes (information measures, consistency measures, dependence measures and distance measures) [26][27].", "startOffset": 277, "endOffset": 281}, {"referenceID": 22, "context": "Filter Approaches use an evaluation function based on the characteristics of the dataset, regardless of any classification algorithm, to select certain attributes or a subset of attributes (information measures, consistency measures, dependence measures and distance measures) [26][27].", "startOffset": 281, "endOffset": 285}, {"referenceID": 23, "context": "This process is reiterated until a best subset of features is found or the maximum number of iterations is attained [28].", "startOffset": 116, "endOffset": 120}, {"referenceID": 24, "context": "BFS is a search algorithm that explores a graph by expanding the most promising node with the best score which will be evaluated using the wrapped BN [29].", "startOffset": 150, "endOffset": 154}, {"referenceID": 25, "context": "SFFS after each step Forward, it applies Backward steps while the subset corresponding improves the efficacy of wrapped BN [30].", "startOffset": 123, "endOffset": 127}, {"referenceID": 26, "context": "Thus, when features are dependent on each other, this algorithm produce a low classification accuracy [31].", "startOffset": 102, "endOffset": 106}, {"referenceID": 27, "context": "MLP is feed-forward neural networks trained with the standard back-propagation algorithm [34].", "startOffset": 89, "endOffset": 93}, {"referenceID": 28, "context": "In the testing phase, the testing dataset is given to the system to find the risk forecast of heart patients and achieved results are evaluated with the evaluation metric accuracy [35].", "startOffset": 180, "endOffset": 184}, {"referenceID": 6, "context": "A C C U R A CY S E N S I T I VI TY S P E C I FI T Y Anooj [8] Tsipouras [9] Abidin et al.", "startOffset": 72, "endOffset": 75}, {"referenceID": 29, "context": "[36]", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[10] Debabrata et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[37] \u00d6z\u00e7ift et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[38]", "startOffset": 0, "endOffset": 4}], "year": 2013, "abstractText": "Feature Selection (FS) has become the focus of much research on decision support systems areas for which datasets with tremendous number of variables are analyzed. In this paper we present a new method for the diagnosis of Coronary Artery Diseases (CAD) founded on Genetic Algorithm (GA) wrapped Bayes Na\u00efve (BN) based FS. Basically, CAD dataset contains two classes defined with 13 features. In GA\u2013BN algorithm, GA generates in each iteration a subset of attributes that will be evaluated using the BN in the second step of the selection procedure. The final set of attribute contains the most relevant feature model that increases the accuracy. The algorithm in this case produces 85.50% classification accuracy in the diagnosis of CAD. Thus, the asset of the Algorithm is then compared with the use of Support Vector Machine (SVM), Multi-Layer Perceptron (MLP) and C4.5 decision tree Algorithm. The result of classification accuracy for those algorithms are respectively 83.5%, 83.16% and 80.85%. Consequently, the GA wrapped BN Algorithm is correspondingly compared with other FS algorithms. The Obtained results have shown very promising outcomes for the diagnosis of CAD.", "creator": "PScript5.dll Version 5.2.2"}}}