{"id": "1306.1034", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2013", "title": "ROTUNDE - A Smart Meeting Cinematography Initiative: Tools, Datasets, and Benchmarks for Cognitive Interpretation and Control", "abstract": "We construe smart meeting cinematography with a focus on professional situations such as meetings and seminars, possibly conducted in a distributed manner across socio-spatially separated groups. The basic objective in smart meeting cinematography is to interpret professional interactions involving people, and automatically produce dynamic recordings of discussions, debates, presentations etc in the presence of multiple communication modalities. Typical modalities include gestures (e.g., raising one's hand for a question, applause), voice and interruption, electronic apparatus (e.g., pressing a button), movement (e.g., standing-up, moving around) etc. ROTUNDE, an instance of smart meeting cinematography concept, aims to: (a) develop functionality-driven benchmarks with respect to the interpretation and control capabilities of human-cinematographers, real-time video editors, surveillance personnel, and typical human performance in everyday situations; (b) Develop general tools for the commonsense cognitive interpretation of dynamic scenes from the viewpoint of visuo-spatial cognition centred perceptual narrativisation. Particular emphasis is placed on declarative representations and interfacing mechanisms that seamlessly integrate within large-scale cognitive (interaction) systems and companion technologies consisting of diverse AI sub-components. For instance, the envisaged tools would provide general capabilities for high-level commonsense reasoning about space, events, actions, change, and interaction.", "histories": [["v1", "Wed, 5 Jun 2013 09:40:24 GMT  (4815kb,D)", "http://arxiv.org/abs/1306.1034v1", "Appears in AAAI-2013 Workshop on: Space, Time, and Ambient Intelligence (STAMI 2013)"]], "COMMENTS": "Appears in AAAI-2013 Workshop on: Space, Time, and Ambient Intelligence (STAMI 2013)", "reviews": [], "SUBJECTS": "cs.AI cs.CV cs.HC", "authors": ["mehul bhatt", "jakob suchan", "christian freksa"], "accepted": false, "id": "1306.1034"}, "pdf": {"name": "1306.1034.pdf", "metadata": {"source": "CRF", "title": "ROTUNDE \u2014 A Smart Meeting Cinematography Initiative Tools, Datasets, and Benchmarks for Cognitive Interpretation and Control", "authors": ["Mehul Bhatt", "Christian Freksa"], "emails": [], "sections": [{"heading": null, "text": "ROTUNDE - A Smart Meeting Cinematography Initiative Tools, Data Sets and Benchmarks for Cognitive Interpretation and Control Mehul Bhatt and Jakob Suchan and Christian Freksa Spatial Cognition Research Center (SFB / TR 8) University of Bremen, Germany"}, {"heading": "Smart Meeting Cinematography", "text": "The basic goal of Smart Meeting Cinematography is to interpret professional human interactions and automatically produce dynamic recordings of discussions, debates, presentations, etc. in the presence of multiple modalities of communication: gestures (e.g. raising a hand for a question, applause), voice and interruptions, electronic devices (e.g. pressing a button), movement (e.g. getting up, walking around), etc. The Rotunda Initiative is under the auspices of the Smart Meeting Cinematography concept, which temporarily focuses the Rotunda on scientific goals and results in the context of the following tasks: \u2022 People, artifacts, and interaction tracking \u2022 human gestures, identification and learning, possibly closed under a context-specific taxonomy \u2022 Cognitive interpretation through selective narrative narrativity and everyday phenomena, as well as interaction in the area of interaction."}, {"heading": "General Tools and Benchmarks", "text": "From an application perspective, the long-term objectives of the Rotunda Initiative are the development of benchmarks and general-purpose tools (A-B): A. Benchmarks for the development of functionality-driven benchmarks for the interpretation and control capabilities of human-kinematographs, real-time video interfaces, surveillance personnel, and typical human performance in everyday situations. Tools Development of general tools for the cognitive interpretation of dynamic scenes from the perspective of visual-spatial cognitive centering of perceptual narration (Bhatt, Suchan, and Schultz 2013). Special emphasis is placed on clarifying representations and interface mechanisms that seamlessly integrate within large-scale cognitive (interaction) systems and accompanying technologies consisting of various AI components (Bhatt, Suchan, which we orient)."}, {"heading": "Sample Setup and Activity Data", "text": "An example setup for the intelligent meeting kinematography concept, consisting of a circular spatial structure, cameras capable of pan and tilt zoom, depth scanning devices (e.g. Microsoft Kinect, Softkinectic Depthsense), sound sensors. Activity data (Fig. 2-4). Sample scenarios and data sets, consisting of: RGB and depth profile, body skeleton data and highly declarative models generated from raw data for further analysis (e.g. for thinking, learning, controlling). Activity sequence: Leaving meetings, corresponding RGB and depth profile data and high-grade declarative models (Fig. 2) Activity sequence: Transmission between people, corresponding RGB and depth profile data (Fig. 3) Activity sequence: Dropping down, corresponding RGB and depth profile data and body skeleton model (Fig. 4)."}, {"heading": "Acknowledgements", "text": "The preliminary concept of the Rotunda Initiative and its development and benchmarking agenda were presented in the Dagstuhl seminars \"12491 - Interpreting Observated Action\" (S. BiundoStephan, H. W. Guesgen, J. Hertzberg., and S. Marsland) and \"12492 - Human Activity Recognition in Smart Environments\" (J. Begole, J. Crowley, P. Lukowicz, A. Schmidt). \"We thank the seminar participants for discussions, feedback, and impulses. We thank them for their support by the DFG Spatial Cognition Research Center (SFB / TR 8)."}], "references": [{"title": "Spatio-Temporal Abduction for Scenario and Narrative Completion", "author": ["Bhatt", "M. Flanagan 2010] Bhatt", "G. Flanagan"], "venue": "In Proceedings of the International Workshop on Spatio-Temporal Dynamics, co-located with the European Conference on Artificial Intelligence", "citeRegEx": "Bhatt et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bhatt et al\\.", "year": 2010}, {"title": "CLP(QS): A Declarative Spatial Reasoning Framework", "author": ["Lee Bhatt", "M. Schultz 2011] Bhatt", "J.H. Lee", "C. Schultz"], "venue": "In COSIT: Conference on Spatial Information", "citeRegEx": "Bhatt et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bhatt et al\\.", "year": 2011}, {"title": "Cognitive Interpretation of Everyday Activities \u2013 Toward Perceptual Narrative Based Visuo-Spatial Scene Interpretation", "author": ["Suchan Bhatt", "M. Schultz 2013] Bhatt", "J. Suchan", "C. Schultz"], "venue": null, "citeRegEx": "Bhatt et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bhatt et al\\.", "year": 2013}, {"title": "Interleaved inductive-abductive reasoning for learning complex event models", "author": ["Dubba"], "venue": "Inductive Logic Programming,", "citeRegEx": "Dubba,? \\Q2012\\E", "shortCiteRegEx": "Dubba", "year": 2012}, {"title": "Narrative based Postdictive Reasoning for Cognitive Robotics", "author": ["Eppe", "M. Bhatt 2013] Eppe", "M. Bhatt"], "venue": "In COMMONSENSE 2013: 11th International Symposium on Logical Formalizations of Commonsense Reasoning", "citeRegEx": "Eppe et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Eppe et al\\.", "year": 2013}, {"title": "Toward an activity theory based model of spatio-temporal interactions - integrating situational inference and dynamic (sensor) control", "author": ["Suchan", "J. Bhatt 2012] Suchan", "M. Bhatt"], "venue": null, "citeRegEx": "Suchan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Suchan et al\\.", "year": 2012}, {"title": "The ExpCog Framework: High-Level Spatial Control and Planning for Cognitive Robotics. In Bridges between the Methodological and Practical Work of the Robotics", "author": ["Suchan", "J. Bhatt 2013] Suchan", "M. Bhatt"], "venue": null, "citeRegEx": "Suchan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Suchan et al\\.", "year": 2013}], "referenceMentions": [], "year": 2013, "abstractText": "The basic objective in smart meeting cinematography is to interpret professional interactions involving people, and automatically produce dynamic recordings of discussions, debates, presentations etc in the presence of multiple communication modalities. Typical modalities include gestures (e.g., raising one\u2019s hand for a question, applause), voice and interruption, electronic apparatus (e.g., pressing a button), movement (e.g., standing-up, moving around) etc.", "creator": "LaTeX with hyperref package"}}}