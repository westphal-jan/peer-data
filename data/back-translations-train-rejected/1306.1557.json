{"id": "1306.1557", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2013", "title": "Extending Universal Intelligence Models with Formal Notion of Representation", "abstract": "Solomonoff induction is known to be universal, but incomputable. Its approximations, namely, the Minimum Description (or Message) Length (MDL) principles, are adopted in practice in the efficient, but non-universal form. Recent attempts to bridge this gap leaded to development of the Representational MDL principle that originates from formal decomposition of the task of induction. In this paper, possible extension of the RMDL principle in the context of universal intelligence agents is considered, for which introduction of representations is shown to be an unavoidable meta-heuristic and a step toward efficient general intelligence. Hierarchical representations and model optimization with the use of information-theoretic interpretation of the adaptive resonance are also discussed.", "histories": [["v1", "Thu, 6 Jun 2013 21:11:19 GMT  (583kb)", "http://arxiv.org/abs/1306.1557v1", "proceedings of AGI 2012, Lecture Notes in Artificial Intelligence, Vol. 7716, pp. 242-251, Springer-Verlag, 2012. The final publication is available at link.springer.com"]], "COMMENTS": "proceedings of AGI 2012, Lecture Notes in Artificial Intelligence, Vol. 7716, pp. 242-251, Springer-Verlag, 2012. The final publication is available at link.springer.com", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["alexey potapov", "sergey rodionov"], "accepted": false, "id": "1306.1557"}, "pdf": {"name": "1306.1557.pdf", "metadata": {"source": "CRF", "title": "Extending Universal Intelligence Models with Formal Notion of Representation", "authors": ["Alexey Potapov", "Sergey Rodionov"], "emails": ["potapov@aideus.com", "rodionov@aideus.com"], "sections": [{"heading": null, "text": "Keywords: universal agents, Kolmogorov complexity, principle of minimum description length, representations"}, {"heading": "1 Introduction", "text": "The idea of universal induction and prediction based on algorithmic information theory was invented a long time ago [1]. In theory, it eliminates the fundamental problem of previous probabilities, false solutions that lead to such negative practical effects as over-learning, over-adaptation, over-segmentation and so on. However, it would be quite natural to try to develop some models of universal intelligence on this basis. However, the corresponding detailed models have only been published relatively recently (e.g. [2]). Moreover, the theory of universal induction was not even popular in machine learning. The reason is quite obvious - it offers incompressible methods that require additional training sessions of large sizes in order to make good predictions. Practical alternatives such as the Minimum Description Length (MDL) or the Minimum Message Length (MML) principles are much more popular - they require training of the large quantities that proceed from the formation to make good predictions."}, {"heading": "2 Background", "text": "The intelligence model of intelligence as a kind of search for the best chain of actions was the first to be introduced in the field of universal intelligence. It can be used to solve any problem, but only in the case of known certain settings and unlimited computing resources. However, Universal Solomonoff Induction / Prediction offers the possibility to extend this model to cases of arbitrary (predictable) unknown environments. However, the problem of computing resources persists and becomes more complicated. Moreover, an unbiased universal agent may take a lot of time to obtain necessary information about the world in order to ensure its own survival, even if it has infinite computational resources. As the search for chains of action can be accelerated, the production problem should be regarded as a learning process. Solomonoff Induction is based on the notion of algorithmic probability calculated for a binary string of characters."}, {"heading": "3 Representational MDL Principle", "text": "The minimal description principle states that the best model of the given data source is that which minimizes the sum of the information contained - in bits - (in bits, in bits, of data encoded with the use of the model. In theory, this principle is based on the Kolmogorov method (algorithmic) complexity KU (\u03b1), which is defined for a certain string alpha. (3) The MDL principle is derived from the Kolmogorov complexity by dividing the program for UTM p = \u00b5\u03b4 into the algorithm itself (the regular component of the model) \u00b5 and its input data (the random component).KU (\u03b1) = minp [l (p) = min\u00b53)."}, {"heading": "4 Hierarchical Representations and Adaptive Resonance", "text": "Individual descriptions of substrings, even within a good representation, will still contain some reciprocal information (large-area regularities in the initial string), so if you have subdivided the string \u03b1 into the substrings \u03b11\u03b12... \u03b1n, and the descriptions \u00b5i\u03b4i are constructed independently for each substring, it is natural to try to compress (or group) the string \u00b5 = \u00b51\u00b52... \u00b5n (deltas can be ignored at the next level of the description because they are interpreted as noise within the RMDL principle), which can still be very long, so that you want to try to compress (or group) the string into larger substrings, and to describe those substrings within a higher level of representation. Resulting models (regular parts of the descriptions) can be further compressed, and so on. Specific subdivision of the string into substrings cannot be unknown into substrings models, and can be considered part of a model."}, {"heading": "5 Adoption of the RMDL Principle in Universal Algorithmic Intelligence", "text": "The opinion that representations should be included in the models of general intelligence has already been expressed [13, 14]. However, representations are usually implemented only in the form of prior information expressed in a special design of the programming language. Besides the inadequacy of a strict quantitative analysis of the quality of representation, however, the main limitation here is the absence of the decomposition of the model construction. On the other hand, the necessity of decomposition can also be realized. In particular, the importance of fragments and the ability to solve tasks are noted only small Kolmogorov complexity [7, 15, 16]. The RMDL principle can strictly take these two aspects into account. Consider the universal intelligent agent based on algorithmic probability. We will use Hutter's model for convenience to skip unnecessary detailed descriptions of lesser known models."}, {"heading": "6 Conclusions", "text": "The necessary formal definition was recently given together with the representation principle MDL, which is derived from the decomposition of Kolmogorov complexity. In this paper, we discussed the possibility of extending the model of universal algorithmic intelligence (AIBA). We showed that this principle can be quite naturally integrated into this model, making it somewhat closer to efficient artificial general intelligence. Information-theoretical criteria of the quality of representations and models can be used for the more consistent construction of optimized methods of machine perception and learning, including multi-level systems with adaptive resonance. However, the RMDL principle only partially solves the problem of the quality of representations in the models of universal algorithmic intelligence. It was originally introduced for tasks whose decomposition is defined a priori (e.g. a computer vision system should analyze images independently), and representations are necessary to reduce the negative effects of this representation."}], "references": [{"title": "A Formal Theory of Inductive Inference, par1 and part 2", "author": ["R. Solomonoff"], "venue": "Information and Control, vol. 7, pp. 1\u201322, 224\u2013254", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1964}, {"title": "Universal Artificial Intelligence: Sequential Decisions Based on Algorithmic Probability", "author": ["M. Hutter"], "venue": "Springer", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "The New AI: General & Sound & Relevant for Physics", "author": ["J. Schmidhuber"], "venue": "Artificial General Intelligence. Cognitive Technologies, B. Goertzel and C. Pennachin (Eds.), pp. 175\u2013198. Springer", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Comparative Analysis of Structural Representations of Images based on the Principle of Representational Minimum Description Length", "author": ["A.S. Potapov"], "venue": "Journal of Optical Technology, vol. 75, iss. 11, pp. 715\u2013720", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Theoretic-Informational Approach to the Introduction of Feedback into Multilevel Machine-Vision Systems", "author": ["A.S. Potapov"], "venue": "Journal of Optical Technology, vol. 74, iss. 10, pp. 694\u2013699", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Algorithmic Probability, Heuristic Programming and AGI", "author": ["R. Solomonoff"], "venue": "E.Baum, M.Hutter, E.Kitzelmann (Eds), Advances in Intelligent Systems Research, vol. 10 (Proc. 3 Conf. on AGI, Lugano, Switzerland, March 5-8, 2010), pp. 151\u2013157", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "A Computational Approximation to the AIXI Model", "author": ["S. Pankov"], "venue": "Frontiers in Artificial Intelligence and Applications (Proc. 1 AGI Conference), vol. 171, pp. 256\u2013267", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Bias and No Free Lunch in Formal Measures of Intelligence // Journal of Artificial General Intelligence 1, pp", "author": ["B. Hibbard"], "venue": "54\u201361", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Compression and Intelligence: Social Environments and Communication", "author": ["D. Dowe", "J. Hernandez-Orallo", "P. Das"], "venue": "Proc. Artificial General Intelligence \u2013 4 International Conference, Mountain View, CA, USA, August 3\u20136, 2011. Lecture Notes in Computer Science 6830, pp. 204\u2013211, Springer", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Vision: A Computational Investigation into the Human Representation and Processing of Visual Information", "author": ["D. Marr"], "venue": "MIT Press", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1982}, {"title": "Hebbian Constraint on the Resolution of the Homunculus Fallacy Leads to a Network that Searches for Hidden Cause-Effect Relationships", "author": ["A. Lorincz"], "venue": "B. Goertzel, P. Hitzler, M. Hutter (Eds), Advances in Intelligent Systems Research, vol. 8 (Proc. 2 Conf. on Artificial General Intelligence, Arlington, Virginia, USA, March 6-9, 2009), pp. 126\u2013131", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning Deep Architectures for AI", "author": ["Y. Bengio"], "venue": "Foundations and Trends in Machine Learning, vol. 2, no. 1, pp. 1\u2013127", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Program Representation for General Intelligence", "author": ["M. Looks", "B. Goertzel"], "venue": "B. Goertzel, P. Hitzler, M. Hutter (Eds), Advances in Intelligent Systems Research, vol. 8 (Proc. 2 Conf. on Artificial General Intelligence, Arlington, Virginia, USA, March 6-9, 2009), pp. 114\u2013119", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Towards Practical Universal Search", "author": ["T. Schaul", "J. Schmidhuber"], "venue": "E.Baum, M.Hutter, E.Kitzelmann (Eds), Advances in Intelligent Systems Research, vol. 10 (Proc. 3 Conf. on AGI, Lugano, Switzerland, March 5-8, 2010), pp. 139\u2013144", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Artificial General Segmentation", "author": ["D. Hewlett", "P. Cohen"], "venue": "E.Baum, M.Hutter, E.Kitzelmann (Eds), Advances in Intelligent Systems Research, vol. 10 (Proc. 3 Conf. on AGI, Lugano, Switzerland, March 5\u20138, 2010), pp. 31\u201336", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "The CHREST Architecture of Cognition", "author": ["F. Gobet", "P.C.R. Lane"], "venue": "The Role of Perception in General Intelligence. In: E.Baum, M.Hutter, E.Kitzelmann (Eds), Advances in Intelligent Systems Research, vol. 10 (Proc. 3 Conf. on AGI, Lugano, Switzerland, March 5\u20138, 2010.), pp. 7\u201312", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Frontier Search", "author": ["Y. Sun", "T. Glasmachers", "T. Schaul", "J. Schmidhuber"], "venue": "E.Baum, M.Hutter, E.Kitzelmann (Eds), Advances in Intelligent Systems Research, vol. 10 (Proc. 3 Conf. on AGI, Lugano, Switzerland, March 5-8, 2010.), pp. 158\u2013163", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "The idea of universal induction and prediction on the basis of algorithmic information theory was invented a long time ago [1].", "startOffset": 123, "endOffset": 126}, {"referenceID": 1, "context": "[2]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "This slowdown can be eliminated via self-optimization [3], but its time for unbiased intelligence can also be very large.", "startOffset": 54, "endOffset": 57}, {"referenceID": 3, "context": "In order to bridge this gap, the notion of representation was recently formalized within the algorithmic information theory, and the Representational MDL (RMDL) principle was introduced [4].", "startOffset": 186, "endOffset": 189}, {"referenceID": 4, "context": "Residual mutual information between these subtasks can be taken into account by adaptive resonance models, which also have the informationtheoretic formalization [5].", "startOffset": 162, "endOffset": 165}, {"referenceID": 1, "context": "Apparently, the universal agent based on the algorithmic probability (such as AI\u03be [2]) may require executing many actions to make history string long enough to neutralize influence of the arbitrarily selected U.", "startOffset": 82, "endOffset": 85}, {"referenceID": 5, "context": "This idea was pointed out by different authors [6, 7].", "startOffset": 47, "endOffset": 53}, {"referenceID": 6, "context": "This idea was pointed out by different authors [6, 7].", "startOffset": 47, "endOffset": 53}, {"referenceID": 7, "context": "It is also said [8] that the choice of UTM can affect the \u201crelative intelligence of agents\u201d.", "startOffset": 16, "endOffset": 19}, {"referenceID": 8, "context": "It can be useful in communications between intelligent agents or for reducing the amount of computations [9], but in general the MDL principle is a rough approximation of the algorithmic probability.", "startOffset": 105, "endOffset": 108}, {"referenceID": 9, "context": "Since S can be interpreted as an algorithm (some program for UTM), which produces any given data string from its description, the algorithm S precisely fits the verbal notion of representation formulated by David Marr [10].", "startOffset": 218, "endOffset": 222}, {"referenceID": 10, "context": "\u201cinternal representation interprets input reconstructing it\u201d [11]).", "startOffset": 61, "endOffset": 65}, {"referenceID": 3, "context": "Therefore, the following more strict definition can be given [4].", "startOffset": 61, "endOffset": 64}, {"referenceID": 8, "context": "Any three- (or more) part coding of an individual string could be re-structured to the two-part coding scheme [9], but S and \u03bc in the RMDL principle cannot be united, because S describes the problem class, while \u03bc describes its instance.", "startOffset": 110, "endOffset": 113}, {"referenceID": 11, "context": "It is also interesting to note that the idea of deep learning architectures [12] arose from the fact that complexity of some models is exponentially larger within shallow representations than within deep representations.", "startOffset": 76, "endOffset": 80}, {"referenceID": 4, "context": "Qualitative expression of support values can be derived from the RMDL principle in the form of equation (9), so it can be used in the informationtheoretic formalization of the Adaptive Resonance Theory [5].", "startOffset": 202, "endOffset": 205}, {"referenceID": 12, "context": "The opinion that representations should be incorporated into the models of general intelligence has been already stated [13, 14].", "startOffset": 120, "endOffset": 128}, {"referenceID": 13, "context": "The opinion that representations should be incorporated into the models of general intelligence has been already stated [13, 14].", "startOffset": 120, "endOffset": 128}, {"referenceID": 6, "context": "In particular, importance of chunks and possibility to solve tasks only of small Kolmogorov complexity are noted [7, 15, 16].", "startOffset": 113, "endOffset": 124}, {"referenceID": 14, "context": "In particular, importance of chunks and possibility to solve tasks only of small Kolmogorov complexity are noted [7, 15, 16].", "startOffset": 113, "endOffset": 124}, {"referenceID": 15, "context": "In particular, importance of chunks and possibility to solve tasks only of small Kolmogorov complexity are noted [7, 15, 16].", "startOffset": 113, "endOffset": 124}, {"referenceID": 1, "context": "The AI\u03be agent is intended to maximize the total reward choosing its actions [2]:", "startOffset": 76, "endOffset": 79}, {"referenceID": 16, "context": "defined in [17]).", "startOffset": 11, "endOffset": 15}], "year": 2012, "abstractText": "Solomonoff induction is known to be universal, but incomputable. Its approximations, namely, the Minimum Description (or Message) Length (MDL) principles, are adopted in practice in the efficient, but non-universal form. Recent attempts to bridge this gap leaded to development of the Representational MDL principle that originates from formal decomposition of the task of induction. In this paper, possible extension of the RMDL principle in the context of universal intelligence agents is considered, for which introduction of representations is shown to be an unavoidable meta-heuristic and a step toward efficient general intelligence. Hierarchical representations and model optimization with the use of information-theoretic interpretation of the adaptive resonance are also discussed.", "creator": "Word"}}}