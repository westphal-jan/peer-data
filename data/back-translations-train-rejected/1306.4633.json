{"id": "1306.4633", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2013", "title": "A Fuzzy Based Approach to Text Mining and Document Clustering", "abstract": "Fuzzy logic deals with degrees of truth. In this paper, we have shown how to apply fuzzy logic in text mining in order to perform document clustering. We took an example of document clustering where the documents had to be clustered into two categories. The method involved cleaning up the text and stemming of words. Then, we chose m number of features which differ significantly in their word frequencies (WF), normalized by document length, between documents belonging to these two clusters. The documents to be clustered were represented as a collection of m normalized WF values. Fuzzy c-means (FCM) algorithm was used to cluster these documents into two clusters. After the FCM execution finished, the documents in the two clusters were analysed for the values of their respective m features. It was known that documents belonging to a document type, say X, tend to have higher WF values for some particular features. If the documents belonging to a cluster had higher WF values for those same features, then that cluster was said to represent X. By fuzzy logic, we not only get the cluster name, but also the degree to which a document belongs to a cluster.", "histories": [["v1", "Thu, 6 Jun 2013 07:35:23 GMT  (359kb)", "http://arxiv.org/abs/1306.4633v1", "10 pages, 6 tables, 1 figure, review paper, International Journal of Data Mining &amp; Knowledge Management Process (IJDKP) ISSN : 2230 - 9608[Online] ; 2231 - 007X [Print]. Paper can be found atthis http URL"]], "COMMENTS": "10 pages, 6 tables, 1 figure, review paper, International Journal of Data Mining &amp; Knowledge Management Process (IJDKP) ISSN : 2230 - 9608[Online] ; 2231 - 007X [Print]. Paper can be found atthis http URL", "reviews": [], "SUBJECTS": "cs.LG cs.IR", "authors": ["sumit goswami", "mayank singh shishodia"], "accepted": false, "id": "1306.4633"}, "pdf": {"name": "1306.4633.pdf", "metadata": {"source": "CRF", "title": "A FUZZY BASED APPROACH TO TEXT MINING AND DOCUMENT CLUSTERING", "authors": ["Sumit Goswami", "Mayank Singh Shishodia"], "emails": ["sumit_13@yahoo.com", "mayanksshishodia@gmail.com"], "sections": [{"heading": null, "text": "In this paper, we showed how to apply fuzzy logic in text mining to perform document clusters. We took an example of document clusters where the documents had to be clustered into two categories, which involved cleansing the text and parentage of words. Then, we selected \"m\" characteristics that differ markedly in their word frequency (WF), normalized by the length of the document between the documents belonging to those two clusters. Documents to be clustered were presented as a collection of \"m\" normalized WF values. It was known that documents belonging to a document type \"X\" tended to have higher WF values for certain characteristics for certain clusters. \"Once the FCM execution was complete, the documents in the two clusters were analyzed for the values of their respective\" m \"characteristics. It was known that documents belonging to a document type\" X \"tended to have higher WF values for certain characteristics,\" if the documents have higher WF characteristics for those clusters, then the documents have higher WF characteristics for those clusters."}, {"heading": "1. INTRODUCTION", "text": "Text mining is the automated process of extracting previously unknown information from the analysis of these unstructured texts [1]. Although text mining is similar to data mining, it is very different. Data mining is related to pattern extraction from databases, while text mining is a natural language. It is also different from searching, especially web search, where the information you are looking for already exists. In text mining, the computer tries to extract something new from the resources that are already available.In this review article, we have applied fuzzy logic to text mining to perform clustering in a number of predefined clusters. As an example, we have shown how to categorize given documents into two categories - sports and politics. First, the documents are cleaned by removing advertising and tags, the hyphens are treated and the stopwords are removed. Word stem is performed to represent each word by its root [2]. Each document is then assigned as a cumulative character (the meaning of which)."}, {"heading": "2. FUZZY LOGIC", "text": "Fuzzy logic is a mathematical logic model in which truth can be partial, i.e. it can have a value between 0 and 1 that is completely false and perfectly true [6]. It is based on approximate thinking rather than exact thinking."}, {"heading": "2.1 Fuzzy Logic vs Probability", "text": "The probability can be divided into two broad categories - evidence and physical. Let's look at an event E with a probability of 80%. Evidence probability means that the probability of E occurring, given the evidence currently available, is 80%. On the other hand, the physical probability is that if the experiment with E were to be repeated infinitely many times as a result, then 80% of E would occur [7]. For example, let's look at a car \"A\" that travels 150 kilometers per hour. Now, that car would definitely be considered as fast. Let's look at another car \"B\" that travels 180 kilometers per hour. In a repeatable experiment, it's not that the car \"B\" will be faster more often than \"A\" [physical probability] or that, given the current information, it's more likely that the car \"B\" is faster than the car \"A.\" Both cars own the property quickly, but in different ways. If we use Fuzzy Logic for this problem and there is a comparison, then the cars are called \"the cars that are faster than the two cars.\""}, {"heading": "2.2 Degrees of Truth", "text": "The degree of truth stems from the function of membership. An example is shown in Figure 1: Suppose we get an explanation that a high frequency of occurrence of the word \"ball\" in a document means that the document is related to sports. To associate numerical values with these \"high,\" or similarly \"low,\" \"medium,\" etc., we use a membership function. Linguistic hedging can be used to create additional categories by adding adjectives such as \"very,\" \"fair,\" \"less,\" \"more,\" etc. Figure 1 shows a membership function that determines when the frequency of occurrence of the word \"ball\" in a document should be low, medium, or high. However, it should be noted that the membership function depends on the situation and the problem how the designer perceives it. For example, someone else can design the membership function where the word frequency of even 500 words in a document is considered low. This may be a piece of the ball, 44 times the document for the ball may be a sample for the 13,000, a ball containing the last word."}, {"heading": "3. CLUSTERING", "text": "Using fuzzy logic and text mining, we can merge similar documents. Document clustering is used by the computer to group documents into meaningful groups.We will use the c-means algorithm. This algorithm is divided into two types - hard c-means and FCM [6].Hard c-means algorithm is used to group \"m\" observations into \"c\" clusters.Each cluster has its cluster center. The observation belongs to the cluster that is the closest to it. Clustering is sharp, which means that each observation is in one cluster and only one cluster.FCM is a variant of the hard c-means cluster algorithm. Each observation here has a membership value associated with each of the clusters, which conversely relates to the distance of that observation from the cluster center."}, {"heading": "3.1 The FCM Algorithm", "text": "The main objective of the FCM algorithm is to minimize the objective function according to [6]:, (2), where each real number greater than 1uij indicates the membership xi in the Jth clusterxi, the ith dimension of the measured data is the ith dimension of the cluster center. The formula for updating the cluster center ci is: (3) The values of the partition matrix are updated using the formula: (4) The iteration of the FCM algorithm stops if the maximum change in the values of the fuzzy c partition matrix is less than E, where E is a termination criterion with a value between 0 and 1. The steps followed in the FCM algorithm are given below: 1. Initiate the fuzzy partition matrix, U = [uij] matrix, U (0) 2. In k step: Calculate the vectors C (k) = [cj] with U (k)."}, {"heading": "4. Bag of Words Representation of a Document", "text": "Consider a paragraph: \"It is a variation of the Hard C-Means cluster algorithm. Each observation here has a member value that is associated with each of the clusters and is inversely related to the distance of that observation from the center of the cluster.\" The representation of the pouch for the above paragraph will resemble Table1. Apart from individual words, we can also use phrases that yield better results. Few examples of this are \"engineering students,\" \"computer games,\" tourist attraction, \"\" gold medal, \"etc. The same dictionary technique can be modified to treat the phrases as single words. In our method, we assign the weights of the number of occurrences of the word in the document, which are normalized by the length of the document and multiplied by 10,000."}, {"heading": "5. STEPS INVOLVED IN APPLYING FUZZY LOGIC TO TEXT MINING", "text": "The following steps are followed to apply fuzzy logic to text mining."}, {"heading": "5.1 Pre-processing of Text", "text": "This phase involves cleaning up the text such as removing advertising, etc. We also need to deal with hyphens, removing tags from documents such as HTML, XML, etc. Removing this unwanted text helps improve the efficiency of our algorithm."}, {"heading": "5.2 Feature Generation", "text": "Word Stemming [2] is performed. Word Stemming refers to the representation of the word by its root, for example the words - driving a car, driving a car and driving a car should be represented by driving a car. This is important because not all documents are present in the same active or passive voice or in the same tense."}, {"heading": "5.3 Feature Selection", "text": "The number of attributes used in our process will be further reduced. We will only select the attributes that will help us in our process [3] [4] [5]. To bundle the documents related to sports and politics separately, the presence of names in a document will not help much. However, in both cases there may be names. However, in some situations it will be difficult to manually point out the attributes that distinguish documents that should belong to different types. In such situations, we need to find out what attributes we should use for clustering."}, {"heading": "5.4 Clustering", "text": "The method used here is the FCM cluster algorithm. Each document to be clustered has already been presented as a \"bag of words,\" and only the essential \"words\" (features) have been retained from this \"bag.\" The goal now is to group the documents into categories (referred to as classes in FCM).When using FCM, the documents are bundled with similar frequency (normalized by document length) of various selected characteristics. The number of clusters to be created can be specified at an early stage, but this can later lead to inaccurate results if this number is not appropriate. This problem is known as cluster validity. Once the FCM execution is complete, either because of the predetermined number of iterations or because the maximum change in the fuzzy partition matrix is less than the threshold, we get the required number of clusters and all documents have been bundled under them."}, {"heading": "5.5 Evaluation and Interpretation of Results", "text": "If the member value of a document for a particular cluster is high, it can be said that the document belongs strongly to that cluster. However, if all the member values corresponding to a particular document are almost the same (Example 35,.35,.30 among three clusters), this would imply that the document does not belong very strongly to any of these clusters."}, {"heading": "6. EXAMPLE", "text": "Suppose we get some documents that we have to categorize into two categories - \"sports\" and \"politics.\" We will not introduce the first two steps that we have followed, as they are quite simple. We will start from the third - selection of characteristics. We had no idea what words (characteristics) we could use to find our documents. We have some documents that we know in connection with sports and politics. We have applied steps 1 and 2 to them and then counted the word frequency of the different words with eq (1). Then we have categorized the differences in these WF values for the same category and the documents related to politics."}, {"heading": "V11= (180+200+210+7)/4=149.25", "text": "Similarly, the calculation of all V1j getV1 = {149.25, 300, 162.5, 7.5} is the center of cluster 1.Similarly, V2 = {50.110.75, 67.75, 33.25} is the center of cluster 2.Now calculate the Euclidean distances of each document vector from both central clusters: D11 = (((180-149.25) 2 + (400-300) 2 + (200-162.5) 2 + (1-7.75) 2) 1 / 2 = 111.32"}, {"heading": "D12 = 149.5, D13 = 339.5, D14 = 352.5, D15 = 102.2, D16 = 353.4, D17 = 109.2, D18 = 351.1", "text": "Also from cluster two: D21 = (((180-50) 2 + (400-110.75) 2 + (200-67.75) 2 + (1-33.25) 2) 1 / 2 = 345.10"}, {"heading": "D22 = 382.2, D23 = 105.1, D24 = 118.3, D25 = 334.4, D26 = 119.6, D27 = 339.7, D28 = 116.9", "text": "Now that we have the distance of each vector from both cluster centers, we will update the fuzzy partition matrix using eq (4). Note that we have already set the value of the \"m\" in this formula earlier in this example. U11 = [1 + (111.32 / 345.10) 2] -1 =.90, U12 =.867, U23 =.913, U24 =.898, U15 =.9146, U26 =.897, U17 =.906, U28 =.901The remaining values of the fuzzy partition matrix will be updated to add each column to 1. We will get the updated fuzzy partition matrix so that our threshold change (hold condition) was 0.001. Our maximum change here is 0.133, which is greater than 0.001, U28 =.901The remaining values of the fuzzy partition matrix will be updated to add each column to 1."}, {"heading": "7. INTERPRETING THE RESULTS", "text": "Suppose our final blurred partition matrix for 8 documents looks something like this: We see that Doc1, Doc2, Doc5, Doc7 belong to Cluster 1, while Doc3, Doc4, Doc6, Doc8 belong to Cluster 2 because of the high membership values in these respective clusters. Since these documents have been combined, it can be said that Cluster 1 is sport. At the same time, Cluster2 contains documents with a higher frequency of words such as democracy (which have to do with politics). Therefore, Cluster2 represents politics. Here, Doc1 refers to sports to a large extent (due to its very high membership value). If we set the criteria that membership values greater than 0.85 can be called \"strong membership\" in relation to a given cluster, then Doc1 and Doc1 can strongly (due to its very high membership value) say that the results of Sports 1 are stronger than those of Sports 1. \""}, {"heading": "8. CONCLUSION", "text": "In this paper, we have shown how Fuzzy Logic can be used in text mining to cluster documents, taking an example where the documents were grouped into two themes: - \"sport\" and \"politics.\" The advantage of Fuzzy Logic over probability was that we could calculate in the former the degree to which a particular document belonged to either the categories \"sport\" or \"politics.\" This was not possible in the probability model. In other words, instead of simply saying whether the document belonged to \"sport\" or \"politics,\" we could now say to what extent the characteristics of the document resembled those of a sports-related document or a policy-related document. By doing this for all the documents in the data set, we could also compare two documents and say which one belongs to which topic \"more.\" Moreover, since each document will have some member values in each of the clusters, no usable document will ever be excluded from the search results [1] [5]."}, {"heading": "9. REFERENCES", "text": "1. Vishal Gupta, Gurpreet S. Lehal; \"A Survey of Text Mining Techniques and Applications\"; Journal of Emerging Technologies in Web Intelligence, Vol.1, No.1, August 20092. K.Sathiyakumari, V.Preamsudha, G.Manimekalai; \"Unsupervised Approach for Document Clustering Modified Fuzzy C mean Algorithm\"; International Journal of Computer & Organization Trends -Volume 11 Issue3-2011.3. R. Rajendra Prasath, Sudeshna Sarkar: Unsupervised Feature Generation using KnowledgeRepositories for Effective Text Categorization. ECAI 2010: 1101-11024. Sumit Goswami, Sudeshna Sarkar, Mayur Rustagi: Stylometric Analysis of Bloggers' Ageand Gender."}, {"heading": "5. Sumit Goswami, Mayank Singh Shishodia; \u201cA fuzzy based approach to stylometric analysis", "text": "Age and sex of bloggers \"; HIS 2012: 47-51"}, {"heading": "6. Ross, T. J. (2010); \u201cFuzzy Logic with Engineering Applications\u201d, Third Edition, John Wiley", "text": "& Sons, Ltd, Chichester, UK 7. Fuzzy logic vs Proobability (Good Math, Bad Math); http: / / scientopia.org / blogs / goodmath / 2011 / 02 / 02 / fuzzy-logic-vs-probability /, last reviewed 28 July 2012 8. Nogueira, T.M.; \"On The Use of Fuzzy Rules to Text Document Classification\"; 10th International Conference on Hybrid Intelligent Systems (HIS) 2010; 23-25 August 2010 Atlanta, USA."}], "references": [{"title": "A Survey of Text Mining Techniques and Applications\u201d", "author": ["Vishal Gupta", "Gurpreet S. Lehal"], "venue": "Journal of Emerging Technologies in Web Intelligence,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Unsupervised Feature Generation using Knowledge Repositories for Effective Text Categorization", "author": ["R. Rajendra Prasath", "Sudeshna Sarkar"], "venue": "ECAI", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Stylometric Analysis of Bloggers' Age and Gender", "author": ["Sumit Goswami", "Sudeshna Sarkar", "Mayur Rustagi"], "venue": "ICWSM", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "A fuzzy based approach to stylometric analysis of blogger\u201fs age and gender\u201d", "author": ["Sumit Goswami", "Mayank Singh Shishodia"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Fuzzy Logic with Engineering Applications", "author": ["T.J. Ross"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "On The Use of Fuzzy Rules to Text Document Classification \u201d", "author": ["T.M. Nogueira"], "venue": "International Conference on Hybrid Intelligent Systems", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Text Mining is the automated process of extracting some previously unknown information from analysis of these unstructured texts [1].", "startOffset": 129, "endOffset": 132}, {"referenceID": 1, "context": "WF = (Word Count/ (Total Words in the Document)) x10000 (1) \u201em\u201f number of words are chosen [3][4][5] and each document is represented as a set of \u201em\u201f values which are the WF values of those corresponding \u201em\u201f words in that document.", "startOffset": 91, "endOffset": 94}, {"referenceID": 2, "context": "WF = (Word Count/ (Total Words in the Document)) x10000 (1) \u201em\u201f number of words are chosen [3][4][5] and each document is represented as a set of \u201em\u201f values which are the WF values of those corresponding \u201em\u201f words in that document.", "startOffset": 94, "endOffset": 97}, {"referenceID": 3, "context": "WF = (Word Count/ (Total Words in the Document)) x10000 (1) \u201em\u201f number of words are chosen [3][4][5] and each document is represented as a set of \u201em\u201f values which are the WF values of those corresponding \u201em\u201f words in that document.", "startOffset": 97, "endOffset": 100}, {"referenceID": 4, "context": "it can have value between 0 and 1, that is completely false and completely true [6] .", "startOffset": 80, "endOffset": 83}, {"referenceID": 4, "context": "This algorithm is classified into two types- Hard c-means and FCM [6] .", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "1 The FCM Algorithm The main aim of FCM algorithm is to minimize the objective function given by [6] :", "startOffset": 97, "endOffset": 100}, {"referenceID": 1, "context": "We choose only the features which will help us in our process [3][4][5] .", "startOffset": 62, "endOffset": 65}, {"referenceID": 2, "context": "We choose only the features which will help us in our process [3][4][5] .", "startOffset": 65, "endOffset": 68}, {"referenceID": 3, "context": "We choose only the features which will help us in our process [3][4][5] .", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "Keeping in mind the constraints that all entries should be in the interval [0, 1] and the columns should add to a total of 1 and considering that we are given 4 documents to cluster:", "startOffset": 75, "endOffset": 81}, {"referenceID": 5, "context": "This interpretation of results in linguistic form [8] is what gives advantage to usage of Fuzzy Logic over Probability models like Bayesian in Text Mining.", "startOffset": 50, "endOffset": 53}], "year": 2013, "abstractText": "Fuzzy logic deals with degrees of truth. In this paper, we have shown how to apply fuzzy logic in text mining in order to perform document clustering. We took an example of document clustering where the documents had to be clustered into two categories. The method involved cleaning up the text and stemming of words. Then, we chose \u2018m\u2019 features which differ significantly in their word frequencies (WF), normalized by document length, between documents belonging to these two clusters. The documents to be clustered were represented as a collection of \u2018m\u2019 normalized WF values. Fuzzy c-means (FCM) algorithm was used to cluster these documents into two clusters. After the FCM execution finished, the documents in the two clusters were analysed for the values of their respective \u2018m\u2019 features. It was known that documents belonging to a document type \u2018X\u2019 tend to have higher WF values for some particular features. If the documents belonging to a cluster had higher WF values for those same features, then that cluster was said to represent \u2018X\u2019. By fuzzy logic, we not only get the cluster name, but also the degree to which a document belongs to a cluster.", "creator": "Microsoft\u00ae Word 2010"}}}