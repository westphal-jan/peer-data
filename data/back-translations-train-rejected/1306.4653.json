{"id": "1306.4653", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jun-2013", "title": "Multiarmed Bandits With Limited Expert Advice", "abstract": "We solve the COLT 2013 open problem of Seldin et. al. on minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice. We give an algorithm for the setting of K arms and N experts out of which we are allowed to query and use only M experts' advices in each round, which has a regret bound of 4\\sqrt{\\frac{\\min\\{K, M\\} N \\log(N)}{M} T} after T rounds.", "histories": [["v1", "Wed, 19 Jun 2013 19:25:51 GMT  (5kb)", "http://arxiv.org/abs/1306.4653v1", null], ["v2", "Thu, 27 Jun 2013 19:48:35 GMT  (8kb)", "http://arxiv.org/abs/1306.4653v2", "Updated with lower bound nearly matching the upper bound"], ["v3", "Fri, 28 Jun 2013 18:35:06 GMT  (8kb)", "http://arxiv.org/abs/1306.4653v3", "Updated with lower bound nearly matching the upper bound, and fixed some typos"], ["v4", "Mon, 8 Jul 2013 19:05:49 GMT  (9kb)", "http://arxiv.org/abs/1306.4653v4", "Updated with tighter upper bound based on PolyINF algorithm, lower bound nearly matching the upper bound, and fixed some typos"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["satyen kale"], "accepted": false, "id": "1306.4653"}, "pdf": {"name": "1306.4653.pdf", "metadata": {"source": "CRF", "title": "Multiarmed Bandits With Limited Expert Advice", "authors": ["Satyen Kale"], "emails": ["sckale@us.ibm.com"], "sections": [{"heading": null, "text": "ar Xiv: 130 6.46 53v1 [cs.LG] 1 9Ju n20 13in each round with a regret limit of 4 \u221a min {K, M} N log (N) M T after T rounds."}, {"heading": "1 Introduction", "text": "Consider the following advisory efficient list of multi-armed bandits with expert advice problem introduced by Seldin et al. [2]. In each turn t = 1, 2,.., T we must draw an arm. At the same time, an opponent sets losses for each arm a = 1, 2,.., K =. Any expert h can give advice on which arm to draw in the form of a probability distribution. This advice gives expert h an expected loss of the arm in turn. The catch is that we can only follow the advice of most M experts of our choice in each round. The goal is to select subgroups of M experts in each round to refute the advice of N. \u2212 The advice is that we can follow the advice of most M experts of our choice in each round."}, {"heading": "2 Preliminaries", "text": "In each round of the algorithm, we can assume that each expert suggests exactly one arm to play in each round; i.e., that he (a) = 1 suggests a K for exactly one arm and 0 for all other arms. Let's call such guide vectors \"standard-base-vectors.\" To see this, we can randomly round a general guide-vector after a standard-base-vector by constructing a new guide-vector key and a new guide-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-v"}, {"heading": "3 Algorithm", "text": "Name the groups B1, B2, BR, and define R: = {1, 2,.., R}. Execute the Multiplicative Weight (MW) algorithm for all experts, specifying the loss of expert h at a later date; we will ensure that the probability for all but M experts is not so high that only M experts need to be consulted for their advice. If the distribution for experts generated by the MW algorithm at a later date is an estimate for the loss of arms (we will specify this later; we will ensure that the probability is not so high that only M experts need to be consulted for their advice). If the distribution for experts at a later date is t qt, then the distribution in round t + 1 is specified by the following update rule: qt + 1 (h): qt + qt (h)."}, {"heading": "4 Analysis", "text": "Theorem 1 Satz 1 Satz Satz 1 Satz Satz 1 Satz 2 Satz 2 Satz 2 Satz 2 Satz 2 Satz 2 Satz 3 Satz 3 Satz 3 Satz 3 Satz 3 Satz 3 Satz 3 Satz 3 Satz 3 Satz 3 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 4 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 5 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 6 Satz 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7"}, {"heading": "Acknowledgments", "text": "The author thanks Elad Hazan, Dean Foster, Rob Schapire and Yevgeny Seldin for discussing this issue."}], "references": [{"title": "The Multiplicative Weights Update Method: a Meta-Algorithm and Applications", "author": ["Sanjeev Arora", "Elad Hazan", "Satyen Kale"], "venue": "Theory of Computing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Open Problem: Advice-Efficient Adversarial Multiarmed Bandits with Expert Advice", "author": ["Yevgeny Seldin", "Koby Crammer", "Peter Bartlett"], "venue": "In COLT,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}], "referenceMentions": [{"referenceID": 1, "context": "[2] on minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Simultaneously, an adversary sets losses lt(a) \u2208 [0, 1] for each arm a \u2208 K.", "startOffset": 49, "endOffset": 55}, {"referenceID": 1, "context": "[2], and in fact gives a better regret bound than the bound conjectured in [2], which was O ( \u221a KN log(N) M T )", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2], and in fact gives a better regret bound than the bound conjectured in [2], which was O ( \u221a KN log(N) M T )", "startOffset": 75, "endOffset": 78}, {"referenceID": 0, "context": "The MW algorithm guarantees (see [1]) that as long as \u03b7 is chosen so that |\u03b7Y h t | \u2264 1 for all t, h, we have for any expert h T \u2211", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "+ \u03b3 (\u2235 lt(a) \u2208 [0, 1]) = (1\u2212 \u03b3) \uf8ee", "startOffset": 15, "endOffset": 21}, {"referenceID": 0, "context": "h\u2208BIt qt(h)\u03be (At) ( 1 Prt[It, At] 2 (\u2235 \u03be(At) \u2208 [0, 1] and lt(At) \u2208 [0, 1]) = rt(It)p It t (At) \u00b7 1 Prt[It, At] (", "startOffset": 47, "endOffset": 53}, {"referenceID": 0, "context": "h\u2208BIt qt(h)\u03be (At) ( 1 Prt[It, At] 2 (\u2235 \u03be(At) \u2208 [0, 1] and lt(At) \u2208 [0, 1]) = rt(It)p It t (At) \u00b7 1 Prt[It, At] (", "startOffset": 67, "endOffset": 73}], "year": 2017, "abstractText": "We solve the COLT 2013 open problem of Seldin et al. [2] on minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice. We give an algorithm for the setting of K arms and N experts out of which we are allowed to query and use only M experts\u2019 advices in each round, which has a regret bound of 4 \u221a min{K,M}N log(N) M T after T rounds.", "creator": "LaTeX with hyperref package"}}}