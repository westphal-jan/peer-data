{"id": "1306.4714", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jun-2013", "title": "Penetration Testing == POMDP Solving?", "abstract": "Penetration Testing is a methodology for assessing network security, by generating and executing possible attacks. Doing so automatically allows for regular and systematic testing without a prohibitive amount of human labor. A key question then is how to generate the attacks. This is naturally formulated as a planning problem. Previous work (Lucangeli et al. 2010) used classical planning and hence ignores all the incomplete knowledge that characterizes hacking. More recent work (Sarraute et al. 2011) makes strong independence assumptions for the sake of scaling, and lacks a clear formal concept of what the attack planning problem actually is. Herein, we model that problem in terms of partially observable Markov decision processes (POMDP). This grounds penetration testing in a well-researched formalism, highlighting important aspects of this problem's nature. POMDPs allow to model information gathering as an integral part of the problem, thus providing for the first time a means to intelligently mix scanning actions with actual exploits.", "histories": [["v1", "Wed, 19 Jun 2013 22:39:20 GMT  (85kb,D)", "http://arxiv.org/abs/1306.4714v1", "Proceedings of the 3rd Workshop on Intelligent Security (SecArt'11), at IJCAI'11"]], "COMMENTS": "Proceedings of the 3rd Workshop on Intelligent Security (SecArt'11), at IJCAI'11", "reviews": [], "SUBJECTS": "cs.AI cs.CR", "authors": ["carlos sarraute", "olivier buffet", "joerg hoffmann core security technologies", "itba", "inria)"], "accepted": false, "id": "1306.4714"}, "pdf": {"name": "1306.4714.pdf", "metadata": {"source": "META", "title": "Penetration Testing == POMDP Solving?", "authors": ["Carlos Sarraute", "Olivier Buffet", "J\u00f6rg Hoffmann"], "emails": ["carlos@coresecurity.com", "olivier.buffet@loria.fr", "joerg.hoffmann@loria.fr"], "sections": [{"heading": "Introduction", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "Background", "text": "We fill in some background information about pentesting and POMDPs."}, {"heading": "Penetration Testing", "text": "The goal of a typical penetration test task is to gain control of as many computers in a network as possible, preferring some machines (e.g. because of their critical content), starting with a controlled computer: either outside the targeted network (so that the first targets are machines that are accessible via the Internet) or within that network (e.g. by using a Trojan horse). As illustrated in Figure 1, three types of computers can be distinguished at any given time: those that are under control (where an agent has been installed that can perform actions); those that are reachable from a controlled computer because they are a2Sometimes non-deterministic effects are an adequate abstraction of state uncertainty, such as \"crossing the road.\" The situation with pentesting is different because repeated executions produce identical outcomes. Sub-network with one of them: and those that are inaccessible from a controlled computer (with any controlled machine)."}, {"heading": "POMDPs", "text": "POMDPs are normally defined (Monahan 1982; Cassandra 1998) by a tuple < S, A, O, O, r, b0 > where the system in any state is s \u00b2 S (the state room), the agent performs an action through A (the observation room) which leads to (1) a transition to a state s \u00b2, corresponding to the transition function T (s, a \u00b2 s \u00b2) = Pr (s \u00b2 s \u00b2 s \u00b2 s, a), (2) an observation o \u00b2 O (the observation room) according to the observation function O (s \u00b2, a) = Pr (o \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s, a) a scalar reward r (s \u00b2 s \u00b2 s \u00b2 s, a), (2) an observation o \u00b2 (the observation room) according to the observation function O (s \u00b2 s \u00b2 s, a \u00b2 s \u00b2 s \u00b2 s, a), a (the observation room) according to the observation function O (s \u00b2 s \u00b2, a), o \u00b2 s \u00b2 s \u00b2 s (the observation room) according to the observation function O (s \u00b2), o \u00b2 s \u00b2 s \u00b2 s (the observation room), a), a scalar reward r (s \u00b2 (s \u00b2 s \u00b2 s \u00b2 s, a), a), an observation function O \u00b2 s \u00b2 (the observation zone, a), a), a (s \u00b2 (the observation room), a), an observation function O \u00b2 s \u00b2 s \u00b2 s (the observation room, a), a), a (the observation function O \u00b2 s \u00b2 s \u00b2, a), a (the observation room, a)."}, {"heading": "Modeling Penetration Testing with POMDPs", "text": "Since penetration testing is about acting under partial observation, POMDPs are a natural candidate for modelling this particular problem. They make it possible to model the problem of knowledge acquisition and take into account probabilistic information, such as the fact that certain configurations or vulnerabilities occur more frequently than others. In comparison, classical planning approaches (Lucangeli et al. 2010) assume that the entire network configuration is known, so that no research is required. In this section, we discuss how penetration testing can be formalised using POMDPs. As we will see, the uncertainty lies essentially in the original state of belief. This differs from modelling uncertainty in pentestering using probabilistic outcomes, as in (Sarraute et al. 2011), which does not take into account the real dynamics of the system."}, {"heading": "States", "text": "First, any reasonable penetration test will have a finite execution. There is nothing here that can be gained by the infinite execution of a looping behavior. Each pentest terminates either when an event (e.g. attack detection) stops it, or when the additional access rights that could still be gained (from the finite number of access rights) do not outweigh the associated costs, implying that there is an absorbing terminal state and that we need to solve a stochastic shortest path problem (SSP). Then, we do not need the full state of the system to describe the current situation. Therefore, we will focus on aspects that are relevant to the task. For example, this state does not need to include network topology, as it is assumed to be static and known here, but it does need to be taken into account for the configuration of the system."}, {"heading": "Actions (& Observations)", "text": "In fact, it is not as if it is a real problem, but a pure problem that has come to a head in recent years. (...) It is not as if it is a pure problem. (...) It is not as if it is a pure problem. (...) It is not as if it is a pure problem. (...) It is not as if it is a pure problem. (...) It is not as if it is a real problem. (...) It is not as if it is a pure problem. (...) It is not as if it is a pure problem. (...) It is not as if it is a real problem. (...)"}, {"heading": "Rewards", "text": "Otherwise, the reward function has to consider several things: value of a computer (rc): The goal of a pentest is to gain access to a number of computers. At this point, we therefore propose to assign a fixed reward for each successful exploitation (on a previously uncontrolled machine). In a more realistic environment, one could reward the first access to certain valuable data, regardless of which computer hosts the data. Time is money (rt): Every action - be it a test or an exploitation - has a duration so that the expected duration of the pentest can be minimized by assigning a cost (negative reward) to each transition that is proportional to its duration. One could also consider a maximum time for the pentest rather than minimizing it. Detection risk (rd): We do not explicitly model the event of the pentest (which would lead to a terminal state with important costs), but let's just consider that the transition costs depend on the probability that these multiple components are a component."}, {"heading": "POMDP Model Generation", "text": "Generating a POMDP model for pentesting requires knowledge of possible states, actions, and observations, plus the reward function and initial state of belief. First, it should be noted that the POMDP model can evolve from one pentest to another because it requires new applications, exploits, or tests. Information and observation models for the various possible tests and exploits can be derived from the documentation of test tools (see, for example, the nmap man page) and databases such as CVE (Common Vulnerabilities and Exposures) 4. Information could probably be automatically extracted from such databases, which are already highly structured. In our experiments, we will start with a proprietary database from Core Security Technologies. The two remaining components of the model - the initial belief state - contain quantitative information that is more difficult to acquire."}, {"heading": "Solving Penetration Testing with POMDPs", "text": "We now describe our experiments. First, we fill in some details about the setup, then discuss different scaling scenarios, before taking a closer look at some sample policies generated by the POMDP solver."}, {"heading": "Experiments Setup", "text": "The experiments are run on a machine with an Intel Core2 Duo CPU with 2.2 GHz and 3 GB RAM. We use the APPL (Approximate POMDP Planning) toolkit5. This C + + implementation of the SARSOP algorithm is easy to compile and use and has reasonable performance. The solver is executed without time limit until a target accuracy of 0.001 is reached. Since we solve a stochastic problem with the shortest route, no discount factor is required, but we use \u03b3 = 0.95 to improve performance. We will briefly discuss the effects of changing and modifying. Our problem generator is implemented in Python. It has 3 parameters: \u2022 Number of machines M in the target network, \u2022 Number of exploits E in the pentesting tool that are on the target network, which are ap-plicable on the target network."}, {"heading": "Combined Scaling", "text": "We discuss the performance of the \"quantity of uncertainty\" as a function of the T. \"Intuitively, T increases the probability of diffusion.\" To make data representation practicable, we will first scale only 2 of the parameters. Consider the first Figure 8 (a), which scales the phenomena M and T. E is fixed to the minimum value, i.e., each machine has a fixed OS version and a target application. In this setting, there are 3M states where the generated POMDP file has 6562 states and occupies 71 MB on the hard disk; the APPL solver actually runs out of memory when it tries to analyze it. In this and all the experiments that follow, M \u2264 2, the runtime exponentially grows with M - eventually even solver input. Interestingly, as for T, this shows a very pronounced easy-hard-easy pattern. To investigate the reasons for this, we found that it is due to a low-high-low-high-low-T function as a low-low-T pattern."}, {"heading": "POMDPs make Better Hackers", "text": "To illustrate the policies found by the POMDP solver, let us consider a simple example in which the pentester has four exploits: an SSH exploit (on OpenBSD, port 22), a wuftpd exploit (on Linux, port 21), an IIS exploit (on Windows, port 80), and an Apache exploit (on Linux, port 80). The probability that the target machine is Windows is higher than the probability of other operating systems. Previous automated pentesting methods, such as Lucangeli and others (2010), proceed by first running a port scan on common ports, then running an OS detection module (s), and finally starting exploits for potentially vulnerable services. Our POMDP model first tests whether port 80 is open because the expected reward is greater than the exploitation of port 80, than for any of the explosions."}, {"heading": "Discussion", "text": "In fact, it is the case that one is able to find a solution that is capable of finding a solution, that is capable of finding a solution, and that is able to find a solution that is capable of finding a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, and that is able to find a solution that is able to find a solution, that is able to find a solution, that is able to find a solution."}], "references": [{"title": "A closer look at MOMDPs", "author": ["M. Araya-L\u00f3pez", "V. Thomas", "O. Buffet", "F. Charpillet"], "venue": "Proc. of ICTAI-10.", "citeRegEx": "Araya.L\u00f3pez et al\\.,? 2010", "shortCiteRegEx": "Araya.L\u00f3pez et al\\.", "year": 2010}, {"title": "Why attacking systems is a good idea", "author": ["I. Arce", "G. McGraw"], "venue": "IEEE Computer Society - Security & Privacy Magazine 2(4).", "citeRegEx": "Arce and McGraw,? 2004", "shortCiteRegEx": "Arce and McGraw", "year": 2004}, {"title": "The theory of dynamic programming", "author": ["R. Bellman"], "venue": "Bull. Amer. Math. Soc. 60:503\u2013516.", "citeRegEx": "Bellman,? 1954", "shortCiteRegEx": "Bellman", "year": 1954}, {"title": "Quantitative Risk Analysis of Computer Networks", "author": ["D. Bilar"], "venue": "Ph.D. Dissertation, Dartmouth College.", "citeRegEx": "Bilar,? 2003", "shortCiteRegEx": "Bilar", "year": 2003}, {"title": "Course of action generation for cyber security using classical planning", "author": ["M.S. Boddy", "J. Gohde", "T. Haigh", "S.A. Harp"], "venue": "Proc. of ICAPS\u201905.", "citeRegEx": "Boddy et al\\.,? 2005", "shortCiteRegEx": "Boddy et al\\.", "year": 2005}, {"title": "Deterministic POMDPs revisited", "author": ["B. Bonet"], "venue": "Proc. of UAI\u201909.", "citeRegEx": "Bonet,? 2009", "shortCiteRegEx": "Bonet", "year": 2009}, {"title": "Exact and Approximate Algorithms for Partially Observable Markov Decision Processes", "author": ["A.R. Cassandra"], "venue": "Ph.D. Dissertation, Brown University, Dept of Computer Science.", "citeRegEx": "Cassandra,? 1998", "shortCiteRegEx": "Cassandra", "year": 1998}, {"title": "A systematic approach to multi-stage network attack analysis", "author": ["J. Dawkins", "J. Hale"], "venue": "Proc. of DISCEX III.", "citeRegEx": "Dawkins and Hale,? 2003", "shortCiteRegEx": "Dawkins and Hale", "year": 2003}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": "MIT Press.", "citeRegEx": "Koller and Friedman,? 2009", "shortCiteRegEx": "Koller and Friedman", "year": 2009}, {"title": "SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces", "author": ["H. Kurniawati", "D. Hsu", "W. Lee"], "venue": "Robotics: Science and Systems IV.", "citeRegEx": "Kurniawati et al\\.,? 2008", "shortCiteRegEx": "Kurniawati et al\\.", "year": 2008}, {"title": "Attack planning in the real world", "author": ["J. Lucangeli", "C. Sarraute", "G. Richarte"], "venue": "Workshop on Intelligent Security (SecArt 2010).", "citeRegEx": "Lucangeli et al\\.,? 2010", "shortCiteRegEx": "Lucangeli et al\\.", "year": 2010}, {"title": "Remote OS detection via TCP/IP stack fingerprinting", "author": ["G.F. Lyon"], "venue": "Phrack Magazine 8(54).", "citeRegEx": "Lyon,? 1998", "shortCiteRegEx": "Lyon", "year": 1998}, {"title": "A survey of partially observable Markov decision processes", "author": ["G. Monahan"], "venue": "Management Science 28:1\u201316.", "citeRegEx": "Monahan,? 1982", "shortCiteRegEx": "Monahan", "year": 1982}, {"title": "An algorithm to find optimal attack paths in nondeterministic scenarios", "author": ["C. Sarraute", "G. Richarte", "J. Lucangeli"], "venue": "ACM Workshop on Artificial Intelligence and Security (AISec\u201911).", "citeRegEx": "Sarraute et al\\.,? 2011", "shortCiteRegEx": "Sarraute et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 10, "context": "Previous work (Lucangeli et al. 2010) used classical planning and hence ignores all the incomplete knowledge that characterizes hacking.", "startOffset": 14, "endOffset": 37}, {"referenceID": 13, "context": "More recent work (Sarraute et al. 2011) makes strong independence assumptions for the sake of scaling, and lacks a clear formal concept of what the attack planning problem actually is.", "startOffset": 17, "endOffset": 39}, {"referenceID": 1, "context": ", (Arce and McGraw 2004)).", "startOffset": 2, "endOffset": 24}, {"referenceID": 4, "context": "This is known in the AI Planning community as the \u201cCyber Security\u201d domain (Boddy et al. 2005).", "startOffset": 74, "endOffset": 93}, {"referenceID": 10, "context": "Independently (though considerably later), the approach was put forward also by the pentesting industry (Lucangeli et al. 2010).", "startOffset": 104, "endOffset": 127}, {"referenceID": 1, "context": ", (Arce and McGraw 2004)). Doing so automatically allows for regular and systematic testing without a prohibitive amount of human labor, and makes pentesting more accessible to non-experts. A key question then is how to automatically generate the attacks. A natural way to address this issue is as an attack planning problem. This is known in the AI Planning community as the \u201cCyber Security\u201d domain (Boddy et al. 2005). Independently (though considerably later), the approach was put forward also by the pentesting industry (Lucangeli et al. 2010). The two domains essentially differ only in the industrial context addressed. Herein, we are concerned exclusively with the specific context of regular automatic pentesting, as in Core Security\u2019s \u201cCore Insight Enterprise\u201d tool. We will use the term \u201cattack planning\u201d in that sense. Lucangeli et al. (2010) encoded attack planning into PDDL, and used off-the-shelf planners.", "startOffset": 3, "endOffset": 855}, {"referenceID": 3, "context": ", (Bilar 2003; Dawkins and Hale 2003)) are concerned with the defender\u2019s viewpoint, and tackle a very different kind of uncertainty attempting to model what an attacker would be likely to do.", "startOffset": 2, "endOffset": 37}, {"referenceID": 7, "context": ", (Bilar 2003; Dawkins and Hale 2003)) are concerned with the defender\u2019s viewpoint, and tackle a very different kind of uncertainty attempting to model what an attacker would be likely to do.", "startOffset": 2, "endOffset": 37}, {"referenceID": 13, "context": "formed in part by one of the authors (Sarraute et al. 2011).", "startOffset": 37, "endOffset": 59}, {"referenceID": 13, "context": "formed in part by one of the authors (Sarraute et al. 2011). On the positive side, the proposed attack planner demonstrates industrial-scale runtime performance, and in fact its worst-case runtime is low-order polynomial. On the negative side, the planner does not offer a solution to (b)\u2014it still reasons only about exploits, not scanning\u2014and of course its efficiency is bought at the cost of strong simplifying assumptions. Also, the work provides no clear notion of what attack planning under uncertainty actually is. Herein, we take the opposite extreme of the trade-off between accuracy and performance. We tackle the problem in full, in particular addressing information gathering as an integral part of the attack. We achieve this by modeling the problem in terms of partially observable Markov decision processes (POMDP). As a side effect, this modeling activity serves to clarify some important aspects of this problem\u2019s nature. A basic insight is that, whereas Sarraute et al. (2011) model the uncertainty as non-deterministic actions\u2014success probabilities of exploits\u2014this uncertainty is more naturally modeled as an uncertainty about states.", "startOffset": 38, "endOffset": 994}, {"referenceID": 13, "context": "formed in part by one of the authors (Sarraute et al. 2011). On the positive side, the proposed attack planner demonstrates industrial-scale runtime performance, and in fact its worst-case runtime is low-order polynomial. On the negative side, the planner does not offer a solution to (b)\u2014it still reasons only about exploits, not scanning\u2014and of course its efficiency is bought at the cost of strong simplifying assumptions. Also, the work provides no clear notion of what attack planning under uncertainty actually is. Herein, we take the opposite extreme of the trade-off between accuracy and performance. We tackle the problem in full, in particular addressing information gathering as an integral part of the attack. We achieve this by modeling the problem in terms of partially observable Markov decision processes (POMDP). As a side effect, this modeling activity serves to clarify some important aspects of this problem\u2019s nature. A basic insight is that, whereas Sarraute et al. (2011) model the uncertainty as non-deterministic actions\u2014success probabilities of exploits\u2014this uncertainty is more naturally modeled as an uncertainty about states. The exploits as such are deterministic in that their outcome is fully determined by the system configuration.2 Once this basic modeling choice is made, all the rest falls into place naturally. Our experiments are based on a problem generator that is not industrial-scale realistic, but that allows to create reasonable test instances by scaling the number of machines, the number of possible exploits, and the time elapsed since the last activity of the pentesting tool. Unsurprisingly, we find that POMDP solvers do not scale to large networks. However, scaling is reasonable for individual pairs of machines. As argued by Sarraute et al. (2011), such pairwise strategies can serve as the basic building blocks in a framework decomposing the overall problem into two abstraction levels.", "startOffset": 38, "endOffset": 1801}, {"referenceID": 12, "context": "POMDPs are usually defined (Monahan 1982; Cassandra 1998) by a tuple \u3008S,A,O, T,O, r, b0\u3009 where, at any time step, the system being in some state s \u2208 S (the state space), the agent performs an action a \u2208 A (the action space) that results in (1) a transition to a state s\u2032 according to the transition function T (s, a, s\u2032) = Pr(s\u2032|s, a), (2) an observation o \u2208 O (the observation space) according to the observation function O(s\u2032, a, o) = Pr(o|s\u2032, a) and (3) a scalar reward r(s, a).", "startOffset": 27, "endOffset": 57}, {"referenceID": 6, "context": "POMDPs are usually defined (Monahan 1982; Cassandra 1998) by a tuple \u3008S,A,O, T,O, r, b0\u3009 where, at any time step, the system being in some state s \u2208 S (the state space), the agent performs an action a \u2208 A (the action space) that results in (1) a transition to a state s\u2032 according to the transition function T (s, a, s\u2032) = Pr(s\u2032|s, a), (2) an observation o \u2208 O (the observation space) according to the observation function O(s\u2032, a, o) = Pr(o|s\u2032, a) and (3) a scalar reward r(s, a).", "startOffset": 27, "endOffset": 57}, {"referenceID": 2, "context": "Bellman\u2019s principle of optimality (Bellman 1954) lets us compute this function recursively through the value function", "startOffset": 34, "endOffset": 48}, {"referenceID": 9, "context": "For our experiments we use SARSOP (Kurniawati et al. 2008), a state of the art point-based algorithm, i.", "startOffset": 34, "endOffset": 58}, {"referenceID": 10, "context": "In comparison, classical planning approaches (Lucangeli et al. 2010) assume that the whole network configuration is known, so that no exploration is required.", "startOffset": 45, "endOffset": 68}, {"referenceID": 13, "context": "This is different from modeling the uncertainty in pentesting using probabilistic action outcomes as in (Sarraute et al. 2011), which does not account for the real dynamics of the system.", "startOffset": 104, "endOffset": 126}, {"referenceID": 10, "context": "In comparison, classical planning approaches (Lucangeli et al. 2010) assume that the whole network configuration is known, so that no exploration is required. The present section discusses how to formalize penetration testing using POMDPs. As we shall see, the uncertainty is located essentially in the initial belief state. This is different from modeling the uncertainty in pentesting using probabilistic action outcomes as in (Sarraute et al. 2011), which does not account for the real dynamics of the system. Also, as indicated previously, unlike our POMDPs, the approach of Sarraute et al. (2011) only chooses exploits, assuming a naive a priori knowledge acquisition and thus ignoring the interaction between these two.", "startOffset": 46, "endOffset": 602}, {"referenceID": 11, "context": "Tests Tests are typically performed using programs such as nmap (Lyon 1998), which scans a specific computer for open ports and, by analyzing the response behavior of ports, allows to make guesses about which OS and services are running.", "startOffset": 64, "endOffset": 75}, {"referenceID": 10, "context": "Lucangeli et al. (2010), proceed by first performing a port scan on common ports, then executing OS detection module(s), and finally launching exploits for potentially vulnerable services.", "startOffset": 0, "endOffset": 24}, {"referenceID": 10, "context": "Lucangeli et al. (2010), proceed by first performing a port scan on common ports, then executing OS detection module(s), and finally launching exploits for potentially vulnerable services. With our POMDP model, the policy obtained is to first test whether port 80 is open, because the expected reward is greater for the two exploits which target port 80, than for each of the exploits for port 21 or 22. If port 80 is open, the next action is to launch the IIS exploit for port 80, skipping the OS detection because Windows is more probable than Linux, and the additional information that OS Detect can provide doesn\u2019t justify its cost (additional running time). If the exploit is successful, terminate. Otherwise, continue with the Apache exploit (not probing port 80 since that was already done), and if that fails then probe port 21, etc. In summary, the policy orders exploits by promise, and executes port probe and OS detection actions on demand where they are cost-effective. This improves on Sarraute et al. (2011), whose technique is capable only of ordering exploits by promise.", "startOffset": 0, "endOffset": 1023}, {"referenceID": 10, "context": "POMDPs can model pentesting more naturally and accurately than previously proposed planning-based models (Lucangeli et al. 2010; Sarraute et al. 2011).", "startOffset": 105, "endOffset": 150}, {"referenceID": 13, "context": "POMDPs can model pentesting more naturally and accurately than previously proposed planning-based models (Lucangeli et al. 2010; Sarraute et al. 2011).", "startOffset": 105, "endOffset": 150}, {"referenceID": 5, "context": ", (Bonet 2009)).", "startOffset": 2, "endOffset": 14}, {"referenceID": 8, "context": "Both could potentially be adressed by learning appropriate graphical models (Koller and Friedman 2009), based on up-to-date real-world statistics.", "startOffset": 76, "endOffset": 102}, {"referenceID": 8, "context": "POMDPs can model pentesting more naturally and accurately than previously proposed planning-based models (Lucangeli et al. 2010; Sarraute et al. 2011). While, in general, scaling is limited, we have seen that it appears reasonable in the 2-machines case where we are considering only how to get from one machine to another. An idea to use POMDP reasoning in practice is thus to perform it for all connected pairs of machines in the network, and thereafter use these solutions as the input for a high-level planning procedure. That procedure would consider the pairwise solutions to be atomic, i.e., no backtracking over these decisions would be made. Indeed, this is one of the abstractions made\u2014successfully, as far as runtime performance is concerned\u2014by Sarraute et al. (2011). Our immediate future work will be to explore whether a POMDP-based solution of this type is useful, the question being how large the overhead for planning all pairs is, and how much of the solution quality gets retained at the global level.", "startOffset": 106, "endOffset": 779}], "year": 2013, "abstractText": "Penetration Testing is a methodology for assessing network security, by generating and executing possible attacks. Doing so automatically allows for regular and systematic testing without a prohibitive amount of human labor. A key question then is how to generate the attacks. This is naturally formulated as a planning problem. Previous work (Lucangeli et al. 2010) used classical planning and hence ignores all the incomplete knowledge that characterizes hacking. More recent work (Sarraute et al. 2011) makes strong independence assumptions for the sake of scaling, and lacks a clear formal concept of what the attack planning problem actually is. Herein, we model that problem in terms of partially observable Markov decision processes (POMDP). This grounds penetration testing in a well-researched formalism, highlighting important aspects of this problem\u2019s nature. POMDPs allow to model information gathering as an integral part of the problem, thus providing for the first time a means to intelligently mix scanning actions with actual exploits.", "creator": "TeX"}}}