{"id": "1306.6302", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jun-2013", "title": "Solving Relational MDPs with Exogenous Events and Additive Rewards", "abstract": "We formalize a simple but natural subclass of service domains for relational planning problems with object-centered, independent exogenous events and additive rewards capturing, for example, problems in inventory control. Focusing on this subclass, we present a new symbolic planning algorithm which is the first algorithm that has explicit performance guarantees for relational MDPs with exogenous events. In particular, under some technical conditions, our planning algorithm provides a monotonic lower bound on the optimal value function. To support this algorithm we present novel evaluation and reduction techniques for generalized first order decision diagrams, a knowledge representation for real-valued functions over relational world states. Our planning algorithm uses a set of focus states, which serves as a training set, to simplify and approximate the symbolic solution, and can thus be seen to perform learning for planning. A preliminary experimental evaluation demonstrates the validity of our approach.", "histories": [["v1", "Wed, 26 Jun 2013 17:59:49 GMT  (1022kb,D)", "https://arxiv.org/abs/1306.6302v1", "This is an extended version of our ECML/PKDD 2013 paper including all proofs"], ["v2", "Thu, 27 Jun 2013 13:57:19 GMT  (1022kb,D)", "http://arxiv.org/abs/1306.6302v2", "This is an extended version of our ECML/PKDD 2013 paper including all proofs. (v2 corrects typos and updates ref [10] to cite this report as the full version)"]], "COMMENTS": "This is an extended version of our ECML/PKDD 2013 paper including all proofs", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["s joshi", "r khardon", "p tadepalli", "a raghavan", "a fern"], "accepted": false, "id": "1306.6302"}, "pdf": {"name": "1306.6302.pdf", "metadata": {"source": "CRF", "title": "Solving Relational MDPs with Exogenous Events and Additive Rewards", "authors": ["Saket Joshi", "Roni Khardon", "Prasad Tadepalli", "Aswin Raghavan", "Alan Fern"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Preliminaries: Relational Symbolic Dynamic Programming", "text": "In fact, it is a purely mental game, in which the aim is to find a solution that is capable of finding a solution that meets the needs of the individual."}, {"heading": "3 Model and Algorithms for Service Domains", "text": "We assume that our extensions to SDP to handle exogenous events. Exogenous events refer to spontaneous changes of state without action. Our main modeling assumptions, called A1, are that we have object-related exogenous actions that are taken automatically in each and every step. In particular, we are able to take measures that affect object i and the conditions and effects of {E (i)} in such a way that they do not affect each other."}, {"heading": "3.1 The Template Method", "text": "In fact, it is the case that most of them are able to survive themselves if they do not abide by the rules. (...) In fact, it is the case that most of them are unable to abide by the rules. (...) It is not the case that they have to abide by the rules. (...) It is the case that they have to abide by the rules. (...) \"\" It is the case that they do not have to abide by the rules. (...) \"(...)\" (...) \"(...)\" (...) \"(...\") \"((...)\" (() \"(...)\" (() () (()) () () () () () () () () () ()) () () ()) () () () () ()) () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () ()) () () () () () () ()) () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () () () (() () () () (() (() () () (() () () (() () () (() () ((() () () (() () () (() () () () () () () ((() (() (() () () (() () () ((() () ((() () () (() () ("}, {"heading": "4 Evaluation and Reduction of GFODDs", "text": "The symbolic operations in the SDP algorithm yield are redundant in the sense that parts of them can be removed without changing the values they compute. Lately, we have introduced the idea of model verification to compress such diagrams. The basic idea is obviously simple. In view of a series of \"focus states\" S, we evaluate the diagram for each interpretation in S. Any part of the diagram that does not \"contribute to the final value of this idea\" is removed. The result is a diagram that refers exactly to the focus states, but can be approximate to other states. We refer the reader to [8,7] for further motivation and justification. In this work, several variants of this idea have been formally analyzed (for max and min aggregation), it has been shown that we have been developed well empirically (for max aggregated), and methods for generalizing S via random paths."}, {"heading": "5 Experimental Validation", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "6 Conclusions", "text": "The paper presents service areas as abstraction of planning problems with additive rewards and multiple simultaneous but independent exogenous events. We provide a new relational SDP algorithm and the first complete analysis of such an algorithm with verifiable guarantees. In particular, our algorithm, the template method, guarantees a monotonous lower limit of the real value function under some technical conditions. We have also shown that this lower limit lies between the value of straight line plans and the real value function. As a second contribution, we introduce new evaluation and reduction algorithms for GFODD representation, which in turn facilitate the efficient implementation of the SDP algorithm. Preliminary experiments show the feasibility of our approach and that our algorithm can also be applied in situations that violate some of the assumptions used in the analysis. The paper provides a first step to analyze and solve common problems with exogenous events by focusing on a well-defined subset of such models."}, {"heading": "8 Proof of Theorem 1 (Monotonic Lower Bound)", "text": "The proof of Lemma 1 and the following text imply that we have for all V satisfactory A1-A4 T \u2032 [V] \u2264 T [V]. Well, if R is not negative, V0 = R and Vi + 1 = T \u2032 [Vi] this implies that we have for all i T \u2032 [Vi] \u2264 T [Vi] \u2264 V \u0445. Next, we show that we have under the same conditions on V0 and R for all iVi \u2264 T \u2032 [Vi] = Vi + 1. (3) Combining the two, we get Vi \u2264 Vi + 1 = T \u2032 [Vi] \u2264 T [Vi] \u2264 V \u0445 as needed. We prove equality (3) by induction on i. For the initial case it is obvious that V0 \u2264 V1, because V0 = R and V1 = R + W, where W is the regressed and discounted value function, which is guaranteed not negative."}, {"heading": "9 Proof of Observation 1 (Relation to Straight Line Plans)", "text": "Consider the regression overE (k) and the source of the approximation in the sequential argument where we do not standardize apart. If we treat Vn as the value function of the next step, we grasp the ability to take the best action in the next state achieved after the current exogenous action. Now, by calculating ma\u00dfavgy [(f1 (x, y) + f2 (x, y))] the choice of the next action (determined by x), without knowing which action variant Ej (k) has taken place. Effectively, we have pushed the expectation variant via the action variants Ej (x, y) + f2 (x, y)]] into the maximum measures for the next step. Well, because this is done for all k, and for each iteration of the value drive maxx.The result is comparable to the true m step to explicitly exceed the value."}, {"heading": "10 Preparation for Proof of Theorem 2 (Correctness of Model Evaluation Algorithm)", "text": "We start by determining the accuracy of the evaluation step alone without specializing in maxx avgy aggregation and the additional steps for reductions.The pseudo code for the evaluation step was given above. Note that the two children of the node n may have aggregated different sets of variables (due to additional parents).Therefore, we will aggregate the table from each page separately in the code (down to maxvar (n) + 1) before we take the merge. Once the two sides are combined, we need to aggregate the variables between maxvar (n) + 1 and maxabove (n) + 1 before we return the table.We have the following values returned by the evaluation procedure is exactly mapB (I).Proof. Given a node n, we have the value of maxabove (n), and a concrete substitution of variables z1 to zmaxabove (n)."}, {"heading": "11 Proof of Theorem 2 (Correctness of Edge Marking in Model Evaluation Algorithm)", "text": "We start by giving a more detailed version of the algorithmic enhancement of the edgeband capture algorithm, but this is not the case. (1) If we select the number of edges for the new entry, the number of edges for the new entry is unfilled in all the entries in all entries. (3) If a node varies the number of edges for the new entry, the number of edges for the new entry is identical. (3) If a node varies the number of edges for the new entry, the number of edges is the smallest is lexicographic. (4) A leaf node reverses the lexicographic set as its edgeband the proof of theorem 2 is similar in that we define property and prove that it is."}], "references": [{"title": "Algebraic decision diagrams and their applications", "author": ["R. Bahar", "E. Frohm", "C. Gaona", "G. Hachtel", "E. Macii", "A. Pardo", "F. Somenzi"], "venue": "Proceedings of the IEEE/ACM International Conference on Computer-Aided Design. pp. 188\u2013191", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "Decision-theoretic planning: Structural assumptions and computational leverage", "author": ["C. Boutilier", "T. Dean", "S. Hanks"], "venue": "Journal of Artificial Intelligence Research 11, 1\u201394", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Symbolic dynamic programming for first-order MDPs", "author": ["C. Boutilier", "R. Reiter", "B. Price"], "venue": "Proceedings of the International Joint Conference of Artificial Intelligence. pp. 690\u2013700", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2001}, {"title": "Efficient solution algorithms for factored MDPs", "author": ["C. Guestrin", "D. Koller", "R. Parr", "S. Venkataraman"], "venue": "Journal of Artificial Intelligence Research 19, 399\u2013468", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "SPUDD: Stochastic planning using decision diagrams", "author": ["J. Hoey", "R. St-Aubin", "A. Hu", "C. Boutilier"], "venue": "Proceedings of Uncertainty in Artificial Intelligence. pp. 279\u2013288", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1999}, {"title": "FluCaP: a heuristic search planner for firstorder MDPs", "author": ["S. H\u00f6lldobler", "E. Karabaev", "O. Skvortsova"], "venue": "Journal of Artificial Intelligence Research 27, 419\u2013439", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Self-Taught decision theoretic planning with first-order decision diagrams", "author": ["S. Joshi", "K. Kersting", "R. Khardon"], "venue": "Proceedings of the International Conference on Automated Planning and Scheduling. pp. 89\u201396", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Decision theoretic planning with generalized first order decision diagrams", "author": ["S. Joshi", "K. Kersting", "R. Khardon"], "venue": "Artificial Intelligence 175, 2198\u20132222", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic relational planning with first-order decision diagrams", "author": ["S. Joshi", "R. Khardon"], "venue": "Journal of Artificial Intelligence Research 41, 231\u2013266", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Solving relational MDPs with exogenous events and additive rewards", "author": ["S. Joshi", "R. Khardon", "P. Tadepalli", "A. Raghavan", "A. Fern"], "venue": "CoRR abs/1306.6302", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Bellman goes relational", "author": ["K. Kersting", "M. van Otterlo", "L. De Raedt"], "venue": "Proceedings of the International Conference on Machine Learning. pp. 465\u2013472", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Bounded real-time dynamic programming: RTDP with monotone upper bounds and performance guarantees", "author": ["H.B. McMahan", "M. Likhachev", "G.J. Gordon"], "venue": "Proceedings of the International Conference on Machine Learning. pp. 569\u2013576", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming", "author": ["M.L. Puterman"], "venue": "Wiley", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1994}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S. Russell", "P. Norvig"], "venue": "Prentice Hall Series in Artificial Intelligence", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "First-order decision-theoretic planning in structured relational environments", "author": ["S. Sanner"], "venue": "Ph.D. thesis, University of Toronto", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Relational dynamic influence diagram language (RDDL): Language description http://users.cecs.anu.edu.au/\u223csanner/IPPC 2011/RDDL.pdf", "author": ["S. Sanner"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Approximate solution techniques for factored first-order MDPs", "author": ["S. Sanner", "C. Boutilier"], "venue": "Proceedings of the International Conference on Automated Planning and Scheduling. pp. 288\u2013295", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "Practical solution techniques for first-order MDPs", "author": ["S. Sanner", "C. Boutilier"], "venue": "Artificial Intelligence 173, 748\u2013788", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Approximate dynamic programming with affine ADDs", "author": ["S. Sanner", "W. Uther", "K. Delgado"], "venue": "Proceeding of the International Conference on Autonomous Agents and Multiagent Systems. pp. 1349\u20131356", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "First-Order decision diagrams for relational MDPs", "author": ["C. Wang", "S. Joshi", "R. Khardon"], "venue": "Journal of Artificial Intelligence Research 31, 431\u2013472", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 4, "context": ", using algebraic decision diagrams (ADDs) [5] or linear function approximation [4].", "startOffset": 43, "endOffset": 46}, {"referenceID": 3, "context": ", using algebraic decision diagrams (ADDs) [5] or linear function approximation [4].", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": "This approach can easily model exogenous events [2] but it plans for a fixed domain size and requires increased time and space due to the grounding.", "startOffset": 48, "endOffset": 51}, {"referenceID": 2, "context": "The relational (first order logic) SDP approach [3] provides a solution which is independent of the domain size, i.", "startOffset": 48, "endOffset": 51}, {"referenceID": 16, "context": "To our knowledge, the only work to have approached this is [17,15].", "startOffset": 59, "endOffset": 66}, {"referenceID": 14, "context": "To our knowledge, the only work to have approached this is [17,15].", "startOffset": 59, "endOffset": 66}, {"referenceID": 7, "context": "Our second main contribution provides algorithmic support to implement this algorithm using the GFODD representation of [8].", "startOffset": 120, "endOffset": 123}, {"referenceID": 4, "context": "Our results demonstrate that the new algorithm can be implemented efficiently, that its size-independent solution scales much better than propositional approaches [5,19], and that it produces high quality policies.", "startOffset": 163, "endOffset": 169}, {"referenceID": 18, "context": "Our results demonstrate that the new algorithm can be implemented efficiently, that its size-independent solution scales much better than propositional approaches [5,19], and that it produces high quality policies.", "startOffset": 163, "endOffset": 169}, {"referenceID": 13, "context": "We assume familiarity with basic notions of Markov Decision Processes (MDPs) and First Order Logic [14,13].", "startOffset": 99, "endOffset": 106}, {"referenceID": 12, "context": "We assume familiarity with basic notions of Markov Decision Processes (MDPs) and First Order Logic [14,13].", "startOffset": 99, "endOffset": 106}, {"referenceID": 2, "context": "The state transitions induced by agent actions are modeled exactly as in previous SDP work [3].", "startOffset": 91, "endOffset": 94}, {"referenceID": 7, "context": "In this paper we use the GFODD representation of [8] but the same ideas work for any representation that can express open-expressions and closed expressions over interpretations (states).", "startOffset": 49, "endOffset": 52}, {"referenceID": 0, "context": "As in propositional diagrams [1], for efficiency reasons, the order over nodes in the diagram must conform to a fixed ordering over node labels, which are first order atoms in our case.", "startOffset": 29, "endOffset": 32}, {"referenceID": 7, "context": "The work in [8] showed that if the binary operation is safe, i.", "startOffset": 12, "endOffset": 15}, {"referenceID": 19, "context": "The Apply procedure [20,8] calculates a diagram representing f(x) + g(y) using operations over the graphs representing f(x) and g(y).", "startOffset": 20, "endOffset": 26}, {"referenceID": 7, "context": "The Apply procedure [20,8] calculates a diagram representing f(x) + g(y) using operations over the graphs representing f(x) and g(y).", "startOffset": 20, "endOffset": 26}, {"referenceID": 7, "context": "The SDP algorithm of [8] generalizing [3] calculates one iteration of value iteration as follows.", "startOffset": 21, "endOffset": 24}, {"referenceID": 2, "context": "The SDP algorithm of [8] generalizing [3] calculates one iteration of value iteration as follows.", "startOffset": 38, "endOffset": 41}, {"referenceID": 2, "context": "Note that in contrast to other representations of planning operators (but similar to the successor state axioms of [3]) TVDs specify the truth value after the action and not the change in truth value.", "startOffset": 115, "endOffset": 118}, {"referenceID": 19, "context": "Following [20,8] we require that Pr(Aj(x)|A(x)) and T (Aj(x), p(y)) have no aggregations and cannot introduce new variables, that is, the first refers to x only and the second to x and y but no other variables.", "startOffset": 10, "endOffset": 16}, {"referenceID": 7, "context": "Following [20,8] we require that Pr(Aj(x)|A(x)) and T (Aj(x), p(y)) have no aggregations and cannot introduce new variables, that is, the first refers to x only and the second to x and y but no other variables.", "startOffset": 10, "endOffset": 16}, {"referenceID": 7, "context": "The SDP algorithm of [8] implements Eq (1) using the following 4 steps.", "startOffset": 21, "endOffset": 24}, {"referenceID": 19, "context": "To maintain the diagrams sorted we must in fact use a different implementation than block replacement; the implementation does not affect the constructions or proofs in the paper and we therefore refer the reader to [20] for the details.", "startOffset": 216, "endOffset": 220}, {"referenceID": 19, "context": "As argued by [20], to guarantee correctness, both summation steps (\u2295j and R\u2295 steps) must standardize apart the functions before adding them.", "startOffset": 13, "endOffset": 17}, {"referenceID": 10, "context": "Several instantiations of this idea have been implemented [11,6,18,20].", "startOffset": 58, "endOffset": 70}, {"referenceID": 5, "context": "Several instantiations of this idea have been implemented [11,6,18,20].", "startOffset": 58, "endOffset": 70}, {"referenceID": 17, "context": "Several instantiations of this idea have been implemented [11,6,18,20].", "startOffset": 58, "endOffset": 70}, {"referenceID": 19, "context": "Several instantiations of this idea have been implemented [11,6,18,20].", "startOffset": 58, "endOffset": 70}, {"referenceID": 7, "context": "Except for the work of [8,18] previous work has handled only max aggregation.", "startOffset": 23, "endOffset": 29}, {"referenceID": 17, "context": "Except for the work of [8,18] previous work has handled only max aggregation.", "startOffset": 23, "endOffset": 29}, {"referenceID": 7, "context": "Previous work [8] relies on the fact that the binary operations \u2295, \u2297, and max are safe with respect to max,min aggregation to", "startOffset": 14, "endOffset": 17}, {"referenceID": 16, "context": "complex expressions that require counting formulas over the domain [17,15].", "startOffset": 67, "endOffset": 74}, {"referenceID": 14, "context": "complex expressions that require counting formulas over the domain [17,15].", "startOffset": 67, "endOffset": 74}, {"referenceID": 9, "context": "This proof and other omitted details can be found in the full version of this paper [10].", "startOffset": 84, "endOffset": 88}, {"referenceID": 9, "context": "An additional argument (details available in [10]) shows that this is a monotonic lower bound, that is, for all i we have T [Vi] \u2265 Vi where T [V ] is the true Bellman backup.", "startOffset": 45, "endOffset": 49}, {"referenceID": 11, "context": ", [12]) that if this holds then the value of the greedy policy w.", "startOffset": 2, "endOffset": 6}, {"referenceID": 1, "context": ", discussion in [2]) does not calculate a policy and instead at any state it seeks the best", "startOffset": 16, "endOffset": 19}, {"referenceID": 9, "context": "As the next observation argues (proof available in [10]) the template method provides a related approximation.", "startOffset": 51, "endOffset": 55}, {"referenceID": 7, "context": "Recently, [8,7] introduced the idea of model checking reductions to compress such diagrams.", "startOffset": 10, "endOffset": 15}, {"referenceID": 6, "context": "Recently, [8,7] introduced the idea of model checking reductions to compress such diagrams.", "startOffset": 10, "endOffset": 15}, {"referenceID": 7, "context": "We refer the reader to [8,7] for further motivation and justification.", "startOffset": 23, "endOffset": 28}, {"referenceID": 6, "context": "We refer the reader to [8,7] for further motivation and justification.", "startOffset": 23, "endOffset": 28}, {"referenceID": 9, "context": "The next theorem is proved by induction over the structure of the GFODD (details available in [10]).", "startOffset": 94, "endOffset": 98}, {"referenceID": 8, "context": "To that end we implemented our algorithms in Prolog as an extension of the FODD-PLANNER [9], and compared it to SPUDD [5] and MADCAP [19] that take advantage of propositionally factored state spaces, and implement VI using propositional algebraic decision diagrams (ADD) and affine ADDs respectively.", "startOffset": 88, "endOffset": 91}, {"referenceID": 4, "context": "To that end we implemented our algorithms in Prolog as an extension of the FODD-PLANNER [9], and compared it to SPUDD [5] and MADCAP [19] that take advantage of propositionally factored state spaces, and implement VI using propositional algebraic decision diagrams (ADD) and affine ADDs respectively.", "startOffset": 118, "endOffset": 121}, {"referenceID": 18, "context": "To that end we implemented our algorithms in Prolog as an extension of the FODD-PLANNER [9], and compared it to SPUDD [5] and MADCAP [19] that take advantage of propositionally factored state spaces, and implement VI using propositional algebraic decision diagrams (ADD) and affine ADDs respectively.", "startOffset": 133, "endOffset": 137}, {"referenceID": 15, "context": "translated into propositional descriptions using software provided for the IPPC 2011 planning competition [16].", "startOffset": 106, "endOffset": 110}], "year": 2013, "abstractText": "We formalize a simple but natural subclass of service domains for relational planning problems with object-centered, independent exogenous events and additive rewards capturing, for example, problems in inventory control. Focusing on this subclass, we present a new symbolic planning algorithm which is the first algorithm that has explicit performance guarantees for relational MDPs with exogenous events. In particular, under some technical conditions, our planning algorithm provides a monotonic lower bound on the optimal value function. To support this algorithm we present novel evaluation and reduction techniques for generalized first order decision diagrams, a knowledge representation for realvalued functions over relational world states. Our planning algorithm uses a set of focus states, which serves as a training set, to simplify and approximate the symbolic solution, and can thus be seen to perform learning for planning. A preliminary experimental evaluation demonstrates the validity of our approach.", "creator": "LaTeX with hyperref package"}}}