{"id": "1306.6649", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2013", "title": "Measurements of collective machine intelligence", "abstract": "Independent from the still ongoing research in measuring individual intelligence, we anticipate and provide a framework for measuring collective intelligence. Collective intelligence refers to the idea that several individuals can collaborate in order to achieve high levels of intelligence. We present thus some ideas on how the intelligence of a group can be measured and simulate such tests. We will however focus here on groups of artificial intelligence agents (i.e., machines). We will explore how a group of agents is able to choose the appropriate problem and to specialize for a variety of tasks. This is a feature which is an important contributor to the increase of intelligence in a group (apart from the addition of more agents and the improvement due to common decision making). Our results reveal some interesting results about how (collective) intelligence can be modeled, about how collective intelligence tests can be designed and about the underlying dynamics of collective intelligence. As it will be useful for our simulations, we provide also some improvements of the threshold allocation model originally used in the area of swarm intelligence but further generalized here.", "histories": [["v1", "Thu, 27 Jun 2013 20:10:45 GMT  (1152kb,D)", "http://arxiv.org/abs/1306.6649v1", "78 pages"]], "COMMENTS": "78 pages", "reviews": [], "SUBJECTS": "cs.AI cs.MA", "authors": ["michel halmes"], "accepted": false, "id": "1306.6649"}, "pdf": {"name": "1306.6649.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "Master in Computer EngineeringMaster ThesisMeasurements of collective machine intelligenceStudent: Michel Halmes Universite \u0301 Libre de BruxellesSupervisor: Prof. Jose \u0301 ndez-OralloJuly 1, 2013ar Xiv: 130 6.66 49v1 [cs.AI] 27 Jun 2013Thank you to my superior Prof. Jose Hernandez-Orallo for supporting my master thesis throughout the year. I thank you for the time you have considered for this project and for your constructive comments that have guided my work. Finally, I would also like to thank the many people who made my Erasmus year in Valencia an unforgettable time.AbstractIntelligence is a fairly intuitive concept of our everyday life. As usual, ac-knowledged in psychometry, intelligence is the ability that is measured by intelligence tests."}, {"heading": "1 Goal statement and overview 6", "text": "1.1......................................................................."}, {"heading": "2 Intelligence and intelligence tests 8", "text": "2.1 Psychometrics, IQ tests and comparative cognition....... 8 2.2 Turing test......................................... 9 2.3 Inductive inference.............................."}, {"heading": "3 Collective intelligence 14", "text": "3.1 A few words on social intelligence............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "4 An approach based on abstracted intelligence, vote aggregation and task allocation 21", "text": "4.1 Conceptualization of \"intelligence\"............... 224.1.1 Abstraction of information processing capabilities: item response functions................ 224.1.2 Summary of group capabilities: voting systems.... 24 4.2 Introduction of social aspects......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"}, {"heading": "5 Experiments 30", "text": "The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies. The proxies."}, {"heading": "6 Analysis of the results 58", "text": "6.1. Modeling of intelligence......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "7 Discussions for future work 63", "text": "7.1 Use of Agent Capability in Resource Allocation Process....... 63 7.2 Individual Response Peaks................... 64 7.3 Different Types of Problems........................ 65 7.4 Intelligence Influencing Allocation Capacity.......... 65 7.5 Asymptotic Performance Worse Than Random............ 66"}, {"heading": "8 Conclusion 68", "text": "Bibliography & Attachments 69Bibliography 69"}, {"heading": "A Appendices 74", "text": "A.1 Proof of equation (5.3)......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "1.1 Goal statement", "text": "The aim of this master's thesis is to experiment with models of collective abstraction of machine intelligence in order to observe some interesting phenomena in the intellectual abilities of several collaborating machines. In other words, we would like to analyze the dynamics underlying a group of AI agents that collectively solve a problem that \"requires a minimum level of intelligence.\" The results of such a study could be very useful for the development of collective intelligence tests when combined methods are used to measure individual intelligence. Questions that are of interest in this context include: \u2022 Can the intelligence of a group be significantly higher than the intelligence of the (most intelligent) agents in the group (with positive influence from collaboration)? \u2022 Can it be smaller (with negative impact from disruption)? \u2022 How should agents aggregate their skills? What common decision-making system is best suited? Is it advantageous to provide agents with a measure of relative intelligence from the group, as they must perform multiple tasks at the same time?"}, {"heading": "1.2 Overview", "text": "We start with the definition of the concept of intelligence and present the main approaches and associated formalities for measuring this intelligence (Chapter 2), and then we present the concept of collective intelligence (Chapter 3). We focus mainly on collective intelligence for machines. However, we also mention related concepts for humans, such as the wisdom of the masses and social intelligence. In Chapter 4 we explain the approach to simulating a collective intelligence test. Therefore, we explain how we model the test problems and how we introduce social aspects into the test. Afterwards, we conduct some experiments (Chapter 5). We have several experimental setups, each of which is explained first and then analyzed and interpreted. In Chapter 6 we analyze the results from a more integrated perspective. In Chapter 7 we explain some additional setups that might be interesting for future work. Finally, we conclude with a look at what goals have been achieved and deliver the message from this report. Chapter 2 Intelligence and intelligence tests In this chapter, we briefly define the concept of both intelligence and informatics from the point of view."}, {"heading": "2.1 Psychometrics, IQ tests and comparative cog-", "text": "The concept of intelligence is quite intuitive for all of us. It describes the ability of subjects - humans, but also animals or machines - to perform cognitive tasks. What exactly intelligence is and what cognitive tasks exactly reflect intelligence is less clear. However, the most commonly accepted measure of intelligence is the so-called intelligence quotient (IQ), which is in fact the normalized test score achieved in an IQ test. Consequently, \"intelligence is the ability measured by the IQ test.\" IQ tests are designed by psychologists; more precisely, those working in the field of psychometry. Typically, the IQ test measures abstract thinking skills. The problems of the test largely relate to skills such as verbal understanding, vocabulary, spatial visualization, associative memory, perceptual speed, reasoning and induction. In 1904, psychologist Spearman discovered a positive correlation between the performances in these various tasks."}, {"heading": "2.2 The Turing test", "text": "The Turing test expresses how far a computer is capable of resembling a human being. It is named after its famous inventor, who was very concerned about machine intelligence as early as 1950. Turing [57], for example, asked if computers would one day be able to \"think.\" He was convinced that they could one day do so. Since the definition of \"thinking\" is again quite abstract, he envisioned the following test, which he originally called an imitation game. In this test, a human judge conducts a written conversation with a human and a machine without knowing who it is. If a machine were to be built in the future in such a way that the judge could not clearly distinguish the machine from a human, Turing argued that the machine could \"think\" and that it had reached human intelligence. Over time, other versions of the Turing test were invented to compare machines with humans."}, {"heading": "2.3 Inductive inference", "text": "A more recent approach is to use inductive conclusions for the development of intelligence tests, i.e. for the measurement and definition of intelligence. [24, 20, 37] In inductive consequence tests, the evaluator - a human, an animal or a machine - will actually take a non-random sequence of characters x = {x1, x2,.} Usually, but not necessarily, these characters are taken as bits. The evaluator must then learn the underlying pattern of this sequence and begin to predict the next string x = {x1, x2,.) If we are correct on all predictions from a certain moment on, we say that the evaluator has learned to predict the sequence. The advantage of using inductive conclusions is that we mathematically plan it. This formalism comes from the algorithmic information theory developed by Kolmogorov [32], Chaitin [9] and Solomonoff [52]."}, {"heading": "3.1 A few words on social intelligence", "text": "The idea of social intelligence [8] was first mentioned by Thorndike [56]. However, he distinguished three facets of intelligence: the ability to understand and manage ideas (abstract intelligence), concrete objects (mechanical intelligence) and people (social intelligence). Many authors have since discussed social aspects of intelligence. Vernon [58] defines them as \"the ability to cope with people in general, social techniques or ease in society, knowledge of social affairs, receptivity to stimuli from other members of a group, as well as insight into transient moods or underlying personality traits of strangers.\" Soon, the first social intelligence tests emerged. The first such test was the George Washington Social Intelligence Test (GWSIT) [44]. This test is chapter 3. Collective intelligence and ideas \u2022 \u2022 The wisdom of the masses is composed of a series of subtests, which are combined to provide an aggregate index of social intelligence, ideas, ideas, intellect, intellect, intellect, intellects, ideas, and ideas. Aspective aspects that are measured are: Judgment of social situations \u2022 memory \u2022 Ideas \u2022 The names and human faces \u2022 \u2022 Six human observation \u2022 The intellects \u2022 The intellects, faces \u2022 The intellects, faces \u2022 The ideas, faces \u2022 The ideas, faces, faces, faces and observation."}, {"heading": "3.2 The wisdom of the crowds", "text": "Let's leave social intelligence aside for a moment and consider collective intelligence. As mentioned in the introduction to this chapter, the idea behind it is that a group of less intelligent agents can be more intelligent than a very intelligent agent. However, the principle applies equally to man, which is usually referred to as the wisdom of the masses. One of the first of them had chapter 3. Collective intelligence 3.3 Francis Galton used this principle. [18] In 1907, Galton attended a fair where participants had to guess the weight of an ox. The narrowest guess won a prize. However, Galton managed to get his hands on the votes of the people after the contest. The voice of most participants was very different from the real weight. Some participants estimated well below and others way above the weight of the ox. Of the 800 participants, no one suspected the correct value. However, when Galton calculated the mean vote - which he called the value of the people, the voice of the people - he noted."}, {"heading": "3.3 Collective intelligence systems", "text": "In fact, most people who are able to move to another world are moving to another world in which they cannot find themselves."}, {"heading": "3.4 Approaches to collective intelligence design", "text": "There are several approaches to how collective intelligence systems can be designed."}, {"heading": "3.4.1 Reinforcement learning", "text": "A first approach is the use of Reinforcement Learning (RL). In this approach, the reward would be defined as consisting in part of individual benefit and global benefit. However, in many cases, RL is not well suited due to the large scope of action [66], so we will not discuss this approach further."}, {"heading": "3.4.2 Market-based mechanisms", "text": "As mentioned above, the markets are a perfect example of applying the wisdom of the masses (\"collective human intelligence\"). An approach to designing collective intelligence systems is to present the problem to be solved by the group as a market. As an example, let's briefly take the approach of Campos et al. [7]. In this paper, a group of paint booths - the agents - must produce paint finishers from an assembly line. The goal - i.e., world function - is to minimize the overall dimensions of the trucks. Indeed, the trucks must be painted according to customer order. Each paint booth disposes of all colors. However, the change from one color to another requires an additional time to flush out the old paint and fill the booth with the appropriate color. Therefore, the number of color switches should be minimized. Campos et al. [7] present a market-based approach in which each agent makes an offer to paint the truck."}, {"heading": "3.4.3 Swarm intelligence", "text": "These social insects are suitable for the design of collective intelligence, as most of them are based on collective behaviour without centralised control. They are in large populations of self-organised, simple agents. However, most importantly, one can be inspired by social insects, as they use simple but effective communication models. More specifically, social insects - and thus agents of swarm intelligence systems - communicate in two ways. This communication can be established via physical contact (antenna nation), visual contact, chemical contact, etc. Secondly, there is indirect communication about the environment itself."}, {"heading": "3.5 Results from research on human collective", "text": "The main conclusions of such research are essentially identical [42, 67, 68]. When a group of people is faced with a cognitive task, their performance is only very poorly correlated with the average or even the maximum intelligence of their members. Instead, the social aspects of the group members explained the results of the group. Good communication and cooperation between members is more important than the IQ of the members. A first important factor is the social sensitivity of the group members. In groups with high collective intelligence, the members had a high social sensitivity to each other: they paid attention to each other and asked questions. In such groups, too, the members performed very well in the social intelligence tests in which they formatted the others."}, {"heading": "An approach based on", "text": "Abstract Intelligence, Voice Aggregation and Task DistributionAs mentioned in the Objective Statement (1.1), the broad context of this Master's thesis is to develop an intelligence test for groups of AI agents. Of course, such an effort is far too ambitious, especially given the progress made in the field of individual intelligence research. Therefore, the goal of this master's thesis will only be to provide some insights into the dynamics of collective intelligence that may contribute to the development of such a test.Two aspects are crucial for the development of a coherent collective intelligence test: 1. As we have seen in 2.3, the field of research that formally analyses intelligence tends more and more towards defining intelligence as the ability to process information; more precisely compression. The intelligence test for collectives should therefore also be based on similar concepts. However, we will go a step further and make an abstraction that is exactly what the agents are talking about."}, {"heading": "4.1 Conceptualization of \u201cintelligence\u201d", "text": "As already mentioned (2.3), we have some answers to the first question, that is, how to conceptualize \"intelligence.\" The term intelligence must be related to the ability to process / compress information. Kolmogorov complexity provides us with tools to derive a mathematical concept of difficulty that can ultimately be used to measure intelligence. Nevertheless, estimating the Kolmogorov complexity of objects per se (due to the standstill problem) is quite complicated. Besides, we want to analyze every ability and not just intelligence. Therefore, we will make an abstraction of the type of test problem with which we will evaluate the intelligence / abilities of the group. Henceforth, we will no longer talk about \"intelligence,\" but about \"ability.\" In this way, what we are actually modelling could be any kind of test (including, for example, a physical ability)."}, {"heading": "4.1.1 Abstraction from information processing capabilities: Item response functions", "text": "In IRT, probabilities are associated with how a person reacts to an item and refines it, by defining an item-response function (which is actually a set of items), and we will briefly present here the three parameter problems in which, for example, it is useful to provide a framework to analyze how well an evaluation works in order to interpret and refine the results, by defining an item-response function. In this model, the probability that a person succeeds on an item is defined as follows: P (\u03b1) = c + 1 \u2212 c1 + exp [\u2212 b] (4.1), in which the person's abilities and a b and c are the item parameters. You have the following interpretation: a: The discrimination (scale, slope) represents the maximum slope of the reaction function (in terms of the person's ability).In other words, we are actually reflecting a person or person who is not successful."}, {"heading": "4.1.2 Aggregation of a group\u2019s abilities: Voting systems", "text": "Since we are talking about collective intelligence here, we are not only looking at one, but a group of n > 1 agents of the abilities \u03b1 = {\u03b11,., \u03b1n}. We are referring to the group, the entirety of the agents, as N. The individual agents are referred to by i, in order to measure the collective ability / intelligence resulting from the aggregation of the groups, a common decision-making system is required. One of the most general configurations of such a system is, for example, an election scheme. The group is confronted with an evaluation problem of difficulty (e.g. predicting a non-random series of decisions). Each actor will give its answer to the problem (as determined by P\u03bb). The group could then use an absolute majority voting system to determine its answer. The group will correctly solve the problem if more than 50% of the agents have correctly solved it."}, {"heading": "4.2 Introducing social aspects", "text": "We have discussed how to solve intelligence as an abstract problem. We have done this using item-response functions as abstraction, and voting systems as aggregation of skills / intelligence. However, this aggregation is without any form of interaction, cooperation or specialization among agents. Therefore, the second problem reflects the consideration of social aspects. How to include social aspects in machine intelligence tests has not been addressed to a large extent by the academic literature so far. The only exception is a multi-agent extension of the individual intelligence tests carried out in Insa-Cabrera et al, where several attitudes of cooperation and competition are examined. Our work is about collective intelligence, and we will focus on the way in which tasks are assigned."}, {"heading": "4.3 Factors of interest", "text": "As we mentioned in the introduction, we are interested in assessing collective behavior, taking into account some of the following characteristics (or all of them): Number of agents: The number of agents is, of course, one of the most important characteristics to take into account. Agent skills: The level of agent competence (and their diversity) is critical. Number and variety of tasks: We could have considered a task at a time that must be solved by all agents. While this will be one of the situations considered, we will examine the much broader problem that the group needs to solve multiple tasks at the same time. This implies assignment and, if the tasks are different, specialization of agents. Agents Specialization: If different tasks are used, should we have specialized agents? Methods of collective decision-making: If there are more agents than tasks, then some agents will cooperate on the same task."}, {"heading": "5.1 Voting on one problem", "text": "First, we will run the simulations based on a single problem, eliminating the effects of the resource allocation algorithm and focusing on the design of the voting system. What we want to observe is how the group performs compared to the average performance of the agents when they tackle the problem alone. First, we will observe the performance of a completely homogeneous group. As we will theoretically demonstrate, we expect the group to achieve any level of performance because the agents are only slightly better than random, there are a sufficient number of agents, and the agents \"voices are independent. However, if the group is composed of agents with very different degrees of intelligence, we could observe other, more surprising results. For example, we will simulate a situation where a very intelligent agent interacts with many less intelligent agents (and vice versa)."}, {"heading": "5.1.1 Homogeneous group of agents", "text": "To begin with, let us imagine a very simple setup. There will only be one problem, that of different agents with the same capability \u03b1.One can expect that the more agents working on the same problem, the better the accuracy of the group will be. More precisely, in a homogeneous group of agents, the probability that the stochastic process composed of the (independent) answers provided follows a binomial distribution: r1, r2,."}, {"heading": "5.1.2 The impact of adding low performing agents", "text": "The aim here is to test the three electoral systems that we have defined: Majority voting = Majority voting, vote weighting according to \u03b1 and using the optimal weight. In the previous point, the electoral systems are all reduced to the majority (i.e., unweighted) votes as all agents are identical. We must therefore place ourselves in a case of a heterogeneous group in which we will examine a group of very different agents; some have a very high capability 4, which gives them an accuracy close to 100%. Others have a very low one, which makes their decision almost random. We will then observe how each of the common decisions that the system makes is influenced when more and more agents with very low abilities are added. More precisely, we define our unique problem as having a difficulty of more than 10. Our group always includes a \"good\" agent with the capability \u03b1 = 205. \"Then we will successively add\" bad \"agents with the capability \u03b1 = 56. The chart above shows the average accuracy of the group of the P50\" n."}, {"heading": "5.1.3 The impact of adding high performing agents", "text": "Figure 5.3 shows the result for a similar experiment to the previous one. However, we are adding good agents instead of bad agents here. Trivially, the performance for all three systems increases and converges to 100% if we add more good agents. The performance of the weighted systems is better or equal to the unweighted version. Both weighted versions have similar performance, so what exact weight is used is not of great importance here. The only role of the weighting system here is to eliminate the influence that bad agents can have on the voting result. What might surprise us is that the performance of a group, including an even number of good agents, is the same for all voting systems, because if the good agents disagree on the right answer, the bad agent decides on the outcome of the group whether the system is weighted or unweighted. Let's also briefly discuss what happens if the system contains an odd number of good agents. In the unweighted version, it may happen that a group needs a coin flight to determine the vote."}, {"heading": "5.2 Simplified version of the allocation model", "text": "In the previous section, we analyzed the voting systems by working on only one problem. In this section, for the first time, we will present a structure with multiple problems to verify and familiarize ourselves with the correct functioning of the allocation model. However, we will not immediately apply the allocation model as defined in 4.2. We will first use a simplified allocation model, and we will also modify our structure to enforce an \"optimal\" allocation, in order to verify that chapter 5. Experiments 5.2 Simplified version of the multi-problem allocation model is actually able to \"correctly\" assign the agents. We will first address the latter point, and then explain how we simplify the model."}, {"heading": "5.2.1 Imposing an appropriate allocation: specialized agents", "text": "The question, therefore, is how a group should assign itself to maximize its performance. First, we need to define what we understand as a performance measure. As mentioned above in Equation (4.6), the performance of the group can be expressed in such a way that it is currently still an open question in individual intelligence tests (see 2.3). There are an infinite number of ways to define this functionality. Therefore, we will abstract the aggregate measure of performance. Instead, we will define a more intuitive idea of the \"optimal\" mapping. What we will do is to associate a problem with each agent so that the agent systematically functions better because the agent is a \"specialist\" of that problem. \"We will not assign a specialized problem to the\" optimal \"mapping.\""}, {"heading": "5.2.2 A simplified allocation model", "text": "Our model, as it has now been defined, is very complex and includes many parameters, so we need to simplify it. To eliminate a few parameters, we will first work with a model where the reaction thresholds \u03b8ij are static. In order to be largely associated with its appropriate problem, the reaction threshold of the active substance i takes a low value on its appropriate problem and a high value on all others. We will also simplify the rule for updating the stimuli. In order to eliminate at least one parameter, we will no longer consider the term \u03b2nj n. We have previously questioned the usefulness of this term (4,2). Therefore, the updating rule only depends on the average performance of the problem, which in turn depends on the appropriateness of the allocation. Consequently, the simplified updating rule is: Sj, Sj, Sj, Sj, Sj, Sj,..."}, {"heading": "5.2.3 Simulation with specialized agents and the simplified allocation model", "text": "Figure 5.4 shows the percentage of (discrete) time allocated to the agents for their appropriate problem - henceforth given by% Approp - as a function of the ratio \u03b8noApprop \u03b8Approp, i.e. the quotient of the threshold of an inappropriate problem and the corresponding problem 9. Specifically, the values shown here correspond to an average of over 20 runs of a simulation with 1000 time steps. We will simulate two agents, each of which is specialized in a particular of the two problems. This percentage of correct allocation is an interesting value, since it can be considered a substitute for the performance of the agent regardless of the difficulties of the problems. As explained, the agent has a higher ability (3\u03b1) for his appropriate problem, which is why it is better to assign it predominantly to this specific problem. Therefore, the average ability of the agent for his problems with this percentage increases: \u03b2 = 3\u03b1 =% Approp + \u03b1% Approp% Approp (1% is clearly assigned to this problem \u2212 1% is greater than the corresponding problem)."}, {"heading": "5.3 Standard version of the allocation model with", "text": "In this section, we will use the standard version of the threshold model to verify that the model is able to provide us with coherent values of the thresholds. Nevertheless, we will prescribe the appropriate allocation by specializing each agent in the problem. We will then adjust our model until we have reached the appropriate allocation, so we are sure that our parameter setting is correct. We will also discuss the introduction of the term \u03b2nj n into the stimulus update rule."}, {"heading": "5.3.1 Allocation model testing and improvements", "text": "The graph in Figure 5.5 shows the proportion of correct mappings for the four different settings that we will discuss next. (The values we have shown correspond to an average of over 50 runs of a simulation with 1000 time steps.) The simulations are tailored to 2 problems with difficulty problems that actually have an appropriate threshold. (Thus, the accuracy of such agents is 57.6% for an inappropriate problem and 80.3% for their corresponding oneChapter 5. Experiments 5.3 Standard version of the allocation model with specialized agents (a) Standard model with 2 agentsWe use a setup with two specialized agents on two problems (the same as in the previous section). As we can observe, with the default setting of the allocation model, the mapping does not differ from random. Agents are mapped to one of the problems 50% of the time. As we have seen, our mapping model works correctly when the threshold is lower than the threshold of the non-appropriate problems."}, {"heading": "5.3.2 Remark on dynamic environments", "text": "In the previous subsection, we improved our allocation model and confirmed that it works relatively well, i.e. the specialized agents are largely assigned to their appropriate problem. Of course, our goal is not to achieve the best possible allocation model. However, it is important to have a model that works reasonably well in order to gain some insights from our experiments. It might be interesting to present an important aspect of our model: it is dynamic. In the static version of our model, we saw that we come arbitrarily close to a 100% appropriate allocation by making a high value dependent on each other. In the dynamic version, this is not possible because the agents do not know what problem they have."}, {"heading": "5.4 Use of the problems\u2019 difficulties in the allo-", "text": "In other words, the actors did not use information about the difficulties of the problems to assign themselves; this will now change and the difficulties will become widely known. However, we will change the rule of the cyclical adjustment to allow a higher share of the allocation and maintain a systematically higher stimulus for the most difficult problems. To simplify the setup - but without any loss of universality - we assume that there are three levels of difficulty: first, we will make the parameters of the cyclical adjustment dependent on the difficulty: Sj +."}, {"heading": "5.4.1 Simulation", "text": "We perform the following experiment: Our group consists of 12 homogeneous agents with the ability \u03b1 = 5. They must, in fact, be assigned to 3 problems with difficulty \u03bbl = 3; \u03bbm = 5; \u03bbh = 6. Therefore, a single agent would achieve an accuracy of 73.1%, 61.9% and 58.3% or difficulty, respectively. Diagrams in Figure 5.8 show the results of this experiment over 30 different cases of parameter settings. The graph above shows the average group accuracy for the three problems. In this case, we also show the average number of agents assigned to each of the three problems. We analyze four different cases of parameter settings. Case (a) serves as a reference where all parameters have the same values for the three problems. We use the typical parameter values that we use = 4 and \u03b2 = 1.5. In the other cases, we multiply the parameters that we want to increase (\u03b22) by a factor high > 1. Similarly, we multiply the parameters that we want to reduce by a factor."}, {"heading": "5.4.3 Uniform problem weighting", "text": "\"We just saw that we need to provide a measure of difficulty to get the highest possible score, the group needs to know how to solve the individual problems.\" \"We only have the difficulty that the individual problems require more resources than others.\" \"But it's difficult to solve the problems.\" \"It's a problem we can't solve.\" \"It's a problem we can't solve.\" \"It's a problem we can't solve.\" \"It's a problem we have to solve.\" \"It's a problem we can't solve.\" \"It's a problem we have to solve.\" \"It's a problem we don't want to solve.\" \"It's a problem we don't want to solve.\" It's a problem we don't want to solve. \"It's a problem we don't want to solve.\" It's a problem we don't want to solve. \"It's a problem we don't want to solve.\" It's a problem we don't want to solve. \""}, {"heading": "5.5 Use of the agents\u2019 ability in the voting pro-", "text": "In the previous section, we discussed how the group could use information about the difficulties of the problems and whether this measure should actually be made available to the group. We are now doing the same with the competence measurement \u03b1. This information could be used in two ways: firstly, it can be used in the coordination process and secondly in the allocation process. We will leave the latter point to future work and only discuss the first one here. In the coordination process, \u03b1 could be used to give more weight to the smartest actors. In 4.1.2, we have defined three weighting systems: a majority voting system, a proportional weighting system to \u03b1 and the optimal, proportional weighting system to Log P\u03bb (\u03b1i) 1 \u2212 P\u03bb (\u03b1i). We have already discussed these weighting systems in detail in 5.1."}, {"heading": "5.5.1 Should the group be provided with a measure of ability?", "text": "However, there is one question that is still open: To what extent are agents able to judge their own ability, or does it have to be provided by the tester (provided that they are actually known, which is not trivial)? Our answer to this question is similar to that of the previous point 5.4.2, where we argued that Chapter 5. Experiments 5.6 Imitation of agents should not provide information about the testers \"difficulties. Likewise, we argue that the group should not be provided with a competence standard, and the reasons are actually identical to those of the previous point. Firstly, there are (currently) no valid measurements of intelligence. In the case of a monotonically increasing reaction function, our agents can at least be used as a relative measure of ability: it is < the reasons are actually identical to those of the previous point. First, there are (currently) no valid measurements of intelligence."}, {"heading": "5.6 Imitating agents", "text": "Until now, we have assumed that the agents provide their responses independently, which could be considered a very restrictive hypothesis when examining \"collective\" intelligence. Typically, one would expect that cooperation should lead to positive interactions and increase the performance of the group. Indeed, we are now analyzing a form of collaboration that could possibly lead to negative interactions. So far, the agents \"responses follow a binomial15 The individual accuracies of the agents are 50.0%, 50.7%, 53.4%, 57.6%, 61.9%, 65.9% and 69.3% in relation to the respective responses. Chapter 5. Experiments 5.6 Imitation of the agentsprobability distribution, which implies that the responses are independent of each other. First, we will assume that the n agents make their decisions successively (sequentially) and not as previously assumed. We will then assume that the agents are somewhat\" lazy \"and are inspired by the responses."}, {"heading": "5.6.1 Random imitation", "text": "In Figure 5.10 we show the average group performance (over 30 runs in 1000 time steps) for imitating agents who deliver (imitate) their answers in a random order. The test setup is the same as in the previous section 5.5. That is, seven agents of the ability \u03b1 = {1, 2, 3, 4, 5, 6, 7} are working on a problem in Chapter 5. Experiments 5.6 Imitation of agents Difficulty \u03bb = 516. A majority voting system is used. As can be observed, the performance decreases with the imitation rate. As explained, this is due to the loss of independence of the individual voices, which increases the deviation of the percentage of correct voices. In the answer provided by the group is the answer given by the first agent. As the latter is randomly selected, the group accuracy is the average of individual accuracy, which in our case is 58.4%."}, {"heading": "5.6.2 Best imitation", "text": "As a matter of fact, the actors and actors who know their answers to the question of what they should do know very well what they should do and what they should do. - The actors and actors who give their answers to the question of what they should do and what they should do are the actors and actors of the actors, the actors and actors of the actors and actors of the actors and actors of the actors and actors of the actors of the actors and actors of the actors and actors of the actors and actors of the actors and actors of the actors and actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors of the actors of the actors and actors of the actors of the actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors of the actors of the actors and actors of the actors of the actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors of the actors and actors of the actors of the actors and actors of the actors and actors of the actors of the actors and actors of the actors of the actors and actors of the actors of the actors and actors of the women and actors of the women and actors of the actors and actors of the actors and actors of the actors and actors of the actors of the women and actors of the actors and women and actors of the actors of the actors of the actors and women and actors of the actors of the women and women and actors of the actors of the actors and"}, {"heading": "6.1 Modeling of intelligence", "text": "Our work represents a step forward in the modeling of (collective) intelligence. We used the item-response theory approach for this purpose by specifying a response function in Equation (4.2): P\u03bb (\u03b1) = 12 + 1 1 + exp (2 \u03bb\u03b1) This approach was at the same time very simple, but still quite general. Firstly, the model depends on only two parameters: one - the ability \u03b1 - to characterize the agent and the other - the difficulty \u03bb - to characterize the problem. In addition, this function decreases monotonously with \u03bb and increases monotonously with \u03b1. Furthermore, it approaches an accuracy of 50% with increasing difficulty of the problem. However, all of these properties could be slightly modified. In 7.2 we will see that with a slight modification of the previous function, one can also model individual peak functions. However, we argue that the approach in 5.2.1 is actually even more general. In the latter section, we define - instead of a constant agent for each ability - an ix."}, {"heading": "6.2 Collective intelligence tests", "text": "Our approach has also enabled us to get some ideas about how a collective intelligence test could be designed. Chapter 6. Analysis of results 6.3 Collective decision-making"}, {"heading": "6.2.1 How to introduce a social dimension into collective intelligence tests", "text": "An innovative evolution of our approach deals with the testing of social aspects of collective intelligence. We suggested that the group should not be tested on just one problem, but on several at the same time. Therefore, the group must be able to organize itself so that it distributes its resources across all problems. As we understood from our experiments, the proper distribution of agents to the problems is not a trivial task. For example, each actor might be good at another problem. Assigning agents in such a way that each actor is assigned to a problem he is good at is not easy. However, most importantly, the assignment task forces the group to communicate - for example, about the abilities of the actor and the difficulties of the problem - which is an important aspect of collective intelligence."}, {"heading": "6.2.2 Dynamic environments", "text": "In 5.3.2 we also argued that dynamic environments - i.e. environments in which, for example, the difficulties of problems change over time - are more difficult and can be used to distinguish between groups."}, {"heading": "6.2.3 Which information to provide?", "text": "We have also given an answer to what information should be provided to the group. We have argued that as little information as possible should be provided to the group. We have discussed here whether the difficulties of the problem (see 5.4) or the abilities of the agent (see 5.5) should be provided to the group. None of these measures should be provided because there is no \"universal\" definition of the ability or difficulty. Any measure of the agent's ability must be tailored to a problem and any measure of the difficulty of the problem must be specific to an agent. Moreover, the environment provides sufficient information about these measures. However, in order to use these measures successfully, the agents must be able to communicate through them."}, {"heading": "6.3 Collective decision making", "text": "One of the most important questions in the collective performance of a group is how the group makes a common decision (for one problem or for several). We have observed several phenomena."}, {"heading": "6.3.1 The dynamics of odd and even number of agents", "text": "We have theoretically explained that if you increase the number of agents to a problem, the performance of the group should increase. Chapter 6. Analysis of Results 6.3 Collective Decision Making We have observed that this increase is typically different when you move from an even number of agents to an odd number than vice versa. One reason for this is that it can happen in a group with an even number of agents, that the vote is indefinite and that a random change must be used to decide the vote of the group. We have analytically shown that in a homogeneous group that applies majority decisions, an odd number of agents do as well as the group with the narrowest even number of agents."}, {"heading": "6.3.2 The importance of voting systems", "text": "We have shown that in a majority voting system, the performance of good agents can be significantly impaired by the presence of bad agents. Nevertheless, we know that there is one and only one optimal voting system, in which each agent whose answer is not random makes a positive contribution to the performance of the group. In fact, the optimal weighting system is to be recorded proportionally P\u03bbj (\u03b1i) 1 \u2212 P\u03bbj (\u03b1i), even for agents whose performance is actually worse than random, as we will discuss in 7.5. As we have shown in 5.4.2, all the components of this system - the individual accuracy of the problem P\u03bbj (\u03b1i) - can easily be appreciated by the group."}, {"heading": "6.3.3 Independence of votes", "text": "In 5.6, we analyzed what might happen if we dropped the hypothesis of independent voices. We modelled this by assuming that agents imitate each other, which can be seen as a form of collaboration / communication between agents. As we have shown, one can typically expect (in cases of fairly homogeneous and / or sufficiently large groups) that the performance of the group will decrease as agents \"imitation rate increases. Therefore, the independence of voices could be seen as a strength of the group. To show this has some interesting consequences for one of the most important collective intelligence systems: financial systems. Systems are supposed to be efficient because many agents make their decisions independently of each other. Each market participant makes mistakes, but these mistakes are compensated by the fact that the average buying or selling decision of a large number of market participants does not result in a price that at any moment reflects the intrinsic value of an asset."}, {"heading": "6.4 Allocation models", "text": "The problem of task allocation is another important issue in collective intelligence. Our approach has shown some interesting modifications to the threshold assignment model that could also inspire other users of this model."}, {"heading": "6.4.1 Avoiding stimulus divergence", "text": "We have proposed a feature that avoids the divergence of stimulus: In (4.10) we have inserted a factor < 1: Sj \u2190 Sj \u2190 Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj < Sj > Sj > Sj > Sj > Sj > Sj > Sj < Sj > Sj > Sj > Sj > Sj > Sj > Sj > Sj < Sj > Sj > Sj > Sj > Sj > Sj < Sj > Sj > Sj < Sj > Sj < Sj > Sj > Sj < Sj > Sj < Sj < Sj > Sj < Sj > Sj > Sj < Sj < Sj > Sj < Sj > Sj < Sj < Sj < Sj > Sj > Sj < Sj < Sj < Sj < Sj < Sj > Sj < Sj < Sj > Sj < Sj < Sj < Sj > Sj < Sj < Sj > Sj < Sj < Sj < Sj < Sj < Sj < Sj < Sj < Sj < Sj < Sj < Sj < Sj < Sj < Sj"}, {"heading": "6.4.2 Additional terms in the stimulus update rule", "text": "We have also shown that the rule for updating stimuli can be adjusted with some problem-specific terms. In (4.10) we have included a term that reflects the recent performance of the group in relation to the problem. However, we have also shown that the term \u03b2nj nij should always be retained in the model. This term can be interpreted (in the standard model) as the term that forces the group to distribute the problems to some extent uniformly. Supplemented by other terms (and possibly in combination with a lower associated parameter), its purpose is rather to avoid extreme assignments where one (or more) problems are solved and / or all actors are assigned to a problem. In 5.4.1 we have also shown that it might be useful to convert the parameters of the update rule to functions of other parameters, here a measure of difficulty."}, {"heading": "6.4.3 Adaptation of the threshold update rule", "text": "Finally, our experiments suggest that including additional parameters in the threshold update rule could also improve the performance of our allocation model. In Equation (5,5), we assured that agents would typically be assigned Chapter 6. Analyzing the results 6.4 Allocation models for problems they can deal with well by making the rule dependent on the individual performance of the agent. In this chapter, we will discuss further ideas for experiments that can be conducted in the context of the approach outlined here."}, {"heading": "7.1 Use of agent ability in the resource alloca-", "text": "However, this information could also be used to assign the agents to the problems, which in turn means that the difficulties of the problems must be publicly known. To do this, we can take inspiration from the problem of mail retrieval, in which a group of postmen must retrieve mail from different cities, using the typical threshold model to assign the postman to the cities. Nevertheless, an additional piece of information is considered: the distance dz (i) j between the current city z (i) of postmen i and other cities j that could be served next. This information is important because the distance is proportional to the time the postmen are traveling."}, {"heading": "7.2 Single peaked response functions", "text": "So far, we have assumed that the ability to solve a problem correctly (more precisely, the corresponding probability P\u03bb (\u03b1))) is a monotonously decreasing function of difficulty \u03bb for each agent. However, it could be, for example, that a very intelligent agent has difficulty solving very simple problems (say, they are \"too simple\").There are indeed examples of problems where such a phenomenon occurs. Specifically, there are tests in which an agent performs better than adults. The question is: in which direction is the bus going? Most preschoolers answer this test correctly: the bus is going to the left. However, most adults are unable to give the right answer, even after a long period of reflection. The justification - which is also provided by preschoolers - why is the bus going to the left - is that you cannot see the entrance door that you would see if the bus were going to the right.1The discussion is being held for countries where traffic takes place."}, {"heading": "7.3 Different types of problems", "text": "It would also be interesting to examine what happens when we introduce several types of problems, \u03c0. Each agent i then has not only a skill \u03b1i, but a vector of abilities \u03b1i (\u03c0j). Now we see that this is a generalization of the ability matrix \u03b1ij that we defined in 5.2.1 for specialized agents."}, {"heading": "7.4 Intelligence affecting the allocation capabil-", "text": "So far, we have assumed that the ability to solve the problem has no influence on the task assignment algorithm, but this is a strong hypothesis. It may well be that very intelligent individuals are also better able to relate to the most suitable problem. Therefore, we could test the effects of dependence of the algorithm on the parameter \u03b1. Furthermore, we could add a random noise level (\u03b1i) to the probability of switching to another problem within the threshold model: Prob (i 7 \u2192 j) = S2jS2j + \u03b8 2 ij. Discussions for future work aggravate 7.5 Asymptotic power (7.4) The magnitude of this random noise \"disturbance\" is inversely proportional to the intelligence threshold of the agent. This reflects that less intelligent agents are less able to understand the task assignment."}, {"heading": "7.5 Asymptotic performance worse that random", "text": "So it is interesting to analyze what happens when P\u03bb (\u03b1) becomes less than 50% for problems that are too difficult for the agent. Typically, one would expect this to reduce the performance of the group, for example, when majority decisions are made. As we discussed in 5.1, bad agents are able to disrupt good agents; for agents that have an accuracy of less than 50%, this is even more likely. However, it should be noted that a group that uses the optimal weight scheme is actually positively influenced by agents that exhibit an accuracy that is used by others."}, {"heading": "Appendix A", "text": "Appendix A.1 Proof of Equation (5,3) What we are proving here is the following: Accuracy of a group with an even number of agents is similar to that of the group with the next and lower odd number of agents: P2n = P2n \u2212 n \u2212 n \u2212 n n n n NLet's start with an arbitrary even number of agents represented by 2n: n n n N: n N: P2n = 2n n n N: n N: n N: n N: n N: n N: n N: n N: The first term again represents the probability of all voice combinations that result in a majority for the correct answer, and the second term represents the probability that a coin change is necessary and successful. In the first term we will make a change to the index so that we start the sum in zero: k \u00b2 = k \u2212 n \u2212 1. The factor in the second term can also be simplified: 1 \u00b7 n \u00b7 n \u00b7 k = 2 = 2!"}], "references": [{"title": "Quantitative study of the fixed threshold model for the regulation of division of labour in insect societies", "author": ["Eric Bonabeau", "Guy Theraulaz", "Jean-Louis Deneubourg"], "venue": "Proceedings of the Royal Society of London. Series B: Biological Sciences,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1996}, {"title": "Adaptive task allocation inspired by a model of division of labor in social insects", "author": ["Eric Bonabeau", "Andrej Sobkowski", "Guy Theraulaz", "Jean-Louis Deneubourg"], "venue": "Biocomputing and emergent computation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Swarm intelligence: from natural to artificial systems", "author": ["Eric Bonabeau", "Marco Dorigo", "Guy Theraulaz"], "venue": "Number 1. OUP USA,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Inspiration for optimization from social insect", "author": ["Eric Bonabeau", "Marco Dorigo", "Guy Theraulaz"], "venue": "behaviour. Nature,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "Intelligence as the tests test it", "author": ["E.G. Boring"], "venue": "New Republic,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1923}, {"title": "Applying the ant system to the vehicle routing problem", "author": ["Bernd Bullnheimer", "Richard F Hartl", "Christine Strauss"], "venue": "In Meta-Heuristics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "Dynamic scheduling and division of labor in social insects", "author": ["Mike Campos", "Eric Bonabeau", "Guy Theraulaz", "Jean-Louis Deneubourg"], "venue": "Adaptive Behavior,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Personality and social intelligence", "author": ["Nancy Cantor", "John F Kihlstrom"], "venue": "Prentice-Hall Englewood Cliffs, NJ,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1987}, {"title": "On the length of programs for computing finite binary sequences", "author": ["Gregory J Chaitin"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1966}, {"title": "Urban search and rescue robots: from tragedy to technology", "author": ["Angela Davids"], "venue": "Intelligent Systems, IEEE,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "Problem with the rating agencies is how they are used", "author": ["Eric De Keuleneer"], "venue": "Financial Times: www.ft.com/cms/s/0/", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Ai - what is this? a definition of artificial intelligence. PC Magazine Bulgaria (in Bulgarian, English version at http: // www. dobrev", "author": ["D. Dobrev"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Formal definition of artificial intelligence", "author": ["Dimiter Dobrev"], "venue": "International Journal of Information Theories and Applications,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Ant colonies for the travelling salesman problem. BioSystems", "author": ["Marco Dorigo", "Luca Maria Gambardella"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1997}, {"title": "A computational extension to the Turing Test", "author": ["D.L. Dowe", "A.R. Hajek"], "venue": "Proceedings of the 4th Conference of the Australasian Cognitive Science Society,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1997}, {"title": "IQ tests are not for machines", "author": ["D.L. Dowe", "J. Hern\u00e1ndez-Orallo"], "venue": "yet. Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Watson: Beyond Jeopardy", "author": ["David Ferrucci", "Anthony Levas", "Sugato Bagchi", "David Gondek", "Erik Mueller"], "venue": "Artificial Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "The tragedy of the commons", "author": ["Hardin Garrett"], "venue": "Science, 162(3859):1243\u2013", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1968}, {"title": "Beyond the Turing Test", "author": ["J. Hern\u00e1ndez-Orallo"], "venue": "J. Logic, Language & Information,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2000}, {"title": "On the computational measurement of intelligence factors", "author": ["J. Hern\u00e1ndez-Orallo"], "venue": "National Institute of Standards and Technology,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}, {"title": "Universal psychometrics: Measuring cognitive abilities in the machine kingdom", "author": ["J. Hern\u00e1ndez-Orallo", "D.L. Dowe", "M.V. Hern\u00e1ndez-Lloreda"], "venue": "Cognitive Systems Research, (to appear),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2003}, {"title": "Measuring universal intelligence: Towards an anytime intelligence test", "author": ["Jos\u00e9 Hern\u00e1ndez-Orallo", "David L Dowe"], "venue": "Artificial Intelligence,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "A formal definition of intelligence based on an intensional variant of algorithmic complexity", "author": ["Jos\u00e9 Hern\u00e1ndez-Orallo", "Neus Minaya-Collado"], "venue": "In Proceedings of International Symposium of Engineering of Intelligent Systems", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1998}, {"title": "On more realistic environment distributions for defining, evaluating and developing intelligence", "author": ["Jos\u00e9 Hern\u00e1ndez-Orallo", "David L Dowe", "Sergio Espa\u00f1a-Cubillo", "M Victoria Hern\u00e1ndez-Lloreda", "Javier Insa-Cabrera"], "venue": "In Artificial general intelligence,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Turing tests with turing machines", "author": ["Jos\u00e9 Hern\u00e1ndez-Orallo", "Javier Insa", "David L Dowe", "Bill Hibbard"], "venue": "In The Alan Turing Centenary Conference, Turing-100, Manchester,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Bias and no free lunch in formal measures of intelligence", "author": ["B. Hibbard"], "venue": "Journal of Artificial General Intelligence,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Adversarial sequence prediction", "author": ["Bill Hibbard"], "venue": "Frontiers in Artificial Intelligence and Applications,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2008}, {"title": "The measurement of social intelligence", "author": ["Thelma Hunt"], "venue": "Journal of Applied Psychology,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1928}, {"title": "On measuring social intelligence: experiments on competition and cooperation", "author": ["Javier Insa-Cabrera", "Jos\u00e9-Luis Benacloch-Ayuso", "Jos\u00e9 Hern\u00e1ndez- Orallo"], "venue": "In Artificial General Intelligence,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Robocup rescue: Search and rescue in large-scale disasters as a domain for autonomous agents research", "author": ["Hiroaki Kitano", "Satoshi Tadokoro", "Itsuki Noda", "Hitoshi Matsubara", "Tomoichi Takahashi", "Atsuhi Shinjou", "Susumu Shimada"], "venue": "In Systems, Man, and Cybernetics,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1999}, {"title": "Three approaches to the definition of the concept quantity of information", "author": ["Andrei Nikolaevich Kolmogorov"], "venue": "Problemy peredachi informatsii,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1965}, {"title": "Crowd iq: Measuring the intelligence of crowdsourcing platforms", "author": ["Michal Kosinski", "Yoram Bachrach", "Gjergji Kasneci", "Jurgen Van-Gael", "Thore Graepel"], "venue": "In Proceedings of the 3rd Annual ACM Web Science Conference,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Combining Pattern Classifiers: Methods and Algorithms", "author": ["Ludmila I Kuncheva"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2004}, {"title": "A colony of ant-like agents for partitioning in VLSI technology", "author": ["Pascale Kuntz", "Paul Layzell", "Dominique Snyers"], "venue": "In Proceedings of the Fourth European Conference on Artificial Life,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1997}, {"title": "A universal measure of intelligence for artificial agents", "author": ["S. Legg", "M. Hutter"], "venue": "In Intl Joint Conf on Artificial Intelligence, IJCAI,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2005}, {"title": "Universal intelligence: A definition of machine intelligence", "author": ["Shane Legg", "Marcus Hutter"], "venue": "Minds and Machines,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2007}, {"title": "Universal sequential search problems", "author": ["Leonid A Levin"], "venue": "Problemy Peredachi Informatsii,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1973}, {"title": "Vitanyi. An introduction to Kolmogorov complexity and its applications", "author": ["Ming Li", "Paul MB"], "venue": "Springer-Verlag, 3rd edition,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1993}, {"title": "Statistical theories of mental test scores, volume 47", "author": ["Frederic M Lord", "Melvin R Novick", "Allan Birnbaum"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1968}, {"title": "Task allocation via self-organizing swarm coalitions in distributed mobile sensor network", "author": ["Kian Hsiang Low", "Wee Kheng Leow", "Marcelo H Ang"], "venue": "In Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1999}, {"title": "Social savvy boosts the collective intelligence of groups", "author": ["Greg Miller"], "venue": "Science, 330(6000):22\u201322,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2010}, {"title": "The cooperation of swarm-bots: Physical interactions in collective robotics", "author": ["Francesco Mondada", "Luca Maria Gambardella", "Dario Floreano", "Stefano Nolfi", "J-L Deneuborg", "Marco Dorigo"], "venue": "Robotics & Automation Magazine, IEEE,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2005}, {"title": "Are you socially intelligent", "author": ["Fred August Moss", "Thelma Hunt"], "venue": "Scientific American,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 1927}, {"title": "Kasparov vs. Deep Blue: Computer chess comes of age", "author": ["Monty Newborn", "Monroe Newborn"], "venue": null, "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1997}, {"title": "The evolution of imitation", "author": ["Andr\u00e9 Orl\u00e9an"], "venue": "In The Economics of Networks,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1998}, {"title": "Measurements of social intelligence", "author": ["Maureen O\u2019Sullivan", "Joy Paul Guilford", "Richard deMille"], "venue": "Reports from the Psychological Laboratory,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 1965}, {"title": "A universal prior for integers and estimation by minimum description length", "author": ["J. Rissanen"], "venue": "Annals of Statistics,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 1983}, {"title": "Minds, brains, and programs", "author": ["John R Searle"], "venue": "Behavioral and brain sciences,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 1980}, {"title": "Social intelligence: A concept in search of data", "author": ["Luke A Shanley", "Ronald E Walker", "Jeanne M Foley"], "venue": "Psychological Reports,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1971}, {"title": "Shettleworth. Cognition, evolution, and behavior", "author": ["J Sara"], "venue": null, "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2009}, {"title": "A formal theory of inductive inference. part I", "author": ["Ray J Solomonoff"], "venue": "Information and control,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 1964}, {"title": "General intelligence\u201d, objectively determined and measured", "author": ["Charles Spearman"], "venue": "The American Journal of Psychology,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 1904}, {"title": "Intelligence, information processing, and analogical reasoning", "author": ["Robert J Sternberg"], "venue": null, "citeRegEx": "54", "shortCiteRegEx": "54", "year": 1977}, {"title": "Artificial stupidity", "author": ["John Sundman"], "venue": "Salon, Feb,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2003}, {"title": "Some characteristics of the good judge of personality", "author": ["Philip E Vernon"], "venue": "The Journal of Social Psychology,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 1933}, {"title": "Telling humans and computers apart automatically or how lazy cryptographers do AI", "author": ["Louis von Ahn", "Manuel Blum", "John Langford"], "venue": "Computer Science Department,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2002}, {"title": "Statistical and Inductive Inference by Minimum Message Length", "author": ["C.S. Wallace"], "venue": null, "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2005}, {"title": "An information measure for classification", "author": ["C.S. Wallace", "D.M. Boulton"], "venue": "Computer Journal,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 1968}, {"title": "The measurement and appraisal of adult intelligence", "author": ["David Wechsler"], "venue": "Academic Medicine,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 1958}, {"title": "The relation between caste ratios and division of labor in the ant genus pheidole (hymenoptera: Formicidae)", "author": ["Edward O Wilson"], "venue": "Behavioral Ecology and Sociobiology,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 1984}, {"title": "An introduction to collective intelligence", "author": ["David H Wolpert", "Kagan Tumer"], "venue": "arXiv preprint cs/9908014,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 1999}, {"title": "What makes a team smarter? More women", "author": ["Anita Woolley", "Thomas Malone"], "venue": "Harvard Business Review,", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2011}, {"title": "Evidence for a collective intelligence factor in the performance of human", "author": ["Anita Williams Woolley", "Christopher F Chabris", "Alex Pentland", "Nada Hashmi", "Thomas W Malone"], "venue": "groups. Science,", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2010}], "referenceMentions": [{"referenceID": 4, "context": "Hence, following Boring [5], \u201cintelligence is the ability measured by the IQ test\u201d.", "startOffset": 24, "endOffset": 27}, {"referenceID": 51, "context": "In 1904, the psychologist Spearman [53] discovered a positive correlation across the performances in these different tasks.", "startOffset": 35, "endOffset": 39}, {"referenceID": 15, "context": "A further discussion of what a universal test is and why IQ tests are not universal can be found in [16] and [22].", "startOffset": 100, "endOffset": 104}, {"referenceID": 20, "context": "A further discussion of what a universal test is and why IQ tests are not universal can be found in [16] and [22].", "startOffset": 109, "endOffset": 113}, {"referenceID": 49, "context": "(see for instance [51])", "startOffset": 18, "endOffset": 22}, {"referenceID": 43, "context": "In 1997, a chess machine named deep blue beat the Russian chess master Garry Kasparov [45].", "startOffset": 86, "endOffset": 90}, {"referenceID": 16, "context": "In 2011, an IBM project called Watson beat humans in the game Jeopardy! [17].", "startOffset": 72, "endOffset": 76}, {"referenceID": 55, "context": "Currently, this can still be done using the CAPTCHA tests [59], where distorted letters and numbers have to be identified in a picture.", "startOffset": 58, "endOffset": 62}, {"referenceID": 47, "context": "[49].", "startOffset": 0, "endOffset": 4}, {"referenceID": 53, "context": "And it has indeed been shown that a fairly easy algorithm could actually maintain a human-like conversation, without actually understanding the content of the conversation [55].", "startOffset": 172, "endOffset": 176}, {"referenceID": 22, "context": "A recent approach has been to use inductive inference for designing intelligence test, hence for to measuring and defining intelligence [24, 20, 37].", "startOffset": 136, "endOffset": 148}, {"referenceID": 18, "context": "A recent approach has been to use inductive inference for designing intelligence test, hence for to measuring and defining intelligence [24, 20, 37].", "startOffset": 136, "endOffset": 148}, {"referenceID": 35, "context": "A recent approach has been to use inductive inference for designing intelligence test, hence for to measuring and defining intelligence [24, 20, 37].", "startOffset": 136, "endOffset": 148}, {"referenceID": 30, "context": "This formalism stems from algorithmic information theory developed by Kolmogorov [32], Chaitin [9] and Solomonoff [52].", "startOffset": 81, "endOffset": 85}, {"referenceID": 8, "context": "This formalism stems from algorithmic information theory developed by Kolmogorov [32], Chaitin [9] and Solomonoff [52].", "startOffset": 95, "endOffset": 98}, {"referenceID": 50, "context": "This formalism stems from algorithmic information theory developed by Kolmogorov [32], Chaitin [9] and Solomonoff [52].", "startOffset": 114, "endOffset": 118}, {"referenceID": 37, "context": "The Kolomorow Complexity of a sequence x \u2013 actually the amount of information contained in it \u2013 is given by the size of the smallest program q on a Universal Turing Machine U so that the latter generates this sequence on output [39]: KU (x) = min q |q| : U(q) = x (2.", "startOffset": 228, "endOffset": 232}, {"referenceID": 57, "context": "The Kolomorov complexity is often also referred to as the Minimum Description Length (MDL) [61, 60, 48], which is the shortest string, which taken as an algorithm produces x.", "startOffset": 91, "endOffset": 103}, {"referenceID": 56, "context": "The Kolomorov complexity is often also referred to as the Minimum Description Length (MDL) [61, 60, 48], which is the shortest string, which taken as an algorithm produces x.", "startOffset": 91, "endOffset": 103}, {"referenceID": 46, "context": "The Kolomorov complexity is often also referred to as the Minimum Description Length (MDL) [61, 60, 48], which is the shortest string, which taken as an algorithm produces x.", "startOffset": 91, "endOffset": 103}, {"referenceID": 22, "context": "Hern\u00e1ndez-Orallo and Minaya-Collado [24] have designed a test based on inductive sequence prediction.", "startOffset": 36, "endOffset": 40}, {"referenceID": 22, "context": "Hern\u00e1ndez-Orallo and Minaya-Collado [24] refer hence to \u201cintelligence as the ability of compression\u201d, although they argue that this direct connection needs to be further refined and developed (and led beyond inductive inference [21]).", "startOffset": 36, "endOffset": 40}, {"referenceID": 19, "context": "Hern\u00e1ndez-Orallo and Minaya-Collado [24] refer hence to \u201cintelligence as the ability of compression\u201d, although they argue that this direct connection needs to be further refined and developed (and led beyond inductive inference [21]).", "startOffset": 228, "endOffset": 232}, {"referenceID": 35, "context": "However, the polynomial 2k\u221220k+70k\u221298k+48 follows also the same initial pattern [37].", "startOffset": 80, "endOffset": 84}, {"referenceID": 50, "context": "Solomonoff [52] defined the a priori probability that on any input on a Universal Turing Machine U appears the string x.", "startOffset": 11, "endOffset": 15}, {"referenceID": 14, "context": "An advantage is also that a measure of intelligence base on prediction/compression overcomes the Chinese Room argument[15].", "startOffset": 118, "endOffset": 122}, {"referenceID": 36, "context": ", the Levin\u2019s Kt [38]).", "startOffset": 17, "endOffset": 21}, {"referenceID": 11, "context": "This idea and its use for evaluating intelligence was pioneered by Dobrev [12, 13].", "startOffset": 74, "endOffset": 82}, {"referenceID": 12, "context": "This idea and its use for evaluating intelligence was pioneered by Dobrev [12, 13].", "startOffset": 74, "endOffset": 82}, {"referenceID": 34, "context": "It was then further elaborated in a more elegant way by Legg and Hutter [36] using Markov Decision Processes and reinforcement learning.", "startOffset": 72, "endOffset": 76}, {"referenceID": 23, "context": "[25] discuss how an environment with several evaluees can be constructed.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "This is for instance useful for the design of adversarial prediction problems, where one evaluee has to predict a sequence generated by the other, as in [28, 26].", "startOffset": 153, "endOffset": 161}, {"referenceID": 24, "context": "This is for instance useful for the design of adversarial prediction problems, where one evaluee has to predict a sequence generated by the other, as in [28, 26].", "startOffset": 153, "endOffset": 161}, {"referenceID": 35, "context": "Legg and Hutter [37] use the here presented formalism from algorithmic information theory to design a universal measure of intelligence.", "startOffset": 16, "endOffset": 20}, {"referenceID": 21, "context": "Some of these issues are addressed in [23, 27].", "startOffset": 38, "endOffset": 46}, {"referenceID": 25, "context": "Some of these issues are addressed in [23, 27].", "startOffset": 38, "endOffset": 46}, {"referenceID": 23, "context": "[25] and as we will discuss furthermore (see e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[25] suggest for instance to define a minimum complexity of the problems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "The idea of social intelligence [8] was first mentioned by Thorndike [56].", "startOffset": 32, "endOffset": 35}, {"referenceID": 54, "context": "Vernon [58] defines it as \u201cthe ability to get along with people in general, social techniques or ease in society, knowledge of social matters, susceptibility to stimuli from other members of a group, as well as insight into temporary moods or underlying personality traits of stranger\u201d.", "startOffset": 7, "endOffset": 11}, {"referenceID": 42, "context": "The first of such tests was the George Washington Social Intelligence Test (GWSIT) [44].", "startOffset": 83, "endOffset": 87}, {"referenceID": 27, "context": "However, this test soon came under criticism as it correlated much with abstract intelligence tests [29].", "startOffset": 100, "endOffset": 104}, {"referenceID": 58, "context": ", [62]) argued that \u201csocial intelligence is nothing else than general intelligence applied to the social domain\u201d.", "startOffset": 2, "endOffset": 6}, {"referenceID": 45, "context": "[47] for instance developed a test which seems to withstand such criticism [50].", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "[47] for instance developed a test which seems to withstand such criticism [50].", "startOffset": 75, "endOffset": 79}, {"referenceID": 60, "context": "In artificial intelligence, Collective intelligence [66] commonly refers to multiagent systems (i.", "startOffset": 52, "endOffset": 56}, {"referenceID": 17, "context": "It was first discussed by Garret Hardin [19].", "startOffset": 40, "endOffset": 44}, {"referenceID": 60, "context": "Yet in many cases, RL is not well suited due to the big size of the action-policy space [66].", "startOffset": 88, "endOffset": 92}, {"referenceID": 6, "context": "[7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] present a market-based approach, where each agent i makes a bid to paint truck j.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] also present an ant-algorithm which defeats the market-based version.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] is the same as the one we present in 4.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Swarm intelligence is \u201cany attempt to design algorithms or distributed problemsolving devices inspired by the collective behavior of social insect colonies and other animal societies\u201d [3].", "startOffset": 184, "endOffset": 187}, {"referenceID": 13, "context": "Examples of NP-hard problems for which ant-colony algorithms have been successfully developed are for instance the traveling salesman problem [14], routing problems [6], scheduling problems [69] or partitioning [35] problems, Not only for optimization algorithms, but also for collective intelligence systems with physically separated agents, social insects can be an inspiring source for designers.", "startOffset": 142, "endOffset": 146}, {"referenceID": 5, "context": "Examples of NP-hard problems for which ant-colony algorithms have been successfully developed are for instance the traveling salesman problem [14], routing problems [6], scheduling problems [69] or partitioning [35] problems, Not only for optimization algorithms, but also for collective intelligence systems with physically separated agents, social insects can be an inspiring source for designers.", "startOffset": 165, "endOffset": 168}, {"referenceID": 33, "context": "Examples of NP-hard problems for which ant-colony algorithms have been successfully developed are for instance the traveling salesman problem [14], routing problems [6], scheduling problems [69] or partitioning [35] problems, Not only for optimization algorithms, but also for collective intelligence systems with physically separated agents, social insects can be an inspiring source for designers.", "startOffset": 211, "endOffset": 215}, {"referenceID": 41, "context": "Several research projects have started to assess the use of swarm robots for search and rescue (SAR) tasks after disasters [43, 10, 31].", "startOffset": 123, "endOffset": 135}, {"referenceID": 9, "context": "Several research projects have started to assess the use of swarm robots for search and rescue (SAR) tasks after disasters [43, 10, 31].", "startOffset": 123, "endOffset": 135}, {"referenceID": 29, "context": "Several research projects have started to assess the use of swarm robots for search and rescue (SAR) tasks after disasters [43, 10, 31].", "startOffset": 123, "endOffset": 135}, {"referenceID": 40, "context": "The main conclusions of such research are basically identical [42, 67, 68].", "startOffset": 62, "endOffset": 74}, {"referenceID": 61, "context": "The main conclusions of such research are basically identical [42, 67, 68].", "startOffset": 62, "endOffset": 74}, {"referenceID": 62, "context": "The main conclusions of such research are basically identical [42, 67, 68].", "startOffset": 62, "endOffset": 74}, {"referenceID": 31, "context": "[33], who use a so-called crowdsource platform \u2013 a platform allowing employers to connect to several job seekers who will execute small tasks against a little reward \u2013 to evaluate collective intelligence.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "We will mathematically conceptualize abilities making reference to the field of item response theory (IRT) [40].", "startOffset": 107, "endOffset": 111}, {"referenceID": 38, "context": "We will present briefly here the three parameter logistic model [40].", "startOffset": 64, "endOffset": 68}, {"referenceID": 32, "context": "The literature about multi-classifier systems [34] provides us with some theoretical results about which performance might be expected from such a majority voting system.", "startOffset": 46, "endOffset": 50}, {"referenceID": 32, "context": "Defining k = bn/2c + 1, the bounds on the group\u2019s accuracy are given by [34]:", "startOffset": 72, "endOffset": 76}, {"referenceID": 32, "context": "Again, the literature about multi-classifier systems [34] provide us with some theoretical results about weighted voting systems.", "startOffset": 53, "endOffset": 57}, {"referenceID": 28, "context": "[30], where several cooperation and competition settings are studied.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "One such algorithm is the dynamic task allocation algorithm inspired from division of labor observed with social insects such as ants ([4, 2, 41]).", "startOffset": 135, "endOffset": 145}, {"referenceID": 1, "context": "One such algorithm is the dynamic task allocation algorithm inspired from division of labor observed with social insects such as ants ([4, 2, 41]).", "startOffset": 135, "endOffset": 145}, {"referenceID": 39, "context": "One such algorithm is the dynamic task allocation algorithm inspired from division of labor observed with social insects such as ants ([4, 2, 41]).", "startOffset": 135, "endOffset": 145}, {"referenceID": 59, "context": "As observed by Wilson [65], in such ant colonies two distinct types of ants are present.", "startOffset": 22, "endOffset": 26}, {"referenceID": 59, "context": "Wilson [65] observed however that if minors were retrieved from the colony, majors will consequently also perform the former\u2019s task.", "startOffset": 7, "endOffset": 11}, {"referenceID": 0, "context": "[1] showed that the division of labor/task allocation observed for the Pheidole genus, could easily be modeled trough a so-called threshold model.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "In the standard model [4, 2, 41], the thresholds are updated in a way so as to avoid unnecessary switching from one task to another.", "startOffset": 22, "endOffset": 32}, {"referenceID": 1, "context": "In the standard model [4, 2, 41], the thresholds are updated in a way so as to avoid unnecessary switching from one task to another.", "startOffset": 22, "endOffset": 32}, {"referenceID": 39, "context": "In the standard model [4, 2, 41], the thresholds are updated in a way so as to avoid unnecessary switching from one task to another.", "startOffset": 22, "endOffset": 32}, {"referenceID": 1, "context": "[2] to get a first idea of the parameters\u2019 matter of size.", "startOffset": 0, "endOffset": 3}, {"referenceID": 32, "context": "Our results are hence coherent with what we know already form multi-classifier systems [34].", "startOffset": 87, "endOffset": 91}, {"referenceID": 35, "context": "5) \u2013 as proposed by Legg and Hutter [37] \u2013 weights the problems using a universal distribution.", "startOffset": 36, "endOffset": 40}, {"referenceID": 21, "context": "Some ideas about how this might be done, can be found in Hern\u00e1ndez-Orallo and Dowe [23].", "startOffset": 83, "endOffset": 87}, {"referenceID": 44, "context": "Orl\u00e9an [46] investigates the dynamics of a group where some agents are truly informed and others are pure imitators of the informed agents (their vote is determined through the majority vote of the informed agents).", "startOffset": 7, "endOffset": 11}, {"referenceID": 10, "context": "De Keuleneer [11] talking about the over-reliance on rating agencies puts it like this:", "startOffset": 13, "endOffset": 17}, {"referenceID": 1, "context": "[2], we can incorporate the distance in our allocation model so that the probability of allocation becomes inversely proportional to it:", "startOffset": 0, "endOffset": 3}], "year": 2013, "abstractText": "Intelligence is a fairly intuitive concept of our everyday life. As usually acknowledged in psychometrics, \u201cintelligence is the ability measured by intelligence tests\u201d. However, defining what exactly intelligence tests should measure is less obvious. During the last decade, computer scientists have attempted to provide a formal definition of intelligence. There seems now to be the tendency that intelligence should make reference to the formalism provided by the field of algorithmic information theory. Yet, a consensus is far from being reached. Independent from the still ongoing research in measuring individual intelligence, we anticipate and provide a framework for measuring collective intelligence. Collective intelligence refers to the idea that several individuals can collaborate in order to achieve high levels of intelligence. We present thus some ideas on how the intelligence of a group can be measured and simulate such tests. We will however focus here on groups of artificial intelligence agents (i.e., machines). We will explore how a group of agents is able to choose the appropriate problem and to specialize for a variety of tasks. This is a feature which is an important contributor to the increase of intelligence in a group (apart from the addition of more agents and the improvement due to common decision making). Our results reveal some interesting results about how (collective) intelligence can be modeled, about how collective intelligence tests can be designed and about the underlying dynamics of collective intelligence. As it will be useful for our simulations, we provide also some improvements of the threshold allocation model originally used in the area of swarm intelligence but further generalized here.", "creator": "LaTeX with hyperref package"}}}