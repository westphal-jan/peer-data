{"id": "1306.6944", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2013", "title": "The DeLiVerMATH project - Text analysis in mathematics", "abstract": "A high-quality content analysis is essential for retrieval functionalities but the manual extraction of key phrases and classification is expensive. Natural language processing provides a framework to automatize the process. Here, a machine-based approach for the content analysis of mathematical texts is described. A prototype for key phrase extraction and classification of mathematical texts is presented.", "histories": [["v1", "Fri, 7 Jun 2013 15:48:06 GMT  (596kb,D)", "http://arxiv.org/abs/1306.6944v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.DL cs.IR", "authors": ["ulf sch\\\"oneberg", "wolfram sperber"], "accepted": false, "id": "1306.6944"}, "pdf": {"name": "1306.6944.pdf", "metadata": {"source": "CRF", "title": "The DeLiVerMATH project Text analysis in mathematics", "authors": ["Ulf Sch\u00f6neberg", "Wolfram Sperber"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "The database zbMATH [1] of the FIZ Karlsruhe / Zentralblatt MATH is the most comprehensive bibliographic revision service in mathematics. Key terms as well as the classification of mathematical publications are central features of content analysis in zbMATH. So far, these data are produced by experts, which means time and laborious work. In recent years, computer linguistics has developed concepts for the processing of natural language by combining linguistic analyses and statistics. These concepts and tools have been used as a platform for our activities to develop machine-assisted methods for key term extraction and classification according to the Mathematical Subject Classification (MSC2010) [2]. The DeLiVerMATH project, which is funded by the German Research Foundation, is a joint activity of the Library TIB Hannover, the Research Centre L3S Hannover and the FIZ Karlsruhe. It started in March 2012."}, {"heading": "2 The prototype", "text": "We start with the presentation of a prototype that extracts key phrases and classifies a mathematical text. Snapshot on Figure 1 demonstrates its functionality. The original text, here a review of zbMATH, is located in the upper left panel. Input can - in principle - be any mathematical text. The extracted candidates for key phrases and their frequency are displayed in the list on the right side and are also highlighted in the original text. The proposed MSC classes, calculated using Naive Bayes (nb) and Support Vector Machines (sv), are displayed below the input text. Currently, classification is limited to the top level of the MSC. In addition, a list of unknown tokens (tokens outside the dictionary) together with a suggested word classes.ar Xiv: 130 6.69 44v1 [cs.CL] 7 Jun 201 3"}, {"heading": "3 Natural Language Processing (NLP) in mathematical publications", "text": "There is a wide range of methods of text analysis, in particular segmentation, in order to identify text units - namely, in the way in which one can split a text stream into words, symbols and formulas, as one cannot do in other languages. - Pardon, the identification of text fragments, for example, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language, in the language of the language, in the language, in the language, in the language of the language, in the language, in the language, in the language of the language, in the language, in the language of the language, in the language, in the language, in the language of the language, in the language of the language, in the language, in the language of the language, in the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language of the language of the language, in the language of the language, in the language of the language, in the language of the language, in the language of the language of the language, in the language of the language, in the language of the language of the language, in the language of the language, in the language of the language of the language, in the language of the language"}, {"heading": "4 Evaluation", "text": "The additional effort required to evaluate key sentences and classification is low, as the tool can be integrated and integrated into the daily workflow, and editors can easily reject a proposed key sentence and classification. We note that the number of key sentences appears to be significantly higher than the number of manually generated key sentences that could be used for better retrieval (e.g. to find similar publications) and ranking, and some techniques for rejecting irrelevant phrases and recognizing similar phrases need to be developed. Other methods for classification are under development, the prototype demonstrates the classification calculated using the Naive Bayes and the Vector Machine approach, and it appears that the quality is sufficient for the top level of the MSC."}, {"heading": "5 Outlook", "text": "The methods and tools are developed and tested for the database zbMATH, but can also be used for the content analysis of full texts. So far, the method is limited to English texts. Expansion to other languages is possible by adding dictionaries and grammars of other languages. A production version of the tool could be provided on the website of the FIZ Karlsruhe / Zentralblatt Mathematik as an additional service for the mathematical community. The aim of the project is to build a controlled vocabulary of mathematics and coordinate it with the MSC. Therefore, the most common key phrases for the MSC classes are determined. These phrases could form the basis of a controlled vocabulary for mathematics, a useful tool for standardization of mathematical language and communication and a starting point for the development of a thesaurus for mathematics. The prototype is a first step towards a machine-assisted content analysis of mathematical publications. We are optimistic that the approach described above can contribute to a cheaper content analysis and enable an improved reeval."}], "references": [{"title": "Part-of-Speech-Tagghing guidelines for the Penn Treebank Project (3rd Revision, 2nd printing)", "author": ["B. Santorini"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1990}, {"title": "Automatic grammatical tagging of English", "author": ["B.B. Greene", "G.M. Rubin"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1981}, {"title": "Comparing a linguistic and a stochastic tagger", "author": ["C. Samuelsson", "A. Voutilainen"], "venue": "Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1997}], "referenceMentions": [{"referenceID": 0, "context": "Here we use the Penn Treebank PoS scheme [3] consisting of 45 tags for words and punctuation symbols.", "startOffset": 41, "endOffset": 44}, {"referenceID": 1, "context": "Here, the Brown corpus [4] is used as a dictionary covering more than 1,000,000 English words which are classified according to the Penn Treebank scheme.", "startOffset": 23, "endOffset": 26}, {"referenceID": 2, "context": "Within the DeLiVerMATH project, the Stanford PoS Tagger [5] is used.", "startOffset": 56, "endOffset": 59}], "year": 2017, "abstractText": "A high-quality content analysis is essential for retrieval functionalities but the manual extraction of key phrases and classification is expensive. Natural language processing provides a framework to automatize the process. Here, a machine-based approach for the content analysis of mathematical texts is described. A prototype for key phrase extraction and classification of mathematical texts is presented.", "creator": "LaTeX with hyperref package"}}}