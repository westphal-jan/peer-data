{"id": "1307.0261", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jul-2013", "title": "WebSets: Extracting Sets of Entities from the Web Using Unsupervised Information Extraction", "abstract": "We describe a open-domain information extraction method for extracting concept-instance pairs from an HTML corpus. Most earlier approaches to this problem rely on combining clusters of distributionally similar terms and concept-instance pairs obtained with Hearst patterns. In contrast, our method relies on a novel approach for clustering terms found in HTML tables, and then assigning concept names to these clusters using Hearst patterns. The method can be efficiently applied to a large corpus, and experimental results on several datasets show that our method can accurately extract large numbers of concept-instance pairs.", "histories": [["v1", "Mon, 1 Jul 2013 02:49:08 GMT  (75kb,D)", "http://arxiv.org/abs/1307.0261v1", "10 pages; International Conference on Web Search and Data Mining 2012"]], "COMMENTS": "10 pages; International Conference on Web Search and Data Mining 2012", "reviews": [], "SUBJECTS": "cs.LG cs.CL cs.IR", "authors": ["bhavana dalvi", "william w cohen", "jamie callan"], "accepted": false, "id": "1307.0261"}, "pdf": {"name": "1307.0261.pdf", "metadata": {"source": "CRF", "title": "WebSets: Extracting Sets of Entities from the Web Using Unsupervised Information Extraction", "authors": ["Bhavana Dalvi", "William W. Cohen", "Jamie Callan"], "emails": ["bbd@cs.cmu.edu", "wcohen@cs.cmu.edu", "callan@cs.cmu.edu"], "sections": [{"heading": null, "text": "Categories and Subject Descriptions: I.2.6 [Artificial Intelligence]: Learning - AcquisitionGeneral Terms: Algorithms, Experimentation.Keywords: Web Mining, Clustering, Hyponymy Relation Acquisition."}, {"heading": "1. INTRODUCTION", "text": "Many NLP tasks - including summaries, co-reference resolution, and named entity extraction - are facilitated by acquiring large amounts of concept and instance pairs (such as \"Goddess Venus\" and \"US President,\" \"Bill Clinton\"). Ontologies that include many such pairs exist, but are often incomplete. Here, we look at the problem of automatically harvesting concept pairs from a large body of HTML tables. Past approaches to this problem are primarily based on the recognition of coordinate concepts and hyponyms patterns, sometimes called Hearst patterns, are surface patterns (such as \"Xs like Y\") that indicate that a concept instance pair is. Two terms i and j are coordinated concepts when i and j are instances of the same concept: for example, \"Bill Clinton\" and \"Richard Nixon\" are coordinated concepts because they are both instances of the concept."}, {"heading": "2. RELATED WORK", "text": "The extraction of information from unstructured and semi-structured sources of information on the web has been an active field of research in recent years. In this section, we summarize the existing techniques according to their categorization, based on the inputs they use and the goals they are trying to achieve."}, {"heading": "2.1 Exploiting Tables on the Web", "text": "Gatterbauer et al. [8] focus on extracting tabular data from different types of pages that have tabular visual representations when displayed in the browser. Although we do not use these techniques, they could be used by WebSets to collect more tabular information from a body. WebTables [2] system extracted schema information from a huge corpus of 14.1 billion HTML tables from Google's general purpose web crawl. They built up an attribute correlation statistics database (AcsDB) that can be used to create an attribute name thesaurus and a scheme for automatic completion. Unfortunately, the WebTables corpora is not publi-ar Xiv: 130 7.02 61v1 [cs.LG] 1 July 201 3cally available; it would be an interesting project to apply WebSets to a corpus of this size."}, {"heading": "2.2 Information Extraction Systems", "text": "It is indeed the case that we will be able to go in search of a solution that will enable us, will enable us to put ourselves in a position, will enable us to put ourselves in a position, will enable us to put ourselves in a position, will enable us to put ourselves in a position, will enable us to put ourselves in a position, will enable us to put ourselves in a position, will enable us to put ourselves in a position, will enable us to put ourselves in a position where we are."}, {"heading": "3. WEBSETS", "text": "In this section, we describe a method of unattended information extraction called WebSets, which extracts concept pairs from HTML tables in a given corpus. To create term clusters, the system should first extract tables by analyzing HTML pages, and then decide which tables have useful relational data. According to the hypothesis that entities appearing in a table column may be of the same concept, each table column in this extracted data is a candidate list; the system must therefore have a mechanism to cluster these table columns. Clustering the table columns results in entities, each of which potentially belongs to a coherent concept, and these sentences become more useful when labeled with appropriate concept names. In summary, the technique we are developing must solve the following sub-problems: 1. Table Identification: 2. Extract tables that are highly likely to label these sub-sets as effective."}, {"heading": "3.1 Table Identification", "text": "Currently, WebSets analyzes tables defined by < table > tags1, which is only a fraction of the structured data available on the Web. Using other techniques such as gate builders et al. [8] can provide more input data to learn from. Furthermore, only a small fraction of HTML tables actually contain useful relational data (see Section 4); the remaining tables are used for formatting or rendering purposes rather than for displaying relational data. To filter out useful tables, WebSets uses the following features: (1) the number of rows (2) 1We have found that a large number of HTML pages have incorrect syntax. We use the HTML syntax cleaning software Tidy [1] to correct the syntax in these sites.The number of unlinked columns (3) the length of cells after formatting tags are removed (4) whether the other HTML tables contain the thresholds specified in our experiments section 4."}, {"heading": "3.2 Entity Clustering", "text": "This year it is more than ever before."}, {"heading": "3.3 Hypernym Recommendation", "text": "In fact, it is the case that it is a matter of a way in which people in the various countries of the world find themselves, in the most varied forms in which they move. (...) In fact, it is as if they are able to put themselves and themselves at the centre. (...) It is not as if they are able to put themselves at the centre. (...) It is as if they are able to put themselves at the centre. (...) It is as if they are able to put themselves at the centre. (...) It is as if they are able to put themselves at the centre. (...) It is as if they are able to put themselves at the centre. (...) It is as if they are able to put themselves at the centre. (...) It is as if they are able to put themselves at the centre. (...) It is as if they are able to put themselves at the centre. (...) It is as if they are able to put themselves at the centre."}, {"heading": "4. EXPERIMENTAL EVALUATION", "text": "These experiments assume that our method extracts a list of concept instance pairs from the HTML corpus. Later in this section, we discuss how well WebSets work end-to-end, as a tool to process a large HTML corpus and to build coherent groups of entities along with the labels of each one. Data sets and evaluations of these experiments are published online at http: / / rtw.ml.cmu.edu / wk / WebSets / wsdm _ 2012 _ online / index.html."}, {"heading": "4.1 Datasets", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "4.2 Evaluation of Individual Stages", "text": "In this section, we consider only those columns that do not have tables. We consider WebSets as a method to generate a large number of concept pairs that exceed a certain number of predefined thresholds. (These thresholds are derived from intuitions that go after some samples of data, and are kept constant for all datasets and experiments described in this paper. If we evaluate a random sample of recursive tables, 93% of them are useless for our purposes, and only 7% of them contain relational data. We choose to ignore the recursive tables. We construct triplets of entities in a table column, hence a table should have at least 3 rows. Since we do not use data in our system, we only consider those columns that do not have recursive tables."}, {"heading": "4.3 WebSets as an IE technique", "text": "This year it is more than ever before."}, {"heading": "5. ACKNOWLEDGMENTS", "text": "This work is supported in part by the Intelligence Advanced Research Projects Activity (IARPA) through the Air Force Research Laboratory (AFRL) under contract number FA8650-10C-7058. The U.S. government is authorized to reproduce and distribute reproductions for government purposes, regardless of the copyright comments contained therein. Part of this work is also supported by the Google Research Grant. The views and conclusions contained therein are those of the authors and should not be interpreted to necessarily represent the official policies or endorsements of Google, IARPA, AFRL or the U.S. government."}, {"heading": "6. CONCLUSION", "text": "Our approach is novel in that it relies exclusively on HTML tables to detect coordinate tables. We introduced a novel cluster method that finds extremely precise (cluster purity 83-99%) coordinate tempo clusters by merging table columns containing overlapping triplets of instances. This cluster method exceeds k averages in terms of purity, edge index, and FM index. We demonstrated that the temporal complexity of our cluster algorithm is O (N-Log-N), making it more efficient than K averages or agglomerative cluster algorithms. We also presented a new method for combining candidate-concept pairs and coordinate-term clusters, and demonstrated that this method can be improved on table-rich corpora over Van Durme and Pasca methods. Our method increased the accuracy from 50% to 78%, while generating almost a hundred times the number of concept emptying responses and clusters."}, {"heading": "7. REFERENCES", "text": "[1] Html TIDY project. http: / / tidy.sourceforge.net /. [2] M. J. Cafarella, E. Wu, A. Halevy, Y. Zhang and D. Z. Wang. Webtables: Exploring the power of tables on the web. PVLDB, 2008. [3] J. Callan. The clueweb09 dataset. http: / / boston.lti.cs.cmu.edu / Data / clueweb09 /. A. Carlson, J. Betteridge, R. Wang, E. R. Hruschka, Jr., and T. M. Mitchell. Coupled semi-supervised learning for information extraction. In WSDM, 2010. W. H. E. Day and H. Edelsbrunner. Efficient algorithms for agglomerative hierarchical methods. In Journal of Classification, 1984."}], "references": [{"title": "Webtables: Exploring the power of tables on the web", "author": ["M.J. Cafarella", "E. Wu", "A. Halevy", "Y. Zhang", "D.Z. Wang"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Coupled semi-supervised learning for information extraction", "author": ["A. Carlson", "J. Betteridge", "R.C. Wang", "E.R. Hruschka", "Jr.", "T.M. Mitchell"], "venue": "In WSDM,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Efficient algorithms for agglomerative hierarchical clustering methods", "author": ["W.H.E. Day", "H. Edelsbrunner"], "venue": "In Journal of Classification,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1984}, {"title": "Web-scale information extraction in knowitall: (preliminary results)", "author": ["O. Etzioni", "M. Cafarella", "D. Downey", "S. Kok", "A.-M. Popescu", "T. Shaked", "S. Soderland", "D.S. Weld", "A. Yates"], "venue": "In WWW,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Unsupervised named-entity extraction from the web: An experimental study", "author": ["O. Etzioni", "M. Cafarella", "D. Downey", "A.-M. Popescu", "T. Shaked", "S. Soderland", "D.S. Weld", "A. Yate"], "venue": "In AI,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "Towards domain-independent information extraction from web tables", "author": ["W. Gatterbauer", "P. Bohunsky", "M. Herzog", "B. Kr\u00fcpl", "B. Pollak"], "venue": "In WWW,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Answering table augmentation queries from unstructured lists on the web", "author": ["R. Gupta", "S. Sarawagi"], "venue": "In VLDB,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Joint training for open-domain extraction on the web: exploiting overlap when supervision is limited", "author": ["R. Gupta", "S. Sarawagi"], "venue": "In WSDM,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Automatic acquisition of hyponyms from large text corpora", "author": ["M.A. Hearst"], "venue": "In ACL,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1992}, {"title": "Using anchor text, spam filtering and wikipedia for web search and entity", "author": ["J. Kamps", "R. Kaptein", "M. Koolen"], "venue": "ranking. TREC,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "A semi-supervised method to learn and construct taxonomies using the web", "author": ["Z. Kozareva", "E. Hovy"], "venue": "In EMNLP,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Annotating and searching web tables using entities, types and relationships", "author": ["G. Limaye", "S. Sarawagi", "S. Chakrabarti"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Concept discovery from text", "author": ["D. Lin", "P. Pantel"], "venue": "In COLING,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}, {"title": "Introduction to information retrieval", "author": ["C.D. Manning", "P. Raghavan", "H. Schtze"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Automatically labeling semantic classes", "author": ["P. Pantel", "D. Ravichandran"], "venue": "In HLT-NAACL,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "Towards the web of concepts: Extracting concepts from large datasets", "author": ["A. Parameswaran", "H. Garcia-Molina", "A. Rajaraman"], "venue": "In VLDB,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Probabilistic metrics for soft-clustering and topic model validation", "author": ["E. Ramirez", "R. Brena", "D. Magatti", "F. Stella"], "venue": "In Web Intelligence and Intelligent Agent Technology (WI-IAT),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "What is this, anyway: Automatic hypernym discovery", "author": ["A. Ritter", "S. Soderland", "O. Etzioni"], "venue": "In AAAI,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Acquiring hyponymy relations from web documents", "author": ["K. Shinzato", "K. Torisawa"], "venue": "In HLT-NAACL,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}, {"title": "Learning syntactic patterns for automatic hypernym discovery", "author": ["R. Snow", "D. Jurafsky", "A.Y. Ng"], "venue": "In NIPS,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2004}, {"title": "Cheap and fast - but is it good? evaluating non-expert annotations for natural language tasks", "author": ["R. Snow", "B. O\u2019Connor", "D. Jurafsky", "A.Y. Ng"], "venue": "In EMNLP,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Weakly-supervised acquisition of labeled class instances using graph random walks", "author": ["P.P. Talukdar", "J. Reisinger", "M. Pa\u015fca", "D. Ravichandran", "R. Bhagat", "F. Pereira"], "venue": "In EMNLP,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "Finding cars, goddesses and enzymes: parametrizable acquisition of labeled instances for open-domain information extraction", "author": ["B. Van Durme", "M. Pasca"], "venue": "In AAAI,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "Automatic set instance extraction using the web", "author": ["R.C. Wang", "W.W. Cohen"], "venue": "In ACL,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Character-level analysis of semi-structured documents for set expansion", "author": ["R.C. Wang", "W.W. Cohen"], "venue": "In EMNLP,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "Analyzing social bookmarking systems: A del.icio.us cookbook", "author": ["R. Wetzker", "C. Zimmermann", "C. Bauckhage"], "venue": "Mining Social Data (MSoDa) Workshop Proceedings,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Textrunner: Open information extraction on the web", "author": ["A. Yates", "M. Cafarella", "M. Banko", "O. Etzioni", "M. Broadhead", "S. Soderland"], "venue": "In NAACL,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}], "referenceMentions": [{"referenceID": 8, "context": "Hyponym patterns, sometimes called Hearst patterns [11], are surface patterns (like \u201cXs such as Y\u201d) indicating that X,Y are a concept-instance pair.", "startOffset": 51, "endOffset": 55}, {"referenceID": 12, "context": "Coordinate terms are most frequently detected by clustering terms based on distributional similarity [15]\u2014i.", "startOffset": 101, "endOffset": 105}, {"referenceID": 22, "context": "Various techniques can be used to combine these coordinate-term and hyponym information to generate additional concept-instance pairs [26, 22].", "startOffset": 134, "endOffset": 142}, {"referenceID": 19, "context": "Various techniques can be used to combine these coordinate-term and hyponym information to generate additional concept-instance pairs [26, 22].", "startOffset": 134, "endOffset": 142}, {"referenceID": 22, "context": "We also present a new method for combining hyponym and coordinate-term information, and show that on table-rich corpora, this method improves on previously-published techniques [26], obtaining higher accuracy while generating nearly hundred times the number of concept-instance pairs.", "startOffset": 177, "endOffset": 181}, {"referenceID": 8, "context": "The experiments in this paper are conducted on several different HTML corpora and a collection of Hearst pattern [11] instances that have been extracted from ClueWeb09, all of which are made available for future researchers.", "startOffset": 113, "endOffset": 117}, {"referenceID": 5, "context": "[8] focus on extracting tabular data from various kinds of pages that have table-like visual representations when rendered in a browser.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "The WebTables [2] system extracted schema information from a huge corpus of 14.", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "[9] focuses on the task of extending a table given a few seed rows.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "Similarly, SEAL (Set Expansion for Any Language) [28] is a set expansion system which starts with a few seed examples and extends them using lists detected using character-based heuristics.", "startOffset": 49, "endOffset": 53}, {"referenceID": 7, "context": "Gupta and Sarawagi [10] consider jointly training structured extraction models from overlapping web source (primarily in tables), thus avoiding the need for labeled data.", "startOffset": 19, "endOffset": 23}, {"referenceID": 11, "context": "[14] proposed a system to use an existing catalog and type hierarchy for annotating table columns and cells.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "These systems include KnowItAll [6, 7], ASIA [27], and Coupled Pattern Learning (CPL) [4].", "startOffset": 32, "endOffset": 38}, {"referenceID": 4, "context": "These systems include KnowItAll [6, 7], ASIA [27], and Coupled Pattern Learning (CPL) [4].", "startOffset": 32, "endOffset": 38}, {"referenceID": 23, "context": "These systems include KnowItAll [6, 7], ASIA [27], and Coupled Pattern Learning (CPL) [4].", "startOffset": 45, "endOffset": 49}, {"referenceID": 1, "context": "These systems include KnowItAll [6, 7], ASIA [27], and Coupled Pattern Learning (CPL) [4].", "startOffset": 86, "endOffset": 89}, {"referenceID": 15, "context": "[18] propose a concept extraction algorithm which can identify a canonical form of a concept, filtering out sub-concepts or superconcepts; and Ritter et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[20] describe a scheme for filtering concept-instance pairs, using a SVM classifier which uses as features frequency statistics for several Hearst patterns on a large corpus.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[22] learns \u201cdependency path\u201d features, which can further expand the set of conceptinstance pairs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "TextRunner [30] is an open-domain IE system which makes a single pass over the corpus of unstructured text and extracts a large set of relational tuples, without requiring any human input.", "startOffset": 11, "endOffset": 15}, {"referenceID": 14, "context": "Pantel and Ravichandran [17] proposes a method to automatically label distributional term clusters using Hearst-like patterns, and Van Durme and Pasca [26] proposed an alternative approach method to extract labeled classes of instances from unstructured text.", "startOffset": 24, "endOffset": 28}, {"referenceID": 22, "context": "Pantel and Ravichandran [17] proposes a method to automatically label distributional term clusters using Hearst-like patterns, and Van Durme and Pasca [26] proposed an alternative approach method to extract labeled classes of instances from unstructured text.", "startOffset": 151, "endOffset": 155}, {"referenceID": 21, "context": "[24] proposed a graph random walk based semi-supervised label propagation technique for open domain class instance extractions, which extends the system of Van Durme and Pasca by using table data (from WebTables) as well as free-text distributional clusters.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "Coupled SEAL (CSEAL) [4] use of mutual exclusion, containment and type checking relationships to extend SEAL, and CPL [4] and CSEAL are the two components of NELL [25], a multi-strategy semi-supervised learning system.", "startOffset": 21, "endOffset": 24}, {"referenceID": 1, "context": "Coupled SEAL (CSEAL) [4] use of mutual exclusion, containment and type checking relationships to extend SEAL, and CPL [4] and CSEAL are the two components of NELL [25], a multi-strategy semi-supervised learning system.", "startOffset": 118, "endOffset": 121}, {"referenceID": 18, "context": "Shinzato and Torisawa [21] showed that coordinate terms can be extracted from itemizations in structured web documents.", "startOffset": 22, "endOffset": 26}, {"referenceID": 5, "context": "[8] can provide more input data to learn sets from.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Non-parametric algorithms like agglomerative clustering [5] fit most of our requirements.", "startOffset": 56, "endOffset": 59}, {"referenceID": 23, "context": "These correspond to a subset of the Hearst patterns used in ASIA [27] together with some \u201cdoubly anchored\u201d versions of these patterns [13].", "startOffset": 65, "endOffset": 69}, {"referenceID": 10, "context": "These correspond to a subset of the Hearst patterns used in ASIA [27] together with some \u201cdoubly anchored\u201d versions of these patterns [13].", "startOffset": 134, "endOffset": 138}, {"referenceID": 22, "context": "Our method scores labels differently from Van Durme and Pasca method [26] It is also different in the sense that they output a concept-instance pair < x, y > only when < x, y > appears in the set of candidate concept-instance pairs, whereas we extend the labels to the whole cluster.", "startOffset": 69, "endOffset": 73}, {"referenceID": 25, "context": "Delicious Sports: This dataset is a subset of DAILabor Delicious corpus [29], created by taking only those URLs which are tagged as \u201csports\u201d.", "startOffset": 72, "endOffset": 76}, {"referenceID": 25, "context": "Delicious Music: This dataset is a subset of DAILabor Delicious corpus [29], created by taking only those URLs which are tagged as \u201cmusic\u201d.", "startOffset": 71, "endOffset": 75}, {"referenceID": 9, "context": "For this purpose we used the Fusion spam scores[12] provided by Waterloo university and used pages with spam-rank score higher than 60%.", "startOffset": 47, "endOffset": 51}, {"referenceID": 13, "context": "We compare the clustering algorithms in terms of commonly used clustering metrics: cluster purity (Purity), normalized mutual information (NMI), rand index (RI) [16] and Fowlkes-Mallows index (FM) which are defined as follows:", "startOffset": 161, "endOffset": 165}, {"referenceID": 16, "context": "[19].", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "We compare our hypernym recommendation technique with Van Durme and Pasca technique [26].", "startOffset": 84, "endOffset": 88}, {"referenceID": 20, "context": "The objective evaluation of the kind \u201cwhether X belongs to category Y\u201d is done using Amazon Mechanical Turk [23].", "startOffset": 108, "endOffset": 112}, {"referenceID": 22, "context": "We also presented a new method for combining candidate concept-instance pairs and coordinate-term clusters, and showed that on table-rich corpora, this method improved on Van Durme and Pasca method [26].", "startOffset": 198, "endOffset": 202}], "year": 2013, "abstractText": "We describe a open-domain information extraction method for extracting concept-instance pairs from an HTML corpus. Most earlier approaches to this problem rely on combining clusters of distributionally similar terms and conceptinstance pairs obtained with Hearst patterns. In contrast, our method relies on a novel approach for clustering terms found in HTML tables, and then assigning concept names to these clusters using Hearst patterns. The method can be efficiently applied to a large corpus, and experimental results on several datasets show that our method can accurately extract large numbers of concept-instance pairs.", "creator": "LaTeX with hyperref package"}}}