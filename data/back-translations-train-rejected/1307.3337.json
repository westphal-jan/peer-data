{"id": "1307.3337", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jul-2013", "title": "Unsupervised Gene Expression Data using Enhanced Clustering Method", "abstract": "Microarrays are made it possible to simultaneously monitor the expression profiles of thousands of genes under various experimental conditions. Identification of co-expressed genes and coherent patterns is the central goal in microarray or gene expression data analysis and is an important task in bioinformatics research. Feature selection is a process to select features which are more informative. It is one of the important steps in knowledge discovery. The problem is that not all features are important. Some of the features may be redundant, and others may be irrelevant and noisy. In this work the unsupervised Gene selection method and Enhanced Center Initialization Algorithm (ECIA) with K-Means algorithms have been applied for clustering of Gene Expression Data. This proposed clustering algorithm overcomes the drawbacks in terms of specifying the optimal number of clusters and initialization of good cluster centroids. Gene Expression Data show that could identify compact clusters with performs well in terms of the Silhouette Coefficients cluster measure.", "histories": [["v1", "Fri, 12 Jul 2013 06:20:59 GMT  (461kb)", "http://arxiv.org/abs/1307.3337v1", "5 pages, 1 figures, conference"]], "COMMENTS": "5 pages, 1 figures, conference", "reviews": [], "SUBJECTS": "cs.CE cs.LG", "authors": ["t chandrasekhar", "k thangavel", "e elayaraja", "e n sathishkumar"], "accepted": false, "id": "1307.3337"}, "pdf": {"name": "1307.3337.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Gene Expression Data using Enhanced Clustering Method", "authors": [], "emails": ["ch_ansekh80@rediffmail.com", "drktvel@gmail.com", "elayarajaphd.e@gmail.com", "en.sathishkumar@yahoo.in"], "sections": [{"heading": null, "text": "It is indeed the case that we are able to go in search of a solution that is capable of finding the solution that we need in order to find a solution."}, {"heading": "A. Analysis the Data", "text": "The gene expression data is min-max normalization by setting min 0 and max 1. Min-max normalization results in a linear transformation of the original data. Suppose that minA and maxA are the minimum and maximum values of an attribute. \u2212 \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\", \"\", \"\" \",\" \"\" \"\" \"\" \"\" \",\" \"\" \"\", \"\" \"\", \"\" \",\" \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\" \",\" \"\", \"\" \""}, {"heading": "B. Unsupervised Gene Selection", "text": "Gene selection is an important problem in the study of gene expression data. In some cases, there are too many redundant or missing values in gene expression data. In this section, an existing work by Velayutham and Thangavel et al. proposes an algorithm of unattended feature selection (unattended quick reduction algorithms) [21]. This method is based on dependency measurements using the rough set theory. The indiscernibility relationship thus generated can be considered a new mathematical tool for imperfect data analysis. Theory has found application in many fields. Objects characterized by the same information are indistinguishable (similar) in view of the information available about them. The indiscernibility relationship thus generated is the mathematical basis of the rough set theory. Any quantity of all indiscernible (similar) objects is called an elementary set and forms a basic set (of knowledge) of the universe."}, {"heading": "C. Unsupervised Quick Reduct Algorithm[21]", "text": "The USQR algorithm tries to calculate a reduction without exhaustively generating all possible subsets. It starts with an empty set and adds one after the other the attributes that lead to the largest increase in the coarse specified dependency metric until the maximum possible value for the dataset results from it. According to the algorithm, the mean dependency of each attribute subset is calculated and the best candidate is selected: g (1) R ({}) = K ({a}) and () algorithm 1: The USQR algorithm (C) C, the set of all conditional features; (1) R {(2) make (3) T (4) x (C-R) (5) Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-"}, {"heading": "A. K-Means Clustering", "text": "The main objective of cluster analysis is to group objects that are similar in a cluster and separate objects that differ from each other by assigning them to different clusters. One of the most popular cluster analysis methods is the K-Means cluster algorithm [3, 9, 12]. In this algorithm, objects are assigned to a predefined number of clusters specified by the user (let's assume K-Cluster). The idea is to select random cluster centers, one for each cluster. These centers will preferably be as far apart as possible. In this algorithm, euclidean distance is usually used to find the distance between data points and centers [6, 13, 22]. Euclidean distance between two multidimensional data points X = (x1, x2, x3,..., xm) and Y = (y1, y2, y3, y3,..., ym) the distance between data points is described as cluster."}, {"heading": "B. The Enhanced method", "text": "This section examines the cluster center initialization algorithm to improve the performance of the KMeans algorithm. http: / / Set of n datapoints. di = {x1, x2, x3,..., xi, xi,..., xm} / Set of attributes of one data point. k / / Number of desired clusters.Ensure: A set of k clusters.Steps: 1. In the given record D, if the data contains the bothpositive and negative attribute values, the values then go to step 2. Find the minimum attribute value in the given data D. 3. For each point we evaluate the data with the data."}, {"heading": "A. Comparative Analysis", "text": "To access the quality of the clusters, we used the silhouette measurement proposed by Rousseeuw [11, 15, 16]. In this method run the initial centric values that were taken 7, then as ten times running to ECIA with Kmeans cluster data in 7 groups as Table 3.TABLE II. COMPARATIVE ANALYSIS TO FILTER OF GENE EXPRESSION DATAData sets Before UnsupervisedGene SelectionAfter UnsupervisedGene selectionSerum 517 * 17 Yeast 2884 * 17 118 * 17Simulated 300 * 17 * 17 * 17Leukaemia 7129 * 34 142 * 34TABLE III. COMPARATIVE ANALYSIS OF GENE EXPRESSION DATAval.84 * 17 * 17 * 17Simulated 300 * 17 Leukaemia 7129 * 434TABLE 270,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,00"}, {"heading": "B. Performance Comparison", "text": "Among four sets of data, each produces a compact cluster and provides the best genes. In this thesis, the method of unattended gene selection USQR was investigated, which is used to avoid too many redundant or missing values in microarray gene expression data. In this unattended gene selection method, unattended gene selection is based on the use of rough set methods. These methods are used to obtain a minimum number of random gene sets, and then we use K-Means cluster technology to improve the quality of clusters. One of the disadvantages of the K-Means algorithm is the random selection of the initial seed point of the desired clusters. This was overcome with ECIA to avoid random selection of the initial values. Therefore, the ECIA algorithm is not dependent on cluster selection and automatic evaluation of the initial seed centering, and it produces different better results. Both algorithms were tested with different gene readings to determine the performance of the clusters."}], "references": [{"title": "Initializing K-Means using Genetic Algorithms", "author": ["Bashar Al-Shboul", "Sung-Hyon Myaeng"], "venue": "World Academy of Science, Engineering and Technology", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "K-Means Clustering Algorithm with Improved Initial center", "author": ["Chen Zhang", "Shixiong Xia"], "venue": "Second International Workshop on Knowledge Discovery and Data Mining (WKDD), pp. 790-792, 2009.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Mininmum Redundancy Feature Selection from Microarray Gene Expression Data\u201d, proceedings of the International Bioinformatic Conference", "author": ["Chris Ding", "Hanchuna Peng"], "venue": "Date on 11-14,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "A New Algorithm to Get the Initial Centroids", "author": ["F. Yuan", "Z.H. Meng", "H.X. Zhangz", "C.R. Dong"], "venue": "proceedings of the 3rdInternational Conference on Machine Learning and Cybernetics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "K - Modes clustering", "author": ["A Chaturvedi J.C.", "P Green"], "venue": "Journals of Classification, (18):35\u201355, 2001.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Fuzzy C means method for clustering microarray data", "author": ["Doulaye Dembele", "Philippe Kastner"], "venue": "Bioinformatics, vol.19,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "An Interactive Approach to mining Gene Expression Data", "author": ["Daxin Jiang", "Jian Pei", "Aidong Zhang"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "Network constrained clustering for gene microarray Data\u201d, doi:10.1093 /bioinformatics", "author": ["Dongxiao Zhu", "Alfred O Hero", "Hong Cheng", "Ritu Khanna", "Anand Swaroop"], "venue": "bti 655,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "An Efficient enhanced K-Means clustering algorithm", "author": ["A.M Fahim", "M Salem A", "A Torkey", "A Ramadan M"], "venue": "Journal of Zhejiang University,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Automatic Generation of Merge Factor for Clustering Microarray Data", "author": ["K Karteeka Pavan", "Allam Appa Rao", "A V Dattatreya Rao", "GR Sridhar"], "venue": "IJCSNS International Journal of Computer Science and Network Security,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Divisive Correlation Clustering Algorithm (DCCA) for grouping of genes: detecting varying Patterns in expression profiles", "author": ["K.R De", "A. Bhattacharya"], "venue": "bioinformatics, Vol. 24, pp. 1359-1366, 2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Improving the accuracy and efficiency of the K-Means clustering algorithm\u201d, international Conference on Data Mining and Knowledge Engineering (ICDMKE)", "author": ["K.A. Abdul Nazeer", "M.P. Sebastian"], "venue": "Proceedings of the World Congress on Engineering (WCE- 2009), London, UK", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Selecting variables for K-Means cluster analysis by using a genetic algorithm that optimises the silhouettes", "author": ["R. Llet\u00ed", "M.C. Ortiz", "L.A. Sarabia", "M.S. S\u00e1nchez"], "venue": "Analytica Chimica Acta,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "An Efficient Approach for Computing Silhouette Coefficients", "author": ["Moh'd Belal Al- Zoubi", "Mohammad al Rawi"], "venue": "Journal of Computer Science", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Means Clustering Algorithm with Improved Initial Center", "author": ["Madhu Yedla", "Srinivasa Rao Pathakota", "T M Srinivasa", "\u201cEnhancing K"], "venue": "Madhu Yedla et al. / (IJCSIT) International Journal of Computer Science and Information Technologies,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Microarray biochip technology", "author": ["Sunnyvale", "Schena M"], "venue": "CA: Eaton Publishing;", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2000}, {"title": "An Effective Technique for Clustering Incremental Gene expression data", "author": ["Sauravjoyti Sarmah", "Dhruba K. Bhattacharyya"], "venue": "IJCSI International Journal of Computer Science Issues,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Improved K-Means Clustering Algorithm for Exploring Local Protein Sequence Motifs Representing Common Structural Property", "author": ["Wei Zhong", "Gulsah Altun", "Robert Harrison", "Phang C. Tai", "Yi Pan"], "venue": "IEEE transactions on nano bio science,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Cancer Classification Using Single Genes", "author": ["Xiaosheng Wang", "Osamu Gotoh"], "venue": "20th international conference on Genome informatics(GIW 2009),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Incremental Genetic K-Means Algorithm and its Application in Gene Expression Data Analysis", "author": ["Y. Lu", "S. Lu", "F. Fotouhi", "Y. Deng", "S. Brown"], "venue": "BMC Bioinformatics,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "Means Clustering Algorithm with Improved Initial Center", "author": ["Y. Madhu", "Srinivasa Rao Pathakota", "T M Srinivasa", "\u201cEnhancing K"], "venue": "Madhu Yedla et al. / (IJCSIT) International Journal of Computer Science and Information Technologies,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}], "referenceMentions": [{"referenceID": 10, "context": "Results from these experiments are usually presented in the form of a data matrix in which rows represent genes and columns represent conditions or samples [13].", "startOffset": 156, "endOffset": 160}, {"referenceID": 15, "context": "Analysis of these data sets reveals genes of unknown functions and the discovery of functional relationships between genes [19].", "startOffset": 123, "endOffset": 127}, {"referenceID": 16, "context": "In sample based clustering, the samples can be partitioned into homogeneous groups where the genes are regarded as features and the samples as objects [20].", "startOffset": 151, "endOffset": 155}, {"referenceID": 2, "context": "another [4].", "startOffset": 8, "endOffset": 11}, {"referenceID": 2, "context": "Of the tens of thousands of genes in experiments, only a smaller number of them show strong correlation with the targeted phenotypes [4, 17].", "startOffset": 133, "endOffset": 140}, {"referenceID": 1, "context": "The most popular clustering algorithms in microarray gene expression analysis are Hierarchical clustering, K-Means clustering [3], and SOM [9].", "startOffset": 126, "endOffset": 129}, {"referenceID": 7, "context": "The most popular clustering algorithms in microarray gene expression analysis are Hierarchical clustering, K-Means clustering [3], and SOM [9].", "startOffset": 139, "endOffset": 142}, {"referenceID": 5, "context": "The most popular clustering methods are K-Means clustering algorithm which is developed by Mac Queen [7].", "startOffset": 101, "endOffset": 104}, {"referenceID": 0, "context": "To overcome the above drawback the current research focused on developing the clustering algorithms without giving the initial number of clusters [2, 3, 5].", "startOffset": 146, "endOffset": 155}, {"referenceID": 1, "context": "To overcome the above drawback the current research focused on developing the clustering algorithms without giving the initial number of clusters [2, 3, 5].", "startOffset": 146, "endOffset": 155}, {"referenceID": 3, "context": "To overcome the above drawback the current research focused on developing the clustering algorithms without giving the initial number of clusters [2, 3, 5].", "startOffset": 146, "endOffset": 155}, {"referenceID": 2, "context": "There are studies suggesting that only a few genes are sufficient [4].", "startOffset": 66, "endOffset": 69}, {"referenceID": 6, "context": "These \"marker\" genes provide additional scientific understanding of the problem [8].", "startOffset": 80, "endOffset": 83}, {"referenceID": 2, "context": "The discretization is done as follows [4].", "startOffset": 38, "endOffset": 41}, {"referenceID": 19, "context": "Any set of all indiscernible (similar) objects is called an elementary set, and forms a basic granule (atom) of knowledge about the universe [17, 24].", "startOffset": 141, "endOffset": 149}, {"referenceID": 1, "context": "One of the most popular clustering methods is K-Means clustering algorithm [3, 9, 12].", "startOffset": 75, "endOffset": 85}, {"referenceID": 7, "context": "One of the most popular clustering methods is K-Means clustering algorithm [3, 9, 12].", "startOffset": 75, "endOffset": 85}, {"referenceID": 4, "context": "In this algorithm mostly Euclidean distance is used to find distance between data points and centroids [6, 13, 22].", "startOffset": 103, "endOffset": 114}, {"referenceID": 10, "context": "In this algorithm mostly Euclidean distance is used to find distance between data points and centroids [6, 13, 22].", "startOffset": 103, "endOffset": 114}, {"referenceID": 17, "context": "In this algorithm mostly Euclidean distance is used to find distance between data points and centroids [6, 13, 22].", "startOffset": 103, "endOffset": 114}, {"referenceID": 14, "context": "Algorithm 2: K-Means clustering algorithm [18]", "startOffset": 42, "endOffset": 46}, {"referenceID": 11, "context": "Though the K-Means algorithm is simple, it has some drawbacks of quality of the final clustering, since it highly depends on the arbitrary selection of the initial centroids[1, 14].", "startOffset": 173, "endOffset": 180}, {"referenceID": 20, "context": "Algorithm 3: Enhanced Centre Initialization Algorithm (ECIA) [25]", "startOffset": 61, "endOffset": 65}, {"referenceID": 18, "context": "In this section, we describe the data sets used to analyze the methods studied in sections 2 and 3, which are arranged for the listed in Table 1, number of features/genes are in column wise, and number of items/samples are in row wise [23].", "startOffset": 235, "endOffset": 239}, {"referenceID": 8, "context": "1) Serum data: This data set is described and used in [10].", "startOffset": 54, "endOffset": 58}, {"referenceID": 9, "context": "shl and corresponds to the selection of 517 genes whose expression varies in response to serum concentration inhuman fibroblasts [11].", "startOffset": 129, "endOffset": 133}, {"referenceID": 1, "context": "The set contains 300 Genes [3].", "startOffset": 27, "endOffset": 30}, {"referenceID": 9, "context": "To access the quality of the clusters, we used the silhouette measure proposed by Rousseeuw [11, 15, 16].", "startOffset": 92, "endOffset": 104}, {"referenceID": 12, "context": "To access the quality of the clusters, we used the silhouette measure proposed by Rousseeuw [11, 15, 16].", "startOffset": 92, "endOffset": 104}, {"referenceID": 13, "context": "To access the quality of the clusters, we used the silhouette measure proposed by Rousseeuw [11, 15, 16].", "startOffset": 92, "endOffset": 104}], "year": 2013, "abstractText": "Microarrays are made it possible to simultaneously monitor the expression profiles of thousands of genes under various experimental conditions. Identification of co-expressed genes and coherent patterns is the central goal in microarray or gene expression data analysis and is an important task in bioinformatics research. Feature selection is a process to select features which are more informative. It is one of the important steps in knowledge discovery. The problem is that not all features are important. Some of the features may be redundant, and others may be irrelevant and noisy. In this work the unsupervised Gene selection method and Enhanced Center Initialization Algorithm (ECIA) with K-Means algorithms have been applied for clustering of Gene Expression Data. This proposed clustering algorithm overcomes the drawbacks in terms of specifying the optimal number of clusters and initialization of good cluster centroids. Gene Expression Data show that could identify compact clusters with performs well in terms of the Silhouette Coefficients cluster measure. Keywords\u2014Clustering; Unsupervised Feature Selection; ECIA; K-Means; Gene expression data", "creator": "Microsoft\u00ae Office Word 2007"}}}