{"id": "1307.3687", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jul-2013", "title": "On Analyzing Estimation Errors due to Constrained Connections in Online Review Systems", "abstract": "Constrained connection is the phenomenon that a reviewer can only review a subset of products/services due to narrow range of interests or limited attention capacity. In this work, we study how constrained connections can affect estimation performance in online review systems (ORS). We find that reviewers' constrained connections will cause poor estimation performance, both from the measurements of estimation accuracy and Bayesian Cramer Rao lower bound.", "histories": [["v1", "Sun, 14 Jul 2013 01:37:48 GMT  (60kb)", "http://arxiv.org/abs/1307.3687v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.LG", "authors": ["junzhou zhao"], "accepted": false, "id": "1307.3687"}, "pdf": {"name": "1307.3687.pdf", "metadata": {"source": "CRF", "title": "On Analyzing Estimation Errors due to Constrained Connections in Online Review Systems", "authors": ["Junzhou Zhao"], "emails": [], "sections": [{"heading": null, "text": "Most works ignore the function of the underlying topology of ORS. The topology of a rating system that represents an online review is a fact. INTRODUCTIONOnline reviews are increasingly important factors for customers to decide whether they want to buy a product or service in online markets. Therefore, online review systems have become battlegrounds for companies that compete with each other by hiring \"Internet Water Mercenaries,\" also known as paid spammers, to give positive reviews of their products / services and negative reviews of their competitors. These fake reviews disrupt customers \"confidence in the quality of products / services and companies that ruin their reputation.Therefore, an increasingly important problem in online review systems is the accuracy of finding the truth of both reviewers (e.g. the reviewer is a spammer or non-spammer) and articles (e.g. the product / service judgment of customers about the quality of products / services provided by companies)."}, {"heading": "II. BACKGROUND AND BASIC RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Data Model", "text": "Following on from the existing work [7], [5], [6] we assume that there are a number of reviewers who represent the quality of article i, e.g. zi = + 1 if article i is good; zi = \u2212 1 if I am bad. Any reviewer can select articles he wants to review. However, a review represents the reviewer's attitude to an article. If we use article i to denote the review to i, it means that article i (or rui = \u2212 1) is rated as good (or bad). However, reviewers are not always set exactly to article, and we use article i [0, 1] to represent the probability that the reviewer can give correct reviews, i.e. that article i (rui = zi)."}, {"heading": "B. Maximum A Posteriori Estimator", "text": "A convenient way to estimate the parameters of the previous model is to consider both as parameters and z as hidden variables (3). David and Skene [3] presented an approach to maximizing expectations (EM) to maximize probability. (1) E-step: In the E-step we must calculate the probability of hidden variables containing the other variables P (z | R). (2) E-step: In the E-step we must calculate the probability of hidden variables resulting from the other variables P (z | R, \u03b8) that can be transferred to the other variables P (zi | R \u00b7 i, \u03b8)."}, {"heading": "III. ESTIMATION ERRORS ANALYSIS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Lower Bound on Estimation Errors", "text": "The mean square error of 2001 is defined as the MAP estimate [9, Chapter 2]. We rewrite Van Trees \"book [9, page 73] Eq. (217) and get the following RelationshipMSE estimate [9, Chapter 2] and get the following RelationshipMSE estimate. (12) is the element (u, v) of the Fisher information matrix J. The above relationship requires that the MAP estimate be weakly unbiased [9, Chapter 2], where Juv = \u2212 E [6] -E [8] -E-Logp (\u03b8 | R) -prediction of the MAP estimate defined by the algorithm is unknown. However, it is known that under general conditions for large n the posterior distribution of the MAP coefficient may be different. [9, Chapter 2] the MAP estimate defined by the algorithm is different."}, {"heading": "B. Obtaining BCRLB in Combining with EM Procedure", "text": "Since P (\u03b8 | R) P (z | zipzipp \u2212 zipp) \u2212 zipp (z | zipp, R), (13) Then becomes 2 logP (zipp, z | R), Then becomes 2 logP (zipp, z | R), Then becomes 2 logP (zipp, z | R), Then becomes 2 logP (zipp, z | R), Finally becomes 2 logP (zipp, z | R), The latter P (z | zipp), The latter P (z | V), The latter P (z | V), The latter P (z | V), The latter P (z | V), The latter P (z | VI, R), The latter P (z | VI, R), The latter P (z | VI), The latter P (z | V), The latter P (z | VI, R), The latter P (z | VI, R), The latter P (z | R)."}, {"heading": "IV. EMPIRICAL RESULTS", "text": "To investigate how constrained compounds can affect the estimation accuracy of MAPE, we first present several two-sided graph models, and then examine how these models affect the performance of MAPE, which is measured by the accuracy of classification of items and BCRLBs."}, {"heading": "A. Bipartite Graph Models", "text": "1) Random Graph Model Grnd: Each edge (u, i) in Grnd is formed by evenly selecting a reviewer u \u0433V and evenly selecting an article i-I. 2) Item Preferential Attachment Graph Model GiPA: The assumption of this model is that popular articles are easier to obtain ratings. Therefore, an edge (u, i) in GiPA is formed by evenly randomly selecting a reviewer u-V and selecting the article i-I with probability ratio to i-degree in GiPA. 3) Reviewers and Item Preferential Attachment Graph Model GriPA: We can also assume that a more active reviewer is more likely to review articles. Therefore, an edge (u, i) is formed in GiPA by selecting a reviewer u-V with probability ratio to u-degree and article i-I with probability ratio to i-degree in GiPA."}, {"heading": "B. Building Ground Truth Known Datasets", "text": "Using a diagram created by one of the above models, we describe the procedure for generating verification samples R.We specify a series of | V | reviewers and | I | items. Let's assume that each user's parameter \u03b8u is selected from the previous beta distribution P (\u03b8u) \u0441\u0430 \u2212 1u (1 \u2212 \u03b8u) \u03b2 \u2212 1, i.e., the reviewer u gives the correct verification with a predetermined probability \u03b1 / (\u03b1 + \u03b2).For each item i, we randomly assign a designation zi [\u00b1 1} by flipping a fair coin, i.e. P (zi = + 1) = P (zi = \u2212 1) = 0.5. The method for generating R = [1] follows the following. Algorithm 1: Generating R.Input: G (V, I, E), {zi} i-I, {percu} u-V, n. Output: verification samples < if it turns into a random number < R.1 | 1 when it turns into [Pi], when it does a certain number [Pi]."}, {"heading": "C. Comparing Items Inference Accuracy Under Different Graphs", "text": "In the first experiment, we compare the classification accuracy of items under different graph models. We define an item labeled + 1 (or \u2212 1) if \u00b5i (+ 1) > 0.5 (or \u00b5i (\u2212 1) > 0.5). Accuracy is defined as Accuracy = TP + TNP + N. TP and TN are the true positives and true negatives, respectively. Accuracy describes the fraction of items that can be corrected.The results are presented in Fig. 2. First, we created diagrams with the number of nodes | V | = 500 and the different number of edges (| E | = 1000, 2000, 3000, 4000, 5000) using different graph models. In each figure, we created summary samples of different sizes (500 \u2264 | R | \u2264 5000) and show the accuracy of items averaged over 100 experiments. We observe that if | R | is increased, the accuracy of grit models also increases as the modometer approaches, and that MAPE confirms the differences are greater."}, {"heading": "D. Comparing Estimation Errors Under Different Graphs", "text": "In the second experiment, we examine how different graph modes affect BCRLBs. Settings are the same as in the previous experiment. We compare the average rooted mean of quadratic error (RMSE) (defined as RMSE = \u221a MSE) across different graph models in Fig. 3. RMSE decreases approximately at the rate of 1 / n across all graphs. In different graphs, when n is large (we do not consider BCRLB to be small n, because MAPE tends to be small when n is small), the RMSE on GriPA has the largest lower limit, then GiPA comes, and the RMSE on Grnd has the lowest lower limit. This indicates that the RMSE of all MAPEs gets worse as more constraints on graphs are added."}, {"heading": "V. CONCLUSION", "text": "Restricted connections are common in the real world. A reviewer cannot check all articles in online verification systems for various reasons. In this study, we find that this restricted connection will always cause poor key performance, both from the point of view of inference accuracy and the RMSE lower limit."}], "references": [{"title": "Opinion fraud detection in online reviews by network effects", "author": ["Leman Akoglu", "Rishi Chandy", "Christos Faloutsos"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Mathematical Methods of Statistics", "author": ["Harald Cram\u00e9r"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1946}, {"title": "Maximum likelihood estimation of observeerror-rates using the em algorithm", "author": ["A.P. Dawid", "A.M. Skene"], "venue": "JSTOR,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1979}, {"title": "Assessing the accuracy of the maximum lielihood estimator: Observed versus expected fisher information", "author": ["Bradley Efron", "David V. Hinkley"], "venue": "JSTOR, 65:457\u2013482,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1978}, {"title": "Iterative learning for reliable crowdsourcing systems", "author": ["David R. Karger", "Sewoong Oh", "Devavrat Shah"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Variational inference for crowdsourcing", "author": ["Qiang Liu", "Jian Peng", "Alexander Ihler"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Learning from crowds", "author": ["Vikas C. Raykar", "Shipeng Yu", "Linda H. Zhao", "Gerardo Hermosillo Valadez", "Charles Florin", "Luca Bogoni"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Toos for Statistics Inference: Methods for the Exploration of Posterior Distribution and Likelihood Functions", "author": ["Martin A. Tanner"], "venue": "Springer Series in Statistics,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Detection, Estimation, and Modulation Theory", "author": ["H.L. Van Trees"], "venue": "Wiley, 1st edition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1968}, {"title": "Review graph based online store review spammer detection", "author": ["Guan Wang", "Sihong Xie", "Bing Liu", "Philip S. Yu"], "venue": "Grnd GiPA GriPA", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}], "referenceMentions": [{"referenceID": 9, "context": "In previous studies[10], [1], most of the works ignore the function of the underlying topology of ORS.", "startOffset": 19, "endOffset": 23}, {"referenceID": 0, "context": "In previous studies[10], [1], most of the works ignore the function of the underlying topology of ORS.", "startOffset": 25, "endOffset": 28}, {"referenceID": 6, "context": "Data Model Following the existing works[7], [5], [6], we assume that there are a set of reviewers V and a set of items I in an online review system.", "startOffset": 39, "endOffset": 42}, {"referenceID": 4, "context": "Data Model Following the existing works[7], [5], [6], we assume that there are a set of reviewers V and a set of items I in an online review system.", "startOffset": 44, "endOffset": 47}, {"referenceID": 5, "context": "Data Model Following the existing works[7], [5], [6], we assume that there are a set of reviewers V and a set of items I in an online review system.", "startOffset": 49, "endOffset": 52}, {"referenceID": 0, "context": "However, reviewers are not always accurate to review items, and we use \u03b8u \u2208 [0, 1] to represent the probability that the reviewer can give correct reviews, i.", "startOffset": 76, "endOffset": 82}, {"referenceID": 2, "context": "Maximum A Posteriori Estimator A convenient way to estimate parameters of the previous model is by considering \u03b8 as parameters and z as hidden variables[3].", "startOffset": 152, "endOffset": 155}, {"referenceID": 2, "context": "David and Skene[3] presented an expectation maximization (EM) approach to maximize the likelihood.", "startOffset": 15, "endOffset": 18}, {"referenceID": 1, "context": "However, it is known that under general conditions, for large n, the posterior distribution of \u03b8 can be approximated by normal distribution[2], [9], [4], [8] P (\u03b8|R) \u2192 N (\u03b8\u0302MAP, I(\u03b8\u0302MAP)) as n \u2192 \u221e, where I(\u03b8\u0302MAP) is the observed Fisher information matrix, and each element (u, v) of I(\u03b8\u0302MAP) is defined by [I(\u03b8\u0302MAP)]uv = \u2212 \u2202 logP (\u03b8|R) \u2202\u03b8u\u2202\u03b8v \u2223", "startOffset": 139, "endOffset": 142}, {"referenceID": 8, "context": "However, it is known that under general conditions, for large n, the posterior distribution of \u03b8 can be approximated by normal distribution[2], [9], [4], [8] P (\u03b8|R) \u2192 N (\u03b8\u0302MAP, I(\u03b8\u0302MAP)) as n \u2192 \u221e, where I(\u03b8\u0302MAP) is the observed Fisher information matrix, and each element (u, v) of I(\u03b8\u0302MAP) is defined by [I(\u03b8\u0302MAP)]uv = \u2212 \u2202 logP (\u03b8|R) \u2202\u03b8u\u2202\u03b8v \u2223", "startOffset": 144, "endOffset": 147}, {"referenceID": 3, "context": "However, it is known that under general conditions, for large n, the posterior distribution of \u03b8 can be approximated by normal distribution[2], [9], [4], [8] P (\u03b8|R) \u2192 N (\u03b8\u0302MAP, I(\u03b8\u0302MAP)) as n \u2192 \u221e, where I(\u03b8\u0302MAP) is the observed Fisher information matrix, and each element (u, v) of I(\u03b8\u0302MAP) is defined by [I(\u03b8\u0302MAP)]uv = \u2212 \u2202 logP (\u03b8|R) \u2202\u03b8u\u2202\u03b8v \u2223", "startOffset": 149, "endOffset": 152}, {"referenceID": 7, "context": "However, it is known that under general conditions, for large n, the posterior distribution of \u03b8 can be approximated by normal distribution[2], [9], [4], [8] P (\u03b8|R) \u2192 N (\u03b8\u0302MAP, I(\u03b8\u0302MAP)) as n \u2192 \u221e, where I(\u03b8\u0302MAP) is the observed Fisher information matrix, and each element (u, v) of I(\u03b8\u0302MAP) is defined by [I(\u03b8\u0302MAP)]uv = \u2212 \u2202 logP (\u03b8|R) \u2202\u03b8u\u2202\u03b8v \u2223", "startOffset": 154, "endOffset": 157}], "year": 2013, "abstractText": "In this work, we study how constrained connections can cause estimation errors in online review systems. Constrained connection is the phenomenon that a reviewer can only review a subset of products/services due to reviewer\u2019s narrow range of interests or limited attention capacity. We find that reviewers\u2019 constrained connections will cause poor inference performance, both from the measurements of estimation accuracy and Bayesian Cram\u00e9r Rao lower bound.", "creator": "gnuplot 4.6 patchlevel 0"}}}