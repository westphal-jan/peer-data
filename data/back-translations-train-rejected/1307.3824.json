{"id": "1307.3824", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jul-2013", "title": "The Fundamental Learning Problem that Genetic Algorithms with Uniform Crossover Solve Efficiently and Repeatedly As Evolution Proceeds", "abstract": "This paper establishes theoretical bonafides for implicit concurrent multivariate effect evaluation--implicit concurrency for short---a broad and versatile computational learning efficiency thought to underlie general-purpose, non-local, noise-tolerant optimization in genetic algorithms with uniform crossover (UGAs). We demonstrate that implicit concurrency is indeed a form of efficient learning by showing that it can be used to obtain close-to-optimal bounds on the time and queries required to approximately correctly solve a constrained version (k=7, \\eta=1/5) of a recognizable computational learning problem: learning parities with noisy membership queries. We argue that a UGA that treats the noisy membership query oracle as a fitness function can be straightforwardly used to approximately correctly learn the essential attributes in O(log^1.585 n) queries and O(n log^1.585 n) time, where n is the total number of attributes. Our proof relies on an accessible symmetry argument and the use of statistical hypothesis testing to reject a global null hypothesis at the 10^-100 level of significance. It is, to the best of our knowledge, the first relatively rigorous identification of efficient computational learning in an evolutionary algorithm on a non-trivial learning problem.", "histories": [["v1", "Mon, 15 Jul 2013 06:32:52 GMT  (390kb,D)", "http://arxiv.org/abs/1307.3824v1", "For an easy introduction to implicit concurrency (with animations), visitthis http URL"]], "COMMENTS": "For an easy introduction to implicit concurrency (with animations), visitthis http URL", "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.CC cs.DM cs.LG", "authors": ["keki m burjorjee"], "accepted": false, "id": "1307.3824"}, "pdf": {"name": "1307.3824.pdf", "metadata": {"source": "CRF", "title": "The Fundamental Learning Problem that Genetic Algorithms with Uniform Crossover Solve Efficiently and Repeatedly As Evolution Proceeds", "authors": ["Keki M. Burjorjee"], "emails": ["kekib@cs.brandeis.edu"], "sections": [{"heading": "1 Introduction", "text": "We have recently hypothesized [2] that an efficient form of computer-aided learning underlies universal, nonlocal, noise-tolerant optimizations of genetic algorithms with uniform crossover (UGAs).The hypothetical computational efficiency, implicit simultaneous multivariate effect evaluation - or implicit simultaneity - is broad and versatile, and has significant implications for efficient large-scale, universal global optimization in the presence of noise, and hence, in turn, for large-scale machine learning. In this paper, we describe implicit simultaneity and explain how it can advance a universal, non-local, noise-tolerant optimization. Subsequently, we find that implicit simultaneity is a bonafide form of efficient computer-aided learning by using it to come close to optimal limits of the interrogation and time complexity of an algorithm that triggers a limited version of a learning literature:"}, {"heading": "2 Implicit Concurrenct Multivariate Effect Evaluation", "text": "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111"}, {"heading": "2.1 Use (and Abuse) of Implicit Concurrency", "text": "Assuming that implicit simultaneity is possible, how can it be used to drive efficient general-purpose, non-local, noise-tolerant optimization? Consider the following heuristics: Use implicit simultaneity to identify a rough schema partition JIK with a significant effect. Now, limit future searches to the schema in that partition with the highest average scan capability. Limitation of future searches in this way boils down to permanently specifying the bits in each place whose index in me has a fixed value, and performing the search over the remaining places. In other words, selecting a schema effectively leads to a new, low-dimensional search area. Importantly, rough schema partitions in the new search space that has negligible effects in the old search space have a detectable effect on the new space."}, {"heading": "2.2 Needed: The Scientific Method, Practiced With Rigor", "text": "Unfortunately, several aspects of the above description are ambiguous. (How small is the hypothesis? What constitutes a \"negligible\" effect?) In fact, a formal statement of the above, let alone formal proof, is difficult to provide. Evolutionary algorithms are typically constructed from the point of view of biomikry, not formal analyzability, making it difficult to formalize / prove complexity theory results without making simplistic assumptions that effectively neutralize the algorithm or the fitness function used in the analysis. We have argued before [2] that adopting the scientific method [15] is a necessary and appropriate response to this hurdle. Finally, strictly practiced science is the foundation of many useful technical disciplines. A hallmark of rigorous science is the ongoing creation and testing of predictions. Predictions that prove to be true give credence to the hypotheses they bring with them."}, {"heading": "2.3 Implicit Concurrency 6= Implicit Parallelism", "text": "Given the name and description of the concepts in schema theory, implicit simultaneity bears a superficial resemblance to implicit parallelism; the two hypothetical phenomena are emphatically not identical. We present a comparison between the two with the observation that implicit simultaneity and implicit parallelism belong to different types of genetic algorithms - one with a close link between genetic loci and one without linkage. This difference does not make these hypothetical engines of optimization competitive from a scientific perspective. Nevertheless, a comparison between the two is instructive of what they reveal about implicit simultaneity."}, {"heading": "3 The Learning Model", "text": "For each quantity K so that | K | < n and each binary string x {0, 1} n the string y, whose indexes are not in K. A significant attribute with random classification error is a Tupel???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????"}, {"heading": "4 Our Result and Approach", "text": "For k = 7 and p = 1 / 5, we specify an algorithm that learns almost correctly < k, p, p > in O (log1.585 n) queries and O (n log1.585 n) time. Our argument is based on the use of hypotheses tests to reject two null hypotheses, each of which is adjusted to a Bonferroni significance level of 10 \u2212 100 / 2. In other words, we rely on a hypotheses test based on the rejection of a global null hypothesis at the 10 \u2212 100 significance level. In layman's terms, our result is based on conclusions that have a probability of 1 in 10100 x to be wrong. While approximately correct learning lends itself to easy comparisons with other forms of learning in the computational learning literature, the following, weaker, definition of learning ltltl ltl, which is performed in a more natural way, is the definition of the problem."}, {"heading": "5 Symmetry Analysis Based Conclusions", "text": "For each integer m * Z +, Dm is the set {0, 1m, 2 m \u00b2 q,.., m \u2212 1 m, 1}. Let V be some genetic algorithm with a population of bitstring chromosomes of length n. A hypothetical population is defined in Figure 1. We define the 1-frequency of any place i *, the size of the population. [n] In each generation, the frequency of the bit string 1 at place i in the population of V in the population of V at place i in generation divided by m, the size of the population of the population of K. [1,.] let oneFreq (V, \u03c4, i) denote the discrete probability distribution over domain Dm, which results in the 1-frequency of the place i in generation."}, {"heading": "6 Statistical Hypothesis Testing Based Conclusions", "text": "Fact 6: Let D be some discrete set. Let D be any subset S'D, and any independent and identically distributed random variables X1,., XN, the following statements are synonymous: 1. (1 \u2212) NLet \"7\" denotes the equality function over seven bits, let \"s\" = < n = 5, k = 7, f = 7, K = [7], p = 1 / 5 > be an oracle, and let's be the genetic algorithm described in Algorithm 1 with population size 1500 and mutation rate 0.004 that treats as a fitness function. \""}, {"heading": "7 Discussion and Conclusion", "text": "We used an empirical symmetrical proof method with a probability of error of 1: 10100 to conclude that a genetic algorithm with a uniform crossover can be used to solve the problem of noisy learning parities < k = 7, f = 7, \u03b7 = 1 / 5 > in O (log1.585 n) queries and O (n log1.585 n) time. These limits are slightly higher than the known optimal limits for a more difficult version of the problem in which the oracle is not interrogated adaptively: O (log n) or O (n) [6, 8]. Narrower limits in terms of interrogation complexity than those obtained can be achieved by recursive majority tuning with a higher branching factor (e.g. 5 instead of 3). However, for our purposes the obtained limits are sufficient. Finding that a genetic algorithm with uniform frequency branches can easily be used to achieve the general solution of the two-way hypothesis and to achieve the optimum limits required >."}, {"heading": "A Formal Analysis", "text": "Algorithm 3: Recursive-3-way-Maj (', (x1,., x3') = 1 < K = 1 (< K = 1,., x3 ') 1 (< K = 1) 1 (< K = 1) 1 (< K = 1 (.,., x3') 5 y2 = Recursive-3-way-Maj (',.,., x3') 1 (< K = 1) 1 (.,.,.,.,.) 2 (.,.,.) 2 (.,.,.,.) 2 (.,.,.,.,.,.) 2 (.,.,.,.,. (.,.,.) 2 (.,.,.,. (.,.,.). (.,.,. (.,.). (.,.,. (.,.). (.,.,. (.,.,.). (.,.,. (.,.). (.,. (.,.,.). (.,. (.,.). (.,.,.,. (.,.,.). (.,.,.,. (.,.,.). (.,.,. (.,.,.,.,.). (.,.,. (.,.,.,.,.,.). (.,.,.,.,.,.,.,.,. (.,.,.,.,.,.,.,.,.). (.,.,. (.,.,.,.,.,.,.,.). (.,.,.,.). (.,.,. (.,.,.,..,.,.,.,.,.,.,.,.,.). (.,.,. (.,.,.,.,.,.,.,.,..,.,.,..,.,..,.,.,.).,...,.,.,..,...,.."}, {"heading": "B On Our Use of Symmetry", "text": "A homologous crossover operation between two chromosomes of length \"can be modeled by a vector of\" random binary variables < X1,.., X, \"of which a crossover mask is sampled. Similarly, a mutation operation can be independently and identically distributed by a vector of\" random binary variables < Y1,., Y, \"of which a mutation mask is sampled by the random variables X1,., X.\" This absence of positive bias [5] in uniform crossover constitutes symmetry. Essentially, the bits of all chromosomes permutate before crossover, and permutate the bits before crossover dynamics."}], "references": [{"title": "Sufficient conditions for coarse-graining evolutionary dynamics", "author": ["Keki Burjorjee"], "venue": "In Foundations of Genetic Algorithms 9 (FOGA IX),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Explaining optimization in genetic algorithms with uniform crossover", "author": ["Keki M. Burjorjee"], "venue": "In Proceedings of the twelfth workshop on Foundations of genetic algorithms XII, FOGA XII", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Introduction to Algorithms", "author": ["T.H. Cormen", "C.H. Leiserson", "R.L. Rivest"], "venue": "McGraw-Hill", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1990}, {"title": "Intuition Pumps and Other Tools for Thinking", "author": ["Daniel C Dennett"], "venue": "WW Norton & Company,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Biases in the crossover landscape", "author": ["L.J. Eshelman", "R.A. Caruana", "J.D. Schaffer"], "venue": "Proceedings of the third international conference on Genetic algorithms table of contents, pages 10\u201319", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1989}, {"title": "Attribute-efficient and non-adaptive learning of parities and dnf expressions", "author": ["Vitaly Feldman"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Genetic Algorithms in Search, Optimization & Machine Learning", "author": ["David E. Goldberg"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1989}, {"title": "An application of codes to attribute-efficient learning", "author": ["Thomas Hofmeister"], "venue": "In Computational Learning Theory,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "Probability Theory: The Logic of Science", "author": ["E.T. Jaynes"], "venue": "Cambridge University Press", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Survey propagation revisited", "author": ["Lukas Kroc", "Ashish Sabharwal", "Bart Selman"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "A new look at survey propagation and its generalizations", "author": ["Elitza Maneva", "Elchanan Mossel", "Martin J. Wainwright"], "venue": "J. ACM,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Analytic and algorithmic solution of random satisfiability problems", "author": ["M. M\u00e9zard", "G. Parisi", "R. Zecchina"], "venue": "Science, 297(5582):812\u2013815", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "An Introduction to Genetic Algorithms", "author": ["Melanie Mitchell"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1996}, {"title": "Conjectures and Refutations", "author": ["Karl Popper"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "The Logic Of Scientific Discovery", "author": ["Karl Popper"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Genetic Algorithms: Principles and Perspectives: a Guide to GA Theory", "author": ["C.R. Reeves", "J.E. Rowe"], "venue": "Kluwer Academic Publishers", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2003}, {"title": "Local search strategies for satisfiability testing", "author": ["B. Selman", "H. Kautz", "B. Cohen"], "venue": "Cliques, coloring, and satisfiability: Second DIMACS implementation challenge, 26:521\u2013532", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1993}, {"title": "Identification of partial disjunction, parity, and threshold functions", "author": ["Uehara", "Tsuchida", "Wegener"], "venue": "TCS: Theoretical Computer Science,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2000}], "referenceMentions": [{"referenceID": 1, "context": "We recently hypothesized [2] that an efficient form of computational learning underlies generalpurpose, non-local, noise-tolerant optimization in genetic algorithms with uniform crossover (UGAs).", "startOffset": 25, "endOffset": 28}, {"referenceID": 17, "context": "We then establish that implicit concurrency is a bonafide form of efficient computational learning by using it to obtain close to optimal bounds on the query and time complexity of an algorithm that solves a constrained version of a problem from the computational learning literature: learning parities with a noisy membership query oracle [18, 6].", "startOffset": 340, "endOffset": 347}, {"referenceID": 5, "context": "We then establish that implicit concurrency is a bonafide form of efficient computational learning by using it to obtain close to optimal bounds on the query and time complexity of an algorithm that solves a constrained version of a problem from the computational learning literature: learning parities with a noisy membership query oracle [18, 6].", "startOffset": 340, "endOffset": 347}, {"referenceID": 12, "context": "First, a brief primer on schemata and schema partitions [13]: Let S = {0, 1}n be a search space consisting of binary strings of length n and let I be some set of indices between 1 and n, i.", "startOffset": 56, "endOffset": 60}, {"referenceID": 3, "context": "Consider the following intuition pump [4] that illuminates how effects change with the coarseness of schema partitions.", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "We claim it is general-purpose firstly, because it relies on a very weak assumption about the distribution of fitness over a search space\u2014the existence of staggered conditional effects [2]; and secondly, because it is an example of a decimation heuristic, and as such is in good company.", "startOffset": 185, "endOffset": 188}, {"referenceID": 11, "context": "Decimation heuristics such as Survey Propagation [12, 10] and Belief Propagation [11], when used in concert with local search heuristics (e.", "startOffset": 49, "endOffset": 57}, {"referenceID": 9, "context": "Decimation heuristics such as Survey Propagation [12, 10] and Belief Propagation [11], when used in concert with local search heuristics (e.", "startOffset": 49, "endOffset": 57}, {"referenceID": 10, "context": "Decimation heuristics such as Survey Propagation [12, 10] and Belief Propagation [11], when used in concert with local search heuristics (e.", "startOffset": 81, "endOffset": 85}, {"referenceID": 16, "context": "WalkSat [17]), are state of the art methods for solving large instances of a number of NP-Hard combinatorial optimization problems close to their solvability/unsolvability thresholds.", "startOffset": 8, "endOffset": 12}, {"referenceID": 1, "context": "The hyperclimbing hypothesis [2] posits that by and large, the heuristic described above is the abstract heuristic that UGAs implement\u2014or as is the case more often than not, misimplement (it stands to reason that a \u201csecret sauce\u201d computational efficiency that stays secret will not be harnessed fully).", "startOffset": 29, "endOffset": 32}, {"referenceID": 1, "context": "We have argued previously [2] that the adoption of the scientific method [15] is a necessary", "startOffset": 26, "endOffset": 29}, {"referenceID": 14, "context": "We have argued previously [2] that the adoption of the scientific method [15] is a necessary", "startOffset": 73, "endOffset": 77}, {"referenceID": 14, "context": "The more unexpected a prediction (in the absence of the hypothesis), the greater the credence owed the hypothesis if the prediction is validated [15, 14].", "startOffset": 145, "endOffset": 153}, {"referenceID": 13, "context": "The more unexpected a prediction (in the absence of the hypothesis), the greater the credence owed the hypothesis if the prediction is validated [15, 14].", "startOffset": 145, "endOffset": 153}, {"referenceID": 6, "context": "Given its name and description in terms of concepts from schema theory, implicit concurrency bears a superficial resemblance to implicit parallelism, the hypothetical \u201cengine\u201d presumed, under the beleaguered building block hypothesis [7, 16], to power optimization in genetic algorithms with strong linkage between genetic loci.", "startOffset": 234, "endOffset": 241}, {"referenceID": 15, "context": "Given its name and description in terms of concepts from schema theory, implicit concurrency bears a superficial resemblance to implicit parallelism, the hypothetical \u201cengine\u201d presumed, under the beleaguered building block hypothesis [7, 16], to power optimization in genetic algorithms with strong linkage between genetic loci.", "startOffset": 234, "endOffset": 241}, {"referenceID": 2, "context": "For example, for chromosomes of length n, the number of schema partitions with fineness order 7 is ( n 7 ) \u2208 \u03a9(n7) [3].", "startOffset": 115, "endOffset": 118}, {"referenceID": 6, "context": "Let \u22957 denote the parity function over seven bits, let \u03c8 = \u3008n = 5, k = 7, f = \u22957 , K = [7], \u03b7 = 1/5\u3009 be an oracle, and let G\u03c8 be the genetic algorithm described in Algorithm 1 with population size 1500 and mutation rate 0.", "startOffset": 87, "endOffset": 90}, {"referenceID": 0, "context": "Rand() returns a number drawn uniformly at random from the interval [0,1] and rand(a, b) < c denotes an a by b array of bits such that for each bit, the probability that it is 1 is c.", "startOffset": 68, "endOffset": 73}, {"referenceID": 0, "context": "5 2 for t \u2190 1 to \u03c4 do 3 fitnessVals \u2190 evaluate-fitness(pop) 4 for i \u21901 to m do 5 totalFitness \u2190 totalFitness + fitnessVals[i] 6 end 7 cumNormFitnessVals[1] \u2190 fitnessVals[1] 8 for i \u21902 to m do 9 cumNormFitnessVals[i] \u2190 cumNormFitnessVals[i\u2212 1] + 10 (fitnessVals[i]/totalFitness) 11 end 12 for i \u2190 1 to 2m do 13 k \u2190 rand() 14 ctr \u2190 1 15 while k > cumNormFitnessVals[ctr] do 16 ctr \u2190 ctr + 1 17 end 18 parentIndices[i] \u2190 ctr 19 end 20 crossOverMasks \u2190 rand(m,n) < 0.", "startOffset": 152, "endOffset": 155}, {"referenceID": 0, "context": "5 2 for t \u2190 1 to \u03c4 do 3 fitnessVals \u2190 evaluate-fitness(pop) 4 for i \u21901 to m do 5 totalFitness \u2190 totalFitness + fitnessVals[i] 6 end 7 cumNormFitnessVals[1] \u2190 fitnessVals[1] 8 for i \u21902 to m do 9 cumNormFitnessVals[i] \u2190 cumNormFitnessVals[i\u2212 1] + 10 (fitnessVals[i]/totalFitness) 11 end 12 for i \u2190 1 to 2m do 13 k \u2190 rand() 14 ctr \u2190 1 15 while k > cumNormFitnessVals[ctr] do 16 ctr \u2190 ctr + 1 17 end 18 parentIndices[i] \u2190 ctr 19 end 20 crossOverMasks \u2190 rand(m,n) < 0.", "startOffset": 169, "endOffset": 172}, {"referenceID": 6, "context": "004, and \u03c8 is the oracle \u3008n = 8, k = 7, f = \u22957,K = [7], \u03b7 = 1/5\u3009.", "startOffset": 51, "endOffset": 54}, {"referenceID": 5, "context": "These bounds are marginally higher than the known optimal bounds for a more difficult version of the problem in which the oracle is queried non-adaptively : O(log n) and O(n) respectively [6, 8].", "startOffset": 188, "endOffset": 194}, {"referenceID": 7, "context": "These bounds are marginally higher than the known optimal bounds for a more difficult version of the problem in which the oracle is queried non-adaptively : O(log n) and O(n) respectively [6, 8].", "startOffset": 188, "endOffset": 194}], "year": 2013, "abstractText": "This paper establishes theoretical bonafides for implicit concurrent multivariate effect evaluation\u2014implicit concurrency for short\u2014a broad and versatile computational learning efficiency thought to underlie general-purpose, non-local, noise-tolerant optimization in genetic algorithms with uniform crossover (UGAs). We demonstrate that implicit concurrency is indeed a form of efficient learning by showing that it can be used to obtain close-to-optimal bounds on the time and queries required to approximately correctly solve a constrained version (k = 7, \u03b7 = 1/5) of a recognizable computational learning problem: learning parities with noisy membership queries. We argue that a UGA that treats the noisy membership query oracle as a fitness function can be straightforwardly used to approximately correctly learn the essential attributes in O(log n) queries and O(n log n) time, where n is the total number of attributes. Our proof relies on an accessible symmetry argument and the use of statistical hypothesis testing to reject a global null hypothesis at the 10\u2212100 level of significance. It is, to the best of our knowledge, the first relatively rigorous identification of efficient computational learning in an evolutionary algorithm on a non-trivial learning problem.", "creator": "LaTeX with hyperref package"}}}