{"id": "1307.6365", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jul-2013", "title": "Time-Series Classification Through Histograms of Symbolic Polynomials", "abstract": "Time-series classification has attracted considerable research attention due to the various domains where time-series data are observed, ranging from medicine to econometrics. Traditionally, the focus of time-series classification has been on short time-series data composed of a unique pattern with intraclass pattern distortions and variations, while recently there have been attempts to focus on longer series composed of various local patterns. This study presents a novel method which can detect local patterns in long time-series via fitting local polynomial functions of arbitrary degrees. The coefficients of the polynomial functions are converted to symbolic words via equivolume discretizations of the coefficients' distributions. The symbolic polynomial words enable the detection of similar local patterns by assigning the same words to similar polynomials. Moreover, a histogram of the frequencies of the words is constructed from each time-series' bag of words. Each row of the histogram enables a new representation for the series and symbolize the existence of local patterns and their frequencies. Experimental evidence demonstrates outstanding results of our method compared to the state-of-art baselines, by exhibiting the best classification accuracies in all the datasets and having statistically significant improvements in the absolute majority of experiments.", "histories": [["v1", "Wed, 24 Jul 2013 10:07:50 GMT  (7692kb,D)", "http://arxiv.org/abs/1307.6365v1", null], ["v2", "Thu, 25 Jul 2013 03:40:27 GMT  (7692kb,D)", "http://arxiv.org/abs/1307.6365v2", "Submitted to IEEE ICDM 2013"], ["v3", "Wed, 31 Jul 2013 10:58:02 GMT  (0kb,I)", "http://arxiv.org/abs/1307.6365v3", "Potential conflict with conference dual submission rule"], ["v4", "Mon, 23 Dec 2013 22:26:35 GMT  (5380kb,D)", "http://arxiv.org/abs/1307.6365v4", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB cs.LG", "authors": ["josif grabocka", "martin wistuba", "lars schmidt-thieme"], "accepted": false, "id": "1307.6365"}, "pdf": {"name": "1307.6365.pdf", "metadata": {"source": "CRF", "title": "Time-Series Classification Through Histograms of Symbolic Polynomials", "authors": ["Josif Grabocka", "Martin Wistuba", "Lars Schmidt-Thieme"], "emails": ["schmidt-thieme}@ismll.uni-hildesheim.de"], "sections": [{"heading": null, "text": "This year, we have reached a point where it can only take one year to reach an agreement."}, {"heading": "II. RELATED WORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Time-Series Representations", "text": "In order to understand the regularities embedded in time series, a large number of researchers have invested in the derivation and discovery of time series representations. The ultimate goal of the representation methods is to encapsulate the regularities of time series patterns by suppressing intrinsic noise. Discrete Fourier transformations have attempted to represent repetitive series structures as the sum of sinusoidal signals [5]. Similarly, wave series transformations approach a time series through orthonormal representations in the form of wavelets [6]. Such representations work best on the assumption that series often contain recurring regularities and low noise, which is not necessarily the case in real applications. Singular Value Decomposition is a dimension reduction technology that is also used to extract latent dimensional information from a series."}, {"heading": "B. Time-Series Similarity Metrics", "text": "The time series community has invested considerable efforts in understanding the concept of similarity between the series. Time series patterns exhibit a high degree of intra- and interclass variation, in the form of loud distortions, phase delays, frequency differences, and signal scales. Accurate metrics for assessing the distance between two rows play a crucial role in terms of clustering and classification accuracy. Euclidean distance, commonly known as the L2 standard between vectors, is a fast metric that compares the offset of each pair of points from two rows belonging to the same time stamp index. Although it is a fast metric of linear time complexity, the euclidean distance is not directly designed to detect pattern variations. A popular metric called Dynamic Time Shift (DTW) overcomes the shortcomings of euclidean distance by allowing the detection of relative time indices belonging to similar regions."}, {"heading": "C. Time-Series Classification", "text": "During the last decade, most time series attempts have been aimed at classifying the short time series. However, the definition of short life could lead to ambiguous understandings, so we would allow some scope for further clarification of our definition. On the other hand, we assume that we have an imaginary large amount of data containing all the leaves of a forest. Then, our imaginary task will be to compare different forests in which the forest is located."}, {"heading": "III. PROPOSED METHOD", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Preamble Definitions", "text": "The number of symbols in an alphabet is called the size of the alphabet and is indicated by \u03b1 = | \u03a3 |. For illustration purposes, we will use the Latin variant for the English language, which is composed of the set of character symbols. = (A, B, C,., Y, Z).2) Word: A word w from an alphabet is defined as a sequence of symbols, hence a sequence of possible sequences of arbitrary length l, defined as the Kleene star. - Sequence l = 0\u0445l. For example, CACB is a word from the English alphabet with the length four.3) Polynomial: A polynomial: A polynomial of the row d with the coefficients \u03b2, Rd Rd + 1, is known as a sum of terms known as monomes."}, {"heading": "B. Proposed Principle", "text": "The principle proposed in this study is to recognize local patterns in a time series by calculating local polynomials. In addition, the polynomials provide a superior mean for recognizing local patterns compared to constant or linear models, as they can perceive information such as the curvature of a subseries. In addition, for relatively large sliding windows, the polynomials can approximate the underlying series segment without overmatching. In this paper, we show that the polynomial fit for the sliding window scenario can be calculated in linear runtime. Once the local polynomials are calculated, we propose a novel method to use the polynomial coefficients to calculate the frequencies of the patterns. Polynomial coefficients are converted into alphabetical words using an equivolume discretization approach. Such a conversion of real coefficients into short symbolic words allows the translation of similar polynomials into histories, so that similar patterns can be recognized as the same word."}, {"heading": "C. Local Polynomial Fitting", "text": "The segment of the time series within the sliding window is normalized before it reaches an average of 0 and a deviation of 1. The incremental step for sliding a window is one, so that each partial sequence is scanned. Calculation of the coefficients of a polynomial regression is done by minimizing the smallest square errors between the thepolynomial estimate and the true values of the partial series. The objective function is denoted by L and is referred to in Equation 2. The task is to approximate the real values Y of the time series window Y, previously referred to as St, n.L (Y, Y)."}, {"heading": "D. Converting Coefficients To Symbolic Words", "text": "The next step of our study is the conversion of calculated polynomial coefficients \u03a6 from algorithm 1 to index values. The principle of the conversion is to convert each of the d + 1 coefficients # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "E. Populating the Histogram", "text": "Once we have converted our polynomial coefficients and converted them into words, the next step is to convert the words into a histogram of word frequencies, as in Figure 3. The steps of the histogram population are determined by algorithm 3. The first step is to create a dictionary D, which is a sentence of each word that appears at least once in any time series. Then, we create a histogram H with as many lines as time series and as many columns as there are words in the dictionary. The initial values of the histogram cells are 0. Each cell shows a positive integer that represents semantically how often a word (column index) appears in a time series (row index). The algorithm iterates over all words in a row and increases the frequency of occurrence of that word in the histogram. Once the histogram is populated, each line of the histogram becomes a vector that contains the frequency of the diameter."}, {"heading": "F. Comparison To Other Methods", "text": "The closest method that is comparable to ours is the approach that builds histograms from SAX words [3], [4]. However, the SAX words build from locally constant approximations, which are generally less meaningful than the polynomials of our approach. Figure 5 shows the shortcomings of the locally constant approximation in detecting the curvatures of a sliding window subrow. In the experiment in Figure 5, we used an alphabet of size four and used the classic quantity threshold for SAX as values {\u2212 0.67, 0, 0.67}. Please note that the rows are represented by black dots and represent normalized window segments. We have adapted both a constant model and our polynomic model to the row data. Suppose that we want to have an SAX word for each of the sliding window segments, the SAX word can have the Snox segment for both of the ABnox words, which are easy to recognize."}, {"heading": "G. Classifier", "text": "The classifier we will use is the closest method, which is a strong classifier in the time series classification [1] and is used by modern methods [4]. After the original time series has been converted into pattern frequency representations in the form of lines of a histogram matrix, each line is treated as a vector instance. The nearest neighbor will use the Euclidean distance to calculate the difference between the lines of the histogram."}, {"heading": "IV. EXPERIMENTAL SETUP", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Descriptions of Datasets", "text": "All the experiments are based on data sets retrieved from Physionet, a repository of complex physiological signals, primarily from the field of health care [23]. Our first data set, ECG2, represents time series from the field of electrocardiography belonging to five different sources; the other data sets were not used in the field of time series classification, so we processed and accepted them for a classification task. As the first paper to use them for the classification of time series, we dedicate a few lines to explain the preparation of the data sets. \u2022 The data set contains measurements of running patterns (aka) of patients with idiopathic Parkinson's disease and of patients with healthy (control) patients who are able to grasp the force under their feet."}, {"heading": "B. Baselines", "text": "Let's name our method as SymPol, which means symbolic polynomials, and refer to our method with the abbreviation in the other sections. To evaluate the performance of SymPol, we compare against the following three baselinees.1) BSAX: refers to the method of constructing sacks of SAX words from time series using a sliding-window approach. The words occurring in the sacks are used to fill a histogram of frequencies [4]. A method that comes closest to the closest neighbor is used to classify the histogram instances by treating the histogram lines as the new time series representation. Comparing against this classifier will give the chance to understand the utility of polynomic approximation compared to constant models and will provide evidence of the quality of the results. 2) ENN: is the classically closest neighbor classifier T2-classifier that works as the total distance sequence of the Eumetric 2, without the loss of the local time series."}, {"heading": "C. Reproducibility", "text": "The first empirical evidence focuses on the accuracy of our method with respect to the classification of time series; the second experiment analyses the calculation time of the methods; all experiments were calculated in a five-step cross-validation experimental setup. Of the four groups used for training, one was selected as a validation set and the remaining three as a training set. As a summary, all combinations of parameters were evaluated on the validation set and learned on the three training sets, while the parameter values showing the smallest errors in validation were selected; the parameter values were finally evaluated via the test set (learning from the three training sets) to report the final error rate.A search mechanism was selected to search for the smallest errors in validation."}, {"heading": "D. Results", "text": "TABLE III: Error Rate ResultsDataset SymPol ENN DTWNN (Mean) \u03c3 (Mean) \u00b5 (Mean) \u03c3 (Mean) \u043c (Mean) \u03c3 (Mean) \u03c3 (Mean) \u03c3 (Mean) \u03c3 (St.dev.) \u03c3 (st.deer 0.0080 0.0098 0.02120 0.0160 GAITPD 0.0238 0.0548 0.0211 0.2468 RATBP 0.0206 RATBP 0.1333 0.0272 0.4389 0.3333 NESFDB 0.494 0.4310 0.0212 0.40.40.40.4212"}, {"heading": "E. Hyper-parameter Search Sensitivity", "text": "As illustrated in Section IV-C, our hyperparameter search is the grid search where we search for all possible combinations of the values of a parameter with all possible values of other parameters. As Figure 6 shows, the error rate in relation to the parameter values of the method is nonlinear. Therefore, a grid search is practical since gradient-based methods would have led to local optima, while nonlinear optimization techniques would require much more calculations than the grid. As shown in the figure, the grid search was successful in determining the global optimum in the region indicated by a marker."}, {"heading": "V. CONCLUSION", "text": "In this study, we introduced a novel method for classifying long time series composed of local patterns. Local polynomial approximations are calculated using the sliding window method for each normalized segment under the sliding window. The calculated polynomial coefficients are converted into symbolic forms (i.e., literal words) using an equivalent decretization method. Thresholds for the distribution of the values of each coefficient are set to divide the histogram of the coefficient into equal regions, and each region is assigned an alphabet symbol. In a second step, all polynomial coefficients are converted into characters by locating them within the thresholds of the histogram and assigning them to the region symbol. The final literal representation of a polynomial is a word composed of the concatenation of the character of each coefficient, in the order of the monomial degree of the coefficient. Once the sacks of words are composed, a word methodology is composed with a histogram of the frequency of each word."}], "references": [{"title": "Querying and mining of time series data: experimental comparison of representations and distance measures", "author": ["H. Ding", "G. Trajcevski", "P. Scheuermann", "X. Wang", "E. Keogh"], "venue": "Proc. VLDB Endow., vol. 1, no. 2, pp. 1542\u20131552, Aug. 2008. [Online]. Available: http://dl.acm.org/citation.cfm?id=1454159.1454226", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Motif-based classification of time series with bayesian networks and svms", "author": ["K. Buza", "L. Schmidt-Thieme"], "venue": "GfKl, ser. Studies in Classification, Data Analysis, and Knowledge Organization, A. Fink, B. Lausen, W. Seidel, and A. Ultsch, Eds. Springer, 2008, pp. 105\u2013 114.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Finding structural similarity in time series data using bag-of-patterns representation", "author": ["J. Lin", "Y. Li"], "venue": "Proceedings of the 21st International Conference on Scientific and Statistical Database Management, ser. SSDBM 2009. Berlin, Heidelberg: Springer-Verlag, 2009, pp. 461\u2013477. [Online]. Available: http://dx.doi.org/10.1007/978-3-642-02279-1 33", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Rotation-invariant similarity in time series using bag-of-patterns representation", "author": ["J. Lin", "R. Khade", "Y. Li"], "venue": "J. Intell. Inf. Syst., vol. 39, no. 2, pp. 287\u2013315, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Fast subsequence matching in time-series databases", "author": ["C. Faloutsos", "M. Ranganathan", "Y. Manolopoulos"], "venue": "Proceedings of the 1994 ACM SIGMOD international conference on Management of data, ser. SIGMOD \u201994. New York, NY, USA: ACM, 1994, pp. 419\u2013429. [Online]. Available: http://doi.acm.org/10.1145/191839.191925", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1994}, {"title": "Efficient time series matching by wavelets", "author": ["K.-P. Chan", "A.-C. Fu"], "venue": "15th International Conference on Data Engineering, Proceedings 1999, 1999, pp. 126\u2013133.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1999}, {"title": "Singular-value decomposition approach to time series modelling", "author": ["J.A. Cadzow", "B. Baseghi", "T. Hsu"], "venue": "Communications, Radar and Signal Processing, IEE Proceedings F, vol. 130, no. 3, pp. 202\u2013210, 1983.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1983}, {"title": "Classification of sparse time series via supervised matrix factorization", "author": ["J. Grabocka", "A. Nanopoulos", "L. Schmidt-Thieme"], "venue": "AAAI, J. Hoffmann and B. Selman, Eds. AAAI Press, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Dimensionality reduction for fast similarity search in large time series databases", "author": ["E.J. Keogh", "K. Chakrabarti", "M.J. Pazzani", "S. Mehrotra"], "venue": "Knowl. Inf. Syst., vol. 3, no. 3, pp. 263\u2013286, 2001.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2001}, {"title": "Experiencing sax: a novel symbolic representation of time series", "author": ["J. Lin", "E. Keogh", "L. Wei", "S. Lonardi"], "venue": "Data Min. Knowl. Discov., vol. 15, no. 2, pp. 107\u2013144, Oct. 2007. [Online]. Available: http://dx.doi.org/10.1007/s10618-007-0064-z", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Saxually explicit images: Finding unusual shapes", "author": ["L. Wei", "E. Keogh", "X. Xi"], "venue": "Proceedings of the Sixth International Conference on Data Mining, ser. ICDM \u201906. Washington, DC, USA: IEEE  Computer Society, 2006, pp. 711\u2013720. [Online]. Available: http: //dx.doi.org/10.1109/ICDM.2006.138", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "isax: indexing and mining terabyte sized time series", "author": ["J. Shieh", "E. Keogh"], "venue": "Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, ser. KDD \u201908. New York, NY, USA: ACM, 2008, pp. 623\u2013631. [Online]. Available: http://doi.acm.org/10.1145/1401890.1401966", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "isax 2.0: Indexing and mining one billion time series", "author": ["A. Camerra", "T. Palpanas", "J. Shieh", "E. Keogh"], "venue": "Proceedings of the 2010 IEEE International Conference on Data Mining, ser. ICDM \u201910. Washington, DC, USA: IEEE Computer Society, 2010, pp. 58\u201367. [Online]. Available: http://dx.doi.org/10.1109/ICDM.2010.124", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Online segmentation of time series based on polynomial least-squares approximations", "author": ["E. Fuchs", "T. Gruber", "J. Nitschke", "B. Sick"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 32, no. 12, pp. 2232\u20132245, Dec. 2010. [Online]. Available: http://dx.doi.org/10.1109/TPAMI.2010.44", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Searching and mining trillions of time series subsequences under dynamic time warping", "author": ["T. Rakthanmanon", "B. Campana", "A. Mueen", "G. Batista", "B. Westover", "Q. Zhu", "J. Zakaria", "E. Keogh"], "venue": "Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, ser. KDD 2012. New York, NY, USA: ACM, 2012, pp. 262\u2013270. [Online]. Available: http://doi.acm.org/10.1145/2339530.2339576", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "On the marriage of lp-norms and edit distance", "author": ["L. Chen", "R. Ng"], "venue": "Proceedings of the Thirtieth international conference on Very large data bases - Volume 30, ser. VLDB \u201904. VLDB Endowment, 2004, pp. 792\u2013803. [Online]. Available: http://dl.acm.org/citation.cfm? id=1316689.1316758", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Robust and fast similarity search for moving object trajectories", "author": ["L. Chen", "M.T. \u00d6zsu", "V. Oria"], "venue": "Proceedings of the 2005 ACM SIGMOD international conference on Management of data, ser. SIGMOD \u201905. New York, NY, USA: ACM, 2005, pp. 491\u2013502. [Online]. Available: http://doi.acm.org/10.1145/1066157.1066213", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Discovering similar multidimensional trajectories", "author": ["M. Vlachos", "G. Kollios", "D. Gunopulos"], "venue": "Data Engineering, 2002. Proceedings. 18th International Conference on, 2002, pp. 673\u2013684.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2002}, {"title": "Spade: On shapebased pattern detection in streaming time series", "author": ["Y. Chen", "M. Nascimento", "B.-C. Ooi", "A. Tung"], "venue": "Data Engineering, 2007. ICDE 2007. IEEE 23rd International Conference on, 2007, pp. 786\u2013795.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Support vector machines and dynamic time warping for time series", "author": ["S. Gudmundsson", "T.P. Runarsson", "S. Sigurdsson"], "venue": "IJCNN. IEEE, 2008, pp. 2772\u20132776.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Time series classification using support vector machine with gaussian elastic metric kernel", "author": ["D. Zhang", "W. Zuo", "D. Zhang", "H. Zhang"], "venue": "Pattern Recognition (ICPR), 2010 20th International Conference on, 2010, pp. 29\u201332.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Invariant timeseries classification", "author": ["J. Grabocka", "A. Nanopoulos", "L. Schmidt-Thieme"], "venue": "ECML/PKDD (2), ser. Lecture Notes in Computer Science, P. A. Flach, T. D. Bie, and N. Cristianini, Eds., vol. 7524. Springer, 2012, pp. 725\u2013740.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals", "author": ["A.L. Goldberger", "L.A.N. Amaral", "L. Glass", "J.M. Hausdorff", "P.C. Ivanov", "R.G. Mark", "J.E. Mietus", "G.B. Moody", "C.-K. Peng", "H.E. Stanley"], "venue": "Circulation, vol. 101, no. 23, pp. e215\u2013e220, 2000 (June 13), circulation Electronic Pages: http://circ.ahajournals.org/cgi/content/full/101/23/e215 PMID:1085218; doi: 10.1161/01.CIR.101.23.e215.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Rhythmic auditory stimulation modulates gait variability in parkinson\u2019s disease.", "author": ["J. Hausdorff", "J. Lowenthal", "T. Herman", "L. Gruendlinger", "C. Peretz", "N. Giladi"], "venue": "Eur J Neurosci,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "Identifying physiological origins of baroreflex dysfunction in salt-sensitive hypertension in the dahl ss rat.", "author": ["S.M. Bugenhagen", "A.W. Cowley", "D.A. Beard"], "venue": "Physiol Genomics,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}, {"title": "Vibrating insoles and balance control in elderly", "author": ["A. Priplata", "J. Niemi", "J. Harry", "L. Lipsitz", "J. Collins"], "venue": "people.\u201d Lancet,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Among other successful techniques in this category, the nearest neighbor classifier equipped with a similarity metric called Dynamic Time Warping (DTW) has been shown to perform well in a large number of datasets [1].", "startOffset": 213, "endOffset": 216}, {"referenceID": 1, "context": "Nevertheless, few studies [2]\u2013[4] have been dedicated towards the classification of time-series data which is long and composed of many local patterns.", "startOffset": 26, "endOffset": 29}, {"referenceID": 3, "context": "Nevertheless, few studies [2]\u2013[4] have been dedicated towards the classification of time-series data which is long and composed of many local patterns.", "startOffset": 30, "endOffset": 33}, {"referenceID": 1, "context": "Text mining approaches which compute bags of words occurring in a text and then utilize histograms of the occurrences of each word, have been recently applied to the time-series domain by the metaphor of computing \u201dbags of patterns\u201d [2], [4].", "startOffset": 233, "endOffset": 236}, {"referenceID": 3, "context": "Text mining approaches which compute bags of words occurring in a text and then utilize histograms of the occurrences of each word, have been recently applied to the time-series domain by the metaphor of computing \u201dbags of patterns\u201d [2], [4].", "startOffset": 238, "endOffset": 241}, {"referenceID": 2, "context": "The novelty of our method, compared to state-of-art approaches [3], [4] which utilize constant functions to express local patterns, relies on offering an expressive technique to represent patterns as polynomial of arbitrary degrees.", "startOffset": 63, "endOffset": 66}, {"referenceID": 3, "context": "The novelty of our method, compared to state-of-art approaches [3], [4] which utilize constant functions to express local patterns, relies on offering an expressive technique to represent patterns as polynomial of arbitrary degrees.", "startOffset": 68, "endOffset": 71}, {"referenceID": 3, "context": "We experimented with the datasets from [4], and in order to widen the variety of data we introduce three new datasets.", "startOffset": 39, "endOffset": 42}, {"referenceID": 4, "context": "Discrete Fourier transforms have attempted to represent repeating series structures as a sum of sinusoidal signals [5].", "startOffset": 115, "endOffset": 118}, {"referenceID": 5, "context": "Similarly, wavelet transformations approximate a timeseries via orthonormal representations in the form of wavelets [6].", "startOffset": 116, "endOffset": 119}, {"referenceID": 6, "context": "Singular Value Decomposition is a dimensionality reduction technique which has also been applied to extract latent dimensionality information of a series [7], while supervised decomposition techniques have aimed at incorporating class information into the low-rank data learning [8].", "startOffset": 154, "endOffset": 157}, {"referenceID": 7, "context": "Singular Value Decomposition is a dimensionality reduction technique which has also been applied to extract latent dimensionality information of a series [7], while supervised decomposition techniques have aimed at incorporating class information into the low-rank data learning [8].", "startOffset": 279, "endOffset": 282}, {"referenceID": 8, "context": "Those chunks are converted to a single mean value and the concatenation of means create a short form known as a Piecewise Constant Approximation [9].", "startOffset": 145, "endOffset": 148}, {"referenceID": 9, "context": "A more sophisticated technique operates by converting the mean values into symbolic form into a method called Symbolic Aggregate Approximation, denoted shortly as SAX [10], [11].", "startOffset": 167, "endOffset": 171}, {"referenceID": 10, "context": "A more sophisticated technique operates by converting the mean values into symbolic form into a method called Symbolic Aggregate Approximation, denoted shortly as SAX [10], [11].", "startOffset": 173, "endOffset": 177}, {"referenceID": 11, "context": "Further sophistication of lower bounding techniques have advanced the representation method towards efficient indexing and searching [12], enabling large scale mining of time series [13].", "startOffset": 133, "endOffset": 137}, {"referenceID": 12, "context": "Further sophistication of lower bounding techniques have advanced the representation method towards efficient indexing and searching [12], enabling large scale mining of time series [13].", "startOffset": 182, "endOffset": 186}, {"referenceID": 13, "context": "For instance least squares approximation of time series via orthogonal polynomials have been proposed for segmentation purposes in a hybrid sliding/growing window scenario [14].", "startOffset": 172, "endOffset": 176}, {"referenceID": 0, "context": "DTW achieves highly competitive classification accuracies and is regarded as a strong baseline [1].", "startOffset": 95, "endOffset": 98}, {"referenceID": 14, "context": "Even though DTW is slow in the original formulation having a quadratic run-time complexity, still recent techniques involving early pruning and lower bounding have utilized DTW for fast large scale search [15].", "startOffset": 205, "endOffset": 209}, {"referenceID": 15, "context": "Other techniques have put emphasis on the need to apply edit distance penalties for assessing the similarity between time series [16], [17].", "startOffset": 129, "endOffset": 133}, {"referenceID": 16, "context": "Other techniques have put emphasis on the need to apply edit distance penalties for assessing the similarity between time series [16], [17].", "startOffset": 135, "endOffset": 139}, {"referenceID": 17, "context": "Other approaches have put emphasis on detecting the longest common subsequence of series, believing in the assumption that time series have a fingerprint segment which is the most determinant with respect to classification [18].", "startOffset": 223, "endOffset": 227}, {"referenceID": 18, "context": "Detection of similarities in a streaming time-series scenarios motivated attempts to handle scaling and shifting in the temporal and amplitude aspects [19].", "startOffset": 151, "endOffset": 155}, {"referenceID": 0, "context": "Among the initial pioneer methods and still one of the best performing ones is the nearest neighbor classifier accompanied by the DTW distance metrics, which constitute a hard-to-beat baseline [1].", "startOffset": 193, "endOffset": 196}, {"referenceID": 19, "context": "Other powerful nonlinear classifiers like the Support Vector Machines have been tweaked to operate over time series, partially because originally the kernel functions are not designed for invariant pattern detection and partially because DTW is not a positive semi-definite kernel [20].", "startOffset": 281, "endOffset": 285}, {"referenceID": 20, "context": "Therefore the creation of positive semi-definite kernels like the Gaussian elastic metric kernel arose [21].", "startOffset": 103, "endOffset": 107}, {"referenceID": 21, "context": "Another approach proposed to handle variations by inflating the training set and creating new distorted instances from the original ones [22].", "startOffset": 137, "endOffset": 141}, {"referenceID": 1, "context": "For instance, underlying series patterns have been expressed as the motifs and the difference between the motif frequencies has been utilized [2].", "startOffset": 142, "endOffset": 145}, {"referenceID": 2, "context": "Other approaches have explored the conversion of each sliding window segment into a literal word constructed by piecewise constant approximations and the SAX method [3], [4].", "startOffset": 165, "endOffset": 168}, {"referenceID": 3, "context": "Other approaches have explored the conversion of each sliding window segment into a literal word constructed by piecewise constant approximations and the SAX method [3], [4].", "startOffset": 170, "endOffset": 173}, {"referenceID": 3, "context": "Such a technique has been shown to be rotation-invariant, because the occurrence of a pattern is not related to its position [4].", "startOffset": 125, "endOffset": 128}, {"referenceID": 2, "context": "The closest method comparable in nature to ours is the approach which builds histograms from SAX words [3], [4].", "startOffset": 103, "endOffset": 106}, {"referenceID": 3, "context": "The closest method comparable in nature to ours is the approach which builds histograms from SAX words [3], [4].", "startOffset": 108, "endOffset": 111}, {"referenceID": 0, "context": "The classifier that we are going to use is the nearest neighbor method, which is a strong classifier in time-series classification [1] and is used by state-of-art methods [4].", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "The classifier that we are going to use is the nearest neighbor method, which is a strong classifier in time-series classification [1] and is used by state-of-art methods [4].", "startOffset": 171, "endOffset": 174}, {"referenceID": 22, "context": "All the experiments are based on datasets retrieved from Physionet, a repository of complex physiological signals primarily from the health care domain [23].", "startOffset": 152, "endOffset": 156}, {"referenceID": 3, "context": "Our first dataset, ECG2, represents time series from the domain of Electrocardiography belonging to five different sources [4].", "startOffset": 123, "endOffset": 126}, {"referenceID": 23, "context": "\u2022 GAITPD: The dataset contains measures of walking patterns (aka gait) from 93 patients with idiopathic Parkinson\u2019s Disease and 73 healthy (control) patients [24].", "startOffset": 158, "endOffset": 162}, {"referenceID": 24, "context": "[25].", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "A group of 27 individuals of young and old age groups were voluntarily tested for postural sway behaviors [26].", "startOffset": 106, "endOffset": 110}, {"referenceID": 3, "context": "The words occurring in the bags are used to populate a histogram of frequencies [4].", "startOffset": 80, "endOffset": 83}, {"referenceID": 0, "context": "3) DTWNN: differs from the Euclidean nearest neighbor classifier in defining a new distance metric for the comparison of two time series and performs well in time-series classification [1].", "startOffset": 185, "endOffset": 188}], "year": 2017, "abstractText": "Time-series classification has attracted considerable research attention due to the various domains where timeseries data are observed, ranging from medicine to econometrics. Traditionally, the focus of time-series classification has been on short time-series data composed of a unique pattern with intraclass pattern distortions and variations, while recently there have been attempts to focus on longer series composed of various local patterns. This study presents a novel method which can detect local patterns in long time-series via fitting local polynomial functions of arbitrary degrees. The coefficients of the polynomial functions are converted to symbolic words via equivolume discretizations of the coefficients\u2019 distributions. The symbolic polynomial words enable the detection of similar local patterns by assigning the same words to similar polynomials. Moreover, a histogram of the frequencies of the words is constructed from each time-series\u2019 bag of words. Each row of the histogram enables a new representation for the series and symbolize the existence of local patterns and their frequencies. Experimental evidence demonstrates outstanding results of our method compared to the state-of-art baselines, by exhibiting the best classification accuracies in all the datasets and having statistically significant improvements in the absolute majority of experiments.", "creator": "LaTeX with hyperref package"}}}