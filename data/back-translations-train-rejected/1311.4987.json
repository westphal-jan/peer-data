{"id": "1311.4987", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Nov-2013", "title": "Analyzing Evolutionary Optimization in Noisy Environments", "abstract": "Many optimization tasks have to be handled in noisy environments, where we cannot obtain the exact evaluation of a solution but only a noisy one. For noisy optimization tasks, evolutionary algorithms (EAs), a kind of stochastic metaheuristic search algorithm, have been widely and successfully applied. Previous work mainly focuses on empirical studying and designing EAs for noisy optimization, while, the theoretical counterpart has been little investigated. In this paper, we investigate a largely ignored question, i.e., whether an optimization problem will always become harder for EAs in a noisy environment. We prove that the answer is negative, with respect to the measurement of the expected running time. The result implies that, for optimization tasks that have already been quite hard to solve, the noise may not have a negative effect, and the easier a task the more negatively affected by the noise. On a representative problem where the noise has a strong negative effect, we examine two commonly employed mechanisms in EAs dealing with noise, the re-evaluation and the threshold selection strategies. The analysis discloses that the two strategies, however, both are not effective, i.e., they do not make the EA more noise tolerant. We then find that a small modification of the threshold selection allows it to be proven as an effective strategy for dealing with the noise in the problem.", "histories": [["v1", "Wed, 20 Nov 2013 09:28:52 GMT  (275kb,D)", "http://arxiv.org/abs/1311.4987v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["chao qian", "yang yu", "zhi-hua zhou"], "accepted": false, "id": "1311.4987"}, "pdf": {"name": "1311.4987.pdf", "metadata": {"source": "CRF", "title": "Analyzing Evolutionary Optimization in Noisy Environments", "authors": ["Chao Qian", "Yang Yu", "Zhi-Hua Zhou"], "emails": ["qianc@lamda.nju.edu.cn", "yuy@nju.edu.cn", "zhouzh@nju.edu.cn"], "sections": [{"heading": null, "text": "Many optimization tasks have to be accomplished in noisy environments, where we cannot get an exact assessment of a solution, only a loud one. Previous work has mainly focused on empirical studies and designing EAs for noisy optimization, while the theoretical counterpart has been little studied. In this paper, we examine a largely ignored question, namely whether an optimization problem for EAs in a noisy environment is becoming more and more difficult. We prove that the answer is negative in terms of measuring the expected runtime. The result implies that in optimization tasks that were already quite difficult to solve, noise cannot have a negative effect, and the simpler a task, the more negatively it is influenced by noise. On a representative problem where noise has a strong negative threshold, we examine two commonly used mechanisms."}, {"heading": "1. Introduction", "text": "This year, it will be able to put itself at the top of the list in the way that it has put itself at the top of the party."}, {"heading": "2. Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Noisy Optimization", "text": "A general optimization problem can be represented as arg maxx f (x), where goal f is also called fitness in the context of evolutionary calculation. In real optimization tasks, the suitability assessment for a solution is usually disturbed by noise, and consequently we cannot obtain the exact fitness value, but only one. In this work we will include the following types of noise, and we will always refer to fN (x) and f (x) as the noisy and true fitness of a solution x, in relation to the respective size. Additive noise fN (x) = f (x) + \u03b4, where this noise is uniformly selected from [\u03b41, \u03b42] for random analytical work, using multiplicate noise fN (x) = f (x) for random analysis. Multiplicative noise fN (x) = f (x)."}, {"heading": "2.2. Evolutionary Algorithms", "text": "Evolutionary algorithms (EAs) [4] are a kind of population-based metaheuristic optimization algorithms = 1. Although there are many variants, the common procedure of EAs can be described as follows: 1. Create a set of solutions (so-called Population); 2. Reproduce new solutions from the current population; 3. Evaluate the newly generated solutions; 4. Update the population by removing bad solutions; 5. Repeat steps 2-5 until any criterion met.The (1 + 1) -EA, as in Algorithm 1, is a simple EA to maximize pseudo-boolean problems above {0, 1} n, which reflects the general structure of EAs. It gets only one solution and repeatedly improves the current solution by using bitwise mutation (i.e., the 3rd step of Algorithm 1). It has been generally used for runtime analysis of EAs, e.g. [17, 12].Algorithm 1 (3. + 1.), making it more apparent with EA-function."}, {"heading": "2.3. Markov Chain Modeling", "text": "We will analyze the EAs by modeling them as Markov chains in this work. Here, we first give some preliminary solutions (EAs generate solutions only on the basis of their currently held solutions, so they can be modeled and analyzed as Markov chains, e.g.: [17, 28]. A Markov chain [EA] with at least one optimal solution is constructed by taking the EA population space X as the state space of the chain, i.e., X-X-X denotes the set of all optimal populations that contain at least one optimal solution. EA's goal is to reach from an initial population of X-X. The process of an EA looking for X-X distribution can be analyzed by examining the corresponding Markov chain. A Markov chain."}, {"heading": "2.4. Pseudo-Boolean Functions", "text": "The pseudo-Boolean function class in definition 2 is a large function class that requires only the solution space to be {0, 1} n and the objective space R. Many well-known NP-hard problems (e.g. the vertex cover problem and the 0-1 knapsack problem) belong to this class. Various pseudo-Boolean problems with different structures and difficulties have been used to analyze the runtime of EAs and then reveal properties of EAs, e.g. [11, 17, 12]. Note that we are only looking at maximization problems in this paper, since the minimization of f is equivalent to the maximizing ability of f \u2212 f. Definition 2 (pseudo-Boolean function) A function in the pseudo-Boolean function class is in the form of: f: {0, 1} n \u2192 R.Ihardest (or called Trap) problem in definition 3 is a special instance in this class that is simple."}, {"heading": "3. Noise is Not Always Bad", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Empirical Evidence", "text": "It has been observed that a noisy fitness assessment can make optimization for EAs more difficult, as it can cause a bad solution to have a \"better\" fitness and then mislead the search direction of EAs. Droste [10] has shown that the runtime of (1 + 1) -EA can increase from polynomial to exponential due to the presence of noise. However, when investigating the runtime of (1 + 1) -EA to solve the most difficult case in the pseudo-Boolean function class, we observed that noise can also facilitate optimization for EAs, which means that the presence of noise reduces the runtime of EAs to find the optimal solution.For the most difficult problem above {0, 1} n, there are 2n possible solutions, which are multiplied by their respective integer values of 0, 1,.., 2n \u2212 1."}, {"heading": "3.2. A Sufficient Condition", "text": "In this section, by comparing the expected runtime of EAs with and without noise, a sufficient condition is derived under which the noise is an optimization for EAs. Most practical EAs employ time-invariant operators, so we can model an EA without noise by a homogeneous Markov chain. Whereas for an EA with noise, since the noise may change over time, we can simply model it by a Markov chain. Note: The two EAs with and without noise differ only in whether the fitness evaluation is disturbed by noise, so they must have the same values onN1 and N2 for their runtime. Then, the comparison of their expected runtime with the EFHT of their respective Markov chains.We first define a division of the state space of a homogeneous Markov space based on the EFHT, and then define a prominent probability of a Markov chain of one state in one step."}, {"heading": "3.3. Discussion", "text": "We have shown that noise makes the most difficult and simplest problems easier and harder, each for (1 + \u03bb) -EA =. These two problems are known to be the hardest and simplest instances, or, in the pseudo-Boolean function class, with a unique global optimum for (1 + \u03bb) -EA = harder. We can intuitively interpret the effects of noise detected for EAs on these two problems, while EA searches along the deceptive direction can add a certain randomness to give the EA a chance to move in the right direction; for the simplest problem, the EA searches along the right direction, while noise can only damage the optimization process. We therefore hypothesize that we only need to worry about noise when the optimization problem is moderate or less complex. To further verify our hypothesis, we deal with the Jumpm, n problem, which is a problem with adaptable difficulty, and is configured as Iemost difficult when the problem can be configured as 1 and the problem can be most difficult."}, {"heading": "4. On the Usefulness of Noise Handling Strategies", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Re-evaluation", "text": "There are, of course, two fitness assessment options for EAs [2, 21, 16, 19]: \u2022 single-evaluation we evaluate a solution once, and use the evaluated fitness for this solutionation in the future. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 n Each time we access the fitness of a solution by evaluation, we are recalculated and recalculated for (1 + 1) -EA in algorithm 1 when we use a re-evaluation, both f (x) and f (x) in each iteration; if we are only calculated f (x) bit in algorithm 1 and the previously obtained fitness f (x) is reused. Intuitively, re-evaluation noise can be smoothed and thus better for noisy optimizations, but it also increases the fitness evaluation costs and thus increases runtime. Its usefulness was not yet clear."}, {"heading": "4.2. Threshold Selection", "text": "During the process of evolutionary optimization, most of the improvements are in a generation 1. Such a strategy can reduce the risk of poor evaluation. Although the use of re-evaluation, due to noisy fitness evaluation, is not real, a significant portion of these improvements are not real, where a worse solution seems to have a \"better\" threshold and then survives to replace the true better solution that has a \"worse\" fitness, which can mislead the search direction of EAs and then slow down the efficiency of EAs or cause EAs to get caught up in the local optimal solution, as observed in Section 4.1. To address this problem, a selection strategy for dealing with noise has been proposed [23]. \u2022 Threshold selection of a successor solution is only accepted if their fitness is greater than that of the parent solution by at least a predefined threshold. 0.For example, for (1 + 1) -EA with threshold selection as in algorithm 3, its 4th step changes \"by if it finds (f) greater than x (f).\""}, {"heading": "4.3. Smooth Threshold Selection", "text": "We propose the smooth threshold as in definition 8, which changes the initial threshold selection by changing the hard threshold to a smooth value = 1. We should show that such a small change will improve the PNT from (1 + 1) -EA to the simplest problem to 1, which means that the expected runtime of (1 + 1) -EA is always polynaemic and disregards the single-bit noise level. Definition 8 (Smooth Threshold) Let's leave the gap between the fitness of the progeny solution x \u00b2 and the parent solution x \u00b2 and the parent solution x \u00b2, i.e., the process will behave the following: (1) if the threshold of 0, x \u00b2 L is rejected; (2) if we accept the gap of 1, x \u00b2 we will be accepted with the probability of 15n; (3) if the difference of 1, x \u00b2 is accepted. Theorem 9 The PNT of (1 + 1) -EA with the smooth threshold of 1, we will be accepted with the probability of 1."}, {"heading": "5. Discussions and Conclusions", "text": "This study explores theoretical questions of noise optimization through evolutionary algorithms. First, we discover that an optimization problem can become easier than in a noisy environment. We then deduce a sufficient condition under which noise makes optimization easier or harder. We also hypothesize that we only need to care about noise when the optimization problem is moderate or less complex. Experiments on the Jumpm, which has an adjustable degree of difficulty, support our hypothesis."}, {"heading": "6. Acknowledgements", "text": "to add..."}], "references": [{"title": "Random walks, universal traversal sequences, and the complexity of maze problems", "author": ["R. Aleliunas", "R. Karp", "R. Lipton", "L. Lovasz", "C. Rackoff"], "venue": "In Proceedings of the 20th Annual Symposium on Foundations of Computer Science", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1979}, {"title": "Local performance of the (1+1)-ES in a noisy environment", "author": ["D.V. Arnold", "H.-G. Beyer"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "A comparison of evolution strategies with other direct search methods in the presence of noise", "author": ["D.V. Arnold", "H.-G. Beyer"], "venue": "Computational Optimization and Applications,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms", "author": ["T. B\u00e4ck"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1996}, {"title": "New experimentalism applied to evolutionary computation", "author": ["T. Bartz-Beielstein"], "venue": "PhD thesis, University of Dortmund,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Threshold selection, hypothesis tests, and DOE methods", "author": ["T. Beielstein", "S. Markon"], "venue": "In Proceedings of the IEEE Congress on Evolutionary Computation", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Evolutionary algorithms in noisy environments: theoretical issues and guidelines for practice", "author": ["H.-G. Beyer"], "venue": "Computer Methods in Applied Mechanics and Engineering,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Automated passive filter synthesis using a novel tree representation and genetic programming", "author": ["S.-J. Chang", "H.-S. Hou", "Y.-K. Su"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "A new query reweighting method for document retrieval based on genetic algorithms", "author": ["Y. Chang", "S. Chen"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "Analysis of the (1+1) EA for a noisy OneMax", "author": ["S. Droste"], "venue": "In Proceedings of the 6th ACM Annual Conference on Genetic and Evolutionary Computation", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "A rigorous complexity analysis of the (1+1) evolutionary algorithm for linear functions with Boolean inputs", "author": ["S. Droste", "T. Jansen", "I. Wegener"], "venue": "Evolutionary Computation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1998}, {"title": "On the analysis of the (1+1) evolutionary algorithm", "author": ["S. Droste", "T. Jansen", "I. Wegener"], "venue": "Theoretical Computer Science,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "Genetic algorithms in noisy environments", "author": ["J.M. Fitzpatrick", "J.J. Grefenstette"], "venue": "Machine learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "Fre\u0131\u030cdlin. Markov Processes and Differential Equations: Asymptotic Problems", "author": ["I. M"], "venue": "Birkha\u0308user Verlag, Basel, Switzerland,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1996}, {"title": "A survey of evolutionary algorithms for data mining and knowledge discovery", "author": ["A.A. Freitas"], "venue": "Advances in Evolutionary Computing: Theory and Applications,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "An investigation on noisy environments in evolutionary multiobjective optimization", "author": ["C. Goh", "K. Tan"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Drift analysis and average time complexity of evolutionary algorithms", "author": ["J. He", "X. Yao"], "venue": "Artificial Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2001}, {"title": "A study of drift analysis for estimating computation time of evolutionary algorithms", "author": ["J. He", "X. Yao"], "venue": "Natural Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "Hoeffding and Bernstein races for selecting policies in evolutionary direct policy search", "author": ["V. Heidrich-Meisner", "C. Igel"], "venue": "In Proceedings of the 26th International Conference on Machine Learning", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "On the choice of the offspring population size in evolutionary algorithms", "author": ["T. Jansen", "K. Jong", "I. Wegener"], "venue": "Evolutionary Computation,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Evolutionary optimization in uncertain environments-a survey", "author": ["Y. Jin", "J. Branke"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "An evolutionary clustering algorithm for gene expression microarray data analysis", "author": ["P. Ma", "K. Chan", "X. Yao", "D. Chiu"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Thresholding-a selection operator for noisy ES", "author": ["S. Markon", "D.V. Arnold", "T. Back", "T. Beielstein", "H.-G. Beyer"], "venue": "In Proceedings of the IEEE Congress on Evolutionary Computation", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}, {"title": "Randomized local search, evolutionary algorithms, and the minimum spanning tree problem", "author": ["F. Neumann", "I. Wegener"], "venue": "Theoretical Computer Science,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "On algorithm-dependent boundary case identification for problem classes", "author": ["C. Qian", "Y. Yu", "Z.-H. Zhou"], "venue": "In Proceedings of the 12th International Conference on Parallel Problem Solving from Nature", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "A partial order approach to noisy fitness functions", "author": ["G. Rudolph"], "venue": "In Proceedings of the IEEE Congress on Evolutionary Computation", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2001}, {"title": "A new method for lower bounds on the running time of evolutionary algorithms", "author": ["D. Sudholt"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "A new approach to estimating the expected first hitting time of evolutionary algorithms", "author": ["Y. Yu", "Z.-H. Zhou"], "venue": "Artificial Intelligence,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2008}], "referenceMentions": [{"referenceID": 3, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 37, "endOffset": 40}, {"referenceID": 14, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 112, "endOffset": 126}, {"referenceID": 21, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 112, "endOffset": 126}, {"referenceID": 8, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 112, "endOffset": 126}, {"referenceID": 7, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 112, "endOffset": 126}, {"referenceID": 20, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 103, "endOffset": 111}, {"referenceID": 15, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 103, "endOffset": 111}, {"referenceID": 22, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 380, "endOffset": 390}, {"referenceID": 5, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 380, "endOffset": 390}, {"referenceID": 4, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 380, "endOffset": 390}, {"referenceID": 12, "context": "An assumption implied by using a noise handling mechanism in EAs is that the noise makes the optimization harder, so that a better handling mechanism can reduce the negative effect by the noise [13, 7, 26, 3].", "startOffset": 194, "endOffset": 208}, {"referenceID": 6, "context": "An assumption implied by using a noise handling mechanism in EAs is that the noise makes the optimization harder, so that a better handling mechanism can reduce the negative effect by the noise [13, 7, 26, 3].", "startOffset": 194, "endOffset": 208}, {"referenceID": 25, "context": "An assumption implied by using a noise handling mechanism in EAs is that the noise makes the optimization harder, so that a better handling mechanism can reduce the negative effect by the noise [13, 7, 26, 3].", "startOffset": 194, "endOffset": 208}, {"referenceID": 2, "context": "An assumption implied by using a noise handling mechanism in EAs is that the noise makes the optimization harder, so that a better handling mechanism can reduce the negative effect by the noise [13, 7, 26, 3].", "startOffset": 194, "endOffset": 208}, {"referenceID": 24, "context": "We start by presenting an experimental evidence using (1+1)-EA optimizing the hardest case in the pseudo-Boolean function class [25].", "startOffset": 128, "endOffset": 132}, {"referenceID": 9, "context": "Since the (1+1)-EA with re-evaluation has the PNT \u0398( logn n ) [10], it is surprisingly that the re-evaluation makes the PNT much worse.", "startOffset": 62, "endOffset": 66}, {"referenceID": 6, "context": "Additive and multiplicative noise has been often used for analyzing the effect of noise [7, 21].", "startOffset": 88, "endOffset": 95}, {"referenceID": 20, "context": "Additive and multiplicative noise has been often used for analyzing the effect of noise [7, 21].", "startOffset": 88, "endOffset": 95}, {"referenceID": 9, "context": "Onebit noise is specifically for optimizing pseudo-Boolean problems over {0, 1}, and also the investigated noise in the only previous work for analyzing running time of EAs in noisy optimization [10].", "startOffset": 195, "endOffset": 199}, {"referenceID": 3, "context": "Evolutionary algorithms (EAs) [4] are a kind of population-based metaheuristic optimization algorithms.", "startOffset": 30, "endOffset": 33}, {"referenceID": 16, "context": ", [17, 12].", "startOffset": 2, "endOffset": 10}, {"referenceID": 11, "context": ", [17, 12].", "startOffset": 2, "endOffset": 10}, {"referenceID": 19, "context": "It has been used to disclose the effect of offspring population size by running time analysis [20, 24].", "startOffset": 94, "endOffset": 102}, {"referenceID": 23, "context": "It has been used to disclose the effect of offspring population size by running time analysis [20, 24].", "startOffset": 94, "endOffset": 102}, {"referenceID": 16, "context": ", computing f(\u00b7)) until an optimal solution is found for the first time, since the fitness evaluation is the computational process with the highest cost of the algorithm [17, 28].", "startOffset": 170, "endOffset": 178}, {"referenceID": 27, "context": ", computing f(\u00b7)) until an optimal solution is found for the first time, since the fitness evaluation is the computational process with the highest cost of the algorithm [17, 28].", "startOffset": 170, "endOffset": 178}, {"referenceID": 16, "context": ", [17, 28].", "startOffset": 2, "endOffset": 10}, {"referenceID": 27, "context": ", [17, 28].", "startOffset": 2, "endOffset": 10}, {"referenceID": 13, "context": "The following two lemmas on the EFHT of Markov chains [14] will be used in this paper.", "startOffset": 54, "endOffset": 58}, {"referenceID": 16, "context": "For analyzing the EFHT of Markov chains, drift analysis [17, 18] is a commonly used tool, which will also be used in this paper.", "startOffset": 56, "endOffset": 64}, {"referenceID": 17, "context": "For analyzing the EFHT of Markov chains, drift analysis [17, 18] is a commonly used tool, which will also be used in this paper.", "startOffset": 56, "endOffset": 64}, {"referenceID": 16, "context": "Lemma 3 (Drift Analysis [17, 18]) Given a Markov chain {\u03bet} t=0 and a distance function V (x), if it satisfies that for any t \u2265 0 and any \u03bet with V (\u03bet) > 0, 0 < cl \u2264 E[[V (\u03bet)\u2212 V (\u03bet+1)|\u03bet]] \u2264 cu, then the EFHT of this chain satisfies that V (\u03be0)/cu \u2264 E[[\u03c4 |\u03be0]] \u2264 V (\u03be0)/cl, where cl, cu are constants.", "startOffset": 24, "endOffset": 32}, {"referenceID": 17, "context": "Lemma 3 (Drift Analysis [17, 18]) Given a Markov chain {\u03bet} t=0 and a distance function V (x), if it satisfies that for any t \u2265 0 and any \u03bet with V (\u03bet) > 0, 0 < cl \u2264 E[[V (\u03bet)\u2212 V (\u03bet+1)|\u03bet]] \u2264 cu, then the EFHT of this chain satisfies that V (\u03be0)/cu \u2264 E[[\u03c4 |\u03be0]] \u2264 V (\u03be0)/cl, where cl, cu are constants.", "startOffset": 24, "endOffset": 32}, {"referenceID": 10, "context": ", [11, 17, 12].", "startOffset": 2, "endOffset": 14}, {"referenceID": 16, "context": ", [11, 17, 12].", "startOffset": 2, "endOffset": 14}, {"referenceID": 11, "context": ", [11, 17, 12].", "startOffset": 2, "endOffset": 14}, {"referenceID": 11, "context": "It has been widely used in the theoretical analysis of EAs, and the expected running time of (1+1)-EA with mutation probability 1 n has been proved to be \u0398(n ) [12].", "startOffset": 160, "endOffset": 164}, {"referenceID": 24, "context": "It has also been recognized as the hardest instance in the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA [25].", "startOffset": 135, "endOffset": 139}, {"referenceID": 16, "context": "The running time of EAs has been well studied on this problem [17, 12, 27].", "startOffset": 62, "endOffset": 74}, {"referenceID": 11, "context": "The running time of EAs has been well studied on this problem [17, 12, 27].", "startOffset": 62, "endOffset": 74}, {"referenceID": 26, "context": "The running time of EAs has been well studied on this problem [17, 12, 27].", "startOffset": 62, "endOffset": 74}, {"referenceID": 11, "context": "Particularly, the expected running time of (1+1)-EA with mutation probability 1 n on it has been proved to be \u0398(n log n) [12].", "startOffset": 121, "endOffset": 125}, {"referenceID": 24, "context": "It has also been recognized as the easiest instance in the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA [25].", "startOffset": 135, "endOffset": 139}, {"referenceID": 9, "context": "Droste [10] proved that the running time of (1+1)-EA can increase from polynomial to exponential due to the presence of noise.", "startOffset": 7, "endOffset": 11}, {"referenceID": 24, "context": "These two problems are known to be the hardest and the easiest instance respectively in the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA [25].", "startOffset": 168, "endOffset": 172}, {"referenceID": 11, "context": "It is known that the expected running time of the (1+1)-EA on Jumpm,n is \u0398(n + n log n) [12], which implies that Jumpm,n with larger value of m is harder.", "startOffset": 88, "endOffset": 92}, {"referenceID": 1, "context": "There are naturally two fitness evaluation options for EAs [2, 21, 16, 19]:", "startOffset": 59, "endOffset": 74}, {"referenceID": 20, "context": "There are naturally two fitness evaluation options for EAs [2, 21, 16, 19]:", "startOffset": 59, "endOffset": 74}, {"referenceID": 15, "context": "There are naturally two fitness evaluation options for EAs [2, 21, 16, 19]:", "startOffset": 59, "endOffset": 74}, {"referenceID": 18, "context": "There are naturally two fitness evaluation options for EAs [2, 21, 16, 19]:", "startOffset": 59, "endOffset": 74}, {"referenceID": 9, "context": "Lemma 8 ([10]) For (1+1)-EA using re-evaluation with mutation probability 1 n on Ieasiest problem under one-bit noise, the expected running time is polynomial when pn \u2208 O(log(n)/n), and the running time is polynomial with super-polynomially small probability when pn \u2208 \u03c9(log(n)/n).", "startOffset": 9, "endOffset": 13}, {"referenceID": 22, "context": "To deal with this problem, a selection strategy for EAs handling noise was proposed [23].", "startOffset": 84, "endOffset": 88}, {"referenceID": 22, "context": ", the progress of one step) of EAs with threshold selection has been shown on some problems [23, 6, 5], its usefulness for the global performance (i.", "startOffset": 92, "endOffset": 102}, {"referenceID": 5, "context": ", the progress of one step) of EAs with threshold selection has been shown on some problems [23, 6, 5], its usefulness for the global performance (i.", "startOffset": 92, "endOffset": 102}, {"referenceID": 4, "context": ", the progress of one step) of EAs with threshold selection has been shown on some problems [23, 6, 5], its usefulness for the global performance (i.", "startOffset": 92, "endOffset": 102}, {"referenceID": 0, "context": "Lemma 9 ([1]) Given an undirected connected graphG = (V,E), the expected cover time of a random walk onG is upper bounded by 2|E|(|V | \u2212 1), where the cover time of a random walk onG is the number of steps until each vertex v \u2208 V has been visited at least once.", "startOffset": 9, "endOffset": 12}, {"referenceID": 0, "context": "Thus, the expected running time of the whole optimization process is O(n) for any pn \u2208 [0, 1], and then this theorem holds.", "startOffset": 87, "endOffset": 93}], "year": 2013, "abstractText": "Many optimization tasks have to be handled in noisy environments, where we cannot obtain the exact evaluation of a solution but only a noisy one. For noisy optimization tasks, evolutionary algorithms (EAs), a kind of stochastic metaheuristic search algorithm, have been widely and successfully applied. Previous work mainly focuses on empirical studying and designing EAs for noisy optimization, while, the theoretical counterpart has been little investigated. In this paper, we investigate a largely ignored question, i.e., whether an optimization problem will always become harder for EAs in a noisy environment. We prove that the answer is negative, with respect to the measurement of the expected running time. The result implies that, for optimization tasks that have already been quite hard to solve, the noise may not have a negative effect, and the easier a task the more negatively affected by the noise. On a representative problem where the noise has a strong negative effect, we examine two commonly employed mechanisms in EAs dealing with noise, the re-evaluation and the threshold selection strategies. The analysis discloses that the two strategies, however, both are not effective, i.e., they do not make the EA more noise tolerant. We then find that a small modification of the threshold selection allows it to be proven as an effective strategy for dealing with the noise in the problem.", "creator": "LaTeX with hyperref package"}}}