{"id": "1311.5836", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Nov-2013", "title": "Automatic Ranking of MT Outputs using Approximations", "abstract": "Since long, research on machine translation has been ongoing. Still, we do not get good translations from MT engines so developed. Manual ranking of these outputs tends to be very time consuming and expensive. Identifying which one is better or worse than the others is a very taxing task. In this paper, we show an approach which can provide automatic ranks to MT outputs (translations) taken from different MT Engines and which is based on N-gram approximations. We provide a solution where no human intervention is required for ranking systems. Further we also show the evaluations of our results which show equivalent results as that of human ranking.", "histories": [["v1", "Fri, 22 Nov 2013 18:13:06 GMT  (537kb)", "http://arxiv.org/abs/1311.5836v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["pooja gupta", "nisheeth joshi", "iti mathur"], "accepted": false, "id": "1311.5836"}, "pdf": {"name": "1311.5836.pdf", "metadata": {"source": "CRF", "title": "Automatic Ranking of MT Outputs using Approximations", "authors": ["Pooja Gupta", "Nisheeth Joshi", "Iti Mathur"], "emails": ["poojagupta2291@gmail.com", "nisheeth.joshi@rediffmail.com", "mathur_iti@rediffmail.com"], "sections": [{"heading": "General Terms", "text": "Natural language processing, machine translation"}, {"heading": "Keywords", "text": "N-gram language models, trigram approximations, maximum probability estimation."}, {"heading": "1. INTRODUCTION", "text": "Ngram Approximation is the sub-task of Natural Language Processing (NLP), the branch of artificial intelligence. Approximation has many applications mainly in machine translation and natural language processing. In this essay, we present an unattended learning approach to developing a ranking system. To this end, we have conducted our study on English-Hindi language pairs. We describe in detail the discriminatory training approach of machine learning to determine the best MT Engine Output. The main idea behind using MT Engine Output is to predict the correct translation of a sentence. Assessing the correct machine translation performance is very difficult. Many MT engines are developed in the world and there are various metrics that can be used to calculate the quality of machine translation. Using the ranking system, we can find out the best and accurate translation in minimum time. 5. The rest of the work is organized as follows section 2, which describes the review section 3."}, {"heading": "2. LITERATURE SURVEY", "text": "As we know, machine translation (MT) is becoming increasingly popular among end users, and the basic idea of estimating the quality of automatic translation for a given task is called trust estimation [1]. This trust estimation task has been transformed into a quality estimation task, in which the central idea remains the same. This estimation task is a relatively new aspect in machine translation research. In this area, previous work includes statistical methods for predicting confidence at the word level [2], in which only by looking at words people have attempted to analyze the quality of the translation. This method has been used by Specia et al. [3], who used a regression technique and used SVM classifiers, classifiers. Raybaud et al., 2009) [4] this study was expanded further by assessing correctness using several probabilistic metrics."}, {"heading": "3. OUR APPROACH", "text": "As language models, they can very easily grasp the structure (grammar) of the language, not relying on any linguistic analysis, but requiring a large corpus to which they can apply mathematical models. In this study, we used the Markov assumption and used Markov chains of order 2."}, {"heading": "3.1 Experimental Setup", "text": "For the development of our system, we used 35,000 sentences from the tourism sector. These were English sentences, the translations of which were provided by a human being. From these 35K sentences we generated the unigrams, bigrams and trigrams. The statistics of this study are in Table 1. Equations 1, 2 and 3 show the generation of uni-, bi- and triarms. () = () | (1) = () () () () (2) () () () (3)"}, {"heading": "Corpus Sentences Trigrams Bigrams Unigrams", "text": "We also used GIZA + + to generate parallel English-Hindi dictionaries, which we then checked and corrected manually. We used the following algorithm to generate the n-grams for our study. We applied this algorithm to both English and Hindi sentences. Input: Raw sentences Output: annotated text (N-gram text)"}, {"heading": "LM Algorithm", "text": "Step 1. Enter raw set files and repeat steps 2 to 4 for each set. Step 2. Divide each word of the set. Step 3. Generate trigrams, bigrams and unigrams for the entire set. Step 4. If n-gram is already present, increase the frequency. Step 5. If n-gram is unique, sort it in descending order according to its frequencies. Step 6. Create probability of trigrams with equation 3. Step 7. Create probability of bigrams with equation 2. Step 8. Create probability of unigrams with equation 1. Step 9. The performance obtained in the file is in our desired n-glove format. For our study we used 1300 English sets and used six MT motors. The list of motors is illustrated in Table 2. Among these E1, E2 and E3, MT motors are freely available on the Internet. E4, E5 and E6 are based on the MT-4 system, which we developed with different MT-MT motors."}, {"heading": "3.2 Methodology", "text": "To classify the MT output of different systems, we first generated the trigrams of the English sentence and its translations, which were generated by different MT engines. To classify the translations, we used the following algorithm: Input: English Sentence with MT outputs Output: Ranked MT output list"}, {"heading": "Ranking Algorithm", "text": "Step 1. Trigrams are generated from English sentences. Step 2. These trigrams are matched with the English language model and matching ones are retained. Step 3. Match the matching dictionaries of the English trigram with the parallel list of the English-Hindi lexicon. Step 4. If a match is found, register the corresponding Hindi lexicon. Step 5. Match the Hindi language model with registered Hindi lexicon and sum up the probabilities of each match. Step 6. Perform these steps on all MT editions. Step 7. Sort the MT editions in descending order with respect to their cumulative probabilities. Table 2. MT systems"}, {"heading": "Engine No. Description", "text": "E1 Microsoft Bing MT Engine1 E2 Google MT Engine2 E3 Babylon MT Engine3 E4 Moses Syntax Based Model E5 Moses Phrase Model E6 Example Based MT EngineFigure 1 shows how this whole approach works. To better understand the functionality, we have illustrated the whole process using the following examples: Jim Corbett National Park is the oldest national park in India and was founded in 1936 as Hailey National Park to protect the endangered Bengal tiger."}, {"heading": "E1 Output: \u093f\u091c\u092e \u0915\u0949\u092c\u091f \u0928\u0947\u0936\u0928\u0932 \u092a\u093e\u0915 \u092d\u093e\u0930\u0924 \u092e \u0938\u092c\u0938 \u0947 \u092a\u0941\u0930\u093e\u0928\u093e", "text": "The US and the EU have agreed that they cannot agree on a common currency, but only on a common currency, on a common currency and on a common currency."}, {"heading": "E2 Output: \u093f\u091c\u092e \u0915\u0949\u092c\u091f \u0928\u0936\u0947\u0928\u0932 \u092a\u093e\u0915 \u092d\u093e\u0930\u0924 \u092e \u0938\u092c\u0938 \u0947\u092a\u0941\u0930\u093e\u0928\u093e", "text": "In recent years, the number of unemployed in the United States has multiplied and the number of unemployed has doubled compared to the previous year."}, {"heading": "E3 Output: \u093f\u091c\u092e \u0915\u093e\u092c\u091f \u0930\u093e \u092f \u0909 \u092f\u093e\u0928 \u0915 \u0925\u093e\u092a\u0928\u093e \u0915 \u0917\u0908", "text": "The United States, China, China, China, the United States, China, China, China, the United States, China, China, China, the United States, China, China, China, the United States, China, China, China, China, the United States, China, China, China, China and the United States."}, {"heading": "E4 Output: \u093f\u091c\u092e \u0915\u094b\u092c\u0924 \u0928\u093e\u0936\u0928\u0932 \u092a\u093e\u0915 \u092d\u093e\u0930\u0924 \u092e \u0938\u092c\u0938 \u0947\u092a\u0941\u0930\u093e\u0928\u093e", "text": "The EU Commission and the EU Commission have agreed that the E5 environmental zone should be increased by up to 50 percent over the next five years. The EU Commission has increased the E5 environmental zone for the E10 environmental zones by up to 50 percent, and the EU Commission by up to 50 percent."}, {"heading": "E6 Output: \u093f\u091c\u092e \u0915\u0949\u092c\u091f \u0928\u0936\u0928\u0932 \u092a\u093e\u0915 \u0915\u094b \u092d\u093e\u0930\u0924 \u092e \u093e\u091a\u0940\u0928", "text": "The US and the EU have agreed that the US and EU member states must be able to fulfil their obligations to Iran."}, {"heading": "Engine Unigrams Bigrams Trigrams Prob.", "text": "Table 3 shows the n-gram statistics of these propositions and also the sum of the cumulative probabilities of these trigrams. Looking at the data, one can classify the system according to their probabilities."}, {"heading": "4. EVALUATION", "text": "To evaluate the performance of our system, we collected 1300 sentences from the tourism sector. These sentences were not part of the 35,000 that were used to train the models. To validate our results, we compared the ranks of the system with those given to the MT systems by a human evaluator. The human evaluator used a subjective human evaluation metric, which we used by Joshi et al. This metric rated an MT edition on ten parameters. These were: 1. Translation of gender and number of nouns (s).2. Identification of the proper name (s).3. Use of adjectives and adverbs corresponding to the nouns and verbs.4. Selection of proper words / synonyms (Lexical Choice).5. Sequence of phrases and clauses in the translation. 6. Use of punctuation marks in the translation 7. Translation of tenses in the sentence 8. Translation of the voice in the sentence 9."}, {"heading": "5. CONCLUSION", "text": "In this paper, we have shown the effective use of language models in the ranking of MT systems. To this end, we have created language models for both English and Hindi. We have also used parallel lexicographs to match the trigrams thus created. We have also measured the MT motors against 1300 sentences that were not part of the training corpus, and compared the ranks provided by a human judge. It turned out that the ranks generated by the LM-based ranking and the ranks of the human judge were similar. Thus, we have come to the conclusion that we can use this technique for the automatic ranking of MT systems. This can be considered a preliminary study as we still need to conduct further experiments to make reasonable assumptions. In addition, as an immediate future study, we can incorporate part of the language and morphological characteristics into language models and then perform the rank and see if the performance of the system improves or not. In addition, we can conduct this ranking system and can educate the classifiers in both."}, {"heading": "6. REFERENCES", "text": "[1] Blatz, J., Fitzgerald, E., Foster, G., Gandhi Peters, S., Goutte, C., Kulesza, A., Sanchis, A, & Ueffing, N. 2004. Confidence estimation for machine translation. In Proedings of 20th Coling, Geneva. [2] Ueffing, N., & Ney, H. 2005. Word-level confidence estimation for machine translation, using phrase-level Quality of Machine Translation models. Computational Linguistics. [3] Specia, L., Turchi, M., Cancedda, N., Dymetman, M., Cristianini, N. 2009. Estimating the Sentence-Level Quality of Machine Translation Systems. In Human Meeting of the European Association for Machine Translation (EAMT-2009) Barcelona, Spain. [4] Raybaud, S., Lavecchia, C., David, L., Kamel, S. 2009."}], "references": [{"title": "Confidence estimation for machine translation", "author": ["J. Blatz", "E. Fitzgerald", "G. Foster", "S. Gandrabur", "C. Goutte", "A. Kulesza", "A Sanchis", "N. Ueffing"], "venue": "In proceedings of 20th Coling, Geneva", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Word-level confidence estimation for machine translation using phrase-based translation models", "author": ["N. Ueffing", "H. Ney"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Estimating the Sentence-Level Quality of Machine Translation Systems. In 13th Annual Meeting of the European Association for Machine Translation (EAMT-2009) Barcelona, Spain", "author": ["L. Specia", "M. Turchi", "N. Cancedda", "M. Dymetman", "N. Cristianini"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Word-and sentence-level confidence measures for machine translation. In 13th Annual Meeting of the European Association for Machine Translation (EAMT", "author": ["S. Raybaud", "C. Lavecchia", "L. David", "S. Kamel"], "venue": "European Association of Machine Translation", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Combining Outputs from Multiple Machine Translation Systems", "author": ["Rosti", "A.-V", "N.F. Ayan", "B. Xiang", "S. Matsoukas", "R. Schwartz", "B.J. Dorr"], "venue": "In Proceedings of the North American Chapter of the Association for Computational Linguistics Human Language Technologies", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Modeling and Simulation Design", "author": ["P. Tavel"], "venue": "AK Peters Ltd", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Combining Quality Prediction and System Selection for Improved Automatic Translation Output", "author": ["R. Soricut", "S. Narsale"], "venue": "In Proceedings of the Seventh Workshop on Statistical Machine Translation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Quality Estimation for Machine Translation output using linguistic analysis and decoding features", "author": ["E. Avramidis"], "venue": "In Proceedings of the 7th Workshop on Statistical Machine Translation, Montre\u0301al, Canada", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Analysing Quality of English-Hindi Machine Translation Engine Outputs Using Bayesian Classification", "author": ["R. Gupta", "N. Joshi", "I. Mathur"], "venue": "International Journal of Artificial Intelligence and Applications,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Improved Smoothing for N-gram Language Models Based on Ordinary Counts", "author": ["R.C. Moore", "C. Quirk"], "venue": "In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Discriminative Training of 150 Million Translation Parameters and Its Application to Pruning", "author": ["H. Setiawan", "B. Zhou"], "venue": "In Proceedings of NAACL-HLT", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "A unified framework for phrase-based, hierarchical, and syntaxbased statistical machine translation", "author": ["H. Hoang", "P. Koehn", "A. Lopez"], "venue": "In Proc. of the International Workshop on Spoken Language Translation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Translation Memory for Indian Languages: An Aid for Human Translators", "author": ["N. Joshi", "I. Mathur", "S. Mathur"], "venue": "Proceedings of 2nd International Conference and Workshop in Emerging Trends in Technology", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Design of English-Hindi Translation Memory for Efficient Translation", "author": ["N. Joshi", "I. Mathur"], "venue": "In Proc. of National Conference on Recent Advances in Computer Engineering", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Human and Automatic Evaluation of English to Hindi Machine Translation Systems.\" Advances in Computer Science, Engineering & Applications", "author": ["N. Joshi", "H Darbari", "I. Mathur"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "HEval: Yet Another Human Evaluation Metric", "author": ["N. Joshi", "I. Mathur", "H Darbari", "A. Kumar"], "venue": "International Journal of Natural Language Computing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "The main idea of estimating the quality of automatic translations for a particular task is called as the confidence estimation [1].", "startOffset": 127, "endOffset": 130}, {"referenceID": 1, "context": "In this area, previous work includes statistical methods on predicting word-level confidence [2] where just by looking at words people tried to analyze the quality of the translation.", "startOffset": 93, "endOffset": 96}, {"referenceID": 2, "context": "[3] who applied a regression technique and used SVM based classifiers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": ", 2009) [4] further extended this study by estimating correctness using several probabilistic measures.", "startOffset": 8, "endOffset": 11}, {"referenceID": 4, "context": "[5] also performed sentence-level selections with generalized linear models that were based on re-ranking of N-best lists merged from many MT systems.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] have described machine translation evaluation as a ranking problem as it is often done by the humans.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Soricut and Narsal [7] used machine learning for ranking the candidate translations; they then selected the highest-ranked translation as the final output.", "startOffset": 19, "endOffset": 22}, {"referenceID": 7, "context": "Avramidis [8] showed an approach of ranking the outputs using grammatical features.", "startOffset": 10, "endOffset": 13}, {"referenceID": 8, "context": "[9] applied a na\u00efve bayes classifier on English-Hindi Machine Translation System and ranked them.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Moore and Quirk [10] described smoothing method for N-gram language models based on ordinary counts for generation of language models which can be used for quality estimation task.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "Setiawan and Zhou [11] employed discriminative training of 150 million translation parameters and its applications to pruning.", "startOffset": 18, "endOffset": 22}, {"referenceID": 11, "context": "This system used syntax based model [13].", "startOffset": 36, "endOffset": 40}, {"referenceID": 12, "context": "[14] [15].", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "[16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] have illustrated the entire working and detailed evaluation of this metric.", "startOffset": 0, "endOffset": 4}], "year": 2013, "abstractText": "Since long, research on machine translation has been ongoing. Still, we do not get good translations from MT engines so developed. Manual ranking of these outputs tends to be very time consuming and expensive. Identifying which one is better or worse than the others is a very taxing task. In this paper, we show an approach which can provide automatic ranks to MT outputs (translations) taken from different MT Engines and which is based on N-gram approximations. We provide a solution where no human intervention is required for ranking systems. Further we also show the evaluations of our results which show equivalent results as that of human ranking. General Terms Natural Language Processing, Machine Translation", "creator": null}}}