{"id": "1311.6211", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Nov-2013", "title": "Novelty Detection Under Multi-Instance Multi-Label Framework", "abstract": "Novelty detection plays an important role in machine learning and signal processing. This paper studies novelty detection in a new setting where the data object is represented as a bag of instances and associated with multiple class labels, referred to as multi-instance multi-label (MIML) learning. Contrary to the common assumption in MIML that each instance in a bag belongs to one of the known classes, in novelty detection, we focus on the scenario where bags may contain novel-class instances. The goal is to determine, for any given instance in a new bag, whether it belongs to a known class or a novel class. Detecting novelty in the MIML setting captures many real-world phenomena and has many potential applications. For example, in a collection of tagged images, the tag may only cover a subset of objects existing in the images. Discovering an object whose class has not been previously tagged can be useful for the purpose of soliciting a label for the new object class. To address this novel problem, we present a discriminative framework for detecting new class instances. Experiments demonstrate the effectiveness of our proposed method, and reveal that the presence of unlabeled novel instances in training bags is helpful to the detection of such instances in testing stage.", "histories": [["v1", "Mon, 25 Nov 2013 05:27:41 GMT  (385kb)", "http://arxiv.org/abs/1311.6211v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["qi lou", "raviv raich", "forrest briggs", "xiaoli z fern"], "accepted": false, "id": "1311.6211"}, "pdf": {"name": "1311.6211.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["xfern}@eecs.oregonstate.edu"], "sections": [{"heading": null, "text": "ar Xiv: 131 1.62 11v1 [cs.LG] 2 5N ov2 01Index Terms - novelty detection, multi-instance multilabel, kernel method"}, {"heading": "1. INTRODUCTION", "text": "This year, the time has come for it to be able to achieve the objectives I have mentioned, in the way that they are able to achieve them."}, {"heading": "2. PROPOSED METHODS", "text": "Suppose we get a collection of labeled bags {(X1, Y1), (X2, Y2),.. (XN, YN) in which the ith bag Xi, X is a series of instances from attribute space X, Rd, and Yi is a subset of the well-known label Y = N i = 1 Yi. Our goal is to determine for a given instance whether or not it belongs to a known class in Y.To illustrate the intuition behind our general strategy, we consider the toy problem shown in Table 1, which extends to the traditional MIML learning framework. Our goal is to determine for a given instance x-X whether or not it belongs to a known class in Y.Consider the well-known label problem in Table 1. The well-known label set is {I, II}. We have four labeled bags available."}, {"heading": "2.1. Kernel Based Scoring Functions", "text": "We define the score function for the class c as follows: fc (x) = max max. xJ (xl) = imp (x, xl) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp (x) = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp = imp ="}, {"heading": "2.2. Parameter Tuning", "text": "In our experiment, we use the Gaussian kernel, i.e. k (xi, xj) = e \u2212 \u03b3-xi \u2212 xj \u04452, where the parameter \u03b3 is the euclidean norm. \u03b3 controls the bandwidth of the kernel. Therefore, there are a pair of parameters \u03bb and \u03b3 in the objective function to be determined. During the training, we search for the pair of parameters in a wide range of values and select the pair with the corresponding \u03b1c, which minimize that the bandwidth i = 1 | Y | \u2211 c = 1g (yic max xij \u0445Xi fc (xij)), where g (x) = 1x < 0 is the zero-one loss function. Note that 1x < 0 is a lower limit of the hinge loss max {0, 1 \u2212 x}. We vary the value of the threshold for generating ROCs during the test. The values of the threshold are derived from training examples."}, {"heading": "3. EXPERIMENTAL RESULTS", "text": "In this section, we present a series of experimental results based on both synthetic data and real-world data to demonstrate the effectiveness of our algorithm. In addition, we present a comparison to first-class SVM, a remarkable algorithm for detecting anomalies."}, {"heading": "3.1. MNIST Handwritten Digits Dataset", "text": "We created the synthetic data based on the MNIST handwritten data set1. Each image in the data set is a 28 by 28 bitmap, i.e., a vector of 784 dimensions. By using PCA, we reduced the dimension of the instances to 20.We created training and testing bags from the MNIST instances. Some examples of handwritten numbers bags are1Available on-line http: / / www.cs.nyu.edu / \u02dc roweis / data.htmlshown in table 3. Two processes for creating bags are listed in Algorithm 2 and Algorithm 3. The only difference between these two methods is that Algorithm 3 excludes the possibility of labeling a bag, i.e., a bag including purely novel examples. For Dirichlet process used in our simulation, we use relatively low concentration parameters \u03b2 = (\u03b21, \u03b22, \u03b210) for dirichlet distribution."}, {"heading": "3.2. HJA Birdsong Dataset", "text": "We tested our algorithm on the real dataset - HYA Bird Singing2, which was used in [11, 12] This dataset consists of 548 bags, each of which contains several 38-dimensional instances. The bag size, i.e. the number of instances in a bag, varies from 1 to 26, of which the average is about 9. The dataset consists of 4998 instances of 13 species. Species names and the number of ingredients for these species are in Table 7. Each species corresponds to a class in the complete labelset {1, 2,., 13}. We took a subset of the complete labelset as a known labelset and experimented with various choices of the known labelset. Table 8 shows the average AUCs of various known labelsets. Specifically, we have made each species appear at least once in these known labelsets as a known labelset and experimented with various choices of the known labelset."}, {"heading": "Y AUC Y AUC", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.3. Comparison with One-Class SVM", "text": "Our algorithm deals with the detection problem with the MIML setting, which differs from the traditional setting for detecting anomalies. We argue that traditional detection algorithms of anomalies cannot be applied directly to our problem. To make a comparison, we use SVM [13-15] of a class, a known algorithm for detecting anomalies. To apply SVM of a class, we construct a normal class training, consisting of examples from the well-known label set. Parameters vary from 0 to 1 with step size 0.02 to generate ROCs. The Gausskore is used for SVM of a class. We select the parameter for the kernel in a wide range and select the best one for SMV posthoc classes. We present this unfair advantage over SVM of a class for two reasons: (i) It is unclear how to optimize the parameter when there are no new instances. (ii) We would like to illustrate the SVM with only a table of 5."}, {"heading": "Y AUC Y AUC", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4. CONCLUSION", "text": "A large number of simulations show that our algorithm works well not only on synthetic data, but also on real-world data. We also show that the presence of unlabeled examples in the training set is useful for detecting new class examples during the test. We present the advantage in the MIML environment for detecting novelties. Although positive examples of novelty that are not directly labeled offer a clear advantage over methods based on data that do not include novel class examples. There are many relative problems that require investigation, one of which will be how to use the information from bag labels in detection when bag labels are available, which may improve the performance of our algorithm since we did not use such information in our experiment."}, {"heading": "5. REFERENCES", "text": "[1] Markos Markou and Sameer Singh, \"Novelty detection: A review - part 1: Statistical approaches,\" Signal Processing, vol. 83, pp. 2481-2497, 2003. [2] Markos Markou and Sameer Singh, \"Novelty detection: A review - part 2: Neural network based approaches,\" Signal Processing, vol. 585-592, pp. 2499-2521, 2003. [3] Alfred O. Hero, \"Geometric Entropy minimization (gem) for anomaly detection and localization,\" in NIPS., 2006, pp. 585-592, MIT Press. [4] Kumar Sricharan and Alfred O. Alex, \"Efficient anomaly detection using bipartite k-nn graphs,\" in NIPS, 2011, pp.478-486."}], "references": [{"title": "Novelty detection: A review - part 1: Statistical approaches", "author": ["Markos Markou", "Sameer Singh"], "venue": "Signal Processing, vol. 83, pp. 2481\u20132497, 2003.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2003}, {"title": "Novelty detection:  A review - part 2: Neural network based approaches", "author": ["Markos Markou", "Sameer Singh"], "venue": "Signal Processing, vol. 83, pp. 2499\u20132521, 2003.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Geometric entropy minimization (gem) for anomaly detection and localization", "author": ["Alfred O. Hero"], "venue": "NIPS. 2006, pp. 585\u2013592, MIT Press.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Efficient anomaly detection using bipartite k-nn graphs", "author": ["Kumar Sricharan", "Alfred O. Hero"], "venue": "NIPS, 2011, pp. 478\u2013486.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Anomaly detection with score functions based on nearest neighbor graphs", "author": ["Manqi Zhao", "Venkatesh Saligrama"], "venue": "NIPS, 2009, pp. 2250\u20132258.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Support vector method for novelty detection", "author": ["Bernhard Sch\u00f6lkopf", "Robert C. Williamson", "Alex J. Smola", "John Shawe-Taylor", "John C. Platt"], "venue": "NIPS, 1999, pp. 582\u2013588.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1999}, {"title": "Multi-instance multi-label learning", "author": ["Zhi-Hua Zhou", "Min-Ling Zhang", "Sheng-Jun Huang", "Yu-Feng Li"], "venue": "Artif. Intell., vol. 176, no. 1, pp. 2291\u20132320, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Rankloss support instance machines for miml instance annotation", "author": ["Forrest Briggs", "Xiaoli Z. Fern", "Raviv Raich"], "venue": "KDD, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Representations of quasi-newton matrices and their use in limited memory methods", "author": ["Richard H. Byrd", "Jorge Nocedal", "Robert B. Schnabel"], "venue": "1994.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1994}, {"title": "Multiinstance multi-label learning for image classification with large vocabularies", "author": ["Oksana Yakhnenko", "Vasant Honavar"], "venue": "Proceedings of the British Machine Vision Conference. 2011, pp. 59.1\u201359.12, BMVA Press.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Instance annotation for multi-instance multilabel learning", "author": ["Forrest Briggs", "Xiaoli Z. Fern", "Raviv Raich", "Qi Lou"], "venue": "Transactions on Knowledge Discovery from Data (TKDD), 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "A conditional multinomial mixture model for superset label learning", "author": ["Li-Ping Liu", "Thomas G. Dietterich"], "venue": "NIPS, 2012, pp. 557\u2013565.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Estimating the support of a high-dimensional distribution", "author": ["Bernhard Sch\u00f6lkopf", "John C. Platt", "John Shawe-taylor", "Alex J. Smola", "Robert C. Williamson"], "venue": "1999.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1999}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology, vol. 2, pp. 27:1\u2013 27:27, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "One-class svms for document classification", "author": ["Larry M. Manevitz", "Malik Yousef", "Nello Cristianini", "John Shawe-taylor", "Bob Williamson"], "venue": "Journal of Machine Learning Research, vol. 2, pp. 139\u2013154, 2001.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "Novelty detection is the identification of new or unknown data that is not labeled during training [1].", "startOffset": 99, "endOffset": 102}, {"referenceID": 0, "context": "Early work is generally divided into two categories [1, 2].", "startOffset": 52, "endOffset": 58}, {"referenceID": 1, "context": "Early work is generally divided into two categories [1, 2].", "startOffset": 52, "endOffset": 58}, {"referenceID": 2, "context": "In [3], geo-", "startOffset": 3, "endOffset": 6}, {"referenceID": 3, "context": "An efficient anomaly detection method using bipartite k-NN graphs is presented in [4].", "startOffset": 82, "endOffset": 85}, {"referenceID": 4, "context": "In [5], an anomaly detection algorithm is proposed based on score functions.", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "In [6], SVMs are applied to novelty detection to learn a function f that is positive on a subset S of the input space and negative outside S.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "The MIML framework has been primarily studied for supervised learning [7] and widely used in applications where data is associated with multiple classes and can be naturally represented as bags of instances (i.", "startOffset": 70, "endOffset": 73}, {"referenceID": 7, "context": "Based on a collection of such labeled recordings, the goal is to annotate each vocalization in a new recording [8].", "startOffset": 111, "endOffset": 114}, {"referenceID": 7, "context": "Other loss functions such as rank loss [8] have already been introduced for MIML learning.", "startOffset": 39, "endOffset": 42}, {"referenceID": 8, "context": "To solve this convex problem, we deploy the L-BFGS [9] algorithm.", "startOffset": 51, "endOffset": 54}, {"referenceID": 7, "context": "Note that many algorithms [8,10] for MIML learning that attempt to learn an instance-level score functions including the proposed approach are based on a non-convex objective.", "startOffset": 26, "endOffset": 32}, {"referenceID": 9, "context": "Note that many algorithms [8,10] for MIML learning that attempt to learn an instance-level score functions including the proposed approach are based on a non-convex objective.", "startOffset": 26, "endOffset": 32}, {"referenceID": 10, "context": "We tested our algorithm on the real-world dataset - HJA birdsong dataset2, which has been used in [11, 12].", "startOffset": 98, "endOffset": 106}, {"referenceID": 11, "context": "We tested our algorithm on the real-world dataset - HJA birdsong dataset2, which has been used in [11, 12].", "startOffset": 98, "endOffset": 106}, {"referenceID": 12, "context": "To make comparison, we adopt one-class SVM [13\u201315], a well known algorithm for anomaly detection.", "startOffset": 43, "endOffset": 50}, {"referenceID": 13, "context": "To make comparison, we adopt one-class SVM [13\u201315], a well known algorithm for anomaly detection.", "startOffset": 43, "endOffset": 50}, {"referenceID": 14, "context": "To make comparison, we adopt one-class SVM [13\u201315], a well known algorithm for anomaly detection.", "startOffset": 43, "endOffset": 50}], "year": 2013, "abstractText": "Novelty detection plays an important role in machine learning and signal processing. This paper studies novelty detection in a new setting where the data object is represented as a bag of instances and associated with multiple class labels, referred to as multi-instance multi-label (MIML) learning. Contrary to the common assumption in MIML that each instance in a bag belongs to one of the known classes, in novelty detection, we focus on the scenario where bags may contain novel-class instances. The goal is to determine, for any given instance in a new bag, whether it belongs to a known class or a novel class. Detecting novelty in the MIML setting captures many realworld phenomena and has many potential applications. For example, in a collection of tagged images, the tag may only cover a subset of objects existing in the images. Discovering an object whose class has not been previously tagged can be useful for the purpose of soliciting a label for the new object class. To address this novel problem, we present a discriminative framework for detecting new class instances. Experiments demonstrate the effectiveness of our proposed method, and reveal that the presence of unlabeled novel instances in training bags is helpful to the detection of such instances in testing stage.", "creator": "LaTeX with hyperref package"}}}