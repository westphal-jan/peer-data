{"id": "1312.1530", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Dec-2013", "title": "Bandit Online Optimization Over the Permutahedron", "abstract": "The permutahedron is the convex polytope with vertex set consisting of the vectors $(\\pi(1),\\dots, \\pi(n))$ for all permutations (bijections) $\\pi$ over $\\{1,\\dots, n\\}$. We study a bandit game in which, at each step $t$, an adversary chooses a hidden weight weight vector $s_t$, a player chooses a vertex $\\pi_t$ of the permutahedron and suffers an observed loss of $\\sum_{i=1}^n \\pi(i) s_t(i)$.", "histories": [["v1", "Thu, 5 Dec 2013 13:00:23 GMT  (14kb)", "https://arxiv.org/abs/1312.1530v1", null], ["v2", "Sun, 6 Jul 2014 12:47:36 GMT  (25kb)", "http://arxiv.org/abs/1312.1530v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["nir ailon", "kohei hatano", "eiji takimoto"], "accepted": false, "id": "1312.1530"}, "pdf": {"name": "1312.1530.pdf", "metadata": {"source": "CRF", "title": "Bandit Online Optimization Over the Permutahedron", "authors": ["Nir Ailon", "Kohei Hatano", "Eiji Takimoto"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 131 2.15 30v2 [cs.LG] 6 Ji = 1 \u03c0t (i) st (i).We examine the problem in two steps. In the first scheme st is a point in the polytopic dual to the permutaheder. The algorithm CombBand by Cesa-Bianchi et al (2009) guarantees a regret of O (n \u221a T log n) after T-steps. Unfortunately, at each step CombBand requires an n-for-n matrix permanent computation, a # P -hard problem. Approaching the permanent is possible in the impractical runtime of O (n10), with an additional strong inverse polynomic dependence on the desired accuracy. We provide an algorithm of slightly inferior regret O (n3 / 2 \u221a T) but with more realistic time complexity O (n3) per step. The technical contribution is linked to the variance of the plackett lucie exploration process."}, {"heading": "1 Introduction", "text": "\"Consider a game in which a player plays a permutation of some principle V = {1,.}, n} at each step and then suffers (and observes) a loss. We model the loss as the sum of the items of some latent quality of the item, weighted according to its position in the permutation. The game repeats itself and the quality of the items may change over time. The game models many scenarios in which the player is an online system (say, a search / recommendation engine) that presents a ranking of the items (results / products) to a stream of users. A user's experience is positive when he perceives the quality of the top items on the list to be higher than that at the bottom. The goal of the system is to create a total positive experience for its users. There are a myriad of methods for modeling the rank losses in literature, especially (but not exclusively) for information recovery."}, {"heading": "2 Results, Techniques and Contribution", "text": "The first of two outcomes, called Theorem 1, is for the setting in which loss is fixed in each step (compared to other steps); the first of two outcomes, called Theorem 1, is for the setting in which loss is fixed (compared to other steps); our algorithm, BanditRank, requires permutations from a distribution known as the Plackett-Luce model (see [12]), which is widely used in statistics and econometrics (see eg [3]); it uses an inverse covariance matrix of distribution to obtain an unbiased loss vector estimator, which is a standard technique [6]; the main technical difficulty is that the properties of the second moment of Plackett-Luce are limited by establishing positive semi-definition of a particular family of 3 matrices; the second of three matrices is interesting as a tool for studying permutations."}, {"heading": "3 Definitions and Problem Statement", "text": "Let's get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to a point where we can get to get to get to a point where we can get to a point where we can get to a point where we can get a point where we can get to a point where we can get to a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get a point where we can get"}, {"heading": "4.1 Proof of Lemma 2", "text": "The expression E [X22] can be used as asE [X21] = u = u = u = u = u = u = u = u (u = u = u = u = u = u = u = u = u = u = u (u = u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s) s (u) s (u) s) s (u) s (u) s) s (u) s (u) s) u (u) s) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s (u) s) s (u) s (u) s (u) s) s (u) s (u) s (u) s (u) s) s (u (u) s) s (u (u) s) s (u (u) s) s) s (u (u (u) s) s) s (u (u (u) s) s) s (u (u) s) s (u (u) s) s) s (u (u) s) s) s (u (u) s) s (u (u (u) s) s) s) s (u (u (u) s) s) s (u (u) s) s) s) s (u (u (u (u) s) s) s) s (u (u (u) s), u (u (u (u (u) s) s), u (u (u (u (u) s) s) (u (u (u), u (u (u) (u (u), u) (u (u"}, {"heading": "5 Bandit Algorithm based on Projection and", "text": "Decomposition In this section we propose another bandit algorithm OSMDRank, which is described in algorithm 2. (This is defined in algorithm 2) We will work under the more limited assumption that algorithm 2 algorithm OSMDRank (n, p), time horizon T 2: let x1 = 0, Q) (Note that x1 = argmina, Q (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (a), F (c), F (c), F (c), D (c), D (c), F (c), D (a), D (c), D (c), F (c), D (a)."}, {"heading": "6 Future Work", "text": "The most important open question is whether there is an algorithm of expected regret O (n \u221a T) and time O (n3) in the setting of section 4. Another interesting field of research is the study of other ranking polytopes. For example, in the face of a strictly monotonous increasing function f: R 7 \u2192 R can be considered as an action set fn (Sn), defined as f n (Sn): = {(f (\u03c0 (1))), f (\u03c0 (2),..., f (\u03c0 (n)): \u03c0 (Sn)."}, {"heading": "Acknowledgments", "text": "Ailon appreciates the generous support of a Marie Curie reintegration grant PIRG07-GA-2010-268403, a grant from the Israel Science Foundation (ISF) 127 / 133 and a grant from the Jacobs Technion-Cornell Innovation Institute (JTCII)."}, {"heading": "A Derivations in proof of Lemma 2", "text": "After definition and then by applying the properties of the distribution PLn (w), Haa = [p] a (a) b (a) b (a) b (b) b (a) - p (a) - p (a) - p (a) p (c) p (c) - p (a) p (a) p (a) p (b) - p (c) a) - p (b) p (c) p (c) - p (b) - p (c) c - c c (c) c - c (c) - b (b) (p (c) - b (p - w w w w w) - p (c) p (b) - p (c) - p (c) c - c (c) - c (c) - b (c) - p (c) (c) - b (p (c) - b (b) (p - w w w w w w) - p (b) - p (c) - p (c) - b (b) - p (c) - c - c - c (c) - c (c) b) - p (c) b (c) - b (c) (p (c) - b) (c) - p (c) - b (c) (p (c) - b) (p (c) - b (c) - p (c) - b (c) - b (p (c) - b (c) - p (c) - p (w w w w w) p (w w) p (w) p (w w) p (w w) p (w) p (w w) p (w w) p (w) p (w) p (w w) p (p (b) p (w) p (c) p (c) p (w) p (c) p (w) p (w) p (c) p (c) p (c) p (c) p (w) p (c) p (c) p (c) p (w w w w) p (w w w) p (w w) p (c) p (c) p (c) p (c) p (b - p (c) p (c) p (c) p (c) p ("}], "references": [{"title": "Improved Bounds for Online Learning Over the Permutahedron and Other Ranking Polytopes", "author": ["Nir Ailon"], "venue": "In AISTATS,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire"], "venue": "SIAM J. Comput.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Assessing the potential demand for electric cars", "author": ["S Beggs", "S Cardell", "J Hausman"], "venue": "Journal of Econometrics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1981}, {"title": "Introduction to Online Optimization", "author": ["S\u00e9bastien Bubeck"], "venue": "http://www.princeton.edu/~bubeck/BubeckLectureNotes.pdf,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Towards Minimax Policies for Online Linear Optimization with Bandit Feedback", "author": ["S\u00e9bastien Bubeck", "Nicol\u00f2 Cesa-Bianchi", "Sham M. Kakade"], "venue": "In Proceedings of 25th Annual Conference on Learning Theory (COLT", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Combinatorial bandits", "author": ["Nicol\u00f2 Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "The price of bandit information for online optimization", "author": ["Varsha Dani", "Thomas P. Hayes", "Sham Kakade"], "venue": "In NIPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "The convex optimization approach to regret minimization", "author": ["Elad Hazan"], "venue": "Optimization for Machine Learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Volumetric spanners and their applications to machine learning", "author": ["Elad Hazan", "Zohar Shay Karnin", "Raghu Mehka"], "venue": "CoRR, abs/1312.6214,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Learning Permutations with Exponential Weights", "author": ["David P. Helmbold", "Manfred K. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "A polynomial-time approximation algorithm for the permanent of a matrix with nonnegative entries", "author": ["Mark Jerrum", "Alistair Sinclair", "Eric Vigoda"], "venue": "J. ACM,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Analyzing and Modeling Rank Data", "author": ["John I. Marden"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "Online Prediction under Submodular Constraints", "author": ["Daiki Suehiro", "Kohei Hatano", "Shuji Kijima", "Eiji Takimoto", "Kiyohito Nagano"], "venue": "In Proceedings of 23th Annual Conference on Algorithmic Learning Theory (ALT", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "The complexity of computing the permanent", "author": ["Leslie G. Valiant"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1979}, {"title": "Online Linear Optimization over Permutations", "author": ["Shota Yasutake", "Kohei Hatano", "Shuji Kijima", "Eiji Takimoto", "Masayuki Takeda"], "venue": "In Proceedings of the 22nd International Symposium on Algorithms and Computation (ISAAC", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "The relationship between Luce\u2019s choice axiom, Thurstone\u2019s theory of comparative judgment, and the double exponential distribution", "author": ["J. Yellott"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1977}], "referenceMentions": [{"referenceID": 11, "context": "Our algorithm, BanditRank, plays permutations from a distribution known as the Plackett-Luce model (see [12]) which is widely used in statistics and econometrics (see eg [3]).", "startOffset": 104, "endOffset": 108}, {"referenceID": 2, "context": "Our algorithm, BanditRank, plays permutations from a distribution known as the Plackett-Luce model (see [12]) which is widely used in statistics and econometrics (see eg [3]).", "startOffset": 170, "endOffset": 173}, {"referenceID": 5, "context": "It uses an inverse covariance matrix of the distribution in order to obtain an unbiased loss vector estimator, which is a standard technique [6].", "startOffset": 141, "endOffset": 144}, {"referenceID": 5, "context": "This result should be compared to CombBand of [6], where a framework for playing bandit games over combinatorially structured sets was developed.", "startOffset": 46, "endOffset": 49}, {"referenceID": 6, "context": "Their techniques extend that of [7].", "startOffset": 32, "endOffset": 35}, {"referenceID": 13, "context": "Unfortunately, nonnegative permanent computation is #P -hard, as shown by [14].", "startOffset": 74, "endOffset": 78}, {"referenceID": 10, "context": "groundbreaking result of [11] presents a polynomial time approximation scheme for permanent, which runs in time O(n) for fixed accuracy.", "startOffset": 25, "endOffset": 29}, {"referenceID": 8, "context": "[9] have improved the state-of-the-art general purpose algorithm for linear bandit optimization, implying an algorithm with regret O(n \u221a T ) for our problem, but with worse running time \u00d5(n).", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "We present and analyze an algorithm OSMDRank based on the bandit algorithm OSMD of [5] with projection and decomposition techniques over the permutahedron ([15, 13]).", "startOffset": 83, "endOffset": 86}, {"referenceID": 14, "context": "We present and analyze an algorithm OSMDRank based on the bandit algorithm OSMD of [5] with projection and decomposition techniques over the permutahedron ([15, 13]).", "startOffset": 156, "endOffset": 164}, {"referenceID": 12, "context": "We present and analyze an algorithm OSMDRank based on the bandit algorithm OSMD of [5] with projection and decomposition techniques over the permutahedron ([15, 13]).", "startOffset": 156, "endOffset": 164}, {"referenceID": 9, "context": "[10] were the first to study a more general version of this problem, where the action set is the vertex set of the Birkhoff-von-Neumann polytope (doubly-stochastic matrices).", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] studied the problem by casting it as a submodularly constrained optimization problem, giving near optimal regret bounds, and more recently Ailon [1] both provided optimal regret bounds with improved running time and established tight regret lower bounds.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[13] studied the problem by casting it as a submodularly constrained optimization problem, giving near optimal regret bounds, and more recently Ailon [1] both provided optimal regret bounds with improved running time and established tight regret lower bounds.", "startOffset": 150, "endOffset": 153}, {"referenceID": 11, "context": "An important well known property of the distribution is that it can be equivalently defined as a Random Utility Model (RUM) [12, 16]: To draw a permutation, add a random iid noise variable following the Gumbel distribution to each weight, and then sort the items of V in decreasing value of noisy-weights.", "startOffset": 124, "endOffset": 132}, {"referenceID": 15, "context": "An important well known property of the distribution is that it can be equivalently defined as a Random Utility Model (RUM) [12, 16]: To draw a permutation, add a random iid noise variable following the Gumbel distribution to each weight, and then sort the items of V in decreasing value of noisy-weights.", "startOffset": 124, "endOffset": 132}, {"referenceID": 5, "context": "\u2019s CombBand [6], which is itself an adaptation of Auer et al.", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "\u2019s Exp3 [2] from the finite case to the structured combinatorial case.", "startOffset": 8, "endOffset": 11}, {"referenceID": 11, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "We refer to [12] for definition and history of the BradleyTerry-Luce model.", "startOffset": 12, "endOffset": 16}, {"referenceID": 5, "context": "The proof of the theorem proceeds roughly as the main result upper bounding the expected regret of CombBand in [6].", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "We now note that (1) \u2211 \u03c0\u0302\u2208\u015c qt(\u03c0\u0302|wt\u22121)l\u0303t = lt (following the properties of matrix pseudo-inverse in Line 7 in Algorithm 1), and (2) \u2211 \u03c0\u0302\u2208\u015cn qt(\u03c0\u0302|wt\u22121)l\u0303t(\u03c0) ] \u2264 n (see top of page 31 together with Lemma 15 in [6]).", "startOffset": 212, "endOffset": 215}, {"referenceID": 11, "context": "9) Since Plackett-Luce is a random utility model (see [12]), it is clear that whenever a pair of pairs u 6= v, u\u2032 6= v\u2032 satisfies |{u, v, u\u2032, v\u2032}| = 4, p(u \u227a v \u2227 u\u2032 \u227a v\u2032|w) = p(u \u227a v|w)p(u\u2032 \u227a v\u2032|w).", "startOffset": 54, "endOffset": 58}, {"referenceID": 4, "context": "[5], on which our algorithm is based.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": ", [8]) for linear loss functions.", "startOffset": 2, "endOffset": 5}, {"referenceID": 14, "context": "The decomposition can be done using the technique of [15], which runs in O(n logn) time.", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "Our projection algorithm is an extension of that in [13] and our proof follows a similar argument in [13].", "startOffset": 52, "endOffset": 56}, {"referenceID": 12, "context": "Our projection algorithm is an extension of that in [13] and our proof follows a similar argument in [13].", "startOffset": 101, "endOffset": 105}, {"referenceID": 12, "context": "Then, it can be shown that projection preserves the order in q by using Lemma 1 in [13].", "startOffset": 83, "endOffset": 87}, {"referenceID": 12, "context": "By following a similar argument in [13], we can show that the output p indeed satisfies the KKT optimality conditions for projection, which completes the proof of the first statement.", "startOffset": 35, "endOffset": 39}, {"referenceID": 14, "context": "relative entropy or Euclidean norm squared), a different projection scheme is possible in time O(n) (see [15, 13] for the details).", "startOffset": 105, "endOffset": 113}, {"referenceID": 12, "context": "relative entropy or Euclidean norm squared), a different projection scheme is possible in time O(n) (see [15, 13] for the details).", "startOffset": 105, "endOffset": 113}, {"referenceID": 3, "context": ", chapters 5 and 7 on OMD and OSMD of Bubeck\u2019s lecture notes [4]).", "startOffset": 61, "endOffset": 64}, {"referenceID": 4, "context": "The key facts are: (i) A variant of Theorem 2 of [5] (regret bound of OSMD) holds for OSMD with Projection, (ii) E[\u03c0t] = (1\u2212\u03b3)xt, 13", "startOffset": 49, "endOffset": 52}], "year": 2014, "abstractText": "The permutahedron is the convex polytope with vertex set consisting of the vectors (\u03c0(1), . . . , \u03c0(n)) for all permutations (bijections) \u03c0 over {1, . . . , n}. We study a bandit game in which, at each step t, an adversary chooses a hidden weight weight vector st, a player chooses a vertex \u03c0t of the permutahedron and suffers an observed instantaneous loss of \u2211n i=1 \u03c0t(i)st(i). We study the problem in two regimes. In the first regime, st is a point in the polytope dual to the permutahedron. Algorithm CombBand of Cesa-Bianchi et al (2009) guarantees a regret of O(n \u221a T log n) after T steps. Unfortunately, CombBand requires at each step an n-by-n matrix permanent computation, a #P -hard problem. Approximating the permanent is possible in the impractical running time of O(n), with an additional heavy inverse-polynomial dependence on the sought accuracy. We provide an algorithm of slightly worse regret O(n \u221a T ) but with more realistic time complexity O(n) per step. The technical contribution is a bound on the variance of the Plackett-Luce noisy sorting process\u2019s \u2018pseudo loss\u2019, obtained by establishing positive semi-definiteness of a family of 3-by-3 matrices of rational functions in exponents of 3 parameters. In the second regime, st is in the hypercube. For this case we present and analyze an algorithm based on Bubeck et al.\u2019s (2012) OSMD approach with a novel projection and decomposition technique for the permutahedron. The algorithm is efficient and achieves a regret of O(n \u221a T ), but for a more restricted space of possible loss vectors.", "creator": "LaTeX with hyperref package"}}}