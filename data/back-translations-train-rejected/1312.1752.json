{"id": "1312.1752", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Dec-2013", "title": "Particle Swarm Optimization of Information-Content Weighting of Symbolic Aggregate Approximation", "abstract": "Bio-inspired optimization algorithms have been gaining more popularity recently. One of the most important of these algorithms is particle swarm optimization (PSO). PSO is based on the collective intelligence of a swam of particles. Each particle explores a part of the search space looking for the optimal position and adjusts its position according to two factors; the first is its own experience and the second is the collective experience of the whole swarm. PSO has been successfully used to solve many optimization problems. In this work we use PSO to improve the performance of a well-known representation method of time series data which is the symbolic aggregate approximation (SAX). As with other time series representation methods, SAX results in loss of information when applied to represent time series. In this paper we use PSO to propose a new minimum distance WMD for SAX to remedy this problem. Unlike the original minimum distance, the new distance sets different weights to different segments of the time series according to their information content. This weighted minimum distance enhances the performance of SAX as we show through experiments using different time series datasets.", "histories": [["v1", "Fri, 6 Dec 2013 02:22:59 GMT  (106kb)", "http://arxiv.org/abs/1312.1752v1", "The 8th International Conference on Advanced Data Mining and Applications (ADMA 2012)"]], "COMMENTS": "The 8th International Conference on Advanced Data Mining and Applications (ADMA 2012)", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["muhammad marwan muhammad fuad"], "accepted": false, "id": "1312.1752"}, "pdf": {"name": "1312.1752.pdf", "metadata": {"source": "CRF", "title": "Particle Swarm Optimization of Information-Content Weighting of Symbolic Aggregate Approximation", "authors": ["Muhammad Marwan", "Muhammad Fuad"], "emails": ["marwan.fuad@iet.ntnu.no"], "sections": [{"heading": null, "text": "Keywords: Particle Swarm Optimization, Bio-inspired Optimization, Time Series Data Mining, Information Loss, Information Content, Symbolic Aggregate Approximation."}, {"heading": "1 Introduction", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 The Symbolic Aggregate Approximation (SAX)", "text": "The symbolic aggregate approximation method (SAX) [14] is one of the most important symbolic representation methods of time series. The main advantage of SAX is that the similarity measurement it uses, called MINDIST, uses statistical reference tables, making it easy to calculate with a total complexity of () NO.SAX, based on the assumption that normalized time series have the Gaussian distribution, so that by determining the breakpoints corresponding to a certain alphabet size, one can obtain equal ranges below the Gaussian curve. SAX is applied as follows: 1-The time series are standardized, 2-The dimensionality of the time series is reduced with PAA [9], [30] 3-The PAA representation of the time series is discredited by determining the number and location of breakpoints."}, {"heading": "2.2 Information Content", "text": "The quantification of the information content carried by a vector was first introduced by Shannon in the year [24]. This concept is measured by so-called entropy and is defined for a discrete probabilistic system by: \u2211 \u2212 = i ii plogpH (3), with the base of the logarithm at 2.This concept has many applications in cryptography, data transmission, natural language processing, data compression and others.In time series mining, the concept of information content was implicitly or explicitly present in various representation methods of time series data. DFT [2], [3] and DWT [5], for example, are based on the fact that the first coefficients are the most significant; i.e. they contain most of the information in the time series, so that the other coefficients can be truncated without much loss of information. APCA [10] segments the time series into segments of different lengths, so that their individual reconstruction errors are minimal."}, {"heading": "3 Particle Swarm Optimization of Information-Content Weighting of Symbolic Aggregate Approximation (PSOWSAX)", "text": "In the time in which we have to engage with other regions that are less informational, we seem to be very good. (...) In the time in which we have to engage with other countries, it is as if we have to engage with other countries. (...) In the time in which we have to engage with other countries, it is as if we have to engage with other countries. (...) In the time in which we engage with other countries, it is as if we have to engage with other countries. (...) In the time in which we have to engage with other countries, it is as if we have to engage with other countries. (...) In the time in which we have to engage with each other, it is as if we have to engage with other countries. (...) The time in which we want to engage with each other. (...) The time in which we want to engage with each other. (...) The time in which we want to engage with each other. (...) The time in which we want to engage with each other."}, {"heading": "4 Experimental Validation", "text": "We tested our distance to a time series classification task and see which is the smallest error we have for each of the three literacy steps we tested. This is the same repository where the original SAX was tested. This repository comprises between 90% and 100% of all publicly accessible, labeled time series records in the world, and it represents the interest of the database community, not just a group [6]. We tested our method in a classification task based on the first closest point (1-NN) rule, comparing each time series with other time series in the dataset. If the 1-NN is not in the same class, the error counter is 1. The purpose of the experiments is to compare PSOWSAX (our new method that uses WMD as a measure of similarity) with the original method (which uses MINDIST as a measure of similarity)."}, {"heading": "5 Conclusion", "text": "In this paper, using a new scheme based on particle sponge optimization, we demonstrated how to improve the performance of SAX, one of the most important symbolic representation methods of time series data, by using a new similarity measurement WMD, which assigns different weights to different segments of the time series according to their information content. Loss of information caused by methods for displaying time series can be better restored by setting different weights for different regions of the time series according to their information content, and the optimization process takes place at a time when the new scheme has the same low complexity as the original SAX. We validated the new scheme by performing classification task experiments on different datasets, and the experiments showed that our new scheme yields better results than the original one. One possible future work will consist of linking the work presented in this paper in two ways with the work presented in [20]."}], "references": [{"title": "Webster's New World College Dictionary, Webster's New World, ISBN 0764571257", "author": ["M. Agnes"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Efficient Similarity Search in Sequence Databases", "author": ["R. Agrawal", "C. Faloutsos", "A. Swami"], "venue": "Proceedings of the 4th Conf. on Foundations of Data Organization and Algorithms.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1993}, {"title": "Fast Similarity Search in the Presence of Noise, Scaling, and Translation in Time-Series Databases", "author": ["R. Agrawal", "K.I. Lin", "H.S. Sawhney", "K. Shim"], "venue": "In Proceedings of the 21st Int'l Conference on Very Large Databases. Zurich,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1995}, {"title": "Indexing Spatio-temporal Trajectories with Chebyshev Polynomials", "author": ["Y. Cai", "R. Ng"], "venue": "In SIGMOD", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Efficient Time Series Matching by Wavelets", "author": ["K. Chan", "A.W. Fu"], "venue": "In proc. of the 15th IEEE Int'l Conf. on Data Engineering. Sydney, Australia, Mar 23-26. pp 126-133.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1999}, {"title": "Querying and Mining of Time Series Data: Experimental Comparison of Representations and Distance Measures", "author": ["H. Ding", "G. Trajcevski", "P. Scheuermann", "X. Wang", "E. Keogh"], "venue": "In Proc of the 34th VLDB", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "What Makes Particle Swarm Optimization a Very Interesting and Powerful Algorithm", "author": ["J.L. Fern\u00e1ndez-Mart\u00ednez", "E. Garc\u00eda-Gonzalo"], "venue": "Handbook of Swarm Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Practical Genetic Algorithms with CD-ROM", "author": ["R.L. Haupt", "S.E. Haupt"], "venue": "Wiley-Interscience", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases", "author": ["E Keogh", "K Chakrabarti", "M. Pazzani", "Mehrotra"], "venue": "J. of Know. and Inform. Sys.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2000}, {"title": "Locally Adaptive Dimensionality Reduction for Similarity Search in Large Time Series Databases", "author": ["E Keogh", "K Chakrabarti", "M. Pazzani", "S. Mehrotra"], "venue": "SIGMOD pp 151-162", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2001}, {"title": "HOT SAX: Efficiently Finding the Most Unusual Time Series Subsequence", "author": ["E. Keogh", "J. Lin", "A. Fu"], "venue": "In Proc. of the 5th IEEE International Conference on Data Mining (ICDM 2005), Houston, Texas, Nov 27-30", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Efficiently Supporting Ad Hoc Queries in Large Datasets of Time Sequences", "author": ["F. Korn", "H. Jagadish", "C. Faloutsos"], "venue": "Proceedings of SIGMOD '97, Tucson, AZ, pp 289-300", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1997}, {"title": "A Symbolic Representation of Time Series, with Implications for Streaming Algorithms", "author": ["J. Lin", "E. Keogh", "S. Lonardi", "B.Y. Chiu"], "venue": "DMKD", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Experiencing SAX: a Novel Symbolic Representation of Time Series", "author": ["J. Lin", "E. Keogh", "L. Wei", "S. Lonardi"], "venue": "DMKD Journal", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "Multiresolution Symbolic Representation of Time Series", "author": ["C. Megalooikonomou"], "venue": "In proceedings of the 21st IEEE International Conference on Data Engineering (ICDE). Tokyo, Japan.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "The L-index: An Indexing Structure for Efficient Subsequence Matching in Time Sequence Databases", "author": ["Y. Morinaka", "M. Yoshikawa", "T. Amagasa", "S. Uemura"], "venue": "In Proc. 5th PacificAisa Conf. on Knowledge Discovery and Data Mining, pages 51-60", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2001}, {"title": "Enhancing the Symbolic Aggregate Approximation Method Using Updated Lookup Tables", "author": ["M.M. Muhammad Fuad", "P.F. Marteau"], "venue": "14th International Conference on Knowledge-Based and Intelligent Information & Engineering Systems \u2013 KES 2010. Cardiff, Wales, UK. September 8-10", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Fast Retrieval of Time Series by Combining a Multiresolution Filter with a Representation Technique", "author": ["M.M. Muhammad Fuad", "P.F. Marteau"], "venue": "The International Conference on Advanced Data Mining and Applications\u2013ADMA2010, ChongQing, China, 21 November", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Genetic Algorithms-Based Symbolic Aggregate Approximation", "author": ["M.M. Muhammad Fuad"], "venue": "14th International Conference on Data Warehousing and Knowledge Discovery - DaWaK 2012 \u2013 Vienna, Austria, September 3 \u2013 7", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-resolution Approach to Time Series Retrieval", "author": ["M.M. Muhammad Fuad", "P.F. Marteau"], "venue": "Fourteenth International Database Engineering and Applications Symposium\u2013 IDEAS 2010 , 16-18 August, 2010, Montreal, QC, CANADA", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Speeding-up the Similarity Search in Time Series Databases by Coupling Dimensionality Reduction Techniques with a Fast-and-dirty Filter", "author": ["M.M. Muhammad Fuad", "P.F. Marteau"], "venue": "Fourth IEEE International Conference on Semantic Computing\u2013 ICSC 2010, 22-24 September 2010, Carnegie Mellon University, Pittsburgh, PA, USA", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Flocks, Herds and Schools: A Distributed Behavioral Model", "author": ["C.W. Reynolds"], "venue": "SIGGRAPH Comput. Graph. 21, 4", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1987}, {"title": "A Mathematical Theory of Communication", "author": ["C. Shannon"], "venue": "The Bell Systems Technical Journal 27, 379\u2013423, 623\u2013656", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1948}, {"title": "iSAX: Disk-Aware Mining and Indexing of Massive Time Series Datasets", "author": ["J. Shieh", "E. Keogh"], "venue": "Data Mining and Knowledge Discovery", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "iSAX: Indexing and Mining Terabyte Sized Time Series", "author": ["J. Shieh", "E. Keogh"], "venue": "In Proceeding of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Las Vegas, Nevada, USA, August 24 \u2013 27", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "Time Series Analysis with Multiple Resolutions", "author": ["Q. Wang", "V. Megalooikonomou", "C. Faloutsos"], "venue": "Inf. Syst. 35, 1", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "SAXually Explict Images: Finding Unusual Shapes", "author": ["L. Wei", "E. Keogh", "X. Xi"], "venue": "ICDM", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "FALCON: Feedback Adaptive Loop for Content-Based Retrieval VLDB", "author": ["L. Wu", "C. Faloutsos", "K. Sycara", "T. Payne"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2000}, {"title": "Fast Time Sequence Indexing for Arbitrary Lp Norms", "author": ["B.K. Yi", "C. Faloutsos"], "venue": "Proceedings of the 26th International Conference on Very Large Databases, Cairo, Egypt", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2000}, {"title": "Robust PSO-based Constrained Optimization by Perturbing the Particle\u2019s Memory", "author": ["A.M. Zavala", "A.H. Aguirre", "E.V. Diharce"], "venue": "Swarm Intelligence: Focus on ant and particle swarm optimization, Felix T. S. Chan and Manoj Kumar Tiwari,Ed. I-Tech Education and Publishing", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 1, "context": "The most widely known methods are Discrete Fourier Transform (DFT) [2] and [3], Discrete Wavelet Transform (DWT) [5], Singular Value Decomposition (SVD) [13], Adaptive Piecewise Constant Approximation (APCA) [10], Piecewise Aggregate Approximation (PAA) [9] and [30], Piecewise Linear Approximation (PLA) [17], and Chebyshev Polynomials (CP) [4].", "startOffset": 67, "endOffset": 70}, {"referenceID": 2, "context": "The most widely known methods are Discrete Fourier Transform (DFT) [2] and [3], Discrete Wavelet Transform (DWT) [5], Singular Value Decomposition (SVD) [13], Adaptive Piecewise Constant Approximation (APCA) [10], Piecewise Aggregate Approximation (PAA) [9] and [30], Piecewise Linear Approximation (PLA) [17], and Chebyshev Polynomials (CP) [4].", "startOffset": 75, "endOffset": 78}, {"referenceID": 4, "context": "The most widely known methods are Discrete Fourier Transform (DFT) [2] and [3], Discrete Wavelet Transform (DWT) [5], Singular Value Decomposition (SVD) [13], Adaptive Piecewise Constant Approximation (APCA) [10], Piecewise Aggregate Approximation (PAA) [9] and [30], Piecewise Linear Approximation (PLA) [17], and Chebyshev Polynomials (CP) [4].", "startOffset": 113, "endOffset": 116}, {"referenceID": 11, "context": "The most widely known methods are Discrete Fourier Transform (DFT) [2] and [3], Discrete Wavelet Transform (DWT) [5], Singular Value Decomposition (SVD) [13], Adaptive Piecewise Constant Approximation (APCA) [10], Piecewise Aggregate Approximation (PAA) [9] and [30], Piecewise Linear Approximation (PLA) [17], and Chebyshev Polynomials (CP) [4].", "startOffset": 153, "endOffset": 157}, {"referenceID": 9, "context": "The most widely known methods are Discrete Fourier Transform (DFT) [2] and [3], Discrete Wavelet Transform (DWT) [5], Singular Value Decomposition (SVD) [13], Adaptive Piecewise Constant Approximation (APCA) [10], Piecewise Aggregate Approximation (PAA) [9] and [30], Piecewise Linear Approximation (PLA) [17], and Chebyshev Polynomials (CP) [4].", "startOffset": 208, "endOffset": 212}, {"referenceID": 8, "context": "The most widely known methods are Discrete Fourier Transform (DFT) [2] and [3], Discrete Wavelet Transform (DWT) [5], Singular Value Decomposition (SVD) [13], Adaptive Piecewise Constant Approximation (APCA) [10], Piecewise Aggregate Approximation (PAA) [9] and [30], Piecewise Linear Approximation (PLA) [17], and Chebyshev Polynomials (CP) [4].", "startOffset": 254, "endOffset": 257}, {"referenceID": 28, "context": "The most widely known methods are Discrete Fourier Transform (DFT) [2] and [3], Discrete Wavelet Transform (DWT) [5], Singular Value Decomposition (SVD) [13], Adaptive Piecewise Constant Approximation (APCA) [10], Piecewise Aggregate Approximation (PAA) [9] and [30], Piecewise Linear Approximation (PLA) [17], and Chebyshev Polynomials (CP) [4].", "startOffset": 262, "endOffset": 266}, {"referenceID": 15, "context": "The most widely known methods are Discrete Fourier Transform (DFT) [2] and [3], Discrete Wavelet Transform (DWT) [5], Singular Value Decomposition (SVD) [13], Adaptive Piecewise Constant Approximation (APCA) [10], Piecewise Aggregate Approximation (PAA) [9] and [30], Piecewise Linear Approximation (PLA) [17], and Chebyshev Polynomials (CP) [4].", "startOffset": 305, "endOffset": 309}, {"referenceID": 3, "context": "The most widely known methods are Discrete Fourier Transform (DFT) [2] and [3], Discrete Wavelet Transform (DWT) [5], Singular Value Decomposition (SVD) [13], Adaptive Piecewise Constant Approximation (APCA) [10], Piecewise Aggregate Approximation (PAA) [9] and [30], Piecewise Linear Approximation (PLA) [17], and Chebyshev Polynomials (CP) [4].", "startOffset": 342, "endOffset": 345}, {"referenceID": 14, "context": "In [16] and [27] a method of multi resolution representation of time series is presented.", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "In [16] and [27] a method of multi resolution representation of time series is presented.", "startOffset": 12, "endOffset": 16}, {"referenceID": 17, "context": "In [19] and [20] other multi-resolution method are proposed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "In [19] and [20] other multi-resolution method are proposed.", "startOffset": 12, "endOffset": 16}, {"referenceID": 20, "context": "The technique presented in [22] couples and fast-and-dirty filter with a multi-resolution representation of the time series.", "startOffset": 27, "endOffset": 31}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "One of its main advantages is that symbolic representation permits researchers to benefit from the ample symbolic algorithms known in the text-retrieval and bioinformatics communities [14].", "startOffset": 184, "endOffset": 188}, {"referenceID": 13, "context": "But in general, most of these symbolic representation methods suffered from two main inconveniences [15]; the first is that the dimensionality of the symbolic representation method is the same as that of the original space, so there is no virtual dimensionality reduction.", "startOffset": 100, "endOffset": 104}, {"referenceID": 12, "context": "The Symbolic Aggregate approXimation method (SAX) [14] is one of the most important symbolic representation methods of time series.", "startOffset": 50, "endOffset": 54}, {"referenceID": 8, "context": "2-The dimensionality of the time series is reduced using PAA [9], [30] 3-The PAA representation of the time series is discretized by determining the number and location of the breakpoints (The number of the breakpoints is chosen by the user).", "startOffset": 61, "endOffset": 64}, {"referenceID": 28, "context": "2-The dimensionality of the time series is reduced using PAA [9], [30] 3-The PAA representation of the time series is discretized by determining the number and location of the breakpoints (The number of the breakpoints is chosen by the user).", "startOffset": 66, "endOffset": 70}, {"referenceID": 8, "context": "It is proven in [9], [30] that the above similarity distance is a lower bound of the Euclidean distance applied in the original space of time series.", "startOffset": 16, "endOffset": 19}, {"referenceID": 28, "context": "It is proven in [9], [30] that the above similarity distance is a lower bound of the Euclidean distance applied in the original space of time series.", "startOffset": 21, "endOffset": 25}, {"referenceID": 10, "context": "There are other versions and extensions of SAX [11], [25], [26], [28].", "startOffset": 47, "endOffset": 51}, {"referenceID": 23, "context": "There are other versions and extensions of SAX [11], [25], [26], [28].", "startOffset": 53, "endOffset": 57}, {"referenceID": 24, "context": "There are other versions and extensions of SAX [11], [25], [26], [28].", "startOffset": 59, "endOffset": 63}, {"referenceID": 26, "context": "There are other versions and extensions of SAX [11], [25], [26], [28].", "startOffset": 65, "endOffset": 69}, {"referenceID": 16, "context": "These versions use it for other applications or apply it to index massive datasets, or compute MINDIST differently [18].", "startOffset": 115, "endOffset": 119}, {"referenceID": 22, "context": "Quantifying the content of information a vector carries was first introduced by Shannon in [24].", "startOffset": 91, "endOffset": 95}, {"referenceID": 1, "context": "DFT [2], [3] and DWT [5], for instance are based on the fact that the first coefficients are the most meaningful ones; i.", "startOffset": 4, "endOffset": 7}, {"referenceID": 2, "context": "DFT [2], [3] and DWT [5], for instance are based on the fact that the first coefficients are the most meaningful ones; i.", "startOffset": 9, "endOffset": 12}, {"referenceID": 4, "context": "DFT [2], [3] and DWT [5], for instance are based on the fact that the first coefficients are the most meaningful ones; i.", "startOffset": 21, "endOffset": 24}, {"referenceID": 9, "context": "APCA [10] segments the time series into segments of varying lengths such that their individual reconstruction errors are minimal.", "startOffset": 5, "endOffset": 9}, {"referenceID": 27, "context": "In [29] the authors proposed setting the weights using relevance feedback provided by the user.", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "PSO was inspired by the social behavior of some animals, such as bird flocking or fish schooling [8].", "startOffset": 97, "endOffset": 100}, {"referenceID": 21, "context": "[23] proposed a model that simulates a swarm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "In the following we present a standard PSO [7].", "startOffset": 43, "endOffset": 46}, {"referenceID": 0, "context": "Exploration is defined as the act of searching for the purpose of discovery, and exploitation is defined as the act of utilizing something for any purpose [1].", "startOffset": 155, "endOffset": 158}, {"referenceID": 29, "context": "Diversity in PSO comes from two sources [31]; the first is the difference between the particle\u2019s current position and that of its best neighbor, and the other is the difference between the particle\u2019s current position and its best historical position.", "startOffset": 40, "endOffset": 44}, {"referenceID": 5, "context": "This repository makes up between 90% and 100% of all publicly available, labeled time series data sets in the world, and it represents the interest of the data mining/database community, and not just one group [6].", "startOffset": 210, "endOffset": 213}, {"referenceID": 18, "context": "A possible future work will be to associate the work presented in this paper with the work presented in [20].", "startOffset": 104, "endOffset": 108}, {"referenceID": 18, "context": "This can be achieved in two ways; the first is to use the optimization scheme presented in [20] to locate the breakpoints then to use the optimization scheme presented in this work to set different weights to different segments according to their information content.", "startOffset": 91, "endOffset": 95}], "year": 2012, "abstractText": "Bio-inspired optimization algorithms have been gaining more popularity recently. One of the most important of these algorithms is particle swarm optimization (PSO). PSO is based on the collective intelligence of a swam of particles. Each particle explores a part of the search space looking for the optimal position and adjusts its position according to two factors; the first is its own experience and the second is the collective experience of the whole swarm. PSO has been successfully used to solve many optimization problems. In this work we use PSO to improve the performance of a well-known representation method of time series data which is the symbolic aggregate approximation (SAX). As with other time series representation methods, SAX results in loss of information when applied to represent time series. In this paper we use PSO to propose a new minimum distance WMD for SAX to remedy this problem. Unlike the original minimum distance, the new distance sets different weights to different segments of the time series according to their information content. This weighted minimum distance enhances the performance of SAX as we show through experiments using different time series datasets.", "creator": "PScript5.dll Version 5.2.2"}}}