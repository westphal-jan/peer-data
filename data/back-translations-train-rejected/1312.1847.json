{"id": "1312.1847", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Dec-2013", "title": "Understanding Deep Architectures using a Recursive Convolutional Network", "abstract": "Convolutional neural network models have recently been shown to achieve excellent performance on challenging recognition benchmarks. However, like many deep models, there is little guidance on how the architecture of the model should be selected. Important hyper-parameters such as the degree of parameter sharing, number of layers, units per layer, and overall number of parameters must be selected manually through trial-and-error. To address this, we introduce a novel type of recursive neural network that is convolutional in nature. Its similarity to standard convolutional models allows us to tease apart the important architectural factors that influence performance. We find that for a given parameter budget, deeper models are preferred over shallow ones, and models with more parameters are preferred to those with fewer. Surprisingly and perhaps counterintuitively, we find that performance is independent of the number of units, so long as the network depth and number of parameters is held constant. This suggests that, computational efficiency considerations aside, parameter sharing within deep networks may not be so beneficial as previously supposed.", "histories": [["v1", "Fri, 6 Dec 2013 12:55:05 GMT  (195kb,D)", "https://arxiv.org/abs/1312.1847v1", null], ["v2", "Wed, 19 Feb 2014 17:55:37 GMT  (151kb,D)", "http://arxiv.org/abs/1312.1847v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["david eigen", "jason rolfe", "rob fergus", "yann lecun"], "accepted": false, "id": "1312.1847"}, "pdf": {"name": "1312.1847.pdf", "metadata": {"source": "CRF", "title": "Understanding Deep Architectures using a Recursive Convolutional Network", "authors": ["David Eigen", "Jason Rolfe", "Rob Fergus", "Yann LeCun"], "emails": ["deigen@cs.nyu.edu", "rolfe@cs.nyu.edu", "fergus@cs.nyu.edu", "yann@cs.nyu.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, the majority of them will be able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "1.1 Related Work", "text": "The model we use is related to recursive neural networks. These are well-studied models [11, 21, 27], which are of course suitable for temporal and sequential data. Thus, it was recently shown that they performed excellently in phoneme recognition [8] and italic handwriting recognition [7], but are only limited to image data. Socher et al. [26] showed how image segments could be merged recursively to perform scene parsing. More recently [25], they used a revolutionary network at a separate stage to first learn features on RGB depth data before they were hierarchically merged. In these models, the input dimension is twice as large as the output. This contrast to our model, which has the same input and output dimensions. Our network also has connections to multiple auto-encoder models. Low coding [18] algorithms like ISTA, for example, use ISTA algorithms."}, {"heading": "2 Approach", "text": "Our study is based on a multi-layer convolutionary network [14], for which all layers beyond the first layer have the same size and connecting topology. All layers use unidirectional linear units (ReLU) [3, 4, 16]. We perform maximum pooling after the first layer with non-overlapping windows. To emphasize the difference between the pooled first layer and the unpooled higher layers, we do not use explicit pooling. We refer to the number of characteristic maps per layer as M, and the number of layers after the first as L. To emphasize the difference between the pooled first layer and the unpooled higher layers, we designate the first conversion core after V and the cores of the higher layers after Wl. A pro-map bias bl is applied in conjunction with the convolutions. A final classification matrix C forms the last hidden layer on soft- max layers."}, {"heading": "2.1 Instantiation on CIFAR-10 and SVHN", "text": "We describe our models for the CIFAR-10 [12] and SVHN [17] datasets used in our experiments. In both cases, each image is Xn of size 32 \u00b7 32 \u00b7 3. In the following equations, we drop the superscript n, which indicates the index in the dataset for notational simplicity. The first layer uses a set of M cores Vm of size 8 \u00b7 8 \u00b7 3 via a spatial convolution with stripe one (referred to as Celsius) and per-card bias b0m, followed by the elemental reflection nonlinearity. We use an \"equal\" convolution (i.e. the addition of the edges), which results in an equal-sized representation P of 32 \u00b7 32 \u00b7 M. This representation is then padded within each function card with non-overlapping 4 \u00d7 4 windows, resulting in a hidden layer Z1 of size Z1."}, {"heading": "3 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Performance Evaluation", "text": "For CIFAR-10, we tested the models with M = 32, 64, 128 or 256 feature cards per layer, and L = 1, 2, 4, 8 or 16 layers above the first layer. For SVHN, we used M = 32, 64, 128 or 256 feature cards and L = 1, 2, 4 or 8 layers above the first layer. That we were able to train networks at these great depths is due to the initialization of all W lm due to identity: This first copies activations in the first layer to the last, and gradients from the last layer to the first. Both unbound and bound models had difficulty learning with zero-centered Gaussian initializations in some of the larger layers."}, {"heading": "3.2 Effects of the Numbers of Feature maps, Parameters and Layers", "text": "In a traditional unbound convolutional network, the number of character cards M, layers L and the parameters P are linked: Increasing the number of character cards or layers increases the total number of parameters in addition to the representational power gained by higher dimensionality (more character cards) or greater nonlinearity (more layers). But by using the bound version of our model, we can independently study the effects of each of these three variables. To achieve this, we consider the following three cases, each of which we examine with the described setup: 1. Control for M and P, different L: Using the bound model (constant M and P), we evaluate the performance for different layer numbers L.2. Control for M and L, different P: Compile pairs of bound and unbound models with the same number of character cards M and layers L. The number of parameters P increases when we go from bound to unbound layer L.2. Control for M and L, different P: Compile pairs of bound and unbound models with the same number of character cards M and layers."}, {"heading": "3.2.1 Case 1: Number of Layers", "text": "We examine the first of these cases in Fig. 4. Here, we record the classification performance for different number of layers, using only the bound model that controls the number of parameters; a different curve is shown for different number of characteristic maps; for both CIFAR-10 and SVHN, performance gets better as the number of layers increases, although CIFAR-10 test errors have an upward trend of 8 layers; the predominant reason for this seems to be that the training error is still decreasing; at these depths, therefore, adding more layers alone leads to performance improvement, although no additional parameters are introduced; this is because additional layers allow the network to learn more complex functions by using more nonlinearities.This conclusion is further supported by Fig. 5, which shows the performance of the unbound model by number of parameters and layers. Note that vertical cross sections of these sections correspond to constant parameters mapping."}, {"heading": "3.2.2 Case 2: Number of Parameters", "text": "In order to vary the number of parameters P and at the same time record the number of characteristic cards M and LayerL, we consider pairs of bound and unbound models where M and L remain the same within each pair.The number of parameters P is then greater for the unbound model. The result of this comparison is shown in Fig. 6. Each point corresponds to a model pair; we show the classification performance of the bound model on the x axis and the performance of the unbound model on the y axis. Since the points fall below the y = x line, the classification performance for the unbound model is better than for the unbound model. This is not surprising as the unbound model has more overall parameters and thus more flexibility. Also, note that the two models converge to the same test performance as the classification improves - this is because both models have enough flexibility for the largest number of L and M to achieve maximum test performance and thus overtake experiments."}, {"heading": "3.2.3 Case 3: Number of Feature Maps", "text": "We now look at the third condition from above, the effect of variation in the number of character cards M while simultaneously fixing the number of layers L and the parameters P. For a given L, we find model pairs whose number of parameters P is very close by varying the number of character cards. For example, an unbound model with L = 3 layers and M = 71 character cards P = 195473 has parameters, while a bound model with L = 3 layers and M = 108 character cards P = 195058 has parameters - a difference of only 0.2%. In this experiment, we randomly stitched model pairs with the same number of layers and where the number of parameters was within 1.0% of each other. We looked at models where the number of layers above the first was between 2 and 8, and the number of character cards was between 16 and 256 (for CIFAR-10) or between 16 and 150 (SVHN)."}, {"heading": "4 Discussion", "text": "Above, we have shown that while the number of layers and parameters each have a significant impact on performance, the number of feature cards has little impact once the number of parameters is taken into account. This may be somewhat counterproductive, as we would have expected the use of higher-dimensional representations to increase performance rather than placing them in a few layers, even though this comes at the expense of reducing the feature card. This is exactly what you might expect if the number of feature cards has little impact compared to the number of layers. Our analysis used a special bound architecture and has some important caveats. First, while the bound architecture serves as a useful point of comparison leading to several interesting conclusions, its behavior is relatively unknown compared to the usual unbound models."}], "references": [{"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM Journal on Imaging Sciences, 2(1):183\u2013202", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Flexible", "author": ["D.C. Ciresan", "U. Meier", "J. Masci", "L.M. Gambardella", "J. Schmidhuber"], "venue": "high performance convolutional neural networks for image classification. In IJCAI", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "The importance of encoding versus training with sparse coding and vector quantization", "author": ["A. Coates", "A.Y. Ng"], "venue": "ICML, volume 8, pages 921\u2013928", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Deep sparse rectifier networks", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "AISTATS, volume 15, pages 315\u2013323", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Maxout networks", "author": ["I. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "ICML", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Multi-prediction deep boltzmann machines", "author": ["I.J. Goodfellow", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "NIPS", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "A novel connectionist system for improved unconstrained handwriting recognition", "author": ["A. Graves", "M. Liwicki", "S. Fernandez", "R. Bertolami", "H. Bunke", "J. Schmidhuber"], "venue": "PAMI, 31(5)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A. Mohamed", "G. Hinton"], "venue": "ICASSP", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning fast approximations of sparse coding", "author": ["K. Gregor", "Y. LeCun"], "venue": "ICML", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastave", "A. Krizhevsky", "I. Sutskever", "R.R. Salakhutdinov"], "venue": "arXiv:1207.0580", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation, 9(8):1735\u20131780", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1997}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Technical Report TR-2009, University of Toronto", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1998}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A. Ng"], "venue": "ICML, volume 26", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "ICML, pages 807\u2013814", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Y. Netzer", "T. Wang", "A. Coates", "A. Bissacco", "B. Wu", "A.Y. Ng"], "venue": "NIPS Workshop", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Sparse coding with an overcomplete basis set: A strategy employed by V1? Vision Research", "author": ["B.A. Olshausen", "D.J. Field"], "venue": "37(23):3311\u20133325", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "Discriminative recurrent sparse auto-encoders", "author": ["J. Rolfe", "Y. LeCun"], "venue": "ICLR", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Sparse coding via thresholding and local competition in neural circuits", "author": ["C.J. Rozell", "D.H. Johnson", "R.G. Baraniuk", "B.A. Olshausen"], "venue": "Neural Computation,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Training recurrent networks by evolino", "author": ["J. Schmidhuber", "D. Wierstra", "M. Gagliolo", "F. Gomez"], "venue": "Neural Computation, 19(3):757\u2013779", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Convolutional neural networks applied to house numbers digit classification", "author": ["P. Sermanet", "S. Chintala", "Y. LeCun"], "venue": "ICPR", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Overfeat: Integrated recognition", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "localization and detection using convolutional networks. http://arxiv.org/abs/1312.6229", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Practical bayesian optimzation of machine learning algorithms", "author": ["J. Snoek", "H. Larochelle", "R. Adams"], "venue": "NIPS", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Convolutional-Recursive Deep Learning for 3D Object Classification", "author": ["R. Socher", "B. Huval", "B. Bhat", "C.D. Manning", "A.Y. Ng"], "venue": "NIPS", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks", "author": ["R. Socher", "C.C. Lin", "A.Y. Ng", "C.D. Manning"], "venue": "ICML", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "Temporal kernel recurrent neural networks", "author": ["I. Sutskever", "G. Hinton"], "venue": "Neural Networks, 23:239\u2013243", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Regularization of neural networks using dropconnect", "author": ["L. Wan", "M. Zeiler", "Z. Sixin", "Y. LeCun", "R. Fergus"], "venue": "ICML", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "Stochastic pooling", "author": ["M. Zeiler", "R. Fergus"], "venue": "ICLR", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "Arxiv.org 1131.2901v3", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 12, "context": "1 Introduction Convolutional networks have recently made significant progress in a variety of image classification and detection tasks [13, 2, 23], with further gains and applications continuing to be realized.", "startOffset": 135, "endOffset": 146}, {"referenceID": 1, "context": "1 Introduction Convolutional networks have recently made significant progress in a variety of image classification and detection tasks [13, 2, 23], with further gains and applications continuing to be realized.", "startOffset": 135, "endOffset": 146}, {"referenceID": 22, "context": "1 Introduction Convolutional networks have recently made significant progress in a variety of image classification and detection tasks [13, 2, 23], with further gains and applications continuing to be realized.", "startOffset": 135, "endOffset": 146}, {"referenceID": 12, "context": "Notably, multiple layers of unpooled convolution [13, 30] have been utilized lately with considerable success.", "startOffset": 49, "endOffset": 57}, {"referenceID": 29, "context": "Notably, multiple layers of unpooled convolution [13, 30] have been utilized lately with considerable success.", "startOffset": 49, "endOffset": 57}, {"referenceID": 12, "context": "[13] for ImageNet classification has five convolutional layers which turn out to be key to its performance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "In [30], Zeiler and Fergus reimplemented this model and adjusted different parts in turn.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "These are are well-studied models [11, 21, 27], naturally suited to temporal and sequential data.", "startOffset": 34, "endOffset": 46}, {"referenceID": 20, "context": "These are are well-studied models [11, 21, 27], naturally suited to temporal and sequential data.", "startOffset": 34, "endOffset": 46}, {"referenceID": 26, "context": "These are are well-studied models [11, 21, 27], naturally suited to temporal and sequential data.", "startOffset": 34, "endOffset": 46}, {"referenceID": 7, "context": "For example, they have recently been shown to deliver excellent performance for phoneme recognition [8] and cursive handwriting recognition [7].", "startOffset": 100, "endOffset": 103}, {"referenceID": 6, "context": "For example, they have recently been shown to deliver excellent performance for phoneme recognition [8] and cursive handwriting recognition [7].", "startOffset": 140, "endOffset": 143}, {"referenceID": 25, "context": "[26] showed how image segments could be recursively merged to perform scene parsing.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "More recently [25], they used a convolutional network in a separate stage to first learn features on RGB-Depth data, prior to hierarchical merging.", "startOffset": 14, "endOffset": 18}, {"referenceID": 17, "context": "Sparse coding [18] uses iterative algorithms, such as ISTA [1], to perform inference.", "startOffset": 14, "endOffset": 18}, {"referenceID": 0, "context": "Sparse coding [18] uses iterative algorithms, such as ISTA [1], to perform inference.", "startOffset": 59, "endOffset": 62}, {"referenceID": 19, "context": "[20] showed how the ISTA scheme can be unwrapped into a repeated series of network layers, which can be viewed as a recursive net.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Gregor & LeCun [9] showed how to backpropagate through such a network to give fast approximations to sparse coding known as LISTA.", "startOffset": 15, "endOffset": 18}, {"referenceID": 18, "context": "Rolfe & LeCun [19] then showed in their DrSAE model how a discriminative term can be added.", "startOffset": 14, "endOffset": 18}, {"referenceID": 14, "context": "There also are interesting relationships with convolutional Deep Belief Networks [15], as well as Multi-Prediction Deep Boltzmann Machines [6].", "startOffset": 81, "endOffset": 85}, {"referenceID": 5, "context": "There also are interesting relationships with convolutional Deep Belief Networks [15], as well as Multi-Prediction Deep Boltzmann Machines [6].", "startOffset": 139, "endOffset": 142}, {"referenceID": 5, "context": "As pointed out by [6], mean field inference in such models can be unrolled and viewed as a type of recurrent network.", "startOffset": 18, "endOffset": 21}, {"referenceID": 14, "context": "In contrast to the model we use, however, [15] trains unsupervised using contrastive divergence, while [6] is nonconvolutional and focuses on conditioning on random combinations of inputs and targets.", "startOffset": 42, "endOffset": 46}, {"referenceID": 5, "context": "In contrast to the model we use, however, [15] trains unsupervised using contrastive divergence, while [6] is nonconvolutional and focuses on conditioning on random combinations of inputs and targets.", "startOffset": 103, "endOffset": 106}, {"referenceID": 13, "context": "Our investigation is based on a multilayer Convolutional Network [14], for which all layers beyond the first have the same size and connection topology.", "startOffset": 65, "endOffset": 69}, {"referenceID": 2, "context": "All layers use rectified linear units (ReLU) [3, 4, 16].", "startOffset": 45, "endOffset": 55}, {"referenceID": 3, "context": "All layers use rectified linear units (ReLU) [3, 4, 16].", "startOffset": 45, "endOffset": 55}, {"referenceID": 15, "context": "All layers use rectified linear units (ReLU) [3, 4, 16].", "startOffset": 45, "endOffset": 55}, {"referenceID": 8, "context": "This novel recursive, convolutional architecture is reminiscent of LISTA [9], but without a direct projection from the input to each hidden layer.", "startOffset": 73, "endOffset": 76}, {"referenceID": 11, "context": "1 Instantiation on CIFAR-10 and SVHN We describe our models for the CIFAR-10 [12] and SVHN [17] datasets used in our experiments.", "startOffset": 77, "endOffset": 81}, {"referenceID": 16, "context": "1 Instantiation on CIFAR-10 and SVHN We describe our models for the CIFAR-10 [12] and SVHN [17] datasets used in our experiments.", "startOffset": 91, "endOffset": 95}, {"referenceID": 9, "context": "First, we note that despite the simple architecture of our model, it still achieves competitive performance on both datasets, relative to other models that, like ours, do not use any image transformations or other regularizations such as dropout [10, 28], stochastic pooling [29] or maxout [5] (see Table 1).", "startOffset": 246, "endOffset": 254}, {"referenceID": 27, "context": "First, we note that despite the simple architecture of our model, it still achieves competitive performance on both datasets, relative to other models that, like ours, do not use any image transformations or other regularizations such as dropout [10, 28], stochastic pooling [29] or maxout [5] (see Table 1).", "startOffset": 246, "endOffset": 254}, {"referenceID": 28, "context": "First, we note that despite the simple architecture of our model, it still achieves competitive performance on both datasets, relative to other models that, like ours, do not use any image transformations or other regularizations such as dropout [10, 28], stochastic pooling [29] or maxout [5] (see Table 1).", "startOffset": 275, "endOffset": 279}, {"referenceID": 4, "context": "First, we note that despite the simple architecture of our model, it still achieves competitive performance on both datasets, relative to other models that, like ours, do not use any image transformations or other regularizations such as dropout [10, 28], stochastic pooling [29] or maxout [5] (see Table 1).", "startOffset": 290, "endOffset": 293}, {"referenceID": 23, "context": "[24] 15.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] 15.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] 16.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "6 Coates & Ng [3] 18.", "startOffset": 14, "endOffset": 17}, {"referenceID": 28, "context": "1 Zeiler & Fergus (max pool) [29] 3.", "startOffset": 29, "endOffset": 33}, {"referenceID": 21, "context": "[22] 4.", "startOffset": 0, "endOffset": 4}], "year": 2014, "abstractText": "A key challenge in designing convolutional network models is sizing them appropriately. Many factors are involved in these decisions, including number of layers, feature maps, kernel sizes, etc. Complicating this further is the fact that each of these influence not only the numbers and dimensions of the activation units, but also the total number of parameters. In this paper we focus on assessing the independent contributions of three of these linked variables: The numbers of layers, feature maps, and parameters. To accomplish this, we employ a recursive convolutional network whose weights are tied between layers; this allows us to vary each of the three factors in a controlled setting. We find that while increasing the numbers of layers and parameters each have clear benefit, the number of feature maps (and hence dimensionality of the representation) appears ancillary, and finds most of its benefit through the introduction of more weights. Our results (i) empirically confirm the notion that adding layers alone increases computational power, within the context of convolutional layers, and (ii) suggest that precise sizing of convolutional feature map dimensions is itself of little concern; more attention should be paid to the number of parameters in these layers instead.", "creator": "LaTeX with hyperref package"}}}