{"id": "1312.3903", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Dec-2013", "title": "A Methodology for Player Modeling based on Machine Learning", "abstract": "AI is gradually receiving more attention as a fundamental feature to increase the immersion in digital games. Among the several AI approaches, player modeling is becoming an important one. The main idea is to understand and model the player characteristics and behaviors in order to develop a better AI. In this work, we discuss several aspects of this new field. We proposed a taxonomy to organize the area, discussing several facets of this topic, ranging from implementation decisions up to what a model attempts to describe. We then classify, in our taxonomy, some of the most important works in this field. We also presented a generic approach to deal with player modeling using ML, and we instantiated this approach to model players' preferences in the game Civilization IV. The instantiation of this approach has several steps. We first discuss a generic representation, regardless of what is being modeled, and evaluate it performing experiments with the strategy game Civilization IV. Continuing the instantiation of the proposed approach we evaluated the applicability of using game score information to distinguish different preferences. We presented a characterization of virtual agents in the game, comparing their behavior with their stated preferences. Once we have characterized these agents, we were able to observe that different preferences generate different behaviors, measured by several game indicators. We then tackled the preference modeling problem as a binary classification task, with a supervised learning approach. We compared four different methods, based on different paradigms (SVM, AdaBoost, NaiveBayes and JRip), evaluating them on a set of matches played by different virtual agents. We conclude our work using the learned models to infer human players' preferences. Using some of the evaluated classifiers we obtained accuracies over 60% for most of the inferred preferences.", "histories": [["v1", "Fri, 13 Dec 2013 18:32:51 GMT  (2163kb,D)", "http://arxiv.org/abs/1312.3903v1", "Thesis presented by Marlos C. Machado as part of the requirements for the degree or Master of Science in Computer Science granted by the Universidade Federal de Minas Gerais. February, 18th, 2013"]], "COMMENTS": "Thesis presented by Marlos C. Machado as part of the requirements for the degree or Master of Science in Computer Science granted by the Universidade Federal de Minas Gerais. February, 18th, 2013", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["marlos c machado"], "accepted": false, "id": "1312.3903"}, "pdf": {"name": "1312.3903.pdf", "metadata": {"source": "CRF", "title": "UMA METODOLOGIA PARA MODELAGEM DE JOGADORES BASEADA EM APRENDIZADO DE MA\u0301QUINA", "authors": ["MARLOS CHOLODOVSKIS MACHADO", "APRENDIZADO DE M\u00c1QUINA", "Marlos Cholodovskis"], "emails": [], "sections": [{"heading": null, "text": "UMA METODOLOGIA PARA MODELAGEM DEJOGADORES BASEADA EMAPRENDIZADO DE M\u00c1QUINAar Xiv: 131 2.39 03v1 [cs.AI] 13 December 201 3MARLOS CHOLODOVSKIS MACHADOUMA METODOLOGIA PARA MODELAGEM DEJOGADORES BASEADA EMAPRENDIZADO DE M\u00c1QUINADisserta\u00e7\u00e3o apresentada ao Programa de P\u00f3s-Gradua\u00e7\u00e3o em Ci\u00eancia da Computa\u00e7\u00e3o do Instituto de Ci\u00eancias Exatas da Universidade Federal de Minas Gerais como requisito parcial para obten\u00e7\u00e3o do grau de Mestre em Ci\u00eancia da Computa\u00e7\u00e3o-Gradua\u00e7\u00e3o em Ci\u00eancia em Ci\u00eancia, Ci\u00eancia do Instituto de Ci\u00eancias Exatas Exatas da Universidade Minas Gerais, como requisito parcial para para do obten\u00e7\u00e3o do grau de Mestre-Grau de Ci\u00eas-Gradua\u00e7\u00e3o-Gradua\u00e7\u00e3o in Ci\u00eanacio-Gradua\u00e7\u00e3o em Ci\u00eanacio-Gradua\u00e7\u00e3o em Ci\u00eanacio-Gradua\u00e7\u00e3o em Ci\u00eanacio, Ci\u00eanacio, AI, AAAI, AAAACAI, CACACI, LUICACACI, CAI, LUIZ CHAIMOWICORCORCORCORCO, CORCO, CORCORCO, CORCORCO, ORCORCO, ORCORCO, VADIVADIVADICO,"}, {"heading": "A METHODOLOGY FOR PLAYER MODELING BASED", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "ON MACHINE LEARNING", "text": "s degree in Computer Science. ADVISOR: LUIZ CHAIMOWICZ CO-ADVISOR: GISELE LOBO PAPPABelo HorizonteFebruary 2013c \u00a9 2013, Marlos Cholodovskis Machado. Todos os direitos reservados.Machado, Marlos Cholodovskis. M149m Uma metodologia para modelagem de jogadoresbaseada em aprendizado de m\u00e1quina / Marlos Cholodovskis Machado. - Belo Horizonte, 2013.xxvii, 99 f.: il.; 29cmDisserta\u00e7\u00e3o para modelagem de jogadoresbaseada em aprendizado de m\u00e1quina / Marlos Cholodovskis Machado. Belonte, 2013.xi."}, {"heading": "Acknowledgments", "text": "The only exception is Pieter Spronck, who is grateful to me for sharing his data, source codes and impressions with me! Quando eu comecei o mestrado, pensava que que n\u00e3o teria muitas pessoas para agradecer ao ao ao final. Achava que agradeceria somente aos pais, orientadores, irm\u00e3o e noiva. Eu estava errado, sou grato a muitas pessoas.Primeiro, referente \u00e0 minha fam\u00edlia, eu gostaria de agradecer aos pais, que paeus pais, que sempre, incondicionalmente mente me incentivaram fazer o mestrado."}, {"heading": "1 Introduction 1", "text": "1.1 Context and motivation..........................................................................................................................."}, {"heading": "2 Background 7", "text": "2.1 Civilisation IV..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "3 Related Work and Player Modeling Taxonomy 15", "text": "3.1 Related work............................................. 153.1.1 Artificial Intelligence Opponents........................ 16xxv3.1.2 Game Design............................................................ 203.2 Player Modeling Taxonomy......................................................."}, {"heading": "4 A Generic Approach for Player Modeling as an ML Problem 29", "text": "4.1 Preference Modeling Methodology as Machine Learning Problem 294.1.1 Representation Definition................. 30 4.1.2 Features and Examples Definition......................... 30 4.1.3 Problem Modeling and Appropriate Algorithms........... 30 4.1.4 Parameter Configuration............................. 324.2...................................................."}, {"heading": "5 Player Modeling in Civilization IV 39", "text": "5.1 Data set..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "6 Experimental Results 59", "text": "......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"}, {"heading": "7 Conclusion 77", "text": "xxvi7.1 Contributions and discussions.............................. 77 7.2 Future work............................"}, {"heading": "Appendix A CIVILIZATION IV Dataset Features 89", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Appendix B Summary of Indicators\u2019 Linear Regressions 91", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Appendix C Questionnaires applied to Human Players 93", "text": "C.1 Pre-Test Questionnaire.............................. 93 C.2 Post-Test Questionnaire........................... 97"}, {"heading": "D Accuracy Classifying each Human Player 99", "text": "xxvii \"Would you please tell me which way to go from here?\" \"It depends a lot on where you want to go,\" said the cat. \"I don't care where,\" said Alice. \"Then it doesn't matter which way you go,\" said Cat.Lewis Carroll, Alice's Adventures in WonderlandChapter 1IntroductionThis chapter discusses the context of this thesis as well as the motivation to explore player modeling. It also presents the objectives of the work, the main contributions of the work, the publications it has generated, and an overview of the organization of the rest of the text."}, {"heading": "1.1 Context and Motivation", "text": "The main objective of most games is entertainment [Nareyek, 2004]. Entertainment is a subjective concept, and in order to know how much a game entertains a player, some general metrics are used. One of the most important metrics is immersion, which is generally related to how captivating and captivating a game is [Manovich, 2001; Taylor, 2002; Bakkes et al., 2009]. Two common approaches to achieving immersion are the use of stunning graphics and the development of a good artificial intelligence (AI) system. While graphics are responsible for the initial \"seduction\" of players, AI is responsible for their interest in the game. For a long time, the game industry has focused much of its efforts on graphics for its AAA games1. In recent years, however, the focus has shifted to AI, which has often been reduced to a less important role, and new techniques are now constantly proposed."}, {"heading": "2 CHAPTER 1. INTRODUCTION", "text": "It is the case that most people who are able are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "1.2. PROBLEM DEFINITION AND OBJECTIVES 3", "text": "Although player modeling has received much more attention recently, it has been considered a relevant topic for some years now [Carmel and Markovitch, 1993; van den Herik et al., 2005; Laviers et al., 2009]. In this context, we present our research objectives, followed by our main contributions."}, {"heading": "1.2 Problem Definition and Objectives", "text": "As discussed above, the term player modeling can be used to model multiple player facets. In this work, we use player modeling, which refers to the modeling of player styles. This is called in the nomenclature of Spronck and the Teuling [2010]; the Teuling [2010] preference modeling. We intend to model the game styles automatically by using data from played games. To accomplish this task, it is important to ensure that the extracted data is relevant and allow us to differentiate between different players. As the techniques of player modeling can be generalized to apply to a number of games, and not to a specific one, we present a generic approach for this and an assessment of a generic representation for players in different games. In order to automatically identify styles in the game CIVILIZATION IV, we perform our generic approach to the problem of preference modeling at. Finally, we organize based on the enormous attention that the player has to receive in the modeling set."}, {"heading": "1.3 Contributions", "text": "In summary, the most important contributions of this work are: \u2022 A taxonomy for the player modeling field, more precisely: - We extracted several different features from the literature and proposed a taxonomy that classifies each work according to six different aspects: description, categories, objectives, applications, methods and implementation; - We categorized several important works in the literature using our taxonomy. \u2022 After presenting an organization for the field, we treat the player modeling problem in two phases: - We propose a generic approach to player modeling as a machine learning problem;"}, {"heading": "4 CHAPTER 1. INTRODUCTION", "text": "- We discuss a generic representation that can be used in different games, evaluating the possibility of its use in the industry, which shows that it fulfills most of the functions required by Isla [2005]. \u2022 We then instantiate the approach that is proposed in our problem, i.e., modeling preferences of CIVILIZATION IV players. \u2022 To do this, we performed several tasks: - Evaluated the possibility of using the generic representation discussed, which shows that we are able to infer the representation of an agent who observed his behavior in the game CIVILIZATION IV. - Games evaluate the applicability of CIVILIZATION IV in-game indicators as characteristics of an ML approach. To do this, we characterized CIVILIZATION IV agents behavior with linear regressions: \"Shows that different agents\" preferences cause an observable effect on multiple game indicators; and evaluating the effects of the game outcome in indicators."}, {"heading": "1.4. ROADMAP 5", "text": "\u2022 Machado, M. C., Rocha, B. S. L., and Chaimowicz, L. Agents Behavior and Preferences Characterization in Civilization IV. In Proceedings of the X Brazilian Symposium on Computer Games and Digital Entertainment (SBGames), Salvador, Brazil, 2011. \u2022 Machado, M. C., Pappa, G. L., and Chaimowicz, L. A Binary Classification Approach for Automatic Preference Modeling of Virtual Agents in Civilization IV. In Proceedings of the 8th International Conference on Computational Intelligence and Games (CIG), Granada, Spain, 2012. \u2022 de Freitas Cunha, R., Machado, M. C., and Chaimowicz, L. RTSmate: Towards an Advice System for RTS Games. In ACM Computers in Entertainment (CiE), 2013 (in press)."}, {"heading": "1.4 Roadmap", "text": "The rest of this work is divided into seven chapters, as follows: Chapter 2: In the second chapter, we will discuss the background information required for this work. First, we will discuss the game platform used in this work and present its characteristics and programming interfaces. Second, we will present the methods of machine learning used to classify players (and virtual agents), and discuss their main differences. Chapter 3: In this chapter, we will present the most important work related to player modeling. For this reason, we will structure the chapter according to applications for player modeling, namely: game design, interactive storytelling and opponents of artificial intelligence. In presenting the related work, the enormous amount of published work in this field and the lack of organization of this work became evident. Therefore, we will also present the taxonomy that we propose for player modeling.Chapter 4: In this chapter, we propose a generic approach to player modeling as a machine learning problem and present a generic representation for gamers."}, {"heading": "6 CHAPTER 1. INTRODUCTION", "text": "Chapter 6: After introducing the approach proposed in Chapter 4, we classify the preferences of different agents using four different ML techniques. All methods use supervised learning, and these are: Naive Bayes, JRip, AdaBoost and SVM. In this chapter, we evaluate the performance of these techniques for modeling virtual agents and (human) players in the game CIVILIZATION IV. Chapter 7: Finally, in this last chapter, we present our conclusions, summarize our findings and discuss some future policies. If knowledge can create problems, we cannot solve them through ignorance. Isaac AsimovChapter 2BackgroundThis chapter presents background knowledge for the rest of this thesis. We will discuss two main topics used in this thesis: (1) the game platform, its properties and programming interfaces; and (2) the most important concepts of machine learning, the classifiers of our experiments and experiments."}, {"heading": "2.1 Civilization IV", "text": "In this work, we used CIVILIZATION IV as the playsite to conduct our experiments. Platform selection is a very important step in the exploration of digital games, as implementation is usually limited by the game interface. In addition, it is also important to ensure that the selected game has the basic characteristics required for the proposed research. We discuss all these topics in order. A more in-depth discussion of several different playsites and their possibilities is presented in [Machado et al., 2011a]. CIVILIZATION IV is a turn-based strategy game (TBS) 1, developed in 2005 by the studio Firaxis Games. In this game, each player is represented by a leader who controls an empire. Players / empires compete with each other to achieve one of the many game-winning conditions. A high-level description of this game is beautifully presented by the Teuling [2010]: \"In CIVILIZATION IV, a player begins with the selection of an appropriate leader and leader."}, {"heading": "8 CHAPTER 2. BACKGROUND", "text": "An original feature of CIVILISATION IV is that defeating the enemy is not the only way to be victorious. There are six conditions to be victorious, as mentioned in [2K Games, 2005]: (1) Time Victory, (2) Conquest Victory, (3) Domination Victory, (4) Cultural Victory, (5) Space Race and (6) Diplomatic Victory. Because of these six different conditions of victory, the relationship between the player and the opponent differs from most strategy games. For the bulk of the game, the player is at peace with his opponents. Therefore, it is possible to interact, negotiate, trade, threaten and do business with opponents. Only after a player declares war or declares war on him is a player at war. Any player can declare war at any time, unless that player is in an agreement with an opponent that explicitly prohibits a declaration of war."}, {"heading": "2.2. MACHINE LEARNING 9", "text": "The preferences are represented by attributes that define the way an agent plays, and are: (1) culture, (2) gold, (3) growth, (4) military, (5) religion, and (6) science. The assigned weights represent a \"weak\" (value 2) or \"strong\" preference (value 5), and no preference at all (value 0). Each behavior allows the agent to search for one of the six winning conditions. The focus of this thesis is to automatically identify suitable weights that represent observed behavior, both for virtual agents and for human players. 2.1.0.1 Programming interfaceTo access game data and edit the agents \"behaviors, CIVILIZATION IV offers two different options: (1) to edit game resources, such as XMLs; or (2) to edit the game source code (or apply scripts to it)."}, {"heading": "2.2 Machine Learning", "text": "Machine Learning (ML) is a common approach to preference modelling, as we want to \"learn\" a model from a range of available actors (examples) and then use this model to classify new actors. There are three main approaches to learning: supervised, semi-supervised and unsupervised learning [Alpaydin, 2010]."}, {"heading": "10 CHAPTER 2. BACKGROUND", "text": "While in supervised learning a complete set of marked data is available (we know users \"preferences beforehand), in unsupervised learning no classes are known. If we take as an example the task of preference learning, both in supervised and unsupervised learning, the data we learn from is already played matches, along with the preferences of the players. In the case of supervised learning, however, these preferences were previously described by an expert, while in unsupervised learning the algorithm learns using distance measurements between data examples. Semi-supervised learning, for its part, uses both marked and unmarked data during the training process. Here, we model the preferences of virtual agents in the game Civilization IV using various supervised learning techniques. Each applied technique uses a different paradigm. We will discuss the main features of each algorithm used in this thesis in the next sections. For a deeper explanation see [Alpaydin, 2010]."}, {"heading": "2.2.1 Support Vector Machine", "text": "Supports the classification of the Vector Machines (SVM) model as an optimization problem and is considered state-of-the-art in classification for many different domains. Each training / test instance is modeled as a vector, with each feature representing a different dimension. SVM attempts to divide the space into two different subspaces with a hyperplane, assuming that the data can be linearly separated or that there is a kernel function capable of transforming the space to achieve this goal. SVM separates the space with a hyperplane using a marginal2. This marginal2 allows noise shifts without changing the class classification because it has \"breathing space.\" Each class is located on one side of the marginals. SVM is an optimization problem that seeks an optimal separation of the hyperplane, i.e. maximizing the marginal2. This problem can be solved with the help of square optimization methods [2010, Alpaydin]."}, {"heading": "2.2. MACHINE LEARNING 11", "text": "The gamma parameter defines the influence of a support vector on its environment. A low gamma means a higher influence that leads to a small number of support vectors, while a high gamma transforms each training vector into a support vector, as each vector has a small impact on the entire space. Figure 2.2 shows the basic SVM concepts. Once we have an input space, we apply a core function \u03c6 to map the input space into a feature space where the classification is performed. Classification is then done by finding a hyperplane that maximizes the distance between the instances (blue and red spheres) and the support vectors derived from the hyperplane."}, {"heading": "2.2.2 Naive Bayes", "text": "Naive Bayes is a probabilistic classifier that assumes that all characteristics (inputs) are independent, which creates a classifier that makes its prediction to evaluate the probability of each given class. Although this assumption is unrealistic, Naive Bayes performs well in a wide range of areas, apart from being fast. It can be represented by the following equation: P (0) = d \u00b2 j = 1p (1), where \"is\" the input and \"C\" is a multinomic variable that takes a class code as defined by Alpaydin [2010]. Once the algorithm assumes a conditional independence, we can calculate the conditional distribution over class C as a product of p (1) for all j and then easily discover the probability of being a specific class when the input of the characteristics (1) is given."}, {"heading": "12 CHAPTER 2. BACKGROUND", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.2.3 JRip", "text": "JRip is a Java implementation of RIPPER [Cohen, 1995] and follows a divide-and-conquer strategy that divides the input space into different regions and finds rules for those regions. In this approach, rules are learned with IF-THEN statements, one by one, and the algorithm executes two different phases successively: (1) grow and (2) truncate. Alpaydin [2010] notes that \"we start with the case of two classes in which we speak of positive and negative examples (...) rules are added to explain positive examples in such a way that if an instance is not covered by any rule, it is classified as negative. Thus, a rule, if it matches, is either correct (true positive) or it causes a false positive. (...) Once a rule has grown, it is truncated by deleting conditions in reverse order to find the rule that\" maximizes a metric referred to as a ruleset metric, which can be understood as a set of rules calculating algorithms based on the number of probable and very interesting algorithms we have used in this algorithm. \""}, {"heading": "2.2.4 AdaBoost", "text": "This algorithm is based on the idea of combining multiple learners who complement each other to generate a classifier with higher accuracy. Alpaydin [2010] defines a boosting algorithm and presents an example as follows: \"In the face of a large training set, we arbitrarily divide it into three parts. We use \u03c71 and turn d1. We then take 2 and submit it to d1. We take all cases that have been incorrectly classified by d1, and as many cases where d1 of 2 is correct, and these together form the training set of d2. We then take 1 and submit it to d1 and d2. The cases where d1 and d2 do not coincide form the training set of d3, and as many cases where d1 of 2 is correct, we submit it to d1 and d2; if they coincide, this is the response of d3. The cases where d1 and d2 do not coincide form the training set of d3."}, {"heading": "2.2. MACHINE LEARNING 13", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.2.5 Summary", "text": "In this section, the main techniques used in this work were discussed. Their main aim was not to discuss each technique in depth, but to show that each algorithm is based on a different paradigm that expects a different attribute from the dataset. Our main concern was to highlight these differences between algorithms and to show that our choice was not arbitrary. In summary, Naive Bayes assumes that the different characteristics that represent a player are independent without being dependent on each other. Another simple approach is JRip, where each class must be distinguished by a set of simple rules. On the other hand, more complex approaches are SVM and AdaBoost. SVM assumes that different classes in space can be separated by a core function (or linear), while AdaBoost combines various weak classifiers that focus on parts of the input space to produce a classifier with higher accuracy."}, {"heading": "3.1 Related Work", "text": "Slagle and Dixon [1970] were the first to attempt to model players, but research focusing specifically on player modeling began in 1993 and initially aimed to improve search in wild trees [Carmel and Markovitch, 1993]. At the time, the computing power available in computers was much less than it is today, and due to this limitation, the authors proposed player modeling as an alternative to better pruning wild trees in CHESS. Another work from the same year, which also examined the potential of player models in tree modeling, is [Iida et al., 1993].15"}, {"heading": "16 CHAPTER 3. RELATED WORK AND PLAYER MODELING TAXONOMY", "text": "From this point on, for almost a decade, the few studies in this area were applied to classic games such as CHESS [Carmel and Markovitch, 1993], GO [Ramon et al., 2002], ROSHAMBO1 [Billings, 2000; Egnor, 2000], the Repeated Prisoner's Dilemma [Kendall, 2005], and POKER [Billings et al., 1998; Davidson et al., 2000] This scenario began to change with Houlette [2003], who discussed the applicability of the player model in more complex games such as those of the FPS genre and proposed a model to represent these players. Houlette [2003] described this representation as \"a collection of numerical attributes or features describing the playing style of a single player.\" After Houlette's work, several other researchers began to focus on non-traditional games such as FPS, RPG, and strategy games."}, {"heading": "3.1.1 Artificial Intelligent Opponents", "text": "The vast majority of research related to player modeling is on this topic, and the first work of the field that will be discussed at the beginning of this section [Carmel and Markovitch, 1993; Iida et al., 1993; Ramon et al., 2002], can also be classified here. It is also sometimes referred to as opponent modeling. A first branch of research in player modeling refers to games in which AI is generally implemented using tree search algorithms such as MiniMax. Games in this category are board and card games. Some of recent work focus on the game POKER. Billings [2006]; Aiolli and Palazzi [2008] used a set of weights for each possible player type TEXAS HOLD'EM POKER and predicted their own choice of action as a weighted match of all player types. On the other hand, Ponsen et al. [2010] is a poker player-player with Monte Carlo IT search algorithms and tree-related parts used to find a tree type of play, in addition to tree-related modeling."}, {"heading": "3.1. RELATED WORK 17", "text": "In fact, it is the case that most of them are able to survive themselves if they are not able to survive themselves."}, {"heading": "18 CHAPTER 3. RELATED WORK AND PLAYER MODELING TAXONOMY", "text": "approach can be seen as an attempt to present smart NPCs that do not violate game rules (ignore fog from War2, for example), a shared resource, as Laird and van Lent [2000] have already discussed. Two recent papers on this topic are [Weber et al., 2011; Tastan et al., 2012]. Weber et al. [2011] modeled the movement / position of players in the game STARCRAFT, using a particle-based approach, while [Tastan et al., 2012] \"inverse amplification to learn a player-specific motion model using sample tracks.\" Valkenberg [2007] also worked on this problem by trying to predict the position of players in the game WORLD OF WARCRAFT. Despite the fact that he did not have much success, the problem he worked on is an excellent example of the topics discussed. A more successful approach was presented in [Hladky and Butliko, 2008, the game for COTER COSTRIE]."}, {"heading": "3.1.2 Game Design", "text": "The basic idea of player modeling related to game design is to create environments that are most suitable for each player. This is one of the ways of customizing the game. Once you get a model of a player, it can create levels that maximize the player's entertainment. There are several ways to maximize your own entertainment, such as determining the player's game preferences to adapt the scenario to his style. For example, if the game finds that a player likes to be a sniper in FPS games, it can generate points for him to stay on. The importance of including player models in content creation has been discussed in [Togelius et al., 2011]. 2Sections of the game world where the player has no visible units create an environment with imperfect information. It is said that these invisible parts are hidden by a fog of war."}, {"heading": "3.1. RELATED WORK 19", "text": "The way in which these strategies are applied also plays an important role in the development of strategies and strategies."}, {"heading": "20 CHAPTER 3. RELATED WORK AND PLAYER MODELING TAXONOMY", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1.3 Interactive Storytelling", "text": "In addition to adapting the game scenario or difficulty, another possibility is to adapt the dramaturgical plot of a game, which is called interactive storytelling. Another short definition of interactive storytelling was given by Thue et al. [2007]: \"(...) a story-based experience in which the sequence of events unfolding while the player is playing.\" [Thue et al., 2007]. This application explicitly requires adaptive behavior because it is interactive. Despite this fact, it does not necessarily implement an adaptation to the preferences of the player, although Sharma et al. [2007] showed that player modeling is a key factor in the success of interactive game-based drama. One of the first works to use information from specific players to generate a tailor-made story is [Thue et al., 2007]. In this work, the authors suggest PaSSAGE, implemented in the game NEVER WINNERS."}, {"heading": "3.2 Player Modeling Taxonomy", "text": "As we pointed out at the beginning of this chapter, player modeling is currently a hot topic of research, with several papers published in this field. However, the field is not fully structured, as no organization is used to identify the possible different approaches to this problem. Therefore, our first contribution in this paper is the taxonomy proposal, in which we discuss research approaches and objectives in the modeling of actors. We presented this taxonomy for the first time in [Machado et al., 2011a]. In this section, we will first discuss some work related to our taxonomy, i.e. other proposals aimed at the organization of the field. We will then present our taxonomy, its classes and possible values. In order to help the reader distinguish between the individual classes, we will introduce a question before describing it that can be considered a guide to the classification of each work. Finally, Table 3.2 shows some of the most relevant work in this field classified in our taxonomy."}, {"heading": "3.2.1 Taxonomy\u2019s Related Work", "text": "A first more general paper that presented a rough division of the field was [Sharma et al., 2007]. In this paper, the authors simply divided player modeling by their (direct or indirect) measurement approach, noting that direct measurements can use, for example, biometric data, while indirect measurements use in-game data (or game metrics) derived from observation. We focus this thesis only on this second category, i.e. our taxonomy classifies works that use indirect measurements. The authors divided the field into four main categories that they named facets, namely Domain, Purpose, Scope and Source: \"The domain facet of a model answers the question of what it is that the model generates or describes the player.\" The usefulness of a model also describes the function of a model intended for application. \""}, {"heading": "22 CHAPTER 3. RELATED WORK AND PLAYER MODELING TAXONOMY", "text": "The unique concept in [Bakkes et al., 2012], which has not been discussed here before, is player profiling. Bakkes et al. [2012] defines it as an attempt to \"automatically create psychologically or sociologically verified player profiles, which provide motives or explanations for observed behavior, whether it is strategic behavior, tactical behavior, or actions.\" To illustrate this topic, we present a contrast between player modeling and player profiling, presented by van Lankveld et al. [2010]: \"Player profiling is a technique used to learn a player's inclinations through automatic observation in games.\" [Thue et al., 2007] (...) Player profiling is the automated approach to personality profiling (...) In player profiling, we are looking for correlations between the player's behavior in the game and his results in a personality test. \"[van Lankveld et al., 2010] Since player profiling is not the subject of Ylam's research, Y. In this area, we will continue to discuss it in 2009, 2009, and Yvan, 2009, and some of them in 2009."}, {"heading": "3.2.2 Proposed Taxonomy", "text": "Our taxonomy is made up of six different classes covering different aspects of player modeling research, from high-level concepts such as what needs to be modeled to implementation details. We discuss each of the six classes in the next sections, summarizing their main components and possible values in Table 3.1. Note that we present several facets of player modeling work, but some of them have already been discussed by other researchers in different scenarios. Our main contribution was to select and organize different classifications to obtain a common taxonomy."}, {"heading": "3.2.2.1 Description", "text": "What would you like to describe with your model?"}, {"heading": "3.2. PLAYER MODELING TAXONOMY 23", "text": "The modeling of the player can be defined as an abstract description of the current state of a player at a given time. This description can be made in various ways, such as satisfaction, knowledge, position and strategy [van den Herik et al., 2005].The main objective of a game is to entertain its players, who are different from each other and may not enjoy the same challenges or opportunities of the game. If their satisfaction is modeled, we may be able to adapt the gameplay to each player. This is called satisfaction modeling. In terms of the artificial intelligence of agents, we may want to model the player's knowledge, as this can be useful in several environments with imperfect information. A concrete example can be found in games with war fog, where answers to the following questions can be very useful: What part of the map does the player know? He / she knows our position? In a game with constant evolution, what degree of evolution has already been achieved? All of these questions can be answered with knowledge modeling."}, {"heading": "3.2.2.2 Time Frame", "text": "When are you going to process the data? Do you have enough time to do this online? The different descriptions in the previous section lead us to different levels or categories of using player models and different moments to process the data. The lowest level of abstraction with constant processing is online tracking, which is about predicting immediate future actions. A higher level (Online Strategy Recognition) is associated with strategy recognition, as it involves identifying a number of actions as an overarching goal or strategy. Finally, offline verification is the evaluation of a game log after its completion. This last level is what many professional players do when they \"study\" their opponents for a game. Laviers et al. [2009] discuss these three topics and argue that online tracking is used for individual players, while Online Strategy Recognition can be applied to entire teams. This is true because there is no definition for the action of a unique team. Nevertheless, it is important for us to recognize that individual strategies can be applied."}, {"heading": "24 CHAPTER 3. RELATED WORK AND PLAYER MODELING TAXONOMY", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.2.3 Goals", "text": "As mentioned above, we strongly believe that player modeling is an appropriate approach to improving the AI of NPCs in games, and this improvement is reflected in various types of objectives for NPCs, which can be divided into three main sets: (1) to work with human players, (2) to be their opponents, or (3) to be neutral to them, but to be part of the story.The first set related to collaborative agents is very difficult because human players have expectations when supported by NPCs. These expectations are related to their actions: often human players are unable to act properly because the NPCs do not behave as a unique team. Most games implement agents in coordination and collaboration through basic commands such as \"Attack,\" \"Patrol,\" and \"Hide.\" The biggest challenge is getting these agents to act autonomously according to the behavior of the players, without the need for specific orders."}, {"heading": "3.2.2.4 Applications", "text": "What game activities will you improve with your model?"}, {"heading": "3.2. PLAYER MODELING TAXONOMY 25", "text": "At a lower level of abstraction, as van den Herik et al. [2005] discusses, we can list four main applications for player modeling: speculation in heuristic search, tutorials and training, non-player characters and multiperson games. We have renamed and redistributed them in terms of meaning and generality. We have renamed speculation in heuristic search into speculation in search and split tutorials into two different applications. Finally, we group non-player characters and multiperson games as substitution applications. We have added a fifth application, which is game design. Several other applications can be listed, but we believe that these five cover a satisfactory range of topics.Search speculation is generally applied to games where artificial intelligence is more related to searching in game trees, generally for opposing goals. Depending on game complexity, it may be impracticable to verify any possibility and even pruning techniques such as PCs is insufficient."}, {"heading": "3.2.2.5 Methods", "text": "We can also divide the field of player modeling into more specific methods, which are closely related to its description purpose. Spronck and Den Teuling [2010] mentioned that most research in the field of player modeling is done with action models, i.e. an attempt to model the activities of players in such a way that the action of the next player can be predicted (online tracking). Works that use a series of actions (without predicting the next action)."}, {"heading": "26 CHAPTER 3. RELATED WORK AND PLAYER MODELING TAXONOMY", "text": "Spronck and Den Teuling [2010] define preference modeling as modelling the \"player wants to achieve or experience something in the game, and to what extent he is able to do so.\" This is a very precise definition and in fact affects the satisfaction of the player. The latter two methods are positioning and knowledge modeling, the first trying to get relevant information about the location of the player, while the second trying to model the knowledge of the player himself, that is, what he already knows. Position modeling can be better defined than trying to predict NPC's positions in games with imperfect information (e.g., war fog). This is valuable information because knowledge of a player's position in general provides a tactical advantage in a game, as discussed here. This approach can be seen as an attempt to present intelligent NPCs that do not violate game rules (e.g. ignore the fog of war), not to differentiate a commonly used resource such as LV 2000 and LV 2000, whereby it is possible to differentiate between LV 2000 and LV 2000."}, {"heading": "3.2.2.6 Implementation", "text": "What is the interface between your algorithms and the game in which your model is to be used? After we have defined some of the subsets of player modeling that relate to goals, applications, research areas, etc., we can conclude this section with the lower abstraction level of discussion: the implementation. Two approaches can be highlighted: explicit and implicit. Spronck [2005] says: \"An opponent [player] model is explicit in the game AI if a specification of the attributes of the opponent [player] exists independent of the decision-making process.\" Therefore, an explicit player model is separated from the main source code and it is generally implicitly implemented by scripts or XML files. On the other hand, the attributes in implicit approaches are generally embedded and diluted into different parts of the code, making the task of identifying and describing these attributes more difficult. 3.2 P A Y E M YO L E E 27O There is no way to construct two flaws in software that make it simple."}, {"heading": "A Generic Approach for Player", "text": "Modeling as an ML Problem This chapter discusses how to approach player modeling as a Machine Learning (ML) problem, presenting a general methodology for its application. In this first step, it defines how different actors can be represented. Therefore, this chapter also advocates a generic representation of players proposed by Houlette [2003], which the author introduced almost as a theoretical model while this chapter discusses its applicability. The next chapter, which focuses on the instantiation of the methodology proposed here, evaluates the feasibility of the discussed representation, which was first presented in [Machado et al., 2012a], while most of the discussions on generic player representation take place in [Machado et al., 2012b]."}, {"heading": "4.1 A Methodology for Preference Modeling as a", "text": "This section proposes a methodology for modeling players according to an ML approach. Different aspects of the player can be modeled, such as actions, preferences and positions. The methodology consists of six phases: \u2022 Defining a representation for the player; \u2022 Defining relevant characteristics according to the game; 29"}, {"heading": "30 CHAPTER 4. A GENERIC APPROACH FOR PLAYER MODELING AS AN ML PROBLEM", "text": "\u2022 Choose which relevant examples to use; \u2022 Model the problem of player modeling as an ML task that can be supervised (as in this work) or unsupervised; \u2022 Choose the appropriate algorithms; and \u2022 Find the best parameter configurations for the selected algorithms. All these topics are discussed here in general, as this approach can be applied to any game to define player models."}, {"heading": "4.1.1 Representation Definition", "text": "As already mentioned, a first general concern in the context of player modeling is the representation of different players. It is important to be able to represent different aspects of a player in the game, for example, in order to obtain models for players with different preferences or knowledge, which the AI of the game will be able to access to generate different behaviors, scenarios or diagrams. This step is crucial in defining an ML approach to player modeling, as the selected algorithm must be able to generate the model of the player, for example, if one decides to depict a player as a tree, he may have difficulty using a neural network to generate it. Therefore, this task is required regardless of the approach, with ML or Not.Section 4.2 representing a generic representation that can be used to model a player / agent."}, {"heading": "4.1.2 Features and Examples Definition", "text": "For example, for the problem of preference modeling, these indicators should be able to represent different behaviors of players with different preferences, based on the assumption that different behaviors are generated by different preferences. Once the game platform is defined, a study of the selected data can be useful to ensure that the assumptions regarding data relevance are correct. We performed all these steps in Chapter 5 when we applied this methodology to the game CIVILIZATION IV. Despite their dependence on the game used as a test field, some general approaches may be common in games of the same genre. Thus, strategy games generally present multiple game indicators during a game. These indicators are related to resources, military and technological features of the game, and they are strong candidate features for an ML technique."}, {"heading": "4.1. A METHODOLOGY FOR PREFERENCE MODELING AS A MACHINE LEARNING", "text": "PROBLEM 31 In a first-person shooter (FPS) game, indicators derived from observations of player behavior, such as lifespan, selected weapons and locations, number of deaths, among other things, can define a player's preference. In the case of action adventure games, such as the TOMB RAIDER series, player preferences can be defined by other indicators, including causes of death, total number of deaths, completion time, and demand for help. In fact, all of these indicators were used by Dragons et al. [2009] to model players in the game TOMB RAIDER: UNDERWORLD.Although a feature definition is essential for each game genre, it is important to emphasize that data availability may vary for researchers depending on game types, mainly because different game developers have different approaches to data extraction. While some scripts and even source code modifications allow for game play, others are extremely hesitant to allow interaction with any game."}, {"heading": "4.1.3 Problem Modeling and Appropriate Algorithms", "text": "Once we define relevant characteristics and examples of a player's modeling, we must decide how to represent different players. This representation depends on two different aspects: If we are able to identify the models of the players in advance and which algorithm we select for the task. All three ML approaches discussed in Chapter 2 (supervised, semi-supervised and unsupervised) can be applied to the modeling of the players. If the information of the players is not previously known, unsupervised learning may fit better. In this case, the players are clustered using similar attributes using a distance metric, and the researchers are expected to identify each group based on their characteristics. An example of this approach can be found in [Dragons et al., 2009]. On the other hand, if the models of the players are previously known, we can classify new players using these attributes. This is the approach presented in this thesis, which identifies the preferences of the virtual agents of CIVIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII"}, {"heading": "32 CHAPTER 4. A GENERIC APPROACH FOR PLAYER MODELING AS AN ML PROBLEM", "text": "One approach is to predict different preference levels. For example, one can assume that the player does not have preferences, weak preferences or strong preferences for a particular topic. This is the approach taken in [the Teuling, 2010; Spronck and the Teuling, 2010], which is called a multi-class problem, which takes into account three classes. We believe that the main problem with this approach is that human players have difficulty defining their preferences in terms of levels, it is much easier to simply say whether they have a preference or not. Furthermore, it can be more complicated to obtain data sets detailing different levels than to know whether a player has a preference or not. Given these drawbacks, an alternative approach used in this work is to model the problem using a binary classification strategy, in which we want to find out whether the player simply has or does not have a preference for a particular feature."}, {"heading": "4.1.4 Parameters Configuration", "text": "ML algorithms are very sensitive to parameters. Therefore, it is very important for researchers to spend some time tuning the parameters of the algorithm. If the researcher does not know the most important parameters to be studied, it may be useful to apply a technique that can help him select these parameters. A common approach is 2k factorial design, which is \"used to determine the effect of k factors, each of which has two alternatives or levels.\" [Jain, 1991] An important point when it comes to parameter tuning is computing time. The higher the number of examples used for training, the worse the computing time. A simple solution to this problem is to select the dataset while maintaining its original features, such as class distribution."}, {"heading": "4.2. A GENERIC\u2019S PLAYER REPRESENTATION 33", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2 A Generic\u2019s Player Representation", "text": "Just as a generic method of player modeling is a valuable discussion, a generic representation capable of modeling various aspects of a player is a useful resource. We are advocating here for a representation proposed by Houlette [2003], which has not presented any real implementation or evaluation of its feasibility. Therefore, our main contribution here is to present a discussion of its theoretical applicability and in the industry based on several industry requirements listed by Isla [2005]. Besides [Houlette, 2003], one of the few papers that discusses a general methodology for obtaining models in different environments is [Charles and Black, 2004]. Nevertheless, it does not confirm their assumptions in a real game. A sequence of this work is presented in [Charles et al., 2005] in which the authors also discuss a high-level framework for adaptive game AI. They briefly present an approach to modeling players with fractional, but do not investigate further."}, {"heading": "4.2.1 Houlette\u2019s Representation", "text": "The representation discussed here to model players is based on two main components: a set of variables representing specific features of the game, and a set of weights multiplying these variables, set by the game designer and AI programmer, and based on the expertise of each game, an inescapable prerequisite for adaptive AI such as Spronck [2005] and Bakkes et al. [2009]. The weights represent the importance attached to the feature represented by this variable, which can be set manually by the designer / programmer or learned from experience. It is possible to obtain completely different behaviors by varying the weights of each player, allowing players to adapt to different game conditions. Formally, the model is presented as a set of non-weights in which n is the number of features to be modelled: Pm = < w0, w1,..., wi > where a weight for the characteristic of the game model is very different from the one that can be applied to the other."}, {"heading": "34 CHAPTER 4. A GENERIC APPROACH FOR PLAYER MODELING AS AN ML PROBLEM", "text": "The main advantage of this approach is that once techniques are created to derive weights, they can be applied to different games that use this approach. As an example, we can use POKER to illustrate our discussion. POKER is a very hard game for computers that are unable to defeat the best human players. A promising approach is player modeling, and there is much work in this area, such as [Billings et al., 1998; Davidson et al., 2000; Southey et al., 2005; Bard and Bowling, 2007]."}, {"heading": "4.2. A GENERIC\u2019S PLAYER REPRESENTATION 35", "text": "Generating these weights (or other types of modeling) from repetitive games, observing players and other virtual agents, and tracking game outcomes often involves the use of machine learning techniques, and the most commonly used are those inspired in nature as neural networks or genetic algorithms. After discussing this applicability of representation, our focus is on introducing the generic methodology proposed here to model the preferences of players in the game CIVILIZATION IV. We will use this representation and then focus on this thesis of determining the weights so that they represent both virtual agents and the preferences of human players."}, {"heading": "4.2.2 Applicability", "text": "A useful model must be able to satisfactorily represent different actors with different characteristics, including the ability to permit any behavior that is derived only from the model, which could be considered a coverage requirement. As we have already discussed, once suitable characteristics have been selected, this is fully feasible. Furthermore, it is desirable that it be applicable in the industry, which would confirm its validity. We will discuss both issues below."}, {"heading": "4.2.2.1 Representativeness", "text": "With regard to the representativeness of a model, we believe that it would be effective if it were able to perform two different tasks: 1. The generation of different behaviors by variation of the model. In this approach, different weights generate different behaviors; and 2. A model that generates a certain behavior must be \"derivable,\" that is, one must be able to derive a model that generates an observed behavior, which task is to derive variable weights from the observation. The above requirements create a cycle: Once we observe a certain behavior, we must be able to derive the model that generated it, and we must be able to generate different behaviors from the model.This evaluation must be performed in the specific game that is used to model players."}, {"heading": "36 CHAPTER 4. A GENERIC APPROACH FOR PLAYER MODELING AS AN ML PROBLEM", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.2.2 Applicability in Commercial Games", "text": "An important topic to be discussed before presenting the instantiation of the discussed methodology and representation is the applicability of representation in commercial games. In general, the game industry is somewhat reticent about the AI solutions proposed by the Academy. As by Fairclough et al. [2001]; Laird and Lent [2001]; Bakkes et al. [2009], there are several reasons for this: the concern about unpredictable behavior, the need for severe modifications and specifications for each game, and the difficulty of understanding the reasons for some observed behaviors and modifying any configuration. We argue that due to their simplicity and expressivity, representation avoids most of these problems."}, {"heading": "4.2. A GENERIC\u2019S PLAYER REPRESENTATION 37", "text": "This is precisely the main advantage of this representation, as it can be seen as a set of parameters that allow a clear definition of behavior. The second design principle is \"value above all else.\" This is Isla's fourth principle: \"Let's take something that works and what doesn't.\" The third principle is that it doesn't apply to representation, but to other levels."}, {"heading": "5.1 Dataset", "text": "Chapter 2 introduced the game CIVILIZATION IV, its mechanics and programming interface, and discussed the script AIAutoPlay, which allows us to log games between two virtual agents. Based on these topics, we are able to sniff out the game and collect data while virtual agents (or human players) are playing. Using this feature, Den Teuling [2010] was able to generate a data set to classify the preferences of the players (we will discuss this classification approach further in Chapter 39)."}, {"heading": "40 CHAPTER 5. PLAYER MODELING IN CIVILIZATION IV", "text": "The first two were created by the Teuling [2010] and edited here for our purpose; the third is described in Chapter 6.The first decision that needs to be made to sniff out the game aspect is when to collect data. In the case of CIVILIZATION IV, the game structure facilitates this decision because its turn-based pace clearly defines the time of data collection at the end of each hand.As we said earlier, the Teuling [2010] used the AiAutoPlay script to capture the game dataset; this script allows the game to be played by two virtual agents, since its turn-based pace clearly defines the time of data collection at the end of each hand.This is an important feature because it allows the dataset to have hundreds of matches, which would be impossible if human players had to play these matches.This script allows the game to be played by two virtual agents, eliminating the requirement of human players."}, {"heading": "5.2. FEATURES DEFINITION 41", "text": "In Section 5.2, we show that some indicators are able to distinguish different behaviors, which supports our decision. In fact, these characteristics were used in all three datasets mentioned. the Teuling [2010] modeled each round as a vector (example), and since evolution along the match is an important factor, they expanded the set of basic characteristics to add this term of time. the authors call these new characteristics, presented in Table 5.2, compound characteristics. A second dataset, also related to virtual agents, was created to evaluate the generalization. We call it an alternative dataset. It was created using a different set of six agents and we will discuss its use in Chapter 6, where it is used.Each other virtual agent has a specific set of preferences defined by different values representing levels (0 - no preference; 2 - medium preference; 5 - high preferences)."}, {"heading": "5.2 Features Definition", "text": "A first important step in discussing the available data is a better understanding of the behavior of virtual agents and their expression in game data. To accomplish this task, we model the game CIVILIZATION IV as a series of states, with each state defined by the data collected at the end of each turn. These data consist of several game information, such as the amount of gold in a civilization or the number of cities. In addition, each virtual agent in the game can have different characteristics."}, {"heading": "42 CHAPTER 5. PLAYER MODELING IN CIVILIZATION IV", "text": "In order to evaluate the usefulness of the available gameplay data and thus to define our characteristics, some questions need to be answered: \u2022 The information on the intermediate states of the game characterizes different preferences of different agents? \u2022 What information available distinguishes the preferences of agents? What is the relationship between their predefined attributes and this information? In this section, we answer these questions by characterizing the behavior of AI-controlled agents in search of relationships between the predefined preferences and their behavior. The discussions presented here derive from the results in [Machado et al., 2011b]."}, {"heading": "5.2.1 Methodology", "text": "Our goal is to characterize the behavior of the different agents based on their game data and to correlate them with their preferences by generating linear regressions based on game state indicators collected in multiple games between different AI agents. Our intuition was that we would be able to find different functions that describe game data for different agents because they have different preferences, which would justify the selection of these data as a feature. To perform this evaluation, we used a subset of the traditional data set discussed in Section 5.1. We examined three agent preferences: culture, gold and growth. Characterization was performed by observing games between two different agents and analyzing the data generated by these observations. We carefully selected these agents so that one of them has no interest in a particular preference and the other has a high interest in that preference (values 0 and 5 in the game)."}, {"heading": "5.2. FEATURES DEFINITION 43", "text": "We start with the premise that the opposing agent's actions do not affect the condition of the player we are analyzing, and we characterize several of his behaviors and preferences. After this first phase, we relax in this premise and observe that it is correct, as we show in Section 5.2.2.4. This result gives us confidence to adopt this independence in applying our ML approach. We have used the leaders in the example above to analyze the gold preference (Louis XIV and Mansa Musa). To analyze the growth and cultural preferences, we have used the agents Alexander and Hatshepsut. The growth preference has a peculiarity: in our dataset there was no agent with a high interest in this preference (value 5), only an average interest (value 2)."}, {"heading": "5.2.2 Agents Characterization", "text": "This year it is more than ever before."}, {"heading": "5.2. FEATURES DEFINITION 51", "text": "that a number of features that contain gameplay data can be used to differentiate the preferences of players using ML algorithms."}, {"heading": "5.2.2.4 Victory and Defeat", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "5.2. FEATURES DEFINITION 53", "text": "In fact, the fact is that most of them are able to assert themselves, that they are able to assert themselves, that they are able to achieve their goals."}, {"heading": "5.3 Players Representation", "text": "As for the generic representation proposed in the previous chapter, in this section we refer you to the game CIVILIZATION IV. As already discussed, a good model must be able to generate different behaviors by varying the representation of a virtual agent, as well as being \"derivable,\" i.e. by observing the behavior one must be able to represent it. We discuss these two topics one after the other. To assess whether it is possible to conclude on models of agents, we conduct an experiment in which we manually derive some of the weights that virtual agents could model by comparing these weights with those in their predefined models, showing how different behaviors can be explained and expressed by different models."}, {"heading": "5.3. PLAYERS REPRESENTATION 55", "text": "Machado et al. [2012b] discuss this topic using the game COUNTER STRIKE. We show how small changes in the model can generate different behaviors in the game. At this point we have decided not to discuss this topic further in order to focus on the game CIVILISATION IV."}, {"heading": "5.3.1 Civilization IV: from behaviors to models", "text": "In fact, most of them will be able to move around without having to do so."}, {"heading": "5.4. OVERVIEW 57", "text": "After this characterization we can clearly see that Alexander indicators are below those of Hatshepsut. Then we can conclude that CuA < CuH. Simply put, that we have only two different values, 0 and 5, we can say that PmA = < 0,... > and PmH = < 5,... >, which corresponds to the original model of the agent. Our goal here was to show that it is possible to generate models in the discussed representation from data collected during the game."}, {"heading": "5.4 Overview", "text": "In this chapter, we have instantiated the first three steps of the generic approach proposed to model the problem of predicting preferences. We have first distinguished the preferences of virtual agents based on gameplay data, which show that these different behaviors can be observed over time and derived manually for some preferences, which has helped us define the characteristics to be used by the ML algorithm we have defined (the gameplay indicators); we have also come to the conclusion that the effects of the division between won and lost games are not as useful, which helps us to understand the relevant examples as defined in Chapter 4; then we have presented an evaluation in terms of generic representation that shows their feasibility in the game CIVILIZATION IV; the next chapter discusses the use of ML to automatically define the preferences of players; and first discusses the final steps of the instantiation of the approach, the best parameter discussed in the previous chapter, the ML algorithm: the task of choosing the best one."}, {"heading": "6.1 Experimental Methodology", "text": "Before presenting our experimental methodology, we will define how to address the preference modeling problem, the fourth step of the methodology proposed in Chapter 4. We have decided to model it as a supervised learning task once we know the preferences of each artificial player. Furthermore, it is easy to ask human players to classify themselves. In this approach, the algorithm learns a model by finding relationships between a set of characteristics that describe the examples (matches) and a class (preferences)."}, {"heading": "60 CHAPTER 6. EXPERIMENTAL RESULTS", "text": "This decision was based on the assumption in Section 4.1.3, where we claim that human players have difficulty mapping their preferences at various levels. Furthermore, as we show in Table 6.1, some preferences do not have more than two values in the original data set. This approach represents one of the biggest differences between our work and that of [the Teuling, 2010; Spronck and the Teuling, 2010], which deals with modeling players as a multi-class problem. As experimental results show, our approach achieves better accuracy. In terms of the classification algorithms listed in Chapter 4, our first idea was to use the SVM to directly compare our results with those reported in [the Teuling, 2010; Spronck and the Teuling, 2010]."}, {"heading": "6.1.1 K-Fold Cross Validation", "text": "Cross-validation is a method traditionally used in ML literature to provide statistical certainty to experiments. It divides the data set into k different folds (in our case k = 10), with one fold being separated for the test and the other k \u2212 1 being used during the training process. This approach generates k different training and test sets, each set being different from the other nine. The reported end results correspond to the average error over the k-folds to ensure that the results were not found randomly according to the characteristics of the learning data. If this process is layered, the folds preserve the class distribution."}, {"heading": "6.1. EXPERIMENTAL METHODOLOGY 61", "text": "of the original record."}, {"heading": "6.1.2 Parameters Optimization and Data Sampling", "text": "After using the SVM algorithm as one of the classifiers, we proceeded to the parameter setting, the last step of the approach proposed in Chapter 4. We searched for the best possible parameters only for SVM, because it is known to be extremely sensitive to parameter variations. In practice, we optimized two different parameters: cost (c) and gamma (g). Their meanings were already presented in Chapter 2. Algorithm 1 presents the grid search, which was performed with simple and its maximum and minimal values values (defined in the tool). This algorithm is applied to each fold of the cross validation. We search for best _ c and best _ g. The step values used are also those defined in the tool easy.Algorithm 1 to ensure the accuracy of the best grid search: c and c)."}, {"heading": "62 CHAPTER 6. EXPERIMENTAL RESULTS", "text": "Since our dataset contained data from complete matches and their development, we took a close look at the data taking into account not their vectors but their matches. In other words, we added or removed complete vector sets, with each set representing a whole match. It is important to stress that we only sampled the training set, not the test set. In other words, we first created a set containing 1 / 10 of the data set (due to 10x cross validation), which is the test set. After this step, we will try the remaining matches to create the training set. We originally had 240 matches and stitched 25% of their original size, obtaining a test set of 24 matches and a training set of 54 matches. All reported results were obtained through the best parameter configuration, which was selected by simply using the sampling process described above. Note that the test process being performed with the learning algorithms is different from those used for the sampling process and the models."}, {"heading": "6.1. EXPERIMENTAL METHODOLOGY 63", "text": "Algorithm 2 Sample Dataset Input: Sample Perc {0 \u2264 perc \u2264 1} Array matches with all matches {Each match contains all its moves} Output: Array sampledMatches with sampledMatches \u2190 \u2205 Matches WithPref \u2190 \u2205 Matches WithoutPref \u2190 \u2205 Matches for i = 0 to matches.size do {Check if the agent of this match prefers} if matches [i]. preference = true then matchesWithPref.add (Matches [i]) else matchesWithoutPref.add (Matches [i]) end if shuffle (matchesWithPref) shuffle (matchesWithPref) for i = 0 to matchesWithPref.size \u00d7 perc do sampledMatches.size \u00d7 perc do sampledMatches.size (matchesWithPref [i]) end for i = 0 to matchesWithPref.size"}, {"heading": "64 CHAPTER 6. EXPERIMENTAL RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.2 Classification of Virtual Agents Preferences", "text": "The experimental phase with artificial agents (non-human actors) was divided into two steps: As already mentioned, we first predicted the virtual agent preferences from the traditional dataset using a standardized 10-fold cross-validation procedure; then, in a second experiment, we used the entire traditional dataset to create a model that classified the agents in the alternative dataset; and in the first experiment, we used 130 characteristics, including two at the end of each match, called match result and peace, to evaluate the generalization capabilities of the models in predicting the preferences of unknown agents, since generalization is the most important feature for the model to be used in real situations in games; and in the first experiment, we retrained our dataset to remove them; this allowed us to perform offline verification (as discussed in Chapter 3); since we do not have these two characteristics in the alternative dataset, with unknown agents, we retrained our dataset to remove them; and in our second experiment, to use 128 tracing characteristics."}, {"heading": "6.2.1 Off-line Review of Known Agents", "text": "We compare the four methods of binary classification (Binary-Class SVM, Naive Bayes, AdaBoost and JRip) with the majority class and the results reported by Spronck and the Teuling [2010], which we called Multi-Class SMO. As we discussed earlier, this work can be considered our starting point as the authors tackled the same problem of preference modeling in the game CIVILIZATION IV. Experimental results are shown in Table 6.3.The majority class corresponds to the percentage of the most common class in the dataset. For culture preference, for example, 67.0% of the revolutions were played by agents with no preference for culture, meaning that if the classifier had learned nothing and classified each revolution as \"without preference,\" he would receive the reported accuracy, the Multi-Class SMO column presents the results reported in [the Teuling, 2010; Spronck and Teuling, 2010]."}, {"heading": "6.2. CLASSIFICATION OF VIRTUAL AGENTS PREFERENCES 65", "text": "As stated in Table 6.4, we use the majority class as a starting point, just to represent the improvement of our approach. We understand that it is not an ideal baseline, and we only use it to judge whether the applied algorithms are \"something.\" Firstly, to achieve good performance compared to AdaBoost and JRip, we can see that the unique algorithm is better than a possible majority approach for all preferences. Secondly, to achieve good performance in comparison, and thirdly, to require more time to be trained with good parameters."}, {"heading": "6.2. CLASSIFICATION OF VIRTUAL AGENTS PREFERENCES 67", "text": "To conclude this first discussion, it is interesting to highlight some observed behaviors. A first conclusion that can be drawn is that SVM does not seem to be the best approach to preference modeling, despite the preference given to it by researchers in this field, such as [Spronck and den Teuling, 2010; Machado et al., 2012a]. Regarding Naive Bayes, we could find that it is as good as SVM in three preferences, although it runs immediately, while SVM takes days to classify agents. Furthermore, Naive Bayes presented the lowest variation between classifications (no RMSE higher than 4.0), suggesting that it could be a more stable method for this problem. JRip may be an interesting approach, because it not only presents the best overall performance, with all the accuracies higher than 65%, but it also gives us rules that allow game designers to understand and \"debug\" a certain classification."}, {"heading": "6.2.2 Online Tracking of Unknown Agents", "text": "To complete our virtual agent experiments, we examined how general the learned models are. In this case, we used all instances of the first data set as a training set and the alternative data set as a test set, consisting of agents that were not used to generate the matches in the training set. Let's remember the class distribution of all preferences in Table 6.1. As explained above, we did not use it in this second experiment due to the low SVM performance and high computing costs; the results are shown in Table 6.5 and the improvement over the baseline in Table 6.6."}, {"heading": "68 CHAPTER 6. EXPERIMENTAL RESULTS", "text": "A first interesting finding is that the algorithms used, using the binary classification approach, exceed Teuling [2010] s (SVM) in accuracy, confirming our assumption that SVM, although considered state-of-the-art for several classification problems, may not be sufficient to model player preferences. AdaBoost and JRip performances were remarkable, especially when compared to our baseline. For most of the preferences, these methods were able to achieve accuracies above 60%, such as 68.1% (AdaBoost) and 62.5% (JRip) against 38.6% of the accuracy achieved by the baseline in predicting the gold preference; and 66.6% (AdaBoost) and 59.3% (JRip) against 34.6% of the base preferences (AdaBoost) and 62.5% (JRip) against the prediction of military preferences."}, {"heading": "6.3. PLAYER MODELING 69", "text": "\u2022 Religion: CumulativeDeclaredWar = 0 \u0445 CumulativeWar = 35 \u0445 War = 0 \u2192 Religious Preference (570 / 0); \u2022 Science: CitiesDiff = 3 \u0445 CumulativeWar = 77 \u0445 Cities = 8 \u2192 Science Preference (182 / 0); These rules already give us insight into the behavior and preferences of virtual agents, such as the meaning of wars and the number of cities to define a player preference. In fact, we can observe even very solid rules, such as a lower number of declarations of war for virtual agents with preferences for culture and religion. The rule listed, which recognizes no military preferences, is also very intuitive and confirms our discussion of JRip benefits. Naive Bayes presented the worst performance among the evaluated algorithms, although it is better than the baseline in four different preferences. This poor performance can be explained by Naive Baye's assumption of independence between characteristics."}, {"heading": "6.3 Player Modeling", "text": "After presenting an approach to classifying the preferences of virtual agents that could surpass previous approaches in literature, it is important to test our method with \"real\" data. In this last section, we will discuss how we have collected data from human players and how the aforementioned algorithms work when applied to this data."}, {"heading": "6.3.1 Players\u2019 Data", "text": "In order to evaluate our approach to data generated by human players, we recruited volunteers for the game CIVILIZATION IV. They had to insert a script into the game directory to sniff out their results along a game. This script is called AIAutoPlay and was modified and used by the Teuling [2010] to generate the data sets with virtual agents. We also used it in this work, as discussed earlier. Its installation consists only of replacing some dlls from the original game. It is important to stress that we ended up with the same 128 features used in the online tracking experiment."}, {"heading": "70 CHAPTER 6. EXPERIMENTAL RESULTS", "text": "We did not impose any limitations on players in terms of experience or other characteristics, we required them to play a 1x1 game and log the game. Before the game, they signed a consent form and completed a questionnaire about their experience with TBS games and, more specifically, games from the CIVILIZATION series. After completing this questionnaire, they played the game and sent us their data. We assess this number satisfactorily on the basis of the hard-to-obtain players. A Civilization IV game can last longer than four hours and few people accepted to take part in such a test. For example, for usability tests, it is said that three to five users are sufficient to conduct an experiment."}, {"heading": "6.3.2 Classification of Players\u2019 Preference", "text": "In order to classify human players based on supervised learning, a large dataset of marked samples is required, which is not possible in practice, since no player can provide so much data."}, {"heading": "6.3. PLAYER MODELING 71", "text": "This is one of the reasons for conducting the online tracking experiment in the last section to assess the feasibility of this approach. We use the same training set used in the online tracking experiment, which contains all the matches of the traditional data set, to train the models that classify the players \"games. In fact, we have used the already generated ones. The results of the classification are set out in Table 6.8. We have decided not to publish the Teuling results [2010] regarding the classification of human players because they have conducted experiments with only two players using a different modeling and algorithm."}, {"heading": "72 CHAPTER 6. EXPERIMENTAL RESULTS", "text": "If we look at the results of all seven players, we find that among all classifiers, at least one of them has achieved an accuracy of over 50% for each preference. Naive Bayes has achieved accuracies of over 50% for growth (62.7%), military (61.7%) and science (89.7%), while AdaBoost and JRip have obtained accuracies of over 50% for culture (91.5%, 94.5%), gold (74.5%, 74.5%) and religion (60.7%, 54.5%). Naive seems to have generated rules that classify the most turns in the most common class for culture preference, and in the rarest class for growth and science preferences. As we have already discussed, the growth preference has a peculiarity that we have removed its most discriminatory twists: the first 100. This may have impaired the learning algorithm if it has decided the growth preferences in dealing with all other outcomes consistently. Despite presenting a poor performance for some classifiers, some of the other classifiers are not derived from human ones."}, {"heading": "6.3. PLAYER MODELING 73", "text": "Interestingly, Naive Bayes was successful in three different preferences (growth, military, and science), while AdaBoost and JRip were more than 50% accurate in the other three (culture, gold, and religion). Further studies need to be done to ensure that a particular classifier is better and always achieves better results for a particular preference. If this is not true, a hybrid approach that takes into account different classifiers for different preferences can lead to higher overall accuracy, but the first thing to judge is whether these results are due to players misreporting their preferences."}, {"heading": "6.3.2.1 Evaluating Players\u2019 Preference Considering their Expertise", "text": "The post-test religion questionnaire asked users to list their preferences in the game they were playing and their confidence in the list provided. Based on the pretest questionnaire and the question of player confidence, we grouped players into two different groups: \u2022 Experienced: Three players belong to this group, those who had already played a game in the CIVILIZATION series \"a lot\" and who reported having a high level of confidence in their self-identification. \u2022 Beginners: This group includes 4 players, those who, at best, have played a game in the CIVILIZATION series only a few times. This experiment was designed to evaluate whether the results were affected by inexperienced players who did not call themselves \"correct,\" i.e., experienced players with a great knowledge of the game would do so. In other words, we evaluate the assumption that the generated model correctly identifies the preferences, but human players do not have a common understanding of these preferences."}, {"heading": "74 CHAPTER 6. EXPERIMENTAL RESULTS", "text": "Unlike the Teuling [2010], we did not achieve higher accuracy in experienced players. JRip, for example, had improved half of its results in the group of experienced players (Gold, Growth and Religion) and reduced the other half (Culture, Military and Science). Looking at NaiveBayes \"results, we found that it resulted in higher accuracy variations; the algorithm achieved an accuracy of 53.7% in the classification of beginners\" gold preference, while it only achieved 8.5% accuracy in experienced players; there was a similar variation in religion (39.3% versus 3.8%) and military (39.3% versus 96.2%); based on these results, we can conclude that in this experiment, the separation between the player's experience or trust in his self-proclaimed preferences did not consistently improve players \"preferences."}, {"heading": "6.4. OVERVIEW ABOUT MODELING PLAYERS USING ML 75", "text": "presents the obtained accuracy in the classification of each player and their level of experience (classified by us based on their answers in the questionnaires).We see that there are experienced players who are not correctly classified, while there are beginners who are. Therefore, further investigations are necessary."}, {"heading": "6.4 Overview about Modeling Players using ML", "text": "After conducting experiments that classify virtual agents and human players, we are able to conduct a higher-level discussion about the machine learning approach that is applied to the problem of player modeling. As an overview, we have been able to create models of virtual agents that are generic enough to classify other virtual agents with satisfactory accuracy. However, the same generated models have not always been effective in classifying human players, which can be justified by behaviors of virtual agents that are not universally applicable to human players. Despite our efforts to confirm our assumption that matches between virtual agents are capable of generating useful examples of the classifier, we must consider the possibility that the data generated may not be sufficient to determine the classifier and revise it."}, {"heading": "76 CHAPTER 6. EXPERIMENTAL RESULTS", "text": "This problem is a complex one that needs further investigation. Unsurprisingly, we were able to show that, it seems, the algorithm that was considered state of the art for several classification tasks, and more specifically, this problem [Spronck and the Teuling, 2010], was exceeded by those we used in our methodology (...) \"In relation to variance, the biggest problem in machine learning is the curse of dimensionality (...) Generalization becomes exponentially more difficult as the dimensionality (number of features) of examples grows (...).\" This could be the second problem with the ML approaches. In this thesis, we have shown that a subset of our features was useful to be used by a classifier. However, we added many more features by intuition. This is a common error in the player's papers that could lead to worse results."}, {"heading": "7.1 Contributions and Discussion", "text": "In this paper, we have presented an in-depth discussion on player modeling. Among our most important contributions and related publications are: \u2022 Organizing a taxonomy to organize the field [Machado et al., 2011a]; \u2022 Proposing a generic approach to addressing player modeling as a machine learning problem [Machado et al., 2012a]; \u2022 Assessing a generic representation that can be used to model players in different games [Machado et al., 2012b]; \u2022 Proposing an approach based on linear regressions to evaluate the ability of traits to distinguish between different classes [Machado et al., 2011b]; and 77"}, {"heading": "78 CHAPTER 7. CONCLUSION", "text": "The evaluation of the various classifications, in terms of their accuracy and generalisation, has been undertaken by us in terms of the effectiveness of the proposed approach, and by comparing all the evaluated classifications we can conclude that there are two main decisions that can be made for future development: one can choose naivety as a simple and quicker approach to the problem, but this can lead to poorer performance."}, {"heading": "7.2. FUTURE WORK 79", "text": "We are aware that a player can change his preference over the course of a match, but we believe that the reported results rather suggest that the number of moves should be taken as evidence. We have tried to do this by adding temporal features such as derivatives, but it is not clear whether they are sufficient. Finally, despite conducting assessments of the representativeness of some features, we assumed that all the other features available would also be representative, and used them all in our classifiers. This contradicts what Domingos [2012] says that \"one might think that collecting additional features would never do any harm as, at worst, they would not provide new information about the class. But, in fact, their benefits may be outweighed by the curse of dimensionality.\" Therefore, a different approach should be evaluated in the future."}, {"heading": "7.2 Future Work", "text": "With regard to the proposed taxonomy, a more quantitative work can be developed to analyze the current status of the field, classify more work with the proposed taxonomy and search for trends. Furthermore, a complete new analysis can be conducted with regard to learning algorithms, answering questions such as \"What can we learn in games?.\" For example, we could correlate the main learning techniques with the main problems of the field. This topic was proposed by Houlette [2003], suggesting the generation of weights that represent very low measures, such as the throwing of grenades or the use of guns, and a hierarchical organization that extracts information at a higher level than the combination of its leaf nodes."}, {"heading": "80 CHAPTER 7. CONCLUSION", "text": "As we have already discussed, we believe that the absence of the first 100 revolutions was crucial to the poor accuracy achieved in the classification of growth preferences. The problem of functional selection is a difficult issue because, as discussed, one feature can be insignificant in itself (such as train), but when it is associated with others, it can be very useful. In fact, there are several ways to further evaluate this issue and, as far as we know, few papers have presented concerns regarding the automatic selection of the smaller and most representative features for player modeling. In addition, our results can be improved by the application of over / undersampling techniques in our data set, which has to do with unbalanced classes. Another issue we do not discuss, but also worth an investigation due to its applicability throughout the field, is the evaluation of the correctness of players, who are themselves referred to as preferences."}, {"heading": "82 BIBLIOGRAPHY", "text": "In the USA, Canada, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, USA, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada, Canada,"}, {"heading": "84 BIBLIOGRAPHY", "text": "Gow, J., Baumgarten, R., Cairns, P. A., Colton, S., and Miller, P. (2012). Unsupervised Modeling of Player Style With LDA. IEEE Transactions on Computational Intelligence and AI in Games, 4 (3): 152-166.Hladky, S. and Bulitko, V. (2008). An Evaluation of Models for Predicting Opponent Positions in First-Person Shooter Video Games. In Proceedings of the IEEE Symposium on Computational Intelligence and Games, CIG, pp. 39-46. IEEE Press.Houlette, R. (2003). Player Modeling for Adaptive Games, pp. 557-566. Charles River Media.Iida, H., Uiterwijk, J., Herik, H. v. d., and Herschberg, I. (1993). Potential Applications of Opponent Model Search."}, {"heading": "86 BIBLIOGRAPHY", "text": "In the second half of the last decade, in which we are in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last century, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the second half of the last decade, in the last decade and in the second half of the last decade."}, {"heading": "88 BIBLIOGRAPHY", "text": "In the meantime, it has been shown that this is not only a problem, but also a problem that has been solved in recent years. (...) In the meantime, it has been shown that it is a problem. (...) In the meantime, it has been shown that it is a problem that cannot be solved. (...) In the meantime, it has been shown that it cannot be solved. (...) In the meantime, it has been shown that the problem cannot be solved. (...) In the meantime, it has been solved. (...) In the meantime, it has been shown that the problem can be solved. (...) In the meantime, it has been solved. (...) In the meantime, it has been solved."}, {"heading": "Appendix A", "text": "Features of the CIVILIZATION IV dataset"}, {"heading": "90 APPENDIX A. CIVILIZATION IV DATASET FEATURES", "text": "38: PopulationDiff 67: Economy 111: GoldDifferivatives 76: IndustryDifferivatives 24: PopulationDifferivatives 36: EconomicDifferivatives 68: EconomicDifferivatives 112: GoldRateDerivatives 25: PopulationDiffTrend 69: EconomyTrend 113: GoldRateTrend 26: PopulationDiffTrendTrendDerivatives 70: EconomicTrendDerivatives 29: GoldTrend 73: EconomicDifferivatives 117: ResearchTrend 30: GoldTrendDerivatives 74: EconomicDiffendendDerivatives 118: ResearchTrendDerivatives 31: GoldDifferivatives 75: Industry 119: Cultural War 32: GoldDifferivatives 76: IndustryDifferivatives 74: Differivatives 118: ResearchTrendTrend 30: GoldTrendDerivatives 74: EconomicTrendDerivatives 118: ResearchTrendDerivatives 31: GoldDiffendDerivatives: GoldDiffendates 115: Populatives 75: Industrial War 32: Gold Diffomaterivatives 112: Economy 112: Economy 12: Economy 12: Economy112: Economy 12: Economy112: Economy112: Economy: Economy12: Economy12: Economy27: EconomyDiff: Population Diff: Diff 67: Economy: Economy 112: Population Differivatives: Population Differivatives 112: Population Differivatives 111: Industrial Differivatives 76: Industrial Differivatives 112: Industrial Differivatives 76: Industrial Differivatives 76: IndustrialDifferivatives 76: IndustrialDifferivatives 76: IndustrialDifferivatives 76: IndustrialDifferivatives 112: IndustryTrend 72: IndustrialDifferivatives 118: IndustrialDifferivatives 118: PopulationDifferivendTrend 118: Population DifferivendTrend 118: EconomyTrend: EconomyTrend 118: EconomyTrend"}, {"heading": "Appendix B", "text": "Summary of the linear regressions of the indicators"}, {"heading": "92 APPENDIX B. SUMMARY OF INDICATORS\u2019 LINEAR REGRESSIONS", "text": "GoldRate Mansa Musa (1: 460) \u00b1 \u00b1 10) Victory 99.03% \u2212 6.2833 (\u00b1 19.5158) 0.4842 (\u00b1 0.0733) 90% Victory Louis XIV (1: 460) \u00b1 0.010 (\u00b1 4.060) Defeat 97.98% \u2212 11.8778 (\u00b1 4.6118) 0.2867 (\u00b1 0.0173) Victory Mansa Musa (1: 460) Defeat 84.60 (\u2212 0.060) \u2212 0.4737 (\u00b1 26.7967) 0.2326 (\u00b1 0.01007) 3 (\u00b1 0.01007) Victory Alexander Louis XIV (1: 460) Victory Alexander Louis XIV (1: 460) Victory 79.94% (\u00b1 0.004) Victory Mansa (2: Victory Mansa Mustory (\u00b1 0.007) 99 (\u00b1 0.007) Victory Mansa Musa (\u00b1 0.007) 99 99 99 99 99 Mussa Musa Victory 993 (\u00b1 93) Victory (\u00b1 475) (\u00b1 40.79) Victory Alexander Louis XIV (1: Victory) Victory Alexander Louis XIV (\u00b1 460) Victory 99.94 (\u00b1 0.004) Victory Mansa (\u00b1 0.004) Victory Mansa (2: Victory Mansa 99 99 Mussa 99 Mussa 99 (\u00b1 0.007) Victory 960 93 (\u00b1 475) Victory Alexander XIV (\u00b1 40.79) 40.79 (\u00b1 479) Victory Alexander XIV (\u00b1 40.79) (\u00b1 40.79) Victory Mansa Mansa Mussa (1: Victory) Mansa (1: 99 99 99 99 Mussa 99 99 99 Mussa 99 (\u00b1 99) Victory 960 93 93 (Victory) (\u00b1 40.75) 40.79) 40.79 (\u00b1 40.79)"}, {"heading": "Appendix C", "text": "Questionnaires relating to human gamesThis appendix presents both questionnaires that were applied to human gamblers. After signing a consent form, they were asked to complete a pre-test questionnaire with the aim of maintaining the profile of the player. After completing, they played a game of the game CIVILIZATION IV and were asked to complete the post-test questionnaire. All questionnaires were submitted to the players in Portugal. C.1 Pre-test questionnaire was the larger questionnaire that players had to complete. Not all players answered all questions because the questionnaire was dynamic, i.e. he did not ask the player how many times he / she had played a game when the player replied in the previous question that he / she did not know any turn-based strategy games. All available questions on the questionnaire are shown in Figures C.1, C.2, C.3, C.4 and C.5."}, {"heading": "94 APPENDIX C. QUESTIONNAIRES APPLIED TO HUMAN PLAYERS", "text": "C.1. PRETEST QUESTION 95"}, {"heading": "96 APPENDIX C. QUESTIONNAIRES APPLIED TO HUMAN PLAYERS", "text": "C.2. POST-TEST QUESTIONNAIRE 97C.2 Post-Test questionnaire After the game, all players were required to complete the post-test questionnaire, which was designed to determine the players \"preferences and their confidence in the self-designated preferences. This questionnaire is shown in Figure C.6."}, {"heading": "Appendix D", "text": "Accuracy in classifying each human player"}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "Artificial Intelligence (AI) is gradually receiving more attention as a fundamental feature to increase the immersion in digital games. Among the several AI approaches, player modeling is becoming an important one. The main idea is to understand and model the player characteristics and behaviors in order to develop a better AI. It is possible to model player aspects in different levels of abstraction, such as actions, position, preferences, knowledge and satisfaction. This modeling allows games to customize their AI, difficulty or levels to specific players, making the game experience more interesting. In this work, we discuss several aspects of this new field. Since several works have been tackling this problem, we proposed a taxonomy to organize the area, discussing several facets of this topic, ranging from implementation decisions up to what a model attempts to describe. We then classify, in our taxonomy, some of the most important works in this field. Besides the taxonomy, we also presented a generic approach to deal with player modeling using machine learning, and we instantiated this approach to model players\u2019 preferences in the game CIVILIZATION IV. The instantiation of this approach has several steps. We first discuss a generic representation, regardless of what is being modeled, and evaluate it performing experiments with the strategy game CIVILIZATION IV. Results show the effectiveness of this representation in characterizing and modeling agents. Continuing the instantiation of the proposed approach we evaluated the applicability of using game score information to distinguish different preferences. To perform this task we presented a characterization of virtual agents in the game, comparing their behavior with their stated preferences. Once we have characterized these agents, we were able to observe that different preferences generate different behaviors, measured by several game indicators. Using this information we tackled the preference modeling problem as a binary classification task, with a supervised learning approach. We compared four different methods, based on different paradigms (SVM, AdaBoost, NaiveBayes and JRip), evaluating them on a set of matches played by different virtual agents. We obtained accuracies that improved by far the state of the art. We conclude our work using the learned models to infer human players\u2019", "creator": "LaTeX with hyperref package"}}}