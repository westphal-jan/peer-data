{"id": "1312.4384", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Dec-2013", "title": "Rectifying Self Organizing Maps for Automatic Concept Learning from Web Images", "abstract": "We attack the problem of learning concepts automatically from noisy web image search results. Going beyond low level attributes, such as colour and texture, we explore weakly-labelled datasets for the learning of higher level concepts, such as scene categories. The idea is based on discovering common characteristics shared among subsets of images by posing a method that is able to organise the data while eliminating irrelevant instances. We propose a novel clustering and outlier detection method, namely Rectifying Self Organizing Maps (RSOM). Given an image collection returned for a concept query, RSOM provides clusters pruned from outliers. Each cluster is used to train a model representing a different characteristics of the concept. The proposed method outperforms the state-of-the-art studies on the task of learning low-level concepts, and it is competitive in learning higher level concepts as well. It is capable to work at large scale with no supervision through exploiting the available sources.", "histories": [["v1", "Mon, 16 Dec 2013 14:51:00 GMT  (6565kb,D)", "http://arxiv.org/abs/1312.4384v1", "present CVPR2014 submission"]], "COMMENTS": "present CVPR2014 submission", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["eren golge", "pinar duygulu"], "accepted": false, "id": "1312.4384"}, "pdf": {"name": "1312.4384.pdf", "metadata": {"source": "CRF", "title": "Rectifying Self Organizing Maps for Automatic Concept Learning from Web Images", "authors": ["Eren Golge", "Pinar Duygulu"], "emails": ["eren.golge@bilkent.edu.tr", "pinar.duygulu@gmail.com"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them will be able to move to another world in which they will be able to integrate."}, {"heading": "2. Related work", "text": "The use of attributes has been the focus of many recent studies [2, 8, 1]. In [3] Farhadi et al. learn complex attributes (form, materials, parts) in a fully controlled manner that focuses on the recognition of new types of objects. In [10], semantic attribute comments derived from studies in cognitive science are used binarily for zero-shot learning. In this study, we focus on learning attributes independently of object categories. Torresani et al. [21] introduce classes, attributes that have no specific semantic meanings but meanings derived from intersections of properties, and they receive training data directly from web image search. Rastegari et al. [18] propose to discover implicit attributes that are not necessarily semantic, but category-specific characteristics by learning discriminatory hyper-level hyper-sensitivity and image sensitivity criteria."}, {"heading": "3. Rectifying Self Organizing Maps", "text": "These phenomena, which are called \"receptive fields\" in visual neural systems, are simulated with different neural systems in which neurons are represented by weights designed to make neurons sensitive to different types of input factors. Elicitation of this structure is made possible by competitive learning approaches. Input with M instances X = {x1, x2..., xM}. Let N = {n1, nK} be the locations of neuron units on the SOM map andW = {w1, w2} be the associated weights."}, {"heading": "4. Concept learning with RSOM", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Learning low-level attributes", "text": "The data is poorly labeled, with the labels given for the entire image, rather than the specific regions. Most importantly, the large volume of data itself is sufficient to provide instances at different scales and illuminations, and therefore we do not perform scaling or normalization. RSOM then uses the collection of all the patches extracted from all the images for a single attribute to capture the various attributes of the Attribute Training models."}, {"heading": "4.2. Learning higher level concepts", "text": "To show that RSOM can be generalized to higher-level concepts, we have collected images for scene categories from the web to learn these concepts. In this case, we use all the images as instances and aim to find groups of images, each representing a different characteristic of the scene category. These clusters are then used as models similar to the Learning attribute. Specifically, we conduct scene classification experiments for 15 scene categories, as in [11]. Note that we do not use manually labeled training sets, but directly the noisy web images that are cropped and organized by RSOM. This task is also different from using low-level attributes for scene detection, in which case we learn the scene concept directly, without needing any further information."}, {"heading": "5. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Qualitative evaluation of clusters", "text": "As Figure 3 shows, RSOM captures different characteristics of concepts in separate distinctive clusters, eliminating outlier clusters that group irrelevant images that are coherent with each other, as well as outlier elements that are mistakenly mixed with elements of distinctive clusters."}, {"heading": "5.2. Implementation details", "text": "Figure 4 shows the effect of the parameters \u03b8, \u03c4 and \u03bd. For each parameter, the other two are set to the optimal value achieved by cross-validation. SVM parameters are also selected with 10x cross-validation and grid search. We terminate the search process when the current accuracy is less than the average accuracy of the backward step of 5 to 10 years. Our RSOM implementation is driven by GPGPU programming via the CUDA environment, which results in a large time saving."}, {"heading": "5.3. Attribute learning", "text": "It is indeed the case that we will be able to go in search of a solution that meets the needs of the people."}, {"heading": "5.4. Learning concepts of scene categories", "text": "As an alternative to recognizing scenes through the learned low-level attributes, we learn directly overarching concepts for scene categories. We focus on learning 15 scene concepts used in [11] by collecting images from the web for these concepts. We have shown that our method competes with the state of the art without the need for supervised training. We have made a slight change to our original RSOM implementation for recognizing scene concepts (which we call RSOM-S) by finding the hard negatives in the first classification and using them in a different classification (we call this new method RSOM-SHM). As the results in Figure 6 show, with this simple addition, we achieve better performance than the state-of-the-art studies, but without any supervision."}, {"heading": "6. Conclusion", "text": "In this paper, we propose Rectifying Self Organizing Maps, which resembles SOM with cluster properties and is novel in terms of outlier detection dynamics. We use RSOM for weakly monitored learning of visual concepts from large-scale, noisy web data. Multiple classifiers are built for each attribute from clusters trimmed by outliers, so each classifier is sensitive to a different visual variation. Our experiments show that we are able to capture low-level concepts on new images and have a good foundation for higher-level detection tasks such as scene detection with low-cost settings. We also show that we can learn higher-level concepts directly."}], "references": [{"title": "Adding unlabeled samples to categories by learned attributes", "author": ["J. Choi", "M. Rastegari", "A. Farhadi", "L.S. Davis"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "and D", "author": ["A. Farhadi", "I. Endres"], "venue": "Hoiem. D.: Attribute-centric recognition for crosscategory generalization. CVPR", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Describing objects by their attributes", "author": ["A. Farhadi", "I. Endres", "D. Hoiem", "D. Forsyth"], "venue": "CVPR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning visual attributes", "author": ["V. Ferrari", "A. Zisserman"], "venue": "NIPS", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "A kohonen som based", "author": ["T. Harris"], "venue": "machine health monitoring system which enables diagnosis of faults not seen in the training set. Neural Networks. IJCNN\u201993-Nagoya.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1993}, {"title": "Receptive fields", "author": ["D.H. Hubel", "T.N. Wiesel"], "venue": "binocular interaction and functional architecture in the cat\u2019s visual cortex. The Journal of physiology", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1962}, {"title": "Self-organizing maps", "author": ["T. Kohonen"], "venue": "Springer", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1997}, {"title": "Attribute and simile classifiers for face verification", "author": ["N. Kumar", "A.C. Berg", "P.N. Belhumeur", "S.K. Nayar"], "venue": "ICCV", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Scene recognition on the semantic manifold", "author": ["R. Kwitt", "N. Vasconcelos", "N. Rasiwasia"], "venue": "ECCV", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning to detect unseen object classes by between-class attribute transfer", "author": ["C.H. Lampert", "H. Nickisch", "S. Harmeling"], "venue": "CVPR", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "CVPR", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Harvesting mid-level visual concepts from large-scale internet images", "author": ["Q. Li", "J. Wu", "Z. Tu"], "venue": "CVPR", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "A model of habituation applied to mobile robots", "author": ["S. Marsland", "U. Nehmzow", "J. Shapiro"], "venue": "Proceedings of Towards Intelligent Mobile Robots", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1999}, {"title": "Novelty Detection for Robot Neotaxis", "author": ["S. Marsland", "U. Nehmzow", "J. Shapiro"], "venue": "Proceedings 2nd NC", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2000}, {"title": "Self-organizing maps for outlier detection", "author": ["A. Mu\u00f1oz", "J. Muruz\u00e1bal"], "venue": "Neurocomputing", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "Scene recognition and weakly supervised object localization with deformable part-based models", "author": ["M. Pandey", "S. Lazebnik"], "venue": "ICCV", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Recognizing indoor scenes", "author": ["A. Quattoni", "A. Torralba"], "venue": "CVPR", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Attribute discovery via predictable discriminative binary codes", "author": ["M. Rastegari", "A. Farhadi", "D. Forsyth"], "venue": "ECCV", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Attribute learning in largescale datasets", "author": ["O. Russakovsky", "L. Fei-Fei"], "venue": "Trends and Topics in Computer Vision", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Novelty detection in a kohonen-like network with a long-term depression learning rule", "author": ["D. Theofilou", "V. Steuber", "E.D. Schutter"], "venue": "Neurocomputing", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "Efficient object category recognition using classemes", "author": ["L. Torresani", "M. Szummer", "A. Fitzgibbon"], "venue": "ECCV", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning color names for real-world applications", "author": ["J. Van De Weijer", "C. Schmid", "J. Verbeek", "D. Larlus"], "venue": "Image Processing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Novelty detection using self-organizing maps", "author": ["A. Ypma", "E. Ypma", "R.P. Duin"], "venue": "Proc. of ICONIP\u201997", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1997}], "referenceMentions": [{"referenceID": 21, "context": "However, data collected from web inherits all type of challenges due to illumination, reflection, scale, and pose variations as well as camera and compression effects[22].", "startOffset": 166, "endOffset": 170}, {"referenceID": 6, "context": "We propose a novel method Rectifying Self Organizing Maps (RSOM) which improves the well-known Self Organizing Maps (SOM) [7] through detection and elimination of outliers.", "startOffset": 122, "endOffset": 125}, {"referenceID": 1, "context": "The use of attributes has been the focus of many recent studies [2, 8, 1].", "startOffset": 64, "endOffset": 73}, {"referenceID": 7, "context": "The use of attributes has been the focus of many recent studies [2, 8, 1].", "startOffset": 64, "endOffset": 73}, {"referenceID": 0, "context": "The use of attributes has been the focus of many recent studies [2, 8, 1].", "startOffset": 64, "endOffset": 73}, {"referenceID": 2, "context": "In [3], Farhadi et al.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "In [10], for human labelled animal categories, semantic attribute annotations available from studies in cognitive science were used in a binary fashion for zero-shot learning.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "[21] introduce classemes, attributes that do not have specific semantic meanings, but meanings expected to emerge from intersections of properties, and they obtain training data directly from web image search.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] propose discovering implicit attributes that are not necessarily semantic but preserve categoryspecific traits through learning discriminative hyperplanes with max-margin and locality sensitive hashing criteria.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "Learning semantic appearance attributes, such as colour, texture and shape, on large scale ImageNet dataset is attacked in [19] relying on image level human labels using Amazon\u2019s Mechanical Turk for supervised learning.", "startOffset": 123, "endOffset": 127}, {"referenceID": 21, "context": "Another study on learning colour names from web images is proposed in [22] where a PLSA based model is used for representing the colour names of pixels.", "startOffset": 70, "endOffset": 74}, {"referenceID": 3, "context": "Similar to ours, the approach of Ferrari and Zisserman [4] considers attributes as patterns sharing some characteristic properties where basic units are the image segments with uniform appearance.", "startOffset": 55, "endOffset": 58}, {"referenceID": 6, "context": "Revisiting Self Organizing Maps (SOM): Intrinsic dynamics of SOM are inspired from developed animal brain where each part is known to be receptive to different sensory inputs and which has a topographically organized structure[7].", "startOffset": 226, "endOffset": 229}, {"referenceID": 5, "context": "This phenomena, which is called as \u201dreceptive field\u201d in visual neural systems [6], is simulated with SOM, where neurons are represented by weights that are calibrated to make neurons sensitive to different type of inputs.", "startOffset": 78, "endOffset": 81}, {"referenceID": 0, "context": "RSOM is capable of detecting outlier units via a threshold \u03b8 in the range [0, 1].", "startOffset": 74, "endOffset": 80}, {"referenceID": 14, "context": "We exploit box plot statistics, similar to [15].", "startOffset": 43, "endOffset": 47}, {"referenceID": 12, "context": "Discussion of other methods on outlier detection with SOM: [13, 14] utilise the habitation of the instances.", "startOffset": 59, "endOffset": 67}, {"referenceID": 13, "context": "Discussion of other methods on outlier detection with SOM: [13, 14] utilise the habitation of the instances.", "startOffset": 59, "endOffset": 67}, {"referenceID": 4, "context": "[5] benefits from weights prototyping the instances in a cluster.", "startOffset": 0, "endOffset": 3}, {"referenceID": 22, "context": "In [23], aim is to have different mapping of activated neuron for the outlier instances.", "startOffset": 3, "endOffset": 7}, {"referenceID": 19, "context": "LTD-KN [20] performs Kohonen learning rule inversely.", "startOffset": 7, "endOffset": 11}, {"referenceID": 10, "context": "For this purpose, first we divide the image into grids in three levels using spatial pyramiding [11].", "startOffset": 96, "endOffset": 100}, {"referenceID": 10, "context": "Specifically, we perform experiments for scene classification for 15 scene categories as in [11].", "startOffset": 92, "endOffset": 96}, {"referenceID": 21, "context": "Datasets: We collected images from Google for 11 distinct colours as in [22] and 13 textures.", "startOffset": 72, "endOffset": 76}, {"referenceID": 21, "context": "To test the results on a human labelled dataset, we use Ebay dataset provided by [22] which has labels for the pixels in cropped regions.", "startOffset": 81, "endOffset": 85}, {"referenceID": 21, "context": "Unlike [22], we didn\u2019t apply gamma correction.", "startOffset": 7, "endOffset": 11}, {"referenceID": 21, "context": "Second dataset is Google Colour Images [22] previously used by [22] for learning colour attributes.", "startOffset": 39, "endOffset": 43}, {"referenceID": 21, "context": "Second dataset is Google Colour Images [22] previously used by [22] for learning colour attributes.", "startOffset": 63, "endOffset": 67}, {"referenceID": 18, "context": "The last dataset is sample annotated images from ImageNet [19] for 25 attributes.", "startOffset": 58, "endOffset": 62}, {"referenceID": 16, "context": "The second task on scene recognition is performed on MIT-indoor [17], and Scene-15 [11] datasets.", "startOffset": 64, "endOffset": 68}, {"referenceID": 10, "context": "The second task on scene recognition is performed on MIT-indoor [17], and Scene-15 [11] datasets.", "startOffset": 83, "endOffset": 87}, {"referenceID": 21, "context": "As a baseline method (BL), we use all Bing Google [22] ImageNet [19] EBAY [22] 0.", "startOffset": 50, "endOffset": 54}, {"referenceID": 18, "context": "As a baseline method (BL), we use all Bing Google [22] ImageNet [19] EBAY [22] 0.", "startOffset": 64, "endOffset": 68}, {"referenceID": 21, "context": "As a baseline method (BL), we use all Bing Google [22] ImageNet [19] EBAY [22] 0.", "startOffset": 74, "endOffset": 78}, {"referenceID": 21, "context": "Method RSOM-M RSOM PLSA-reg [22].", "startOffset": 28, "endOffset": 32}, {"referenceID": 21, "context": "Equal Error Rates on EBAY dataset for image retrieval using the configuration of [22].", "startOffset": 81, "endOffset": 85}, {"referenceID": 21, "context": "RSOM does not utilise the image masks used in [22], while RSOM-M does.", "startOffset": 46, "endOffset": 50}, {"referenceID": 18, "context": "8% of Russakovsky and Fei-Fei[19].", "startOffset": 29, "endOffset": 33}, {"referenceID": 21, "context": "Our method is also utilised for retrieving images on EBAY dataset as in [22].", "startOffset": 72, "endOffset": 76}, {"referenceID": 21, "context": "We utilise RSOM with patches obtained from the entire images (RSOM) as well as from the masks provided by [22] (RSOM-M).", "startOffset": 106, "endOffset": 110}, {"referenceID": 21, "context": "As shown in Table1, even without masks RSOM is comparable to the performance of the PLSA based method of [22], and with the same setting RSOM outperforms the PLSA based method.", "startOffset": 105, "endOffset": 109}, {"referenceID": 16, "context": "On the task of scene recognition with learned attributes, we compare our method (RSOM-A) with state-of-the-art methods on MIT-indoor [17] and Scene-15 [11] datasets.", "startOffset": 133, "endOffset": 137}, {"referenceID": 10, "context": "On the task of scene recognition with learned attributes, we compare our method (RSOM-A) with state-of-the-art methods on MIT-indoor [17] and Scene-15 [11] datasets.", "startOffset": 151, "endOffset": 155}, {"referenceID": 11, "context": "Our method performs competitively with[12] while using shorter feature vectors, and outperforms the others.", "startOffset": 38, "endOffset": 42}, {"referenceID": 10, "context": "We focus on learning 15 scene concepts used in [11], through collecting images from web for these concepts.", "startOffset": 47, "endOffset": 51}, {"referenceID": 16, "context": "Method MIT-indoor [17] Scene-15 [11]", "startOffset": 18, "endOffset": 22}, {"referenceID": 10, "context": "Method MIT-indoor [17] Scene-15 [11]", "startOffset": 32, "endOffset": 36}, {"referenceID": 11, "context": "[12] VQ 47.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] 43.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[9] 44% 82.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[11] 81.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Comparison of our methods on scene recognition in relation to state-of-the-art studies on MIT-Indoor [17] and Scene-15 [11] datasets.", "startOffset": 101, "endOffset": 105}, {"referenceID": 10, "context": "Comparison of our methods on scene recognition in relation to state-of-the-art studies on MIT-Indoor [17] and Scene-15 [11] datasets.", "startOffset": 119, "endOffset": 123}, {"referenceID": 10, "context": "ac cu ra cy RSOM [11]", "startOffset": 17, "endOffset": 21}, {"referenceID": 10, "context": "3% for RSOM-S+HM , versus 81% for [11] .", "startOffset": 34, "endOffset": 38}], "year": 2013, "abstractText": "We attack the problem of learning concepts automatically from noisy web image search results. Going beyond low level attributes, such as colour and texture, we explore weakly-labelled datasets for the learning of higher level concepts, such as scene categories. The idea is based on discovering common characteristics shared among subsets of images by posing a method that is able to organise the data while eliminating irrelevant instances. We propose a novel clustering and outlier detection method, namely Rectifying Self Organizing Maps (RSOM). Given an image collection returned for a concept query, RSOM provides clusters pruned from outliers. Each cluster is used to train a model representing a different characteristics of the concept. The proposed method outperforms the state-of-the-art studies on the task of learning low-level concepts, and it is competitive in learning higher level concepts as well. It is capable to work at large scale with no supervision through exploiting the available sources.", "creator": "LaTeX with hyperref package"}}}