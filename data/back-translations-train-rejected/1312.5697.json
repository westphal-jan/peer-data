{"id": "1312.5697", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Dec-2013", "title": "Using Web Co-occurrence Statistics for Improving Image Categorization", "abstract": "Object recognition and localization are important tasks in computer vision. The focus of this work is the incorporation of contextual information in order to improve object recognition and localization. For instance, it is natural to expect not to see an elephant to appear in the middle of an ocean. We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents. By merely counting the number of times nouns (such as elephants, sharks, oceans, etc.) co-occur in web documents, we obtain a good estimate of expected co-occurrences in visual data. We then cast the problem of combining textual co-occurrence statistics with the predictions of image-based classifiers as an optimization problem. The resulting optimization problem serves as a surrogate for our inference procedure. Albeit the simplicity of the resulting optimization problem, it is effective in improving both recognition and localization accuracy. Concretely, we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets.", "histories": [["v1", "Thu, 19 Dec 2013 18:53:47 GMT  (52345kb,D)", "https://arxiv.org/abs/1312.5697v1", null], ["v2", "Fri, 20 Dec 2013 18:12:16 GMT  (52434kb,D)", "http://arxiv.org/abs/1312.5697v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["samy bengio", "jeff dean", "dumitru erhan", "eugene ie", "quoc le", "rew rabinovich", "jonathon shlens", "yoram singer"], "accepted": false, "id": "1312.5697"}, "pdf": {"name": "1312.5697.pdf", "metadata": {"source": "CRF", "title": "Using Web Co-occurrence Statistics for Improving Image Categorization", "authors": ["Samy Bengio", "Jeff Dean", "Dumitru Erhan", "Eugene Ie", "Quoc Le", "Andrew Rabinovich", "Jonathon Shlens"], "emails": ["bengio@google.com", "jeff@google.com", "dumitru@google.com", "eugeneie@google.com", "qvl@google.com", "amrabino@google.com", "shlens@google.com", "singer@google.com"], "sections": [{"heading": "1 Introduction", "text": "The fact is that you are able to put yourself in a situation where you are able to put yourself in a situation where you are able to put yourself in a situation where you are able to put yourself in a situation where you are able to put yourself in."}, {"heading": "2 The Laconic Setting", "text": "We start by looking at the notation used in the thesis as an external object. We refer to scalars by lowercase letters, vectors by bold lowercase letters, e.g. v-Rp, and matrices by uppercase letters. Transposing a matrixA is essentially punished. Vectors are also considered as p-1 matrices. Therefore, the 2-norm of a vector can be called vTv. We refer to the number of different object classes by p.The Laconic lens consists of three components: an image-based object score obtained from an image classification (see Sec.4), a co-occurrence score based on term proximity in text-based web data (see Sec.3), and a regulation term to prevent overfitting. We refer to the vector of object scores by \u00b5 Rp, where the value of \u00b5j increases with the probability that the object appears in the image as an externj."}, {"heading": "3 Label Co-Occurrences", "text": "To estimate the previous probability of observing two i and j labels in the same image, we took a sample of web documents with a total of a few billion documents, and for each document we have any possible sub-sequence (embossed window) of consecutive words of length 20. We then counted how often each label was observed, along with the number of simultaneous occurrences of label pairs within each window. Next, we created estimates for the point-by-point mutual information: si, j = log (p (i, j) p (i) p (j)))))), (8) with p (i, j) and p (i) simply normalizing the above counts to probability.We discarded all pairs whose simultaneous frequency was below a threshold. Since web data is relatively loud and our collection was quite large, even bizarre connections on the board can be observed several times."}, {"heading": "4 Experiments", "text": "In this section we report on the results of two experiments with public datasets. The first dataset, Sun12, is small but the largest of its kind, since each image is labeled with multiple labels. The second dataset, ImageNet for detection, is much larger, but most images are associated with a single label.To evaluate Laconic, we used the following metrics: \u2022 Precision @ k is the number of correct labels returned at the top k positions divided by k. \u2022 AveragePrecision is the mean of Precision @ ki, where ki is the position obtained by Target label i for all target labels. \u2022 Detection @ k is the number of correct labels returned at the top k positions, where a detection is valid if both the labeling is correct and the boundary box returned is at least 50% with the target box.For each dataset, a neural validation was selected for the above."}, {"heading": "4.1 Sun12", "text": "In fact, most of us are able to outdo ourselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag. \""}, {"heading": "4.2 ImageNet Detection Dataset", "text": "This year, we have reached the point where we feel we are in a position to achieve the objectives I have mentioned, but we do not feel we are in a position to achieve them."}, {"heading": "5 Conclusion", "text": "We have proposed a new approach to integrate page information from web documents with the output of a deep neural network to improve classification and recognition accuracy. We have empirically evaluated our algorithm on two different datasets, Sun12 and Imagenet, and have achieved consistent improvements in classification and recognition accuracy on both datasets. In future work, we plan to go a step further and include spatial text information, such as how often we observe phrases such as \"the chair is next to the table\" or \"the car is under the bridge\" and construct triplets of shape (Object1, Relation, Object2) in which the relationship expresses spatial correspondence between the two objects. Such information could potentially lead to more comprehensive and accurate visual scene analysis. On the front of the inference, we plan to explore alternative traceable approaches."}], "references": [{"title": "Understanding web images by object relation network", "author": ["N. Chen", "Q.-Y. Zhou", "V.K. Prasanna"], "venue": "In Proceedings of the 21st World Wide Web Conference,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei-Fei"], "venue": "In IEEE Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J.C. Duchi", "E. Hazan", "Y. Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Object categorization using co-occurence, location and appearance", "author": ["C. Galleguillos", "A. Rabinovich", "S. Belongie"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Learning spatial context: Using stuff to find things", "author": ["G. Heitz", "D. Koller"], "venue": "In ECCV,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R.R. Salakhutdinov"], "venue": "arXiv preprint arXiv:1207.0580,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Beitrag zur theorie des ferromagnetismus", "author": ["E. Ising"], "venue": "Z. Phys.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1925}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Building high-level features using large scale unsupervised learning", "author": ["Q.V. Le", "M.A. Ranzato", "R. Monga", "M. Devin", "K. Chen", "G.S. Corrado", "J. Dean", "A.Y. Ng"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Fundamentals of Speech Recognition", "author": ["L. Rabiner", "B.-H. Juang"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1993}, {"title": "Objects in context", "author": ["A. Rabinovich", "A. Vedaldi", "C. Galleguillos", "E. Wiewiora", "S. Belongie"], "venue": "In International Conference on Computer Vision (ICCV),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Contextual priming for object detection", "author": ["A. Torralba"], "venue": "International Journal of Computer Vision,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Sun database: Large-scale scene recognition from abbey to zoo", "author": ["J. Xiao", "J. Hays", "K. Ehinger", "A. Oliva", "A. Torralba"], "venue": "In 2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}], "referenceMentions": [{"referenceID": 3, "context": "Few approaches were proposed in the computer vision literature to incorporate contextual information, see for instance [4, 11, 12].", "startOffset": 119, "endOffset": 130}, {"referenceID": 10, "context": "Few approaches were proposed in the computer vision literature to incorporate contextual information, see for instance [4, 11, 12].", "startOffset": 119, "endOffset": 130}, {"referenceID": 11, "context": "Few approaches were proposed in the computer vision literature to incorporate contextual information, see for instance [4, 11, 12].", "startOffset": 119, "endOffset": 130}, {"referenceID": 11, "context": "The first considers global image features to be the source of context, thus trying to capture class-specific features [12].", "startOffset": 118, "endOffset": 122}, {"referenceID": 10, "context": "The second classifies objects while taking into account the existence of the rest of the objects in the scene [11].", "startOffset": 110, "endOffset": 114}, {"referenceID": 3, "context": "[4] considers both semantic context, that is, co-occurrences of objects as well as spatial relations between objects.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "In [1], the authors further extend the latter approach by proposing an \u201cObject Relation Network\u201d that models behavioral relations between objects in images.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "the usage of unlabeled data through grouping of image regions of the same context was proposed in [5].", "startOffset": 98, "endOffset": 101}, {"referenceID": 9, "context": "In contrast, modern speech recognition approaches have been using language models for many years [10].", "startOffset": 97, "endOffset": 101}, {"referenceID": 6, "context": "The sum of (4) and (2) is essentially the Ising model [7].", "startOffset": 54, "endOffset": 57}, {"referenceID": 12, "context": "Sun12 is a subset of the SUN dataset [13], consisting of fully annotated images from SUN.", "startOffset": 37, "endOffset": 41}, {"referenceID": 7, "context": "These were then used to train a large scale convolutional network similar to [8], which won the last ImageNet challenge.", "startOffset": 77, "endOffset": 80}, {"referenceID": 2, "context": "The full model was trained using stochastic gradient descent combined with the AdaGrad algorithm [3] along with the Dropout [6] regularization technique.", "startOffset": 97, "endOffset": 100}, {"referenceID": 5, "context": "The full model was trained using stochastic gradient descent combined with the AdaGrad algorithm [3] along with the Dropout [6] regularization technique.", "startOffset": 124, "endOffset": 127}, {"referenceID": 10, "context": "In comparison, naively using a conditional random field such as the one described in [11], would require the evaluation of", "startOffset": 85, "endOffset": 89}, {"referenceID": 1, "context": "Our second set of experiments is with the ImageNet dataset [2] (fall 2011 release).", "startOffset": 59, "endOffset": 62}, {"referenceID": 8, "context": "The architecture of the model is based on the model described in [9].", "startOffset": 65, "endOffset": 68}], "year": 2013, "abstractText": "Object recognition and localization are important tasks in computer vision. The focus of this work is the incorporation of contextual information in order to improve object recognition and localization. For instance, it is natural to expect not to see an elephant to appear in the middle of an ocean. We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents. By merely counting the number of times nouns (such as elephants, sharks, oceans, etc.) co-occur in web documents, we obtain a good estimate of expected co-occurrences in visual data. We then cast the problem of combining textual co-occurrence statistics with the predictions of image-based classifiers as an optimization problem. The resulting optimization problem serves as a surrogate for our inference procedure. Albeit the simplicity of the resulting optimization problem, it is effective in improving both recognition and localization accuracy. Concretely, we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets.", "creator": "TeX"}}}