{"id": "1312.6062", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2013", "title": "Stopping Criteria in Contrastive Divergence: Alternatives to the Reconstruction Error", "abstract": "Restricted Boltzmann Machines (RBMs) are general unsupervised learning devices to ascertain generative models of data distributions. RBMs are often trained using the Contrastive Divergence learning algorithm (CD), an approximation to the gradient of the data log-likelihood. A simple reconstruction error is often used to decide whether the approximation provided by the CD algorithm is good enough, though several authors (Schulz et al., 2010; Fischer &amp; Igel, 2010) have raised doubts concerning the feasibility of this procedure. However, not many alternatives to the reconstruction error have been used in the literature. In this manuscript we investigate simple alternatives to the reconstruction error in order to detect as soon as possible the decrease in the log-likelihood during learning.", "histories": [["v1", "Fri, 20 Dec 2013 18:14:44 GMT  (394kb,D)", "https://arxiv.org/abs/1312.6062v1", "7 pages, 4 figures"], ["v2", "Wed, 9 Apr 2014 07:42:24 GMT  (455kb,D)", "http://arxiv.org/abs/1312.6062v2", "7 pages, 4 figures"]], "COMMENTS": "7 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["david buchaca", "enrique romero", "ferran mazzanti", "jordi delgado"], "accepted": false, "id": "1312.6062"}, "pdf": {"name": "1312.6062.pdf", "metadata": {"source": "CRF", "title": "Stopping Criteria in Contrastive Divergence: Alternatives to the Reconstruction Error", "authors": ["David Buchaca Prats", "Enrique Romero Merino"], "emails": ["DAVIDBUCHACA@GMAIL.COM", "EROMERO@LSI.UPC.EDU", "FERRAN.MAZZANTI@UPC.EDU", "JDELGADO@LSI.UPC.EDU"], "sections": [{"heading": null, "text": "Restricted Boltzmann Machines (RBMs) are generally unattended learning devices for generative models of data distributions. RBMs are often trained using the Contrastive Divergence Learning Algorithm (CD), an approximation of the course of data logging probability. Often, a simple reconstruction error is used to determine whether the approach by the CD algorithm is good enough, although several authors (Schulz et al., 2010; Fischer & Igel, 2010) have expressed doubts about the feasibility of this method. However, not many alternatives to the reconstruction error have been used in the literature. In this manuscript, we examine simple alternatives to the reconstruction error in order to determine the reduction of log probability during learning as quickly as possible."}, {"heading": "1. Introduction", "text": "Learning algorithms for deep multi-layered neural networks have long been known (Rumelgio et al., 1986), although none of them has been widely used to solve large-scale real-world problems. However, 2006, Deep Belief Networks (DBNs) (Hinton et al., 2006) proved to be a real breakthrough in this area, as the proposed learning algorithms were ultimately a viable and practical method of building these networks, with spectacular results (Hinton & Salakhutdinov, 2006; Larochelle et al., 2009; Lee et al., 2009; Le et al., 2012). DBNs have limited Boltzmann machines (RBMs, 1986) as their buildingblocks. RBMs are topologically constrained Boltzmann machines (BMs) with two layers, one of hidden and another of visible neurons, and no intra-layered connections."}, {"heading": "2. Learning in Restricted Boltzmann Machines", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Energy-based Probabilistic Models", "text": "Energy-based probability models define a probability distribution from an energy function as follows: P (x, h) = e \u2212 energy (x, h) Z, (1) where x stands for visible variables and h are hidden variables (typically binary) that are introduced to increase the meaningfulness of the model. Normalization factor Z is called a partition function and readsZ = x, h e \u2212 energy (x, h), but the evaluation of the partition function Z is mathematically prohibitive because it involves an exponentially large number of terms. The energy function depends on several parameters that are adjusted during the learning phase, by maximizing the probability of the data. In energy-based models, the derivation of the log probability can be called \u2212 logical (P) Asia-Asian phase, which is adjusted during the learning phase."}, {"heading": "2.2. Restricted Boltzmann Machines", "text": "Restricted Boltzmann machines are energy-based probability models whose energy function is as follows: energy (x, h) = \u2212 btx \u2212 cth \u2212 htWx. (5) RBMs form the core of DBNs (Hinton et al., 2006) and other deep architectures that use RBMs for unsupervised pre-training prior to the supervised step. (Hinton & Salakhutdinov, 2006; Bengio et al., 2007; Larochelle et al., 2009) As a consequence of the special form of energy function, both P (h | x) and P (x | h) are factored into RBMs. In this way, it is possible to calculate P (h | x) and P (x | h) in one step, which allows Gibbs sampling to be performed efficiently (Geman & Geman, 1984), which can be the basis for calculating an approximation of the derivation of the protocol probability (4)."}, {"heading": "2.3. Contrastive Divergence", "text": "The most common learning algorithm for RBMs uses an algorithm to estimate the derivative of the protocol probability of an expert model called CD (Hinton, 2002).The algorithm for CDn estimates the derivative of the log probability as \u2212 \u2202 logP (x1; \u03b8) \u2202 \u03b8'E P (h | x1) [\u2202 Energy (x1, h) \u2202 \u03b8] \u2212 EP (h | xn + 1) [\u2202 Energy (xn + 1, h). (6) where xn + 1 is the last sample from the Gibbs chain proceeding from x1 to n steps: h1 \u0445 P (h | x1) x2 \u0445 P (x | h1)... hn \u00b2 P (h | xn) xn + 1 \u0445 P (x | hn).For binary RBMs, E P (h | x) [overseas Energy (x, h) \u0445 P (x | h1)... hn \u00b2 P (h | xn) + x1 hn (x)."}, {"heading": "2.4. Monitoring the Learning Process in RBMs", "text": "Since RBMs are probability models, the reconstruction error of a data point x (i) is calculated as the probability of x (i), which is considered a reconstruction error due to the expected value of h for x (i): R (x (i)) = P (x (i) | E [h | x (i)]."}, {"heading": "3. Proposed Stopping Criteria", "text": "The idea behind this is that the standard rule used during learning depends on the evaluation of the positive and negative phases; the positive phase tends to decrease the probability of the states in relation to the training data (hence), while the negative phase of the states in relation to the training data increases, while the negative phase tends to increase."}, {"heading": "4. Experiments", "text": "In fact, it is such that it is a matter of a way in which people move in the most diverse areas of life, in which they move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "5. Conclusion", "text": "Based on the fact that learning attempts to increase the contribution of the states concerned and reduce the rest, two new estimators based on the ratio of two probabilities have been proposed and discussed as an alternative to the reconstruction error. It has been shown that the better estimator obtained by replacing the value of the (binary) hidden units h with 1 \u2212 h may eventually be able to monitor the actual behavior of the logality probability of the model without additional computational costs. This estimator works well for CD1, but for CD10, which is thought to provide better learning results at the expense of a linear increase in computational costs. We believe that the use of the estimator presented here in CD1 learning problems leads to a later stop criterion for the learning algorithm that provides qualitatively compatible results with those obtained in standard CDn learning for moderate n."}, {"heading": "Acknowledgments", "text": "JD: This work was partially supported by the MICINN project TIN2011-27479-C04-03 (BASMATI) and by SGR20091428 (LARCA).FM: This work was supported by funding number FIS201125275 of the DGI (Spain) and funding number 2009-SGR1003 of the Generalitat de Catalunya (Spain).ER: This research is partially funded by the Spanish research project TIN2012-31377."}], "references": [{"title": "Learning deep architectures for AI", "author": ["Y. Bengio"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Bengio,? \\Q2009\\E", "shortCiteRegEx": "Bengio", "year": 2009}, {"title": "Justifying and Generalizing Contrastive Divergence", "author": ["Y. Bengio", "O. Delalleau"], "venue": "Neural Computation,", "citeRegEx": "Bengio and Delalleau,? \\Q2009\\E", "shortCiteRegEx": "Bengio and Delalleau", "year": 2009}, {"title": "Greedy Layer-wise Training of Deep Networks", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle"], "venue": "In Advances in Neural Information Processing (NIPS\u201906),", "citeRegEx": "Bengio et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2007}, {"title": "On Contrastive Divergence Learning", "author": ["M.A. Carreira-Perpi\u00f1\u00e1n", "G.E. Hinton"], "venue": "In International Workshop on Artificial Intelligence and Statistics,", "citeRegEx": "Carreira.Perpi\u00f1\u00e1n and Hinton,? \\Q2005\\E", "shortCiteRegEx": "Carreira.Perpi\u00f1\u00e1n and Hinton", "year": 2005}, {"title": "Empirical Analysis of the Divergence of Gibbs Sampling Based Learning Algorithms for Restricted Boltzmann Machines", "author": ["A. Fischer", "C. Igel"], "venue": "In International Conference on Artificial Neural Networks (ICANN),", "citeRegEx": "Fischer and Igel,? \\Q2010\\E", "shortCiteRegEx": "Fischer and Igel", "year": 2010}, {"title": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images", "author": ["S. Geman", "D. Geman"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence,", "citeRegEx": "Geman and Geman,? \\Q1984\\E", "shortCiteRegEx": "Geman and Geman", "year": 1984}, {"title": "Training Products of Experts by Minimizing Contrastive Divergence", "author": ["G.E. Hinton"], "venue": "Neural Computation,", "citeRegEx": "Hinton,? \\Q2002\\E", "shortCiteRegEx": "Hinton", "year": 2002}, {"title": "Reducing the Dimensionality of Data with", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Neural Networks. Science,", "citeRegEx": "Hinton and Salakhutdinov,? \\Q2006\\E", "shortCiteRegEx": "Hinton and Salakhutdinov", "year": 2006}, {"title": "A Fast Learning Algorithm for Deep Belief Nets", "author": ["G.E. Hinton", "S. Osindero", "Y. Teh"], "venue": "Neural Computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Exploring Strategies for Training Deep Neural Networks", "author": ["H. Larochelle", "Y. Bengio", "J. Lourador", "P. Lamblin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Larochelle et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Larochelle et al\\.", "year": 2009}, {"title": "Building High-level Features Using Large Scale Unsupervised Learning", "author": ["Q.V. Le", "M.A. Ranzato", "R. Monga", "M. Devin", "K. Chen", "G.S. Corrado", "A.Y. Ng"], "venue": "In 29th International Conference on Machine Learning,", "citeRegEx": "Le et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Le et al\\.", "year": 2012}, {"title": "Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng"], "venue": "In International Conference on Machine Learning, pp", "citeRegEx": "Lee et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2009}, {"title": "Investigating Convergence of Restricted Boltzmann Machine Learning", "author": ["H. Schulz", "A. M\u00fcller", "S. Behnke"], "venue": "In NIPS 2010 Workshop on Deep Learning and Unsupervised Feature Learning,", "citeRegEx": "Schulz et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Schulz et al\\.", "year": 2010}, {"title": "Information Processing in Dynamical Systems: Foundations of Harmony Theory", "author": ["P. Smolensky"], "venue": "Parallel Distributed Processing: Explorations in the Microstructure of Cognition (vol", "citeRegEx": "Smolensky,? \\Q1986\\E", "shortCiteRegEx": "Smolensky", "year": 1986}, {"title": "Training Restricted Boltzmann Machines using Approximations to the Likelihood Gradient", "author": ["T. Tieleman"], "venue": "In 25th International Conference on Machine Learning,", "citeRegEx": "Tieleman,? \\Q2008\\E", "shortCiteRegEx": "Tieleman", "year": 2008}, {"title": "Using Fast Weights to Improve Persistent Contrastive Divergence", "author": ["T. Tieleman", "G.E. Hinton"], "venue": "In 26th International Conference on Machine Learning,", "citeRegEx": "Tieleman and Hinton,? \\Q2009\\E", "shortCiteRegEx": "Tieleman and Hinton", "year": 2009}, {"title": "The Convergence of Contrastive Divergence", "author": ["A. Yuille"], "venue": "In Advances in Neural Information Processing Systems (NIPS\u201904),", "citeRegEx": "Yuille,? \\Q2005\\E", "shortCiteRegEx": "Yuille", "year": 2005}], "referenceMentions": [{"referenceID": 12, "context": "A simple reconstruction error is often used to decide whether the approximation provided by the CD algorithm is good enough, though several authors (Schulz et al., 2010; Fischer & Igel, 2010) have raised doubts concerning the feasibility of this procedure.", "startOffset": 148, "endOffset": 191}, {"referenceID": 8, "context": "In 2006, Deep Belief Networks (DBNs) (Hinton et al., 2006) came out as a real breakthrough in this field, since the learning algorithms proposed ended up being a feasible and practical method to train these networks, with spectacular results (Hinton & Salakhutdinov, 2006; Larochelle et al.", "startOffset": 37, "endOffset": 58}, {"referenceID": 9, "context": ", 2006) came out as a real breakthrough in this field, since the learning algorithms proposed ended up being a feasible and practical method to train these networks, with spectacular results (Hinton & Salakhutdinov, 2006; Larochelle et al., 2009; Lee et al., 2009; Le et al., 2012).", "startOffset": 191, "endOffset": 281}, {"referenceID": 11, "context": ", 2006) came out as a real breakthrough in this field, since the learning algorithms proposed ended up being a feasible and practical method to train these networks, with spectacular results (Hinton & Salakhutdinov, 2006; Larochelle et al., 2009; Lee et al., 2009; Le et al., 2012).", "startOffset": 191, "endOffset": 281}, {"referenceID": 10, "context": ", 2006) came out as a real breakthrough in this field, since the learning algorithms proposed ended up being a feasible and practical method to train these networks, with spectacular results (Hinton & Salakhutdinov, 2006; Larochelle et al., 2009; Lee et al., 2009; Le et al., 2012).", "startOffset": 191, "endOffset": 281}, {"referenceID": 13, "context": "DBNs have Restricted Boltzmann Machines (RBMs) (Smolensky, 1986) as their building blocks.", "startOffset": 47, "endOffset": 64}, {"referenceID": 0, "context": "This property makes working with RBMs simpler than with regular BMs, and in particular the stochastic computation of the log-likelihood gradient may be performed more efficiently by means of Gibbs sampling (Bengio, 2009).", "startOffset": 206, "endOffset": 220}, {"referenceID": 6, "context": "In 2002, the Contrastive Divergence learning algorithm (CD) was proposed as an efficient training method for product-of-expert models, from which RBMs are a special case (Hinton, 2002).", "startOffset": 170, "endOffset": 184}, {"referenceID": 2, "context": "This fact was important for deep learning since some authors suggested that a multi-layer deep neural network is better trained when each layer is pre-trained separately as if it were a single RBM (Hinton & Salakhutdinov, 2006; Bengio et al., 2007; Larochelle et al., 2009).", "startOffset": 197, "endOffset": 273}, {"referenceID": 9, "context": "This fact was important for deep learning since some authors suggested that a multi-layer deep neural network is better trained when each layer is pre-trained separately as if it were a single RBM (Hinton & Salakhutdinov, 2006; Bengio et al., 2007; Larochelle et al., 2009).", "startOffset": 197, "endOffset": 273}, {"referenceID": 16, "context": "Despite CD being an approximation of the true log-likelihood gradient (Bengio & Delalleau, 2009), it is biased and it may not converge in some cases (Carreira-Perpi\u00f1\u00e1n & Hinton, 2005; Yuille, 2005; MacKay, 2001).", "startOffset": 149, "endOffset": 211}, {"referenceID": 14, "context": "Moreover, it has been observed that CD, and variants such as Persistent CD (Tieleman, 2008) or Fast Persistent CD (Tieleman & Hinton, 2009) can lead to a steady decrease of the log-likelihood during learning (Fischer & Igel, 2010; Desjardins et al.", "startOffset": 75, "endOffset": 91}, {"referenceID": 12, "context": "AIS seems to work better than reconstruction error in some cases, though it my also fail (Schulz et al., 2010).", "startOffset": 89, "endOffset": 110}, {"referenceID": 8, "context": "RBMs are at the core of DBNs (Hinton et al., 2006) and other deep architectures that use RBMs to unsupervised pre-training previous to the supervised step (Hinton & Salakhutdinov, 2006; Bengio et al.", "startOffset": 29, "endOffset": 50}, {"referenceID": 2, "context": ", 2006) and other deep architectures that use RBMs to unsupervised pre-training previous to the supervised step (Hinton & Salakhutdinov, 2006; Bengio et al., 2007; Larochelle et al., 2009).", "startOffset": 112, "endOffset": 188}, {"referenceID": 9, "context": ", 2006) and other deep architectures that use RBMs to unsupervised pre-training previous to the supervised step (Hinton & Salakhutdinov, 2006; Bengio et al., 2007; Larochelle et al., 2009).", "startOffset": 112, "endOffset": 188}, {"referenceID": 6, "context": "The most common learning algorithm for RBMs uses an algorithm to estimate the derivative of the log-likelihood of a Product of Experts model called CD (Hinton, 2002).", "startOffset": 151, "endOffset": 165}, {"referenceID": 14, "context": "Several alternatives to CDn are Persistent CD (PCD) (Tieleman, 2008), Fast PCD (FPCD) (Tieleman & Hinton, 2009) or Parallel Tempering (PT) (Desjardins et al.", "startOffset": 52, "endOffset": 68}, {"referenceID": 12, "context": "Some authors have shown that it may happen that learning induces an undesirable decrease in likelihood that goes undetected by the reconstruction error (Schulz et al., 2010; Fischer & Igel, 2010).", "startOffset": 152, "endOffset": 195}], "year": 2014, "abstractText": "Restricted Boltzmann Machines (RBMs) are general unsupervised learning devices to ascertain generative models of data distributions. RBMs are often trained using the Contrastive Divergence learning algorithm (CD), an approximation to the gradient of the data log-likelihood. A simple reconstruction error is often used to decide whether the approximation provided by the CD algorithm is good enough, though several authors (Schulz et al., 2010; Fischer & Igel, 2010) have raised doubts concerning the feasibility of this procedure. However, not many alternatives to the reconstruction error have been used in the literature. In this manuscript we investigate simple alternatives to the reconstruction error in order to detect as soon as possible the decrease in the log-likelihood during learning. Proceedings of the 2 International Conference on Learning Representations, Banff, Canada, 2014. Copyright 2014 by the author(s).", "creator": "TeX"}}}