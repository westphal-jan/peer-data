{"id": "1312.6171", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2013", "title": "Learning Paired-associate Images with An Unsupervised Deep Learning Architecture", "abstract": "This paper presents an unsupervised multi-modal learning system that learns associative representation from two input modalities (channels) such that input on one channel will correctly generate the associated response at the other channel and vice versa. In this way, the system develops a kind of supervised classification model meant to simulate aspects of human associative memory. The system uses a deep learning architecture (DLA) composed of two input/output channels formed from stacked Restricted Boltzmann Machines (RBM) and an associative memory network that combines the two channels. The DLA is trained on pairs of MNIST handwritten digit images to develop hierarchical features and associative representations that are able to reconstruct one image given its paired-associate. Experiments show that the multi-modal learning system generates models that are as accurate as back-propagation networks but with the advantage of unsupervised learning from either paired or non-paired training examples.", "histories": [["v1", "Fri, 20 Dec 2013 23:07:25 GMT  (320kb,D)", "https://arxiv.org/abs/1312.6171v1", "9 pages, for ICLR-2014"], ["v2", "Fri, 10 Jan 2014 23:19:26 GMT  (336kb,D)", "http://arxiv.org/abs/1312.6171v2", "9 pages, for ICLR-2014"]], "COMMENTS": "9 pages, for ICLR-2014", "reviews": [], "SUBJECTS": "cs.NE cs.CV cs.LG", "authors": ["ti wang", "daniel l silver"], "accepted": false, "id": "1312.6171"}, "pdf": {"name": "1312.6171.pdf", "metadata": {"source": "CRF", "title": "Learning Paired-associate Images with An Unsupervised Deep Learning Architecture", "authors": [], "emails": ["danny.silver@acadiau.ca"], "sections": [{"heading": "1 Introduction", "text": "People learn knowledge from the environment through data provided in multiple forms, or modalities such as LA chaep networks. Psychologists define multimodal learning as learning from multiple sensory modalities [11]. Researchers have shown that people's understanding of new concepts is enhanced through multimodal knowledge representations [10]. The human brain has adapted to merge associated sensory signals in order to learn more effectively and efficiently. The long-term goal of this research is to develop a learning system that simulates aspects of human multimodal learning ability. In particular, we are investigating unsupervised learning methods that can create a model that allows generalization and classification from one input or output modality to another (e.g. from visual to verbal). We are interested in how this can be done without relying on any form of supervised learning that suffers from the need to work exemplarily."}, {"heading": "2 Background", "text": "Artificial neural networks (ANNs) are often used to solve classification problems such as image and speech recognition, but many do not work in the same way as the human nervous system. ANNs for retransmission are good for modeling complex mapping relationships between input and output data, but not so good for reconstructing or recalling a pattern. Humans have the ability to recover complete information from partial information; this is called associative memory [4]. When a child watches a tennis game, he learns the look of the tennis ball and the racket. The next time the child sees an image of a tennis ball, he can remember an image of a racket and the game. Associative ANNs are clearly an important part of learning about the world.Associative ANNs are inspired by cognitive psychology and are designed to mimic the way in which collections of biological neurons can store associative memories and retrieve associative patterns from the brain. [12]"}, {"heading": "2.1 Restricted Boltzmann Machine", "text": "A restricted Boltzmann machine (RBM) is a variant of a BM that is designed to overcome long training times by limiting the number of connections in its network and using a modified learning algorithm. RBMs have both visible and hidden layers of neurons just like BMs, but there are no intralayer connections, so they can be characterized as two-part graphics (see Figure 1). If they agree on an equilibrium, neurons hj turn on with the probability pj = 11 + exp (\u2212 bj), and Neuronvi turns on with the probability pi = 11 + exp."}, {"heading": "2.2 Deep Learning Architectures", "text": "Humans tend to organize ideas and concepts hierarchically [5]. Abstract concepts are learned and retrieved through the composition of simpler concepts [1]. This approach makes sense in a world where most objects consist of parts that in turn consist of smaller features. For example, a car is a combination of smaller parts such as wheels and frames, and a wheel consists of smaller features such as a tire and a rim. Neuroscientific studies have confirmed that this compositional structure can be seen in the human nervous system. Mammalian brain uses a deep learning architecture with multiple levels of abstraction corresponding to different areas of the neocortex [14]. Deep learning architectures, or DLA, are a sub-area of machine learning that places great emphasis on hierarchical composition and unsupervised learning methods. DLAs can be developed by superimposing layers of RBMs."}, {"heading": "3 Multi-modal Learning Using an Unsupervised DLA", "text": "The aim of this research is to develop a learning system that can store and retrieve multi-channel data using an associative memory network. The learning system should be able to retrieve the pattern of the associative network using one sensory modality and given data from another sensory modality. The long-term goal of our research is to create a system that can learn concepts using two or more sensory / motor modalities such as audio, optics and voice (see Figure 3)."}, {"heading": "3.1 Learning Paired-Associate Images", "text": "Consider the problem of learning paired-associated images on two input modalities (channels). We propose to use a DLA network that, after training, will be able to produce a paired image on one channel when prompted with an image on another channel. We suggest the process to simulate human sensory modalities and associative memory and to provide insights into how classifications can be performed using an unattended learning approach. The learning system consists of two main parts, an associative memory network and two associative sensory channel networks (see Figure 4). Sensory channel networks are designed for the recognition and reconstruction of sensory data. The associative memory network binds the sensory channel networks together and simulates human associative memory. Both parts can be constructed using reduced representation, the memory capacity of an RBM is not as highly connected as one half is found to be."}, {"heading": "3.2 Impact of Learning Non-paired Patterns", "text": "In this case, the \"meow\" is the audio signal and the image of the cat is the visual signal. These two sensory channels can come together to enable paired associated learning, but their individual channel representations can be learned and improved separately. We suggest that learning each sensory modality with paired-free examples will help improve the ability of associative memory to produce the correct image on one channel when it is given on the other associated. It would be instructive to conduct an experiment to test the effects on the multi-channel learning system by training the sensory channels separately with paired-free examples."}, {"heading": "4 Empirical Studies", "text": "Three empirical studies were conducted with two different datasets: the first and third experiments used paired images from the MNIST dataset of handwritten numerals; the second experiment used paired images from a synthetic dataset of numerals. In all experiments, five pairs of odd and even numbers were assigned: 1-2, 3-4, 5-6, 7-8, 9-0."}, {"heading": "4.1 Experiment 1", "text": "The aim of this experiment is to compare the unmonitored DLA layers."}, {"heading": "4.2 Experiment 2", "text": "The aim of this experiment is to develop autoassociative models that can overcome noise in synthetic training examples. An unattended DLA with BP ANNs at the back and monitored is developed from a smoked data set and the quality of their regenerated images is compared. The first 100 of these images are used as a training set containing five different sets of 10 x 5 repaired images from Figure 8. 10% random noise was added to each template image to produce 60 instances of each category, or a total of 300. The first 100 of these images are used as a training set, the next 100 are used as a validation set, while the remaining 100 are used as a test set. The DLA architecture is used in accordance with the previous experiment to develop an unattended learning model."}, {"heading": "4.3 Experiment 3", "text": "The aim of this experiment, in accordance with Section 3.2, is to develop an associative learning system with both associated examples, designed to test whether the performance of an associative learning system can be improved by separately training the sensory channels with unrepaired examples. This experiment uses the database of MNIST examples as in Experiment 1. The experiment is repeated four times with different training sets and test sets. For each repetition, four models are built with the same training examples, the first model being associated with the database of MNIST examples. The experiment is repeated four times with different training sets, validation and test sets."}, {"heading": "5 Conclusion", "text": "Our long-term goal is to develop learning systems that are capable of learning conceptual representations from multiple sensory input and / or motor output modalities in a similar way to humans. We have demonstrated an unattended deep learning architecture (DLA) that can reconstruct an image of a handwritten MNIST number from another paired handwritten number. It develops a kind of supervised classification model that simulates aspects of human associative memory. DLA is formed using stacked Boltzmann machines (RBM) and trained with the Contrastive Divergence (CD) algorithm. RBM, an associative storage network that links the input / output channels, requires refinement with a rear technology to increase memory accuracy when only 50% of its visible neurons are available from one channel."}], "references": [{"title": "Learning deep architectures for ai", "author": ["Yoshua Bengio"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Scaling learning algorithms towards AI", "author": ["Yoshua Bengio", "Yann Lecun"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Binary coding of speech spectrograms using a deep auto-encoder", "author": ["Li Deng", "Michael L. Seltzer", "Dong Yu", "Alex Acero", "Abdel rahman Mohamed", "Geoffrey E. Hinton"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Deep unsupervised feature learning for natural language processing", "author": ["Stephan Gouws"], "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop, NAACL HLT", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Learning multiple layers of representation", "author": ["Geoffrey E. Hinton"], "venue": "Trends in Cognitive Sciences,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "The wake-sleep algorithm for unsupervised neural networks", "author": ["Geoffrey E. Hinton", "Peter Dayan", "Brendan J. Frey", "Radford M. Neal"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1995}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E. Hinton", "Simon Osindero"], "venue": "Neural Computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Parallel distributed processing: explorations in the microstructure of cognition, vol. 1. chapter Learning and relearning in Boltzmann machines, pages 282\u2013317", "author": ["Geoffrey E. Hinton", "Terrence J. Sejnowski"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1986}, {"title": "Multimedia Learning", "author": ["Richard.E. Mayer"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Mental representations", "author": ["Allan. Paivio"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1990}, {"title": "Neural associative memories and sparse coding", "author": ["G. Nther Palm"], "venue": "Neural Netw.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Sparse feature learning for deep belief networks", "author": ["Marc\u2019Aurelio Ranzato", "Y lan Boureau", "Yann Lecun"], "venue": "In NIPS-2007,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "A quantitative theory of immediate visual recognition", "author": ["Thomas Serre", "Gabriel Kreiman", "Minjoon Kouh", "Charles Cadieu", "Ulf Knoblich", "Tomaso Poggio"], "venue": "Prog Brain Res,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Multimodal learning with deep boltzmann machines", "author": ["Nitish Srivastava", "Ruslan Salakhutdinov"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Classification Via Reconstruction Using A Multi-Channel Deep Learning Architecture", "author": ["Ti Wang"], "venue": "Masters Thesis,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}], "referenceMentions": [{"referenceID": 9, "context": "Psychologists define multi-modal learning as learning new knowledge from multiple sensory modalities [11].", "startOffset": 101, "endOffset": 105}, {"referenceID": 8, "context": "Researchers have shown that people\u2019s understanding of new concepts is enhanced with mixed-modality knowledge representations [10].", "startOffset": 125, "endOffset": 129}, {"referenceID": 4, "context": "Deep learning is a sub-area of machine learning, which typically uses Restricted Boltzmann Machines (RBM), a type of stochastic associative artificial neural network (ANN), to develop a multilayer generative models [6].", "startOffset": 215, "endOffset": 218}, {"referenceID": 0, "context": "Deep learning architectures, or DLA, provide an exciting new substrate upon which to explore new computational and representational models of how knowledge can be acquired, consolidated and used [1].", "startOffset": 195, "endOffset": 198}, {"referenceID": 6, "context": "Prior work has investigated the use of DLAs and unsupervised learning methods to develop models for a variety of purposes including auto-associative memory, pattern completion, and clustering as well as generalization and classification [8].", "startOffset": 237, "endOffset": 240}, {"referenceID": 10, "context": "Associative ANNs are inspired by cognitive psychology and are designed to mimic the way that collections of biological neurons may store and recall associative memories [12].", "startOffset": 169, "endOffset": 173}, {"referenceID": 6, "context": "RBMs have both visible and hidden layers of neurons just like BMs, however there are no intralayer connections, so they can be characterized as a bipartite graph (see Figure 1) [8].", "startOffset": 177, "endOffset": 180}, {"referenceID": 7, "context": "i \u2211 j vihjwij where bi and bj are the bias terms for their respective nodes [9].", "startOffset": 76, "endOffset": 79}, {"referenceID": 6, "context": "The method of weight update we use for this research is called Contrastive Divergence, or CD [8].", "startOffset": 93, "endOffset": 96}, {"referenceID": 3, "context": "Humans tend to organize ideas and concepts hierarchically [5].", "startOffset": 58, "endOffset": 61}, {"referenceID": 0, "context": "Abstract concepts are learned and recalled through the composition of simpler concepts [1].", "startOffset": 87, "endOffset": 90}, {"referenceID": 12, "context": "The mammalian brain uses a deep learning architecture with multiple levels of abstraction corresponding to different areas of the neocortex [14].", "startOffset": 140, "endOffset": 144}, {"referenceID": 6, "context": "DLAs can be developed by stacking layers of RBMs one on top of another [8].", "startOffset": 71, "endOffset": 74}, {"referenceID": 4, "context": "They have been successfully used to develop models for recognizing hand-writing images of digits in a manner that simulates the human visual cortex [6] RBM-based DLA systems are capable of doing unsupervised clustering of unlabeled data based on a hierarchy of features.", "startOffset": 148, "endOffset": 151}, {"referenceID": 0, "context": "As shown in Figure 2, the hidden layer of one RBM can be used as the input layer for a higher level RBM [1].", "startOffset": 104, "endOffset": 107}, {"referenceID": 2, "context": "Deep architectures can be used as an autoencoder to model high-dimensional data, such as images and audio [3].", "startOffset": 106, "endOffset": 109}, {"referenceID": 1, "context": "Bengio reports that deep architectures are more expressive than shallow ones by analyzing the depth-breadth trade-off of architecture representation [2].", "startOffset": 149, "endOffset": 152}, {"referenceID": 0, "context": "Perhaps most importantly, deep learning methods learn representative hierarchies directly from the data [1].", "startOffset": 104, "endOffset": 107}, {"referenceID": 11, "context": "This is in contrast to approaches such as convolutional networks that use receptive fields and modified back-propagation methods that rely heavily on known topological characteristics of the input space [13].", "startOffset": 203, "endOffset": 207}, {"referenceID": 14, "context": "We have determined that an RBM is unable to recall patterns when only half of the visible neurons are given correct pattern values [16].", "startOffset": 131, "endOffset": 135}, {"referenceID": 4, "context": "As per Hinton, the weights of the network require fine tuning [6].", "startOffset": 62, "endOffset": 65}, {"referenceID": 5, "context": "To protect the accuracy of the generative model, it is necessary to untie the weights between the top layer of each channel and the associative memory network layer and create two sets of weights - recognition weights and generative weights (see Figure 5) [7, 8].", "startOffset": 256, "endOffset": 262}, {"referenceID": 6, "context": "To protect the accuracy of the generative model, it is necessary to untie the weights between the top layer of each channel and the associative memory network layer and create two sets of weights - recognition weights and generative weights (see Figure 5) [7, 8].", "startOffset": 256, "endOffset": 262}, {"referenceID": 13, "context": "With back-fitting, the multi-modal DLA should be able to achieve the learning goal that was previously done with supervised learning by Srivastava [15].", "startOffset": 147, "endOffset": 151}, {"referenceID": 6, "context": "Hidden layers 1 and 1\u2019 and then layers 2 and 2\u2019 will develop more abstract features of the original images [8].", "startOffset": 107, "endOffset": 110}, {"referenceID": 6, "context": "15% errors [8].", "startOffset": 11, "endOffset": 14}, {"referenceID": 0, "context": "The RMSE between the pixels of each reconstructed image and its corresponding template (without noise) was computed to give an average error over all examples (image pixels are normalized to the range [0,1]).", "startOffset": 201, "endOffset": 206}], "year": 2014, "abstractText": "This paper presents an unsupervised multi-modal learning system that learns associative representation from two input modalities, or channels, such that input on one channel will correctly generate the associated response at the other and vice versa. In this way, the system develops a kind of supervised classification model meant to simulate aspects of human associative memory. The system uses a deep learning architecture (DLA) composed of two input/output channels formed from stacked Restricted Boltzmann Machines (RBM) and an associative memory network that combines the two channels. The DLA is trained on pairs of MNIST handwritten digit images to develop hierarchical features and associative representations that are able to reconstruct one image given its paired-associate. Experiments show that the multi-modal learning system generates models that are as accurate as back-propagation networks but with the advantage of a bi-directional network and unsupervised learning from either paired or non-paired training examples.", "creator": "LaTeX with hyperref package"}}}