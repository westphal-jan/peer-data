{"id": "1312.6180", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2013", "title": "Manifold regularized kernel logistic regression for web image annotation", "abstract": "With the rapid advance of Internet technology and smart devices, users often need to manage large amounts of multimedia information using smart devices, such as personal image and video accessing and browsing. These requirements heavily rely on the success of image (video) annotation, and thus large scale image annotation through innovative machine learning methods has attracted intensive attention in recent years. One representative work is support vector machine (SVM). Although it works well in binary classification, SVM has a non-smooth loss function and can not naturally cover multi-class case. In this paper, we propose manifold regularized kernel logistic regression (KLR) for web image annotation. Compared to SVM, KLR has the following advantages: (1) the KLR has a smooth loss function; (2) the KLR produces an explicit estimate of the probability instead of class label; and (3) the KLR can naturally be generalized to the multi-class case. We carefully conduct experiments on MIR FLICKR dataset and demonstrate the effectiveness of manifold regularized kernel logistic regression for image annotation.", "histories": [["v1", "Sat, 21 Dec 2013 00:32:24 GMT  (1262kb)", "http://arxiv.org/abs/1312.6180v1", "submitted to Neurocomputing"]], "COMMENTS": "submitted to Neurocomputing", "reviews": [], "SUBJECTS": "cs.LG cs.MM", "authors": ["w liu", "h liu", "d tao", "y wang", "k lu"], "accepted": false, "id": "1312.6180"}, "pdf": {"name": "1312.6180.pdf", "metadata": {"source": "CRF", "title": "Manifold regularized kernel logistic regression for web image annotation", "authors": ["W. Liu", "H. Liu", "Y. Wang", "K. Lu"], "emails": [], "sections": [{"heading": null, "text": "With the rapid advancement of Internet technology and smart devices, users often need to manage large volumes of multimedia information using smart devices, such as personal image and video access and surfing. These requirements depend heavily on the success of image (video) annotation, and therefore large-scale image annotation has attracted intense attention through innovative methods of machine learning in recent years. A representative piece of work is the support of the vector engine (SVM). Although it works well in binary classification, SVM has the following advantages: (1) the KLR has a smooth loss function and cannot naturally cover multi-class cases; (2) the KLR produces an explicit estimate of probability instead of class designation; and (3) the KLR can, of course, be generalized to multi-class cases."}, {"heading": "1. Introduction", "text": "In fact, it is not easy to manage the photos and videos at the semantic level, and that is why it is necessary that the methods mentioned in recent years attract attention, and that they are able to be able to be e-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-e-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-e-mail E-mail E-mail E-mail E-e-e-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-mail E-e-e-mail E-mail E-mail E-e-e-mail E-mail E-mail E-e-e-e-e-mail E-e-e-mail E-mail E-mail E-mail E-e-e-mail E-e-e-mail E-e-e-e-e-e-e-e-mail E-"}, {"heading": "2. Related work", "text": "In recent years, many algorithms have been proposed for multimedia retrieval, including image captions / classifications, video indexing and 3D object descriptions, etc. In short, the associated image / video captioning methods can be divided into three categories based on the machine-based leaning schemes used, which are unsupervised, supervised and semi-supervised. Unsupervised learning methods use unsupervised machine learning methods such as non-negative matrix factorization [3], which group [10] to comment on images / videos. Supervised leaning methods such as support vector machines [13] are aimed at determining the relationship between labels and visual features. In view of the growing number of samples, some active learning methods are being introduced [14] to interactively select only effective samples for labeling. Considering the high user effort of labeling, semi-supervised learning methods use both a small number of labeled samples and a large number of labeled samples in general, as well as a short number of labeled samples."}, {"heading": "3. Manifold regularized kernel logistic regression", "text": "And in the second half of the second half of the second half of the second half of the second half of the second half of the second half of the second half of the second half, in the first two thirds of the second half, in the second half of the second half, in the second half of the second half, in the second half of the second half, in the third, in the third, and in the third, and in the third, and in the third, and in the fourth, and in the third, and in the fourth, and in the third, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the fourth, and in the third, and in the third, and in the third, and in the second half, and in the second half of the second half of the second half, and in the second half of the second half of the second half, and in the second half, and in the second half, and in the second half of the second half of the second half of the second half, and in the second half of the second half, and in the second half, and in the second half, and in the second half, and in the second half, and in the second half, and in the second half, and in the second half, and in the second half, and in the second half, in the second half, and in the second half, in the second half, in the second half, in the second half, in the second half, and in the second half, in the second half, and in the second half, in the second half, in the second half, in the second half, in the second half, and in the second, and in the second half, in the second half, and in the second, in the second, in the second half, in the second, in the second, in the second"}, {"heading": "4. Algorithm", "text": "In this section we use the conjugate gradient algorithm to optimize problem (4).The gradient of the objective function in (4) can be described as follows: Then we have the optimization method of the conjugate gradient algorithm as follows: Step 1: Initialize. Step 2: Do until step 3. Optimizing the problem (4) is efficient and effective due to the smoothing nature of the objective function.The mapping of various loss functions in Figure 1 shows that the logistical loss can achieve an almost equivalent performance to the hinge loss. In the following section we describe the comparison experiments."}, {"heading": "5. Experiments", "text": "To assess the effectiveness of the proposed algorithm, we carefully compile web image annotations to the Flickr datasets [6] offered by the LIACS Medialab at Leiden University, which were introduced by the ACM Committee in 2008. The dataset contains 25,000 images of animals, including people living at night."}, {"heading": "6. Conclusion", "text": "This work studies manifold regularized kernel logistic regression (KLR) for web image annotation 11-2499. Technically, we develop Laplacian regularized kernel logistic regression and implementation image annotation task on MIR Flickr dataset. Compared to the representative SVM classifier, the KLR has a smooth loss function and produce an explicit estimate of probability instead of class label. The carefully conducted experiments demonstrate the effectiveness of manifold regularized kernel logistic regression for image annotation.In the future, we will introduce the proposed Laplacian regularized kernel logistic regression to other applications. We will also further extend the proposed method to other mannifold regularizations and explore the relationship of the different regularizations.Reference [1] M. Belkin, P. Niyogi, and V. Sindhwan i. \"Manifold regularization: A geometricframework for learning from labeled and uneled examples."}], "references": [{"title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples", "author": ["M. Belkin", "P. Niyogi", "V. Sindhwan i"], "venue": "J. Mach. Learn. Res. vol. 7, no. 11, pp. 2399\u20132434, Nov. 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "NeNMF: An Optimal Gradient Method for Nonnegative Matrix Factorization", "author": ["Naiyang Guan", "Dacheng Tao", "Zhigang Luo", "Bo Yuan"], "venue": "IEEE Transactions on Signal Processing", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Non-negative patch alignment framework", "author": ["N. Guan", "D. Tao", "Z. Luo", "B. Yuan"], "venue": "IEEE Trans. Neural Netw. , vol. 22, no. 8, pp. 1218\u20131230, Aug. 2011", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Multimodal semi-supervised learning for image classification", "author": ["M. Guillaumin", "J. Verbeek", "C. Schmid"], "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jul. 2010, pp. 902\u2013909.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "The MIR flickr retrieval evaluation", "author": ["M.J. Huiskes", "M.S. Lew"], "venue": "Proc. 1st ACM Int. Conf. Multimedia Inf. Retr., 2008, pp. 39\u201343.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Multiview Hessian Regularization for Image  Annotation", "author": ["Weifeng Liu", "Dacheng Tao"], "venue": "IEEE Transactions on Image Processing, vol. 22, pp. 2676 - 2687, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Multiview Hessian Discriminative Sparse Coding for Image Annotation", "author": ["Weifeng Liu", "Dacheng Tao", "Jun Cheng", "Yuanyan Tang"], "venue": "Computer Vision and Image Understanding, 2013.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Manifold Regularized Multitask Learning for Semi-Supervised Multilabel Image Classification", "author": ["Yong Luo", "Dacheng Tao", "Bo Geng", "Chao Xu", "Stephen J. Maybank"], "venue": "IEEE Transactions on Image Processing", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Cluster-Based Landmark and Event Detection for Tagged Photo Collections", "author": ["S. Papadopoulos", "C. Zigkolis", "Y. Kompatsiaris", "A. Vakali"], "venue": "IEEE Multimedia, vol. 18, no. 1, pp. 52-63, 2011", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Induction of Decision Trees", "author": ["J.R. Quinlan"], "venue": "Machine Learning, vol. 1, no. 1, pp. 81-106, 1986.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1986}, {"title": "Asymmetric Bagging and Random Subspace for Support Vector Machines-Based Relevance Feedback in Image Retrieval", "author": ["Dacheng Tao", "Xiaoou Tang", "Xuelong Li", "Xindong Wu"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Interactive Video Indexing With Statistical Active Learning", "author": ["Zheng-Jun Zha", "Meng Wang", "Yan-Tao Zheng", "Yi Yang", "Richang Hong", "Tat-Seng Chua"], "venue": "IEEE Transactions on Multimedia", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Kernel Logistic Regression and the Import Vector  Machine", "author": ["Ji Zhu", "Trevor Hastie"], "venue": "JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2001}, {"title": "Joint multi-label multi-instance learning for image classification", "author": ["Zheng-Jun Zha", "Xian-Sheng Hua", "Tao Mei", "Jingdong Wang", "Guo-Jun Qi", "Zengfu Wang"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}], "referenceMentions": [{"referenceID": 11, "context": "However, it is not convenient to effectively manage the photos or videos at the semantic level, and therefore large scale image/video annotation through innovative machine learning methods has attracted intensive attention in recent years and been successfully deployed for many practical applications in multimedia, computer vision and image processing [14] [16] [17] 0.", "startOffset": 354, "endOffset": 358}, {"referenceID": 13, "context": "However, it is not convenient to effectively manage the photos or videos at the semantic level, and therefore large scale image/video annotation through innovative machine learning methods has attracted intensive attention in recent years and been successfully deployed for many practical applications in multimedia, computer vision and image processing [14] [16] [17] 0.", "startOffset": 364, "endOffset": 368}, {"referenceID": 10, "context": "[12] SVM usually minimizes a hinge loss to train the maximum-margin classifier.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Although hinge loss is a convex function, it is not differentiable and can not naturally be generalized to multi-class cases[15] .", "startOffset": 124, "endOffset": 128}, {"referenceID": 5, "context": "Then semi-supervised learning (SSL) has been employed for semi-automatic image annotation[7] [8] .", "startOffset": 89, "endOffset": 92}, {"referenceID": 6, "context": "Then semi-supervised learning (SSL) has been employed for semi-automatic image annotation[7] [8] .", "startOffset": 93, "endOffset": 96}, {"referenceID": 0, "context": "intrinsic structure of all the training samples including labeled and unlabelled images[1] .", "startOffset": 87, "endOffset": 90}, {"referenceID": 0, "context": "tries to explore the geometry of intrinsic data probability distribution by penalizing the objective function along the potential manifold [1] [4] .", "startOffset": 139, "endOffset": 142}, {"referenceID": 2, "context": "tries to explore the geometry of intrinsic data probability distribution by penalizing the objective function along the potential manifold [1] [4] .", "startOffset": 143, "endOffset": 146}, {"referenceID": 1, "context": "Unsupervised learning methods use unsupervised machine learning methods such as nonnegative matrix factorization [3] , clustering[10] to annotate images/videos.", "startOffset": 113, "endOffset": 116}, {"referenceID": 8, "context": "Unsupervised learning methods use unsupervised machine learning methods such as nonnegative matrix factorization [3] , clustering[10] to annotate images/videos.", "startOffset": 129, "endOffset": 133}, {"referenceID": 9, "context": "Supervised leaning methods such as support vector machines [13] , decision trees[11] aim to find the relationship between labels and visual features.", "startOffset": 80, "endOffset": 84}, {"referenceID": 11, "context": "Considering the growing large amount of samples, some active learning methods [14] are introduced to interactively select only effective samples for labeling.", "startOffset": 78, "endOffset": 82}, {"referenceID": 7, "context": "Considering the heavy user labeling effort, semi-supervised learning methods exploit both a small number of labeled samples and a large number of unlabeled samples to boost the generalization of learning model and receive more and more intensive attention recently [9] .", "startOffset": 265, "endOffset": 268}, {"referenceID": 4, "context": "To evaluate the effectiveness of the proposed algorithm, we carefully conduct web image annotation experiments on the MIR Flickr dataset [6] that is offered by the LIACS Medialab at Leiden University, the Netherlands and introduced by the ACM MIR Committee in 2008 as an ACM sponsored image retrieval evaluation.", "startOffset": 137, "endOffset": 140}, {"referenceID": 3, "context": "In our experiment, we employ GIST descriptor extracted by Guillaumin [5] .", "startOffset": 69, "endOffset": 72}, {"referenceID": 0, "context": "[1] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "2007 [3] Naiyang Guan, Dacheng Tao, Zhigang Luo, Bo Yuan: NeNMF: An Optimal Gradient Method for Nonnegative Matrix Factorization.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "IEEE Transactions on Signal Processing 60(6): 2882-2898 (2012) [4] N.", "startOffset": 63, "endOffset": 66}, {"referenceID": 3, "context": "2011 [5] M.", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "[6] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] Weifeng Liu, Dacheng Tao, \"Multiview Hessian Regularization for Image", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8] Weifeng Liu, Dacheng Tao, Jun Cheng, and Yuanyan Tang, \"Multiview Hessian Discriminative Sparse Coding for Image Annotation,\" Computer Vision and Image Understanding, 2013.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] Yong Luo, Dacheng Tao, Bo Geng, Chao Xu, Stephen J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "IEEE Transactions on Image Processing 22(2): 523-536 (2013) [10] S.", "startOffset": 60, "endOffset": 64}, {"referenceID": 9, "context": "52-63, 2011 [11] J.", "startOffset": 12, "endOffset": 16}, {"referenceID": 10, "context": "[12] Dacheng Tao, Xiaoou Tang, Xuelong Li, Xindong Wu: Asymmetric Bagging and Random Subspace for Support Vector Machines-Based Relevance Feedback in Image Retrieval.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[14] Zheng-Jun Zha, Meng Wang, Yan-Tao Zheng, Yi Yang, Richang Hong, Tat-Seng Chua: Interactive Video Indexing With Statistical Active Learning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "IEEE Transactions on Multimedia 14(1): 17-27 (2012) [15] Ji Zhu and Trevor Hastie, Kernel Logistic Regression and the Import Vector", "startOffset": 52, "endOffset": 56}, {"referenceID": 13, "context": "ACM Multimedia 2009: 15-24 [17] Zheng-Jun Zha, Xian-Sheng Hua, Tao Mei, Jingdong Wang, Guo-Jun Qi, Zengfu Wang: Joint multi-label multi-instance learning for image classification.", "startOffset": 27, "endOffset": 31}], "year": 2013, "abstractText": "With the rapid advance of Internet technology and smart devices, users often need to manage large amounts of multimedia information using smart devices, such as personal image and video accessing and browsing. These requirements heavily rely on the success of image (video) annotation, and thus large scale image annotation through innovative machine learning methods has attracted intensive attention in recent years. One representative work is support vector machine (SVM). Although it works well in binary classification, SVM has a non-smooth loss function and can not naturally cover multi-class case. In this paper, we propose manifold regularized kernel logistic regression (KLR) for web image annotation. Compared to SVM, KLR has the following advantages: (1) the KLR has a smooth loss function; (2) the KLR produces an explicit estimate of the probability instead of class label; and (3) the KLR can naturally be generalized to the multi-class case. We carefully conduct experiments on MIR FLICKR dataset and demonstrate the effectiveness of manifold regularized kernel logistic regression for image annotation.", "creator": "Microsoft\u00ae Office Word 2007"}}}