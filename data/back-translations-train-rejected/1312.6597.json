{"id": "1312.6597", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Dec-2013", "title": "Co-Multistage of Multiple Classifiers for Imbalanced Multiclass Learning", "abstract": "In this work, we propose two stochastic architectural models (CMC and CMC-M) with two layers of classifiers applicable to datasets with one and multiple skewed classes. This distinction becomes important when the datasets have a large number of classes. Therefore, we present a novel solution to imbalanced multiclass learning with several skewed majority classes, which improves minority classes identification. This fact is particularly important for text classification tasks, such as event detection. Our models combined with pre-processing sampling techniques improved the classification results on 6 well-known datasets. Finally, we have also introduced a new metric SG-Mean to overcome the multiplication by zero limitation of G-Mean.", "histories": [["v1", "Mon, 23 Dec 2013 16:52:56 GMT  (118kb,D)", "https://arxiv.org/abs/1312.6597v1", "Preliminary version of the paper"], ["v2", "Fri, 24 Jan 2014 23:09:17 GMT  (126kb,D)", "http://arxiv.org/abs/1312.6597v2", "Preliminary version of the paper"]], "COMMENTS": "Preliminary version of the paper", "reviews": [], "SUBJECTS": "cs.LG cs.IR", "authors": ["luis marujo", "anatole gershman", "jaime carbonell", "david martins de matos", "jo\\~ao p neto"], "accepted": false, "id": "1312.6597"}, "pdf": {"name": "1312.6597.pdf", "metadata": {"source": "CRF", "title": "Co-Multistage of Multiple Classifiers for Imbalanced Multiclass Learning", "authors": [], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Many tasks of multiple-world classification, such as e-mail analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], facial recognition, discriminatory classification [7], text classification [8,9,10], and species distribution [11] may have highly balanced or unbalanced class distribution techniques. Theoretically, a dataset is defined that exhibits an unbalanced distribution when at least one class exhibits an unequal number of instances relative to others. However, the community limits the definition of unbalanced datasets that exhibit high or extreme unbalanced rates. High unbalanced rates are the overarching problem of supervised machine learning algorithms. The first reported work focuses on multiclass imbalances. [12], G-mean metric [13] extends the problem of multiclass-class imbalances to include multi-class learning, whereas the previous problem of cost-sensitive work focused on multiclass imbalances."}, {"heading": "4 Experimental Setup", "text": "The classification results of the various algorithms are calculated using 80% of the data set for education and 20% for the exam. Initial evaluation included two sets of data using the state-of-the-art cost-sensitive AdaC2 method. To this end, we added three additional sets of data from the text classification. Both CMC and CMC-M have a multi-level interaction of several individual classifiers. All classifiers follow an architecture of three classifiers with standard parameter values, except the first. The sequence of classifiers in the multi-level ensembles follows a heuristic, starting with the simplest / weakest classifier and continuing to the most complex / strongest. The current order was determined by the evaluation of each heterogeneous classifier."}, {"heading": "4.1 Datasets", "text": "We started our evaluation with two publicly available datasets in the UCI ML Repository to compare our work with the state of the art [12]. The \"NewThyroid\" dataset is one of the most popular datasets in the UCI ML Repository. It contains 1,728 cases described by 6 nominal ordered attributes. The \"NewThyroid\" dataset was created to predict the thyroid class of patients, corresponding to three classes: euthyroidism (normal), thyroid hypothyroidism and hyperthyroidism. This is a small dataset of 215 examples of patients describing 7 by five attributes each. The normal class corresponds to the most common class with 69.77%. But these datasets hardly capture the problem of multiple distorted majority classes. As a result, we have included 4 additional datasets from the text classification task. The datasets, up to 21 word classes and large TREC / 3 news classes are from multiple majorities."}, {"heading": "4.2 Results", "text": "This year, it has reached the point where it will be able to put itself at the top of the list in the way in which it has pushed itself to the top."}, {"heading": "5 Conclusions", "text": "In this paper, we introduced 2 new stochastic models to increase the robustness of unbalanced multiculturalism. These 2 models explore different class topologies. The first model, CMC, improves unbalanced multiculturalism with unbalanced classes state-of-art. However, the literature does not provide a clear distinction between majority and minority classes, where a precise distinction between majority classes and minority classes is not necessary. Thus, we define the distinction between majority classes (16,36,37) and minority classes. Another reason is that most research is focused on datasets with few classes, where the majority classes and minority classes are not necessary."}], "references": [{"title": "On effective e-mail classification via neural networks,", "author": ["B. Cui", "A. Mondal", "J. Shen", "G. Cong", "K.-L. Tan"], "venue": "Database and Exp. Systems Appl.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Promail: Using progressive email social network for spam detection,", "author": ["C.-Y. Tseng", "J.-W. Huang", "M.-S. Chen"], "venue": "Advances in KDD Mining,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Link spam target detection using page farms,", "author": ["B. Zhou", "J. Pei"], "venue": "TKDD,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Mining impact-targeted activity patterns in imbalanced data,", "author": ["L. Cao", "Y. Zhao", "C. Zhang"], "venue": "IEEE TKDE, vol. 20,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Test strategies for cost-sensitive decision trees,", "author": ["S. Sheng", "C.X. Ling", "Q. Yang"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Discrimination-aware classification for imbalanced datasets,", "author": ["G. Ristanoski", "W. Liu", "J. Bailey"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Automatic web-page classification by using machine learning methods,", "author": ["M. Tsukada", "T. Washio", "H. Motoda"], "venue": "Web Intelligence: R.D.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Text classification without labeled negative documents,", "author": ["G.P.C. Fung", "J.X. Yu", "H. Lu", "P.S. Yu"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "A balanced ensemble approach to weighting classifiers for text classification,", "author": ["G.P.C. Fung", "J. Yu", "H. Wang", "D. Cheung", "H. Liu"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Species distribution modeling and prediction: A class imbalance problem,", "author": ["R. Johnson", "N. Chawla", "J. Hellmann"], "venue": "CIDU,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Boosting for learning multiple classes with imbalanced class distribution,", "author": ["Y. Sun", "M. Kamel", "Y. Wang"], "venue": "in Proc. of ICDM\u201906", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Addressing the curse of imbalanced training sets: one-sided selection,", "author": ["M. Kubat", "S. Matwin"], "venue": "in Proc. of ICML,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}, {"title": "An iterative method for multi-class costsensitive learning,", "author": ["N. Abe", "B. Zadrozny", "J. Langford"], "venue": "in Proc. of ACM SIGKDD. ACM,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "On multi-class cost-sensitive learning,", "author": ["Z. Zhou", "X. Liu"], "venue": "Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Smote: Synthetic minority oversampling technique,", "author": ["N. Chawla", "K. Bowyer", "L. Hall", "W. Kegelmeyer"], "venue": "JAIR, vol", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "MSMOTE: Improving classification performance when training data is imbalanced,", "author": ["S. Hu", "Y. Liang", "L. Ma", "Y. He"], "venue": "in WCSE\u201909. IEEE,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Borderline-smote: A new over-sampling method in imbalanced data sets learning,", "author": ["H. Han", "W.-Y. Wang", "B.-H. Mao"], "venue": "Adv. in Intell. Computing,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Selective pre-processing of imbalanced data for improving classification performance,", "author": ["J. Stefanowski", "S. Wilk"], "venue": "Data Ware. and K.D., pp", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Adacost: misclassification costsensitive boosting,", "author": ["W. Fan", "S.J. Stolfo", "J. Zhang", "P.K. Chan"], "venue": "in ICML,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1999}, {"title": "Cost-sensitive boosting for classification of imbalanced data,", "author": ["Y. Sun", "M.S. Kamel", "A.K. Wong", "Y. Wang"], "venue": "Pattern Recognition,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "An imbalanced data rule learner,", "author": ["C.H. Nguyen", "T. Ho"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "Smoteboost: Improving prediction of the minority class in boosting,", "author": ["N. Chawla", "A. Lazarevic", "L. Hall", "K. Bowyer"], "venue": "PKDD", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Diversity analysis on imbalanced data sets by using ensemble models,", "author": ["S. Wang", "X. Yao"], "venue": "IEEE Symposium CIDM \u201909,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Exploratory undersampling for class-imbalance learning,", "author": ["X. Liu", "J. Wu", "Z. Zhou"], "venue": "IEEE TSMC, Part B,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "Multistage pattern recognition with reject option,", "author": ["P. Pudil", "J. Novovicova", "S. Blaha", "J. Kittler"], "venue": "Proceedings of 11th IAPR. IEEE,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1992}, {"title": "Toward a phish free world,", "author": ["G. Xiang"], "venue": "Ph.D. dissertation,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Building multiclass classifiers for remote homology detection and fold recognition,", "author": ["H. Rangwala", "G. Karypis"], "venue": "BMC bioinformatics,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2006}, {"title": "An empirical study of applying ensembles of heterogeneous classifiers on imperfect data,", "author": ["K.-W. Hsu", "J. Srivastava"], "venue": "ser. PAKDD\u201909,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}, {"title": "Active feature selection using classes,", "author": ["H. Liu", "L. Yu", "M. Dash", "H. Motoda"], "venue": "Advances in Knowledge Discovery and Data Mining,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2003}, {"title": "A novel recommendation method based on rough set and integrated feature mining,", "author": ["V. Tseng", "J.-H. Su", "B.-W. Wang", "C.-Y. Hsiao"], "venue": "ICICIC", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2008}, {"title": "An effective attribute clustering approach for feature selection and replacement.", "author": ["T.-P. Hong", "P.-C. Wang", "Y.-C. Lee"], "venue": "Cybernetics and Systems,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2009}, {"title": "Boosting prediction accuracy on imbalanced datasets with svm ensembles,", "author": ["Y. Liu", "A. An", "X. Huang"], "venue": "Advances in KDD Mining,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2006}, {"title": "A study of the behavior of several methods for balancing machine learning training data,", "author": ["G. Batista", "R.C. Prati", "M.C. Monard"], "venue": "SIGKDD Explor. N.,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2004}, {"title": "Learning from imbalanced data,", "author": ["H. He", "E.A. Garcia"], "venue": "IEEE TKDE,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2009}, {"title": "Classification of imbalanced data: A review,", "author": ["Y. Sun", "A.K. Wong", "S.K. Mohamed"], "venue": "Inter. Journal of Pattern Recog. and A.I.,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 61, "endOffset": 68}, {"referenceID": 1, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 61, "endOffset": 68}, {"referenceID": 2, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 61, "endOffset": 68}, {"referenceID": 3, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 86, "endOffset": 89}, {"referenceID": 4, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 111, "endOffset": 116}, {"referenceID": 5, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 172, "endOffset": 175}, {"referenceID": 6, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 197, "endOffset": 205}, {"referenceID": 7, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 197, "endOffset": 205}, {"referenceID": 8, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 197, "endOffset": 205}, {"referenceID": 9, "context": "Many real-world classification tasks, such as email analysis [1,2,3], fraud detection [4], medical diagnostics [5,6], face recognition, discrimination aware classification [7], text classification [8,9,10], and species distribution [11] can have a highly skewed or imbalanced class distributions datasets.", "startOffset": 232, "endOffset": 236}, {"referenceID": 10, "context": "The first reported work focused on the multiclass imbalance problem [12], extended the G-mean metric [13] to multiclass problem.", "startOffset": 68, "endOffset": 72}, {"referenceID": 11, "context": "The first reported work focused on the multiclass imbalance problem [12], extended the G-mean metric [13] to multiclass problem.", "startOffset": 101, "endOffset": 105}, {"referenceID": 12, "context": "While previous work [14,15] on cost-sensitive learning for multiclass settings addresses the problem of multiclass imbalance, the cost matrix was already available or manually created for a two-class scenario based on the nature of the problem.", "startOffset": 20, "endOffset": 27}, {"referenceID": 13, "context": "While previous work [14,15] on cost-sensitive learning for multiclass settings addresses the problem of multiclass imbalance, the cost matrix was already available or manually created for a two-class scenario based on the nature of the problem.", "startOffset": 20, "endOffset": 27}, {"referenceID": 14, "context": "g: random oversampling, SMOTE [17], and SMOTE variations such as MSMOTE [18], BorderLine-SMOTE [19]), and a combination of both (e.", "startOffset": 30, "endOffset": 34}, {"referenceID": 15, "context": "g: random oversampling, SMOTE [17], and SMOTE variations such as MSMOTE [18], BorderLine-SMOTE [19]), and a combination of both (e.", "startOffset": 72, "endOffset": 76}, {"referenceID": 16, "context": "g: random oversampling, SMOTE [17], and SMOTE variations such as MSMOTE [18], BorderLine-SMOTE [19]), and a combination of both (e.", "startOffset": 95, "endOffset": 99}, {"referenceID": 17, "context": ": SPIDER [20]) AdaCost [21], AdaC1,2,3 [12,22] are ar X iv :1 31 2.", "startOffset": 9, "endOffset": 13}, {"referenceID": 18, "context": ": SPIDER [20]) AdaCost [21], AdaC1,2,3 [12,22] are ar X iv :1 31 2.", "startOffset": 23, "endOffset": 27}, {"referenceID": 10, "context": ": SPIDER [20]) AdaCost [21], AdaC1,2,3 [12,22] are ar X iv :1 31 2.", "startOffset": 39, "endOffset": 46}, {"referenceID": 19, "context": ": SPIDER [20]) AdaCost [21], AdaC1,2,3 [12,22] are ar X iv :1 31 2.", "startOffset": 39, "endOffset": 46}, {"referenceID": 20, "context": "There are also cost-sensitive rule base systems [23].", "startOffset": 48, "endOffset": 52}, {"referenceID": 21, "context": ": SMOTEBoost [24], SMOTEBagging [25], EasyEnsemble [26], and BalanceCascade [26].", "startOffset": 13, "endOffset": 17}, {"referenceID": 22, "context": ": SMOTEBoost [24], SMOTEBagging [25], EasyEnsemble [26], and BalanceCascade [26].", "startOffset": 32, "endOffset": 36}, {"referenceID": 23, "context": ": SMOTEBoost [24], SMOTEBagging [25], EasyEnsemble [26], and BalanceCascade [26].", "startOffset": 51, "endOffset": 55}, {"referenceID": 23, "context": ": SMOTEBoost [24], SMOTEBagging [25], EasyEnsemble [26], and BalanceCascade [26].", "startOffset": 76, "endOffset": 80}, {"referenceID": 24, "context": "It combines 1 binary view with 3 multiclass views of the data using 4 multistage ensemble classifiers [27].", "startOffset": 102, "endOffset": 106}, {"referenceID": 25, "context": "As a result, the first layer is similar to the cascade learning framework for phishing detection [28], which is a binary classification problem.", "startOffset": 97, "endOffset": 101}, {"referenceID": 24, "context": "Each multistage classifier is an ensemble of individual classifiers [27,29].", "startOffset": 68, "endOffset": 75}, {"referenceID": 26, "context": "Each multistage classifier is an ensemble of individual classifiers [27,29].", "startOffset": 68, "endOffset": 75}, {"referenceID": 27, "context": "The classifiers heterogeneity also improves imbalanced classification [30].", "startOffset": 70, "endOffset": 74}, {"referenceID": 28, "context": "Random feature selections is the simplest feature selection method [31,32,33,7].", "startOffset": 67, "endOffset": 79}, {"referenceID": 29, "context": "Random feature selections is the simplest feature selection method [31,32,33,7].", "startOffset": 67, "endOffset": 79}, {"referenceID": 30, "context": "Random feature selections is the simplest feature selection method [31,32,33,7].", "startOffset": 67, "endOffset": 79}, {"referenceID": 5, "context": "Random feature selections is the simplest feature selection method [31,32,33,7].", "startOffset": 67, "endOffset": 79}, {"referenceID": 10, "context": "We started our evaluation with two publicly available datasets at the UCI ML Repository to compare our work with the state-of-art [12].", "startOffset": 130, "endOffset": 134}, {"referenceID": 10, "context": "First, we evaluated CMC on two UCI datasets to compare with state-of-art methods [12]: Adaboost.", "startOffset": 81, "endOffset": 85}, {"referenceID": 31, "context": ": SVM [34,35].", "startOffset": 6, "endOffset": 13}, {"referenceID": 32, "context": ": SVM [34,35].", "startOffset": 6, "endOffset": 13}, {"referenceID": 11, "context": "However, fine tuning the undersampling G-mean metric [13] yielded very small improvements.", "startOffset": 53, "endOffset": 57}, {"referenceID": 33, "context": "One of the possible reasons for this gap is in focus on the binary case as 3 recent surveys about imbalanced learning [16,36,37] claim.", "startOffset": 118, "endOffset": 128}, {"referenceID": 34, "context": "One of the possible reasons for this gap is in focus on the binary case as 3 recent surveys about imbalanced learning [16,36,37] claim.", "startOffset": 118, "endOffset": 128}], "year": 2014, "abstractText": "In this work, we propose two stochastic architectural models (CMC and CMC-M ) with two layers of classifiers applicable to datasets with one and multiple skewed classes. This distinction becomes important when the datasets have a large number of classes. Therefore, we present a novel solution to imbalanced multiclass learning with several skewed majority classes, which improves minority classes identification. This fact is particularly important for text classification tasks, such as event detection. Our models combined with preprocessing sampling techniques improved the classification results on 6 well-known datasets. Finally, we have also introduced a new metric SG-Mean to overcome the multiplication by zero limitation of G-Mean.", "creator": "LaTeX with hyperref package"}}}