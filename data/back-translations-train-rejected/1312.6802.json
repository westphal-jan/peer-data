{"id": "1312.6802", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2013", "title": "Suffix Stripping Problem as an Optimization Problem", "abstract": "Stemming or suffix stripping, an important part of the modern Information Retrieval systems, is to find the root word (stem) out of a given cluster of words. Existing algorithms targeting this problem have been developed in a haphazard manner. In this work, we model this problem as an optimization problem. An Integer Program is being developed to overcome the shortcomings of the existing approaches. The sample results of the proposed method are also being compared with an established technique in the field for English language. An AMPL code for the same IP has also been given.", "histories": [["v1", "Tue, 24 Dec 2013 12:06:48 GMT  (447kb)", "http://arxiv.org/abs/1312.6802v1", "14 pages, 4 tables"]], "COMMENTS": "14 pages, 4 tables", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["b p pande", "pawan tamta", "h s dhami"], "accepted": false, "id": "1312.6802"}, "pdf": {"name": "1312.6802.pdf", "metadata": {"source": "CRF", "title": "Suffix Stripping Problem as an Optimization Problem", "authors": ["B. P. Pande", "Pawan Tamta", "H.S. Dhami"], "emails": [], "sections": [{"heading": null, "text": "1Stemming or suffix stripping, an important component of modern information retrieval systems, consists in finding the root word from a given cluster of words. Existing algorithms aimed at this problem have been developed arbitrarily. In this thesis, we model this problem as an optimization problem. An integer program is being developed to overcome the shortcomings of the existing approaches. Sample results of the proposed method are also compared with an established technique in the English language. An AMPL code for the same IP has also been provided. Keywords: Affix removal, Stemming, Information Retrieval (IR), Conflation and Integer Program (IP)."}, {"heading": "1. Introduction", "text": "In simple terms, the problem can be expressed as follows: in view of the fact that a word containing a different word, a different word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another word, another, another word, another word, another word, another word, another word, another word, another, another word, another word, another word, another word, another word, another, another word, another word, another word, another word, another word, another word, another word, another word, another, another word, another, another word, another word,"}, {"heading": "2. Preliminaries and Definitions", "text": "The process of mixing does not guarantee that the results are correct from a linguistic point of view. Hypothesizing a variable N-gram model in which the next character or symbol of a word is predicted using previous symbols (2 \u2264 N \u2264 word length). We are interested in building containers of variable lengths in which each container contains symbol sequences that were last scanned. Specifically, we designate a given W of length N asW = w1w2w3... wi... wNWhere wi is any character, i.e. wi A, set of alphabets. We define the frequency f (w1w2... wi) as the number of times in which a character sequence w1w2... wi appears in a training corpus. We are interested in relative frequencies, i.e. how often a particular symbol wj follows the string w1w2... wi. These can be used as a probability estimate, maximum probability calculus (MLE)."}, {"heading": "3. Formulation of the Algorithm", "text": "We emphasize two objectives that an efficient algorithm must fulfill. First, the performance obtained must be the root of all flexed words. Second, the algorithm must be language independent. A meaningful stem can be achieved by taking sequential probabilities into account. Before modelling the integer program for the problem, we will discuss the following observations from the sample data: 1. In most cases, the highest probability is not clear about N-grammars of a word. 2. Generally, the probability is increased with the increase in word length, a sudden decrease is subject to the transition from one state to another. 3. A continuous increase in probabilities identifies the whole word as astem.4. Probabilities equal to three or more positions can be associated with a common suffix, such as ing.5. Constant probabilities at the end for more than three positions we can alsoindicate whole words as stem.6. A continuously increasing sequence of probabilities at the end is associated with a consolidated ending that can be removed to obtain a general insight."}, {"heading": "4. Experimental Results", "text": "In order to empirically test our approach, we must first test the sequential frequencies of Ngrams of a rich corpus = = 46.09 + 46.09 +. For the English language, we rely on COCA [4]. This corpus has two advantages; firstly, it has a rich collection of English words and secondly, it is easy to calculate the N gram frequencies using wild maps. Consider the functioning of our approach with the manifestation of the proposed IP. We consider the English word Parsons as a test candidate. The sequential frequencies of COCA and probabilities are listed as: Table: 4.1: COCA frequencies for the word ParsonsWord N-Gram frequency (f) PMLE (Ce) Parsons as test candidates. 0 Pa 536621.288 Par 250520.466 Pars 2284,009 Pars 606,265 Parson 606 1 Parsons."}, {"heading": "5. Conclusions and Future work", "text": "The efficiency of the current work is determined on the basis of the results of 100 randomly selected words and compared with the results of Porter's Snowball stamp [20] (Appendix A.1). For the English language, Porter's stamp is used very frequently and has become the de facto standard algorithm. The survey was divided into three sections, the first section contains the results identical to those of Porter (58), the second section illustrates themorphologically better results (18) and in the third section we present the results to Porter (24). We tried to develop a probabilistic stamp that should be language independent and produced one that depends on mere character frequencies and not morphological knowledge. This equips our technique to survive in a multilingual environment where the need for specific morphological knowledge has been reduced."}, {"heading": "6. References", "text": "In fact, it is the case that most of them are in a position to outdo themselves when they go into another world, in which they move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}], "references": [{"title": "Structure of morphologically expanded queries: A genetic algorithm approach, Data & Knowledge Engineering, Volume", "author": ["Araujo Lourdes", "Zaragoza Hugo", "P\u00e9rez-Ag\u00fcera Jose R", "P\u00e9rez-Iglesias Joaqu\u00edn"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Suffix removal and word conflation", "author": ["Dawson John"], "venue": "ALLC Bulletin, Volume 2, No. 3, 33-46", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1974}, {"title": "English Stemming Algorithm", "author": ["S. English Joshua"], "venue": "Pragmatic Solutions, Inc.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "DARE: Domain Analysis and Reuse Environment, Annals of Software Engineering (5)", "author": ["W Frakes"], "venue": "125-141", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1998}, {"title": "Context sensitive stemming for web search", "author": ["Funchun Peng", "Nawaaz Ahmed", "Xin Li", "Yumao Lu."], "venue": "Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, 639-646", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Word Segmentation by Letter Successor Varieties", "author": ["Hafer M", "S. Weiss"], "venue": "Information Storage and Retrieval,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1974}, {"title": "How effective is suffixing", "author": ["Harman Donna"], "venue": "Journal of the American Society for Information Science,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1991}, {"title": "Viewing stemming as recall enhancement", "author": ["Kraaij Wessel", "Pohlmann Renee"], "venue": "Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval, 40-48", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1996}, {"title": "Viewing morphology as an inference process", "author": ["Krovetz Robert"], "venue": "Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval, 191-202", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1993}, {"title": "Development of a stemming algorithm", "author": ["J.B. Lovins"], "venue": "Mechanical Translation and Computational Linguistics, 11, 22-31", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1968}, {"title": "YASS: Yet another suffix stripper", "author": ["Majumder Prasenjit"], "venue": "ACM Transactions on Information Systems. 25(4), Article No. 18", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Single N-gram stemming", "author": ["Mayfield James", "McNamee Paul"], "venue": "Proceedings of the 26th annual international ACM SIGIR conference on Research and development in information retrieval, 415-416", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2003}, {"title": "Design, Implementation, and Evaluation of a Methodology for Automatic Stemmer Generation", "author": ["Melucci Massimo", "Orio Nicola"], "venue": "Journal of the American Society for Information Science and Technology, 58(5), 673\u2013686", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Another stemmer", "author": ["D. Paice Chris"], "venue": "ACM SIGIR Forum, 24(3). 56-61", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1990}, {"title": "Application of Natural Language Processing Tools in Stemming", "author": ["P. Pande B.", "S. Dhami H."], "venue": "International Journal of Computer Applications, 27(6):14-19", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "An algorithm for suffix stripping", "author": ["F. Porter M."], "venue": "Program 14, 130-137", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1980}, {"title": "Snowball: A language for stemming algorithms", "author": ["M.F. Porter"], "venue": "Available at <http://snowball.tartarus.org/>,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2001}, {"title": "Towards an error free stemming", "author": ["Tamah Eiman", "Shammari-Al"], "venue": "IADIS European Conference Data Mining,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "Lexical and Algorithmic Stemming Compared for 9 European Languages with Hummingbird SearchServer  TM at CLEF 2003", "author": ["Tomlinson Stephen"], "venue": "CLEF 2003: 286-300", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2003}, {"title": "Corpus-based stemming using cooccurrence of word variants, ACM Transactions on Information Systems", "author": ["Xu Jinxi", "Croft Bruce W."], "venue": "Volume 16 (1)1, 61-81", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1998}], "referenceMentions": [{"referenceID": 7, "context": "Stemming can enhance the retrieval effectiveness, research has shown that it enhances the recall [11].", "startOffset": 97, "endOffset": 101}, {"referenceID": 9, "context": "The first published stemmer was coined by Julie Beth Lovins in 1968 [13].", "startOffset": 68, "endOffset": 72}, {"referenceID": 3, "context": "Stemming is used to determine domain vocabularies in domain analysis [7].", "startOffset": 69, "endOffset": 72}, {"referenceID": 16, "context": "The Snowball stemmers [20] have also been compared with such commercial lexical stemmers with varying results [22].", "startOffset": 22, "endOffset": 26}, {"referenceID": 18, "context": "The Snowball stemmers [20] have also been compared with such commercial lexical stemmers with varying results [22].", "startOffset": 110, "endOffset": 114}, {"referenceID": 9, "context": "Some highlighted language dependent conflation algorithms are Lovin\u2019s algorithm [13], Dawson\u2019s algorithm [5], Porter algorithm [19], Paise/Husk algorithm [17], Krovetz algorithm [12], Harmans\u2019s \u2018S\u2019 stemmer [10] etc.", "startOffset": 80, "endOffset": 84}, {"referenceID": 1, "context": "Some highlighted language dependent conflation algorithms are Lovin\u2019s algorithm [13], Dawson\u2019s algorithm [5], Porter algorithm [19], Paise/Husk algorithm [17], Krovetz algorithm [12], Harmans\u2019s \u2018S\u2019 stemmer [10] etc.", "startOffset": 105, "endOffset": 108}, {"referenceID": 15, "context": "Some highlighted language dependent conflation algorithms are Lovin\u2019s algorithm [13], Dawson\u2019s algorithm [5], Porter algorithm [19], Paise/Husk algorithm [17], Krovetz algorithm [12], Harmans\u2019s \u2018S\u2019 stemmer [10] etc.", "startOffset": 127, "endOffset": 131}, {"referenceID": 13, "context": "Some highlighted language dependent conflation algorithms are Lovin\u2019s algorithm [13], Dawson\u2019s algorithm [5], Porter algorithm [19], Paise/Husk algorithm [17], Krovetz algorithm [12], Harmans\u2019s \u2018S\u2019 stemmer [10] etc.", "startOffset": 154, "endOffset": 158}, {"referenceID": 8, "context": "Some highlighted language dependent conflation algorithms are Lovin\u2019s algorithm [13], Dawson\u2019s algorithm [5], Porter algorithm [19], Paise/Husk algorithm [17], Krovetz algorithm [12], Harmans\u2019s \u2018S\u2019 stemmer [10] etc.", "startOffset": 178, "endOffset": 182}, {"referenceID": 6, "context": "Some highlighted language dependent conflation algorithms are Lovin\u2019s algorithm [13], Dawson\u2019s algorithm [5], Porter algorithm [19], Paise/Husk algorithm [17], Krovetz algorithm [12], Harmans\u2019s \u2018S\u2019 stemmer [10] etc.", "startOffset": 206, "endOffset": 210}, {"referenceID": 0, "context": "Some recent trends can also be seen towards rule based stemming [1], [6], [18], [21].", "startOffset": 64, "endOffset": 67}, {"referenceID": 2, "context": "Some recent trends can also be seen towards rule based stemming [1], [6], [18], [21].", "startOffset": 69, "endOffset": 72}, {"referenceID": 14, "context": "Some recent trends can also be seen towards rule based stemming [1], [6], [18], [21].", "startOffset": 74, "endOffset": 78}, {"referenceID": 17, "context": "Some recent trends can also be seen towards rule based stemming [1], [6], [18], [21].", "startOffset": 80, "endOffset": 84}, {"referenceID": 5, "context": "Successor variety word segmentation by Hafer and Weiss [9], Corpus based stemming by Jinxi Xu and W.", "startOffset": 55, "endOffset": 58}, {"referenceID": 19, "context": "Bruce [23], N-gram stemming by James Mayfield and Paul McNamee [15], hidden markov model (HMM) based automatic stemmer by Massimo Melucci and Nicola Orio [16], YASS stemmer by Prasenjit Majumder, et al [14], Context sensitive stemming by Peng Funchun et al.", "startOffset": 6, "endOffset": 10}, {"referenceID": 11, "context": "Bruce [23], N-gram stemming by James Mayfield and Paul McNamee [15], hidden markov model (HMM) based automatic stemmer by Massimo Melucci and Nicola Orio [16], YASS stemmer by Prasenjit Majumder, et al [14], Context sensitive stemming by Peng Funchun et al.", "startOffset": 63, "endOffset": 67}, {"referenceID": 12, "context": "Bruce [23], N-gram stemming by James Mayfield and Paul McNamee [15], hidden markov model (HMM) based automatic stemmer by Massimo Melucci and Nicola Orio [16], YASS stemmer by Prasenjit Majumder, et al [14], Context sensitive stemming by Peng Funchun et al.", "startOffset": 154, "endOffset": 158}, {"referenceID": 10, "context": "Bruce [23], N-gram stemming by James Mayfield and Paul McNamee [15], hidden markov model (HMM) based automatic stemmer by Massimo Melucci and Nicola Orio [16], YASS stemmer by Prasenjit Majumder, et al [14], Context sensitive stemming by Peng Funchun et al.", "startOffset": 202, "endOffset": 206}, {"referenceID": 4, "context": "[8] are some of the important literature articles under statistical domain of stemming.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "1 gives a comparison of outputs of our technique and Porter\u2019s Snowball stems [20] and in appendix A.", "startOffset": 77, "endOffset": 81}, {"referenceID": 16, "context": "The efficiency of current work is being concluded on the basis of the output obtained for 100 randomly chosen words, and comparing them with outputs of Porter\u2019s Snowball stemmer [20] (Appendix A.", "startOffset": 178, "endOffset": 182}], "year": 2013, "abstractText": "Stemming or suffix stripping, an important part of the modern Information Retrieval systems, is to find the root word (stem) out of a given cluster of words. Existing algorithms targeting this problem have been developed in a haphazard manner. In this work, we model this problem as an optimization problem. An Integer Program is being developed to overcome the shortcomings of the existing approaches. The sample results of the proposed method are also being compared with an established technique in the field for English language. An AMPL code for the same IP has also been given.", "creator": "Microsoft\u00ae Office Word 2007"}}}