{"id": "1312.6849", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2013", "title": "Speech Recognition Front End Without Information Loss", "abstract": "Phoneme classification is investigated for linear feature domains with the aim of improving robustness to additive noise. In linear feature domains noise adaptation is exact, potentially leading to more accurate classification than representations involving non-linear processing and dimensionality reduction. A generative framework is developed for isolated phoneme classification using linear features. Initial results are shown for representations consisting of concatenated frames from the centre of the phoneme, each containing $f$ frames. As phonemes have variable duration, no single $f$ is optimal for all phonemes, therefore an average is taken over models with a range of values of $f$. Results are further improved by including information from the entire phoneme and transitions. In the presence of additive noise, classification in this framework performs better than an analogous PLP classifier, adapted to noise using cepstral mean and variance normalisation, below $18$dB SNR. Finally we propose classification using a combination of acoustic waveform and PLP log-likelihoods. The combined classifier performs uniformly better than either of the individual classifiers across all noise levels.", "histories": [["v1", "Tue, 24 Dec 2013 16:36:16 GMT  (111kb)", "http://arxiv.org/abs/1312.6849v1", null], ["v2", "Mon, 30 Mar 2015 09:17:46 GMT  (151kb)", "http://arxiv.org/abs/1312.6849v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.CV cs.LG", "authors": ["matthew ager", "zoran cvetkovic", "peter sollich"], "accepted": false, "id": "1312.6849"}, "pdf": {"name": "1312.6849.pdf", "metadata": {"source": "CRF", "title": "Phoneme Classification in High-Dimensional Linear Feature Domains", "authors": ["Matthew Ager", "Zoran Cvetkovi\u0107"], "emails": [], "sections": [{"heading": null, "text": "This year, we have reached the stage where we feel we can put ourselves at the top without being able to put ourselves at the top."}, {"heading": "II. EXPLORATORY DATA ANALYSIS", "text": "Before constructing probability models of high-dimensional feature-speech linear representations, let us first examine possible low-dimensional structures in the phoneme classes. Suppose such a structure exists and can be characterized, then it could be used to find better representations for language and construct more accurate probabilistic models. Many speech representations reduce the dimension of speech signals by nonlinear processing, prominent examples being MFCC and PLP. These methods do not directly include information about the structure of phoneme class distributions, but instead model the properties of speech perception. Here, we are initially interested in data-driven methods of dimension reduction, such as those investigated in [11], [12] including linear discrimination analysis [13] (LDA), local linear embedding [14] (LLE), and isomap [15]. With linear approaches such as LDA, a projected feature-space of reduced dimensional mapping would be preserved so that the advantages of a feature-mapping would be possible."}, {"heading": "A. Finding Non-linear Structures", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "B. Generative Classification", "text": "The predicted class of a test point, x, is determined as the class with the greatest probability to be evaluated at x. Typically, the log probability is used for the calculation, but we refer to the log probability from x to L (x) = Log (1), where x can be predicted as part of one of the K classes. Including the previous probability of class k means that we effectively maximize the log posterior probability of class k. x.1) Gaussian Mixture Models: Without further prior knowledge of the phoneme distributions, we use Gaussian Mixture Models."}, {"heading": "C. Results of Exploratory Classification in PLP and Acoustic Waveform Domains", "text": "In fact, most of them are able to survive themselves if they don't put themselves in a position to survive themselves, \"he told the Deutsche Presse-Agentur.\" I don't think they are able to survive themselves, \"he told the Deutsche Presse-Agentur.\" But I don't think they are able to save the world if they can't. \""}, {"heading": "D. Conclusions of Exploratory Data Analysis", "text": "Explorative data analysis shows that acoustic waveform classifiers, which can be precisely adapted to noise when noise conditions are known, are also more robust to avoid discrepancies between assumed and actual test conditions. Furthermore, the combined classifier maintains the accuracy of the PLP under quiet conditions while maintaining the robustness of acoustic waveforms in the presence of noise. To confirm these conclusions, a more realistic test is required. As described above, we also found that the best model matches with only a small number of mixing components, whether using full covariance matrices or limited density models in the form of MPPCA. In both cases, too many model parameters are required to specify each mixing component, meaning that mixing with many components cannot be reliably learned from limited data. In the next section, the question of reducing the parameter count will be even more acute, as many of the phemon classes have fewer examples than previously considered."}, {"heading": "III. FIXED DURATION REPRESENTATION WITH REFINED MODELS", "text": "In this section we will look at how generative models can be improved to perform more realistic classification tasks. All previous experiments are now repeated on the standard TIMIT benchmark [29], adding noise so that the SNR is specified at record level. This means that the local SNR of the phoneme segments can differ significantly from the record level value. There are large differences in the size of the phoneme classes, so these relative frequencies have a greater effect than the previous one in (1). We will also look at the averaging of the model, eliminating the need to select the number of components in mixed models."}, {"heading": "A. Model Refinements", "text": "The question of whether this is a way in which the data is presented on a basis on which the correlations between the characteristics are weak is clearly not the case due to the strong temporal correlations in the speech waveforms. Therefore, we have systematically examined candidates with low correlation bases derived from PCA. Although the optimal basis for decoration on the training set is actually formed by the phoneme-specific main components, we found that the lowest test error is actually achieved with a DCT model."}, {"heading": "B. Experimental setup", "text": "Phoneme realizations were extracted from the SI and SX phrases of the TIMIT database = 64. # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "C. Results", "text": "The results of the study show that there has been no improvement beyond four components, as explained in Section III-A2, instead of working with models with fixed numbers of components, we average over models, i.e. over the number of mixing components in which the number of mixing components in which the mixing components are indicated, i.e. over the number of mixing components in which all results were reported, shows that the improvement achieved by these two acoustic waveforms is approximately 2% for both acoustic waveforms and PLP8 with a small improvement for MFCC as well. The model average average average improved results in terms of noise and this will be discussed further in the next section."}, {"heading": "IV. SEGMENT DURATION, VARIABLE DURATION PHONEME MAPPING AND CLASSIFIER COMBINATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Segment Duration", "text": "The sum of all relevant information should be maintained by our phoneme representation, but since it is difficult to determine exactly what information is relevant, we first select f consecutive frames that come closest to the center of each phoneme and link it. While the exact number of frames required for an accurate classification can in principle be derived from the statistics of phoneme segment durations, Table I shows that these durations not only vary significantly between classes, but that the standard deviation within each class is at least 24 ms. Therefore, no single length can be appropriate for all classes. Determining an optimal f from the data statistics would be even more complicated if they include the additional information about the dynamics of the signal outside the f frames."}, {"heading": "B. Sector sum", "text": "s data, which have a consistent dimension. Next, we establish a method to map the phoneme segments with variable length to a fixed length representation for classification. In the previous subsection, only frames from the center of the phonemsegments were used to represent a phonem (max. (max.) concatenation (max.) to use information from the entire segment, by taking f frames with centers that come closest to each of the time constants A, B, C, D and E, which are distributed along the duration of the phoneme. In this way, the representation consists of five sequences of f frames per phoneme. These frames are then linked to each other, to give five vectors xA, xB, C, xD and xE, x, which are distributed along the duration of the phoneme 8. In this way, the representation is made up of five sequences of f frames per phoneme. These frames are then linked to each other, to give five vectors xA, xB, C, D and xE, C, x, which are distributed along the duration of the phoneme. x, as in Figure 8. In this way, x, x, the representation consists of five frames of f frames per phoneme. These frames are then, x, x, x x, x x, x, x x, x x, x x x, x, x x x, x x x x, x x, x x x x x, x x x x, x x x x x, x x x x x x x, x x x x x x, x x x x x x x, x x x x x x, x x x x x x, x x x x x x x x x x x x, x x x x x x, x x x x x x x x x x x, x x x x x x x x x x, x x x x x x x x x x, x x x x x x x x x x x x x x x, x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "C. Results", "text": "Figure 9 shows the impact of the number of frames concatenated from each sector on the classification error, focusing on calm conditions. We see that the best results for acoustic waveform classifiers are achieved by 9 frames, and about 11 frames for PLP without deltas. PLP + \u2206, 000 features, however, are less sensitive to the number of frames with a small difference in the error rate from 1 to 13 frames. We can now also quantitatively evaluate the performance advantage of the inclusion of deltas. If we compare the best results for PLP without deltas, 22.4% with 11 frames, with the best frames with the difference in the error rate of PLP +; 21.8% with 7 frames, then the performance gap of 0.6% is much smaller than if we compare error rates, where both classifiers used the same number of frames. Clearly, it is not surprising that less PLP + PLP is the performance gap of 0.6% when we compare error rates, where both classifiers used the same number of frames."}, {"heading": "D. Combination of PLP and Acoustic Waveform Classifiers", "text": "To obtain the advantages of both representations, we propose to merge them using a linear combination of the corresponding log probabilities parameterized by a coefficient \u03b1: T\u03b1 (x) = (1 \u2212 \u03b1) Tplp (x) + \u03b1Twave (x) (19), where Tplp (x) and Twave (x) are the log probabilities of a point x. T\u03b1 (x) is then used instead of T (x) in (18) to predict the class. The combination differs from (6) because the effect of the previous class probabilities is now more relevant and the absolute log probability of a point x must be used, instead of the scaled quantities. This, in turn, corresponds to a multi-stream model in which each sector and value of f is an independent stream."}, {"heading": "V. CONCLUSION & DISCUSSION", "text": "In this paper, we have examined some of the potential benefits of phoneme classification in linear characteristics that are directly related to the acoustic waveform, with the aim of implementing the exact fit of the resulting density. In Section II, we outlined the results of our exploratory data analysis, in which we estimated the intrinsic nonlinear dimensions lower than the linear dimensions. This observation suggested that it should be possible to construct low dimensions that will later be used with generative classifiers, but existing techniques have not found sufficient structure in the phonematic datasets, as it is too thin to precisely define the embedded."}], "references": [{"title": "An Analysis of Perceptual Confusions among some English Consonants", "author": ["G. Miller", "P. Nicely"], "venue": "J. Acoust. Soc. Am., vol. 27, pp. 338\u2013352, 1955.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1955}, {"title": "Speech Recognition by Machines and Humans", "author": ["R. Lippmann"], "venue": "Speech Comm., vol. 22, no. 1, pp. 1\u201315, 1997.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "Human and Machine Consonant Recognition", "author": ["J. Sroka", "L. Braida"], "venue": "Speech Comm., vol. 45, no. 4, pp. 401\u2013423, 2005.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "Perceptual Linear Predictive (PLP) Analysis of Speech", "author": ["H. Hermansky"], "venue": "J. Acoust. Soc. Am., vol. 87, no. 4, pp. 1738\u20131752, 1990.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1990}, {"title": "Linear Predictive Hidden Markov Models and the Speech Signal", "author": ["A. Poritz"], "venue": "Proc. ICASSP, 1982.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1982}, {"title": "Revisting Autoregressive Hidden Markov Modeling of Speech Signals", "author": ["Y. Ephraim", "W. Roberts"], "venue": "IEEE Signal Processing Letters, vol. 12, no. 2, Feb. 2005, pp. 166\u2013169.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Waveform-Based Speech Recognition Using Hidden Filter Models: Parameter Selection and Sensitivity to Power Normalization", "author": ["H. Sheikhzadeh", "L. Deng"], "venue": "IEEE Trans. Speech and Audio Processing, vol. 2, no. 1, pp. 80 \u201389, Jan 1994.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1994}, {"title": "Switching Linear Dynamical Systems for Noise Robust Speech Recognition", "author": ["B. Mesot", "D. Barber"], "venue": "IEEE Trans. Audio, Speech and Language Processing, vol. 15, no. 6, pp. 1850\u20131858, 2007.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1850}, {"title": "Modeling Natural Sounds with Modulation Cascade Processes", "author": ["R.E. Turner", "M. Sahani"], "venue": "Advances in Neural Information Processing Systems, vol. 20, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Mixtures of Probabilistic Principal Component Analysers", "author": ["M. Tipping", "C. Bishop"], "venue": "Neural Computation, vol. 11, no. 2, pp. 443\u2013482, 1999.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning the Intrinsic Dimensions of the TIMIT Speech Database with Maximum Variance Unfolding", "author": ["N. Vasiloglou", "A.G.D. Anderson"], "venue": "IEEE Workshops on DSP and SPE, 2009.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Dimensionality Reduction-based Phoneme Recognition", "author": ["S. Zhang", "Z. Zhao"], "venue": "Proc. ICSP, 2008.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction", "author": ["T. Hastie", "R. Tibshirani", "J. Friedman"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Nonlinear Dimensionality Reduction by Locally Linear Embedding", "author": ["S. Roweis", "L. Saul"], "venue": "Science, vol. 290, pp. 2323\u20132326, 2000.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2000}, {"title": "Spectral Methods for Dimensionality Reduction", "author": ["L. Saul", "K. Weinberger", "J. Ham", "F. Sha", "D. Lee"], "venue": "Semisupervised Learning. Cambridge, MA: MIT Press, 2006.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Probabilistic Non-Linear Principal Component Analysis with Gaussian Process Latent Variable Models", "author": ["N. Lawrence"], "venue": "J. Mach. Learn. Res., vol. 6, pp. 1783 \u20131816, 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1816}, {"title": "Intrinsic Dimensionality Estimation of Submanifolds in R", "author": ["M. Hein", "J.-Y. Audibert"], "venue": "Proc. ICML, vol. 119, 2005, pp. 289\u2013296.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Geodesic Entropic Graphs for Dimension and Entropy Estimation in Manifold Learning", "author": ["J. Costa", "A. Hero"], "venue": "IEEE Trans. on Signal Processing, vol. 52, no. 8, pp. 2210\u20132221, 2004.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2004}, {"title": "On the Numerical Determination of the Dimension of an Attractor", "author": ["F. Takens"], "venue": "Lecture notes in mathematics. Dynamical systems and bifurcations, vol. 1125. Springer, 1985, p. 99.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1985}, {"title": "Dimensionality reduction: A comparative review", "author": ["L. van der Maaten", "E. Postma", "H. van den Herik"], "venue": "2007.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Global Coordination of Local Linear Models", "author": ["S. Roweis", "L. Saul", "G. Hinton"], "venue": "Advances in Neural Information Processing Systems, vol. 14, 2002.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2002}, {"title": "Robust Signal-to-Noise Ratio Estimation Based on Waveform Amplitude Distribution Analysis", "author": ["C. Kim", "R. Stern"], "venue": "Proc. Interspeech, 2008.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Robust continuous speech recognition using parallel model combination", "author": ["M. Gales", "S. Young"], "venue": "IEEE Trans. on Speech and Audio Processing, vol. 4, pp. 352\u2013359, 1996.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1996}, {"title": "Improved Mean and Variance Normalization for Robust Speech Recognition", "author": ["P. Jain", "H. Hermansky"], "venue": "Proc. ICASSP, 2001.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "Environmental Robustness in Automatic Speech Recognition", "author": ["R. Rose"], "venue": "Robust2004 - ISCA and COST278 Workshop on Robustness in Conversational Interaction, 2004.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2004}, {"title": "The DARPA TIMIT acoustic-phonetic continous speech", "author": ["J. Garofolo", "L. Lamel", "W. Fisher", "J. Fiscus", "D. Pallett"], "venue": "corpus. NIST. Philiadelphia: Linguistic Data Consortium,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1993}, {"title": "PLP and RASTA (and MFCC, and inversion) in Matlab", "author": ["D. Ellis"], "venue": "2005, online web resource, http://labrosa.ee.columbia.edu/matlab/rastamat/.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}, {"title": "Towards Robust Phoneme Classification: Augmentation of PLP Models with Acoustic Waveforms", "author": ["M. Ager", "Z. Cvetkovi\u0107", "P. Sollich", "B. Yu"], "venue": "Proc. EUSIPCO, 2008.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "Speaker-Independent Phone Recognition using Hidden Markov Models", "author": ["K.-F. Lee", "H.-W. Hon"], "venue": "IEEE Trans. Acoustics, Speech and Signal Processing, vol. 37, no. 11, pp. 1641\u20131648, 1989.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1989}, {"title": "Bayesian Quadratic Discriminant Analysis", "author": ["S. Srivastava", "M. Gupta", "B. Frigyik"], "venue": "Journal of Machine Learning Research, vol. 8, pp. 1287\u2013 1314, 2007.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "Large Margin Gaussian Mixture Modeling for Phonetic Classification and Recognition", "author": ["F. Sha", "L. Saul"], "venue": "Proc. ICASSP, 2006.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2006}, {"title": "The NOISEX-92 study on the effect of additive noise on automatic speech recognition", "author": ["A. Varga", "H. Steeneken", "M. Tomlinson", "D. Jones"], "venue": "DRA Speech Research Unit, Tech. Rep., 1992.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1992}, {"title": "On the Use of Support Vector Machines for Phonetic Classification", "author": ["P. Clarkson", "P. Moreno"], "venue": "Proc. ICASSP, vol. 2, 1999, pp. 585\u2013588.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1999}, {"title": "HMM-Based Speech Recognition Using State-Dependent, Discriminatively Derived Transforms on Mel- Warped DFT Features", "author": ["R. Chengalvarayan", "L. Deng"], "venue": "IEEE Trans. Speech and Audio Processing, vol. 5, no. 3, pp. 243 \u2013256, May 1997.  12", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1997}, {"title": "Hierarchical Large-Margin Gaussian Mixture Models For Phonetic Classification", "author": ["H. Chang", "J. Glass"], "venue": "Proc. IEEE ASRU Workshop, 2007, pp. 272\u2013275.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2007}, {"title": "Noise Robust Phonetic Classification with Linear Regularized Least Squares and Second-Order Features", "author": ["R. Rifkin", "K. Schutte", "M. Saad", "J. Bouvrie", "J. Glass"], "venue": "Proc. ICASSP, 2007, pp. IV\u2013881\u2013IV\u2013 884.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2007}, {"title": "Hidden Conditional Random Field with Distribution Constraints for Phone Classification", "author": ["D. Yu", "L. Deng", "A. Acero"], "venue": "Proc. Interspeech, 2009.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2009}, {"title": "Broad Phonetic Classification using Discriminative Bayesian Networks", "author": ["F. Pernkopf", "T. Pham", "J. Bilmes"], "venue": "Speech Comm., vol. 51, no. 2, 2009.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "STUDIES have shown that automatic speech recognition (ASR) systems still lack performance when compared to human listeners in adverse conditions that involve additive noise [1], [2], [3].", "startOffset": 173, "endOffset": 176}, {"referenceID": 1, "context": "STUDIES have shown that automatic speech recognition (ASR) systems still lack performance when compared to human listeners in adverse conditions that involve additive noise [1], [2], [3].", "startOffset": 178, "endOffset": 181}, {"referenceID": 2, "context": "STUDIES have shown that automatic speech recognition (ASR) systems still lack performance when compared to human listeners in adverse conditions that involve additive noise [1], [2], [3].", "startOffset": 183, "endOffset": 186}, {"referenceID": 3, "context": "For instance, mel-frequency cepstral coefficients (MFCC) and perceptual linear prediction coefficients (PLP) [4] both involve non-linear dimension reduction which makes exact noise adaptation very difficult in practice.", "startOffset": 109, "endOffset": 112}, {"referenceID": 4, "context": "Linear representations have been considered previously by other authors, including Poritz [5] and Ephraim and Roberts [6].", "startOffset": 90, "endOffset": 93}, {"referenceID": 5, "context": "Linear representations have been considered previously by other authors, including Poritz [5] and Ephraim and Roberts [6].", "startOffset": 118, "endOffset": 121}, {"referenceID": 6, "context": "Sheikhzadeh and Deng [7] apply hidden filter models directly on acoustic waveforms, avoiding artificial frame boundaries and therefore allowing better modelling of short duration events.", "startOffset": 21, "endOffset": 24}, {"referenceID": 7, "context": "Mesot and Barber [8] later proposed the use of switching linear dynamical systems (SLDS), again explicitly modelling speech as a time series.", "startOffset": 17, "endOffset": 20}, {"referenceID": 8, "context": "Turner and Sahani proposed using modulation cascade processes to model natural sounds simultaneously on many time-scales [9], but the application of this approach to ASR remains to be explored.", "startOffset": 121, "endOffset": 124}, {"referenceID": 9, "context": "In preliminary experiments on a small subset of phonemes, we therefore employ standard GMM classifiers using full covariance matrices followed by lower-rank approximations derived from probabilistic principal component analysis (PPCA) [10].", "startOffset": 235, "endOffset": 239}, {"referenceID": 10, "context": "Here we are initially interested in data-driven methods of dimensionality reduction as explored in [11], [12], including linear discriminant analysis [13] (LDA), locally linear embedding [14] (LLE) and Isomap [15].", "startOffset": 99, "endOffset": 103}, {"referenceID": 11, "context": "Here we are initially interested in data-driven methods of dimensionality reduction as explored in [11], [12], including linear discriminant analysis [13] (LDA), locally linear embedding [14] (LLE) and Isomap [15].", "startOffset": 105, "endOffset": 109}, {"referenceID": 12, "context": "Here we are initially interested in data-driven methods of dimensionality reduction as explored in [11], [12], including linear discriminant analysis [13] (LDA), locally linear embedding [14] (LLE) and Isomap [15].", "startOffset": 150, "endOffset": 154}, {"referenceID": 13, "context": "Here we are initially interested in data-driven methods of dimensionality reduction as explored in [11], [12], including linear discriminant analysis [13] (LDA), locally linear embedding [14] (LLE) and Isomap [15].", "startOffset": 187, "endOffset": 191}, {"referenceID": 14, "context": "Here we are initially interested in data-driven methods of dimensionality reduction as explored in [11], [12], including linear discriminant analysis [13] (LDA), locally linear embedding [14] (LLE) and Isomap [15].", "startOffset": 209, "endOffset": 213}, {"referenceID": 15, "context": "This could include Gaussian process latent variable models [16] (GP-LVM), which require as input an estimate of the dimension of the non-linear feature space.", "startOffset": 59, "endOffset": 63}, {"referenceID": 16, "context": "[17], Costa et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] and Takens [19] and applied them to the phomeme class data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[18] and Takens [19] and applied them to the phomeme class data.", "startOffset": 16, "endOffset": 20}, {"referenceID": 19, "context": "A number of techniques have recently been developed to find such non-linear manifold structures in data [20].", "startOffset": 104, "endOffset": 108}, {"referenceID": 14, "context": "After an extensive study of the benefits and limitations of these methods, Isomap [15] and LLE [14][21] were selected for application to the phoneme dataset.", "startOffset": 82, "endOffset": 86}, {"referenceID": 13, "context": "After an extensive study of the benefits and limitations of these methods, Isomap [15] and LLE [14][21] were selected for application to the phoneme dataset.", "startOffset": 95, "endOffset": 99}, {"referenceID": 20, "context": "After an extensive study of the benefits and limitations of these methods, Isomap [15] and LLE [14][21] were selected for application to the phoneme dataset.", "startOffset": 99, "endOffset": 103}, {"referenceID": 14, "context": "Our initial comparison with PCA output showed that for a given embedding dimension the approximation provided by Isomap was better in terms of the L error [15] for our data.", "startOffset": 155, "endOffset": 159}, {"referenceID": 9, "context": "Instead we considered using density estimates derived from mixtures of probabilistic principal component analysis (MPPCA) [10].", "startOffset": 122, "endOffset": 126}, {"referenceID": 21, "context": "We assume throughout that this is known, as it can be estimated reliably during periods without speech activity or using other techniques [22].", "startOffset": 138, "endOffset": 142}, {"referenceID": 6, "context": "Clearly some normalisation of this type is needed to avoid adverse effects of irrelevant differences in speaker volume on classification performance, an issue that has been carefully studied in previous work [7].", "startOffset": 208, "endOffset": 211}, {"referenceID": 22, "context": "Parallel model combination as proposed by Gales and Young [23] is an approximate approach for MFCC.", "startOffset": 58, "endOffset": 62}, {"referenceID": 23, "context": "A commonly used alternative method for adapting probabilistic models to additive noise is cepstral mean and variance normalisation (CMVN) [24], and we will consider this method in subsequent sections.", "startOffset": 138, "endOffset": 142}, {"referenceID": 22, "context": "Matched conditions are nevertheless useful in our exploratory classification experiments: because training data comes directly from the desired noisy speech distribution, then assuming enough data is available to estimate class densities accurately this approach provides the optimal baseline for all noise adaptation methods [23],[25].", "startOffset": 326, "endOffset": 330}, {"referenceID": 24, "context": "Matched conditions are nevertheless useful in our exploratory classification experiments: because training data comes directly from the desired noisy speech distribution, then assuming enough data is available to estimate class densities accurately this approach provides the optimal baseline for all noise adaptation methods [23],[25].", "startOffset": 331, "endOffset": 335}, {"referenceID": 25, "context": "In the exploratory study we consider only realisations of six phonemes (/b/, /f/, /m/, /r/, /t/, /z/) that were extracted from the TIMIT database [26].", "startOffset": 146, "endOffset": 150}, {"referenceID": 26, "context": "A sliding 25ms Hamming window was used with an overlap of 15ms leading to four frames of 13 coefficients [27].", "startOffset": 105, "endOffset": 109}, {"referenceID": 27, "context": "This range is broad, so the particular form of the fitted combination function is not critical [28].", "startOffset": 95, "endOffset": 99}, {"referenceID": 28, "context": "All previous experiments are now repeated on the standard TIMIT benchmark [29] with noise added so that the SNR is specified at sentence level.", "startOffset": 74, "endOffset": 78}, {"referenceID": 29, "context": "We use an alternative approach and take the model average over the number of components, effectively a mixture of mixtures [30].", "startOffset": 123, "endOffset": 127}, {"referenceID": 23, "context": "As mentioned above, cepstral mean and variance normalisation (CMVN) [24] is an approach commonly used in practice to compensate noise corrupted features.", "startOffset": 68, "endOffset": 72}, {"referenceID": 25, "context": "Realisations of phonemes were extracted from the SI and SX sentences of the TIMIT [26] database.", "startOffset": 82, "endOffset": 86}, {"referenceID": 28, "context": "The glottal closures are removed and the remaining classes are then combined into 48 groups in accordance with [29], [31].", "startOffset": 111, "endOffset": 115}, {"referenceID": 30, "context": "The glottal closures are removed and the remaining classes are then combined into 48 groups in accordance with [29], [31].", "startOffset": 117, "endOffset": 121}, {"referenceID": 28, "context": "For the purposes of calculating error rates, some very similar phoneme groups are further regarded as identical, resulting in 39 groups of effectively distinguishable phonemes [29].", "startOffset": 176, "endOffset": 180}, {"referenceID": 26, "context": "Standard implementations [27] of MFCC and PLP with default parameter values are used to produce a 13-dimensional feature vector from each time frame.", "startOffset": 25, "endOffset": 29}, {"referenceID": 31, "context": "The same experiment was repeated using pink noise extracted from the NOISEX-92 database [32].", "startOffset": 88, "endOffset": 92}, {"referenceID": 30, "context": "Results for GMM classification on the TIMIT benchmark in quiet conditions have previously been reported in [31], [33] with errors of 25.", "startOffset": 107, "endOffset": 111}, {"referenceID": 32, "context": "Results for GMM classification on the TIMIT benchmark in quiet conditions have previously been reported in [31], [33] with errors of 25.", "startOffset": 113, "endOffset": 117}, {"referenceID": 32, "context": "Top: Division described in [33] resulting in five sectors, three covering the duration of the phoneme and two of 40ms duration around the transitions.", "startOffset": 27, "endOffset": 31}, {"referenceID": 33, "context": "HMM (Minimum Classification Error) [35] 31.", "startOffset": 35, "endOffset": 39}, {"referenceID": 32, "context": "GMM baseline [33] 26.", "startOffset": 13, "endOffset": 17}, {"referenceID": 34, "context": "GMM baseline [36] 24.", "startOffset": 13, "endOffset": 17}, {"referenceID": 35, "context": "GMM baseline [37] 23.", "startOffset": 13, "endOffset": 17}, {"referenceID": 32, "context": "SVM, 5th order polynomial kernel [33] 22.", "startOffset": 33, "endOffset": 37}, {"referenceID": 30, "context": "Large Margin GMM (LMGMM) [31] 21.", "startOffset": 25, "endOffset": 29}, {"referenceID": 35, "context": "Regularized least squares [37] 20.", "startOffset": 26, "endOffset": 30}, {"referenceID": 36, "context": "Hidden conditional random fields [38] 20.", "startOffset": 33, "endOffset": 37}, {"referenceID": 34, "context": "Hierarchical LMGMM H(2,4) [36] 18.", "startOffset": 26, "endOffset": 30}, {"referenceID": 33, "context": "Optimum-transformed HMM with context (THMM) [35] 17.", "startOffset": 44, "endOffset": 48}, {"referenceID": 34, "context": "Committee hierarchical LMGMM H(2,4) [36] 16.", "startOffset": 36, "endOffset": 40}, {"referenceID": 33, "context": "All of the entries show the error for isolated phoneme classification except for the optimum-transformed HMM (THMM) [35] that uses context information derived from continuous speech.", "startOffset": 116, "endOffset": 120}, {"referenceID": 34, "context": "We expect that the results can be further improved by including techniques considered by other authors, in particular, committee classifiers and the use of a hierarchy to reduce broad phoneme class confusions [36],[39].", "startOffset": 209, "endOffset": 213}, {"referenceID": 37, "context": "We expect that the results can be further improved by including techniques considered by other authors, in particular, committee classifiers and the use of a hierarchy to reduce broad phoneme class confusions [36],[39].", "startOffset": 214, "endOffset": 218}], "year": 2017, "abstractText": "Phoneme classification is investigated for linear feature domains with the aim of improving robustness to additive noise. In linear feature domains noise adaptation is exact, potentially leading to more accurate classification than representations involving non-linear processing and dimensionality reduction. A generative framework is developed for isolated phoneme classification using linear features. Initial results are shown for representations consisting of concatenated frames from the centre of the phoneme, each containing f frames. As phonemes have variable duration, no single f is optimal for all phonemes, therefore an average is taken over models with a range of values of f . Results are further improved by including information from the entire phoneme and transitions. In the presence of additive noise, classification in this framework performs better than an analogous PLP classifier, adapted to noise using cepstral mean and variance normalisation, below 18dB SNR. Finally we propose classification using a combination of acoustic waveform and PLP log-likelihoods. The combined classifier performs uniformly better than either of the individual classifiers across all noise levels.", "creator": "LaTeX with hyperref package"}}}