{"id": "1312.6885", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2013", "title": "Deep learning for class-generic object detection", "abstract": "We investigate the use of deep neural networks for the novel task of class generic object detection. We show that neural networks originally designed for image recognition can be trained to detect objects within images, regardless of their class, including objects for which no bounding box labels have been provided. In addition, we show that bounding box labels yield a 1% performance increase on the ImageNet recognition challenge.", "histories": [["v1", "Tue, 24 Dec 2013 20:38:18 GMT  (821kb,D)", "http://arxiv.org/abs/1312.6885v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["brody huval", "adam coates", "rew ng"], "accepted": false, "id": "1312.6885"}, "pdf": {"name": "1312.6885.pdf", "metadata": {"source": "META", "title": "Deep learning for class-generic object detection", "authors": ["Brody Huval", "Adam Coates", "Andrew Ng"], "emails": ["BRODYH@STANFORD.EDU", "ACOATES@STANFORD.EDU", "ANG@STANFORD.EDU"], "sections": [{"heading": "1. Introduction", "text": "The task of removing objects from the background is fundamental to many computer tasks. As a result, objects are located through the use of object segments, object detectors and register suggestions. Most detectors are trained individually for each object class, which requires class labeling. In this approach, it is difficult to transfer information from previously trained detectors to novel classes where it is not available. This situation is common in current datasets, which have many class labels but imperfect labeling."}, {"heading": "2. Related works", "text": "(Szegedy et al., 2013) used a similar neural network for object detection in Pascal VOCs. Like our approach, they avoided the use of sliding windows or regional suggestions and instead directly used a deep neural network to predict object detection. However, their work focuses on only a handful of classes of Pascal VOCs, and five different networks are trained for each class. In contrast, we train a single network that is capable of providing class-generic object detection. Regional suggestion algorithms are typically flat methods Xiv: 131 2.68 85v1 [cs.CV] 2 4D ec2 013, which focus on detecting objects with high recall rate (Endres & Hoiem, 2010; Alexe et al., 2012; Uijlings et al., 2013). Therefore, they return hundreds to thousands of potential Bounding Boxes for evaluation, which is still an algorithm required for identifying a large number of potential objects compared to CNN."}, {"heading": "3. Object Detection from Neural Networks", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Model", "text": "The Convolutional Neural Network (CNN) we use is similar to that of Krizhevsky et al., 2012) for object classification. The network consists of five layers of folds followed by two tightly bonded layers. Each layer applies a Rectified Linear Unit (ReLU) as nonlinearity. Only the first, second and fifth layers use local contrast normalization (LCN) and maximum pooling. The final output is a 4096 dimensional feature vector for the image. See (Krizhevsky et al., 2012) for details."}, {"heading": "3.2. Bounding Box Training", "text": "In image classification (Krizhevsky et al., 2012), the final feature vector is entered into a Softmax layer that provides a probability distribution via class labels. Instead, we use a Softmax layer to provide a probability distribution over a discredited space of boundary boxes. This 4-dimensional space encodes the x-y position, scale, and aspect ratio of a boundary box. Since the Softmax layer handles each output cable independently, the network receives the same loss for boundary boxes with high or low overlap with the basic truth, which is not ideal. This also results in a small number of each label during training. To solve this, instead of placing a one or zero on each label, a Gaussian distribution centered on the correct label. The result is a smaller loss when a boundary box of the basic truth is normalized to allow multiple boundary boxes to be placed in each location."}, {"heading": "3.3. Classification pretraining", "text": "When training a CNN for image recognition, the network learns discriminatory filters that help detect the different classes while ignoring potentially disruptive generic backgrounds. As a result, the task of detection and detection are interconnected, and information from one task can improve the results from the other. To implement this intuition, we optionally train our network on the image detection task. Our results will confirm the usefulness of this intuition: image detection pre-training improves performance in class-generic object detection. Conversely, object detection pre-training can enhance image detection performance."}, {"heading": "4. Experiments", "text": "To conduct our experiments, we use several GPUs for training (Coates et al., 2013; Krizhevsky et al., 2012)."}, {"heading": "4.1. Dataset", "text": "All experiments were conducted as part of the Imagenet 2012 Localization Challenge (Deng et al., 2009), which provides 1.2 million classification images with 592,000 images, including labels of boundary fields across 1,000 different categories / synsets."}, {"heading": "4.2. Evaluation", "text": "To show that our network is able to detect objects even though we have never seen their Bounding Boxes, we randomly selected 100 object classes from the 1000 ImageNet Challenge classes and trained without their Bounding Boxes. Then, we evaluated the performance using a validation set containing only the 100 object classes available during the training, which was performed with one network based on random weights and another based on a network prepared for image recognition for all 1000 object classes. Our results are shown in Table 1. To measure the performance decline since the Bounding Boxes from 100 available classes were not available, the performance for both networks, pre-trained and randomly, is reported when they are trained on all 1000 Bounding Box classes, shown in Table 2. Accuracy recall curves are also shown for these four cases in Figure 1. Examples of correct and incorrect detections from our network based on Bounding Bounding Classes provided 2.Finally, in Figure 2."}, {"heading": "5. Conclusion", "text": "By using a single deep neural network, we have investigated a method for detecting object proximity that can use both class and Bounding Box labels. Our network is able to generalize to classes for which it has never seen Bounding Box labels before, and benefits from class labels when available. In addition, we have found that the object proximity detection task is a modest improvement on the ImageNet detection problem that does not involve detection."}], "references": [{"title": "Measuring the objectness of image windows", "author": ["Alexe", "Bogdan", "Deselaers", "Thomas", "Ferrari", "Vittorio"], "venue": null, "citeRegEx": "Alexe et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Alexe et al\\.", "year": 2012}, {"title": "Deep learning with cots hpc systems", "author": ["Coates", "Adam", "Huval", "Brody", "Wang", "Tao", "Wu", "David", "Catanzaro", "Bryan", "Andrew", "Ng"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Coates et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2013}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Li-Jia", "Kai", "Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Category independent object proposals", "author": ["Endres", "Ian", "Hoiem", "Derek"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "Endres et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Endres et al\\.", "year": 2010}, {"title": "Object detection with discriminatively trained part-based models", "author": ["Felzenszwalb", "Pedro F", "Girshick", "Ross B", "McAllester", "David", "Ramanan", "Deva"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2010}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["Girshick", "Ross", "Donahue", "Jeff", "Darrell", "Trevor", "Malik", "Jitendra"], "venue": "arXiv preprint arXiv:1311.2524,", "citeRegEx": "Girshick et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Girshick et al\\.", "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoff"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Deep neural networks for object detection", "author": ["Szegedy", "Christian", "Toshev", "Alexander", "Erhan", "Dumitru"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Szegedy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2013}, {"title": "Selective search for object recognition", "author": ["JRR Uijlings", "KEA van de Sande", "T Gevers", "Smeulders", "AWM"], "venue": "International Journal of Computer Vision, pp", "citeRegEx": "Uijlings et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Uijlings et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "This approach harnesses the notion of object-ness (Endres & Hoiem, 2010; Alexe et al., 2012; Uijlings et al., 2013) to build a deep neural network (Krizhevsky et al.", "startOffset": 50, "endOffset": 115}, {"referenceID": 8, "context": "This approach harnesses the notion of object-ness (Endres & Hoiem, 2010; Alexe et al., 2012; Uijlings et al., 2013) to build a deep neural network (Krizhevsky et al.", "startOffset": 50, "endOffset": 115}, {"referenceID": 6, "context": ", 2013) to build a deep neural network (Krizhevsky et al., 2012) able to detect novel objects where bounding box labels have not been provided.", "startOffset": 39, "endOffset": 64}, {"referenceID": 4, "context": "One successful approach to object detection is to train a single detector for each class of objects (for example, the Deformable Parts Model (DPM) (Felzenszwalb et al., 2010)).", "startOffset": 147, "endOffset": 174}, {"referenceID": 2, "context": "For example, the Image-Net dataset has 14 million class labels but only about 7% are labeled with bounding boxes (Deng et al., 2009).", "startOffset": 113, "endOffset": 132}, {"referenceID": 0, "context": "Recently, region proposal algorithms have shown good performance in object detection pipelines by proposing class-generic locations for further classification (Endres & Hoiem, 2010; Alexe et al., 2012; Girshick et al., 2013; Uijlings et al., 2013).", "startOffset": 159, "endOffset": 247}, {"referenceID": 5, "context": "Recently, region proposal algorithms have shown good performance in object detection pipelines by proposing class-generic locations for further classification (Endres & Hoiem, 2010; Alexe et al., 2012; Girshick et al., 2013; Uijlings et al., 2013).", "startOffset": 159, "endOffset": 247}, {"referenceID": 8, "context": "Recently, region proposal algorithms have shown good performance in object detection pipelines by proposing class-generic locations for further classification (Endres & Hoiem, 2010; Alexe et al., 2012; Girshick et al., 2013; Uijlings et al., 2013).", "startOffset": 159, "endOffset": 247}, {"referenceID": 7, "context": "(Szegedy et al., 2013) have used a similar neural network for object detection in Pascal VOC.", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "that focus on high-recall object-ness detection (Endres & Hoiem, 2010; Alexe et al., 2012; Uijlings et al., 2013).", "startOffset": 48, "endOffset": 113}, {"referenceID": 8, "context": "that focus on high-recall object-ness detection (Endres & Hoiem, 2010; Alexe et al., 2012; Uijlings et al., 2013).", "startOffset": 48, "endOffset": 113}, {"referenceID": 6, "context": "The Convolutional Neural Network (CNN) we use is similar to that proposed by (Krizhevsky et al., 2012) for object classification.", "startOffset": 77, "endOffset": 102}, {"referenceID": 6, "context": "See (Krizhevsky et al., 2012) for details.", "startOffset": 4, "endOffset": 29}, {"referenceID": 6, "context": "In the image classification results from (Krizhevsky et al., 2012), the final feature vector is input to a softmax layer which provides a probability distribution over class labels.", "startOffset": 41, "endOffset": 66}, {"referenceID": 1, "context": "To perform our experiments, we use multiple GPUs for training (Coates et al., 2013; Krizhevsky et al., 2012).", "startOffset": 62, "endOffset": 108}, {"referenceID": 6, "context": "To perform our experiments, we use multiple GPUs for training (Coates et al., 2013; Krizhevsky et al., 2012).", "startOffset": 62, "endOffset": 108}, {"referenceID": 2, "context": "All experiments were performed on the Imagenet 2012 Localization Challenge (Deng et al., 2009).", "startOffset": 75, "endOffset": 94}], "year": 2013, "abstractText": "We investigate the use of deep neural networks for the novel task of class-generic object detection. We show that neural networks originally designed for image recognition can be trained to detect objects within images, regardless of their class, including objects for which no bounding box labels have been provided. In addition, we show that bounding box labels yield a 1% performance increase on the ImageNet recognition challenge.", "creator": "LaTeX with hyperref package"}}}