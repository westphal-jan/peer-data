{"id": "1401.0509", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2013", "title": "Zero-Shot Learning for Semantic Utterance Classification", "abstract": "We propose two novel zero-shot learning methods for semantic utterance classification (SUC) using deep learning. Both approaches rely on learning deep semantic embeddings from a large amount of Query Click Log data obtained from a search engine. Traditional semantic utterance classification systems require large amounts of labelled data, whereas our proposed methods make use of the structure of the task to allow classification without labeled data. We also develop a zero-shot semantic clustering algorithm for extracting discriminative features for supervised semantic utterance classification systems. We demonstrate the effectiveness of the zero-shot semantic learning algorithm on the SUC dataset collected by \\cite{DCN}. Furthermore, we show that extracting features using zero-shot semantic clustering for a linear SVM reaches state-of-the-art result on that dataset.", "histories": [["v1", "Fri, 20 Dec 2013 17:08:26 GMT  (209kb,D)", "http://arxiv.org/abs/1401.0509v1", null], ["v2", "Tue, 18 Feb 2014 20:34:08 GMT  (520kb,D)", "http://arxiv.org/abs/1401.0509v2", null], ["v3", "Fri, 7 Mar 2014 23:31:02 GMT  (520kb,D)", "http://arxiv.org/abs/1401.0509v3", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["yann n dauphin", "gokhan tur", "dilek hakkani-tur", "larry heck"], "accepted": false, "id": "1401.0509"}, "pdf": {"name": "1401.0509.pdf", "metadata": {"source": "CRF", "title": "Zero-Shot Learning and Clustering for Semantic Utterance Classification", "authors": ["Yann N. Dauphin", "Gokhan Tur", "Dilek Hakkani-T\u00fcr", "Larry Heck"], "emails": [], "sections": [{"heading": null, "text": "We propose two novel zero-shot learning methods for semantic expression classification (SUC) using deep learning. Both approaches are based on learning deep semantic embedding from a large amount of query click log data obtained from a search engine. Conventional semantic expression classification systems require large amounts of labeled data, while our proposed methods use the structure of the task to enable classification without labeled data. In addition, we develop a zero-shot clustering algorithm to extract discriminatory features for monitored semantic expression classification systems. We demonstrate the effectiveness of the zero-shot semantic learning algorithm on the SUC dataset collected by [1]. Furthermore, we demonstrate that the extraction of features using zero-shot semantic clustering for a linear SVM is state-of-the-art."}, {"heading": "1 Introduction", "text": "Conversational understanding systems aim to automatically classify the user request into one of the predefined semantic categories and extract related arguments [2]. Typically, supervised classification methods are used to estimate conditional probabilities, and a number of marked expressions are used in training. Typically, such systems use established classification algorithms, such as boosting [3], supporting vector machines (SVMs) [4], or maximum entropy models [5]. Following recent advances in deep learning techniques, we present in this paper the application of deep networks trained in a conversation understanding system with large amounts of implicitly commented data for the semantic utterance classification (SUC). In this respect, this study proposes a new approach that differs significantly from previous work using deep learning as an alternative classification technique [6, 1, 7]."}, {"heading": "2 Semantic Utterance Classification", "text": "The Semantic Enunciation Classification (SUC) aims to classify a given speech utterance Xr into one of the M-semantic classes, where r is the expression index. After observing Xr, C-r is chosen to maximize the class-back probability Xr, P (Cr | Xr), isar Xiv: 140 1.05 09v1 [cs.CL] 2 0D ec2 01. More formally, C-r = argmax Cr P (Cr | Xr). (1) Semantic classifiers must allow significant expression variations. A user can say, \"I want to fly from San Francisco to New York next Sunday,\" and another user can express the same information by saying, \"Show me weekend flights between JFK and SFO.\" Not only is there an a-priori limitation on what the user can say, these systems must also have a generation of data from the weekend class. \""}, {"heading": "3 Related work", "text": "Early work on spoken expression classification was carried out mainly for call routing or the intention-determining system, such as the AT & T How May I Help You? (HMIHY) system [9], relying on saliciency phrases or the Lucent Bell Labs vector-space model [10]. With advances in machine learning, particularly in discriminatory classification techniques, researchers have been able to apply standard classification algorithms over the past decade. Typically, word-n-grams are used as features after pre-processing with generic units such as data, locations or telephone numbers. Due to the very large size of the input room, large margin classification algorithms such as SVMs [4] or Boosting [3] were found to be very good candidates. Deep learning methods were first used for semantic expression classification by Sarikaya et al. [6]."}, {"heading": "4 Query Click Logs", "text": "Query Click Logs (QCL) are logs of unstructured text that contain both the user requests sent to a search engine and the links that users clicked on from the list of sites returned by that search engine. A common representation of this data is a two-part query / click graph, as shown in Figure 2, where one set of nodes represents queries and the other set of nodes represents URLs, and an edge is placed between two nodes representing a query q and a URL u when at least one user who entered q has clicked. Traditionally, the edge of the click chart is weighted to a URL based on the raw click frequency (number of clicks) from a query. Some of the challenges in extracting useful information from QCL is that the feature space is very highly dimensional (there are thousands of URL clicks associated with many queries) and there are millions of queries logged daily."}, {"heading": "5 Zero-Shot Semantic Learning", "text": "In fact, most people are able to recognize themselves and understand what they are doing to change the world."}, {"heading": "6 Zero-Shot Semantic Clustering", "text": "In fact, it is so that it is a matter of a way in which the people in the individual countries behave in a way as they do in the USA. (...) It is as if they were able to establish themselves in the USA. (...) It is as if they were able to establish themselves in the USA. (...) It is as if in the USA they were able to learn in the USA. (...) It is as if in the USA in the USA they were able to live in the USA. (...) It is as if in the USA in the USA in the USA they were able to live in the USA. (...) It is as if in the United States of the United States of the United States of the United States of the United States of the United States, of the United States of the United States of the United States of the United States, of the United States of the United States of the United States, of the United States of the United States of the United States, of the United States of the United States of the United States of the United States, of the United States of the United States of the United States, of the United States of the United States of the United States of the United States, of the United States of the United States of the United States of the United States of the United States, of the United States of the United States of the United States of the United States, of the United States of the United States of the United States of the United States of the United States, of the United States of the United States of the United States of the United States, of the United States of the United States of the United States of the United States of the United States of the United States, of the United States of the United States of the United States of the United States of the United States of the United States, United States of the United States of the United States of the United States of the United States of the United States, United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States, United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States, United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States of the United States of"}, {"heading": "7 Experiments", "text": "In this section, we evaluate the proposed semantic learning and clustering methods proposed in the previous sections. We have spent a month collecting query log data from a search engine to learn the embedding. We have limited the web pages to the 1000 most popular web pages in this log. However, the words in the word pocket are the 9521 found in the supervised SUC task that we will use. All queries containing only unknown words have been filtered out. We found that using a list of stop words improves the results. After these limitations, the dataset includes 620,474 different queries. We evaluate the performance of the methods for SUC on the datasets collected by users of a spoken dialogue system. There are 16,000 training comments, 2000 comments for validation and 2000 comments for testing. Each comment is marked with one of 25 domains. The hyper parameters of the models are matched to the validation."}, {"heading": "8 Conclusion", "text": "We have presented two new methods of zero-shot learning for SUC: Zero-shot semantic learning allows classification without labels with applications for SUC problems with a large number of classes. Zero-shot semantic clustering is a method of feature extraction for traditional SUC systems. Both approaches use unlabeled data through deep learning and our experiments have shown the effectiveness of both methods."}], "references": [{"title": "Towards deeper understanding deep convex networks for semantic utterance classification", "author": ["G. Tur", "L. Deng", "D. Hakkani-T\u00fcr", "X. He"], "venue": "In Proceedings of the ICASSP, Kyoto, Japan, March 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Spoken Language Understanding: Systems for Extracting Semantic Information from Speech", "author": ["G. Tur", "R. De Mori", "Eds"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Boostexter: A boosting-based system for text categorization", "author": ["R.E. Schapire", "Y. Singer"], "venue": "Machine Learning, vol. 39, no. 2/3, pp. 135\u2013168, 2000.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2000}, {"title": "Optimizing SVMs for complex call classification", "author": ["P. Haffner", "G. Tur", "J. Wright"], "venue": "Proceedings of the ICASSP, Hong Kong, April 2003. 7", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "An integrative and discriminative technique for spoken utterance classification", "author": ["S. Yaman", "L. Deng", "D. Yu", "Y.-Y. Wang", "A. Acero"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 16, no. 6, pp. 1207\u20131214, 2008.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Deep belief nets for natural language callrouting", "author": ["R. Sarikaya", "G.E. Hinton", "B. Ramabhadran"], "venue": "Proceedings of the ICASSP, Prague, Czech Republic, 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Use of kernel deep convex networks and end-to-end learning for spoken language understanding", "author": ["L. Deng", "G. Tur", "X. He", "D. Hakkani-T\u00fcr"], "venue": "In Prooceedings of the IEEE SLT Workshop, Miami, FL, December 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Intent Determination and Spoken Utterance Classification, Chpater 3 in Book: Spoken Language Understanding", "author": ["G. Tur", "L. Deng"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "How May I Help You", "author": ["A.L. Gorin", "G. Riccardi", "J.H. Wright"], "venue": "Speech Communication, vol. 23, pp. 113\u2013127, 1997.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "Vector-based natural language call routing", "author": ["J. Chu-Carroll", "B. Carpenter"], "venue": "Computational Linguistics, vol. 25, no. 3, pp. 361\u2013388, 1999.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1999}, {"title": "Deep convex nets: A scalable architecture for speech pattern classification", "author": ["L. Deng", "D. Yu"], "venue": "Proceedings of the Interspeech, Florence, Italy, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Scalable stacking and learning for building deep architectures", "author": ["L. Deng", "D. Yu", "J. Platt"], "venue": "Proc. ICASSP, Kyoto, Japan, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Zero-data learning of new tasks", "author": ["Hugo Larochelle", "Dumitru Erhan", "Yoshua Bengio"], "venue": "AAAI Conference on Artificial Intelligence, 2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Zero-shot learning with semantic output codes", "author": ["Mark Palatucci", "Dean Pomerleau", "Geoffrey E Hinton", "Tom M Mitchell"], "venue": "Advances in neural information processing systems, 2009, pp. 1410\u20131418.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Neural net language models", "author": ["Yoshua Bengio"], "venue": "Scholarpedia, vol. 3, no. 1, pp. 3881, 2008.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Deep sparse rectifier neural networks", "author": ["Xavier Glorot", "Antoine Bordes", "Yoshua Bengio"], "venue": "JMLR W&CP: Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2011), Apr. 2011.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey Hinton"], "venue": "Advances in Neural Information Processing Systems 25 (NIPS\u20192012). 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["Xavier Glorot", "Antoine Bordes", "Yoshua Bengio"], "venue": "Proceedings of theTwenty-eight International Conference on Machine Learning (ICML\u201911) [25], pp. 97\u2013110.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 0}, {"title": "Classification using discriminative restricted Boltzmann machines", "author": ["Hugo Larochelle", "Yoshua Bengio"], "venue": "Proceedings of the Twenty-fifth International Conference on Machine Learning (ICML\u201908), William W. Cohen, Andrew McCallum, and Sam T. Roweis, Eds. 2008, pp. 536\u2013543, ACM.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E. Hinton", "Simon Osindero", "Yee Whye Teh"], "venue": "Neural Computation, vol. 18, pp. 1527\u20131554, 2006.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["Pascal Vincent", "Hugo Larochelle", "Isabelle Lajoie", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "venue": "Journal of Machine Learning Research, vol. 11, pp. 3371\u2013 3408, Dec. 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Contractive auto-encoders: Explicit invariance during feature extraction", "author": ["Salah Rifai", "Pascal Vincent", "Xavier Muller", "Xavier Glorot", "Yoshua Bengio"], "venue": "Proceedings of theTwentyeight International Conference on Machine Learning (ICML\u201911) [25].", "citeRegEx": "22", "shortCiteRegEx": null, "year": 0}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Geoffrey E. Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "Tech. Rep., arXiv:1207.0580, 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Exploiting query click logs for utterance domain detection in spoken language understanding", "author": ["D. Hakkani-T\u00fcr", "L. Heck", "G. Tur"], "venue": "Proceedings of the ICASSP, Prague, Czech Republic, 2011. 8", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "We demonstrate the effectiveness of the zero-shot semantic learning algorithm on the SUC dataset collected by [1].", "startOffset": 110, "endOffset": 113}, {"referenceID": 1, "context": "Conversational understanding systems aim to automatically classify the user request in one of the predefined semantic categories and extract related arguments [2].", "startOffset": 159, "endOffset": 162}, {"referenceID": 2, "context": "Such systems typically use established classification algorithms, such as Boosting [3], support vector machines (SVMs) [4], or maximum entropy models [5].", "startOffset": 83, "endOffset": 86}, {"referenceID": 3, "context": "Such systems typically use established classification algorithms, such as Boosting [3], support vector machines (SVMs) [4], or maximum entropy models [5].", "startOffset": 119, "endOffset": 122}, {"referenceID": 4, "context": "Such systems typically use established classification algorithms, such as Boosting [3], support vector machines (SVMs) [4], or maximum entropy models [5].", "startOffset": 150, "endOffset": 153}, {"referenceID": 5, "context": "In that respect, this study proposes a novel approach that is significantly different from the previous works which employ deep learning as an alternative classification technique [6, 1, 7].", "startOffset": 180, "endOffset": 189}, {"referenceID": 0, "context": "In that respect, this study proposes a novel approach that is significantly different from the previous works which employ deep learning as an alternative classification technique [6, 1, 7].", "startOffset": 180, "endOffset": 189}, {"referenceID": 6, "context": "In that respect, this study proposes a novel approach that is significantly different from the previous works which employ deep learning as an alternative classification technique [6, 1, 7].", "startOffset": 180, "endOffset": 189}, {"referenceID": 7, "context": "Typically, binary or weighted n-gram features, with n = 1, 2, 3, to capture the likelihood of the n-grams, are generated to express the user intent for the semantic class C [8].", "startOffset": 173, "endOffset": 176}, {"referenceID": 8, "context": "Early work on spoken utterance classification has been done mostly for call routing or intent determination system, such as the AT&T How May I Help You? (HMIHY) system [9], relying on salience phrases, or the Lucent Bell Labs vector space model [10].", "startOffset": 168, "endOffset": 171}, {"referenceID": 9, "context": "Early work on spoken utterance classification has been done mostly for call routing or intent determination system, such as the AT&T How May I Help You? (HMIHY) system [9], relying on salience phrases, or the Lucent Bell Labs vector space model [10].", "startOffset": 245, "endOffset": 249}, {"referenceID": 3, "context": "Because of the very large dimensions of the input space, large margin classifiers such as SVMs [4] or Boosting [3] were found to be very good candidates.", "startOffset": 95, "endOffset": 98}, {"referenceID": 2, "context": "Because of the very large dimensions of the input space, large margin classifiers such as SVMs [4] or Boosting [3] were found to be very good candidates.", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "In our earlier work, we have investigated the use of deep learning methods, namely Deep Convex Networks (DCNs) [1] and Kernel DCNs (K-DCNs) [7], for semantic utterance classification using lexical, named entity, and query click features.", "startOffset": 111, "endOffset": 114}, {"referenceID": 6, "context": "In our earlier work, we have investigated the use of deep learning methods, namely Deep Convex Networks (DCNs) [1] and Kernel DCNs (K-DCNs) [7], for semantic utterance classification using lexical, named entity, and query click features.", "startOffset": 140, "endOffset": 143}, {"referenceID": 10, "context": "DCN is shown to be superior to DBN, not only in terms of accuracy, but also in training scalability and efficiency [11, 12].", "startOffset": 115, "endOffset": 123}, {"referenceID": 11, "context": "DCN is shown to be superior to DBN, not only in terms of accuracy, but also in training scalability and efficiency [11, 12].", "startOffset": 115, "endOffset": 123}, {"referenceID": 12, "context": "This is a form of zero-shot learning [13, 14].", "startOffset": 37, "endOffset": 45}, {"referenceID": 13, "context": "This is a form of zero-shot learning [13, 14].", "startOffset": 37, "endOffset": 45}, {"referenceID": 14, "context": "This learning scheme is inspired by the neural language models [15] who learn word embeddings by learning to predict the next word in a sentence.", "startOffset": 63, "endOffset": 67}, {"referenceID": 15, "context": "Though rectified linear units are not smooth, research [16, 17] has shown that they can greatly improve the speed of learning of the network.", "startOffset": 55, "endOffset": 63}, {"referenceID": 16, "context": "Though rectified linear units are not smooth, research [16, 17] has shown that they can greatly improve the speed of learning of the network.", "startOffset": 55, "endOffset": 63}, {"referenceID": 17, "context": "The embeddings described in Section 5 could be useful and it has been shown [18, 19] that using unsupervised learning algorithms like the restricted Boltzmann machine [20] can help leverage this additional data.", "startOffset": 76, "endOffset": 84}, {"referenceID": 18, "context": "The embeddings described in Section 5 could be useful and it has been shown [18, 19] that using unsupervised learning algorithms like the restricted Boltzmann machine [20] can help leverage this additional data.", "startOffset": 76, "endOffset": 84}, {"referenceID": 19, "context": "The embeddings described in Section 5 could be useful and it has been shown [18, 19] that using unsupervised learning algorithms like the restricted Boltzmann machine [20] can help leverage this additional data.", "startOffset": 167, "endOffset": 171}, {"referenceID": 19, "context": "It is satisfied by the various pretraining methods like restricted Boltzmann machines [20] and regularized auto-encoders [21, 22].", "startOffset": 86, "endOffset": 90}, {"referenceID": 20, "context": "It is satisfied by the various pretraining methods like restricted Boltzmann machines [20] and regularized auto-encoders [21, 22].", "startOffset": 121, "endOffset": 129}, {"referenceID": 21, "context": "It is satisfied by the various pretraining methods like restricted Boltzmann machines [20] and regularized auto-encoders [21, 22].", "startOffset": 121, "endOffset": 129}, {"referenceID": 0, "context": "We evaluate the performance of the methods for SUC on the dataset gathered by [1].", "startOffset": 78, "endOffset": 81}, {"referenceID": 22, "context": "We found that it was helpful to regularize the networks using dropout [23].", "startOffset": 70, "endOffset": 74}, {"referenceID": 23, "context": "09% QCL features [24] 5.", "startOffset": 17, "endOffset": 21}], "year": 2017, "abstractText": "We propose two novel zero-shot learning methods for semantic utterance classification (SUC) using deep learning. Both approaches rely on learning deep semantic embeddings from a large amount of Query Click Log data obtained from a search engine. Traditional semantic utterance classification systems require large amounts of labelled data, whereas our proposed methods make use of the structure of the task to allow classification without labeled data. We also develop a zero-shot semantic clustering algorithm for extracting discriminative features for supervised semantic utterance classification systems. We demonstrate the effectiveness of the zero-shot semantic learning algorithm on the SUC dataset collected by [1]. Furthermore, we show that extracting features using zero-shot semantic clustering for a linear SVM reaches state-of-the-art result on that dataset.", "creator": "LaTeX with hyperref package"}}}