{"id": "1401.3427", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Analogical Dissimilarity: Definition, Algorithms and Two Experiments in Machine Learning", "abstract": "This paper defines the notion of analogical dissimilarity between four objects, with a special focus on objects structured as sequences. Firstly, it studies the case where the four objects have a null analogical dissimilarity, i.e. are in analogical proportion. Secondly, when one of these objects is unknown, it gives algorithms to compute it. Thirdly, it tackles the problem of defining analogical dissimilarity, which is a measure of how far four objects are from being in analogical proportion. In particular, when objects are sequences, it gives a definition and an algorithm based on an optimal alignment of the four sequences. It gives also learning algorithms, i.e. methods to find the triple of objects in a learning sample which has the least analogical dissimilarity with a given object. Two practical experiments are described: the first is a classification problem on benchmarks of binary and nominal data, the second shows how the generation of sequences by solving analogical equations enables a handwritten character recognition system to rapidly be adapted to a new writer.", "histories": [["v1", "Wed, 15 Jan 2014 04:42:13 GMT  (343kb)", "http://arxiv.org/abs/1401.3427v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["laurent miclet", "sabri bayoudh", "arnaud delhay"], "accepted": false, "id": "1401.3427"}, "pdf": {"name": "1401.3427.pdf", "metadata": {"source": "CRF", "title": "Analogical Dissimilarity: Definition, Algorithms and Two Experiments in Machine Learning", "authors": ["Laurent Miclet", "Sabri Bayoudh", "Arnaud Delhay"], "emails": ["LAURENT.MICLET@UNIV-RENNES1.FR", "SABRI.BAYOUDH@UNIV-ST-ETIENNE.FR", "ARNAUD.DELHAY@UNIV-RENNES1.FR"], "sections": [{"heading": null, "text": "It focuses on objects structured as sequences. First, it examines the case where the four objects exhibit zero analog dissimilarity, i.e. are in an analog relationship. Second, if one of these objects is unknown, there are algorithms to calculate it. Third, there is the problem of defining analog dissimilarity, which is a measure of how far four objects are from an analog relationship. Specifically, if objects are sequences, there is a definition and an algorithm based on an optimal alignment of the four sequences. Furthermore, there are learning algorithms, i.e. methods to find three times as many objects in a study sample that exhibit the least analog dissimilarity to a given object. Two practical experiments are described: The first is a classification problem based on benchmarks of binary and nominal data, and the second shows how sequence generation by the solver can be quickly adapted to a new handwriting system."}, {"heading": "1. Introduction", "text": "Analogy is a way of thinking that has been studied throughout the history of philosophy and is widely used in artificial intelligence and linguistics. In this essay, we focus on a limited concept of analogy called \"analog proportion.\""}, {"heading": "1.1 Analogical Proportion between Four Elements", "text": "An analogous ratio between the four elements A, B, C, and D in the same universe is usually expressed as follows: \"A is for B as C is for D.\" Depending on the element, analogous proportions can have very different meanings1. They are based, for example, on the semantics of words. In contrast, the above examples show the intrinsic ambiguities in defining an analogous ratio. \"abcd is for abc as abbd is for abb\" or \"g is for gt as gg is for ggt.\" Morphologically or not, the above examples show the intrinsic ambiguities in defining an analogous ratio. We could also accept that \"g is for gt as well as gg for ggt\" for other good reasons."}, {"heading": "1.2 Solving Analogical Equations", "text": "When one of the four elements is unknown, an analog ratio turns into an equation. For example, on sequences of letters, the analog ratio \"Wolf shall leaf like Wolf to x\" corresponds to the equation S = {x | Wolf shall leaf like Wolf to x. \"The solution to this equation consists in calculating the (possibly empty) set of sequences x that fulfills the analogy. Sequence sheets are an exact semantic and morphological solution. However, we will see that it is not easy to design an algorithm that is able to solve this type of equation, especially in the search for an approximate solution, if necessary. Solving analog equations on sequences is useful for linguistic analysis tasks and has mainly been applied (using empirical resolution techniques or in simple cases) to lexical analysis tasks. For example, Yvon (1999) provides an analog approach for elements to phonematic analysis tasks in general and can be found with the help of text analysis."}, {"heading": "1.3 Using Analogical Proportions in Machine Learning", "text": "Let S = {(x, u (x))} be a finite set of educational examples, where x is the description of an example (x can be a sequence or a vector in Rn, for example) and u (x) its designation in a finite set. In view of the description of a new pattern, we would like to assign a designation u (y) to y, which is based only on the knowledge of S. This is the problem of inductive learning of a classification rule of examples, which consists in finding the value of u at dot y (Mitchell, 1997). The next neighbor method, which is the most popular lazy learning method, simply finds in S the description x, which minimizes a certain distance to y and hypothesizes u (x), the label of x, for the label of y.Moving one step further, learning from analogical proportions is such in S for a triple (x, z, t) search in a domance. \""}, {"heading": "1.4 Related Work", "text": "We are related to several areas of artificial intelligence. Obviously, the first idea is that thinking is defined by analogy. A lot of work has been done on this subject from a cognitive point of view that has led to computer-based models of thinking: see, for example, the classic paper (Falkenhainer, Forbus, & Gentner, 1989), the book (Gentner, Holyoak, & Kokinov, 2001) and the more recent study (Holyoak, 2005). Normally, these works use the term transmission, which does not fall within the scope of this article. It means that some knowledge about solving a problem is transported to another area. As we are working on four objects located in the same space, we implicitly ignore the notion of transmission between different areas. Technically speaking, these limitations allow us to use \"exchange of means.\""}, {"heading": "1.5 Organization of the Paper", "text": "This work is divided into six sections. After this introduction, in section 2 we present the general principles that govern the definition of an analog ratio between four objects in the same set, and we define what an analog equation is in a set. We apply these definitions in Rn and {0, 1} n. Finally, this section defines the analog ratio between four sequences in an alphabet in which an analogy is defined, using an optimal alignment method between the four sequences.Section 3 introduces the new concept of analog dissimilarity (AD) between four objects by measuring in some way how much these objects are in analogy. In particular, it must be tantamount to saying that four objects are in analogy and that their analog dissimilarity is zero. Then we expand it to sequences that yield two algorithms: SEQUANA4 calculates the value of the four sequences and SANVOLA."}, {"heading": "2. Analogical Proportions and Equations", "text": "In this section we give a formal definition of the analog ratio between four objects and explain what an analog equation should solve. Instances of general definitions are given if the objects are either finite sets (or equivalent binary vectors) or vectors of real numbers or sequences of finite alphabets."}, {"heading": "2.1 The Axioms of Analogical Proportion", "text": "The meaning of an analogous ratio A: B:: C: D between four objects in a set X depends on the nature of X, in which the \"is to\" and the \"as\" relations must be defined. Nevertheless, general properties can be requested, according to the usual meaning of the word \"analogy\" in philosophy and linguistics. If (A, B, C, D) three fundamental axioms can be given: Definition 2.1 (analogous ratio) An analogous ratio to a set X is a relationship to X4, i.e. a subset A: X4. If (A: B::: C, D), the four elements A, B, C and D are said to an analogous ratio, and we write: \"the analogous ratio A::: C::: D applies\" or simply A: B: C: D: D applies to a subset A: X4. If (A: B::: C: D: D reads \"A is to B: D as C to an analogous ratio, and we write:\" the analogous ratio A::: \"the ratio A::: C::: C: D applies\" or simply A: A: C: C: C: A subset A: X4: X4. \"D: D: D applies to a subset A: X4.\" If (A: X4), D: X4 applies to a subset A: X4."}, {"heading": "2.2 Analogical Equations", "text": "The solution to an analogous equation is to find the fourth term of an analogous ratio, with the first three known. Definition 2.2 (analogous equation) D is a solution to the analogous equation A: B:: C: x, if and only if A: B:: C: D. We already know from earlier sections that an analogous equation can have either no solution or a unique solution or several solutions, depending on the nature of the objects and definition of the analogy."}, {"heading": "2.3 Analogical Proportion between Finite Sets and Binary Objects", "text": "If the \"as\" ratio is equality between sets, Lepage has given a definition of an analogous ratio between sets that is consistent with the axioms, which will be useful in Section 2.3.2, where objects are described by groups of binary characters."}, {"heading": "2.3.1 AN ANALOGICAL PROPORTION IN FINITE SETS", "text": "Definition 2.3 (Analogous ratio between finite sets) Four sets A, B, C and D are in an analogous ratio A: B:: C: D, if and only if A can be converted to B and C to D by adding and subtracting the same elements to A and C. This is the case, for example, with the four sets: A = {t1, t2, t3, t4,}, B = {t1, t2, t3, t5} and C = {t1, t4, t6, t7}, D = {t1, t5, t6, t7}, where t4 was added from A to C and t5 to A to D, giving B and D."}, {"heading": "2.3.2 SOLVING ANALOGICAL EQUATIONS IN FINITE SETS", "text": "Considering the analogy in sets, Lepage (2003) has pointed out the following theorem with regard to the axioms of analogy (Section 2.1): Theorem 2.4 (Solution of an analogous equation in sets) Let A, B and C. The analogous equation A: B:: C: D, where D is the unknown, has a solution if and only if the following conditions apply:"}, {"heading": "A \u2286 B \u222a C and A \u2287 B \u2229 C", "text": "The solution is then unique, given by: D = (((B-C)\\ A) (B-C) 2.3.3 ANALOGICAL PROPORTIONS IN {0, 1} nLet X now be the quantity {0, 1} n. For each x-X and each i-X [1, n], fi (x) = 1 (or fi (x) = 0) means that the binary attribute fi is the value TRUE (or FALSE) on the object x. Let A: B:: C: D be an analogue equation. \u2022 For each attribute fi there are only eight different possibilities of values on A, B and C. We can derive the solutions from the definition and properties of the analogy on sets, using the two following principles: \u2022 Each attribute fi (D) can be independently compressed. \u2022 The following table gives the solution fi (D): fi (A) 0 0 1 fi (B) 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 (2)."}, {"heading": "2.4 Analogical Proportion in Rn", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.4.1 DEFINITION", "text": "Let O be the origin of Rn. Let a = (a1, a2,.., an) be a vector of Rn as defined by its n coordinates. Let a, b, c and d be four vectors of Rn. The interpretation of an analogous ratio a: b:: c: d is usually that a, b, c, d are the corners of a parallelogram, a and d are opposite corners (see Figure 1). Definition 2.5 (analogous ratio in Rn) Four elements of Rn are in the analogous ratio (a: b:: c: d), if and only if they form a parallelogram, then this is the case \u2212 \u2192 Oa + \u2212 \u2192 Od = \u2212 \u2192 Whether + \u2212 \u2192 Oc or equivalent \u2212 \u2192 Oc or equivalent \u2212 ab = \u2192 cd or equivalent \u2212 the equation:"}, {"heading": "2.5 Analogical Proportion between Sequences", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.5.1 NOTATIONS", "text": "A sequence2 is a finite series of symbols from a finite alphabet \u03a3. The set of all sequences is called \u03a3. X, y stands for the concatenation of x and y. we also denote | x | = n the length of x, and we write x as x = x1.... x | or x = x [1]... x [n], with xi or x [i]. We denote the empty word, the zero length, and \u03a3 + = \u03a3. A factor (or subword) for a sequence x is a sequence in \u03a3, so that there are two sequences u and v in \u03a3 with: x = ufv. For example, Abb and bbac are factors of abbacbbaba.A subsequence of a sequence x = x1.... x | x | | is composed of the letters x with the indices 1. ik, so that Abb and bbac are factors of abbacbbaba.A subsequence of a sequence x = x1. < for babies < two; < < for babies."}, {"heading": "2.5.2 DEFINITION", "text": "symbol that we will need in subsequent sections. Definition 2.6 (Semantic Equivalence) Let us assume that x is a sequence of three letters and a sequence of four letters and a sequence of four letters. Let us assume that there is an analogy between two letters and a sequence of four letters, i.e. that for every fourth letter a, b, c, d letters of the digit x, the relationship a: b:: c: d is defined as either TRUE or FALSE.Definition 2.7 (Alignment between two sequences) A sequence x: a sequence x, c: d letters of the digits of the digits of the digits of the digits x is either TRUE or FALSE.Definition 2.7 (Alignment between two sequences) A sequence between two sequences A sequence x: A sequence x is a sequence between two digits digits digits digits x."}, {"heading": "3. Analogical Dissimilarity", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Motivation", "text": "In this section, we are interested in defining a relaxed analogy, whose linguistic expression \"a is almost as c is to d\" would be. In order to remain consistent with our previous definitions, we measure the term \"almost\" by a positive real value equivalent to 0 if the analogy is true, and increase it if the four objects are less likely to be in analogy. We also want this value, which we call \"analog inequality\" (AD), to have good properties in relation to the analogy. We want it to be symmetrical in order to remain unchanged if we permutate the mean terms of analogy and finally respect a triangular inequality. These requirements allow us to generalize in Section 4 AD a classical fast neighbor search algorithm and to exhibit an algorithmic learning process designed to extract the principle of non-uniformity, three times the number of objects that have the least AD."}, {"heading": "3.2.1 PROPERTIES", "text": "In this definition, the analog dissimilarity has the following properties: Property 3.1 (Properties of AD in {0, 1} n) Coherence with Analogy. (AD (u, v, w, x) = 0) \u21d4 u: v:: w: xSymmetry for \"as.\" AD (u, v, w, x) = AD (w, x, u, v) Exchange of medians. AD (u, v, w, x) = AD (u, w, v, x) Triangular inequality. AD (u, v, z, t) \u2264 AD (u, v, w, x) + AD (w, x, z, t) Asymmetry for \"is to.\" Generally: AD (u, v, w, x) 6 = AD (v, u, w, x) The first properties are relatively simple from the definition. The demonstration of the third is also simple."}, {"heading": "3.3 Analogical Dissimilarity in Rn", "text": "The analogous dissimilarity between four vectors must in some way reflect how far they are from the construction of a parallelogram. Four vectors u, v, w and x are in an analogous relationship (i.e. they form a parallelogram) to opposite sides \u2212 \u2192 uv and \u2212 \u2192 wx, if and only if \u2212 \u2192 Ou + \u2212 \u2192 Ox = \u2212 Ov + \u2212 or equivalent u + x = v + w, we have chosen the following definition (see Figure 2): Definition 3.3 (Analogous dissimilarity between vectors) \u2212 (v + w).It is equivalent to the inequality between the properties AD (u, v, w, w, w): x."}, {"heading": "3.4 Analogical Dissimilarity between Sequences", "text": "The first algorithm, called SEQUANA4, calculates the analogue dissimilarity between four sequences in sequence; the second algorithm, called SOLVANA, generates the Directed Acyclic Graph (DAG) of all solutions in an analogue equation of the sequences; if there is no solution, this results in the DAG of all sentences having the least analogue dissimilarity when associated with the three known sentences of the equation.These two algorithms are quite general in that they do not make any particular assumption about the alphabet of the sequences.This alphabet is simply extended to \u03a3 \u00b2 = \u03a3 \u00b2 = \u03a3 \u00b2 in order to generate analogies, as described in Section 2.5. The analogue dissimilarity of the individual sequences must be such that: AD (, a), a = 0, b = \u03a3 \u00b2 = \u03a3 \u00b2, and c, but no more is required for each of the others."}, {"heading": "3.4.1 DEFINITION", "text": "We now assume that there is an analogous dissimilarity between four sequences, but the analogous dissimilarity between four sequences is the sum of the analogous dissimilarity between the four sequences. The analogous dissimilarity AD (u, v, w, x) between four sequences is the sum of the costs of approximating the minimum cost of the four sequences. This definition ensures that the following properties are correct: coherence with analogy, symmetry with \"as,\" replacement of medians, and asymmetry with \"is to.\" Depending on what we are looking for, many methods have been developed to predict alignment in bioinformatics."}, {"heading": "3.5 Computing the Analogical Dissimilarity between Four Sequences: the SEQUANA4 Algorithm", "text": "We calculate AD (u, v, w, x) using a dynamic programming algorithm called SEQUANA4, which progresses in synchronicity in the four sequences to achieve optimal alignment.3. With this definition of AD, the \"triangle inequality\" property is not always on sequences.The output is the analog dissimilarity between four sets of, namely"}, {"heading": "3.6 Generalized Resolution of Analogical Equations in Sequences: the SOLVANA Algorithm", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.6.1 APPROXIMATE SOLUTIONS TO AN ANALOGICAL EQUATION", "text": "Until now, we have considered that an analog equation has either one (or more) exact solutions, or no solution. In the latter case, the concept of analog dissimilarity is useful to define an approximate solution.Definition 3.5 (The best approximate solution for an analog equation) Let X be a set on which an analogy and an analog dissimilarity AD is defined. Let a: b: c: x be an analog equation in X. The set of best approximate solutions to this equation is given by: {y: argminy: argminy: X AD (a, b, c, y) In other words, the best approximate solutions are the objects y: c: x that are closest in analogical ratios to a, b, and c. Obviously, this definition generalizes those of a solution to an analog equation in Section 2.2. Since we have defined AD with good properties on multiple alphabets."}, {"heading": "3.6.2 THE SOLVANA ALGORITHM", "text": "This algorithm uses dynamic programming to construct a three-dimensional array. When the construction is complete, a traceability is performed to generate the DAG of all the best solutions. An arrangement of four sequences of different lengths is realized by inserting letters so that all four sequences have the same length. Once this is done, we look at the analog dissimilarity in each column of the analog equation \"A is to B as C is to x.\" To find the fourth sequence, we fill M with the following repetition: M [i, j] 1 x, k] 1 x, j, k \u2264 x x, k \u2264 n1 x, k \u2212 ck the same equation. \""}, {"heading": "3.6.3 EXAMPLE", "text": "Let \u03a3 = {a, b, c, A, B, C} be an alphabet defined by 5 binary characters, as follows: f1 f2 f3 f4 f5 a 1 0 1 0 1 0 b 0 1 0 1 0 0 0 1 B 0 1 0 1 1 1 0 0 0 0 0 0 0The first three characters indicate what the letter is (for example, f1 applies only to a and A) and the last two indicate the case of the letter (f4 applies to lowercase, f5 to uppercase).For example, let us start with: Bc::: Bc: x be an analogous equation. There is no exact solution, but six best approximate solutions y, so that AD (ab, Bc, Bc, y) = 4, for example y = BB or y = Cc."}, {"heading": "4. Analogical Dissimilarity and Machine Learning", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Motivation", "text": "We assume here that there is an analogy defined on set X and an analogous dissimilarity AD with the following properties: coherence with analogy, symmetry for \"as,\" triangular inequality, replacement of medians, and asymmetry for \"is to.\" Let S be a set of elements of X that is of cardinality m, and let y be another element of X with y 6% S. The problem we will address in this section is to find the triple of objects (u, v, w) in such a way that: AD (u, v, w, y) = argmin t1, t2, t3 \u0445 S AD (t1, t2, t3, y) This will lead us directly to use the term AD in supervised machine learning, e.g. a classification rule."}, {"heading": "4.2 The Brute Force Solution", "text": "An obvious solution is to study all the triples in S. This brute force method requires m3 calls to a method of calculating the analog dissimilarity between four objects of X. According to the properties of the analog dissimilarity, this number can in fact be divided by 8, but it does not change the theoretical and practical complexity of the search. The situation is similar to the search for the closest neighbor in machine learning, for which the naive algorithm requires m-distance calculations. Many suggestions have been made to reduce this complexity (see, for example, the work of Ch\u00e1vez, Navarro, Baeza-Yates and Marroqu\u00edn, 2001). As we have focused on an extension of the AESA algorithm based on the property of triangular inequality for distances (Mic\u00f3, Oncina and Vidal, 1994)."}, {"heading": "4.3 \u2018FADANA\u2019: FAst search of the least Dissimilar ANAlogy", "text": "This section describes a quick algorithm to use a series of objects S of cardinality m and an object y to find the three objects (z, t, x) in S in such a way that the analog dissimilarity AD (z, t, x, y) is minimal. It is based on the AESA technique, which can be extended to analog dissimilarity. Thanks to its properties, an analog dissimilarity AD (z, t, x, y) can be regarded as the distance between the two pairs (z, t) and (x, y), and as a result we will essentially work on object pairs. In this paragraph, we will use the equivalent terms \"(analog) distance between the two pairs (u, v) and (w, x)\" and \"(analog) dissimilarity between the four elements u, v, w and x,\" to describe AD (u, v, w, x)."}, {"heading": "4.3.1 PRELIMINARY COMPUTATION", "text": "In this part, which is done offline, we have to calculate the analog dissimilarity between all four objects in the database. This step has a temporal and spatial complexity of O (m4), where m is the size of S. We come back to this point in Section 4.4, where we will move from an AESA-like to a LAESA-like technique and reduce the computational complexity."}, {"heading": "4.3.2 PRINCIPLE OF THE ALGORITHM", "text": "The basic operation is to compose a few objects by adding an object xi-S to y, where i = 1, m. The goal is now to find the pair of objects in S with the smallest distance to (xi, y) and then to turn xi into xi + 1. Finally, loop times in an AESA-like selection and elimination technique ensure that the triple in S shows the least analog dissimilarity when associated with y."}, {"heading": "4.3.3 NOTATIONS", "text": "Let us specify: \u2022 C the set of pairs (u, v) to which the distance (xi, y) has already been calculated. \u2022 \u03b4 = argmin (z, t) \u0441U (AD (z, t, xi, y))) \u2022 \u03b4i = argmin (z, t) \u0432U, 1 \u2264 j \u2264 i (AD (z, t, xi, y))) \u2022 Dist = {AD (z, t, xi, y), (z, t) \u0445C} \u2022 Dist (j) the jte element of Dist \u2022 QuadU = {(z, t, xi, y), (z, t) \u0445C} \u2022 QuadU (j) the jth element of QuadU The algorithm is constructed in the three following phases:"}, {"heading": "4.3.4 INITIALIZATION", "text": "Each time xi changes (if i is increased by 1), the set U is replenished with all possible object pairs. C and Dist, each containing the pairs and the distances to (xi, y) measured during a loop, are initialized as empty sets. The local minimum Min, which contains the minimum of analog similarities in a loop, is set to infinity. k = Map (C) represents the number of pairs used to calculate the distance in the current loop (xi, y). k is initialized to zero. Algorithm 1 Algorithm FADANA: Initialization. begin U \u2190 {(xi, xj), i = 1, m and j = 1, m}; C = 1, m}; Min \u2190 + \u221e; Dist \u2605; k \u2190; End"}, {"heading": "4.3.5 SELECTION", "text": "The goal of this function is to extract from the set U the pair (zz, tt) that is most promising in terms of the minimal analog dissimilarity with (xi, y), using the criterion: (zz, tt) = argmin (u, v) \u2022 U Max (z, t) \u2022 C \u2022 AD (u, v, z, t) \u2212 AD (z, t, xi, y) \u2022 Algorithm 2 algorithm FADANA: Selection of the most promising pair. Selection (U, C, (xi, y), Dist) starts s \u00b2 0 for i = 1, Map (U) doif s \u2264 j \u00b2 C | AD (zj, tj, ui, vi) \u2212 Dist (j, j, (j, y, vi) \u00b7 AD (zj, tj, ui, vi) \u2212 Dist (j) \u2212 Dist (j); argmin \u00b2 i; End for return (uarg min, varg); End"}, {"heading": "4.3.6 ELIMINATION", "text": "In this section, all pairs (u, v, tk) where analogue removal with (xi, y) cannot be less than what we have already found can be eliminated by the following two criteria: AD (u, v, t, t) \u2264 AD (z, v, xi, y) \u2265 AD (u, v, xi, y) and AD (u, v, y) \u2012 AD (u, v, xi) \u2012 AD (u, xi, y) Vacancy control control (u, v, y) Vacancy control (u, v, y) and AD (u, xi, y) \u2012 AD (u, xi, y) (u, y) Vacancy control (u, y) Vacancy control (u, y) Vacancy control (u, y) (u, y) Vacancy control (u, y)"}, {"heading": "4.4 Selection of Base Prototypes in FADANA", "text": "So far, FADANA has the disadvantage of requiring a pre-calculation time and storage in O (m4), which is impossible in practice for m > 100. To go even further, we have developed an improved version of the FADANA algorithm, in which the preliminary calculation and storage is limited to N m2, where N is a certain number of object pairs, the principle being similar to that of LAESA (Mic\u00f3 et al., 1994). N-base prototypes are selected pairs among the m2 possibilities by a greedy process, with the first being selected randomly, the second as far as possible from the first, and so on. The distance between object pairs is, according to the definition of analog inequality: B ((x, y), (z, t)) = AD (z, t, x, y)."}, {"heading": "4.5 Efficiency of FADANA", "text": "We tested this algorithm using four databases from the UCI repository (Newman, Hettich, Blake, & Merz, 1998), noting each time the percentage of AD calculated in-line for a different number of base prototypes compared to those of the na\u00efve method (see Figure 5, the scales are logarithmic) The number of base prototypes is expressed as a percentage on the learning set. If the learning set contains m elements, the number of possible 3-tuples that can be built is, of course, m3. This point explains why the percentage of base prototypes can rise above 100% compared to the size of the learning set. The number of inline calculations of AD is the mean value above the testset.We find in these results that the optimal number of base prototypes is between 10% and 20% when we want to optimize the computational time results."}, {"heading": "5. Two Applications in Machine Learning Problems", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Classification of Objects Described by Binary and Nominal Features", "text": "The purpose of this first experiment is to measure the benefit of analog dissimilarity applied to a fundamental problem of classification, compared to standard classifiers such as k-nearest neighbors, neural networks, and decision trees. In this benchmarking, we are not yet interested in classifying sequences, but merely in investigating what the basic concept of analog dissimilarity can contribute to learning a classification rule for symbolic objects."}, {"heading": "5.1.1 METHOD DESCRIPTION", "text": "The objects are defined by binary attributes. Let x be an object that is not in S. The learning problem is to find the class of a new object x, using the learning sentence S. To do this, we define a learning rule based on the concept of analog difference, which depends on an integer k that could be called the least different 3-tuple rule. Basically, among all 3 tuples (a, b, c) in S3, we consider the subset of those that generate the least analog difference when associated with x (the FADANA algorithm is used here). For a part of them, the analog equation h (a): h (b): h (c): g has an exact solution in the finiteness of the class.We hold only these 3 classes."}, {"heading": "5.1.2 WEIGHTING THE ATTRIBUTES", "text": "The basic idea in the weighting of attributes is that they do not have the same meaning in the classification, and that more importance must be placed on the most discriminating group. The idea of selecting or improving interesting attributes is classic in machine learning and not entirely new in the context of analogy. In an essay by Turney (2005), discrimination is performed by keeping the most common patterns in words. Therefore, greater importance is attached to attributes that are actually discriminatory. However, in an analogous classification system, there are several ways to find the class of the unknown element. Let's take the previous example of two class problems (see Table 1) to focus on this point. We note that there are two ways to choose between classrooms 0 and classrooms 1 (there is also a third possible configuration that is equivalent to the second by replacing the means). We must therefore consider the equation that is used to find the class."}, {"heading": "5.1.3 LEARNING THE WEIGHTING MATRIX FROM THE TRAINING SAMPLE", "text": "We estimate Wkij by the frequency with which the attribute k is analogous to the first element class \u03c9i, and solve it in the class \u03c9j. First, we table the division of each attribute ak on the classes \u03c9i:... ak = 0.. n0i... where ak is the attribute k and n0i (or n1i) is the number of objects in class i (... ak = 0. n0i... ak = 1. n1i.), where ak is the attribute k and n0i (or n1i) is the number of objects in class i, which is the value 0 (or 1) for the binary attribute k k k k. Hence, \u2211 1 k = 0. nki = 1 nki = m (the number of objects in the learning group). Second, we calculate Wkij by calculating the probability, a correct analogous ratio to the first element class 0."}, {"heading": "5.1.4 EXPERIMENTS AND RESULTS", "text": "In fact, most of them are able to play by the rules that they have established in recent years, \"he said in an interview with Welt am Sonntag newspaper."}, {"heading": "5.2 Handwritten Character Recognition: Generation of New Examples", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2.1 INTRODUCTION", "text": "In a number of pattern recognition systems, therefore, collecting labeled data is expensive or user-friendly to provide the system with a consistent learning example. However, to be efficient, any statistical classification system must be retrained to the new personal writing style or new patterns with as many examples as possible, or at least to a sufficient number of well-chosen examples. To overcome this paradox and thus enable the learning of a classifier with very few examples, a simple idea is to generate new examples by randomly adding noise to the elements of a small learning sample. Bishop (2007) does not give theoretical coverage of such a procedure, but draws a pragmatic conclusion:... \"the addition of random noise to the inputs.\""}, {"heading": "5.2.2 ANALOGY BASED GENERATION", "text": "In this second experiment, we are interested in handwritten letters recorded online. They are represented by a sequence of letters of type \u03a3, where \u03a3 = {1, 2,..., 16, 0, C,..., N} is the alphabet of the Freeman symbol code, which is augmented by anchor point symbols. These anchor points are derived from an analysis of the stable handwriting properties defined in (Mouch\u00e8re et al., 2007): Pen-up / down, y-extrema, angular points and in-loop-y extremes. With a learning set containing a few examples for each letter, we generate synthetic examples in analog proportion, as described in Section 3.6 (see Figure 7). Thus, by creating artificial examples of the letter f based on an analog ratio, we expand the learning set with new and other examples, as shown in the following images."}, {"heading": "5.2.3 EXPERIMENTS", "text": "In this section we show that our generation strategies improve the recognition rate of three classical classifiers, which we captured with little data. Experimental Protocol In the database we use (Mouch\u00e8re et al., 2007), twelve different authors have 40 times the 26 lowercase letters (1040 characters) on a PDA. We use a 4-speed cross-validation. The experiments consist of two phases in which three writer-dependent recognition systems are learned: a Radial Base Functional Network (RBFN), a K-Nearest Neighbor (K-NN) and a One-against-all Support Vector Machine (SVM). We calculate two reference detection systems without data generation, which match the detection rate achieved with 10 original characters without characters."}, {"heading": "6. Conclusions and Future Work", "text": "In this article, we have examined a formal concept of analogy between four objects in the same universe. We have given definitions of analogy, formulas, and algorithms for solving analog equations in certain areas. We have placed a particular emphasis on objects structured as sequences, with an original definition of analogy based on optimal alignments. We have also introduced in a coherent manner the new concept of analog dissimilarity, which quantifies how far four objects are from analogy. This term is useful for lazy, supervised learning: we have shown how time-consuming brachialisms can amuse algorithms by generalizing a quick search for algorithms."}, {"heading": "Acknowledgments", "text": "The authors would like to thank the anonymous speakers for their constructive and detailed comments on the first version of this article."}], "references": [{"title": "Case-based reasoning: Foundational issues, methodological variations, and system approaches", "author": ["A. Aamodt", "E. Plaza"], "venue": "Artificial Intelligence Communications,", "citeRegEx": "Aamodt and Plaza,? \\Q1994\\E", "shortCiteRegEx": "Aamodt and Plaza", "year": 1994}, {"title": "Learning by analogy : a classification rule for binary and nominal data", "author": ["S. Bayoudh", "L. Miclet", "A. Delhay"], "venue": "International Joint Conference on Artificial Intelligence,", "citeRegEx": "Bayoudh et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bayoudh et al\\.", "year": 2007}, {"title": "Learning a classifier with very few examples: analogy based and knowledge based generation of new examples for character", "author": ["S. Bayoudh", "H. Mouch\u00e8re", "L. Miclet", "E. Anquetil"], "venue": null, "citeRegEx": "Bayoudh et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bayoudh et al\\.", "year": 2007}, {"title": "Pattern Recognition and Machine Learning", "author": ["C. Bishop"], "venue": "Springer.", "citeRegEx": "Bishop,? 2007", "shortCiteRegEx": "Bishop", "year": 2007}, {"title": "Generating synthetic speech prosody with lazy learning in tree structures", "author": ["L. Blin", "L. Miclet"], "venue": "In Proceedings of CoNLL-2000 : 4th Conference on Computational Natural Language Learning,", "citeRegEx": "Blin and Miclet,? \\Q2000\\E", "shortCiteRegEx": "Blin and Miclet", "year": 2000}, {"title": "Graph Matching in Pattern Recognition and Machine Vision, Special Issue of International Journal of Pattern Recognition and Artificial Intelligence", "author": ["H. Bunke", "T. Caelli"], "venue": "World Scientific", "citeRegEx": "Bunke and Caelli,? \\Q2004\\E", "shortCiteRegEx": "Bunke and Caelli", "year": 2004}, {"title": "Training set expansion in handwritten character recognition", "author": ["J. Cano", "J. P\u00e9rez-Cortes", "J. Arlandis", "R. Llobet"], "venue": "In 9th Int. Workshop on Structural and Syntactic Pattern Recognition,", "citeRegEx": "Cano et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Cano et al\\.", "year": 2002}, {"title": "Searching in metric spaces", "author": ["E. Ch\u00e1vez", "G. Navarro", "R. Baeza-Yates", "Marroqu\u00edn", "J.-L"], "venue": "ACM Comput. Surv.,", "citeRegEx": "Ch\u00e1vez et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Ch\u00e1vez et al\\.", "year": 2001}, {"title": "Apprentissage artificiel : concepts et algorithmes", "author": ["A. Cornu\u00e9jols", "L. Miclet"], "venue": null, "citeRegEx": "Cornu\u00e9jols and Miclet,? \\Q2002\\E", "shortCiteRegEx": "Cornu\u00e9jols and Miclet", "year": 2002}, {"title": "Abstraction considered harmful: lazy learning of language processing", "author": ["W. Daelemans"], "venue": "den Herik, H. J. V., & Weijters, A. (Eds.), Proceedings of the sixth Belgian-Dutch Conference on Machine Learning, pp. 3\u201312, Maastricht, The Nederlands.", "citeRegEx": "Daelemans,? 1996", "shortCiteRegEx": "Daelemans", "year": 1996}, {"title": "Analogical projection in pattern perception", "author": ["M. Dastani", "B. Indurkhya", "R. Scha"], "venue": "Journal of Experimental and Theoretical Artificial Intelligence,", "citeRegEx": "Dastani et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Dastani et al\\.", "year": 2003}, {"title": "Analogical equations in sequences : Definition and resolution", "author": ["A. Delhay", "L. Miclet"], "venue": "In International Colloquium on Grammatical Induction,", "citeRegEx": "Delhay and Miclet,? \\Q2004\\E", "shortCiteRegEx": "Delhay and Miclet", "year": 2004}, {"title": "A divide and conquer approach to multiple alignment", "author": ["A.W.M. Dress", "G. F\u00fcllen", "S. Perrey"], "venue": "In ISMB,", "citeRegEx": "Dress et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Dress et al\\.", "year": 1995}, {"title": "Muscle: a multiple sequence alignment method with reduced time and space complexity", "author": ["R. Edgar"], "venue": "BMC Bioinformatics, 5(1), 113.", "citeRegEx": "Edgar,? 2004", "shortCiteRegEx": "Edgar", "year": 2004}, {"title": "The structure-mapping engine: Algorithm and examples", "author": ["B. Falkenhainer", "K. Forbus", "D. Gentner"], "venue": "Artificial Intelligence,", "citeRegEx": "Falkenhainer et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Falkenhainer et al\\.", "year": 1989}, {"title": "The analogical mind: Perspectives from cognitive science", "author": ["D. Gentner", "K.J. Holyoak", "B. Kokinov"], "venue": null, "citeRegEx": "Gentner et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Gentner et al\\.", "year": 2001}, {"title": "Some statistical issues in the comparison of speech recognition algorithms", "author": ["L. Gillick", "S. Cox"], "venue": "In IEEE Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "Gillick and Cox,? \\Q1989\\E", "shortCiteRegEx": "Gillick and Cox", "year": 1989}, {"title": "Fluid Concepts and Creative Analogies", "author": ["D. Hofstadter"], "venue": "Fluid Analogies Research Group", "citeRegEx": "Hofstadter,? \\Q1994\\E", "shortCiteRegEx": "Hofstadter", "year": 1994}, {"title": "Analogy", "author": ["K. Holyoak"], "venue": "The Cambridge Handbook of Thinking and Reasoning, chap. 6. Cambridge University Press.", "citeRegEx": "Holyoak,? 2005", "shortCiteRegEx": "Holyoak", "year": 2005}, {"title": "Using statistical testing in the evaluation of retrieval experiments", "author": ["D. Hull"], "venue": "Research and Development in Information Retrieval, pp. 329\u2013338.", "citeRegEx": "Hull,? 1993", "shortCiteRegEx": "Hull", "year": 1993}, {"title": "A rehabilitation of analogy in syntax (and elsewhere)", "author": ["E. Itkonen", "J. Haukioja"], "venue": null, "citeRegEx": "Itkonen and Haukioja,? \\Q1997\\E", "shortCiteRegEx": "Itkonen and Haukioja", "year": 1997}, {"title": "Apparatus and method for producing analogically similar word based on pseudodistances between words", "author": ["Y. Lepage"], "venue": null, "citeRegEx": "Lepage,? \\Q2001\\E", "shortCiteRegEx": "Lepage", "year": 2001}, {"title": "De l\u2019analogie rendant compte de la commutation en linguistique", "author": ["Y. Lepage"], "venue": "Universit\u00e9 Joseph Fourier, Grenoble. Habilitation \u00e0 diriger les recherches.", "citeRegEx": "Lepage,? 2003", "shortCiteRegEx": "Lepage", "year": 2003}, {"title": "A new version of the nearest-neighbour approximating and eliminating search algorithm aesa with linear preprocessing-time and memory requirements", "author": ["L. Mic\u00f3", "J. Oncina", "E. Vidal"], "venue": "Pattern Recognition Letters,", "citeRegEx": "Mic\u00f3 et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Mic\u00f3 et al\\.", "year": 1994}, {"title": "Analogy-Making as Perception", "author": ["M. Mitchell"], "venue": "MIT Press.", "citeRegEx": "Mitchell,? 1993", "shortCiteRegEx": "Mitchell", "year": 1993}, {"title": "Machine Learning", "author": ["T. Mitchell"], "venue": "McGraw-Hill.", "citeRegEx": "Mitchell,? 1997", "shortCiteRegEx": "Mitchell", "year": 1997}, {"title": "Writer style adaptation in on-line handwriting recognizers by a fuzzy mechanism approach: The adapt method", "author": ["H. Mouch\u00e8re", "E. Anquetil", "N. Ragot"], "venue": "Int. Journal of Pattern Recognition and Artificial Intelligence,", "citeRegEx": "Mouch\u00e8re et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Mouch\u00e8re et al\\.", "year": 2007}, {"title": "A general method applicable to the search for similarities in the amino acid sequence of two proteins", "author": ["S.B. Needleman", "C.D. Wunsch"], "venue": "J Mol Biol,", "citeRegEx": "Needleman and Wunsch,? \\Q1970\\E", "shortCiteRegEx": "Needleman and Wunsch", "year": 1970}, {"title": "UCI repository of machine learning databases", "author": ["D. Newman", "S. Hettich", "C. Blake", "C. Merz"], "venue": null, "citeRegEx": "Newman et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Newman et al\\.", "year": 1998}, {"title": "Analogy in the lexicon: a probe into analogy-based machine learning of language", "author": ["V. Pirrelli", "F. Yvon"], "venue": "In Proceedings of the 6th International Symposium on Human Communication,", "citeRegEx": "Pirrelli and Yvon,? \\Q1999\\E", "shortCiteRegEx": "Pirrelli and Yvon", "year": 1999}, {"title": "An algebraic framework for solving proportional and predictive analogies", "author": ["U. Schmid", "H. Gust", "K\u00fchnberger", "K.-U", "J. Burghardt"], "venue": "Proceedings of the European Conference on Cognitive Science (EuroCogSci", "citeRegEx": "Schmid et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Schmid et al\\.", "year": 2003}, {"title": "Identification of common molecular subsequences", "author": ["T.F. Smith", "M.S. Waterman"], "venue": "Journal of Molecular Biology,", "citeRegEx": "Smith and Waterman,? \\Q1981\\E", "shortCiteRegEx": "Smith and Waterman", "year": 1981}, {"title": "Analogie dans les s\u00e9quences : un solveur \u00e0 \u00e9tats finis", "author": ["N. Stroppa", "F. Yvon"], "venue": "TALN", "citeRegEx": "Stroppa and Yvon,? \\Q2004\\E", "shortCiteRegEx": "Stroppa and Yvon", "year": 2004}, {"title": "Improved sensitivity of profile searches through the use of sequence weights and gap excision", "author": ["J.D. Thompson", "D.G. Higgins", "T.J. Gibson"], "venue": "Computer Applications in the Biosciences,", "citeRegEx": "Thompson et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Thompson et al\\.", "year": 1994}, {"title": "Measuring semantic similarity by latent relational analysis", "author": ["P.D. Turney"], "venue": "Proceedings Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-05), 05, 1136.", "citeRegEx": "Turney,? 2005", "shortCiteRegEx": "Turney", "year": 2005}, {"title": "On the complexity of multiple sequence alignment", "author": ["L. Wang", "T. Jiang"], "venue": "Journal of Computational Biology,", "citeRegEx": "Wang and Jiang,? \\Q1994\\E", "shortCiteRegEx": "Wang and Jiang", "year": 1994}, {"title": "Data Mining: Practical machine learning tools and techniques, 2nd Edition", "author": ["I.H. Witten", "E. Frank"], "venue": null, "citeRegEx": "Witten and Frank,? \\Q2005\\E", "shortCiteRegEx": "Witten and Frank", "year": 2005}, {"title": "Paradigmatic cascades: a linguistically sound model of pronunciation by analogy", "author": ["F. Yvon"], "venue": "Proceedings of the 35th annual meeting of the Association for Computational Linguistics (ACL), Madrid, Spain.", "citeRegEx": "Yvon,? 1997", "shortCiteRegEx": "Yvon", "year": 1997}, {"title": "Pronouncing unknown words using multi-dimensional analogies", "author": ["F. Yvon"], "venue": "Proceeding of the European conference on Speech Application and Technology (Eurospeech), Vol. 1, pp. 199\u2013202, Budapest, Hungary.", "citeRegEx": "Yvon,? 1999", "shortCiteRegEx": "Yvon", "year": 1999}, {"title": "Solving analogical equations on words", "author": ["F. Yvon", "N. Stroppa", "A. Delhay", "L. Miclet"], "venue": "Tech. rep. ENST2004D005, E\u0301cole Nationale Supe\u0301rieure des Te\u0301le\u0301communications", "citeRegEx": "Yvon et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Yvon et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 9, "context": "More generally, the resolution of analogical equations can also be seen as a basic component of learning by analogy systems, which are part of the lazy learning techniques (Daelemans, 1996).", "startOffset": 172, "endOffset": 189}, {"referenceID": 36, "context": "For example, Yvon (1999) presents an analogical approach to the grapheme-to-phoneme conversion, for text-to-speech synthesis purposes.", "startOffset": 13, "endOffset": 25}, {"referenceID": 25, "context": "This is the problem of inductive learning of a classification rule from examples, which consists in finding the value of u at point y (Mitchell, 1997).", "startOffset": 134, "endOffset": 150}, {"referenceID": 24, "context": "This is the problem of inductive learning of a classification rule from examples, which consists in finding the value of u at point y (Mitchell, 1997). The nearest neighbor method, which is the most popular lazy learning technique, simply finds in S the description x which minimizes some distance to y and hypothesizes u(x), the label of x, for the label of y. Moving one step further, learning from analogical proportions consists in searching in S for a triple (x, z, t) such that \u201cx is to z as t is to y\u201d and predicts for y the label \u00fb(y) which is solution of the equation \u201cu(x) is to u(z) as u(t) is to \u00fb(y)\u201d. If more than one triple is found, a voting procedure can be used. Such a learning technique is based on the resolution of analogical equations. Pirrelli and Yvon (1999) discuss the relevance of such a learning procedure for various linguistic analysis tasks.", "startOffset": 135, "endOffset": 784}, {"referenceID": 18, "context": "Much work has been done on this subject from a cognitive science point of view, which had led to computational models of reasoning by analogy: see for example, the classical paper (Falkenhainer, Forbus, & Gentner, 1989), the book (Gentner, Holyoak, & Kokinov, 2001) and the recent survey (Holyoak, 2005).", "startOffset": 288, "endOffset": 303}, {"referenceID": 25, "context": "Our work also aims to define some supervised machine learning process (Mitchell, 1997; Cornu\u00e9jols & Miclet, 2002), in the spirit of lazy learning.", "startOffset": 70, "endOffset": 113}, {"referenceID": 14, "context": "Much work has been done on this subject from a cognitive science point of view, which had led to computational models of reasoning by analogy: see for example, the classical paper (Falkenhainer, Forbus, & Gentner, 1989), the book (Gentner, Holyoak, & Kokinov, 2001) and the recent survey (Holyoak, 2005). Usually, these works use the notion of transfer, which is not within the scope of this article. It means that some knowledge on solving a problem in a domain is transported to another domain. Since we work on four objects that are in the same space, we implicitly ignore the notion of transfer between different domains. Technically speaking, this restriction allows us to use an axiom called \u2018exchange of the means\u2019 to define an analogical proportion (see Definition 2.1). However, we share with these works the following idea: there may be a similar relation between two couples of structured objects even if the objects are apparently quite different. We are interested in giving a formal and algorithmic definition of such a relation. Our work also aims to define some supervised machine learning process (Mitchell, 1997; Cornu\u00e9jols & Miclet, 2002), in the spirit of lazy learning. We do not seek to extract a model from the learning data, but merely conclude what is the class, or more generally the supervision, of a new object by inspecting (a part of) the learning data. Usually, lazy learning, like the k-nearest neighbors technique, makes use of unstructured objects, such as vectors. Since distance measures can be also defined on strings, trees and even graphs, this technique has also been used on structured objects, in the framework of structural pattern recognition (see for example the work of Bunke & Caelli, 2004; Blin & Miclet, 2000; Basu, Bunke, & Del Bimbo, 2005). We extend here the search of the nearest neighbor in the learning set to that of the best triple (when combined with the new object, it is the closest to make an analogical proportion). This requires defining what is an analogical proportion on structured objects, like sequences, but also to give a definition of how far a 4-tuple of objects is from being in analogy (that we call analogical dissimilarity). Learning by analogy on sequences has already being studied, in a more restricted manner, on linguistic data (Yvon, 1997, 1999; Itkonen & Haukioja, 1997). Reasoning and learning by analogy has proven useful in tasks like grapheme to phoneme conversion, morphology and translation. Sequences of letters and/or of phonemes are a natural application to our work, but we are also interested in other type of data, structured as sequences or trees, such as prosodic representations for speech synthesis, biochemical sequences, online handwriting recognition, etc. Analogical proportions between four structured objects of the same universe, mainly strings, have been studied with a mathematical and algorithmic approach, like ours, by Mitchell (1993) and Hofstadter et al.", "startOffset": 240, "endOffset": 2946}, {"referenceID": 14, "context": "Analogical proportions between four structured objects of the same universe, mainly strings, have been studied with a mathematical and algorithmic approach, like ours, by Mitchell (1993) and Hofstadter et al. (1994), Dastani et al.", "startOffset": 191, "endOffset": 216}, {"referenceID": 9, "context": "(1994), Dastani et al. (2003), Schmid et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 9, "context": "(1994), Dastani et al. (2003), Schmid et al. (2003). To the best of our knowledge our proposition is original: to give a formal definition of what can be an analogical dissimilarity between four objects, in particular between sequences, and to produce algorithms that enable the efficient use of this concept in machine learning practical problems.", "startOffset": 8, "endOffset": 52}, {"referenceID": 9, "context": "(1994), Dastani et al. (2003), Schmid et al. (2003). To the best of our knowledge our proposition is original: to give a formal definition of what can be an analogical dissimilarity between four objects, in particular between sequences, and to produce algorithms that enable the efficient use of this concept in machine learning practical problems. We have already discussed how to compute exact analogical proportions between sequences in the paper by Yvon et al. (2004) and given a preliminary attempt to compute analogical dissimilarity between sequences in the paper by Delhay and Miclet (2004).", "startOffset": 8, "endOffset": 472}, {"referenceID": 9, "context": "(1994), Dastani et al. (2003), Schmid et al. (2003). To the best of our knowledge our proposition is original: to give a formal definition of what can be an analogical dissimilarity between four objects, in particular between sequences, and to produce algorithms that enable the efficient use of this concept in machine learning practical problems. We have already discussed how to compute exact analogical proportions between sequences in the paper by Yvon et al. (2004) and given a preliminary attempt to compute analogical dissimilarity between sequences in the paper by Delhay and Miclet (2004). Excerpts of the present article have been presented in conferences (Bayoudh, Miclet, & Delhay, 2007a; Bayoudh, Mouch\u00e8re, Miclet, & Anquetil, 2007b).", "startOffset": 8, "endOffset": 599}, {"referenceID": 0, "context": ", let us quote Aamodt and Plaza (1994) about the use of the term \u2018analogy\u2019 in Case-Based Reasoning (CBR): \u2019Analogy-based reasoning: This term is sometimes used, as a synonym to case-based reasoning, to describe the typical case-based approach.", "startOffset": 15, "endOffset": 39}, {"referenceID": 21, "context": "According to Lepage (2003) three basic axioms can be given: Definition 2.", "startOffset": 13, "endOffset": 27}, {"referenceID": 21, "context": "2 SOLVING ANALOGICAL EQUATIONS IN FINITE SETS Considering analogy in sets, Lepage (2003) has shown the following theorem, with respect to the axioms of analogy (section 2.", "startOffset": 75, "endOffset": 89}, {"referenceID": 21, "context": "One has to note that Lepage (2001) and Stroppa and Yvon (2004) have already proposed a definition of an analogical proportion between sequences with applications to linguistic data.", "startOffset": 21, "endOffset": 35}, {"referenceID": 21, "context": "One has to note that Lepage (2001) and Stroppa and Yvon (2004) have already proposed a definition of an analogical proportion between sequences with applications to linguistic data.", "startOffset": 21, "endOffset": 63}, {"referenceID": 13, "context": "For structure or functional similarity like in protein modelization, pattern identification or structure prediction in DNA, methods using simultaneous alignment like MSA (Wang & Jiang, 1994) or DCA (Dress, F\u00fcllen, & Perrey, 1995), or iterative alignment like MUSCLE (Edgar, 2004) are the best.", "startOffset": 266, "endOffset": 279}, {"referenceID": 23, "context": "The principle is similar to that of LAESA (Mic\u00f3 et al., 1994).", "startOffset": 42, "endOffset": 61}, {"referenceID": 34, "context": "In a paper of Turney (2005), a discrimination is done by keeping the most frequent patterns in words.", "startOffset": 14, "endOffset": 28}, {"referenceID": 3, "context": "In his recent book, Bishop (2007) gives no theoretical coverage of such a procedure, but rather draws a pragmatic conclusion: \u2018 .", "startOffset": 20, "endOffset": 34}, {"referenceID": 26, "context": "These anchorage points come from an analysis of the stable handwriting properties, as defined in (Mouch\u00e8re et al., 2007): pen-up/down, y-extrema, angular points and in-loop y-extrema.", "startOffset": 97, "endOffset": 120}, {"referenceID": 26, "context": "Experimental Protocol In the data base that we use (Mouch\u00e8re et al., 2007), twelve different writers have written 40 times the 26 lowercase letters (1040 characters) on a PDA.", "startOffset": 51, "endOffset": 74}, {"referenceID": 19, "context": "The second method is non-parametric: the SIGN TEST (Hull, 1993).", "startOffset": 51, "endOffset": 63}], "year": 2008, "abstractText": "This paper defines the notion of analogical dissimilarity between four objects, with a special focus on objects structured as sequences. Firstly, it studies the case where the four objects have a null analogical dissimilarity, i.e. are in analogical proportion. Secondly, when one of these objects is unknown, it gives algorithms to compute it. Thirdly, it tackles the problem of defining analogical dissimilarity, which is a measure of how far four objects are from being in analogical proportion. In particular, when objects are sequences, it gives a definition and an algorithm based on an optimal alignment of the four sequences. It gives also learning algorithms, i.e. methods to find the triple of objects in a learning sample which has the least analogical dissimilarity with a given object. Two practical experiments are described: the first is a classification problem on benchmarks of binary and nominal data, the second shows how the generation of sequences by solving analogical equations enables a handwritten character recognition system to rapidly be adapted to a new writer.", "creator": null}}}