{"id": "1401.3461", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "A Bilinear Programming Approach for Multiagent Planning", "abstract": "Multiagent planning and coordination problems are common and known to be computationally hard. We show that a wide range of two-agent problems can be formulated as bilinear programs. We present a successive approximation algorithm that significantly outperforms the coverage set algorithm, which is the state-of-the-art method for this class of multiagent problems. Because the algorithm is formulated for bilinear programs, it is more general and simpler to implement. The new algorithm can be terminated at any time and-unlike the coverage set algorithm-it facilitates the derivation of a useful online performance bound. It is also much more efficient, on average reducing the computation time of the optimal solution by about four orders of magnitude. Finally, we introduce an automatic dimensionality reduction method that improves the effectiveness of the algorithm, extending its applicability to new domains and providing a new way to analyze a subclass of bilinear programs.", "histories": [["v1", "Wed, 15 Jan 2014 05:21:26 GMT  (393kb)", "http://arxiv.org/abs/1401.3461v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["marek petrik", "shlomo zilberstein"], "accepted": false, "id": "1401.3461"}, "pdf": {"name": "1401.3461.pdf", "metadata": {"source": "CRF", "title": "A Bilinear Programming Approach for Multiagent Planning", "authors": ["Marek Petrik", "Shlomo Zilberstein"], "emails": ["petrik@cs.umass.edu", "shlomo@cs.umass.edu"], "sections": [{"heading": "1. Introduction", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "2. Formulating Multiagent Planning Problems as Bilinear Programs", "text": "We start with a formal description of the bilinear programs and the various types of multi-agent planning problems that can be formulated as such. In addition to the multi-agent planning problems, bilinear programs can be used to solve a variety of other problems such as robotic manipulation (Pang, Trinkle, & Lo, 1996), bilinear separation (Bennett & Mangasarian, 1992), and even general linear complementarity problems (Mangasarian, 1995). We focus on multi-agent planning problems where this formulation proves particularly effective. Definition 1. A divisible bilinear program in its normal form is defined as: maximize w, x, y, z f, y, y, y, e.g."}, {"heading": "2.1 DEC-MDPs", "text": "As already mentioned, this domain is two independent and observation-independent DECMDP (Becker et al., 2004), respectively completed experiments that must be worked out as a bilinear program. [Intuitively] a DECMDP is transition-independent when no actor can influence the transitions of the other actors. [An example we use is the problem of Mars rover planning (Bresina, Golden, & Washington, 1999), initially formulated as DEC-MDP by Becker et al. (2003). [The DEC-MDP model has proven useful in several multi-agent planning domains."}, {"heading": "2.2 Average-Reward Infinite-Horizon DEC-MDPs", "text": "The previous formulation deals with the finite horizon of DEC MDPs. An average reward problem can also be formulated as a bilinear program (Petrik & Zilberstein, 2007b), which is particularly useful for infinite-horizon DEC MDPs. Consider, for example, the Infinitehorizon version of the Multiple Access Broadcast Channel (MABC) (Rosberg, 1983; Ooi & Wornell, 1996). In this problem, which has been widely used in recent studies of decentralized decision-making, two communication devices share a single channel and they must periodically transmit some data. However, the channel can only transmit a single message at a given time. If both agents send messages at the same time, this results in a collision, and the transmission fails."}, {"heading": "2.3 General DEC-POMDPs and Extensive Games", "text": "The general DEC-POMDP problem and the extensive form games with two agents, or players, can also be formulated as 11b 11b programs. However, the limitations may not be separable because actions of one agent affect the other agent, and the approach in this case may be similar to the linear complementarity problem formulation of large games (Koller, Megiddo, & von Stengel, 1994), and the holistic program work of DEC-POMDPs (Aras & Charpillet, 2007). The approach we are developing is closely related to event-driven DECPOMDPs (Becker et al., 2004), but is generally more efficient than any other actions. Nevertheless, the size of the bilinear program is exponentially similar to the size of the DEC-POMDP. This can be expected since the solution of DEC-POMDPs is complete since NEXP (Bernstein et al., 2000), while the solution of bilinear programs is complete (Mangasarian, 1995)."}, {"heading": "2.4 General Two-Player Games", "text": "In addition to cooperative problems, some competition problems with 2 players can be formulated as bilinear programs. It is well known that the problem of finding a balance for a bi-matrix game can be formulated as a linear complementarity problem (Cottle, Pang, & Stone, 1992). It has also been shown that a linear complementarity problem can be formulated directly as a bilinear program (Mangasarian, 1995). There are many ways to formulate a game, so we simply assume that each agent optimizes a linear program, as follows. maximize x x x x x d1 (x) = rT1 x x x x x x TC1y are subject to 0 (8) x x x x x x x = maximize y y y y y y y y y y."}, {"heading": "3. Solving Bilinear Programs", "text": "A simple method for solving bilinear programs is the iterative method presented in algorithm 1. Parameter B represents the bilinear program. While the algorithm often performs well in practice, it tends to converge to a suboptimal solution (Mangasarian, 1995). When applied to DEC MDPs, this algorithm is essentially identical to JESP (Nair, Tambe, Yokoo, Pynadath, & Marsella, 2003) - one of the early solution methods. In the following, we use f (w, x, y, z) to denote the objective value of Equation (1). The rest of this section represents a new, readily available algorithm for solving bilinear programs. The aim of the algorithm is to produce a good solution quickly and then improve the solution in the remaining time."}, {"heading": "3.1 The Successive Approximation Algorithm", "text": "In fact, the question as to the causes of the crisis is a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, an answer, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason, a question of reason of reason, a question of a question of a question of reason, a question of a question of a question of reason, a question of a question of a question of reason, a question of a question of a question of a question of reason, a question of a question of a question of reason, a question of a question of a question of reason, a question of a question of a question of reason, a question of a question of a question of reason, a question of a question of a question of a question of reason, a question of a question of a question of a question of a question of reason, a question of a question of a question of reason, a question of a question of a question of a question of a question of a question of reason, a question of a question of a question of a question of a question of a question of a question of a question of a question of a question of reason, a question of a question of a question of a question of a question of reason, a question of a question of a question of a question of a question of a question of a question of reason, a question of a question of a question of a question of a question of a question of a question of a question of a question of a question of a question of reason, a question of a question of a question of a question of a question of a question of a question of a question of a question of a question of a question of a question of a"}, {"heading": "3.2 Online Error Bound", "text": "In this section we will show exactly how we use triangulation in the algorithm to calculate an error boundary. To calculate the approximate boundary, we define the approximate best response function g (y) as: g) = maximum approximate response g (y) as: g) = maximum approximate response g (y) = maximum approximate response g (y) as: g) = maximum approximate solution f (w, x, y, 0).Notice that z is not taken into account in this expression as we assume that the bilinear program is in semi-compact form. The value of the best approximate solution while executing the algorithm is: max {w, x, y, z, w).X (w)."}, {"heading": "3.3 Advanced Pivot Point Selection", "text": "As described above, the pivot points in both cases are optimal to determine the maximum error rate in each polyhedron and to minimize the approximation error. (The basic approaches described in Section 3.1 can be refined, because the goal is not to approximate the function g (y) with the least error, but to find the optimal solution. (We first define a specified Yh method, which we will search for the maximum error, since the optimal solution f (y).Yh = {s, y, y, y, y, u, the maximum error rate could be limited to this region. (We first define a specified Yh method, which we will search for the maximum error, because the optimal solution f (y).Yh The next statement states that the maximum error must only be calculated in a superset of Yh.Proposition."}, {"heading": "4. Dimensionality Reduction", "text": "In this section we will show the principles behind the automatic determination of the necessary dimensionality of a given problem. (1) Dimensionality is inherently part of the model, not the problem itself. There may be equivalent models of a given problem with very different dimensionalities. (2) Procedures to reduce dimensionality are therefore not necessary if the modeler can create a model with minimal dimensionality. However, in many cases this is not trivial. Moreover, some dimensions may have little impact on overall performance. (2) To determine which of these dimensionalities can be neglected, we must make an efficient contribution."}, {"heading": "5. Offline Bound", "text": "In this section, we develop an approximate limit that only depends on the number of points for which g (y) is measured and on the structure of the problem. This limit is useful in practice because it provides performance guarantees without actually solving the problem. \u2212 In addition, the limit shows which parameters of the problem affect the performance of the algorithm. \u2212 Theorem 21. \u2212 In order to achieve an approximation error of no more than two points, the number of points to be evaluated in a regular grid with k points in each dimension must be sufficient: kn (maximum possible inclination of g (y) and the maximum distance between the points. \u2212 Theorem 21. \u2212 In order to achieve an approximation error of no more than two points, the number of points to be evaluated in a regular grid order with k points in each dimension must be fulfilled: kn (maximum possible inclination of g (y) and the maximum distance between the points. \u2212 Theorem 21. \u2212 To achieve an approximation error of no more than two points, the number of points to be evaluated in a regular grid order with a number of points following in each dimension."}, {"heading": "6. Experimental Results", "text": "We turn to an empirical analysis of the performance of the algorithm to solve the problem with the experiments produced, using the previously described Mars rover problem. We compared our algorithm with the original CSA and with a mixed integer linear program (MILP) described for Eq. (1) such as Petrik and Zilberstein (2007b). Although Eq. (1) can also be modeled as a linear complementarity problem (LCP) (Murty, 1988; Cottle et al, 1992), we do not evaluate this option experimentally because LCPs are closely related to MILPs (Rosen, 1986). We expect these two formulations to show a similar performance. Nor do we compare any of the methods described by Horst and Tuy (1996) and Bennett and Mangasarian (1992) due to their very different nature and high complexity, and because some of these algorithms do not offer a guarantee of optimum performance."}, {"heading": "7. Conclusion and Further Work", "text": "In fact, most of them will be able to feel as if they are able to play by the rules, and that they will be able to play by the rules, and that they will be able to play by the rules."}, {"heading": "Acknowledgments", "text": "We thank Chris Amato, Raghav Aras, Alan Carlin, Hala Mostafa, and the anonymous reviewers for their useful comments and suggestions. This work was partially supported by the Air Force Office of Scientific Research under grant numbers FA9550-05-1-0254 and FA955008-1-0181, and by the National Science Foundation under grant numbers IIS-0535061 and IIS-0812149."}, {"heading": "Appendix A. Proofs", "text": "It is not to be expected that an agreement will be reached. (...) It is not to be expected that an agreement will be reached. (...) It is not to be expected that an agreement will be reached. (...) It is not to be expected that an agreement will be reached. (...) It is to be expected that an agreement will be reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached. (...) No agreement has been reached."}, {"heading": "Appendix B. Practical Dimensionality Reduction", "text": "In this section we describe an approach to dimensionality reduction that is easy to implement. Note that there are at least two possible approaches to using the reduced dimensionality. First, it is possible to use the dimensionality information to limit the algorithm to work only in the significant dimensions of Y. Second, it is possible to modify the two-dimensional program so that it has a small dimensionality. Dimensionality reduction is applied to the following two-dimensional program: maximize w, x, y, z rT1 x + s T 1w + x TCy + s T 2 z is subject to."}, {"heading": "Appendix C. Sum of Convex and Concave Functions", "text": "In this section we show that the function with the best answer g (y) must not be convex = inex if the program is not in a semi-compact form. Convexity of the function with the best answer is crucial for limiting the approximation error and for eliminating the dominated regions. We show that if the program is not in a semi-compact form, the function with the best answer can be written as the sum of a convex function and a concave function. To show that one can consider the following bilinear program, maximize w, x, y, f = rT1 x + s T 1w + rT2 y + s T 2 z subject to A1x + B1w = b1 A2y + B2z = b2 w, y (25) This problem can be reformulated as: f = max {y, z (y, z), z), z} max {x {x, w} T1."}], "references": [{"title": "Interaction structure and dimensionality in decentralized problem solving", "author": ["M. Allen", "M. Petrik", "S. Zilberstein"], "venue": "In Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Allen et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Allen et al\\.", "year": 2008}, {"title": "Interaction structure and dimensionality in decentralized problem solving", "author": ["M. Allen", "M. Petrik", "S. Zilberstein"], "venue": "Tech. rep. 08-11,", "citeRegEx": "Allen et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Allen et al\\.", "year": 2008}, {"title": "Mathematical programming methods for decentralized POMDPs", "author": ["R. Aras"], "venue": "Ph.D. thesis,", "citeRegEx": "Aras,? \\Q2008\\E", "shortCiteRegEx": "Aras", "year": 2008}, {"title": "A mixed integer linear programming method for the finitehorizon Dec-POMDP problem", "author": ["R. Aras", "F. Charpillet"], "venue": "In International Conference on Automated Planning and Scheduling (ICAPS),", "citeRegEx": "Aras and Charpillet,? \\Q2007\\E", "shortCiteRegEx": "Aras and Charpillet", "year": 2007}, {"title": "Exploiting Structure in Decentralized Markov Decision Processes", "author": ["R. Becker"], "venue": "Ph.D. thesis,", "citeRegEx": "Becker,? \\Q2006\\E", "shortCiteRegEx": "Becker", "year": 2006}, {"title": "Decentralized Markov decision processes with event-driven interactions", "author": ["R. Becker", "V. Lesser", "S. Zilberstein"], "venue": "In International Joint Conference on Autonomous Agents and Multi Agent Systems (AAMAS),", "citeRegEx": "Becker et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Becker et al\\.", "year": 2004}, {"title": "Transition-independent decentralized Markov decision processes", "author": ["R. Becker", "S. Zilberstein", "V. Lesser"], "venue": "In International Joint Conference on Autonomous Agents and Multi Agent Systems (AAMAS),", "citeRegEx": "Becker et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Becker et al\\.", "year": 2003}, {"title": "Solving transition independent decentralized Markov decision processes", "author": ["R. Becker", "S. Zilberstein", "V. Lesser", "C.V. Goldman"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Becker et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Becker et al\\.", "year": 2004}, {"title": "Bilinear separation of two sets in n-space", "author": ["K.P. Bennett", "O.L. Mangasarian"], "venue": "Tech. rep.,", "citeRegEx": "Bennett and Mangasarian,? \\Q1992\\E", "shortCiteRegEx": "Bennett and Mangasarian", "year": 1992}, {"title": "The complexity of decentralized control of Markov decision processes", "author": ["D.S. Bernstein", "S. Zilberstein", "N. Immerman"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Bernstein et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Bernstein et al\\.", "year": 2000}, {"title": "Sequential optimality and coordination in multiagent systems", "author": ["C. Boutilier"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "Boutilier,? \\Q1999\\E", "shortCiteRegEx": "Boutilier", "year": 1999}, {"title": "Increased fexibility and robustness of Mars rovers", "author": ["J.L. Bresina", "K. Golden", "D.E. Smith", "R. Washington"], "venue": "In International Symposium on AI, Robotics, and Automation in Space,", "citeRegEx": "Bresina et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Bresina et al\\.", "year": 1999}, {"title": "Algorithms for Partially Observable Markov Decision Processes", "author": ["H.T. Cheng"], "venue": "Ph.D. thesis,", "citeRegEx": "Cheng,? \\Q1988\\E", "shortCiteRegEx": "Cheng", "year": 1988}, {"title": "The Linear Complementarity Problem", "author": ["R.W. Cottle", "Pang", "J.-S", "R.E. Stone"], "venue": null, "citeRegEx": "Cottle et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Cottle et al\\.", "year": 1992}, {"title": "Approximate solutions for partially observable stochastic games with common payoffs", "author": ["R. Emery-Montemerlo", "G. Gordon", "J. Schneider", "S. Thrun"], "venue": "In International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS),", "citeRegEx": "Emery.Montemerlo et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Emery.Montemerlo et al\\.", "year": 2004}, {"title": "A practical approach to approximate bilinear functions in mathematical programming problems by using Schurs decomposition and SOS type 2 variables", "author": ["S.A. Gabriel", "R. Garca-Bertrand", "P. Sahakij", "A.J. Conejo"], "venue": "Journal of the Operational Research Society,", "citeRegEx": "Gabriel et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Gabriel et al\\.", "year": 2005}, {"title": "Communication-based decomposition mechanisms for decentralized MDPs", "author": ["C.V. Goldman", "S. Zilberstein"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Goldman and Zilberstein,? \\Q2008\\E", "shortCiteRegEx": "Goldman and Zilberstein", "year": 2008}, {"title": "Global optimization: Deterministic approaches", "author": ["R. Horst", "H. Tuy"], "venue": null, "citeRegEx": "Horst and Tuy,? \\Q1996\\E", "shortCiteRegEx": "Horst and Tuy", "year": 1996}, {"title": "Exploiting locality of interaction in networked distributed POMDPs", "author": ["Y. Kim", "R. Nair", "P. Varakantham", "M. Tambe", "M. Yokoo"], "venue": "In AAAI Spring Symposium on Distributed Planning and Scheduling,", "citeRegEx": "Kim et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2006}, {"title": "Fast algorithms for finding randomized strategies in game trees", "author": ["D. Koller", "N. Megiddo", "B. von Stengel"], "venue": "In ACM Symposium on the Theory of Computing,", "citeRegEx": "Koller et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Koller et al\\.", "year": 1994}, {"title": "The linear complementarity problem as a separable bilinear program", "author": ["O.L. Mangasarian"], "venue": "Journal of Global Optimization,", "citeRegEx": "Mangasarian,? \\Q1995\\E", "shortCiteRegEx": "Mangasarian", "year": 1995}, {"title": "Linear complementarity, linear and nonlinear programming. Helderman-Verlag", "author": ["K.G. Murty"], "venue": null, "citeRegEx": "Murty,? \\Q1988\\E", "shortCiteRegEx": "Murty", "year": 1988}, {"title": "Taming decentralized POMDPs: Towards efficient policy computation for multiagent settings", "author": ["R. Nair", "M. Tambe", "M. Yokoo", "D. Pynadath", "S. Marsella"], "venue": "In International Joint Conference on Artificial Inteligence,", "citeRegEx": "Nair et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Nair et al\\.", "year": 2003}, {"title": "Communication for improving policy computation in distributed pomdps", "author": ["R. Nair", "M. Roth", "M. Yokoo", "M. Tambe"], "venue": "In International Joint Conference on Agents and Multiagent Systems (AAMAS),", "citeRegEx": "Nair et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Nair et al\\.", "year": 2004}, {"title": "Decentralized control of a multiple access broadcast channel: performance bounds", "author": ["J.M. Ooi", "G.W. Wornell"], "venue": "In Proceeding of the IEEE Conference on Decision and Control,", "citeRegEx": "Ooi and Wornell,? \\Q1996\\E", "shortCiteRegEx": "Ooi and Wornell", "year": 1996}, {"title": "A course in game theory", "author": ["M.J. Osborne", "A. Rubinstein"], "venue": null, "citeRegEx": "Osborne and Rubinstein,? \\Q1994\\E", "shortCiteRegEx": "Osborne and Rubinstein", "year": 1994}, {"title": "A complementarity approach to a quasistatic rigid body motion problem", "author": ["Pang", "J.-S", "J.C. Trinkle", "G. Lo"], "venue": "Journal of Computational Optimization and Applications,", "citeRegEx": "Pang et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Pang et al\\.", "year": 1996}, {"title": "Anytime coordination using separable bilinear programs", "author": ["M. Petrik", "S. Zilberstein"], "venue": "In Conference on Artificial Intelligence,", "citeRegEx": "Petrik and Zilberstein,? \\Q2007\\E", "shortCiteRegEx": "Petrik and Zilberstein", "year": 2007}, {"title": "Average reward decentralized Markov decision processes", "author": ["M. Petrik", "S. Zilberstein"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "Petrik and Zilberstein,? \\Q2007\\E", "shortCiteRegEx": "Petrik and Zilberstein", "year": 2007}, {"title": "Markov decision processes: Discrete stochastic dynamic programming", "author": ["M.L. Puterman"], "venue": null, "citeRegEx": "Puterman,? \\Q2005\\E", "shortCiteRegEx": "Puterman", "year": 2005}, {"title": "Optimal decentralized control in a multiaccess channel with partial information", "author": ["Z. Rosberg"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "Rosberg,? \\Q1983\\E", "shortCiteRegEx": "Rosberg", "year": 1983}, {"title": "Solution of general LCP by 0-1 mixed integer programming", "author": ["J.B. Rosen"], "venue": "Tech. rep. Computer Science Tech. Report 8623,", "citeRegEx": "Rosen,? \\Q1986\\E", "shortCiteRegEx": "Rosen", "year": 1986}, {"title": "Modeling bounded rationality", "author": ["A. Rubinstein"], "venue": null, "citeRegEx": "Rubinstein,? \\Q1997\\E", "shortCiteRegEx": "Rubinstein", "year": 1997}, {"title": "Memory bounded dynamic programming for DECPOMDPs", "author": ["S. Seuken", "S. Zilberstein"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "Seuken and Zilberstein,? \\Q2007\\E", "shortCiteRegEx": "Seuken and Zilberstein", "year": 2007}, {"title": "Formal models and algorithms for decentralized decision making under uncertainty", "author": ["S. Seuken", "S. Zilberstein"], "venue": "Autonomous Agents and Multiagent Systems,", "citeRegEx": "Seuken and Zilberstein,? \\Q2008\\E", "shortCiteRegEx": "Seuken and Zilberstein", "year": 2008}, {"title": "A finitely convergent algorithm for bilinear programming problems using polar cuts and disjunctive face cuts", "author": ["H.D. Sherali", "C.M. Shetty"], "venue": "Mathematical Programming,", "citeRegEx": "Sherali and Shetty,? \\Q1980\\E", "shortCiteRegEx": "Sherali and Shetty", "year": 1980}, {"title": "Linear Programming: Foundations and Extensions (2nd edition)", "author": ["R.J. Vanderbei"], "venue": null, "citeRegEx": "Vanderbei,? \\Q2001\\E", "shortCiteRegEx": "Vanderbei", "year": 2001}, {"title": "A linear programming approach to solving bilinear programmes", "author": ["D.J. White"], "venue": "Mathematical Programming,", "citeRegEx": "White,? \\Q1992\\E", "shortCiteRegEx": "White", "year": 1992}], "referenceMentions": [{"referenceID": 10, "context": "This results in a multiagent Markov decision process (Boutilier, 1999), which is essentially an MDP with a factored action set.", "startOffset": 53, "endOffset": 70}, {"referenceID": 32, "context": "DEC-POMDPs are closely related to extensive games (Rubinstein, 1997).", "startOffset": 50, "endOffset": 68}, {"referenceID": 6, "context": "In this paper, we introduce an efficient algorithm for several restricted classes, most notably decentralized MDPs with transition and observation independence (Becker et al., 2003).", "startOffset": 160, "endOffset": 181}, {"referenceID": 4, "context": "When the algorithm is applied to DEC-MDPs, it improves efficiency by several orders of magnitude compared with previous state-of the art algorithms (Becker, 2006; Petrik & Zilberstein, 2007a).", "startOffset": 148, "endOffset": 191}, {"referenceID": 20, "context": "1992), and even general linear complementarity problems (Mangasarian, 1995).", "startOffset": 56, "endOffset": 75}, {"referenceID": 36, "context": "The latter formulation can be easily transformed into the normal form using standard transformations of linear programs (Vanderbei, 2001).", "startOffset": 120, "endOffset": 137}, {"referenceID": 5, "context": "1 DEC-MDPs As mentioned previously, any transition-independent and observation-independent DECMDP (Becker et al., 2004) may be formulated as a bilinear program.", "startOffset": 98, "endOffset": 119}, {"referenceID": 4, "context": "One example that we use is the Mars rover planning problem (Bresina, Golden, Smith, & Washington, 1999), first formulated as a DEC-MDP by Becker et al. (2003). This domain involves two autonomous rovers that visit several sites in a given order and may decide to perform certain scientific experiments at each site.", "startOffset": 138, "endOffset": 159}, {"referenceID": 4, "context": "One example that we use is the Mars rover planning problem (Bresina, Golden, Smith, & Washington, 1999), first formulated as a DEC-MDP by Becker et al. (2003). This domain involves two autonomous rovers that visit several sites in a given order and may decide to perform certain scientific experiments at each site. The overall activity must be completed within a given time limit. The uncertainty about the duration of each experiment is modeled by a given discrete distribution. While the rovers operate independently and receive local rewards for each completed experiment, the global reward function also depends on some experiments completed by both rovers. The interaction between the rovers is thus limited to a relatively small number of such overlapping tasks. We return to this problem and describe it in more detail in Section 6. A DEC-MDP problem is composed of two MDPs with state-sets S1, S2 and action sets A1, A2. The functions r1 and r2 define local rewards for action-state pairs. The initial state distributions are \u03b11 and \u03b12. The MDPs are coupled through a global reward function defined by the matrix R. Each entry R(i, j) represents the joint reward for the state-action i by one agent and j by the other. Our definition of a DEC-MDP is based on the work of Becker et al. (2004), with some modifications that we discuss below.", "startOffset": 138, "endOffset": 1301}, {"referenceID": 29, "context": "This property is commonly used when an MDP is formulated as a linear program (Puterman, 2005).", "startOffset": 77, "endOffset": 93}, {"referenceID": 29, "context": "The solution of a DEC-MDP is a deterministic stationary policy \u03c0 = (\u03c01, \u03c02), where \u03c0i : Si 7\u2192 Ai is the standard MDP policy (Puterman, 2005) for agent i.", "startOffset": 124, "endOffset": 140}, {"referenceID": 4, "context": "In particular, this extended reward structure arises from introducing the primitive and compound events in the work of Becker et al. (2004). This reward structure is necessary to capture the characteristics of the Mars rover benchmark.", "startOffset": 119, "endOffset": 140}, {"referenceID": 5, "context": "The correctness of the policy calculation follows from the existence of an optimal policy that is deterministic and depends only on the local states of that agent (Becker et al., 2004).", "startOffset": 163, "endOffset": 184}, {"referenceID": 29, "context": "The matrices A1 and A2 are the same as for the dual formulation of total expected reward MDPs (Puterman, 2005), representing the following equalities for agent i: \u2211", "startOffset": 94, "endOffset": 110}, {"referenceID": 18, "context": "Interestingly, this class of problems has been previously formulated (Kim et al., 2006).", "startOffset": 69, "endOffset": 87}, {"referenceID": 30, "context": "For example, consider the infinitehorizon version of the Multiple Access Broadcast Channel (MABC) (Rosberg, 1983; Ooi & Wornell, 1996).", "startOffset": 98, "endOffset": 134}, {"referenceID": 30, "context": "For example, consider the infinitehorizon version of the Multiple Access Broadcast Channel (MABC) (Rosberg, 1983; Ooi & Wornell, 1996). In this problem, which has been used widely in recent studies of decentralized decision making, two communication devices share a single channel, and they need to periodically transmit some data. However, the channel can transmit only a single message at a time. When both agents send messages at the same time, this leads to a collision, and the transmission fails. The memory of the devices is limited, thus they need to send the messages sooner rather than later. We adapt the model from the work of Rosberg (1983), which is particularly suitable because it assumes no sharing of local information among the devices.", "startOffset": 99, "endOffset": 654}, {"referenceID": 29, "context": "Puterman (2005), for example, provides a more detailed discussion of the definition and meaning of policy gain.", "startOffset": 0, "endOffset": 16}, {"referenceID": 29, "context": "The variables in the program come from the dual formulation of the average-reward MDP linear program (Puterman, 2005).", "startOffset": 101, "endOffset": 117}, {"referenceID": 27, "context": "Petrik and Zilberstein (2007b) provide further details of this formulation.", "startOffset": 0, "endOffset": 31}, {"referenceID": 5, "context": "The approach we develop is closely related to event-driven DECPOMDPs (Becker et al., 2004), but it is in general more efficient.", "startOffset": 69, "endOffset": 90}, {"referenceID": 9, "context": "This can be expected since solving DEC-POMDPs is NEXP-complete (Bernstein et al., 2000), while solving bilinear programs is NP-complete (Mangasarian, 1995).", "startOffset": 63, "endOffset": 87}, {"referenceID": 20, "context": ", 2000), while solving bilinear programs is NP-complete (Mangasarian, 1995).", "startOffset": 56, "endOffset": 75}, {"referenceID": 2, "context": "The approach in this case may be similar to linear complementarity problem formulation of extensive games (Koller, Megiddo, & von Stengel, 1994), and integer linear program formulation of DEC-POMDPs (Aras & Charpillet, 2007). The approach we develop is closely related to event-driven DECPOMDPs (Becker et al., 2004), but it is in general more efficient. Nevertheless, the size of the bilinear program is exponential in the size of the DEC-POMDP. This can be expected since solving DEC-POMDPs is NEXP-complete (Bernstein et al., 2000), while solving bilinear programs is NP-complete (Mangasarian, 1995). Because the general formulation in this case is somewhat cumbersome, we only illustrate it using the following simple example. Aras (2008) provides the details of a similar construction.", "startOffset": 200, "endOffset": 743}, {"referenceID": 20, "context": "It has also been shown that a linear complementarity problem may be formulated as a bilinear problem (Mangasarian, 1995).", "startOffset": 101, "endOffset": 120}, {"referenceID": 36, "context": "The complementary slackness values (Vanderbei, 2001) for the linear programs Eq.", "startOffset": 35, "endOffset": 52}, {"referenceID": 20, "context": "While the algorithm often performs well in practice, it tends to converge to a suboptimal solution (Mangasarian, 1995).", "startOffset": 99, "endOffset": 118}, {"referenceID": 5, "context": "This general approach is also used by the coverage set algorithm (Becker et al., 2004).", "startOffset": 65, "endOffset": 86}, {"referenceID": 5, "context": "That guarantees that g(y) is eventually known precisely (Becker et al., 2004).", "startOffset": 56, "endOffset": 77}, {"referenceID": 12, "context": "A similar approach was also taken for POMDPs (Cheng, 1988).", "startOffset": 45, "endOffset": 58}, {"referenceID": 36, "context": "In general, the simplex algorithm is preferable to interior point methods for this program because of its small size (Vanderbei, 2001).", "startOffset": 117, "endOffset": 134}, {"referenceID": 4, "context": "The maximal difference is actually achieved in points where some of the planes meet, as Becker et al. (2004) have suggested.", "startOffset": 88, "endOffset": 109}, {"referenceID": 4, "context": "As described in the next section, the dimensionality reduction technique generalizes the reduction that Becker et al. (2004) used implicitly.", "startOffset": 104, "endOffset": 125}, {"referenceID": 21, "context": "(1) can also be modeled as a linear complementarity problem (LCP) (Murty, 1988; Cottle et al., 1992), we do not evaluate that option experimentally because LCPs are closely related to MILPs (Rosen, 1986).", "startOffset": 66, "endOffset": 100}, {"referenceID": 13, "context": "(1) can also be modeled as a linear complementarity problem (LCP) (Murty, 1988; Cottle et al., 1992), we do not evaluate that option experimentally because LCPs are closely related to MILPs (Rosen, 1986).", "startOffset": 66, "endOffset": 100}, {"referenceID": 31, "context": ", 1992), we do not evaluate that option experimentally because LCPs are closely related to MILPs (Rosen, 1986).", "startOffset": 97, "endOffset": 110}, {"referenceID": 18, "context": "(1) as Petrik and Zilberstein (2007b) describe.", "startOffset": 7, "endOffset": 38}, {"referenceID": 8, "context": "(1) can also be modeled as a linear complementarity problem (LCP) (Murty, 1988; Cottle et al., 1992), we do not evaluate that option experimentally because LCPs are closely related to MILPs (Rosen, 1986). We expect these two formulations to exhibit similar performance. We also do not compare to any of the methods described by Horst and Tuy (1996) and Bennett and Mangasarian (1992) due to their very different nature and high complexity, and because some of these algorithms do not provide any optimality guarantees.", "startOffset": 80, "endOffset": 349}, {"referenceID": 4, "context": "We also do not compare to any of the methods described by Horst and Tuy (1996) and Bennett and Mangasarian (1992) due to their very different nature and high complexity, and because some of these algorithms do not provide any optimality guarantees.", "startOffset": 83, "endOffset": 114}, {"referenceID": 4, "context": "Becker et al. (2004) achieved the same compression using compound events, where each compound event represents the fact that an experiment is performed on some site regardless of the specific time.", "startOffset": 0, "endOffset": 21}, {"referenceID": 5, "context": "problem setup with at most 4 shared sites, CSA solved only 76% of the problems, and the longest solution took approximately 4 hours (Becker et al., 2004).", "startOffset": 132, "endOffset": 153}, {"referenceID": 37, "context": "Besides multiagent coordination problems, bilinear programs have been previously used to solve problems in operations research and global optimization (Sherali & Shetty, 1980; White, 1992; Gabriel, Garca-Bertrand, Sahakij, & Conejo, 2005).", "startOffset": 151, "endOffset": 238}, {"referenceID": 17, "context": "Horst and Tuy (1996) provide an excellent overview of these techniques.", "startOffset": 0, "endOffset": 21}], "year": 2009, "abstractText": "Multiagent planning and coordination problems are common and known to be computationally hard. We show that a wide range of two-agent problems can be formulated as bilinear programs. We present a successive approximation algorithm that significantly outperforms the coverage set algorithm, which is the state-of-the-art method for this class of multiagent problems. Because the algorithm is formulated for bilinear programs, it is more general and simpler to implement. The new algorithm can be terminated at any time and\u2013unlike the coverage set algorithm\u2013it facilitates the derivation of a useful online performance bound. It is also much more efficient, on average reducing the computation time of the optimal solution by about four orders of magnitude. Finally, we introduce an automatic dimensionality reduction method that improves the effectiveness of the algorithm, extending its applicability to new domains and providing a new way to analyze a subclass of bilinear programs.", "creator": "LaTeX with hyperref package"}}}