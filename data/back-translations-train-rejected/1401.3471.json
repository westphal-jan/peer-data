{"id": "1401.3471", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Conservative Inference Rule for Uncertain Reasoning under Incompleteness", "abstract": "In this paper we formulate the problem of inference under incomplete information in very general terms. This includes modelling the process responsible for the incompleteness, which we call the incompleteness process. We allow the process behaviour to be partly unknown. Then we use Walleys theory of coherent lower previsions, a generalisation of the Bayesian theory to imprecision, to derive the rule to update beliefs under incompleteness that logically follows from our assumptions, and that we call conservative inference rule. This rule has some remarkable properties: it is an abstract rule to update beliefs that can be applied in any situation or domain; it gives us the opportunity to be neither too optimistic nor too pessimistic about the incompleteness process, which is a necessary condition to draw reliable while strong enough conclusions; and it is a coherent rule, in the sense that it cannot lead to inconsistencies. We give examples to show how the new rule can be applied in expert systems, in parametric statistical inference, and in pattern classification, and discuss more generally the view of incompleteness processes defended here as well as some of its consequences.", "histories": [["v1", "Wed, 15 Jan 2014 05:28:54 GMT  (509kb)", "http://arxiv.org/abs/1401.3471v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["marco zaffalon", "enrique miranda"], "accepted": false, "id": "1401.3471"}, "pdf": {"name": "1401.3471.pdf", "metadata": {"source": "CRF", "title": "Conservative Inference Rule for Uncertain Reasoning under Incompleteness", "authors": ["Marco Zaffalon", "Enrique Miranda"], "emails": ["zaffalon@idsia.ch", "mirandaenrique@uniovi.es"], "sections": [{"heading": "1. Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2. Coherent Lower Previsions", "text": "We give a brief introduction to the concepts and outcomes of the behavioral theory of imprecise pricing of K > J = J. We refer the reader to the work of Walley (1991) for an in-depth study of contiguous lower previsions and to the work of Miranda (2008) for an overview of the theory.Consider a possibility space that can, for example, represent the amount of possible outcomes of an experiment. In the theory of coherent lower previsions, the views on the probability of these outcomes are represented by lower previsions of games of chance. (Definition 1) Consider a possibility space in which a game of chance represents a limited reality-rated function based on. The set of all games of chance based on L (2005) is a lower functional element that we define as a real functional element."}, {"heading": "3. The Basic Setting", "text": "In this section we present the basic assumptions about the spaces considered in our model and about the incompleteness process."}, {"heading": "3.1 The Domain", "text": "As we mentioned in the introduction, in this essay we consider the problem of drawing conclusions about the value that a target variable Z in Z draws from information about the value that another variable Y takes in a sentence Y. In this essay we assume that the sentence Y is finite, but the set Z of possible values for the target variable Z can be infinite."}, {"heading": "3.2 The Incompleteness Process", "text": "It is not uncommon that the devices we use to obtain information about Y, whatever they are, do not let us see it exactly as it is. (For this reason, we are explicitly dependent on observing Y through a new variable W, which incorporates values into the finite setW of possible observations. We call W the observation of Y. W is the result of the observation process.) We point out that it is necessary to introduce variable W even if it is a perfectly normal habit to deal only with the variables Z and Y. The possibility of dropping W depends on the assumptions made if we assume that CAR / MAR then overrides the variable at a certain point in the derivative, resulting in formulations containing only Z and Y."}, {"heading": "3.3 Refining Facts, Observations, and the Incompleteness Process", "text": "In this section, we add a structure to the incompleteness process by presenting it as the combination of two different incompleteness processes acting on different parts of a fact. (We model these two parts by writing Y: (Y) and Y (Y) are two new variables, with values in Y and Y (each such that Y = Y). (W) and W (W) show analogously what the observation W of Y is as observation W of Y (together with the observation W of Y), and thus we write W: (W). (W) and W (W) are two new variables, with values in W (respectively W). The additional variables introduced, in fact, allow us to think about two new IPs: the first action on variable Y and the second on variable Y, which leads to observation W, and thus characterized by a certain multi-rated chart Y."}, {"heading": "4. The Conservative Inference Rule", "text": "The notations introduced so far finally allow us to write the definition of the conservative rule of conclusion. To this extent, we assume that we have beliefs about (Z, Y) in the form of a common lower preference P 1.Definition 7 (conservative rule of conclusion). Let us consider a gamble g on Z and w \u00b2 W, and let us assume that P 1 (w) \"positive\" events 1: = \"y,\" \"p,\" \"w,\" \"c,\" \"c,\" \"c,\" \"c,\" \"c,\" \"c,\" \"c,\" \"c,\" \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c. \""}, {"heading": "4.1 Significance of the Conservative Inference Rule", "text": "We can think of the CIR as a generalization of two types of updating rules: it generalizes the traditional updating rule, which requires, for example, discarding missing observations; the CIR agrees with such a rule if the intellectual property consists only of the CAR component; but if there is no CAR component and all intellectual property is unknown, the CIR is similar (but more powerful than that) to the so-called conservative updating rule (CUR) of De Cooman and Zaffalon (2004); if both components are present, the CIR acts as a mixture of traditional updating and CUR.As the CUR, the CIR is an imprecise rule: it generally leads to lower and higher expectations and partially defined decisions; this is partly because it allows the inaccuracy of P 1. But even if we consider this a linear bias P1, the CIR turns out to be an inaccuracy rule: an inaccuracy as a consequence of our inaccuracy."}, {"heading": "4.1.1 Comparison with CUR", "text": "In this case, it is only a matter of time until there is an agreement. (...) In this case, it is only a matter of time until there is an agreement. (...) It is a matter of time until there is an agreement. (...) It is a matter of time until there is an agreement. (...) It is a matter of time until there is an agreement. (...) It is a matter of time until there is a decision. (...) It is a matter of time until there is an agreement. (...) \"(...)\" (...) \"(...)\" (... \")\" (... \"(...)\" (... \")\" (... \")\" (... \")\" (... \")\" (... \")\" (... \")\" (... \")\" (... \"(...)\" (...) \"(...\") \"(...\") \"(...\") \"(...\") (... \") (...\" (...) \"(...\") \"(...\") \"(...\") (... \"(...\") \"(...\") (... \") (...\" () (... \") () (...\") (... \"() () (...\") () (... \") (...\") (... \") () (...\") (... \") () () (...\") () (... \") (...\") (... \") () (...\") () (... \") () (...\") () (... \") () (...\") (... \") () (...\") () () (... \") () () (...\") (... \") () () () () () () (() () () (()) (()) ((((())))) ((((((((())))) (((((((()))))) (((((((())))) ((((((((()))))) (((((((((((())))))))) ((((((((((()))))))"}, {"heading": "4.1.2 Originality of CIR", "text": "It is interesting that the CIR, like traditional updates and CUR, is based only on the variables Z and Y: i.e. in the application of the CIR, one does not have to take into account the W variables, which makes the use of the CIR particularly easy. Another consideration concerns the originality: to the best of our knowledge and belief, the CIR appears here for the first time. There are articles in the literature that resemble the CIR in the case of learning statistical models from samples made incomplete by an unknown error process (e.g. Manski, 2003; Ramoni & Sebastiani, 2001; Zaffalon, 2002). This is not surprising, since the intuition to take into account all the completions of an incomplete sample is actually very natural."}, {"heading": "5. Applications", "text": "In the following sections, we will show how the CIR easily leads to several different rules depending on the application studied, presenting a number of examples. To simplify matters, we will not go into the details of the cards used with their different values; we will only consider W-shaped as the totality of all non-empty subsets of Y-shaped and assume that the hypotheses made throughout the essay are valid. We will adopt similar considerations for CAR intellectual property."}, {"heading": "5.1 CIR for Expert Systems", "text": "This is not the first time that an expert has examined the diagnostic results as well as the probabilities that define the Asian network in which the value of the target is set. The Asian network in Figure 1 represents a well-known artificial example of an expert system in the medical field. It is believed that an expert has introduced the graph as well as the probabilities that define the Asian network, as shown in Table 1. If we want to use the network to make the diagnosis, we first select a target node, such as R or B. Then we collect information about the patient, as well as the results of medical tests, such as X-rays, and make it available to the network by providing the related nodes in the values observed. Finally, we question the network to update the probability of the target node."}, {"heading": "5.2 CIR for Parametric Statistical Inference", "text": "We assume that the Di variables have the same space of possibilities for each i. We can illustrate the problem of parametric statistical inferences by refocusing on the Asian Bayesian network in Figure 1: a common step in the construction of Bayesian networks is to relate the net parameters from a data collection."}, {"heading": "5.2.1 IID+ID Case", "text": "In the previous section, we did not make hypotheses about the generation of the complete sample. However, in practice, it is very common to deal with independent and identically distributed data (also called multinomial data), and indeed we have adopted IID for the data in (2). With multinomial data, the units are distributed identically, and this helps to simplify developments. Let us call D the space of possibilities common to the units. If we assume that D is finite (as we will do in our derivation of the CIR rule in Section 7.3), the parameter \"W\" is defined as a vector. [2] d \"d\" d \"d\" d \"d\" d \"d\" d \"d\" d \"d\" d \"d\" d \"d\" d \"d\" d \"d\" d. \""}, {"heading": "5.2.2 Full IID Case?", "text": "Is it reasonable to assume that an IP is equally distributed next to independently distributed processes? And what are the consequences of such an assumption? Let's start with the second question. Under IID for complete data, the generic element d-D has a fixed aleatory probability, which we call \"d.\" Let's call W the space of possibilities common to the variables Wi, i = 1..., N) Under IID for IP, the generic element w of W has a fixed aleatory probability of being produced by \"d,\" let's call it \"\u03a6dw.\" Consequently, w has a fixed unconditional aleatory probability of being produced: \"w: = \u2211 d-D,\" which means that the process that produces elements of W is also multinomial. This seems to greatly simplify the setup that has been considered so far, and can therefore be regarded as an advantage of full IID adoption (this advantage has clear practical consequences in the case of classifying patterns as illustrated in Section 5.2)."}, {"heading": "5.2.3 CAR Units", "text": "The idea behind this is that the general IP does not have to be distributed equally, it may happen that it functions as a CAR process for some units. Let's say that a certain unit 0 is coarsely coarsed at random; the question is what form the CIR takes today. It is easy to see this by defining Y units: = (Y-1,.., Y-N), Y units: = (D0, Y-1,..., Y-N), and the corresponding observation variables W-1,... (W-1,.), W-N: = (W0, W-1,..., W-N), which lead to the following rule: R-w units, w units, w-y-y units, i.e. min-y units."}, {"heading": "5.3 CIR for Pattern Classification", "text": "This section focuses on problems of pattern classification, a specific case of so-called predictive inference for people classified in Asia. Loosely speaking, this type of inference is about predicting future elements of a sequence based on the available part of the sequence itself. In a classification problem, the available sequence is represented by the following matrix: C1 F1 C2 F2...... CN FN. (6) The generic line i, or unit i, the matrix represents an object described by a pair of variables that we call Di: (Ci, Fi) in accordance with the notation used for parametric inference. Variable Ci represents a characteristic of the object we are interested in and which we call class. By defining pattern classification, C is a finite unit. Variable Fi represents some characteristics of the object that are informative about the class."}, {"heading": "5.3.1 An Example", "text": "Let's refocus on the first example in Section 5.3, where we were interested in classifying people as either smokers or non-smokers. To make things easier, we take gc to be the 0-1 loss function, that is, we calculate subordinate probabilities, not expectations, to issue a na\u00efve classification. Furthermore, we take the graph of the Asian network to represent the probable dependencies between the variables involved (but we do not assume that the net parameters we have given are part of the inferential task of the classification that we need to solve). To make the example more manageable, we assume that for all the people we want to classify, we miss information about the variables V, O, L, and A in the Asian network, and that this misunderstanding is MAR: that is, these variables constitute F + 1. This implies that we can actually evaluate diskard variables V, B, L, and O only by looking at them."}, {"heading": "5.3.2 On the Failure of Empirical Evaluations", "text": "This year, it is only a matter of time before we reach an agreement."}, {"heading": "6. Advanced Notions about Coherent Lower Previsions", "text": "We introduce some advanced ideas on coherent lower previsions that we need in the rest of the paper, especially for deriving CIR in Section 7."}, {"heading": "6.1 Coherence of a Number of Conditional Lower Previsions", "text": "It is therefore not uncommon for a subject to apply a finite number of different, subordinate previsions. (XOm) It is not uncommon for us to apply a finite number of different, subordinate previsions. (XOm) It is inevitable that we seek a conditional, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, subordinate, (XOj, subordinate, XOj, subordinate, XOj, subordinate, (XOm)."}, {"heading": "6.2 Coherence Graphs", "text": "In fact, most of them will be able to play by the rules they had in the past, and they will be able to play by the rules that were in place in the past."}, {"heading": "6.3 Updating Coherent Lower Previsions", "text": "An updating rule that can be applied to lower predictions is the regular extension: Definition 13 Let P be a coherent lower prediction (f | x) is R (f | x): = inf {P (fIx) P (x): P (x): P (x), P (x) > 0}.Remember that M (P) is the series of linear predictions P with the domain L (X n) dominating P. When XI is finite and P (x) > 0 for all x-XI. The conditional lower prediction R (XO | XI) by regular extension is consistent with P. The definition shows that the regular extension also has a nice sensitivity analysis: i.e., the application of the Bayes rule to the prevailing linear predictions X.Perhaps for this reason, the regular extension R & XII was repeatedly proposed (R = 1991) and not the prediction from 1991 to 2004, but rather."}, {"heading": "6.4 Products of Conditional Lower Previsions", "text": "XI2) (XI2) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3)) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XIX) (XIX) (XI3) (XI3) (XI3) (XIX) (XIX) (XIX) (XI3) (XIX (XI3) (XIX) (XIX (XI3) (XIX) (XI3) (XIX (XI3) (XI3) (XI3) (XI3) (XIX (XI3) (XIX) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) (XI3) ("}, {"heading": "7. Derivation of CIR", "text": "In the next sections, we will make a series of assumptions, discuss them, and finally use them to derive ZIR."}, {"heading": "7.1 Modelling Beliefs", "text": "In this area, we are in a position to limit ourselves to the question of whether we see ourselves in a position to show ourselves in a position to show that we see ourselves in a position to stay in the world, and that we see ourselves in a position to stay in the world, in which we live, in which we live, in the world in which we live, in which we live, in the world in which we live, in which we live, in the world in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in the world, in which we live, in which we live, in the world, in which we live, in which we live, in the world, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live in which we live, in which we live, in which we live in which we live, in which we live, in which we live in which we live, in which we live, in which we live in which we live, in which we live, in which we live, in which we live in which we live, in which we live, we live in which we live, in which we live, in which we live in the world, in which we live, in which we live, in which we live, we live in which we live, in which we live in which we live, in which we live in which we live, we live in the world, in which we live, in the world, in which we live, in which we live, in which we live in which we live, in which we live, we live in which we live, we live in which we live in the world, in which we live, in the world, in which we live, in which we live, in which we live, in which we live, in which we live in which we live, we live in which we live in which we live, we live in the world, in the world, in which we live, in which we live, in"}, {"heading": "7.1.1 Domain Beliefs", "text": "Consider the variables Z and Y, which represent facts. Belief in facts in the form of a coherent lower prejudice P 1 is specific to the area under consideration; this is why we call them domain beliefs. In the case of the Asia network, P 1 would merely correspond to the common mass function encoded by the network itself. We will only make a minimal assumption about domain beliefs just because P 1 must be as flexible a tool as possible to express beliefs in a wide range of domains. This task is put on hold after we have focused on a very different type of beliefs, which we call beliefs about the incompleteness process."}, {"heading": "7.1.2 Beliefs about the Incompleteness Process", "text": "This means that we assume that it is an unknown IP model, about which we are almost ignorant. The term \"almost\" emphasizes that, despite a deep kind of ignorance, something is assumed that is known about the unknown IP. For one thing, it produces incompleteness only on the basis of Y. Formally, we assume that there is a separately related conditional lower model."}, {"heading": "7.1.3 Joint Beliefs", "text": "The question in this paragraph is whether the two models that we have in mind are actually the question, whether the two models that we know of are the question, the question, whether it is really the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question, whether it is the question."}, {"heading": "7.1.4 An Assumption about Domain Beliefs", "text": "It should be remembered that we have introduced W as a way to model observations, and therefore our beliefs should be consistent with the possibility of making such an observation. To this extent, it seems necessary that we at least believe that we can establish: W \u21d2 P ({w} \u043a) > 0, (DB1), taking into account the coherence implies that P (w) = P 1 (w). Assumption (DB1) is equivalent to the existence of an extreme point P1 of M (P 1), so that P1 (w) > 0. The following sentence shows that this assumption is sufficient to reconcile our beliefs with the possibility of performing the observation. Assumption 1 (DB1) implies that P (w): = P (Z, Y, w) > 0.Evidence."}, {"heading": "7.2 Assumptions Discussed", "text": "This year, it has reached the point where it will be able to seek a solution that is capable of finding a solution, that is capable of finding a solution, and that is able to find a solution that is capable of finding a solution, that is capable of finding a solution, that is capable of finding a solution, that is capable of finding a solution, that is capable of finding a solution, that is capable of finding a solution, that is capable of finding a solution, that is capable of finding a solution. \""}, {"heading": "7.3 Derivation of CIR", "text": "To formulate the fundamental problem of this paper, we must focus on the problem of adaptation to a generic function (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G (G). (G). (G). (G). (G). (G). (G). (G (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G). (G"}, {"heading": "8. Conclusions", "text": "This year, the time has come for us to be able to assert ourselves, to be able to be able, to be able to be in a position, to be able to be in a position, to be able to be in a position, to be able to be in a position, to be able to be in a position, to be in a position, to be in a position, to be in a position, to be in a position, to be in a position, to be able to be in a position, to be able to unite. \""}, {"heading": "Acknowledgments", "text": "It is important to be aware that not all multivalued cards are in line with the CAR assumption. Here's an example: Let's take Y: = {1, 3, 4}, W: = {a, 3}, W: = {a, 3, 4}, W: = {a, 3, 4}, W: = {a, 4, 4}, W: = 3, \"W: = 3,\" W: = 3, \"W: = 3,\" W: =, b, c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3,\" c: 3, \"c: 3, c: 3,\" c: 3, \"c: 3, c: 3,\" c: 3, c: 3, c: 3, c: 3, \"c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3, c: 3,"}, {"heading": "Appendix B. Coherence of CIR", "text": "In this appendix, we will prove that the assessments in the construction of the Conservative Conclusion satisfy only the notion of coherence, and furthermore that they are also related to a number of other conditional and unconditional premises that we can deduce from them. We will also cover the case in which the unconditional premise P 1 (Z, Y) is constructed from a number of other conditional and unconditional premises, which is a very typical case in practice. We will then consider the variables X1,., Xn, the values in the respective sets X1,., Xn, and take a collection of conditional premises P 1 (XO1),., Pm (XOm). We will begin with a dilemma that shows that A1 graph naturally has an idea of the associated lower premises: in particular, that it is possible to allow the index of the two lower premises."}], "references": [{"title": "Equivalence between Bayesian and credal nets on an updating problem", "author": ["A. Antonucci", "M. Zaffalon"], "venue": "Proceedings of the third international conference on Soft Methods in Probability and Statistics,", "citeRegEx": "Antonucci and Zaffalon,? \\Q2006\\E", "shortCiteRegEx": "Antonucci and Zaffalon", "year": 2006}, {"title": "Fast algorithms for robust classification with Bayesian nets", "author": ["A. Antonucci", "M. Zaffalon"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "Antonucci and Zaffalon,? \\Q2007\\E", "shortCiteRegEx": "Antonucci and Zaffalon", "year": 2007}, {"title": "Decision-theoretic specification of credal networks: a unified language for uncertain modeling with sets of Bayesian networks", "author": ["A. Antonucci", "M. Zaffalon"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "Antonucci and Zaffalon,? \\Q2008\\E", "shortCiteRegEx": "Antonucci and Zaffalon", "year": 2008}, {"title": "Generalized loopy 2U: a new algorithm for approximate inference in credal networks", "author": ["A. Antonucci", "M. Zaffalon", "Y. Sun", "C.P. de Campos"], "venue": "Proceedings of the fourth European Workshop on Probabilistic Graphical Models,", "citeRegEx": "Antonucci et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Antonucci et al\\.", "year": 2008}, {"title": "Bayesian interpretation of frequentist procedures for a Bernoulli process", "author": ["Bernard", "J.-M."], "venue": "The American Statistician, 50 (1), 7\u201313.", "citeRegEx": "Bernard and J..M.,? 1996", "shortCiteRegEx": "Bernard and J..M.", "year": 1996}, {"title": "Theory of Charges", "author": ["K.P.S. Bhaskara Rao", "M. Bhaskara Rao"], "venue": null, "citeRegEx": "Rao and Rao,? \\Q1983\\E", "shortCiteRegEx": "Rao and Rao", "year": 1983}, {"title": "Independence concepts for convex sets of probabilities", "author": ["L. Campos", "S. Moral"], "venue": null, "citeRegEx": "Campos and Moral,? \\Q1995\\E", "shortCiteRegEx": "Campos and Moral", "year": 1995}, {"title": "Learning reliable classifiers from small or incomplete data sets: the naive credal classifier 2", "author": ["G. Corani", "M. Zaffalon"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Corani and Zaffalon,? \\Q2008\\E", "shortCiteRegEx": "Corani and Zaffalon", "year": 2008}, {"title": "A survey of concepts of independence for imprecise probability", "author": ["I. Couso", "S. Moral", "P. Walley"], "venue": "Risk, Decision and Policy,", "citeRegEx": "Couso et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Couso et al\\.", "year": 2000}, {"title": "Credal networks", "author": ["F.G. Cozman"], "venue": "Artificial Intelligence, 120 (2), 199\u2013233.", "citeRegEx": "Cozman,? 2000", "shortCiteRegEx": "Cozman", "year": 2000}, {"title": "Graphical models for imprecise probabilities", "author": ["F.G. Cozman"], "venue": "International Journal of Approximate Reasoning, 39 (2\u20133), 167\u2013184.", "citeRegEx": "Cozman,? 2005", "shortCiteRegEx": "Cozman", "year": 2005}, {"title": "The inferential complexity of bayesian and credal networks", "author": ["C.P. De Campos", "F.G. Cozman"], "venue": "In IJCAI-05,", "citeRegEx": "Campos and Cozman,? \\Q2005\\E", "shortCiteRegEx": "Campos and Cozman", "year": 2005}, {"title": "The concept of conditional fuzzy measures", "author": ["L.M. De Campos", "M.T. Lamata", "S. Moral"], "venue": "International Journal of Intelligent Systems,", "citeRegEx": "Campos et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Campos et al\\.", "year": 1990}, {"title": "Updating beliefs with incomplete observations", "author": ["G. De Cooman", "M. Zaffalon"], "venue": "Artificial Intelligence,", "citeRegEx": "Cooman and Zaffalon,? \\Q2004\\E", "shortCiteRegEx": "Cooman and Zaffalon", "year": 2004}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": "Journal of the Royal Statistical Society,", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "Pattern Classification and Scene Analysis", "author": ["R.O. Duda", "P.E. Hart"], "venue": null, "citeRegEx": "Duda and Hart,? \\Q1973\\E", "shortCiteRegEx": "Duda and Hart", "year": 1973}, {"title": "A new approach to updating beliefs", "author": ["R. Fagin", "J.Y. Halpern"], "venue": "Uncertainty in Artificial Intelligence,", "citeRegEx": "Fagin and Halpern,? \\Q1991\\E", "shortCiteRegEx": "Fagin and Halpern", "year": 1991}, {"title": "Coarsening at random: characterisations, conjectures and counter-examples", "author": ["R. Gill", "M. Van der Laan", "J. Robins"], "venue": "Proceedings of the first Seattle Conference on Biostatistics,", "citeRegEx": "Gill et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Gill et al\\.", "year": 1997}, {"title": "Ignorability in statistical and probabilistic inference", "author": ["M. Jaeger"], "venue": "Journal of Artificial Intelligence Research, 24, 889\u2013917.", "citeRegEx": "Jaeger,? 2008", "shortCiteRegEx": "Jaeger", "year": 2008}, {"title": "Bayesian updating and belief functions", "author": ["Jaffray", "J.-Y."], "venue": "IEEE Transactions on Systems, Man and Cybernetics, 22, 1144\u20131152.", "citeRegEx": "Jaffray and J..Y.,? 1992", "shortCiteRegEx": "Jaffray and J..Y.", "year": 1992}, {"title": "The Enterprise of Knowledge", "author": ["I. Levi"], "venue": "MIT Press, London.", "citeRegEx": "Levi,? 1980", "shortCiteRegEx": "Levi", "year": 1980}, {"title": "Statistical Analysis with Missing Data", "author": ["R.J.A. Little", "D.B. Rubin"], "venue": null, "citeRegEx": "Little and Rubin,? \\Q1987\\E", "shortCiteRegEx": "Little and Rubin", "year": 1987}, {"title": "Partial Identification of Probability Distributions", "author": ["C.F. Manski"], "venue": "Springer-Verlag, New York.", "citeRegEx": "Manski,? 2003", "shortCiteRegEx": "Manski", "year": 2003}, {"title": "A survey of the theory of coherent lower previsions", "author": ["E. Miranda"], "venue": "International Journal of Approximate Reasoning, 48 (2), 628\u2013658.", "citeRegEx": "Miranda,? 2008", "shortCiteRegEx": "Miranda", "year": 2008}, {"title": "Updating coherent previsions on finite spaces", "author": ["E. Miranda"], "venue": "Fuzzy Sets and Systems, 160 (9), 1286\u20131307.", "citeRegEx": "Miranda,? 2009", "shortCiteRegEx": "Miranda", "year": 2009}, {"title": "Coherence and independence in non-linear spaces", "author": ["E. Miranda", "G. De Cooman"], "venue": "Tech. rep.,", "citeRegEx": "Miranda and Cooman,? \\Q2005\\E", "shortCiteRegEx": "Miranda and Cooman", "year": 2005}, {"title": "Marginal extension in the theory of coherent lower previsions", "author": ["E. Miranda", "G. De Cooman"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "Miranda and Cooman,? \\Q2007\\E", "shortCiteRegEx": "Miranda and Cooman", "year": 2007}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": "Morgan Kaufmann, San Mateo.", "citeRegEx": "Pearl,? 1988", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Learning from what you don\u2019t observe", "author": ["M.A. Peot", "R.D. Shachter"], "venue": "Uncertainty in Artificial Intelligence (Proceedings of the Fourteenth Conference),", "citeRegEx": "Peot and Shachter,? \\Q1998\\E", "shortCiteRegEx": "Peot and Shachter", "year": 1998}, {"title": "Some observations on inverse probability including a new indifference rule", "author": ["W. Perks"], "venue": "J. Inst. Actuar., 73, 285\u2013312.", "citeRegEx": "Perks,? 1947", "shortCiteRegEx": "Perks", "year": 1947}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["L. Rabiner"], "venue": "Proceedings of the IEEE, 77 (2), 257\u2013286.", "citeRegEx": "Rabiner,? 1989", "shortCiteRegEx": "Rabiner", "year": 1989}, {"title": "Robust learning with missing data", "author": ["M. Ramoni", "P. Sebastiani"], "venue": "Machine Learning,", "citeRegEx": "Ramoni and Sebastiani,? \\Q2001\\E", "shortCiteRegEx": "Ramoni and Sebastiani", "year": 2001}, {"title": "Conditional probability", "author": ["G. Shafer"], "venue": "International Statistical Review, 53, 261\u2013277.", "citeRegEx": "Shafer,? 1985", "shortCiteRegEx": "Shafer", "year": 1985}, {"title": "Me\u00dffehler und Information", "author": ["V. Strassen"], "venue": "Zeitschrift f\u00fcr Wahrscheinlichkeitstheorie und Verwandte Gebiete, 2, 273\u2013305.", "citeRegEx": "Strassen,? 1964", "shortCiteRegEx": "Strassen", "year": 1964}, {"title": "Decision making under uncertainty using imprecise probabilities: an introductory overview", "author": ["M.C.M. Troffaes"], "venue": "International Journal of Approximate Reasoning, 45 (1), 17\u201329.", "citeRegEx": "Troffaes,? 2007", "shortCiteRegEx": "Troffaes", "year": 2007}, {"title": "Coherent lower (and upper) probabilities", "author": ["P. Walley"], "venue": "Tech. rep. Statistics Research Report 22, University of Warwick, Coventry.", "citeRegEx": "Walley,? 1981", "shortCiteRegEx": "Walley", "year": 1981}, {"title": "Statistical Reasoning with Imprecise Probabilities", "author": ["P. Walley"], "venue": "Chapman and Hall, New York.", "citeRegEx": "Walley,? 1991", "shortCiteRegEx": "Walley", "year": 1991}, {"title": "Inferences from multinomial data: learning about a bag of marbles", "author": ["P. Walley"], "venue": "J. R. Statist. Soc. B, 58 (1), 3\u201357.", "citeRegEx": "Walley,? 1996a", "shortCiteRegEx": "Walley", "year": 1996}, {"title": "Measures of uncertainty in expert systems", "author": ["P. Walley"], "venue": "Artificial Intelligence, 83 (1), 1\u201358.", "citeRegEx": "Walley,? 1996b", "shortCiteRegEx": "Walley", "year": 1996}, {"title": "Direct algorithms for checking consistecy and making inferences for conditional probability assessments", "author": ["P. Walley", "R. Pelessoni", "P. Vicig"], "venue": "Journal of Statistical Planning and Inference,", "citeRegEx": "Walley et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Walley et al\\.", "year": 2004}, {"title": "Statistical inference of the naive credal classifier", "author": ["M. Zaffalon"], "venue": "De Cooman, G., Fine, T. L., & Seidenfeld, T. (Eds.), ISIPTA \u201901: Proceedings of the Second International Symposium on Imprecise Probabilities and Their Applications, pp. 384\u2013393, The Netherlands. Shaker.", "citeRegEx": "Zaffalon,? 2001", "shortCiteRegEx": "Zaffalon", "year": 2001}, {"title": "Exact credal treatment of missing data", "author": ["M. Zaffalon"], "venue": "Journal of Statistical Planning and Inference, 105 (1), 105\u2013122.", "citeRegEx": "Zaffalon,? 2002", "shortCiteRegEx": "Zaffalon", "year": 2002}, {"title": "Conservative rules for predictive inference with incomplete data", "author": ["M. Zaffalon"], "venue": "Cozman, F. G., Nau, R., & Seidenfeld, T. (Eds.), ISIPTA \u201905: Proceedings of the Fourth International Symposium on Imprecise Probabilities and Their Applications, pp. 406\u2013415, Manno, Switzerland. SIPTA.", "citeRegEx": "Zaffalon,? 2005", "shortCiteRegEx": "Zaffalon", "year": 2005}], "referenceMentions": [{"referenceID": 27, "context": "Let us make this more concrete with the help of the graphical language of Bayesian networks (Pearl, 1988):2 consider the well-known \u2018Asia\u2019 net displayed in Figure 1, which is intended to model an artificial medical problem.", "startOffset": 92, "endOffset": 105}, {"referenceID": 36, "context": "De Cooman and Zaffalon (2004) tried to remedy this by an approach to IPs alternative to CAR that is based on coherent lower previsions (Walley, 1991), i.", "startOffset": 135, "endOffset": 149}, {"referenceID": 16, "context": "The assumption that models non-selectiveness is called coarsening at random (or CAR, see Gill et al., 1997), or missing at random (or MAR, see Little & Rubin, 1987) in the special case of missingness processes (see also Jaeger, 2008). CAR implies that the incompleteness is non-informative and can be ignored; it thus creates the formal basis for applying the methods developed for complete information to the incomplete case. For example, if we assume that the vector (?, ?, ?, h\u2032\u2032, ?, ?, a\u2032) has been created by a CAR IP, then we are allowed to infer the value of R on the sole basis of the subvector (h\u2032\u2032, a\u2032); more precisely, if we aim at computing the posterior probability of R = r\u2032, CAR allows us to write P (R = r\u2032|W = (?, ?, ?, h\u2032\u2032, ?, ?, a\u2032)) = P (R = r\u2032|H = h\u2032\u2032, A = a\u2032). But this is not the case in general. In fact, incompleteness may well be informative. For example, in the Asia network, it may be the case that the information on whether or not a person has been to Asia is not provided with the same frequency in the two groups. This is an example of incompleteness generated within a communication protocol, where giving or not some information is a key part of the communication. This somewhat selective way of reporting information, albeit very frequent, is not compatible with the CAR assumption. This was pointed out long ago by Shafer (1985), who also has outlined the implications as well as the complications for uncertain reasoning: among these, the fact that modelling IPs can be a very difficult task.", "startOffset": 89, "endOffset": 1365}, {"referenceID": 13, "context": "De Cooman and Zaffalon (2004) tried to remedy this by an approach to IPs alternative to CAR that is based on coherent lower previsions (Walley, 1991), i.", "startOffset": 3, "endOffset": 30}, {"referenceID": 13, "context": "De Cooman and Zaffalon (2004) tried to remedy this by an approach to IPs alternative to CAR that is based on coherent lower previsions (Walley, 1991), i.e., closed convex sets of probabilities also called credal sets by Levi (1980). This has led to a rule for updating beliefs under incomplete information in expert systems called the conservative updating rule (CUR).", "startOffset": 3, "endOffset": 232}, {"referenceID": 35, "context": "To this aim, we first give advanced notions about coherent lower previsions in Section 6, such as updating, independence, and coherence in the sense of Walley (1991). Then we state a number of probabilistic assumptions in Section 7.", "startOffset": 152, "endOffset": 166}, {"referenceID": 33, "context": "We refer the reader to the work of Walley (1991) for an in-depth study of coherent lower previsions, and to the paper by Miranda (2008) for a survey of the theory.", "startOffset": 35, "endOffset": 49}, {"referenceID": 23, "context": "We refer the reader to the work of Walley (1991) for an in-depth study of coherent lower previsions, and to the paper by Miranda (2008) for a survey of the theory.", "startOffset": 121, "endOffset": 136}, {"referenceID": 23, "context": "We refer to the work by Miranda and De Cooman (2005) and Walley (1991) for more general definitions of the following notions in this section in terms of partitions, and for domains that are not necessarily (these) linear sets of gambles.", "startOffset": 24, "endOffset": 53}, {"referenceID": 23, "context": "We refer to the work by Miranda and De Cooman (2005) and Walley (1991) for more general definitions of the following notions in this section in terms of partitions, and for domains that are not necessarily (these) linear sets of gambles.", "startOffset": 24, "endOffset": 71}, {"referenceID": 13, "context": "On the other hand, if there is no CAR component, and the overall IP is unknown, CIR is similar to (but more powerful than) the so-called conservative updating rule (CUR) proposed by De Cooman and Zaffalon (2004). When both components are present, CIR acts as a mix of traditional updating and CUR.", "startOffset": 185, "endOffset": 212}, {"referenceID": 41, "context": "contributions in the literature similar to CIR for the case of statistical model learning from samples made incomplete by an unknown missingness process (e.g., Manski, 2003; Ramoni & Sebastiani, 2001; Zaffalon, 2002).", "startOffset": 153, "endOffset": 216}, {"referenceID": 9, "context": "Credal networks, for example, provide such modelling capabilities (Cozman, 2000, 2005). It is easy to rephrase expert system models in the setting of this paper. Say that the expert system is based on the vector of variables (Z, \u02321, . . . , \u0232m, \u01761, . . . , \u0176n), where Z is the target variable, and the others are those subject to the unknown and the CAR IP, respectively. Then it is sufficient to write \u0232 := (\u02321, . . . , \u0232m), \u0176 := (\u01761, . . . , \u0176n), and to consider that a set M of joint mass functions for (Z, Y ), or equivalently the lower prevision P 1 made by taking its lower envelope, is given. Doing inference with an expert system, in quite a general form, corresponds then to compute R(g|w\u0304, \u0175), where w\u0304 is now the observation of the \u0232 vector and \u0175 that of the \u0176 vector. We consider some cases to make things clearer. At an extreme, which we already mentioned, there is the case m = 0, which means that there is only the CAR IP. The updating rule that follows from CIR is then the traditional updating: R(g|\u0175) = R(g|{\u0175}\u2217). Say that, to be even more specific, g is the indicator function Iz of some z \u2208 Z, and that {\u0175}\u2217 = {(\u01771, . . . , \u0177j , \u0177\u2032 j+1, . . . , \u0177\u2032 n) \u2208 \u0176 : \u0177\u2032 j+1 \u2208 \u0176j+1, . . . , \u0177\u2032 n \u2208 \u0176n)}, i.e., that the first j variables of \u0176 are observed precisely, while the others are missing. The updating rule becomes: R(g|{\u0175}\u2217) = R(Iz|\u01771, . . . , \u0177j , \u0176j+1, . . . , \u0176n) = R(Iz|\u01771, . . . , \u0177j), which is equal to infP\u2265P 1:P (\u01771,...,\u0177j)>0 P (z|\u01771, . . . , \u0177j). The latter is an updating rule implemented by credal networks; and if P 1 is a linear prevision, it is the rule used with Bayesian networks. Consider now the other extreme: n = 0, i.e., when there is only the unknown IP. Similarly to the previous case, say that g is the indicator function for z; and that {w\u0304}\u2217 = {(\u02331, . . . , \u0233i, \u0233\u2032 i+1, . . . , \u0233\u2032 m) \u2208 \u0232 : \u0233\u2032 i+1 \u2208 \u0232i+1, . . . , \u0233\u2032 m \u2208 \u0232m)}. CIR becomes then R(g|w\u0304) = min\u0233i+1\u2208\u0232i+1,...,\u0233m\u2208\u0232m infP\u2265P 1:P (\u02331,...,\u0233m)>0 P (z|\u02331, . . . , \u0233m). This case nearly coincides with the conservative updating rule proposed by De Cooman and Zaffalon (2004), with the differences already discussed in Section 4.", "startOffset": 67, "endOffset": 2071}, {"referenceID": 0, "context": "In the context of doing classification with Bayesian nets according to CUR, Antonucci and Zaffalon (2007) have proved an NP-hardness result, as well as given an exact algorithm.", "startOffset": 76, "endOffset": 106}, {"referenceID": 0, "context": "In the context of doing classification with Bayesian nets according to CUR, Antonucci and Zaffalon (2007) have proved an NP-hardness result, as well as given an exact algorithm. The algorithm is a variant of the variable elimination algorithm that has a better complexity than the traditional algorithms on Bayesian nets (implicitly using CAR): it works in linear time not only on polytree networks (i.e., those for which there is at most one path between any two nodes in the graph after dropping the orientation of the arcs) but also on a number of more general nets; on the remaining ones it takes exponential time. Moreover, in another paper, Antonucci and Zaffalon (2006) have shown that when there are missing observations the problem of CIR-updating in Bayesian nets and that of traditional (i.", "startOffset": 76, "endOffset": 677}, {"referenceID": 29, "context": "Setting s := 1 and t\u2032 := 1/2, namely, Perks\u2019 prior (see Perks, 1947), we obtain 1+st \u2032 3+s = 0.375, which can be regarded as an approximation to the true parameter value. Imprecise probability approaches to parametric inference often extend Bayesian statistical methods by working with a set of prior density functions, and by updating each of them by Bayes\u2019 rule, whenever possible, using the same likelihood function, thus obtaining a set of posteriors. An example is the imprecise Dirichlet model proposed by Walley (1996a). In our notation and terminology, this means that in the imprecise case parametric inference is based on the unconditional lower prevision P 1(\u0398, Y ), obtained by means of the prior P 1(\u0398) and the likelihood P (Y |\u0398) through a rule called marginal extension, that is updated into the posterior lower prevision R(\u0398|Y ) by a procedure called regular extension.", "startOffset": 38, "endOffset": 527}, {"referenceID": 41, "context": "This is a very intuitive procedure; therefore, it is not surprising that analogous procedures have already been advocated with missing data in the context of robust statistical inference (see, e.g., Manski, 2003; Ramoni & Sebastiani, 2001; Zaffalon, 2002).", "startOffset": 187, "endOffset": 255}, {"referenceID": 34, "context": "Walley (1991) calls maximality the related decision criterion.", "startOffset": 0, "endOffset": 14}, {"referenceID": 34, "context": "See the work of Troffaes (2007) for a comparison with other criteria.", "startOffset": 16, "endOffset": 32}, {"referenceID": 23, "context": "2) established by Miranda and De Cooman (2007).", "startOffset": 18, "endOffset": 47}, {"referenceID": 23, "context": "One can create a symmetric notion of epistemic independence (see, e.g., Walley, 1991; Miranda, 2008) by requiring that both Xj is irrelevant to Xi and Xi is irrelevant to Xj ; still, strong independence implies epistemic independence but the other way around does not hold.", "startOffset": 60, "endOffset": 100}, {"referenceID": 35, "context": "We refer to Sections 2 and 6 and, more generally, to the book by Walley (1991) for the concepts and results we shall need.", "startOffset": 65, "endOffset": 79}, {"referenceID": 22, "context": "But also on the formal level, recent research has suggested that CAR should be assumed to hold less frequently that it appears to be in practice (Gr\u00fcnwald & Halpern, 2003); and one should also remember that there is no way to test CAR statistically (Manski, 2003), so that there is always some degree of arbitrariness in assuming it.", "startOffset": 249, "endOffset": 263}, {"referenceID": 32, "context": "It is not saying anything new: the difficulty in modelling IPs has been pointed out already long ago (Shafer, 1985; Gr\u00fcnwald & Halpern, 2003).", "startOffset": 101, "endOffset": 141}, {"referenceID": 13, "context": "This has been already discussed by De Cooman and Zaffalon (2004), who proposed the regular extension as a more effective updating rule.", "startOffset": 38, "endOffset": 65}, {"referenceID": 35, "context": "These hypotheses guarantee that we can use Walley\u2019s notion of regular extension to update our beliefs and that the assessments thus obtained are coherent with our initial assessments. We should like to conclude this section commenting also a bit on some of the assumptions we have considered in the construction of our model and in some open problems that we can derive from this work. One point is the requirement that some of the spaces of possibilities be finite. This could be relaxed by taking into account that a conditional prevision defined by regular extension can be coherent with the unconditional it is derived from even in the infinite case. However, we cannot guarantee that the third point of Lemma 2 in Appendix B holds in these more general situations, and this point is necessary for the proof of Theorem 3. This is related to the notion of conglomerability discussed in much detail by Walley (1991). An open problem would be to extend our results to more general situations by addressing the question of conglomerability.", "startOffset": 43, "endOffset": 918}, {"referenceID": 35, "context": "These hypotheses guarantee that we can use Walley\u2019s notion of regular extension to update our beliefs and that the assessments thus obtained are coherent with our initial assessments. We should like to conclude this section commenting also a bit on some of the assumptions we have considered in the construction of our model and in some open problems that we can derive from this work. One point is the requirement that some of the spaces of possibilities be finite. This could be relaxed by taking into account that a conditional prevision defined by regular extension can be coherent with the unconditional it is derived from even in the infinite case. However, we cannot guarantee that the third point of Lemma 2 in Appendix B holds in these more general situations, and this point is necessary for the proof of Theorem 3. This is related to the notion of conglomerability discussed in much detail by Walley (1991). An open problem would be to extend our results to more general situations by addressing the question of conglomerability. On the other hand, as we said, our results are applicable even if the target space Z of our variable of interest, Z, is infinite. This has allowed us, for instance, to model parametric inference in the case where the parameter space is infinite, as discussed in Section 5.2. Moreover, we are not assuming that the upper probability of the values of Z is positive, and this allows us to include the case where our prior beliefs about the parameter are precise and the parameter space is infinite, which coincides with the traditional setup. Another important point is our assumption on the domains of our lower previsions: we have required for instance that P 1(Z, Y ) is defined on the set of all XZ\u222aY -measurable gambles. Similar considerations have been made for P 2(W\u0304 |\u0232 ) and P 3(\u0174 |\u0176 ). When these requirements are not met, we can still apply our results by extending our assessments using the notion of natural extension given by Walley (1991). It is easy to see that these extensions will satisfy the hypotheses of our theorems.", "startOffset": 43, "endOffset": 1992}, {"referenceID": 42, "context": "Preliminary work on the topic of this paper appeared in the proceedings of ISIPTA \u201905: the fourth International Symposium on Imprecise Probabilities and Their Applications (Zaffalon, 2005).", "startOffset": 172, "endOffset": 188}, {"referenceID": 23, "context": "From the results by Miranda and De Cooman (2007), if we let Pj(XOj |XIj ) be an extreme point ofM(P j(XOj |XIj )) for j = 1, .", "startOffset": 20, "endOffset": 49}, {"referenceID": 23, "context": "It is a consequence of the marginal extension theorem by Miranda and De Cooman (2007) that for any \u03bb \u2208 \u039b the previsions P\u03bb, P\u03bb(XO1 |XA1\u222aI1), .", "startOffset": 57, "endOffset": 86}, {"referenceID": 23, "context": "It is a consequence of the marginal extension theorem by Miranda and De Cooman (2007) that for any \u03bb \u2208 \u039b the previsions P\u03bb, P\u03bb(XO1 |XA1\u222aI1), . . . , P\u03bb(XOm |XAm\u222aIm) are coherent. Applying Theorem 8.1.6 in Walley (1991), we deduce that the lower envelopes of these families, which are the lower previsions P , P 1(XO1 |XA1\u222aI1), .", "startOffset": 57, "endOffset": 219}, {"referenceID": 35, "context": "4 in the book of Walley (1991) to deduce that the coherence of P ,R(XO|XI) is equivalent to P (Iz(f \u2212R(f |z))) = 0 for all z \u2208 XI .", "startOffset": 17, "endOffset": 31}, {"referenceID": 23, "context": "From Miranda and Zaffalon (2009, Theorem 1), P 1(XO1 |XI1), . . . , Pm(XOm |XIm) are weakly coherent if and only if there is a joint lower prevision P (X1, . . . , Xn) that is pairwise coherent with each conditional lower prevision P j(XOj |XIj ) in the collection. Similar results hold in the case where we focus on collections made of linear previsions, with the difference that the joint whose existence is equivalent to weak coherence is linear, too. However, under the behavioural interpretation, a number of weakly coherent conditional lower previsions can still present some forms of inconsistency; see Walley (1991, Example 7.3.5) for an example and Walley (1991, Chapter 7), Walley, Pelessoni, and Vicig (2004), Miranda (2009) for some discussion.", "startOffset": 5, "endOffset": 720}, {"referenceID": 23, "context": "From Miranda and Zaffalon (2009, Theorem 1), P 1(XO1 |XI1), . . . , Pm(XOm |XIm) are weakly coherent if and only if there is a joint lower prevision P (X1, . . . , Xn) that is pairwise coherent with each conditional lower prevision P j(XOj |XIj ) in the collection. Similar results hold in the case where we focus on collections made of linear previsions, with the difference that the joint whose existence is equivalent to weak coherence is linear, too. However, under the behavioural interpretation, a number of weakly coherent conditional lower previsions can still present some forms of inconsistency; see Walley (1991, Example 7.3.5) for an example and Walley (1991, Chapter 7), Walley, Pelessoni, and Vicig (2004), Miranda (2009) for some discussion.", "startOffset": 5, "endOffset": 736}, {"referenceID": 33, "context": ", k, it follows from [Appendix J3] in the book of Walley (1991) that P and Pm+j(XOm+j |XIm+j ) are coherent.", "startOffset": 50, "endOffset": 64}, {"referenceID": 23, "context": "Applying Theorem 1 by Miranda and Zaffalon (2009), we deduce that the previsions P , P 1(XO1 |XI1), .", "startOffset": 22, "endOffset": 50}, {"referenceID": 23, "context": "Applying Theorem 1 by Miranda and Zaffalon (2009), we deduce that the previsions P , P 1(XO1 |XI1), . . . , Pm+k(XOm+k |XIm+k) are weakly coherent. Hence, Theorem 7.1.5 by Walley (1991) implies that it suffices to show that P 1(XO1 |XI1), .", "startOffset": 22, "endOffset": 186}, {"referenceID": 23, "context": ", Pm(XOm |XIm) on the one hand and the conditional assessments P (\u0174 |\u0176 ), P (W\u0304 |\u0232 ) on the other hand: from the results by Miranda and De Cooman (2007), the extreme points of the set M(P (XO1 , .", "startOffset": 124, "endOffset": 153}, {"referenceID": 23, "context": "It is enough to observe that the probabilistic assessments used to build credal networks lead to an A1+ coherence graph, as detailed in Theorem 8 by Miranda and Zaffalon (2009), and that such a graph, supplemented with the parts for P (W\u0304 |\u0232 ) and P (\u0174 |\u0176 ), remains an A1+ graph.", "startOffset": 149, "endOffset": 177}], "year": 2009, "abstractText": "In this paper we formulate the problem of inference under incomplete information in very general terms. This includes modelling the process responsible for the incompleteness, which we call the incompleteness process. We allow the process\u2019 behaviour to be partly unknown. Then we use Walley\u2019s theory of coherent lower previsions, a generalisation of the Bayesian theory to imprecision, to derive the rule to update beliefs under incompleteness that logically follows from our assumptions, and that we call conservative inference rule. This rule has some remarkable properties: it is an abstract rule to update beliefs that can be applied in any situation or domain; it gives us the opportunity to be neither too optimistic nor too pessimistic about the incompleteness process, which is a necessary condition to draw reliable while strong enough conclusions; and it is a coherent rule, in the sense that it cannot lead to inconsistencies. We give examples to show how the new rule can be applied in expert systems, in parametric statistical inference, and in pattern classification, and discuss more generally the view of incompleteness processes defended here as well as some of its consequences.", "creator": "TeX"}}}