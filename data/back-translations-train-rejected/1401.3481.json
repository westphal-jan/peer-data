{"id": "1401.3481", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Bounds Arc Consistency for Weighted CSPs", "abstract": "The Weighted Constraint Satisfaction Problem (WCSP) framework allows representing and solving problems involving both hard constraints and cost functions. It has been applied to various problems, including resource allocation, bioinformatics, scheduling, etc. To solve such problems, solvers usually rely on branch-and-bound algorithms equipped with local consistency filtering, mostly soft arc consistency. However, these techniques are not well suited to solve problems with very large domains. Motivated by the resolution of an RNA gene localization problem inside large genomic sequences, and in the spirit of bounds consistency for large domains in crisp CSPs, we introduce soft bounds arc consistency, a new weighted local consistency specifically designed for WCSP with very large domains. Compared to soft arc consistency, BAC provides significantly improved time and space asymptotic complexity. In this paper, we show how the semantics of cost functions can be exploited to further improve the time complexity of BAC. We also compare both in theory and in practice the efficiency of BAC on a WCSP with bounds consistency enforced on a crisp CSP using cost variables. On two different real problems modeled as WCSP, including our RNA gene localization problem, we observe that maintaining bounds arc consistency outperforms arc consistency and also improves over bounds consistency enforced on a constraint model with cost variables.", "histories": [["v1", "Wed, 15 Jan 2014 05:34:30 GMT  (325kb)", "http://arxiv.org/abs/1401.3481v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["matthias zytnicki", "christine gaspin", "simon de givry", "thomas schiex"], "accepted": false, "id": "1401.3481"}, "pdf": {"name": "1401.3481.pdf", "metadata": {"source": "CRF", "title": "Bounds Arc Consistency for Weighted CSPs", "authors": ["Matthias Zytnicki", "Christine Gaspin", "Simon de Givry", "Thomas Schiex"], "emails": ["Matthias.Zytnicki@versailles.inra.fr", "Christine.Gaspin@toulouse.inra.fr", "Simon.DeGivry@toulouse.inra.fr", "Thomas.Schiex@toulouse.inra.fr"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them have set out in search of a solution that they themselves do not know. (...) Most of them have set out in search of a solution. (...) Most of them have set out in search of a solution. (...) Most of them have set out in search of a solution. (...) Most of them have set out in search of a solution. (...) Most of them have set out in search of a solution. (...) Most of them have set out in search of a solution. (...) Most of them have set out in search of a solution. (...) Most of them have set out in search of a solution. (...) Most of them have set out in search of a solution. (...)"}, {"heading": "2. Definitions and Notations", "text": "This section presents the most important terms used throughout the essay. We will define the (weighted) Constraint Satisfaction Problems, as well as a local consistency property commonly used to solve the Weighted Constraint Satisfaction Problem: Arc Consistency (AC *)."}, {"heading": "2.1 Constraint Networks", "text": "\"We have to get involved in the fact that it is not just a question, but also a question of whether it is a question at all, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question, whether it is a question,"}, {"heading": "2.2 Weighted Constraint Networks", "text": "Definition 2.4 A weighted constraint network (WCN) is a tuple P = < X, D, W, k >, where X = {x1,.., xn} is a set of variables, and D = {D (x1),.., D (xn)} is the set of finite domains of each variable. W is a set of cost functions. A cost function wS \u00b2 W associates a set of integer costs wS (tS).0, k] to each assignment tS of variables in S. The positive number k defines a maximum (intolerable) cost.The cost k, which can be limited or infinite, is the cost associated with prohibited assignments."}, {"heading": "A WCN is node consistent iff every variable is node consistent.", "text": "In fact, it is a way in which the cost of tackling the problem goes from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem from tackling the problem to tackling the problem."}, {"heading": "3. Bounds Arc Consistency (BAC)", "text": "It is a question of a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way and a way in which it is about a way and a way in which it is about a way and a way and a way in which it is about a way in which it is about a way and a way and a way and a way in which it is about a way and a way and a way in which it is about a way and a way and a way in which it is about a way in which it is about a way and a way and a way in which it is about a way and a way and a way in which it is about a way and a way in which it is about a way and a way and a way in which it is about a way and a way in which it is about a way and"}, {"heading": "4. Enhancing BAC", "text": "In many cases, BAC is very weak compared to AC * in situations where it seems possible to derive an appropriate w-value from it."}, {"heading": "5. Exploiting Cost Function Semantics in BAC\u2205", "text": "In crystal clear AC, several classes of binary constraints are possible to enforce AC significantly faster (in O (ed) instead of O (ed2), as Van Hentenryck et al., 1992). Similarly, it is actually possible to use the semantics of cost functions to improve the time complexity of BAC enforcement. As the evidence of Proposition 4.2 shows, the dominant factors in this complexity can be derived from the complexity of calculating the minimum cost functions during projection in lines 53 and 57 of the algorithm 3. Therefore, any cost function that makes these calculations less costly can lead to an improvement in the total time complexity. Proposition 5.1 In a binary WCN, the minimum cost functions in lines 53 and 57 of algorithm 3. Ei D (xi), Ej D (xj) may result in the minimum wij of the total time complexity in line 2."}, {"heading": "5.1 Functional Cost Functions", "text": "The concept of functional limitation can be extended to cost functions as follows: Definition 5.3 A cost function wij is functional."}, {"heading": "5.2 Anti-Functional and Semi-Convex Cost Functions", "text": "Definition 5.5 A cost function wij is anti-functional w.r.t. The variable xi-iff: \u2022 [2, vj), [3], [4], [5], [5], [5], [6], [6], [6], [6], [6], [6], [7], [7], [7], [8], [8], [8], [8], [8], [8], [8], [8], \"[8,\", \"\", \",\", \"\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\","}, {"heading": "5.3 Monotonic and Convex Cost Functions", "text": "Definition 5.9 Suppose that domain D (xi) (or D (xj)) is contained in a series of Di (or Dj), which is completely ordered in the order < i (or < j). A cost function wij is monotonous iff: - (vi, v \"i, vj, v\" j) - D 2 i \"D 2 i\" i \"i\" i \"i\" j \"vj\" wij \"(v\" i, v \"j) \u2264 wij\" (vi, vj) The cost function w \"ij\" = {0 if xi \"xj\" 1 is otherwise an example of a monotonous cost function. Monotonous cost functions are actually cases of a larger class of functions called convex functions. Definition 5.10 A function wij is convex \"iff,\" it is half convex. \"r.t. each of its variables."}, {"heading": "6. Comparison with Crisp Bounds Consistency", "text": "And I think it's important to say that I'm not going to talk about it, and I'm not going to talk about it, but I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk"}, {"heading": "7. Other Related Works", "text": "Definition 3.1 of the BAC is closely related to the definition of arc consistency introduced by Freud and Wallace. Definition of BAC can be seen as a very simplified form of WCN, in which cost functions only generate costs of 0 or 1 (if associated consistency is violated).Definition of BAC can be seen as an extension of AC consistency, which allows dealing with arbitrary cost functions, and can only be applied to domain consistency."}, {"heading": "8. Experimental Results", "text": "We experimented with arc consistency using two benchmarks translated into weighted CSPs: the first benchmark relates to the planning and planning of AI, which is a benchmark for mission management of agile satellites (Verfaillie & Lema, 2001; de Givry & Jeannin, 2006).The maximum domain size of the temporal variables is 201.This reasonable size and the fact that there are only binary cost functions allow us to compare BAC with strong local consistencies such as EDAC *.In addition, this benchmark was also modeled using the matured version of WCN, creating an experimental counterpart to the theoretical comparison of Section 6.The second benchmark comes from bioinformatics and models the problem of locating non-coding RNA molecules in genomes (The \u2012 bault et al., 2006; Zytnicki et al., 2008)."}, {"heading": "8.1 A Mission Management Benchmark for Agile Satellites", "text": "We define a simplified version described by de Givry and Jeannin (2006) of the selected photograph value, but not a problem of selecting and planning Earth observations for agile satellites. A complete description of the problem is given by Verfaillie and Lema (2001). A photograph can only be taken during a window of time depending on the location photographed. Minimum repositioning times are required between two consecutive photographs. All physical limitations (time frames and repositioning times) must be met, and the sum of the revenue from the selected photographs must be maximized, which corresponds to a minimization of the \"rejected revenue\" of the unselected photographs. We define the number of candidate photos. We define decision variables that represent the acquisition times of the candidate photos."}, {"heading": "8.2 Non-coding RNA Gene Localization", "text": "There are four types of these nucleotides, all identified by a single letter: A, U, G and C. Therefore, an RNA can be represented as a word formed by the four letters. This sequence defines what is called the primary structure of RNA molecules. RNA molecules have the ability to retreat through the development of interactions between nucleotides, and form pairs that interact most frequently with each other."}, {"heading": "9. Conclusions and Future Work", "text": "The first local consistency, BAC, has a time complexity that can be easily reduced if the semantics of the cost function are appropriate. A possible extension of this property, \u2205 -IC, was also presented. Our experiments showed that maintaining the consistency of the arc is much better than AC * for problems with large domains, such as ncRNA localization and scheduling for Earth observation satellites. This is due to the fact that AC * cannot handle problems with large domains, especially due to its high complexity of memory, but also because BAC performs particularly well with specific classes of cost functions. Similar to the consistency of boundaries implemented on almost all state-of-the-art CSP solvers, this new local property is implemented in the open source touchbar2 WCSP solution."}], "references": [{"title": "The essence of constraint propagation", "author": ["K. Apt"], "venue": "Theoretical computer science,", "citeRegEx": "Apt,? \\Q1999\\E", "shortCiteRegEx": "Apt", "year": 1999}, {"title": "Refining the basic constraint propagation algorithm", "author": ["C. Bessi\u00e8re", "R\u00e9gin", "J.-C"], "venue": "In Proc. of IJCAI\u201901,", "citeRegEx": "Bessi\u00e8re et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Bessi\u00e8re et al\\.", "year": 2001}, {"title": "Markov Random Fields: Theory and Applications", "author": ["R. Chellappa", "A. Jain"], "venue": null, "citeRegEx": "Chellappa and Jain,? \\Q1993\\E", "shortCiteRegEx": "Chellappa and Jain", "year": 1993}, {"title": "Finite domain bounds consistency revisited", "author": ["C.W. Choi", "W. Harvey", "J.H.M. Lee", "P.J. Stuckey"], "venue": "In Proc. of Australian Conference on Artificial Intelligence,", "citeRegEx": "Choi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Choi et al\\.", "year": 2006}, {"title": "Arc consistency for soft constraints", "author": ["M. Cooper", "T. Schiex"], "venue": "Artificial Intelligence,", "citeRegEx": "Cooper and Schiex,? \\Q2004\\E", "shortCiteRegEx": "Cooper and Schiex", "year": 2004}, {"title": "Virtual arc consistency for weighted CSP", "author": ["M.C. Cooper", "S. de Givry", "M. S\u00e0nchez", "T. Schiex", "M. Zytnicki"], "venue": "In Proc. of AAAI\u20192008", "citeRegEx": "Cooper et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Cooper et al\\.", "year": 2008}, {"title": "Optimal soft arc consistency", "author": ["M.C. Cooper", "S. de Givry", "T. Schiex"], "venue": "In Proc. of IJCAI\u201907,", "citeRegEx": "Cooper et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cooper et al\\.", "year": 2007}, {"title": "A unified framework for partial and hybrid search methods in constraint programming", "author": ["S. de Givry", "L. Jeannin"], "venue": "Computer & Operations Research,", "citeRegEx": "Givry and Jeannin,? \\Q2006\\E", "shortCiteRegEx": "Givry and Jeannin", "year": 2006}, {"title": "The THALES constraint programming framework for hard and soft real-time applications", "author": ["S. de Givry", "L. Jeannin", "F. Josset", "J. Mattioli", "N. Museux", "P. Sav\u00e9ant"], "venue": "The PLANET Newsletter, Issue", "citeRegEx": "Givry et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Givry et al\\.", "year": 2002}, {"title": "Partial constraint satisfaction", "author": ["E. Freuder", "R. Wallace"], "venue": "Artificial Intelligence,", "citeRegEx": "Freuder and Wallace,? \\Q1992\\E", "shortCiteRegEx": "Freuder and Wallace", "year": 1992}, {"title": "Pattern searching/alignment with RNA primary and secondary structures: an effective descriptor for tRNA", "author": ["D. Gautheret", "F. Major", "R. Cedergren"], "venue": "Comp. Appl. Biosc.,", "citeRegEx": "Gautheret et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Gautheret et al\\.", "year": 1990}, {"title": "Existential arc consistency: Getting closer to full arc consistency in weighted CSPs", "author": ["F. Heras", "J. Larrosa", "S. de Givry", "M. Zytnicki"], "venue": "In Proc. of IJCAI\u201905,", "citeRegEx": "Heras et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Heras et al\\.", "year": 2005}, {"title": "Temporal constraint reasoning with preferences", "author": ["L. Khatib", "P. Morris", "R. Morris", "F. Rossi"], "venue": "In Proc. of IJCAI\u201901,", "citeRegEx": "Khatib et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Khatib et al\\.", "year": 2001}, {"title": "Node and arc consistency in weighted CSP", "author": ["J. Larrosa"], "venue": "In Proc. of AAAI\u201902,", "citeRegEx": "Larrosa,? \\Q2002\\E", "shortCiteRegEx": "Larrosa", "year": 2002}, {"title": "Solving weighted CSP by maintaining arc-consistency", "author": ["J. Larrosa", "T. Schiex"], "venue": "Artificial Intelligence,", "citeRegEx": "Larrosa and Schiex,? \\Q2004\\E", "shortCiteRegEx": "Larrosa and Schiex", "year": 2004}, {"title": "Towards Efficient Consistency Enforcement for Global Constraints in Weighted Constraint Satisfaction", "author": ["J. Lee", "K. Leung"], "venue": "In Proc. of IJCAI\u201909", "citeRegEx": "Lee and Leung,? \\Q2009\\E", "shortCiteRegEx": "Lee and Leung", "year": 2009}, {"title": "Consistency techniques for numeric CSPs", "author": ["O. Lhomme"], "venue": "In Proc. of IJCAI\u201993,", "citeRegEx": "Lhomme,? \\Q1993\\E", "shortCiteRegEx": "Lhomme", "year": 1993}, {"title": "Meta-constraints on violations for over constrained problems", "author": ["T. Petit", "R\u00e9gin", "J.-C", "C. Bessi\u00e8re"], "venue": "In Proc. of ICTAI\u201900,", "citeRegEx": "Petit et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Petit et al\\.", "year": 2000}, {"title": "Range-based algorithm for Max-CSP", "author": ["T. Petit", "J.C. R\u00e9gin", "C. Bessi\u00e8re"], "venue": "In Proc. of CP\u201902,", "citeRegEx": "Petit et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Petit et al\\.", "year": 2002}, {"title": "A filtering algorithm for constraints of difference in CSPs", "author": ["R\u00e9gin", "J.-C"], "venue": "In Proc. of AAAI\u201994,", "citeRegEx": "R\u00e9gin and J..C.,? \\Q1994\\E", "shortCiteRegEx": "R\u00e9gin and J..C.", "year": 1994}, {"title": "Mendelian error detection in complex pedigrees using weighted constraint satisfaction", "author": ["M. S\u00e0nchez", "S. de Givry", "T. Schiex"], "venue": "techniques. Constraints,", "citeRegEx": "S\u00e0nchez et al\\.,? \\Q2008\\E", "shortCiteRegEx": "S\u00e0nchez et al\\.", "year": 2008}, {"title": "An Algorithm for Optimal Winner Determination in Combinatorial Auctions", "author": ["T. Sandholm"], "venue": "In Proc. of IJCAI\u201999,", "citeRegEx": "Sandholm,? \\Q1999\\E", "shortCiteRegEx": "Sandholm", "year": 1999}, {"title": "Arc consistency for soft constraints", "author": ["T. Schiex"], "venue": "In Proc. of CP\u201900,", "citeRegEx": "Schiex,? \\Q2000\\E", "shortCiteRegEx": "Schiex", "year": 2000}, {"title": "A lattice-theoretical fixpoint theorem and its applications", "author": ["A. Tarski"], "venue": "Pacific Journal of Mathematics,", "citeRegEx": "Tarski,? \\Q1955\\E", "shortCiteRegEx": "Tarski", "year": 1955}, {"title": "Searching RNA motifs and their intermolecular contacts with constraint", "author": ["P. Th\u00e9bault", "S. de Givry", "T. Schiex", "C. Gaspin"], "venue": "networks. Bioinformatics,", "citeRegEx": "Th\u00e9bault et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Th\u00e9bault et al\\.", "year": 2006}, {"title": "A generic arc-consistency algorithm and its specializations", "author": ["P. Van Hentenryck", "Y. Deville", "Teng", "C.-M"], "venue": "Artificial Intelligence,", "citeRegEx": "Hentenryck et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Hentenryck et al\\.", "year": 1992}, {"title": "On global warming: Flow-based soft global constraints", "author": ["W. Van Hoeve", "G. Pesant", "L. Rousseau"], "venue": "Journal of Heuristics,", "citeRegEx": "Hoeve et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hoeve et al\\.", "year": 2006}, {"title": "Selecting and scheduling observations for agile satellites: some lessons from the constraint reasoning community point of view", "author": ["G. Verfaillie", "M. Lem\u00e2\u0131tre"], "venue": "In Proc. of CP\u201901,", "citeRegEx": "Verfaillie and Lem\u00e2\u0131tre,? \\Q2001\\E", "shortCiteRegEx": "Verfaillie and Lem\u00e2\u0131tre", "year": 2001}, {"title": "On the computational complexity of 2-interval pattern matching problems", "author": ["S. Vialette"], "venue": "Theoretical Computer Science,", "citeRegEx": "Vialette,? \\Q2004\\E", "shortCiteRegEx": "Vialette", "year": 2004}, {"title": "DARN! A soft constraint solver for RNA motif", "author": ["M. Zytnicki", "C. Gaspin", "T. Schiex"], "venue": "localization. Constraints,", "citeRegEx": "Zytnicki et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zytnicki et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 21, "context": "The WCSP defines a simple optimization (minimization) framework with a wide range of applications in resource allocation, scheduling, bioinformatics (S\u00e0nchez, de Givry, & Schiex, 2008; Zytnicki, Gaspin, & Schiex, 2008), electronic markets (Sandholm, 1999), etc.", "startOffset": 239, "endOffset": 255}, {"referenceID": 22, "context": "This includes soft AC (Schiex, 2000), AC* (Larrosa, 2002), FDAC* (Larrosa & Schiex, 2004), EDAC* (Heras, Larrosa, de Givry, & Zytnicki, 2005), OSAC (Cooper, de Givry, & Schiex, 2007) and VAC (Cooper, de Givry, S\u00e0nchez, Schiex, & Zytnicki, 2008) among others.", "startOffset": 22, "endOffset": 36}, {"referenceID": 13, "context": "This includes soft AC (Schiex, 2000), AC* (Larrosa, 2002), FDAC* (Larrosa & Schiex, 2004), EDAC* (Heras, Larrosa, de Givry, & Zytnicki, 2005), OSAC (Cooper, de Givry, & Schiex, 2007) and VAC (Cooper, de Givry, S\u00e0nchez, Schiex, & Zytnicki, 2008) among others.", "startOffset": 42, "endOffset": 57}, {"referenceID": 16, "context": "Initially modeled as a crisp CSP, this problem has been tackled using bounds consistency (Choi, Harvey, Lee, & Stuckey, 2006; Lhomme, 1993) and dedicated propagators using efficient pattern matching algorithms (Th\u00e9bault, de Givry, Schiex, & Gaspin, 2006).", "startOffset": 89, "endOffset": 139}, {"referenceID": 29, "context": "To conclude, we experimentally compare the efficiency of algorithms that maintain these different local consistencies inside branch-and-bound on agile satellite scheduling problems (Verfaillie & Lem\u00e2\u0131tre, 2001) and RNA gene localization problems (Zytnicki et al., 2008) and observe clear speedups compared to different existing local consistencies.", "startOffset": 246, "endOffset": 269}, {"referenceID": 3, "context": "Using the terminology introduced by Choi et al. (2006), the bounds consistency considered in this paper is the bounds(D) consistency.", "startOffset": 36, "endOffset": 55}, {"referenceID": 21, "context": "Initially introduced by Schiex (2000), the extension of arc consistency to WCSP has been refined by Larrosa (2002) leading to the definition of AC*.", "startOffset": 24, "endOffset": 38}, {"referenceID": 13, "context": "Initially introduced by Schiex (2000), the extension of arc consistency to WCSP has been refined by Larrosa (2002) leading to the definition of AC*.", "startOffset": 100, "endOffset": 115}, {"referenceID": 13, "context": "7 (Larrosa, 2002) A variable xi is node consistent iff: \u2022 \u2200vi \u2208 D(xi), w\u2205 \u2295 wi(vi) < k.", "startOffset": 2, "endOffset": 17}, {"referenceID": 4, "context": "As shown by Cooper and Schiex (2004), the fundamental mechanism required here is the ability to move costs between different scopes.", "startOffset": 12, "endOffset": 37}, {"referenceID": 3, "context": "One can note that this definition is a proper generalization of bounds consistency since when k = 1, it is actually equivalent to the definition of bounds(D) consistency for crisp CSP (Choi et al., 2006) (also equivalent to bounds(Z) consistency since domains are defined as intervals).", "startOffset": 184, "endOffset": 203}, {"referenceID": 13, "context": "Note that exploiting the information of last supports as in AC2001 (Bessi\u00e8re & R\u00e9gin, 2001) does not reduce the worst-case time complexity because the minimum cost of a cost function must be recomputed from scratch each time a domain has been reduced and the last support has been lost (Larrosa, 2002).", "startOffset": 286, "endOffset": 301}, {"referenceID": 6, "context": "Note that although OSAC (Cooper et al., 2007) is able to find an optimal w\u2205 (at much higher", "startOffset": 24, "endOffset": 45}, {"referenceID": 23, "context": "Obviously, every function f \u2208 FBAC is order preserving: \u2200(P1,P2) \u2208 \u2118 2 1(P),P1 \u2291 P2 \u21d2 f(P1) \u2291 f(P2) By application of the Tarski-Knaster theorem (Tarski, 1955), it is known that every function f \u2208 FBAC (applied until quiescence during BAC enforcement) has at least one fixpoint, and that the set of these fixed points forms a lattice for \u2291.", "startOffset": 145, "endOffset": 159}, {"referenceID": 0, "context": "This proof technique is usual for proving convergence of the chaotic iteration of a collection of suitable functions and has been used for characterizing CSP local consistency by Apt (1999). During the enforcement of BAC, the original problem P = \u3008X ,D,W, k\u3009 is iteratively transformed into a set of different problems which are all equivalent to P, and obtained by deleting values violating BAC.", "startOffset": 179, "endOffset": 190}, {"referenceID": 4, "context": "Note that the subtraction applied to all constraint tuples at line 75 can be done in constant time without modifying the constraint by using an additional \u2206S data-structure, similar to the \u2206 data-structure introduced by Cooper and Schiex (2004). This data-structure keeps track of the cost which has been projected from wS to w\u2205.", "startOffset": 220, "endOffset": 245}, {"referenceID": 25, "context": "They can actually be directly exploited to generalize the results presented by Van Hentenryck et al. (1992) for functional, anti-functional and monotonic constraints.", "startOffset": 83, "endOffset": 108}, {"referenceID": 17, "context": "Comparison with Crisp Bounds Consistency Petit et al. (2000) have proposed to transform WCNs into crisp constraint networks with extra cost variables.", "startOffset": 41, "endOffset": 61}, {"referenceID": 16, "context": "A filtering related to BAC could be achieved in the reified approach by an extra shaving process where each variable is assigned to one of its domain bounds and this bound is deleted if an inconsistency is found after enforcing bounds consistency (Lhomme, 1993).", "startOffset": 247, "endOffset": 261}, {"referenceID": 9, "context": "1 of BAC is closely related to the notion of arc consistency counts introduced by Freuder and Wallace (1992) for Max-CSP processing.", "startOffset": 82, "endOffset": 109}, {"referenceID": 9, "context": "1 of BAC is closely related to the notion of arc consistency counts introduced by Freuder and Wallace (1992) for Max-CSP processing. The Max-CSP can be seen as a very simplified form of WCN where cost functions only generate costs of 0 or 1 (when the associated constraint is violated). Our definition of BAC can be seen as an extension of AC counts allowing dealing with arbitrary cost functions, including the usage of w\u2205 and k, and applied only to domain bounds as in bounds consistency. The addition of \u2205-IC makes BAC more powerful. Dealing with large domains in Max-CSP has also been considered in the Range-Based Algorithm, again designed for Max-CSP by Petit, R\u00e9gin, and Bessi\u00e8re (2002). This algorithm uses reversible directed arc consistency (DAC) counts and exploits the fact that in Max-CSP, several successive values in a domain may have the same DAC counts.", "startOffset": 82, "endOffset": 694}, {"referenceID": 3, "context": "Several alternative definition of bounds consistency exist in crisp CSPs (Choi et al., 2006).", "startOffset": 73, "endOffset": 92}, {"referenceID": 24, "context": "The second benchmark comes from bioinformatics and models the problem of the localization of non-coding RNA molecules in genomes (Th\u00e9bault et al., 2006; Zytnicki et al., 2008).", "startOffset": 129, "endOffset": 175}, {"referenceID": 29, "context": "The second benchmark comes from bioinformatics and models the problem of the localization of non-coding RNA molecules in genomes (Th\u00e9bault et al., 2006; Zytnicki et al., 2008).", "startOffset": 129, "endOffset": 175}, {"referenceID": 7, "context": "We solved a simplified version described by de Givry and Jeannin (2006) of a problem of selecting and scheduling earth observations for agile satellites.", "startOffset": 47, "endOffset": 72}, {"referenceID": 7, "context": "We solved a simplified version described by de Givry and Jeannin (2006) of a problem of selecting and scheduling earth observations for agile satellites. A complete description of the problem is given by Verfaillie and Lem\u00e2\u0131tre (2001). The satellite has a pool of candidate photographs to take.", "startOffset": 47, "endOffset": 235}, {"referenceID": 11, "context": "We compared BAC (denoted by BAC0 in the experimental results) with EDAC* (Heras et al., 2005) (denoted by EDAC*).", "startOffset": 73, "endOffset": 93}, {"referenceID": 7, "context": "As proposed by de Givry and Jeannin (2006), we create a binary hard constraint for every pair of photographs (resulting in a complete constraint graph) which enforces the minimal repositioning times if both photographs are selected (represented by a disjunctive constraint).", "startOffset": 18, "endOffset": 43}, {"referenceID": 7, "context": "As proposed by de Givry and Jeannin (2006), we create a binary hard constraint for every pair of photographs (resulting in a complete constraint graph) which enforces the minimal repositioning times if both photographs are selected (represented by a disjunctive constraint). For each photograph, a unary cost function associates its rejected revenue to the corresponding extra value. In order to have a better filtering, we moved costs from unary cost functions inside the binary hard constraints in a preprocessing step. This allows bounds arc consistency filtering to exploit the revenue information and the repositioning times jointly, possibly increasing w\u2205 and the starting times of some photographs. To achieve this, for each variable xi, the unary cost function wi is successively combined (using \u2295) with each binary hard constraint wij that involves xi. This yields N \u2212 1 new binary cost functions w \u2032 ij defined as w\u2032 ij(t) = wij(t) \u2295 wi(t[xi]), having both hard (+\u221e) and soft weights. These binary cost functions w\u2032 ij replace the unary cost function wi and the N \u2212 1 original binary hard constraints wij . Notice that this transformation has the side effect of multiplying all soft weights by N \u2212 1. This does preserve the equivalence with the original problem since all finite weights are just multiplied by the same constant (N \u2212 1). The search procedure is an exact depth-first branch-and-bound dedicated to scheduling problems, using a schedule or postpone strategy as described by de Givry and Jeannin (2006) which avoids the enumeration of all possible starting time values.", "startOffset": 18, "endOffset": 1525}, {"referenceID": 7, "context": "As proposed by de Givry and Jeannin (2006), we create a binary hard constraint for every pair of photographs (resulting in a complete constraint graph) which enforces the minimal repositioning times if both photographs are selected (represented by a disjunctive constraint). For each photograph, a unary cost function associates its rejected revenue to the corresponding extra value. In order to have a better filtering, we moved costs from unary cost functions inside the binary hard constraints in a preprocessing step. This allows bounds arc consistency filtering to exploit the revenue information and the repositioning times jointly, possibly increasing w\u2205 and the starting times of some photographs. To achieve this, for each variable xi, the unary cost function wi is successively combined (using \u2295) with each binary hard constraint wij that involves xi. This yields N \u2212 1 new binary cost functions w \u2032 ij defined as w\u2032 ij(t) = wij(t) \u2295 wi(t[xi]), having both hard (+\u221e) and soft weights. These binary cost functions w\u2032 ij replace the unary cost function wi and the N \u2212 1 original binary hard constraints wij . Notice that this transformation has the side effect of multiplying all soft weights by N \u2212 1. This does preserve the equivalence with the original problem since all finite weights are just multiplied by the same constant (N \u2212 1). The search procedure is an exact depth-first branch-and-bound dedicated to scheduling problems, using a schedule or postpone strategy as described by de Givry and Jeannin (2006) which avoids the enumeration of all possible starting time values. No initial upper bound was provided (k = +\u221e). We generated 100 random instances for different numbers of candidate photographs (N varying from 10 to 30)2. We compared BAC (denoted by BAC0 in the experimental results) with EDAC* (Heras et al., 2005) (denoted by EDAC*). Note that FDAC* and VAC (applied in preprocessing and during search, in addition to EDAC*) were also tested on these instances, but did not improve over EDAC* (FDAC* was slightly faster than EDAC* but developed more search nodes and VAC was significantly slower than EDAC*, without improving w\u2205 in preprocessing). OSAC is not practical on this benchmark (for N = 20, it has to solve a linear problem with 50, 000 variables and about 4 million constraints). All the algorithms are using the same search procedure. They are implemented in the toulbar2 C++ solver3. Finding the minimum cost of the previously-described binary cost functions (which are convex if we consider the extra domain values for rejected photographs separately), is done in constant time for BAC. It is done in time O(d2) for EDAC* (d = 201). We also report the results obtained by maintaining bounds consistency on the reified problem using meta-constraints as described by de Givry and Jeannin (2006), using the claire/Eclair C++ constraint programming solver (de Givry, Jeannin, Josset, Mattioli, Museux, & Sav\u00e9ant, 2002) developed by THALES (denoted by B-consistency).", "startOffset": 18, "endOffset": 2834}, {"referenceID": 28, "context": "The problem of searching for an occurrence of a gene signature in a genomic sequence is NP-complete for complex combinations of helix structures (Vialette, 2004).", "startOffset": 145, "endOffset": 161}, {"referenceID": 29, "context": "Because of the sheer domain size, and given that the complex pattern matching oriented cost functions do not have any specific property that could speedup filtering, BAC alone has been used for filtering these cost functions (Zytnicki et al., 2008).", "startOffset": 225, "endOffset": 248}, {"referenceID": 29, "context": "See the work of Zytnicki et al. (2008) for a complete description of the cost functions.", "startOffset": 16, "endOffset": 39}, {"referenceID": 13, "context": "Just to illustrate the absolute necessity of using bounds arc consistency in this problem, we compared bounds arc consistency enforcement with AC* (Larrosa, 2002) on sub-sequences of the genome of Escherichia coli, which is 4.", "startOffset": 147, "endOffset": 162}, {"referenceID": 13, "context": "Just to illustrate the absolute necessity of using bounds arc consistency in this problem, we compared bounds arc consistency enforcement with AC* (Larrosa, 2002) on sub-sequences of the genome of Escherichia coli, which is 4.9 million nucleotides long. Because of their identical space complexity and because they have not been defined nor implemented on non-binary cost functions (helix is a quaternarycost function), DAC, FDAC or EDAC have not been tested (see the work of S\u00e0nchez et al., 2008, however for an extension of FDAC to ternary cost functions). The results are displayed in Table 1. For different beginning sub-sequences of the complete sequence, we report the size of the sub-sequence in which the signature is searched for (10k is a sequence of 10,000 nucleotides), as well as the number of solutions found. We also show the number of backtracks and the time spent on a 3 GHz Intel Xeon with 2 GB. A \u201c-\u201d means the instance could not be solved due to memory reasons, and despite memory optimizations. BAC solved the complete sequence in less than 3 seconds. BAC is approximately 300, 000 (resp. 4, 400, 000) times faster than AC* for the 10k (resp. 50k) sub-sequence. More results on other genomes and ncRNA signatures can be found in the work of Zytnicki et al. (2008). The reason of the superiority of BAC over AC* is twofold.", "startOffset": 148, "endOffset": 1285}, {"referenceID": 13, "context": "This line of research has been recently explored by Lee and Leung (2009). Finally, another interesting extension of this work would be to better exploit the connection between BAC and bounds consistency by exploiting the idea of Virtual Arc Consistency introduced by Cooper et al.", "startOffset": 52, "endOffset": 73}, {"referenceID": 5, "context": "Finally, another interesting extension of this work would be to better exploit the connection between BAC and bounds consistency by exploiting the idea of Virtual Arc Consistency introduced by Cooper et al. (2008). The connection established by Virtual AC between crisp CNs and WCNs is much finer grained than in the reification approach considered by Petit et al.", "startOffset": 193, "endOffset": 214}, {"referenceID": 5, "context": "Finally, another interesting extension of this work would be to better exploit the connection between BAC and bounds consistency by exploiting the idea of Virtual Arc Consistency introduced by Cooper et al. (2008). The connection established by Virtual AC between crisp CNs and WCNs is much finer grained than in the reification approach considered by Petit et al. (2000) and could provide strong practical and theoretical results.", "startOffset": 193, "endOffset": 372}], "year": 2009, "abstractText": "The Weighted Constraint Satisfaction Problem (WCSP) framework allows representing and solving problems involving both hard constraints and cost functions. It has been applied to various problems, including resource allocation, bioinformatics, scheduling, etc. To solve such problems, solvers usually rely on branch-and-bound algorithms equipped with local consistency filtering, mostly soft arc consistency. However, these techniques are not well suited to solve problems with very large domains. Motivated by the resolution of an RNA gene localization problem inside large genomic sequences, and in the spirit of bounds consistency for large domains in crisp CSPs, we introduce soft bounds arc consistency, a new weighted local consistency specifically designed for WCSP with very large domains. Compared to soft arc consistency, BAC provides significantly improved time and space asymptotic complexity. In this paper, we show how the semantics of cost functions can be exploited to further improve the time complexity of BAC. We also compare both in theory and in practice the efficiency of BAC on a WCSP with bounds consistency enforced on a crisp CSP using cost variables. On two different real problems modeled as WCSP, including our RNA gene localization problem, we observe that maintaining bounds arc consistency outperforms arc consistency and also improves over bounds consistency enforced on a constraint model with cost variables.", "creator": "gnuplot 4.2 patchlevel 3 "}}}