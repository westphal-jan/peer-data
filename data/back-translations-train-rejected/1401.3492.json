{"id": "1401.3492", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "ParamILS: An Automatic Algorithm Configuration Framework", "abstract": "The identification of performance-optimizing parameter settings is an important part of the development and application of algorithms. We describe an automatic framework for this algorithm configuration problem. More formally, we provide methods for optimizing a target algorithm's performance on a given class of problem instances by varying a set of ordinal and/or categorical parameters. We review a family of local-search-based algorithm configuration procedures and present novel techniques for accelerating them by adaptively limiting the time spent for evaluating individual configurations. We describe the results of a comprehensive experimental evaluation of our methods, based on the configuration of prominent complete and incomplete algorithms for SAT. We also present what is, to our knowledge, the first published work on automatically configuring the CPLEX mixed integer programming solver. All the algorithms we considered had default parameter settings that were manually identified with considerable effort. Nevertheless, using our automated algorithm configuration procedures, we achieved substantial and consistent performance improvements.", "histories": [["v1", "Wed, 15 Jan 2014 05:40:11 GMT  (788kb)", "http://arxiv.org/abs/1401.3492v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["frank hutter", "thomas stuetzle", "kevin leyton-brown", "holger h hoos"], "accepted": false, "id": "1401.3492"}, "pdf": {"name": "1401.3492.pdf", "metadata": {"source": "CRF", "title": "ParamILS: An Automatic Algorithm Configuration Framework", "authors": ["Frank Hutter", "Holger H. Hoos", "Kevin Leyton-Brown"], "emails": ["HUTTER@CS.UBC.CA", "HOOS@CS.UBC.CA", "KEVINLB@CS.UBC.CA", "STUETZLE@ULB.AC.BE"], "sections": [{"heading": null, "text": "We describe an automatic framework for this problem of algorithm configuration. Formally, we offer methods to optimize the performance of a target algorithm for a specific class of problem cases by varying a set of ordinal and / or categorical parameters. We review a family of local search-based algorithm configuration procedures and present novel techniques to accelerate them by adaptive limitation of the time taken to evaluate individual configurations. We describe the results of a comprehensive experimental evaluation of our methods based on the configuration of prominent complete and incomplete algorithms for SAT. We also present what we know is the first published work on the automatic configuration of the CPLEX mixed integer programmer. All the algorithms we looked at had standard parameter settings that were identified manually with considerable effort. Nevertheless, we have achieved substantial and consistent performance improvements using our automated algorithm configuration procedures."}, {"heading": "1. Introduction", "text": "In fact, most of them are able to survive on their own, and they are able to survive on their own."}, {"heading": "2. Problem Statement and Notation", "text": "We assume that we will use the algorithm configuration in this article."}, {"heading": "3. ParamILS: Iterated Local Search in Parameter Configuration Space", "text": "In this section, we cover the first and most important of the above-mentioned dimensions of automated algorithm configuration, the search strategy, by describing an iterated local search framework called ParamILS. First, we repair the other two dimensions by using a fixed benchmark set of instances and fixed cut-off times to evaluate each parameter configuration. Thus, the stochastic optimization problem of the algorithm configuration is reduced to a simple optimization problem, namely finding the parameter configuration that yields the lowest average runtime on the given benchmark set. Then, in Section 3.3, we deal with the second question of how many runs should be performed for each configuration."}, {"heading": "3.1 The ParamILS framework", "text": "Consider the following manual parameter optimization process: 1. we start with some initial parameter configurations; 2. we experiment with changes to individual parameter values and accept new configurations if they lead to improved performance; 3. we repeat step 2 until no change to individual parameters leads to an improvement.This widely used procedure corresponds to a manual local search in the parameter configuration space. Specifically, it corresponds to an iterative initial improvement procedure with a search space consisting of all possible configurations, an objective function that quantifies the performance of the target algorithm with a given configuration, and a neighborhood relationship based on changing a single parameter value at a time (i.e. a \"one-exchange\" environment). If this manual procedure is viewed as a local search algorithm, it is advantageous because it provides the automation of the procedure as well as its improvement through the use of ideas from the stochastic local search community."}, {"heading": "3.2 The BasicILS Algorithm", "text": "To make ParamILS relatively robust with respect to these settings, we visit this issue in Section 8.4.Algorithms: Should you convert it to an executable configuration method? Should you better understand the function? Should you better use the function? Should you better use the function? Should you describe the simplest procedure we call BasicILS? Should you use the term BasicILS (N) to refer to a ParamILS algorithm that implements the function better (1, 2)? Should you just compare the simplest procedure 2? N of the cost statistics c (2) and c (2) that relate to N. 4 Our original parameter decisions < r, s, prestart > = < 10, 0.01 > (from Hutter et al., 2007) we were somewhat arbitrary, although we expected a fairly robust performance with respect to these settings."}, {"heading": "3.3 FocusedILS: Adaptively Selecting the Number of Training Instances", "text": "However, the question of how to select the number of training sessions based on the number of individual runs available is not an easy one to answer: Optimizing performance using a too small training set results in good training performance, but poor generalization to previously invisible test benchmarks. On the other hand, we clearly cannot evaluate every parameter configuration on a huge training configuration - if we would unreasonably slow down the number of runs available. (FocusedILS is a variant of the parameter configuration that addresses this problem by varying the number of training samples from one parameter configuration to another.) We evaluate the number of runs available to estimate the cost statistics. (D) for a parameter configuration of N (D) is a variant of runs with different parameter configurations. We are faced with the question of whether we are comparing two parameter configurations for which we are comparing both parameter configurations."}, {"heading": "4. Adaptive Capping of Algorithm Runs", "text": "Now we look at the last of our dimensions of automated algorithm configuration, the cutoff time for each run of the target algorithm. We are introducing an effective and simple capping technique that adaptively determines the cutoff time for each run. The motivation for this cutoff technique stems from a problem faced by all the configuration processes considered in this article: Often, the search for a performance-optimizing capping technique spends a lot of time evaluating a parameter configuration that is much worse than other previously seen configurations.Consider, for example, a case where the parameter configuration \u03b81 takes a total of 10 seconds to solve N = 100 instances (i.e., it has an average runtime of 0.1 seconds per instance), and another parameter configuration success2 takes 100 seconds to solve the first of these instances. To compare the average runtime of the two instances, we need 100 seconds based on these instances N = 100 seconds per instance (i.e., it needs an average run time of 1 from this instance, and an average time of 1 from that other instances)."}, {"heading": "4.1 Adaptive Capping in BasicILS", "text": "In this section, we present an adaptive cap for BasicILS. First, we present a path-preserving version of the adaptive cap (TP cap) that demonstrably does not change the search history of BasicILS and can lead to large computing savings. Subsequently, we modify this strategy heuristically to implement a more aggressive adaptive cap (Aggr cap) that potentially performs even better in practice."}, {"heading": "4.1.1 TRAJECTORY-PRESERVING CAPPING", "text": "Note that all comparisons between parameter configurations in ParamILS are made in pairs. In BasicILS (N), these comparisons are based on procedures betterN (\u03b81, \u03b82), where \u03b82 is either the best configuration encountered in this ILS iteration, or the best configuration of the last ILS iteration. Without adaptive capping, these comparisons can take a long time, because a poor parameter configuration \u03b8 can easily take more than an order of magnitude longer than good configurations.In the case of optimizing the mean of non-negative cost functions (such as runtime or solution costs), we implement a limited evaluation of a parameter configuration based on N runs and a given performance that is objectively bound in procedures (see procedure 4). This procedure consistently performs runs for parameter configuration and after each run a lower limit for c-N runs."}, {"heading": "4.1.2 AGGRESSIVE CAPPING", "text": "Since we show in this heuristic extension of our adaptive capping technique that we can apply trajective-preserving adaptive capping techniques to a more aggressive capping strategy that can end the evaluation of a poorly performed configuration at any point in time, we can result in significant accelerations in BasicILS. However, this approach is sometimes less efficient than it could be, because the upper limit of cumulative runtime for the capping configuration is calculated from the best configuration in the current ILS iteration (where a new ILS iteration begins after each perturbation) as if a new configuration is being led to a new configuration. In the frequent case that this new configuration is poorly executed, the capping criterion does not apply as quickly as the comparison against the overall incumbent. To counteract this effect, we are implementing a more aggressive capping strategy that can end the evaluation of a poorly performed configuration."}, {"heading": "4.2 Adaptive Capping in FocusedILS", "text": "The main difference between BasicILS and FocusedILS is that the latter adaptively varies the number of runs used to evaluate each parameter configuration, making this difference difficult but not preventing the use of adaptive capping. This is because FocusedILS always compares pairs of parameter configurations based on the same number of runs for each configuration, although this number may differ from one comparison to the next. Therefore, we can extend adaptive capping to FocusedILS by using separate limits for each number of runs. Remember that FocusedILS never moves from one configuration to an adjacent configuration without performing at least as many runs as Forward for Forward. Since we track the performance of Forward with any number of runs M \u2264 N (Forward), a limit on the rating of Forward \u2032 is always available without performing at least as many runs for Forward \u2032 as for Forward."}, {"heading": "5. Experimental Preliminaries", "text": "In this section, we provide background information on the computer experiments presented in the following sections. First, we describe the design of our experiments. Next, we present the configuration scenarios (algorithm / benchmark data combinations) that are examined in the following section. Finally, we describe the details of our low-level experimental setup."}, {"heading": "5.1 Experimental Design", "text": "Here we describe our objective function and the methods we have used in selecting instances and seeds."}, {"heading": "5.1.1 CONFIGURATION OBJECTIVE: PENALIZED AVERAGE RUNTIME", "text": "In Section 2, we mentioned that problems arise with the configuration of algorithms in connection with various different cost statistics. In fact, in our previous work, we examined several of them: maximizing the solution quality achieved in a certain time, minimizing the runtime required to achieve a certain solution quality, and minimizing the runtime required to solve a single problem instance (Hutter et al., 2007).In this work, we focus on the goal of achieving the mean runtime across instances from a distribution D. This optimization goal naturally occurs in many practical applications. It also implies a strong correlation between c (\u03b8) and the time required to obtain a good empirical estimate of c (\u03b8).This correlation helps to effectively make our adaptive coverage schema. One might wonder whether means are the right way to aggregate runtimes. In some preliminary experiments, we found that minimizing the mean runtime we have to perform relatively less congruent parameters including large runtime configurations."}, {"heading": "5.1.2 SELECTING INSTANCES AND SEEDS", "text": "As already mentioned, there is often only a limited number of cases where our algorithm can be evaluated. This is the case in the experiments we report here. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < &"}, {"heading": "5.1.3 COMPARISON OF CONFIGURATION PROCEDURES", "text": "Since the selection of instances (and to some extent of seeds) is very important for the final result of the optimization, we always performed a number of independent runs of each configuration method (typically 25) in our experimental evaluations. We created a separate list of instances and seeds for each run, with the kindest run of each configuration method using the same kest list of instances and seeds. (Note, however, that the disjoint test set for measuring the performance of parameter configurations was identical for all runs.) We performed a paired statistical test to compare the final results obtained in the runs of two configuration methods. A paired test was required, as the kest run of both methods contained the same kest list of instances and seeds. In particular, we performed a two-sided Max Wilcoxon test with the zero hypothesis that there was no difference in performance as p values below 0.05 were statistically significant."}, {"heading": "5.2 Configuration Scenarios", "text": "In Section 6, we analyze our configurators based on five configuration scenarios, each combining a high-performance algorithm with a widely studied benchmark dataset. Table 1 provides an overview of these scenarios, which we call BROAD scenarios. The algorithms and benchmark instance sets used in these scenarios are described in detail in Section 5.2.1 and 5.2.2, respectively. In these five BROAD configuration scenarios, we have set relatively aggressive cut-off times of five seconds per run of the target algorithm and allowed each configuration procedure to execute the target algorithm for an aggregate runtime of five CPU hours. These short cut-off times and relatively short times for the algorithm configuration were deliberately chosen to allow many configuration runs for each BROAD scenario. In contrast, in a second group of configuration scenarios (focused solely on CPLEX), we have shifted much longer cut-off times to and more configuration times for this 7."}, {"heading": "5.2.1 TARGET ALGORITHMS", "text": "In fact, most of them are able to play by the rules that they have imposed on themselves, and they are able to play by the rules that they have imposed on themselves, \"he told the Deutsche Presse-Agentur.\" We have to play by the rules, \"he said,\" we have to play by the rules. \""}, {"heading": "5.2.2 BENCHMARK INSTANCES", "text": "We applied our target algorithms to three sets of benchmark instances: SAT-encoded quasi-group completion problems, SAT-encoded graph coloring problems based on small world diagrams, and MIP-encoded winner determination problems based on combinatorial auctions. Each set consisted of 2,000 instances evenly divided into training and test sectors. QCP Our first benchmark set contained 23,000 instances of the quasi-group completion problem (QCP), which was extensively investigated by AI researchers. We created these QCP instances around the solvability phase transition using the parameters given by Gomes and Selman (1997). Specifically, the sequence n was consistently pulled from the interval [26, 43] and the number of holes H (open entries in the Latin square) was uniformly determined."}, {"heading": "5.3 Experimental Setup", "text": "We conducted all our experiments on a cluster of 55 dual 3.2 GHz Intel Xeon PCs with 2MB cache and 2GB RAM under OpenSuSE Linux 10.1. We measured runtime as CPU time on these reference computers. All of our configuration procedures were implemented as Ruby scripts, and we do not factor the runtime of these scripts into the configuration time. In \"simple\" configuration scenarios, where most algorithm runs are completed in milliseconds, the overhead of our scripts can be significant. In fact, the longest configuration run we observed took 24 hours to execute a target algorithm runtime of five hours. In contrast, we observed virtually no overhead in the harsher CPLEX scenarios described in Section 7."}, {"heading": "6. Empirical Evaluation of BasicILS, FocusedILS and Adaptive Capping", "text": "In this section, we use our BROAD scenarios to empirically examine the performance of BasicILS (N) and FocusedILS, as well as the effects of adaptive cap. We first demonstrate the large accelerations that ParamILS achieves over the standard parameters, and then examine the components responsible for this success."}, {"heading": "6.1 Empirical Comparison of Default and Optimized Parameter Configurations", "text": "In this section, for each of our five BROAD configuration scenarios, we compare the performance of the respective algorithm with the final configurations found by BasicILS (100) and FocusedILS. Table 3, and in particular Figure 2, show that the configurators have led to very considerable speeds. In Table 3, we report on the final performance achieved through 25 independent runs of each configurator. For each independent configuration that was performed, we used a different set of training instances and seeds (constructed as described in Section 5.1.2). We note that there was often a fairly large discrepancy in the performances found in different runs of the configurators, and that the configuration with the best training performance tended to achieve a better test performance than the others during the run. Therefore, we used this configuration as a result of the algorithm configuration, with five runs running at the same time. (Note that the selection of the configuration is found to be perfect in the run with the training performance."}, {"heading": "6.2 Empirical Comparison of BasicILS and Simple Baselines", "text": "In this section, we evaluate the effectiveness of BasicILS (N) against two of its components: \u2022 a simple random search used in BasicILS for initialization (we dub it RandomSearch (N) and provide pseudo code for it in Algorithm 5); and \u2022 a simple local search, the same kind of iterative initial improvement in BasicILS (N) (we dub it SimpleLS (N)). To evaluate a component, in this section and in Section 6.3, we examine our algorithms without adaptive coverage. We then examine the effects of our adaptive coverage methods in Section 6.4.If there is a sufficient structure in the search space, we expect BasicILS RandomSearch to be better than local minima, we expect BasicILS to perform better than simple search."}, {"heading": "6.3 Empirical Comparison of FocusedILS and BasicILS", "text": "In this area, we are researching the performance of the system."}, {"heading": "6.4 Empirical Evaluation of Adaptive Capping in BasicILS and FocusedILS", "text": "In fact, most of them are able to survive on their own without having to move to another world."}, {"heading": "7. Case Study: Configuring CPLEX for Real-World Benchmarks", "text": "In this year we have it in the hand in which we are, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand, in the hand,"}, {"heading": "8. Review of Other ParamILS Applications", "text": "In this section we will look at a number of other applications of ParamILS - some from earlier stages of its development, others more recently - demonstrating its usefulness and versatility. 8.1 The configuration of SAPS, GLS + and SAT4JHutter et al. (2007), in the first publication on ParamILS, reported experiments with three target algorithms to demonstrate the effectiveness of the approach: the SAT algorithm SAPS (which has 4 numerical parameters), the local search algorithm GLS + to solve the most likely explanation problem (MPE) in Bayesian networks (which has 5 numerical parameters; Hutter, Hoos & Stu \ufffd tzle, 2005), and the tree search program SAT4J (which has 4 categorical and 7 numerical parameters; http: / / www.sat4j.org). They compared the performance of the respective algorithm, the performance of the CALIBRA system SILA-BRSILA-SILA-SILA-SILA-S4-SILA-S4-S4-S4-SILA-4-S4-S4-SILS-4-4-S4-S4-4-4-SILS-4-4-4-4-SILA-4-SILS-4-4-4-4-SILS-4-4-SILS-4)."}, {"heading": "8.2 Configuration of Spear for Industrial Verification Problems", "text": "Hutter et al. (2007) applied ParamILS to a specific \"real\" application domain to optimize performance: the configuration of the 26 parameters of the DPLL solver SPEAR to minimize its mean runtime on a number of practical verification instances. Specifically, they looked at two sets of industrial problem cases, Limited Model Check (BMC) instances from Zarpas (2005) and Software Check (SWV) instances generated by the static checker CALYSTO (Babic \u0301 & Hu, 2007).The instances from both problem distributions showed a large variation in hardness for SPEAR. For the SWV instances, many instances were solved in milliseconds, but others were not solved in days, despite the fact that SPEAR was designed specifically for this type of instance, that its developer had generated the problem himself (and therefore had intimate domain knowledge)."}, {"heading": "8.3 Configuration of SATenstein", "text": "KhudaBukhsh, Xu, Hoos and Leyton-Brown (2009) used ParamILS to perform automatic algorithm design in the context of stochastic local search algorithms for SAT. Specifically, they introduced a new framework for local SAT solvers called SATenstein and used ParamILS to select good instances of the framework for given instance distributions. SATenstein combines three broad categories of SLS-based SAT solvers: WalkSAT-based algorithms, dynamic local search algorithms and G2WSAT variants, all of which are combined in a highly parameterized framework solver with a total of 41 parameters and 4.82 \u00b7 1012 unique instances. FocusedILS was used to configure SATenstein on six different problem distributions, and the resulting solvers were compared with eleven state-of-the-art LS-based SAT solvers."}, {"heading": "8.4 Self-Configuration of ParamILS", "text": "As a heuristic optimization process, ParamILS itself is controlled by a number of parameters: the number of random configurations that r must be scanned at the beginning of the search; the level of interference, s; and the likelihood of a random restart, prestart. In addition, our aggressive coverage mechanism uses an additional parameter: the bound multiplier, bm. Throughout this article, we have used the manually set default values < r, s, prestart, bm > = < 10, 3, 0.01, 2 >.7. See http: / / www.cril.univ-artois.fr / SAT07. SPEAR was not allowed to participate in the second round of this contest because its source code is not publicly available. In the most recent work (see Section 8.2 of Hutter, 2009), we have enabled the configurator as crucial."}, {"heading": "8.5 Other Applications of ParamILS", "text": "Thachuk, Shmygelska and Hoos (2007) used BasicILS to determine performance-optimizing parameter settings for a new Monte Carlo protein folding algorithm in the 2DHP and 3D-HP models.8 Although their algorithm has only four parameters (two categorical and two continuous), BasicILS achieved significant performance improvements. While the manually selected configurations tended to favor either short or long protein sequences, BasicILS found a configuration that consistently provided good average runtimes for all types of sequences. On average, the acceleration factor achieved was about 1.5, and for certain classes of protein sequences up to 3. While all manually selected configurations performed worse than the previous state-of-the-art algorithm for this problem in some cases, the robust parameter configurations selected by BasicILS resulted in consistently better performance."}, {"heading": "9. Related Work", "text": "Many researchers before us were dissatisfied with the manual configuration of algorithms, and various departments have developed their own approaches to automatic parameter setting. We begin this section with the most closely related work - approaches that use direct search to find good parameter configurations - and then describe other methods. Finally, we discuss work on related issues, such as finding the best parameter configuration or algorithm per instance, and approaches that adjust their parameters during the execution of an algorithm (see also Hoos, 2008, for more related work on automated algorithm design).8 BasicILS was used because FocusedILS was not yet developed at the time this study was carried out."}, {"heading": "9.1 Direct Search Methods for Algorithm Configuration", "text": "Approaches to automated algorithm configuration date back to the early 1990s, when a number of adaptive problem solving systems were developed, one of which is \"Composer\" (Gratch & Dejong, 1992), which successfully applied the five parameters of an algorithm for communication between a collection of ground-based antennas and spaceships (Gratch & Chien, 1996), each of which has a better configuration than the current configuration. MULTITAC takes as input generic heuristics, a specific problem domain and a distribution of problem situations, and adapts the generic heuristics to the problems of the domain and implements them."}, {"heading": "9.2 Other Methods for Algorithm Configuration", "text": "In fact, it is as if most of them will be able to abide by the rules that they have imposed on themselves, and that they will be able to abide by the rules that they have imposed on themselves. (...) In fact, it is as if they are able to break the rules. (...) In fact, it is as if they are able to determine themselves how they want to behave. (...) It is as if they are able to determine themselves. (...) It is as if they are able to determine themselves. (...) (...). (...) It is as if they are able to determine themselves. (...) It is as if they are able to determine themselves. (...) It is as if they are able to determine themselves. (...)"}, {"heading": "9.3 Related Algorithm Configuration Problems", "text": "Similar approaches attempt to find the best configuration or algorithm per instance, or adjust the parameters of the algorithm during the execution of an algorithm. Approaches to setting the parameters per instance have been described by Patterson and Kautz (2001), Cavazos and O'Boyle (2006) and Hutter et al. (2006). Furthermore, approaches that attempt to select the best algorithm per instance have been investigated by Leyton-Brown, Nudelman and Shoham (2002), Carchrae and Beck (2005), Gebruers, Hnich, Bridge and Freuder (2005), Gagliolo and Schmidhuber (2006), as well as Xu, Hoos and Leyton-Brown (2008), Carchrae & Beck (2005), Bridge and Freuder (2005)."}, {"heading": "9.4 Relation to Other Local Search Methods", "text": "Since ParamILS performs an iterated local search with one-sided neighbourhood, it is very similar in spirit to the local search methods for other problems such as SAT (Selman, Levesque & Mitchell, 1992; Hoos & Stuetzle, 2005), CSP (Minton, Johnston, Philips & Laird, 1992) and MPE (Kask & Dechter, 1999; Hutter et al., 2005).Since ParamILS is a local search method, existing theoretical frameworks (see e.g. Hoos, 2002; Mengshoel, 2008) could be used in principle for their analysis."}, {"heading": "10. Discussion, Conclusions and Future work", "text": "This year it is more than ever before."}, {"heading": "Acknowledgments", "text": "We thank Kevin Murphy for many helpful discussions regarding this work. We also thank Domagoj Babic, the author of SPEAR, and Dave Tompkins, the author of the implementation of UBCSAT SAPS, which we used in our experiments. We thank the researchers who provided the instance generators used in our work, in particular Gent et al. (1999), Gomes and Selman (1997), LeytonBrown et al. (2000), Babic and Hu (2007), Zarpas (2005), Le Berre and Simon (2004), Aktu \ufffd rk et al. (2007), Atamtu \ufffd rk and Mun \ufffd oz (2004), Atamtu \ufffd rk (2003) and Andronescu et al. (2007)."}], "references": [{"title": "Fine-tuning of algorithms using fractional experimental design and local search", "author": ["B. Adenso-Diaz", "M. Laguna"], "venue": "Operations Research,", "citeRegEx": "Adenso.Diaz and Laguna,? \\Q2006\\E", "shortCiteRegEx": "Adenso.Diaz and Laguna", "year": 2006}, {"title": "A strong conic quadratic reformulation for machine-job assignment with controllable processing times. Research Report BCOL.07.01, University of CaliforniaBerkeley", "author": ["S.M. Akt\u00fcrk", "A. Atamt\u00fcrk", "S. G\u00fcrel"], "venue": null, "citeRegEx": "Akt\u00fcrk et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Akt\u00fcrk et al\\.", "year": 2007}, {"title": "Efficient parameter estimation for RNA secondary structure", "author": ["M. Andronescu", "A. Condon", "H.H. Hoos", "D.H. Mathews", "K.P. Murphy"], "venue": "prediction. Bioinformatics,", "citeRegEx": "Andronescu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Andronescu et al\\.", "year": 2007}, {"title": "On the facets of the mixed\u2013integer knapsack polyhedron", "author": ["A. Atamt\u00fcrk"], "venue": "Mathematical Programming,", "citeRegEx": "Atamt\u00fcrk,? \\Q2003\\E", "shortCiteRegEx": "Atamt\u00fcrk", "year": 2003}, {"title": "A study of the lot-sizing polytope", "author": ["A. Atamt\u00fcrk", "J.C. Mu\u00f1oz"], "venue": "Mathematical Programming,", "citeRegEx": "Atamt\u00fcrk and Mu\u00f1oz,? \\Q2004\\E", "shortCiteRegEx": "Atamt\u00fcrk and Mu\u00f1oz", "year": 2004}, {"title": "Finding optimal algorithmic parameters using the mesh adaptive direct search algorithm", "author": ["C. Audet", "D. Orban"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Audet and Orban,? \\Q2006\\E", "shortCiteRegEx": "Audet and Orban", "year": 2006}, {"title": "Structural Abstraction of Software Verification Conditions", "author": ["D. Babi\u0107", "A.J. Hu"], "venue": "Computer Aided Verification: 19th International Conference, CAV 2007,", "citeRegEx": "Babi\u0107 and Hu,? \\Q2007\\E", "shortCiteRegEx": "Babi\u0107 and Hu", "year": 2007}, {"title": "Improvement strategies for the F-Race algorithm: Sampling design and iterative refinement", "author": ["P. Balaprakash", "M. Birattari", "T. St\u00fctzle"], "venue": "4th International Workshop on Hybrid Metaheuristics (MH\u201907),", "citeRegEx": "Balaprakash et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Balaprakash et al\\.", "year": 2007}, {"title": "Experimental Research in Evolutionary Computation: The New Experimentalism", "author": ["T. Bartz-Beielstein"], "venue": "Natural Computing Series", "citeRegEx": "Bartz.Beielstein,? \\Q2006\\E", "shortCiteRegEx": "Bartz.Beielstein", "year": 2006}, {"title": "Reactive Search and Intelligent Optimization, volume 45 of Operations research/Computer Science Interfaces", "author": ["R. Battiti", "M. Brunato", "F. Mascia"], "venue": null, "citeRegEx": "Battiti et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Battiti et al\\.", "year": 2008}, {"title": "The Problem of Tuning Metaheuristics as Seen from a Machine Learning Perspective", "author": ["M. Birattari"], "venue": "PhD thesis, Universite\u0301 Libre de Bruxelles,", "citeRegEx": "Birattari,? \\Q2004\\E", "shortCiteRegEx": "Birattari", "year": 2004}, {"title": "A racing algorithm for configuring metaheuristics", "author": ["M. Birattari", "T. St\u00fctzle", "L. Paquete", "K. Varrentrapp"], "venue": "Proceedings of the Genetic and Evolutionary Computation Conference (GECCO2002),", "citeRegEx": "Birattari et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Birattari et al\\.", "year": 2002}, {"title": "Applying machine learning to low-knowledge control of optimization algorithms", "author": ["T. Carchrae", "J.C. Beck"], "venue": "Computational Intelligence,", "citeRegEx": "Carchrae and Beck,? \\Q2005\\E", "shortCiteRegEx": "Carchrae and Beck", "year": 2005}, {"title": "Method-specific dynamic compilation using logistic regression", "author": ["J. Cavazos", "M.F.P. O\u2019Boyle"], "venue": "Proceedings of the ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications", "citeRegEx": "Cavazos and O.Boyle,? \\Q2006\\E", "shortCiteRegEx": "Cavazos and O.Boyle", "year": 2006}, {"title": "Using experimental design to find effective parameter settings for heuristics", "author": ["S.P. Coy", "B.L. Golden", "G.C. Runger", "E.A. Wasil"], "venue": "Journal of Heuristics,", "citeRegEx": "Coy et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Coy et al\\.", "year": 2001}, {"title": "Generic online optimization of multiple configuration parameters with application to a database server", "author": ["Y. Diao", "F. Eskesen", "S. Froehlich", "J.L. Hellerstein", "L. Spainhower", "M. Surendra"], "venue": "14th IFIP/IEEE International Workshop on Distributed Systems: Operations and Management (DSOM-03),", "citeRegEx": "Diao et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Diao et al\\.", "year": 2003}, {"title": "An automatically configured modular algorithm for post enrollment course timetabling", "author": ["C. Fawcett", "H.H. Hoos", "M. Chiarandini"], "venue": "Technical Report TR-2009-15,", "citeRegEx": "Fawcett et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Fawcett et al\\.", "year": 2009}, {"title": "Dynamic algorithm portfolios", "author": ["M. Gagliolo", "J. Schmidhuber"], "venue": "Ninth International Symposium on Artificial Intelligence and Mathematics (AI-MATH-06)", "citeRegEx": "Gagliolo and Schmidhuber,? \\Q2006\\E", "shortCiteRegEx": "Gagliolo and Schmidhuber", "year": 2006}, {"title": "Learning restart strategies", "author": ["M. Gagliolo", "J. Schmidhuber"], "venue": "Proceedings of the Twentieth International Joint Conference on Artificial Intelligence (IJCAI\u201907),", "citeRegEx": "Gagliolo and Schmidhuber,? \\Q2007\\E", "shortCiteRegEx": "Gagliolo and Schmidhuber", "year": 2007}, {"title": "Using CBR to select solution strategies in constraint programming", "author": ["C. Gebruers", "B. Hnich", "D. Bridge", "E. Freuder"], "venue": "Proceedings of the 6th International Conference on Case Based Reasoning (ICCBR\u201905),", "citeRegEx": "Gebruers et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Gebruers et al\\.", "year": 2005}, {"title": "Morphing: Combining structure and randomness", "author": ["I.P. Gent", "H.H. Hoos", "P. Prosser", "T. Walsh"], "venue": "Proceedings of the Sixteenth National Conference on Artificial Intelligence (AAAI\u201999), (pp. 654\u2013660).,", "citeRegEx": "Gent et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Gent et al\\.", "year": 1999}, {"title": "Problem structure in the presence of perturbations", "author": ["C.P. Gomes", "B. Selman"], "venue": "Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI\u201997),", "citeRegEx": "Gomes and Selman,? \\Q1997\\E", "shortCiteRegEx": "Gomes and Selman", "year": 1997}, {"title": "Adaptive problem-solving for large-scale scheduling problems: A case study", "author": ["J. Gratch", "S.A. Chien"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Gratch and Chien,? \\Q1996\\E", "shortCiteRegEx": "Gratch and Chien", "year": 1996}, {"title": "Composer: A probabilistic solution to the utility problem in speed-up learning", "author": ["J. Gratch", "G. Dejong"], "venue": "Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI\u201992),", "citeRegEx": "Gratch and Dejong,? \\Q1992\\E", "shortCiteRegEx": "Gratch and Dejong", "year": 1992}, {"title": "A mixture-model for the behaviour of SLS algorithms for SAT", "author": ["H.H. Hoos"], "venue": "In Proceedings of the Eighteenth National Conference on Artificial Intelligence", "citeRegEx": "Hoos,? \\Q2002\\E", "shortCiteRegEx": "Hoos", "year": 2002}, {"title": "Computer-aided design of high-performance algorithms", "author": ["H.H. Hoos"], "venue": "Technical Report TR-2008-16,", "citeRegEx": "Hoos,? \\Q2008\\E", "shortCiteRegEx": "Hoos", "year": 2008}, {"title": "Stochastic Local Search \u2013 Foundations & Applications", "author": ["H.H. Hoos", "T. St\u00fctzle"], "venue": null, "citeRegEx": "Hoos and St\u00fctzle,? \\Q2005\\E", "shortCiteRegEx": "Hoos and St\u00fctzle", "year": 2005}, {"title": "A Bayesian approach to tackling hard computational problems", "author": ["E. Horvitz", "Y. Ruan", "C.P. Gomes", "H. Kautz", "B. Selman", "D.M. Chickering"], "venue": "Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Horvitz et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Horvitz et al\\.", "year": 2001}, {"title": "Automated Configuration of Algorithms for Solving Hard Computational Problems", "author": ["F. Hutter"], "venue": "PhD thesis,", "citeRegEx": "Hutter,? \\Q2009\\E", "shortCiteRegEx": "Hutter", "year": 2009}, {"title": "Boosting Verification by Automatic Tuning of Decision Procedures", "author": ["F. Hutter", "D. Babi\u0107", "H.H. Hoos", "A.J. Hu"], "venue": "In Proceedings of Formal Methods in Computer Aided Design (FMCAD\u201907),", "citeRegEx": "Hutter et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2007}, {"title": "Performance prediction and automated tuning of randomized and parametric algorithms", "author": ["F. Hutter", "Y. Hamadi", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Principles and Practice of Constraint Programming \u2013 CP 2006: Twelfth International Conference,", "citeRegEx": "Hutter et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2006}, {"title": "Tradeoffs in the empirical evaluation of competing algorithm designs", "author": ["F. Hutter", "H. Hoos", "K. Leyton-Brown"], "venue": "Technical Report TR-2009-21,", "citeRegEx": "Hutter et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2009}, {"title": "An experimental investigation of model-based parameter optimisation: SPO and beyond", "author": ["F. Hutter", "H.H. Hoos", "K. Leyton-Brown", "K.P. Murphy"], "venue": "In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2009),", "citeRegEx": "Hutter et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2009}, {"title": "Efficient stochastic local search for MPE solving", "author": ["F. Hutter", "H.H. Hoos", "T. St\u00fctzle"], "venue": "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI\u201905),", "citeRegEx": "Hutter et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2005}, {"title": "Automatic algorithm configuration based on local search", "author": ["F. Hutter", "H.H. Hoos", "T. St\u00fctzle"], "venue": "Proceedings of the Twenty-second National Conference on Artificial Intelligence (AAAI\u201907),", "citeRegEx": "Hutter et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2007}, {"title": "Scaling and probabilistic smoothing: Efficient dynamic local search for SAT", "author": ["F. Hutter", "D.A.D. Tompkins", "H.H. Hoos"], "venue": "Principles and Practice of Constraint Programming \u2013 CP 2002: Eighth International Conference,", "citeRegEx": "Hutter et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2002}, {"title": "A theoretician\u2019s guide to the experimental analysis of algorithms", "author": ["D.S. Johnson"], "venue": null, "citeRegEx": "Johnson,? \\Q2002\\E", "shortCiteRegEx": "Johnson", "year": 2002}, {"title": "Efficient global optimization of expensive black box functions", "author": ["D.R. Jones", "M. Schonlau", "W.J. Welch"], "venue": "Journal of Global Optimization,", "citeRegEx": "Jones et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Jones et al\\.", "year": 1998}, {"title": "Stochastic local search for Bayesian networks", "author": ["K. Kask", "R. Dechter"], "venue": "In The Seventh International Workshop on Artificial Intelligence and Statistics (AISTATS\u201999)", "citeRegEx": "Kask and Dechter,? \\Q1999\\E", "shortCiteRegEx": "Kask and Dechter", "year": 1999}, {"title": "Dynamic restart policies", "author": ["H. Kautz", "E. Horvitz", "Y. Ruan", "C.P. Gomes", "B. Selman"], "venue": "Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI\u201902),", "citeRegEx": "Kautz et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kautz et al\\.", "year": 2002}, {"title": "SATenstein: Automatically building local search sat solvers from components", "author": ["A. KhudaBukhsh", "L. Xu", "H.H. Hoos", "K. Leyton-Brown"], "venue": "In Proceedings of the Twenty-first International Joint Conference on Artificial Intelligence (IJCAI\u201909),", "citeRegEx": "KhudaBukhsh et al\\.,? \\Q2009\\E", "shortCiteRegEx": "KhudaBukhsh et al\\.", "year": 2009}, {"title": "Fifty-five solvers in Vancouver: The SAT 2004 competition", "author": ["D. Le Berre", "L. Simon"], "venue": "Theory and Applications of Satisfiability Testing: Proceedings of the Seventh International Conference (SAT\u201904),", "citeRegEx": "Berre and Simon,? \\Q2004\\E", "shortCiteRegEx": "Berre and Simon", "year": 2004}, {"title": "Learning the empirical hardness of optimization problems: The case of combinatorial auctions", "author": ["K. Leyton-Brown", "E. Nudelman", "Y. Shoham"], "venue": "Principles and Practice of Constraint Programming \u2013 CP 2002: Eighth International Conference,", "citeRegEx": "Leyton.Brown et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Leyton.Brown et al\\.", "year": 2002}, {"title": "Towards a universal test suite for combinatorial auction algorithms", "author": ["K. Leyton-Brown", "M. Pearson", "Y. Shoham"], "venue": null, "citeRegEx": "Leyton.Brown et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Leyton.Brown et al\\.", "year": 2000}, {"title": "Iterated local search", "author": ["H.R. Louren\u00e7o", "O. Martin", "T. St\u00fctzle"], "venue": "Handbook of Metaheuristics (pp", "citeRegEx": "Louren\u00e7o et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Louren\u00e7o et al\\.", "year": 2002}, {"title": "Hoeffding races: Accelerating model selection search for classification and function approximation", "author": ["O. Maron", "A. Moore"], "venue": "Advances in Neural Information Processing Systems 7 (NIPS-94),", "citeRegEx": "Maron and Moore,? \\Q1994\\E", "shortCiteRegEx": "Maron and Moore", "year": 1994}, {"title": "Understanding the role of noise in stochastic local search: Analysis and experiments", "author": ["O.J. Mengshoel"], "venue": "Artificial Intelligence,", "citeRegEx": "Mengshoel,? \\Q2008\\E", "shortCiteRegEx": "Mengshoel", "year": 2008}, {"title": "An analytic learning system for specializing heuristics", "author": ["S. Minton"], "venue": "Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI\u201993),", "citeRegEx": "Minton,? \\Q1993\\E", "shortCiteRegEx": "Minton", "year": 1993}, {"title": "Automatically configuring constraint satisfaction programs: A case", "author": ["S. Minton"], "venue": "study. Constraints,", "citeRegEx": "Minton,? \\Q1996\\E", "shortCiteRegEx": "Minton", "year": 1996}, {"title": "Minimizing conflicts: A heuristic repair method for constraint-satisfaction and scheduling problems", "author": ["S. Minton", "M.D. Johnston", "A.B. Philips", "P. Laird"], "venue": "Artificial Intelligence,", "citeRegEx": "Minton et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Minton et al\\.", "year": 1992}, {"title": "Auto-WalkSAT: a self-tuning implementation of WalkSAT", "author": ["D.J. Patterson", "H. Kautz"], "venue": "In Electronic Notes in Discrete Mathematics (ENDM),", "citeRegEx": "Patterson and Kautz,? \\Q2001\\E", "shortCiteRegEx": "Patterson and Kautz", "year": 2001}, {"title": "Sequential experiment designs for screening and tuning parameters of stochastic heuristics", "author": ["E. Ridge", "D. Kudenko"], "venue": "Workshop on Empirical Methods for the Analysis of Algorithms at the Ninth International Conference on Parallel Problem Solving from Nature (PPSN),", "citeRegEx": "Ridge and Kudenko,? \\Q2006\\E", "shortCiteRegEx": "Ridge and Kudenko", "year": 2006}, {"title": "The Design and Analysis of Computer Experiments", "author": ["T.J. Santner", "B.J. Williams", "W.I. Notz"], "venue": null, "citeRegEx": "Santner et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Santner et al\\.", "year": 2003}, {"title": "A new method for solving hard satisfiability problems", "author": ["B. Selman", "H.J. Levesque", "D. Mitchell"], "venue": "Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI\u201992),", "citeRegEx": "Selman et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Selman et al\\.", "year": 1992}, {"title": "Introduction to Stochastic Search and Optimization", "author": ["J.C. Spall"], "venue": null, "citeRegEx": "Spall,? \\Q2003\\E", "shortCiteRegEx": "Spall", "year": 2003}, {"title": "Evolution of constraint satisfaction strategies in examination timetabling", "author": ["H. Terashima-Mar\u0131\u0301n", "P. Ross", "M. Valenzuela-R\u00e9ndon"], "venue": "In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-1999),", "citeRegEx": "Terashima.Mar\u0131\u0301n et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Terashima.Mar\u0131\u0301n et al\\.", "year": 1999}, {"title": "A replica exchange monte carlo algorithm for protein folding in the hp model", "author": ["C. Thachuk", "A. Shmygelska", "H.H. Hoos"], "venue": "BMC Bioinformatics,", "citeRegEx": "Thachuk et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Thachuk et al\\.", "year": 2007}, {"title": "UBCSAT: An implementation and experimentation environment for SLS algorithms for SAT & MAX-SAT", "author": ["D.A.D. Tompkins", "H.H. Hoos"], "venue": "In Theory and Applications of Satisfiability Testing: Proceedings of the Seventh International Conference (SAT\u201904),", "citeRegEx": "Tompkins and Hoos,? \\Q2004\\E", "shortCiteRegEx": "Tompkins and Hoos", "year": 2004}, {"title": "SATzilla: portfolio-based algorithm selection for SAT", "author": ["L. Xu", "F. Hutter", "H.H. Hoos", "K. Leyton-Brown"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Xu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2008}, {"title": "Benchmarking SAT Solvers for Bounded Model Checking", "author": ["E. Zarpas"], "venue": "Theory and Applications of Satisfiability Testing: Proceedings of the Eighth International Conference (SAT\u201905),", "citeRegEx": "Zarpas,? \\Q2005\\E", "shortCiteRegEx": "Zarpas", "year": 2005}], "referenceMentions": [{"referenceID": 36, "context": "There are many acknowledgements in the literature that finding performance-optimizing parameter configurations of heuristic algorithms often requires considerable effort (see, e.g., Gratch & Chien, 1996; Johnson, 2002; Diao, Eskesen, Froehlich, Hellerstein, Spainhower & Surendra, 2003; Birattari, 2004; Adenso-Diaz & Laguna, 2006).", "startOffset": 170, "endOffset": 331}, {"referenceID": 10, "context": "There are many acknowledgements in the literature that finding performance-optimizing parameter configurations of heuristic algorithms often requires considerable effort (see, e.g., Gratch & Chien, 1996; Johnson, 2002; Diao, Eskesen, Froehlich, Hellerstein, Spainhower & Surendra, 2003; Birattari, 2004; Adenso-Diaz & Laguna, 2006).", "startOffset": 170, "endOffset": 331}, {"referenceID": 36, "context": "\u2022 Empirical studies, evaluations, and comparisons of algorithms A central question in comparing heuristic algorithms is whether one algorithm outperforms another because it is fundamentally superior, or because its developers more successfully optimized its parameters (Johnson, 2002).", "startOffset": 269, "endOffset": 284}, {"referenceID": 47, "context": "Briefly, these include exhaustive enumeration, hill-climbing (Gratch & Dejong, 1992), beam search (Minton, 1993), genetic algorithms (Terashima-Mar\u0131\u0301n, Ross & Valenzuela-R\u00e9ndon, 1999), experimental design approaches (Coy, Golden, Runger & Wasil, 2001), sequential parameter optimization (Bartz-Beielstein, 2006), racing algorithms (Birattari, St\u00fctzle, Paquete & Varrentrapp, 2002; Birattari, 2004; Balaprakash, Birattari & St\u00fctzle, 2007), and combinations of fractional experimental design and local search (Adenso-Diaz & Laguna, 2006).", "startOffset": 98, "endOffset": 112}, {"referenceID": 8, "context": "Briefly, these include exhaustive enumeration, hill-climbing (Gratch & Dejong, 1992), beam search (Minton, 1993), genetic algorithms (Terashima-Mar\u0131\u0301n, Ross & Valenzuela-R\u00e9ndon, 1999), experimental design approaches (Coy, Golden, Runger & Wasil, 2001), sequential parameter optimization (Bartz-Beielstein, 2006), racing algorithms (Birattari, St\u00fctzle, Paquete & Varrentrapp, 2002; Birattari, 2004; Balaprakash, Birattari & St\u00fctzle, 2007), and combinations of fractional experimental design and local search (Adenso-Diaz & Laguna, 2006).", "startOffset": 287, "endOffset": 311}, {"referenceID": 10, "context": "Briefly, these include exhaustive enumeration, hill-climbing (Gratch & Dejong, 1992), beam search (Minton, 1993), genetic algorithms (Terashima-Mar\u0131\u0301n, Ross & Valenzuela-R\u00e9ndon, 1999), experimental design approaches (Coy, Golden, Runger & Wasil, 2001), sequential parameter optimization (Bartz-Beielstein, 2006), racing algorithms (Birattari, St\u00fctzle, Paquete & Varrentrapp, 2002; Birattari, 2004; Balaprakash, Birattari & St\u00fctzle, 2007), and combinations of fractional experimental design and local search (Adenso-Diaz & Laguna, 2006).", "startOffset": 331, "endOffset": 437}, {"referenceID": 24, "context": "Hutter, Hoos and Leyton-Brown (2009) considered this design space in detail, focusing on the tradeoff between the (fixed) number of problem instances to be used for the evaluation of each parameter configuration and the (fixed) cutoff time used for each run, as well as the interaction of these choices with the number of configurations that can be considered.", "startOffset": 8, "endOffset": 37}, {"referenceID": 14, "context": "Like many other related approaches (see, e.g., Minton, 1996; Coy et al., 2001; Adenso-Diaz & Laguna, 2006), it deals with the stochastic part of the optimisation problem by using an estimate based on a fixed training set of N instances.", "startOffset": 35, "endOffset": 106}, {"referenceID": 29, "context": "Indeed, in our past work we explored several of them: maximizing solution quality achieved in a given time, minimizing the runtime required to reach a given solution quality, and minimizing the runtime required to solve a single problem instance (Hutter et al., 2007).", "startOffset": 246, "endOffset": 267}, {"referenceID": 21, "context": "We generated these QCP instances around the solubility phase transition, using the parameters given by Gomes and Selman (1997). Specifically, the order n was drawn uniformly from the interval [26, 43], and the number of holes H (open entries in the Latin square) was drawn uniformly from [1.", "startOffset": 103, "endOffset": 127}, {"referenceID": 20, "context": "SW-GCP Our second benchmark set contained 20 000 instances of the graph colouring problem (GCP) based on the small world (SW) graphs of Gent et al. (1999). Of these, we sampled 2000 instances uniformly at random for use with SPEAR; these had on average 1813 variables (standard deviation: 703) and 13 902 clauses (standard deviation: 5393), and 1109 of them were satisfiable.", "startOffset": 136, "endOffset": 155}, {"referenceID": 43, "context": "We used the regions generator from the Combinatorial Auction Test Suite (Leyton-Brown et al., 2000), with the goods parameter set to 100 and the bids parameter set to 500.", "startOffset": 72, "endOffset": 99}, {"referenceID": 29, "context": "These results are consistent with our past work in which FocusedILS achieved statistically significantly better performance than BasicILS(100) (Hutter et al., 2007).", "startOffset": 143, "endOffset": 164}, {"referenceID": 3, "context": "It was obtained from the Berkeley Computational Optimization Lab5 and was introduced by Akt\u00fcrk, Atamt\u00fcrk and S. G\u00fcrel (2007). These instances contain an average of 2 769 variables and 2 255 constraints, with respective standard deviations of 2 133 and 1 592.", "startOffset": 96, "endOffset": 125}, {"referenceID": 3, "context": "It was also obtained from the Berkeley Computational Optimization Lab and was introduced by Atamt\u00fcrk and Mu\u00f1oz (2004). All 100 instances contain 181 variables and 180 constraints.", "startOffset": 92, "endOffset": 118}, {"referenceID": 3, "context": "\u2022 MIK This set of 120 MILP-encoded mixed-integer knapsack instances was also obtained from the Berkeley Computational Optimization Lab and was originally introduced by Atamt\u00fcrk (2003). These instances contain an average of 384 variables and 151 constraints, with respective standard deviations of 309 and 127.", "startOffset": 168, "endOffset": 184}, {"referenceID": 24, "context": "Thachuk, Shmygelska and Hoos (2007 ) used BasicILS in order to determine performance-optimizing parameter settings of a new replica-exchange Monte Carlo algorithm for protein folding in the 2DHP and 3D-HP models.8 Even though their algorithm has only four parameters (two categorical and two continuous), BasicILS achieved substantial performance improvements. While the manuallyselected configurations were biased in favour of either short or long protein sequences, BasicILS found a configuration which consistently yielded good mean runtimes for all types of sequences. On average, the speedup factor achieved was approximately 1.5, and for certain classes of protein sequences up to 3. While all manually-selected configurations performed worse than the previous state-of-the-art algorithm for this problem on some instances, the robust parameter configurations selected by BasicILS yielded uniformly better performance. In very recent work, Fawcett, Hoos and Chiarandini (2009) used several variants of ParamILS (including a version that has been slightly extended beyond the ones presented here) to design a modular stochastic local search algorithm for the post-enrollment course timetabling problem.", "startOffset": 24, "endOffset": 983}, {"referenceID": 29, "context": "When we first introduced ParamILS, we performed experiments comparing its performance against CALIBRA (Hutter et al., 2007).", "startOffset": 102, "endOffset": 123}, {"referenceID": 12, "context": "Another search-based approach that uses a fixed training set was introduced by Coy et al. (2001). Their approach works in two stages.", "startOffset": 79, "endOffset": 97}, {"referenceID": 0, "context": "A similar approach, also based on a combination of experimental design and gradient descent, using a fixed training set for evaluation, is implemented in the CALIBRA system of Adenso-Diaz and Laguna (2006). CALIBRA starts by evaluating each parameter configuration in a full factorial design with two values per parameter.", "startOffset": 176, "endOffset": 206}, {"referenceID": 0, "context": "A similar approach, also based on a combination of experimental design and gradient descent, using a fixed training set for evaluation, is implemented in the CALIBRA system of Adenso-Diaz and Laguna (2006). CALIBRA starts by evaluating each parameter configuration in a full factorial design with two values per parameter. It then iteratively homes in to good regions of parameter configuration space by employing fractional experimental designs that evaluate nine configurations around the best performing configuration found so far. The grid for the experimental design is refined in each iteration. Once a local optimum is found, the search is restarted (with a coarser grid). Experiments showed CALIBRA\u2019s ability to find parameter settings for six target algorithms that matched or outperformed the respective originally-proposed parameter configurations. Its main drawback is the limitation to tuning numerical and ordinal parameters, and to a maximum of five parameters. When we first introduced ParamILS, we performed experiments comparing its performance against CALIBRA (Hutter et al., 2007). These experiments are reviewed in Section 8.1. Terashima-Mar\u0131\u0301n et al. (1999) introduced a genetic algorithm for configuring a constraint satisfaction algorithm for large-scale university exam scheduling.", "startOffset": 176, "endOffset": 1180}, {"referenceID": 0, "context": "A similar approach, also based on a combination of experimental design and gradient descent, using a fixed training set for evaluation, is implemented in the CALIBRA system of Adenso-Diaz and Laguna (2006). CALIBRA starts by evaluating each parameter configuration in a full factorial design with two values per parameter. It then iteratively homes in to good regions of parameter configuration space by employing fractional experimental designs that evaluate nine configurations around the best performing configuration found so far. The grid for the experimental design is refined in each iteration. Once a local optimum is found, the search is restarted (with a coarser grid). Experiments showed CALIBRA\u2019s ability to find parameter settings for six target algorithms that matched or outperformed the respective originally-proposed parameter configurations. Its main drawback is the limitation to tuning numerical and ordinal parameters, and to a maximum of five parameters. When we first introduced ParamILS, we performed experiments comparing its performance against CALIBRA (Hutter et al., 2007). These experiments are reviewed in Section 8.1. Terashima-Mar\u0131\u0301n et al. (1999) introduced a genetic algorithm for configuring a constraint satisfaction algorithm for large-scale university exam scheduling. They constructed and configured an algorithm that works in two stages and has seven configurable categorical parameters. They optimized these choices with a genetic algorithm for each of 12 problem instances, and for each of them found a configuration that improved performance over a modified Brelaz algorithm. However, note that they performed this optimization separately for each instance. Their paper did not quantify how long these optimizations took, but stated that \u201cIssues about the time for delivering solutions with this method are still a matter of research\u201d. Work on automated parameter tuning can also be found in the numerical optimization literature. In particular, Audet and Orban (2006) proposed the mesh adaptive direct search algorithm.", "startOffset": 176, "endOffset": 2012}, {"referenceID": 8, "context": "Sequential parameter optimization (SPO) (Bartz-Beielstein, 2006) is a model-based parameter optimization approach based on the Design and Analysis of Computer Experiments (DACE; see, e.", "startOffset": 40, "endOffset": 64}, {"referenceID": 8, "context": "Sequential parameter optimization (SPO) (Bartz-Beielstein, 2006) is a model-based parameter optimization approach based on the Design and Analysis of Computer Experiments (DACE; see, e.g., Santner, Williams & Notz, 2003), a prominent approach in statistics for blackbox function optimization. SPO starts by running the target algorithm with parameter configurations from a Latin hypercube design on a number of training instances. It then builds a response surface model based on Gaussian process regression and uses the model\u2019s predictions and predictive uncertainties to determine the next parameter configuration to evaluate. The metric underlying the choice of promising parameter configurations is the expected improvement criterion used by Jones, Schonlau and Welch (1998). After each algorithm run, the response surface is refitted, and a new parameter configuration is determined based on the updated model.", "startOffset": 41, "endOffset": 779}, {"referenceID": 7, "context": "A recent extension presented by Balaprakash et al. (2007) iteratively performs F-Race on subsets of parameter configurations.", "startOffset": 32, "endOffset": 58}, {"referenceID": 7, "context": "A recent extension presented by Balaprakash et al. (2007) iteratively performs F-Race on subsets of parameter configurations. This approach scales better to large configuration spaces, but the version described by Balaprakash et al. (2007) handles only algorithms with numerical parameters.", "startOffset": 32, "endOffset": 240}, {"referenceID": 36, "context": "Approaches for setting parameters on a per-instance basis have been described by Patterson and Kautz (2001), Cavazos and O\u2019Boyle (2006), and Hutter et al.", "startOffset": 81, "endOffset": 108}, {"referenceID": 12, "context": "Approaches for setting parameters on a per-instance basis have been described by Patterson and Kautz (2001), Cavazos and O\u2019Boyle (2006), and Hutter et al.", "startOffset": 109, "endOffset": 136}, {"referenceID": 12, "context": "Approaches for setting parameters on a per-instance basis have been described by Patterson and Kautz (2001), Cavazos and O\u2019Boyle (2006), and Hutter et al. (2006). Furthermore, approaches that attempt to select the best algorithm on a per-instance basis have been studied by Leyton-Brown, Nudelman and Shoham (2002), Carchrae and Beck (2005), Gebruers, Hnich, Bridge and Freuder (2005), Gagliolo and Schmidhuber (2006), and Xu, Hutter, Hoos and Leyton-Brown (2008).", "startOffset": 109, "endOffset": 162}, {"referenceID": 12, "context": "Approaches for setting parameters on a per-instance basis have been described by Patterson and Kautz (2001), Cavazos and O\u2019Boyle (2006), and Hutter et al. (2006). Furthermore, approaches that attempt to select the best algorithm on a per-instance basis have been studied by Leyton-Brown, Nudelman and Shoham (2002), Carchrae and Beck (2005), Gebruers, Hnich, Bridge and Freuder (2005), Gagliolo and Schmidhuber (2006), and Xu, Hutter, Hoos and Leyton-Brown (2008).", "startOffset": 109, "endOffset": 315}, {"referenceID": 12, "context": "Furthermore, approaches that attempt to select the best algorithm on a per-instance basis have been studied by Leyton-Brown, Nudelman and Shoham (2002), Carchrae and Beck (2005), Gebruers, Hnich, Bridge and Freuder (2005), Gagliolo and Schmidhuber (2006), and Xu, Hutter, Hoos and Leyton-Brown (2008).", "startOffset": 153, "endOffset": 178}, {"referenceID": 12, "context": "Furthermore, approaches that attempt to select the best algorithm on a per-instance basis have been studied by Leyton-Brown, Nudelman and Shoham (2002), Carchrae and Beck (2005), Gebruers, Hnich, Bridge and Freuder (2005), Gagliolo and Schmidhuber (2006), and Xu, Hutter, Hoos and Leyton-Brown (2008).", "startOffset": 153, "endOffset": 222}, {"referenceID": 12, "context": "Furthermore, approaches that attempt to select the best algorithm on a per-instance basis have been studied by Leyton-Brown, Nudelman and Shoham (2002), Carchrae and Beck (2005), Gebruers, Hnich, Bridge and Freuder (2005), Gagliolo and Schmidhuber (2006), and Xu, Hutter, Hoos and Leyton-Brown (2008).", "startOffset": 153, "endOffset": 255}, {"referenceID": 12, "context": "Furthermore, approaches that attempt to select the best algorithm on a per-instance basis have been studied by Leyton-Brown, Nudelman and Shoham (2002), Carchrae and Beck (2005), Gebruers, Hnich, Bridge and Freuder (2005), Gagliolo and Schmidhuber (2006), and Xu, Hutter, Hoos and Leyton-Brown (2008). In other related work, decisions about when to restart an algorithm are made online, during the run of an algorithm (Horvitz, Ruan, Gomes, Kautz, Selman & Chickering, 2001; Kautz, Horvitz, Ruan, Gomes & Selman, 2002; Gagliolo & Schmidhuber, 2007).", "startOffset": 153, "endOffset": 301}, {"referenceID": 33, "context": "Since ParamILS performs an iterated local search with a one-exchange neighbourhood, it is very similar in spirit to local search methods for other problems, such as SAT (Selman, Levesque & Mitchell, 1992; Hoos & St\u00fctzle, 2005), CSP (Minton, Johnston, Philips & Laird, 1992), and MPE (Kask & Dechter, 1999; Hutter et al., 2005).", "startOffset": 283, "endOffset": 326}, {"referenceID": 46, "context": "Since ParamILS is a local search method, existing theoretical frameworks (see, e.g., Hoos, 2002; Mengshoel, 2008), could in principle be used for its analysis.", "startOffset": 73, "endOffset": 113}, {"referenceID": 29, "context": "\u2022 An objective function While we used median performance in our first study on ParamILS (Hutter et al., 2007), we have since found cases where optimizing median performance led to parameter configurations with good median but poor overall performance.", "startOffset": 88, "endOffset": 109}, {"referenceID": 15, "context": "We thank the researchers who provided the instances or instance generators used in our work, in particular Gent et al. (1999), Gomes and Selman (1997), LeytonBrown et al.", "startOffset": 107, "endOffset": 126}, {"referenceID": 15, "context": "We thank the researchers who provided the instances or instance generators used in our work, in particular Gent et al. (1999), Gomes and Selman (1997), LeytonBrown et al.", "startOffset": 107, "endOffset": 151}, {"referenceID": 15, "context": "We thank the researchers who provided the instances or instance generators used in our work, in particular Gent et al. (1999), Gomes and Selman (1997), LeytonBrown et al. (2000), Babi\u0107 and Hu (2007), Zarpas (2005), Le Berre and Simon (2004), Akt\u00fcrk et al.", "startOffset": 107, "endOffset": 178}, {"referenceID": 2, "context": "(2000), Babi\u0107 and Hu (2007), Zarpas (2005), Le Berre and Simon (2004), Akt\u00fcrk et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 2, "context": "(2000), Babi\u0107 and Hu (2007), Zarpas (2005), Le Berre and Simon (2004), Akt\u00fcrk et al.", "startOffset": 8, "endOffset": 43}, {"referenceID": 2, "context": "(2000), Babi\u0107 and Hu (2007), Zarpas (2005), Le Berre and Simon (2004), Akt\u00fcrk et al.", "startOffset": 8, "endOffset": 70}, {"referenceID": 1, "context": "(2000), Babi\u0107 and Hu (2007), Zarpas (2005), Le Berre and Simon (2004), Akt\u00fcrk et al. (2007), Atamt\u00fcrk and Mu\u00f1oz (2004), Atamt\u00fcrk (2003), and Andronescu et al.", "startOffset": 71, "endOffset": 92}, {"referenceID": 1, "context": "(2000), Babi\u0107 and Hu (2007), Zarpas (2005), Le Berre and Simon (2004), Akt\u00fcrk et al. (2007), Atamt\u00fcrk and Mu\u00f1oz (2004), Atamt\u00fcrk (2003), and Andronescu et al.", "startOffset": 71, "endOffset": 119}, {"referenceID": 1, "context": "(2000), Babi\u0107 and Hu (2007), Zarpas (2005), Le Berre and Simon (2004), Akt\u00fcrk et al. (2007), Atamt\u00fcrk and Mu\u00f1oz (2004), Atamt\u00fcrk (2003), and Andronescu et al.", "startOffset": 71, "endOffset": 136}, {"referenceID": 1, "context": "(2000), Babi\u0107 and Hu (2007), Zarpas (2005), Le Berre and Simon (2004), Akt\u00fcrk et al. (2007), Atamt\u00fcrk and Mu\u00f1oz (2004), Atamt\u00fcrk (2003), and Andronescu et al. (2007). Lin Xu created the specific sets of QCP and SWGCP instances we used.", "startOffset": 71, "endOffset": 166}], "year": 2009, "abstractText": "The identification of performance-optimizing parameter settings is an important part of the development and application of algorithms. We describe an automatic framework for this algorithm configuration problem. More formally, we provide methods for optimizing a target algorithm\u2019s performance on a given class of problem instances by varying a set of ordinal and/or categorical parameters. We review a family of local-search-based algorithm configuration procedures and present novel techniques for accelerating them by adaptively limiting the time spent for evaluating individual configurations. We describe the results of a comprehensive experimental evaluation of our methods, based on the configuration of prominent complete and incomplete algorithms for SAT. We also present what is, to our knowledge, the first published work on automatically configuring the CPLEX mixed integer programming solver. All the algorithms we considered had default parameter settings that were manually identified with considerable effort. Nevertheless, using our automated algorithm configuration procedures, we achieved substantial and consistent performance improvements.", "creator": "TeX"}}}