{"id": "1401.3493", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Predicting the Performance of IDA* using Conditional Distributions", "abstract": "Korf, Reid, and Edelkamp introduced a formula to predict the number of nodes IDA* will expand on a single iteration for a given consistent heuristic, and experimentally demonstrated that it could make very accurate predictions. In this paper we show that, in addition to requiring the heuristic to be consistent, their formulas predictions are accurate only at levels of the brute-force search tree where the heuristic values obey the unconditional distribution that they defined and then used in their formula. We then propose a new formula that works well without these requirements, i.e., it can make accurate predictions of IDA*s performance for inconsistent heuristics and if the heuristic values in any level do not obey the unconditional distribution. In order to achieve this we introduce the conditional distribution of heuristic values which is a generalization of their unconditional heuristic distribution. We also provide extensions of our formula that handle individual start states and the augmentation of IDA* with bidirectional pathmax (BPMX), a technique for propagating heuristic values when inconsistent heuristics are used. Experimental results demonstrate the accuracy of our new method and all its variations.", "histories": [["v1", "Wed, 15 Jan 2014 05:41:44 GMT  (345kb)", "http://arxiv.org/abs/1401.3493v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["uzi zahavi", "ariel felner", "neil burch", "robert c holte"], "accepted": false, "id": "1401.3493"}, "pdf": {"name": "1401.3493.pdf", "metadata": {"source": "CRF", "title": "Predicting the Performance of IDA* using Conditional Distributions", "authors": ["Uzi Zahavi", "Ariel Felner", "Neil Burch", "Robert C. Holte"], "emails": ["zahaviu@cs.biu.ac.il", "felner@bgu.ac.il", "burch@cs.ualberta.ca", "holte@cs.ualberta.ca"], "sections": [{"heading": "1. Introduction and Overview", "text": "Heuristic search algorithms as A * (Hart, Nilsson, & Raphael, 1968) and IDA * (Korf, 1985) are directed by the cost function f (n) = g (n) + h (n), where g (n) is the actual distance from the start state to state n and h (n) is a heuristic function to the cost of a least-cost path from n to the next goal state. If h (n) is permissible, if h (n) \u2264 dist (n, goal) for each state n and goal state state, where dist (n, m) is the cost of a least-cost path from n to m. If h (n) is admissible, i.e. there is always a lower estimate of the optimal cost, these algorithms are guaranteed to provide an optimal path from the start state to a goal state, if one exists.c \u00a9 2010 AI Access Foundation."}, {"heading": "2. Background", "text": "In our experiments we use exactly the same domains. In this section we describe them as well as the search algorithm and the various heuristic functions used in our experiments."}, {"heading": "2.1 Problem Domains", "text": "Two of the classic examples in AI literature of a one-agent pathway problem are Rubik's Cube and the sliding puzzle."}, {"heading": "2.1.1 Rubik\u2019s Cube", "text": "Rubik's cube was invented in 1974 by Erno Rubik from Hungary. The standard version consists of a 3 x 3 x 3 x 3 cube (Figure 1), with different coloured stickers on each of the exposed squares of the partial cubes or cubes. There are 20 movable cubes and 6 stable cubes in the middle of each face. The movable cubes can be divided into eight corner cubes with three faces each and twelve corner cubes with two faces each. Corner cubes can only be moved between corner positions, and edge cubes can only be moved between edge positions. Each of the 6 sides of the cube rotated by 90, 180 or 270 degrees in relation to the rest of the cube. This results in 18 possible moves for each state. Since the rotation of the same face is redundant twice in a row, the branching factor can be reduced to 15 after the first move. Furthermore, movements of opposite faces are independent."}, {"heading": "2.1.2 The Sliding-tile Puzzles", "text": "The sliding puzzle consists of a square frame with a row of numbered square tiles in the empty position. The problem is to rearrange the tiles from a random initial configuration to a specific target configuration. State space grows exponentially as the number of tiles increases, and it has been shown that finding optimal solutions to the sliding tile problem is NPcomplete (Ratner & Warmuth, 1986). The two most common versions of the sliding puzzle are the 3 x 3 x 8 puzzle and the 4 x 4 x 15 puzzle. The 8 puzzle contains 9! / 2 (181,440) achievable states, and the 15 puzzle contains about 1013 achievable states. The objectives of these puzzles are shown in Figure 2.The classic heuristic function for sliding tiles contains 9 (181,440) achievable states, and the 15 puzzle contains about 1013 achievable states."}, {"heading": "2.2 Iterative Deepening A*", "text": "The Iterative Indentation A * (IDA *) (Korf, 1985) performs a series of depth searches and increases the cost threshold each time d. In the depth search, all nodes n are extended with f (n) \u2264 d. Threshold d is first set to h (s), where s is the start node. If a destination is found on the basis of the current threshold, the search ends successfully. Otherwise, IDA * proceeds to the next iteration by increasing d to the minimum f-value that d exceeded in the previous iteration."}, {"heading": "2.3 Pattern Databases (PDBs)", "text": "An effective approach to obtaining acceptable heuristics is to create a simplified version or abstraction of DB space (DB operators to abstract space) and then use exact distances in abstract space as estimates of distances in the original state. The kind of abstractions we use in this paper for the sliding puzzles is in Figure 3. The left side of the figure shows a 15 puzzle state S and the target state. The right side shows the corresponding abstract states that are defined by storing the numbers on all tiles except 2, 3, 6 and 7. To estimate the distance from S to the target state in the 15 puzzle, we calculate the exact distance from the abstract state that corresponds to the abstract target state. A Pattern Database (PDB) is a search table that stores the distance to the abstract target of each abstract state (or \"pattern\")."}, {"heading": "2.4 Geometric Symmetries", "text": "It is common practice to use special properties of a state space to allow additional heuristic evaluations.In particular, additional PDB investigations can be carried out in a single HDB. For example, if we look at Rubik's cube and suppose we have a HDB based on the positions of the cubes that have a yellow face (the positions of the other cubes do not matter), the reflection and rotation of the puzzle allows similar investigations into cubes of a different color (e.g. green, red, etc.), since the puzzle is perfectly symmetrical in terms of color. Thus, there are 24 symmetrical investigations for such a HDB, and for each of these cubes in the same HDB different heuristic values are obtained. All these heuristic values are permissible for each given state of the puzzle. As another example, we look at the sliding puzzle with sliding tiles."}, {"heading": "2.5 Methods for Creating Inconsistent Heuristics", "text": "It is indeed the case that we are able to put ourselves at the top of society in the way in which we have placed ourselves at the top of the society in which we find ourselves."}, {"heading": "3.1.1 Conditions for Node Expansion in IDA*", "text": "To understand how Pex (s, d, i) is handled in CRE, it is necessary to consider the conditions required for the extension of the node. A node in the level i of BFSD is expanded by IDA * if it meets two conditions: 1. F (n), 2. D (n), 3. D (n), 4. D (n), 5. D (n), 6. D (n), 6. D (n), 7. D (n), 7. D (n), 8. D (n), 8. D (n), 8. D (n), 8. D (n), 8. D (n), 8. D (n), 9. D (n), 9. D (n), 9. (), 9. (), 9. (), 9. (), (), (), (), (), ((), (), ((), (), ((), ((), (), ((), (), ((), ((), (), ((), (), (()), (()), ((())), ((()."}, {"heading": "3.2.1 Inconsistent Heuristics", "text": "This year it is more than ever before."}, {"heading": "3.2.2 Sets of Start States Whose Heuristics Values do not Obey the unconditional heuristic distribution", "text": "As explained above, KRE used the unconditional heuristic distribution P (v) and proved in its theoretical analysis that its use in the KRE formula would give accurate predictions in the great depth limit. In fact, accurate predictions will occur once the heuristic distribution in the depth of interest d comes close to P (v). This happens at great depths by definition, but this can happen even at very shallow levels under certain circumstances. The reason why KRE was able to produce extremely accurate predictions in its experiments with the unconditional heuristic distribution P (v) for all depths and all start states is that its experiments report average predictions and performance for a large number of randomly drawn start states. In the spaces used in KRE experiments, the heuristic distribution of a large random set of start states P (v) for all depths and all start states P (v) will show."}, {"heading": "3.2.3 Convergence of the Heuristic Distributions at Large Depths", "text": "This year, it is so far that it will only take a few more days before there is a result in which there is a result."}, {"heading": "4.1 Conditional Distribution of Heuristic Values", "text": "The conditional distribution of heuristic values is called P (v | context), where the context represents local properties of the search tree in the neighborhood of a node that affect the distribution of heuristic values in the children of the node. If Pn (v) is the percentage of children of the node n that has a heuristic value less than or equal to v, we define P (v | context) as the average of Pn (v) over all nodes that meet the conditions defined by the context. P (v | context) can be interpreted as the probability that a node with a heuristic value less than or equal to v is produced when a node that meets the conditions specified by the context is extended. If the context is empty, it is called P (v) as in Section 3. We use p (v | context) (lowercase p) to indicate the probability that a node with a heuristic value equal to v is produced when a node that meets the conditions is specified in context."}, {"heading": "4.1.1 The Basic 1-Step Model", "text": "The condition context can be any combination of local properties of the search tree, including the properties of the node itself (e.g. its heuristic value), the operator used to create the node, the properties of the ancestors of the node in the search tree, etc. The simplest conditional distribution is p (v | vp), the probability of a node having a heuristic value is equal to v, which is created when a node with a value vp is expanded. We call this a 1-step model, because each value is conditioned by nodes that are only one step away. Under special circumstances, p (v | vp) can be precisely determined by analyzing the state space and the heuristic matrix, but generally it must be approached empirically by sampling the state space p. In our sampling method p (v | vp) the state value of p [v] [vp] is set in a two-dimensional matrix."}, {"heading": "4.1.2 Richer Models", "text": "If the node is expanded, there will be some children because the number of nodes is increasing. (In fact, the number of nodes that are pointed out in the nodes is not as high as the number of nodes. (We refer to the parent node as gp). We point out that the number of nodes cannot be taken into account in the manner in which it is expanded. (In the way in which it is expanded, it is necessary to expand the context of the conditional probability because it expands the information from the ancestors to two steps. (We refer to the parent node as gp). (We point out that this is from p, vgp) and call it a \"2-step\" model because it expands the conditions from the ancestors to two steps. (V, vgp) gives the probability of a node value with a hypocritical value (We refer to a vristic value)."}, {"heading": "4.3 Prediction Using the Basic 1-Step Model", "text": "When the basic 1-step conditional distribution p (v | vp) is used, Ni (s, d, v) can be recursively estimated as follows: Ni (s, d, v) \u2248 N factor i (s, d, v) = d factor vp = 0N factor i-1 (s, d, vp) \u00b7 bvp \u00b7 p (5), where bvp is the average branching factor of nodes with heuristic value vp that is estimated during the scanning process that estimates the conditional distribution. (5) The reasoning behind this equation is that Ni \u2212 1 (s, d, vp) \u00b7 ristic formula is the total number of children generated by IDA * over the nodes that it is equal at level i \u2212 1 with heuristic value that is equal to heuristic value. This multiplies by p (v | vp) to obtain the expected number of these children that have branched."}, {"heading": "4.4 Prediction Using Richer Models", "text": "If the two-stage conditional distribution p (v | vp, vgp) = Level V = Level DA (v = Level) is used, we define Ni (s, d, vp) as the number of nodes that IDA * will generate at level i with a heuristic value equal to v of nodes at level i \u2212 1 with heuristic value vp (s, v, v, vp). Ni (s, d, v, vp) can be recursively estimated as follows: Ni (s, d, v, vp). N (s, d, v, v, vp) is the initial value of s (i \u2212 2)."}, {"heading": "4.5 Prediction Accuracy", "text": "The accuracy of our predictions can be arbitrarily good or arbitrarily bad depending on the accuracy of the conditional model used. In the following subsections, we examine each of these extreme cases. In principle, broadening the context should never reduce the accuracy of the predictions because additional information is taken into account. However, if the conditional model is estimated by sampling, an extended context can lead to poorer predictions because there are fewer samplings in each context. This is our explanation of why the single-stage model is more accurate than the two-stage model in lines h = 6 and h = 9 in Table 7 in Section 6.2 below."}, {"heading": "4.5.1 Perfect Predictions", "text": "In fact, it is such that it is a matter of a way in which it is about the satisfaction of people who are able to put themselves in a position to put themselves in the world, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live."}, {"heading": "4.5.2 Very Poor Predictions", "text": "The predictions of a conditional model will be extremely inaccurate if the distribution of heuristic values is independent of the information provided by the context. We illustrate this with an example based on the 4x3 sliding puzzle and two heuristics, a budget based on the positions of tiles 1-7 and the blank, and a heuristic based on 0 for each state. If the given state has the blank in its target position, or in a position that is an even number of steps away from the target position, the heuristic value for that state is taken out of the budget. The other states have a heuristic value of 0."}, {"heading": "5. Experimental Setup", "text": "The next two sections describe the experimental results we obtained by operating IDA * and comparing the number of nodes it expands to the number predicted by KRE and byCDP. We experimented on the same two application areas used by KRE, namely Rubik's Cube (Section 6) and the Sliding Tile Puzzle (Section 7). In each area, we evaluated the accuracy of the two formulas, for both consistent and inconsistent heuristics, on a series of soluble start states that were randomly generated. In all the experiments reported here, the start states for a particular IDA * threshold d were subject to a special condition. State s is performed only as start state in combination with threshold d * if IDA * actually performs an iteration with threshold d when s is the start state."}, {"heading": "50 91,329,281 18,758 9,904,973", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "49 40,479,725 20,389 6,037,064", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "48 20,355,110 21,028 3,508,482", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "47 8,963,747 22,243 2,108,766", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "46 4,542,249 22,266 1,182,522", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "45 1,985,565 22,937 688,119", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "44 1,014,941 22,484 393,406", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "43 439,942 22,525 219,001", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6. Experimental Results for Rubik\u2019s Cube", "text": "Starting with Rubik's Cube experiments, the heuristics used here are the 6-edged PDB heuristics described above (Section 3.2.1). We experimented with (consistent) periodic review and (inconsistent) random symmetry and dual review on this database. Two models were used for the CDP formula, CDP1 and CDP2, each of which denotes the one- and two-step models. As outlined in Section 4.1.1, the conditional distribution tables were constructed by generating one billion states (each generated by applying 180 random movements to the target state) by calculating all of their neighbors and including their heuristic information in the matrix representing the one-step model. For the two-step model, we also generated all of our grandchildren and used their heuristic information to obtain reliable samples that we compile with the hay rix table."}, {"heading": "6.1 Rubik\u2019s Cube with Consistent Heuristics", "text": "Table 6 compares KRE to CDP1 and CDP2. The accuracy of the three prediction methods was compared during regular research on the hexagonal PDB. Results in each line are averages over a set of 1000 random states. Each line shows the results of an IDA * iteration with different threshold (d) specified in the first column. The second column (IDA *) shows the actual number of extended nodes for each IDA * threshold. The next columns show the prediction and accuracy (\"ratio\") of each prediction defined as the ratio between the predicted number and the actual number of extended nodes. As reported in the KRE paper, the KRE formula for consistent heuristics proved to be very accurate when averaged over a large set of random start states. The table shows that CDP1 is reasonably large, but does not include systematic children, because the model is underrated."}, {"heading": "6.2 Rubik\u2019s Cube with Start States Having Specific Heuristic Values", "text": "Table 2, shown above (Section 3.2.2), and the related discussion, show that KRE may not make accurate predictions when start states are limited to a certain heuristic value h. For the example shown (IDA * threshold 12), KRE will always predict a value of 8, 161, 064, but the exact value depends on the specific group of start states used, since the IDA * threshold of 12 is not large enough to be the number of nodes independent of start states. Table 7 adds the predictions of the CDP to Table 2, showing that both versions of the CDP substantially exceed KRE in relation to a specific group of start states."}, {"heading": "6.3 Rubik\u2019s Cube with Inconsistent Heuristics", "text": "The same experiments have been repeated for inconsistent heuristics. As discussed in Section 3.2.1, KRE provides the same prediction for all heuristics (consistent and inconsistent) derived from a single PDB and overestimated for the inconsistent heuristics. Table 8 shows that CDP2 is extremely accurate, and its prediction is always within 2% of the actual number of nodes that expand. To understand what happens when the m node is expanded to the right side of Figure 7, two children are generated, nodes n and (assuming operators have inverses as in Ruheuriks Cube), the 1-step model used by CDP1 systematically underestimates the actual number of nodes that are expanded for regular and dual investigations."}, {"heading": "7. Experimental Results - Sliding-Tile Puzzle", "text": "In the KRE experiments on the sliding puzzle, three state types are used, based on whether the blank is in a corner, edge or inside. We used the same state types in our experiments and used exact repetition equations for N (s, v, d, t) in the type-dependent version of the KRE formula. heuristic use was Manhattan Distance (MD). We experimented with the 2-step CDP method, which includes the type system in the recurrence equations. Results for the 1-step CDP are not taken into account here because it was poorly performed in early versions of these experiments. For the 8 puzzle states, the conditional distribution P (v, t | vp, tgp) was needed by CDP2 and the typed conditional distribution P (v, t) was not needed."}, {"heading": "7.1 Inconsistent Heuristics for the Sliding-tile Puzzle", "text": "Our next experiment relates to an inconsistent heuristic of the 8 puzzle. We defined two PDBs, one based on the position of the blank and tiles 1-4, the other based on the position of the blank and tiles 5-8. To create an inconsistent heuristic, only one of the PDBs was consulted regularly. PDB selection was systematic and not random based on the position of the blank. Various occurrences of the same state were guaranteed, but neighboring countries were guaranteed to consult different PDBs, resulting in inconsistencies. Results are presented in Table 10 for a variety of IDA * thresholds. The \"Num\" column indicates for each threshold how many start states were used. Results show that CDP's predictions are reasonably accurate and much more accurate than the KRE values that were performed up to a factor of 26, similar experiments."}, {"heading": "8. Accurate Predictions for Single Start States", "text": "We have seen that CDP works well when the base cases of recursive calculation of Ni (s, d, v) are seeded by a large number of start states, regardless of how their heuristic values are distributed. However, the actual number of extended nodes for a particular start state may differ from the number predicted by CDP. Conditional distribution reflects the expected values across all nodes sharing the same context, and the individual start state of interest may behave differently from the \"average\" state that has the same context. Consider the cube state of a Rubik with a heuristic value of 8. CDP2 predicts that IDA * for such a state with IDA * threshold 12. Table 2 shows that on average (over 1,000 start states with a heuristic value of 8) 6, 002, 025 states are extended."}, {"heading": "8.1 Rubik\u2019s Cube, 6-edge PDB Heuristic", "text": "Table 12 shows the results for four specific Rubik's Cube states with a heuristic value of 8 (the regular 6-edged PDB search) when the IDA * threshold was set to 12. We chose the states with the lowest and largest number of expanded nodes and two states around the median. The first column shows the actual number of nodes that IDA * expands for each state. The next columns show the number of advanced nodes predicted by our extended CDP2 formula, where the initial search extends to depths of (r) of 0, 2, 5 and 6. These initial searches clearly provide much better predictions than the original CDP2 (with r = 0), which predicts 6, 743, 686 for all of these states. At an initial search to depth of 6, the predictions are very precise."}, {"heading": "8.2 Rubik\u2019s Cube, 8-6-6 Heuristic", "text": "Section 3.2.3 presented KRE predictions for two start states, s6, with a heuristic value of 6 and s11, with a heuristic value of 11, for Rubik's cube with a value of 8-6-6. Here we repeat these experiments with CDP1. Tables 13 and 14 show the results with an initial search for depth (r) 0 and 4. The tables show that CDP1 was able to achieve much better predictions than KRE in most cases and that an initial search to depth 4 generally improved the predictions of CDP1."}, {"heading": "8.3 Experiments on the 8-Puzzle - Single Start States", "text": "We performed experiments with the extended CDP2 formula for all states of the 8 puzzle with the (consistent) MD heuristics. We use the term \"study\" to refer to each pair of a single start state and a specific IDA * threshold d. The studies included all possible values of d and for each d all start states for which IDA * would actually perform a search with the IDA * threshold d. Predictions were made separately for each experiment and the relative error, predicted / in fact, was calculated for the experiment. Results are shown in Figure 8. There are four curves in the figure, for KRE, for CDP and for the extended CDP with initial search depths (r) of 5 and 10. The x-axis is a relative error. The y-axis is the percentage of studies for which the prediction had a relative error of x or less. For example, the y value of 20% for the KRE curve with a value of 94% greater than the actual KRP x = 0.5% was estimated by the RP = 0.5%."}, {"heading": "9. Performance Range for a Given Unconditional Distribution", "text": "The experiments in this paper that used the hexagonal PDB for Rubik's Cube have highlighted the fact that the number of nodes IDA * can vary enormously depending on the way the PDB is used (Zahavi et al., 2007). To make this clear, the middle three columns of Table 15 show data that were already visible in Tables 6 and 8, namely the number of nodes IDA * expands when the 6-edged PDB is used in a regular manner, with dual lookups and random lookups. IDA * expands ten times fewer nodes when the 6-edged PDB is consulted with random symmetry searches than when consulted in a normal way. This raises the intriguing question of what power spectrum can be achieved by variation of the conditional distribution when the unconditional distribution is fixed."}, {"heading": "9.1 Upper Limit", "text": "The upper extreme, which leads to an expansion of most nodes, occurs when consistent heuristics are used. This is because IDA * only expands potential nodes, i.e. the maximum number of nodes expands if the conditional distribution is such that the parent of each potential node is at level i \u2212 1. An exact calculation of the number of potential nodes in the brute force tree is therefore a theoretical upper limit on the number of nodes IDA * could expand for a given unconditional distribution. As we have already discussed, one way to estimate the number of potential nodes is to use the KRE formula. This estimate of the upper limit of the number of nodes that IDA * could expand is called CDP. Alternatively, the number of potential nodes can be approximated using the CDP formula, with the conditional distribution given."}, {"heading": "9.2 Lower Limit", "text": "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "10. Predicting the Performance of IDA* with BPMX", "text": "s heuristic value can be much higher than that of the parent. If this occurs in a state room with undirected edges, the heuristic value of the child can be transferred back to the parent. If this causes the parent's f-value to exceed the IDA * threshold, the entire search sub-tree rooted by the parent can be pruned without producing any of the remaining children. This propagation technology is called bidirectional pathmax (BPMX) (Felner et al., 2005; Zahavi et al., 2007). It has been proven to be very effective in reducing the search effort by pruning subtrees that would otherwise be studied. We will now show how to modify CDP to deal with BPMX propagation. Since BPMX is only applicable to states with undirected edges, the discussion in this section is limited to such areas."}, {"heading": "10.1 Bidirectional Pathmax (BPMX)", "text": "It is not the first time that a child is born in another country than a child is born in another country. (...) It is the first time that a child is born in another country. (...) It is the second time that a child is born in another country. (...) It is the first time that a child is born in another country. (...) It is the second time that a child is born in another country. (...) It is the second time that a child is born in another country. (...) It is the second time that a child is born in another country. (...) It is the second time that a child is born in another country. (...) It is the third time that a child is born in another country. (...) It is the second time that a child is born in another country. (...) It is the third time that a child is born in another country. (...) It is the third time that a child is born in another country."}, {"heading": "10.5 Experiments on Rubik\u2019s Cube with BPMX", "text": "Since BPMX only affects inconsistent heuristics, only the \"dual\" and \"random symmetry\" were tested, and each heuristic was tested for IDA * thresholds 8 to 13. The results, averaged over the same set of 1000 random states, are shown in Table 17. The \"No BPMX\" columns are taken from Table 8. The additional columns show our results with BPMX. The column \"IDA * + BPMX\" shows the actual number of extended nodes when using BPMX. BPMX reduces the number of extended nodes in this section by more than 30% and by more than 25% in random symmetry, increasing the unmodified CDP2 predictions by about the same amount. The \"CDP bx 2\" column shows that the changes introduced in this section significantly improve accuracy."}, {"heading": "11. Related Work", "text": "Previous work on predicting the performance of A * or IDA * based on the properties of heuristics is divided into two camps: the first bases its analysis on the accuracy of heuristics, while the second bases its analysis, as we have done, on the distribution of heuristic values. In the next two subsections, these approaches will be examined."}, {"heading": "11.1 Analysis Based on a Heuristic\u2019s Accuracy", "text": "A common approach is to characterize a heuristic tree by focusing on the error in heuristic analysis (the deviation from the optimal cost).The first analysis in this line, which focuses on the impact of errors on the performance of search algorithms, was performed by Pohl (1970).Many other works in this line have appeared since (Pohl, 1977), in the manner in which they relate to the treatment of complex errors in practice, in the way in which they relate to the treatment of errors in practice. Sen, Bagchi, & Zhang, 2004; Dinh, Russell, & Su, 2007; Helmert & Ro \u00bc ger, 2008).These works usually proceed from an abstract model space of a tree in which each node has exactly b children and aim to provide the asymptotic estimate for the number of extended nodes. They differ mainly from the model assumptions."}, {"heading": "11.2 Analysis Based on the Heuristic Distribution", "text": "As discussed at the beginning of this paper, KRE has proposed an alternative approach to calculating the temporal complexity of IDA * on multiple target spaces (Korf & Reid, 1998; Korf et al., 2001). Assuming that heuristic accuracy is very difficult to obtain, they proposed to derive the analysis from the unconditional distribution of heuristic values, which is at least approximate; they also came up with a method for deriving a closed formula for Ni, the number of nodes at level i of the brute force search tree. This method was later formalized (Edelkamp, 2001b). Unlike the work described in the previous subsection, which provides a \"Big O\" complexity analysis, the goal of KRE (and ours) is to accurately predict that the number of nodes IDA * expand.KRE correctly indicate that if operators do not all have the same cost, Ni must be defined as the number of nodes that can be achieved by a path of the general cost."}, {"heading": "12. Conclusions and Future Work", "text": "KRE introduced the idea of characterizing heuristics by their unconditional heuristic distribution and presented its formula for predicting the number of nodes based on an iteration of IDA *, based on the unconditional heuristic distribution. The work we have presented in this paper takes another step in this direction. The conditional distribution we have introduced and the predictive formula CDP based on it expand our understanding of how characteristics of heuristics affect the performance of IDA *. Our CDP method advances KRE by improving its predictions at low depth, across a wider range of start states and for inconsistent heuristics. We have also shown how it can be used to make an accurate prediction for a single start state and for an IDA * search where BPMX uses heuristic value propagations. Of course, with the more complex methods more prediction work is required and particular reliability needs to be obtained in predicting the accuracy of the data to be used."}, {"heading": "13. Acknowledgments", "text": "Robert Holte and Neil Burch would like to thank Ariel Felner for the continued support of this work by the Canadian Research Council for Science and Technology (NSERC) and the Informatics Circle of Research Excellence (iCORE) in Alberta. The code for Rubik's Cube in this paper is based on the implementation of Richard E. Korf's pioneering work in this field (Korf, 1997). We thank the anonymous reviewer who encouraged us to expand our experimental results and better explain the results of KRE and their relationship to our results."}], "references": [{"title": "Recent results in analyzing the performance of heuristic search", "author": ["T. Breyer", "R. Korf"], "venue": "In Proceedings of the First International Workshop on Search in Artificial Intelligence and Robotics (held in conjunction with AAAI),", "citeRegEx": "Breyer and Korf,? \\Q2008\\E", "shortCiteRegEx": "Breyer and Korf", "year": 2008}, {"title": "High-performance A* search using rapidly growing heuristics", "author": ["S.V. Chenoweth", "H.W. Davis"], "venue": "In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence", "citeRegEx": "Chenoweth and Davis,? \\Q1991\\E", "shortCiteRegEx": "Chenoweth and Davis", "year": 1991}, {"title": "Efficiently searching the 15-puzzle", "author": ["J.C. Culberson", "J. Schaeffer"], "venue": "Tech. rep. 94-08,", "citeRegEx": "Culberson and Schaeffer,? \\Q1994\\E", "shortCiteRegEx": "Culberson and Schaeffer", "year": 1994}, {"title": "On the value of good advice: The complexity of A* search with accurate heuristics", "author": ["H.T. Dinh", "A. Russell", "Y. Su"], "venue": "In Proceedings of the Twenty-Second Conference on Artificial Intelligence", "citeRegEx": "Dinh et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dinh et al\\.", "year": 2007}, {"title": "Planning with pattern databases", "author": ["S. Edelkamp"], "venue": "In Proceedings of the 6th European Conference on Planning (ECP-01),", "citeRegEx": "Edelkamp,? \\Q2001\\E", "shortCiteRegEx": "Edelkamp", "year": 2001}, {"title": "Prediction of regular search tree growth by spectral analysis", "author": ["S. Edelkamp"], "venue": "In Advances in Artificial Intelligence, Joint German/Austrian Conference on AI,", "citeRegEx": "Edelkamp,? \\Q2001\\E", "shortCiteRegEx": "Edelkamp", "year": 2001}, {"title": "Additive pattern database heuristics", "author": ["A. Felner", "R.E. Korf", "S. Hanan"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Felner et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Felner et al\\.", "year": 2004}, {"title": "Compressed pattern databases", "author": ["A. Felner", "R.E. Korf", "R. Meshulam", "R.C. Holte"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Felner et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Felner et al\\.", "year": 2007}, {"title": "Dual lookups in pattern databases", "author": ["A. Felner", "U. Zahavi", "J. Schaeffer", "R.C. Holte"], "venue": "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence", "citeRegEx": "Felner et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Felner et al\\.", "year": 2005}, {"title": "Performance Measurement and Analysis of Certain Search Algorithms", "author": ["J. Gaschnig"], "venue": "Ph.D. thesis,", "citeRegEx": "Gaschnig,? \\Q1979\\E", "shortCiteRegEx": "Gaschnig", "year": 1979}, {"title": "A formal basis for the heuristic determination of minimum cost paths", "author": ["P.E. Hart", "N.J. Nilsson", "B. Raphael"], "venue": "IEEE Transactions on Systems Science and Cybernetics,", "citeRegEx": "Hart et al\\.,? \\Q1968\\E", "shortCiteRegEx": "Hart et al\\.", "year": 1968}, {"title": "How good is almost perfect", "author": ["M. Helmert", "G. R\u00f6ger"], "venue": "In Proceedings of the Twenty-Third Conference on Artificial Intelligence", "citeRegEx": "Helmert and R\u00f6ger,? \\Q2008\\E", "shortCiteRegEx": "Helmert and R\u00f6ger", "year": 2008}, {"title": "Maximizing over multiple pattern databases speeds up heuristic search", "author": ["R.C. Holte", "A. Felner", "J. Newton", "R. Meshulam", "D. Furcy"], "venue": "Artificial Intelligence,", "citeRegEx": "Holte et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Holte et al\\.", "year": 2006}, {"title": "Steps towards the automatic creation of search heuristics", "author": ["R.C. Holte", "I.T. Hern\u00e1dv\u00f6lgyi"], "venue": "Tech. rep. TR04-02,", "citeRegEx": "Holte and Hern\u00e1dv\u00f6lgyi,? \\Q2004\\E", "shortCiteRegEx": "Holte and Hern\u00e1dv\u00f6lgyi", "year": 2004}, {"title": "Probabilistic analysis of the complexity of A", "author": ["N. Huyn", "R. Dechter", "J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "Huyn et al\\.,? \\Q1980\\E", "shortCiteRegEx": "Huyn et al\\.", "year": 1980}, {"title": "Searching for an optimal path in a tree with random costs", "author": ["R.M. Karp", "J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "Karp and Pearl,? \\Q1983\\E", "shortCiteRegEx": "Karp and Pearl", "year": 1983}, {"title": "Depth-first iterative-deepening: An optimal admissible tree search", "author": ["R.E. Korf"], "venue": "Artificial Intelligence,", "citeRegEx": "Korf,? \\Q1985\\E", "shortCiteRegEx": "Korf", "year": 1985}, {"title": "Finding optimal solutions to Rubik\u2019s Cube using pattern databases", "author": ["R.E. Korf"], "venue": "In Proceedings of the Fourteenth Conference on Artificial Intelligence", "citeRegEx": "Korf,? \\Q1997\\E", "shortCiteRegEx": "Korf", "year": 1997}, {"title": "Analyzing the performance of pattern database heuristics", "author": ["R.E. Korf"], "venue": "In Proceedings of the Twenty-Second Conference on Artificial Intelligence", "citeRegEx": "Korf,? \\Q2007\\E", "shortCiteRegEx": "Korf", "year": 2007}, {"title": "Disjoint pattern database heuristics", "author": ["R.E. Korf", "A. Felner"], "venue": "Artificial Intelligence,", "citeRegEx": "Korf and Felner,? \\Q2002\\E", "shortCiteRegEx": "Korf and Felner", "year": 2002}, {"title": "Complexity analysis of admissible heuristic search", "author": ["R.E. Korf", "M. Reid"], "venue": "In Proceedings of the Fifteenth Conference on Artificial Intelligence", "citeRegEx": "Korf and Reid,? \\Q1998\\E", "shortCiteRegEx": "Korf and Reid", "year": 1998}, {"title": "On the complexity of admissible search algorithms", "author": ["A. Martelli"], "venue": "Artificial Intelligence,", "citeRegEx": "Martelli,? \\Q1977\\E", "shortCiteRegEx": "Martelli", "year": 1977}, {"title": "An expected-cost analysis of backtracking and non-backtracking algorithms", "author": ["C.J.H. McDiarmid", "G.M. Provan"], "venue": "In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence", "citeRegEx": "McDiarmid and Provan,? \\Q1991\\E", "shortCiteRegEx": "McDiarmid and Provan", "year": 1991}, {"title": "Memory-efficient A* heuristics for multiple sequence alignment", "author": ["M. McNaughton", "P. Lu", "J. Schaeffer", "D. Szafron"], "venue": "In Proceedings of the Eighteenth Conference on Artificial Intelligence", "citeRegEx": "McNaughton et al\\.,? \\Q2002\\E", "shortCiteRegEx": "McNaughton et al\\.", "year": 2002}, {"title": "A heuristic search algorithm with modifiable estimate", "author": ["L. M\u00e9ro"], "venue": "Artificial Intelligence,", "citeRegEx": "M\u00e9ro,? \\Q1984\\E", "shortCiteRegEx": "M\u00e9ro", "year": 1984}, {"title": "Heuristics: Intelligent Search Strategies for Computer Problem Solving", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1984\\E", "shortCiteRegEx": "Pearl", "year": 1984}, {"title": "Heuristic search viewed as path finding in a graph", "author": ["I. Pohl"], "venue": "Artificial Intelligence,", "citeRegEx": "Pohl,? \\Q1970\\E", "shortCiteRegEx": "Pohl", "year": 1970}, {"title": "Practical and theoretical considerations in heuristic search algorithms", "author": ["I. Pohl"], "venue": "Machine Intelligence,", "citeRegEx": "Pohl,? \\Q1977\\E", "shortCiteRegEx": "Pohl", "year": 1977}, {"title": "Finding a shortest solution for the n \u00d7 n extension of the 15-puzzle is intractable", "author": ["D. Ratner", "M.K. Warmuth"], "venue": "In Proceedings of the Fifth Conference on Artificial Intelligence", "citeRegEx": "Ratner and Warmuth,? \\Q1986\\E", "shortCiteRegEx": "Ratner and Warmuth", "year": 1986}, {"title": "Adaptive Tree Search", "author": ["W. Ruml"], "venue": "Ph.D. thesis,", "citeRegEx": "Ruml,? \\Q2002\\E", "shortCiteRegEx": "Ruml", "year": 2002}, {"title": "Average-case analysis of best-first search in two representative directed acyclic graphs", "author": ["A.K. Sen", "A. Bagchi", "W. Zhang"], "venue": "Artificial Intelligence,", "citeRegEx": "Sen et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Sen et al\\.", "year": 2004}, {"title": "Predicting the performance of IDA* with conditional distributions", "author": ["U. Zahavi", "A. Felner", "N. Burch", "R.C. Holte"], "venue": "In Proceedings of the Twenty-Third Conference on Artificial Intelligence", "citeRegEx": "Zahavi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zahavi et al\\.", "year": 2008}, {"title": "Dual search in permutation state spaces", "author": ["U. Zahavi", "A. Felner", "R. Holte", "J. Schaeffer"], "venue": "In Proceedings of the Twenty-First Conference on Artificial Intelligence", "citeRegEx": "Zahavi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zahavi et al\\.", "year": 2006}, {"title": "Duality in permutation state spaces and the dual search algorithm", "author": ["U. Zahavi", "A. Felner", "R.C. Holte", "J. Schaeffer"], "venue": "Artificial Intelligence,", "citeRegEx": "Zahavi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zahavi et al\\.", "year": 2008}, {"title": "Space-efficient memory-based heuristics", "author": ["R. Zhou", "E.A. Hansen"], "venue": "In Proceedings of the Nineteenth Conference on Artificial Intelligence", "citeRegEx": "Zhou and Hansen,? \\Q2004\\E", "shortCiteRegEx": "Zhou and Hansen", "year": 2004}], "referenceMentions": [{"referenceID": 16, "context": "Heuristic search algorithms such as A* (Hart, Nilsson, & Raphael, 1968) and IDA* (Korf, 1985) are guided by the cost function f(n) = g(n)+h(n), where g(n) is the actual distance from the start state to state n and h(n) is a heuristic function estimating the cost from n to the nearest goal state.", "startOffset": 81, "endOffset": 93}, {"referenceID": 17, "context": "Prior to KRE, the standard method for comparing two heuristic functions was to compare their average values, with preference being given to the heuristic with the larger average (Korf, 1997; Korf & Felner, 2002; Felner, Korf, Meshulam, & Holte, 2007).", "startOffset": 178, "endOffset": 250}, {"referenceID": 8, "context": "Finally, we adapt CDP to make predictions when IDA* is augmented with the bidirectional pathmax method (BPMX) (Felner et al., 2005).", "startOffset": 110, "endOffset": 131}, {"referenceID": 17, "context": "34847 (Korf, 1997).", "startOffset": 6, "endOffset": 18}, {"referenceID": 16, "context": "2 Iterative Deepening A* Iterative deepening A* (IDA*) (Korf, 1985) performs a series of depth-first searches, increasing a cost threshold d each time.", "startOffset": 55, "endOffset": 67}, {"referenceID": 17, "context": "Pattern databases have proven very useful for finding lower bounds for combinatorial puzzles (Korf, 1997; Culberson & Schaeffer, 1998; Korf & Felner, 2002; Felner, Korf, & Hanan, 2004; Felner et al., 2007).", "startOffset": 93, "endOffset": 205}, {"referenceID": 7, "context": "Pattern databases have proven very useful for finding lower bounds for combinatorial puzzles (Korf, 1997; Culberson & Schaeffer, 1998; Korf & Felner, 2002; Felner, Korf, & Hanan, 2004; Felner et al., 2007).", "startOffset": 93, "endOffset": 205}, {"referenceID": 8, "context": "An exact definition and explanations about the dual lookup is provided in the original papers (Felner et al., 2005; Zahavi et al., 2006, 2008).", "startOffset": 94, "endOffset": 142}, {"referenceID": 8, "context": "This propagation technique is called bidirectional pathmax (BPMX) (Felner et al., 2005; Zahavi et al., 2007).", "startOffset": 66, "endOffset": 108}, {"referenceID": 24, "context": "1 Bidirectional Pathmax (BPMX) Traditional pathmax (M\u00e9ro, 1984) propagates heuristic values from a parent to its children, and can be applied in any state space.", "startOffset": 51, "endOffset": 63}, {"referenceID": 27, "context": "Many other papers in this line have appeared since (Pohl, 1977; Gaschnig, 1979; Huyn, Dechter, & Pearl, 1980; Karp & Pearl, 1983; Pearl, 1984; Chenoweth & Davis, 1991; McDiarmid & Provan, 1991; Sen, Bagchi, & Zhang, 2004; Dinh, Russell, & Su, 2007; Helmert & R\u00f6ger, 2008).", "startOffset": 51, "endOffset": 271}, {"referenceID": 9, "context": "Many other papers in this line have appeared since (Pohl, 1977; Gaschnig, 1979; Huyn, Dechter, & Pearl, 1980; Karp & Pearl, 1983; Pearl, 1984; Chenoweth & Davis, 1991; McDiarmid & Provan, 1991; Sen, Bagchi, & Zhang, 2004; Dinh, Russell, & Su, 2007; Helmert & R\u00f6ger, 2008).", "startOffset": 51, "endOffset": 271}, {"referenceID": 25, "context": "Many other papers in this line have appeared since (Pohl, 1977; Gaschnig, 1979; Huyn, Dechter, & Pearl, 1980; Karp & Pearl, 1983; Pearl, 1984; Chenoweth & Davis, 1991; McDiarmid & Provan, 1991; Sen, Bagchi, & Zhang, 2004; Dinh, Russell, & Su, 2007; Helmert & R\u00f6ger, 2008).", "startOffset": 51, "endOffset": 271}, {"referenceID": 27, "context": "They found that if the relative error, |h(n)\u2212h \u2217(n)| h(n) , is constant, the search complexity will be exponential (in the length of solution path) but if the absolute error, |h(n) \u2212 h\u2217(n)|, is bounded by a constant the search complexity is linear (Pohl, 1977; Gaschnig, 1979).", "startOffset": 248, "endOffset": 276}, {"referenceID": 9, "context": "They found that if the relative error, |h(n)\u2212h \u2217(n)| h(n) , is constant, the search complexity will be exponential (in the length of solution path) but if the absolute error, |h(n) \u2212 h\u2217(n)|, is bounded by a constant the search complexity is linear (Pohl, 1977; Gaschnig, 1979).", "startOffset": 248, "endOffset": 276}, {"referenceID": 14, "context": "Since it is difficult to guarantee precise bounds on the magnitude of errors produced by a given heuristic, a probabilistic characterization of these magnitudes was suggested (Huyn et al., 1980; Pearl, 1984).", "startOffset": 175, "endOffset": 207}, {"referenceID": 25, "context": "Since it is difficult to guarantee precise bounds on the magnitude of errors produced by a given heuristic, a probabilistic characterization of these magnitudes was suggested (Huyn et al., 1980; Pearl, 1984).", "startOffset": 175, "endOffset": 207}, {"referenceID": 22, "context": "The first analysis in this line, focusing on the effect of errors on the performance of search algorithms, was done by Pohl (1970). Many other papers in this line have appeared since (Pohl, 1977; Gaschnig, 1979; Huyn, Dechter, & Pearl, 1980; Karp & Pearl, 1983; Pearl, 1984; Chenoweth & Davis, 1991; McDiarmid & Provan, 1991; Sen, Bagchi, & Zhang, 2004; Dinh, Russell, & Su, 2007; Helmert & R\u00f6ger, 2008).", "startOffset": 119, "endOffset": 131}, {"referenceID": 8, "context": "Many other papers in this line have appeared since (Pohl, 1977; Gaschnig, 1979; Huyn, Dechter, & Pearl, 1980; Karp & Pearl, 1983; Pearl, 1984; Chenoweth & Davis, 1991; McDiarmid & Provan, 1991; Sen, Bagchi, & Zhang, 2004; Dinh, Russell, & Su, 2007; Helmert & R\u00f6ger, 2008). These works usually assume an abstract model space of a tree where every node has exactly b children and aim to provide the asymptotic estimation for the number of expanded nodes. They mainly differ by the model assumptions (e.g. binary or non-binary trees) and for what case the results are derived (worst case or average case). Worst case analysis showed that there is a correlation between the heuristic errors and the search complexity. They found that if the relative error, |h(n)\u2212h \u2217(n)| h(n) , is constant, the search complexity will be exponential (in the length of solution path) but if the absolute error, |h(n) \u2212 h\u2217(n)|, is bounded by a constant the search complexity is linear (Pohl, 1977; Gaschnig, 1979). Three main assumptions used by Pohl (1977) are that the branching factor is assumed to be constant across inputs, that there is a single goal state and that there are no transpositions in the search space.", "startOffset": 64, "endOffset": 1035}, {"referenceID": 1, "context": "Additional research in this line was conducted by Chenoweth and Davis (1991). Instead of using the IID model, they suggested using the \u201cNC model\u201d, which places no constraints on the errors of h.", "startOffset": 50, "endOffset": 77}, {"referenceID": 29, "context": "By contrast, Sen et al. (2004) presented a general technique for extending the analysis of the average case performance of A* from search spaces that are trees to search spaces that are directed acyclic graphs.", "startOffset": 13, "endOffset": 31}, {"referenceID": 3, "context": "Recent research in this line, analyzing the complexity of the A* algorithm was presented by Dinh et al. (2007). This research presented both worst and average case analysis for the performance of A* for approximately accurate heuristics8 for search problems with multiple solutions.", "startOffset": 92, "endOffset": 111}, {"referenceID": 29, "context": "The calculation of Ni in this more general setting has been studied in detail by Ruml, in a slightly different context (Ruml, 2002).", "startOffset": 119, "endOffset": 131}, {"referenceID": 18, "context": "Based on the work of KRE and on the insight that for PDB heuristics there is a correlation between the size of the PDB and its heuristic value distribution, a new analysis limited to PDB heuristics has been done (Korf, 2007; Breyer & Korf, 2008).", "startOffset": 212, "endOffset": 245}, {"referenceID": 21, "context": "Indeed, in the worst case, for every state A* will enumerate all the paths to the state in decreasing order of cost, thereby generating exactly the same search tree as IDA* (Martelli, 1977).", "startOffset": 173, "endOffset": 189}, {"referenceID": 17, "context": "Korf used in his seminal work on this domain(Korf, 1997).", "startOffset": 44, "endOffset": 56}], "year": 2010, "abstractText": "Korf, Reid, and Edelkamp introduced a formula to predict the number of nodes IDA* will expand on a single iteration for a given consistent heuristic, and experimentally demonstrated that it could make very accurate predictions. In this paper we show that, in addition to requiring the heuristic to be consistent, their formula\u2019s predictions are accurate only at levels of the brute-force search tree where the heuristic values obey the unconditional distribution that they defined and then used in their formula. We then propose a new formula that works well without these requirements, i.e., it can make accurate predictions of IDA*\u2019s performance for inconsistent heuristics and if the heuristic values in any level do not obey the unconditional distribution. In order to achieve this we introduce the conditional distribution of heuristic values which is a generalization of their unconditional heuristic distribution. We also provide extensions of our formula that handle individual start states and the augmentation of IDA* with bidirectional pathmax (BPMX), a technique for propagating heuristic values when inconsistent heuristics are used. Experimental results demonstrate the accuracy of our new method and all its variations.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}