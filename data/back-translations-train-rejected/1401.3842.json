{"id": "1401.3842", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Developing Approaches for Solving a Telecommunications Feature Subscription Problem", "abstract": "Call control features (e.g., call-divert, voice-mail) are primitive options to which users can subscribe off-line to personalise their service. The configuration of a feature subscription involves choosing and sequencing features from a catalogue and is subject to constraints that prevent undesirable feature interactions at run-time. When the subscription requested by a user is inconsistent, one problem is to find an optimal relaxation, which is a generalisation of the feedback vertex set problem on directed graphs, and thus it is an NP-hard task. We present several constraint programming formulations of the problem. We also present formulations using partial weighted maximum Boolean satisfiability and mixed integer linear programming. We study all these formulations by experimentally comparing them on a variety of randomly generated instances of the feature subscription problem.", "histories": [["v1", "Thu, 16 Jan 2014 04:54:27 GMT  (356kb)", "http://arxiv.org/abs/1401.3842v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["david lesaint", "deepak mehta", "barry o'sullivan", "luis quesada", "nic wilson"], "accepted": false, "id": "1401.3842"}, "pdf": {"name": "1401.3842.pdf", "metadata": {"source": "CRF", "title": "Developing Approaches for Solving a Telecommunications Feature Subscription Problem", "authors": ["David Lesaint", "Deepak Mehta", "Barry O\u2019Sullivan", "Luis Quesada", "Nic Wilson"], "emails": ["david.lesaint@bt.com", "d.mehta@4c.ucc.ie", "b.osullivan@4c.ucc.ie", "l.quesada@4c.ucc.ie", "n.wilson@4c.ucc.ie"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them are able to survive on their own and on their own."}, {"heading": "2. Background", "text": "In this section, we present a number of concepts on binary relationships and constraints that will be used in the next sections."}, {"heading": "2.1 Binary Relations", "text": "A binary relationship over a finite set X is an association of elements of X with elements of X. Let R have a binary relationship over a finite set X. A relationship R over a finite set X is irreflexive if and only if there is no x-X relationship, so < x, x > x R. A relationship R on a set X is transitive if and only if for all x, y and z in X, [< x, y > x]. The transitive closure of a binary relationship R on a set X is the smallest transitive relationship on a set X, the R. We use the notation R & \u043c to denote the transitive closure of a relationship R on a set X. A relationship R on a set X is asymmetric if and only if for all x, y in X, [< x, y > x] is a transitive relationship."}, {"heading": "2.2 Constraint Programming", "text": "In fact, most of them will be able to abide by the rules that they have applied in practice."}, {"heading": "3. Configuring Feature Subscriptions", "text": "In fact, most of us will be able to move to another world in which we are able, in which we are able to move, and in which we are able to change the world."}, {"heading": "4. Reformulating the Original Definition of Feature Subscription", "text": "< F > \"s\" s \"s\" s \"s. < F\" s \"s\" s \"s\" s \"s. < F\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s. < F\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. < F \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. < F \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\""}, {"heading": "5. Symmetry Inherent in the Reformulation", "text": "[1] In this section, if a full subscription as defined in Section 3 is a full subscription of two full subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription-subscription"}, {"heading": "6. Relaxations of Feature Subscriptions", "text": "If such a subscription is not consistent, then the goal is to relax it by dropping one or more features or user preferences to generate a consistent subscription that comes closest to the original user needs. Therefore, we could introduce a feature w: F: P \u2192 N that assigns weights of features and user preferences, indicating the meaning of features and user preferences. The meaning of the S subscription is generated directly by data collection or analysis of user interactions. In the rest of the paper, a subscription is defined by S = < F, P, W, W."}, {"heading": "7. Basic COP Model for Finding an Optimal Relaxation", "text": "In this section we present the problematic of an optimal relationship of the subscriptions. (F, H, P, W > the subscriptions < Fc, Hc > like the subscriptions of the subscriptions.) The subscriptions of the subscriptions are only possible if the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the subscriptions of the"}, {"heading": "7.1 Arc Consistency", "text": "Let's be the sum of the number of user preferences and the number of catalog preferences, let's be n the sum of the number of attributes and the number of user preferences, and let's be d the number of attributes. The complexity of achieving arc consistency (ac) on a (catalog / user) preference constraint is constant in relation to the number of variables. A catalog preference constraint can be made arc consistent if one of the boolean variables involved in the constraint is initialized or one of the domains of the position variables is modified. Thus, a catalog preference constraint can be made arc consistent at most (1 + 1 + (d \u2212 1) + (d \u2212 1)) times, which is effectively 2d times."}, {"heading": "7.2 Singleton Arc Consistency", "text": "Maintaining a higher level of consistency can be time-consuming, but if more values can be removed from the domains of variables, the search effort can be overeduced and this can save time. We will study the effects of maintaining the singleton arc consistency (sac) on the Boolean variables and ac on the remaining variables and label them with sac-1. We have used the sac-1 (Debruyne & Bessiere, 1997) algorithm for enforcing sac on the Boolean variables. Enforcing sac on the Boolean variables works in a sac-1 manner by traversing a list of 2n variable-value pairs. For each instantiation of a Boolean variable x on each value 0 / 1, if there is a domain wipe-out, while enforcing ac then the value of ac then the corresponding domain and ac is not enforced."}, {"heading": "7.3 Restricted Singleton Arc Consistency", "text": "The main problem with sac-1 is that deleting a single value retrieves the loop. Restricted Singleton Arc Consistency (rsac) avoids this by looking at each variable-value pair only once (Prosser, Stergiou, & Walsh, 2000). We examine the effects of enforcement (rsac) on the Boolean variables and ac on the remaining variables, labeling them rsacb. the worst time complexity of rsacb is O (n (e d + n2))."}, {"heading": "8. Other CP Models", "text": "In this section, we present two other cp approaches: The first approach uses a global constraint that achieves a higher level of consistency by taking into account the cycles of priority constraints; the second approach models the problem as a weighted constraint satisfaction problem."}, {"heading": "8.1 Global Constraint", "text": "It takes a look at the structure of the problem to get more values. (...) If a user has selected a set of attributes, then one can conclude that the problem is inconsistent without doing any searching. (...) This is possible by deriving the boundaries of objective functionality from the precedent cases 1, 2, 3, 4 and 4. (...) The soft global precedence Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection Connection"}, {"heading": "8.2 Weighted CSP Model", "text": "The classical csp system has been extended by associating each variable and each function with costs. (i) The classical csp system has been extended by associating each variable with costs. (i.) The csp system has been expanded. (i.) The csp system has been expanded by defining a specific rating structure S (i.) when it is either a strictly positive natural number or an infinity. (i.) The csp system is a set of natural materials that are less than or equal. (i.) The csp system is the sum of the rating structure defined as: a). (i.) The csp system is either a strictly positive natural number or an infinity. (i.) The csp system is defined as the sum of the rating structure defined as: a). (i. (i.) The wcsp instance is defined by a rating structure S (k), a set of variable constraints (such as a series of classical instances) and a set of constraints."}, {"heading": "9. Boolean Satisfiability", "text": "The Boolean satisfaction problem (sat) is a decision problem, the example of which is an expression in the propositional logic. The problem is to decide whether to assign true and false values to the variables that make the expression true. Normally, the expression is written in conjunctive normal form. The partially weighted maximum Boolean satisfaction problem (pwmsat) is an extension of sat that includes the terms hard and soft clauses. Any solution should respect the hard clauses. Soft clauses are associated with weights. The goal is to find an assignment that meets all the hard clauses and minimizes the sum of the weights of the dissatisfied soft clauses. In this section, we present Boolean satisfaction formulations to find the optimal relaxation of a feature subscription."}, {"heading": "9.1 Atom-based Encoding", "text": "It is only a matter of time before a decision is reached as to whether it is a decision taken in the USA, in Europe, in the USA, in Europe, in the USA, in the USA, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in"}, {"heading": "9.2 Symbol-based Encoding", "text": "Another approach based on a symbol-based encoding of subordination constraints is presented by Codish et al. (2009). (& \u00ac) Subordination constraints (Codish, Lagoon, & Stuckey, 2008) are basically propositional formulas, except that sentences can also be statements about a subordination on a finite set of symbols. In a symbol-based encoding of transitivity and asymmetricity properties of a precedent relationship, implicitly enforced, a Boolean variable bfi is also associated with each attribute i-F. It indicates whether i is included or excluded. A Boolean variable bpij is associated with each precedent relationship. Given a function g (n), a precedent relationship (g)))) denotes the set of functions f (n) so that there are positive constants c1, c2, and n0."}, {"heading": "9.2.1 Unary Encoding", "text": "< < < < and mk + 1, a clause < >. < and mk + 1, a clause < >. < and mk + 1, a clause < >. < and mk + 1, a clause < >. < and mk + 1, a clause < >. < and mk + 1, a clause < >. < and a clause < >. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. & lt. &. &. & lt. & lt. & lt. &. & lt. & &. & &. & & &. & & lt. & &. &. &. & &. & &. & & &. &. & & &. &. & & &. &. &. &. & &. & &. & &. & &. & & &. &. & &. & & & &. & &. & & &. & & &. &. & & & & &. &"}, {"heading": "9.2.2 Binary Encoding", "text": "In symbol-based binary encoding, each attribute is associated with an ordered set of Boolean variables that represents the binary log encoding of its place.The binary encoding-2. Ji \u2022 jK is a Boolean formula that is satisfactory only if i precedes j.ing with a non-negative integer a \u2264 n is a value sequence assigned to k variables v1,... vk, where k = dlog2 ne. The value of such a representation is 1 \u2264 m \u2264 k 2k \u2212 m \u00b7 vm. For example, the sequence 101 represents the number 5 using 3 variables. A precedence constraint is encoded using a lexicographic comparator (Apt, 2003). In the face of two numbers in binary encoded form < i1,."}, {"heading": "9.3 Comparison of the Encodings", "text": "The question of the way in which they relate to the question of the way in which they relate to the question of the way in which they relate to the question of the way in which they relate to the question of the way in which they relate to the question of the way in which they relate to the question of the way in which they relate to the question of the way in which they relate to the question of the way in which they relate to the question of the way in which they relate to the way in which they relate to the question of the way in which they relate to the way in which they relate to the way in which they relate to the way in which they relate to the way in which they relate to the way in which they relate to the way in which they relate to the question of the way in which they relate to the way in which they relate to the question of the way in which they relate to the question relates to the way in which they relate to the question of the way in which they relate to the question relate to the way in which they relate to the question of the way they relate to the way in which they relate to the question of the way they relate to the way in which they relate to the question of the way in which they relate to the way they relate to the question of the way in which they relate to the question of the way they relate to the way in which they relate to the way in which they relate to the way in which they relate to the question of the question of the way in which they relate to the way they relate to the question of the way in which they relate to the way in which they relate to the question of the way in which they relate to the question of the way they relate to the way in which they relate to the question of the way in which they relate to the question of the way in which they relate to the question in which they relate to the question relate to the way in which they relate to the question in which they relate to the question relate to the way in which they relate to the question in which they relate to the question in which they relate to the question of the way in which they relate to the question of the question of the way in which they relate"}, {"heading": "10. Mixed Integer Linear Programming", "text": "If some variables are forced to be evaluated integer, the problem is referred to as the Mixed Integer Linear Programming (mip) problem. If there are only 2 attributes, the clauses underlying Ji in seb will be inconsistent, in which case the inconsistency can be detected to some extent. However, if there are only 2 attributes, the clauses underlying Ji in seb will be optimized by the representation of the function, the linear constraints to be respected, and the domain of the variables involved. Both basic cop formulations and the atom-based pwmsat formulation for seeking an optimal relativization of a function < F, H, P, w > can be translated into a Mip formulation."}, {"heading": "11. Experimental Results", "text": "In this section we will describe the empirical evaluation of the search for optimal relaxation of randomly generated feature subscriptions using constraint programming, partially weighted maximum Boolean satisfaction, and integer linear programming."}, {"heading": "11.1 Problem Generation and Experimental Settings", "text": "< < fc, Bc, Tc >. These are the number of attributes, Bc is the number of attributes, Bc is the number of binary constraints, and Tc is the number of types of constraints. Note that i-j means that in a given subscription, both attributes i and j cannot exist together. A random catalog is created by randomly selecting Bc pairs of attributes from fc (fc \u2212 1) / 2 pairs of attributes. Each selected pair of attributes is then associated with a type of constraint randomly selected from Tc. A random catalog is generated by randomly selecting Bc pairs of attributes (fc \u2212 1) / 2 pairs of attributes."}, {"heading": "11.2 Evaluation of Constraint Programming Formulations", "text": "This year it is more than ever before."}, {"heading": "11.3 Evaluation of the Boolean Satisfiability Formulations", "text": "The idea behind it is that the idea is about a project, which is about a project, which is about a project, which is about a project, which is primarily about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a project, which is about a"}, {"heading": "11.4 Comparison between CP, SAT and MIP-based approaches", "text": "In fact, it is true that this is a type and manner in which most people are in a position to transfer to the world in which they want to live. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "12. Conclusions and Future Work", "text": "This year, it has come to the point that it will only be a matter of time before it is ready, until it is ready."}, {"heading": "Acknowledgments", "text": "This material is based on work supported by Science Foundation Ireland under grants no. 05 / IN / I886, 08 / PI / I1912 and Embark Post Doctoral Fellowships no. CT1080049908 and no. CT1080049909. Authors would like to thank Hadrien Cambazard, Daniel Le Berre and Alan Holland for their support in using choco, sat4j and cplex respectively. Authors would like to thank Simon de Givry for his help in formulating the problem. Also, Michael Codish for providing the symbol-based coding instances to Daniel Le Berre. We thank all reviewers for valuable comments that have helped us improve the quality of the work."}], "references": [{"title": "Principles of Constraint Programming", "author": ["K. Apt"], "venue": null, "citeRegEx": "Apt,? \\Q2003\\E", "shortCiteRegEx": "Apt", "year": 2003}, {"title": "Optimal and suboptimal singleton arc consistency algorithms", "author": ["C. Bessiere", "R. Debruyne"], "venue": "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI", "citeRegEx": "Bessiere and Debruyne,? \\Q2004\\E", "shortCiteRegEx": "Bessiere and Debruyne", "year": 2004}, {"title": "MAC and combined heuristics: Two reasons to forsake FC (and cbj?) on hard problems", "author": ["C. Bessiere", "Regin", "J.-C"], "venue": "In Proceedings of the Second International Conference on Principles and Practice of Constraint Programming (CP", "citeRegEx": "Bessiere et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Bessiere et al\\.", "year": 1996}, {"title": "Domain filtering consistencies for non-binary constraints", "author": ["C. Bessiere", "K. Stergiou", "T. Walsh"], "venue": "Artificial Intelligence,", "citeRegEx": "Bessiere et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bessiere et al\\.", "year": 2008}, {"title": "An Open Architecture for Next-Generation Telecommunication Services", "author": ["G.W. Bond", "E. Cheung", "H. Purdy", "P. Zave", "C. Ramming"], "venue": "ACM Transactions on Internet Technology,", "citeRegEx": "Bond et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bond et al\\.", "year": 2004}, {"title": "Boosting systematic search by weighting constraints", "author": ["F. Boussemart", "F. Hemery", "C. Lecoutre", "L. Sais"], "venue": "Proceedings of the 16th European Conference on Artificial Intelligence (ECAI", "citeRegEx": "Boussemart et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Boussemart et al\\.", "year": 2004}, {"title": "Feature Interaction: A Critical Review and Considered Forecast", "author": ["M. Calder", "M. Kolberg", "E.H. Magill", "S. Reiff-Marganiec"], "venue": "Computer Networks,", "citeRegEx": "Calder et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Calder et al\\.", "year": 2003}, {"title": "Telecommunications feature subscription as a partial order constraint problem", "author": ["M. Codish", "V. Lagoon", "P.J. Stuckey"], "venue": "In Proceedings of the 24th International Conference on Logic Programming (ICLP", "citeRegEx": "Codish et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Codish et al\\.", "year": 2008}, {"title": "A declarative encoding of telecommunications feature subscription in SAT", "author": ["M. Codish", "S. Genaim", "P. Stuckey"], "venue": "In Proceedings of the 11th ACM SIGPLAN conference on Principles and practice of declarative programming (PPDP", "citeRegEx": "Codish et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Codish et al\\.", "year": 2009}, {"title": "Logic programming with satisfiability", "author": ["M. Codish", "V. Lagoon", "P. Stuckey"], "venue": "Theory and Practice of Logic Programming,", "citeRegEx": "Codish et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Codish et al\\.", "year": 2008}, {"title": "Introduction to Algorithms", "author": ["T. Cormen", "C. Leiserson", "R. Rivest"], "venue": null, "citeRegEx": "Cormen et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Cormen et al\\.", "year": 1990}, {"title": "Solving max-sat as weighted csp", "author": ["S. de Givry", "J. Larrosa", "P. Meseguer", "T. Schiex"], "venue": null, "citeRegEx": "Givry et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Givry et al\\.", "year": 2003}, {"title": "Some practical filtering techniques for the constraint satifaction problem", "author": ["R. Debruyne", "C. Bessiere"], "venue": "In Proceedings of the 15th International Joint Conference on Artificial Intelligence (IJCAI", "citeRegEx": "Debruyne and Bessiere,? \\Q1997\\E", "shortCiteRegEx": "Debruyne and Bessiere", "year": 1997}, {"title": "An extensible SAT-solver", "author": ["N. E\u00e9n", "N. S\u00f6rensson"], "venue": "In Proceedings of the Sixth International Conference on Theory and Applications of Satisfiability Testing (SAT", "citeRegEx": "E\u00e9n and S\u00f6rensson,? \\Q2003\\E", "shortCiteRegEx": "E\u00e9n and S\u00f6rensson", "year": 2003}, {"title": "Translating pseudo-boolean constraints into SAT", "author": ["N. E\u00e9n", "N. S\u00f6rensson"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation (JSAT),", "citeRegEx": "E\u00e9n and S\u00f6rensson,? \\Q2006\\E", "shortCiteRegEx": "E\u00e9n and S\u00f6rensson", "year": 2006}, {"title": "Feedback set problems", "author": ["P. Festa", "P. Pardalos", "M. Resende"], "venue": "Tech. rep. 99.2.2,", "citeRegEx": "Festa et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Festa et al\\.", "year": 1999}, {"title": "The footprint sorting problem", "author": ["C. Fried", "W. Hordijk", "S. Prohaska", "C. Stadler", "P. Stadler"], "venue": "Journal of Chemical Information and Modeling,", "citeRegEx": "Fried et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Fried et al\\.", "year": 2004}, {"title": "Computers and Intractability: A Guide to the The Theory of NP-Completeness", "author": ["M. Garey", "D. Johnson"], "venue": null, "citeRegEx": "Garey and Johnson,? \\Q1979\\E", "shortCiteRegEx": "Garey and Johnson", "year": 1979}, {"title": "The conflict-driven answer set solver clasp: Progress report", "author": ["M. Gebser", "B. Kaufmann", "T. Schaub"], "venue": "In Proceedings of the 10th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR", "citeRegEx": "Gebser et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gebser et al\\.", "year": 2009}, {"title": "Distributed Feature Composition: a Virtual Architecture for Telecommunications Services", "author": ["M. Jackson", "P. Zave"], "venue": "IEEE Transactions on Software Engineering (TSE),", "citeRegEx": "Jackson and Zave,? \\Q1998\\E", "shortCiteRegEx": "Jackson and Zave", "year": 1998}, {"title": "Node and arc consistency in weighted CSP", "author": ["J. Larrosa"], "venue": "In Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI", "citeRegEx": "Larrosa,? \\Q2002\\E", "shortCiteRegEx": "Larrosa", "year": 2002}, {"title": "Maintaining singleton arc consistency", "author": ["C. Lecoutre", "P. Patrick"], "venue": "In Proceedings of the 3rd International Workshop on Constraint Propagation And Implementation", "citeRegEx": "Lecoutre and Patrick,? \\Q2006\\E", "shortCiteRegEx": "Lecoutre and Patrick", "year": 2006}, {"title": "Constraint Networks: Techniques and Algorithms", "author": ["C. Lecoutre"], "venue": null, "citeRegEx": "Lecoutre,? \\Q2009\\E", "shortCiteRegEx": "Lecoutre", "year": 2009}, {"title": "A greedy approach to establish singleton arc consistency", "author": ["C. Lecoutre", "S. Cardon"], "venue": "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI", "citeRegEx": "Lecoutre and Cardon,? \\Q2005\\E", "shortCiteRegEx": "Lecoutre and Cardon", "year": 2005}, {"title": "A Soft Global Precedence Constraint", "author": ["D. Lesaint", "D. Mehta", "B. O\u2019Sullivan", "L. Quesada", "N. Wilson"], "venue": "In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI-09),", "citeRegEx": "Lesaint et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lesaint et al\\.", "year": 2009}, {"title": "Consistency techniques for finding an optimal relaxation of a feature subscription", "author": ["D. Lesaint", "D. Mehta", "B. O\u2019Sullivan", "L. Quesada", "N. Wilson"], "venue": "In Proceeding of the 20th IEEE International Conference on Tools with Artificial Intelligence(ICTAI", "citeRegEx": "Lesaint et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Lesaint et al\\.", "year": 2008}, {"title": "Personalisation of Telecommunications Services as Combinatorial Optimisation", "author": ["D. Lesaint", "D. Mehta", "B. O\u2019Sullivan", "L. Quesada", "N. Wilson"], "venue": "In Proceedings of The Twentieth Conference on Innovative Applications of Artificial Intelligence (IAAI", "citeRegEx": "Lesaint et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Lesaint et al\\.", "year": 2008}, {"title": "Solving a Telecommunications Feature Subscription Configuration Problem", "author": ["D. Lesaint", "D. Mehta", "B. O\u2019Sullivan", "L. Quesada", "N. Wilson"], "venue": "In Proceedings of the 14th International Conference on Principles and Practice of Constraint Programming (CP", "citeRegEx": "Lesaint et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Lesaint et al\\.", "year": 2008}, {"title": "The IMS: IP Multimedia Concepts and Services (2nd edition)", "author": ["M. Poikselka", "G. Mayer", "H. Khartabil", "A. Niemi"], "venue": null, "citeRegEx": "Poikselka et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Poikselka et al\\.", "year": 2006}, {"title": "Generating linear extensions fast", "author": ["G. Pruesse", "F. Ruskey"], "venue": "The SIAM Journal on Computing,", "citeRegEx": "Pruesse and Ruskey,? \\Q1994\\E", "shortCiteRegEx": "Pruesse and Ruskey", "year": 1994}, {"title": "SIP: Session initiation protocol RFC 3261 (proposed standard updated by RFCs", "author": ["J. Rosenberg", "H. Schulzrinne", "G. Camarillo", "A. Johnston", "J. Peterson", "R. Sparks", "M. Handley", "E. Schooler"], "venue": null, "citeRegEx": "Rosenberg et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Rosenberg et al\\.", "year": 2002}, {"title": "SIP: Basics and Beyond", "author": ["R. Sparks"], "venue": "ACM Queue,", "citeRegEx": "Sparks,? \\Q2007\\E", "shortCiteRegEx": "Sparks", "year": 2007}, {"title": "On the complexity of derivations in the propositional calculus", "author": ["G.S. Tseitin"], "venue": "Studies in Mathematics and Mathematical Logic,", "citeRegEx": "Tseitin,? \\Q1968\\E", "shortCiteRegEx": "Tseitin", "year": 1968}, {"title": "Practical applications of constraint programming", "author": ["M. Wallace"], "venue": "Constraints Journal,", "citeRegEx": "Wallace,? \\Q1996\\E", "shortCiteRegEx": "Wallace", "year": 1996}, {"title": "An Experiment in Feature Engineering", "author": ["P. Zave"], "venue": "Programming Methodology,", "citeRegEx": "Zave,? \\Q2003\\E", "shortCiteRegEx": "Zave", "year": 2003}, {"title": "Arc consistency on n-ary monotonic and linear constraints", "author": ["Y. Zhang", "R. Yap"], "venue": "In Proceedings of the 6th International Conference on Principles and Practice of Constraint Programming (CP", "citeRegEx": "Zhang and Yap,? \\Q2000\\E", "shortCiteRegEx": "Zhang and Yap", "year": 2000}], "referenceMentions": [{"referenceID": 31, "context": "The architectural style commonly found in platforms that are based on the Session Initiation Protocol (Rosenberg, Schulzrinne, Camarillo, Johnston, Peterson, Sparks, Handley, & Schooler, 2002; Sparks, 2007) notably, the Internet Multimedia Subsystem (Poikselka, Mayer, Khartabil, & Niemi, 2006), consists of chaining applications between end-points.", "startOffset": 102, "endOffset": 206}, {"referenceID": 4, "context": "Distributed Feature Composition (dfc) provides a method and a formal architecture to address feature interactions (Jackson & Zave, 1998, 2003; Bond et al., 2004).", "startOffset": 114, "endOffset": 161}, {"referenceID": 33, "context": "Constraint Programming (cp) has been successfully used in many applications such as planning, scheduling, resource allocation, routing, and bio-informatics (Wallace, 1996).", "startOffset": 156, "endOffset": 171}, {"referenceID": 34, "context": "Constraints are formulated by designers on pairs of source features and pairs of target features to prevent undesirable feature interactions (Zave, 2003).", "startOffset": 141, "endOffset": 153}, {"referenceID": 22, "context": "Following the work of Lecoutre (2009) an arc consistency algorithm is said to be incremental if and only if its worst-case time complexity is the same when it is applied once on a given network P and when it is applied up to m times on P where between any two consecutive executions, at least one value has been deleted.", "startOffset": 22, "endOffset": 38}, {"referenceID": 24, "context": "The soft global precedence constraint SoftPrec was proposed by Lesaint et al. (2008a). It holds if and only if there is a strict partial order on the selected features subject to the relevant hard (catalogue) precedence constraints and the selected soft (user) precedence constraints, and the value of the subscription is within the provided bounds.", "startOffset": 63, "endOffset": 86}, {"referenceID": 24, "context": "The soft global precedence constraint SoftPrec was proposed by Lesaint et al. (2008a). It holds if and only if there is a strict partial order on the selected features subject to the relevant hard (catalogue) precedence constraints and the selected soft (user) precedence constraints, and the value of the subscription is within the provided bounds. As shown by Lesaint et al. (2008a), achieving ac for SoftPrec is NP-complete since there is no way to determine in polynomial time whether there is a strict partial order whose value is between the given bounds.", "startOffset": 63, "endOffset": 385}, {"referenceID": 20, "context": "The classical csp framework has been extended by associating weights (or costs) with tuples (Larrosa, 2002).", "startOffset": 92, "endOffset": 107}, {"referenceID": 7, "context": "Another sat approach based on a symbol-based encoding of partial order constraints is presented by Codish et al. (2009). Partial order constraints (Codish, Lagoon, & Stuckey, 2008) are basically propositional formulae except that propositions can also be statements about a partial order on a finite set of symbols.", "startOffset": 99, "endOffset": 120}, {"referenceID": 10, "context": "Given a function g(n), \u0398(g(n)) denotes the set of functions f(n) such that there exist positive constants c1, c2 and n0 such that 0 \u2264 c1g(n) \u2264 f(n) \u2264 c2g(n) for all n \u2265 n0 (Cormen et al., 1990).", "startOffset": 172, "endOffset": 193}, {"referenceID": 7, "context": "Two different ways of encoding a precedence constraint Ji \u227a jK are presented by Codish et al. (2009), which are called the unary encoding and the binary encoding.", "startOffset": 80, "endOffset": 101}, {"referenceID": 7, "context": "Two different ways of encoding a precedence constraint Ji \u227a jK are presented by Codish et al. (2009), which are called the unary encoding and the binary encoding. A brief description of them is presented in Section 9.2.1 and Section 9.2.2, which will provide a basis for their theoretical comparisons. Advanced techniques for encoding the objective function have also been proposed by Codish et al. (2009). However the encoding of the objective function is orthogonal to the way the precedences are encoded.", "startOffset": 80, "endOffset": 406}, {"referenceID": 7, "context": "Two different ways of encoding a precedence constraint Ji \u227a jK are presented by Codish et al. (2009), which are called the unary encoding and the binary encoding. A brief description of them is presented in Section 9.2.1 and Section 9.2.2, which will provide a basis for their theoretical comparisons. Advanced techniques for encoding the objective function have also been proposed by Codish et al. (2009). However the encoding of the objective function is orthogonal to the way the precedences are encoded. As our purpose is to compare the encoding of the precedence constraints, we omit the details of the encoding of the objective function for the symbol-based encoding proposed by Codish et al. (2009). Instead, we assume that in this approach the objective function is encoded as it is done in the atom-based case.", "startOffset": 80, "endOffset": 706}, {"referenceID": 8, "context": "In the symbol-based unary encoding (Codish et al., 2009) each feature is associated with an ordered set of Boolean variables that represents the unary encoding of its position.", "startOffset": 35, "endOffset": 56}, {"referenceID": 0, "context": "A precedence constraint is encoded using a lexicographical comparator (Apt, 2003).", "startOffset": 70, "endOffset": 81}, {"referenceID": 32, "context": "Therefore, the Tseitin transformation3 (Tseitin, 1968) is used to obtain the corresponding formula in conjunctive normal form.", "startOffset": 39, "endOffset": 54}, {"referenceID": 22, "context": "Indeed there exists other sub-optimal but efficient algorithms for enforcing singleton arc consistency on constraints networks, as proposed by Lecoutre et al. (2005) and, it remains to see whether any of these efficient algorithms can reduce the running time of msacb.", "startOffset": 143, "endOffset": 166}, {"referenceID": 22, "context": "Indeed there exists other sub-optimal but efficient algorithms for enforcing singleton arc consistency on constraints networks, as proposed by Lecoutre et al. (2005) and, it remains to see whether any of these efficient algorithms can reduce the running time of msacb. Notice that sacb can prune more values than rsacb. However, in practice, the difference between their pruning on the instances of feature subscriptions is not much, which is evident based on the number of nodes and time shown in Tables 2 and 3. We recall that rsacb enforces partial sacb. At a given node in the search tree, rsacb enforces arc consistency at most one time for each assignment of a value to each Boolean variable, whereas sacb can enforce arc consistency at most n times in the worst-case. Here n is the sum of the Boolean variables associated with features and user precedences. Nevertheless, in practice, we observed that it was much less. For example, for any instance of feature subscription of the class \u300840, 40\u3009 arc consistency was enforced at most 7 times for any variable-value pair, which is much less than n = 80. This also justifies the use of a non-optimal version of algorithm to enforce sacb. Our wcsp formulation for finding an optimal relaxation of a feature subscription was also tested. For this purpose toulbar2 (a generic solver for wcsp) was used7. In general the results in terms of time were poor. We remark that a solution of the wcsp model is a total order on the features whose position variables are assigned values greater than 0. Due to holes (when a feature is excluded) different assignments of the position variables may lead to the same total order. Thus, more search effort could be spent for the wcsp formulation. We recall that in the basic cop model the decision variables are only the Boolean variables that indicate the inclusion/exclusion of features and user precedences and not the position variables. Therefore, an optimal solution of the basic cop model may not necessarily be a total order on the included features. Nevertheless, it can be obtained by computing a topological sort on the included user precedences and the catalogue precedences defined over the included features. In order to remove the symmetries the wcsp formulation, as described in Section 8.2, can be augmented. One way could be to associate costs with the values (greater than 0) of the position variables in such a way that there is a unique assignment of values to the variables, which is optimal for a given strict partial order. Our preliminary investigation suggested that the number of nodes were reduced but at the expense of increasing the time. In our current setting, the wcsp approach has been used as a black box. Indeed, certain improvements can be made which may improve the performance in terms of time. For example, stronger soft consistency techniques can be applied similar to the singleton arc consistency for the cop model, which is more efficient for feature subscription problem. We also investigated the impact of using the global constraint SoftPrec. This global constraint was implemented in choco. The results obtained by using it are denoted by sp. Five variants of SoftPrec have been investigated by Lesaint et al. (2009). The results presented in this paper correspond to the variant that was observed to be the best in terms of time, which Lesaint et al.", "startOffset": 143, "endOffset": 3252}, {"referenceID": 22, "context": "Indeed there exists other sub-optimal but efficient algorithms for enforcing singleton arc consistency on constraints networks, as proposed by Lecoutre et al. (2005) and, it remains to see whether any of these efficient algorithms can reduce the running time of msacb. Notice that sacb can prune more values than rsacb. However, in practice, the difference between their pruning on the instances of feature subscriptions is not much, which is evident based on the number of nodes and time shown in Tables 2 and 3. We recall that rsacb enforces partial sacb. At a given node in the search tree, rsacb enforces arc consistency at most one time for each assignment of a value to each Boolean variable, whereas sacb can enforce arc consistency at most n times in the worst-case. Here n is the sum of the Boolean variables associated with features and user precedences. Nevertheless, in practice, we observed that it was much less. For example, for any instance of feature subscription of the class \u300840, 40\u3009 arc consistency was enforced at most 7 times for any variable-value pair, which is much less than n = 80. This also justifies the use of a non-optimal version of algorithm to enforce sacb. Our wcsp formulation for finding an optimal relaxation of a feature subscription was also tested. For this purpose toulbar2 (a generic solver for wcsp) was used7. In general the results in terms of time were poor. We remark that a solution of the wcsp model is a total order on the features whose position variables are assigned values greater than 0. Due to holes (when a feature is excluded) different assignments of the position variables may lead to the same total order. Thus, more search effort could be spent for the wcsp formulation. We recall that in the basic cop model the decision variables are only the Boolean variables that indicate the inclusion/exclusion of features and user precedences and not the position variables. Therefore, an optimal solution of the basic cop model may not necessarily be a total order on the included features. Nevertheless, it can be obtained by computing a topological sort on the included user precedences and the catalogue precedences defined over the included features. In order to remove the symmetries the wcsp formulation, as described in Section 8.2, can be augmented. One way could be to associate costs with the values (greater than 0) of the position variables in such a way that there is a unique assignment of values to the variables, which is optimal for a given strict partial order. Our preliminary investigation suggested that the number of nodes were reduced but at the expense of increasing the time. In our current setting, the wcsp approach has been used as a black box. Indeed, certain improvements can be made which may improve the performance in terms of time. For example, stronger soft consistency techniques can be applied similar to the singleton arc consistency for the cop model, which is more efficient for feature subscription problem. We also investigated the impact of using the global constraint SoftPrec. This global constraint was implemented in choco. The results obtained by using it are denoted by sp. Five variants of SoftPrec have been investigated by Lesaint et al. (2009). The results presented in this paper correspond to the variant that was observed to be the best in terms of time, which Lesaint et al. (2009) denoted by sp4.", "startOffset": 143, "endOffset": 3394}, {"referenceID": 22, "context": "Indeed there exists other sub-optimal but efficient algorithms for enforcing singleton arc consistency on constraints networks, as proposed by Lecoutre et al. (2005) and, it remains to see whether any of these efficient algorithms can reduce the running time of msacb. Notice that sacb can prune more values than rsacb. However, in practice, the difference between their pruning on the instances of feature subscriptions is not much, which is evident based on the number of nodes and time shown in Tables 2 and 3. We recall that rsacb enforces partial sacb. At a given node in the search tree, rsacb enforces arc consistency at most one time for each assignment of a value to each Boolean variable, whereas sacb can enforce arc consistency at most n times in the worst-case. Here n is the sum of the Boolean variables associated with features and user precedences. Nevertheless, in practice, we observed that it was much less. For example, for any instance of feature subscription of the class \u300840, 40\u3009 arc consistency was enforced at most 7 times for any variable-value pair, which is much less than n = 80. This also justifies the use of a non-optimal version of algorithm to enforce sacb. Our wcsp formulation for finding an optimal relaxation of a feature subscription was also tested. For this purpose toulbar2 (a generic solver for wcsp) was used7. In general the results in terms of time were poor. We remark that a solution of the wcsp model is a total order on the features whose position variables are assigned values greater than 0. Due to holes (when a feature is excluded) different assignments of the position variables may lead to the same total order. Thus, more search effort could be spent for the wcsp formulation. We recall that in the basic cop model the decision variables are only the Boolean variables that indicate the inclusion/exclusion of features and user precedences and not the position variables. Therefore, an optimal solution of the basic cop model may not necessarily be a total order on the included features. Nevertheless, it can be obtained by computing a topological sort on the included user precedences and the catalogue precedences defined over the included features. In order to remove the symmetries the wcsp formulation, as described in Section 8.2, can be augmented. One way could be to associate costs with the values (greater than 0) of the position variables in such a way that there is a unique assignment of values to the variables, which is optimal for a given strict partial order. Our preliminary investigation suggested that the number of nodes were reduced but at the expense of increasing the time. In our current setting, the wcsp approach has been used as a black box. Indeed, certain improvements can be made which may improve the performance in terms of time. For example, stronger soft consistency techniques can be applied similar to the singleton arc consistency for the cop model, which is more efficient for feature subscription problem. We also investigated the impact of using the global constraint SoftPrec. This global constraint was implemented in choco. The results obtained by using it are denoted by sp. Five variants of SoftPrec have been investigated by Lesaint et al. (2009). The results presented in this paper correspond to the variant that was observed to be the best in terms of time, which Lesaint et al. (2009) denoted by sp4. The results in Tables 68 show that SoftPrec always outperforms mrsacb on average. However, Lesaint et al. (2008a) theoretically showed that the pruning achieved by maintaining rsac on the Boolean", "startOffset": 143, "endOffset": 3524}, {"referenceID": 20, "context": "As the two last solvers are pseudo-Boolean solvers, the pwmsat instances were translated into linear pseudo-Boolean instances by associating each clause with a linear pseudo-Boolean constraint, and defining the objective function as the weighted sum of the soft clauses in the pwmsat model (de Givry, Larrosa, Meseguer, & Schiex, 2003). The results of the evaluation are summarized in Table 4. We remark that the results for the sat4j solver, especially for the dense catalogues, are roughly 10 times faster in terms of time when compared to those presented by Lesaint et al. (2008c). This is simply due to the advances in the version of the sat4j that has been used to obtain the results.", "startOffset": 301, "endOffset": 584}, {"referenceID": 7, "context": "Codish et al. (2009) have also made these results public.", "startOffset": 0, "endOffset": 21}, {"referenceID": 7, "context": "Although the results reported in Tables 1, 2 and 3 of the works of Codish et al. (2008, 2009) suggest that seb is much better than ae, the results shown in Table 5 contradict this conclusion. The results obtained by using seb are significantly outperformed by those obtained by using ae. This apparent conflict could be for one of several reasons. The results reported by Codish et al. (2008) were based on different instances for different encodings and the instances used for the symbol-based encoding were very much easier and in fact some large size instances with 50 features were already consistent.", "startOffset": 67, "endOffset": 393}, {"referenceID": 7, "context": "Although the results reported in Tables 1, 2 and 3 of the works of Codish et al. (2008, 2009) suggest that seb is much better than ae, the results shown in Table 5 contradict this conclusion. The results obtained by using seb are significantly outperformed by those obtained by using ae. This apparent conflict could be for one of several reasons. The results reported by Codish et al. (2008) were based on different instances for different encodings and the instances used for the symbol-based encoding were very much easier and in fact some large size instances with 50 features were already consistent. Also, the experiments for different encodings were conducted on different machines. Codish et al. (2008, 2009) obtained the results for the symbol-based encoding and the atom-based encodings using different solvers. The experiments for seb were done using a solver, which has been implemented on top of minisat, while for ae the results were obtained using the sat4j solver. It is apparent from Table 4 that the use of different solvers can make a huge difference in terms of runtime. In fact, we have observed a huge improvement for ae when tested with the minisat+ solver. This latter fact suggests that the speed up observed by Codish et al. (2008, 2009) could be mostly because of the use of minisat. Also, notice that the results depicted in Table 5 are in accordance with the fact that unit propagation in the atom-based encoding is strictly stronger than unit propagation in the symbol-based binary encoding. Although unit propagation on ae encoding is equivalent to unit propagation on seu encoding when assignments are restricted to problem variables, empirically it is not always possible to observe this due to the exploration of the search trees in different orders. Table 5 shows that ae and seu are incomparable in terms of time. Therefore, it is not possible to conclude superiority of any of the two approaches. We have also been informed that the instances of the symbol-based encodings also include the computation of the objective function, and the comparison of the value of the objective function with an upper bound as described by Codish et al. (2009). However, they are not needed when applying the pwmsat solver of sat4j.", "startOffset": 67, "endOffset": 2181}, {"referenceID": 24, "context": "Notice that the results for the mip approach have improved significantly when compared with the results presented by Lesaint et al. (2008c). This is because of the usage of real-valued variables for the positions of features.", "startOffset": 117, "endOffset": 140}], "year": 2010, "abstractText": "Call control features (e.g., call-divert, voice-mail) are primitive options to which users can subscribe off-line to personalise their service. The configuration of a feature subscription involves choosing and sequencing features from a catalogue and is subject to constraints that prevent undesirable feature interactions at run-time. When the subscription requested by a user is inconsistent, one problem is to find an optimal relaxation, which is a generalisation of the feedback vertex set problem on directed graphs, and thus it is an NP-hard task. We present several constraint programming formulations of the problem. We also present formulations using partial weighted maximum Boolean satisfiability and mixed integer linear programming. We study all these formulations by experimentally comparing them on a variety of randomly generated instances of the feature subscription problem.", "creator": "TeX"}}}