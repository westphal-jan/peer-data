{"id": "1401.3848", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Approximate Model-Based Diagnosis Using Greedy Stochastic Search", "abstract": "We propose a StochAstic Fault diagnosis AlgoRIthm, called SAFARI, which trades off guarantees of computing minimal diagnoses for computational efficiency. We empirically demonstrate, using the 74XXX and ISCAS-85 suites of benchmark combinatorial circuits, that SAFARI achieves several orders-of-magnitude speedup over two well-known deterministic algorithms, CDA* and HA*, for multiple-fault diagnoses; further, SAFARI can compute a range of multiple-fault diagnoses that CDA* and HA* cannot. We also prove that SAFARI is optimal for a range of propositional fault models, such as the widely-used weak-fault models (models with ignorance of abnormal behavior). We discuss the optimality of SAFARI in a class of strong-fault circuit models with stuck-at failure modes. By modeling the algorithm itself as a Markov chain, we provide exact bounds on the minimality of the diagnosis computed. SAFARI also displays strong anytime behavior, and will return a diagnosis after any non-trivial inference time.", "histories": [["v1", "Thu, 16 Jan 2014 04:57:50 GMT  (468kb)", "http://arxiv.org/abs/1401.3848v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["alexander feldman", "gregory provan", "arjan van gemund"], "accepted": false, "id": "1401.3848"}, "pdf": {"name": "1401.3848.pdf", "metadata": {"source": "CRF", "title": "Approximate Model-Based Diagnosis Using Greedy Stochastic Search", "authors": ["Alexander Feldman", "Gregory Provan", "Arjan van Gemund"], "emails": ["a.b.feldman@tudelft.nl", "g.provan@cs.ucc.ie", "a.j.c.vangemund@tudelft.nl"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of us are able to play by the rules that we have set ourselves to play by them. (...) Most of them are able to play by the rules. (...) Most of them are able to play by the rules. (...) Most of them are able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...) Most of them are not able to play by the rules. (...)"}, {"heading": "2. Technical Background", "text": "Our discussion continues by formalizing some MBD terms. This paper uses the traditional diagnostic definitions (de Kleer & Williams, 1987), except that we use propositional logical terms (conjunctions of words) instead of sentences of missing components.Central to MBD, a model of an artifact is presented as a propositional formula over a set of variables (SD, COMPS, OBS >, where SD is a propositional theory over a set of variables V, COMPS, V, COMPS is the set of assumptions, and OBS is the group of observable systems."}, {"heading": "2.1 A Running Example", "text": "The subtractor shown there consists of seven components: an inverter, two or gates, two xor gates and two and gates. The expression h (o-gates) models the normative (healthy) behavior of an inverter, where the variables i, o and h represent input, output and health. Similarly, an xor gate is modelled as h-gates (o-gates) (o-gates (i1 gates) and an or-gates by h-gates (o gates). Finally, an xor gate is specified as h-gates (i1 gates) (i2 gates). The above propositional formulas are copied for each gate (i1 gates)."}, {"heading": "2.2 Diagnosis and Minimal Diagnosis", "text": "This is not the first time that diagnosis has been made in the two diagnoses Lit and Lit + (\"all nominal\" assignment in our example is the \"all nominal\" assignment is the \"all nominal\" assignment. \"All nominal\" assignment is the \"all nominal\" assignment. \"All nominal\" assignment is the \"all nominal\" assignment. \"\" All nominal \"assignment is the\" all nominal \"assignment.\" What follows is a formal definition of consistency. \"\" We \"h2.\""}, {"heading": "2.3 Converting Propositional Formulae to Clausal Form", "text": "In both cases, important structural information has been lost, which can lead to performance deterioration when a formula is consistent with a solution."}, {"heading": "2.4 Complexity of Diagnostic Inference", "text": "This section discusses the complexity of the problems we are interested in, namely the problem of calculating a single diagnosis or the set of all minimum diagnoses, using two minimum criteria, subset minimality () and cardinality minimality (\u2264). We assume that the complexity of calculating all diagnoses is defined by a variable set V from which the number of diagnoses can be assumed (or errors) variables.Table 1 introduces the notation we use to define these 4 types of diagnostic problems.The complexity of calculating all diagnoses is more difficult than calculating a single diagnosis, as the number of diagnoses is exponential in the input magnitude in the worst case (number of components).This problem is limited from below by the problem of counting the number of diagnoses, which has been demonstrated as # co-NP -Complete (Hermann & Pichler, 2007)."}, {"heading": "3. Stochastic MBD Algorithm", "text": "In this section we discuss an algorithm for calculating multiple error diagnoses using stochastic search."}, {"heading": "3.1 A Simple Example (Continued)", "text": "\"We will review the consistency of all 2 | COMPS | possible health aspects for a diagnostic problem, 128 in the case of our current example."}, {"heading": "3.2 A Greedy Stochastic Algorithm", "text": "The question, which arises, is whether it can come at all to a random, unbalanced diagnostic order, if there are no random diagnostic requirements, but only random diagnostic requirements, concepts, concepts, concepts, concepts, concepts, concepts, results, results, concepts, concepts, concepts, concepts, terms, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, results, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts, concepts,"}, {"heading": "3.3 Basic Properties of the Greedy Stochastic Search", "text": "Before we proceed with the topics of completeness and optimism, we show that Safari is solid, i.e., only one diagnosis will come back. < < p > < / p > p > p > p > p > p > p > p < p > p > p < p > p < p > p < p > p > p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p.\" \"p\" p \"p.\" \"p\" p. \"\" p \"p.\" p. \"p.\" \"p.\" p. \"\" p. \"\" p. \"p.\" \"p.\" p. \"p.\" p. \"p.\" p."}, {"heading": "3.4 Complexity of Inference Using Greedy Stochastic Search", "text": "We will show that the primary determinant of inference complexity is the consistency check of consistency with SD. This is the solution to the complexity problem (SAT) which is NP-complete (Cook, 1971). We will show how we can use the incomplete satisfaction check to reduce this complexity, i.e., it will check the consistency of consistency with SD. We will call the complexity of a consistency check (SAT) which is NP-complete (Cook, 1971). We will show how we can use the incomplete satisfaction check to reduce this complexity to guarantee the cost of complexity."}, {"heading": "4. Optimality Analysis (Single Diagnosis)", "text": "Unlike deterministic algorithms, there is no absolute guarantee that the optimal solution (minimal diagnosis) will be found in the Safari algorithm. Below, we give an intuition behind the performance of the Safari algorithm based on an approximate analytical model that estimates the likelihood of achieving a diagnostic solution of specific minimality."}, {"heading": "4.1 Optimality of Safari in Weak-Fault Models", "text": "Let's start by looking at a single run of the algorithm without repetitions, assuming that there is only a minimal diagnosis. Next, we will expand the model with repetitions."}, {"heading": "4.1.1 Basic Model", "text": "Consider a diagnostic system DS = < SD, COMPS, OBS > so that SD-WFM, and an observation \u03b1 that \u03b1 manifests only a minimal diagnosis \u03c9. For the following argument, we will configure Safari with M = 1, N = 1, and we will assume that the initial solution is the trivial \"all faulty\" diagnosis. If Safari randomly selects a faulty variable and flips it over, we will say that it is a \"success\" if the new candidate is a diagnosis, and a \"failure\" otherwise. Let k denote the number of steps the algorithm successfully takes in the direction of the minimal diagnosis of cardinality and measures the number of variables whose values are reversed in the process of ascent from faulty to healthy. Let f (k) denote the probability distribution function (pdf) of k."}, {"heading": "4.1.2 Modeling Retries", "text": "In this section, we extend the model to repetitions, which has a profound effect on the resulting pdf = = = = process chain of f. Again, if we look at the transition between step k and k + 1, where the algorithm attempts to m = 1,..., M fails before leaving. As the algorithm can see (see Alg. 1), if a variable flip generates an inconsistency, a repetition attempt is executed while m is incremented. From elementary combinatories, we can calculate the probability that after flipping any M, we have different negative letters in step k. Similar to (3), in step k, there are erroneous letters in the form from which M is selected (as variable \"flips\" that lead to inconsistency are recorded and not tried again), so that there is no difference between the selection of M variables in the preceding or succession."}, {"heading": "4.2 Optimality of Safari in Strong-Fault Models", "text": "From the above analysis, we have seen that in WFM it is easy to move from a non-minimal diagnosis to a partial diagnosis of the minimum diagnosis. As explained below, this is not necessarily the case for high-error models. However, in many practical cases, high-error models exhibit at least partially behavior similar to MDH, allowing greedy algorithms like Safari to achieve results that come close to the optimal values."}, {"heading": "4.2.1 Partial Continuity in Strong-Fault Stuck-At Models", "text": "In what follows, we limit our attention to a large subclass of SFM, called SFSM (Struss & Dressler, 1992).Definition 14 (Strong-Fault Stuck-At-Model).A system DS = < SD, COMPS > belongs to the class SFSM iff SD is equivalent to (h1).Definition 14 (Strong-Fault Stuck-At-Model).Definition SD is equivalent to (h1).Definition SD is equivalent to (h1).Definition SD is equivalent to (h1).Definition SD is a positive or negative literal in Fj.MDH (Hypothesis 1) does not consider SFSM models. Consider an adder whose inputs and outputs are all zeros, and whose goal models are all attached to-1."}, {"heading": "4.2.2 Performance Modeling with Stuck-At Models", "text": "??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????"}, {"heading": "4.3 Validation", "text": "In the preceding sections, we have illustrated the progress of Safari with synthetic circuits showing specific behavior (diagnoses). Later in this section, we will present the pdf of the greedy search on one of the small benchmark circuits (for more information on the 74181 model see Fig. 6).Safari's progress with a weak fault model of the 74181 circuit is shown in Fig. 10. We have opted for a difficult observation that leads to a minimal diagnosis of cardinality 7 (left) and a simple observation that leads to a single error diagnosis (right).Both diagrams show that the probability mass shifts to the right when M is increased, and the effect is more profound for the smaller cardinality.The effect of the error modes stuck at-0 and stuck at-1 on the probability of success of Safari is shown in Fig. 11. Obviously, in this case, the minimal probability of the increase in the M is still dependent on the smallest observation, although the smallest observation is a small one."}, {"heading": "5. Optimality Analysis (Multiple Diagnoses)", "text": "The preceding section describes the process of calculating a diagnosis with Safari (N = 1). \"In this section, we discuss the use of Safari in the calculation (or counting) of all minimum cardinality diagnoses (N = 1). For the rest of the section, we assume that Safari is configured with a minimum diagnosis. Furthermore, in practice, diagnosticians are interested in a sample of minimum cardinality diagnosis. (SD) The number of minimum diagnoses (SD) can be configured exponentially in | COMPS. (In addition, diagnosticians are interested in a sample of minimum cardinality diagnosis. (SD) The number of minimum diagnoses (SD) can remember that the minimum cardinal diagnosis (SD) actually exists. (SD)"}, {"heading": "6. Experimental Results", "text": "In order to compare the optimality and performance of Safari with different diagnostic algorithms, we have performed more than one million diagnostic calculations on 64 dual CPU nodes belonging to a cluster, each node containing two 2.4 GHz AMD Opteron DP 250 processors and 4 GB of RAM. Safari's default configuration (unless otherwise stated) was M = 8 and N = 4; that is, Safari is configured for a maximum number of 8 repetitions before abandoning the ascent, and a total of 4 attempts. To provide more accurate average runtime optimities and performance data, all stochastic algorithms (i.e. those based on SLS Max-SAT and Safari) were repeatedly executed on each model and observation vector."}, {"heading": "6.1 Implementation Notes and Test Set Description", "text": "We have implemented Safari in approximately 1 000 lines of C code (without the dependence of the LTMS, the user interface and the DPLL code) and it is part of the Lydia package. 7Traditionally, MBD algorithms have been tested on diagnostic models of digital circuits as included in the ISCAS85 benchmark suite (Brglez & Fujiwara, 1985). To provide both weak and strong failure cases, we have translated each circuit into a weak, deadlocked-0 perspective (S-A-0) and stuck-1 model (S-A-1). In the deadlocked models, the performance of each faulty circuit is assumed to be constant (cf. Def. 14).The performance of the algorithms depends on the different degrees of observation (S-A-1)."}, {"heading": "6.2 Comparison to Complete Algorithms", "text": "Table 4 shows the results of comparing Safari with the implementations of two state-of-the-art complete and deterministic diagnostic algorithms: a modification for the completeness of CDA * (Williams & Ragno, 2007) and HA * (Feldman & van Gemund, 2006); Table 4 shows for each model and algorithm the percentage of all tests for which a diagnosis could be calculated within a one-minute limitation period; as shown in the three right columns of Table 4, Safari was able to find diagnoses for all observation vectors, while the performance of the two deterministic algorithms (columns two to seven) decreased with the increase in model size and cardinality of the observation vector."}, {"heading": "6.3 Comparison to Algorithms Based on ALLSAT and Model Counting", "text": "We compared the performance of Safari to that of a pure SAT-based approach that uses blocking clauses to avoid duplicate diagnoses (Jin, Han, & Somenzi, 2005).Although SAT coding has worked efficiently in a variety of other areas such as planning, weak health modeling makes the diagnostic problem so inadequate that an uninformed ALLSAT strategy (i.e., a search that does not exploit the continuity imposed by weak error modeling) is quite inefficient, even for small models. To back up our claim, we have experimented with the state-of-the-art satisfaction solver RelSat, version 2.02 (Bayardo & Pehoushek, 2000).Instead of numbering all solutions and filtering only the minimal diagnoses, we have conducted model counts whose relationship to MBD has been extensively studied."}, {"heading": "6.4 Performance of the Greedy Stochastic Search", "text": "Table 6 shows the absolute performance of Safari (M = | COMPS |, N = 4), which ranges from less than a millisecond for the small models to about 30 seconds for the largest strong error model. These fast absolute times show that Safari is suitable for online brainteasers where autonomy depends on a quick calculation of diagnoses. For each model, the minimum and maximum time to calculate a diagnosis has been calculated, shown in the tmin and tmax columns, respectively. The small tmax \u2212 tmin range confirms our theoretical results that Safari is insensitive to the error cardinalities of the diagnoses it calculates. CDA * and HA * performance, on the other hand, depends on the error cardinality and deteriorates rapidly with increasing error cardinality."}, {"heading": "6.5 Optimality of the Greedy Stochastic Search", "text": "From the results of the full diagnostic methods (CDA * and HA *) we know the exact cardinalities of the minimum cardinality diagnoses for some of the observations. By taking into account these observations, which lead to single and double errors, we have assessed the average optimality of Safari. Table 7 shows these optimality results for the greedy search. The second column of Table 7 shows the number of observation vectors that lead to individual errors for each weak error model. The third column shows the average cardinality of Safari. The second and third columns are repeated for the S-A-0 and S-A-1 models. Table 7 shows that the average cardinality returned by Safari for SD-WFM is approximately optimal for both single and double errors. The c1355 model shows the worst results for the single error observations, while c499 shows the most difficult weakest cardinality returned by Safari for SD-WFM is nearly optimal for both single and double errors."}, {"heading": "6.6 Computing Multiple Minimal-Cardinality Diagnoses", "text": "Next, we present the results of experiments that support the claims in Section 5. To do this, we first selected these observations \u03b1, for which we could calculate using a deterministic algorithm such as CDA * or HA * (usually observations that lead to single or double errors), and then configured Safari with M = | COMPS | and N = 10 | GP = 10 | GP-1 models. Finally, we have to filter out the minimal-cardinal diagnoses from the diagnoses calculated by Safari. Results are summarized in Table 8.Table 8 and repeat the same columns for weak, S-A-0 and S-A-1 models, and the data in these columns are to be interpreted as follows. The columns marked with the minimum and maximum number of minimal-cardinal diagnoses do not even show the minimum number of minimal-cardinal diagnoses per model as they are calculated by a deterministic algorithm."}, {"heading": "6.7 Experimentation Summary", "text": "We have applied Safari to a number of benchmark combinatorial circuits encoded with weak error models and strong error models, and have shown significant performance improvements in multiple error diagnoses compared to two state-of-the-art deterministic algorithms, CDA * and HA *. Our results suggest that Safari exhibits at least an acceleration of the order of magnitude compared to CDA * and HA * for multiple error diagnoses. Furthermore, while search complexity for the deterministic algorithms tested increases exponentially with error cardinality, the search complexity for this stochastic algorithm appears to be independent of error cardinality. We have compared Safari's performance to that of a MaxSAT-based algorithm, and Safari shows at least an order of magnitude of SLS diagnoses when calculating diagnoses."}, {"heading": "7. Related Work", "text": "In fact, most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are not able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are able to save themselves. (...)"}, {"heading": "8. Conclusion and Future Work", "text": "We have shown that subset-minimal diagnoses can be optimally calculated in weak error models and in an important subset of strong error models, and that almost all minimum cardinality diagnoses can be calculated for more general error models.8. Mountaineering proceeds as follows: for a current state s with costs of f (s), a neighboring state s (s) is generated by reversing a randomly selected hypothesis. If f (s) is better than f (s), s (s) becomes the current state; otherwise it is discarded. If iterations occur without the current state changing, the local search ends. 9. Disturbance-local search, starting from a current state s with costs of f (s), selects random variable h, and applies Taboo Search to identify a better state by flipping through its taboo status plan."}], "references": [{"title": "Approximating cost-based abduction is NP-hard", "author": ["A.M. Abdelbar"], "venue": "Artificial Intelligence, 159 (1-2), 231\u2013239.", "citeRegEx": "Abdelbar,? 2004", "shortCiteRegEx": "Abdelbar", "year": 2004}, {"title": "Exploring the fitness landscape and the run-time behaviour of an iterated local search algorithm for cost-based abduction", "author": ["A.M. Abdelbar", "S.H. Gheita", "H.A. Amer"], "venue": "Experimental & Theoretical Artificial Intelligence,", "citeRegEx": "Abdelbar et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Abdelbar et al\\.", "year": 2006}, {"title": "Counting models using connected components", "author": ["R.J. Bayardo", "J.D. Pehoushek"], "venue": "In Proc. AAAI\u201900,", "citeRegEx": "Bayardo and Pehoushek,? \\Q2000\\E", "shortCiteRegEx": "Bayardo and Pehoushek", "year": 2000}, {"title": "A neutral netlist of 10 combinational benchmark circuits and a target translator in fortran", "author": ["F. Brglez", "H. Fujiwara"], "venue": "In Proc. ISCAS\u201985,", "citeRegEx": "Brglez and Fujiwara,? \\Q1985\\E", "shortCiteRegEx": "Brglez and Fujiwara", "year": 1985}, {"title": "Symbolic Boolean manipulation with ordered binary-decision diagrams", "author": ["R.E. Bryant"], "venue": "ACM Computing Surveys, 24 (3), 293\u2013318.", "citeRegEx": "Bryant,? 1992", "shortCiteRegEx": "Bryant", "year": 1992}, {"title": "RODON - a model-based diagnosis approach for the DX diagnostic competition", "author": ["P. Bunus", "O. Isaksson", "B. Frey", "B. M\u00fcnker"], "venue": "In Proc", "citeRegEx": "Bunus et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bunus et al\\.", "year": 2009}, {"title": "The computational complexity of abduction", "author": ["T. Bylander", "D. Allemang", "M. Tanner", "J. Josephson"], "venue": "Artificial Intelligence,", "citeRegEx": "Bylander et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Bylander et al\\.", "year": 1991}, {"title": "Cost-based abduction and MAP explanation", "author": ["E. Charniak", "S.E. Shimony"], "venue": "Artificial Intelligence,", "citeRegEx": "Charniak and Shimony,? \\Q1994\\E", "shortCiteRegEx": "Charniak and Shimony", "year": 1994}, {"title": "The complexity of theorem-proving procedures", "author": ["S.A. Cook"], "venue": "Proc. STOC\u201971, pp. 151\u2013158.", "citeRegEx": "Cook,? 1971", "shortCiteRegEx": "Cook", "year": 1971}, {"title": "Model-based diagnosis using structured system descriptions", "author": ["A. Darwiche"], "venue": "Journal of Artificial Intelligence Research, 8, 165\u2013222.", "citeRegEx": "Darwiche,? 1998", "shortCiteRegEx": "Darwiche", "year": 1998}, {"title": "A machine program for theorem-proving", "author": ["M. Davis", "G. Logemann", "D. Loveland"], "venue": "Communications of the ACM,", "citeRegEx": "Davis et al\\.,? \\Q1962\\E", "shortCiteRegEx": "Davis et al\\.", "year": 1962}, {"title": "An assumption-based TMS", "author": ["J. de Kleer"], "venue": "Artificial Intelligence,", "citeRegEx": "Kleer,? \\Q1986\\E", "shortCiteRegEx": "Kleer", "year": 1986}, {"title": "Using crude probability estimates to guide diagnosis", "author": ["J. de Kleer"], "venue": "Artificial Intelligence,", "citeRegEx": "Kleer,? \\Q1990\\E", "shortCiteRegEx": "Kleer", "year": 1990}, {"title": "Minimum cardinality candidate generation", "author": ["J. de Kleer"], "venue": "In Proc. DX\u201909,", "citeRegEx": "Kleer,? \\Q2009\\E", "shortCiteRegEx": "Kleer", "year": 2009}, {"title": "Characterizing diagnoses and systems", "author": ["J. de Kleer", "A. Mackworth", "R. Reiter"], "venue": "Artificial Intelligence,", "citeRegEx": "Kleer et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Kleer et al\\.", "year": 1992}, {"title": "Diagnosing multiple faults", "author": ["J. de Kleer", "B. Williams"], "venue": "Artificial Intelligence,", "citeRegEx": "Kleer and Williams,? \\Q1987\\E", "shortCiteRegEx": "Kleer and Williams", "year": 1987}, {"title": "An extensible SAT-solver", "author": ["N. E\u00e9n", "N. S\u00f6rensson"], "venue": "In Proc. SAT\u201903,", "citeRegEx": "E\u00e9n and S\u00f6rensson,? \\Q2003\\E", "shortCiteRegEx": "E\u00e9n and S\u00f6rensson", "year": 2003}, {"title": "The complexity of logic-based abduction", "author": ["T. Eiter", "G. Gottlob"], "venue": "Journal of the ACM,", "citeRegEx": "Eiter and Gottlob,? \\Q1995\\E", "shortCiteRegEx": "Eiter and Gottlob", "year": 1995}, {"title": "Computing minimal diagnoses by greedy stochastic search", "author": ["A. Feldman", "G. Provan", "A. van Gemund"], "venue": "In Proc. AAAI\u201908,", "citeRegEx": "Feldman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2008}, {"title": "Computing observation vectors for max-fault min-cardinality diagnoses", "author": ["A. Feldman", "G. Provan", "A. van Gemund"], "venue": "In Proc. AAAI\u201908,", "citeRegEx": "Feldman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2008}, {"title": "A family of model-based diagnosis algorithms based on Max-SAT", "author": ["A. Feldman", "G. Provan", "A. van Gemund"], "venue": "Tech. rep. ES-2009-02,", "citeRegEx": "Feldman et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2009}, {"title": "The Lydia approach to combinational model-based diagnosis", "author": ["A. Feldman", "G. Provan", "A. van Gemund"], "venue": "In Proc. DX\u201909,", "citeRegEx": "Feldman et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2009}, {"title": "A two-step hierarchical algorithm for model-based diagnosis", "author": ["A. Feldman", "A. van Gemund"], "venue": "In Proc. AAAI\u201906,", "citeRegEx": "Feldman and Gemund,? \\Q2006\\E", "shortCiteRegEx": "Feldman and Gemund", "year": 2006}, {"title": "A novel model-based diagnosis engine: Theory and applications", "author": ["A. Fijany", "F. Vatan", "A. Barrett", "M. James", "C. Williams", "R. Mackey"], "venue": "In Proc. IEEE Aerospace\u201903,", "citeRegEx": "Fijany et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Fijany et al\\.", "year": 2003}, {"title": "Building Problem Solvers", "author": ["K. Forbus", "J. de Kleer"], "venue": null, "citeRegEx": "Forbus and Kleer,? \\Q1993\\E", "shortCiteRegEx": "Forbus and Kleer", "year": 1993}, {"title": "Improvements to Propositional Satisfiability Search Algorithms", "author": ["J.W. Freeman"], "venue": "Ph.D. thesis, University of Pennsylvania.", "citeRegEx": "Freeman,? 1995", "shortCiteRegEx": "Freeman", "year": 1995}, {"title": "Systematic versus stochastic constraint satisfaction", "author": ["E.C. Freuder", "R. Dechter", "M.L. Ginsberg", "B. Selman", "E.P.K. Tsang"], "venue": "In Proc. IJCAI\u201995,", "citeRegEx": "Freuder et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Freuder et al\\.", "year": 1995}, {"title": "Physical impossibility instead of fault models", "author": ["G. Friedrich", "G. Gottlob", "W. Nejdl"], "venue": "In Proc. AAAI\u201990,", "citeRegEx": "Friedrich et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Friedrich et al\\.", "year": 1990}, {"title": "From sampling to model counting", "author": ["C.P. Gomes", "J. Hoffmann", "A. Sabharwal", "B. Selman"], "venue": "In Proc. IJCAI\u201907,", "citeRegEx": "Gomes et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gomes et al\\.", "year": 2007}, {"title": "Unveiling the ISCAS-85 benchmarks: A case study in reverse engineering", "author": ["M. Hansen", "H. Yalcin", "J. Hayes"], "venue": "IEEE Design & Test,", "citeRegEx": "Hansen et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Hansen et al\\.", "year": 1999}, {"title": "Counting complexity of propositional abduction", "author": ["M. Hermann", "R. Pichler"], "venue": "In Proc. IJCAI\u201907,", "citeRegEx": "Hermann and Pichler,? \\Q2007\\E", "shortCiteRegEx": "Hermann and Pichler", "year": 2007}, {"title": "SAT-encodings, search space structure, and local search performance", "author": ["H. Hoos"], "venue": "Proc. IJCAI\u201999, pp. 296\u2013303.", "citeRegEx": "Hoos,? 1999", "shortCiteRegEx": "Hoos", "year": 1999}, {"title": "Stochastic Local Search: Foundations and Applications", "author": ["H. Hoos", "T. St\u00fctzle"], "venue": null, "citeRegEx": "Hoos and St\u00fctzle,? \\Q2004\\E", "shortCiteRegEx": "Hoos and St\u00fctzle", "year": 2004}, {"title": "Scaling and probabilistic smoothing: Efficient dynamic local search for SAT", "author": ["F. Hutter", "D.A.D. Tompkins", "H.H. Hoos"], "venue": "In Proc. CP\u201902,", "citeRegEx": "Hutter et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2002}, {"title": "Efficient conflict analysis for finding all satisfying assignments of a Boolean circuit", "author": ["H. Jin", "H. Han", "F. Somenzi"], "venue": "In Proc. TACAS\u201905,", "citeRegEx": "Jin et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Jin et al\\.", "year": 2005}, {"title": "Stochastic local search for Bayesian networks", "author": ["K. Kask", "R. Dechter"], "venue": "In Proc. AISTAT\u201999,", "citeRegEx": "Kask and Dechter,? \\Q1999\\E", "shortCiteRegEx": "Kask and Dechter", "year": 1999}, {"title": "A model counting characterization of diagnoses", "author": ["T.K.S. Kumar"], "venue": "Proc. DX\u201902, pp. 70\u201376.", "citeRegEx": "Kumar,? 2002", "shortCiteRegEx": "Kumar", "year": 2002}, {"title": "First international diagnosis competition - DXC\u201909", "author": ["T. Kurtoglu", "S. Narasimhan", "S. Poll", "D. Garcia", "L. Kuhn", "J. de Kleer", "A. van Gemund", "A. Feldman"], "venue": "In Proc", "citeRegEx": "Kurtoglu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kurtoglu et al\\.", "year": 2009}, {"title": "The impact of branching heuristics in propositional satisfiability algorithms", "author": ["J.P. Marques-Silva"], "venue": "Proc. EPIA\u201999, pp. 62\u201374.", "citeRegEx": "Marques.Silva,? 1999", "shortCiteRegEx": "Marques.Silva", "year": 1999}, {"title": "Truth maintenance", "author": ["D.A. McAllester"], "venue": "Proc. AAAI\u201990, Vol. 2, pp. 1109\u20131116.", "citeRegEx": "McAllester,? 1990", "shortCiteRegEx": "McAllester", "year": 1990}, {"title": "A theory of diagnosis from first principles", "author": ["R. Reiter"], "venue": "Artificial Intelligence, 32 (1), 57\u201395.", "citeRegEx": "Reiter,? 1987", "shortCiteRegEx": "Reiter", "year": 1987}, {"title": "On the hardness of approximate reasoning", "author": ["D. Roth"], "venue": "Artificial Intelligence, 82 (1-2), 273\u2013302.", "citeRegEx": "Roth,? 1996", "shortCiteRegEx": "Roth", "year": 1996}, {"title": "A linear constraint satisfaction approach to cost-based abduction", "author": ["E. Santos Jr."], "venue": "Artificial Intelligence, 65 (1), 1\u201328.", "citeRegEx": "Jr.,? 1994", "shortCiteRegEx": "Jr.", "year": 1994}, {"title": "Fault diagnosis and logic debugging using Boolean satisfiability", "author": ["A. Smith", "A. Veneris", "M.F. Ali", "A. Viglas"], "venue": "IEEE Transactions on CAD of Integrated Circuits and Systems,", "citeRegEx": "Smith et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2005}, {"title": "Design diagnosis using Boolean satisfiability", "author": ["A. Smith", "A. Veneris", "A. Viglas"], "venue": "In Proc. ASP-DAC\u201904,", "citeRegEx": "Smith et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2004}, {"title": "Physical negation\u201d - integrating fault models into the General Diagnostic Engine", "author": ["P. Struss", "O. Dressler"], "venue": "In Readings in Model-Based Diagnosis,", "citeRegEx": "Struss and Dressler,? \\Q1992\\E", "shortCiteRegEx": "Struss and Dressler", "year": 1992}, {"title": "Solving non-clausal formulas with DPLL search", "author": ["C. Thiffault", "F. Bacchus", "T. Walsh"], "venue": "In Proc. CP\u201904,", "citeRegEx": "Thiffault et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Thiffault et al\\.", "year": 2004}, {"title": "On the complexity of proofs in propositional logics", "author": ["G. Tseitin"], "venue": "Siekmann, J., & Wrightson, G. (Eds.), Automation of Reasoning: Classical Papers in Computational Logic (1967\u20131970), Vol. 2. Springer-Verlag.", "citeRegEx": "Tseitin,? 1983", "shortCiteRegEx": "Tseitin", "year": 1983}, {"title": "Conflict-directed A* and its role in model-based embedded systems", "author": ["B. Williams", "R. Ragno"], "venue": "Journal of Discrete Applied Mathematics,", "citeRegEx": "Williams and Ragno,? \\Q2007\\E", "shortCiteRegEx": "Williams and Ragno", "year": 2007}, {"title": "An efficient algorithm for unit propagation", "author": ["H. Zhang", "M.E. Stickel"], "venue": "In Proc. AI-MATH\u201996,", "citeRegEx": "Zhang and Stickel,? \\Q1996\\E", "shortCiteRegEx": "Zhang and Stickel", "year": 1996}], "referenceMentions": [{"referenceID": 40, "context": "The standard MBD formalization (Reiter, 1987) frames a diagnostic problem in terms of a set of logical clauses that include mode-variables describing the nominal and fault status of system components; from this the diagnostic status of the system can be computed given an observation of the system\u2019s sensors.", "startOffset": 31, "endOffset": 45}, {"referenceID": 31, "context": "This can be easily generalized by introducing multi-valued logic or suitable encodings (Hoos, 1999).", "startOffset": 87, "endOffset": 99}, {"referenceID": 47, "context": "Converting a propositional formula to CNF can be done with (Tseitin, 1983) or without (Forbus & de Kleer, 1993) the introduction of intermediate variables.", "startOffset": 59, "endOffset": 74}, {"referenceID": 27, "context": "Under the same restriction, for SD \u2208 SFM, deciding if a first minimal diagnosis exists is NP-hard (Friedrich et al., 1990).", "startOffset": 98, "endOffset": 122}, {"referenceID": 16, "context": "The complexity of a closely-related problem, Propositional Abduction Problems (PAPs), has been studied by Eiter and Gottlob (1995). They show that for a propositional PAP, the problem of determining if a solution exists is \u03a32 -complete.", "startOffset": 106, "endOffset": 131}, {"referenceID": 16, "context": "The complexity of a closely-related problem, Propositional Abduction Problems (PAPs), has been studied by Eiter and Gottlob (1995). They show that for a propositional PAP, the problem of determining if a solution exists is \u03a32 -complete. Computing a minimal diagnosis is a search problem, and hence it is more difficult to pose a decision question for proving complexity results. Consequently, one can just note that computing a diagnosis minimal with respect to \u2286 / \u2264 requires O(log |COMPS|) calls to an NP oracle (Eiter & Gottlob, 1995), asking the oracle at each step if a diagnosis containing at most k faulty components exists. Results on abduction problems indicate that the task of approximate diagnosis is intractable. Roth (1996) has addressed the problems of abductive inference, and of approximating such inference.", "startOffset": 106, "endOffset": 738}, {"referenceID": 0, "context": "Abdelbar (2004) has studied the complexity of approximating Horn abduction problems, showing that even for a particular Horn restriction of the propositional problem of interest, the approximation problem is intractable.", "startOffset": 0, "endOffset": 16}, {"referenceID": 27, "context": "Diagnosing a strong-fault model is known to be strictly more difficult than a weak-fault model (Friedrich et al., 1990).", "startOffset": 95, "endOffset": 119}, {"referenceID": 38, "context": "Of course, random polarity decisions may effect negatively branching heuristics (Marques-Silva, 1999) but such analysis is also beyond the scope of this paper.", "startOffset": 80, "endOffset": 101}, {"referenceID": 39, "context": "To increase the implementation efficiency of Safari, we combine a BCP-based LTMS engine (McAllester, 1990) and a full-fledged DPLL solver in two-stage consistency checking.", "startOffset": 88, "endOffset": 106}, {"referenceID": 25, "context": "For the full DPLL checking we use POSIT (Freeman, 1995) or MiniSat (E\u00e9n & S\u00f6rensson, 2003).", "startOffset": 40, "endOffset": 55}, {"referenceID": 8, "context": "This is solving the satisfiability problem (SAT), which is NP-complete (Cook, 1971).", "startOffset": 71, "endOffset": 83}, {"referenceID": 36, "context": "Instead of enumerating all solutions and filtering the minimal diagnoses only, we have performed model-counting, whose relation to MBD has been extensively studied (Kumar, 2002).", "startOffset": 164, "endOffset": 177}, {"referenceID": 36, "context": "Instead of enumerating all solutions and filtering the minimal diagnoses only, we have performed model-counting, whose relation to MBD has been extensively studied (Kumar, 2002). While it was possible to solve the two smallest circuits, the solver did not terminate for any of the larger models within the predetermined time of 1 hour. The results are shown in Table 5. The second column of Table 5 shows the model count returned by RelSat, with sample single-fault observations from our benchmark. The third column reports the time for model counting. This slow performance on relatively small diagnostic instances leads us to the conclusion that specialized solvers like Safari are better suited for finding minimal diagnoses than off-the-shelf ALLSAT (model counting) implementations that do not encode inference properties similar to those encoded in Safari. We have used the state-of-the-art, non-exact model counting method SampleCount (Gomes, Hoffmann, Sabharwal, & Selman, 2007) to compute lower bounds of the model counts. The results are shown in the third and fourth columns of Table 5. Configured with the default settings (\u03b1 = 3.5, t = 2, z = 20, cutoff 10 000 flips), SampleCount could not find lower bounds for circuits larger than c1355. Although the performance of SampleCount is significantly better than RelSAT, the fact that SampleCount computes lower bounds and does not scale to large circuits prevent us from building a diagnosis algorithm based on approximate model counting. A satisfiability-based method for diagnosing an optimized version of ISCAS85 has been used by Smith, Veneris, and Viglas (2004). In a more recent paper (Smith, Veneris, Ali, & Viglas, 2005), the SAT-based approach has been replaced by a Quantified Boolean Formula (QBF) solver for computing multiple-fault diagnoses.", "startOffset": 165, "endOffset": 1628}, {"referenceID": 40, "context": "Examples of search algorithms include A\u2217-based algorithms, such as CDA\u2217 (Williams & Ragno, 2007) and hitting set algorithms (Reiter, 1987).", "startOffset": 124, "endOffset": 138}, {"referenceID": 9, "context": "Examples of such algorithms include the ATMS (de Kleer, 1986) and other prime-implicant methods (Kean & Tsiknis, 1993), DNNF (Darwiche, 1998), and OBDD (Bryant, 1992).", "startOffset": 125, "endOffset": 141}, {"referenceID": 4, "context": "Examples of such algorithms include the ATMS (de Kleer, 1986) and other prime-implicant methods (Kean & Tsiknis, 1993), DNNF (Darwiche, 1998), and OBDD (Bryant, 1992).", "startOffset": 152, "endOffset": 166}, {"referenceID": 34, "context": "At first glance, it seems like MBD could be efficiently solved using an encoding as a SAT (Jin et al., 2005), constraint satisfaction (Freuder, Dechter, Ginsberg, Selman, & Tsang, 1995) or Bayesian network (Kask & Dechter, 1999) problem.", "startOffset": 90, "endOffset": 108}, {"referenceID": 34, "context": "We show that Safari exploits a particular property of MBD problems, called diagnostic continuity, which improves the optimality of Safari compared to, for example, straightforward ALLSAT encodings (Jin et al., 2005).", "startOffset": 197, "endOffset": 215}, {"referenceID": 26, "context": "Stochastic algorithms have been discussed in the framework of constraint satisfaction (Freuder et al., 1995) and Bayesian network inference (Kask & Dechter, 1999).", "startOffset": 86, "endOffset": 108}, {"referenceID": 25, "context": "Stochastic algorithms have been discussed in the framework of constraint satisfaction (Freuder et al., 1995) and Bayesian network inference (Kask & Dechter, 1999). The latter two approaches can be used for solving suitably translated MBD problems. It is often the case, though, that these encodings are more difficult for search than specialized ones. MBD is an instance of constraint optimization, with particular constraints over failure variables. MBD has developed algorithms to exploit these domain properties, and our proposed approach differs significantly from almost all MBD algorithms that appear in the literature. While most advanced MBD algorithms are deterministic, Safari borrows from SLS algorithms that, rather than backtracking, may randomly flip variable assignments to determine a satisfying assignment. Complete MBD algorithms typically make use of preferences, e.g., fault-mode probabilities, to improve search efficiency; Safari uses this technique on top of its stochastic search over the space of diagnoses. A closely-related diagnostic approach is that of Fijany, Vatan, Barrett, James, Williams, and Mackey (2003), who map the minimal-hitting set problem into the problem of finding an assignment with bounded weight satisfying a monotone SAT problem, and then propose to use efficient SAT algorithms for computing diagnoses.", "startOffset": 87, "endOffset": 1141}, {"referenceID": 0, "context": "area, the primary paper that adopts stochastic local search is by Abdelbar, Gheita, and Amer (2006). In this paper, they present a hybrid two-stage method that is based on Iterated Local Search (ILS) and Repetitive Simulated Annealing (RSA).", "startOffset": 66, "endOffset": 100}, {"referenceID": 0, "context": "area, the primary paper that adopts stochastic local search is by Abdelbar, Gheita, and Amer (2006). In this paper, they present a hybrid two-stage method that is based on Iterated Local Search (ILS) and Repetitive Simulated Annealing (RSA). The ILS stage of the algorithm uses a simple hill-climbing method (randomly flipping assumables) for the local search phase, and tabu search for the perturbation phase. RSA repeatedly applies Simulated Annealing (SA), starting each time from a random initial state. The hybrid method initially starts from an arbitrary state, or a greedily-chosen state. It then applies the ILS algorithm; if this algorithm fails to find the optimal solution after a fixed number \u03c4 of hill-climbing steps8 or after a fixed number R of repetitions of the perturbation-local search cycle,9 ILS-based search is terminated and the RSA algorithm is run until the optimal solution is found. Our work differs from that of Abdelbar et al. (2006) in several ways.", "startOffset": 66, "endOffset": 963}], "year": 2010, "abstractText": "We propose a StochAstic Fault diagnosis AlgoRIthm, called Safari, which trades off guarantees of computing minimal diagnoses for computational efficiency. We empirically demonstrate, using the 74XXX and ISCAS85 suites of benchmark combinatorial circuits, that Safari achieves several orders-of-magnitude speedup over two well-known deterministic algorithms, CDA\u2217 and HA\u2217, for multiple-fault diagnoses; further, Safari can compute a range of multiple-fault diagnoses that CDA\u2217 and HA\u2217 cannot. We also prove that Safari is optimal for a range of propositional fault models, such as the widely-used weak-fault models (models with ignorance of abnormal behavior). We discuss the optimality of Safari in a class of strong-fault circuit models with stuck-at failure modes. By modeling the algorithm itself as a Markov chain, we provide exact bounds on the minimality of the diagnosis computed. Safari also displays strong anytime behavior, and will return a diagnosis after any non-trivial inference time.", "creator": "dvips(k) 5.95a Copyright 2005 Radical Eye Software"}}}