{"id": "1401.3851", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Intrusion Detection using Continuous Time Bayesian Networks", "abstract": "Intrusion detection systems (IDSs) fall into two high-level categories: network-based systems (NIDS) that monitor network behaviors, and host-based systems (HIDS) that monitor system calls. In this work, we present a general technique for both systems. We use anomaly detection, which identifies patterns not conforming to a historic norm. In both types of systems, the rates of change vary dramatically over time (due to burstiness) and over components (due to service difference). To efficiently model such systems, we use continuous time Bayesian networks (CTBNs) and avoid specifying a fixed update interval common to discrete-time models. We build generative models from the normal training data, and abnormal behaviors are flagged based on their likelihood under this norm. For NIDS, we construct a hierarchical CTBN model for the network packet traces and use Rao-Blackwellized particle filtering to learn the parameters. We illustrate the power of our method through experiments on detecting real worms and identifying hosts on two publicly available network traces, the MAWI dataset and the LBNL dataset. For HIDS, we develop a novel learning method to deal with the finite resolution of system log file time stamps, without losing the benefits of our continuous time model. We demonstrate the method by detecting intrusions in the DARPA 1998 BSM dataset.", "histories": [["v1", "Thu, 16 Jan 2014 04:59:06 GMT  (466kb)", "http://arxiv.org/abs/1401.3851v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CR", "authors": ["jing xu", "christian r shelton"], "accepted": false, "id": "1401.3851"}, "pdf": {"name": "1401.3851.pdf", "metadata": {"source": "CRF", "title": "Intrusion Detection using Continuous Time Bayesian Networks", "authors": ["Jing Xu", "Christian R. Shelton"], "emails": ["JINGXU@CS.UCR.EDU", "CSHELTON@CS.UCR.EDU"], "sections": [{"heading": null, "text": "(NIDS), which monitors network behavior, and host-based systems (HIDS), which monitors system calls. In this paper, we present a general technique for both systems. We use anomaly detection, which identifies patterns that do not conform to a historical norm. In both systems, the change rates vary dramatically over time (due to rupture) and across components (due to service differences). To model such systems efficiently, we use continuous Bayesian networks (CTBNs) and avoid setting a fixed update interval, which is common for discrete time models. We build generative models from the normal training data, and abnormal behaviors are characterized based on their probability under this norm. For NIDS, we construct a hierarchical CTBN model for network packet histories and use Rao-Blackwellized Particle Filtering to learn the parameters. We illustrate the power of our guest packaging detection method by using two publicly accessible identification experiments."}, {"heading": "1. Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2. Related Work", "text": "The work of Eskin, Arnold, Prerau, Portnoy, and Stolfo (2002) is similar to our approach in that they apply their methodology to these two types of data. They map data elements into a trait space and detect anomalies by using cluster-based estimation, K-closest neighbors, and a class SVM to determine which points lie in sparse regions, using a data-dependent normalization characteristic map for network traffic data, and a spectrum kernel for system call tracking."}, {"heading": "2.1 NIDS", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "2.2 HIDS", "text": "Previous work on detecting break-ins in system call logs can be roughly grouped into two categories: sequence-based and function-based. Sequence-based methods focus on the sequential sequence of events, while function-based methods treat system calls as independent data elements. Our method belongs to the earlier category, since we use a CTBN to model the dynamics of sequences.Time-delay embedding (tide) and sequence-time-delayed embedding (stide) are two examples of sequence-based methods (Forrest, A.Hofmeyr, Somayaji, & A.Longstaff, 1996; A.Hofmeyr, Forrest, & Somayaji, 1998). They generalize the data by building a database that stores previously seen system calls sub-sequences, and test by searching for sub-sequences in the database. These methods are straightforward and often produce good results."}, {"heading": "2.3 Other Work", "text": "Simma et al. (2008) also use a continuous time model to think about network traffic. To estimate the parameters of the large network we build for network traffic data, we use Rao-Blackwellized Particle Filters (RBPFs). Doucet, de Freitas, Murphy and Russell (2000) propose an RBPF algorithm for Bayesian dynamic networks that works in discrete time by exploiting the structure of the DBN. Ng, Pfeffer and Dearden (2005) extend the RBPF to continuous time dynamic systems and apply the method to the experimental Mars rover K-9 of NASA Ames Research Center. Their model is a hybrid system that contains both discrete and continuous variables, using particle filters for the discrete variables and uncontrolled Mars rovers that apply only to continuous work (our BFS model is for the same time only)."}, {"heading": "3. Continuous Time Bayesian Networks", "text": "We begin with a brief look at the definition of Markov processes and continuous Bayesian networks (CTBNs)."}, {"heading": "3.1 Homogeneous Markov Process", "text": "A finite, continuous, homogeneous Markov process Xt is described by an initial distribution P 0X and at a state space V al (X) = {x1,..., xn} by a n \u00b7 n matrix of transition intensities: QX = \u2212 qx1 qx1x2... qx1xn qx2x1 \u2212 qx2... qx2xn......... qxnx1 qxnx2.. \u2212 qxn. qxixj is the intensity (or rate) of the transition from state xi to state xj and qxi = \u2211 j 6 = i qxixj. The transient behavior of Xt can be described as follows. Variable X remains exponentially distributed in state x for time with the parameter qx."}, {"heading": "3.2 Complete Data", "text": "Complete data for an HMP is represented by a series of trajectorsD = {\u03c41,... \u03c4n}. Each trajectory \u03c4i is a complete series of state transitions: d = {(xd, td, x \u2032 d)}, which means that X remained in state xd for a duration of td and then passed into state x \u2032 d. Therefore, we know the exact state of variables X at any time 0 \u2264 t \u2264 T."}, {"heading": "3.3 Sufficient Statistics and Likelihood", "text": "Considering an HMP and its complete DataD, the probability of a single state transition is d = {(xd, td, x \u2032 d)} \"D isLX (q, \u03b8: d) = (qxd exp (\u2212 qxdtd))) (\u03b8xdx \u2032 d). The probability function for D can be dissected by transition: LX (q, \u03b8: D) = (d, D LX (q: d)) (d, D LX (\u03b8: d))) = (x qM [x] x exp (\u2212 qxT [x])) (x x x x \u2032 6 = x \u03b8 M [x, x \u2032] xx \u2032). If we take the log of the above function, we get the log probability: lX (q) = lX (q: D) + lX (D: D) = x.\""}, {"heading": "3.4 Learning from Complete Data", "text": "To estimate the parameters of the transition intensity matrix Q, we maximize the above log probability function. This results in the maximum probability estimates: q: x = M [x] T [x], \u03b8: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"}, {"heading": "3.5 Incomplete Data", "text": "Incomplete data from an HMP consists of partially observed trajectories D = {\u03c4 \u2212 1,... \u03c4 \u2212 n}. Each trajectory \u03c4 \u2212 i consists of a series of d = {(Sd, td, dt)} observations, where Sd is a subsystem (a non-empty subset of the states of X) of the process. Each of the triplets specifies an \"interval detection,\" which states that the variable X is located in the subsystem Sd from time td to time td + dt. Some of the observations may be permanent, i.e. we observe only X-Sd at time t, but do not know how long it will stay there. This is called \"point detection\" and can be generalized with the same triplet notation described above by setting the duration to 0. For a partially observed trajectory, we observe only sequences of subsystems and do not observe the state transitions within the subsystems."}, {"heading": "3.6 Expected Sufficient Statistics and Expected Likelihood", "text": "We can consider possible completions of a partially observed orbit, which specify the transitions that are consistent with the partial orbit. By combining the partial orbit and its completion, we obtain a complete orbit. We defined D + = {\u03c4 + 1,..., \u03c4 + n} as completions of all partial orbits in D. In one model, we have a distribution probability of D +, givenD. For dataD +, the expected sufficient statistics in terms of probability density of possible completions of the data are T [x], M [x], x [x] and M [x]. The expected protocol probability is E [lX (q, Tennessee: D +) = E [lX (q: D +)] + E [lX (Term: D +)] = E [lX (Term: D +) = E [x] ln (x] ln (x] ln (qx) \u2212 qxT [x] \u00b2 6 = x x x \u00b2 (xx)."}, {"heading": "3.7 Learning from Incomplete Data", "text": "The Expectation Maximization (EM) algorithm can be used to find a local maximum of the probability of subtractors. The EM algorithm iterates over the following E-step and M-step to the convergence of the derived probability function. This is the most complex part of the algorithm. We will give more details below. M-step: From the calculated numbers, the expected sufficient statistics are calculated, whereby the new model parameters for the next EM iteration are updated: qx = M-value [x]. This is the most complex part of the algorithm."}, {"heading": "3.8 Continuous Time Bayesian Networks", "text": "Although HMP is good for modeling many dynamic systems, it has its limits when systems have multiple components, because the state space grows exponentially in the number of variables. An HMP does not model the variable independence and therefore must use a uniform state X to represent the common behavior of all components involved in the system. In this section, we will show how a continuous Bayesian network can be used to solve this problem. Nodelman et al. (2002) expand the theory of HMPs and present continuous Bayesian networks (CTBNs) that model the common dynamics of multiple local variables by allowing the transition model of each local variable X to be a Markov process whose parameterization depends on a subset of other variables U."}, {"heading": "3.9 Definition", "text": "The fact is that we see ourselves as being able to be in a position, and that we are able, we will be able to be in a position, we will be able to be in a position, we will be able to be in a position, we will be able to put ourselves in a position, we will be able to put ourselves in a position, we will be able to put ourselves in a position, we will be able to put ourselves in a position, we will be able to put ourselves in a position, we will be in a position."}, {"heading": "3.10 Learning", "text": "In the context of CTBNs, the model parameters consist of the CTBN structure G, the initial distribution P0, which is parameterized by a regular Bayesian network, and the conditional intensity matrices (CIMs) of each variable on the network. In this section, we assume that we know the CTBN structure, so we focus only on parameter learning. Moreover, we assume that the model is not reducible. Therefore, the initial distribution P0 loses importance in the context of CTBN inference and learning, especially when the time span becomes significantly large. Therefore, parameter learning in our context consists in estimating the conditional intensity matrices QXi | Ui for each variable Xi, where Ui is the set of the parent variables of Xi."}, {"heading": "3.10.1 LEARNING FROM COMPLETE DATA", "text": "Nodelman et al. (2003) presented an efficient method to learn a CTBN model from fully observed trajectories. With complete data, we know complete instances of all variables for the entire trajectory. Thus, we know which CIM controls the transition dynamics of each variable at any time. Sufficient statistics are M [x, x | u] - the number of X transitions from state x to x \u2032. The probability function forD can be decomposed as LN (q, \u03b8: D) = total duration, the X remains in state x given its parental instantiation. We denoteM [x | u] = x \u2032 M [x, x \u2032 | u]. The probability function forD can be decomposed as LN (q, \u03b8: D) = X-X-LXi (qXi | Ui: D)."}, {"heading": "3.10.2 LEARNING FROM INCOMPLETE DATA", "text": "Nodelman, Shelton and Koller (2005) present the algorithm of expectation maximization (EM) to learn a CTBN model from partially observed paths. Expected sufficient statistics are M-x, x-u, the expected number of times X passes from state x to x-u if its parent takes the values u and T-x-u, the expected period of time in which X remains in state x. We refer to M-x-u as \"M-x,\" x-u. \"The expected protocol probability can be broken down in the same way as in Equation 4, except that the sufficient statistics M-x, x-u, T-x-u and M-x-u are replaced by the expected sufficient statistics M-x-u."}, {"heading": "3.11 Inference", "text": "In view of a CTBN model and some (partially) observed data, we would now like to query the model and calculate, for example, the expected sufficient statistics for the above mentioned EM algorithm."}, {"heading": "3.11.1 EXACT INFERENCE", "text": "Nodelman et al. (2005) provide an exact inference algorithm that uses expectation maximization to argue and learn the parameters from partially observed data. This exact inference algorithm requires flattening all variables in a single Markov process and performing inferences as in an HMP. It has the problem of increasing the state space exponentially. Therefore, the exact inference method is practicable only for problems with very small state spaces."}, {"heading": "3.11.2 APPROXIMATE INFERENCE", "text": "Nodelman, Koller and Shelton (2005) present an expectation propagation algorithm. Saria, Nodelman and Koller (2007) provide another message passing algorithm that adjusts the time granularity. Cohn, El-Hay, Friedman and Kupferman (2009) offer an average field variation approach. El-Hay, Friedman and Kupferman (2008) show a Gibbs sampling approach using the Monte Carlo Expectation Maximization. Fan and Shelton (2008) provide another sampling-based approach using priority sampling. El-Hay, Cohn, Friedman and Kupferman (2010) describe a different expectation propagation approach. To estimate the parameters of the models we build for the two applications, we use non-discrete filters (NIDS and HIDS)."}, {"heading": "3.12 CTBN Applications", "text": "Nodelman and Horvitz (2003) used CTBNs to think about the presence and availability of users over time; Ng et al. (2005) used CTBNs to monitor a mobile robot; Nodelman et al. (2005) used CTBNs to model the history of life events; Fan and Shelton (2009) modeled social networks via CTBNs; and our previous work (Xu & Shelton, 2008) presented an NIDS for host machines using CTBNs, but did not include HIDS."}, {"heading": "4. Anomaly Detection Using Network Traffic", "text": "In this section, we will introduce an algorithm for detecting anomalies in network traffic using CTBNs. We will focus only on a single host within the network. The sequence and timing of events (e.g. packet transmission and connection establishment) are very important for the flow of network traffic. It depends not only on how many connections were initiated at the last minute, but also on their timing: if they were evenly distributed, the track is probably normal, but if they all occurred in a fast burst, it is more suspicious. Likewise, the order is important. If connections to sequentially growing ports were made, it is more likely that it was a scan virus, whereas the same set of ports in random order is more like normal traffic. These are just simple examples. We would like to see more complex patterns. A typical machine on the network can have multiple activities with different types of service (e.g. HTTP, SMTP). The number of ports describing the type of service a particular port belongs to."}, {"heading": "4.1 A CTBN Model for Network Traffic", "text": "We use the same port-level submodel as our previous work (Xu & Shelton, 2008), so we have a latent variable H and four fully observed toggle variables: Pin, Pout, Cinc, Cdec. The Packet-in, Pin and Packet-out, Pout nodes represent the transmission of a packet to or from the host. They have no intrinsic state: the transmission of a packet is essentially an immediate event. Therefore, they have events (or \"transitions\") without state. This is modeled using a toggle variable in which an event is evidence of a change in the state of the variable and the transition rate associated with each state being the same. Connection Increase Cin and Connection Disconnect Cdec together describe the status of the number of concurrent connections C active on the host."}, {"heading": "4.2 Parameter Learning Using RBPF", "text": "To calculate the expected sufficient statistics in the E-step of the EM learning process, we use a particle filter to efficiently analyze a portion of the variables. It is expected that the exact inference algorithm of Nodelman et al. (2002) that all variables are embedded in a common intensity matrix and the reasons for the resulting homogeneous Markov process. The time complexity is exponential in the number of variables. For example, if there are 9 portal models, the network contains 46 variables in the total number. (Fan & Shelton, 2008) and the importance of sampling techniques such as the clique tree algorithm (Nodelman et al., 2002), the algorithms (Nodelman et al., 2005; Saria et al., 2007), the importance of sampling (Fan & Shelton, 2008) and Gibbs sampling (El-Hay et al., 2008) overcome this problem by recognizing the particle structure that our black filter has to perfect."}, {"heading": "4.3 Online Testing Using Likelihood", "text": "Once the CTBN model has been adjusted to historical data, we detect attacks by calculating the probability of a window of the data (see Section 6.1). If the probability falls below a threshold, we mark the window as abnormal. Otherwise, we mark it as normal. In our experiments, we fix the window as fixed in time, Tw. So, if the window of interest starts at a point in time T, we want to calculate the probability p (T, T + Tw] where it [s, t] represents the observed connections and packets from time to time t. Again, we use an RBPF to estimate this probability. Samples at a point in time T represent the previous distribution P (G | Earth [0, T]). If we propagate them forward over the window of length Tw, we obtain a series of trajectories for G, gi. Each submodel can balance P (T, T + Tw] by the exact sum (T) of probability (forward weighted)."}, {"heading": "5. Anomaly Detection Using System Calls", "text": "Now we turn to the problem of detecting anomalies using system call protocols."}, {"heading": "5.1 A CTBN Model for System Calls", "text": "The hsci-eaJnmhsrmhsrmhsdcnlhsAeaeu nvo mde hsci-eaJnmhsrmhsrmhsdcnlhsrhsrmhsrmhsAeaeu nvo mde hsci-eaJnmhsrmhsrmhsrhsrhsrhsrmhsAeaeaeu nvo mde hsci-eaJnmhsrmhsrmhsrhsrmhsrmhsrmhsrhsrcnlhsrhsrmhsAeaeaeai.s The hsci-eSrmhsrmhsrmhsrhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrhsrhsrmhsrmhsrhsrmhsrmhsrhsrmhsrmhsrhsrmhsrmhsrmhsrmhsrmhsrmhsrhsrmhsrmhsrmhsAeaeeeeeeeoi.s The hsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrmhsrm"}, {"heading": "5.2 Parameter Estimation with Finite Resolution Clocks", "text": "This means that we know exactly that the system call S1 follows if they are recorded in this order in the audit logs. Thus, all system calls are only partially observed; this kind of partial observation has not previously been taken into account in the logs; a typical history of system calls is recorded in this order in the audit logs; thus, all system calls are only partially observed; this kind of partial observation has not previously been taken into account in the CTBN data; a typical history of system calls is observed in a certain time after the next clock, followed by a quiet phase of arbitrary length, and yet another bundle of events at any time after 1 and so on."}, {"heading": "5.3 Testing Using Likelihood", "text": "Once we have learned the model from the normal process in the system call logs, we calculate the log probability of a future process under the model, and then compare the log probability with a predefined threshold. If it is below the threshold, a possible anomaly is displayed, and these calculations can be performed accurately with just one hidden variable."}, {"heading": "6. Evaluation", "text": "In order to evaluate our methodology, we constructed experiments on two different types of data: traces of network traffic and system call logs. In the following sections, we show the results of the experiments for both tasks. A dynamic Bayesian network (DBN) is another popular technique for graphically modelling temporal data. Because they split time, events without state changes (instantaneous events) are difficult to model. Any reasonable time resolution leads to several events for the same variable within a period of time. There is no standard method for encoding this data in a DBN. When we use a switch variable, it only captures the parity of the number of events over the time interval. In addition, events for the NIDS are very inflated. During active times, several packets are sent per second. During inactive times, there can be no activity for hours."}, {"heading": "6.1 Experiment Results on Network Traffic", "text": "In this section we present our experimental results on NIDS."}, {"heading": "6.1.1 DATASETS", "text": "We verify our approach using two publicly available real-time trace repositories for network traffic: the MAWI backbone traffic working group MAWI and the LBNL / ICSI internal enterprise traffic LBNL.The MAWI backbone traffic is part of the WIDE project, which has been collecting daily packet header traces since 2001. It captures network traffic through the inter-Pacific tunnel between Japan and the U.S. The dataset uses tcpdump and IP anonymization tools to record 15-minute traces every day, and consists largely of traffic to or from Japanese universities. In our experiment, we use the traces from January 1 to 4, 2008, with 36,592,148 connections over a total duration of one hour. The LBNL traces are recorded by a medium-sized website, with an emphasis on the characterization of internal corporate traffic."}, {"heading": "6.1.2 WORM DETECTION", "text": "We start with the problem of worm detection (Xu & Shelter, 2008), which divides traffic lanes for each host: half for training and half for testing. We learn a CTBN model from the training data of each host. As the available network data is not all known intruders, we will select the real attack paths in the test areas, especially if it is below the threshold, we predict it as an abnormal time span. We define the basic truth for a window to be abnormal when a single log value exists for each sliding window, and compare it to a predefined threshold. We only consider windows that compare our method with our previous use of RBPF with our previous factored model. We define the basic probability for a window in which it exists, and is normal. The window size we use that contains at least one network containing at least one network."}, {"heading": "6.1.3 HOST IDENTIFICATION", "text": "We learn each host based on their network traffic patterns. For example, a household typically installs a network router. Each family member is connected to that router. Outside of the Internet, the network traffic that emanates from the router behaves as if it comes from a peer, but it actually comes from other people. Dad may be reading sports messages while kids are surfing social networks. It's as interesting as it is useful to tell which family member is contributing the current network traffic. The first series of experiments we construct is a host model that fights identity theft. If a network identity is being abused by the attacker, host identification techniques can help the network administrator determine whether the current network traffic of that host is consistent or not. The first series of experiments we construct is a host model that matches the competition. The same 10 hosts chose for the worm identification tasks of LBNL datets that matched our test pool BN, which we learned to top-up each host."}, {"heading": "6.2 Experiment Results on System Call Logs", "text": "In this section we present our experimental results on HIDS."}, {"heading": "6.2.1 DATASET", "text": "The dataset we used is the 1998 DARPA Intrusion Detection Evaluation Data Set from MIT Lincoln Laboratory. Seven weeks of training data containing network-based attacks marked in the middle of normal background data are available on the DARPA website. Solaris Basic Security Module (BSM) praudit audit data on system call logs are for research analysis. We follow Kang, Fuller and Honavar (2005) to cross the BSM protocols and create a labeled list file that identifies individual processes. The resulting statistics are in the left table of Figure 11. The frequency of all system calls appearing in the dataset is summarized in descending order to the right of Figure 11."}, {"heading": "6.2.2 ANOMALY DETECTION", "text": "Our experimental goal is to detect abnormal processes. We train our CTBN model on normal processes only and test on a mixture of normal and attack processes. The state space of the held variable H is set to 2. The log probability of an entire process under the learned model represents the score of this process. We compare the score with a predefined threshold to classify the process as normal. We implement sequence time-delayed embedding (stems) and stings with the frequency threshold for comparison (Warrender, & Pearlmutter, 1999). These two algorithms build a database of all previously seen system calls and compare the test sequences with it. They are direct and perform very well on the system threshold (t)."}, {"heading": "7. Conclusions", "text": "In the field of time reasoning, we introduced two additions to the CTBN literature: First, we showed a particle filter with continuous evidence, the Rao-Blackwell particle filter. Second, we showed that we can learn and think about data that contains inaccurate timings without discrediting time. In the field of intrusion detection, we demonstrated a framework that handles two interconnected tasks well with very different types of data. By focusing solely on the timing of events, without taking into account complex characteristics, we were able to trump existing methods. The continuous nature of our model greatly contributed to modelling the bursting event sequences that occur in system logs and network traffic. We did not have to resort to time-splitting to produce either fast cuts that are inefficient over long periods of time, or long cuts that would complicate timing of system events (a combination of the two information queries)."}, {"heading": "Acknowledgments", "text": "This project was supported by Intel Research and UC MICRO, the Air Force Office of Scientific Research (FA9550-07-1-0076) and the Defense Advanced Research Project Agency (HR001109-1-0030)."}], "references": [{"title": "An adaptive anomaly detector for worm detection", "author": ["J.M. Agosta", "C. Duik-Wasser", "J. Chandrashekar", "C. Livadas"], "venue": "In Workshop on Tackling Computer Systems Problems with Machine Learning Techniques", "citeRegEx": "Agosta et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Agosta et al\\.", "year": 2007}, {"title": "Intrusion detection using sequences of system calls", "author": ["S.A.Hofmeyr", "S. Forrest", "A. Somayaji"], "venue": "Journal of Computer Security,", "citeRegEx": "A.Hofmeyr et al\\.,? \\Q1998\\E", "shortCiteRegEx": "A.Hofmeyr et al\\.", "year": 1998}, {"title": "Host anomaly detection performance analysis based on system call of neuro-fuzzy using soundex algorithm and n-gram technique", "author": ["B. Cha"], "venue": "In Systems Communications (ICW)", "citeRegEx": "Cha,? \\Q2005\\E", "shortCiteRegEx": "Cha", "year": 2005}, {"title": "LIBSVM: a library for support vector machines. http:// www.csie.ntu.edu.tw/ \u0303cjlin/libsvm", "author": ["Chang", "C.-C", "Lin", "C.-J"], "venue": null, "citeRegEx": "Chang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2001}, {"title": "Mean field variational approximation for continous-time Bayesian networks", "author": ["I. Cohn", "T. El-Hay", "N. Friedman", "R. Kupferman"], "venue": "In Uncertainty in Artificial Intelligence", "citeRegEx": "Cohn et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 2009}, {"title": "Extracting hidden anomalies using sketch and non Gaussian multiresulotion statistical detection procedures", "author": ["G. Dewaele", "K. Fukuda", "P. Borgnat"], "venue": "In ACM SIGCOMM", "citeRegEx": "Dewaele et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dewaele et al\\.", "year": 2007}, {"title": "Rao-Blackwellised particle filtering for dynamic Bayesian networks", "author": ["A. Doucet", "N. de Freitas", "K. Murphy", "S. Russel"], "venue": "In Uncertainty in Artificial Intelligence", "citeRegEx": "Doucet et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Doucet et al\\.", "year": 2000}, {"title": "Continuous-time belief propagation", "author": ["T. El-Hay", "I. Cohn", "N. Friedman", "R. Kupferman"], "venue": "In Proceedings of the Twenty-Seventh International Conference on Machine Learning", "citeRegEx": "El.Hay et al\\.,? \\Q2010\\E", "shortCiteRegEx": "El.Hay et al\\.", "year": 2010}, {"title": "Gibbs sampling in factorized continous-time Markov processes", "author": ["T. El-Hay", "N. Friedman", "R. Kupferman"], "venue": "In Uncertainty in Artificial Intelligence", "citeRegEx": "El.Hay et al\\.,? \\Q2008\\E", "shortCiteRegEx": "El.Hay et al\\.", "year": 2008}, {"title": "Anomaly detection over noisy data using learned probability distributions", "author": ["E. Eskin"], "venue": "In International Conference on Machine Learning", "citeRegEx": "Eskin,? \\Q2000\\E", "shortCiteRegEx": "Eskin", "year": 2000}, {"title": "A geometric framework for unsupervised anomaly detection: Detecting intrusions in unlabeled data", "author": ["E. Eskin", "A. Arnold", "M. Prerau", "L. Portnoy", "S. Stolfo"], "venue": "Applications of Data Mining in Computer Security. Kluwer", "citeRegEx": "Eskin et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Eskin et al\\.", "year": 2002}, {"title": "Sampling for approximate inference in continuous time Bayesian networks", "author": ["Y. Fan", "C.R. Shelton"], "venue": "In Symposium on Artificial Intelligence and Mathematics", "citeRegEx": "Fan and Shelton,? \\Q2008\\E", "shortCiteRegEx": "Fan and Shelton", "year": 2008}, {"title": "Learning continuous-time social network dynamics", "author": ["Y. Fan", "C.R. Shelton"], "venue": "In Proceedings of the Twenty-Fifth International Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Fan and Shelton,? \\Q2009\\E", "shortCiteRegEx": "Fan and Shelton", "year": 2009}, {"title": "A sense of self for unix processes", "author": ["S. Forrest", "S.A.Hofmeyr", "A. Somayaji", "T.A.Longstaff"], "venue": "In IEEE Symposium on Security and Privacy,", "citeRegEx": "Forrest et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Forrest et al\\.", "year": 1996}, {"title": "Robust support vector machines for anomaly detection in computer security", "author": ["W. Hu", "Y. Liao", "V. Vemuri"], "venue": "In International Conference on Machine Learning and Applications", "citeRegEx": "Hu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2003}, {"title": "Learning classifiers for misuse detetction using a bag of system calls representation", "author": ["Kang", "D.-K", "D. Fuller", "V. Honavar"], "venue": "In IEEE International Conferences on Intelligence and Security Informatics", "citeRegEx": "Kang et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Kang et al\\.", "year": 2005}, {"title": "BLINC: Multilevel traffic classification in the dark", "author": ["T. Karagiannis", "K. Papagiannaki", "M. Faloutsos"], "venue": "In ACM SIGCOMM", "citeRegEx": "Karagiannis et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Karagiannis et al\\.", "year": 2005}, {"title": "Bayesian event classification for intrusion detection", "author": ["C. Kruegel", "D. Mutz", "W. Robertson", "F. Valeur"], "venue": "In Annual Computer Security Applications Conference", "citeRegEx": "Kruegel et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kruegel et al\\.", "year": 2003}, {"title": "Mining anomalies using traffic feature distributions", "author": ["A. Lakhina", "M. Crovella", "C. Diot"], "venue": "In ACM SIGCOMM,", "citeRegEx": "Lakhina et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Lakhina et al\\.", "year": 2005}, {"title": "A compare study of anomaly detection schemes in network intrusion detection", "author": ["A. Lazarevic", "L. Ertoz", "V. Kumar", "A. Ozgur", "J. Srivastava"], "venue": "In SIAM International Conference on Data Mining", "citeRegEx": "Lazarevic et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Lazarevic et al\\.", "year": 2003}, {"title": "The spectrum kernel: A string kernel for SVM protein classification", "author": ["C. Leslie", "E. Eskin", "W.S. Noble"], "venue": "In Pacific Symposium on Biocomputing", "citeRegEx": "Leslie et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Leslie et al\\.", "year": 2002}, {"title": "Host-based detection of worms through peer to peer cooperation", "author": ["D.J. Malan", "M.D. Smith"], "venue": "In Workshop on Rapid Malcode", "citeRegEx": "Malan and Smith,? \\Q2005\\E", "shortCiteRegEx": "Malan and Smith", "year": 2005}, {"title": "Internet traffic classification using Bayesian analysis techniques", "author": ["A.W. Moore", "D. Zuev"], "venue": "In ACM SIGMETRICS", "citeRegEx": "Moore and Zuev,? \\Q2005\\E", "shortCiteRegEx": "Moore and Zuev", "year": 2005}, {"title": "Continuous time particle filtering", "author": ["B. Ng", "A. Pfeffer", "R. Dearden"], "venue": "InNational Conference on Artificial Intelligence,", "citeRegEx": "Ng et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ng et al\\.", "year": 2005}, {"title": "Continuous time Bayesian networks for inferring users\u2019 presence and activities with extensions for modeling and evaluation", "author": ["U. Nodelman", "E. Horvitz"], "venue": "Tech. rep. MSR-TR-2003-97, Microsoft Research", "citeRegEx": "Nodelman and Horvitz,? \\Q2003\\E", "shortCiteRegEx": "Nodelman and Horvitz", "year": 2003}, {"title": "Expectation propagation for continuous time Bayesian networks", "author": ["U. Nodelman", "D. Koller", "C.R. Shelton"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "Nodelman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Nodelman et al\\.", "year": 2005}, {"title": "Continuous time Bayesian networks", "author": ["U. Nodelman", "C.R. Shelton", "D. Koller"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "Nodelman et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Nodelman et al\\.", "year": 2002}, {"title": "Learning continuous time Bayesian networks", "author": ["U. Nodelman", "C.R. Shelton", "D. Koller"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "Nodelman et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Nodelman et al\\.", "year": 2003}, {"title": "Expectation maximization and complex duration distributions for continuous time Bayesian networks", "author": ["U. Nodelman", "C.R. Shelton", "D. Koller"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "Nodelman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Nodelman et al\\.", "year": 2005}, {"title": "Numerical Recipes in C (Second edition)", "author": ["W.H. Press", "S.A. Teukolsky", "W.T. Vetterling", "B.P. Flannery"], "venue": null, "citeRegEx": "Press et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Press et al\\.", "year": 1992}, {"title": "Attack plan recognition and prediction using causal networks", "author": ["X. Qin", "W. Lee"], "venue": "In Annual Computer Security Application Conference,", "citeRegEx": "Qin and Lee,? \\Q2004\\E", "shortCiteRegEx": "Qin and Lee", "year": 2004}, {"title": "Language models for detection of unknown attacks in network traffic", "author": ["K. Rieck", "P. Laskov"], "venue": "In Journal in Computer Virology", "citeRegEx": "Rieck and Laskov,? \\Q2007\\E", "shortCiteRegEx": "Rieck and Laskov", "year": 2007}, {"title": "Reasoning at the right time granularity", "author": ["S. Saria", "U. Nodelman", "D. Koller"], "venue": "InUncertainty in Artificial Intelligence", "citeRegEx": "Saria et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Saria et al\\.", "year": 2007}, {"title": "CT-NOR: Representing and reasoning about events in continuous time", "author": ["A. Simma", "M. Goldszmidt", "J. MacCormick", "P. Barham", "R. Black", "R. Isaacs", "R. Mortier"], "venue": "In Uncertainty in Artificial Intelligence", "citeRegEx": "Simma et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Simma et al\\.", "year": 2008}, {"title": "Flow classification by histogram", "author": ["A. Soule", "L. Salamatian", "N. Taft", "R. Emilion", "K. Papagiannali"], "venue": "In ACM SIGMETRICS", "citeRegEx": "Soule et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Soule et al\\.", "year": 2004}, {"title": "Combining filtering and statistical methods for anomaly detection", "author": ["A. Soule", "K. Salamatian", "N. Taft"], "venue": "In Internet Measurement Conference,", "citeRegEx": "Soule et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Soule et al\\.", "year": 2005}, {"title": "Learning useful system call attributes for anomaly detection", "author": ["G. Tandon", "P.K. Chan"], "venue": "In The Florida Artificial Intelligence Research Society Conference,", "citeRegEx": "Tandon and Chan,? \\Q2005\\E", "shortCiteRegEx": "Tandon and Chan", "year": 2005}, {"title": "Detecting intrusions using system calls: Alternative data models", "author": ["C. Warrender", "S. Forrest", "B. Pearlmutter"], "venue": "In IEEE Symposium on Security and Privacy,", "citeRegEx": "Warrender et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Warrender et al\\.", "year": 1999}, {"title": "Continuous time Bayesian networks for host level network intrusion detection", "author": ["J. Xu", "C.R. Shelton"], "venue": "In European Conference on Machine Learning", "citeRegEx": "Xu and Shelton,? \\Q2008\\E", "shortCiteRegEx": "Xu and Shelton", "year": 2008}, {"title": "Profiling internet backbone traffic: Behavior models and applications", "author": ["K. Xu", "Zhang", "Z.-L", "S. Bhattacharyya"], "venue": "In ACM SIGCOMM", "citeRegEx": "Xu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2005}, {"title": "Multivariate statistical analysis of audit trails for host-based intrusion detection", "author": ["N. Ye", "S.M. Emran", "Q. Chen", "S. Vilbert"], "venue": "IEEE Transactions of Computers,", "citeRegEx": "Ye et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ye et al\\.", "year": 2002}, {"title": "Parzen-window network intrusion detectors", "author": ["Yeung", "D.-Y", "C. Chow"], "venue": "In International Conference on Pattern Recognition", "citeRegEx": "Yeung et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Yeung et al\\.", "year": 2002}, {"title": "User profiling for intrusion detection using dynamic and static", "author": ["XU", "SHELTON Yeung", "D.-Y", "Y. Ding"], "venue": null, "citeRegEx": "XU et al\\.,? \\Q2002\\E", "shortCiteRegEx": "XU et al\\.", "year": 2002}], "referenceMentions": [{"referenceID": 9, "context": "The work of Eskin, Arnold, Prerau, Portnoy, and Stolfo (2002) is similar to our approach in that they apply their method to both of these kinds of", "startOffset": 12, "endOffset": 62}, {"referenceID": 18, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al.", "startOffset": 145, "endOffset": 168}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al.", "startOffset": 169, "endOffset": 180}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al.", "startOffset": 169, "endOffset": 200}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information.", "startOffset": 169, "endOffset": 225}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information. Network-wide data and human intervention have advantages, but they can also lead to difficulties (data collation in the face of an attack and increased human effort), so we chose to leave them out of our solution. Many learning, or adaptive, methods have been proposed for network data. Some of these \u2014 for example, those of Zuev and Moore (2005) and Soule, Salamatian, Taft, Emilion, and Papagiannali (2004) \u2014 approach the problem as a classification task which requires labeled data.", "startOffset": 169, "endOffset": 760}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information. Network-wide data and human intervention have advantages, but they can also lead to difficulties (data collation in the face of an attack and increased human effort), so we chose to leave them out of our solution. Many learning, or adaptive, methods have been proposed for network data. Some of these \u2014 for example, those of Zuev and Moore (2005) and Soule, Salamatian, Taft, Emilion, and Papagiannali (2004) \u2014 approach the problem as a classification task which requires labeled data.", "startOffset": 169, "endOffset": 822}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information. Network-wide data and human intervention have advantages, but they can also lead to difficulties (data collation in the face of an attack and increased human effort), so we chose to leave them out of our solution. Many learning, or adaptive, methods have been proposed for network data. Some of these \u2014 for example, those of Zuev and Moore (2005) and Soule, Salamatian, Taft, Emilion, and Papagiannali (2004) \u2014 approach the problem as a classification task which requires labeled data. Dewaele, Fukuda, and Borgnat (2007) profile the statistical characteristics of anomalies by using random projection techniques (sketches) to reduce the data dimensionality and a multi-resolution non-Gaussian marginal distribution to extract anomalies at different aggregation levels.", "startOffset": 169, "endOffset": 935}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information. Network-wide data and human intervention have advantages, but they can also lead to difficulties (data collation in the face of an attack and increased human effort), so we chose to leave them out of our solution. Many learning, or adaptive, methods have been proposed for network data. Some of these \u2014 for example, those of Zuev and Moore (2005) and Soule, Salamatian, Taft, Emilion, and Papagiannali (2004) \u2014 approach the problem as a classification task which requires labeled data. Dewaele, Fukuda, and Borgnat (2007) profile the statistical characteristics of anomalies by using random projection techniques (sketches) to reduce the data dimensionality and a multi-resolution non-Gaussian marginal distribution to extract anomalies at different aggregation levels. The goal of such papers is usually not to detect attacks but rather to classify non-attacks by traffic type; if applied to attack detection, they would risk missing new types of attacks. Furthermore, they frequently treat each network activity separately, instead of considering their temporal context. Lakhina, Crovella, and Diot (2005) has a nice summary of adaptive (or statistical) methods that look at anomaly detection (instead of classification).", "startOffset": 169, "endOffset": 1521}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information. Network-wide data and human intervention have advantages, but they can also lead to difficulties (data collation in the face of an attack and increased human effort), so we chose to leave them out of our solution. Many learning, or adaptive, methods have been proposed for network data. Some of these \u2014 for example, those of Zuev and Moore (2005) and Soule, Salamatian, Taft, Emilion, and Papagiannali (2004) \u2014 approach the problem as a classification task which requires labeled data. Dewaele, Fukuda, and Borgnat (2007) profile the statistical characteristics of anomalies by using random projection techniques (sketches) to reduce the data dimensionality and a multi-resolution non-Gaussian marginal distribution to extract anomalies at different aggregation levels. The goal of such papers is usually not to detect attacks but rather to classify non-attacks by traffic type; if applied to attack detection, they would risk missing new types of attacks. Furthermore, they frequently treat each network activity separately, instead of considering their temporal context. Lakhina, Crovella, and Diot (2005) has a nice summary of adaptive (or statistical) methods that look at anomaly detection (instead of classification). They use an entropy-based method for the entire network traffic. Many of the other methods, such as that of Ye, Emran, Chen, and Vilbert (2002), use either statistical tests or subspace methods that assume the features of the connections or packets are distributed normally.", "startOffset": 169, "endOffset": 1781}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information. Network-wide data and human intervention have advantages, but they can also lead to difficulties (data collation in the face of an attack and increased human effort), so we chose to leave them out of our solution. Many learning, or adaptive, methods have been proposed for network data. Some of these \u2014 for example, those of Zuev and Moore (2005) and Soule, Salamatian, Taft, Emilion, and Papagiannali (2004) \u2014 approach the problem as a classification task which requires labeled data. Dewaele, Fukuda, and Borgnat (2007) profile the statistical characteristics of anomalies by using random projection techniques (sketches) to reduce the data dimensionality and a multi-resolution non-Gaussian marginal distribution to extract anomalies at different aggregation levels. The goal of such papers is usually not to detect attacks but rather to classify non-attacks by traffic type; if applied to attack detection, they would risk missing new types of attacks. Furthermore, they frequently treat each network activity separately, instead of considering their temporal context. Lakhina, Crovella, and Diot (2005) has a nice summary of adaptive (or statistical) methods that look at anomaly detection (instead of classification). They use an entropy-based method for the entire network traffic. Many of the other methods, such as that of Ye, Emran, Chen, and Vilbert (2002), use either statistical tests or subspace methods that assume the features of the connections or packets are distributed normally. Rieck and Laskov (2007) model the language features like n-grams and words from connection payloads.", "startOffset": 169, "endOffset": 1936}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information. Network-wide data and human intervention have advantages, but they can also lead to difficulties (data collation in the face of an attack and increased human effort), so we chose to leave them out of our solution. Many learning, or adaptive, methods have been proposed for network data. Some of these \u2014 for example, those of Zuev and Moore (2005) and Soule, Salamatian, Taft, Emilion, and Papagiannali (2004) \u2014 approach the problem as a classification task which requires labeled data. Dewaele, Fukuda, and Borgnat (2007) profile the statistical characteristics of anomalies by using random projection techniques (sketches) to reduce the data dimensionality and a multi-resolution non-Gaussian marginal distribution to extract anomalies at different aggregation levels. The goal of such papers is usually not to detect attacks but rather to classify non-attacks by traffic type; if applied to attack detection, they would risk missing new types of attacks. Furthermore, they frequently treat each network activity separately, instead of considering their temporal context. Lakhina, Crovella, and Diot (2005) has a nice summary of adaptive (or statistical) methods that look at anomaly detection (instead of classification). They use an entropy-based method for the entire network traffic. Many of the other methods, such as that of Ye, Emran, Chen, and Vilbert (2002), use either statistical tests or subspace methods that assume the features of the connections or packets are distributed normally. Rieck and Laskov (2007) model the language features like n-grams and words from connection payloads. Xu, Zhang, and Bhattacharyya (2005) also use unsupervised methods, but they concentrate on clustering traffic across a whole network.", "startOffset": 169, "endOffset": 2049}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information. Network-wide data and human intervention have advantages, but they can also lead to difficulties (data collation in the face of an attack and increased human effort), so we chose to leave them out of our solution. Many learning, or adaptive, methods have been proposed for network data. Some of these \u2014 for example, those of Zuev and Moore (2005) and Soule, Salamatian, Taft, Emilion, and Papagiannali (2004) \u2014 approach the problem as a classification task which requires labeled data. Dewaele, Fukuda, and Borgnat (2007) profile the statistical characteristics of anomalies by using random projection techniques (sketches) to reduce the data dimensionality and a multi-resolution non-Gaussian marginal distribution to extract anomalies at different aggregation levels. The goal of such papers is usually not to detect attacks but rather to classify non-attacks by traffic type; if applied to attack detection, they would risk missing new types of attacks. Furthermore, they frequently treat each network activity separately, instead of considering their temporal context. Lakhina, Crovella, and Diot (2005) has a nice summary of adaptive (or statistical) methods that look at anomaly detection (instead of classification). They use an entropy-based method for the entire network traffic. Many of the other methods, such as that of Ye, Emran, Chen, and Vilbert (2002), use either statistical tests or subspace methods that assume the features of the connections or packets are distributed normally. Rieck and Laskov (2007) model the language features like n-grams and words from connection payloads. Xu, Zhang, and Bhattacharyya (2005) also use unsupervised methods, but they concentrate on clustering traffic across a whole network. Similarly, Soule, Salamatian, and Taft (2005) build an anomaly detector based on Markov models, but it is for the network traffic patterns as a whole and does not function at the host level.", "startOffset": 169, "endOffset": 2193}, {"referenceID": 2, "context": "In particular, we also assume that we do not have access to the internals of the machines on the networks, which rules out methods like those of Malan and Smith (2005), Cha (2005), Qin and Lee (2004), and Eskin et al. (2002). However, we differ in that our approach does not rely on preset values, require human intervention and interpretation, nor assume that we have access to network-wide traffic information. Network-wide data and human intervention have advantages, but they can also lead to difficulties (data collation in the face of an attack and increased human effort), so we chose to leave them out of our solution. Many learning, or adaptive, methods have been proposed for network data. Some of these \u2014 for example, those of Zuev and Moore (2005) and Soule, Salamatian, Taft, Emilion, and Papagiannali (2004) \u2014 approach the problem as a classification task which requires labeled data. Dewaele, Fukuda, and Borgnat (2007) profile the statistical characteristics of anomalies by using random projection techniques (sketches) to reduce the data dimensionality and a multi-resolution non-Gaussian marginal distribution to extract anomalies at different aggregation levels. The goal of such papers is usually not to detect attacks but rather to classify non-attacks by traffic type; if applied to attack detection, they would risk missing new types of attacks. Furthermore, they frequently treat each network activity separately, instead of considering their temporal context. Lakhina, Crovella, and Diot (2005) has a nice summary of adaptive (or statistical) methods that look at anomaly detection (instead of classification). They use an entropy-based method for the entire network traffic. Many of the other methods, such as that of Ye, Emran, Chen, and Vilbert (2002), use either statistical tests or subspace methods that assume the features of the connections or packets are distributed normally. Rieck and Laskov (2007) model the language features like n-grams and words from connection payloads. Xu, Zhang, and Bhattacharyya (2005) also use unsupervised methods, but they concentrate on clustering traffic across a whole network. Similarly, Soule, Salamatian, and Taft (2005) build an anomaly detector based on Markov models, but it is for the network traffic patterns as a whole and does not function at the host level. The work of Soule et al. (2004) is very similar in statistical flavor to our work.", "startOffset": 169, "endOffset": 2370}, {"referenceID": 21, "context": "The work of Moore and Zuev (2005), like our approach, models traffic with graphical models, in particular, Naive Bayes networks.", "startOffset": 12, "endOffset": 34}, {"referenceID": 21, "context": "The work of Moore and Zuev (2005), like our approach, models traffic with graphical models, in particular, Naive Bayes networks. But their goal is to categorize network traffic instead of detecting attacks. Kruegel, Mutz, Robertson, and Valeur (2003) present a Bayesian approach to the detecting problem as an event classification task while we only care about whether the host is under attack during an interval.", "startOffset": 12, "endOffset": 251}, {"referenceID": 21, "context": "The work of Moore and Zuev (2005), like our approach, models traffic with graphical models, in particular, Naive Bayes networks. But their goal is to categorize network traffic instead of detecting attacks. Kruegel, Mutz, Robertson, and Valeur (2003) present a Bayesian approach to the detecting problem as an event classification task while we only care about whether the host is under attack during an interval. The work of Lazarevic, Ertoz, Kumar, Ozgur, and Srivastava (2003) is also similar to our work.", "startOffset": 12, "endOffset": 480}, {"referenceID": 2, "context": "Agosta, Duik-Wasser, Chandrashekar, and Livadas (2007) present an adaptive detector whose threshold is time-varying.", "startOffset": 21, "endOffset": 55}, {"referenceID": 2, "context": "Tandon and Chan (2005) look at a richer set of attributes like return value and arguments associated with a system call while we only make use of the system call names.", "startOffset": 11, "endOffset": 23}, {"referenceID": 2, "context": "Tandon and Chan (2005) look at a richer set of attributes like return value and arguments associated with a system call while we only make use of the system call names. Feature based methods like those of Hu, Liao, and Vemuri (2003) use the same dataset we use, the DARPA 1998 BSM dataset, but their training data is noisy and they try to find a classification hyperplane using robust support vector machines (RSVMs) to separate normal system call profiles from intrusive ones.", "startOffset": 11, "endOffset": 233}, {"referenceID": 2, "context": "Tandon and Chan (2005) look at a richer set of attributes like return value and arguments associated with a system call while we only make use of the system call names. Feature based methods like those of Hu, Liao, and Vemuri (2003) use the same dataset we use, the DARPA 1998 BSM dataset, but their training data is noisy and they try to find a classification hyperplane using robust support vector machines (RSVMs) to separate normal system call profiles from intrusive ones. Eskin (2000) also works on noisy data.", "startOffset": 11, "endOffset": 491}, {"referenceID": 2, "context": "Tandon and Chan (2005) look at a richer set of attributes like return value and arguments associated with a system call while we only make use of the system call names. Feature based methods like those of Hu, Liao, and Vemuri (2003) use the same dataset we use, the DARPA 1998 BSM dataset, but their training data is noisy and they try to find a classification hyperplane using robust support vector machines (RSVMs) to separate normal system call profiles from intrusive ones. Eskin (2000) also works on noisy data. They make the assumption that their training data contains a large portion of normal elements and few anomalies. They present a mixture of distribution over normal and abnormal data and calculate the likelihood change if a data point is moved from normal part to abnormal part to get the optimum data partition. Yeung and Ding (2002) try to use both techniques.", "startOffset": 11, "endOffset": 851}, {"referenceID": 25, "context": "Nodelman et al. (2002) extend the theory of HMPs and present continuous time Bayesian networks (CTBNs), which model the joint dynamics of several local variables by allowing the transition model of each local variable X to be a Markov process whose parametrization depends on some subset of other variables U .", "startOffset": 0, "endOffset": 23}, {"referenceID": 27, "context": "Definition 2 (Nodelman et al., 2003) A continuous time Bayesian networkN over a set of stochastic processes X consists of two components: an initial distribution P 0 X , specified as a Bayesian network B over a set of random variables X, and a continuous transition model, specified using a directed (possibly cyclic) graph G whose nodes areX \u2208 X; UX denotes the parents ofX in G.", "startOffset": 13, "endOffset": 36}, {"referenceID": 11, "context": "Fan and Shelton (2008) give another sampling based approach that uses importance sampling.", "startOffset": 0, "endOffset": 23}, {"referenceID": 11, "context": "Fan and Shelton (2008) give another sampling based approach that uses importance sampling. El-Hay, Cohn, Friedman, and Kupferman (2010) describe a different expectation propagation approach.", "startOffset": 0, "endOffset": 136}, {"referenceID": 11, "context": "Fan and Shelton (2008) give another sampling based approach that uses importance sampling. El-Hay, Cohn, Friedman, and Kupferman (2010) describe a different expectation propagation approach. To estimate the parameters of the models we build for the two applications (NIDS and HIDS), we employ inference algorithms including exact inference and a Rao-Blackwellized particle filtering (RBPF) algorithm, depending on the model size. Ng et al. (2005) extended RBPF to CTBNs.", "startOffset": 0, "endOffset": 447}, {"referenceID": 21, "context": "Nodelman and Horvitz (2003) used CTBNs to reason about users\u2019 presence and availability over time.", "startOffset": 0, "endOffset": 28}, {"referenceID": 21, "context": "Ng et al. (2005) used CTBNs to monitor a mobile robot.", "startOffset": 0, "endOffset": 17}, {"referenceID": 21, "context": "Ng et al. (2005) used CTBNs to monitor a mobile robot. Nodelman et al. (2005) used CTBNs to model life event history.", "startOffset": 0, "endOffset": 78}, {"referenceID": 11, "context": "Fan and Shelton (2009) modeled social networks via CTBNs.", "startOffset": 0, "endOffset": 23}, {"referenceID": 26, "context": "Approximate inference techniques like the clique tree algorithm (Nodelman et al., 2002), message passing algorithms (Nodelman et al.", "startOffset": 64, "endOffset": 87}, {"referenceID": 25, "context": ", 2002), message passing algorithms (Nodelman et al., 2005; Saria et al., 2007), importance sampling (Fan", "startOffset": 36, "endOffset": 79}, {"referenceID": 32, "context": ", 2002), message passing algorithms (Nodelman et al., 2005; Saria et al., 2007), importance sampling (Fan", "startOffset": 36, "endOffset": 79}, {"referenceID": 25, "context": "To calculate the expected sufficient statistics in the E-step of EM for parameter learning, the exact inference algorithm of Nodelman et al. (2002) flattens all the variables into a joint intensity matrix and reasons about the resulting homogeneous Markov process.", "startOffset": 125, "endOffset": 148}, {"referenceID": 8, "context": "& Shelton, 2008) and Gibbs sampling (El-Hay et al., 2008) overcome this problem by sacrificing accuracy.", "startOffset": 36, "endOffset": 57}, {"referenceID": 6, "context": "It is difficult to sample directly from the posterior distribution, so we use an importance sampler to sample a particle from a proposal distribution and the particles are weighted by the ratio of its likelihood under the posterior distribution to the likelihood under the proposal distribution (Doucet et al., 2000).", "startOffset": 295, "endOffset": 316}, {"referenceID": 25, "context": "This last integral, \u222b hk P (hk, \u03c4k|g)SS(g, hk, \u03c4k) dhk, and P (\u03c4j |gi) can be calculated using the technique described by Nodelman et al. (2005), for exact ESS calculation.", "startOffset": 122, "endOffset": 145}, {"referenceID": 26, "context": "While those transition rates were set to zero (to force the system to agree with the evidence), such conditioning does not change the diagonal elements of the rate matrix (Nodelman et al., 2002).", "startOffset": 171, "endOffset": 194}, {"referenceID": 25, "context": "Again, we refer to the work of Nodelman et al. (2005) for the algorithm.", "startOffset": 31, "endOffset": 54}, {"referenceID": 19, "context": "Figure 6: Features for nearest neighbor approach from the work of (Lazarevic et al., 2003).", "startOffset": 66, "endOffset": 90}, {"referenceID": 9, "context": "We compare our method employing RBPF with our previous factored CTBN model (Xu & Shelton, 2008), connection counting, nearest neighbor, Parzen-window detector (Yeung & Chow, 2002), and one-class SVM with a spectrum string kernel (Leslie, Eskin, & Noble, 2002). The connection counting method is straightforward. We score a window by the number of initiated connections in the window. As most worms aggregate many connections in a short time, this method captures this particular anomaly well. To make nearest neighbor competitive, we try to extract a reasonable set of features. We follow the feature selection of the work of Lazarevic et al. (2003), who use a total of 23 features.", "startOffset": 238, "endOffset": 650}, {"referenceID": 14, "context": "We follow Hu et al. (2003) and transform a process into a feature vector, consisting of the occurrence numbers of each system call in the process.", "startOffset": 10, "endOffset": 27}], "year": 2010, "abstractText": "Intrusion detection systems (IDSs) fall into two high-level categories: network-based systems (NIDS) that monitor network behaviors, and host-based systems (HIDS) that monitor system calls. In this work, we present a general technique for both systems. We use anomaly detection, which identifies patterns not conforming to a historic norm. In both types of systems, the rates of change vary dramatically over time (due to burstiness) and over components (due to service difference). To efficiently model such systems, we use continuous time Bayesian networks (CTBNs) and avoid specifying a fixed update interval common to discrete-time models. We build generative models from the normal training data, and abnormal behaviors are flagged based on their likelihood under this norm. For NIDS, we construct a hierarchical CTBN model for the network packet traces and use Rao-Blackwellized particle filtering to learn the parameters. We illustrate the power of our method through experiments on detecting real worms and identifying hosts on two publicly available network traces, the MAWI dataset and the LBNL dataset. For HIDS, we develop a novel learning method to deal with the finite resolution of system log file time stamps, without losing the benefits of our continuous time model. We demonstrate the method by detecting intrusions in the DARPA 1998 BSM dataset.", "creator": "TeX"}}}