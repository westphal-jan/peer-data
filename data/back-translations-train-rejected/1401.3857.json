{"id": "1401.3857", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Case-Based Subgoaling in Real-Time Heuristic Search for Video Game Pathfinding", "abstract": "Real-time heuristic search algorithms satisfy a constant bound on the amount of planning per action, independent of problem size. As a result, they scale up well as problems become larger. This property would make them well suited for video games where Artificial Intelligence controlled agents must react quickly to user commands and to other agents actions. On the downside, real-time search algorithms employ learning methods that frequently lead to poor solution quality and cause the agent to appear irrational by re-visiting the same problem states repeatedly. The situation changed recently with a new algorithm, D LRTA*, which attempted to eliminate learning by automatically selecting subgoals. D LRTA* is well poised for video games, except it has a complex and memory-demanding pre-computation phase during which it builds a database of subgoals. In this paper, we propose a simpler and more memory-efficient way of pre-computing subgoals thereby eliminating the main obstacle to applying state-of-the-art real-time search methods in video games. The new algorithm solves a number of randomly chosen problems off-line, compresses the solutions into a series of subgoals and stores them in a database. When presented with a novel problem on-line, it queries the database for the most similar previously solved case and uses its subgoals to solve the problem. In the domain of pathfinding on four large video game maps, the new algorithm delivers solutions eight times better while using 57 times less memory and requiring 14% less pre-computation time.", "histories": [["v1", "Thu, 16 Jan 2014 05:02:02 GMT  (1088kb)", "http://arxiv.org/abs/1401.3857v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["vadim bulitko", "yngvi bj\\\"ornsson", "ramon lawrence"], "accepted": false, "id": "1401.3857"}, "pdf": {"name": "1401.3857.pdf", "metadata": {"source": "CRF", "title": "Case-Based Subgoaling in Real-Time Heuristic Search for Video Game Pathfinding", "authors": ["Vadim Bulitko", "Yngvi Bj\u00f6rnsson", "Ramon Lawrence"], "emails": ["BULITKO@UALBERTA.CA", "YNGVI@RU.IS", "RAMON.LAWRENCE@UBC.CA"], "sections": [{"heading": "1. Introduction", "text": "In fact, it is the case that most people are able to determine for themselves what they want and what they want. (...) In fact, it is the case that people are able to determine for themselves what they want. (...) It is not that they want it. (...) It is not that they want it. (...) It is that they want it. (...) It is not that they want it. (...) It is that they do not want it. (...) It is that they want it. (...) It is that they want it. (...) It is that they want it. (...) It is that they want it. (...) It is that they do not want it. (...) It is that they do not want it. (...) They do not want it. (...) They do not want it. (...) They do not want it. (...)"}, {"heading": "2. Problem Formulation", "text": "We define a heuristic search problem as a directed graph that has a finite series of states (vertices) and weighted edges until a single state is designated as the destination state. At any given time, a search agent has a single current state, a vertex in the search chart, and takes action (or takes a step) by traversing an edge between the states s1 and s2 of the agent that changes its current state from s1 to s2. We say that a state is visited by the agent when it is the current state of the agent at some point in time. As it is common in the field of real heuristic search, we assume that the route planning happens between steps (i.e.) the agent does not think while traversing an edge, \"we plan a move\" - \"an edge\" loop until the agent gets to his destination state and solves the problem."}, {"heading": "3. LRTA*: The Core Algorithm", "text": "The core of most heuristic real-time search algorithms is an algorithm called Learning Real-Time A * (LRTA *) (Korf, 1990). It is illustrated in Figure 1 and works as follows: \"As long as the target-state target is not reached, the algorithm links planning and execution in lines 4 to 7. In our generalized version, we have added a new step in line 3 to select the target-state target (the original algorithm uses the global target at all times).We will describe the details of the target selection later in the thesis. In line 4, a cost-limited width-first double-detection search is used to find border states with costs up to Gmax away from the current state. For each border state, its value is the sum of the costs of a shortest path from s to s-destination, which is denoted by g (s, s)."}, {"heading": "4. Related Research", "text": "Most of the resulting algorithms can be described by the following four attributes: The local search space is the totality of states whose heuristic strategies are accessed during the planning stage; the two joint decisions are complete decisions with limited depth (Korf, 1990; Shimbo & Ishida, 2003; Shue, Li, & Zamani, 2001; Furcy & Koenig, 2000; Hern\u00e1ndez \"n, 2005a; Sigmundarson & Ishida, 2006; Sigmundarson & Bjo\" s, 2006; Rayner, Davison, Anderson, & Lu, 2007) and A * -shaped lookahead (Koenig, 2004; Koenig & Likhachev, 2006); other decisions are decision theory formations (Russell & Wefald, 1991) and dynamic choices (Koenig, 2004; Koenig & Likhachev, 2006)."}, {"heading": "5. Intuition for kNN LRTA*", "text": "In fact, it is so that we are in a time, in which we are in a phase, in which we are in a phase, in which we are in a phase, in which we are in a phase, in which we are in a phase, in which we are in a phase, in which we are in a phase, in which we are in which we are in a phase, in which we are in which we are in a phase, in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we in which we are in which we in which we are in which we in which we are in which we are in which we in which we are in which we are in which we in which we are in which we in which we are in which we in which we are in which we in which we are in which we in which we in which we are in which we are in which we in which we in which we are in which we in which we are in which we in which we in which we are in which we in which we are in which we in which we in which we in which we are in which we in which we are in which we in which we are in which we in which we are in which we are in which we are in which we are in which we in which we in which we in which we are in which we in which we in which we in which we are in which we in which we are in which we are in which are in which we in which we in which we in which we in which we are in which we are in which we in which we are in which we in which we are in which we are in which we in which we are in which we are in which we in which we are in which we in which we are in which we are in which we in which we are in which we in which we are in which we in which we are in which we are in which we in which we in which we in which we are in which we in which we in which we in which we in which we in which we in which are in which we in which we in which we in which we in"}, {"heading": "6. kNN LRTA* in Detail", "text": "In this section we specify kNN LRTA * in such detail that it can be implemented by other researchers, starting with a base version and then describing some significant improvements."}, {"heading": "6.1 Basic kNN LRTA*", "text": "kNN LRTA * consists of two parts: database precalculation (offline) and LRTA * with dynamically selected sub-targets (on-line. pseudocode for the offline part is in fact represented in line 5. The top-level function computeSubgoals takes a user-controlled parameter N and a search graph (e.g., a grid-based map in path finding) and builds a sub-target database of N \u00b2 compressed paths. Each path is randomly selected in line 4 of start and destination states (sstart, s 1 sub-destination, s np). If the path does not exist or is too short (line 5), we discard it and regenerate the start and target states. The sequence of states is compressed in the function that returns a sequence of states (sstart, s 1 sub-destination, s np)."}, {"heading": "6.2 Enhanced kNN LRTA*", "text": "We have introduced the basic kNN LRTA * algorithms that are on the verge of reaching the data set. In this section, we introduce six extensions. First, before selecting a record in the selectSubgoals function, we check whether the global target is reachable from the current state of the agent. Second, by selecting a record in the selectSubgoals routine, we perform an accessibility check between the current state of the agent and the first sub-target in the record. If the first sub-target is attainable, we set it as a target for LRTA *. Otherwise, we set the LRTA * start state of the record that is already being checked to be attainable within the selectSubgoals function. Third, when the state LRTA * is reached."}, {"heading": "7. Theoretical Analysis", "text": "In this section we check the completeness of the algorithm and analyze its complexity."}, {"heading": "7.1 Off-line Complexity", "text": "Offline kNN LRTA * generates N records in a space of S states. Let's consider the diameter of the space (i.e. the number of states along the longest possible shortest path between two states) as \u03b4S. Theorem 1 Offline complexity of the worst case of kNN LRTA * is O (N\u03b4S + S).BULITKO, BJO \ufffd RNSSON, & LAWRENCEProof. In the worst case, each optimal path generates kNN LRTA * between randomly selected start and destination is \u03b4S long and minimally compressible. Minimum compression means that each state is stored on the path. If all N records have this property, then the total amount of database storage is O (N\u03b4S). Additionally, A * is executed for each record and has the least favorable space complexity of S. 2Theorem 2 Offline complexity of NLTA * is a logical problem."}, {"heading": "7.2 On-line Complexity", "text": "In this section, we assume that LRTA * generates all immediate neighbors of its current state, and only them on each turn. In our network search, this can easily be achieved by setting gmax = 1.4. More generally, this can be guaranteed by replacing line 4 in Figure 1 with \"Generating immediate succession states of s.\" Theorem 3 kNN LRTA * s on-line is the worst spatial complexity of TA O (dmax + S), where dmax is the maximum out-degree of all vertex states and S is the total number of states. evidence. The open list of kNN LRTA * is at most the maximum number of immediate neighbors of each state (i.e. dmax, dmax). As LRTA * learns, it must store updated heuristic values of which there is no more than S. Therefore, the total spatial complexity of LRTA * O (dmax + S)."}, {"heading": "7.3 Completeness", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "8. Empirical Evaluation", "text": "Identifying pathways in video games is a challenging task, with many units often having to plan their paths at the same time and respond promptly to user commands. Ever-increasing map sizes and limited computing resources allocated to in-game AI make the task even more difficult. Accordingly, video game pathfinding has been used as a testbed in recent work on heuristic real-time search."}, {"heading": "8.1 Test Problems", "text": "Cards modeled after game levels of Baldur's Gate (BioWare Corp, 1998) and WarCraft III: Reign of Chaos (Blizzard Entertainment, 2002) were a common choice (e.g. Sturtevant & Buro, 2005; Bulitko et al., 2008), but these cards are small by today's standards and do not represent the state of the industry. For this paper, we developed a new series of cards modeled after game levels of Counter-Strike: Source (Valve Corporation, 2004), a popular first-person shooter. In this game, the geometry is specified in a vector format. We developed software to convert them into a network of arbitrary resolution, whereas the previous papers are commonly used in the range of 104 to 105 grid cells (e.g. between 150 x 141 and 512 x 512 cells in Sturtevant, 2007)."}, {"heading": "8.2 Algorithms Evaluated", "text": "We rated kNN LRTA * with the following parameters. The size values of the database were in the records {1000, 5000, 10000, 40000, 60000, 80000}. Online, we allowed our mountaineering test to increase by up to 250 steps before concluding that the target state is inaccessible for a particular problem. This value was selected after several experiments and had to be appropriate for the record density on the map. In fact, a larger database requires fewer mountaineering steps to get the likelihood of finding a mountaineering record for a particular problem. BULITKO, BJO \ufffd RNSSON, & LAWRENCEWe performed accessibility checks on the 10 most similar records. 4 Whenever selective targets did not find a matching record, we allowed LRTA * to head toward its global goal, up to three times the heuristic estimate of the remaining path."}, {"heading": "8.3 Solution Suboptimality and Per-Move Planning Time", "text": "In fact, most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are not able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are able to survive on their own. \"(...) Most of them are able to survive on their own.\""}, {"heading": "8.4 Database Pre-computation Time", "text": "The left sub-diagram shows all the parameterizations of D LRTA * and kNN LRTA *, while the right diagram focuses on more powerful configurations. Table 2 shows the individual parameterizations. kNN LRTA * has three advantages over D LRTA *. Firstly, kNN LRTA * with 40,000 and 60,000 datasets easily dominates D LRTA \u2212 \u2212 (9): It has better sub-optimization with a lower pre-computation time. kNN LRTA * (80000) is an overkill for these maps as it does not improve sub-optimization by much (11.96% versus 12.77% achievable with 60000 datasets) while requiring the longest pre-computation time. Secondly, database computation is easier to compare with the kNN LRTA database because the individual datasets are completely independent of each other."}, {"heading": "8.5 Database Size", "text": "In this section, we will focus on database size. The next section will cover all the memory consumed on the line: open and closed lists, and updated heuristic values. Each D-LRTA * database stores exactly three states. kNN LRTA * TA records have two or more states than the number of records."}, {"heading": "8.6 On-line Space Complexity", "text": "This year, it is only a matter of time before an outcome is reached: \"It's too early to say what we want,\" he says. \"It's too early,\" he says, \"but it's too early to do it.\""}, {"heading": "8.7 Simultaneous Pathfinding by Multiple Agents", "text": "In most video games, however, half a dozen to a thousand agents (e.g. Gas Powered Games, 2007) can be found simultaneously on the same map. Such a scenario favors kNN LRTA * and D LRTA *, whose sub-target databases are map-specific but independent of start and destination states. Consequently, multiple agents running D LRTA * and kNN LRTA * can share the same sub-target databases. [6] In contrast, the total memory consumed by TBA * is specific to a particular agent and cannot be shared with other agents operating on the same map. [6] Note that such multiple agents generally cannot share their heuristic h, as it is calculated and updated with respect to different targets. [7] CASE-BASED SUBGOALING IN REAL-TIME HEURISTIC SEARCHHence is the total amount of cumulative connectivity agents equal to the total amount of memory aggregated at the same time as the total amount of K."}, {"heading": "9. Discussion", "text": "This is the first time the high-performance search algorithms TBA *, D LRTA * and D LRTA * have been evaluated."}, {"heading": "10. Current Shortcomings and Future Work", "text": "Although kNN LRTA * exceeds the existing state-of-the-art real-time search algorithms overall for our problems, kNN LRTA * has several shortcomings. Firstly, the database records are generated from randomly selected start and end states. This means that the coverage of the space is not necessarily even: some small but hard-to-reach regions of the space may never get a suitable data set, while some easy-to-reach regions may get multiple redundant data sets covering it. Increasing database efficiency would allow a smaller database to achieve uniform coverage and thus equivalent online performance. This in turn reduces the pre-calculation time of the kNN LRTA * database, which can currently reach over 100 hours per card. While the calculation can be accelerated on an almost linear scale by using multi-core processors, and the time on the gaming company's side can be calculated by selfless minutes, the sub-base of the NTA should be computed by most of the players *."}, {"heading": "11. Beyond Grid Pathfinding", "text": "Formally, with the exception of its kD tree module, the algorithm is applicable to arbitrarily weighted graphs that meet the constraints at the beginning of Section 2. In principle, it should be applicable to general planning, using the ideas of searching planners ASP (Bonet, Loerincs, & Geffner, 1997), the HSPfamily (Bonet & Geffner, 2001), FF (Hoffmann, 2000), SHERPA (Koenig, Furcy, & Bauer, 2002), and LDFS (Bonet & Geffner, 2006). As we have already described in the paper, using the kD tree index requires some correspondence between coordinate similarity and heuristic distance."}, {"heading": "12. Conclusions", "text": "In this paper, we addressed the problem of heuristic real-time search, whose planning time per turn does not depend on the number of states. We proposed a new mechanism for automatically selecting sub-targets, and the resulting algorithm proved to be theoretically complete and significantly exceeded the previous state-of-the-art D LRTA * and TBA * algorithms on large video game cards in several important performance measures."}, {"heading": "Acknowledgments", "text": "This research was supported by grants from the National Science and Engineering Research Council of Canada (NSERC), the Icelandic Centre for Research (RANNI'S) and a Marie Curie Scholarship from the European Community Structuring ERA Programme under contract number MIRG-CT2005-017284. We are pleased to have the help of Josh Sterling, Stephen Hladky and Daniel Huntley."}], "references": [{"title": "Integrating OO road network database, cases and knowledge for route finding", "author": ["M.A. Anwar", "T. Yoshida"], "venue": "In ACM Symposium on Applied Computing (SAC),", "citeRegEx": "Anwar and Yoshida,? \\Q2001\\E", "shortCiteRegEx": "Anwar and Yoshida", "year": 2001}, {"title": "Learning to act using real-time dynamic programming", "author": ["A.G. Barto", "S.J. Bradtke", "S.P. Singh"], "venue": "Artificial Intelligence,", "citeRegEx": "Barto et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Barto et al\\.", "year": 1995}, {"title": "TBA*: Time-bounded A", "author": ["Y. Bj\u00f6rnsson", "V. Bulitko", "N. Sturtevant"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Bj\u00f6rnsson et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bj\u00f6rnsson et al\\.", "year": 2009}, {"title": "Improved heuristics for optimal path-finding on game maps", "author": ["Y. Bj\u00f6rnsson", "K. Halld\u00f3rsson"], "venue": "Proceedings of the Second Artificial Intelligence and Interactive Digital Entertainment Conference (AIIDE),", "citeRegEx": "Bj\u00f6rnsson and Halld\u00f3rsson,? \\Q2006\\E", "shortCiteRegEx": "Bj\u00f6rnsson and Halld\u00f3rsson", "year": 2006}, {"title": "Planning as heuristic search", "author": ["B. Bonet", "H. Geffner"], "venue": "Artificial Intelligence,", "citeRegEx": "Bonet and Geffner,? \\Q2001\\E", "shortCiteRegEx": "Bonet and Geffner", "year": 2001}, {"title": "Learning depth-first search: A unified approach to heuristic search in deterministic and non-deterministic settings, and its application to MDPs", "author": ["B. Bonet", "H. Geffner"], "venue": "In Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS),", "citeRegEx": "Bonet and Geffner,? \\Q2006\\E", "shortCiteRegEx": "Bonet and Geffner", "year": 2006}, {"title": "A fast and robust action selection mechanism for planning", "author": ["B. Bonet", "G. Loerincs", "H. Geffner"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Bonet et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Bonet et al\\.", "year": 1997}, {"title": "Stratified case-based reasoning: Reusing hierarchical problem solving episodes", "author": ["K. Branting", "D.W. Aha"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Branting and Aha,? \\Q1995\\E", "shortCiteRegEx": "Branting and Aha", "year": 1995}, {"title": "Learning for adaptive real-time search", "author": ["V. Bulitko"], "venue": "Tech. rep. http://arxiv.org/abs/cs.AI/0407016,", "citeRegEx": "Bulitko,? \\Q2004\\E", "shortCiteRegEx": "Bulitko", "year": 2004}, {"title": "kNN LRTA*: Simple subgoaling for real-time search", "author": ["V. Bulitko", "Y. Bj\u00f6rnsson"], "venue": "In Proceedings of Artificial Intelligence and Interactive Digital Entertainment (AIIDE),", "citeRegEx": "Bulitko and Bj\u00f6rnsson,? \\Q2009\\E", "shortCiteRegEx": "Bulitko and Bj\u00f6rnsson", "year": 2009}, {"title": "Dynamic Control in Path-Planning with Real-Time Heuristic Search", "author": ["V. Bulitko", "Y. Bj\u00f6rnsson", "M. Lu\u0161trek", "J. Schaeffer", "S. Sigmundarson"], "venue": "In Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS),", "citeRegEx": "Bulitko et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bulitko et al\\.", "year": 2007}, {"title": "Learning in real time search: A unifying framework", "author": ["V. Bulitko", "G. Lee"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Bulitko and Lee,? \\Q2006\\E", "shortCiteRegEx": "Bulitko and Lee", "year": 2006}, {"title": "Dynamic control in real-time heuristic search", "author": ["V. Bulitko", "M. Lu\u0161trek", "J. Schaeffer", "Y. Bj\u00f6rnsson", "S. Sigmundarson"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Bulitko et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bulitko et al\\.", "year": 2008}, {"title": "Graph abstraction in real-time heuristic search", "author": ["V. Bulitko", "N. Sturtevant", "J. Lu", "T. Yau"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Bulitko et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bulitko et al\\.", "year": 2007}, {"title": "Prodigy: An integrated architecture for planning and learning", "author": ["J.G. Carbonell", "C. Knoblock", "S. Minton"], "venue": null, "citeRegEx": "Carbonell et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Carbonell et al\\.", "year": 1990}, {"title": "Optimizations of data structures, heuristics and algorithms for path-finding on maps", "author": ["T. Cazenave"], "venue": "Proceedings of the", "citeRegEx": "Cazenave,? \\Q2006\\E", "shortCiteRegEx": "Cazenave", "year": 2006}, {"title": "Speeding up the convergence of real-time search", "author": ["D. Furcy", "S. Koenig"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Furcy and Koenig,? \\Q2000\\E", "shortCiteRegEx": "Furcy and Koenig", "year": 2000}, {"title": "Contraction hierarchies: Faster and simpler hierarchical routing in road networks", "author": ["R. Geisberger", "P. Sanders", "D. Schultes", "D. Delling"], "venue": "WEA, Vol. 5038 of Lecture Notes in Computer Science,", "citeRegEx": "Geisberger et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Geisberger et al\\.", "year": 2008}, {"title": "Combining search and analogical reasoning in path planning from road maps", "author": ["K. Haigh", "M. Veloso"], "venue": "In Proceedings of the AAAI-93 Workshop on Case-Based Reasoning,", "citeRegEx": "Haigh and Veloso,? \\Q1993\\E", "shortCiteRegEx": "Haigh and Veloso", "year": 1993}, {"title": "A formal basis for the heuristic determination of minimum cost paths", "author": ["P. Hart", "N. Nilsson", "B. Raphael"], "venue": "IEEE Transactions on Systems Science and Cybernetics,", "citeRegEx": "Hart et al\\.,? \\Q1968\\E", "shortCiteRegEx": "Hart et al\\.", "year": 1968}, {"title": "Improving convergence of LRTA*(k)", "author": ["C. Hern\u00e1ndez", "P. Meseguer"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), Workshop on Planning and Learning in A Priori Unknown or Dynamic Domains,", "citeRegEx": "Hern\u00e1ndez and Meseguer,? \\Q2005\\E", "shortCiteRegEx": "Hern\u00e1ndez and Meseguer", "year": 2005}, {"title": "Using case-based reasoning for mobile robot path planning", "author": ["J. Hodal", "J. Dvorak"], "venue": "Engineering Mechanics,", "citeRegEx": "Hodal and Dvorak,? \\Q2008\\E", "shortCiteRegEx": "Hodal and Dvorak", "year": 2008}, {"title": "A heuristic for domain independent planning and its use in an enforced hillclimbing algorithm", "author": ["J. Hoffmann"], "venue": "In Proceedings of the 12th International Symposium on Methodologies for Intelligent Systems (ISMIS),", "citeRegEx": "Hoffmann,? \\Q2000\\E", "shortCiteRegEx": "Hoffmann", "year": 2000}, {"title": "Moving target search with intelligence", "author": ["T. Ishida"], "venue": "In National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Ishida,? \\Q1992\\E", "shortCiteRegEx": "Ishida", "year": 1992}, {"title": "A comparison of fast search methods for real-time situated agents", "author": ["S. Koenig"], "venue": "In Proceedings of Int. Joint Conf. on Autonomous Agents and Multiagent Systems, pp", "citeRegEx": "Koenig,? \\Q2004\\E", "shortCiteRegEx": "Koenig", "year": 2004}, {"title": "Heuristic search-based replanning", "author": ["S. Koenig", "D. Furcy", "C. Bauer"], "venue": "In Proceedings of the Int. Conference on Artificial Intelligence Planning and Scheduling,", "citeRegEx": "Koenig et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Koenig et al\\.", "year": 2002}, {"title": "Real-time adaptive A", "author": ["S. Koenig", "M. Likhachev"], "venue": "In Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS),", "citeRegEx": "Koenig and Likhachev,? \\Q2006\\E", "shortCiteRegEx": "Koenig and Likhachev", "year": 2006}, {"title": "Depth-first iterative deepening: An optimal admissible tree search", "author": ["R. Korf"], "venue": "Artificial Intelligence,", "citeRegEx": "Korf,? \\Q1985\\E", "shortCiteRegEx": "Korf", "year": 1985}, {"title": "Real-time heuristic search", "author": ["R. Korf"], "venue": "Artificial Intelligence,", "citeRegEx": "Korf,? \\Q1990\\E", "shortCiteRegEx": "Korf", "year": 1990}, {"title": "Anytime dynamic A*: An anytime, replanning algorithm", "author": ["M. Likhachev", "D.I. Ferguson", "G.J. Gordon", "A. Stentz", "S. Thrun"], "venue": "In ICAPS,", "citeRegEx": "Likhachev et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Likhachev et al\\.", "year": 2005}, {"title": "ARA*: Anytime A* with provable bounds on sub-optimality", "author": ["M. Likhachev", "G.J. Gordon", "S. Thrun"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Likhachev et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Likhachev et al\\.", "year": 2004}, {"title": "Lookahead pathology in real-time path-finding", "author": ["M. Lu\u0161trek", "V. Bulitko"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI), Workshop on Learning For Search,", "citeRegEx": "Lu\u0161trek and Bulitko,? \\Q2006\\E", "shortCiteRegEx": "Lu\u0161trek and Bulitko", "year": 2006}, {"title": "Efficient Memory-based Learning for Robot Control", "author": ["A. Moore"], "venue": "Ph.D. thesis,", "citeRegEx": "Moore,? \\Q1991\\E", "shortCiteRegEx": "Moore", "year": 1991}, {"title": "Plan reuse versus plan generation: A theoretical and empirical analysis", "author": ["B. Nebel", "J. Koehler"], "venue": "Artificial Intelligence,", "citeRegEx": "Nebel and Koehler,? \\Q1995\\E", "shortCiteRegEx": "Nebel and Koehler", "year": 1995}, {"title": "Real-time heuristic search with a priority queue", "author": ["D.C. Rayner", "K. Davison", "V. Bulitko", "K. Anderson", "J. Lu"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Rayner et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Rayner et al\\.", "year": 2007}, {"title": "Do the right thing: Studies in limited rationality", "author": ["S. Russell", "E. Wefald"], "venue": null, "citeRegEx": "Russell and Wefald,? \\Q1991\\E", "shortCiteRegEx": "Russell and Wefald", "year": 1991}, {"title": "Controlling the learning process of real-time heuristic search", "author": ["M. Shimbo", "T. Ishida"], "venue": "Artificial Intelligence,", "citeRegEx": "Shimbo and Ishida,? \\Q2003\\E", "shortCiteRegEx": "Shimbo and Ishida", "year": 2003}, {"title": "An intelligent heuristic algorithm for project scheduling problems", "author": ["Shue", "L.-Y", "Li", "S.-T", "R. Zamani"], "venue": "In Proceedings of the 32nd Annual Meeting of the Decision Sciences", "citeRegEx": "Shue et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Shue et al\\.", "year": 2001}, {"title": "An admissible heuristic search algorithm", "author": ["Shue", "L.-Y", "R. Zamani"], "venue": "In Proceedings of the 7th International Symposium on Methodologies for Intelligent Systems (ISMIS-93),", "citeRegEx": "Shue et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Shue et al\\.", "year": 1993}, {"title": "Value Back-Propagation vs. Backtracking in RealTime Search", "author": ["S. Sigmundarson", "Y. Bj\u00f6rnsson"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI), Workshop on Learning For Search,", "citeRegEx": "Sigmundarson and Bj\u00f6rnsson,? \\Q2006\\E", "shortCiteRegEx": "Sigmundarson and Bj\u00f6rnsson", "year": 2006}, {"title": "The focussed D* algorithm for real-time replanning", "author": ["A. Stenz"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Stenz,? \\Q1995\\E", "shortCiteRegEx": "Stenz", "year": 1995}, {"title": "Memory-efficient abstractions for pathfinding", "author": ["N. Sturtevant"], "venue": "In Proceedings of the third conference on Artificial Intelligence and Interactive Digital Entertainment,", "citeRegEx": "Sturtevant,? \\Q2007\\E", "shortCiteRegEx": "Sturtevant", "year": 2007}, {"title": "Partial pathfinding using map abstraction and refinement", "author": ["N. Sturtevant", "M. Buro"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Sturtevant and Buro,? \\Q2005\\E", "shortCiteRegEx": "Sturtevant and Buro", "year": 2005}, {"title": "Memory-based heuristics for explicit state spaces", "author": ["N.R. Sturtevant", "A. Felner", "M. Barrer", "J. Schaeffer", "N. Burch"], "venue": "Proceedings of the 21st International Joint Conference on Artificial Intelligence,", "citeRegEx": "Sturtevant et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sturtevant et al\\.", "year": 2009}, {"title": "A path planning algorithm based on typical case reasoning", "author": ["M. Weng", "X. Wei", "R. Qu", "Z. Cai"], "venue": "Geo-spatial Information Science,", "citeRegEx": "Weng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Weng et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 27, "context": "For instance, static search algorithms such as A* (Hart, Nilsson, & Raphael, 1968), IDA* (Korf, 1985) and PRA* (Sturtevant & Buro, 2005; Sturtevant, 2007), re-planning algorithms such as D* (Stenz, 1995), anytime algorithms such as ARA* (Likhachev, Gordon, & Thrun, 2004) and anytime re-planning algorithms such as AD* (Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2005) cannot guarantee a constant bound on planning time per action.", "startOffset": 89, "endOffset": 101}, {"referenceID": 41, "context": "For instance, static search algorithms such as A* (Hart, Nilsson, & Raphael, 1968), IDA* (Korf, 1985) and PRA* (Sturtevant & Buro, 2005; Sturtevant, 2007), re-planning algorithms such as D* (Stenz, 1995), anytime algorithms such as ARA* (Likhachev, Gordon, & Thrun, 2004) and anytime re-planning algorithms such as AD* (Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2005) cannot guarantee a constant bound on planning time per action.", "startOffset": 111, "endOffset": 154}, {"referenceID": 40, "context": "For instance, static search algorithms such as A* (Hart, Nilsson, & Raphael, 1968), IDA* (Korf, 1985) and PRA* (Sturtevant & Buro, 2005; Sturtevant, 2007), re-planning algorithms such as D* (Stenz, 1995), anytime algorithms such as ARA* (Likhachev, Gordon, & Thrun, 2004) and anytime re-planning algorithms such as AD* (Likhachev, Ferguson, Gordon, Stentz, & Thrun, 2005) cannot guarantee a constant bound on planning time per action.", "startOffset": 190, "endOffset": 203}, {"referenceID": 28, "context": "The actions are then taken and the planning-execution cycle repeats (Korf, 1990).", "startOffset": 68, "endOffset": 80}, {"referenceID": 23, "context": ", repeatedly re-visit) the state space due to the need to fill in heuristic depressions (Ishida, 1992).", "startOffset": 88, "endOffset": 102}, {"referenceID": 28, "context": "Since the seminal work on LRTA* (Korf, 1990), researchers have attempted to speed up the learning process.", "startOffset": 32, "endOffset": 44}, {"referenceID": 28, "context": "The core of most real-time heuristic search algorithms is an algorithm called Learning Real-Time A* (LRTA*) (Korf, 1990).", "startOffset": 108, "endOffset": 120}, {"referenceID": 28, "context": "The two common choices are full-width limited-depth lookahead (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue, Li, & Zamani, 2001; Furcy & Koenig, 2000; Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner, Davison, Bulitko, Anderson, & Lu, 2007) and A*-shaped lookahead (Koenig, 2004; Koenig & Likhachev, 2006).", "startOffset": 62, "endOffset": 282}, {"referenceID": 24, "context": "The two common choices are full-width limited-depth lookahead (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue, Li, & Zamani, 2001; Furcy & Koenig, 2000; Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner, Davison, Bulitko, Anderson, & Lu, 2007) and A*-shaped lookahead (Koenig, 2004; Koenig & Likhachev, 2006).", "startOffset": 307, "endOffset": 347}, {"referenceID": 8, "context": "Additional choices are decision-theoretic based shaping (Russell & Wefald, 1991) and dynamic lookahead depth-selection (Bulitko, 2004; Lu\u0161trek & Bulitko, 2006).", "startOffset": 119, "endOffset": 159}, {"referenceID": 28, "context": "Common choices are: the current state only (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue et al., 2001; Furcy & Koenig, 2000; Bulitko, 2004), all states within the local search space (Koenig, 2004; Koenig & Likhachev, 2006) and previously visited states and their neighbors (Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al.", "startOffset": 43, "endOffset": 155}, {"referenceID": 37, "context": "Common choices are: the current state only (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue et al., 2001; Furcy & Koenig, 2000; Bulitko, 2004), all states within the local search space (Koenig, 2004; Koenig & Likhachev, 2006) and previously visited states and their neighbors (Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al.", "startOffset": 43, "endOffset": 155}, {"referenceID": 8, "context": "Common choices are: the current state only (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue et al., 2001; Furcy & Koenig, 2000; Bulitko, 2004), all states within the local search space (Koenig, 2004; Koenig & Likhachev, 2006) and previously visited states and their neighbors (Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al.", "startOffset": 43, "endOffset": 155}, {"referenceID": 24, "context": ", 2001; Furcy & Koenig, 2000; Bulitko, 2004), all states within the local search space (Koenig, 2004; Koenig & Likhachev, 2006) and previously visited states and their neighbors (Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al.", "startOffset": 87, "endOffset": 127}, {"referenceID": 34, "context": ", 2001; Furcy & Koenig, 2000; Bulitko, 2004), all states within the local search space (Koenig, 2004; Koenig & Likhachev, 2006) and previously visited states and their neighbors (Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al., 2007).", "startOffset": 178, "endOffset": 267}, {"referenceID": 28, "context": "The common choices are mini-min (Korf, 1990; Shue & Zamani, 1993; Shue et al., 2001; Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al., 2007), their weighted versions (Shimbo & Ishida, 2003), max of mins (Bulitko, 2004), modified Dijkstra\u2019s algorithm (Koenig, 2004), and updates with respect to the shortest path from the current state to the best-looking state on the frontier of the local search space (Koenig & Likhachev, 2006).", "startOffset": 32, "endOffset": 173}, {"referenceID": 37, "context": "The common choices are mini-min (Korf, 1990; Shue & Zamani, 1993; Shue et al., 2001; Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al., 2007), their weighted versions (Shimbo & Ishida, 2003), max of mins (Bulitko, 2004), modified Dijkstra\u2019s algorithm (Koenig, 2004), and updates with respect to the shortest path from the current state to the best-looking state on the frontier of the local search space (Koenig & Likhachev, 2006).", "startOffset": 32, "endOffset": 173}, {"referenceID": 34, "context": "The common choices are mini-min (Korf, 1990; Shue & Zamani, 1993; Shue et al., 2001; Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al., 2007), their weighted versions (Shimbo & Ishida, 2003), max of mins (Bulitko, 2004), modified Dijkstra\u2019s algorithm (Koenig, 2004), and updates with respect to the shortest path from the current state to the best-looking state on the frontier of the local search space (Koenig & Likhachev, 2006).", "startOffset": 32, "endOffset": 173}, {"referenceID": 8, "context": ", 2007), their weighted versions (Shimbo & Ishida, 2003), max of mins (Bulitko, 2004), modified Dijkstra\u2019s algorithm (Koenig, 2004), and updates with respect to the shortest path from the current state to the best-looking state on the frontier of the local search space (Koenig & Likhachev, 2006).", "startOffset": 70, "endOffset": 85}, {"referenceID": 24, "context": ", 2007), their weighted versions (Shimbo & Ishida, 2003), max of mins (Bulitko, 2004), modified Dijkstra\u2019s algorithm (Koenig, 2004), and updates with respect to the shortest path from the current state to the best-looking state on the frontier of the local search space (Koenig & Likhachev, 2006).", "startOffset": 117, "endOffset": 131}, {"referenceID": 28, "context": "Commonly used strategies include: the first move of an optimal path to the most promising frontier state (Korf, 1990; Furcy & Koenig, 2000; Hern\u00e1ndez & Meseguer, 2005a, 2005b), the entire path (Bulitko, 2004), and backtracking moves (Shue & Zamani, 1993; Shue et al.", "startOffset": 105, "endOffset": 175}, {"referenceID": 8, "context": "Commonly used strategies include: the first move of an optimal path to the most promising frontier state (Korf, 1990; Furcy & Koenig, 2000; Hern\u00e1ndez & Meseguer, 2005a, 2005b), the entire path (Bulitko, 2004), and backtracking moves (Shue & Zamani, 1993; Shue et al.", "startOffset": 193, "endOffset": 208}, {"referenceID": 37, "context": "Commonly used strategies include: the first move of an optimal path to the most promising frontier state (Korf, 1990; Furcy & Koenig, 2000; Hern\u00e1ndez & Meseguer, 2005a, 2005b), the entire path (Bulitko, 2004), and backtracking moves (Shue & Zamani, 1993; Shue et al., 2001; Bulitko, 2004; Sigmundarson & Bj\u00f6rnsson, 2006).", "startOffset": 233, "endOffset": 320}, {"referenceID": 8, "context": "Commonly used strategies include: the first move of an optimal path to the most promising frontier state (Korf, 1990; Furcy & Koenig, 2000; Hern\u00e1ndez & Meseguer, 2005a, 2005b), the entire path (Bulitko, 2004), and backtracking moves (Shue & Zamani, 1993; Shue et al., 2001; Bulitko, 2004; Sigmundarson & Bj\u00f6rnsson, 2006).", "startOffset": 233, "endOffset": 320}, {"referenceID": 8, "context": "The two common choices are full-width limited-depth lookahead (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue, Li, & Zamani, 2001; Furcy & Koenig, 2000; Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner, Davison, Bulitko, Anderson, & Lu, 2007) and A*-shaped lookahead (Koenig, 2004; Koenig & Likhachev, 2006). Additional choices are decision-theoretic based shaping (Russell & Wefald, 1991) and dynamic lookahead depth-selection (Bulitko, 2004; Lu\u0161trek & Bulitko, 2006). Finally, searching in a smaller, abstracted state has been used as well (Bulitko, Sturtevant, Lu, & Yau, 2007). The local learning space is the set of states whose heuristic values are updated. Common choices are: the current state only (Korf, 1990; Shimbo & Ishida, 2003; Shue & Zamani, 1993; Shue et al., 2001; Furcy & Koenig, 2000; Bulitko, 2004), all states within the local search space (Koenig, 2004; Koenig & Likhachev, 2006) and previously visited states and their neighbors (Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al., 2007). A learning rule is used to update the heuristic values of the states in the learning space. The common choices are mini-min (Korf, 1990; Shue & Zamani, 1993; Shue et al., 2001; Hern\u00e1ndez & Meseguer, 2005a, 2005b; Sigmundarson & Bj\u00f6rnsson, 2006; Rayner et al., 2007), their weighted versions (Shimbo & Ishida, 2003), max of mins (Bulitko, 2004), modified Dijkstra\u2019s algorithm (Koenig, 2004), and updates with respect to the shortest path from the current state to the best-looking state on the frontier of the local search space (Koenig & Likhachev, 2006). Additionally, several algorithms learn more than one heuristic function (Russell & Wefald, 1991; Furcy & Koenig, 2000; Shimbo & Ishida, 2003). The control strategy decides on the move following the planning and learning phases. Commonly used strategies include: the first move of an optimal path to the most promising frontier state (Korf, 1990; Furcy & Koenig, 2000; Hern\u00e1ndez & Meseguer, 2005a, 2005b), the entire path (Bulitko, 2004), and backtracking moves (Shue & Zamani, 1993; Shue et al., 2001; Bulitko, 2004; Sigmundarson & Bj\u00f6rnsson, 2006). Given the multitude of proposed algorithms, unification efforts have been undertaken. In particular, Bulitko and Lee (2006) suggested a framework, called Learning Real Time Search (LRTS), to", "startOffset": 252, "endOffset": 2314}, {"referenceID": 28, "context": "combine and extend LRTA* (Korf, 1990), weighted LRTA* (Shimbo & Ishida, 2003), SLA* (Shue & Zamani, 1993), SLA*T (Shue et al.", "startOffset": 25, "endOffset": 37}, {"referenceID": 37, "context": "combine and extend LRTA* (Korf, 1990), weighted LRTA* (Shimbo & Ishida, 2003), SLA* (Shue & Zamani, 1993), SLA*T (Shue et al., 2001), and to a large extent, \u03b3-Trap (Bulitko, 2004).", "startOffset": 113, "endOffset": 132}, {"referenceID": 8, "context": ", 2001), and to a large extent, \u03b3-Trap (Bulitko, 2004).", "startOffset": 39, "endOffset": 54}, {"referenceID": 12, "context": "Although in general planning a goal is often represented as a conjunction of simple subgoals, to the best of our knowledge, the only real-time heuristic search algorithm to implement subgoaling is D LRTA* (Bulitko, Bj\u00f6rnsson, Lu\u0161trek, Schaeffer, & Sigmundarson, 2007; Bulitko et al., 2008).", "startOffset": 205, "endOffset": 289}, {"referenceID": 7, "context": ", 2001), and to a large extent, \u03b3-Trap (Bulitko, 2004). In the dimensions described above, LRTS operates as follows. It uses a full-width fixed-depth local search space with transposition tables to prune duplicate states. LRTS uses a max of mins learning rule to update the heuristic value of the current state (its local learning space). The control strategy moves the agent to the most promising frontier state if the cumulative volume of heuristic function updates on a trial is under a user-specified quota or backtracks to its previous state otherwise. While the approaches listed above all brought about various improvements, breakthrough performance came in the form of subgoaling. Since commonly used heuristics simplify the problem at hand (e.g., the octile distance in grid-world pathfinding ignores obstacles), using LRTA* with near-by subgoals effectively increases heuristic quality and thus reduces the amount of learning. Although in general planning a goal is often represented as a conjunction of simple subgoals, to the best of our knowledge, the only real-time heuristic search algorithm to implement subgoaling is D LRTA* (Bulitko, Bj\u00f6rnsson, Lu\u0161trek, Schaeffer, & Sigmundarson, 2007; Bulitko et al., 2008). In its pre-processing phase, D LRTA* uses the clique abstraction of Sturtevant and Buro (2005) to create a smaller search graph.", "startOffset": 40, "endOffset": 1323}, {"referenceID": 2, "context": "Another recent high-performance real-time search algorithm is Time-Bounded A* (TBA*) by Bj\u00f6rnsson et al. (2009), a time-bounded variant of the classic A*.", "startOffset": 88, "endOffset": 112}, {"referenceID": 15, "context": "Two such enhanced heuristics are the differential heuristic (Cazenave, 2006; Sturtevant, Felner, Barrer, Schaeffer, & Burch, 2009) and the canonical heuristic (Sturtevant et al.", "startOffset": 60, "endOffset": 130}, {"referenceID": 7, "context": "As for mobile robot navigation, two heuristic search algorithms working in ground space and using a CBR-based approach were introduced by Branting and Aha (1995). The simpler one, when looking for a path between states a and b, searches the pre-calculated case base for a path that contains both a and b.", "startOffset": 138, "endOffset": 162}, {"referenceID": 32, "context": "A kd-tree (Moore, 1991) is a spatial tree index that can have a sublinear time complexity for nearest-neighbor searches.", "startOffset": 10, "endOffset": 23}, {"referenceID": 32, "context": "The nearest-neighbor search algorithm is explained by Moore (1991). Note that the kd-tree index works for regular grid pathfinding problems but not necessarily all heuristic search problems.", "startOffset": 54, "endOffset": 67}, {"referenceID": 28, "context": "In the latter case, kNN LRTA* is complete because the underlying LRTA* is complete (Korf, 1990) as long as it generates all immediate neighbors of its current state.", "startOffset": 83, "endOffset": 95}, {"referenceID": 12, "context": ", 1998) and WarCraft III: Reign of Chaos (Blizzard Entertainment, 2002) have been a common choice (e.g., Sturtevant & Buro, 2005; Bulitko et al., 2008).", "startOffset": 98, "endOffset": 151}, {"referenceID": 10, "context": "original non-abstract states and \u03b1 is a constant reduction factor (Bulitko et al., 2007).", "startOffset": 66, "endOffset": 88}, {"referenceID": 22, "context": "In principle, it should be applicable to general planning using the ideas from search-based planners ASP (Bonet, Loerincs, & Geffner, 1997), the HSPfamily (Bonet & Geffner, 2001), FF (Hoffmann, 2000), SHERPA (Koenig, Furcy, & Bauer, 2002) and LDFS (Bonet & Geffner, 2006).", "startOffset": 183, "endOffset": 199}], "year": 2010, "abstractText": "Real-time heuristic search algorithms satisfy a constant bound on the amount of planning per action, independent of problem size. As a result, they scale up well as problems become larger. This property would make them well suited for video games where Artificial Intelligence controlled agents must react quickly to user commands and to other agents\u2019 actions. On the downside, real-time search algorithms employ learning methods that frequently lead to poor solution quality and cause the agent to appear irrational by re-visiting the same problem states repeatedly. The situation changed recently with a new algorithm, D LRTA*, which attempted to eliminate learning by automatically selecting subgoals. D LRTA* is well poised for video games, except it has a complex and memory-demanding pre-computation phase during which it builds a database of subgoals. In this paper, we propose a simpler and more memory-efficient way of pre-computing subgoals thereby eliminating the main obstacle to applying state-of-the-art real-time search methods in video games. The new algorithm solves a number of randomly chosen problems off-line, compresses the solutions into a series of subgoals and stores them in a database. When presented with a novel problem on-line, it queries the database for the most similar previously solved case and uses its subgoals to solve the problem. In the domain of pathfinding on four large video game maps, the new algorithm delivers solutions eight times better while using 57 times less memory and requiring 14% less pre-computation time.", "creator": "TeX"}}}