{"id": "1401.3908", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Centrality-as-Relevance: Support Sets and Similarity as Geometric Proximity", "abstract": "In automatic summarization, centrality-as-relevance means that the most important content of an information source, or a collection of information sources, corresponds to the most central passages, considering a representation where such notion makes sense (graph, spatial, etc.). We assess the main paradigms, and introduce a new centrality-based relevance model for automatic summarization that relies on the use of support sets to better estimate the relevant content. Geometric proximity is used to compute semantic relatedness. Centrality (relevance) is determined by considering the whole input source (and not only local information), and by taking into account the existence of minor topics or lateral subjects in the information sources to be summarized. The method consists in creating, for each passage of the input source, a support set consisting only of the most semantically related passages. Then, the determination of the most relevant content is achieved by selecting the passages that occur in the largest number of support sets. This model produces extractive summaries that are generic, and language- and domain-independent. Thorough automatic evaluation shows that the method achieves state-of-the-art performance, both in written text, and automatically transcribed speech summarization, including when compared to considerably more complex approaches.", "histories": [["v1", "Thu, 16 Jan 2014 05:23:22 GMT  (736kb)", "http://arxiv.org/abs/1401.3908v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["ricardo ribeiro", "david martins de matos"], "accepted": false, "id": "1401.3908"}, "pdf": {"name": "1401.3908.pdf", "metadata": {"source": "CRF", "title": "Revisiting Centrality-as-Relevance: Support Sets and Similarity as Geometric Proximity", "authors": ["Ricardo Ribeiro", "David Martins de Matos"], "emails": ["ricardo.ribeiro@inesc-id.pt", "david.matos@inesc-id.pt"], "sections": [{"heading": "1. Introduction", "text": "A summary of events in recent years shows that most people are able to survive on their own and on their own."}, {"heading": "2. Centrality-as-Relevance", "text": "There are two main approaches to a centrality-based summary: passage-to-centroid similarity and pair-by-pair passage similarity."}, {"heading": "2.1 Passage-to-Centroid Similarity-based Centrality", "text": "In the centroid-based summary, the centrality of the passage is defined by the similarity between the passage and a pseudo-passage, which, taking into account a geometric representation of the input source, is the center of the space defined by the passages of the input source, the centroid signature. The work in the multi-document summary by Radev et al. (1999, 2000) and Radev, Jing, Stys, and Tam (2004) and the work developed by Lin and Hovy (2000) are examples of this approach. Radev et al. present a centroid-based multi-document summary (MEAD) that serves as an insertion of a cluster of documents. Linked documents are a centroid signature. Documents are represented by vectors of tf-idf weights and the centroid documents, which consist of a vector that gives the values of the weighted-idf documents."}, {"heading": "2.2 Pair-wise Passage Similarity-based Centrality", "text": "In the second half of the last decade, the number of unemployed has multiplied compared to previous years. (...) In the second half of the last decade, the number of unemployed has multiplied in the second half of the last decade. (...) In the second half of the last decade, the number of unemployed has multiplied in the second half of the last decade. (...) In the third half of the last decade, the number of unemployed has multiplied in the second half of the last decade. (...) In the second half of the last decade, the number of unemployed has multiplied in the second half of the last decade. (...) In the third half of the last decade, the number of unemployed has multiplied in the second half of the last decade. (...) In the second half of the last decade, the number of unemployed has multiplied in the second half of the last decade. (...)"}, {"heading": "2.3 Beyond Automatic Summarization", "text": "Apart from the summary, and taking into account that PageRank and HITS come from the field of information retrieval, centrality-based methods similar to those described above have been successfully applied to reordered document sets returned by retrieval methods.Kurland and Lee (2005, 2010), however, present a series of graph-based algorithms similar to our model to rearrange a previously retrieved document collection (C).The method begins by defining a k -nearest-neighbor (kNN) diagram of the original collection based on generational links similar to Eq. 10 (KL, Kullback-Leibler divergence; MLE, maximum probability estimate; \u00b5, smoothing parameters of a dirichlet-smoothed version of p (\u00b7); d and s, documents).pKL, \u00b5d RRD (s), exp (LLEs \u2212 LEs."}, {"heading": "3. Support Sets and Geometric Proximity", "text": "In this paper, we hypothesize that summarized input sources understand different topics (lateral problems that go beyond the main topic) and model this idea by defining for each passage in the input source a support set based on semantic references. Semantic references are estimated within the geometric framework in which we examine several distance measurements to calculate proximity; the most relevant content is determined by calculating the most central passages based on the collection of support sources; the proposed model estimates the most prominent passages of an input source based solely on information extracted from the used input source."}, {"heading": "3.1 Model", "text": "The leading concept in our model is the concept of the support set: the first step of our method of assessing the relevant content is to create a support set for each passage of the input source by calculating the similarity between each passage and the remaining ones, selecting the next passages that belong to the support set. The most relevant passages are those that occur in the largest number of support sets. Nevertheless, given a segmented information source I, p1, p2,..., pN, support sets Si are defined with each passage pi as being in the neighborhood. 12 (sim () is a similarity function, and \u03b5i is a threshold). Nevertheless, {s, I: sim (s, pi) > principles 6 = pi} (12) The most relevant segments are given by selecting the passages that satisfy the Eq. 13, arg max s, the support for that particular passage."}, {"heading": "3.2 Semantic Space", "text": "We represent the input source I in a term by passages matrix A, where each matrix element aij = f (ti, pj) is a function that relates the occurrence of each term ti within each passage pj (T is the number of different terms; N is the number of passages). A = a1,1... a1, N... aT, 1.. aT, N (14) Regarding the definition of the weighting function f (ti, pj) several term weighting schemes have been examined in the literature - for analysis of the effects of different weighting schemes on text or language summaries see the work of Ora, san et al. (2004) and Murray and Renals (2007) and Ribeiro and de Matos (2008b) respectively. Since the exact nature of the weighting function, although relevant, is not central to our work, pahlj, for reasons of simplicity."}, {"heading": "3.3 Semantic Relatedness", "text": "As suggested by Sahlgren (2006), the meaning-are-places metaphor (Koosis, 1998, 70) is completely indeterminate without the similarity-is-proximity metaphor. In this sense, we examine the prevailing distance measurements found in literature based on the general Minkowski distance (Eq. 17).distminkowski (x, y) = (n, y) = (n, x), the difference (n), the Chebyshev distance (N, Eq. 20), the Chebyshev distance (N, Eq. 21) and the broken distance metrics (we experimented with the Manhattan distance (N = 0.5, N = 0.75, and N = 1. (3). Note that if 0 < N < 1, Eq. 17 are not metrics."}, {"heading": "3.4 Threshold Estimation", "text": "As already mentioned, a simple approach to threshold estimation is to define a fixed cardinality for all support groups, a KNN approach. This means that the thresholds, although unknown, are different for each support group. A simple heuristic, which allows to automatically set thresholds per pass, is to select as members of the support group the passages whose distance to the passage associated with the support group under construction is smaller than the average distance. In the next sections, we will examine several heuristics inspired by the nature of the problem that can be used as possibly better approaches to threshold estimation."}, {"heading": "3.4.1 Heuristics Based on Distance Progression Analysis", "text": "One possible approach is to analyze the progression of the distance values between each passage and the remaining ones during the creation of the respective support set. This type of heuristics uses a sorted permutation, di1 \u2264 di2 \u2264 \u00b7 \u00b7 \u00b7 \u2264 diN \u2212 1, of the distances of the passages, sk, to passage pi (according to the support set under construction), with dik = dist (sk, pi), 1 \u2264 k \u2264 N \u2212 1, and N of the number of passages. We examine three approaches: a standard deviation-based approach where \u03b5i is given by equivalent 23, with a parameter that regulates the interval width by the average deviation relative to the standard deviation; an approach based on the decreasing differences between successive distances, dik + 2 \u2212 dik + 2 \u2212 dik + 1 < dik + 1 \u2212 ltts."}, {"heading": "3.4.2 Heuristics Based on Passage Order", "text": "The estimation of specific thresholds is aimed at defining support sets containing the most important passages of the passage to be analyzed. In this sense, in this group of heuristics we examine the structure of the input source to divide the candidate passages to be located in the support group into two subgroups: those closer to the passage associated with the support group under construction, and the other apartments. These heuristics use a permutation, di1, d i 2, \u00b7 \u00b7, diN \u2212 1, the spacing of the passages, sk, to the passage, pi, relative to the support group under construction, with d i k = dist (sk, pi), 1 \u2264 k \u2264 N \u2212 1, according to the order of occurrence of the passages sk in the input source. Algorithm 1 describes the general procedure."}, {"heading": "3.4.3 Heuristics Based on Weighted Graph Creation Techniques", "text": "In this set of heuristics, we examine two weighting functions (Zhu, 2005) (equals 24 and 25), bearing in mind that if the returned value exceeds a certain threshold, passage sk belongs to the support clause of passage pi, where dik = dist (sk, pi).exp (\u2212 (dik \u2212 min 1 \u2264 j \u2264 N \u2212 1 (dij)) 2 / \u03b12) > \u03b4 (24) (tanh (\u2212 \u03b1 (dik \u2212 1N \u2212 1 N \u2212 1 \u0445 j = 1 dij)) + 1) / 2 > \u03b4 (25)"}, {"heading": "3.5 Integrating Additional Information", "text": "As argued by Wan, Yang and Xiao (2007) and Ribeiro and de Matos (2008a), the use of additional information helps to build a better understanding of a given topic and thus improve the summary. Wan et al. propose a graph-based ranking model that uses several documents on a given topic to summarize a single one. Ribeiro and de Matos present a method that combines the input sources using the LSA framework. Input: Two values r1 and r2, each representing a subset, and the amount of passages sk and the corresponding distances d i k to the passage associated with the support model. Output: The amount of support for the passage under AnalysisR1, R2, R2, R2, R2, R2, R2, R2, R2, R2, R2, R2, R2, R2,..."}, {"heading": "4. Evaluation", "text": "Several evaluation models have been submitted over the past decade. (Some are automated, others manual) Beyond the long-established precision and recall (mostly useful in evaluating extractive summaries using extractive summaries as models), the literature is filled with metrics (some are automated, others manual) such as Relative Benefits (Radev et al., 2000; Radev & Tam, 2003), SummACCY (Hori, Hori, & Furui, 2003), ROUGE (Lin, 2004), VERT (de Oliveira, Torrens, Cidral, Schossland, & Bittencourt, 2008) or the Pyramid Method (Nenkova, Passonneau, & McKeown, 2007). For a more comprehensive analysis of the evaluation field, see the work of Nenkova, Torrens, Cidral, Schossland & Bittencourt, 2007, Mctencourt, or Pyramikode, Nenkova, 2008."}, {"heading": "4.1 Experiment 1: Text", "text": "In this section, we describe the experiments performed and analyze the corresponding results when using text written as the input source."}, {"heading": "4.1.1 Data", "text": "The corpus used, known as TeMa \u0301 rio, consists of 100 newspaper articles in Brazilian Portuguese (Pardo & Rino, 2003).Although our model is general and language-independent, this corpus has been used in several published studies to make an informed comparison of our results.The articles in the corpus cover several areas, such as \"world,\" \"politics\" and \"foreign policy.\" For each of the 100 newspaper articles, there is a man-made summary; the text has been linked and punctuation removed, while retaining the information on the sentence boundary. Table 1 summarizes the characteristics of this data set."}, {"heading": "4.1.2 Evaluation Setup", "text": "To compare the performance of our model when input is not affected by language-related phenomena, we use previously published state-of-the-art results for the text summary. However, because there was no information about any type of pre-processing for the previous studies, we could not guarantee a fair comparison of our results with the previous studies without defining an appropriate methodology for the comparisons. The following systems were evaluated using TeMa-rio data: \u2022 a set of graphically based summaries presented by Mihalcea and Tarau (2005), namely PageRank Backward, HITSA Backward and HITSH Forward; \u2022 Graphic-v2 (Leite, Rino, Pardo, & Nunes, 2007), a classification-based system that uses features such as the appearance of appropriate nouns, lexical concatenation and ontology; \u2022 two modified versions of Mihalcea models of Micehala."}, {"heading": "4.1.3 Results", "text": "Table 3 illustrates the comparison between the previously proposed models and our model. In this table, our model is identified by the distance name and the conditions used by this particular instance. Each time the best performance is achieved by an instance using sets whose cardinality is expressed in absolute terms (1-5), we also present the best performance using support sets whose cardinality is specified in relative terms (10% -90% of the input source). 17, if N \u2265 1, or Eq. 18, if 0 < N < N < 1. For the automatically set thresholds, we identify those using the following notations: H0 means heuristic based on the average distance; H1 means heuristics based on the analysis of distance progression, with H1.1 corresponding to the standard deviation, H1.2 corresponding to the one."}, {"heading": "4.2 Experiment 2: Speech", "text": "In this section, we describe the experiments performed and analyze the corresponding results if we use automatically transcribed language as input source."}, {"heading": "4.2.1 Data", "text": "To evaluate our ideas in language processing, we used the same data from Ribeiro and de Matos (2008a): the automatic transcriptions of 15 transmitted messages in European Portuguese, part of a news program. Topics include, among others, \"Society,\" \"Politics,\" \"Sports.\" Table 4 describes the composition of the corpus. For each news story, there is a man-made reference summary, which is a summary. The average error rate in word recognition is 19.5% and the automatic sentence segmentation reached an error rate (SER, commonly used to assess this type of task) of 90.2%. As can be observed in Table 4, it is important to distinguish between the notion of the sentence in the written text and that of the sentence-like unit (SU) in the language data. Note in particular the difference in the average number of words per sentence in the summary compared to the average number of words per SU in the news story. According to Liu Stolricke, this year is SUPER 1, although SUPER Village, this concept is different from 2010, SUPER Village, this year is SUPER, SUP1."}, {"heading": "4.2.2 Evaluation Setup", "text": "With respect to language summary, even taking into account the difficulties relating to the applicability of text summary methods to spoken documents, flat approaches such as LSA or MMR appear to achieve benefits comparable to those with specific linguistic characteristics (Penn & Zhu, 2008), especially in unattended approaches. Given the models implemented, we compare the support sets relevance model to the following systems: \u2022 An LSA Baseline. \u2022 The following graph-based methods: Uniform Influx (Kurland & Lee, 2005, 2010), Continuous LexRank and Degree centrality (Erkan & Radev, 2004), and TextRank (Mihalcea & Tarau, 2004, 2005). \u2022 The method proposed by Ribeiro and de Matos (2008a) examines the use of additional related information, less prone to language-related errors (e.g. from online newspapers), in order to improve the summary of the language."}, {"heading": "4.2.3 Results", "text": "This year it is so far that it will be able to drown the aforementioned lcihsrteeSe."}, {"heading": "4.3 Influence of the Size of the Support Sets on the Assessment of Relevance", "text": "However, we analyze the impact of support on the evaluation of relevant content, both in the text and in the word.Figure 6 shows the behavior of model variants with a performance above the baseline over the written text, while Figure 7 shows the variants under the same conditions.The number of passages of the input source is determined in 10% increments. Given the average size of an input source, both in written text (Table 1) and in language transcriptions (Table 4), the absolute properties of these variants will be determined taking into account the size of the input sources and taking into account the absolute number of transcriptions, as well as taking into account the absolute properties (SSC), the absolute cardinalities (SSC) from 1 to 5 passages covering possible variables in the intervals of 0-10%. A first observation concerns the fact that the variety of cardinalities of the support sources makes a difference."}, {"heading": "5. Conclusions", "text": "The number of up-to-date examples of work on the automatic summary of results is significant (Garg, Favre, Reidhammer, & Hakkani-Tu, 2009; Antiques Market, 2009; Ceylan et al., 2010; Li, & Xiao, 2010).In our work, we evaluate the main approaches to centrality - as a relevance paradigm - and present a new centrality-based relevance model."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for their insightful comments. This work was supported by FCT (INESC-ID Multiannual Funding) from the PIDDAC program."}], "references": [{"title": "On the Surprising Behavior of Distance Metrics in High Dimensional Space", "author": ["C.C. Aggarwal", "A. Hinneburg", "D.A. Keim"], "venue": "Database Theory \u2014 ICDT", "citeRegEx": "Aggarwal et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Aggarwal et al\\.", "year": 2001}, {"title": "A complex network approach to text summarization", "author": ["L. Antiqueira", "O.N. Oliveira Jr.", "L. da Fontoura Costa", "M.G.V. Nunes"], "venue": "Information Sciences,", "citeRegEx": "Antiqueira et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Antiqueira et al\\.", "year": 2009}, {"title": "Extending the punctuation module for European Portuguese", "author": ["F. Batista", "H. Moniz", "I. Trancoso", "H. Meinedo", "A.I. Mata", "N.J. Mamede"], "venue": "In Proceedings of the 11th Annual Conference of the International Speech Communication Association (INTERSPEECH", "citeRegEx": "Batista et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Batista et al\\.", "year": 2010}, {"title": "The anatomy of a large-scale hypertextual Web search engine", "author": ["S. Brin", "L. Page"], "venue": "Computer Networks and ISDN Systems,", "citeRegEx": "Brin and Page,? \\Q1998\\E", "shortCiteRegEx": "Brin and Page", "year": 1998}, {"title": "The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries", "author": ["J. Carbonell", "J. Goldstein"], "venue": "SIGIR", "citeRegEx": "Carbonell and Goldstein,? \\Q1998\\E", "shortCiteRegEx": "Carbonell and Goldstein", "year": 1998}, {"title": "Assessing agreement on classification tasks: The kappa statistic", "author": ["J. Carletta"], "venue": "Computational Linguistics, 22 (2), 249\u2013254.", "citeRegEx": "Carletta,? 1996", "shortCiteRegEx": "Carletta", "year": 1996}, {"title": "Quantifying the Limits and Success of Extractive Summarization Systems Across Domains", "author": ["H. Ceylan", "R. Mihalcea", "U. \u00d6zertem", "E. Lloret", "M. Palomar"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL,", "citeRegEx": "Ceylan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ceylan et al\\.", "year": 2010}, {"title": "Are Extractive Text Summarisation Techniques Portable To Broadcast News", "author": ["H. Christensen", "Y. Gotoh", "B. Kolluru", "S. Renals"], "venue": "In Proceedings of the IEEE Work-", "citeRegEx": "Christensen et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Christensen et al\\.", "year": 2003}, {"title": "Sentence Compression as Tree Transduction", "author": ["T. Cohn", "M. Lapata"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Cohn and Lapata,? \\Q2009\\E", "shortCiteRegEx": "Cohn and Lapata", "year": 2009}, {"title": "Evaluating Summaries Automatically \u2013 a system proposal", "author": ["P.C.F. de Oliveira", "E.W. Torrens", "A. Cidral", "S. Schossland", "E. Bittencourt"], "venue": "In Proceedings of the Sixth International Language Resources and Evaluation", "citeRegEx": "Oliveira et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Oliveira et al\\.", "year": 2008}, {"title": "Summarizing Information", "author": ["B. Endres-Niggemeyer"], "venue": "Springer.", "citeRegEx": "Endres.Niggemeyer,? 1998", "shortCiteRegEx": "Endres.Niggemeyer", "year": 1998}, {"title": "Language Model-Based Document Clustering Using Random Walks", "author": ["G. Erkan"], "venue": "Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pp. 479\u2013486. Association for Computational Linguistics.", "citeRegEx": "Erkan,? 2006a", "shortCiteRegEx": "Erkan", "year": 2006}, {"title": "Using Biased Random Walks for Focused Summarization", "author": ["G. Erkan"], "venue": "Proceedings of the Document Understanding Conference.", "citeRegEx": "Erkan,? 2006b", "shortCiteRegEx": "Erkan", "year": 2006}, {"title": "LexRank: Graph-based Centrality as Salience in Text Summarization", "author": ["G. Erkan", "D.R. Radev"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Erkan and Radev,? \\Q2004\\E", "shortCiteRegEx": "Erkan and Radev", "year": 2004}, {"title": "WordNet: An Electronic Lexical Database", "author": ["C. Fellbaum"], "venue": null, "citeRegEx": "Fellbaum,? \\Q1998\\E", "shortCiteRegEx": "Fellbaum", "year": 1998}, {"title": "Recent Advances in Automatic Speech Summarization", "author": ["S. Furui"], "venue": "Proceedings of the 8th Conference on Recherche d\u2019Information Assist\u00e9e par Ordinateur (RIAO). Centre des Hautes \u00c9tudes Internationales d\u2019Informatique Documentaire.", "citeRegEx": "Furui,? 2007", "shortCiteRegEx": "Furui", "year": 2007}, {"title": "ClusterRank: A Graph Based Method for Meeting Summarization", "author": ["N. Garg", "B. Favre", "K. Reidhammer", "D. Hakkani-T\u00fcr"], "venue": "In Proceedings of the 10th Annual Conference of the International Speech Communication Association (INTERSPEECH", "citeRegEx": "Garg et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Garg et al\\.", "year": 2009}, {"title": "Generic Text Summarization Using Relevance Measure and Latent Semantic Analysis", "author": ["Y. Gong", "X. Liu"], "venue": "In SIGIR 2001: Proceedings of the 24st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Gong and Liu,? \\Q2001\\E", "shortCiteRegEx": "Gong and Liu", "year": 2001}, {"title": "Topic Themes for Multi-Document Summarization", "author": ["S. Harabagiu", "F. Lacatusu"], "venue": "In SIGIR 2005: Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Harabagiu and Lacatusu,? \\Q2005\\E", "shortCiteRegEx": "Harabagiu and Lacatusu", "year": 2005}, {"title": "Evaluation Method for Automatic Speech Summarization", "author": ["C. Hori", "T. Hori", "S. Furui"], "venue": "In Proceedings of the 8th EUROSPEECH - INTERSPEECH", "citeRegEx": "Hori et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hori et al\\.", "year": 2003}, {"title": "\u00c9tude comparative de la distribution florale dans une portion des Alpes et des Jura", "author": ["P. Jaccard"], "venue": "Bulletin del la Soci\u00e9t\u00e9 Vaudoise des Sciences Naturelles, 37, 547\u2013579.", "citeRegEx": "Jaccard,? 1901", "shortCiteRegEx": "Jaccard", "year": 1901}, {"title": "Random Indexing of text samples for Latent Semantic Analysis", "author": ["P. Kanerva", "J. Kristoferson", "A. Holst"], "venue": "Proceedings of the 22nd annual conference of the Cognitive Science Society,", "citeRegEx": "Kanerva et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Kanerva et al\\.", "year": 2000}, {"title": "Foundations of real-world intelligence, chap. From words to understanding, pp. 294\u2013311", "author": ["P. Kanerva", "M. Sahlgren"], "venue": "No. 26. Center for the Study of Language and Information", "citeRegEx": "Kanerva and Sahlgren,? \\Q2001\\E", "shortCiteRegEx": "Kanerva and Sahlgren", "year": 2001}, {"title": "Authoritative Sources in a Hyperlinked Environment", "author": ["J.M. Kleinberg"], "venue": "Journal of the ACM, 46 (5), 604\u2013632.", "citeRegEx": "Kleinberg,? 1999", "shortCiteRegEx": "Kleinberg", "year": 1999}, {"title": "Introduction to Hp Spaces", "author": ["P. Koosis"], "venue": "Cambridge Universisty Press. Kurland, O., & Lee, L. (2005). PageRank without Hyperlinks: Structural Re-Ranking using Links Induced by Language Models. In SIGIR 2005: Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 306\u2013313. ACM.", "citeRegEx": "Koosis,? 1998", "shortCiteRegEx": "Koosis", "year": 1998}, {"title": "PageRank without Hyperlinks: Structural Reranking using Links Induced by Language Models", "author": ["O. Kurland", "L. Lee"], "venue": "ACM Transactions on Information Systems,", "citeRegEx": "Kurland and Lee,? \\Q2010\\E", "shortCiteRegEx": "Kurland and Lee", "year": 2010}, {"title": "An Introduction to Latent Semantic Analysis", "author": ["T.K. Landauer", "P.W. Foltz", "D. Laham"], "venue": "Discourse Processes,", "citeRegEx": "Landauer et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Landauer et al\\.", "year": 1998}, {"title": "The Measurement of Observer Agreement for Categorical", "author": ["J.R. Landis", "G.G. Kosh"], "venue": "Data. Biometrics,", "citeRegEx": "Landis and Kosh,? \\Q1977\\E", "shortCiteRegEx": "Landis and Kosh", "year": 1977}, {"title": "Extractive Automatic Summarization: Does more linguitic knowledge make a difference", "author": ["D.S. Leite", "L.H.M. Rino", "T.A.S. Pardo", "M.G.V. Nunes"], "venue": "In Proceedings of the Second Workshop on TextGraphs: Graph-based Algorithms for Natural Language Processing,", "citeRegEx": "Leite et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Leite et al\\.", "year": 2007}, {"title": "ROUGE: A Package for Automatic Evaluation of Summaries", "author": ["Lin", "C.-Y."], "venue": "Moens, M.-F., & Szpakowicz, S. (Eds.), Text Summarization Branches Out: Proceedings of the ACL-04 Workshop, pp. 74\u201381. Association for Computational Linguistics.", "citeRegEx": "Lin and C..Y.,? 2004", "shortCiteRegEx": "Lin and C..Y.", "year": 2004}, {"title": "The Automated Acquisition of Topic Signatures for Text Summarization", "author": ["Lin", "C.-Y", "E. Hovy"], "venue": "Coling", "citeRegEx": "Lin et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2000}, {"title": "Extractive Speech Summarization \u2013 From the View of Decision Theory", "author": ["Lin", "S.-H", "Yeh", "Y.-M", "B. Chen"], "venue": "In Proceedings of the 11th Annual Conference of the International Speech Communication Association (INTERSPEECH", "citeRegEx": "Lin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2010}, {"title": "Enriching Speech Recognition with Automatic Detection of Sentence Boundaries and Disfluencies", "author": ["Y. Liu", "E. Shriberg", "A. Stolcke", "D. Hillard", "M. Ostendorf", "M. Harper"], "venue": "IEEE Transactions on Speech and Audio Processing,", "citeRegEx": "Liu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2006}, {"title": "Semantic and associative priming in highdimensional semantic space", "author": ["K. Lund", "C. Burgess", "R.A. Atchley"], "venue": "Proceedings of the 17th annual conference of the Cognitive Science Society,", "citeRegEx": "Lund et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Lund et al\\.", "year": 1995}, {"title": "The Theory and Practice of Discourse Parsing and Summarization", "author": ["D. Marcu"], "venue": "The MIT Press.", "citeRegEx": "Marcu,? 2000", "shortCiteRegEx": "Marcu", "year": 2000}, {"title": "Comparing Lexical, Acoustic/Prosodic, Strucural and Discourse Features for Speech Summarization", "author": ["S.R. Maskey", "J. Hirschberg"], "venue": "In Proceedings of the 9th EUROSPEECH - INTERSPEECH", "citeRegEx": "Maskey and Hirschberg,? \\Q2005\\E", "shortCiteRegEx": "Maskey and Hirschberg", "year": 2005}, {"title": "From Text to Speech Summarization", "author": ["K.R. McKeown", "J. Hirschberg", "M. Galley", "S.R. Maskey"], "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings,", "citeRegEx": "McKeown et al\\.,? \\Q2005\\E", "shortCiteRegEx": "McKeown et al\\.", "year": 2005}, {"title": "TextRank: Bringing Order into Texts", "author": ["R. Mihalcea", "P. Tarau"], "venue": "In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Mihalcea and Tarau,? \\Q2004\\E", "shortCiteRegEx": "Mihalcea and Tarau", "year": 2004}, {"title": "A Language Independent Algorithm for Single and Multiple Document Summarization", "author": ["R. Mihalcea", "P. Tarau"], "venue": "In Proceedings of the Second International Joint Conference on Natural Language Processing: Companion Volume to the Proceedings of Conference including Posters/Demos and Tutorial Abstracts,", "citeRegEx": "Mihalcea and Tarau,? \\Q2005\\E", "shortCiteRegEx": "Mihalcea and Tarau", "year": 2005}, {"title": "Bootstrapping : a nonparametric approach to statistical inference", "author": ["C.Z. Mooney", "R.D. Duval"], "venue": null, "citeRegEx": "Mooney and Duval,? \\Q1993\\E", "shortCiteRegEx": "Mooney and Duval", "year": 1993}, {"title": "Term-Weighting for Summarization of Multi-Party Spoken Dialogues", "author": ["G. Murray", "S. Renals"], "venue": "Machine Learning for Multimodal Interaction IV,", "citeRegEx": "Murray and Renals,? \\Q2007\\E", "shortCiteRegEx": "Murray and Renals", "year": 2007}, {"title": "Summarization Evaluation for Text and Speech: Issues and Approaches", "author": ["A. Nenkova"], "venue": "Proceedings of INTERSPEECH 2006 - ICSLP, pp. 1527\u20131530. ISCA.", "citeRegEx": "Nenkova,? 2006", "shortCiteRegEx": "Nenkova", "year": 2006}, {"title": "The pyramid method: incorporating human content selection variation in summarization evaluation", "author": ["A. Nenkova", "R. Passonneau", "K. McKeown"], "venue": "ACM Transactions on Speech and Language Processing,", "citeRegEx": "Nenkova et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nenkova et al\\.", "year": 2007}, {"title": "A comparison of summarisation methods based on term specificity estimation", "author": ["C. Or\u0103san", "V. Pekar", "L. Hasler"], "venue": "In Proceedings of the Fourth International Language Resources and Evaluation", "citeRegEx": "Or\u0103san et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Or\u0103san et al\\.", "year": 2004}, {"title": "TeMario: a corpus for automatic text summarization", "author": ["T.A.S. Pardo", "L.H.M. Rino"], "venue": "Tech. rep. NILC-TR-03-09, Nu\u0301cleo Interinstitucional de Lingu\u0308\u0301\u0131stica Computacional (NILC),", "citeRegEx": "Pardo and Rino,? \\Q2003\\E", "shortCiteRegEx": "Pardo and Rino", "year": 2003}, {"title": "A Critical Reassessment of Evaluation Baselines for Speech Summarization", "author": ["G. Penn", "X. Zhu"], "venue": "In Proceeding of ACL-08: HLT,", "citeRegEx": "Penn and Zhu,? \\Q2008\\E", "shortCiteRegEx": "Penn and Zhu", "year": 2008}, {"title": "R: A Language and Environment for Statistical Computing", "author": ["R Development Core Team"], "venue": "R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.", "citeRegEx": "Team,? 2009", "shortCiteRegEx": "Team", "year": 2009}, {"title": "A Description of the CIDR System as Used for TDT-2", "author": ["D.R. Radev", "V. Hatzivassiloglou", "K.R. McKeown"], "venue": "In Proceedings of the DARPA Broadcast News Workshop", "citeRegEx": "Radev et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Radev et al\\.", "year": 1999}, {"title": "Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies", "author": ["D.R. Radev", "H. Jing", "M. Budzikowska"], "venue": null, "citeRegEx": "Radev et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Radev et al\\.", "year": 2000}, {"title": "Centroid-based summarization of multiple documents", "author": ["D.R. Radev", "H. Jing", "M. Sty\u015b", "D. Tam"], "venue": "Information Processing and Management,", "citeRegEx": "Radev et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Radev et al\\.", "year": 2004}, {"title": "Summarization Evaluation using Relative Utility", "author": ["D.R. Radev", "D. Tam"], "venue": "In Proceedings of the 12th international conference on Information and Knowledge Management,", "citeRegEx": "Radev and Tam,? \\Q2003\\E", "shortCiteRegEx": "Radev and Tam", "year": 2003}, {"title": "Extractive Summarization of Broadcast News: Comparing Strategies for European Portuguese", "author": ["R. Ribeiro", "D.M. de Matos"], "venue": "Text, Speech and Dialogue \u2013 10th International Conference,", "citeRegEx": "Ribeiro and Matos,? \\Q2007\\E", "shortCiteRegEx": "Ribeiro and Matos", "year": 2007}, {"title": "Mixed-Source Multi-Document Speech-to-Text Summarization", "author": ["R. Ribeiro", "D.M. de Matos"], "venue": "In Coling 2008: Proceedings of the 2nd workshop on Multi-source Multilingual Information Extraction and Summarization,", "citeRegEx": "Ribeiro and Matos,? \\Q2008\\E", "shortCiteRegEx": "Ribeiro and Matos", "year": 2008}, {"title": "Using Prior Knowledge to Assess Relevance in Speech Summarization", "author": ["R. Ribeiro", "D.M. de Matos"], "venue": "IEEE Workshop on Spoken Language Technology,", "citeRegEx": "Ribeiro and Matos,? \\Q2008\\E", "shortCiteRegEx": "Ribeiro and Matos", "year": 2008}, {"title": "Experiments on linguistically-based term associations", "author": ["G. Ruge"], "venue": "Information Processing and Management, 28 (3), 317\u2013332.", "citeRegEx": "Ruge,? 1992", "shortCiteRegEx": "Ruge", "year": 1992}, {"title": "The Word-Space Model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in high-dimensional vector spaces", "author": ["M. Sahlgren"], "venue": "Ph.D. thesis, Stockholm University.", "citeRegEx": "Sahlgren,? 2006", "shortCiteRegEx": "Sahlgren", "year": 2006}, {"title": "Handbook of Latent Semantic Analysis, chap. Probabilistic Topic Models, pp. 427\u2013448", "author": ["M. Steyvers", "T. Griffiths"], "venue": null, "citeRegEx": "Steyvers and Griffiths,? \\Q2007\\E", "shortCiteRegEx": "Steyvers and Griffiths", "year": 2007}, {"title": "Between shallow and deep: an experiment in automatic summarising", "author": ["R.I. Tucker", "K. Sp\u00e4rck Jones"], "venue": "Tech. rep. 632,", "citeRegEx": "Tucker and Jones,? \\Q2005\\E", "shortCiteRegEx": "Tucker and Jones", "year": 2005}, {"title": "From Frequency to Meaning: Vector Space Models of Semantics", "author": ["P.D. Turney", "P. Pantel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Turney and Pantel,? \\Q2010\\E", "shortCiteRegEx": "Turney and Pantel", "year": 2010}, {"title": "A comprehensive comparative evaluation of RST-based summarization methods", "author": ["V.R. Uz\u00eada", "T.A.S. Pardo", "M.G.V. Nunes"], "venue": "ACM Transactions on Speech and Language Processing,", "citeRegEx": "Uz\u00eada et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Uz\u00eada et al\\.", "year": 2010}, {"title": "Beyond SumBasic: Task-focused summarization and lexical expansion", "author": ["L. Vanderwende", "H. Suzuki", "C. Brockett", "A. Nenkova"], "venue": "Information Processing and Management,", "citeRegEx": "Vanderwende et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Vanderwende et al\\.", "year": 2007}, {"title": "EUSUM: Extracting Easy-to-Understand English Summaries for Non-Native Readers", "author": ["X. Wan", "H. Li", "J. Xiao"], "venue": "In SIGIR 2010: Proceedings of the 33th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Wan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2010}, {"title": "CollabSum: Exploiting Multiple Document Clustering for Collaborative Single Document Summarizations", "author": ["X. Wan", "J. Yang", "J. Xiao"], "venue": "In SIGIR 2007: Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Wan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2007}, {"title": "Minimizing Word Error Rate in Textual Summaries of Spoken Language", "author": ["K. Zechner", "A. Waibel"], "venue": "In Proceedings of the 1st conference of the North American chapter of the ACL,", "citeRegEx": "Zechner and Waibel,? \\Q2000\\E", "shortCiteRegEx": "Zechner and Waibel", "year": 2000}, {"title": "Semi-Supervised Learning with Graphs", "author": ["X. Zhu"], "venue": "Ph.D. thesis, Language Technologies Institute, School of Computer Science, Carnegie Mellon University.", "citeRegEx": "Zhu,? 2005", "shortCiteRegEx": "Zhu", "year": 2005}], "referenceMentions": [{"referenceID": 15, "context": "In fact, spoken language summarization is often considered a much harder task than text summarization (McKeown, Hirschberg, Galley, & Maskey, 2005; Furui, 2007): problems like speech recognition errors, disfluencies, and the accurate identification of sentence boundaries not only increase the difficulty in determining the salient information, but also constrain the applicability of text summarization techniques to speech summarization (although in the presence of planned speech, as it partly happens in the broadcast news domain, that portability is more feasible, Christensen, Gotoh, Kolluru, & Renals, 2003).", "startOffset": 102, "endOffset": 160}, {"referenceID": 15, "context": "In fact, spoken language summarization is often considered a much harder task than text summarization (McKeown, Hirschberg, Galley, & Maskey, 2005; Furui, 2007): problems like speech recognition errors, disfluencies, and the accurate identification of sentence boundaries not only increase the difficulty in determining the salient information, but also constrain the applicability of text summarization techniques to speech summarization (although in the presence of planned speech, as it partly happens in the broadcast news domain, that portability is more feasible, Christensen, Gotoh, Kolluru, & Renals, 2003). Nonetheless, shallow text summarization approaches such as Latent Semantic Analysis (LSA) (Landauer, Foltz, & Laham, 1998; Gong & Liu, 2001) and Maximal Marginal Relevance (MMR) (Carbonell & Goldstein, 1998) seem to achieve performances comparable to the ones using specific speech-related features (Penn & Zhu, 2008). Following the determination of the relevant content, the summary must be composed and presented to the user. If the identified content consists of passages found in the input source that are glued together to form the summary, that summary is usually designated as extract ; on the other hand, when the important content is devised as a series of concepts that are fused into a smaller set and then used to generate a new, concise, and informative text, we are in the presence of an abstract. In between extraction and concept-to-text generation, especially in text summarization, text-to-text generation methods, which rely on text rewriting\u2014paraphrasing\u2014, of which sentence compression is a major representative, are becoming an up-to-date subject (Cohn & Lapata, 2009). Given the hardness of abstraction, the bulk of the work in the area consists of extractive summarization. A common family of approaches to the identification of the relevant content is the centrality family. These methods base the detection of the most salient passages on the identification of the central passages of the input source(s). One of the main representatives of this family is centroid-based summarization. Centroid-based methods build on the idea of a pseudo-passage that represents the central topic of the input source (the centroid) selecting as passages (x) to be included in the summary the ones that are close to the centroid. Pioneer work (on multi-document summarization) by Radev, Hatzivassiloglou, and McKeown (1999) and Radev, Jing, and Budzikowska (2000) creates clusters of documents by representing each document as a tf-idf vector; the centroid of each cluster is also defined as a tf-idf vector, with the coordinates corresponding to the weighted average of the tf-idf values of the documents of the cluster; finally, sentences that contain the words of the centroids are presumably the best representatives of the topic of the cluster, thus being the best candidates to belonging to the summary.", "startOffset": 148, "endOffset": 2449}, {"referenceID": 15, "context": "In fact, spoken language summarization is often considered a much harder task than text summarization (McKeown, Hirschberg, Galley, & Maskey, 2005; Furui, 2007): problems like speech recognition errors, disfluencies, and the accurate identification of sentence boundaries not only increase the difficulty in determining the salient information, but also constrain the applicability of text summarization techniques to speech summarization (although in the presence of planned speech, as it partly happens in the broadcast news domain, that portability is more feasible, Christensen, Gotoh, Kolluru, & Renals, 2003). Nonetheless, shallow text summarization approaches such as Latent Semantic Analysis (LSA) (Landauer, Foltz, & Laham, 1998; Gong & Liu, 2001) and Maximal Marginal Relevance (MMR) (Carbonell & Goldstein, 1998) seem to achieve performances comparable to the ones using specific speech-related features (Penn & Zhu, 2008). Following the determination of the relevant content, the summary must be composed and presented to the user. If the identified content consists of passages found in the input source that are glued together to form the summary, that summary is usually designated as extract ; on the other hand, when the important content is devised as a series of concepts that are fused into a smaller set and then used to generate a new, concise, and informative text, we are in the presence of an abstract. In between extraction and concept-to-text generation, especially in text summarization, text-to-text generation methods, which rely on text rewriting\u2014paraphrasing\u2014, of which sentence compression is a major representative, are becoming an up-to-date subject (Cohn & Lapata, 2009). Given the hardness of abstraction, the bulk of the work in the area consists of extractive summarization. A common family of approaches to the identification of the relevant content is the centrality family. These methods base the detection of the most salient passages on the identification of the central passages of the input source(s). One of the main representatives of this family is centroid-based summarization. Centroid-based methods build on the idea of a pseudo-passage that represents the central topic of the input source (the centroid) selecting as passages (x) to be included in the summary the ones that are close to the centroid. Pioneer work (on multi-document summarization) by Radev, Hatzivassiloglou, and McKeown (1999) and Radev, Jing, and Budzikowska (2000) creates clusters of documents by representing each document as a tf-idf vector; the centroid of each cluster is also defined as a tf-idf vector, with the coordinates corresponding to the weighted average of the tf-idf values of the documents of the cluster; finally, sentences that contain the words of the centroids are presumably the best representatives of the topic of the cluster, thus being the best candidates to belonging to the summary.", "startOffset": 148, "endOffset": 2489}, {"referenceID": 59, "context": "This means that it is common to find, in the input sources to be summarized, lateral issues or considerations that are not relevant to devise the salient information (discourse structure-based summarization is based on the relevance of nuclear text segments, Marcu, 2000; Uz\u00eada et al., 2010), and that may affect centrality-based summarization methods by inducing inadequate centroids or decreasing the scores of more suitable sentences.", "startOffset": 166, "endOffset": 291}, {"referenceID": 47, "context": "The work in multi-document summarization by Radev et al. (1999, 2000) and Radev, Jing, Sty\u015b, and Tam (2004) and the work developed by Lin and Hovy (2000) are examples of this approach.", "startOffset": 44, "endOffset": 108}, {"referenceID": 47, "context": "The work in multi-document summarization by Radev et al. (1999, 2000) and Radev, Jing, Sty\u015b, and Tam (2004) and the work developed by Lin and Hovy (2000) are examples of this approach.", "startOffset": 44, "endOffset": 154}, {"referenceID": 11, "context": "The work presented by Erkan and Radev (2004), as well as the work developed by Mihalcea and Tarau (2005), are examples of this approach.", "startOffset": 22, "endOffset": 45}, {"referenceID": 11, "context": "The work presented by Erkan and Radev (2004), as well as the work developed by Mihalcea and Tarau (2005), are examples of this approach.", "startOffset": 22, "endOffset": 105}, {"referenceID": 11, "context": "The work presented by Erkan and Radev (2004), as well as the work developed by Mihalcea and Tarau (2005), are examples of this approach. Erkan and Radev (2004) propose three graph-based approaches to pair-wise passage similarity-based summarization with similar performance: degree centrality, LexRank, and continuous LexRank.", "startOffset": 22, "endOffset": 160}, {"referenceID": 23, "context": "Mihalcea and Tarau (2005), in addition to Google\u2019s PageRank, also explore the HITS algorithm (Kleinberg, 1999) to perform graph-based extractive text summarization: again, documents are represented as networks of sentences and these networks are used to globally determine the importance of each sentence.", "startOffset": 93, "endOffset": 110}, {"referenceID": 1, "context": "A similar graph-based approach is described by Antiqueira et al. (2009). This work uses complex networks to perform extractive text summarization.", "startOffset": 47, "endOffset": 72}, {"referenceID": 36, "context": "The metric proposed by Mihalcea and Tarau (2004) has an unresolved issue: the denominator is 0 when comparing two equal sentences with length one (something that can happen when processing speech transcriptions).", "startOffset": 23, "endOffset": 49}, {"referenceID": 20, "context": "Instead, the Jaccard similarity coefficient (1901) could be used.", "startOffset": 13, "endOffset": 51}, {"referenceID": 11, "context": "In the degenerate case where all \u03b5i are equal, we fall into the degree centrality model proposed by Erkan and Radev (2004). But using, for instance, a n\u00e4\u0131ve approach of having dynamic thresholds (\u03b5i) set by limiting the cardinality of the support sets (a kNN approach), centrality is changed because each support set has only the most semantically related passages of each passage.", "startOffset": 100, "endOffset": 123}, {"referenceID": 11, "context": "In the degenerate case where all \u03b5i are equal, we fall into the degree centrality model proposed by Erkan and Radev (2004). But using, for instance, a n\u00e4\u0131ve approach of having dynamic thresholds (\u03b5i) set by limiting the cardinality of the support sets (a kNN approach), centrality is changed because each support set has only the most semantically related passages of each passage. From a graph theory perspective, this means that the underlying representation is not undirected, and the support set can be interpreted as the passages recommended by the passage associated to the support set. This contrasts with both LexRank models, which are based on undirected graphs. On the other hand, the models proposed by Mihalcea and Tarau (2005) are closer to our work in the sense that they explore directed graphs, although only in a simple way (graphs can only be directed forward or backward).", "startOffset": 100, "endOffset": 740}, {"referenceID": 42, "context": "In what concerns the definition of the weighting function f(ti, pj), several term weighting schemes have been explored in the literature\u2014for the analysis of the impact of different weighting schemes on either text or speech summarization see the work of Or\u0103san et al. (2004), and Murray and Renals (2007) or Ribeiro and de Matos (2008b), respectively.", "startOffset": 254, "endOffset": 275}, {"referenceID": 40, "context": "(2004), and Murray and Renals (2007) or Ribeiro and de Matos (2008b), respectively.", "startOffset": 12, "endOffset": 37}, {"referenceID": 40, "context": "(2004), and Murray and Renals (2007) or Ribeiro and de Matos (2008b), respectively.", "startOffset": 12, "endOffset": 69}, {"referenceID": 55, "context": "Nevertheless, this is in line with the work of Sahlgren (2006) that shows that in several tasks concerning term semantic relatedness, one of the most effective weighting schemes for small contexts is the binary term weighting scheme (Eq.", "startOffset": 47, "endOffset": 63}, {"referenceID": 55, "context": "As indicated by Sahlgren (2006), the meanings-are-locations metaphor is completely vacuous without the similarity-is-proximity metaphor.", "startOffset": 16, "endOffset": 32}, {"referenceID": 26, "context": "Examples are corpus-based vector space models of semantics (Turney & Pantel, 2010), like LSA (Landauer et al., 1998), Hyperspace Analogue to Language (Lund, Burgess, & Atchley, 1995), or Random Indexing (Kanerva, Kristoferson, & Holst, 2000; Kanerva & Sahlgren, 2001), or similarity metrics based on knowledge-rich semantic resources, such as WordNet (Fellbaum, 1998).", "startOffset": 93, "endOffset": 116}, {"referenceID": 14, "context": ", 1998), Hyperspace Analogue to Language (Lund, Burgess, & Atchley, 1995), or Random Indexing (Kanerva, Kristoferson, & Holst, 2000; Kanerva & Sahlgren, 2001), or similarity metrics based on knowledge-rich semantic resources, such as WordNet (Fellbaum, 1998).", "startOffset": 242, "endOffset": 258}, {"referenceID": 34, "context": "In contrast, Mihalcea and Tarau (2005) and Antiqueira et al.", "startOffset": 13, "endOffset": 39}, {"referenceID": 1, "context": "In contrast, Mihalcea and Tarau (2005) and Antiqueira et al. (2009) define passage similarity as content overlap.", "startOffset": 43, "endOffset": 68}, {"referenceID": 64, "context": "In this set of heuristics, we explore two weight functions (Zhu, 2005) (Eqs.", "startOffset": 59, "endOffset": 70}, {"referenceID": 48, "context": "Several evaluation models have been put forward in the last decade: beyond the long-established precision and recall (mostly useful when evaluating extractive summarization using also extractive summaries as models), literature is filled with metrics (some are automatic, others manual) like Relative utility (Radev et al., 2000; Radev & Tam, 2003), SummACCY (Hori, Hori, & Furui, 2003), ROUGE (Lin, 2004), VERT (de Oliveira, Torrens, Cidral, Schossland, & Bittencourt, 2008), or the Pyramid method (Nenkova, Passonneau, & McKeown, 2007).", "startOffset": 309, "endOffset": 348}, {"referenceID": 15, "context": ", 2000; Radev & Tam, 2003), SummACCY (Hori, Hori, & Furui, 2003), ROUGE (Lin, 2004), VERT (de Oliveira, Torrens, Cidral, Schossland, & Bittencourt, 2008), or the Pyramid method (Nenkova, Passonneau, & McKeown, 2007). For a more comprehensive analysis of the evaluation field see the work by Nenkova (2006) and Nenkova et al.", "startOffset": 52, "endOffset": 306}, {"referenceID": 15, "context": ", 2000; Radev & Tam, 2003), SummACCY (Hori, Hori, & Furui, 2003), ROUGE (Lin, 2004), VERT (de Oliveira, Torrens, Cidral, Schossland, & Bittencourt, 2008), or the Pyramid method (Nenkova, Passonneau, & McKeown, 2007). For a more comprehensive analysis of the evaluation field see the work by Nenkova (2006) and Nenkova et al. (2007). Despite the number of approaches to summary evaluation, the most widely used metric is still ROUGE and is the one we use in our study.", "startOffset": 52, "endOffset": 332}, {"referenceID": 37, "context": "\u2022 a set of graph-based summarizers presented by Mihalcea and Tarau (2005), namely PageRank Backward, HITSA Backward and HITSH Forward; \u2022 SuPor-v2 (Leite, Rino, Pardo, & Nunes, 2007), a classifier-based system that uses features like the occurrence of proper nouns, lexical chaining, and an ontology;", "startOffset": 48, "endOffset": 74}, {"referenceID": 28, "context": "\u2022 two modified versions of Mihalcea\u2019s PageRank Undirected, called TextRank + Thesaurus and TextRank + Stem + StopwordsRem(oval) presented by Leite et al. (2007); and,", "startOffset": 141, "endOffset": 161}, {"referenceID": 1, "context": "\u2022 several complex networks summarizers proposed by Antiqueira et al. (2009).", "startOffset": 51, "endOffset": 76}, {"referenceID": 11, "context": "\u2022 PageRank, proposed by both Mihalcea and Tarau (2004, 2005) and Erkan and Radev (2004) (passage similarity metrics differ and Mihalcea and Tarau also explore directed graphs);", "startOffset": 65, "endOffset": 88}, {"referenceID": 11, "context": "\u2022 Degree centrality as proposed by Erkan and Radev (2004) (we experimented with several thresholds \u03b4, ranging from 0.", "startOffset": 35, "endOffset": 58}, {"referenceID": 11, "context": "Additionally, given that the models proposed by Erkan and Radev (2004) use idf, we present some results (clearly identified) using both weighting schemes: using and not using idf.", "startOffset": 48, "endOffset": 71}, {"referenceID": 1, "context": "It is relevant to note that our model, which has low computational requirements, achieves results comparable to graph-based state-of-the-art systems (Ceylan, Mihalcea, \u00d6zertem, Lloret, & Palomar, 2010; Antiqueira et al., 2009).", "startOffset": 149, "endOffset": 226}, {"referenceID": 1, "context": "It is relevant to note that our model, which has low computational requirements, achieves results comparable to graph-based state-of-the-art systems (Ceylan, Mihalcea, \u00d6zertem, Lloret, & Palomar, 2010; Antiqueira et al., 2009). Notice that although the estimated confidence intervals overlap, the performance of the Manhattan SCC=2 variant is significantly better, using the directional Wilcoxon signed rank test with continuity correction, than the ones of TextRank Undirected, (W = 2584, p < 0.05), Uniform Influx (W = 2740, p < 0.05), and also Continuous LexRank (W = 2381.5, p < 0.1).4 The only variants of our model that perform below the baseline are the Fractional variants with N < 1. Fractional distances with N < 1, as can be seen by the effect of the metric on the unit circle (Figure 1), increase the distance between all passages, negatively influencing the construction of the support sets and, consequently the estimation of relevant content. Concerning the automatically set per passage thresholds, it is possible to observe that the best overall performance was achieved by a metric, Fractional N = 1.(3), with idf, using the heuristic based on the average difference between consecutive distances. For Cosine, Manhattan, Euclidean, and Minkowski variants, the heuristic based on the average distance (Cosine) and the heuristics based on passage order achieved results comparable to the best performing kNN approaches. For Chebyshev and Fractional (with N < 1) variants the best results were obtained using the heuristics based on the analysis of the progression of the distances. Figure 2 shows the improvements over the baseline and over the previous best-performing system. It is possible to perceive that the greatest performance jumps are introduced by Euclidean (10%) and Euclidean (H2.3), Minkowski (SSC=2), and the best-performing Manhattan, all instances of the support sets-based relevance model. Additionally, it is important to notice that the improvement of CN-Voting over the baseline (computed in the same conditions of CN-Voting) is of only 1%, having a performance worse than the poorest TextRank version which had an improvement over the baseline of 1.6%. In what concerns the linguistic knowledge-based systems (SuPor-2 and the enriched versions of TextRank Undirected), we cannot make an informed assessment of their performance since we cannot substantiate the used baseline, taken from the work of Mihalcea and Tarau (2005). Nonetheless, using that baseline, it is clear that linguistic information improves the performance of extractive summarizers beyond what we achieved with our model: improvements over the baseline range from 9% to 17.", "startOffset": 202, "endOffset": 2463}, {"referenceID": 5, "context": "One of the relevant issues that should be assessed is the level of agreement between the two human summarizers: this was accomplished using the kappa coefficient (Carletta, 1996), for which we obtained a value of 0.", "startOffset": 162, "endOffset": 178}, {"referenceID": 11, "context": "Approaches based on generation probabilities seem more adequate to larger contexts, such as documents (Kurland & Lee, 2005, 2010; Erkan, 2006a).", "startOffset": 102, "endOffset": 143}, {"referenceID": 11, "context": "Approaches based on generation probabilities seem more adequate to larger contexts, such as documents (Kurland & Lee, 2005, 2010; Erkan, 2006a). Erkan (2006b) mentions that results in query-based summarization using generation probabilities were worse than the ones obtained by LexRank in generic summarization.", "startOffset": 130, "endOffset": 159}, {"referenceID": 30, "context": "Further, comparing our model to more complex (not centrality-based), state-of-the-art models like the one presented by Lin et al. (2010) suggests that at least similar performance is attained: the relative performance increment of our model over LexRank is of 57.", "startOffset": 119, "endOffset": 137}, {"referenceID": 1, "context": "The number of up-to-date examples of work on automatic summarization using centralitybased relevance models is significant (Garg, Favre, Reidhammer, & Hakkani-T\u00fcr, 2009; Antiqueira et al., 2009; Ceylan et al., 2010; Wan, Li, & Xiao, 2010).", "startOffset": 123, "endOffset": 238}, {"referenceID": 6, "context": "The number of up-to-date examples of work on automatic summarization using centralitybased relevance models is significant (Garg, Favre, Reidhammer, & Hakkani-T\u00fcr, 2009; Antiqueira et al., 2009; Ceylan et al., 2010; Wan, Li, & Xiao, 2010).", "startOffset": 123, "endOffset": 238}, {"referenceID": 1, "context": "The number of up-to-date examples of work on automatic summarization using centralitybased relevance models is significant (Garg, Favre, Reidhammer, & Hakkani-T\u00fcr, 2009; Antiqueira et al., 2009; Ceylan et al., 2010; Wan, Li, & Xiao, 2010). In our work, we assessed the main approaches of the centrality-as-relevance paradigm, and introduced a new centrality-based relevance model for automatic summarization. Our model uses support sets to better characterize the information sources to be summarized, leading to a better estimation of the relevant content. In fact, we assume that input sources comprehend several topics that are uncovered by associating to each passage a support set composed by the most semantically related passages. Building on the ideas of Ruge (1992), [.", "startOffset": 170, "endOffset": 775}], "year": 2011, "abstractText": "In automatic summarization, centrality-as-relevance means that the most important content of an information source, or a collection of information sources, corresponds to the most central passages, considering a representation where such notion makes sense (graph, spatial, etc.). We assess the main paradigms, and introduce a new centrality-based relevance model for automatic summarization that relies on the use of support sets to better estimate the relevant content. Geometric proximity is used to compute semantic relatedness. Centrality (relevance) is determined by considering the whole input source (and not only local information), and by taking into account the existence of minor topics or lateral subjects in the information sources to be summarized. The method consists in creating, for each passage of the input source, a support set consisting only of the most semantically related passages. Then, the determination of the most relevant content is achieved by selecting the passages that occur in the largest number of support sets. This model produces extractive summaries that are generic, and languageand domainindependent. Thorough automatic evaluation shows that the method achieves state-of-theart performance, both in written text, and automatically transcribed speech summarization, including when compared to considerably more complex approaches.", "creator": "TeX"}}}