{"id": "1401.4593", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2014", "title": "Location-Based Reasoning about Complex Multi-Agent Behavior", "abstract": "Recent research has shown that surprisingly rich models of human activity can be learned from GPS (positional) data. However, most effort to date has concentrated on modeling single individuals or statistical properties of groups of people. Moreover, prior work focused solely on modeling actual successful executions (and not failed or attempted executions) of the activities of interest. We, in contrast, take on the task of understanding human interactions, attempted interactions, and intentions from noisy sensor data in a fully relational multi-agent setting. We use a real-world game of capture the flag to illustrate our approach in a well-defined domain that involves many distinct cooperative and competitive joint activities. We model the domain using Markov logic, a statistical-relational language, and learn a theory that jointly denoises the data and infers occurrences of high-level activities, such as a player capturing an enemy. Our unified model combines constraints imposed by the geometry of the game area, the motion model of the players, and by the rules and dynamics of the game in a probabilistically and logically sound fashion. We show that while it may be impossible to directly detect a multi-agent activity due to sensor noise or malfunction, the occurrence of the activity can still be inferred by considering both its impact on the future behaviors of the people involved as well as the events that could have preceded it. Further, we show that given a model of successfully performed multi-agent activities, along with a set of examples of failed attempts at the same activities, our system automatically learns an augmented model that is capable of recognizing success and failure, as well as goals of peoples actions with high accuracy. We compare our approach with other alternatives and show that our unified model, which takes into account not only relationships among individual players, but also relationships among activities over the entire length of a game, although more computationally costly, is significantly more accurate. Finally, we demonstrate that explicitly modeling unsuccessful attempts boosts performance on other important recognition tasks.", "histories": [["v1", "Sat, 18 Jan 2014 21:04:39 GMT  (2211kb)", "http://arxiv.org/abs/1401.4593v1", null]], "reviews": [], "SUBJECTS": "cs.MA cs.AI", "authors": ["adam sadilek", "henry kautz"], "accepted": false, "id": "1401.4593"}, "pdf": {"name": "1401.4593.pdf", "metadata": {"source": "CRF", "title": "Location-Based Reasoning about Complex Multi-Agent Behavior", "authors": ["Adam Sadilek", "Henry Kautz"], "emails": ["SADILEK@CS.ROCHESTER.EDU", "KAUTZ@CS.ROCHESTER.EDU"], "sections": [{"heading": null, "text": "However, most efforts so far have focused on modeling individual individuals or statistical characteristics of groups of people. Furthermore, previous work has focused exclusively on modeling actual successful executions (not failed or attempted executions) of activities of interest. In contrast, we take on the task of understanding human interactions, attempted interactions, and intentions from loud sensor data in a fully relational multi-agent setting. We use a real game to capture the flag to illustrate our approach in a well-defined area that includes many different cooperative and competing common activities. We model the domain using Markov logic, a statistical-relational language, and learn a theory that collectively denotes the data and occurrence of violators at a high level, such as detecting an enemy player. Our unified model combines constraints imposed by the geometry of the game area, and the player's motion model, and the rules and the relationship of the game to a true dynamic within each other."}, {"heading": "1. Introduction", "text": "This year, it is only a matter of time before there is an agreement, until there is an agreement."}, {"heading": "2. Capture The Flag Domain", "text": "In fact, it is so that we are in a time, in which we are in a time, in which we are in a time, in which we are in a time, in which we are in a time, in which we are in a time, in which we are in a time, in which we are in a time, in which we are in a time, in which we are in a time, in which we are in a time, in which we are in which we are in a time, in which we are in which we are in which we are in which we are in which we are in which we are such a time, in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we in which we are in which we in which we are in which we are in which we are in which we in which we are in which we are in which we in which we are in which we in which we are in which we in which we are in which we in which we are in which we in which we in which we are in which we in which we in which we are in which we in which we in which we are in which we in which we in which we are in which we in which we are in which we in which we in which we in which we are in which we in which we are in which we in which we are in which we in which we in which we are in which we are in which we in which we are in which we in which we in which we are in which we are in which we in which we are in which we in which we are in which we in which we are in which we are in which we are in which we are in which we in which we are in which we are in which we in which we are in which we in which we are in which we are in which we in which we are in which we are in which we in which we are in which we in which we are in which we are in which we in which we are in which we in which we are in which we in which we are in which we are in which we are in which we in which we are in which we in which we are in which we in which we in which we are in which we in which we are in which we in which we in which we are in which"}, {"heading": "3. Our Contributions", "text": "We first present a novel method that simultaneously displays position data and learns a model of the multi-agent activities occurring there. We then evaluate the model on the CTF dataset and show that it achieves high accuracy in detecting complex game occurrences. However, creating a model by manually writing new rules or editing existing axioms is tedious and prone to introducing errors or unnecessarily complex theories. Therefore, we want to automate this process by learning (or inducing) new axioms from training data. It is much easier for humans to provide or validate concrete examples than to modify a model directly. This leads to our second contribution: we show how to automatically supplement an existing model of (shared) activities so that it is not only able to detect successful actions, but also identifies failed attempts at the same types of activities. This line of work also shows that explicit modeling attempted interactions in a consistent way improves overall performance."}, {"heading": "4. Background", "text": "The cores of our models described below are implemented in Markov logic (ML), a statistical relationship language. In this section, we give a brief overview of ML, which extends finite firstorder logic (FOL) to a probabilistic environment. For a more detailed (and excellent) treatment of FOL, ML and inductive logic programming, we refer to the work of Shoenfield (1967), Domingos, Kok, Lowd, Poon, Richardson and Singla (2008), as well as De Raedt and Kersting (2008). To compare the models based on Markov logic with alternative approaches, we consider a dynamic Bajesian network model (DBN) in the experiments below as one of our foundations. Therefore, we also review relevant aspects of DBNs in this section."}, {"heading": "4.1 Markov Logic", "text": "In fact, the majority of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight,"}, {"heading": "4.2 Dynamic Bayesian Networks", "text": "A Bayesian network (BN) is a directed probabilistic graphical model (Jordan, 1998). Nodes in the diagram represent random variables and edges represent conditional dependencies (see Figure 4). Therefore, for a BN with n nodes, the common probability distribution of Pr (X1,.., Xn) = n \u00b2 i = 1 Pr (Xi | Pa (Xi))), (3) 1. http: / / alchemy.cs.washington.edu / 2. http: / code.google.com / p / theBeast / where Pa (Xi) denotes the parents of the node Xi. In a typical environment, a subset of random variables is observed (we know their actual values) while the others are hidden and their values must be derived. A dynamic Bayesian network (DBN) is a BN that models sequential data."}, {"heading": "5. Methodology", "text": "In this section, we describe the three main components of our approach. In short, we first manually construct a model for collecting and releasing CTF data and optimizing its parameters within a monitored learning framework (Section 5.1). This is our \"seed theory,\" which is used to denoise raw location data and to recognize successful multi-agent activities. Then, in Section 5.2, we show how we can automatically expand seed theory by inducing the structure and meaning of failed collections and releases, as well as relations with their successful counterparts, and deriving the goals of the activities from them. Finally, in Section 5.3, we use advanced theory to detect these richer multi-agent activities - both successful and failed attempts - and extract the goals of the activities. Specifically, we examine the following four research questions: Q1. Can we reliably detect complex multi-agent activities in the CTF dataset, even in the presence of automated activities, by learning how to use the above-mentioned noise models?"}, {"heading": "5.1 Recognition of Successful Activities", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "5.2 Learning Models of Failed Attempts", "text": "In the work described above, we have designed the structure of a Markov logic network that determines the actual effects on the (n, c, t) -eSp (n, c, t) -eSp (a, c2, t) -eSp (a, c2, t) -eSp (a, c2) -eSp (S2, c2, c2) -eSp (a, c2) -eSp (a, c3, c3) -eSp (a, c3) -eSp (S2, c2, c3, t) -eSp (a, c2) -eSp (a, c2) -eSp (a, c3, t) (eSp) (a, c3, c3) -eSp (a, c3) -eSp (S2, c2, c3, c3, t) -eSp (Sp (a, c2, c2, c3, c3, t) -eSp (a, c2, c2, c2) -eSp (a, c2) -eSp (a, c2) -eSp (a, c2) -eSp (a, c2) -eSp (a, c3) -eSp (a, c2) -eSp (a, c2) -eSp (eSp (a, c2) -eSp (a, c3) -eSp (eSp (a, c2) -eSp (a, c2) -eSp (eSp (eSp) -eSp (eSp) -eSp (eSp (a, c2, c2) -eSp (eSp) -eSp (eSp (eSp) -eSp (eSp) -eSp (eSp (eSp (a, c2, c2, c2), c2, c2, c3) -eSp (eSp) -eSp (eSp (eSp (eSp) -eSp (e"}, {"heading": "5.2.1 THE THEORY AUGMENTATION ALGORITHM", "text": "It is. (It is.) It is. (It is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it is.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it.) It is. (it. (it.) It is. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It is. (it. (it.) It. (it. (it.) It is. (it. (it.) It. (it. (it.) It is. (it. (it.) It. (it. (it.) It. (it. (it.) It is. (it. (it. (it.)"}, {"heading": "5.2.2 CONSISTENCY CHECK: FINDING INCOMPATIBLE FORMULAS", "text": "This year has come to the point where we will be able to put ourselves in a different world, in which we will be able to put ourselves in a world, in which we will be able to put ourselves in a world, in which we will be able to put ourselves in a world, in which we will be able to put ourselves in a world, in which we will be able to put ourselves in a world, in which we will be able to put ourselves in a world, in which we will be able to put ourselves in a world in which we are in."}, {"heading": "5.3 Extracting The Goal From Success and Failure", "text": "Remember that applying the theory expansion process (algorithm 1) to the CTF seed theory of successful interactions (shown in Figures 5 and 6) produces a new set of formulas that capture the structure of failed activities and link it to the existing formulas of seed theory.Logically conflicting formulas I, that algorithm 2 are returns that are not satisfactory in the world with failed activities. At the same time, variants of these formulas coincide with the examples of successful actions taking place in the games. Therefore, I represent the difference between a theory that models only successful activities, and the extended theory of both successful and failed actions derived therefrom. Intuitively, the difference between success and failure can be seen as the intended purpose of a particular activity carried out by a rational agent, and consequently as the goal that the agent has in mind when we examine this specific activity in this section."}, {"heading": "6. Experiments and Results", "text": "We evaluate our approach along the three main directions outlined in Section 5 (Methodology), focusing on answering the four research questions formulated by ibidem. The structure of this section closely follows that of the Methodology section. In short, we are interested in firstly, how our Markov logic models work on the standard multi-agent activity detection task - and how their performance is compared with the alternative models. Secondly, we are interested in the extended model, which captures both successful and failed attempts at activities, which is the MS + F model induced by Algorithm 1, with which we can also extract the intended goal of the activities in question. Thirdly, we compare the performance of MS + F to the task of collectively detecting all four activities with that of an alternative model. Finally, we are interested in the extent to which the argument about failed attempts helps to evaluate the successfully performed activities.All experiments are carried out on our capture of flags, which consists of four separate games."}, {"heading": "6.1 Recognition of Successful Activities", "text": "This year, it has come to the point where it is only a matter of time before a solution is found, in which a solution is found."}, {"heading": "6.2 Learned Formulas and Intentions", "text": "In fact, the fact is that most of them are able to move, to move, and that they are able to move."}, {"heading": "6.3 Recognition of Both Successful and Failed Activities", "text": "We now compare the performance of our MS + F model with an alternative (basic) method that characterises all four activities in the following way: \"We,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" \"we,\" we, \"\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we"}, {"heading": "6.4 The Effect of Modeling Failed Attempts on Recognition of Successful Activities", "text": "To answer research question Q4 (Is modeling failed activities improving performance in detecting the activities themselves?), we want to see how much recognition of attempted activities helps in modeling successful actions (the latter being the default activation problem). To this end, we compare the Markov logic with MS, which together only characterizes successful capture and release with the MS + F model, which collectively characterizes both successful and failed attempts at capture and release (see Section 5.2.1 for a detailed description of the two models). However, in terms of precision, recall and F1 evaluation, we evaluate them only on successful interactions, not on all four types of activities. Figure 11 summarizes the results."}, {"heading": "7. Related Work", "text": "In fact, it is so that most people who are able to understand themselves and their environment are able to understand themselves and understand what they are doing. (...) In fact, it is so that people are able to understand themselves and understand themselves. (...) In fact, it is so that they are able to understand themselves. (...) In fact, it is so that they are able to understand themselves. (...) In fact, it is so that people are able to understand themselves. (...) In fact, it is so that people are able to know themselves what they are doing. (...) In fact, it is so that people are able to understand themselves. (...) In fact, it is so that people are able to understand themselves. (...) In fact, they are able to recognize themselves. (...) In fact, they are able to recognize themselves. (...) In fact, they are able to recognize themselves. (...) In fact, they are able to recognize themselves. (...) In fact, they are able to recognize themselves."}, {"heading": "8. Conclusions", "text": "We have presented a new methodology - moulded into Markov logic - for effectively combining data on denociation with overarching relational considerations over a complex multi-agent area. In particular, we have shown that raw and loud data allows us to automatically and reliably detect and detect both successful and failed interactions in adverse as well as cooperative situations. Furthermore, we have shown that success, failure and the goal of an activity are closely linked, and that with a model of successful events we can, of course, learn models of the other two important aspects of life. Specifically, we have shown that the intentions of rational agents are automatically detected in the process of resolving contradictions between a theory that models successful cases of a series of activities, but explicitly shows examples of failed attempts at these activities."}, {"heading": "9. Future Work", "text": "In this paper, we show that location information alone enables rich models of human interactions, but in the case of online social networks, we have additional access to the content of users \"posts and to both the explicit and implicit interactions of the networks. Interestingly, our current study shows that about 30% of Twitter status updates reveal the location of their authors (Sadilek, Kautz, & Bigham, 2012), which data sources are available to machines today in huge quantities and at an ever-increasing real-time streaming rate. We find that a significant fraction of posts on services such as Facebook and Twitter talk about users\" everyday activities (Naaman, Boase, & Lai, 2010)."}, {"heading": "Acknowledgments", "text": "We would like to thank anonymous critics for their constructive feedback. We would also like to thank Sebastian Riedel for his help with theBeast and Radka Sad\u0131 \u0301 lkova and Wendy Beatty for their helpful comments. This work was supported by the ARO Grant # W911NF-08-1-0242, the DARPA SBIR Contract # W31P4Q08-C-0170 and a gift from Kodak."}], "references": [{"title": "Cyberguide: a mobile context-aware tour guide", "author": ["G.D. Abowd", "C.G. Atkeson", "J. Hong", "S. Long", "R. Kooper", "M. Pinkerton"], "venue": "Wirel. Netw.,", "citeRegEx": "Abowd et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Abowd et al\\.", "year": 1997}, {"title": "Reducing multiclass to binary: A unifying approach for margin classifiers", "author": ["E. Allwein", "R. Schapire", "Y. Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Allwein et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Allwein et al\\.", "year": 2001}, {"title": "Using GPS to learn significant locations and predict movement across multiple users", "author": ["D. Ashbrook", "T. Starner"], "venue": "Personal Ubiquitous Comput.,", "citeRegEx": "Ashbrook and Starner,? \\Q2003\\E", "shortCiteRegEx": "Ashbrook and Starner", "year": 2003}, {"title": "Bayesian models of human action understanding", "author": ["C. Baker", "J. Tenenbaum", "R. Saxe"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Baker et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Baker et al\\.", "year": 2006}, {"title": "Theory-based social goal inference", "author": ["C. Baker", "N. Goodman", "J. Tenenbaum"], "venue": "In Proceedings of the thirtieth annual conference of the cognitive science society,", "citeRegEx": "Baker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Baker et al\\.", "year": 2008}, {"title": "Bayesian theory of mind: Modeling joint belief-desire attribution", "author": ["C. Baker", "R. Saxe", "J. Tenenbaum"], "venue": "In Proceedings of the Thirty-Second Annual Conference of the Cognitive Science Society", "citeRegEx": "Baker et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Baker et al\\.", "year": 2011}, {"title": "Goal inference as inverse planning", "author": ["C. Baker", "J. Tenenbaum", "R. Saxe"], "venue": "In Proceedings of the 29th annual meeting of the cognitive science society", "citeRegEx": "Baker et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Baker et al\\.", "year": 2007}, {"title": "Discerning intentions in dynamic human action", "author": ["D.A. Baldwin", "J.A. Baird"], "venue": "Trends in Cognitive Sciences,", "citeRegEx": "Baldwin and Baird,? \\Q2001\\E", "shortCiteRegEx": "Baldwin and Baird", "year": 2001}, {"title": "COOL: a language for describing coordination in multi agent systems", "author": ["M. Barbuceanu", "M. Fox"], "venue": "In Proceedings of the First International Conference on Multi-Agent Systems", "citeRegEx": "Barbuceanu and Fox,? \\Q1995\\E", "shortCiteRegEx": "Barbuceanu and Fox", "year": 1995}, {"title": "Modeling relationships at multiple scales to improve accuracy of large recommender systems", "author": ["R. Bell", "Y. Koren", "C. Volinsky"], "venue": "In KDD,", "citeRegEx": "Bell et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bell et al\\.", "year": 2007}, {"title": "Discriminative structure learning of Markov logic networks", "author": ["M. Biba", "S. Ferilli", "F. Esposito"], "venue": null, "citeRegEx": "Biba et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Biba et al\\.", "year": 2008}, {"title": "Recognizing activities with multiple cues", "author": ["R. Biswas", "S. Thrun", "K. Fujimura"], "venue": "In Workshop on Human Motion,", "citeRegEx": "Biswas et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Biswas et al\\.", "year": 2007}, {"title": "A general model for online probabilistic plan recognition", "author": ["H.H. Bui"], "venue": "Eighteenth International Joint Conference on Artificial Intelligence (IJCAI-2003).", "citeRegEx": "Bui,? 2003", "shortCiteRegEx": "Bui", "year": 2003}, {"title": "Extending multi-agent cooperation by overhearing", "author": ["P. Busetta", "L. Serafini", "D. Singh", "F. Zini"], "venue": "In Cooperative Information Systems,", "citeRegEx": "Busetta et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Busetta et al\\.", "year": 2001}, {"title": "Anomaly detection: A survey", "author": ["V. Chandola", "A. Banerjee", "V. Kumar"], "venue": "ACM Comput. Surv.,", "citeRegEx": "Chandola et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chandola et al\\.", "year": 2009}, {"title": "Joint deduplication of multiple record types in relational data", "author": ["A. Culotta", "A. McCallum"], "venue": "In Proceedings of the 14th ACM international conference on Information and knowledge management,", "citeRegEx": "Culotta and McCallum,? \\Q2005\\E", "shortCiteRegEx": "Culotta and McCallum", "year": 2005}, {"title": "Deep transfer via second-order Markov logic", "author": ["J. Davis", "P. Domingos"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Davis and Domingos,? \\Q2009\\E", "shortCiteRegEx": "Davis and Domingos", "year": 2009}, {"title": "Logical and relational learning", "author": ["L. De Raedt"], "venue": "Springer-Verlag New York Inc.", "citeRegEx": "Raedt,? 2008", "shortCiteRegEx": "Raedt", "year": 2008}, {"title": "Probabilistic Inductive Logic Programming ", "author": ["L. De Raedt", "P. Frasconi", "K. Kersting", "S. Muggleton"], "venue": "Theory and Applications,", "citeRegEx": "Raedt et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Raedt et al\\.", "year": 2008}, {"title": "Probabilistic inductive logic programming", "author": ["L. De Raedt", "K. Kersting"], "venue": "(De Raedt et al.,", "citeRegEx": "Raedt and Kersting,? \\Q2008\\E", "shortCiteRegEx": "Raedt and Kersting", "year": 2008}, {"title": "Joint determination of anaphoricity and coreference resolution using integer programming", "author": ["P. Denis", "J. Baldridge"], "venue": "In Proceedings of NAACL HLT,", "citeRegEx": "Denis and Baldridge,? \\Q2007\\E", "shortCiteRegEx": "Denis and Baldridge", "year": 2007}, {"title": "Multi-relational record linkage", "author": ["P. Domingos"], "venue": "In Proceedings of the KDD-2004 Workshop on Multi-Relational Data Mining.", "citeRegEx": "Domingos,? 2004", "shortCiteRegEx": "Domingos", "year": 2004}, {"title": "Reality mining: sensing complex social systems", "author": ["N. Eagle", "A. Pentland"], "venue": "Personal and Ubiquitous Computing,", "citeRegEx": "Eagle and Pentland,? \\Q2006\\E", "shortCiteRegEx": "Eagle and Pentland", "year": 2006}, {"title": "Eigenbehaviors: Identifying structure in routine", "author": ["N. Eagle", "A. Pentland"], "venue": "Behavioral Ecology and Sociobiology,", "citeRegEx": "Eagle and Pentland,? \\Q2009\\E", "shortCiteRegEx": "Eagle and Pentland", "year": 2009}, {"title": "Inferring social network structure using mobile phone data", "author": ["N. Eagle", "A. Pentland", "D. Lazer"], "venue": "In Proceedings of the National Academy of Sciences", "citeRegEx": "Eagle et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Eagle et al\\.", "year": 2009}, {"title": "Learning probabilistic relational models", "author": ["N. Friedman", "L. Getoor", "D. Koller", "A. Pfeffer"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "Friedman et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 1999}, {"title": "A probabilistic interpretation of precision, recall and f-score, with implication for evaluation", "author": ["C. Goutte", "E. Gaussier"], "venue": null, "citeRegEx": "Goutte and Gaussier,? \\Q2005\\E", "shortCiteRegEx": "Goutte and Gaussier", "year": 2005}, {"title": "Understanding videos, constructing plots: Learning a visually grounded storyline model from annotated videos", "author": ["A. Gupta", "P. Srinivasan", "J. Shi", "L.S. Davis"], "venue": null, "citeRegEx": "Gupta et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gupta et al\\.", "year": 2009}, {"title": "TildeCRF: conditional random fields for logical sequences", "author": ["B. Gutmann", "K. Kersting"], "venue": "In Machine Learning: ECML", "citeRegEx": "Gutmann and Kersting,? \\Q2006\\E", "shortCiteRegEx": "Gutmann and Kersting", "year": 2006}, {"title": "A statistical-relational activity recognition framework for ambient assisted living systems", "author": ["R. Helaoui", "M. Niepert", "H. Stuckenschmidt"], "venue": "In Ambient Intelligence and Future TrendsInternational Symposium on Ambient Intelligence (ISAmI", "citeRegEx": "Helaoui et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Helaoui et al\\.", "year": 2010}, {"title": "Goal recognition through goal graph analysis", "author": ["J. Hong"], "venue": "Journal of Artificial Intelligence Research, 15, 1\u201330.", "citeRegEx": "Hong,? 2001", "shortCiteRegEx": "Hong", "year": 2001}, {"title": "Prediction, expectation, and surprise: Methods, designs, and study of a deployed traffic forecasting service", "author": ["E. Horvitz", "J. Apacible", "R. Sarin", "L. Liao"], "venue": "In Twenty-First Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Horvitz et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Horvitz et al\\.", "year": 2005}, {"title": "Real world activity recognition with multiple goals", "author": ["D. Hu", "S. Pan", "V. Zheng", "N. Liu", "Q. Yang"], "venue": "In UbiComp,", "citeRegEx": "Hu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2008}, {"title": "Discriminative structure and parameter learning for Markov logic networks", "author": ["T. Huynh", "R. Mooney"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Huynh and Mooney,? \\Q2008\\E", "shortCiteRegEx": "Huynh and Mooney", "year": 2008}, {"title": "Relational Bayesian networks", "author": ["M. Jaeger"], "venue": "Proceedings of the 13th Conference on Uncertainty in Artificial Intelligence, pp. 266\u2013273.", "citeRegEx": "Jaeger,? 1997", "shortCiteRegEx": "Jaeger", "year": 1997}, {"title": "Learning in graphical models", "author": ["M. Jordan"], "venue": "Kluwer Academic Publishers.", "citeRegEx": "Jordan,? 1998", "shortCiteRegEx": "Jordan", "year": 1998}, {"title": "Collaboration and shared plans in the open world: Studies of ridesharing", "author": ["E. Kamar", "E. Horvitz"], "venue": null, "citeRegEx": "Kamar and Horvitz,? \\Q2009\\E", "shortCiteRegEx": "Kamar and Horvitz", "year": 2009}, {"title": "Monitoring teams by overhearing: A multi-agent plan-recognition approach", "author": ["G.A. Kaminka", "Tambe", "D.V.P. M", "D.V. Pynadath", "M. Tambe"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Kaminka et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kaminka et al\\.", "year": 2002}, {"title": "Bayesian logic programs", "author": ["K. Kersting", "L. De Raedt"], "venue": "In Proceedings of the Work-inProgress Track at the 10th International Conference on Inductive Logic Programming", "citeRegEx": "Kersting and Raedt,? \\Q2000\\E", "shortCiteRegEx": "Kersting and Raedt", "year": 2000}, {"title": "Logical hidden Markov models", "author": ["K. Kersting", "L. De Raedt", "T. Raiko"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Kersting et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kersting et al\\.", "year": 2006}, {"title": "Learning the structure of Markov logic networks", "author": ["S. Kok", "P. Domingos"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Kok and Domingos,? \\Q2005\\E", "shortCiteRegEx": "Kok and Domingos", "year": 2005}, {"title": "Statistical predicate invention", "author": ["S. Kok", "P. Domingos"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "Kok and Domingos,? \\Q2007\\E", "shortCiteRegEx": "Kok and Domingos", "year": 2007}, {"title": "Learning Markov logic network structure via hypergraph lifting", "author": ["S. Kok", "P. Domingos"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Kok and Domingos,? \\Q2009\\E", "shortCiteRegEx": "Kok and Domingos", "year": 2009}, {"title": "Statistical predicate invention", "author": ["S. Kok", "P. Domingos"], "venue": "Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "Kok and Domingos,? \\Q2007\\E", "shortCiteRegEx": "Kok and Domingos", "year": 2007}, {"title": "Probabilistic relational models", "author": ["D. Koller"], "venue": "Inductive Logic Programming, pp. 3\u201313. Springer.", "citeRegEx": "Koller,? 1999", "shortCiteRegEx": "Koller", "year": 1999}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty"], "venue": "International Conference on Machine Learning (ICML), pp. 282\u2013289. Morgan Kaufmann.", "citeRegEx": "Lafferty,? 2001", "shortCiteRegEx": "Lafferty", "year": 2001}, {"title": "Relational transformation-based tagging for human activity recognition", "author": ["N. Landwehr", "B. Gutmann", "I. Thon", "M. Philipose", "L. De Raedt"], "venue": "In Proceedings of the 6th International Workshop on Multi-relational Data Mining (MRDM07),", "citeRegEx": "Landwehr et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Landwehr et al\\.", "year": 2007}, {"title": "Learning and inferring transportation routines", "author": ["L. Liao", "D. Patterson", "D. Fox", "H. Kautz"], "venue": "Artificial Intelligence,", "citeRegEx": "Liao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Liao et al\\.", "year": 2007}, {"title": "Learning and inferring transportation routines", "author": ["L. Liao", "D. Fox", "H. Kautz"], "venue": "In Proceedings of the Nineteenth National Conference on Artificial Intelligence", "citeRegEx": "Liao et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Liao et al\\.", "year": 2004}, {"title": "Location-based activity recognition using relational Markov networks", "author": ["L. Liao", "D. Fox", "H. Kautz"], "venue": null, "citeRegEx": "Liao et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Liao et al\\.", "year": 2005}, {"title": "CRF-filters: Discriminative particle filters for sequential state estimation", "author": ["B. Limketkai", "D. Fox", "L. Liao"], "venue": "In Robotics and Automation,", "citeRegEx": "Limketkai et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Limketkai et al\\.", "year": 2007}, {"title": "Temporal information extraction", "author": ["X. Ling", "D. Weld"], "venue": "In Proceedings of the Twenty Fifth National Conference on Artificial Intelligence", "citeRegEx": "Ling and Weld,? \\Q2010\\E", "shortCiteRegEx": "Ling and Weld", "year": 2010}, {"title": "Modelling with PRISM of intelligent system", "author": ["Z. Ma"], "venue": "MSc. Thesis, Linacre College, University of Oxford.", "citeRegEx": "Ma,? 2008", "shortCiteRegEx": "Ma", "year": 2008}, {"title": "Modeling and inference with relational dynamic Bayesian networks", "author": ["C. Manfredotti"], "venue": "Advances in Artificial Intelligence, pp. 287\u2013290. Springer.", "citeRegEx": "Manfredotti,? 2009", "shortCiteRegEx": "Manfredotti", "year": 2009}, {"title": "Relational dynamic Bayesian networks to improve multitarget tracking", "author": ["C. Manfredotti", "E. Messina"], "venue": "In Advanced Concepts for Intelligent Vision Systems,", "citeRegEx": "Manfredotti and Messina,? \\Q2009\\E", "shortCiteRegEx": "Manfredotti and Messina", "year": 2009}, {"title": "Learning RDBNs for activity recognition", "author": ["C. Manfredotti", "H. Hamilton", "S. Zilles"], "venue": "In Neural Information Processing Systems", "citeRegEx": "Manfredotti et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Manfredotti et al\\.", "year": 2010}, {"title": "Bottom-up learning of Markov logic network structure", "author": ["L. Mihalkova", "R. Mooney"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "Mihalkova and Mooney,? \\Q2007\\E", "shortCiteRegEx": "Mihalkova and Mooney", "year": 2007}, {"title": "Recognizing multitasked activities using stochastic context-free grammar", "author": ["D. Moore", "I. Essa"], "venue": "Proceedings of AAAI Conference", "citeRegEx": "Moore and Essa,? \\Q2001\\E", "shortCiteRegEx": "Moore and Essa", "year": 2001}, {"title": "Learning structure and parameters of stochastic logic programs", "author": ["S. Muggleton"], "venue": "Proceedings of the 12th international conference on Inductive logic programming, pp. 198\u2013206. Springer-Verlag.", "citeRegEx": "Muggleton,? 2002", "shortCiteRegEx": "Muggleton", "year": 2002}, {"title": "Dynamic bayesian networks: representation, inference and learning", "author": ["K.P. Murphy"], "venue": "Ph.D. thesis, University of California, Berkeley.", "citeRegEx": "Murphy,? 2002", "shortCiteRegEx": "Murphy", "year": 2002}, {"title": "Is it really about me?: message content in social awareness streams", "author": ["M. Naaman", "J. Boase", "Lai", "C.-H"], "venue": "In CSCW \u201910: Proceedings of the 2010 ACM conference on Computer supported cooperative work,", "citeRegEx": "Naaman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Naaman et al\\.", "year": 2010}, {"title": "Learning first-order probabilistic models with combining rules", "author": ["S. Natarajan", "P. Tadepalli", "E. Altendorf", "T. Dietterich", "A. Fern", "A. Restificar"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Natarajan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Natarajan et al\\.", "year": 2005}, {"title": "Logical hierarchical hidden Markov models for modeling user activities", "author": ["S. Natarajan", "H.H. Bui", "P. Tadepalli", "K. Kersting", "W. Wong"], "venue": "Proc. of ILP-08", "citeRegEx": "Natarajan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Natarajan et al\\.", "year": 2008}, {"title": "Constraint propagation for efficient inference in Markov logic", "author": ["T. Papai", "P. Singla", "H. Kautz"], "venue": "In Seventeenth International Conference on Principles and Practice of Constraint Programming", "citeRegEx": "Papai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Papai et al\\.", "year": 2011}, {"title": "Honest Signals: How They Shape Our World", "author": ["A.S. Pentland"], "venue": "The MIT Press.", "citeRegEx": "Pentland,? 2008", "shortCiteRegEx": "Pentland", "year": 2008}, {"title": "Sound and efficient inference with probabilistic and deterministic dependencies", "author": ["H. Poon", "P. Domingos"], "venue": "In Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "Poon and Domingos,? \\Q2006\\E", "shortCiteRegEx": "Poon and Domingos", "year": 2006}, {"title": "Joint inference in information extraction", "author": ["H. Poon", "P. Domingos"], "venue": "In Proceedings of the 22nd national conference on Artificial intelligence-Volume", "citeRegEx": "Poon and Domingos,? \\Q2007\\E", "shortCiteRegEx": "Poon and Domingos", "year": 2007}, {"title": "Joint unsupervised coreference resolution with Markov logic", "author": ["H. Poon", "P. Domingos"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Poon and Domingos,? \\Q2008\\E", "shortCiteRegEx": "Poon and Domingos", "year": 2008}, {"title": "Improving the accuracy and efficiency of map inference for Markov logic", "author": ["S. Riedel"], "venue": "Proceedings of the Proceedings of the Twenty-Fourth Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-08), pp. 468\u2013475, Corvallis, Oregon. AUAI Press.", "citeRegEx": "Riedel,? 2008", "shortCiteRegEx": "Riedel", "year": 2008}, {"title": "Modeling and reasoning about success, failure, and intent of multi-agent activities", "author": ["A. Sadilek", "H. Kautz"], "venue": "In Mobile Context-Awareness Workshop, Twelfth ACM International Conference on Ubiquitous Computing", "citeRegEx": "Sadilek and Kautz,? \\Q2010\\E", "shortCiteRegEx": "Sadilek and Kautz", "year": 2010}, {"title": "Recognizing multi-agent activities from GPS data", "author": ["A. Sadilek", "H. Kautz"], "venue": "In TwentyFourth AAAI Conference on Artificial Intelligence", "citeRegEx": "Sadilek and Kautz,? \\Q2010\\E", "shortCiteRegEx": "Sadilek and Kautz", "year": 2010}, {"title": "Finding your friends and following them to where you are", "author": ["A. Sadilek", "H. Kautz", "J.P. Bigham"], "venue": "In Fifth ACM International Conference on Web Search and Data Mining (WSDM)", "citeRegEx": "Sadilek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sadilek et al\\.", "year": 2012}, {"title": "Parameter learning of logic programs for symbolic-statistical modeling", "author": ["T. Sato", "Y. Kameya"], "venue": "In Journal of Artificial Intelligence Research", "citeRegEx": "Sato and Kameya,? \\Q2001\\E", "shortCiteRegEx": "Sato and Kameya", "year": 2001}, {"title": "New advances in logic-based probabilistic modeling by PRISM", "author": ["T. Sato", "Y. Kameya"], "venue": "In Probabilistic inductive logic programming,", "citeRegEx": "Sato and Kameya,? \\Q2008\\E", "shortCiteRegEx": "Sato and Kameya", "year": 2008}, {"title": "SCARE: A Case Study with Baghdad", "author": ["P. Shakarian", "V. Subrahmanian", "M.L. Spaino"], "venue": "In Proceedings of the Third International Conference on Computational Cultural Dynamics. AAAI", "citeRegEx": "Shakarian et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shakarian et al\\.", "year": 2009}, {"title": "Activity recognition in desktop environments", "author": ["J. Shen"], "venue": "Ph.D. Thesis, Oregon State University.", "citeRegEx": "Shen,? 2009", "shortCiteRegEx": "Shen", "year": 2009}, {"title": "Mathematical Logic", "author": ["J.R. Shoenfield"], "venue": "Addison-Wesley.", "citeRegEx": "Shoenfield,? 1967", "shortCiteRegEx": "Shoenfield", "year": 1967}, {"title": "Discriminative training of Markov logic networks", "author": ["P. Singla", "P. Domingos"], "venue": "In Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "Singla and Domingos,? \\Q2005\\E", "shortCiteRegEx": "Singla and Domingos", "year": 2005}, {"title": "Markov logic in infinite domains. In UAI-07", "author": ["P. Singla", "P. Domingos"], "venue": null, "citeRegEx": "Singla and Domingos,? \\Q2007\\E", "shortCiteRegEx": "Singla and Domingos", "year": 2007}, {"title": "Rethinking location sharing: exploring the implications of social-driven vs. purpose-driven location sharing", "author": ["K. Tang", "J. Lin", "J. Hong", "D. Siewiorek", "N. Sadeh"], "venue": "In Proceedings of the 12th ACM international conference on Ubiquitous computing,", "citeRegEx": "Tang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2010}, {"title": "Visual event modeling and recognition using Markov logic networks", "author": ["S. Tran", "L. Davis"], "venue": "In Proceedings of the 10th European Conference on Computer Vision", "citeRegEx": "Tran and Davis,? \\Q2008\\E", "shortCiteRegEx": "Tran and Davis", "year": 2008}, {"title": "Help or hinder: Bayesian models of social goal inference", "author": ["T. Ullman", "C. Baker", "O. Macindoe", "O. Evans", "N. Goodman", "J. Tenenbaum"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Ullman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ullman et al\\.", "year": 2010}, {"title": "Conditional random fields for activity recognition", "author": ["D. Vail"], "venue": "Ph.D. Thesis, Carnegie Mellon University.", "citeRegEx": "Vail,? 2008", "shortCiteRegEx": "Vail", "year": 2008}, {"title": "Feature selection for activity recognition in multi-robot domains", "author": ["D. Vail", "M. Veloso"], "venue": "In Proceedings of AAAI,", "citeRegEx": "Vail and Veloso,? \\Q2008\\E", "shortCiteRegEx": "Vail and Veloso", "year": 2008}, {"title": "Hybrid Markov logic networks", "author": ["J. Wang", "P. Domingos"], "venue": "In Proceedings of the 23rd national conference on Artificial intelligence - Volume", "citeRegEx": "Wang and Domingos,? \\Q2008\\E", "shortCiteRegEx": "Wang and Domingos", "year": 2008}, {"title": "An integrated, conditional model of information extraction and coreference with application to citation matching", "author": ["B. Wellner", "A. McCallum", "F. Peng", "M. Hay"], "venue": "In Proceedings of the 20th conference on Uncertainty in artificial intelligence,", "citeRegEx": "Wellner et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Wellner et al\\.", "year": 2004}, {"title": "Learning and transferring roles in multi-agent mdps", "author": ["A. Wilson", "A. Fern", "S. Ray", "P. Tadepalli"], "venue": "In Proceedings of AAAI", "citeRegEx": "Wilson et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wilson et al\\.", "year": 2008}, {"title": "Bayesian role discovery for multi-agent reinforcement learning", "author": ["A. Wilson", "A. Fern", "P. Tadepalli"], "venue": "In Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1-Volume", "citeRegEx": "Wilson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wilson et al\\.", "year": 2010}, {"title": "First order theory refinement", "author": ["S. Wrobel"], "venue": "Advances in inductive logic programming, pp. 14\u201333. IOS Press, Amsterdam.", "citeRegEx": "Wrobel,? 1996", "shortCiteRegEx": "Wrobel", "year": 1996}, {"title": "Joint recognition of multiple concurrent activities using factorial conditional random fields", "author": ["T. Wu", "C. Lian", "J. Hsu"], "venue": "In Proc. 22nd Conf. on Artificial Intelligence (AAAI-2007)", "citeRegEx": "Wu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2007}, {"title": "Jointly identifying temporal relations with Markov logic", "author": ["K. Yoshikawa", "S. Riedel", "M. Asahara", "Y. Matsumoto"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume", "citeRegEx": "Yoshikawa et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yoshikawa et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 64, "context": "For instance, behavioral patterns of people taking taxis, rating movies, choosing a cell phone provider, or sharing music are best explained and predicted by the habits of related people, rather than by all the \u201csingle person\u201d attributes such as age, race, or education (Bell, Koren, & Volinsky, 2007; Pentland, 2008).", "startOffset": 270, "endOffset": 317}, {"referenceID": 12, "context": "In contrast to these observations, most research effort on activity recognition to date has concentrated on modeling single individuals (Bui, 2003; Liao, Fox, & Kautz, 2004, 2005), or statistical properties of aggregate groups of individuals (Abowd, Atkeson, Hong, Long, Kooper, & Pinkerton, 1997; Horvitz, Apacible, Sarin, & Liao, 2005), or combinations of both (Eagle & Pentland, 2006).", "startOffset": 136, "endOffset": 179}, {"referenceID": 33, "context": "Notable exceptions to this \u201cisolated individuals\u201d approach includes the work of Kamar and Horvitz (2009) and Gupta, Srinivasan, Shi, and Davis (2009), where simple relationships among people are just starting to be explicitly considered and leveraged.", "startOffset": 80, "endOffset": 105}, {"referenceID": 33, "context": "Notable exceptions to this \u201cisolated individuals\u201d approach includes the work of Kamar and Horvitz (2009) and Gupta, Srinivasan, Shi, and Davis (2009), where simple relationships among people are just starting to be explicitly considered and leveraged.", "startOffset": 80, "endOffset": 150}, {"referenceID": 21, "context": "For instance, Eagle and Pentland (2006) elegantly model the location of individuals from multi-modal sensory data, but their approach is oblivious to the explicit effects of one\u2019s friends, relatives, etc.", "startOffset": 14, "endOffset": 40}, {"referenceID": 72, "context": "ML, and inductive logic programming see the work of Shoenfield (1967), Domingos, Kok, Lowd, Poon, Richardson, and Singla (2008), and De Raedt and Kersting (2008), respectively.", "startOffset": 52, "endOffset": 70}, {"referenceID": 19, "context": "ML, and inductive logic programming see the work of Shoenfield (1967), Domingos, Kok, Lowd, Poon, Richardson, and Singla (2008), and De Raedt and Kersting (2008), respectively.", "startOffset": 71, "endOffset": 128}, {"referenceID": 17, "context": "ML, and inductive logic programming see the work of Shoenfield (1967), Domingos, Kok, Lowd, Poon, Richardson, and Singla (2008), and De Raedt and Kersting (2008), respectively.", "startOffset": 136, "endOffset": 162}, {"referenceID": 68, "context": "Even though this problem is in general #P-complete, we achieve reasonable run times by applying Cutting Plane MAP Inference (CPI) (Riedel, 2008).", "startOffset": 130, "endOffset": 144}, {"referenceID": 35, "context": "A Bayesian network (BN) is a directed probabilistic graphical model (Jordan, 1998).", "startOffset": 68, "endOffset": 82}, {"referenceID": 58, "context": "For an extensive treatment of DBNs, see the work of Murphy (2002). There are a number of parameter learning and inference techniques for DBNs.", "startOffset": 52, "endOffset": 66}, {"referenceID": 35, "context": "We calculate the Viterbi decoding efficiently using dynamic programming (Jordan, 1998).", "startOffset": 72, "endOffset": 86}, {"referenceID": 11, "context": "In the world of single-agent location-based reasoning, the work of Bui (2003) presents and evaluates a system for probabilistic plan recognition cast as an abstract hidden Markov memory model.", "startOffset": 67, "endOffset": 78}, {"referenceID": 11, "context": "In the world of single-agent location-based reasoning, the work of Bui (2003) presents and evaluates a system for probabilistic plan recognition cast as an abstract hidden Markov memory model. Subsequently, the work of Liao et al. (2004) implements a system for denoising raw GPS traces and simultaneously inferring individuals\u2019 mode of transportation (car, bus, etc.", "startOffset": 67, "endOffset": 238}, {"referenceID": 11, "context": "In the world of single-agent location-based reasoning, the work of Bui (2003) presents and evaluates a system for probabilistic plan recognition cast as an abstract hidden Markov memory model. Subsequently, the work of Liao et al. (2004) implements a system for denoising raw GPS traces and simultaneously inferring individuals\u2019 mode of transportation (car, bus, etc.) and their goal destination. They cast the problem as learning and inference in a dynamic Bayesian network and achieve encouraging results. In a follow-up work, Liao et al. (2005) introduce a framework for locationbased activity recognition, which is implemented as efficient learning and inference in a relational Markov network.", "startOffset": 67, "endOffset": 548}, {"referenceID": 2, "context": "The work of Ashbrook and Starner (2003) focuses on inferring significant locations from raw GPS logs via clustering.", "startOffset": 12, "endOffset": 40}, {"referenceID": 2, "context": "The work of Ashbrook and Starner (2003) focuses on inferring significant locations from raw GPS logs via clustering. The transition probabilities between important places are subsequently used for a number of user modeling tasks, including location prediction. The work of Eagle and Pentland (2006) explores harnessing data collected on regular smart phones for modeling human behavior.", "startOffset": 12, "endOffset": 299}, {"referenceID": 2, "context": "The work of Ashbrook and Starner (2003) focuses on inferring significant locations from raw GPS logs via clustering. The transition probabilities between important places are subsequently used for a number of user modeling tasks, including location prediction. The work of Eagle and Pentland (2006) explores harnessing data collected on regular smart phones for modeling human behavior. Specifically, they infer individuals\u2019 general location from nearby cell towers and Bluetooth devices at various times of day. Applying a hidden Markov model (HMM), they show that predicting if a person is at home, at work, or someplace else can be achieved with more than 90% accuracy. Similarly, the work of Eagle and Pentland (2009) extracts significant patterns and signatures in people\u2019s movement by applying eigenanalysis to smart phone logs.", "startOffset": 12, "endOffset": 722}, {"referenceID": 2, "context": "The work of Ashbrook and Starner (2003) focuses on inferring significant locations from raw GPS logs via clustering. The transition probabilities between important places are subsequently used for a number of user modeling tasks, including location prediction. The work of Eagle and Pentland (2006) explores harnessing data collected on regular smart phones for modeling human behavior. Specifically, they infer individuals\u2019 general location from nearby cell towers and Bluetooth devices at various times of day. Applying a hidden Markov model (HMM), they show that predicting if a person is at home, at work, or someplace else can be achieved with more than 90% accuracy. Similarly, the work of Eagle and Pentland (2009) extracts significant patterns and signatures in people\u2019s movement by applying eigenanalysis to smart phone logs. The work of Hu, Pan, Zheng, Liu, and Yang (2008) concentrates on recognition of interleaving and overlapping activities.", "startOffset": 12, "endOffset": 884}, {"referenceID": 64, "context": ", being at a store often implies shopping) (Tang, Lin, Hong, Siewiorek, & Sadeh, 2010), and our social networks have tremendous influence on our behavior (Pentland, 2008).", "startOffset": 154, "endOffset": 170}, {"referenceID": 27, "context": "Additionally, a number of researchers in machine vision have worked on the problem of recognizing events in videos of sporting events, such as impressive recent work on learning models of baseball plays (Gupta et al., 2009).", "startOffset": 203, "endOffset": 223}, {"referenceID": 31, "context": "Other researchers explore an intelligent and nonintrusive navigation system that takes advantage of predictions of traffic conditions along with a model of user\u2019s knowledge and competence (Horvitz et al., 2005).", "startOffset": 188, "endOffset": 210}, {"referenceID": 0, "context": "Additionally, the work of Abowd et al. (1997) presents a location- and context-aware system, Cyberguide, that helps people explore and fully experience foreign locations.", "startOffset": 26, "endOffset": 46}, {"referenceID": 0, "context": "Additionally, the work of Abowd et al. (1997) presents a location- and context-aware system, Cyberguide, that helps people explore and fully experience foreign locations. Other researchers explore an intelligent and nonintrusive navigation system that takes advantage of predictions of traffic conditions along with a model of user\u2019s knowledge and competence (Horvitz et al., 2005). Finally, the work of Kamar and Horvitz (2009) explore automatic generation of synergistic plans regarding sharing vehicles across multiple commuters.", "startOffset": 26, "endOffset": 429}, {"referenceID": 0, "context": "Additionally, the work of Abowd et al. (1997) presents a location- and context-aware system, Cyberguide, that helps people explore and fully experience foreign locations. Other researchers explore an intelligent and nonintrusive navigation system that takes advantage of predictions of traffic conditions along with a model of user\u2019s knowledge and competence (Horvitz et al., 2005). Finally, the work of Kamar and Horvitz (2009) explore automatic generation of synergistic plans regarding sharing vehicles across multiple commuters. An interesting line of work in cognitive science focuses on intent and goal recognition in a probabilistic framework (Baker, Tenenbaum, & Saxe, 2006, 2007). Specifically, they cast goal inference as inverse planning problem in Markov decision processes, where Bayesian inversion is used to estimate the posterior distribution over possible goals. Recent extensions of this work begin to consider simulated multi-agent domains (Baker, Goodman, & Tenenbaum, 2008; Ullman, Baker, Macindoe, Evans, Goodman, & Tenenbaum, 2010; Baker, Saxe, & Tenenbaum, 2011). Comparison of the computational models against human judgement in synthetic domains shows a strong correlation between people\u2019s predicted and actual behavior. However, the computational challenges involved in dealing with the underlying partially observable Markov decision processes are prohibitive in more complex domains with large state spaces, such as ours. The focus of our work is on a different aspect of reasoning about people\u2019s goals. Rather than inferring a distribution over possible, a priori known goals, we automatically induce the goals of complex multi-agent activities themselves. Other researchers have concentrated on modeling behavior of people and general agents as reinforcement learning problems in both single-agent and multi-agent settings. The work of Ma (2008) proposes a system for household activity recognition cast as a single-agent Markov decision process problem that is subsequently solved using a probabilistic model checker.", "startOffset": 26, "endOffset": 1877}, {"referenceID": 21, "context": ", text segmentation coupled with entity resolution) (Poon & Domingos, 2007), co-reference resolution (Poon & Domingos, 2008), information extraction coupled with co-reference resolution (Wellner, McCallum, Peng, & Hay, 2004), temporal relation identification (Yoshikawa, Riedel, Asahara, & Matsumoto, 2009; Ling & Weld, 2010), and record de-duplication (Domingos, 2004; Culotta & McCallum, 2005).", "startOffset": 353, "endOffset": 395}, {"referenceID": 29, "context": "The work of Hong (2001) concentrates on recognizing the goal of an agent in the course of her activities in a deterministic, but relational setting.", "startOffset": 12, "endOffset": 24}, {"referenceID": 29, "context": "The work of Hong (2001) concentrates on recognizing the goal of an agent in the course of her activities in a deterministic, but relational setting. Interesting work on goal recognition has been also applied to computer-aided monitoring of complex multi-agent systems, where relationships between agents are leveraged to compensate for noise and sparse data (Kaminka, Tambe, Pynadath, & Tambe, 2002). By contrast, in our work we focus on learning the respective goals of a given set of multi-agent activities in a probabilistic setting. The knowledge is in turn leveraged to achieve a stronger robustness of the other recognition tasks. Similarly to the approach of Hong, our system does not need a supplied plan library either. Our work also touches on anomaly detection since our system reasons about the failed attempts of the players. Anomaly detection concerns itself with revealing segments of the data that in some way violate our expectations. For an excellent survey of the subject, we refer the reader to the results of Chandola, Banerjee, and Kumar (2009). In the realm of anomaly detection within people\u2019s activities, the work of Moore and Essa (2001) addresses the problem of error detection and recovery card games that involve two players recorded on video.", "startOffset": 12, "endOffset": 1067}, {"referenceID": 29, "context": "The work of Hong (2001) concentrates on recognizing the goal of an agent in the course of her activities in a deterministic, but relational setting. Interesting work on goal recognition has been also applied to computer-aided monitoring of complex multi-agent systems, where relationships between agents are leveraged to compensate for noise and sparse data (Kaminka, Tambe, Pynadath, & Tambe, 2002). By contrast, in our work we focus on learning the respective goals of a given set of multi-agent activities in a probabilistic setting. The knowledge is in turn leveraged to achieve a stronger robustness of the other recognition tasks. Similarly to the approach of Hong, our system does not need a supplied plan library either. Our work also touches on anomaly detection since our system reasons about the failed attempts of the players. Anomaly detection concerns itself with revealing segments of the data that in some way violate our expectations. For an excellent survey of the subject, we refer the reader to the results of Chandola, Banerjee, and Kumar (2009). In the realm of anomaly detection within people\u2019s activities, the work of Moore and Essa (2001) addresses the problem of error detection and recovery card games that involve two players recorded on video.", "startOffset": 12, "endOffset": 1164}, {"referenceID": 45, "context": "Our Markov logic theory can be viewed as a template for a conditional random field (Lafferty, 2001), an undirected graphical model that captures the conditional probability of hidden labels given observations, rather than the joint probability of both labels and observations, as one would typically do in a directed graphical model.", "startOffset": 83, "endOffset": 99}, {"referenceID": 34, "context": "In the relational world, directed formalisms include relational Bayesian networks (Jaeger, 1997) and their dynamic counterparts (Manfredotti, 2009), probabilistic relational models (Koller, 1999; Friedman, Getoor, Koller, & Pfeffer, 1999), Bayesian logic programs (Kersting & De Raedt, 2000), and first-order conditional influence language (Natarajan, Tadepalli, Altendorf, Dietterich, Fern, & Restificar, 2005).", "startOffset": 82, "endOffset": 96}, {"referenceID": 53, "context": "In the relational world, directed formalisms include relational Bayesian networks (Jaeger, 1997) and their dynamic counterparts (Manfredotti, 2009), probabilistic relational models (Koller, 1999; Friedman, Getoor, Koller, & Pfeffer, 1999), Bayesian logic programs (Kersting & De Raedt, 2000), and first-order conditional influence language (Natarajan, Tadepalli, Altendorf, Dietterich, Fern, & Restificar, 2005).", "startOffset": 128, "endOffset": 147}, {"referenceID": 44, "context": "In the relational world, directed formalisms include relational Bayesian networks (Jaeger, 1997) and their dynamic counterparts (Manfredotti, 2009), probabilistic relational models (Koller, 1999; Friedman, Getoor, Koller, & Pfeffer, 1999), Bayesian logic programs (Kersting & De Raedt, 2000), and first-order conditional influence language (Natarajan, Tadepalli, Altendorf, Dietterich, Fern, & Restificar, 2005).", "startOffset": 181, "endOffset": 238}, {"referenceID": 18, "context": "Interestingly, the work in Denis and Baldridge (2007) jointly addresses the problems of anaphoricity and co-reference via a manual formulation of an integer linear program.", "startOffset": 27, "endOffset": 54}, {"referenceID": 18, "context": "Interestingly, the work in Denis and Baldridge (2007) jointly addresses the problems of anaphoricity and co-reference via a manual formulation of an integer linear program. Joint activity modeling has also been shown to yield better recognition accuracy, as compared to \u201cpipeline\u201d baselines as well as baselines that make strong inter-activity independence assumptions. The work of Wu, Lian, and Hsu (2007) performs joint learning and inference over concurrent singleagent activities using a factorial conditional random field model.", "startOffset": 27, "endOffset": 407}, {"referenceID": 18, "context": "Interestingly, the work in Denis and Baldridge (2007) jointly addresses the problems of anaphoricity and co-reference via a manual formulation of an integer linear program. Joint activity modeling has also been shown to yield better recognition accuracy, as compared to \u201cpipeline\u201d baselines as well as baselines that make strong inter-activity independence assumptions. The work of Wu, Lian, and Hsu (2007) performs joint learning and inference over concurrent singleagent activities using a factorial conditional random field model. Similarly, the work of Helaoui, Niepert, and Stuckenschmidt (2010) models interleaved activities in Markov logic.", "startOffset": 27, "endOffset": 601}, {"referenceID": 18, "context": "Interestingly, the work in Denis and Baldridge (2007) jointly addresses the problems of anaphoricity and co-reference via a manual formulation of an integer linear program. Joint activity modeling has also been shown to yield better recognition accuracy, as compared to \u201cpipeline\u201d baselines as well as baselines that make strong inter-activity independence assumptions. The work of Wu, Lian, and Hsu (2007) performs joint learning and inference over concurrent singleagent activities using a factorial conditional random field model. Similarly, the work of Helaoui, Niepert, and Stuckenschmidt (2010) models interleaved activities in Markov logic. They distinguish between foreground and background activities and infer a time window in which each activity takes place from RFID sensory data. By contrast, we focus on joint reasoning about multi-agent activities and attempts in a fully relational\u2014and arguably significantly more noisy\u2014setting. The work of Manfredotti, Hamilton, and Zilles (2010) propose a hierarchical activity recognition system formulated as learning and inference in relational dynamic Bayesian networks.", "startOffset": 27, "endOffset": 998}, {"referenceID": 16, "context": "The work of Landwehr, Gutmann, Thon, Philipose, and De Raedt (2007) casts single-agent activity recognition as a relational transformation learning problem, building on transformationbased tagging from natural language processing.", "startOffset": 55, "endOffset": 68}, {"referenceID": 16, "context": "Logical hidden Markov models (LHMMs) have been proposed to address this problem (Kersting, De Raedt, & Raiko, 2006). LHMMs are a generalization of standard HMMs that compactly represents probability distributions over sequences of logical atoms rather than flat symbols. LHMMs have been proven strictly more powerful than their propositional counterparts (HMMs). By applying techniques from logic-based reasoning, such as unification, while leveraging the logical structure component of the model, Kersting et al. show that LHMMs often require fewer parameters and achieve higher accuracy than HMMs. LHMMs have been recently applied to activity recognition. In the context of intelligent user interfaces, the work of Shen (2009) designs and evaluates a LHMM model for recognition of people\u2019s activities and workflows carried out on a desktop computer.", "startOffset": 94, "endOffset": 729}, {"referenceID": 88, "context": "In fact, our theory augmentation algorithm can be viewed as an efficient Markov logic based version of theory refinement, a well-established ILP technique that aims to improve the quality of a theory in terms of simplicity, fit to newly acquired data, efficiency or other factors (Wrobel, 1996).", "startOffset": 280, "endOffset": 294}, {"referenceID": 19, "context": "This includes early work on top-down structure learning, where clauses in the knowledge base are greedily modified by adding, flipping, and deleting logical literals (Kok & Domingos, 2005). This search is guided by the likelihood of the training data under the current model. The work of Mihalkova and Mooney (2007) exploit patterns in the ground Markov logic networks to introduce a bottom-up declarative bias that makes their algorithm less susceptible to finding only local optima, as compared to alternative greedy methods.", "startOffset": 173, "endOffset": 316}, {"referenceID": 19, "context": "This includes early work on top-down structure learning, where clauses in the knowledge base are greedily modified by adding, flipping, and deleting logical literals (Kok & Domingos, 2005). This search is guided by the likelihood of the training data under the current model. The work of Mihalkova and Mooney (2007) exploit patterns in the ground Markov logic networks to introduce a bottom-up declarative bias that makes their algorithm less susceptible to finding only local optima, as compared to alternative greedy methods. Similarly, the work of Kok and Domingos (2009) introduce a bottom-up declarative bias based on lifted hypergraph representation of the relational database.", "startOffset": 173, "endOffset": 575}, {"referenceID": 16, "context": "The work of Davis and Domingos (2009) successfully uses second-order Markov logic in deep transfer learning.", "startOffset": 12, "endOffset": 38}], "year": 2012, "abstractText": "Recent research has shown that surprisingly rich models of human activity can be learned from GPS (positional) data. However, most effort to date has concentrated on modeling single individuals or statistical properties of groups of people. Moreover, prior work focused solely on modeling actual successful executions (and not failed or attempted executions) of the activities of interest. We, in contrast, take on the task of understanding human interactions, attempted interactions, and intentions from noisy sensor data in a fully relational multi-agent setting. We use a real-world game of capture the flag to illustrate our approach in a well-defined domain that involves many distinct cooperative and competitive joint activities. We model the domain using Markov logic, a statistical-relational language, and learn a theory that jointly denoises the data and infers occurrences of high-level activities, such as a player capturing an enemy. Our unified model combines constraints imposed by the geometry of the game area, the motion model of the players, and by the rules and dynamics of the game in a probabilistically and logically sound fashion. We show that while it may be impossible to directly detect a multi-agent activity due to sensor noise or malfunction, the occurrence of the activity can still be inferred by considering both its impact on the future behaviors of the people involved as well as the events that could have preceded it. Further, we show that given a model of successfully performed multi-agent activities, along with a set of examples of failed attempts at the same activities, our system automatically learns an augmented model that is capable of recognizing success and failure, as well as goals of people\u2019s actions with high accuracy. We compare our approach with other alternatives and show that our unified model, which takes into account not only relationships among individual players, but also relationships among activities over the entire length of a game, although more computationally costly, is significantly more accurate. Finally, we demonstrate that explicitly modeling unsuccessful attempts boosts performance on other important recognition tasks.", "creator": "TeX"}}}