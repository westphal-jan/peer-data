{"id": "1401.4609", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2014", "title": "Computing All-Pairs Shortest Paths by Leveraging Low Treewidth", "abstract": "We present two new and efficient algorithms for computing all-pairs shortest paths. The algorithms operate on directed graphs with real (possibly negative) weights. They make use of directed path consistency along a vertex ordering d. Both algorithms run in O(n^2 w_d) time, where w_d is the graph width induced by this vertex ordering. For graphs of constant treewidth, this yields O(n^2) time, which is optimal. On chordal graphs, the algorithms run in O(nm) time. In addition, we present a variant that exploits graph separators to arrive at a run time of O(n w_d^2 + n^2 s_d) on general graphs, where s_d andlt= w_d is the size of the largest minimal separator induced by the vertex ordering d. We show empirically that on both constructed and realistic benchmarks, in many cases the algorithms outperform Floyd-Warshalls as well as Johnsons algorithm, which represent the current state of the art with a run time of O(n^3) and O(nm + n^2 log n), respectively. Our algorithms can be used for spatial and temporal reasoning, such as for the Simple Temporal Problem, which underlines their relevance to the planning and scheduling community.", "histories": [["v1", "Sat, 18 Jan 2014 21:23:48 GMT  (2251kb)", "http://arxiv.org/abs/1401.4609v1", null]], "reviews": [], "SUBJECTS": "cs.DS cs.AI", "authors": ["l\\'eon r planken", "mathijs m de weerdt", "roman p j van der krogt"], "accepted": false, "id": "1401.4609"}, "pdf": {"name": "1401.4609.pdf", "metadata": {"source": "META", "title": "Computing All-Pairs Shortest Paths by Leveraging Low Treewidth", "authors": ["L\u00e9on Planken", "Mathijs de Weerdt", "Roman van der Krogt"], "emails": ["l.r.planken@tudelft.nl", "m.m.deweerdt@tudelft.nl", "roman@4c.ucc.ie"], "sections": [{"heading": null, "text": "We present two new and efficient algorithms for calculating all pairs with shortest paths. The algorithms work on directed graphs with real (possibly negative) weights. They use directed path consistency along a vertex order. Both algorithms run in O (n2wd) time, where wd is the graph width induced by this vertex order. For graphs with constant tree width, the result is O (n2) time, which is optimal. For chord graphs, the algorithms run in O (nm) time. In addition, we present a variant that uses graph separators to arrive at a runtime of O (nw2d + n 2sd) on general graphs, where sd \u2264 wd is the size of the largest minimal separator induced by the vertex order d. We demonstrate empirically that on both constructed and realistic benchmarks, the algorithms are in many cases more relevant to the current performance of Floyd's (as well as to the current state of Johnson's)."}, {"heading": "1. Introduction", "text": "The search for the shortest paths is an important and fundamental problem in communication and transport networks, circuit design, bioinformatics, Internet node traffic, social networks, and graph analysis in general - for example, for calculating the shortest paths (Girvan & Newman, 2002) - and is a partial problem of many combinatorial problems, such as those that can be presented as a network flow problem. Especially, in the context of planning and planning, the search for the shortest paths is important to solve a series of binary linear constraints on events (i.e. the Simple Temporal Problem (STP; Dechter, Meiri, & Pearl, 1991), which in turn appears as a sub-problem to the NP-hard Temporal Constraint. (TCSP; Dechter et al, 1991) and Disjunctive Temporal Problems (DTP; Stergiou & Koubarakis, 2000), which are powerful enough to solve problems."}, {"heading": "2. Preliminaries", "text": "In this section, we briefly introduce the algorithm that forces directional path consistency (DPC) and how to find a vertex order required for this algorithm. Then, we present our algorithms for all pairs of shortest paths, all of which require the enforcement of DPC (or a stronger property) as a first step. In our treatment, we assume that the weights at the edges of the graph are real and possibly negative."}, {"heading": "2.1 Directed Path Consistency", "text": "Dechter et al. (1991) presents DPC, included here as algorithm 1, as a way of verifying whether an STP instance consists. 2 This is tantamount to verifying that the graph does not contain a negative cycle (a closed path with negative total weight).The algorithm inputs a weighted directed graph G = < V > and a vertex that represents a bijection between V and the natural numbers. In this paper, we simply represent the vertex in such an order as the natural number i. The (possibly negative) weight on the arc from i to j is represented as wi."}, {"heading": "2.2 Finding a Vertex Ordering", "text": "In principle, DPC can use any order of the vertex to make the graph both chordally and directionally path consistent. However, since the vertex order defines the induced width, it directly influences the runtime and number of edges mc in the resulting graph. As mentioned in the introduction, finding an order d with minimum induced width wd = w \u043c and even the mere determination of the tree width w \u043c is generally a NP-hard problem. Nevertheless, the class of diagrams with constant tree width in O (m) time can be detected and optimally triangular adjusted in O (n) time (Bodlaender, 1996). If G is already chordal, we can find a perfect sequence (which does not lead to fill edges) in O (m) time, e.g. by using maximum cardinality search (MCS; Tarjan & Yannakis 1984), because each sequence is called a perfect neighbor (also called a G)."}, {"heading": "3. All-Pairs Shortest Paths", "text": "Although, to the best of our knowledge, no DPC-based APSP algorithm has yet been proposed, algorithms for calculating shortest paths (SSSP) are relatively easy to derive from known results. Chleq (1995) proposed a point-to-point algorithm that calculates SSSP with a trivial fit; Planken, de Weerdt and Yorke-Smith (2010) implicitly calculate SSSP as part of their IPPC algorithm. These algorithms run in O (mc) time and can therefore simply be executed once for each vertex to obtain an APSP algorithm with O (nmc) O (n2wd) time complexity. Below, we first show how to adapt Chleq's algorithm to calculate APSP; then, we present a new, efficient algorithm called Snowball, which relates to planks et al. (2008) P3C."}, {"heading": "3.1 Chleq\u2019s Approach", "text": "Chleq's (1995) point-to-point short path algorithm was simply called min path and calculates the shortest path between any two vertices s, t-V in a directional, consistent graph G. It is rendered here as algorithm 2 and can then be executed in O (mc) time, because each edge is considered at most twice. The shortest distance from the source vertex s is maintained in an array D. The algorithm iterates downward from s to 1 and then upward from 1 to t, updating the distance field when a shorter path is found. Since the vertex point t is only used as a boundary for the second loop, it is clear that D actually contains shortest distances between all pairs (s, t-t) with t-t-t-t-t-t. Therefore, we can easily adjust this algorithm to calculate SSSP within the same O (mc) time by returning t = n and the whole array D."}, {"heading": "3.2 The Snowball Algorithm", "text": "In this section, we will introduce an algorithm that calculates APSP (or full path consistency) called Snowball, which is included as Algorithm 4, which has the same asymptotic worst-case time limit as Chleq APSP, but originally requires less computational work. Like Chleq APSP, this algorithm first ensures that the input graph points the way; the idea behind the algorithm is then that while executing the outermost loop, we create a clique {1,.. k} of the calculated (shortest) distances, a vertex at a time, starting with the trivial clique consisting of only Vertex 1; while DPC performs a reverse movement along d, Snowball iterates in the other direction. If you add vertex k to the clique, the two inner loops ensure that we calculate the distances between k and all vertices."}, {"heading": "3.3 Improving Run-Time Complexity Using Separators", "text": "& & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & &"}, {"heading": "4. Experiments", "text": "We evaluate the two algorithms together with efficient implementations of Floyd-Warshall and Johnson using a Fibonacci Heap5 across six different benchmark sets. 65. For Johnson, we used the Fibonacci Heap implementation corrected by Fiedler (2008) because the widely used pseudo-code of Cormen, Leiserson, Rivest and Stein (2001) contains bugs. 6. Available at http: / / dx.doi.org / 10.4121 / uuuid: 49388c35-c7fb-464f-9293-cca1406edccfThe properties of the test cases are summarized in Table 1. This table lists the number of test cases, the range of nodes n, edges, induced width wd generated by the minimum heuristic degree, and the size of the largest minimum separators sd in the diagrams. More details on the different sets can be found below."}, {"heading": "4.1 Triangulation", "text": "As discussed in Section 2.2, finding an optimal vertex order (with minimum induced width) is NP-hard, but there are several efficient triangulation euristics for this problem. We conducted our experiments with six different heuristics: the minimum filling and minimum degree heuristics, static variants of both (taking into account only the original graph), an order generated by performing a maximum cardinality search (MCS) on the original graph, and a random order. All of these, with the exception of the minimum filling, have time complexities within the runtime of Chleq APSP and Snowball. We found that the minimum heuristic yield gave on average induced widths below 1.5% higher than those found at minimum filling 7. Our implementations are available in binary form at http: / / dx.doi.org / 10.4121 / uid."}, {"heading": "4.2 Chordal Graphs", "text": "In order to evaluate the performance of the new algorithms using chord graphs, we construct chord graphs of a fixed size of 1,000 vertices with a tree width ranging from 79 to just below the number of vertices, providing an almost complete diagram at the top. The results of this experiment are in Figure 3. In this and other illustrations, the error bars represent the standard deviations in the measured runtime for instances of this size. In diagrams up to an induced width of about three-quarters of the number of vertices, Snowball Floyd-Warshall (which yields the expected horizontal line) significantly exceeds Snowball-Warshall (which yields the expected horizontal line), and overall, the runtime of both new algorithms is significantly lower than Johnson. Figure 4 shows the runtimes on chord diagrams of a constant tree width and with increasing number of vertices. Here, the two new algorithms exceed Johnson by almost an order of magnitude (a factor 9.3 for snowball by 1300 = heating), thus confirming the expectations of the upper vertices even higher."}, {"heading": "4.3 General Graphs", "text": "For general, non-chord-bound graphs, we expect theoretical analysis to show that the O (nw2d) -time Chleq APP and Snowball algorithms are faster than Johnson with his O (nm + n2 log n) 8. Available at http: / / treewidth.com /.time bound when wd low, and that Johnson is faster on sparse graphs (where m is low) with a large induced width wd. The main question is at what induced width this transition occurs. Regarding Floyd-Warshall with its O (n3) limit, we expect that it will always be surpassed by other algorithms on larger n."}, {"heading": "4.3.1 Scale-Free Graphs", "text": "That is, for large values of k, the fraction P (k) of wells in the network with k connections to other wells tends to P (k) \u0445 ck \u2212 \u03b3, for some constant c and parameters \u03b3. In other words, few wells have many wells, while many wells have few wells. Such a property can be found in many real graphs, such as on social networks and on the Internet. Our instances happened to be associated with Albert and Baraba's (2002) preferred fastening method, where a new vertex is added in each iteration to add to the graph, which is then tied to a number of existing wells. The higher the degree of an existing vertex, the more likely it is to be connected to the newly added vertex. To see at which the induced width Johnson is faster, we compare the runtimes on such generated graphs with 1,000 wells."}, {"heading": "4.3.2 Selections from New York Road Network", "text": "More interesting than the artificially constructed graphs are graphs based on real networks for which the shortest path calculations are relevant, the first of which is based on the New York City road network, which we obtained from the DIMACS Challenge.9 This network is very large (with 264,346 corners and 733,846 edges), so we decided to calculate it.http: / / www.dis.uniroma1.it / ~ challenge9 / Shortest paths for (induced) sub-diagrams of different sizes, which were achieved by a simple breadth search from a random starting point to the desired number of corners.The extent of the resulting sub-nets is illustrated in Figure 7 for three different sizes. The results of all the algorithms on these sub-diagrams can be found in Figure 8, with the same order of algorithms as on the chord curves of a fixed tree width."}, {"heading": "4.3.3 STNs from Diamonds", "text": "This benchmark theorem is based on problem cases in the logic of difference proposed by Strichman, Seshia and Bryant (2002), which also appear in the smt-lib (Ranise & Tinelli, 2003), where the constraint graph assumes the form of a circular chain of \"diamonds\" for each instance, each of which consists of two parallel paths of equal length starting from a single vertex and ending at another single vertex. Starting from the latter vertex, two paths begin again to approach a third vertex, a pattern that repeats for each diamond in the chain; the final vertex is then connected to the very first. The sizes of each diamond and the total number of diamonds vary between benchmarks. Problems in this class are actually instances of the NP-complete disjunctive temporal problem (DTP), which represents the most weighting of the imbalances."}, {"heading": "4.3.4 STNs from Job-Shop Scheduling", "text": "To get these diagrams from the instances of the job shop, we again used the extraction method described in the previous section. The most remarkable observation that can be drawn from Figure 10 is that the difference between Johnson and the two new algorithms is not quite as pronounced, although Snowball is consistently the fastest of the three by a small distance. That this distance is so small is most likely due to the structure of these diagrams, which is also reflected in their relatively high induced width. Also, note that the runtimes for diagrams of up to 160 vertices are better, while for larger diagrams the other algorithms are significantly faster."}, {"heading": "4.3.5 STNs from HTNs", "text": "Finally, we consider a benchmark set whose instances mimic so-called sibling-restricted STNs originating from Hierarchical Task Networks (Bui & Yorke-Smith, 2010), which is particularly interesting from a planning point of view: In these diagrams, constraints can only occur between parent tasks and their children and between sibling tasks (Bui & Yorke-Smith, 2010) that cause a deviation from the tree-like HTN structure. We create HTNs using the following parameters: (i) the number of tasks in the initial HTN tree (fixed at 250; note that tasks have a start and end point), (ii) the branching factor that determines the number of children for each task (between 4 and 7), (iii) the depth of the HTN tree (fixed at 250; note that tasks have a start and end point), (ii) the branching factor that determines the number of children for each task (between 4 and 12), (iiii) the number of children for each task (between 12 and 12), (iii) the depth of the tree (iv)."}, {"heading": "4.4 Snowball\u2013Separators", "text": "In this section, we discuss the results of our experiments by comparing these two variants. First, we turn our attention to the benchmark problems in regular illustrations. Our results are summarized in Figure 12. As can be seen, snowball separators actually perform strictly worse on these sets in terms of mileage compared to the original snowball. However, the largest minimal separator is often equal to or only slightly smaller than the induced width. Although there are few separators that are this large, and many may be substantially smaller than the median size below 10, this leads us to conduct experiments in which the dividing lines are kept artificially small."}, {"heading": "4.5 A Proper Upper Bound on the Run Time", "text": "The question of whether and in what form the two countries can agree on a common line has not yet been answered, but it has not yet been decided whether or not they will agree on a common line. (...) The question of whether or not they can agree on a common line has not yet been answered. (...) The question of whether or not they can agree on a common line has not yet been answered. (...) The question of whether or not they can agree on a common line has not been answered. (...) The question of whether or not they can agree on a common line has not yet been answered. (...) The question of whether or not they can agree on a common line has not been answered. (...) The question of whether or not they can agree on a common line has not yet been answered. (...) The question of whether or not they can agree on a common line has not yet been answered. (...) The question of whether or not they can agree on a common line. (...) The question of whether or not they can agree on a common line has not yet been answered."}, {"heading": "5. Related Work", "text": "In theory, this algorithm is faster than Johnson (in the worst cases, for large graphics) when it (n log n) exists (n log n).12 However, there is currently no implementation (as through personal communication with Pettie, 2004).In theory, this algorithm is faster than Johnson (in the worst cases, for large graphics) when it (n log n).12 However, there is currently no implementation (as through personal communication with Pettie, 2004)."}, {"heading": "6. Conclusions and Future Work", "text": "This book presents three algorithms for calculating all-pair ways, from which we see ourselves able to solve the actual problems when we see ourselves able to solve them. (iiii) It is indeed handled as if they were able to outwit themselves. (iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiuuuuuuuuuuuuuuuuuuiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiuuuuuuuuuuuiiiiiiiiiiiiiiuuuuuiiiiiiiiiiiiiiiiiiiiiuuuuiiiiiii"}, {"heading": "Acknowledgments", "text": "Roman van der Krogt is supported by the Science Foundation Ireland under grant number 08 / RFP / CMS1711. We sincerely thank our reviewers for their comments, which have helped us to improve the clarity of the article and strengthen our empirical results, based on a conference paper of the same title, which received an honourable mention for the best student work at the International Conference on Automated Planning (Planken, de Weerdt, & van der Krogt, 2011)."}, {"heading": "Appendix A. Johnson\u2019s Heap", "text": "In the experiments in this paper we presented the results for Johnson with a Fibonacci heap, because only then the theoretical limit of O (nm + n2 log n) time is reached. In practice, using a binary heap for a theoretical limit of O (nm log n) time proves to be more efficient in some cases, as we show by the results in this paragraph. Figure 16 shows the runtimes of Johnson with a binary heap and with a Fibonacci heap on all benchmark sets listed in Table 1. On the Diamonds, HTN, and New York benchmarks the binary heap is a few percent faster than the runtime of Johnson with a binary heap, but the slope of the lines in this logarithmic scale is the same, so we can conclude that the average runtime has similar asymptotic behavior."}], "references": [{"title": "Statistical Mechanics of Complex Networks", "author": ["R. Albert", "Barab\u00e1si", "A.-L"], "venue": "Reviews of Modern Physics,", "citeRegEx": "Albert et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Albert et al\\.", "year": 2002}, {"title": "Complexity of Finding Embeddings in a k -Tree", "author": ["S. Arnborg", "D.G. Corneil", "A. Proskurowski"], "venue": "SIAM Journal on Algebraic and Discrete Methods,", "citeRegEx": "Arnborg et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Arnborg et al\\.", "year": 1987}, {"title": "All-pairs-shortest-length on strongly chordal graphs", "author": ["V. Balachandhran", "C.P. Rangan"], "venue": "Discrete applied mathematics,", "citeRegEx": "Balachandhran and Rangan,? \\Q1996\\E", "shortCiteRegEx": "Balachandhran and Rangan", "year": 1996}, {"title": "Combining hierarchical and goal-directed speed-up techniques for Dijkstra\u2019s algorithm", "author": ["R. Bauer", "D. Delling", "P. Sanders", "D. Schieferdecker", "D. Schultes", "D. Wagner"], "venue": "In Experimental Algorithms (WEA 2008),", "citeRegEx": "Bauer et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bauer et al\\.", "year": 2008}, {"title": "Classes of graphs with bounded tree-width", "author": ["H.L. Bodlaender"], "venue": "Tech. rep. RUU-CS86-22, Utrecht University.", "citeRegEx": "Bodlaender,? 1986", "shortCiteRegEx": "Bodlaender", "year": 1986}, {"title": "A Linear-Time Algorithm for Finding Tree-Decompositions of Small Treewidth", "author": ["H.L. Bodlaender"], "venue": "SIAM Journal on Computing, 25 (6), 1305\u20131317.", "citeRegEx": "Bodlaender,? 1996", "shortCiteRegEx": "Bodlaender", "year": 1996}, {"title": "On Treewidth Approximations", "author": ["V. Bouchitt\u00e9", "D. Kratsch", "H. M\u00fcller", "I. Todinca"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "Bouchitt\u00e9 et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bouchitt\u00e9 et al\\.", "year": 2004}, {"title": "Activity Planning for the Mars Exploration Rovers", "author": ["J.L. Bresina", "A.K. J\u00f3nsson", "P.H. Morris", "K. Rajan"], "venue": "In Proc. of the 15th Int. Conf. on Automated Planning and Scheduling,", "citeRegEx": "Bresina et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Bresina et al\\.", "year": 2005}, {"title": "Efficient Variable Elimination for Semi-Structured Simple Temporal Networks with Continuous Domains", "author": ["H.H. Bui", "N. Yorke-Smith"], "venue": "Knowledge Engineering Review,", "citeRegEx": "Bui and Yorke.Smith,? \\Q2010\\E", "shortCiteRegEx": "Bui and Yorke.Smith", "year": 2010}, {"title": "A Temporal Constraint Network Based Temporal Planner", "author": ["L. Castillo", "J. Fern\u00e1ndez-Olivares", "A. Gonz\u00e1lez"], "venue": "In Proc. of the 21st Workshop of the UK Planning and Scheduling Special Interest Group,", "citeRegEx": "Castillo et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Castillo et al\\.", "year": 2002}, {"title": "Efficiently Handling Temporal Knowledge in an HTN planner", "author": ["L. Castillo", "J. Fern\u00e1ndez-Olivares", "A. Gonz\u00e1lez"], "venue": "In Proc. of the 16th Int. Conf. on Automated Planning and Scheduling,", "citeRegEx": "Castillo et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Castillo et al\\.", "year": 2006}, {"title": "Shortest Paths in Digraphs of Small Treewidth", "author": ["S. Chaudhuri", "C.D. Zaroliagis"], "venue": "Part I: Sequential Algorithms. Algorithmica,", "citeRegEx": "Chaudhuri and Zaroliagis,? \\Q2000\\E", "shortCiteRegEx": "Chaudhuri and Zaroliagis", "year": 2000}, {"title": "Shortest paths algorithms: theory and experimental evaluation", "author": ["B.V. Cherkassky", "A.V. Goldberg", "T. Radzik"], "venue": "Mathematical programming,", "citeRegEx": "Cherkassky et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Cherkassky et al\\.", "year": 1996}, {"title": "Negative-cycle detection algorithms", "author": ["B.V. Cherkassky", "A.V. Goldberg"], "venue": "Mathematical Programming,", "citeRegEx": "Cherkassky and Goldberg,? \\Q1999\\E", "shortCiteRegEx": "Cherkassky and Goldberg", "year": 1999}, {"title": "Efficient Algorithms for Networks of Quantitative Temporal Constraints", "author": ["N. Chleq"], "venue": "Proc. of the 1st Int. Workshop on Constraint Based Reasoning, pp. 40\u201345.", "citeRegEx": "Chleq,? 1995", "shortCiteRegEx": "Chleq", "year": 1995}, {"title": "Flexible execution of plans with choice", "author": ["P.R. Conrad", "J.A. Shah", "B.C. Williams"], "venue": "In Proc. of the 19th Int. Conf. on Automated Planning and Scheduling", "citeRegEx": "Conrad et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Conrad et al\\.", "year": 2009}, {"title": "Introduction to Algorithms, 2nd edition", "author": ["T.H. Cormen", "C.E. Leiserson", "R.L. Rivest", "C. Stein"], "venue": null, "citeRegEx": "Cormen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Cormen et al\\.", "year": 2001}, {"title": "Temporal Constraint Networks", "author": ["R. Dechter", "I. Meiri", "J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "Dechter et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Dechter et al\\.", "year": 1991}, {"title": "Fully Dynamic All-Pairs Shortest Paths with Real Edge Weights", "author": ["C. Demetrescu", "G.F. Italiano"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Demetrescu and Italiano,? \\Q2006\\E", "shortCiteRegEx": "Demetrescu and Italiano", "year": 2006}, {"title": "A note on two problems in connexion with graphs", "author": ["E.W. Dijkstra"], "venue": "Numerische Mathematik,", "citeRegEx": "Dijkstra,? \\Q1959\\E", "shortCiteRegEx": "Dijkstra", "year": 1959}, {"title": "Estimating all pairs shortest paths in restricted graph families: a unified approach", "author": ["F.F. Dragan"], "venue": "Journal of Algorithms, 57 (1), 1\u201321.", "citeRegEx": "Dragan,? 2005", "shortCiteRegEx": "Dragan", "year": 2005}, {"title": "Updating Distances in Dynamic Graphs", "author": ["S. Even", "H. Gazit"], "venue": "Methods of Operations Research,", "citeRegEx": "Even and Gazit,? \\Q1985\\E", "shortCiteRegEx": "Even and Gazit", "year": 1985}, {"title": "Analysis of Java implementations of Fibonacci Heap", "author": ["N. Fiedler"], "venue": "http://tinyurl. com/fibo-heap.", "citeRegEx": "Fiedler,? 2008", "shortCiteRegEx": "Fiedler", "year": 2008}, {"title": "Algorithm 97: Shortest path", "author": ["R.W. Floyd"], "venue": "Communications of the ACM, 5 (6), 345.", "citeRegEx": "Floyd,? 1962", "shortCiteRegEx": "Floyd", "year": 1962}, {"title": "Fibonacci Heaps and Their Uses in Improved Network Optimization Algorithms", "author": ["M. Fredman", "R.E. Tarjan"], "venue": "Journal of the ACM,", "citeRegEx": "Fredman and Tarjan,? \\Q1987\\E", "shortCiteRegEx": "Fredman and Tarjan", "year": 1987}, {"title": "Contraction hierarchies: Faster and simpler hierarchical routing in road networks", "author": ["R. Geisberger", "P. Sanders", "D. Schultes", "D. Delling"], "venue": "In Proc. of the Int. Workshop on Experimental Algorithms,", "citeRegEx": "Geisberger et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Geisberger et al\\.", "year": 2008}, {"title": "Community Structure in Social and Biological Networks", "author": ["M. Girvan", "M.E.J. Newman"], "venue": "Proc. of the National Academy of Sciences of the USA,", "citeRegEx": "Girvan and Newman,? \\Q2002\\E", "shortCiteRegEx": "Girvan and Newman", "year": 2002}, {"title": "Algorithmic Graph Theory and Perfect Graphs", "author": ["M. Golumbic"], "venue": "Elsevier.", "citeRegEx": "Golumbic,? 2004", "shortCiteRegEx": "Golumbic", "year": 2004}, {"title": "Concrete Mathematics: A Foundation for Computer Science (1st edition)", "author": ["R.L. Graham", "D.E. Knuth", "O. Patashnik"], "venue": null, "citeRegEx": "Graham et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Graham et al\\.", "year": 1989}, {"title": "Unified All-Pairs Shortest Path Algorithms in the Chordal Hierarchy", "author": ["K. Han", "C.N. Sekharan", "R. Sridhar"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "Han et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Han et al\\.", "year": 1997}, {"title": "Minimal triangulations of graphs: A survey", "author": ["P. Heggernes"], "venue": "Discrete Mathematics, 306 (3), 297\u2013317. Minimal Separation and Minimal Triangulation.", "citeRegEx": "Heggernes,? 2006", "shortCiteRegEx": "Heggernes", "year": 2006}, {"title": "Efficient Algorithms for Shortest Paths in Sparse Networks", "author": ["D.B. Johnson"], "venue": "Journal of the ACM, 24 (1), 1\u201313.", "citeRegEx": "Johnson,? 1977", "shortCiteRegEx": "Johnson", "year": 1977}, {"title": "Triangulation of Graphs - Algorithms Giving Small Total State Space", "author": ["U. Kj\u00e6rulff"], "venue": "Tech. rep., Aalborg University.", "citeRegEx": "Kj\u00e6rulff,? 1990", "shortCiteRegEx": "Kj\u00e6rulff", "year": 1990}, {"title": "Shortest Paths in Directed Planar Graphs with Negative Lengths: A Linear-space O", "author": ["P.N. Klein", "S. Mozes", "O. Weimann"], "venue": null, "citeRegEx": "Klein et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2010}, {"title": "Shortest path algorithms: A computational study with the C programming language", "author": ["J.F. Mondou", "T.G. Crainic", "S. Nguyen"], "venue": "Computers & Operations Research,", "citeRegEx": "Mondou et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Mondou et al\\.", "year": 1991}, {"title": "A New Approach to All-pairs Shortest Paths on Real-weighted Graphs", "author": ["S. Pettie"], "venue": "Theoretical Computer Science, 312 (1), 47\u201374. Planken, L. R., de Weerdt, M. M., & van der Krogt, R. P. J. (2008). P3C: A New Algorithm for the Simple Temporal Problem. In Proc. of the 18th Int. Conf. on Automated Planning and Scheduling, pp. 256\u2013263.", "citeRegEx": "Pettie,? 2004", "shortCiteRegEx": "Pettie", "year": 2004}, {"title": "Computing allpairs shortest paths by leveraging low treewidth", "author": ["L.R. Planken", "M.M. de Weerdt", "R.P.J. van der Krogt"], "venue": "In Proc. of the 21st Int. Conf. on Automated Planning and Scheduling,", "citeRegEx": "Planken et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Planken et al\\.", "year": 2011}, {"title": "Incrementally Solving STNs by Enforcing Partial Path Consistency", "author": ["L.R. Planken", "M.M. de Weerdt", "N. Yorke-Smith"], "venue": "In Proc. of the 20th Int. Conf. on Automated Planning and Scheduling,", "citeRegEx": "Planken et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Planken et al\\.", "year": 2010}, {"title": "The SMT-LIB Format: An Initial Proposal", "author": ["S. Ranise", "C. Tinelli"], "venue": "In Proc. of Pragmatics of Decision Procedures in Automated Reasoning", "citeRegEx": "Ranise and Tinelli,? \\Q2003\\E", "shortCiteRegEx": "Ranise and Tinelli", "year": 2003}, {"title": "A Graph-Theoretic Study of the Numerical Solution of Sparse Positive Definite Systems of Linear Equations", "author": ["D.J. Rose"], "venue": "Read, R. (Ed.), Graph theory and computing, pp. 183\u2013217. Academic Press.", "citeRegEx": "Rose,? 1972", "shortCiteRegEx": "Rose", "year": 1972}, {"title": "Uncertainty in soft temporal constraint problems: A general framework and controllability algorithms for the fuzzy case", "author": ["F. Rossi", "K.B. Venable", "N. Yorke-Smith"], "venue": "Journal of AI Research,", "citeRegEx": "Rossi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Rossi et al\\.", "year": 2006}, {"title": "On the Tractability of Restricted Disjunctive Temporal Problems", "author": ["T.K. Satish Kumar"], "venue": "Proc. of the 15th Int. Conf. on Automated Planning and Scheduling, pp. 110\u2013119.", "citeRegEx": "Kumar,? 2005", "shortCiteRegEx": "Kumar", "year": 2005}, {"title": "Fast Dynamic Scheduling of Disjunctive Temporal Constraint Networks through Incremental Compilation", "author": ["J.A. Shah", "B.C. Williams"], "venue": "In Proc. of the 18th Int. Conf. on Automated Planning and Scheduling,", "citeRegEx": "Shah and Williams,? \\Q2008\\E", "shortCiteRegEx": "Shah and Williams", "year": 2008}, {"title": "Backtracking algorithms for disjunctions of temporal constraints", "author": ["K. Stergiou", "M. Koubarakis"], "venue": "Artificial Intelligence,", "citeRegEx": "Stergiou and Koubarakis,? \\Q2000\\E", "shortCiteRegEx": "Stergiou and Koubarakis", "year": 2000}, {"title": "Deciding Separation Formulas with SAT", "author": ["O. Strichman", "S.A. Seshia", "R.E. Bryant"], "venue": "In Proc. of the 14th Int. Conf. on Computer Aided Verification,", "citeRegEx": "Strichman et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Strichman et al\\.", "year": 2002}, {"title": "Simple Linear-time Algorithms to Test Chordality of Graphs, Test Acyclicity of Hypergraphs, and Selectively Reduce Acyclic Hypergraphs", "author": ["R.E. Tarjan", "M. Yannakakis"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Tarjan and Yannakakis,? \\Q1984\\E", "shortCiteRegEx": "Tarjan and Yannakakis", "year": 1984}, {"title": "Fully-dynamic All-Pairs Shortest Paths: Faster and Allowing Negative Cycles", "author": ["Planken", "De Weerdt", "M. Van der Krogt Thorup"], "venue": "In Algorithm Theory, Vol. 3111 of LNCS,", "citeRegEx": "Planken et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Planken et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 17, "context": "The STP in turn appears as a sub-problem to the NP-hard Temporal Constraint Satisfaction Problem (TCSP; Dechter et al., 1991) and Disjunctive Temporal Problem (DTP; Stergiou & Koubarakis, 2000), which are powerful enough to model e.", "startOffset": 97, "endOffset": 125}, {"referenceID": 17, "context": "The canonical way of solving an STP instance (Dechter et al., 1991) is by computing all-pairs shortest paths (APSP) on its STN, thus achieving full path consistency.", "startOffset": 45, "endOffset": 67}, {"referenceID": 23, "context": "For graphs with n vertices and m edges, this can be done in O ( n3 ) time with the Floyd\u2013Warshall algorithm (Floyd, 1962), based on Warshall\u2019s (1962) formulation of efficiently computing the transitive closure of Boolean matrices.", "startOffset": 108, "endOffset": 121}, {"referenceID": 4, "context": "In addition to these STNs, examples of such graphs of constant treewidth are outerplanar graphs, graphs of bounded bandwidth, graphs of bounded cutwidth, and series-parallel graphs (Bodlaender, 1986).", "startOffset": 181, "endOffset": 199}, {"referenceID": 27, "context": "Chordal graphs are an important subset of general sparse graphs: interval graphs, trees, k-trees and split graphs are all special cases of chordal graphs (Golumbic, 2004).", "startOffset": 154, "endOffset": 170}, {"referenceID": 14, "context": "The canonical way of solving an STP instance (Dechter et al., 1991) is by computing all-pairs shortest paths (APSP) on its STN, thus achieving full path consistency. For graphs with n vertices and m edges, this can be done in O ( n3 ) time with the Floyd\u2013Warshall algorithm (Floyd, 1962), based on Warshall\u2019s (1962) formulation of efficiently computing the transitive closure of Boolean matrices.", "startOffset": 46, "endOffset": 316}, {"referenceID": 14, "context": "The canonical way of solving an STP instance (Dechter et al., 1991) is by computing all-pairs shortest paths (APSP) on its STN, thus achieving full path consistency. For graphs with n vertices and m edges, this can be done in O ( n3 ) time with the Floyd\u2013Warshall algorithm (Floyd, 1962), based on Warshall\u2019s (1962) formulation of efficiently computing the transitive closure of Boolean matrices. However, the state of the art for computing APSP on sparse graphs is an algorithm based on the technique originally proposed by Johnson (1977), which does some preprocessing to allow n runs of Dijkstra\u2019s (1959) algorithm.", "startOffset": 46, "endOffset": 540}, {"referenceID": 14, "context": "The canonical way of solving an STP instance (Dechter et al., 1991) is by computing all-pairs shortest paths (APSP) on its STN, thus achieving full path consistency. For graphs with n vertices and m edges, this can be done in O ( n3 ) time with the Floyd\u2013Warshall algorithm (Floyd, 1962), based on Warshall\u2019s (1962) formulation of efficiently computing the transitive closure of Boolean matrices. However, the state of the art for computing APSP on sparse graphs is an algorithm based on the technique originally proposed by Johnson (1977), which does some preprocessing to allow n runs of Dijkstra\u2019s (1959) algorithm.", "startOffset": 46, "endOffset": 608}, {"referenceID": 12, "context": "One algorithm, dubbed Chleq\u2013APSP, is based on a point-to-point shortest path algorithm by Chleq (1995); the other, named Snowball, is similar to Planken, de Weerdt, and van der Krogt\u2019s (2008) algorithm for enforcing partial (instead of full) path consistency (PC).", "startOffset": 22, "endOffset": 103}, {"referenceID": 12, "context": "One algorithm, dubbed Chleq\u2013APSP, is based on a point-to-point shortest path algorithm by Chleq (1995); the other, named Snowball, is similar to Planken, de Weerdt, and van der Krogt\u2019s (2008) algorithm for enforcing partial (instead of full) path consistency (PC).", "startOffset": 22, "endOffset": 192}, {"referenceID": 17, "context": "Algorithm 1: DPC (Dechter et al., 1991) Input: Weighted directed graph G = \u3008V,E\u3009; vertex ordering d : V \u2192 {1, .", "startOffset": 17, "endOffset": 39}, {"referenceID": 17, "context": "Dechter et al. (1991) define this induced width of a vertex ordering d procedurally to be exactly the highest number of neighbours j of k with j < k encountered during the DPC algorithm.", "startOffset": 0, "endOffset": 22}, {"referenceID": 5, "context": "time (Bodlaender, 1996).", "startOffset": 5, "endOffset": 23}, {"referenceID": 39, "context": "We mention here the minimum degree heuristic (Rose, 1972), which in each iteration chooses a vertex of lowest degree.", "startOffset": 45, "endOffset": 57}, {"referenceID": 14, "context": "Chleq (1995) proposed a point-to-point shortest path algorithm that with a trivial adaptation computes SSSP; Planken, de Weerdt, and Yorke-Smith (2010) implicitly also compute SSSP as part of their IPPC algorithm.", "startOffset": 0, "endOffset": 13}, {"referenceID": 14, "context": "Chleq (1995) proposed a point-to-point shortest path algorithm that with a trivial adaptation computes SSSP; Planken, de Weerdt, and Yorke-Smith (2010) implicitly also compute SSSP as part of their IPPC algorithm.", "startOffset": 0, "endOffset": 152}, {"referenceID": 14, "context": "Chleq (1995) proposed a point-to-point shortest path algorithm that with a trivial adaptation computes SSSP; Planken, de Weerdt, and Yorke-Smith (2010) implicitly also compute SSSP as part of their IPPC algorithm. These algorithms run in O (mc) time and thus can simply be run once for each vertex to yield an APSP algorithm with O (nmc) \u2286 O ( nwd ) time complexity. Below, we first show how to adapt Chleq\u2019s algorithm to compute APSP; then, we present a new, efficient algorithm named Snowball that relates to Planken et al.\u2019s (2008) PC.", "startOffset": 0, "endOffset": 535}, {"referenceID": 14, "context": "Algorithm 2: Min\u2013path (Chleq, 1995) Input: Weighted directed DPC graph G = \u3008V,E\u3009; (arbitrary) source vertex s and destination vertex t Output: Distance from s to t, or inconsistent if G contains a negative cycle", "startOffset": 22, "endOffset": 35}, {"referenceID": 22, "context": "For Johnson we used the corrected Fibonacci heap implementation by Fiedler (2008), since the widely used pseudocode of Cormen, Leiserson, Rivest, and Stein (2001) contains mistakes.", "startOffset": 67, "endOffset": 82}, {"referenceID": 22, "context": "For Johnson we used the corrected Fibonacci heap implementation by Fiedler (2008), since the widely used pseudocode of Cormen, Leiserson, Rivest, and Stein (2001) contains mistakes.", "startOffset": 67, "endOffset": 163}, {"referenceID": 32, "context": "However, it is also known from the literature that the theoretical bound on the minimum fill heuristic is worse than that of minimum degree (Kj\u00e6rulff, 1990).", "startOffset": 140, "endOffset": 156}, {"referenceID": 14, "context": "5 ) ; the run time of the algorithms Snowball and Chleq\u2013APSP on these instances can therefore be bounded by O ( n2w\u22172.5 ) . To conclude this section, we remark that an alternative to a triangulation heuristic would be to use an approximation algorithm with a bound on the induced width that can be theoretically determined. For example, Bouchitt\u00e9, Kratsch, M\u00fcller, and Todinca (2004) give a O (logw\u2217) approximation of the treewidth w\u2217.", "startOffset": 50, "endOffset": 384}, {"referenceID": 35, "context": "Recently, an improvement was published over theO ( nm+ n2 log n ) algorithm based on Johnson\u2019s (1977) and Fredman and Tarjan\u2019s (1987) work: an algorithm for sparse directed graphs running in O ( nm+ n2 log log n ) time (Pettie, 2004).", "startOffset": 219, "endOffset": 233}, {"referenceID": 20, "context": "See (Dragan, 2005) for an overview and unification of such approaches.", "startOffset": 4, "endOffset": 18}, {"referenceID": 20, "context": "These represent a serious improvement over the O ( n3 ) bound on Floyd\u2013Warshall but do not profit from the fact that in most graphs that occur in practice, the number of edges m is significantly lower than n2. This profit is exactly what algorithms for sparse graphs aim to achieve. Recently, an improvement was published over theO ( nm+ n2 log n ) algorithm based on Johnson\u2019s (1977) and Fredman and Tarjan\u2019s (1987) work: an algorithm for sparse directed graphs running in O ( nm+ n2 log log n ) time (Pettie, 2004).", "startOffset": 65, "endOffset": 385}, {"referenceID": 20, "context": "These represent a serious improvement over the O ( n3 ) bound on Floyd\u2013Warshall but do not profit from the fact that in most graphs that occur in practice, the number of edges m is significantly lower than n2. This profit is exactly what algorithms for sparse graphs aim to achieve. Recently, an improvement was published over theO ( nm+ n2 log n ) algorithm based on Johnson\u2019s (1977) and Fredman and Tarjan\u2019s (1987) work: an algorithm for sparse directed graphs running in O ( nm+ n2 log log n ) time (Pettie, 2004).", "startOffset": 65, "endOffset": 417}, {"referenceID": 11, "context": "Chaudhuri and Zaroliagis (2000) present an algorithm for answering (point-topoint) shortest path queries with O ( w3 dn log n ) preprocessing time and query time O ( w3 d ) .", "startOffset": 0, "endOffset": 32}, {"referenceID": 11, "context": "Chaudhuri and Zaroliagis (2000) present an algorithm for answering (point-topoint) shortest path queries with O ( w3 dn log n ) preprocessing time and query time O ( w3 d ) . A direct extension of their results to APSP would imply a run time of O ( n2w3 d ) on general graphs and O ( nmw2 d ) on chordal graphs. Our result of computing APSP on general graphs in O ( nwd ) and in O (nm) on chordal graphs is thus a strict improvement. A large part of the state-of-the-art in point-to-point shortest paths is focused on road networks (with positive edge weights). These studies have a strong focus on heuristics, ranging from goal-directed search and bi-directional search to using or creating some hierarchical structure, see for example (Geisberger, Sanders, Schultes, & Delling, 2008; Bauer, Delling, Sanders, Schieferdecker, Schultes, & Wagner, 2008). One of these hierarchical heuristics has some similarities to the idea of using chordal graphs. This heuristic is called contraction. The idea there is to distinguish important (core) vertices, which may be possible end points, from vertices that are never used as a start or end point. These latter vertices are then removed (bypassed) one-by-one, connecting their neighbours directly. Other restrictions on the input graphs for which shortest paths are computed can also be assumed, and sometimes lead to algorithms with tighter bounds. For example, for unweighted chordal graphs, APSP lengths can be determined inO ( n2 ) time (Balachandhran & Rangan, 1996; Han, Sekharan, & Sridhar, 1997) if all pairs at distance two are known. See (Dragan, 2005) for an overview and unification of such approaches. Considering only planar graphs, recent work shows that APSP be found in O ( n2 log n ) (Klein, Mozes, & Weimann, 2010), which is an improvement over Johnson in cases where m \u2208 \u03c9 ( n log n ) . In the context of planning and scheduling, a number of similar APSP problems need to be computed sequentially, potentially allowing for a more efficient approach using dynamic algorithms. Even and Gazit (1985) provide a method where addition of a single edge can require O ( n2 ) steps, and deletion O ( n4/m ) on average.", "startOffset": 0, "endOffset": 2060}, {"referenceID": 11, "context": "Chaudhuri and Zaroliagis (2000) present an algorithm for answering (point-topoint) shortest path queries with O ( w3 dn log n ) preprocessing time and query time O ( w3 d ) . A direct extension of their results to APSP would imply a run time of O ( n2w3 d ) on general graphs and O ( nmw2 d ) on chordal graphs. Our result of computing APSP on general graphs in O ( nwd ) and in O (nm) on chordal graphs is thus a strict improvement. A large part of the state-of-the-art in point-to-point shortest paths is focused on road networks (with positive edge weights). These studies have a strong focus on heuristics, ranging from goal-directed search and bi-directional search to using or creating some hierarchical structure, see for example (Geisberger, Sanders, Schultes, & Delling, 2008; Bauer, Delling, Sanders, Schieferdecker, Schultes, & Wagner, 2008). One of these hierarchical heuristics has some similarities to the idea of using chordal graphs. This heuristic is called contraction. The idea there is to distinguish important (core) vertices, which may be possible end points, from vertices that are never used as a start or end point. These latter vertices are then removed (bypassed) one-by-one, connecting their neighbours directly. Other restrictions on the input graphs for which shortest paths are computed can also be assumed, and sometimes lead to algorithms with tighter bounds. For example, for unweighted chordal graphs, APSP lengths can be determined inO ( n2 ) time (Balachandhran & Rangan, 1996; Han, Sekharan, & Sridhar, 1997) if all pairs at distance two are known. See (Dragan, 2005) for an overview and unification of such approaches. Considering only planar graphs, recent work shows that APSP be found in O ( n2 log n ) (Klein, Mozes, & Weimann, 2010), which is an improvement over Johnson in cases where m \u2208 \u03c9 ( n log n ) . In the context of planning and scheduling, a number of similar APSP problems need to be computed sequentially, potentially allowing for a more efficient approach using dynamic algorithms. Even and Gazit (1985) provide a method where addition of a single edge can require O ( n2 ) steps, and deletion O ( n4/m ) on average. Thorup (2004) and Deme-", "startOffset": 0, "endOffset": 2187}, {"referenceID": 36, "context": "Above, we already mentioned the PC algorithm by Planken et al. (2008) for the single-shot case; Planken et al.", "startOffset": 48, "endOffset": 70}, {"referenceID": 36, "context": "Above, we already mentioned the PC algorithm by Planken et al. (2008) for the single-shot case; Planken et al. (2010) describe an algorithm that incrementally maintains the property of partial path consistency on chordal graphs in time linear in the number of edges.", "startOffset": 48, "endOffset": 118}, {"referenceID": 12, "context": "Cherkassky and Goldberg (1999) compared several innovative algorithms for singlesource shortest paths that gave better efficiency than the standard Bellman\u2013Ford algorithm in practice, while having the same worst-case bound of O (nm) on the run time.", "startOffset": 0, "endOffset": 31}, {"referenceID": 12, "context": "Cherkassky and Goldberg (1999) compared several innovative algorithms for singlesource shortest paths that gave better efficiency than the standard Bellman\u2013Ford algorithm in practice, while having the same worst-case bound of O (nm) on the run time. In future work, we will investigate if any of these clever improvements can also be exploited in Snowball. Snowball\u2013Separators can be improved further in a way that does not influence the theoretical complexity but may yield better performance in practice. Iterating over Vother can be seen as a reverse traversal of the part of the clique tree visited before, starting at c\u2019s parent. Then, instead of always using the separator between the current clique node (containing k) and its parent for all previously visited vertices in Vother, we can keep track of the smallest separator encountered during this backwards traversal for no extra asymptotic cost. Since it was shown in Table 1 that the largest minimal separator is often hardly smaller than the induced width, it might well pay off to search for smaller separators. We plan to implement this improvement in the near future. Another possible improvement is suggested by the following observation on DPC. A variant of DPC can be proposed where edge directionality is taken into account: during iteration k, only those neighbours i, j < k are considered for which there is a directed path i\u2192 k \u2192 j, resulting in the addition of the arc i\u2192 j. This set of added arcs would often be much smaller than twice the number of edges added by the standard DPC algorithm, and while the graph produced by the directed variant would not be chordal, the correctness of Snowball would not be impacted. Furthermore, we would like to also experimentally compare our algorithms to the recent algorithms by Pettie (2004) and the algorithms for graphs of constant treewidth by Chaudhuri and Zaroliagis (2000) in future work.", "startOffset": 0, "endOffset": 1808}, {"referenceID": 11, "context": "Furthermore, we would like to also experimentally compare our algorithms to the recent algorithms by Pettie (2004) and the algorithms for graphs of constant treewidth by Chaudhuri and Zaroliagis (2000) in future work.", "startOffset": 170, "endOffset": 202}], "year": 2012, "abstractText": "We present two new and efficient algorithms for computing all-pairs shortest paths. The algorithms operate on directed graphs with real (possibly negative) weights. They make use of directed path consistency along a vertex ordering d. Both algorithms run in O ( nwd ) time, where wd is the graph width induced by this vertex ordering. For graphs of constant treewidth, this yields O ( n ) time, which is optimal. On chordal graphs, the algorithms run in O (nm) time. In addition, we present a variant that exploits graph separators to arrive at a run time of O ( nw d + n sd ) on general graphs, where sd \u2264 wd is the size of the largest minimal separator induced by the vertex ordering d. We show empirically that on both constructed and realistic benchmarks, in many cases the algorithms outperform Floyd\u2013Warshall\u2019s as well as Johnson\u2019s algorithm, which represent the current state of the art with a run time of O ( n ) and O ( nm+ n log n ) , respectively. Our algorithms can be used for spatial and temporal reasoning, such as for the Simple Temporal Problem, which underlines their relevance to the planning and scheduling community.", "creator": "TeX"}}}