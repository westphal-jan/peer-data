{"id": "1401.4869", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jan-2014", "title": "Does Syntactic Knowledge help English-Hindi SMT?", "abstract": "In this paper we explore various parameter settings of the state-of-art Statistical Machine Translation system to improve the quality of the translation for a `distant' language pair like English-Hindi. We proposed new techniques for efficient reordering. A slight improvement over the baseline is reported using these techniques. We also show that a simple pre-processing step can improve the quality of the translation significantly.", "histories": [["v1", "Mon, 20 Jan 2014 11:49:11 GMT  (37kb)", "http://arxiv.org/abs/1401.4869v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["taraka rama", "karthik gali", "avinesh pvs"], "accepted": false, "id": "1401.4869"}, "pdf": {"name": "1401.4869.pdf", "metadata": {"source": "CRF", "title": "Does Syntactic Knowledge help English-Hindi SMT ?", "authors": ["Taraka Rama", "Karthik"], "emails": ["taraka@students.iiit.ac.in", "karthikg@students.iiit.ac.in", "avinesh@students.iiit.ac.in"], "sections": [{"heading": "1 Introduction", "text": "MOSES (Koehn et al., 2007), the SMT tool kit is widely used in machine translation experiments and also for the use of real-time systems. A glance at work published at major NLP conferences shows that the techniques are widely used not only between linguistically related European languages, but also between English-Arabic and English-Chinese, which are linguistically distant pairs. Some work has been done on machine translation of English-Hindi languages (Venkatapathy and Bangalore,), but there is much more to be researched. In this paper we propose new approaches to improve translation quality. the translation quality is evaluated on the basis of the widely used bleu metric (Papineni et al., 2001). We compare ourselves with the basic evaluation and report on the improvements."}, {"heading": "2 Scope for Improvement", "text": "We compare the Bleu score of English-hindi with English-German, English-French in Table 1. The Bleu score for the English-French and English-German language pairs was obtained from the Statistical Machine Translation Website1. For the English-Hindi pair, the Bleu score is shown as indicated in the Shared Task Website2. Differences in the size of training sets must be taken into account when reporting the Bleu score of the translated language pairs. At this point, we have only one reference translation. Ideally, the system needs to be compared with the multiple reference data, and then the Bleu score should be an average of all training units. An obvious reason for the lower Bleu score is the linguistic distance between the two languages. The problem underlying the larger differences between the individual reference data sets is the difference between the different reference data sets and then Bleu scores."}, {"heading": "3 Our Approach", "text": "Our hypothesis is that instead of trying to rearrange the target language using POS tags or giant language models or chunk language models, we should instead rearrange the words in the source language itself. Quality can also be improved by using richer and giant language models, which is an expensive process in itself. Especially for a language like English, which has high-quality syntactic parsers, it is always desirable to tap into these existing resources. Our modeling works like this: the core idea is that learning to rearrange relationships from the analysis of the source language sentence would yield better results. The source sentence is analyzed and therefore rearrange by rearranging the source-target relationships using POS tags on both sides. This scheme would ensure that the transfer rules learned are more general and therefore the intuition that they would improve the performance of the source language set. The second hypothesis concerns the presence of unknown words in the target language output."}, {"heading": "4 Data Sets and Baseline", "text": "We first examined various parameters of the MOSES to see how the quality improves. Training data for word alignment learning was performed on 7000 parallel corpus sentences provided in the Shared Task (taken from the EILMT corpus). We also checked how accuracy increases by increasing the size of the monolingual corpus on which the language model is trained. For the baseline, the following parameters were assumed: the distortion limit was left at 6 and the lexicalized reordering models were trained by msd-bidirectional-fe. The distortion limit shows how often the phrases are reordered. MOSES has both a distance-related reordering model and a lexicalized reordering model. Lexicalized reordering model provides the orientation of a sentence. The distortion limit is simply the absolute difference of the last word of the previously translated English sentence and the first word of the language model when the first phrase was trained in the 7000 language page."}, {"heading": "5 Initial Experiments", "text": "We observed that reducing the maximum phrase length does not improve the bleu score. We continued to test whether the lexicalized reorder models really contribute to the bleu score. We observed that removing the lexicalized order reduces the bleu score. We also played with the distortion limit parameter. We observed that allowing unlimited distortions improves the bleu score. Therefore, the distortion limit was always kept at -1 to allow for an unlimited reorder. We performed the following experiments. Note that all the experiments we performed can be categorized as pre-processing steps. The motive was to investigate whether we could tap into all available rich resources to achieve an improvement in the bleu score. Apart from experiments with parser and bilingual dictionary, we also checked whether all other pre-processing steps can be categorized as pre-processing steps."}, {"heading": "6 Results", "text": "The results were not good enough and did not even reach the baseline. Next, we tried to sketch another experiment with a different configuration of factor models to improve the translation, all in an attempt to improve the translation of the verbs. English verbs appear either as a single form or with the auxiliary before the main verb. In Hindi, the auxiliary verbs follow the main verb in the form of a copula at the end. For example, the \"is\" verb word is aligned to \"heM\" or \"hai\" or \"thA.\" We observed that the reordering of the preposition is fine. In all these experiments, we assumed that the word \"aligmnts\" is correct in a separate task."}, {"heading": "6.1 Learning reorderings from Parser", "text": "The goal was to include as much syntactical information as possible to influence the reorganization, so we tried to learn the rules of the reorganization that govern the reorganization from the parallel corpus. We wanted to tap the resources available for English as much as possible. Here, we used Libin's Dependency Saver (Shen, 2006) to learn the structure of the English sentence, then the target order is taken at the POS to learn the word order rules, these rules were then applied to the English training data, and then the training is done as usual, the following rules were learned."}, {"heading": "6.2 Dictionary Experiments", "text": "The root of the English words was simply replaced by the corresponding Hindi root, as part of the dictionary. When the bilingual dictionary was applied to the unknown words in the tuned output, there was no improvement in the Bleu score compared to the base model. However, an increase in the Bleu score was observed when the dictionary was used to replace the unknown words in the output of the reorder phase. Table 2 shows the results of this experiment. As expected, there was an increase in the Bleu score when the language model was trained using additional corpora."}, {"heading": "6.3 Preprocessing Experiments", "text": "The first experiment was to remove the end of the punctuation marks. We only removed the end of the punctuation markers of the declarative sentences. No other type of punctuation markers was removed, both at the training, development and test set. Markers can be added at the end after the translation is completed. This experiment improved the bleu score on the test set by 0.39. This experiment was conducted without any vote."}, {"heading": "6.4 Tuning", "text": "The adjustment was made using the Minimum Error Rate Training (Och, 2003) from the MOSES toolkit itself. We used the model that was trained on the data, removing the end-of-sentence markers for declarative sentences. The observed bleu score was 19.98. All of these experiments were performed on the language model trained on the training model. Further experiments must be performed on the larger monolingual corpora. Table 3 shows the results of the Ex-perimeters, which include the pre-processing steps."}, {"heading": "7 Observations", "text": "In the course of our expropriations, the following observations were made: the Bleu score did not show a significant improvement when the parser was used to rearrange the sentences on the source page; this refutes our original hypothesis that reordering the relationships learned during parsing would be more general and therefore improve performance; the other pre-processing techniques, such as using a bilingual dictionary, did not change the Bleu score; an interesting observation was that after removing the sentence and saving elsewhere, the Bleu score showed a significant increase from 17.70 to 18.09, which is a considerable improvement when we consider the naivety of this pre-processing step; an improvement of 12.8% over the baseline was observed after adjusting the base model to evolution and testing it on the test set."}, {"heading": "8 Future Directions", "text": "Based on the aforementioned initial experiments, we believe that the reordering of target language expressions will be significantly improved by tapping into the available resources for English. These experiments are just a first step towards improving the Bleu score and much more needs to be achieved."}], "references": [{"title": "Machine Translation: The Shakti Approach", "author": ["A. Bharati", "R. Moona", "P. Reddy", "B. Sankar", "D.M. Sharma", "R. Sangal."], "venue": "Pre-Conference Tutorial at ICON-2003: International Conference on Natu-", "citeRegEx": "Bharati et al\\.,? 2003", "shortCiteRegEx": "Bharati et al\\.", "year": 2003}, {"title": "Factored translation models", "author": ["P. Koehn", "H. Hoang."], "venue": "Proc. of the 2007 Conference on Empirical Methods in Natural Language Processing (EMNLP/Co-NLL).", "citeRegEx": "Koehn and Hoang.,? 2007", "shortCiteRegEx": "Koehn and Hoang.", "year": 2007}, {"title": "Statistical phrase-based translation", "author": ["P. Koehn", "F.J. Och", "D. Marcu."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, pages 48\u201354.", "citeRegEx": "Koehn et al\\.,? 2003", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Moses: Open Source Toolkit for Statistical Machine Translation", "author": ["P. Koehn", "H. Hoang", "A. Birch", "C. Callison-Burch", "M. Federico", "N. Bertoldi", "B. Cowan", "W. Shen", "C. Moran", "R. Zens"], "venue": null, "citeRegEx": "Koehn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2007}, {"title": "JOHNS HOPKINS UNIV BALTIMORE MD CENTER FOR LANGUAGE, and SPEECH PROCESSING (CLSP", "author": ["S. Kumar", "W. Byrne"], "venue": null, "citeRegEx": "Kumar and Byrne,? \\Q2004\\E", "shortCiteRegEx": "Kumar and Byrne", "year": 2004}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Franz Josef Och", "Hermann Ney."], "venue": "Computational Linguistics, 29(1):19\u201351.", "citeRegEx": "Och and Ney.,? 2003", "shortCiteRegEx": "Och and Ney.", "year": 2003}, {"title": "Minimum error rate training in statistical machine translation", "author": ["F.J. Och."], "venue": "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 160\u2013167. Association for Computational Linguistics Morristown,", "citeRegEx": "Och.,? 2003", "shortCiteRegEx": "Och.", "year": 2003}, {"title": "BLEU: a method for automatic evaluation of MT", "author": ["K. Papineni", "S. Roukos", "T. Ward", "WJ Zhu."], "venue": "Research Report, Computer Science RC22176 (W0109-022), IBM Research Division, TJ Watson Research Center, 17.", "citeRegEx": "Papineni et al\\.,? 2001", "shortCiteRegEx": "Papineni et al\\.", "year": 2001}, {"title": "STATISTICAL LTAG PARSING", "author": ["L. Shen."], "venue": "Ph.D. thesis, University of Pennsylvania.", "citeRegEx": "Shen.,? 2006", "shortCiteRegEx": "Shen.", "year": 2006}, {"title": "Srilm-an extensible language modeling toolkit, international conference spoken language processing", "author": ["A. Stolcke."], "venue": "SRI, Denver, Colorado, Tech. Rep.", "citeRegEx": "Stolcke.,? 2002", "shortCiteRegEx": "Stolcke.", "year": 2002}], "referenceMentions": [{"referenceID": 3, "context": "MOSES(Koehn et al., 2007), the SMT tool kit is used very frequently in the machine translation experiments and also for deploying real time systems.", "startOffset": 5, "endOffset": 25}, {"referenceID": 7, "context": "The translation quality is evaluated using the widely popular Bleu metric(Papineni et al., 2001).", "startOffset": 73, "endOffset": 96}, {"referenceID": 1, "context": "Two possible ways are factored models as given in(Koehn and Hoang, 2007) and using a bilingual dictionary to translate the lemmas and if the unknown word is a named entity then transliterate it.", "startOffset": 49, "endOffset": 72}, {"referenceID": 9, "context": "We have taken a language model of order 5 which was trained using SRILM toolkit(Stolcke, 2002).", "startOffset": 79, "endOffset": 94}, {"referenceID": 5, "context": "Further details can be obtained from (Och and Ney, 2003).", "startOffset": 37, "endOffset": 56}, {"referenceID": 0, "context": "the morphological analyzers developed as a part of SHAKTI project(Bharati et al., 2003) to extract the morph information and lemma and POS tags.", "startOffset": 65, "endOffset": 87}, {"referenceID": 8, "context": "Here we used Libin\u2019s dependency parser(Shen, 2006) to learn the structure of the english sentence.", "startOffset": 38, "endOffset": 50}, {"referenceID": 6, "context": "The tuning was done using the Minimum Error Rate Training(Och, 2003) provided in MOSES tool kit itself.", "startOffset": 57, "endOffset": 68}], "year": 2008, "abstractText": "In this paper we explore various parameter settings of the state-of-art Statistical Machine Translation system to improve the quality of the translation for a \u2019distant\u2019 language pair like English-Hindi. We proposed new techniques for efficient reordering. A slight improvement over the baseline is reported using these techniques. We also show that a simple pre-processing step can improve the quality of the translation significantly.", "creator": null}}}