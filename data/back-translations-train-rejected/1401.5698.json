{"id": "1401.5698", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Identification of Pleonastic It Using the Web", "abstract": "In a significant minority of cases, certain pronouns, especially the pronoun it, can be used without referring to any specific entity. This phenomenon of pleonastic pronoun usage poses serious problems for systems aiming at even a shallow understanding of natural language texts. In this paper, a novel approach is proposed to identify such uses of it: the extrapositional cases are identified using a series of queries against the web, and the cleft cases are identified using a simple set of syntactic rules. The system is evaluated with four sets of news articles containing 679 extrapositional cases as well as 78 cleft constructs. The identification results are comparable to those obtained by human efforts.", "histories": [["v1", "Wed, 15 Jan 2014 05:11:43 GMT  (1152kb)", "http://arxiv.org/abs/1401.5698v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yifan li", "petr musilek", "marek reformat", "loren wyard-scott"], "accepted": false, "id": "1401.5698"}, "pdf": {"name": "1401.5698.pdf", "metadata": {"source": "CRF", "title": "Identification of Pleonastic It Using the Web", "authors": ["Yifan Li", "Petr Musilek", "Marek Reformat", "Loren Wyard-Scott"], "emails": ["yifan@ece.ualberta.ca", "musilek@ece.ualberta.ca", "reform@ece.ualberta.ca", "wyard@ece.ualberta.ca"], "sections": [{"heading": "1. Introduction", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move into another world, in which they are able to move into another world, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they are able to live, in which they, in which they, in which they, in which they, in which they, in which they are"}, {"heading": "2. Previous Work", "text": "As Evans (2001) pointed out, their use is dealt with in most serious studies of English grammar, some of which (e.g. Sinclair, 1995) also contain classifications based on semantic categories. In a recent study, Gundel et al. (2005) classified the personal pronouns of third persons into the following comprehensive hierarchy: \u2022 noun phrase (NP) forerunners \u2022 Inferable \u2022 Non-NP forerunners - fact - statement - activity - event - situation - reason \u2022 Pleonastics - complete extraposition - complete split - traposition - drunken extraposition - atmospheric - other pleonastic \u2022 idioms \u2022 Exophorics \u2022 indeterminate Li, Musilek, Reformat, & Wyard-ScottWithout going into the details of each category, the length of the list indicates that the phenomenon of pleonastic splitting and general pronunciation without explicit nominal mittecents in the other category is an Aryan approach."}, {"heading": "2.1 Rule-based Approaches", "text": "The Paice and Husk approach uses bracket patterns such as.. to and it.. but those who have to comply with the syntactical constraints of extraposition and splitting are then evaluated by additional rules represented by word lists. For example, the rule dictates that one of the \"task status\" words, whether good or bad, must be present in the middle of the construct. To reduce false positives, general constraints are applied to sentence features such as construction length and intervening punctuation. Lappin and Leass's approach uses a set of more detailed rules, such as Modaladj being S and It being Cogv-ed being S, where Modaladj and Cogv are predefined lists of modal adjectives."}, {"heading": "2.2 Machine-learning Approaches", "text": "In recent years, there has been a shift toward machine learning approaches that shed new light on the subject. Studies by Evans (2001, 2000) and Boyd et al. (2005) are examples of this class. Both systems deal with memory-based learning based on grammatical trait vectors; however, Boyd et al. \"s approach also includes a decision tree algorithm that produces less ideal results. In his attempt to place applications of this kind in seven categories, including pleonastic and nominal anaphorical approaches, Evans uses 35 traits to encode information such as position / proximity, lemmas and part-of-speech that affect both the pronoun and other components of interest, such as words and noun phrases, in the sentence. Evans reported on 73.38% precision and 69.25% memory of binary classifications of pleonastic cases and a general binary classification of binary cases, and a general classification of binary phrases, and a general classification accuracy of 1.748%."}, {"heading": "3. A Web Based Approach", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...)"}, {"heading": "3.1 Preprocessing", "text": "The pre-processing component transforms the syntactical information embedded in natural-language texts into machine-comprehensible structures; during the pre-processing stage, each word is assigned a part-of-speech tag, and the entire sentence is analyzed using a dependency grammar parser (DG); for simplicity, the current system is designed to use the WSJ corpus, which is already labeled and analyzed with context-free grammar (CFG); a copy table similar to the one proposed by Collins (1999) is used to preserve the head component of each phrase; the rest of the phrase components are then compiled under the 4Metcalf and Barnhart (1999) a chronicle of many important additions to the vocabulary of American English; Li, Musilek, Reformat, & Wyard-Scotthead components form the Dependence Tree 2001, illustrating the structure of a WG tree (using the XG in detail)."}, {"heading": "3.2 Syntactic Filtering", "text": "The syntactic filtering process determines whether a clause meets the grammatical requirements of an extraposition or a column construct by matching the clause with its respective syntactic patterns."}, {"heading": "3.2.1 Extrapositions", "text": "It happens that a clause is introduced either without a complete clause (e.g. 37) or replaced with it. It usually follows the pattern: matrix clause (1) This pattern summarizes the general characteristics of the subject, it must either follow an adjective phrase in which the subject assumes the subject position. If the matrix verb (the verb that follows it) is the main coupling that serves to equate or associate the subject and a consequent logical predicate, it must be followed either by an adjective phrase or a prepositional phrase. 5 There is no specific requirement for the matrix-verb phrase. Likewise, there is almost no restriction placed on the clause."}, {"heading": "3.2.2 Cleft", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "3.2.3 Additional Filters", "text": "In addition to the patterns described in previous sections, a few additional filters will be installed to eliminate some semantically inappropriate constructs, thus reducing the number of trips to search engines. \u2022 For a clause to be identified as a subordinate clause and subsequently processed for extraposition or splitting, the number of commas, dashes and colons between the clause and it should be either zero or more than one, a rule adopted from the Paice and Husk proposal (1987). \u2022 Except for the copula that has to be, sentences with matrix verbs that appear in perfect form will not be considered for extraposition or splitting. \u2022 If it is the subject of multiple verbs, the sentence will not be considered for extraposition or for column. \u2022 Sentries that contain a noun phrase that appears logically along with a subordinate relative clause will not be considered for extraposition, either a column or a matrix."}, {"heading": "3.3 Using the Web as a Corpus", "text": "In fact, it is a purely mental game, in which the aim is to find a solution that is capable of finding a solution that meets the needs of the individual."}, {"heading": "3.4 Design of Search Engine Queries", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "3.4.2 Query Pattern II: Comparative Expletiveness Test", "text": "The second set of patterns provides a simplified representation of the original text in a few different flavors. After execution, the results of individual queries are compared to assess the explorability of the subject pronoun. This set of patterns takes the following general form: pronouns + verb phrases + simplified extraposed clause (6) The only difference between the individual patterns lies in the choice of the matrix term subject pronoun: es, who, this, and he. When the patterns are instantiated and submitted to a search engine, the number of hits from the it version should far exceed the number of other versions that are combined if the original text is an it-extraposition; otherwise, the number of hits should at least be comparable. This behavior reflects the explanatory character of the pronoun in an it-extraposition that invalidates the sentence when it is replaced by other versions."}, {"heading": "3.4.3 Query Pattern III: Missing-object Construction", "text": "This means that you can only search for text patterns that match a particular pattern, but not for sentences that end with a pattern string. Stubs used in Pattern II are generally useful to exclude sentences that are semantically incompatible with the original from search results, but in circumstances where no stub is linked to the queries (where the query results ideally consist of only sentences that end with the query string), the search engine can produce more results than necessary. Sentences that match the pattern that it + kopula + Missing Object Construction has, as it refers to a book, are easy to read. \"What is unique about the construction - and why special treatment is needed - is that a missing object construction has an It-Extraposition counterpart that contains the object, for example,\" it is easy to read the book. \""}, {"heading": "3.4.4 Query Instantiation", "text": "In view of the general design principles of the system, it is not advisable to instantiate the patterns with the original text in the way they relate to the structure of the original object; rather, it is the object of the matrix phrase in which it is used to achieve the desired level of obfuscation; the process of obfuscation leads to different versions based on the structure of the original object: only the header word is used. If the header word is not altered or too much, the modifier will also be able to maintain and maintain compatibility with the original text. \u2022 Common noun phrases: - with a possessive ending or preposition: the phrase is replaced by a header word."}, {"heading": "4. Case Study", "text": "To better illustrate the workings of the system, two sample sentences from the WSJ corpus are selected that go through the entire process: the first sample, [0231: 015], is classified as an It-Extraposition; the other, [0331: 033] (the previous sentence provides context), is a reference case with a nominal history; some details of implementation are also discussed here. [0231: 015] A life insurance company fund manager said three factors make it difficult to read the market direction. [0331: 032-033] Her current report classifies the stock as a \"hold,\" but it seems to be the kind of hold you make on the way to the door. Li, Musilek, Reformat, & W@-@ yard Scott"}, {"heading": "4.1 Syntactic Filtering", "text": "First, the syntactic structures of each sentence are identified and dependencies between the constituent parts are determined, as shown in Figures 3 and 4. Identification of Pleonastic It Using the WebIn sample sentence [0231: 015], making the explorative it represents as an object of the verb more difficult and followed by object completion, so a virtual copula (marked with VBX) is created in the dependency tree to treat it under the same framework as subject extrapositions. [0331: 033] generates two different readings - one assuming that it is the matrix verb (read A, c.f. Figure 4), the other taking it (read B). This is achieved by \"drilling down\" the verb chain that begins with the parent verb of the verb. Once at the top of the chain, the system begins a recursive process to find verbs and infinishes that are directly attached to the current nodes."}, {"heading": "4.2 Pattern Instantiation", "text": "The patterns II \u2032 -it and II \u2032 -other refer to the stripped-down versions (see section 3.4.4, page 359) of II-it and II \u2032 -other, respectively. The searches shown here are created specifically for Google and use features only available in Google. To use an alternative search engine such as Yahoo, the component extensions and determiner lists must be disabled and separate searches for individual pronouns must be prepared. To get accurate results, the searches must be double-quoted before they are sent to search engines. Li, Musilek, Reformat, & Wyard-Scott"}, {"heading": "4.3 Query Results and Classification", "text": "For each read, the number of results for each of the five queries (nw for pattern I; nit for II-it; nX for II-other; n \u2032 it for II-it; and n \u2032 X for II-other) is determined by the search engine; the first 10 results for the what-column query are also validated to obtain the estimated percentage (vw) of valid constructs. W (= nw \u00b7 vw), r (= nX / nit), r \u2032 (= n \u2032 X / n \u2032 it), and R (to choose between r \u2032 or r \u2032, depending on whether max (nit, nX) \u2265 10) are calculated accordingly, as in Table 6.What seems suspicious is that vw is set to 0 for reading [0331: 033].A, which means that no valid instances are found. A quick glance at the returned snippets shows that none of the 10 snippets actually scanned the requested contents."}, {"heading": "5. Evaluation", "text": "In order to give a comprehensive picture of the performance of the system, a double evaluation is applied in addition to the positive category. In the first evaluation, the system is subjected to the same set of sentences that supported its development. Accordingly, the results obtained from this evaluation reflect, to a certain extent, the optimal performance of the system. In the second evaluation, the performance of the system is shown on the basis of unknown texts by running the developed system on the basis of a random data set drawn from the rest of the corpus. Two additional experiments are also carried out to provide an assessment of the system performance over the entire corpus. Throughout the section, three performance measures are used: precision, recall and the balanced F-measure (van Rijsbergen, 1979). Precision is defined as the ratio of correctly classified instances in a particular category (or collection of categories) to the number of instances identified by the system as belonging to the category (categories)."}, {"heading": "5.1 Development Dataset", "text": "(.). (.). (.). (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).).\" (.). \"(.).\" (.).). \"(.).\" (.). \"(.).).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).).\" (.). \"(.).\" (.). \"(.).\" (.).). \"(.\" (.). \"(.).).\" (.). \"(.).\" (. \"(.).).).\" (.). \"(.).).\" (. \"(.).\" (.). \"(.).\" (.). \"(.).).\" (.).). \"(.).\" (.). \"(.).).).\" (.).). \"(.\" (.).).). \"(.\" (.).)."}, {"heading": "5.2 Baselines", "text": "In fact, it is such that most of them will be able to go into another world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "5.3 Results", "text": "The results produced by the proposed system are as follows: Li, Musilek, Reformat, & Wyard-ScottOther statistical significance tests show more information about the performance of the system compared to that of the two volunteers and the baselines: The use of the authors \"annotations as a reference, the system outperforms both human volunteers; while higher performance is usually desirable, in this particular case there may be potential problems in the conception of the experiment; since the English language is used not only by its speakers but also by the same group of people, it is unrealistic to have a system that\" speaks better English than its human counterparts. \"A plausible indication of the paradox is that an analytical approach is needed to gain insight into the issue of pronoun classification, but the casual English speakers do not see it from this perspective."}, {"heading": "5.4 System Performance on Parser Output", "text": "So far, the system has been evaluated on the assumption that the underlying phrases are tagged and analyzed with (almost) perfect accuracy; great efforts have been made to reduce this dependence; for example, information and function marks in the original phrase structures are intentionally discarded; and the system also tries to look for possible extraposition or split clauses that are labeled as additions to the matrix object. However, deficiencies in tagging and parsing can still affect the performance of the system. Occasionally, even the manual markups of the \"golden standard\" appear problematic and randomly get in the way of the task. 21The Simple Object Access Protocol is an XML-based messaging protocol for web services. Li, Musilek, Reformat, & Wyard-ScottIt is therefore necessary to evaluate the system on the basis of sentences that are automatically tagged and analyzed to answer the question of how well it would fare in the real world."}, {"heading": "5.5 Correlation Analysis for Extrapositions", "text": "Figures 5 to 8 illustrate the correlation between the decision factors and the true explanation of the pronoun in question. All 279 elements that passed the original syntactic filtering process are included in the dataset, with the first 116 being extrapositional and the rest separated by a fraction on the X axis. This arrangement is made to better visualize the contrast between the positive group and the negative group. Figures 6 to 8 use different grayscales to indicate the number of results returned by queries - the darker the shadow, the more popular the construct in question is on the Web. The constant Rexp = 0.15 is also indicated with a fraction on the Y axis. Li, Musilek, Reformat, & Wyard-ScottAs illustrates all factors identified in Section 3.5 are good indicators of eliness. W (Figure 5) is the weakest of the four factors due to the number of positives produced by false language."}, {"heading": "5.6 Generalization Study", "text": "The distribution of cases is comparable to that of the development dataset, as shown in Table 17.Li, Musilek, Reformat, & Wyard-ScottTable 19. The two (54 \u2212 52) false-positive extrapolations from the WSJ note are listed below along with their respective context: [1450: 054-055] Another solution that cities might consider is to give special priority to police patrolling small business areas. For cities that lose business to suburban malls, keeping those jobs and sales taxes within city limits may be a wise business investment. [1996: 061-062] You think you can go out and turn things around."}, {"heading": "5.6.1 Performance Analysis", "text": "In the test data set, the system is able to maintain its precision; it shows a slight deterioration in the recall, but overall performance is still within expectations. Results are summarized in Table 20,149 cases evaluated for the extraposition by means of queries covering 62 of the 63 extrapositions, but the excluded case is introduced in the form of a direct question, the details of which the syntactic processing subsystem is not prepared for. Of the other four false negatives, three relate to nomenclature words in the matrix object position. One of the two undetected columns results from imperfect processing in the corpus. Furthermore, the false positivity in the weather / time category is caused by the verb \"hail,\" which was treated by the system as a noun. All five (63 \u2212 58) false-negative extraposition tests are commented in the corpus."}, {"heading": "5.6.2 Estimated System Performance on the Whole Corpus", "text": "To compensate for this, an approximate study will be conducted. Firstly, instances throughout the corpus will be automatically processed using the proposed approach, but the identified identification of Pleonastic It Using the Webcleft instances will then be merged with those already commented on in the corpus to form a rating record of 84 sentences, which will then be manually verified. 76 instances out of the 84 are considered valid column constructs by the authors. Respectful performance of the proposed approach and WSJ annotation will be reported in Table 24; the differences will not be statistically significant. Three of the false positives produced by the proposed approach are actually extraposition22, which is expected (cf. footnote 12, page 351)."}, {"heading": "6. Discussion", "text": "In fact, most of them are able to survive on their own if they do not put themselves in a position to survive on their own."}], "references": [{"title": "Approximate is better than \u201cexact\u201d for interval estimation of binomial proportions", "author": ["A. Agresti", "B.A. Coull"], "venue": "The American Statistician,", "citeRegEx": "Agresti and Coull,? \\Q1998\\E", "shortCiteRegEx": "Agresti and Coull", "year": 1998}, {"title": "Bracketing guidelines for Treebank II style", "author": ["A. Bies", "M. Ferguson", "K. Katz", "R. MacIntyre"], "venue": "Tech. rep. MS-CIS-95-06,", "citeRegEx": "Bies et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Bies et al\\.", "year": 1995}, {"title": "Identifying non-referential it : A machine learning approach incorporating linguistically motivated patterns", "author": ["A. Boyd", "W. Gegg-Harrison", "D. Byron"], "venue": "In Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing,", "citeRegEx": "Boyd et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2005}, {"title": "Coarse-to-fine n-best parsing and maxent discriminative reranking", "author": ["E. Charniak", "M. Johnson"], "venue": "In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Charniak and Johnson,? \\Q2005\\E", "shortCiteRegEx": "Charniak and Johnson", "year": 2005}, {"title": "The statistical significance of the MUC-4 results", "author": ["N. Chinchor"], "venue": "Proceedings of the 4th conference on Message understanding (MUC4), pp. 30\u201350, San Mateo, CA. Morgan Kaufmann.", "citeRegEx": "Chinchor,? 1992", "shortCiteRegEx": "Chinchor", "year": 1992}, {"title": "Learning taxonomic relations from heterogeneous evidence", "author": ["P. Cimiano", "L. Schmidt-Thieme", "A. Pivk", "S. Staab"], "venue": "Frontiers in Artificial Intelligence and Applications,", "citeRegEx": "Cimiano et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Cimiano et al\\.", "year": 2005}, {"title": "Improving the identification of nonanaphoric it using support vector machines", "author": ["J.C. Clemente", "K. Torisawa", "K. Satou"], "venue": "In Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications (NLPBA/BioNLP04)", "citeRegEx": "Clemente et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Clemente et al\\.", "year": 2004}, {"title": "A coefficient of agreement for nominal scales", "author": ["J. Cohen"], "venue": "Educational and Psychological Measurement, 20 (1), 37\u201346.", "citeRegEx": "Cohen,? 1960", "shortCiteRegEx": "Cohen", "year": 1960}, {"title": "Head-Driven Statistical Models for Natural Language Parsing", "author": ["M. Collins"], "venue": "Ph.D. thesis, University of Pennsylvania.", "citeRegEx": "Collins,? 1999", "shortCiteRegEx": "Collins", "year": 1999}, {"title": "A constructional approach to clefts", "author": ["K. Davidse"], "venue": "Linguistics, 38 (6), 1101\u20131131.", "citeRegEx": "Davidse,? 2000", "shortCiteRegEx": "Davidse", "year": 2000}, {"title": "Bootstrap Methods and Their Application. Cambridge series on statistical and probabilistic mathematics", "author": ["A.C. Davison", "D.V. Hinkley"], "venue": null, "citeRegEx": "Davison and Hinkley,? \\Q1997\\E", "shortCiteRegEx": "Davison and Hinkley", "year": 1997}, {"title": "Automatic resolution of anaphora in English", "author": ["M. Denber"], "venue": "Tech. rep., Eastman Kodak Co.", "citeRegEx": "Denber,? 1998", "shortCiteRegEx": "Denber", "year": 1998}, {"title": "The kappa statistic: a second look", "author": ["B. Di Eugenio", "M. Glass"], "venue": "Computational Linguistics,", "citeRegEx": "Eugenio and Glass,? \\Q2004\\E", "shortCiteRegEx": "Eugenio and Glass", "year": 2004}, {"title": "An Introduction to the Bootstrap", "author": ["B. Efron", "R. Tibshirani"], "venue": null, "citeRegEx": "Efron and Tibshirani,? \\Q1993\\E", "shortCiteRegEx": "Efron and Tibshirani", "year": 1993}, {"title": "A comparison of rule-based and machine learning methods for identifying non-nominal it", "author": ["R. Evans"], "venue": "Christodoulakis, D. (Ed.), Proceedings of the 2nd International Conference on Natural Language Processing (NLP00), Vol. 1835 of Lecture Notes in Computer Science, pp. 233\u2013241, Berlin. Springer.", "citeRegEx": "Evans,? 2000", "shortCiteRegEx": "Evans", "year": 2000}, {"title": "Applying machine learning toward an automatic classification of it", "author": ["R. Evans"], "venue": "Literary and Linguistic Computing, 16 (1), 45\u201357.", "citeRegEx": "Evans,? 2001", "shortCiteRegEx": "Evans", "year": 2001}, {"title": "WordNet: An Electronic Lexical Database", "author": ["C. Fellbaum"], "venue": null, "citeRegEx": "Fellbaum,? \\Q1998\\E", "shortCiteRegEx": "Fellbaum", "year": 1998}, {"title": "Implicit and explicit grammar: An empirical study", "author": ["P.S. Green", "K. Hecht"], "venue": "Applied Linguistics,", "citeRegEx": "Green and Hecht,? \\Q1992\\E", "shortCiteRegEx": "Green and Hecht", "year": 1992}, {"title": "Pronouns without NP antecedents: How do we know when a pronoun is referential", "author": ["J. Gundel", "N. Hedberg", "R. Zacharski"], "venue": "Cognitive and Computational Modelling,", "citeRegEx": "Gundel et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Gundel et al\\.", "year": 2005}, {"title": "Where do cleft sentences come from", "author": ["J.K. Gundel"], "venue": "Language, 53 (3), 543\u2013559.", "citeRegEx": "Gundel,? 1977", "shortCiteRegEx": "Gundel", "year": 1977}, {"title": "For-to complement clauses in English: A cognitive grammar analysis", "author": ["Z. Hamawand"], "venue": "Studia Linguistica, 57 (3), 171\u2013192.", "citeRegEx": "Hamawand,? 2003", "shortCiteRegEx": "Hamawand", "year": 2003}, {"title": "Automatic acquisition of hyponyms from large text corpora", "author": ["M.A. Hearst"], "venue": "Proceedings of the 14th international conference on Computational Linguistics, pp. 539\u2013545.", "citeRegEx": "Hearst,? 1992", "shortCiteRegEx": "Hearst", "year": 1992}, {"title": "The Discourse Function of Cleft Sentences in English", "author": ["N. Hedberg"], "venue": "Ph.D. thesis, University of Minnesota.", "citeRegEx": "Hedberg,? 1990", "shortCiteRegEx": "Hedberg", "year": 1990}, {"title": "The referential status of clefts", "author": ["N. Hedberg"], "venue": "Language, 76 (4), 891\u2013920.", "citeRegEx": "Hedberg,? 2000", "shortCiteRegEx": "Hedberg", "year": 2000}, {"title": "It-extraposition in English: A functional view", "author": ["G. Kaltenb\u00f6ck"], "venue": "International Journal of Corpus Linguistics, 10 (2), 119\u2013159.", "citeRegEx": "Kaltenb\u00f6ck,? 2005", "shortCiteRegEx": "Kaltenb\u00f6ck", "year": 2005}, {"title": "Googleology is bad science", "author": ["A. Kilgarriff"], "venue": "Computational Linguistics, 33 (1), 147\u2013151.", "citeRegEx": "Kilgarriff,? 2007", "shortCiteRegEx": "Kilgarriff", "year": 2007}, {"title": "Introduction to the special issue on the Web as corpus", "author": ["A. Kilgarriff", "G. Grefenstette"], "venue": "Computational Linguistics,", "citeRegEx": "Kilgarriff and Grefenstette,? \\Q2003\\E", "shortCiteRegEx": "Kilgarriff and Grefenstette", "year": 2003}, {"title": "Bare NPs: Kind-referring, indefinites, both, or neither", "author": ["M. Krifka"], "venue": "Proceedings of Semantics and Linguistic Theory (SALT) XIII, New York, USA. CLC Publications.", "citeRegEx": "Krifka,? 2003", "shortCiteRegEx": "Krifka", "year": 2003}, {"title": "Content Analysis: An Introduction to Methodology", "author": ["K. Krippendorff"], "venue": "Sage Publications, Inc., Beverly Hills, USA.", "citeRegEx": "Krippendorff,? 1980", "shortCiteRegEx": "Krippendorff", "year": 1980}, {"title": "A framework for the analysis of cleft constructions", "author": ["K. Lambrecht"], "venue": "Linguistics, 39 (3), 463\u2013516.", "citeRegEx": "Lambrecht,? 2001", "shortCiteRegEx": "Lambrecht", "year": 2001}, {"title": "An algorithm for pronominal anaphora resolution", "author": ["S. Lappin", "H.J. Leass"], "venue": "Computational Linguistics,", "citeRegEx": "Lappin and Leass,? \\Q1994\\E", "shortCiteRegEx": "Lappin and Leass", "year": 1994}, {"title": "Building a large annotated corpus of English: the Penn Treebank", "author": ["M.P. Marcus", "M.A. Marcinkiewicz", "B. Santorini"], "venue": "Computational Linguistics,", "citeRegEx": "Marcus et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Comparing knowledge sources for nominal anaphora resolution", "author": ["K. Markert", "M. Nissim"], "venue": "Computational Linguistics,", "citeRegEx": "Markert and Nissim,? \\Q2005\\E", "shortCiteRegEx": "Markert and Nissim", "year": 2005}, {"title": "Using the web for nominal anaphora resolution", "author": ["K. Markert", "M. Nissim", "N.N. Modjeska"], "venue": "Proceedings of the EACL Workshop on the Computational Treatment of Anaphora,", "citeRegEx": "Markert et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Markert et al\\.", "year": 2003}, {"title": "America in So Many Words: Words That Have Shaped America", "author": ["A. Metcalf", "D.K. Barnhart"], "venue": null, "citeRegEx": "Metcalf and Barnhart,? \\Q1999\\E", "shortCiteRegEx": "Metcalf and Barnhart", "year": 1999}, {"title": "Outstanding issues in anaphora resolution", "author": ["R. Mitkov"], "venue": "Gelbukh, A. (Ed.), Proceedings of the 2nd International Conference on Computational Linguistics and Intelligent Text Processing (CICLing01), Vol. 2004 of Lecture Notes in Computer Science, pp. 110\u2013125, Berlin. Springer.", "citeRegEx": "Mitkov,? 2001", "shortCiteRegEx": "Mitkov", "year": 2001}, {"title": "A new, fully automatic version of Mitkov\u2019s knowledge-poor pronoun resolution method", "author": ["R. Mitkov", "R. Evans", "C. Orasan"], "venue": "Proceedings of the 3rd International Conference on Computational Linguistics and Intelligent Text Processing (CICLing02),", "citeRegEx": "Mitkov et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Mitkov et al\\.", "year": 2002}, {"title": "Automatic detection of nonreferential it in spoken multi-party dialog", "author": ["C. M\u00fcller"], "venue": "Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL06), pp. 49\u201356.", "citeRegEx": "M\u00fcller,? 2006", "shortCiteRegEx": "M\u00fcller", "year": 2006}, {"title": "On the surface syntax of constructions with easy-type adjectives", "author": ["D.L. Nanni"], "venue": "Language, 56 (3), 568\u2013581.", "citeRegEx": "Nanni,? 1980", "shortCiteRegEx": "Nanni", "year": 1980}, {"title": "Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution", "author": ["V. Ng", "C. Cardie"], "venue": "In Proceedings of the 19th international conference on Computational linguistics (COLING02),", "citeRegEx": "Ng and Cardie,? \\Q2002\\E", "shortCiteRegEx": "Ng and Cardie", "year": 2002}, {"title": "Computer-Intensive Methods for Testing Hypotheses : An Introduction", "author": ["E.W. Noreen"], "venue": "Wiley-Interscience, New York, USA.", "citeRegEx": "Noreen,? 1989", "shortCiteRegEx": "Noreen", "year": 1989}, {"title": "Towards the automatic recognition of anaphoric features in english text: the impersonal pronoun \u201cit", "author": ["C.D. Paice", "G.D. Husk"], "venue": "Computer Speech & Language,", "citeRegEx": "Paice and Husk,? \\Q1987\\E", "shortCiteRegEx": "Paice and Husk", "year": 1987}, {"title": "Learning accurate, compact, and interpretable tree annotation", "author": ["S. Petrov", "L. Barrett", "R. Thibaux", "D. Klein"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL (ACL06),", "citeRegEx": "Petrov et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2006}, {"title": "Acquiring lexical knowledge for anaphora resolution", "author": ["M. Poesio", "T. Ishikawa", "S.S. im Walde", "R. Vieira"], "venue": "In Proceedings of the Third International Conference on Language Resources and Evaluation,", "citeRegEx": "Poesio et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Poesio et al\\.", "year": 2002}, {"title": "Proper nouns in English", "author": ["C. Sloat"], "venue": "Language, 45 (1), 26\u201330.", "citeRegEx": "Sloat,? 1969", "shortCiteRegEx": "Sloat", "year": 1969}, {"title": "Information Retrieval (2nd edition)", "author": ["C.J. van Rijsbergen"], "venue": null, "citeRegEx": "Rijsbergen,? \\Q1979\\E", "shortCiteRegEx": "Rijsbergen", "year": 1979}, {"title": "Identification of Pleonastic", "author": ["F. Xia", "M. Palmer"], "venue": "In Proceedings of the first international conference on Human language technology research (HLT01),", "citeRegEx": "Xia and Palmer,? \\Q2001\\E", "shortCiteRegEx": "Xia and Palmer", "year": 2001}], "referenceMentions": [{"referenceID": 18, "context": "Applying criteria similar to those established by Gundel et al. (2005), the usage of it can be generally categorized as follows.", "startOffset": 50, "endOffset": 71}, {"referenceID": 19, "context": "Some claim that cleft pronouns should not be classified as expletive (Gundel, 1977; Hedberg, 2000).", "startOffset": 69, "endOffset": 98}, {"referenceID": 23, "context": "Some claim that cleft pronouns should not be classified as expletive (Gundel, 1977; Hedberg, 2000).", "startOffset": 69, "endOffset": 98}, {"referenceID": 14, "context": "As Evans (2001) pointed out, usage of it is covered in most serious surveys of English grammar, some of which (e.", "startOffset": 3, "endOffset": 16}, {"referenceID": 14, "context": "As Evans (2001) pointed out, usage of it is covered in most serious surveys of English grammar, some of which (e.g. Sinclair, 1995) also provide classifications based on semantic categories. In a recent study, Gundel et al. (2005) classify third-person personal pronouns into the following comprehensive hierarchy:", "startOffset": 3, "endOffset": 231}, {"referenceID": 35, "context": "However, despite being identified as one of the open issues of anaphora resolution (Mitkov, 2001), work on automatic identification of pleonastic it is relatively scarce.", "startOffset": 83, "endOffset": 97}, {"referenceID": 30, "context": "Paice and Husk (1987) together with Lappin and Leass (1994) provide examples of rulebased systems that make use of predefined syntactic patterns and word lists.", "startOffset": 36, "endOffset": 60}, {"referenceID": 16, "context": "Denber (1998) suggested using WordNet (Fellbaum, 1998) to extend the word lists, but it is doubtful how helpful this would be considering the enormous number of possible words that are not included in existing lists and the number of inapplicable words that will be identified by such an approach.", "startOffset": 38, "endOffset": 54}, {"referenceID": 39, "context": "For example, Paice and Husk (1987) noticed nearly a 10% decrease in accuracy when rules developed using one subset of the corpus are applied to another subset without modifications.", "startOffset": 13, "endOffset": 35}, {"referenceID": 39, "context": "For example, Paice and Husk (1987) noticed nearly a 10% decrease in accuracy when rules developed using one subset of the corpus are applied to another subset without modifications. Boyd, Gegg-Harrison, and Byron (2005) also observed a significant performance penalty when the approach was applied to a different corpus.", "startOffset": 13, "endOffset": 220}, {"referenceID": 11, "context": "Denber (1998) suggested using WordNet (Fellbaum, 1998) to extend the word lists, but it is doubtful how helpful this would be considering the enormous number of possible words that are not included in existing lists and the number of inapplicable words that will be identified by such an approach.", "startOffset": 0, "endOffset": 14}, {"referenceID": 2, "context": "Studies by Evans (2001, 2000) and Boyd et al. (2005) are examples of this class.", "startOffset": 34, "endOffset": 53}, {"referenceID": 2, "context": "Studies by Evans (2001, 2000) and Boyd et al. (2005) are examples of this class. Both systems employ memory-based learning on grammatical feature vectors; Boyd et al.\u2019s approach also includes a decision tree algorithm that produces less ideal results. In his attempt to place uses of it into seven categories, including pleonastic and nominal anaphoric among others, Evans uses 35 features to encode information such as position/proximity, lemmas, and part-of-speech, related to both the pronoun and other components of interest, such as words and noun phrases, in the sentence. Evans reported 73.38% precision and 69.25% recall for binary classification of pleonastic cases, and an overall binary classification accuracy of 71.48%. In a later study featuring MARS3, a fully automatic pronoun resolution system that employs the same approach, Mitkov, Evans, and Orasan (2002) reported a significantly higher binary classification accuracy of 85.", "startOffset": 34, "endOffset": 876}, {"referenceID": 2, "context": "Studies by Evans (2001, 2000) and Boyd et al. (2005) are examples of this class. Both systems employ memory-based learning on grammatical feature vectors; Boyd et al.\u2019s approach also includes a decision tree algorithm that produces less ideal results. In his attempt to place uses of it into seven categories, including pleonastic and nominal anaphoric among others, Evans uses 35 features to encode information such as position/proximity, lemmas, and part-of-speech, related to both the pronoun and other components of interest, such as words and noun phrases, in the sentence. Evans reported 73.38% precision and 69.25% recall for binary classification of pleonastic cases, and an overall binary classification accuracy of 71.48%. In a later study featuring MARS3, a fully automatic pronoun resolution system that employs the same approach, Mitkov, Evans, and Orasan (2002) reported a significantly higher binary classification accuracy of 85.54% when the approach is applied to technical manuals. Boyd et al.\u2019s (2005) approach targets pleonastic it alone.", "startOffset": 34, "endOffset": 1021}, {"referenceID": 2, "context": "Studies by Evans (2001, 2000) and Boyd et al. (2005) are examples of this class. Both systems employ memory-based learning on grammatical feature vectors; Boyd et al.\u2019s approach also includes a decision tree algorithm that produces less ideal results. In his attempt to place uses of it into seven categories, including pleonastic and nominal anaphoric among others, Evans uses 35 features to encode information such as position/proximity, lemmas, and part-of-speech, related to both the pronoun and other components of interest, such as words and noun phrases, in the sentence. Evans reported 73.38% precision and 69.25% recall for binary classification of pleonastic cases, and an overall binary classification accuracy of 71.48%. In a later study featuring MARS3, a fully automatic pronoun resolution system that employs the same approach, Mitkov, Evans, and Orasan (2002) reported a significantly higher binary classification accuracy of 85.54% when the approach is applied to technical manuals. Boyd et al.\u2019s (2005) approach targets pleonastic it alone. It uses 25 features, most of which concern lengths of specific syntactic structures; also included are part-of-speech information and lemmas of verbs. The study reports an overall precision of 82% and recall of 71%, and, more specifically, recalls on extrapositional and cleft constructs of 81% and 45%, respectively. In addition, Clemente, Torisawa, and Satou (2004) used support vector machines with a feature-set similar to that proposed by Evans (2001) to analyze biological and medical texts, and reported an overall accuracy of 92.", "startOffset": 34, "endOffset": 1427}, {"referenceID": 2, "context": "Studies by Evans (2001, 2000) and Boyd et al. (2005) are examples of this class. Both systems employ memory-based learning on grammatical feature vectors; Boyd et al.\u2019s approach also includes a decision tree algorithm that produces less ideal results. In his attempt to place uses of it into seven categories, including pleonastic and nominal anaphoric among others, Evans uses 35 features to encode information such as position/proximity, lemmas, and part-of-speech, related to both the pronoun and other components of interest, such as words and noun phrases, in the sentence. Evans reported 73.38% precision and 69.25% recall for binary classification of pleonastic cases, and an overall binary classification accuracy of 71.48%. In a later study featuring MARS3, a fully automatic pronoun resolution system that employs the same approach, Mitkov, Evans, and Orasan (2002) reported a significantly higher binary classification accuracy of 85.54% when the approach is applied to technical manuals. Boyd et al.\u2019s (2005) approach targets pleonastic it alone. It uses 25 features, most of which concern lengths of specific syntactic structures; also included are part-of-speech information and lemmas of verbs. The study reports an overall precision of 82% and recall of 71%, and, more specifically, recalls on extrapositional and cleft constructs of 81% and 45%, respectively. In addition, Clemente, Torisawa, and Satou (2004) used support vector machines with a feature-set similar to that proposed by Evans (2001) to analyze biological and medical texts, and reported an overall accuracy of 92.", "startOffset": 34, "endOffset": 1516}, {"referenceID": 2, "context": "Studies by Evans (2001, 2000) and Boyd et al. (2005) are examples of this class. Both systems employ memory-based learning on grammatical feature vectors; Boyd et al.\u2019s approach also includes a decision tree algorithm that produces less ideal results. In his attempt to place uses of it into seven categories, including pleonastic and nominal anaphoric among others, Evans uses 35 features to encode information such as position/proximity, lemmas, and part-of-speech, related to both the pronoun and other components of interest, such as words and noun phrases, in the sentence. Evans reported 73.38% precision and 69.25% recall for binary classification of pleonastic cases, and an overall binary classification accuracy of 71.48%. In a later study featuring MARS3, a fully automatic pronoun resolution system that employs the same approach, Mitkov, Evans, and Orasan (2002) reported a significantly higher binary classification accuracy of 85.54% when the approach is applied to technical manuals. Boyd et al.\u2019s (2005) approach targets pleonastic it alone. It uses 25 features, most of which concern lengths of specific syntactic structures; also included are part-of-speech information and lemmas of verbs. The study reports an overall precision of 82% and recall of 71%, and, more specifically, recalls on extrapositional and cleft constructs of 81% and 45%, respectively. In addition, Clemente, Torisawa, and Satou (2004) used support vector machines with a feature-set similar to that proposed by Evans (2001) to analyze biological and medical texts, and reported an overall accuracy of 92.7% \u2013 higher than that of their own memory-based learning implementation. Ng and Cardie (2002) built a decision tree for binary anaphoricity classification on all types of noun phrases (including pronouns) using the C4.", "startOffset": 34, "endOffset": 1690}, {"referenceID": 2, "context": "Studies by Evans (2001, 2000) and Boyd et al. (2005) are examples of this class. Both systems employ memory-based learning on grammatical feature vectors; Boyd et al.\u2019s approach also includes a decision tree algorithm that produces less ideal results. In his attempt to place uses of it into seven categories, including pleonastic and nominal anaphoric among others, Evans uses 35 features to encode information such as position/proximity, lemmas, and part-of-speech, related to both the pronoun and other components of interest, such as words and noun phrases, in the sentence. Evans reported 73.38% precision and 69.25% recall for binary classification of pleonastic cases, and an overall binary classification accuracy of 71.48%. In a later study featuring MARS3, a fully automatic pronoun resolution system that employs the same approach, Mitkov, Evans, and Orasan (2002) reported a significantly higher binary classification accuracy of 85.54% when the approach is applied to technical manuals. Boyd et al.\u2019s (2005) approach targets pleonastic it alone. It uses 25 features, most of which concern lengths of specific syntactic structures; also included are part-of-speech information and lemmas of verbs. The study reports an overall precision of 82% and recall of 71%, and, more specifically, recalls on extrapositional and cleft constructs of 81% and 45%, respectively. In addition, Clemente, Torisawa, and Satou (2004) used support vector machines with a feature-set similar to that proposed by Evans (2001) to analyze biological and medical texts, and reported an overall accuracy of 92.7% \u2013 higher than that of their own memory-based learning implementation. Ng and Cardie (2002) built a decision tree for binary anaphoricity classification on all types of noun phrases (including pronouns) using the C4.5 induction algorithm. Ng and Cardie reported overall accuracies of 86.1% and 84.0% on the MUC-6 and MUC-7 data sets. Categorical results, however, are not reported and it is not possible to determine the system\u2019s performance on pronouns. Using automatically induced rules, M\u00fcller (2006) reported an overall accuracy of 79.", "startOffset": 34, "endOffset": 2102}, {"referenceID": 21, "context": "The proposed approach is also inspired by Hearst\u2019s (1992) work on mining semantic relationships using text patterns, and many other quests that followed in the same direction (Berland & Charniak, 1999; Poesio, Ishikawa, im Walde, & Vieira, 2002; Markert, Nissim, & Modjeska, 2003; Cimiano, Schmidt-Thieme, Pivk, & Staab, 2005).", "startOffset": 42, "endOffset": 58}, {"referenceID": 8, "context": "A head percolation table similar to that proposed by Collins (1999) is used to obtain the head component of each phrase.", "startOffset": 53, "endOffset": 68}, {"referenceID": 46, "context": "head component to form the dependency tree using a procedure detailed by Xia and Palmer (2001). Figure 2 illustrates the syntactic structure of a sentence in the WSJ corpus.", "startOffset": 73, "endOffset": 95}, {"referenceID": 24, "context": "These constraints are developed by generalizing a small portion of the WSJ corpus and are largely in accordance with the patterns identified by Kaltenb\u00f6ck (2005). Compared to the patterns proposed by Paice and Husk (1987), which also cover cases such as it .", "startOffset": 144, "endOffset": 162}, {"referenceID": 24, "context": "These constraints are developed by generalizing a small portion of the WSJ corpus and are largely in accordance with the patterns identified by Kaltenb\u00f6ck (2005). Compared to the patterns proposed by Paice and Husk (1987), which also cover cases such as it .", "startOffset": 144, "endOffset": 222}, {"referenceID": 41, "context": "Neither insulting nor demeaning is in Paice and Husk\u2019s (1987) list of \u2018task status words\u2019 and therefore cannot activate the it .", "startOffset": 38, "endOffset": 62}, {"referenceID": 24, "context": "According to Kaltenb\u00f6ck\u2019s (2005) analysis there are special cases in which noun phrases appear as an extraposed component, such as \u2018It\u2019s amazing the number of theologians that sided with Hitler.", "startOffset": 13, "endOffset": 33}, {"referenceID": 22, "context": "Following Hedberg (1990), it-clefts can be expressed as follows:", "startOffset": 10, "endOffset": 25}, {"referenceID": 9, "context": "In an it-cleft construct, the cleft clause does not constitute a head-modifier relationship with the clefted constituent, but instead forms an existential and exhaustive presupposition8 (Davidse, 2000; Hedberg, 2000; Lambrecht, 2001).", "startOffset": 186, "endOffset": 233}, {"referenceID": 23, "context": "In an it-cleft construct, the cleft clause does not constitute a head-modifier relationship with the clefted constituent, but instead forms an existential and exhaustive presupposition8 (Davidse, 2000; Hedberg, 2000; Lambrecht, 2001).", "startOffset": 186, "endOffset": 233}, {"referenceID": 29, "context": "In an it-cleft construct, the cleft clause does not constitute a head-modifier relationship with the clefted constituent, but instead forms an existential and exhaustive presupposition8 (Davidse, 2000; Hedberg, 2000; Lambrecht, 2001).", "startOffset": 186, "endOffset": 233}, {"referenceID": 27, "context": "The validity of this assertion is under debate (Krifka, 2003).", "startOffset": 47, "endOffset": 61}, {"referenceID": 43, "context": "Sloat\u2019s (1969) account.", "startOffset": 0, "endOffset": 15}, {"referenceID": 41, "context": "\u2022 For a clause to be identified as a subordinate clause and subsequently processed for extraposition or cleft, the number of commas, dashes and colons between the clause and it should be either zero or more than one, a rule adopted from Paice and Husk\u2019s (1987) proposal.", "startOffset": 237, "endOffset": 261}, {"referenceID": 25, "context": "As Kilgarriff and Grefenstette (2003) pointed out, following the definition of", "startOffset": 3, "endOffset": 38}, {"referenceID": 31, "context": "In Markert and Nissim\u2019s (2005) recent study evaluating different knowledge sources for anaphora resolution, the web-based method achieves far higher recall ratio than those that are BNC- and WordNet-based, while at the same time yielding slightly lower precision.", "startOffset": 3, "endOffset": 31}, {"referenceID": 25, "context": "As also suggested by Kilgarriff (2007) and many others, it is technically more difficult to exploit the web than to use a local corpus and it can often be dangerous to rely solely on statistics provided by commercial search engines.", "startOffset": 21, "endOffset": 39}, {"referenceID": 20, "context": "According to Hamawand (2003), the for .", "startOffset": 13, "endOffset": 29}, {"referenceID": 23, "context": "Kaltenb\u00f6ck (2005) noted that the percentage of extrapositional it constructs carrying new information varies greatly depending on the category of the text.", "startOffset": 0, "endOffset": 18}, {"referenceID": 19, "context": "What-clefts, according to Gundel (1977), from which the it-clefts are derived, have the same existential and exhaustive presuppositions carried by their it-cleft counterparts.", "startOffset": 26, "endOffset": 40}, {"referenceID": 38, "context": "The first pattern, the compound adjective test, is inspired by Nanni\u2019s (1980) study considering the easy-type adjective followed by an infinitive (also commonly termed tough construction) as a single complex adjective.", "startOffset": 63, "endOffset": 78}, {"referenceID": 40, "context": "When two systems are compared, an approximate randomization test (Noreen, 1989) similar to that used by Chinchor (1992) is performed to determine if the difference is of statistical significance.", "startOffset": 65, "endOffset": 79}, {"referenceID": 12, "context": "Following Efron and Tibshirani\u2019s (1993) Bootstrap method, 95% confidence intervals are obtained using the 2.", "startOffset": 10, "endOffset": 40}, {"referenceID": 4, "context": "When two systems are compared, an approximate randomization test (Noreen, 1989) similar to that used by Chinchor (1992) is performed to determine if the difference is of statistical significance.", "startOffset": 104, "endOffset": 120}, {"referenceID": 7, "context": "The degree of agreement between the annotators, measured by the kappa coefficient (\u03ba; Cohen, 1960), is also given in the same table.", "startOffset": 82, "endOffset": 98}, {"referenceID": 28, "context": "Since the distribution of the it instances in the dataset is fairly unbalanced, the commonly-accepted guideline for interpreting \u03ba values (\u03ba > 0.67 and \u03ba > 0.8 as thresholds for tentative and definite conclusions respectively; Krippendorff, 1980) may not be directly applicable in this case.", "startOffset": 138, "endOffset": 246}, {"referenceID": 12, "context": "As Di Eugenio and Glass (2004) and others pointed out, skewed distribution of the categories has a negative effect on the \u03ba value.", "startOffset": 6, "endOffset": 31}, {"referenceID": 41, "context": "Two baselines are available for comparison \u2013 the WSJ annotation, which is done manually and provided with the corpus; and the results from a replication of Paice and Husk\u2019s (1987) algorithm (PHA).", "startOffset": 156, "endOffset": 180}, {"referenceID": 40, "context": "As expected, Paice and Husk\u2019s (1987) algorithm does not perform very well since the WSJ articles are very different from, and tend to be more sophisticated than, the technical essays that the algorithm was designed for.", "startOffset": 13, "endOffset": 37}, {"referenceID": 2, "context": "The performance of the replica is largely in line with what Boyd et al. (2005) obtained from their implementation of the same algorithm on a different dataset.", "startOffset": 60, "endOffset": 79}, {"referenceID": 1, "context": "By stating that the \u2018Characteristic of it extraposition is that the final clause can replace it\u2019, Bies et al. (1995) define the class in the narrowest sense.", "startOffset": 98, "endOffset": 117}, {"referenceID": 41, "context": "The Paice and Husk (1987) algorithm suffers from false-positive it .", "startOffset": 4, "endOffset": 26}, {"referenceID": 41, "context": "\u2022 Compared to Paice and Husk\u2019s (1987) algorithm, the system\u2019s higher precision is statistically significant.", "startOffset": 14, "endOffset": 38}, {"referenceID": 17, "context": "As Green and Hecht (1992) and many others indicated, capable users of a language do not necessarily have the ability to formulate linguistic rules.", "startOffset": 3, "endOffset": 26}, {"referenceID": 3, "context": "Two state-of-the-art parsers are employed for this study: the reranking parser by Charniak and Johnson (2005), and the Berkeley parser by Petrov, Barrett, Thibaux, and Klein (2006).", "startOffset": 82, "endOffset": 110}, {"referenceID": 3, "context": "Two state-of-the-art parsers are employed for this study: the reranking parser by Charniak and Johnson (2005), and the Berkeley parser by Petrov, Barrett, Thibaux, and Klein (2006). The system\u2019s performance on their respective interpretations of the development dataset sentences are reported in Tables 14 and 15.", "startOffset": 82, "endOffset": 181}, {"referenceID": 41, "context": "\u2022 regardless of the parser used, the system outperforms the Paice and Husk (1987) algorithm.", "startOffset": 60, "endOffset": 82}, {"referenceID": 41, "context": "\u2022 the system outperforms the Paice and Husk (1987) algorithm, and the difference is statistically significant.", "startOffset": 29, "endOffset": 51}, {"referenceID": 18, "context": "This is clearly manifested by the existence of truncated extrapositions (Gundel et al., 2005), which obviously have valid referential readings.", "startOffset": 72, "endOffset": 93}], "year": 2009, "abstractText": "In a significant minority of cases, certain pronouns, especially the pronoun it, can be used without referring to any specific entity. This phenomenon of pleonastic pronoun usage poses serious problems for systems aiming at even a shallow understanding of natural language texts. In this paper, a novel approach is proposed to identify such uses of it : the extrapositional cases are identified using a series of queries against the web, and the cleft cases are identified using a simple set of syntactic rules. The system is evaluated with four sets of news articles containing 679 extrapositional cases as well as 78 cleft constructs. The identification results are comparable to those obtained by human efforts.", "creator": "LaTeX with hyperref package"}}}