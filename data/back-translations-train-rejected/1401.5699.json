{"id": "1401.5699", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Text Relatedness Based on a Word Thesaurus", "abstract": "The computation of relatedness between two fragments of text in an automated manner requires taking into account a wide range of factors pertaining to the meaning the two fragments convey, and the pairwise relations between their words. Without doubt, a measure of relatedness between text segments must take into account both the lexical and the semantic relatedness between words. Such a measure that captures well both aspects of text relatedness may help in many tasks, such as text retrieval, classification and clustering. In this paper we present a new approach for measuring the semantic relatedness between words based on their implicit semantic links. The approach exploits only a word thesaurus in order to devise implicit semantic links between words. Based on this approach, we introduce Omiotis, a new measure of semantic relatedness between texts which capitalizes on the word-to-word semantic relatedness measure (SR) and extends it to measure the relatedness between texts. We gradually validate our method: we first evaluate the performance of the semantic relatedness measure between individual words, covering word-to-word similarity and relatedness, synonym identification and word analogy; then, we proceed with evaluating the performance of our method in measuring text-to-text semantic relatedness in two tasks, namely sentence-to-sentence similarity and paraphrase recognition. Experimental evaluation shows that the proposed method outperforms every lexicon-based method of semantic relatedness in the selected tasks and the used data sets, and competes well against corpus-based and hybrid approaches.", "histories": [["v1", "Wed, 15 Jan 2014 05:41:08 GMT  (324kb)", "http://arxiv.org/abs/1401.5699v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["george tsatsaronis", "iraklis varlamis", "michalis vazirgiannis"], "accepted": false, "id": "1401.5699"}, "pdf": {"name": "1401.5699.pdf", "metadata": {"source": "CRF", "title": "Text Relatedness Based on a Word Thesaurus", "authors": ["George Tsatsaronis", "Iraklis Varlamis", "Michalis Vazirgiannis"], "emails": ["GBT@IDI.NTNU.NO", "VARLAMIS@HUA.GR", "MVAZIRG@AUEB.GR"], "sections": [{"heading": null, "text": "Taking into account a wide range of factors related to the meaning conveyed by the two fragments and the paired relationships between their words, there is no doubt that a measure of relationship between text segments can take into account both the lexical and semantic relationship between words. Such a measure, which well captures both aspects of text referentiality, can be useful for many tasks, such as retrieving, classifying and clustering texts. In this paper, we introduce a new approach to measuring the semantic relationship between words based on their implicit semantic linkages, using only one word thesaurus to develop implicit semantic linkages between words. On the basis of this approach, we introduce omiotis, a new measure of semantic relationship between texts that relies on the word-to-word semantic relationship measure (SR), and extends it to measure the relationship between texts."}, {"heading": "1. Introduction", "text": "This year, it has reached the point where it will be able to leave the country in which it is located, unless it is able to take it in its hands."}, {"heading": "2. Preliminaries and Related Work", "text": "Our approach uses a word thesaurus to define a measure of semantic references between words, and extends this measure to the calculation of text references under both semantic and 1. Omiotis is the Greek word for references or similarities. 2. http: / / www.aclweb.org / aclwiki / index.php? title = SAT _ Analogy _ Questionslexical information. To facilitate understanding of our methodology, we will work out preliminary concepts and present related research approaches in this section."}, {"heading": "2.1 Word Thesauri and their use in Text Applications", "text": "This year it has come to the point that it is a purely reactionary project, in which it is a reactionary project, in which it is a reactionary, reactionary and reactionary project."}, {"heading": "2.2 Creating Semantic Networks from Word Thesauri", "text": "Omiotis is based on the creation of semantic paths between words in a text using the concepts and relationships of the thesaurus. Early approaches in this area used glossy words from the respective word definitions to form semantic networks from the text (Veronis & Ide, 1990). The idea of presenting text as a semantic network was originally introduced by Quilian (1969).The expansion of WordNet with semantic relationships that intersect parts of the language has added more possibilities of semantic network construction from the text. Recent approaches to semantic network construction from word thesauri by Mihalcea, Tarau and Figa (2004) and Navigli (2008) utilize a wide range of semantic relationships instead of glossy words, methods that surpassed previous methods that used semantic networks from the words thesauri, Mihalcea, Tarau and Figa (2004) and Navigli (2008), which used semantic high-glossy relationships."}, {"heading": "2.3 Measures of Semantic Relatedness", "text": "This year, it has reached the stage where it will be able to achieve the objectives mentioned, in the way in which it is able to achieve its objectives, in the way in which it is able to achieve its objectives."}, {"heading": "3. Measuring Word-to-Word and Text-to-Text Semantic Relatedness", "text": "In this section, the details of Omiotis, our measure of semantic text references, are presented. The measure uses the idea of semantic relatedness between WordNet senses, extending it to the calculation of the relatedness between words and finally between texts. Since the definition of semantic relatedness ranges from pairs of keyword senses to text pairs, Omiotis is defined so that the relatedness is captured in any granularity. As a result, it can be used in a wide range of linguistic and text related tasks such as WSD, word relatedness and word analogy, text relatedness and keyword ranking. The key points of the proposed measure are: (a) it constructs semantic links between all the senses of words in WordNet and calculates a relatedness between each pair of WordNet senses, (b) it calculates semantic relatedness for a few by giving some terms depending on their meaning or importance."}, {"heading": "3.1 Construct Semantic Links between Words", "text": "The first step in measuring the semantic relationship between two text fragments is to find the implicit semantic connections between the words of the two fragments. Therefore, we present a definition of the semantic relationship for a pair of thesaurus concepts that takes into account the semantic path that connects the concepts and extends it to measure the relationship between words. To solve the problem of constructing semantic paths between words, we are based on our previous method of constructing semantic networks between words (Tsatsaronis et al., 2007)."}, {"heading": "3.1.1 SEMANTIC NETWORK CONSTRUCTION FROM WORD THESAURI", "text": "Figure 1 gives an example of the construction of a semantic network for two words ti and tj. For the sake of simplicity, we assume the construction of a semantic path between the senses S.i.2 and S.j.1 (Initial Phase), although we could do the same for any possible combination of the two senses. First, the two sensory nodes are extended with all the semantic links offered by WordNet. The semantic links of the senses, as found in the thesaurus, become the edges and the pointed senses the nodes of the network (Network Expansion). The expansion process repeats itself recursively until the shortest 4-path between S.i.2 and S.j.1 is found. If no path is found from S.i.2 to S.j.1, then the senses and consequently the words are not semantically related."}, {"heading": "3.1.2 SEMANTIC RELATEDNESS BETWEEN A PAIR OF CONCEPTS", "text": "This year, it is more than ever before that it will be able to take the lead."}, {"heading": "3.1.3 SEMANTIC RELATEDNESS FOR A PAIR OF TERMS", "text": "Based on definition 3, which measures the semantic relationship between a pair of senses S, we can define the semantic relationship between a pair of terms T (t1, t2) as follows. Definition 4 Let us leave a word thesaurus O, let us let T = (t1, t2) be a pair of terms for which there are entries in O, let us leave X1 the set of senses of t1 and X2 the set of senses of t2 in O. Let us leave S1, S2,..., S | X1 | | X2 | be the set of senses, Sk = (si, sj), with si-X1 and sj-X2. Now the semantic relationship of T (SR (T, S, O) is defined as: maxSk {SCM (Sk, O, P) \u00b7 SPE (Sk, P) = maxk-SR (SR, S, O)."}, {"heading": "3.2 Analysis of the SR Measure", "text": "In this section, we will explain the reasons behind the definitions 1, 2 and 3, providing theoretical and / or experimental evidence for the decisions to design the measure. We will illustrate the advantages and disadvantages of the various alternatives using simple examples and argue for our decisions. Finally, we will discuss the advantages of the SR over previous semantic references. The list of decisions taken to design our semantic references includes: a) the use of senses in all POS areas instead of just nouns, b) the use of all semantic references found in WordNet instead of the pure IS-A relationship, c) the use of edge weights and d) the use of depth of senses as a scaling factor. It is important to note that measures of semantic references differ from those of semantic similarity that traditionally use only hierarchical relationships and ignore all other types of semantic relationships."}, {"heading": "3.2.1 USE ALL POS INFORMATION", "text": "First, we argue on the fact that the use of all POS is important in shaping a semantic kinship measure, and may increase the scope of such a measure. The rationale behind this decision is relatively simple. Current datasets for evaluating semantic kinship or even semantic similarity measures are limited to nouns, such as the Rubenstein and Goodenough 65 word pairs (1965), the Miller and Charles 30 word pairs (1991), and the Word Similarity 353 Collection (Finkelstein et al., 2002). Thus, the experimental evaluation in these datasets cannot show the reservation of omitting the remaining parts of the speech. However, text similarities include tasks and their benchmark datasets more than nouns. During the following analysis, the reader must bear in mind that the resulting measure is determined semantic kinship between words."}, {"heading": "3.2.2 USE EVERY TYPE OF SEMANTIC RELATIONS", "text": "The decision to use all parts of language in the construction of semantic graphs, as introduced in our previous paper (Tsatsaronis et al., 2007), imposes the inclusion of all semantic relationships, rather than merely taxonomic (IS-A) relationships. Furthermore, this decision is based on evidence from related literature. Smeaton et al. (1995) provides experimental evidence that measuring semantic similarity by including non-hierarchical link types (i.e. part meronym / holonym, member meronym / holonym, substance meronym / holonym) significantly improves the performance of such a measure. Experimental evaluation was carried out by adopting a small variation of the Resnik measure (1995). Hirst and St-Onge (1998) reported having discovered several limitations and missing connections in the series of WordNet relationships during the construction of lexical chains for detecting and correcting malapropisms."}, {"heading": "3.2.3 USE WEIGHTS ON EDGES", "text": "The work of Resnik (1999) reports that simple edge counting, which implicitly assumes that linkages represent uniform distances in taxonomy, is problematic and is not the best semantic distance measure for WordNet. Similarly, the findings of Sussna (1993), who conducted a thorough experimental evaluation by variation of edge weights to measure the semantic distance between concepts, go in the same direction. Sussna's results showed that semantic edge weights are a not negligible factor in applying his measure to WSD, and that the best results were reported when an edge weighting scheme was used rather than assigning the same weight to each edge. For all these reasons, we decided to assign a weight to each edge type, and chose the simple probability of occurrence for each edge type in WordNet as our edge weighting scheme (see Table 1). This very important factor is missing in several measurement measures proposed in the past by Jaracock (such as those proposed in 1998)."}, {"heading": "3.2.4 USE DEPTH SCALING FACTOR", "text": "Our decision to include the depth scaling factor (SPE in definition 2) in the edge weighting mechanism was inspired by the thorough experimental evaluation by Sussna (1993), which provided evidence of the importance of the edge weighting factor in semantic network-based metrics. According to our experiments with the Millern and Charles data, the Spearman correlation with human judgement was much lower (7 percentage points) than when the SPE factor was adopted (see definition 3)."}, {"heading": "3.2.5 JUSTIFICATION OF SR DEFINITIONS", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "3.3 Omiotis", "text": "To quantify the degree to which two segments of text relate semantically to each other, we build on the SR measurement, which we expand significantly to take into account not only the semantic relativization, but also its lexical similarity. This is because texts may contain overly specialized terms (e.g. an algorithm name) that are not represented in WordNet. Therefore, it is possible to refer fully to the term semantics to determine the degree to which texts would relate to each other. On the other hand, semantics serve as a supplement to our relevance, as other text terms may refer to (nearly) identical concepts. To quantify the lexical similarity between two texts, e.g. text A and B, we start by estimating the meaning of the terms, as they are determined by the standard TF-IDF weighting scheme."}, {"heading": "3.4 Applications of Semantic Relatedness", "text": "In this section we describe the methodology of integrating semantic relationships between pairs of words or text segments into different applications."}, {"heading": "3.4.1 WORD-TO-WORD SIMILARITY", "text": "Rubenstein and Goodenough (1965) received synonymous judgments from 51 human subjects on 65 pairs of words, in an effort to investigate the relationship between context similarity and similarity of meaning (synonymy). Since then, the idea of evaluating the yardsticks of semantic kinship introduced in Definition 4 by comparing them to human judgments on specific pairs of words has become widespread, and even more data sets have been developed. The proposed measure of semantic kinship between words (SR) can be directly used in such a task to evaluate the basis of the omiotis measure, which is the measurement of semantic kinship from word to word. Application is simple: take all word pairs in the word similarity data used, and then calculate the semantic kinship for each pair, defining SR (T, S, O) as in 4."}, {"heading": "3.4.2 SAT ANALOGY TESTS", "text": "The problem of identifying similarities in word analogies between pairs of words is a difficult problem and it has been standardized as a test for assessing the human ability to understand language (A). (A). (A)."}, {"heading": "3.4.3 PARAPHRASE RECOGNITION AND SENTENCE-TO-SENTENCE SIMILARITY", "text": "The performance of applications that rely on natural language processing may suffer from the fact that the processed documents contain lexically different but semantically related text segments; the task itself is important for many text-related applications, such as abstracting (Hirao, Fukusima, Oku-mura, Nobata, & Nanba, 2005), information extraction (Shinyama & Sekine, 2003) and answering questions (Pasca, 2003); and we are experimentally evaluating the use of omiotis in the paraphrasing recognition task (Section 4.2) using the Microsoft Research Paraphrase Corpus (Dolan et al., 2004) and the use of omiotis in the paraphrasing recognition task."}, {"heading": "3.5 Complexity and Implementation Issues", "text": "This year it will be so far that it will be able to erect the aforementioned rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc-the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc-the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rfu the rfu the rfu the rfu-the rfu-the rfu-the rfu-the rfu-the ru-the rfu-the ru-the ru-the ru-the ru-the rfu-the ru-the ru-the ru-the ru-the ru-u-the ru-the ru-the ru-u-the ru-the ru-the ru-u-the ru-the ru-the ru-u-the ru-u-the ru-the ru-the ru-the ru-the ru-u-the ru-the ru-the ru-u-the ru-the ru-the ru-the ru-the ru the ru-the ru the ru-the ru-the ru-the ru-the ru-the ru-the ru the ru the ru the ru-the ru the ru-the ru-the ru the ru the ru the ru the ru the ru-the ru the ru-the ru the ru the ru the ru the ru the ru-"}, {"heading": "4. Experimental Evaluation", "text": "The experimental evaluation of omotis takes place in two areas: first, we test the performance of the semantic word-to-word relationship (SR) on which omotis is based in three types of tasks: (a) word-to-word similarity and kinship, (b) synonym identification and (c) scholastic aptitude test (SAT); second, we evaluate the performance of omotis in two tasks: (a) sentence-to-sentence similarity and (b) the paraphrase recognition task."}, {"heading": "4.1 Evaluation of the Semantic Relatedness (SR) Measure", "text": "The first category includes data sets containing pairs of words for which human subjects provided similarity values or similarity values. In this task, we evaluate the performance of SR in three benchmark data sets, namely the Rubenstein and Goodenough 65 word pairs (1965) (R & G) and the Miller and Charles 30 word pairs (1991) (M & C), for which humans provided similarity values, and also in the Word Similarity 353 Collection (Finkelstein et al., 2002) the synonym selection of synonym questions."}, {"heading": "4.1.1 EVALUATION ON SEMANTIC SIMILARITY AND RELATEDNESS", "text": "For the first category of experiments, we compared our metrics with ten known metrics of semantic kinship (including our own metrics): Hirst and St-Onge (1998) (HS), Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Jarmasz and Szpakowicz (2003) (JS), Gabrilovich and Markovitch (2007, 2009) (GM), Milne and Witten (2008) (WLM), Finkelstein et al. (2002) (LSA), Hughes and Ramage (2007) (HR) and Strube and Ponzetto (2006, 2007a) (SP). For the measurement of Strube and Ponzetto, we also included the results of a version of the metrics based only on IS-A relations (IS-A, 2007b) (IS-SP)."}, {"heading": "4.1.2 EVALUATION ON SYNONYM IDENTIFICATION", "text": "For the synonym identification task, we use the TOEFL 80 question dataset and the ESL 50 question dataset. For the TOEFL dataset, we compare with several other methods. Specifically, we examine: the lexicon-based measurements by Leacock et al. (1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measurements by Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al. (2005); the hybrid measurements by Resnik (1995) (R) (Lin), Lin (1998) (L) (L), Jiang and Conrath (1997), JC), and Turney et al."}, {"heading": "4.1.3 EVALUATION ON SAT ANALOGY QUESTIONS", "text": "The approach we take to evaluate SR in the analogy task is to use the typical benchmark tests used in the related bibliography, namely the Scholastic Aptitude Test (SAT).11 It includes 374 pairs of words and the number of pairs of words that are correctly answered, only 57 percent of the questions, and no machine-aided approach has so far outperformed the performance of the average college user. In Table 7, we present the number of correct answers and the respective proportion of SAT questions measured by the following methods. (RG) Jiang and Conrath have the ability to outperform the performance of the college user. (L), Leacock et al. (LC), Hirst and St-Onge."}, {"heading": "4.2 Evaluation of the Omiotis Measure", "text": "To evaluate the performance of the Omiotis measurement, we conducted two experiments that tested the measurement's ability to detect similarity between sets. The first experiment is based on data generated by Li et al. (2006), and the second experiment is based on the task of paraphrase recognition using Microsoft Research Paraphrase Corpus (Dolan et al., 2004)."}, {"heading": "4.2.1 EVALUATION ON SENTENCE SIMILARITY", "text": "The data compiled by Li et al. (2006) consists of 65 sentence pairs (each pair consists of two sets containing the respective dictionary definitions of the R & G 65 word pairs dataset).The dictionary used was the Collins Cobuild dictionary (Sinclair, 2001).For each sentence pair, the results of the similarity of 32 human participants were provided, ranging from 0.0 (the sentences are independent in meaning) to 4.0 (the sentences are identical in meaning).From the 65 sentence pairs, Li et al. (2006) it was decided to retain a subset of 30 sentence pairs, similar to the process used by Miller and Charles (1991), in order to maintain the sentences whose human ratings produce a more even distribution over the similarity range.Thus, we apply omiotis in this subset of the 65 sentence pairs described by Li et al. (2006) In this data set, we compare omiotis with the STASIS measurement of the similarity we propose."}, {"heading": "4.2.2 EVALUATION ON PARAPHRASE RECOGNITION", "text": "In order to further explore the performance of Omiotis Ayan, we must abide by the rules we have imposed on ourselves. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...) We must abide by the rules. (...)"}, {"heading": "5. Conclusions and Future Work", "text": "The greatest strength of this measure lies in the formulation of the semantic relationship between words. Experimental evaluation has shown that our measurement is more consistent with the human understanding of the semantic relationship between words than previous related metrics. Combining path length, node depth and edge type in a single formula allowed us to apply our semantic kinship measure to various text-based tasks with very good performance. Specifically, the SR measurement exceeds all current metrics in word-to-word tasks in the data used, and the Omiotis measurement in sentence similarity and colloquial recognition tasks very well. Although the results in the word analogy task are satisfactory as no specific adjustment has been made, we are confident that there is still room for improvement. The comprehensive evaluation of SR and omiotis in several applications demonstrates the capabilities of our measures and proves that both plans can be applied to different text tasks as we trust that there is room for improvement."}, {"heading": "Acknowledgments", "text": "Part of this work was done during the time of George Tsatsaronis at the Institute of Computer Science of the Athens University of Economics. We would like to thank Kjetil N\u00f8rva \u0433g for his constructive comments and Ion Androutsopoulos for his feedback on the early stage of this work. We would also like to thank the anonymous reviewers for their detailed feedback."}], "references": [{"title": "A study on similarity and relatedness using distributional and wordnet-based approaches", "author": ["E. Agirre", "E. Alfonseca", "K. Hall", "J. Kravalova", "M. Pasca", "A. Soroa"], "venue": "In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),", "citeRegEx": "Agirre et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Agirre et al\\.", "year": 2009}, {"title": "A proposal for word sense disambiguation using conceptual distance", "author": ["E. Agirre", "G. Rigau"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP)", "citeRegEx": "Agirre and Rigau,? \\Q1995\\E", "shortCiteRegEx": "Agirre and Rigau", "year": 1995}, {"title": "Categorical Data Analysis", "author": ["A. Agresti"], "venue": "Wiley, Hoboken, NJ.", "citeRegEx": "Agresti,? 1990", "shortCiteRegEx": "Agresti", "year": 1990}, {"title": "An information-theoretic perspective of TF-IDF measures", "author": ["A. Aizawa"], "venue": "Information Processing and Management, 39(1), 45\u201365.", "citeRegEx": "Aizawa,? 2003", "shortCiteRegEx": "Aizawa", "year": 2003}, {"title": "Extended gloss overlaps as a measure of semantic relatedness", "author": ["S. Banerjee", "T. Pedersen"], "venue": "In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Banerjee and Pedersen,? \\Q2003\\E", "shortCiteRegEx": "Banerjee and Pedersen", "year": 2003}, {"title": "Using lexical chains for text summarization", "author": ["R. Barzilay", "M. Elhadad"], "venue": "In Proceedings of the ACL 97/EACL 97 Workshop on Intelligent Scalable Text Summarization,", "citeRegEx": "Barzilay and Elhadad,? \\Q1997\\E", "shortCiteRegEx": "Barzilay and Elhadad", "year": 1997}, {"title": "Inferring strategies for sentence ordering in multidocument news summarization", "author": ["R. Barzilay", "M. Elhadad", "K. McKeown"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Barzilay et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Barzilay et al\\.", "year": 2002}, {"title": "A semantic kernel to exploit linguistic knowledge", "author": ["R. Basili", "M. Cammisa", "A. Moschitti"], "venue": "In Proceedings of Advances in Artificial Intelligence, Ninth Congress of the Italian Association for Artificial Intelligence (AI*IA),", "citeRegEx": "Basili et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Basili et al\\.", "year": 2005}, {"title": "Clustering word pairs to answer analogy questions", "author": ["E. Bicici", "D. Yuret"], "venue": "In Proceedings of the Fifteenth Turkish Symposium on Artificial Intelligence and Neural Networks", "citeRegEx": "Bicici and Yuret,? \\Q2006\\E", "shortCiteRegEx": "Bicici and Yuret", "year": 2006}, {"title": "WWW sits the sat: Measuring relational similarity from the web", "author": ["D. Bollegala", "Y. Matsuo", "M. Ishizuka"], "venue": "In Proceedings of the Eighteenth European Conference on Artificial Intelligence (ECAI),", "citeRegEx": "Bollegala et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollegala et al\\.", "year": 2008}, {"title": "Evaluating wordnet-based measures of lexical semantic relatedness", "author": ["A. Budanitsky", "G. Hirst"], "venue": "Computational Linguistics,", "citeRegEx": "Budanitsky and Hirst,? \\Q2006\\E", "shortCiteRegEx": "Budanitsky and Hirst", "year": 2006}, {"title": "Cross-language information retrieval using EuroWordNet and word sense disambiguation", "author": ["P. Clough", "M. Stevenson"], "venue": "In Proceedings of the Twenty Sixth European Conference on Information Retrieval (ECIR),", "citeRegEx": "Clough and Stevenson,? \\Q2004\\E", "shortCiteRegEx": "Clough and Stevenson", "year": 2004}, {"title": "Introduction to Algorithms", "author": ["T. Cormen", "C. Leiserson", "R. Rivest"], "venue": null, "citeRegEx": "Cormen et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Cormen et al\\.", "year": 1990}, {"title": "Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources", "author": ["W. Dolan", "C. Quirk", "C. Brockett"], "venue": "In Proceedings of the Twentieth International Conference on Computational Linguistics (COLING)", "citeRegEx": "Dolan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dolan et al\\.", "year": 2004}, {"title": "WordNet \u2013 an electronic lexical database", "author": ["C. Fellbaum"], "venue": "MIT Press.", "citeRegEx": "Fellbaum,? 1998", "shortCiteRegEx": "Fellbaum", "year": 1998}, {"title": "Using machine translation evaluation techniques to determine sentence-level semantic equivalence", "author": ["A. Finch", "Y. Hwang", "E. Sumita"], "venue": "In Proceedings of the 3rd International Workshop on Paraphrasing,", "citeRegEx": "Finch et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Finch et al\\.", "year": 2005}, {"title": "Placing search in context: The concept revisited", "author": ["L. Finkelstein", "E. Gabrilovich", "Y. Matias", "E. Rivlin", "Z. Solan", "G. Wolfman", "E. Ruppin"], "venue": "ACM Transactions on Information Systems,", "citeRegEx": "Finkelstein et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2002}, {"title": "Frequency distribution of the values of the correlation coefficient in samples of an indefinitely large population", "author": ["R. Fisher"], "venue": "Biometrika, 10, 507\u2013521.", "citeRegEx": "Fisher,? 1915", "shortCiteRegEx": "Fisher", "year": 1915}, {"title": "Computing semantic relatedness using Wikipedia-based explicit semantic analysis", "author": ["E. Gabrilovich", "R. Markovitch"], "venue": "In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Gabrilovich and Markovitch,? \\Q2007\\E", "shortCiteRegEx": "Gabrilovich and Markovitch", "year": 2007}, {"title": "Wikipedia-based semantic interpretation for natural language processing", "author": ["E. Gabrilovich", "R. Markovitch"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Gabrilovich and Markovitch,? \\Q2009\\E", "shortCiteRegEx": "Gabrilovich and Markovitch", "year": 2009}, {"title": "Structure-mapping: A theoretical framework for analogy", "author": ["D. Gentner"], "venue": "Cognitive Science, 7(2), 155\u2013170.", "citeRegEx": "Gentner,? 1983", "shortCiteRegEx": "Gentner", "year": 1983}, {"title": "Feature Extraction, Foundations and Applications", "author": ["I. Guyon", "S. Gunn", "M. Nikravesh", "L. Zadeh"], "venue": null, "citeRegEx": "Guyon et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Guyon et al\\.", "year": 2006}, {"title": "Methods for using textual entailment in open-domain question answering", "author": ["S. Harabagiu", "A. Hickl"], "venue": "In Proceedings of the Joint Conference of the International Committee on Computational Linguistics and the Association for Computational Linguistics (COLING-ACL),", "citeRegEx": "Harabagiu and Hickl,? \\Q2006\\E", "shortCiteRegEx": "Harabagiu and Hickl", "year": 2006}, {"title": "Corpus and evaluation measures for multiple document summarization with multiple sources", "author": ["T. Hirao", "T. Fukusima", "M. Okumura", "C. Nobata", "H. Nanba"], "venue": "In Proceedings of the Twentieth International Conference on Computational Linguistics (COLING),", "citeRegEx": "Hirao et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hirao et al\\.", "year": 2005}, {"title": "Lexical chains as representations of context for the detection and correction of malapropisms", "author": ["G. Hirst", "D. St-Onge"], "venue": "In WordNet: An Electronic Lexical Database,", "citeRegEx": "Hirst and St.Onge,? \\Q1998\\E", "shortCiteRegEx": "Hirst and St.Onge", "year": 1998}, {"title": "Lexical semantic relatedness with random graph walks", "author": ["T. Hughes", "D. Ramage"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Hughes and Ramage,? \\Q2007\\E", "shortCiteRegEx": "Hughes and Ramage", "year": 2007}, {"title": "Word Sense Disambiguation: The State of the Art", "author": ["N. Ide", "J. Veronis"], "venue": "Computational Linguistics,", "citeRegEx": "Ide and Veronis,? \\Q1998\\E", "shortCiteRegEx": "Ide and Veronis", "year": 1998}, {"title": "Semantic text similarity using corpus-based word similarity and string similarity", "author": ["A. Islam", "D. Inkpen"], "venue": "ACM Transactions on Knowledge Discovery from Data,", "citeRegEx": "Islam and Inkpen,? \\Q2008\\E", "shortCiteRegEx": "Islam and Inkpen", "year": 2008}, {"title": "\u00c9tude comparative de la distribution florale dans une portion des alpes et des jura", "author": ["P. Jaccard"], "venue": "Bulletin del la Socie\u0301te\u0301 Vaudoise des Sciences Naturelles,", "citeRegEx": "Jaccard,? \\Q1901\\E", "shortCiteRegEx": "Jaccard", "year": 1901}, {"title": "Roget\u2019s thesaurus and semantic similarity", "author": ["M. Jarmasz"], "venue": "Master\u2019s Thesis, University of Ottawa.", "citeRegEx": "Jarmasz,? 2003", "shortCiteRegEx": "Jarmasz", "year": 2003}, {"title": "Roget\u2019s thesaurus and semantic similarity", "author": ["M. Jarmasz", "S. Szpakowicz"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP),", "citeRegEx": "Jarmasz and Szpakowicz,? \\Q2003\\E", "shortCiteRegEx": "Jarmasz and Szpakowicz", "year": 2003}, {"title": "Semantic similarity based on corpus statistics and lexical taxonomy", "author": ["J. Jiang", "D. Conrath"], "venue": "In Proceedings of the International Conference Research on Computational Linguistics (ROCLING X),", "citeRegEx": "Jiang and Conrath,? \\Q1997\\E", "shortCiteRegEx": "Jiang and Conrath", "year": 1997}, {"title": "Computational Analysis of Present Day", "author": ["H. Kucera", "W. Francis", "J. Caroll"], "venue": null, "citeRegEx": "Kucera et al\\.,? \\Q1967\\E", "shortCiteRegEx": "Kucera et al\\.", "year": 1967}, {"title": "A solution to Plato\u2019s problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge", "author": ["T. Landauer", "S. Dumais"], "venue": "Psychological Review,", "citeRegEx": "Landauer and Dumais,? \\Q1997\\E", "shortCiteRegEx": "Landauer and Dumais", "year": 1997}, {"title": "Introduction to latent semantc analysis", "author": ["T. Landauer", "P. Foltz", "D. Laham"], "venue": "Discourse Processes,", "citeRegEx": "Landauer et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Landauer et al\\.", "year": 1998}, {"title": "Using corpus statistics and WordNet relations for sense identification", "author": ["C. Leacock", "G. Miller", "M. Chodorow"], "venue": "Computational Linguistics,", "citeRegEx": "Leacock et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Leacock et al\\.", "year": 1998}, {"title": "Automated sense disambiguation using machine-readable dictionaries: How to tell a pine cone from an ice cream cone", "author": ["M. Lesk"], "venue": "Proceedings of the Fifth Annual International Conference on Systems Documentation (SIGDOC), pp. 24\u201326.", "citeRegEx": "Lesk,? 1986", "shortCiteRegEx": "Lesk", "year": 1986}, {"title": "Estimators and tail bounds for dimension reduction in l\u03b1 (0 < \u03b1 \u2264 2) using stable random projections", "author": ["P. Li"], "venue": "Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 10\u201319.", "citeRegEx": "Li,? 2008", "shortCiteRegEx": "Li", "year": 2008}, {"title": "Sentence similarity based on semantic nets and corpus statistics", "author": ["Y. Li", "D. McLean", "Z. Bandar", "J. O\u2019Shea", "K. Crockett"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "Li et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Li et al\\.", "year": 2006}, {"title": "An information-theoretic definition of similarity", "author": ["D. Lin"], "venue": "Proceedings of the Fifteenth International Conference on Machine Learning (ICML), pp. 296\u2013304.", "citeRegEx": "Lin,? 1998", "shortCiteRegEx": "Lin", "year": 1998}, {"title": "Multiple alternative sentence compressions for automatic text summarization", "author": ["N. Madnani", "D. Zajic", "B. Dorr", "N. Fazil Ayan", "J. Lin"], "venue": "In Proceedings of the HLT/NAACL Document Understanding Conference (DUC)", "citeRegEx": "Madnani et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Madnani et al\\.", "year": 2007}, {"title": "Generalized latent semantic analysis for term representation", "author": ["I. Matveeva", "G. Levow", "A. Farahat", "C. Royer"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP)", "citeRegEx": "Matveeva et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Matveeva et al\\.", "year": 2005}, {"title": "Word sense disambiguation for exploiting hierarchical thesauri in text classification", "author": ["D. Mavroeidis", "G. Tsatsaronis", "M. Vazirgiannis", "M. Theobald", "G. Weikum"], "venue": "In Proceedings of the Ninth European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD),", "citeRegEx": "Mavroeidis et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Mavroeidis et al\\.", "year": 2005}, {"title": "Corpus-based and knowledge-based measures of text semantic similarity", "author": ["R. Mihalcea", "C. Corley", "C. Strapparava"], "venue": "In Proceedings of the Twenty First Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Mihalcea et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Mihalcea et al\\.", "year": 2006}, {"title": "A method for word sense disambiguation of unrestricted text", "author": ["R. Mihalcea", "D. Moldovan"], "venue": "In Proceedings of the 37th annual meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Mihalcea and Moldovan,? \\Q1999\\E", "shortCiteRegEx": "Mihalcea and Moldovan", "year": 1999}, {"title": "PageRank on semantic networks with application to word sense disambiguation", "author": ["R. Mihalcea", "P. Tarau", "E. Figa"], "venue": "In Proceedings of the Twentieth International Conference on Computational Linguistics (COLING)", "citeRegEx": "Mihalcea et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Mihalcea et al\\.", "year": 2004}, {"title": "Contextual correlates of semantic similarity", "author": ["G. Miller", "W. Charles"], "venue": "Language and Cognitive Processes,", "citeRegEx": "Miller and Charles,? \\Q1991\\E", "shortCiteRegEx": "Miller and Charles", "year": 1991}, {"title": "An effective, low-cost measure of semantic relatedness obtained from Wikipedia links", "author": ["D. Milne", "I. Witten"], "venue": "In Proceedings of the first AAAI Workshop on Wikipedia and Artificial Intelligence (WIKIAI)", "citeRegEx": "Milne and Witten,? \\Q2008\\E", "shortCiteRegEx": "Milne and Witten", "year": 2008}, {"title": "Lexical cohesion computed by thesaural relations as an indicator of the structure of text", "author": ["J. Morris", "G. Hirst"], "venue": "Computational Linguistics,", "citeRegEx": "Morris and Hirst,? \\Q1991\\E", "shortCiteRegEx": "Morris and Hirst", "year": 1991}, {"title": "A structural approach to the automatic adjudication of word sense disagreements", "author": ["R. Navigli"], "venue": "Natural Language Engineering, 14(4), 547\u2013573.", "citeRegEx": "Navigli,? 2008", "shortCiteRegEx": "Navigli", "year": 2008}, {"title": "A comparative study of two short text semantic similarity measures", "author": ["J. O\u2019Shea", "Z. Bandar", "K. Crocket", "D. McLean"], "venue": "In Proceedings of the Agent and Multi-Agent Systems: Technologies and Applications, Second KES International Symposium (KES-AMSTA),", "citeRegEx": "O.Shea et al\\.,? \\Q2008\\E", "shortCiteRegEx": "O.Shea et al\\.", "year": 2008}, {"title": "Dependency-based construction of semantic space models", "author": ["S. Pado", "M. Lapata"], "venue": "Computational Linguistics,", "citeRegEx": "Pado and Lapata,? \\Q2007\\E", "shortCiteRegEx": "Pado and Lapata", "year": 2007}, {"title": "English tasks: All-words and verb lexical sample", "author": ["M. Palmer", "C. Fellbaum", "S. Cotton"], "venue": "In Proceedings of Senseval-2,", "citeRegEx": "Palmer et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Palmer et al\\.", "year": 2001}, {"title": "Open-domain question answering from large text collections", "author": ["M. Pasca"], "venue": "CSLI Studies in Computational Linguistics. CSLI Publications, Distributed by the University of Chicago Press.", "citeRegEx": "Pasca,? 2003", "shortCiteRegEx": "Pasca", "year": 2003}, {"title": "Mining paraphrases from self-anchored web sentence fragments", "author": ["M. Pasca"], "venue": "Proceedings of the Ninth European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD), pp. 193\u2013204.", "citeRegEx": "Pasca,? 2005", "shortCiteRegEx": "Pasca", "year": 2005}, {"title": "Using measures of semantic relatedness for word sense disambiguation", "author": ["S. Patwardhan", "S. Banerjee", "T. Pedersen"], "venue": "In Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics (CICLing),", "citeRegEx": "Patwardhan et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Patwardhan et al\\.", "year": 2003}, {"title": "Using WordNet based context vectors to estimate the semantic relatedness of concepts", "author": ["S. Patwardhan", "T. Pedersen"], "venue": "In Proceedings of the EACL 2006 Workshop Making Sense of Sense - Bringing Computational Linguistics and Psycholinguistics Together,", "citeRegEx": "Patwardhan and Pedersen,? \\Q2006\\E", "shortCiteRegEx": "Patwardhan and Pedersen", "year": 2006}, {"title": "Knowledge derived from Wikipedia for computing semantic relatedness", "author": ["S. Ponzetto", "M. Strube"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Ponzetto and Strube,? \\Q2007\\E", "shortCiteRegEx": "Ponzetto and Strube", "year": 2007}, {"title": "Deriving a large-scale taxonomy from Wikipedia", "author": ["S. Ponzetto", "M. Strube"], "venue": "In Proceedings of the Twenty Second Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Ponzetto and Strube,? \\Q2007\\E", "shortCiteRegEx": "Ponzetto and Strube", "year": 2007}, {"title": "Paraphrase recognition via dissimilarity significance classification", "author": ["L. Qiu", "M. Kan", "T. Chua"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Qiu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Qiu et al\\.", "year": 2006}, {"title": "The teachable language comprehender: a simulation program and theory of language", "author": ["R. Quilian"], "venue": "Communications of ACM, 12(8), 459\u2013476.", "citeRegEx": "Quilian,? 1969", "shortCiteRegEx": "Quilian", "year": 1969}, {"title": "Using information content to evaluate semantic similarity", "author": ["P. Resnik"], "venue": "Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI), pp. 448\u2013453.", "citeRegEx": "Resnik,? 1995", "shortCiteRegEx": "Resnik", "year": 1995}, {"title": "Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language", "author": ["P. Resnik"], "venue": "Journal of Artificial Intelligence Research, 11, 95\u2013130.", "citeRegEx": "Resnik,? 1999", "shortCiteRegEx": "Resnik", "year": 1999}, {"title": "Using WordNet in a knowledge-based approach to information retrieval", "author": ["R. Richardson", "A. Smeaton"], "venue": "In Proceedings of the BCS-IRSG Colloquium", "citeRegEx": "Richardson and Smeaton,? \\Q1995\\E", "shortCiteRegEx": "Richardson and Smeaton", "year": 1995}, {"title": "Contextual correlates of synonymy", "author": ["H. Rubenstein", "J. Goodenough"], "venue": "Communications of the ACM,", "citeRegEx": "Rubenstein and Goodenough,? \\Q1965\\E", "shortCiteRegEx": "Rubenstein and Goodenough", "year": 1965}, {"title": "Using context-window overlapping in synonym discovery and ontology extension", "author": ["M. Ruiz-Casado", "E. Alfonseca", "P. Castells"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP)", "citeRegEx": "Ruiz.Casado et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ruiz.Casado et al\\.", "year": 2005}, {"title": "An evaluation of term dependence models in information retrieval", "author": ["G. Salton", "C. Buckley", "C. Yu"], "venue": "In Proceedings of the Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Salton et al\\.,? \\Q1982\\E", "shortCiteRegEx": "Salton et al\\.", "year": 1982}, {"title": "Introduction to Modern Information Retrieval", "author": ["G. Salton", "M. McGill"], "venue": null, "citeRegEx": "Salton and McGill,? \\Q1983\\E", "shortCiteRegEx": "Salton and McGill", "year": 1983}, {"title": "Word sense disambiguation and information retrieval", "author": ["M. Sanderson"], "venue": "Proceedings of the Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 142\u2013151.", "citeRegEx": "Sanderson,? 1994", "shortCiteRegEx": "Sanderson", "year": 1994}, {"title": "Ambiguous queries: Test collections need more sense", "author": ["M. Sanderson"], "venue": "Proceedings of the Thirty First Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 499\u2013506.", "citeRegEx": "Sanderson,? 2008", "shortCiteRegEx": "Sanderson", "year": 2008}, {"title": "Paraphrase acquisition for information extraction", "author": ["Y. Shinyama", "S. Sekine"], "venue": "In Proceedings of the ACL 2nd Workshop on Paraphrasing: Paraphrase Acquisition and Applications,", "citeRegEx": "Shinyama and Sekine,? \\Q2003\\E", "shortCiteRegEx": "Shinyama and Sekine", "year": 2003}, {"title": "Collins Cobuild English Dictionary for Advanced Learners, 3rd edn", "author": ["J. Sinclair"], "venue": "Harper Collins, New York.", "citeRegEx": "Sinclair,? 2001", "shortCiteRegEx": "Sinclair", "year": 2001}, {"title": "TREC-4 experiments at Dublin City University: Thresholding posting lists, query expansion with WordNet and POS tagging of Spanish", "author": ["A. Smeaton", "F. Kelledy", "R. O\u2019Donnell"], "venue": "In Proceedings of the Fourth Text REtrieval Conference (TREC)", "citeRegEx": "Smeaton et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Smeaton et al\\.", "year": 1995}, {"title": "The English All-words task", "author": ["B. Snyder", "M. Palmer"], "venue": "In Proceedings of Senseval-3,", "citeRegEx": "Snyder and Palmer,? \\Q2004\\E", "shortCiteRegEx": "Snyder and Palmer", "year": 2004}, {"title": "A term weighting method based on lexical chain for automatic summarization", "author": ["Y. Song", "K. Han", "H. Rim"], "venue": "In Proceedings of the Fifth International Conference on Intelligent Text Processing and Computational Linguistics (CICLing),", "citeRegEx": "Song et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Song et al\\.", "year": 2004}, {"title": "Word sense disambiguation in information retrieval revisited", "author": ["C. Stokoe", "M. Oakes", "J. Tait"], "venue": "In Proceedings of the Twenty Sixth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Stokoe et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Stokoe et al\\.", "year": 2003}, {"title": "WikiRelate! Computing semantic relatedness using Wikipedia", "author": ["M. Strube", "S. Ponzetto"], "venue": "In Proceedings of the Twenty First Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Strube and Ponzetto,? \\Q2006\\E", "shortCiteRegEx": "Strube and Ponzetto", "year": 2006}, {"title": "Word sense disambiguation for free-text indexing using a massive semantic network", "author": ["M. Sussna"], "venue": "Proceedings of the Second International Conference on Information and Knowledge Management (CIKM), pp. 67\u201374.", "citeRegEx": "Sussna,? 1993", "shortCiteRegEx": "Sussna", "year": 1993}, {"title": "Frequency estimates for statistical word similarity measures", "author": ["E. Terra", "C. Clarke"], "venue": "In Proceedings of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies Conference (HLT/NAACL).,", "citeRegEx": "Terra and Clarke,? \\Q2003\\E", "shortCiteRegEx": "Terra and Clarke", "year": 2003}, {"title": "A Graph Approach to Measuring Text Distance", "author": ["V. Tsang"], "venue": "PhD Thesis, University of Toronto.", "citeRegEx": "Tsang,? 2008", "shortCiteRegEx": "Tsang", "year": 2008}, {"title": "A generalized vector space model for text retrieval based on semantic relatedness", "author": ["G. Tsatsaronis", "V. Panagiotopoulou"], "venue": "In Proceedings of the the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL - Student Research Workshop),", "citeRegEx": "Tsatsaronis and Panagiotopoulou,? \\Q2009\\E", "shortCiteRegEx": "Tsatsaronis and Panagiotopoulou", "year": 2009}, {"title": "Omiotis: A thesaurus-based measure of text relatedness", "author": ["G. Tsatsaronis", "I. Varlamis", "K. N\u00f8rv\u00e5g", "M. Vazirgiannis"], "venue": "In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD),", "citeRegEx": "Tsatsaronis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Tsatsaronis et al\\.", "year": 2009}, {"title": "Word sense disambiguation with semantic networks", "author": ["G. Tsatsaronis", "I. Varlamis", "M. Vazirgiannis"], "venue": "In Proceedings of the 11th International Conference on Text, Speech and Dialogue (TSD),", "citeRegEx": "Tsatsaronis et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Tsatsaronis et al\\.", "year": 2008}, {"title": "Word sense disambiguation with spreading activation networks generated from thesauri", "author": ["G. Tsatsaronis", "M. Vazirgiannis", "I. Androutsopoulos"], "venue": "In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Tsatsaronis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Tsatsaronis et al\\.", "year": 2007}, {"title": "Mining the Web for synonyms: PMI-IR versus LSA on TOEFL", "author": ["P. Turney"], "venue": "Proceedings of the Twelfth European Conference on Machine Learning (ECML), pp. 491\u2013502.", "citeRegEx": "Turney,? 2001", "shortCiteRegEx": "Turney", "year": 2001}, {"title": "Similarity of semantic relations", "author": ["P. Turney"], "venue": "Computational Linguistics, 32(3), 379\u2013416.", "citeRegEx": "Turney,? 2006", "shortCiteRegEx": "Turney", "year": 2006}, {"title": "The latent relation mapping engine: Algorithm and experiments", "author": ["P. Turney"], "venue": "Journal of Artificial Intelligence Research, 33, 615\u2013655.", "citeRegEx": "Turney,? 2008a", "shortCiteRegEx": "Turney", "year": 2008}, {"title": "A uniform approach to analogies, synonyms, antonyms, and associations", "author": ["P. Turney"], "venue": "Proceedings of the Twenty Second International Conference on Computational Linguistics (COLING), pp. 905\u2013912.", "citeRegEx": "Turney,? 2008b", "shortCiteRegEx": "Turney", "year": 2008}, {"title": "Corpus-based learning of analogies and semantic relations", "author": ["P. Turney", "M. Littman"], "venue": "Machine Learning,", "citeRegEx": "Turney and Littman,? \\Q2005\\E", "shortCiteRegEx": "Turney and Littman", "year": 2005}, {"title": "Combining independent modules to solve multiple-choice synonym and analogy problems", "author": ["P. Turney", "M. Littman", "J. Bigham", "V. Shnayder"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP),", "citeRegEx": "Turney et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2003}, {"title": "The nature of statistical learning theory", "author": ["V. Vapnik"], "venue": "Springer.", "citeRegEx": "Vapnik,? 1995", "shortCiteRegEx": "Vapnik", "year": 1995}, {"title": "WordNet sits the SAT: A knowledge-based approach to lexical analogy", "author": ["T. Veale"], "venue": "Proceedings of the Sixteenth European Conference on Artificial Intelligence (ECAI), pp. 606\u2013 612.", "citeRegEx": "Veale,? 2004", "shortCiteRegEx": "Veale", "year": 2004}, {"title": "Word sense disambiguation with very large neural networks extracted from machine readable dictionaries", "author": ["J. Veronis", "N. Ide"], "venue": "In Proceedings of the Thirteenth International Conference on Computational Linguistics (COLING),", "citeRegEx": "Veronis and Ide,? \\Q1990\\E", "shortCiteRegEx": "Veronis and Ide", "year": 1990}, {"title": "Using WordNet to disambiguate word sense for text retrieval", "author": ["E. Voorhees"], "venue": "Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 171\u2013180.", "citeRegEx": "Voorhees,? 1993", "shortCiteRegEx": "Voorhees", "year": 1993}, {"title": "Using dependency-based features to take the parafarce out of paraphrase", "author": ["S. Wan", "M. Dras", "R. Dale", "C. Paris"], "venue": "In Proceedings of the Australasian Language Technology Workshop,", "citeRegEx": "Wan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2006}, {"title": "Verb semantics and lexical selection", "author": ["Z. Wu", "M. Palmer"], "venue": "In Proceedings of the Thirty Second Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Wu and Palmer,? \\Q1994\\E", "shortCiteRegEx": "Wu and Palmer", "year": 1994}, {"title": "Paraphrase identification by text canonicalization", "author": ["Y. Zhang", "J. Patrick"], "venue": "In Proceedings of the Australasian Language Technology Workshop,", "citeRegEx": "Zhang and Patrick,? \\Q2005\\E", "shortCiteRegEx": "Zhang and Patrick", "year": 2005}], "referenceMentions": [{"referenceID": 37, "context": "Journal of Artificial Intelligence Research 37 (2010) 1-39 Submitted 07/09; published 01/10", "startOffset": 27, "endOffset": 54}, {"referenceID": 3, "context": "Several improvements have been proposed for such techniques towards inventing more sophisticated weighting schemes for the text words, like for example TF-IDF and its variations (Aizawa, 2003).", "startOffset": 178, "endOffset": 192}, {"referenceID": 27, "context": "Primarily, one can think of lexical relatedness or similarity between texts, which can be easily captured by a vectorial representation of texts (van Rijsbergen, 1979) and a standard similarity measure, like Cosine, Dice (Salton & McGill, 1983), and Jaccard (1901). Such models have had high impact in information retrieval over the past decades.", "startOffset": 250, "endOffset": 265}, {"referenceID": 14, "context": "The word-to-word relatedness measure, in its turn, is based on the construction of semantic links between individual words, according to a word thesaurus, which in our case is WordNet (Fellbaum, 1998).", "startOffset": 184, "endOffset": 200}, {"referenceID": 14, "context": "Word thesauri, like WordNet (Fellbaum, 1998) or Roget\u2019s International Thesaurus (Morris & Hirst, 1991), constitute the knowledge base for several text-related research tasks.", "startOffset": 28, "endOffset": 44}, {"referenceID": 42, "context": "From the aforementioned approaches, it is clear that the use of a word thesaurus can offer much potential in the design of models that capture the semantic relatedness between texts, and consequently, it may improve the performance of existing retrieval and classification models under certain circumstances that are discussed in the respective research works (Mavroeidis et al., 2005; Basili et al., 2005; Stokoe et al., 2003; Clough & Stevenson, 2004).", "startOffset": 360, "endOffset": 453}, {"referenceID": 7, "context": "From the aforementioned approaches, it is clear that the use of a word thesaurus can offer much potential in the design of models that capture the semantic relatedness between texts, and consequently, it may improve the performance of existing retrieval and classification models under certain circumstances that are discussed in the respective research works (Mavroeidis et al., 2005; Basili et al., 2005; Stokoe et al., 2003; Clough & Stevenson, 2004).", "startOffset": 360, "endOffset": 453}, {"referenceID": 75, "context": "From the aforementioned approaches, it is clear that the use of a word thesaurus can offer much potential in the design of models that capture the semantic relatedness between texts, and consequently, it may improve the performance of existing retrieval and classification models under certain circumstances that are discussed in the respective research works (Mavroeidis et al., 2005; Basili et al., 2005; Stokoe et al., 2003; Clough & Stevenson, 2004).", "startOffset": 360, "endOffset": 453}, {"referenceID": 11, "context": "Word thesauri, like WordNet (Fellbaum, 1998) or Roget\u2019s International Thesaurus (Morris & Hirst, 1991), constitute the knowledge base for several text-related research tasks. WordNet has been used successfully as a knowledge base in the construction of Generalized Vector Space Models (GVSM) and semantic kernels for document similarity with application to text classification, such as the works of Mavroeidis, Tsatsaronis, Vazirgiannis, Theobald and Weikum (2005), and Basili, Cammisa and Moschitti (2005), and text retrieval, such as the works of Voorhees (1993), Stokoe, Oakes and Tait (2003), and our previous work regarding the definition of a new GVSM that uses word-to-word semantic relatedness (Tsatsaronis & Panagiotopoulou, 2009).", "startOffset": 29, "endOffset": 465}, {"referenceID": 11, "context": "Word thesauri, like WordNet (Fellbaum, 1998) or Roget\u2019s International Thesaurus (Morris & Hirst, 1991), constitute the knowledge base for several text-related research tasks. WordNet has been used successfully as a knowledge base in the construction of Generalized Vector Space Models (GVSM) and semantic kernels for document similarity with application to text classification, such as the works of Mavroeidis, Tsatsaronis, Vazirgiannis, Theobald and Weikum (2005), and Basili, Cammisa and Moschitti (2005), and text retrieval, such as the works of Voorhees (1993), Stokoe, Oakes and Tait (2003), and our previous work regarding the definition of a new GVSM that uses word-to-word semantic relatedness (Tsatsaronis & Panagiotopoulou, 2009).", "startOffset": 29, "endOffset": 507}, {"referenceID": 11, "context": "Word thesauri, like WordNet (Fellbaum, 1998) or Roget\u2019s International Thesaurus (Morris & Hirst, 1991), constitute the knowledge base for several text-related research tasks. WordNet has been used successfully as a knowledge base in the construction of Generalized Vector Space Models (GVSM) and semantic kernels for document similarity with application to text classification, such as the works of Mavroeidis, Tsatsaronis, Vazirgiannis, Theobald and Weikum (2005), and Basili, Cammisa and Moschitti (2005), and text retrieval, such as the works of Voorhees (1993), Stokoe, Oakes and Tait (2003), and our previous work regarding the definition of a new GVSM that uses word-to-word semantic relatedness (Tsatsaronis & Panagiotopoulou, 2009).", "startOffset": 29, "endOffset": 565}, {"referenceID": 11, "context": "Word thesauri, like WordNet (Fellbaum, 1998) or Roget\u2019s International Thesaurus (Morris & Hirst, 1991), constitute the knowledge base for several text-related research tasks. WordNet has been used successfully as a knowledge base in the construction of Generalized Vector Space Models (GVSM) and semantic kernels for document similarity with application to text classification, such as the works of Mavroeidis, Tsatsaronis, Vazirgiannis, Theobald and Weikum (2005), and Basili, Cammisa and Moschitti (2005), and text retrieval, such as the works of Voorhees (1993), Stokoe, Oakes and Tait (2003), and our previous work regarding the definition of a new GVSM that uses word-to-word semantic relatedness (Tsatsaronis & Panagiotopoulou, 2009).", "startOffset": 29, "endOffset": 596}, {"referenceID": 9, "context": "Furthermore, the idea of using a thesaurus as a knowledge base in text retrieval has also been proven successful in the case of cross language information retrieval, like for example in the case of the CLIR system introduced by Clough and Stevenson (2004). Finally, the exploitation of word thesauri in linguistic tasks, such as Word Sense Disambiguation (WSD) (Ide & Veronis, 1998) has yielded interesting results (Mihalcea & Moldovan, 1999; Tsatsaronis, Vazirgiannis, & Androutsopoulos, 2007; Tsatsaronis, Varlamis, & Vazirgiannis, 2008).", "startOffset": 228, "endOffset": 256}, {"referenceID": 5, "context": "In the analysis of Barzilay and Elhadad (1997), and Barzilay, Elhadad and McKeown (2002) the impact of WSD in the performance of text summarization tasks is addressed by considering all possible interpretations of the lexical chains created from text.", "startOffset": 19, "endOffset": 47}, {"referenceID": 5, "context": "In the analysis of Barzilay and Elhadad (1997), and Barzilay, Elhadad and McKeown (2002) the impact of WSD in the performance of text summarization tasks is addressed by considering all possible interpretations of the lexical chains created from text.", "startOffset": 19, "endOffset": 89}, {"referenceID": 83, "context": "In this work we adopt the semantic network construction method that we introduced in the past (Tsatsaronis et al., 2007).", "startOffset": 94, "endOffset": 120}, {"referenceID": 36, "context": "The idea of representing text as a semantic network was initially introduced by Quilian (1969). The expansion of WordNet with semantic relations that cross parts of speech has added more possibilities of semantic network construction from text.", "startOffset": 83, "endOffset": 95}, {"referenceID": 36, "context": "The idea of representing text as a semantic network was initially introduced by Quilian (1969). The expansion of WordNet with semantic relations that cross parts of speech has added more possibilities of semantic network construction from text. More recent approaches to semantic network construction from word thesauri, by Mihalcea, Tarau and Figa (2004) and Navigli (2008), utilize a wide range of WordNet semantic relations instead of the gloss words.", "startOffset": 83, "endOffset": 356}, {"referenceID": 36, "context": "The idea of representing text as a semantic network was initially introduced by Quilian (1969). The expansion of WordNet with semantic relations that cross parts of speech has added more possibilities of semantic network construction from text. More recent approaches to semantic network construction from word thesauri, by Mihalcea, Tarau and Figa (2004) and Navigli (2008), utilize a wide range of WordNet semantic relations instead of the gloss words.", "startOffset": 83, "endOffset": 375}, {"referenceID": 6, "context": "3 Measures of Semantic Relatedness Semantic relatedness between words or concepts has been exploited, in the past, in text summarization (Barzilay et al., 2002), text retrieval (Stokoe et al.", "startOffset": 137, "endOffset": 160}, {"referenceID": 75, "context": ", 2002), text retrieval (Stokoe et al., 2003; Smeaton, Kelledy, & O\u2019Donnell, 1995; Richardson & Smeaton, 1995) and WSD (Patwardhan, Banerjee, & Pedersen, 2003) tasks.", "startOffset": 24, "endOffset": 110}, {"referenceID": 1, "context": "Among dictionary-based measures, the measure of Agirre and Rigau (1995) was one of the first measures developed to compute semantic relatedness between two or more concepts (i.", "startOffset": 48, "endOffset": 72}, {"referenceID": 1, "context": "Among dictionary-based measures, the measure of Agirre and Rigau (1995) was one of the first measures developed to compute semantic relatedness between two or more concepts (i.e., for a set of concepts). Their measure was based on the density and depth of concepts in the set and on the length of the shortest path that connects them. However, they assume that all edges in the path are equally important. The measure proposed by Leacock, Miller and Chodorow (1998) for computing the semantic similarity between a pair of concepts takes into account the length of the shortest path connecting them, measured as the number of nodes participating in the path, and the maximum depth of the taxonomy.", "startOffset": 48, "endOffset": 466}, {"referenceID": 31, "context": "The measure proposed by Jiang and Conrath (1997), is also based on the concept of IC.", "startOffset": 24, "endOffset": 49}, {"referenceID": 37, "context": "The measure of Lin (1998) is also based on IC.", "startOffset": 15, "endOffset": 26}, {"referenceID": 34, "context": "(2002), who perform Latent Semantic Analysis (Landauer et al., 1998) to capture text relatedness and can be considered as a corpus-based method, the measure of Patwardhan and Pedersen (2006), who utilize the gloss words found from the words\u2019 definitions to create WordNet-based context vectors, the methods of Strube and Ponzetto (2006, 2007a), Gabrilovich and Markovitch (2007), and Milne and Witten (2008) who use Wikipedia to compute semantic relatedness and can also be considered as corpus-based approaches, and the method of Mihalcea, Corley and Strappavara (2006), which is a hybrid method that combines knowledge-based and corpus-based measures of text relatedness.", "startOffset": 45, "endOffset": 68}, {"referenceID": 9, "context": "We encourage the reader to consult the analysis of Budanitsky and Hirst (2006) for a detailed discussion on most of the aforementioned measures, as well as for more measures proposed prior to the aforementioned.", "startOffset": 51, "endOffset": 79}, {"referenceID": 4, "context": "While all these measures use only the noun hierarchy (except from the measure of Hirst and St-Onge), the implementation of several of those measures provided by Patwardhan, Banerjee and Pedersen (2003) in the publicly available WordNet::Similarity package can also utilize the verb hierarchy.", "startOffset": 173, "endOffset": 202}, {"referenceID": 4, "context": "While all these measures use only the noun hierarchy (except from the measure of Hirst and St-Onge), the implementation of several of those measures provided by Patwardhan, Banerjee and Pedersen (2003) in the publicly available WordNet::Similarity package can also utilize the verb hierarchy. Still, the relations that cross parts of speech are not considered, as well as other factors discussed in detail in Section 3. In contrast, our measure defines the semantic relatedness between any two concepts, independently of their Part of Speech (POS), utilizing all of the available semantic links offered by WordNet. More recent works of interest on semantic relatedness, include: the measures of Jarmasz and Szpakowicz (2003), who use Roget\u2019s thesaurus to compute semantic similarity, by replicating a number of WordNet-based approaches, the LSA-based measure of Finkelstein et al.", "startOffset": 173, "endOffset": 725}, {"referenceID": 4, "context": "While all these measures use only the noun hierarchy (except from the measure of Hirst and St-Onge), the implementation of several of those measures provided by Patwardhan, Banerjee and Pedersen (2003) in the publicly available WordNet::Similarity package can also utilize the verb hierarchy. Still, the relations that cross parts of speech are not considered, as well as other factors discussed in detail in Section 3. In contrast, our measure defines the semantic relatedness between any two concepts, independently of their Part of Speech (POS), utilizing all of the available semantic links offered by WordNet. More recent works of interest on semantic relatedness, include: the measures of Jarmasz and Szpakowicz (2003), who use Roget\u2019s thesaurus to compute semantic similarity, by replicating a number of WordNet-based approaches, the LSA-based measure of Finkelstein et al. (2002), who perform Latent Semantic Analysis (Landauer et al.", "startOffset": 173, "endOffset": 888}, {"referenceID": 4, "context": "While all these measures use only the noun hierarchy (except from the measure of Hirst and St-Onge), the implementation of several of those measures provided by Patwardhan, Banerjee and Pedersen (2003) in the publicly available WordNet::Similarity package can also utilize the verb hierarchy. Still, the relations that cross parts of speech are not considered, as well as other factors discussed in detail in Section 3. In contrast, our measure defines the semantic relatedness between any two concepts, independently of their Part of Speech (POS), utilizing all of the available semantic links offered by WordNet. More recent works of interest on semantic relatedness, include: the measures of Jarmasz and Szpakowicz (2003), who use Roget\u2019s thesaurus to compute semantic similarity, by replicating a number of WordNet-based approaches, the LSA-based measure of Finkelstein et al. (2002), who perform Latent Semantic Analysis (Landauer et al., 1998) to capture text relatedness and can be considered as a corpus-based method, the measure of Patwardhan and Pedersen (2006), who utilize the gloss words found from the words\u2019 definitions to create WordNet-based context vectors, the methods of Strube and Ponzetto (2006, 2007a), Gabrilovich and Markovitch (2007), and Milne and Witten (2008) who use Wikipedia to compute semantic relatedness and can also be considered as corpus-based approaches, and the method of Mihalcea, Corley and Strappavara (2006), which is a hybrid method that combines knowledge-based and corpus-based measures of text relatedness.", "startOffset": 173, "endOffset": 1072}, {"referenceID": 4, "context": "While all these measures use only the noun hierarchy (except from the measure of Hirst and St-Onge), the implementation of several of those measures provided by Patwardhan, Banerjee and Pedersen (2003) in the publicly available WordNet::Similarity package can also utilize the verb hierarchy. Still, the relations that cross parts of speech are not considered, as well as other factors discussed in detail in Section 3. In contrast, our measure defines the semantic relatedness between any two concepts, independently of their Part of Speech (POS), utilizing all of the available semantic links offered by WordNet. More recent works of interest on semantic relatedness, include: the measures of Jarmasz and Szpakowicz (2003), who use Roget\u2019s thesaurus to compute semantic similarity, by replicating a number of WordNet-based approaches, the LSA-based measure of Finkelstein et al. (2002), who perform Latent Semantic Analysis (Landauer et al., 1998) to capture text relatedness and can be considered as a corpus-based method, the measure of Patwardhan and Pedersen (2006), who utilize the gloss words found from the words\u2019 definitions to create WordNet-based context vectors, the methods of Strube and Ponzetto (2006, 2007a), Gabrilovich and Markovitch (2007), and Milne and Witten (2008) who use Wikipedia to compute semantic relatedness and can also be considered as corpus-based approaches, and the method of Mihalcea, Corley and Strappavara (2006), which is a hybrid method that combines knowledge-based and corpus-based measures of text relatedness.", "startOffset": 173, "endOffset": 1260}, {"referenceID": 4, "context": "While all these measures use only the noun hierarchy (except from the measure of Hirst and St-Onge), the implementation of several of those measures provided by Patwardhan, Banerjee and Pedersen (2003) in the publicly available WordNet::Similarity package can also utilize the verb hierarchy. Still, the relations that cross parts of speech are not considered, as well as other factors discussed in detail in Section 3. In contrast, our measure defines the semantic relatedness between any two concepts, independently of their Part of Speech (POS), utilizing all of the available semantic links offered by WordNet. More recent works of interest on semantic relatedness, include: the measures of Jarmasz and Szpakowicz (2003), who use Roget\u2019s thesaurus to compute semantic similarity, by replicating a number of WordNet-based approaches, the LSA-based measure of Finkelstein et al. (2002), who perform Latent Semantic Analysis (Landauer et al., 1998) to capture text relatedness and can be considered as a corpus-based method, the measure of Patwardhan and Pedersen (2006), who utilize the gloss words found from the words\u2019 definitions to create WordNet-based context vectors, the methods of Strube and Ponzetto (2006, 2007a), Gabrilovich and Markovitch (2007), and Milne and Witten (2008) who use Wikipedia to compute semantic relatedness and can also be considered as corpus-based approaches, and the method of Mihalcea, Corley and Strappavara (2006), which is a hybrid method that combines knowledge-based and corpus-based measures of text relatedness.", "startOffset": 173, "endOffset": 1289}, {"referenceID": 4, "context": "While all these measures use only the noun hierarchy (except from the measure of Hirst and St-Onge), the implementation of several of those measures provided by Patwardhan, Banerjee and Pedersen (2003) in the publicly available WordNet::Similarity package can also utilize the verb hierarchy. Still, the relations that cross parts of speech are not considered, as well as other factors discussed in detail in Section 3. In contrast, our measure defines the semantic relatedness between any two concepts, independently of their Part of Speech (POS), utilizing all of the available semantic links offered by WordNet. More recent works of interest on semantic relatedness, include: the measures of Jarmasz and Szpakowicz (2003), who use Roget\u2019s thesaurus to compute semantic similarity, by replicating a number of WordNet-based approaches, the LSA-based measure of Finkelstein et al. (2002), who perform Latent Semantic Analysis (Landauer et al., 1998) to capture text relatedness and can be considered as a corpus-based method, the measure of Patwardhan and Pedersen (2006), who utilize the gloss words found from the words\u2019 definitions to create WordNet-based context vectors, the methods of Strube and Ponzetto (2006, 2007a), Gabrilovich and Markovitch (2007), and Milne and Witten (2008) who use Wikipedia to compute semantic relatedness and can also be considered as corpus-based approaches, and the method of Mihalcea, Corley and Strappavara (2006), which is a hybrid method that combines knowledge-based and corpus-based measures of text relatedness.", "startOffset": 173, "endOffset": 1452}, {"referenceID": 4, "context": "While all these measures use only the noun hierarchy (except from the measure of Hirst and St-Onge), the implementation of several of those measures provided by Patwardhan, Banerjee and Pedersen (2003) in the publicly available WordNet::Similarity package can also utilize the verb hierarchy. Still, the relations that cross parts of speech are not considered, as well as other factors discussed in detail in Section 3. In contrast, our measure defines the semantic relatedness between any two concepts, independently of their Part of Speech (POS), utilizing all of the available semantic links offered by WordNet. More recent works of interest on semantic relatedness, include: the measures of Jarmasz and Szpakowicz (2003), who use Roget\u2019s thesaurus to compute semantic similarity, by replicating a number of WordNet-based approaches, the LSA-based measure of Finkelstein et al. (2002), who perform Latent Semantic Analysis (Landauer et al., 1998) to capture text relatedness and can be considered as a corpus-based method, the measure of Patwardhan and Pedersen (2006), who utilize the gloss words found from the words\u2019 definitions to create WordNet-based context vectors, the methods of Strube and Ponzetto (2006, 2007a), Gabrilovich and Markovitch (2007), and Milne and Witten (2008) who use Wikipedia to compute semantic relatedness and can also be considered as corpus-based approaches, and the method of Mihalcea, Corley and Strappavara (2006), which is a hybrid method that combines knowledge-based and corpus-based measures of text relatedness. Other recent hybrid measures of semantic similarity are: the measure proposed by Li et al. (2006), who use information from WordNet and corpus statistics collected from the Brown Corpus (Kucera,", "startOffset": 173, "endOffset": 1653}, {"referenceID": 74, "context": "Francis, & Caroll, 1967) to compute similarity between very short texts, and the measure for text distance proposed by Tsang (2008), that uses both distributional similarity and ontological/knowledge information to compute the distance between text fragments.", "startOffset": 119, "endOffset": 132}, {"referenceID": 37, "context": "Li et al. (2006) have created a new data set for their experimental evaluation, which we also use in Section 4 to evaluate our Omiotis measure and compare against their approach.", "startOffset": 0, "endOffset": 17}, {"referenceID": 83, "context": "In order to solve the problem of constructing semantic paths between words, we base our approach on our previous method on how to construct semantic networks between words (Tsatsaronis et al., 2007).", "startOffset": 172, "endOffset": 198}, {"referenceID": 42, "context": "A measure for WSD based on the idea of compactness was initially proposed by Mavroeidis et al. (2005). The original measure used only nouns and the hypernym relation, and is extended in the current work to support all of WordNet\u2019s relations and the noun, verb and adjective parts of speech.", "startOffset": 77, "endOffset": 102}, {"referenceID": 37, "context": "Higher compactness between senses implies higher semantic relatedness. The intuition behind edge types\u2019 weighting is that certain types provide stronger semantic connections than others. Considering that the lexicographers of WordNet tend to use some relation types more often than others (we assume that the most used relation types are stronger than the types less used), a straightforward solution is to define edge types\u2019 weights in proportion to their frequency of occurrence in WordNet 2.0. The weights assigned to each type using this solution are shown in Table 1 and are in accordance to those found by Song et al. (2004). The table shows the probability of occurrence in WordNet 2.", "startOffset": 37, "endOffset": 631}, {"referenceID": 16, "context": "Current data sets for evaluating semantic relatedness or even semantic similarity measures are restricted to nouns, like for example the Rubenstein and Goodenough 65 word pairs (1965), the Miller and Charles 30 word pairs (1991), and the Word-Similarity-353 collection (Finkelstein et al., 2002).", "startOffset": 269, "endOffset": 295}, {"referenceID": 36, "context": "Current data sets for evaluating semantic relatedness or even semantic similarity measures are restricted to nouns, like for example the Rubenstein and Goodenough 65 word pairs (1965), the Miller and Charles 30 word pairs (1991), and the Word-Similarity-353 collection (Finkelstein et al.", "startOffset": 116, "endOffset": 184}, {"referenceID": 36, "context": "Current data sets for evaluating semantic relatedness or even semantic similarity measures are restricted to nouns, like for example the Rubenstein and Goodenough 65 word pairs (1965), the Miller and Charles 30 word pairs (1991), and the Word-Similarity-353 collection (Finkelstein et al.", "startOffset": 116, "endOffset": 229}, {"referenceID": 72, "context": "Examples of such measures are: the measure of Sussna (1993), Wu and Palmer (1994), Jiang and Conrath (1997), Resnik (1995, 1999), and the WordNet-based component of the measure proposed by Finkelstein et al.", "startOffset": 46, "endOffset": 60}, {"referenceID": 72, "context": "Examples of such measures are: the measure of Sussna (1993), Wu and Palmer (1994), Jiang and Conrath (1997), Resnik (1995, 1999), and the WordNet-based component of the measure proposed by Finkelstein et al.", "startOffset": 46, "endOffset": 82}, {"referenceID": 30, "context": "Examples of such measures are: the measure of Sussna (1993), Wu and Palmer (1994), Jiang and Conrath (1997), Resnik (1995, 1999), and the WordNet-based component of the measure proposed by Finkelstein et al.", "startOffset": 83, "endOffset": 108}, {"referenceID": 16, "context": "Examples of such measures are: the measure of Sussna (1993), Wu and Palmer (1994), Jiang and Conrath (1997), Resnik (1995, 1999), and the WordNet-based component of the measure proposed by Finkelstein et al. (2002). From this point of view, the decision to use all POS information expands the potential matches found by the measure and allows the use of the measure in more complicated tasks, like paraphrase recognition, text retrieval, and text classification.", "startOffset": 189, "endOffset": 215}, {"referenceID": 83, "context": "2 USE EVERY TYPE OF SEMANTIC RELATIONS The decision to use all parts of speech in the construction of the semantic graphs, as it was introduced in our previous work (Tsatsaronis et al., 2007), imposes the involvement of all semantic relations instead of merely taxonomic (IS-A) ones.", "startOffset": 165, "endOffset": 191}, {"referenceID": 36, "context": "Moreover, this decision was based on evidence from related literature. The work of Smeaton et al. (1995) provides experimental evidence that measuring semantic similarity by incorporating non-hierarchical link types (i.", "startOffset": 59, "endOffset": 105}, {"referenceID": 36, "context": "Moreover, this decision was based on evidence from related literature. The work of Smeaton et al. (1995) provides experimental evidence that measuring semantic similarity by incorporating non-hierarchical link types (i.e. part meronym/holonym, member meronym/holonym, substance meronym/holonym) improves much the performance of such a measure. The experimental evaluation was conducted by adopting a small variation of the Resnik\u2019s measure (1995). Hirst and St-Onge (1998) reported that they have discovered several limitations and missing connections in the set of WordNet relations during the construction of lexical chains from sentences for the detection and correction of malapropisms.", "startOffset": 59, "endOffset": 447}, {"referenceID": 24, "context": "Hirst and St-Onge (1998) reported that they have discovered several limitations and missing connections in the set of WordNet relations during the construction of lexical chains from sentences for the detection and correction of malapropisms.", "startOffset": 0, "endOffset": 25}, {"referenceID": 55, "context": "3 USE WEIGHTS ON EDGES The work of Resnik (1999) reports that simple edge counting, which implicitly assumes that links in the taxonomy represent uniform distances, is problematic and is not the best semantic distance measure for WordNet.", "startOffset": 35, "endOffset": 49}, {"referenceID": 33, "context": "3 USE WEIGHTS ON EDGES The work of Resnik (1999) reports that simple edge counting, which implicitly assumes that links in the taxonomy represent uniform distances, is problematic and is not the best semantic distance measure for WordNet. In a similar direction lie the findings of Sussna (1993), who has performed thorough experimental evaluation by varying edge weights in order to measure semantic distance between concepts.", "startOffset": 93, "endOffset": 296}, {"referenceID": 32, "context": "This very important factor is absent in several similarity measures proposed in the past, such as in the measures of Leacock et al. (1998), Jarmasz and Szpakowicz (2003) and Banerjee and Pedersen (2003), which are outperformed in experimental evaluation by our measure.", "startOffset": 117, "endOffset": 139}, {"referenceID": 28, "context": "(1998), Jarmasz and Szpakowicz (2003) and Banerjee and Pedersen (2003), which are outperformed in experimental evaluation by our measure.", "startOffset": 8, "endOffset": 38}, {"referenceID": 4, "context": "(1998), Jarmasz and Szpakowicz (2003) and Banerjee and Pedersen (2003), which are outperformed in experimental evaluation by our measure.", "startOffset": 42, "endOffset": 71}, {"referenceID": 37, "context": "4 USE DEPTH SCALING FACTOR Our decision to incorporate the depth scaling factor (SPE in Definition 2) in the edge weighting mechanism has been inspired by the thorough experimental evaluation conducted by Sussna (1993),", "startOffset": 15, "endOffset": 219}, {"referenceID": 18, "context": "Although, such measures, like the ones proposed by Gabrilovich and Markovitch (2007), and Ponzetto and Strube (2007a), provide a larger coverage regarding concepts that do not reside in WordNet, they require the processing of a very large corpora (Wikipedia), which also changes very fast and very frequently.", "startOffset": 51, "endOffset": 85}, {"referenceID": 18, "context": "Although, such measures, like the ones proposed by Gabrilovich and Markovitch (2007), and Ponzetto and Strube (2007a), provide a larger coverage regarding concepts that do not reside in WordNet, they require the processing of a very large corpora (Wikipedia), which also changes very fast and very frequently.", "startOffset": 51, "endOffset": 118}, {"referenceID": 37, "context": "Harmonic mean is preferred instead of average, since it provides a more tight upper bound (Li, 2008).", "startOffset": 90, "endOffset": 100}, {"referenceID": 63, "context": "1 WORD-TO-WORD SIMILARITY Rubenstein and Goodenough (1965) obtained synonymy judgements from 51 human subjects on 65 pairs of words, in an effort to investigate the relationship between similarity of context and similarity of meaning (synonymy).", "startOffset": 26, "endOffset": 59}, {"referenceID": 85, "context": "1% (Turney, 2006), the top lexicon-based scores 42% (Veale, 2004) and the top hybrid scores 33.", "startOffset": 3, "endOffset": 17}, {"referenceID": 91, "context": "1% (Turney, 2006), the top lexicon-based scores 42% (Veale, 2004) and the top hybrid scores 33.", "startOffset": 52, "endOffset": 65}, {"referenceID": 61, "context": "2% (Resnik, 1995).", "startOffset": 3, "endOffset": 17}, {"referenceID": 35, "context": "Although it is difficult for machines to model the human cognition of word analogy, several approaches exist in the bibliography that attempt to tackle this problem. Previous approaches can be widely categorized into: corpus-based, lexicon-based and hybrid. Some examples of corpus-based are the approaches of Turney (2008b) and Bicici and Yuret (2006).", "startOffset": 119, "endOffset": 325}, {"referenceID": 8, "context": "Some examples of corpus-based are the approaches of Turney (2008b) and Bicici and Yuret (2006). Examples of lexicon-based approaches, are those of Veale (2004) and the application of the lexicon-based measure by Hirst and St-Onge (1998) in SAT, that can be found in the work of Turney (2006).", "startOffset": 71, "endOffset": 95}, {"referenceID": 8, "context": "Some examples of corpus-based are the approaches of Turney (2008b) and Bicici and Yuret (2006). Examples of lexicon-based approaches, are those of Veale (2004) and the application of the lexicon-based measure by Hirst and St-Onge (1998) in SAT, that can be found in the work of Turney (2006).", "startOffset": 71, "endOffset": 160}, {"referenceID": 8, "context": "Some examples of corpus-based are the approaches of Turney (2008b) and Bicici and Yuret (2006). Examples of lexicon-based approaches, are those of Veale (2004) and the application of the lexicon-based measure by Hirst and St-Onge (1998) in SAT, that can be found in the work of Turney (2006).", "startOffset": 71, "endOffset": 237}, {"referenceID": 8, "context": "Some examples of corpus-based are the approaches of Turney (2008b) and Bicici and Yuret (2006). Examples of lexicon-based approaches, are those of Veale (2004) and the application of the lexicon-based measure by Hirst and St-Onge (1998) in SAT, that can be found in the work of Turney (2006). Hybrid approaches are applied in SAT, through the application of the measures of Resnik (1995) and Lin (1998) that can also be found in the work of Turney (2006).", "startOffset": 71, "endOffset": 292}, {"referenceID": 8, "context": "Some examples of corpus-based are the approaches of Turney (2008b) and Bicici and Yuret (2006). Examples of lexicon-based approaches, are those of Veale (2004) and the application of the lexicon-based measure by Hirst and St-Onge (1998) in SAT, that can be found in the work of Turney (2006). Hybrid approaches are applied in SAT, through the application of the measures of Resnik (1995) and Lin (1998) that can also be found in the work of Turney (2006).", "startOffset": 71, "endOffset": 388}, {"referenceID": 8, "context": "Some examples of corpus-based are the approaches of Turney (2008b) and Bicici and Yuret (2006). Examples of lexicon-based approaches, are those of Veale (2004) and the application of the lexicon-based measure by Hirst and St-Onge (1998) in SAT, that can be found in the work of Turney (2006). Hybrid approaches are applied in SAT, through the application of the measures of Resnik (1995) and Lin (1998) that can also be found in the work of Turney (2006).", "startOffset": 71, "endOffset": 403}, {"referenceID": 8, "context": "Some examples of corpus-based are the approaches of Turney (2008b) and Bicici and Yuret (2006). Examples of lexicon-based approaches, are those of Veale (2004) and the application of the lexicon-based measure by Hirst and St-Onge (1998) in SAT, that can be found in the work of Turney (2006). Hybrid approaches are applied in SAT, through the application of the measures of Resnik (1995) and Lin (1998) that can also be found in the work of Turney (2006). In order for the reader to understand the difficulty of answering SAT questions, we must point out that the average US college applicant scores 57% (Turney & Littman, 2005), while the top corpus-based approach scores 56.", "startOffset": 71, "endOffset": 455}, {"referenceID": 20, "context": "Another way of categorizing the approaches that measure semantic similarity in analogy tasks is to distinguish among attributional and relational similarity measures (Gentner, 1983).", "startOffset": 166, "endOffset": 181}, {"referenceID": 85, "context": "7 Representative approaches of the first category are lexicon-based approaches, while paradigms of relational similarity measures can be found in approaches based on Latent Relational Analysis (LRA) (Turney, 2006).", "startOffset": 199, "endOffset": 213}, {"referenceID": 20, "context": "Another way of categorizing the approaches that measure semantic similarity in analogy tasks is to distinguish among attributional and relational similarity measures (Gentner, 1983).7 Representative approaches of the first category are lexicon-based approaches, while paradigms of relational similarity measures can be found in approaches based on Latent Relational Analysis (LRA) (Turney, 2006). It is of great interest to point out that LRA-based approaches, like the LRME algorithm proposed recently by Turney (2008a), are superior to attributional similarity approaches in discovering word analogies.", "startOffset": 167, "endOffset": 521}, {"referenceID": 20, "context": "Another way of categorizing the approaches that measure semantic similarity in analogy tasks is to distinguish among attributional and relational similarity measures (Gentner, 1983).7 Representative approaches of the first category are lexicon-based approaches, while paradigms of relational similarity measures can be found in approaches based on Latent Relational Analysis (LRA) (Turney, 2006). It is of great interest to point out that LRA-based approaches, like the LRME algorithm proposed recently by Turney (2008a), are superior to attributional similarity approaches in discovering word analogies. This fact is also supported by the experimental findings of Turney (2006). Without doubt, relational similarity approaches may perform better in the SAT analogy task, but still, as shown later in the experiments we conducted in other applications, like paraphrase recognition, the lexicon-based measures can outperform LRA-based approaches in such tasks.", "startOffset": 167, "endOffset": 679}, {"referenceID": 37, "context": "From this perspective, s1 and s2 try to find the candidate pair that best aligns with the target pair. Figure 4 illustrates these two types of analogies (horizontal and vertical) for an example SAT question. In order to motivate more our selection of s1 and s2 for answering SAT questions, we will discuss in more detail how these two quantities pertain to the concepts of strength and type of the relations between a pair of SAT words. Turney (2006) describes a method for comparing the relations between candidate word pairs and the stem word pair, in which he utilizes the type of the relation connecting the words in each pair and finally selects the pair that best matches the type of the relation connecting the words in the stem pair.", "startOffset": 75, "endOffset": 451}, {"referenceID": 37, "context": "3 PARAPHRASE RECOGNITION AND SENTENCE-TO-SENTENCE SIMILARITY Performance of applications relying on natural language processing may suffer from the fact that the processed documents might contain lexically different, yet semantically related, text segments. The task of recognizing synonym text segments, which is better known as paraphrase recognition, or detection, is challenging and difficult to solve, as shown in the work of Pasca (2005). The task itself is important for many text related applications, like summarization (Hirao, Fukusima, Oku-", "startOffset": 79, "endOffset": 444}, {"referenceID": 53, "context": "mura, Nobata, & Nanba, 2005), information extraction (Shinyama & Sekine, 2003) and question answering (Pasca, 2003).", "startOffset": 102, "endOffset": 115}, {"referenceID": 13, "context": "2), using the Microsoft Research Paraphrase Corpus (Dolan et al., 2004).", "startOffset": 51, "endOffset": 71}, {"referenceID": 13, "context": "2), using the Microsoft Research Paraphrase Corpus (Dolan et al., 2004). The application of Omiotis in paraphrase detection is straightforward: given a pair of text segments, we compute the Omiotis score between them, using Equation 10 and Algorithm 2. Higher values of Omiotis for a given pair denote stronger semantic relation between the examined text segments. The task is now reduced to define a threshold, above which an Omiotis value can be considered as a determining sign of a paraphrasing pair. In the experimental evaluation of Omiotis, we explain in detail how we have selected this threshold for the paraphrase recognition task. In a similar manner, by using Equation 10 and Algorithm 2, the semantic relatedness scores for pairs of sentences can be computed. For this task, we are using the data set of Li et al. (2006) to evaluate Omiotis, comprising 30 sentence pairs, for which human scores are provided.", "startOffset": 52, "endOffset": 834}, {"referenceID": 83, "context": "Primarily, given two words, w1 and w2 the construction time of the semantic network used to compute SR according to Algorithm 1, has been proven to be O(2 \u00b7 kl+1) (Tsatsaronis et al., 2007), where k is the maximum branching factor of the used thesaurus nodes and l is the maximum semantic path length in the thesaurus.", "startOffset": 163, "endOffset": 189}, {"referenceID": 81, "context": "As a proof of concept, we have developed an on-line version of the SR and the Omiotis measures8, where the user can test the term-to-term and sentence-to-sentence semantic relatedness measures (Tsatsaronis et al., 2009).", "startOffset": 193, "endOffset": 219}, {"referenceID": 16, "context": "In this task, we evaluate the performance of SR in three benchmark data sets, namely the Rubenstein and Goodenough 65 word pairs (1965) (R&G), and the Miller and Charles 30 word pairs (1991) (M&C), for which humans have provided similarity scores, and, also, in the Word-Similarity-353 collection (Finkelstein et al., 2002) (353-C), which comprises 353 word pairs, for which humans have provided relatedness scores.", "startOffset": 297, "endOffset": 323}, {"referenceID": 36, "context": "We evaluate the performance of measures, by computing the correlation between the list of the human rankings and the list produced by the measures. In this task, we evaluate the performance of SR in three benchmark data sets, namely the Rubenstein and Goodenough 65 word pairs (1965) (R&G), and the Miller and Charles 30 word pairs (1991) (M&C), for which humans have provided similarity scores, and, also, in the Word-Similarity-353 collection (Finkelstein et al.", "startOffset": 82, "endOffset": 284}, {"referenceID": 36, "context": "We evaluate the performance of measures, by computing the correlation between the list of the human rankings and the list produced by the measures. In this task, we evaluate the performance of SR in three benchmark data sets, namely the Rubenstein and Goodenough 65 word pairs (1965) (R&G), and the Miller and Charles 30 word pairs (1991) (M&C), for which humans have provided similarity scores, and, also, in the Word-Similarity-353 collection (Finkelstein et al.", "startOffset": 82, "endOffset": 339}, {"referenceID": 20, "context": "For the first category of experiments, we compared our measure against ten known measures of semantic relatedness: Hirst and St-Onge (1998) (HS), Jiang and Conrath (1997) (JC), Leacock et al.", "startOffset": 115, "endOffset": 140}, {"referenceID": 20, "context": "For the first category of experiments, we compared our measure against ten known measures of semantic relatedness: Hirst and St-Onge (1998) (HS), Jiang and Conrath (1997) (JC), Leacock et al.", "startOffset": 115, "endOffset": 171}, {"referenceID": 20, "context": "For the first category of experiments, we compared our measure against ten known measures of semantic relatedness: Hirst and St-Onge (1998) (HS), Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Jarmasz and Szpakowicz (2003) (JS), Gabrilovich and Markovitch (2007, 2009) (GM), Milne and Witten (2008) (WLM), Finkelstein et al.", "startOffset": 115, "endOffset": 199}, {"referenceID": 20, "context": "For the first category of experiments, we compared our measure against ten known measures of semantic relatedness: Hirst and St-Onge (1998) (HS), Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Jarmasz and Szpakowicz (2003) (JS), Gabrilovich and Markovitch (2007, 2009) (GM), Milne and Witten (2008) (WLM), Finkelstein et al.", "startOffset": 115, "endOffset": 216}, {"referenceID": 20, "context": "For the first category of experiments, we compared our measure against ten known measures of semantic relatedness: Hirst and St-Onge (1998) (HS), Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Jarmasz and Szpakowicz (2003) (JS), Gabrilovich and Markovitch (2007, 2009) (GM), Milne and Witten (2008) (WLM), Finkelstein et al.", "startOffset": 115, "endOffset": 276}, {"referenceID": 16, "context": "(1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Jarmasz and Szpakowicz (2003) (JS), Gabrilovich and Markovitch (2007, 2009) (GM), Milne and Witten (2008) (WLM), Finkelstein et al.", "startOffset": 90, "endOffset": 160}, {"referenceID": 15, "context": "(1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Jarmasz and Szpakowicz (2003) (JS), Gabrilovich and Markovitch (2007, 2009) (GM), Milne and Witten (2008) (WLM), Finkelstein et al. (2002) (LSA), Hughes and Ramage (2007) (HR), and Strube and Ponzetto (2006, 2007a) (SP).", "startOffset": 167, "endOffset": 193}, {"referenceID": 15, "context": "(1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Jarmasz and Szpakowicz (2003) (JS), Gabrilovich and Markovitch (2007, 2009) (GM), Milne and Witten (2008) (WLM), Finkelstein et al. (2002) (LSA), Hughes and Ramage (2007) (HR), and Strube and Ponzetto (2006, 2007a) (SP).", "startOffset": 167, "endOffset": 225}, {"referenceID": 10, "context": "For the measures HS, JC, LC, L and R, the rankings and the relatedness scores of the word pairs for the R&G and the M&C data sets, are given in the work of Budanitsky and Hirst (2006). For the JS measure, the r value is given in the work of Jarmasz and Szpakowicz (2003) for the R&G and the M&C data sets, and the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007).", "startOffset": 156, "endOffset": 184}, {"referenceID": 10, "context": "For the measures HS, JC, LC, L and R, the rankings and the relatedness scores of the word pairs for the R&G and the M&C data sets, are given in the work of Budanitsky and Hirst (2006). For the JS measure, the r value is given in the work of Jarmasz and Szpakowicz (2003) for the R&G and the M&C data sets, and the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007).", "startOffset": 156, "endOffset": 271}, {"referenceID": 10, "context": "For the measures HS, JC, LC, L and R, the rankings and the relatedness scores of the word pairs for the R&G and the M&C data sets, are given in the work of Budanitsky and Hirst (2006). For the JS measure, the r value is given in the work of Jarmasz and Szpakowicz (2003) for the R&G and the M&C data sets, and the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007). For the GM measure the \u03c1 values are given in the work of Gabrilovich and Markovitch (2007).", "startOffset": 156, "endOffset": 380}, {"referenceID": 10, "context": "For the measures HS, JC, LC, L and R, the rankings and the relatedness scores of the word pairs for the R&G and the M&C data sets, are given in the work of Budanitsky and Hirst (2006). For the JS measure, the r value is given in the work of Jarmasz and Szpakowicz (2003) for the R&G and the M&C data sets, and the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007). For the GM measure the \u03c1 values are given in the work of Gabrilovich and Markovitch (2007). For the WLM measure the \u03c1 values are given in the work of Milne and Witten (2008).", "startOffset": 156, "endOffset": 472}, {"referenceID": 10, "context": "For the measures HS, JC, LC, L and R, the rankings and the relatedness scores of the word pairs for the R&G and the M&C data sets, are given in the work of Budanitsky and Hirst (2006). For the JS measure, the r value is given in the work of Jarmasz and Szpakowicz (2003) for the R&G and the M&C data sets, and the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007). For the GM measure the \u03c1 values are given in the work of Gabrilovich and Markovitch (2007). For the WLM measure the \u03c1 values are given in the work of Milne and Witten (2008). For the LSA method the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007), only for the 353-C data set.", "startOffset": 156, "endOffset": 555}, {"referenceID": 10, "context": "For the measures HS, JC, LC, L and R, the rankings and the relatedness scores of the word pairs for the R&G and the M&C data sets, are given in the work of Budanitsky and Hirst (2006). For the JS measure, the r value is given in the work of Jarmasz and Szpakowicz (2003) for the R&G and the M&C data sets, and the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007). For the GM measure the \u03c1 values are given in the work of Gabrilovich and Markovitch (2007). For the WLM measure the \u03c1 values are given in the work of Milne and Witten (2008). For the LSA method the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007), only for the 353-C data set.", "startOffset": 156, "endOffset": 645}, {"referenceID": 10, "context": "For the measures HS, JC, LC, L and R, the rankings and the relatedness scores of the word pairs for the R&G and the M&C data sets, are given in the work of Budanitsky and Hirst (2006). For the JS measure, the r value is given in the work of Jarmasz and Szpakowicz (2003) for the R&G and the M&C data sets, and the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007). For the GM measure the \u03c1 values are given in the work of Gabrilovich and Markovitch (2007). For the WLM measure the \u03c1 values are given in the work of Milne and Witten (2008). For the LSA method the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007), only for the 353-C data set. For the HR measure the \u03c1 values are given in the work of Hughes and Ramage (2007). Finally, for the SP measure the r values are given in the work of Ponzetto and Strube (2007a), and for the IS-A SP are given in the work of Ponzetto and Strube (2007b).", "startOffset": 156, "endOffset": 757}, {"referenceID": 10, "context": "For the measures HS, JC, LC, L and R, the rankings and the relatedness scores of the word pairs for the R&G and the M&C data sets, are given in the work of Budanitsky and Hirst (2006). For the JS measure, the r value is given in the work of Jarmasz and Szpakowicz (2003) for the R&G and the M&C data sets, and the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007). For the GM measure the \u03c1 values are given in the work of Gabrilovich and Markovitch (2007). For the WLM measure the \u03c1 values are given in the work of Milne and Witten (2008). For the LSA method the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007), only for the 353-C data set. For the HR measure the \u03c1 values are given in the work of Hughes and Ramage (2007). Finally, for the SP measure the r values are given in the work of Ponzetto and Strube (2007a), and for the IS-A SP are given in the work of Ponzetto and Strube (2007b).", "startOffset": 156, "endOffset": 852}, {"referenceID": 10, "context": "For the measures HS, JC, LC, L and R, the rankings and the relatedness scores of the word pairs for the R&G and the M&C data sets, are given in the work of Budanitsky and Hirst (2006). For the JS measure, the r value is given in the work of Jarmasz and Szpakowicz (2003) for the R&G and the M&C data sets, and the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007). For the GM measure the \u03c1 values are given in the work of Gabrilovich and Markovitch (2007). For the WLM measure the \u03c1 values are given in the work of Milne and Witten (2008). For the LSA method the \u03c1 value is given in the work of Gabrilovich and Markovitch (2007), only for the 353-C data set. For the HR measure the \u03c1 values are given in the work of Hughes and Ramage (2007). Finally, for the SP measure the r values are given in the work of Ponzetto and Strube (2007a), and for the IS-A SP are given in the work of Ponzetto and Strube (2007b).", "startOffset": 156, "endOffset": 926}, {"referenceID": 17, "context": "We have also conducted a statistical significance test on the difference between SR correlations and the respective correlations of the compared measures, using Fisher\u2019s z-transformation (Fisher, 1915).", "startOffset": 187, "endOffset": 201}, {"referenceID": 10, "context": "The human scores for all pairs of words for the two data sets can be found in the analysis of Budanitsky and Hirst (2006). Note that the M&C data set is a subset of the R&G data set.", "startOffset": 94, "endOffset": 122}, {"referenceID": 10, "context": "The human scores for all pairs of words for the two data sets can be found in the analysis of Budanitsky and Hirst (2006). Note that the M&C data set is a subset of the R&G data set. In some cases, the computation of \u03c1 or r was not feasible, due to missing information regarding the detailed rankings or relatedness scores for the respective measures. In these cases the table has the entry N/A. Also the LSA measure is omitted in this table because \u03c1 and r were not reported in the literature for these two data sets. We have also conducted a statistical significance test on the difference between SR correlations and the respective correlations of the compared measures, using Fisher\u2019s z-transformation (Fisher, 1915). For each reported number, the symbol \u00a7 indicates that the difference between the correlation produced by SR and the respective measure is statistically significant at the 0.99 confidence level (p < 0.01). The symbol \u2021 indicates the same at the 0.95 confidence level (p < 0.05) and, finally, the symbol \u2020 indicates statistical significance of the correlations\u2019 difference at the 0.90 confidence level (p < 0.10). In cases when the difference is not statistically significant in any of those confidence levels, there is no indicating symbol. In Table 4 we show the values of \u03c1 and r for the 353-C data set. The reason we present the results of the experiments in the 353-C data set in another table than the respective results of the R&B and M&C data sets is that this collection focuses on the concept of semantic relatedness, rather than on the concept of semantic similarity (Gabrilovich & Markovitch, 2007). Relatedness is more general concept than similarity, as argued in the analysis of Budanitsky and Hirst (2006). Thus, it can be argued that the humans in the 353-C thought differently when scoring, compared to the case of the R&B and M&C data sets.", "startOffset": 94, "endOffset": 1742}, {"referenceID": 2, "context": "In order to test the statistical significance of the differences in the measures\u2019 performance, we conducted Fisher\u2019s Exact Test (Agresti, 1990).", "startOffset": 128, "endOffset": 143}, {"referenceID": 89, "context": "The results of Table 5 show that SR ranks second among all reported methods, with the best method being the hybrid PR (Turney et al., 2003).", "startOffset": 118, "endOffset": 139}, {"referenceID": 28, "context": "More specifically, we examine: the lexicon-based measures of Leacock et al. (1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al.", "startOffset": 61, "endOffset": 83}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al.", "startOffset": 13, "endOffset": 38}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al.", "startOffset": 13, "endOffset": 78}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al.", "startOffset": 13, "endOffset": 140}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al.", "startOffset": 13, "endOffset": 169}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al.", "startOffset": 13, "endOffset": 190}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al.", "startOffset": 13, "endOffset": 219}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al. (2005) (M); the hybrid measures of Resnik (1995) (R), Lin (1998) (L), Jiang and Conrath (1997) (JC), and Turney et al.", "startOffset": 13, "endOffset": 252}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al. (2005) (M); the hybrid measures of Resnik (1995) (R), Lin (1998) (L), Jiang and Conrath (1997) (JC), and Turney et al.", "startOffset": 13, "endOffset": 294}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al. (2005) (M); the hybrid measures of Resnik (1995) (R), Lin (1998) (L), Jiang and Conrath (1997) (JC), and Turney et al.", "startOffset": 13, "endOffset": 310}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al. (2005) (M); the hybrid measures of Resnik (1995) (R), Lin (1998) (L), Jiang and Conrath (1997) (JC), and Turney et al.", "startOffset": 13, "endOffset": 340}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al. (2005) (M); the hybrid measures of Resnik (1995) (R), Lin (1998) (L), Jiang and Conrath (1997) (JC), and Turney et al. (2003) (PR); and a Web-based method by RuizCasado et al.", "startOffset": 13, "endOffset": 371}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Landauer and Dumais (1997) (LD), Pado and Lapata (2007) (PL), Turney (2008b) (T), Terra and Clarke (2003) (TC), and Matveeva et al. (2005) (M); the hybrid measures of Resnik (1995) (R), Lin (1998) (L), Jiang and Conrath (1997) (JC), and Turney et al. (2003) (PR); and a Web-based method by RuizCasado et al. (2005) (RC).", "startOffset": 13, "endOffset": 428}, {"referenceID": 2, "context": "In order to test the statistical significance of the differences in the measures\u2019 performance, we conducted Fisher\u2019s Exact Test (Agresti, 1990). As in the previous tables, the symbol \u00a7 indicates statistically significant difference at the 0.99 confidence level, \u2021 at the 0.95 confidence level, and \u2020 at the 0.90 confidence level. The results of Table 5 show that SR ranks second among all reported methods, with the best method being the hybrid PR (Turney et al., 2003). With regards to its comparison with the lexicon-based methods, SR reports better results, statistically significant at the confidence levels indicated. In a similar manner, we have conducted experiments in the ESL 50 questions data set, and compare our results with: the lexicon-based measures of Leacock et al. (1998) (LC), Hirst and StOnge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Turney (2001) (PMI-IR), and Terra and Clarke (2003) (TC); and the hybrid measures of Resnik (1995) (R),", "startOffset": 129, "endOffset": 790}, {"referenceID": 2, "context": "In order to test the statistical significance of the differences in the measures\u2019 performance, we conducted Fisher\u2019s Exact Test (Agresti, 1990). As in the previous tables, the symbol \u00a7 indicates statistically significant difference at the 0.99 confidence level, \u2021 at the 0.95 confidence level, and \u2020 at the 0.90 confidence level. The results of Table 5 show that SR ranks second among all reported methods, with the best method being the hybrid PR (Turney et al., 2003). With regards to its comparison with the lexicon-based methods, SR reports better results, statistically significant at the confidence levels indicated. In a similar manner, we have conducted experiments in the ESL 50 questions data set, and compare our results with: the lexicon-based measures of Leacock et al. (1998) (LC), Hirst and StOnge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Turney (2001) (PMI-IR), and Terra and Clarke (2003) (TC); and the hybrid measures of Resnik (1995) (R),", "startOffset": 129, "endOffset": 820}, {"referenceID": 2, "context": "In order to test the statistical significance of the differences in the measures\u2019 performance, we conducted Fisher\u2019s Exact Test (Agresti, 1990). As in the previous tables, the symbol \u00a7 indicates statistically significant difference at the 0.99 confidence level, \u2021 at the 0.95 confidence level, and \u2020 at the 0.90 confidence level. The results of Table 5 show that SR ranks second among all reported methods, with the best method being the hybrid PR (Turney et al., 2003). With regards to its comparison with the lexicon-based methods, SR reports better results, statistically significant at the confidence levels indicated. In a similar manner, we have conducted experiments in the ESL 50 questions data set, and compare our results with: the lexicon-based measures of Leacock et al. (1998) (LC), Hirst and StOnge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Turney (2001) (PMI-IR), and Terra and Clarke (2003) (TC); and the hybrid measures of Resnik (1995) (R),", "startOffset": 129, "endOffset": 860}, {"referenceID": 2, "context": "In order to test the statistical significance of the differences in the measures\u2019 performance, we conducted Fisher\u2019s Exact Test (Agresti, 1990). As in the previous tables, the symbol \u00a7 indicates statistically significant difference at the 0.99 confidence level, \u2021 at the 0.95 confidence level, and \u2020 at the 0.90 confidence level. The results of Table 5 show that SR ranks second among all reported methods, with the best method being the hybrid PR (Turney et al., 2003). With regards to its comparison with the lexicon-based methods, SR reports better results, statistically significant at the confidence levels indicated. In a similar manner, we have conducted experiments in the ESL 50 questions data set, and compare our results with: the lexicon-based measures of Leacock et al. (1998) (LC), Hirst and StOnge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Turney (2001) (PMI-IR), and Terra and Clarke (2003) (TC); and the hybrid measures of Resnik (1995) (R),", "startOffset": 129, "endOffset": 909}, {"referenceID": 2, "context": "In order to test the statistical significance of the differences in the measures\u2019 performance, we conducted Fisher\u2019s Exact Test (Agresti, 1990). As in the previous tables, the symbol \u00a7 indicates statistically significant difference at the 0.99 confidence level, \u2021 at the 0.95 confidence level, and \u2020 at the 0.90 confidence level. The results of Table 5 show that SR ranks second among all reported methods, with the best method being the hybrid PR (Turney et al., 2003). With regards to its comparison with the lexicon-based methods, SR reports better results, statistically significant at the confidence levels indicated. In a similar manner, we have conducted experiments in the ESL 50 questions data set, and compare our results with: the lexicon-based measures of Leacock et al. (1998) (LC), Hirst and StOnge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Turney (2001) (PMI-IR), and Terra and Clarke (2003) (TC); and the hybrid measures of Resnik (1995) (R),", "startOffset": 129, "endOffset": 947}, {"referenceID": 2, "context": "In order to test the statistical significance of the differences in the measures\u2019 performance, we conducted Fisher\u2019s Exact Test (Agresti, 1990). As in the previous tables, the symbol \u00a7 indicates statistically significant difference at the 0.99 confidence level, \u2021 at the 0.95 confidence level, and \u2020 at the 0.90 confidence level. The results of Table 5 show that SR ranks second among all reported methods, with the best method being the hybrid PR (Turney et al., 2003). With regards to its comparison with the lexicon-based methods, SR reports better results, statistically significant at the confidence levels indicated. In a similar manner, we have conducted experiments in the ESL 50 questions data set, and compare our results with: the lexicon-based measures of Leacock et al. (1998) (LC), Hirst and StOnge (1998) (HS), and Jarmasz and Szpakowicz (2003) (JS); the corpus-based measures of Turney (2001) (PMI-IR), and Terra and Clarke (2003) (TC); and the hybrid measures of Resnik (1995) (R),", "startOffset": 129, "endOffset": 994}, {"referenceID": 31, "context": "Lin (1998) (L), and Jiang and Conrath (1997) (JC).", "startOffset": 20, "endOffset": 45}, {"referenceID": 84, "context": "(2008) (B), Veale (2004) (V), PMI-IR (Turney, 2001) and LRA (Turney, 2006).", "startOffset": 37, "endOffset": 51}, {"referenceID": 85, "context": "(2008) (B), Veale (2004) (V), PMI-IR (Turney, 2001) and LRA (Turney, 2006).", "startOffset": 60, "endOffset": 74}, {"referenceID": 28, "context": "In Table 7, we present the number of correct answers and the respective percentage (recall) on the 374 SAT questions, of the following methods: random guessing (RG), Jiang and Conrath (1997) (JC), Lin (1998) (L), Leacock et al.", "startOffset": 166, "endOffset": 191}, {"referenceID": 28, "context": "In Table 7, we present the number of correct answers and the respective percentage (recall) on the 374 SAT questions, of the following methods: random guessing (RG), Jiang and Conrath (1997) (JC), Lin (1998) (L), Leacock et al.", "startOffset": 166, "endOffset": 208}, {"referenceID": 28, "context": "In Table 7, we present the number of correct answers and the respective percentage (recall) on the 374 SAT questions, of the following methods: random guessing (RG), Jiang and Conrath (1997) (JC), Lin (1998) (L), Leacock et al. (1998) (LC), Hirst and St-Onge (1998) (HS), Resnik (1995) (R), Bollegala et al.", "startOffset": 166, "endOffset": 235}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), Resnik (1995) (R), Bollegala et al.", "startOffset": 13, "endOffset": 38}, {"referenceID": 22, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), Resnik (1995) (R), Bollegala et al.", "startOffset": 13, "endOffset": 58}, {"referenceID": 9, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), Resnik (1995) (R), Bollegala et al. (2008) (B), Veale (2004) (V), PMI-IR (Turney, 2001) and LRA (Turney, 2006).", "startOffset": 63, "endOffset": 87}, {"referenceID": 9, "context": "(1998) (LC), Hirst and St-Onge (1998) (HS), Resnik (1995) (R), Bollegala et al. (2008) (B), Veale (2004) (V), PMI-IR (Turney, 2001) and LRA (Turney, 2006).", "startOffset": 63, "endOffset": 105}, {"referenceID": 85, "context": "At this point we have to note that the LRA method needs almost 8 days to process the 374 SAT questions (Turney, 2006), (B) needs around 6 hours (Bollegala et al.", "startOffset": 103, "endOffset": 117}, {"referenceID": 9, "context": "At this point we have to note that the LRA method needs almost 8 days to process the 374 SAT questions (Turney, 2006), (B) needs around 6 hours (Bollegala et al., 2008), while S needs less than 3 minutes.", "startOffset": 144, "endOffset": 168}, {"referenceID": 36, "context": "We then trained and tested a Naive Bayes classifier using ten-fold cross validation in the 374 SAT questions. The results of this experiment are shown in the table as NB (Naive Bayes). Finally, we also present the top results ever reported in the literature for the specific data set, which is the LRA method by Turney (2006). This is reported in the table as (LRA).", "startOffset": 75, "endOffset": 326}, {"referenceID": 36, "context": "We then trained and tested a Naive Bayes classifier using ten-fold cross validation in the 374 SAT questions. The results of this experiment are shown in the table as NB (Naive Bayes). Finally, we also present the top results ever reported in the literature for the specific data set, which is the LRA method by Turney (2006). This is reported in the table as (LRA). The results presented in Table 7 show that S ranks second among the compared lexicon-based measures with the first being the measure of Veale (2004) (V).", "startOffset": 75, "endOffset": 516}, {"referenceID": 9, "context": "The method of Bollegala et al. (2008) (B) achieves higher score than SR, but needs training in SAT questions.", "startOffset": 14, "endOffset": 38}, {"referenceID": 13, "context": "The second experiment is based on the paraphrase recognition task, using the Microsoft Research Paraphrase Corpus (Dolan et al., 2004).", "startOffset": 114, "endOffset": 134}, {"referenceID": 36, "context": "2 Evaluation of the Omiotis Measure In order to evaluate the performance of the Omiotis measure, we performed two experiments which test the ability of the measure to capture the similarity between sentences. The first experiment is based on the data set produced by Li et al. (2006). The second experiment is based on the paraphrase recognition task, using the Microsoft Research Paraphrase Corpus (Dolan et al.", "startOffset": 144, "endOffset": 284}, {"referenceID": 71, "context": "The used dictionary was the Collins Cobuild dictionary (Sinclair, 2001).", "startOffset": 55, "endOffset": 71}, {"referenceID": 36, "context": "1 EVALUATION ON SENTENCE SIMILARITY The data set produced by Li et al. (2006) comprises 65 sentence pairs (each pair consists of two sentences that are the respective dictionary word definitions of the R&G 65 word pairs data set).", "startOffset": 61, "endOffset": 78}, {"referenceID": 36, "context": "1 EVALUATION ON SENTENCE SIMILARITY The data set produced by Li et al. (2006) comprises 65 sentence pairs (each pair consists of two sentences that are the respective dictionary word definitions of the R&G 65 word pairs data set). The used dictionary was the Collins Cobuild dictionary (Sinclair, 2001). For each sentence pair, similarity scores have been provided by 32 human participants, ranging from 0.0 (the sentences are unrelated in meaning), to 4.0 (the sentences are identical in meaning).12. From the 65 sentence pairs, Li et al. (2006) decided to keep a subset of 30 sentence pairs, similarly to the process applied by Miller and Charles (1991), in order to retain the sentences whose human ratings create a more even distribution across the similarity range.", "startOffset": 61, "endOffset": 547}, {"referenceID": 36, "context": "1 EVALUATION ON SENTENCE SIMILARITY The data set produced by Li et al. (2006) comprises 65 sentence pairs (each pair consists of two sentences that are the respective dictionary word definitions of the R&G 65 word pairs data set). The used dictionary was the Collins Cobuild dictionary (Sinclair, 2001). For each sentence pair, similarity scores have been provided by 32 human participants, ranging from 0.0 (the sentences are unrelated in meaning), to 4.0 (the sentences are identical in meaning).12. From the 65 sentence pairs, Li et al. (2006) decided to keep a subset of 30 sentence pairs, similarly to the process applied by Miller and Charles (1991), in order to retain the sentences whose human ratings create a more even distribution across the similarity range.", "startOffset": 61, "endOffset": 656}, {"referenceID": 36, "context": "1 EVALUATION ON SENTENCE SIMILARITY The data set produced by Li et al. (2006) comprises 65 sentence pairs (each pair consists of two sentences that are the respective dictionary word definitions of the R&G 65 word pairs data set). The used dictionary was the Collins Cobuild dictionary (Sinclair, 2001). For each sentence pair, similarity scores have been provided by 32 human participants, ranging from 0.0 (the sentences are unrelated in meaning), to 4.0 (the sentences are identical in meaning).12. From the 65 sentence pairs, Li et al. (2006) decided to keep a subset of 30 sentence pairs, similarly to the process applied by Miller and Charles (1991), in order to retain the sentences whose human ratings create a more even distribution across the similarity range. Thus, we apply Omiotis in this same subset of the 65 sentence pairs, described by Li et al. (2006). In this data set, we compare Omiotis against the STASIS measure of semantic similarity, proposed by Li et al.", "startOffset": 61, "endOffset": 870}, {"referenceID": 36, "context": "1 EVALUATION ON SENTENCE SIMILARITY The data set produced by Li et al. (2006) comprises 65 sentence pairs (each pair consists of two sentences that are the respective dictionary word definitions of the R&G 65 word pairs data set). The used dictionary was the Collins Cobuild dictionary (Sinclair, 2001). For each sentence pair, similarity scores have been provided by 32 human participants, ranging from 0.0 (the sentences are unrelated in meaning), to 4.0 (the sentences are identical in meaning).12. From the 65 sentence pairs, Li et al. (2006) decided to keep a subset of 30 sentence pairs, similarly to the process applied by Miller and Charles (1991), in order to retain the sentences whose human ratings create a more even distribution across the similarity range. Thus, we apply Omiotis in this same subset of the 65 sentence pairs, described by Li et al. (2006). In this data set, we compare Omiotis against the STASIS measure of semantic similarity, proposed by Li et al. (2006), an LSA-based approach described by O\u2019Shea et al.", "startOffset": 61, "endOffset": 988}, {"referenceID": 36, "context": "1 EVALUATION ON SENTENCE SIMILARITY The data set produced by Li et al. (2006) comprises 65 sentence pairs (each pair consists of two sentences that are the respective dictionary word definitions of the R&G 65 word pairs data set). The used dictionary was the Collins Cobuild dictionary (Sinclair, 2001). For each sentence pair, similarity scores have been provided by 32 human participants, ranging from 0.0 (the sentences are unrelated in meaning), to 4.0 (the sentences are identical in meaning).12. From the 65 sentence pairs, Li et al. (2006) decided to keep a subset of 30 sentence pairs, similarly to the process applied by Miller and Charles (1991), in order to retain the sentences whose human ratings create a more even distribution across the similarity range. Thus, we apply Omiotis in this same subset of the 65 sentence pairs, described by Li et al. (2006). In this data set, we compare Omiotis against the STASIS measure of semantic similarity, proposed by Li et al. (2006), an LSA-based approach described by O\u2019Shea et al. (2008), and the STS measure proposed by Islam and Inkpen (2008).", "startOffset": 61, "endOffset": 1045}, {"referenceID": 27, "context": "(2008), and the STS measure proposed by Islam and Inkpen (2008). To the best of our knowledge, this data set has only been used by these three", "startOffset": 40, "endOffset": 64}, {"referenceID": 29, "context": "text semantic relatedness values, though these types of relations have been reported in the previous bibliography as advantageous (Jarmasz, 2003; Jarmasz & Szpakowicz, 2003), but their individual contribution had never been measured.", "startOffset": 130, "endOffset": 173}, {"referenceID": 29, "context": "text semantic relatedness values, though these types of relations have been reported in the previous bibliography as advantageous (Jarmasz, 2003; Jarmasz & Szpakowicz, 2003), but their individual contribution had never been measured. We also show the r correlation between the average participant (mean of individuals with group; n = 32, leave-one-out resampling and standard deviation 0.072), the worst participant (worst participant with group; n = 32, leave-one-out resampling) and the best participant (best participant with group; n = 32, leave-one-out resampling), taken from the work of O\u2019Shea et al. (2008). In addition, we have also conducted a z-test regarding the difference between Omiotis correlations and the compared measures\u2019 correlations.", "startOffset": 131, "endOffset": 615}, {"referenceID": 13, "context": "In order to further evaluate the performance of Omiotis in measuring the semantic relatedness between small text segments, we conducted additional experiments on the paraphrase recognition task using the test pairs of the Microsoft Research Paraphrase Corpus (Dolan et al., 2004).", "startOffset": 259, "endOffset": 279}, {"referenceID": 33, "context": "& Hickl, 2006), and text summarization (Madnani, Zajic, Dorr, Fazil Ayan, & Lin, 2007). For this task we computed Omiotis between the sentences of every pair and marked as paraphrases only those pairs with Omiotis value greater than a threshold. The threshold was set to 0.2, after tuning in the training set. We used a simple approach for the tuning, namely forward hill-climbing and beam search (Guyon, Gunn, Nikravesh, & Zadeh, 2006). We compare the performance of Omiotis against several other methods of various categories; more precisely, against: (a) two baseline methods, a random selection method that marks randomly each pair as being paraphrase of not (Random), and a vector-based similarity measure, using the cosine similarity measure and TF-IDF weighting for the features (VSM and Cosine) 13, (b) corpusbased methods; the PMI-IR proposed by Turney (2001), an LSA-based approach introduced by Mihalcea et al.", "startOffset": 76, "endOffset": 869}, {"referenceID": 33, "context": "& Hickl, 2006), and text summarization (Madnani, Zajic, Dorr, Fazil Ayan, & Lin, 2007). For this task we computed Omiotis between the sentences of every pair and marked as paraphrases only those pairs with Omiotis value greater than a threshold. The threshold was set to 0.2, after tuning in the training set. We used a simple approach for the tuning, namely forward hill-climbing and beam search (Guyon, Gunn, Nikravesh, & Zadeh, 2006). We compare the performance of Omiotis against several other methods of various categories; more precisely, against: (a) two baseline methods, a random selection method that marks randomly each pair as being paraphrase of not (Random), and a vector-based similarity measure, using the cosine similarity measure and TF-IDF weighting for the features (VSM and Cosine) 13, (b) corpusbased methods; the PMI-IR proposed by Turney (2001), an LSA-based approach introduced by Mihalcea et al. (2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al.", "startOffset": 76, "endOffset": 929}, {"referenceID": 27, "context": "(2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al.", "startOffset": 40, "endOffset": 64}, {"referenceID": 27, "context": "(2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al.", "startOffset": 40, "endOffset": 116}, {"referenceID": 27, "context": "(2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Lesk (1986) (Lesk), Wu and Palmer (1994) (WP), and a metric that combines the measures of this category, proposed by Mihalcea et al.", "startOffset": 40, "endOffset": 144}, {"referenceID": 27, "context": "(2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Lesk (1986) (Lesk), Wu and Palmer (1994) (WP), and a metric that combines the measures of this category, proposed by Mihalcea et al.", "startOffset": 40, "endOffset": 161}, {"referenceID": 27, "context": "(2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Lesk (1986) (Lesk), Wu and Palmer (1994) (WP), and a metric that combines the measures of this category, proposed by Mihalcea et al.", "startOffset": 40, "endOffset": 203}, {"referenceID": 27, "context": "(2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Lesk (1986) (Lesk), Wu and Palmer (1994) (WP), and a metric that combines the measures of this category, proposed by Mihalcea et al.", "startOffset": 40, "endOffset": 232}, {"referenceID": 27, "context": "(2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Lesk (1986) (Lesk), Wu and Palmer (1994) (WP), and a metric that combines the measures of this category, proposed by Mihalcea et al. (2006) (Comb.", "startOffset": 40, "endOffset": 331}, {"referenceID": 27, "context": "(2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Lesk (1986) (Lesk), Wu and Palmer (1994) (WP), and a metric that combines the measures of this category, proposed by Mihalcea et al. (2006) (Comb.), and (d) machine-learning based techniques, which also constitute the state of the art in paraphrase recognition, like the method of Wan et al. (2006), which trains a classifier with lexical and dependency similarity measures, the method of Zhang and Patrick (2005), who also build a feature vector with lexical similarities between the sentence pairs (e.", "startOffset": 40, "endOffset": 490}, {"referenceID": 27, "context": "(2006), and the STS measure proposed by Islam and Inkpen (2008), (c) lexiconbased methods; Jiang and Conrath (1997) (JC), Leacock et al. (1998) (LC), Lin (1998) (L), Resnik (1995, 1999) (R), Lesk (1986) (Lesk), Wu and Palmer (1994) (WP), and a metric that combines the measures of this category, proposed by Mihalcea et al. (2006) (Comb.), and (d) machine-learning based techniques, which also constitute the state of the art in paraphrase recognition, like the method of Wan et al. (2006), which trains a classifier with lexical and dependency similarity measures, the method of Zhang and Patrick (2005), who also build a feature vector with lexical similarities between the sentence pairs (e.", "startOffset": 40, "endOffset": 605}, {"referenceID": 90, "context": "(2006), who use an SVM classifier (Vapnik, 1995) to decide whether or not a set of features for each sentence that has been created by parsing and semantic role labelling matches or not the respective set of the second sentence in the pair, and with what importance, and, finally, the method of Finch et al.", "startOffset": 34, "endOffset": 48}, {"referenceID": 15, "context": "(2006), who use an SVM classifier (Vapnik, 1995) to decide whether or not a set of features for each sentence that has been created by parsing and semantic role labelling matches or not the respective set of the second sentence in the pair, and with what importance, and, finally, the method of Finch et al. (2005), who also train an SVM classifier based on machine translation evaluation metrics.", "startOffset": 295, "endOffset": 315}, {"referenceID": 42, "context": "The results indicate that Omiotis surpasses all the lexicon-based methods, and matches the combined method of Mihalcea et al. (2006). At this point we must mention that we also tuned Omiotis with a goal to maximize F-Measure in the test set, at the cost of dropping precision in favor of recall.", "startOffset": 110, "endOffset": 133}], "year": 2009, "abstractText": "The computation of relatedness between two fragments of text in an automated manner requires taking into account a wide range of factors pertaining to the meaning the two fragments convey, and the pairwise relations between their words. Without doubt, a measure of relatedness between text segments must take into account both the lexical and the semantic relatedness between words. Such a measure that captures well both aspects of text relatedness may help in many tasks, such as text retrieval, classification and clustering. In this paper we present a new approach for measuring the semantic relatedness between words based on their implicit semantic links. The approach exploits only a word thesaurus in order to devise implicit semantic links between words. Based on this approach, we introduce Omiotis, a new measure of semantic relatedness between texts which capitalizes on the word-to-word semantic relatedness measure (SR) and extends it to measure the relatedness between texts. We gradually validate our method: we first evaluate the performance of the semantic relatedness measure between individual words, covering word-to-word similarity and relatedness, synonym identification and word analogy; then, we proceed with evaluating the performance of our method in measuring text-to-text semantic relatedness in two tasks, namely sentence-to-sentence similarity and paraphrase recognition. Experimental evaluation shows that the proposed method outperforms every lexicon-based method of semantic relatedness in the selected tasks and the used data sets, and competes well against corpus-based and hybrid approaches.", "creator": "gnuplot 4.2 patchlevel 2 "}}}