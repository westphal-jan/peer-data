{"id": "1401.5700", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Inferring Shallow-Transfer Machine Translation Rules from Small Parallel Corpora", "abstract": "This paper describes a method for the automatic inference of structural transfer rules to be used in a shallow-transfer machine translation (MT) system from small parallel corpora. The structural transfer rules are based on alignment templates, like those used in statistical MT. Alignment templates are extracted from sentence-aligned parallel corpora and extended with a set of restrictions which are derived from the bilingual dictionary of the MT system and control their application as transfer rules. The experiments conducted using three different language pairs in the free/open-source MT platform Apertium show that translation quality is improved as compared to word-for-word translation (when no transfer rules are used), and that the resulting translation quality is close to that obtained using hand-coded transfer rules. The method we present is entirely unsupervised and benefits from information in the rest of modules of the MT system in which the inferred rules are applied.", "histories": [["v1", "Wed, 15 Jan 2014 05:28:26 GMT  (282kb)", "http://arxiv.org/abs/1401.5700v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["felipe s\\'anchez-mart\\'inez", "mikel l forcada"], "accepted": false, "id": "1401.5700"}, "pdf": {"name": "1401.5700.pdf", "metadata": {"source": "CRF", "title": "Inferring Shallow-Transfer Machine Translation Rules from Small Parallel Corpora", "authors": ["Felipe S\u00e1nchez-Mart\u0301\u0131nez", "Mikel L. Forcada"], "emails": ["fsanchez@dlsi.ua.es", "mlf@dlsi.ua.es"], "sections": [{"heading": "1. Introduction", "text": "In fact, it is a purely reactionary project, which is about putting people's interests at the centre, not putting them at the centre."}, {"heading": "1.1 Overview", "text": "This work focuses on the automatic conclusion of small parallel corpora of structural (shallow) transmission rules used by shallow transfer RBMT systems to transform an SL IR into the TL IR from which the TL text is generated. Developing such transmission rules requires skilled people to encode them manually; therefore, their automatic inference can save some of this human effort. The method we present is completely uncontrolled and benefits from information in the rest of the modules of the MT system in which the inferred rules are applied, in accordance with the method of transferring rules proposed by Sa-Mart. (2008) to train some of the speakers for their use in an unattended manner. In our approach, an existing bilingual dictionary is used to draw conclusions on structural transmission rules (see below), and bilingual entries for this dictionary are not learned."}, {"heading": "1.2 Related Work", "text": "This year it is more than ever before."}, {"heading": "2. The Alignment Template Approach", "text": "The alignment template approach (AT) (Och, 2002; Och & Ney, 2004) was introduced in the SMT framework as one of the features of the Maximum Entropy Model (Och & Ney, 2002) to try to generalize the knowledge learned for a particular phrase into similar phrases. An AT generalizes over bilingual pairs of phrases using word classes instead of words. An AT z = (Sm, Tn, A) consists of a sequence Sm of m SL word classes, a sequence Tn of n TL word classes, and a series of pairs A = {(i, j): (i) calculating the alignment information between the TL and SL word classes in the two sequences."}, {"heading": "2.1 Word Alignments", "text": "A variety of methods, statistically (Och & Ney, 2003) or hybrid (Caseli et al., 2005), 3 can be used to calculate word alignments from a (sentence-oriented) parallel corpus. In the experiments reported in Section 5, word alignments are achieved by forming classic statistical translation models to translate from language L1 into language L2 (and vice versa) and then calculate the Viterbi alignments among the previously estimated translation models.The Viterbi alignment between SL and TL sentences is defined as the alignment most likely to occur among the previously estimated translation models.The resulting Viterbi alignments A1 and A2 (one for each translation direction) are symmetrized by the refined intersection method proposed by Och and Ney (2003, p. 33).Symmetry is needed to align an SL word with more than one TL word."}, {"heading": "2.1.1 Training", "text": "To train the translation models and calculate the viterbi alignments of each pair of aligned sentences found in the training corpus, the free / open source tool4 GIZA + + (Och & Ney, 2003) is used with standard parameters. The calculation of the alignments consists of: 1. Training IBM Model 1 (Brown et al., 1993) for 5 alignment probabilities; in this model, the alignment order does not affect the alignment probabilities; 2. Training the HMM alignment model (Vogel et al., 1996) for 5 alignment probabilities; this alignment model has the property of making alignment probabilities explicitly dependent on the alignment position of the previous word; 3. Training IBM Model 3 (Brown et al., 1993) for 5 alignment probabilities; in this model, the probability of alignment depends on the positions of the aligned words and the length of the previous alignment sentences."}, {"heading": "2.2 Extraction of Bilingual Phrase Pairs", "text": "Bilingual sentence pairs are automatically extracted from the word-sentence pairs. Normally, the extraction of bilingual sentence pairs (Zens et al., 2002) is performed by taking into account all possible pairs below a certain length and ensuring that: (i) all words are continuous, and (ii) words within the bilingual sentence pair are not reconciled with words from the outside. The amount BP (wSJ1, wT I 1, A) = {(wS j + m j, wT i + n i): (wS1,., wSJ), (wT1,.., wTI) can be formally expressed as follows: BP (wSJ1, wT I 1, A) = (wS j + m j), wT i + n i): (i \u2032, j \u00b2)."}, {"heading": "2.3 Generalization", "text": "The generalization of bilingual phrase pairs is done simply by using word classes instead of the words themselves; for this purpose, a function is defined that maps individual words into word classes. Using word classes allows the description of word re-orders, preposition changes, and other deviations between SL and TL. Och and Ney (2004) use automatically obtained (Och, 1999) word classes to extract ATs for SMT. However, RBMT must use linguistically motivated word classes that are related to those of the other modules in the MT system (see Section 3.1)."}, {"heading": "3. Alignment Templates for Shallow-Transfer Machine Translation", "text": "In order to apply the AT approach in a shallow-transfer MT system, the parallel corpus from which the ATs are learned must be in the intermediate representation (IR) used by the translation machine. In shallow-transfer MT, the transformations to be applied are mainly related to lexical forms; therefore, the IR used by the translation machine usually consists of lexical lexical category and morphological diffraction information for each word. In order to convert the parallel corpus into the IR used by the engine, the engine's analysis modules (morphological analyzers and language dividers) are used to analyze both sides of the parallel corpus before calculating the word alignments. After analyzing both sides of the parallel corpus, we have for each word its lexical category and morphological diffraction information. Note that generalizations are carried out on the basis of word alignments and bilingual information in the next phological section (see the extraction)."}, {"heading": "3.1 Word-Class Definition", "text": "Since the transformations to be applied are mainly based on the lexical categories and diffraction information of SL and TL words, the function that maps words into word classes will transform each word into a word class that represents its lexical category and morphological diffraction information (such as verb, preterite, third person, plural). Using lexical categories and morphological diffraction information to define the word classes allows the method to learn general syntactic rules such as rules of order and conformity and verbs. However, in order to learn lexical changes such as preposition changes or auxiliary usage, some words are assigned to single word classes that represent a lexical form, as discussed next."}, {"heading": "3.1.1 Lexicalized Categories", "text": "A number of (lexicalized) categories that are normally involved in lexical modifications, such as prepositions and auxiliary verbs, can be made available. In this way, lexicalized words are placed in one-word classes that represent a particular lexical form. For example, if prepositions are considered lexicalized categories, words for and for different word classes are used, even if they have the same lexical category and morphological inflection information, while words book and house would be in the same word class (noun, singular). Typically, the group of lexicalized categories is a subgroup of closed categories, i.e. those that do not grow by adding new words to the lexicon, auxiliary verbs, prepositions, conjunctions, etc. A typical lexicalized word is a subgroup of closed categories, i.e. those that do not grow by adding new words to the lexicon (pronouns, auxiliary verbs, conjunctions, etc.)."}, {"heading": "3.2 Extending the Definition of Alignment Template", "text": "In Section 2, an AT was defined as a tuple z = (Sm, Tn, A) in which only the alignment A between SL and TL word classes was taken into account. In this section, the definition of AT is extended to z = (Sm, Tn, A, R), adding a set of constraints, R, to the TL diffraction information of the non-lexicalized categories to control their application as part of a transfer rule."}, {"heading": "3.2.1 TL Restrictions", "text": "When we deal with the question (see section 4.3.1), that is, when we apply the derived ATs & < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < &"}, {"heading": "4. Generation of Apertium Transfer Rules", "text": "This section describes the automatic generation of apertium rules for flat structural transfers; however, note that the generation of transfer rules for other flat transmission systems would also be possible by following the approach presented here. Structural transfer in apertium (see Appendix A) uses finite-state pattern matching to detect established patterns of lexical shapes in the usual left-to-right method with the longest agreement in order to process and perform the corresponding transformations. A (generic) flat transfer rule consists of a sequence of lexical shapes to be detected and the transformations to be applied to them."}, {"heading": "4.1 Discarding Useless Bilingual Phrase Pairs", "text": "Not all bilingual sentence pairs are useful for inferring translation rules, as the generalization that would occur from some of them cannot be used in RBMT; more specifically, bilingual sentence pairs that meet one or both of the following conditions are useless and therefore discarded: \u2022 SL and TL non-lexicalized words are not aligned. \u2022 The bilingual sentence pair cannot be reproduced by the MT system in which the translation rules are used. This happens when the translation equivalent in the bilingual dictionary is different from the one observed in the bilingual dictionary. Note that TL constraints are extracted from the bilingual dictionary, and if translation equivalents do not match, the extracted AT may end up having a set of constraints that make no sense at all."}, {"heading": "4.2 Selecting the Alignment Templates to Use", "text": "In order to decide which ATs are to be taken into account when drawing up rules, the method is equipped with a frequency counter threshold. ATs whose frequency number is below this threshold are discarded. In the experiments, two different ways of interpreting the frequency number were tested: \u2022 the direct use of the frequency number c and \u2022 the use of a modified frequency number c \u00b2 = c (1 + log (l)), where l stands for the length of the SL part of the ATs. The second approach aims to solve the problem caused by the fact that longer ATs have lower frequency numbers but may be more accurate because they take more context into account. A similar approach was used by (Mikheev, 1996) in his work on rules for learning a part of the language to favour longer suffixes over shorter ones."}, {"heading": "4.3 Rule Generation", "text": "A rule consists of a set of extended ATs with the same sequence of SL word classes but different sequences of TL word classes, different alignment information, or different TL restrictions. Formally, this can be expressed as U = {(Sm, Tn, A, R). Z: Sm = SU}, (1) where Z refers to the entire set of ATs and SU to the sequence of SL word classes that all ATs in U have in common. Note that each rule corresponds to a different sequence SU of SL word classes and therefore there is no ambiguity in the application of flat transfer rules at the translation time. Each rule U is encoded in Apertium's XML-based transmission language. The code generated for each rule always applies to the most common AT in U that meets the TL restrictions; therefore, competing ATs are selected according to their frequency."}, {"heading": "4.3.1 Application of an Alignment Template", "text": "The actions to be taken for each unit in Tn depend on the nature of its word class: \u2022 if the word class corresponds to a non-lexicalized word, the lexical information provided by the TL word class will be appended to the translated problem; \u2022 if the word class corresponds to a lexical word, the lexical information provided by the TL word class will be appended to the translated problem; \u2022 if the word class corresponds to a lexical word, it will be introduced as it is; remember that word classes belonging to lexical words represent complete lexical forms consisting of lemma, lexical category and morphological movement; \u2022 if the word class corresponds to a lexical word, it will be introduced as it is; remember that word classes belonging to lexical words represent complete lexical forms consisting of lemma, lexical category and morphological movement."}, {"heading": "5. Experiments", "text": "The approach we present in this paper has been tested on both sides of the Atlantic (Es-ca) and on the other side of the Atlantic (es-gl). The parallel world used for education comes from different sources. The Spanish parallel society comes from El Perio. \"dico de Catalunya, 12 a daily newspaper published both in Catalonia and in Spain. The Spanish parallel society comes from Diario Oficial de Galicia, 13 the official publication of the autonomous government of Galicia, published both in Galicia and in Spain. The Spanish parallel society comes from the JRCAcquis Multilingual Corpus al al al al al., 2006, which includes the European Union (EU), we have laws that are applicable in the member states. To test the importance of parallel companies for education, we have used companies of various sizes."}, {"heading": "5.1 Evaluation", "text": "The performance of the presented approach is compared to that of the same MT system, if no transmission rules are used at all (word for word MT), to that of the same MT system when using hand-coded transmission rules 15, and to the use of a modern SMT system trained with the same parallel corpora. For the latter, we used the free / open source SMT toolkit Moses (Koehn et al., 2007) and the SRILM language modeling toolkit (Stolcke, 2002). Training of the SMT system was as follows: 16 Initially, the translation model was trained using 90% of the training corpus. Subsequently, a 5 gram language model was trained with the entire training corpus. Finally, the minimal error rate \"training algorithm\" (Och, 2003) was used to determine the remaining 10% of the training corpus."}, {"heading": "5.1.1 Confidence intervals", "text": "The confidence intervals of the MT quality measures are calculated using the \"bootstrap resampling\" method described by Koehn (2004). In general, the \"bootstrap resampling\" method consists of estimating the accuracy of sample statistics (in our case, translation quality measures) by random sampling from the complete sample set (Efron & Tibshirani, 1994); in the MT, sentences and their respective yardsticks were 15. Those in the corresponding aperitium language packs 16. Detailed training instructions can be found at http: / / www.statmt.org / wmt09 / baseline.html. 17. The minimum error rate \"training\" BLEU used as evaluation yardsticks. Reference translations. This method has the property that no assumptions are made about the underlying distribution of variables that, in our case, terminate the MT quality measures, will consist of 1. The following part of the calculation \u2212 the number of the remaining translations: 1."}, {"heading": "5.1.2 Evaluation corpora", "text": "Table 2 shows the number of sentences and the number of SL and TL words of the different test corpora used to evaluate the derivative rules for each translation considered. These test corpora come from independent parallel corpora, from another source, unrelated to the corpora used for training. More specifically, the test corpora for Spanish-Catalan and Spanish-Galician comes from Revista Consumer Eroski (Alca \u0301 zar, 2005), 18 a magazine aimed at consumers and published in Spanish, Catalan, Galician and Basque; the test corpora for Spanish-Portuguese comes from the joint evaluation task of the SMT.19 workshop."}, {"heading": "5.2 Results", "text": "In fact, most of them are able to follow the rules that they have imposed on themselves. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to determine themselves. (...) Most of them are able to determine themselves. (...)"}, {"heading": "5.2.1 Adding the bilingual dictionary to the SMT training data", "text": "In order to test whether the difference in translation performance between the shallow transfer rules and the SMT system is automatically transferred, Apertium is automatically due to the fact that Apertium uses a comprehensive, manually built bilingual dictionary. (Tyers et al., 2009) It is worth noting that adding the bilingual dictionary to the training corpus not only improves the vocabulary coverage of the SMT systems, but also supports the word alignment process by adding word-to-word alignment, giving the SMT system an added advantage over other systems. The bilingual dictionary has not only been added to the corpus used to learn the AT system for automatic inference to the shallow transfer rules. Table 4 shows the 95% confidence intervals SMT intervals with the TER system and the Ratio-vocabularies."}, {"heading": "5.2.2 Analysis of the inferred rules", "text": "Table 5 shows for each translation task the frequency threshold used in generating rules, the number of rules received and the number of those used in the translation of the corresponding rating corpus; remember that the frequency threshold used in each translation task is the one that minimizes the TER in the translation of the corpora described in Table 1. The data collected in Table 5 correspond to the rules derived from the largest training corpus (2.0 million words in each language). Note that the number of derived rules varies according to the translation task; for example, the number of rules for the Ca is twice as high as the number of rules for the Ca-en, which is because the minimum TER rules are needed in the cases."}, {"heading": "6. Discussion", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, in which they, live, in which they, in which they, in which they, live, in which they, in which they, in fact, in fact, in fact, are able to move, are able to move, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they"}, {"heading": "Acknowledgments", "text": "The work financed by the Spanish Ministry of Education and Science and the European Social Fund through research funding BES-2004-4711, by the Spanish Ministry of Industry, Tourism and Trade through the projects TIC2003-08681-C02-01, FIT340101-2004-3 and FIT-350401-2006-5 and by the Spanish Ministry of Education and Science through the project TIN2006-15071-C03-01. The authors thank the anonymous speakers for their suggestions to improve this work and Francis Tyers for their correction."}, {"heading": "Appendix A. The Apertium Machine Translation Platform", "text": "This appendix briefly describes the free / open source approach of the flat transfer MT-Engine Apertium23 (Armentano-Oller et al., 2006) used for the experiments. Apertium follows the flat transfer approach shown in Figure 10. \u2022 A morphological analyzer that tokenizes the text into surface shapes and provides one or more lexical shapes for each surface shape, consisting of lemma, lexical category and morphological inflection information. \u2022 A part-of-speech tagger (categorical disambiguator) that uses a hidden Markov model (Cutting et al., 1992; Baum & Petrie, 1966) to provide one of the lexical forms corresponding to an ambiguous surface shape. \u2022 A lexical transfer module that reads each lexical form and provides the corresponding lexical form of TL lexical form by looking it up in a bilingual dictionary."}], "references": [{"title": "Towards linguistically searchable text", "author": ["A. Alc\u00e1zar"], "venue": "In Proceedings of BIDE (BilbaoDeusto) Summer School of Linguistics", "citeRegEx": "Alc\u00e1zar,? \\Q2005\\E", "shortCiteRegEx": "Alc\u00e1zar", "year": 2005}, {"title": "Open-source Portuguese-Spanish machine translation", "author": ["C. Armentano-Oller", "R.C. Carrasco", "A.M. Corb\u00c3-Bellot", "M.L. Forcada", "M. Ginest\u0301\u0131-Rosell", "S. Ortiz-Rojas", "J.A. P\u00e9rez-Ortiz", "G. Ram\u0131\u0301rez-S\u00e1nchez", "F. S\u00e1nchez-Mart\u0301\u0131nez", "M.A. Scalco"], "venue": "In Computational Processing of the Portuguese Language, Proceedings of the 7th International Workshop on Computational Processing of Written and Spoken Portuguese,", "citeRegEx": "Armentano.Oller et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Armentano.Oller et al\\.", "year": 2006}, {"title": "Why translation is difficult for computers. In Computers and Translation: A translator\u2019s guide", "author": ["D. Arnold"], "venue": "Benjamins Translation Library", "citeRegEx": "Arnold,? \\Q2003\\E", "shortCiteRegEx": "Arnold", "year": 2003}, {"title": "Statistical inference for probabilistic functions of finite state Markov chains", "author": ["L.E. Baum", "T. Petrie"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Baum and Petrie,? \\Q1966\\E", "shortCiteRegEx": "Baum and Petrie", "year": 1966}, {"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["P.F. Brown", "S.A.D. Pietra", "V.J.D. Pietra", "R.L. Mercer"], "venue": "Computational Linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Adding linguistic knowledge to a lexical example-based translation system", "author": ["R.D. Brown"], "venue": "In Proceedings of the Eighth International Conference on Theoretical and Methodological Issues in Machine Translation", "citeRegEx": "Brown,? \\Q1999\\E", "shortCiteRegEx": "Brown", "year": 1999}, {"title": "LIHLA: A lexical aligner based on language-independent heuristics", "author": ["H.M. Caseli", "M.G.V. Nunes", "M.L. Forcada"], "venue": "In Anais do V Encontro Nacional de InteligA\u0303ancia Artificial (ENIA", "citeRegEx": "Caseli et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Caseli et al\\.", "year": 2005}, {"title": "Automatic induction of bilingual resources from aligned parallel corpora: application to shallow-transfer machine translation", "author": ["H.M. Caseli", "M.G.V. Nunes", "M.L. Forcada"], "venue": "Machine Translation,", "citeRegEx": "Caseli et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Caseli et al\\.", "year": 2006}, {"title": "Learning translation templates from bilingual translation examples", "author": ["I. Cicekli", "H.A. G\u00fcvenir"], "venue": "Applied Intelligence,", "citeRegEx": "Cicekli and G\u00fcvenir,? \\Q2001\\E", "shortCiteRegEx": "Cicekli and G\u00fcvenir", "year": 2001}, {"title": "A practical part-of-speech tagger", "author": ["D. Cutting", "J. Kupiec", "J. Pedersen", "P. Sibun"], "venue": "In Proceedings of the Third Conference on Applied Natural Language Processing. Association for Computational Linguistics,", "citeRegEx": "Cutting et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Cutting et al\\.", "year": 1992}, {"title": "An introduction to the Bootstrap", "author": ["B. Efron", "R.J. Tibshirani"], "venue": null, "citeRegEx": "Efron and Tibshirani,? \\Q1994\\E", "shortCiteRegEx": "Efron and Tibshirani", "year": 1994}, {"title": "Robust large-scale EBMT with marker-based segmentation", "author": ["N. Gough", "A. Way"], "venue": "In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation,", "citeRegEx": "Gough and Way,? \\Q2004\\E", "shortCiteRegEx": "Gough and Way", "year": 2004}, {"title": "The necessity of syntax markers. Two experiments with artificial languages", "author": ["T. Green"], "venue": "Journal of Verbal Learning and Behavior,", "citeRegEx": "Green,? \\Q1979\\E", "shortCiteRegEx": "Green", "year": 1979}, {"title": "An Introduction to Machine Translation", "author": ["W.J. Hutchins", "H.L. Somers"], "venue": null, "citeRegEx": "Hutchins and Somers,? \\Q1992\\E", "shortCiteRegEx": "Hutchins and Somers", "year": 1992}, {"title": "Learning translation templates from bilingual text", "author": ["H. Kaji", "Y. Kida", "Y. Morimoto"], "venue": "In Proceedings of the 14th Conference on Computational Linguistics,", "citeRegEx": "Kaji et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Kaji et al\\.", "year": 1992}, {"title": "A statistical machine translation tutorial workbook", "author": ["K. Knight"], "venue": null, "citeRegEx": "Knight,? \\Q1999\\E", "shortCiteRegEx": "Knight", "year": 1999}, {"title": "Statistical significance tests for machine translation evaluation", "author": ["P. Koehn"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Koehn,? \\Q2004\\E", "shortCiteRegEx": "Koehn", "year": 2004}, {"title": "A trainable transfer-based machine translation approach for languages with limited resources", "author": ["A. Lavie", "K. Probst", "E. Peterson", "S. Vogel", "L. Levin", "A. Font-Llitj\u00f3s", "J. Carbonell"], "venue": "In Proceedings of Workshop of the European Association for Machine Translation", "citeRegEx": "Lavie et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lavie et al\\.", "year": 2004}, {"title": "The technical analysis on translation templates", "author": ["Y. Liu", "C. Zong"], "venue": "In Proceedings of the IEEE International Conference on Systems, Man & Cybernetics (SMC),", "citeRegEx": "Liu and Zong,? \\Q2004\\E", "shortCiteRegEx": "Liu and Zong", "year": 2004}, {"title": "A best-first alignment algorithm for automatic extraction of transfer mappings from bilingual corpora", "author": ["A. Menezes", "S.D. Richardson"], "venue": "In Proceedings of the ACL Workshop on data-driven machine translation,", "citeRegEx": "Menezes and Richardson,? \\Q2001\\E", "shortCiteRegEx": "Menezes and Richardson", "year": 2001}, {"title": "Unsupervised learning of word-category guessing rules", "author": ["A. Mikheev"], "venue": "In Proceedings of the Thirty-Fourth Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Mikheev,? \\Q1996\\E", "shortCiteRegEx": "Mikheev", "year": 1996}, {"title": "A framework of a mechanical translation between English and Japanese by analogy principle", "author": ["M. Nagao"], "venue": "Artifical and Human Intelligence,", "citeRegEx": "Nagao,? \\Q1984\\E", "shortCiteRegEx": "Nagao", "year": 1984}, {"title": "An efficient method for determining bilingual word classes", "author": ["F.J. Och"], "venue": "Ninth Conference of the European Chapter of the Association for Computational Lingustics,", "citeRegEx": "Och,? \\Q1999\\E", "shortCiteRegEx": "Och", "year": 1999}, {"title": "Statistical machine translation: From single-word models to alignment templates", "author": ["F.J. Och"], "venue": "Ph.D. thesis, RWTH Aachen University", "citeRegEx": "Och,? \\Q2002\\E", "shortCiteRegEx": "Och", "year": 2002}, {"title": "Minimum error rate training in statistical machine translation", "author": ["F.J. Och"], "venue": "Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Och,? \\Q2003\\E", "shortCiteRegEx": "Och", "year": 2003}, {"title": "Statistical machine translation: Foundations and recent advances", "author": ["F.J. Och"], "venue": "Tutorial at MT Summit X", "citeRegEx": "Och,? \\Q2005\\E", "shortCiteRegEx": "Och", "year": 2005}, {"title": "Discriminative training and maximum entropy models for statistical machine translation", "author": ["F.J. Och", "H. Ney"], "venue": "In Proceedings of the 40th Annual Meeting of the Association for Computational Lingustics (ACL),", "citeRegEx": "Och and Ney,? \\Q2002\\E", "shortCiteRegEx": "Och and Ney", "year": 2002}, {"title": "A systematic comparison of various statistical alignment models", "author": ["F.J. Och", "H. Ney"], "venue": "Computational Linguistics,", "citeRegEx": "Och and Ney,? \\Q2003\\E", "shortCiteRegEx": "Och and Ney", "year": 2003}, {"title": "The alignment template approach to statistical machine translation", "author": ["F.J. Och", "H. Ney"], "venue": "Computational Linguistics,", "citeRegEx": "Och and Ney,? \\Q2004\\E", "shortCiteRegEx": "Och and Ney", "year": 2004}, {"title": "BLEU: a method for automatic evaluation of machine translation", "author": ["K. Papineni", "S. Roukos", "T. Ward", "W.J. Zhu"], "venue": "In Proceeding of 40th Annual meeting of the Association for Computational Linguistics,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "MT for minority languages using elicitation-based learning of syntactic transfer rules", "author": ["K. Probst", "L. Levin", "E. Peterson", "A. Lavie", "J. Carbonell"], "venue": "Machine Translation,", "citeRegEx": "Probst et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Probst et al\\.", "year": 2002}, {"title": "Automatic induction of shallow-transfer rules for open-source machine translation", "author": ["F. S\u00e1nchez-Mart\u0301\u0131nez", "M.L. Forcada"], "venue": "In Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI", "citeRegEx": "S\u00e1nchez.Mart\u0301\u0131nez and Forcada,? \\Q2007\\E", "shortCiteRegEx": "S\u00e1nchez.Mart\u0301\u0131nez and Forcada", "year": 2007}, {"title": "Using alignment templates to infer shallow-transfer machine translation rules", "author": ["F. S\u00e1nchez-Mart\u0301\u0131nez", "H. Ney"], "venue": "Science", "citeRegEx": "S\u00e1nchez.Mart\u0301\u0131nez and Ney,? \\Q2006\\E", "shortCiteRegEx": "S\u00e1nchez.Mart\u0301\u0131nez and Ney", "year": 2006}, {"title": "Using target-language information to train part-of-speech taggers for machine translation", "author": ["F. S\u00e1nchez-Mart\u0301\u0131nez", "J.A. P\u00e9rez-Ortiz", "M.L. Forcada"], "venue": "Machine Translation,", "citeRegEx": "S\u00e1nchez.Mart\u0301\u0131nez et al\\.,? \\Q2008\\E", "shortCiteRegEx": "S\u00e1nchez.Mart\u0301\u0131nez et al\\.", "year": 2008}, {"title": "NATools - a statistical word aligner workbench", "author": ["A. Sim\u00f5es", "J. Almeida"], "venue": "Procesamiento del Lenguaje Natural,", "citeRegEx": "Sim\u00f5es and Almeida,? \\Q2003\\E", "shortCiteRegEx": "Sim\u00f5es and Almeida", "year": 2003}, {"title": "A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas, \u201cVisions for the Future of Machine Translation", "author": ["M. Snover", "B. Dorr", "R. Schwartz", "L. Micciulla", "J. Makhoul"], "venue": null, "citeRegEx": "Snover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Snover et al\\.", "year": 2006}, {"title": "The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages", "author": ["R. Steinberger", "B. Pouliquen", "A. Widiger", "C. Ignat", "T. Erjavec", "D. Tufis", "D. Varga"], "venue": "In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC)", "citeRegEx": "Steinberger et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Steinberger et al\\.", "year": 2006}, {"title": "SRILM \u2013 an extensible language modeling toolkit", "author": ["A. Stolcke"], "venue": "In Proceedings of the International Conference on Spoken Language Processing,", "citeRegEx": "Stolcke,? \\Q2002\\E", "shortCiteRegEx": "Stolcke", "year": 2002}, {"title": "Rule-based augmentation of training data in Breton\u2013French statistical machine translation", "author": ["F.M. Tyers", "L. Dugast", "J. Park"], "venue": "In Proceedings of the 13th Annual Conference of the European Associtation for Machine Translation,", "citeRegEx": "Tyers et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Tyers et al\\.", "year": 2009}, {"title": "HMM-based word alignment in statistical translation", "author": ["S. Vogel", "H. Ney", "C. Tillmann"], "venue": "In COLING \u201996: The 16th International Conference on Computational Linguistics,", "citeRegEx": "Vogel et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 1996}, {"title": "Phrase-based statistical machine translation", "author": ["R. Zens", "F.J. Och", "H. Ney"], "venue": "In KI 2002: Advances in Artificial Intelligence: Proceedings 25th Annual German Conference on AI,", "citeRegEx": "Zens et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Zens et al\\.", "year": 2002}], "referenceMentions": [{"referenceID": 2, "context": "MT is difficult mainly because natural languages are highly ambiguous and also because two languages do not always express the same content in the same way (Arnold, 2003).", "startOffset": 156, "endOffset": 170}, {"referenceID": 21, "context": "Corpus-based approaches to MT, such as example-based MT (EBMT; Nagao, 1984; Carl & Way, 2003) and statistical MT (SMT; Brown et al.", "startOffset": 56, "endOffset": 93}, {"referenceID": 4, "context": "Corpus-based approaches to MT, such as example-based MT (EBMT; Nagao, 1984; Carl & Way, 2003) and statistical MT (SMT; Brown et al., 1993; Knight, 1999), use large collections of parallel texts as the source of knowledge from which the engine learns how to perform translations.", "startOffset": 113, "endOffset": 152}, {"referenceID": 15, "context": "Corpus-based approaches to MT, such as example-based MT (EBMT; Nagao, 1984; Carl & Way, 2003) and statistical MT (SMT; Brown et al., 1993; Knight, 1999), use large collections of parallel texts as the source of knowledge from which the engine learns how to perform translations.", "startOffset": 113, "endOffset": 152}, {"referenceID": 25, "context": "Although corpus-based approaches to MT have grown in interest over the last years, they require large amounts, in the order of tens of millions of words, of parallel text to achieve reasonable translation quality (Och, 2005).", "startOffset": 213, "endOffset": 224}, {"referenceID": 2, "context": "The process of building a RBMT system involves considerable human effort in order to develop the necessary linguistic resources (Arnold, 2003).", "startOffset": 128, "endOffset": 142}, {"referenceID": 33, "context": "The method we present is entirely unsupervised and benefits from information in the rest of modules of the MT system in which the inferred rules are applied, in line with the method proposed by S\u00e1nchez-Mart\u0301\u0131nez et al. (2008) to train part-of-speech taggers in an unsupervised way for their use in MT.", "startOffset": 194, "endOffset": 226}, {"referenceID": 25, "context": "Small compared to the size of corpora commonly used to build corpus-based MT systems (Och, 2005).", "startOffset": 85, "endOffset": 96}, {"referenceID": 23, "context": "The method we propose for the automatic inference of shallow-transfer rules from parallel corpora is based on the alignment template (AT) approach initially proposed for its use in the SMT framework (Och, 2002; Och & Ney, 2004).", "startOffset": 199, "endOffset": 227}, {"referenceID": 22, "context": "For the purpose of this paper, and to stick to the terminology used by Och and Ney (2004) in the definition of AT and by most SMT practitioners, by phrase we refer to any text segment, not necessarily a well-formed syntactic constituent.", "startOffset": 71, "endOffset": 90}, {"referenceID": 26, "context": "Probst et al. (2002) and Lavie et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 15, "context": "(2002) and Lavie et al. (2004) developed a method to learn transfer rules for MT involving underresourced languages (such as Quechua) with very limited resources.", "startOffset": 11, "endOffset": 31}, {"referenceID": 15, "context": "(2002) and Lavie et al. (2004) developed a method to learn transfer rules for MT involving underresourced languages (such as Quechua) with very limited resources. To this end, a small parallel corpus (of a few thousand sentences) is built with the help of a small set of bilingual speakers of the two languages. The parallel corpus is obtained by translating a controlled corpus from the language with more resources (English or Spanish) into the under-resourced language by means of an elicitation tool. This tool is also used to graphically annotate the word alignments between the two sentences. Finally, hierarchical syntactic rules, which can be seen as constituting a context-free transfer grammar, are inferred from the aligned parallel corpus. Menezes and Richardson (2001) propose a method to infer transfer mappings (rules) between source and target languages.", "startOffset": 11, "endOffset": 782}, {"referenceID": 6, "context": "Caseli et al. (2006) propose a method to infer bilingual resources (structural transfer rules and bilingual dictionaries) to be used in shallow-transfer MT from aligned parallel corpora.", "startOffset": 0, "endOffset": 21}, {"referenceID": 14, "context": "In the EBMT framework, some researchers have dealt with the problem of inferring a kind of translation rules called translation templates (Kaji et al., 1992; Brown, 1999; Cicekli & G\u00fcvenir, 2001).", "startOffset": 138, "endOffset": 195}, {"referenceID": 5, "context": "In the EBMT framework, some researchers have dealt with the problem of inferring a kind of translation rules called translation templates (Kaji et al., 1992; Brown, 1999; Cicekli & G\u00fcvenir, 2001).", "startOffset": 138, "endOffset": 195}, {"referenceID": 5, "context": ", 1992; Brown, 1999; Cicekli & G\u00fcvenir, 2001). A translation template can be defined as a bilingual pair of sentences in which corresponding units (words or phrases) are coupled and replaced by variables. Liu and Zong (2004) provide an interesting review of the different research works dealing with translation templates.", "startOffset": 8, "endOffset": 225}, {"referenceID": 5, "context": ", 1992; Brown, 1999; Cicekli & G\u00fcvenir, 2001). A translation template can be defined as a bilingual pair of sentences in which corresponding units (words or phrases) are coupled and replaced by variables. Liu and Zong (2004) provide an interesting review of the different research works dealing with translation templates. Brown (1999) uses a parallel corpus and some linguistic knowledge in the form of equivalence classes (both syntactic and semantic) to perform a generalization over the bilingual examples collected.", "startOffset": 8, "endOffset": 336}, {"referenceID": 23, "context": "The alignment template (AT) approach (Och, 2002; Och & Ney, 2004) was introduced in the SMT framework as one of the feature functions in the maximum entropy model (Och & Ney, 2002) to try to generalize the knowledge learned for a specific phrase to similar phrases.", "startOffset": 37, "endOffset": 65}, {"referenceID": 6, "context": "A variety of methods, statistical (Och & Ney, 2003) or hybrid (Caseli et al., 2005),3 may be used to compute word alignments from a (sentence-aligned) parallel corpus.", "startOffset": 62, "endOffset": 83}, {"referenceID": 6, "context": "Caseli et al.\u2019s (2005) method is hybrid because prior to the application of heuristics, it uses a statistical tool (NATools) to obtain a probabilistic bilingual dictionary (Sim\u00f5es & Almeida, 2003).", "startOffset": 0, "endOffset": 23}, {"referenceID": 4, "context": "training the IBM model 1 (Brown et al., 1993) for 5 iterations; in this model, word order does not affect the alignment probabilities;", "startOffset": 25, "endOffset": 45}, {"referenceID": 39, "context": "training the HMM alignment model (Vogel et al., 1996) for 5 iterations; this alignment model has the property of making alignment probabilities explicitly dependent on the alignment position of the previous word;", "startOffset": 33, "endOffset": 53}, {"referenceID": 4, "context": "training the IBM model 3 (Brown et al., 1993) for 5 iterations; in this model, the probability of an alignment depends on the positions of the aligned words and on the length of SL and TL sentences.", "startOffset": 25, "endOffset": 45}, {"referenceID": 4, "context": "training the IBM model 4 (Brown et al., 1993) for 5 iterations; this model is identical to IBM model 3 except for the fact that it models the reordering of phrases that may be moved around as units.", "startOffset": 25, "endOffset": 45}, {"referenceID": 40, "context": "Usually, the extraction of bilingual phrase pairs (Zens et al., 2002) is performed by considering all possible pairs below a certain length and ensuring that: (i) all words are consecutive, and (ii) words within the bilingual phrase pair are not aligned with words from outside.", "startOffset": 50, "endOffset": 69}, {"referenceID": 22, "context": "Och and Ney (2004) use automatically obtained (Och, 1999) word classes to extract ATs for SMT.", "startOffset": 46, "endOffset": 57}, {"referenceID": 22, "context": "Och and Ney (2004) use automatically obtained (Och, 1999) word classes to extract ATs for SMT.", "startOffset": 0, "endOffset": 19}, {"referenceID": 20, "context": "A similar approach was used by (Mikheev, 1996) in his work on learning part-of-speech guessing rules to favor longer suffixes over shorter ones.", "startOffset": 31, "endOffset": 46}, {"referenceID": 36, "context": "The Spanish\u2013Catalan parallel corpora come from El Peri\u00f3dico de Catalunya,12 a daily newspaper published both in Catalan and Spanish; the Spanish\u2013Galician parallel corpora come from Diario Oficial de Galicia,13 the official publication of the autonomous government of Galicia published both in Galician and Spanish; the Spanish\u2013Portuguese parallel corpora come from The JRCAcquis Multilingual Parallel Corpus (Steinberger et al., 2006)14 which contains European Union (EU) law applicable in the EU member states.", "startOffset": 408, "endOffset": 434}, {"referenceID": 35, "context": "The frequency count used in the evaluation is the one giving the best translation edit rate (TER; Snover et al., 2006) when translating a corpus, similar to the one used for testing, with 1 000 sentences (see Table 1); in Table 5 (page 627) we provide the thresholds used when the rules are inferred from the corpus with 2.", "startOffset": 92, "endOffset": 118}, {"referenceID": 37, "context": ", 2007) and the SRILM language modelling toolkit (Stolcke, 2002).", "startOffset": 49, "endOffset": 64}, {"referenceID": 24, "context": "Finally, the minimum error \u201crate\u201d training algorithm (Och, 2003) used the remaining 10% of the training corpus to adjust the weight of each feature.", "startOffset": 53, "endOffset": 64}, {"referenceID": 35, "context": "Translation performance is evaluated using two different measures; on the one hand, the translation edit rate (TER; Snover et al., 2006), and on the other hand, the bilingual evaluation understudy (BLEU; Papineni et al.", "startOffset": 110, "endOffset": 136}, {"referenceID": 29, "context": ", 2006), and on the other hand, the bilingual evaluation understudy (BLEU; Papineni et al., 2002); in both cases the same evaluation corpora have been used and the confidence intervals of the measures being reported are given (see below).", "startOffset": 68, "endOffset": 97}, {"referenceID": 16, "context": "Confidence intervals of MT quality measures are calculated through the bootstrap resampling method as described by Koehn (2004). In general, the bootstrap resampling method consists of estimating the precision of sample statistics (in our case, translation quality measures) by randomly resampling with replacement (that is, allowing repetitions) from the full set of samples (Efron & Tibshirani, 1994); in MT, sentences and their respective", "startOffset": 115, "endOffset": 128}, {"referenceID": 0, "context": "More precisely, the test corpora for Spanish\u2013 Catalan and Spanish\u2013Galician comes from Revista Consumer Eroski (Alc\u00e1zar, 2005),18 a magazine addressed to consumers published in Spanish, Catalan, Galician and Basque; the test corpora for Spanish\u2013Portuguese comes from the shared evaluation task of the 2008 workshop on SMT.", "startOffset": 110, "endOffset": 125}, {"referenceID": 38, "context": "With the aim of testing whether the difference in the translation performance between the shallow-transfer rules and the SMT system is due to the fact that Apertium uses a wide-coverage, manually-built bilingual dictionary, we have added the bilingual dictionary in the corresponding Apertium package to the SMT training data (Tyers et al., 2009).", "startOffset": 326, "endOffset": 346}, {"referenceID": 6, "context": "Notice that our approach, unlike that by Caseli et al. (2006), is aimed at learning shallow-transfer rules, not bilingual entries, and that we have used the bilingual dictionary provided by the corresponding Apertium language-pair package.", "startOffset": 41, "endOffset": 62}, {"referenceID": 12, "context": "Our approach could be extended by detecting chunks in the training parallel corpus using linguistic criteria as mentioned in the previous paragraph, or using the \u201cMarker Hypothesis\u201d (Green, 1979), as done by Gough and Way (2004), and then extracting ATs based on chunk classes instead of word classes, as it is done now.", "startOffset": 182, "endOffset": 195}, {"referenceID": 11, "context": "Our approach could be extended by detecting chunks in the training parallel corpus using linguistic criteria as mentioned in the previous paragraph, or using the \u201cMarker Hypothesis\u201d (Green, 1979), as done by Gough and Way (2004), and then extracting ATs based on chunk classes instead of word classes, as it is done now.", "startOffset": 208, "endOffset": 229}, {"referenceID": 1, "context": "This appendix briefly describes the free/open-source shallow-transfer MT engine Apertium23 (Armentano-Oller et al., 2006) used for the experiments.", "startOffset": 91, "endOffset": 121}, {"referenceID": 9, "context": "\u2022 A part-of-speech tagger (categorial disambiguator) which chooses, using a first-order hidden Markov model (Cutting et al., 1992; Baum & Petrie, 1966), one of the lexical forms corresponding to an ambiguous surface form.", "startOffset": 108, "endOffset": 151}], "year": 2009, "abstractText": "This paper describes a method for the automatic inference of structural transfer rules to be used in a shallow-transfer machine translation (MT) system from small parallel corpora. The structural transfer rules are based on alignment templates, like those used in statistical MT. Alignment templates are extracted from sentence-aligned parallel corpora and extended with a set of restrictions which are derived from the bilingual dictionary of the MT system and control their application as transfer rules. The experiments conducted using three different language pairs in the free/open-source MT platform Apertium show that translation quality is improved as compared to word-for-word translation (when no transfer rules are used), and that the resulting translation quality is close to that obtained using hand-coded transfer rules. The method we present is entirely unsupervised and benefits from information in the rest of modules of the MT system in which the inferred rules are applied.", "creator": "TeX"}}}