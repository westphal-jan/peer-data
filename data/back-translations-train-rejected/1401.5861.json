{"id": "1401.5861", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2014", "title": "Online Speedup Learning for Optimal Planning", "abstract": "Domain-independent planning is one of the foundational areas in the field of Artificial Intelligence. A description of a planning task consists of an initial world state, a goal, and a set of actions for modifying the world state. The objective is to find a sequence of actions, that is, a plan, that transforms the initial world state into a goal state. In optimal planning, we are interested in finding not just a plan, but one of the cheapest plans. A prominent approach to optimal planning these days is heuristic state-space search, guided by admissible heuristic functions. Numerous admissible heuristics have been developed, each with its own strengths and weaknesses, and it is well known that there is no single \"best heuristic for optimal planning in general. Thus, which heuristic to choose for a given planning task is a difficult question. This difficulty can be avoided by combining several heuristics, but that requires computing numerous heuristic estimates at each state, and the tradeoff between the time spent doing so and the time saved by the combined advantages of the different heuristics might be high. We present a novel method that reduces the cost of combining admissible heuristics for optimal planning, while maintaining its benefits. Using an idealized search space model, we formulate a decision rule for choosing the best heuristic to compute at each state. We then present an active online learning approach for learning a classifier with that decision rule as the target concept, and employ the learned classifier to decide which heuristic to compute at each state. We evaluate this technique empirically, and show that it substantially outperforms the standard method for combining several heuristics via their pointwise maximum.", "histories": [["v1", "Thu, 23 Jan 2014 02:49:53 GMT  (371kb)", "http://arxiv.org/abs/1401.5861v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["carmel domshlak", "erez karpas", "shaul markovitch"], "accepted": false, "id": "1401.5861"}, "pdf": {"name": "1401.5861.pdf", "metadata": {"source": "CRF", "title": "Online Speedup Learning for Optimal Planning", "authors": ["Carmel Domshlak", "Erez Karpas", "Shaul Markovitch"], "emails": ["DCARMEL@IE.TECHNION.AC.IL", "KARPASE@TECHNION.AC.IL", "SHAULM@CS.TECHNION.AC.IL"], "sections": [{"heading": null, "text": "A description of a planning task consists of an initial world state, a goal, and a series of measures to modify the world state. The goal is to find a sequence of actions, that is, a plan that turns the initial world state into a target state. However, in optimal planning, we are interested in finding not only a plan, but also one of the cheapest plans. A prominent approach to the optimal planning of these days is the heuristic search for an optimal state, guided by an adequate heuristic task. This difficulty can be avoided by combining several strengths and weaknesses, and it is known that there is not a single one that is optimal planning for optimal planning. So, which is heuristic to choose a particular planning task. This difficulty can be avoided by combining several heuristics and weaknesses, but this requires numerous heuristic estimates."}], "references": [{"title": "Bootstrap learning of heuristic functions", "author": ["S.J. Arfaee", "S. Zilles", "R.C. Holte"], "venue": "Proceedings of the Third Annual Symposium on Combinatorial Search (SoCS", "citeRegEx": "Arfaee et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Arfaee et al\\.", "year": 2010}, {"title": "Planning in polynomial time: the SAS-PUBS class", "author": ["C. B\u00e4ckstr\u00f6m", "I. Klein"], "venue": "Computational Intelligence,", "citeRegEx": "B\u00e4ckstr\u00f6m and Klein,? \\Q1991\\E", "shortCiteRegEx": "B\u00e4ckstr\u00f6m and Klein", "year": 1991}, {"title": "Using CSP look-back techniques to solve real-world SAT instances", "author": ["R.J. Bayardo Jr.", "R. Schrag"], "venue": "Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI", "citeRegEx": "Jr. and Schrag,? \\Q1997\\E", "shortCiteRegEx": "Jr. and Schrag", "year": 1997}, {"title": "Strengthening landmark heuristics via hitting sets", "author": ["B. Bonet", "M. Helmert"], "venue": "Proceedings of the 19th European Conference on Artificial Intelligence (ECAI", "citeRegEx": "Bonet and Helmert,? \\Q2010\\E", "shortCiteRegEx": "Bonet and Helmert", "year": 2010}, {"title": "A robust and fast action selection mechanism for planning", "author": ["B. Bonet", "G. Loerincs", "H. Geffner"], "venue": "Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI", "citeRegEx": "Bonet et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Bonet et al\\.", "year": 1997}, {"title": "Macro-FF: Improving AI planning with automatically learned macro-operators", "author": ["A. Botea", "M. Enzenberger", "M. M\u00fcller", "J. Schaeffer"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Botea et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Botea et al\\.", "year": 2005}, {"title": "A multi-path compilation approach to contingent planning", "author": ["R. Brafman", "G. Shani"], "venue": "Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence (AAAI", "citeRegEx": "Brafman and Shani,? \\Q2012\\E", "shortCiteRegEx": "Brafman and Shani", "year": 2012}, {"title": "Hyper-Heuristics: An Emerging Direction in Modern Search Technology", "author": ["E. Burke", "G. Kendall", "J. Newall", "E. Hart", "P. Ross", "S. Schulenburg"], "venue": "In Handbook of Metaheuristics, International Series in Operations Research & Management Science,", "citeRegEx": "Burke et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Burke et al\\.", "year": 2003}, {"title": "Marvin: A heuristic search planner with online macro-action learning", "author": ["A. Coles", "A. Smith"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Coles and Smith,? \\Q2007\\E", "shortCiteRegEx": "Coles and Smith", "year": 2007}, {"title": "Nearest neighbor pattern classification", "author": ["T.M. Cover", "P.E. Hart"], "venue": "IEEE Transactions on Information Theory, 13(1),", "citeRegEx": "Cover and Hart,? \\Q1967\\E", "shortCiteRegEx": "Cover and Hart", "year": 1967}, {"title": "Learning relational decision trees for guiding heuristic planning", "author": ["T. de la Rosa", "S. Jim\u00e9nez", "D. Borrajo"], "venue": "Proceedings of the Eighteenth International Conference on Automated Planning and Scheduling (ICAPS", "citeRegEx": "Rosa et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rosa et al\\.", "year": 2008}, {"title": "To max or not to max: Online learning for speeding up optimal planning", "author": ["C. Domshlak", "E. Karpas", "S. Markovitch"], "venue": "Proceedings of the TwentyFourth AAAI Conference on Artificial Intelligence (AAAI", "citeRegEx": "Domshlak et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Domshlak et al\\.", "year": 2010}, {"title": "Speedup learning", "author": ["A. Fern"], "venue": "Sammut, C., & Webb, G. I. (Eds.), Encyclopedia of Machine Learning, pp. 907\u2013911. Springer.", "citeRegEx": "Fern,? 2010", "shortCiteRegEx": "Fern", "year": 2010}, {"title": "The first learning track of the international planning competition", "author": ["A. Fern", "R. Khardon", "P. Tadepalli"], "venue": "Machine Learning,", "citeRegEx": "Fern et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Fern et al\\.", "year": 2011}, {"title": "Learning and executing generalized robot plans", "author": ["R.E. Fikes", "P.E. Hart", "N.J. Nilsson"], "venue": "Artificial Intelligence,", "citeRegEx": "Fikes et al\\.,? \\Q1972\\E", "shortCiteRegEx": "Fikes et al\\.", "year": 1972}, {"title": "STRIPS: A new approach to the application of theorem proving to problem solving", "author": ["R.E. Fikes", "N.J. Nilsson"], "venue": "Artificial Intelligence,", "citeRegEx": "Fikes and Nilsson,? \\Q1971\\E", "shortCiteRegEx": "Fikes and Nilsson", "year": 1971}, {"title": "A selective macro-learning algorithm and its application to the NxN sliding-tile puzzle", "author": ["L. Finkelstein", "S. Markovitch"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Finkelstein and Markovitch,? \\Q1998\\E", "shortCiteRegEx": "Finkelstein and Markovitch", "year": 1998}, {"title": "The 2011 international planning competition", "author": ["A. Garc\u0131\u0301a-Olaya", "S. Jim\u00e9nez", "C. Linares L\u00f3pez"], "venue": "Tech. rep., Universidad Carlos III de Madrid. http://hdl.handle.net/10016/11710", "citeRegEx": "Garc\u0131\u0301a.Olaya et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Garc\u0131\u0301a.Olaya et al\\.", "year": 2011}, {"title": "The model-based approach to autonomous behavior: A personal view", "author": ["H. Geffner"], "venue": "Fox, M., & Poole, D. (Eds.), Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2010), pp. 1709\u20131712. AAAI Press.", "citeRegEx": "Geffner,? 2010", "shortCiteRegEx": "Geffner", "year": 2010}, {"title": "Domain-independent construction of pattern database heuristics for cost-optimal planning", "author": ["P. Haslum", "A. Botea", "M. Helmert", "B. Bonet", "S. Koenig"], "venue": "Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence (AAAI", "citeRegEx": "Haslum et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Haslum et al\\.", "year": 2007}, {"title": "The Fast Downward planning system", "author": ["M. Helmert"], "venue": "Journal of Artificial Intelligence Research, 26, 191\u2013246.", "citeRegEx": "Helmert,? 2006", "shortCiteRegEx": "Helmert", "year": 2006}, {"title": "Landmarks, critical paths and abstractions: What\u2019s the difference anyway", "author": ["M. Helmert", "C. Domshlak"], "venue": "Proceedings of the Nineteenth International Conference on Automated Planning and Scheduling (ICAPS", "citeRegEx": "Helmert and Domshlak,? \\Q2009\\E", "shortCiteRegEx": "Helmert and Domshlak", "year": 2009}, {"title": "Flexible abstraction heuristics for optimal sequential planning", "author": ["M. Helmert", "P. Haslum", "J. Hoffmann"], "venue": "Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS", "citeRegEx": "Helmert et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Helmert et al\\.", "year": 2007}, {"title": "How good is almost perfect", "author": ["M. Helmert", "G. R\u00f6ger"], "venue": "Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence (AAAI", "citeRegEx": "Helmert and R\u00f6ger,? \\Q2008\\E", "shortCiteRegEx": "Helmert and R\u00f6ger", "year": 2008}, {"title": "Fast Downward Stone Soup: A baseline for building planner portfolios", "author": ["M. Helmert", "G. R\u00f6ger", "E. Karpas"], "venue": "In ICAPS 2011 Workshop on Planning and Learning,", "citeRegEx": "Helmert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Helmert et al\\.", "year": 2011}, {"title": "The FF planning system: Fast plan generation through heuristic search", "author": ["J. Hoffmann", "B. Nebel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Hoffmann and Nebel,? \\Q2001\\E", "shortCiteRegEx": "Hoffmann and Nebel", "year": 2001}, {"title": "ParamILS: An automatic algorithm configuration framework", "author": ["F. Hutter", "H.H. Hoos", "K. Leyton-Brown", "T. St\u00fctzle"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Hutter et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2009}, {"title": "Cost-optimal planning with landmarks", "author": ["E. Karpas", "C. Domshlak"], "venue": "Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI", "citeRegEx": "Karpas and Domshlak,? \\Q2009\\E", "shortCiteRegEx": "Karpas and Domshlak", "year": 2009}, {"title": "Implicit abstraction heuristics", "author": ["M. Katz", "C. Domshlak"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Katz and Domshlak,? \\Q2010\\E", "shortCiteRegEx": "Katz and Domshlak", "year": 2010}, {"title": "Planning as satisfiability", "author": ["H. Kautz", "B. Selman"], "venue": "Proceedings of the 10th European Conference on Artificial Intelligence (ECAI", "citeRegEx": "Kautz and Selman,? \\Q1992\\E", "shortCiteRegEx": "Kautz and Selman", "year": 1992}, {"title": "Soft goals can be compiled away", "author": ["E. Keyder", "H. Geffner"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Keyder and Geffner,? \\Q2009\\E", "shortCiteRegEx": "Keyder and Geffner", "year": 2009}, {"title": "GRASP - a new search algorithm for satisfiability", "author": ["J.P. Marques-Silva", "K.A. Sakallah"], "venue": "In Proceedings of the 1996 IEEE/ACM International Conference on Computer-Aided Design (ICCAD", "citeRegEx": "Marques.Silva and Sakallah,? \\Q1996\\E", "shortCiteRegEx": "Marques.Silva and Sakallah", "year": 1996}, {"title": "Machine Learning Methods for Planning", "author": ["S. Minton"], "venue": "Morgan Kaufmann Publishers Inc.", "citeRegEx": "Minton,? 1994", "shortCiteRegEx": "Minton", "year": 1994}, {"title": "Computing perfect heuristics in polynomial time: On bisimulation and merge-and-shrink abstraction in optimal planning", "author": ["R. Nissim", "J. Hoffmann", "M. Helmert"], "venue": "Proceedings of the 22nd International Joint Conference on Artificial Intelligence", "citeRegEx": "Nissim et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nissim et al\\.", "year": 2011}, {"title": "Compiling uncertainty away in conformant planning problems with bounded width", "author": ["H. Palacios", "H. Geffner"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Palacios and Geffner,? \\Q2009\\E", "shortCiteRegEx": "Palacios and Geffner", "year": 2009}, {"title": "Heuristics: Intelligent Search Strategies for Computer Problem Solving", "author": ["J. Pearl"], "venue": "AddisonWesley.", "citeRegEx": "Pearl,? 1984", "shortCiteRegEx": "Pearl", "year": 1984}, {"title": "ADL: Exploring the middle ground between STRIPS and the situation calculus", "author": ["E.P.D. Pednault"], "venue": "Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning (KR 1989), pp. 324\u2013332. Morgan Kaufmann.", "citeRegEx": "Pednault,? 1989", "shortCiteRegEx": "Pednault", "year": 1989}, {"title": "A new basis for state-space learning systems and a successful implementation", "author": ["L.A. Rendell"], "venue": "Artificial Intelligence, 20(4), 369\u2013392.", "citeRegEx": "Rendell,? 1983", "shortCiteRegEx": "Rendell", "year": 1983}, {"title": "Planning as satisfiability: Parallel plans and algorithms for plan search", "author": ["J. Rintanen", "K. Heljanko", "I. Niemel\u00e4"], "venue": "Artificial Intelligence,", "citeRegEx": "Rintanen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Rintanen et al\\.", "year": 2006}, {"title": "Composing real-time systems", "author": ["S.J. Russell", "S. Zilberstein"], "venue": "Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI", "citeRegEx": "Russell and Zilberstein,? \\Q1991\\E", "shortCiteRegEx": "Russell and Zilberstein", "year": 1991}, {"title": "Nogood recording for static and dynamic constraint satisfaction problems", "author": ["T. Schiex", "G. Verfaillie"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Schiex and Verfaillie,? \\Q1993\\E", "shortCiteRegEx": "Schiex and Verfaillie", "year": 1993}, {"title": "Learning inadmissible heuristics during search", "author": ["J.T. Thayer", "A.J. Dionne", "W. Ruml"], "venue": "Proceedings of the TwentyFirst International Conference on Automated Planning and Scheduling (ICAPS", "citeRegEx": "Thayer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Thayer et al\\.", "year": 2011}, {"title": "Decision tree induction based on efficient tree restructuring", "author": ["P.E. Utgoff", "N.C. Berkman", "J.A. Clouse"], "venue": "Machine Learning,", "citeRegEx": "Utgoff et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Utgoff et al\\.", "year": 1997}, {"title": "Not so naive Bayes: Aggregating one-dependence estimators", "author": ["G.I. Webb", "J.R. Boughton", "Z. Wang"], "venue": "Machine Learning,", "citeRegEx": "Webb et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Webb et al\\.", "year": 2005}, {"title": "FF-Replan: A baseline for probabilistic planning", "author": ["S. Yoon", "A. Fern", "R. Givan"], "venue": "Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS", "citeRegEx": "Yoon et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yoon et al\\.", "year": 2007}, {"title": "Learning control knowledge for forward search planning", "author": ["S. Yoon", "A. Fern", "R. Givan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Yoon et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Yoon et al\\.", "year": 2008}, {"title": "Learning-assisted automated planning: looking back, taking stock, going forward", "author": ["T. Zimmerman", "S. Kambhampati"], "venue": "AI Magazine,", "citeRegEx": "Zimmerman and Kambhampati,? \\Q2003\\E", "shortCiteRegEx": "Zimmerman and Kambhampati", "year": 2003}], "referenceMentions": [{"referenceID": 18, "context": "Planning in AI is best conceived as the model-based approach to automated action selection (Geffner, 2010).", "startOffset": 91, "endOffset": 106}, {"referenceID": 31, "context": "The computational difficulty of domain-independent planning has led many researchers to use speedup learning techniques in order to improve the performance of planning systems; for a survey of many of these, see the work of Minton (1994), Zimmerman and Kambhampati (2003), and Fern, Khardon, and Tadepalli (2011).", "startOffset": 224, "endOffset": 238}, {"referenceID": 31, "context": "The computational difficulty of domain-independent planning has led many researchers to use speedup learning techniques in order to improve the performance of planning systems; for a survey of many of these, see the work of Minton (1994), Zimmerman and Kambhampati (2003), and Fern, Khardon, and Tadepalli (2011).", "startOffset": 224, "endOffset": 272}, {"referenceID": 12, "context": "The computational difficulty of domain-independent planning has led many researchers to use speedup learning techniques in order to improve the performance of planning systems; for a survey of many of these, see the work of Minton (1994), Zimmerman and Kambhampati (2003), and Fern, Khardon, and Tadepalli (2011).", "startOffset": 277, "endOffset": 313}, {"referenceID": 12, "context": "Speedup learning systems can be divided along several dimensions (Zimmerman & Kambhampati, 2003; Fern, 2010).", "startOffset": 65, "endOffset": 108}, {"referenceID": 13, "context": "Offline learning has been applied extensively to domain-independent planning, with varying degrees of success (Fern et al., 2011).", "startOffset": 110, "endOffset": 129}, {"referenceID": 36, "context": "Several formalisms for describing planning tasks are in use, including STRIPS (Fikes & Nilsson, 1971), ADL (Pednault, 1989), and SAS+ (B\u00e4ckstr\u00f6m & Klein, 1991; B\u00e4ckstr\u00f6m & Nebel, 1995).", "startOffset": 107, "endOffset": 123}, {"referenceID": 20, "context": "We describe the SAS+ formalism, the one used by the Fast Downward planner (Helmert, 2006), on top of which we have implemented and evaluated selective max.", "startOffset": 74, "endOffset": 89}, {"referenceID": 7, "context": "As mentioned previously, selective max is a form of hyper-heuristic (Burke et al., 2003) that chooses which heuristic to compute at each state.", "startOffset": 68, "endOffset": 88}, {"referenceID": 35, "context": "Such an idealized search space model was used in the past to analyze the behavior of A\u2217 (Pearl, 1984).", "startOffset": 88, "endOffset": 101}, {"referenceID": 35, "context": "The A\u2217 algorithm with a consistent heuristic h expands states in increasing order of f = g + h (Pearl, 1984).", "startOffset": 95, "endOffset": 108}, {"referenceID": 20, "context": "In particular, the experiments of Helmert and R\u00f6ger (2008) on IPC benchmarks with heuristics with small constant additive errors show that the number of expanded nodes most typically grows exponentially as the (still very small and additive) error increases.", "startOffset": 34, "endOffset": 59}, {"referenceID": 20, "context": "The third state-space sampling procedure, referred to here as PDB sampling, has been proposed by Haslum, Botea, Helmert, Bonet, and Koenig (2007). This procedure also uses unbiased probes, but only adds the last state reached in each probe to the state-space sample.", "startOffset": 112, "endOffset": 146}, {"referenceID": 20, "context": "To evaluate selective max empirically, we implemented it on top of the open-source Fast Downward planner (Helmert, 2006).", "startOffset": 105, "endOffset": 120}, {"referenceID": 17, "context": "The IPC-2011 experiments (Garc\u0131\u0301a-Olaya et al., 2011) were run by the IPC organizers, on their own machines, with a time limit of 30 minutes and a memory limit of 6 GB per planning task.", "startOffset": 25, "endOffset": 53}, {"referenceID": 33, "context": "While there are other admissible heuristics for SAS+ planning that are competitive with the three above (for example, Helmert, Haslum, & Hoffmann, 2007; Nissim et al., 2011; Katz & Domshlak, 2010), they are based on expensive offline preprocessing, followed by very fast online per-state computation.", "startOffset": 104, "endOffset": 196}, {"referenceID": 19, "context": "1: biased probes (selh ), unbiased probes (sel UP h ), and the sampling method of Haslum et al. (2007) (selPDB h ).", "startOffset": 82, "endOffset": 103}, {"referenceID": 43, "context": "A more sophisticated variant of Naive Bayes called AODE (Webb et al., 2005) is also considered here (sel h ).", "startOffset": 56, "endOffset": 75}, {"referenceID": 19, "context": "N 100 initial sample size Sampling method PDB (Haslum et al., 2007) state-space sampling method Classifier Naive Bayes classifier type", "startOffset": 46, "endOffset": 67}, {"referenceID": 42, "context": "Another possible choice is using incremental decision trees (Utgoff et al., 1997), which offer even faster classification, but more expensive learning when the tree structure needs to be changed (sel h ).", "startOffset": 60, "endOffset": 81}, {"referenceID": 24, "context": "Sequential portfolio solvers for optimal planning are another approach for exploiting the merits of different heuristic functions, and they have been very successful in practice, with the Fast Downward Stone Soup sequential portfolio (Helmert et al., 2011) winning the sequential optimal track at IPC2011.", "startOffset": 234, "endOffset": 256}, {"referenceID": 37, "context": "However, despite some early work (Rendell, 1983), relatively little work has dealt with learning for state-space search guided by distance-estimating heuristics, one of the most prominent approaches to planning these days.", "startOffset": 33, "endOffset": 48}, {"referenceID": 37, "context": "However, despite some early work (Rendell, 1983), relatively little work has dealt with learning for state-space search guided by distance-estimating heuristics, one of the most prominent approaches to planning these days. Most works in this direction have been devoted to learning macro-actions (see, for example, Finkelstein & Markovitch, 1998; Botea, Enzenberger, M\u00fcller, & Schaeffer, 2005; Coles & Smith, 2007). Recently, learning for heuristic search planning has received more attention: Yoon et al. (2008) suggested learning (inadmissible) heuristic functions based upon features extracted from relaxed plans.", "startOffset": 34, "endOffset": 513}, {"referenceID": 37, "context": "However, despite some early work (Rendell, 1983), relatively little work has dealt with learning for state-space search guided by distance-estimating heuristics, one of the most prominent approaches to planning these days. Most works in this direction have been devoted to learning macro-actions (see, for example, Finkelstein & Markovitch, 1998; Botea, Enzenberger, M\u00fcller, & Schaeffer, 2005; Coles & Smith, 2007). Recently, learning for heuristic search planning has received more attention: Yoon et al. (2008) suggested learning (inadmissible) heuristic functions based upon features extracted from relaxed plans. Arfaee, Zilles, and Holte (2010) attempted to learn an almost admissible heuristic estimate using a neural network.", "startOffset": 34, "endOffset": 650}, {"referenceID": 37, "context": "However, despite some early work (Rendell, 1983), relatively little work has dealt with learning for state-space search guided by distance-estimating heuristics, one of the most prominent approaches to planning these days. Most works in this direction have been devoted to learning macro-actions (see, for example, Finkelstein & Markovitch, 1998; Botea, Enzenberger, M\u00fcller, & Schaeffer, 2005; Coles & Smith, 2007). Recently, learning for heuristic search planning has received more attention: Yoon et al. (2008) suggested learning (inadmissible) heuristic functions based upon features extracted from relaxed plans. Arfaee, Zilles, and Holte (2010) attempted to learn an almost admissible heuristic estimate using a neural network. Perhaps the most closely related work to ours is that of Thayer, Dionne, and Ruml (2011), who learn to correct errors in heuristic estimates online.", "startOffset": 34, "endOffset": 822}, {"referenceID": 19, "context": "PDB is the sampling method of Haslum et al. (2007), P is the biased probes sampling method, and UP is the unbiased probes sampling method.", "startOffset": 30, "endOffset": 51}], "year": 2012, "abstractText": "Domain-independent planning is one of the foundational areas in the field of Artificial Intelligence. A description of a planning task consists of an initial world state, a goal, and a set of actions for modifying the world state. The objective is to find a sequence of actions, that is, a plan, that transforms the initial world state into a goal state. In optimal planning, we are interested in finding not just a plan, but one of the cheapest plans. A prominent approach to optimal planning these days is heuristic state-space search, guided by admissible heuristic functions. Numerous admissible heuristics have been developed, each with its own strengths and weaknesses, and it is well known that there is no single \u201cbest\u201d heuristic for optimal planning in general. Thus, which heuristic to choose for a given planning task is a difficult question. This difficulty can be avoided by combining several heuristics, but that requires computing numerous heuristic estimates at each state, and the tradeoff between the time spent doing so and the time saved by the combined advantages of the different heuristics might be high. We present a novel method that reduces the cost of combining admissible heuristics for optimal planning, while maintaining its benefits. Using an idealized search space model, we formulate a decision rule for choosing the best heuristic to compute at each state. We then present an active online learning approach for learning a classifier with that decision rule as the target concept, and employ the learned classifier to decide which heuristic to compute at each state. We evaluate this technique empirically, and show that it substantially outperforms the standard method for combining several heuristics via their pointwise maximum.", "creator": "TeX"}}}