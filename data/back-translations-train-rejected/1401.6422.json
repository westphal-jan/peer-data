{"id": "1401.6422", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2014", "title": "Automatic Aggregation by Joint Modeling of Aspects and Values", "abstract": "We present a model for aggregation of product review snippets by joint aspect identification and sentiment analysis. Our model simultaneously identifies an underlying set of ratable aspects presented in the reviews of a product (e.g., sushi and miso for a Japanese restaurant) and determines the corresponding sentiment of each aspect. This approach directly enables discovery of highly-rated or inconsistent aspects of a product. Our generative model admits an efficient variational mean-field inference algorithm. It is also easily extensible, and we describe several modifications and their effects on model structure and inference. We test our model on two tasks, joint aspect identification and sentiment analysis on a set of Yelp reviews and aspect identification alone on a set of medical summaries. We evaluate the performance of the model on aspect identification, sentiment analysis, and per-word labeling accuracy. We demonstrate that our model outperforms applicable baselines by a considerable margin, yielding up to 32% relative error reduction on aspect identification and up to 20% relative error reduction on sentiment analysis.", "histories": [["v1", "Thu, 23 Jan 2014 02:48:07 GMT  (505kb)", "http://arxiv.org/abs/1401.6422v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["christina sauper", "regina barzilay"], "accepted": false, "id": "1401.6422"}, "pdf": {"name": "1401.6422.pdf", "metadata": {"source": "CRF", "title": "Automatic Aggregation by Joint Modeling of Aspects and Values", "authors": ["Christina Sauper", "Regina Barzilay"], "emails": ["csauper@csail.mit.edu", "regina@csail.mit.edu"], "sections": [{"heading": "1. Introduction", "text": "This year it is more than ever before."}, {"heading": "2. Related Work", "text": "Our work falls into the field of multi-aspect sentiment analysis. In this section, we first describe approaches to sentiment analysis at the document and sentence level (Section 2.1), which form the basis for future work, including our own. Then, we describe three common directions of multi-aspect sentiment analysis; in particular, those that use data mining or fixed-aspect analysis (Section 2.2.1), those that include sentiment analysis with multi-document summary (Section 2.2.2), and finally those that focus on subject modeling with additional sentiment components (Section 2.2.3)."}, {"heading": "2.1 Single-Aspect Sentiment Analysis", "text": "Early sentiment analyses focused primarily on identifying broad document-level sentiments (Pang, Lee, & Vaithyanathan, 2002; Turney, 2002; Pang & Lee, 2008). Specifically, these approaches attempted to determine the general polarity of documents, using both rule-based and machine-learning approaches: Turney (2002) used a rule-based method to extract potentially sentimental phrases and then compare them with the sense of words with known polarity, while Pang et al. (2002) used discriminatory methods with features such as unigrams, bigrams, part-of-speech tags, and word position information.While document-level sentiment analyses can give us an overall view of an opinion, looking at individual sentences within the document provides a finer-grained analysis."}, {"heading": "2.2 Aspect-Based Sentiment Analysis", "text": "After working on analyzing individual aspects at the document and sentence levels, the intuition of modeling aspect-based (also called \"feature-based\") sentiments came to the fore. We can roughly divide these approaches into three types of systems based on their techniques: systems that use fixed-aspect approaches or data-mining techniques for aspect selection or sentiment analysis, systems that adapt techniques from the aggregation of multiple documents, and systems that model aspects and feelings together with probabilistic topic models. Here, we examine each approach with relevant examples and compare them to our own work."}, {"heading": "2.2.1 Data-Mining and Fixed-Aspect Techniques for Sentiment Analysis", "text": "In fact, it is in such a way that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process, to a process, to a process, to a process, to a process in which there is a process, to a process, to a process in which there is a process, to a process, to a process in which there is a process, to a process in which there is a process, to a process, to a process in which there is a process, to a process, to a process in which there is a process, to a process, to a process, to a process, to a process in which process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process in which process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process, to a process,"}, {"heading": "2.2.2 Multi-Document Summarization and its Application to Sentiment Analysis", "text": "In fact, it is the case that most of them are in a position to survive themselves by embarking on a search for another path that leads them to another world, in which they are in a different world, in which they no longer find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not want to find themselves, in which they do not find themselves, in which they do not want to find themselves, in which they do not want to find themselves, in which they do not find themselves, in which they do not want to find themselves, in which they do not want to find themselves, in which they cannot find themselves, in which they do not want to live, in which they do not want to live, in which they do not want to, in which they do not want to want, in which they do not want to want, in which they do not want to want, in which they do not want to want, in which they do not want to want, in which they do not want to want, in which they do not want to want, in which they do not want to want, in which they do not want to want, in which they do not want to be in which they do not want to be in which they do not want, in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want, in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want, in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want, in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want, in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want, in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want to be in which they do not want to be in which they do not"}, {"heading": "2.2.3 Probabilistic Topic Modeling for Sentiment Analysis", "text": "In fact, it is the case that most of them will be able to survive themselves without there being a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, in which there is a process, and a process, and a process, and a process, and a process, in which there is a process, and a process, in which there is a process, and a process, and a process, in which there is a process, and it comes to a process, and it comes to a process, and it comes to a process."}, {"heading": "3. Problem Formulation", "text": "Before explaining the details of the model, we describe the random variables and abstractions of our model, as well as some intuitions and assumptions. For a visual explanation of the model components, see Figure 3. We present full details and the generative history in Section 4."}, {"heading": "3.1 Model Components", "text": "Our model consists of five component types: units, snippets, aspects, values and word themes. Here we describe each type and provide examples. 2. Here we explain our complete model with value selection for feelings in the restaurant sector. In the simplified case in the medical sector, where we only want to use aspects, we can simply ignore the value-oriented components of the model."}, {"heading": "3.1.1 Entity", "text": "A company represents a single object described in the review. In the restaurant area, these are individual restaurants such as Tasca Spanish Tapas, Douzo Sushi Bar and Outback Steakhouse."}, {"heading": "3.1.2 Snippet", "text": "A snippet is a short sequence of words generated by the user that describe an entity. These snippet can be provided by the user as they are (for example, in a \"quick reaction box\") or extracted from complete reviews using a phrase extraction system such as that of Sauper, Haghighi and Barzilay (2010). We assume that each snippet contains at most a single aspect (e.g. pizza) and a single value (e.g. positive). In the restaurant area, this corresponds to giving an opinion on a particular dish or category of dishes. Examples from the restaurant area are \"your pasta dishes themselves are perfection,\" \"they had fantastic drinks\" and \"the lasagne rustica was cooked perfectly.\""}, {"heading": "3.1.3 Aspect", "text": "One aspect corresponds to one of several characteristics of an entity. In the restaurant area, where entities represent restaurants, aspects may correspond to individual dishes or categories of dishes, such as pizza or alcoholic beverages. In this area, each entity has its own unique aspects. This allows us to model aspects in the corresponding graininess. An Italian restaurant, for example, might have a dessert aspect that includes information about a variety of cakes, pies and gelato. However, most aspects of a bakery's menu fall within the same dessert aspect. Instead, to present a viable aspect-based summary, separate aspects are required for each cake, cake, etc. As aspects are more company-specific than common, there are no links between restaurants that have aspects in common (e.g. most sushi restaurants will have a sashimi aspect); we consider this as a point for potential future work. Note that it is still possible to compare aspects across entities to find the best one for each restaurant (for example, by comparing the burger for each one of them)."}, {"heading": "3.1.4 Value", "text": "Values represent the information associated with an aspect. In the editorial domain, the two value types represent positive and negative feelings respectively. In general, it is possible to use the value to represent other distinctions; for example, in an area where some aspects are associated with a numerical value and others with a text description, each of them can be defined as a value type. Intended distinctions can be promoted by using start words (see Section 3.2), or they can be left unspecified for the model to assign what it considers best to the data. The number of value types must be specified, but it is possible to use either very few or very many types."}, {"heading": "3.1.5 Word Topic", "text": "While the words are observed in each snippet, each word is associated with an underlying latent theme. Possible latent themes correspond to aspects, values, and background themes. For example, the latent theme of words would be great or terrible value, of words representing entity aspects such as pizza, aspect, and stopwords such as is, or of white noise such as food background."}, {"heading": "3.2 Problem Setup", "text": "In this work, we assume that the snippet words are always adhered to, and that the correlation between snippet and entity is known (i.e. we know which entity a particular snippet describes), and we assume a portion of the speech marks for each word in each snippet. As a final source of control, we can optionally insert small sets of seed words for a lexical distribution to distort the distribution toward the intended meaning. For example, in the case of sentiment, we can add seed words to distort a value distribution toward the positive and one toward the negative. Seed words are certainly not required; they are merely a tool to restrict the use of the distributions of the model to meet all previous expectations. Note that in this formulation, the relevant aspects for each restaurant are not considered; instead, they are represented by lexical distributions induced at inference times."}, {"heading": "4. Model", "text": "Our model has a generative formulation of all the snippets in the corpus. In this section we will first describe in detail the general formulation and notation of the model, then discuss new changes and improvements for certain corpora types. Conclusions for this model will be described in Section 5. As already mentioned, we will describe the complete model including the aspect values."}, {"heading": "4.1 General Formulation", "text": "In this model, we assume a collection of all the snippet words for all entities, s. We use si, j, w to denote the growth word of the jth snippet of the ith entity. We also assume a fixed vocabulary, W. We present a summary of the notation in Table 1, a concise summary of the model in Figure 4, and a model diagram in Figure 5. There are three levels in model design: global distributions common to all the snippet for all entities in the collection, entity-level distributions common to all snippet and word levels, and random variables at the snippet and word levels."}, {"heading": "4.1.1 Global Distributions", "text": "At the global level, we draw a series of distributions that are common to all units in the corpus, including everything that is shared within a domain, such as the background stop word distribution, value types, and word topic transitions. Background distribution A global background word distribution is drawn to represent stop words and cross-domain white noise (e.g., \"food\" becomes white noise in a corpus of restaurant ratings.) This distribution is drawn by a symmetrical dirichlet with concentration parameters sustaB, but in our experiments this is set to 0.2. Value distributions. A value distribution sensitivity is drawn for each value type v. For example, in a valuation domain with positive and negative mood types, there is a distribution over words for the positive type and one for the negative type. Seeds Wseedv receive additional probability mass on which value priors for the type v receive a seed parameter; a non-grained word receives a seed parameter."}, {"heading": "4.1.2 Entity-Specific Distributions", "text": "There are, of course, differences in the aspects that describe snippets and how many snippets describe each aspect. For example, a mobile device that is popular for long battery life will probably have more snippets that describe the battery than a device known for its big screen. Some domains may have huge variations in aspect vocabulary; for example, restaurant reviews cannot compare two restaurants for the same food. To explain these variations, we define a set of entity-specific distributions that generate both aspect vocabularies and popularity aspects, as well as a distribution by value types for each aspect. Aspect Distributions An aspect word distribution is drawn for each aspect a. Each of these aspects represents the distribution by unigrams for a particular aspect. For example, in the restaurant ratings domain, aspects can correspond to menu items such as pizza, while in reviews for mobile phones they are likely to include details such as battery life."}, {"heading": "4.1.3 Snippet- and Word-Specific Random Variables", "text": "Based on the distributions described above, we can now use random variables for each snippet to determine the aspect and type of value described, as well as the order of underlying word themes and words.Aspect A single aspect Zi, jA that this snippet will describe is taken from the aspect of multinomial land use plan. All aspect words in the snippet (e.g. pizza in a corpus of restaurant reviews) are drawn from the appropriate aspect word distribution \u03b8 i, Zi, jA. Value type A single value type Zi, jV are drawn conditionally on the selected aspect from the respective aspect value of multinomial inspi, Z i, j A. All value words in the snippet (e.g. \"large\" in the review domain) are drawn from the associated value distribution list \u03b8 Zi, jV. Word Topic Indicators Follow A Word Indicators ZW 1W indicators."}, {"heading": "4.2 Model Extensions", "text": "There are a few optional components of the model that can improve performance in some cases. We briefly list them here and then present the necessary modifications of the model in detail for each case. Changes to the follow-up process are presented in Section 5.2. First, for corpora that contain irrelevant snippets, we can introduce an additional word distribution \u03b8I and Ignore Word theme so that the model can ignore certain snippets or snippets altogether. Second, if it is possible to acquire a portion of the language markers for these snippets, using them as an additional piece of information is quite beneficial. Finally, for corpora that is expected to share the same aspects, the model can be modified to use the same set of aspect distributions for all units."}, {"heading": "4.2.1 Ignoring Snippets", "text": "When snippets are automatically extracted, they can be loud, and some snippets may violate our original assumptions of having an aspect and a value. For example, we find some snippets that were extracted by mistake and have neither aspect nor value. A priori, these snippets can be difficult to identify. To compensate for this, we modify the model so that partial or whole snippets can be ignored by adding a global unigram distribution, namely the ignorance distribution \u03b8I. This distribution is drawn from a symmetrical dirichlet with the concentration parameter \u03bbI. The ignorer distribution differs from the background distribution in that it contains both common and unusual words. It is intended to select whole snippets or large parts of snippets, so that some words may overlap with the background distribution and other distributions. To successfully integrate this distribution into our theme, we must allow the word theme, Zj, to the indicator W."}, {"heading": "4.2.2 Part-of-Speech Tags", "text": "In some areas, value words describe aspects and tend to be expressed as numbers or adjectives. This intuition can be directly incorporated into the model in the form of additional outputs. Specifically, we modify our HMM to generate both words and tags. In addition, we define distributions by tags \u03b7aA, \u03b7 v V and \u03b7B, similar to the corresponding unigram distributions."}, {"heading": "4.2.3 Shared Aspects", "text": "If domains are very regular and each company is expected to express aspects from a single set, it is beneficial to exchange aspect information between companies. For example, in a medical field, the same general laboratory tests and physical test categories are performed on all patients. Note that this is very different from the restaurant evaluation case, where the aspects of each restaurant are completely different (e.g. pizza, curry, scones, etc.).Aspects can be exchanged in this way by changing aspect distributions \u03b8i, aA to become global distributions \u03b8 a A. Similarly, aspect-value multinomials \u03c6i, a can be shared across all companies like \u03c6a. Treatment of aspect multinomials depends on domain properties. If the distribution across aspects is to be the same across all units, it can also be made global; however, if each individual company is expected to have variations in the number of aspect-related snippets, it should be presented as a specific example for most mobile phones."}, {"heading": "5. Inference", "text": "The aim of the conclusion in this model is to predict the aspect and value for each snippet i and product j taking into account the text of all observed snippets, while marginalizing the remaining hidden parameters: P (Zi, jA, Z i, j V | s) We perform this task with variational inference (Lead, Ng, & Jordan, 2003). The aim of variable inference is in particular to find a tractable approximation Q (\u00b7) to the complete posterior of the model. P (\u03b8B, \u03b8V, \u0394A, \u03b8A, \u03b8A, \u0432, \u03c6, Z | s) \u2248 Q (\u03b8B, \u03b8V, \u03a4A, \u03c6A, \u03c6, \u03c6, \u03c6, Z) For our model we assume a complete factor factoring on average, which is shown in Figure 7. This variational approximation is defined as a product of the factors q (\u00b7) which are assumed to be independent. This approximation enables each factoring to obtain an intractable."}, {"heading": "5.1 Optimization", "text": "Specifically, we update each factor by optimizing the above criterion with all other factors fixed to their current values: q (\u00b7) \u2190 EQ / q (\u00b7) logP (\u03b8B, \u03b8V, \u0442, \u03b8A, \u0432, \u03c6, Z, s) A summary of the variation actualization equations is given in Figure 7, and a graphical representation of the variables involved for each step is shown in Figure 8. Here we will present the update for each factor."}, {"heading": "5.1.1 Snippet Aspect Indicator", "text": "First, we consider updating the aspect indicator for the snippet, Zi, jA (Figure 8a): log q (Zi, jA = a), a (s i, j, w) (1a) + \u2211 w q (Zi, j, wW = A) Eq (\u03b8i, aA) log \u03b8 i, a (s i, j, w) (1b) + N \u2211 v = 1 q (Zi, jV = v) Eq (\u03c6i, a) log \u03c6 i, a (v) (1c) The optimal aspect for a particular snippet depends on three factors. First, we include the probability to discuss each aspect a (Eqn. 1a). As mentioned above, this encodes the previous probability that some aspects will be discussed more often than others. Second, we examine the probability of a particular aspect based on the words in the snippet (Eqn. 1b). For each word identified as an integer, we add the most probable aspect to this one when determining the third aspect."}, {"heading": "5.1.2 Snippet Value Type Indicator", "text": "Next, we consider updating the value type indicator for snippets, Zi, jV (Figure 8b): log q (Zi, jV = v) q (Zi, jA = a) Eq (\u03c6i, a) log \u03c6 i, a (v) (2a) + \u2211 w q (Zi, j, wW = V) Eq (\u03b8vV) log \u03b8 v (s i, j, w) (2b) The best value type for a snippet depends on two factors. First, like the aspect indicator for snippets, we have to consider the compatibility between snippet aspect and value type (Equation 2a). Second, for each word that is identified as a value type, we consider the probability that it comes from the given value type."}, {"heading": "5.1.3 Word Topic Indicator", "text": "Finally, we consider the update of word topic indicators Zi, j, wW (Figure 8c). In contrast to the previous indicators, every possible topic has a slightly different equation, because we must marginalize all possible aspects and value types. Log q (Zi, j, wW = A) - logP (ZW = A) + Eq (Eq) - logP (Zi, j, w \u2212 1W, A) - (A, Zi, j, w + 1W)) + Eq (Zi, j \u2212 1W) - (Zi, aA) - logP (Zi, j, w = V) - (3a) log q (Zi, j, wW = V) - logP (ZQ -, ww = V) - (Zvi, Q - W (Q), ZW (Q - W), ZW (ZW - (Q), ZW (Q -), ZW (Zvi, Q - (Hi), ZW (Q -), ZW (Q -), ZW (ZW (Q -), ZW (Q -), ZW (Q -, Q - (Hi), ZW (Q -), ZW (ZW -, Q -), ZW (ZW (Zi), ZW -, ZW (Zi), ZW (Zi -, Q - (Zi), ZW (Zi), ZW - (Zi - (Zi), ZW - (Zi), ZW - (Zi - (Zi), Zi - (Zi), Zi - (Zi - (Zi, Zi -), Zi - (Zi, Zi -, Zi - (Zi -), Zi - (Zi, Zi), Zi - (Zi -, Zi -, Zi -, Zi -, Zi -), Zi - (Zi -, Zi - (Zi, Zi), Zi - (Zi, Zi -, Zi, Zi -, Zi, Zi, Zi, Zi, Zi, Zi, Zi -"}, {"heading": "5.1.4 Parameter Factors", "text": "Updates for the parameter factors under Variation Conclusion are derived by simply counting the latent variables ZA, ZV, and ZW. Note that these include partial counts; if a particular section has the aspect probability P (Zi, jA = a1) = 0.35, it would contribute 0.35 counting to the probability that i (a1) is taken into account."}, {"heading": "5.1.5 Algorithm Details", "text": "In practice, convergence is achieved by the 50th iteration, so the algorithm is quite efficient. Note that the batch update means that each update is calculated using the values from the previous iteration, as opposed to Gibbs sampling, where updated values are used while running through the corpus. This difference allows for parallelization of the variable update algorithm, which results in a nice efficiency increase. To parallelise the algorithm, we simply divide the entirety of units evenly across the processors. Updates for entity-specific factors and variables are calculated during the run of the data, and updates for global factors are collected and combined at the end of each run."}, {"heading": "5.2 Inference for Model Extensions", "text": "As described in Section 4.2, we can add additional components to the model to improve the performance of data with certain attributes."}, {"heading": "5.2.1 Ignoring Snippets", "text": "The most important modifications to the model for this extension are the addition of the Unigram Distribution \u03b8I and the Word Theme I. The actualization equation for ZW is modified by the addition of the following elements: log q (Zi, j, wW = I), log logP (ZW = I) + Eq (\u03b8I) log \u03b8I (s i, j, w) As in the other parts of this equation (Eqn. 3), it is composed of the previous probability for the Word Theme I and the probability that this Word is generated by \u03b8I. Furthermore, the transition distribution must be updated to include the transition probabilities for I * and \u0445 I. As already mentioned, transition II receives high weight, while all other transitions from and after me receive very low weight."}, {"heading": "5.2.2 Part-of-Speech Tags", "text": "To add a part of the speech markers, the model is updated to include a part of the speech distributions \u03b7A, \u03b7V and \u03b7B for each word topic. Note that the corresponding tag distributions, unlike the uniform distributions \u03b8 i, a and \u03b8vV, are not dependent on the snippet entity, aspect or value, and are taken into account and referenced in the updates for ZW as follows: log q (Zi, j, wW = A) reported logP (Zi, jA = a) + Eq (\u0445q) log (\u0432 (Zi, j, w \u2212 1W, A) as well as log q (A, Zi, j, w + 1W) + Eq (\u03b7A) log \u03b7A (ti \u2212 j, w = A) reported logP (Zi, w = A) + 5 q (Zi, jW, jW = investi, A, A log (investi, jA, jA) log, jA log, jA logjA investi, A investi A, A investi, A investi (jw = 5 investi, si, jW = A investi, A, A investi, A, A (investi, A) log (investi, jW (investi, A, A) log (investi, A, A, A, A (investi, A) log (investi, A, A, A) log (investi, A, A, A (investi, A, A, A, A, A investi, A, A, A investi, A, A, A, A, A investi, A, A, A, A investi, A, A, A, A, A, A investi, A, A, A, A, A, A, A investi, A, A, A, A, A (zw = 5, A investi, A, A, A, A, A (zw, A, A, A, A, A, A investi, A), A, A, A, A, A, A, A, A, A, A, A, A, A, A, A (zw (zw (zw (zw)."}, {"heading": "5.2.3 Shared Aspects", "text": "A global set of common aspects is a simplification of the model by reducing the total number of parameters. This model redefines aspect distributions by defining successaA and aspect value multinomials. Depending on the domain, it can also redefine the aspect multinomially that becomes BA. The resulting latent variable actualization equations are the same; only the updates of the parameter factors change. Instead of collecting counts of snippets describing a single unit, counts are collected throughout the corpus."}, {"heading": "6. Experiments", "text": "We are conducting experiments on two tasks: firstly, we are testing our complete model based on a common prediction of both aspects and sentiments on a corpus of overview data; secondly, we are using a simplified version of the model designed to identify aspects only on a corpus of medical summary data; these areas are structured in completely different ways and therefore pose very different challenges to our model."}, {"heading": "6.1 Joint Identification of Aspect and Sentiment", "text": "Our first task is to test our complete model by collectively predicting aspects and feelings from a collection of restaurant evaluation data. In particular, we would like to dynamically select a number of relevant aspects for each restaurant, identify the snippets that match each aspect, and restore the polarity of each snippet individually and each aspect as a whole. We conduct three experiments to evaluate the effectiveness of our model: first, we test the quality of the aspects learned by evaluating the predicted snippet clusters; second, we evaluate the quality of the polarity classification; and third, we test the accuracy of the label by word."}, {"heading": "6.1.1 Data Set", "text": "Our data set for this task consists of snippets selected from Yelp restaurant reviews by our previous system (Sauper et al., 2010). To ensure that enough data is available for meaningful analysis, we ignore restaurants that have fewer than 20 snippets in all reviews. While our model can easily work with fewer snippets in restaurants, we want to ensure that the cases we select for review are not trivial; i.e. that there is a sufficient number of snippets in each cluster to make a valid comparison. In total, there are 13,879 snippets coming from 328 restaurants in and around the Boston / Cambridge area. The average snippets length is 7.8 words, and there is an average of 42.1 snippets per restaurant. We use the MXPOST marker for this particular example."}, {"heading": "6.1.2 Domain Challenges and Modeling Techniques", "text": "This domain presents two challenging characteristics for our model. Firstly, there is a wide variety of restaurants within our domain, including everything from high-end Asian fusion cuisine to fatty burger-fast-food establishments. If we were to attempt to present these with a single aspect, please refer to this paper for detailed training procedures. The number of aspects required would be immense, and it would be extremely difficult for our model to make fine-grained distinctions between them. By defining aspects for each restaurant separately, as mentioned in Section 4, we can achieve the correct granularity of aspects for each restaurant without an overwhelming or overlapping selection of choices. For example, the model is able to distinguish that an Italian restaurant only needs a single dessert aspect, while a bakery requires separate cakes, cakes and cookie aspirations. Secondly, while there is usually a fairly coherent group of words that might refer to a specific aspect (for example, pizzas), we are likely to refer to a particular aspect of pizza in general terms."}, {"heading": "6.1.3 Cluster Prediction", "text": "The goal of this task is to evaluate the quality of aspect clusters; in particular, the Zi, jA variable in Section 4: 1. While we are in an ideal cluster formation, the predicted clusters will be coherent in their entirety (i.e., all snippets that include a particular aspect in relation to other aspects) and comprehensive (i.e., all snippets that select an aspect as such, we cannot identify as such). For example, a snippet from 20 restaurants is used, 1026 snippets in total (an average of 51.3 snippets per restaurant), such as its crust, cheese, or toppings.Annotation For this experiment, we use a series of gold clusters on the complete sets of snippets from 20 restaurants, 1026 snippets in total (an average of 51.3 snippets per restaurant).Cluster annotations were provided by students in English. Each annotator was provided with a complete set of 199 snippets in total for one restaurant then asked."}, {"heading": "6.1.4 Sentiment Analysis", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "6.1.5 Per-Word Labeling Accuracy", "text": "The purpose of this task is to assess whether or not each word is correctly identified as an aspect of a word. This distinction is critical to achieving the accuracy of both the cluster analysis and the sentiment analysis, so errors can help us identify the weaknesses of our model. Editor's note: It seems difficult to identify the individual terms, so we imply a filtering process to ensure that only high-quality annotations are allowed to achieve results. Specifically, we ask annotators to produce labels for a series of \"difficult\" phrases with known terms (shown in Table 5). These annotators that have successfully made correct or mostly correct annotations containing new phrases containing new phrases are presented for each word, and the majority name is taken for each word."}, {"heading": "6.2 Aspect Identification with Shared Aspects", "text": "For our second task, we use a simplified version of our model, which is designed for aspect recognition only. For this task, we use a corpus of medical visit summaries. In this area, each summary is expected to contain similar relevant information; therefore, the entirety of the aspects is divided body-wide. To evaluate our model in this formulation, we examine the predicted snippet clusters as in the entire model."}, {"heading": "6.2.1 Data Set", "text": "Our data set for this task consists of phrases selected from dictated summaries of patients at the Pediatric Environmental Health Clinic (PEHC) at Children's Hospital Boston, specializing in treating children with lead poisoning. Specifically, at the end of the physician's visit and laboratory results, a PEHC physician dictates a letter to the referring physician with information about past visits, current developmental and family status, examination results, laboratory results, current diagnoses, and future plans. For this experiment, we select phrases from the review and laboratory results sections of the summaries. Phrases are heuristically separated by comma and semicolon. In an area containing a significant amount of extransient information, such as the restaurant domain, we must extract phrases that we believe have some relevance to the task at hand. However, as the medical text is dense and almost all relevant terms are sufficient to extract hayritic phrases, such as the hayritic separation."}, {"heading": "6.2.2 Domain Challenges and Modeling Techniques", "text": "Unlike the restaurant domain, the medical domain uses a single global set of aspects, which are either individual laboratory tests (e.g. lead content, number of white blood cells) or specific body systems (e.g. lungs or cardiovascular systems). Some aspects are much more common than others, and it is very unusual for a summary to contain more than one or two snippets about a particular aspect. Therefore, as mentioned in Section 4.2, we model the aspect of word distribution and the aspect of multinomical how it is divided between all body parts in the corpus.Unlike the restaurant domain, aspects are defined by words taken from the whole snippet. Instead of associating aspects only with measurement names (e.g. \"weight\"), units and other descriptions of measurements (e.g. \"kilogram\") are also relevant for defining aspects. This property extends to both numerical and written measurements; for example, the aspect of \"lungs\" is generally described as \"clearly to ignore one part of the measurement.\""}, {"heading": "6.2.3 Cluster Prediction", "text": "In fact, we have to be able to hide, and we have to be able, we will be able to be able, \"he said.\" We have to be able to be able, \"he said.\" We have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position. \""}, {"heading": "7. Conclusions and Future Work", "text": "In this case, it is as if it were a purely mental game, in which it is a question of finding a solution that is capable of finding a solution that meets the needs of the individual."}, {"heading": "Acknowledgments", "text": "The authors thank NSF (CAREER grant IIS-0448168), NIH (grant 5-R01-LM009723-02), Nokia and the DARPA Machine Reading Program (AFRL prime contract no. FA8750-09-C-0172) for their helpful comments. Any opinions, findings, conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the funding organizations."}], "references": [{"title": "Information fusion in the context of multi-document summarization", "author": ["R. Barzilay", "K.R. McKeown", "M. Elhadad"], "venue": "In Proceedings of ACL,", "citeRegEx": "Barzilay et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Barzilay et al\\.", "year": 1999}, {"title": "Supervised topic models", "author": ["D.M. Blei", "J. McAuliffe"], "venue": "In Advances in NIPS,", "citeRegEx": "Blei and McAuliffe,? \\Q2008\\E", "shortCiteRegEx": "Blei and McAuliffe", "year": 2008}, {"title": "Generating and evaluating evaluative arguments", "author": ["G. Carenini", "J.D. Moore"], "venue": "Artificial Intelligence,", "citeRegEx": "Carenini and Moore,? \\Q2006\\E", "shortCiteRegEx": "Carenini and Moore", "year": 2006}, {"title": "Multi-document summarization of evaluative text", "author": ["G. Carenini", "R. Ng", "A. Pauls"], "venue": "In Proceedings of EACL,", "citeRegEx": "Carenini et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Carenini et al\\.", "year": 2006}, {"title": "Extracting knowledge from evaluative text", "author": ["G. Carenini", "R.T. Ng", "E. Zwart"], "venue": "In Proceedings of K-CAP,", "citeRegEx": "Carenini et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Carenini et al\\.", "year": 2005}, {"title": "In-domain relation discovery with meta-constraints via posterior regularization", "author": ["H. Chen", "E. Benson", "T. Naseem", "R. Barzilay"], "venue": "In Proceedings of ACL,", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "Global models of document structure using latent permutations", "author": ["H. Chen", "S.R.K. Branavan", "R. Barzilay", "D.R. Karger"], "venue": "In Proceedings of ACL/HLT,", "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "Pranking with ranking", "author": ["K. Crammer", "Y. Singer"], "venue": "In Advances in NIPS,", "citeRegEx": "Crammer and Singer,? \\Q2001\\E", "shortCiteRegEx": "Crammer and Singer", "year": 2001}, {"title": "Overview of DUC 2005", "author": ["H.T. Dang"], "venue": "Proceedings of DUC at EMNLP/HLT.", "citeRegEx": "Dang,? 2005", "shortCiteRegEx": "Dang", "year": 2005}, {"title": "Overview of DUC 2006", "author": ["H.T. Dang"], "venue": "Proceedings of DUC at NAACL/HLT.", "citeRegEx": "Dang,? 2006", "shortCiteRegEx": "Dang", "year": 2006}, {"title": "Mining the peanut gallery: opinion extraction and semantic classification of product reviews", "author": ["K. Dave", "S. Lawrence", "D.M. Pennock"], "venue": "In Proceedings of WWW,", "citeRegEx": "Dave et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Dave et al\\.", "year": 2003}, {"title": "Mining and summarizing customer reviews", "author": ["M. Hu", "B. Liu"], "venue": "In Proceedings of SIGKDD,", "citeRegEx": "Hu and Liu,? \\Q2004\\E", "shortCiteRegEx": "Hu and Liu", "year": 2004}, {"title": "CLUTO a clustering toolkit", "author": ["G. Karypis"], "venue": "Tech. rep. 02-017, Dept. of Computer Science, University of Minnesota. Available at http://www.cs.umn.edu \u0303cluto.", "citeRegEx": "Karypis,? 2002", "shortCiteRegEx": "Karypis", "year": 2002}, {"title": "Generating comparative summaries of contradictory opinions in text", "author": ["H.D. Kim", "C. Zhai"], "venue": "In Proceedings of CIKM,", "citeRegEx": "Kim and Zhai,? \\Q2009\\E", "shortCiteRegEx": "Kim and Zhai", "year": 2009}, {"title": "Automatic detection of opinion bearing words and sentences", "author": ["S. Kim", "E. Hovy"], "venue": "In Proceedings of IJCNLP,", "citeRegEx": "Kim and Hovy,? \\Q2005\\E", "shortCiteRegEx": "Kim and Hovy", "year": 2005}, {"title": "Automatic identification of pro and con reasons in online reviews", "author": ["Kim", "S.-M", "E. Hovy"], "venue": "In Proceedings of COLING ACL,", "citeRegEx": "Kim et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2006}, {"title": "Accurate unlexicalized parsing", "author": ["D. Klein", "C.D. Manning"], "venue": "In Proceedings of ACL,", "citeRegEx": "Klein and Manning,? \\Q2003\\E", "shortCiteRegEx": "Klein and Manning", "year": 2003}, {"title": "Opinion observer: Analyzing and comparing opinions on the web", "author": ["B. Liu", "M. Hu", "J. Cheng"], "venue": "In Proceedings of WWW,", "citeRegEx": "Liu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2005}, {"title": "Opinion integration through semi-supervised topic modeling", "author": ["Y. Lu", "C. Zhai"], "venue": "In Proceedings of WWW,", "citeRegEx": "Lu and Zhai,? \\Q2008\\E", "shortCiteRegEx": "Lu and Zhai", "year": 2008}, {"title": "Automatic summarization, Vol", "author": ["I. Mani"], "venue": "3. John Benjamins Pub Co.", "citeRegEx": "Mani,? 2001", "shortCiteRegEx": "Mani", "year": 2001}, {"title": "Structured models for fine-to-coarse sentiment analysis", "author": ["R. McDonald", "K. Hannan", "T. Neylon", "M. Wells", "J. Reynar"], "venue": "In Proceedings of ACL,", "citeRegEx": "McDonald et al\\.,? \\Q2007\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2007}, {"title": "Topic sentiment mixture: modeling facets and opinions in weblogs", "author": ["Q. Mei", "X. Ling", "M. Wondra", "H. Su", "C. Zhai"], "venue": "In Proceedings of WWW,", "citeRegEx": "Mei et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Mei et al\\.", "year": 2007}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["B. Pang", "L. Lee"], "venue": "In Proceedings of ACL,", "citeRegEx": "Pang and Lee,? \\Q2004\\E", "shortCiteRegEx": "Pang and Lee", "year": 2004}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee"], "venue": "Foundations and Trends in Information Retrieval,", "citeRegEx": "Pang and Lee,? \\Q2008\\E", "shortCiteRegEx": "Pang and Lee", "year": 2008}, {"title": "Thumbs up? Sentiment classification using machine learning techniques", "author": ["B. Pang", "L. Lee", "S. Vaithyanathan"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Pang et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2002}, {"title": "OPINE: Extracting product features and opinions from reviews", "author": ["Popescu", "A.-M", "B. Nguyen", "O. Etzioni"], "venue": "In Proceedings of EMNLP/HLT,", "citeRegEx": "Popescu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Popescu et al\\.", "year": 2005}, {"title": "Generating natural language summaries from multiple on-line sources", "author": ["D. Radev", "K. McKeown"], "venue": "Computational Linguistics,", "citeRegEx": "Radev and McKeown,? \\Q1998\\E", "shortCiteRegEx": "Radev and McKeown", "year": 1998}, {"title": "Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies", "author": ["D.R. Radev", "H. Jing", "M. Budzikowska"], "venue": "In Proceedings of the NAACL-ANLP Workshop on Automatic Summarization,", "citeRegEx": "Radev et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Radev et al\\.", "year": 2000}, {"title": "A maximum entropy model for part-of-speech tagging", "author": ["A. Ratnaparkhi"], "venue": "Proceedings of EMNLP, pp. 133\u2013142.", "citeRegEx": "Ratnaparkhi,? 1996", "shortCiteRegEx": "Ratnaparkhi", "year": 1996}, {"title": "Incorporating content structure into text analysis applications", "author": ["C. Sauper", "A. Haghighi", "R. Barzilay"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Sauper et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sauper et al\\.", "year": 2010}, {"title": "Content models with attitude", "author": ["C. Sauper", "A. Haghighi", "R. Barzilay"], "venue": "In Proceedings of ACL,", "citeRegEx": "Sauper et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sauper et al\\.", "year": 2011}, {"title": "Multi-document summarization with subjectivity analysis at DUC", "author": ["Y. Seki", "K. Eguchi", "N. Kanodo", "M. Aono"], "venue": "In Proceedings of DUC at EMNLP/HLT", "citeRegEx": "Seki et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Seki et al\\.", "year": 2005}, {"title": "Opinion-focused summarization and its analysis at DUC", "author": ["Y. Seki", "K. Eguchi", "N. Kanodo", "M. Aono"], "venue": "In Proceedings of DUC at NAACL/HLT,", "citeRegEx": "Seki et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Seki et al\\.", "year": 2006}, {"title": "Multiple aspect ranking using the good grief algorithm", "author": ["B. Snyder", "R. Barzilay"], "venue": "In Proceedings of NAACL/HLT,", "citeRegEx": "Snyder and Barzilay,? \\Q2007\\E", "shortCiteRegEx": "Snyder and Barzilay", "year": 2007}, {"title": "A joint model of text and aspect ratings for sentiment summarization", "author": ["I. Titov", "R. McDonald"], "venue": "In Proceedings of ACL,", "citeRegEx": "Titov and McDonald,? \\Q2008\\E", "shortCiteRegEx": "Titov and McDonald", "year": 2008}, {"title": "Modeling online reviews with multi-grain topic models", "author": ["I. Titov", "R. McDonald"], "venue": "In Proceedings of WWW,", "citeRegEx": "Titov and McDonald,? \\Q2008\\E", "shortCiteRegEx": "Titov and McDonald", "year": 2008}, {"title": "Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews", "author": ["P.D. Turney"], "venue": "Proceedings of ACL, pp. 417\u2013424.", "citeRegEx": "Turney,? 2002", "shortCiteRegEx": "Turney", "year": 2002}, {"title": "A modeltheoretic coreference scoring scheme", "author": ["M. Vilain", "J. Burger", "J. Aberdeen", "D. Connolly", "L. Hirschman"], "venue": "In Proceedings of MUC,", "citeRegEx": "Vilain et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Vilain et al\\.", "year": 1995}, {"title": "Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences", "author": ["H. Yu", "V. Hatzivassiloglou"], "venue": "In Proceedings of EMNLP, pp. 129\u2013136", "citeRegEx": "Yu and Hatzivassiloglou,? \\Q2003\\E", "shortCiteRegEx": "Yu and Hatzivassiloglou", "year": 2003}], "referenceMentions": [{"referenceID": 36, "context": "1 Single-Aspect Sentiment Analysis Early sentiment analysis focused primarily on identification of coarse document-level sentiment (Pang, Lee, & Vaithyanathan, 2002; Turney, 2002; Pang & Lee, 2008).", "startOffset": 131, "endOffset": 197}, {"referenceID": 10, "context": "Both identification of sentiment-bearing sentences and polarity analysis can be performed through supervised classifiers (Yu & Hatzivassiloglou, 2003; Dave et al., 2003) or similarity to known text (Yu & Hatzivassiloglou, 2003; Kim & Hovy, 2005), through measures based on distributional similarity or by using WordNet relationships.", "startOffset": 121, "endOffset": 169}, {"referenceID": 32, "context": "1 Single-Aspect Sentiment Analysis Early sentiment analysis focused primarily on identification of coarse document-level sentiment (Pang, Lee, & Vaithyanathan, 2002; Turney, 2002; Pang & Lee, 2008). Specifically, these approaches attempted to determine the overall polarity of documents. These approaches included both rule-based and machine learning approaches: Turney (2002) used a rule-based method to extract potentially sentiment-bearing phrases and then compared them to the sentiment of known-polarity words, while Pang et al.", "startOffset": 166, "endOffset": 377}, {"referenceID": 21, "context": "These approaches included both rule-based and machine learning approaches: Turney (2002) used a rule-based method to extract potentially sentiment-bearing phrases and then compared them to the sentiment of known-polarity words, while Pang et al. (2002) used discriminative methods with features such as unigrams, bigrams, part-of-speech tags, and word position information.", "startOffset": 234, "endOffset": 253}, {"referenceID": 10, "context": "Both identification of sentiment-bearing sentences and polarity analysis can be performed through supervised classifiers (Yu & Hatzivassiloglou, 2003; Dave et al., 2003) or similarity to known text (Yu & Hatzivassiloglou, 2003; Kim & Hovy, 2005), through measures based on distributional similarity or by using WordNet relationships. By recognizing connections between parts of a document, sentiment analysis can be further improved (Pang & Lee, 2004; McDonald, Hannan, Neylon, Wells, & Reynar, 2007; Pang & Lee, 2008). Pang and Lee (2004) leverage the relationship between sentences to improve document-level sentiment analysis.", "startOffset": 151, "endOffset": 540}, {"referenceID": 17, "context": ", heavy maps deterministically to <weight> (Liu et al., 2005).", "startOffset": 43, "endOffset": 61}, {"referenceID": 11, "context": "Hu and Liu (2004) and Liu et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 11, "context": "Hu and Liu (2004) and Liu et al. (2005) developed a three-step system: First, initial aspects are selected by an association miner and pruned by a series of rules.", "startOffset": 0, "endOffset": 40}, {"referenceID": 17, "context": "Likewise, rather than relying on WordNet relationships such as synonymy, antonymy, hyponymy, or hypernymy (Hu & Liu, 2004; Liu et al., 2005; Popescu et al., 2005), we bootstrap our model from a small set of seed words.", "startOffset": 106, "endOffset": 162}, {"referenceID": 25, "context": "Likewise, rather than relying on WordNet relationships such as synonymy, antonymy, hyponymy, or hypernymy (Hu & Liu, 2004; Liu et al., 2005; Popescu et al., 2005), we bootstrap our model from a small set of seed words.", "startOffset": 106, "endOffset": 162}, {"referenceID": 23, "context": "Popescu et al. (2005) first use these relations to generate the set of aspects for a given product class (e.", "startOffset": 0, "endOffset": 22}, {"referenceID": 19, "context": "This procedure gradually expands sentiment from individual words to aspects to sentences, similar to the Cascade pattern mentioned in the work of McDonald et al. (2007). Like the system of Liu et al.", "startOffset": 146, "endOffset": 169}, {"referenceID": 17, "context": "Like the system of Liu et al. (2005), their system requires a set of manual rules and several outside resources.", "startOffset": 19, "endOffset": 37}, {"referenceID": 17, "context": "Like the system of Liu et al. (2005), their system requires a set of manual rules and several outside resources. While our model does require a few seed words, it does not require any manual rules or additional resources due to its joint formulation. A separate direction of work relies on predefined aspects while focusing on improvement of sentiment analysis prediction. Snyder and Barzilay (2007) define a set of aspects specific to the restaurant domain.", "startOffset": 19, "endOffset": 400}, {"referenceID": 19, "context": "Multi-document summarization techniques generally look for repetition across documents to signal important information (Radev & McKeown, 1998; Barzilay, McKeown, & Elhadad, 1999; Radev, Jing, & Budzikowska, 2000; Mani, 2001).", "startOffset": 119, "endOffset": 224}, {"referenceID": 27, "context": "These aspects are then incorporated into existing summarization systems \u2013 MEAD* sentence extraction (Radev et al., 2000) or SEA natural language generation (Carenini & Moore, 2006) \u2013 to form final summaries.", "startOffset": 100, "endOffset": 120}, {"referenceID": 30, "context": "1 In their system, they employ a subjectivity component using a supervised SVM with lexical features, similar to those in the work of Yu and Hatzivassiloglou (2003) and Dave et al.", "startOffset": 134, "endOffset": 165}, {"referenceID": 8, "context": "1 In their system, they employ a subjectivity component using a supervised SVM with lexical features, similar to those in the work of Yu and Hatzivassiloglou (2003) and Dave et al. (2003). This component is used to identify subjective sentences and, in the work of Seki et al.", "startOffset": 169, "endOffset": 188}, {"referenceID": 8, "context": "1 In their system, they employ a subjectivity component using a supervised SVM with lexical features, similar to those in the work of Yu and Hatzivassiloglou (2003) and Dave et al. (2003). This component is used to identify subjective sentences and, in the work of Seki et al. (2006), their polarity, both in the task and in the sentences selected for the response summary.", "startOffset": 169, "endOffset": 284}, {"referenceID": 8, "context": "1 In their system, they employ a subjectivity component using a supervised SVM with lexical features, similar to those in the work of Yu and Hatzivassiloglou (2003) and Dave et al. (2003). This component is used to identify subjective sentences and, in the work of Seki et al. (2006), their polarity, both in the task and in the sentences selected for the response summary. However, like previous work and unlike our task, there is no aspect-based analysis in their summarization task. It is also fully supervised, relying on a hand-annotated set of about 10,000 sentences to train the SVM. Another line of work focuses on augmenting the summarization system with aspect selection similar to the data-mining approaches of Hu and Liu (2004), rather than using single-aspect analysis.", "startOffset": 169, "endOffset": 740}, {"referenceID": 8, "context": "1 In their system, they employ a subjectivity component using a supervised SVM with lexical features, similar to those in the work of Yu and Hatzivassiloglou (2003) and Dave et al. (2003). This component is used to identify subjective sentences and, in the work of Seki et al. (2006), their polarity, both in the task and in the sentences selected for the response summary. However, like previous work and unlike our task, there is no aspect-based analysis in their summarization task. It is also fully supervised, relying on a hand-annotated set of about 10,000 sentences to train the SVM. Another line of work focuses on augmenting the summarization system with aspect selection similar to the data-mining approaches of Hu and Liu (2004), rather than using single-aspect analysis. Carenini, Ng, and Zwart (2005) and Carenini et al.", "startOffset": 169, "endOffset": 814}, {"referenceID": 3, "context": "Carenini, Ng, and Zwart (2005) and Carenini et al. (2006) augment the previous aspect selection with a user-defined hierarchical organization over aspects; e.", "startOffset": 35, "endOffset": 58}, {"referenceID": 3, "context": "Carenini, Ng, and Zwart (2005) and Carenini et al. (2006) augment the previous aspect selection with a user-defined hierarchical organization over aspects; e.g., digital zoom is part of the lens. Polarity of each aspect is assumed to be given by previous work. These aspects are then incorporated into existing summarization systems \u2013 MEAD* sentence extraction (Radev et al., 2000) or SEA natural language generation (Carenini & Moore, 2006) \u2013 to form final summaries. Like the work of Seki et al. (2005, 2006), this work does not create new techniques for aspect identification or sentiment analysis; instead, they focus on the process of integrating these sources of information with summarization systems. While the aspects produced are comparable across reviews for a particular product, the highly-supervised nature means that this approach is not feasible for a large set of products such as our corpus of reviews from many types of restaurants. Instead, we must be able to dynamically identify relevant aspects. A final line of related work relies on the traditional summarization technique of identifying contrastive or contradictory sentences. Kim and Zhai (2009) focus on generating contrastive summaries by identifying pairs of sentences which express differing opinions on a particular product feature.", "startOffset": 35, "endOffset": 1173}, {"referenceID": 17, "context": "Lu and Zhai (2008) introduce a model with semi-supervised probabilistic latent semantic analysis (PLSA) which identifies sentiment-bearing aspects through segmentation of an expert review.", "startOffset": 0, "endOffset": 19}, {"referenceID": 17, "context": "Lu and Zhai (2008) introduce a model with semi-supervised probabilistic latent semantic analysis (PLSA) which identifies sentiment-bearing aspects through segmentation of an expert review. Then, the model extracts compatible supporting and supplementary text for each aspect from the set of user reviews. Aspect selection is constrained as in the rule-based approaches; specifically, aspect words are required to be nouns. Our work differs from their work significantly. While we share a common goal of identifying and aggregating opinion-bearing aspects, we additionally desire to identify the polarity of opinions, a task not addressed in their work. In addition, obtaining aspects from an expert review is unnecessarily constraining; in practice, while expert reviewers may mention some key aspects, they will not mention every aspect. It is crucial to discover aspects based on the entire set of articles. There is work in the direction of aspect identification from blog posts. For example, Mei et al. (2007) use a variation on latent Dirichlet allocation (LDA) similar to our own to explicitly model both topics and sentiment, then use a hidden Markov model to discover sentiment dynamics across topic life cycles.", "startOffset": 0, "endOffset": 1014}, {"referenceID": 1, "context": "Blei and McAuliffe (2008) propose a form of supervised LDA (sLDA) which incorporates an additional response variable, which can be used to represent sentiment such as the star rating of a movie.", "startOffset": 0, "endOffset": 26}, {"referenceID": 30, "context": "For sentiment analysis, the PRanking algorithm of Snyder and Barzilay (2007) is incorporated in two ways: First, the PRanking algorithm is trained in a pipeline fashion after all topics are generated (Titov & McDonald, 2008b); later, it is incorporated into the model during inference in a joint formulation (Titov & McDonald, 2008a).", "startOffset": 50, "endOffset": 77}, {"referenceID": 19, "context": "Mei et al. (2007) model aspect and sentiment jointly; however their aspects are very vague, and they treat sentiment at the document level rather than the aspect level.", "startOffset": 0, "endOffset": 18}, {"referenceID": 17, "context": "Finally, Lu and Zhai (2008), Blei and McAuliffe (2008), and Titov and McDonald (2008b, 2008a) require supervised annotation or a supervised expert review that we do not have.", "startOffset": 9, "endOffset": 28}, {"referenceID": 1, "context": "Finally, Lu and Zhai (2008), Blei and McAuliffe (2008), and Titov and McDonald (2008b, 2008a) require supervised annotation or a supervised expert review that we do not have.", "startOffset": 29, "endOffset": 55}, {"referenceID": 29, "context": "Our data set for this task consists of snippets selected from Yelp restaurant reviews by our previous system (Sauper et al., 2010).", "startOffset": 109, "endOffset": 130}, {"referenceID": 28, "context": "We use the MXPOST tagger (Ratnaparkhi, 1996) to gather POS tags for the data.", "startOffset": 25, "endOffset": 44}, {"referenceID": 12, "context": "Baseline We use two baselines for this task, both using a clustering algorithm weighted by TF*IDF as implemented by the publicly available CLUTO package (Karypis, 2002),5 using agglomerative clustering with the cosine similarity distance metric (Chen, Branavan, Barzilay, & Karger, 2009; Chen, Benson, Naseem, & Barzilay, 2011).", "startOffset": 153, "endOffset": 168}, {"referenceID": 28, "context": "Each snippet is POS-tagged using MXPOST (Ratnaparkhi, 1996),6 and any non-noun (i.", "startOffset": 40, "endOffset": 59}, {"referenceID": 28, "context": "As in the Yelp domain, we use the MXPOST tagger (Ratnaparkhi, 1996) to gain POS tags.", "startOffset": 48, "endOffset": 67}, {"referenceID": 12, "context": "Both baselines rely on a TF*IDFweighted clustering algorithm, specifically implemented with CLUTO package (Karypis, 2002) using agglomerative clustering with the cosine similarity distance metric.", "startOffset": 106, "endOffset": 121}], "year": 2013, "abstractText": "We present a model for aggregation of product review snippets by joint aspect identification and sentiment analysis. Our model simultaneously identifies an underlying set of ratable aspects presented in the reviews of a product (e.g., sushi and miso for a Japanese restaurant) and determines the corresponding sentiment of each aspect. This approach directly enables discovery of highly-rated or inconsistent aspects of a product. Our generative model admits an efficient variational mean-field inference algorithm. It is also easily extensible, and we describe several modifications and their effects on model structure and inference. We test our model on two tasks, joint aspect identification and sentiment analysis on a set of Yelp reviews and aspect identification alone on a set of medical summaries. We evaluate the performance of the model on aspect identification, sentiment analysis, and per-word labeling accuracy. We demonstrate that our model outperforms applicable baselines by a considerable margin, yielding up to 32% relative error reduction on aspect identification and up to 20% relative error reduction on sentiment analysis.", "creator": "TeX"}}}