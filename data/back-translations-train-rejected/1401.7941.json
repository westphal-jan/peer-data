{"id": "1401.7941", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2014", "title": "Exploiting Causality for Selective Belief Filtering in Dynamic Bayesian Networks", "abstract": "POMDPs are a useful model for decision making in systems with uncertain states. One of the core tasks in a POMDP is the monitoring task, in which the belief state (i.e. the probability distribution over system states) is updated based on incomplete and noisy observations. This can be a hard problem in complex real-world systems due to the often very large state space. In this paper, we explore the idea of accelerating the monitoring task by automatically exploiting causality in the system. We consider a specific type of causal relation, called passivity, which pertains to how system variables cause changes in other variables. We present a novel monitoring method, called Passivity-based Monitoring (PM), which maintains a factored belief state representation and exploits passivity to perform selective updates over the factored beliefs. PM produces exact belief states under certain assumptions and approximate belief states otherwise, where the approximation error is bounded by the degree of uncertainty in the process. We show empirically, in synthetic processes with varying sizes and degrees of passivity, that PM is faster than two standard monitoring methods while achieving competitive accuracy. Furthermore, we demonstrate how passivity occurs naturally in a real-world system such as a multi-robot warehouse, and how PM can exploit this to accelerate the monitoring task.", "histories": [["v1", "Thu, 30 Jan 2014 18:05:48 GMT  (623kb,D)", "https://arxiv.org/abs/1401.7941v1", "45 pages, submitted to Journal of Artificial Intelligence Research"], ["v2", "Wed, 9 Dec 2015 14:54:34 GMT  (1030kb,D)", "http://arxiv.org/abs/1401.7941v2", "43 pages, submitted to Journal of Artificial Intelligence Research (revised version)"], ["v3", "Mon, 25 Apr 2016 17:51:09 GMT  (1353kb,D)", "http://arxiv.org/abs/1401.7941v3", "44 pages; final manuscript published in Journal of Artificial Intelligence Research (JAIR)"]], "COMMENTS": "45 pages, submitted to Journal of Artificial Intelligence Research", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["stefano v albrecht", "subramanian ramamoorthy"], "accepted": false, "id": "1401.7941"}, "pdf": {"name": "1401.7941.pdf", "metadata": {"source": "META", "title": "Exploiting Causality for Selective Belief Filtering in Dynamic Bayesian Networks", "authors": ["Stefano V. Albrecht", "Subramanian Ramamoorthy"], "emails": ["svalb@cs.utexas.edu", "s.ramamoorthy@ed.ac.uk"], "sections": [{"heading": "1. Introduction", "text": "In fact, the manner in which people in the various countries of the world differ in the most varied expressions of the different expressions of the different expressions of the different expressions of the different expressions of the different expressions of the different expressions of the different expressions of the different expressions of the different expressions of the different expressions. However, in view of the possible incompleteness and the noise in the observations, it may not generally be possible to conclude with absolute certainty the state of the process. Instead, we can draw conclusions about the state of the process on the basis of the history of the observations in the form of a probability distribution over the state of the process, which is often referred to as the state of faith and the task of calculating states of faith commonly known as belief in filtering. A number of exact and safe inference methods exist for Bayesian networks (see e.g. Koller & Friedman, 2009; Pearl, 1988) that can be used for filtering in DungBN by adding them to the BN."}, {"heading": "2. Related Work", "text": "There is a comprehensive work on faith filtering in partially observed stochastic processes. In this section, we review filtering methods that use the specific structure of DBNs and classify our work into this and other related literature."}, {"heading": "2.1 Approximate Belief Filtering in DBNs", "text": "In fact, it is the case that most people who work for the rights of women and men work for the equality of men and women. (...) In fact, it is the case that the women and men who work for the equality of men and women work for the equality of men and women. (...) It is the case that women and women work for the equality of men and women. (...) It is the case that women and men and women work for the equality of men and women. (...) It is as if women and men and women work for the equality of men and women in society. \"(...) It is as if women and women live in society.\" (...) It is as if women and women live in society. \"(...) It is as if (...) society is as if (...) women live in society."}, {"heading": "2.2 Belief Filtering in Decision Processes", "text": "The methods discussed in the previous subsection may be used for faith filtering in decision-making processes, including POMDPs (Kaelbling et al., 1998; Sondik, 1971).In this respect, these methods can be regarded as \"pure\" filters, since they deal only with faith filters and not with the control of the decision-making process, in contrast to combined filter methods that permeate the filter and control tasks in decision-making processes and make specific assumptions regarding their solutions.There is a large body of literature on such combined methods, including accessibility-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), point-based methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods methods that provide optimal control."}, {"heading": "2.3 Substructure in Parameterisation", "text": "Bayesian networks, and thus DBNs, allow for a compact parameterization (i.e. specification of probabilities) and efficient inference via conditional independence relations. Furthermore, considerable work has been done in identifying substructures in parameterization in order to further simplify knowledge acquisition and improve conclusions (Koller & Friedman, 2009; Boutilier, Dean, & Hanks, 1999); other notable examples are causal independence (e.g. Heckerman & Breese, 1994; Heckerman, 1993) and context-specific independence (Boutilier, Friedman, Goldszmidt, & Koller, 1996). Causal independence is the assumption that the effects of individual causes on a common variable (i.e. the parents of these variables) are independent of each other."}, {"heading": "3. Technical Preliminaries", "text": "This section introduces the basic concepts and notations used in our work, starting with a brief discussion of the decision-making processes that constitute the context for our work, followed by a discussion of dynamic Bayesian networks as a model for drawing conclusions."}, {"heading": "3.1 Decision Processes, Belief States, Exact Updates", "text": "We consider a stochastic decision-making process in which the process is in the state of \"st\" at all times and a decision-maker, or \"agent,\" selects an action. After execution in \"st,\" the transition to the state of \"st\" + 1 \"S occurs with the probability of\" T \"at (st, st + 1) and the agent receives an observation\" t \"with the probability of\" at \"(st + 1, ot + 1). We assume that the factored representations of the state space\" S \"and the observation space\" O, \"so that S = X1...\" \u00b7 Xn and O = Y1... \"\u00b7 Ym, where the domains\" Xi, \"\" \"Yj\" finite, \"are.\" The notation \"si\" is used to denote the value of the state \"S\" and \"observation space\" O, \"so that S = X1.\" Furthermore, we assume that the process is time invariant, meaning that T \"a\" and modelled \"a\" are used to be independent of the intelligence framework of many Ps, including Dz."}, {"heading": "3.2 Dynamic Bayesian Networks", "text": "A dynamic Bayesian network (DBN) (Dean & Kanazawa, 1989) is a Bayesian network with a special temporal semantics that determines how a stochastic process transitions from one state to another. (DBN) A dynamic Bayesian network of actions is a real example of a stochastic decision process. (Specifically, they are a compact representation of the transitional function T a and observation function Oa of action a: Definition 2 (DBN). A dynamic Bayesian network of actions a: (A) is an acyclic oriented graph consisting of: \u2022 State variables Xt = {xt1} and Xt} and XT = {xt} n}."}, {"heading": "3.3 Additional Definitions", "text": "It will be useful to define: \u2022 The binary order \u2022 is defined by Xt-Xt + 1 so that xti-Xtj and xt + 1i-xt + 1j for all 1 \u2264 i < j \u2264 n and xti-xt + 1j for all 1 \u2264 i, j \u2264 n. \u2022 In view of a set of Z-Xt-Xt + 1 we type Z to denote the tuples containing all the variables of Z, ordered by x. \u2022 In view of the ordered tuples Z = (zi1,..., zi | Z |) we define the set S (Z) = Xi1 \u00d7.... \u00b7 Xi | Z | to include all the value upples for the variables in Z. \u2022 In view of a value uppel sZ = (si1,..., si | Z |) \u0445S (Z) we use the notation Z (Z) as an abbreviation for zil = sil for each zil-Z (i.e. the variables in Z assume their corresponding values from sZ)."}, {"heading": "4. Passivity", "text": "This section introduces a formal definition of passivity, which is then used as the basis for the rest of this article. We also provide a simple method for recognizing passive variables from process dynamics."}, {"heading": "4.1 Formal Definition", "text": "As outlined in section 1, a state variable xt + 1i is called passive in action a if there is a subset of xt + 1i's parents in X t (in the DBN \u2206 a), so xt + 1i can only change its value if at least one of the variables in this subset changes its value. Conversely, xt + 1i does not change if the variables in the subset do not change. Formally, we define passivity as follows: (i) Let the action a be given by a DBN \"a.\" A state variable xt + 1i is called passive if there is a series of variables in the subset, i \"pata.\""}, {"heading": "4.2 Non-Example of Passivity", "text": "What is the purpose of the proposition (i) in the definition of passivity? Finally, as discussed above, proposition (ii) depends on the basic idea of passivity, that is, that a variable can only change its value if one of the variables in relation to which it is passive changes its value. However, it may seem intuitive that proposition (ii) is sufficient for passivity, there are indeed processes in which proposition (ii) alone is not sufficient. In other words, proposition (ii) is necessary but not sufficient for passivity. We illustrate this by example 3 (non-example of passivity). Let us consider a process with two binary state variables, x2 and a single action, shown in Figure 4. (We leave the observation variables for clarity.) The dynamics of the process is such that xt + 11 takes the value of x 2 and x t + 2 the value of the trigger variable."}, {"heading": "4.3 Detecting Passive Variables", "text": "As mentioned in Section 1, passivity is a latent causal property in the sense that it can be extracted from the process dynamics without additional information and without additional assumptions regarding the representation of variable distributions. To determine whether an algorithm 1 passive (xt + 1i, \u2206 a) 1: Input: State variable + 1i, DBN \u00b2 2: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output: Output:: Output: Output: Output: Output: Output: Output: Output:: Output: Output:: Output: Output:: Output: Output:: Output: Output:: Output: Output:: Output::: Output: Output:: Output:: Output: Output:: Output::: Output:: Output: Output:: Output: Output::: Output: Output:: Output: Output:: Output: Output:: Output: Output:: Output: Output::: Output: Output::: Output: Output:: Output: Output::"}, {"heading": "5. Passivity-based Selective Belief Filtering", "text": "In this section, the passivity-based method of selective faith filtering (PSBF), which uses passivity for efficient filtering, is presented. As described in section 3, we assume that the process is specified as a set of dynamic Bayesian networks containing a DBN-a for each action. Therefore, when we refer to an action a (e.g. T a, a, Pa, paa), it is assumed that it is in the context of \u2206 a. PSBF follows the general two-step updating process, in which the state of faith is propagated first by process dynamics (transition step) and then by observation (observation step). Therefore, it is obvious to divide the exposure of PSBF into three parts: (1) the representation of the state of faith, (2) the transition step, and (3) the observation step, which are discussed in sections 5.1, 5.2, and 5.3 respectively."}, {"heading": "5.1 Belief State Representation", "text": "The idea behind PSBF is to maintain different views on different aspects of the process and to take advantage of passivity to carry out selective updates on these different views. Therefore, uniting all individual aspects is a complete description of the state of the process, while the state of belief can be presented as the product of all different beliefs on each aspect. We formally capture the informal notion of \"individual aspects\" in the form of clusters, which are defined as: Definition 4 (clusters). However, clustering Xt + 1 is a sentence C = {C1, CK} that formally fulfils the informal notion of \"individual aspects.\" Ck \"Xt + 1 and C1.\" We refer to the elements Ck + C as clusters. The underlying idea behind the concept of variables in an important sense."}, {"heading": "5.2 Exploiting Passivity in the Transition Step", "text": "It is possible that the transition phase (1) must be carried out exactly in the sense (1) of the transition phase (1). (1) However, the transition phase (1) is not in the sense (1) of the transition phase (1). (1) The transition phase (1) is not in the sense (1) of the transition phase (1). (1) The transition phase (1) is not in the sense (1) of the transition phase (1). (1) The transition phase (1) is not in the sense (1) of the transition phase (1). (2) The transition phase (1) is not in the sense (1) of the transition phase (1). (2) The second transition phase (A2) is not in the sense (1). (2) The transition phase (1) is not in the sense (1). (2) The transition phase (1) is not in the sense (1)."}, {"heading": "5.3 Efficient Incorporation of Observations", "text": "(1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (2). (1). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (3). (3). (3). (3). (2). (2). (3). (3). (2). (3). (3). (2). (3). (2). (3). (3). (3). (2). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3).). (3). (3). (3). (3). (3). (3).). (3). (3). (3).). (3). (3).). (3). (3).). (3).). (3). (3). (3).). (3).). (3). (3).). (3).). (3).). (3).). (3). (3). (3).).).). (3). (3).). (3).).). (3).). (3)."}, {"heading": "5.4 Summary of PSBF", "text": "The preceding sections can be summarized as follows: \u2022 The following sections are represented as follows: \u2022 The faith state is represented as a product of the K faith factors btk: (s) = 1 b-k (s). Each faith factor b-k is a probability distribution over the set S factors (Ck), where Ck-Xt + 1 is a cluster of correlated state variables. \u2022 Transition step: The transition step btk-b + 1k is performed with (6), for all clusters Ck that contain active variables, or for which there is a causal path from an active variable in a t. \u2022 All other clusters are skipped. \u2022 The observation step b-t-t is with (8), for all clusters Ck-C that depend on the observation variables Yt + 1."}, {"heading": "5.5 Space and Time Complexity", "text": "A faith factor bk has an element bk (sk) for each sk-S (Ck).5 Therefore, the total space required to maintain the K faith factors bk, \u2211 K = 1 | S (Ck) |. In addition, the size of the set S (Ck) grows exponentially with the number of variables in Ck, therefore the dominant growth factor in the space requirement is given by the largest cluster Ck, so the number of operations required to perform the transition and the observation steps is in O (exp maxk | Ck |), therefore the representation is feasible for relatively small clusters Ck. Likewise, the number of steps required to perform the transition and the observation steps is in the order of 2 x K = 1 | S (Ck) | in the worst case, that all variables in the CK group (i.e. all clusters must be updated in both steps)."}, {"heading": "5.6 Error Bounds", "text": "There are five possible sources of approximation errors in PSBF: \u2022 If the clusters are correlated (i.e. (A1) or (A3), they are violated (i.e. (A2) or (A4), then the approximation error can be considered an error in (8) cases where the clusters are strongly correlated and overlapped. If there is little correlation and overlap between the clusters, then the approximation error may be small. Conversely, if the clusters are strongly correlated and overlapped, then the approximation error is to be expected at the level of the correlation and overlap."}, {"heading": "6. Experimental Evaluation", "text": "We investigated PSBF in two experimental areas: In Section 6.1 we investigated PSBF in synthetic (i.e. randomly generated) processes with different sizes and passivity. In Section 6.2 we investigated PSBF in a simulation of a multi-robot storage system. A short summary of the experimental results can be found in Section 6.3."}, {"heading": "6.1 Synthetic Processes", "text": "We have initially evaluated PSBF in a number of synthetic processes; PSBF is compared with a selection of alternative methods, including PF (Gordon et al., 1993), RBPF (Doucet et et al., 2000), BK (Boyen & Koller, 1998) and FF (Murphy & Wei\u00df, 2001); see Section 2 for a discussion of these methods; the algorithms were implemented in Matlab 7.13, where we used the Matlab toolbox BNT (Murphy, 2001) to implement BK and FF."}, {"heading": "6.1.1 Specification of Synthetic Processes", "text": "We generated synthetic processes of four different quantities listed in Table 1. Each process was generated as follows: First, each variable xt + 1i is chosen to be passive with the probability of p, in which case we also add the edge (xti, x t + 1 i). We refer to p as the degree of passivity. To capture further edges from Xt / Xt + 1 to Xt + 1, we generate a mixture of Gaussians G with algorithm 4 (see Appendix C). Figure 7 shows an example of G for a process of size M. The set G is used to produce \"areas\" of correlated variables (i.e. the Gaussians), which are then natural candidates for the state cluster.Let the vector of the maximum density be in G, and let the vector of the density be in size M."}, {"heading": "6.1.2 Clustering Methods", "text": "The methods were applied to the variables in Xt + 1 with no edges in which Xt or Y t + 1 are involved: \u2022 < pc > drops the directions of the edges (i.e. for each edge xt + 1i \u2192 xt + 1j) and inserts all variables between which there is an (undirected) path into a cluster. By definition, the resulting clusters fulfill all the assumptions (A1-A4). \u2022 < moral > connects all the parents of a variable and drops the directions (it \"moralizes\" the variables) and then extracts clusters of fully connected variables (\"maximum cliques\"). The resulting clusters may not fulfill any of the assumptions (A1-A4). \u2022 < \"Cluster\" moralizes the variables as variables (it \"moralizes\" the variables) and \"separates\" the clusters of fully connected variables (\"maximum cliques\")."}, {"heading": "6.1.3 Accuracy", "text": "This year, the time has come for such a process to take place in the first half of the year, in which such a process takes place."}, {"heading": "6.1.4 Timing", "text": "We measured the time in the S, M, L, XL processes with passivity of 25%, 50%, 75%, respectively. PSBF and BK used < moral > clustering, which seemed most appropriate for a fair comparison, as it involved the calculation of exact states of belief and relative entropy, which in the S processes was only an average accuracy approximately as good as that of PSBF and BK."}, {"heading": "L (trans)", "text": "From 75% to 100% passivity with further average accelerations of 11% (S), 33% (L), 49% (S). This shows that the calculation gains can grow significantly with the degree of passivity and the size of the process."}, {"heading": "6.2 Multi-robot Warehouse System", "text": "In this section, we will show how passivity can occur naturally in a more complex system and how PSBF can take advantage of this to speed up the filter task. To this end, we will consider a Kiva-style multi-robot storage system (Wurman et al., 2008), in which the task of the robots is to transport goods within the warehouse (see Figure 10a)."}, {"heading": "6.2.1 Specification of Warehouse System", "text": "In fact, most people who are able to move and decelerate are able to move. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "6.2.2 DBN Topology and Clustering", "text": "Figure 11 shows an example DBN for a smaller warehouse with an inventory capsule and two robots. In addition, each inventory capsule I is represented by two variables, I.x and I.y, which correspond to the X and Y positions of the inventory capsule. Therefore, each robot R is represented by four variables: R.x / R.y for its x / y position, R.d for its direction and R.s for its status. The status of a robot R is either R.s = 0 (unloaded) or R.s = I (loaded with inventory capsule I). Constants such as the size of the warehouse and the positions of the workstations are omitted in the DBN. There are four types of clusters: The I clusters (C1-C4) maintain the correlation that when R is loaded with I, then I must always have the same position as R (there are two I clusters for each (I, R) pair."}, {"heading": "6.2.3 Results", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "6.3 Summary of Experimental Evaluation", "text": "The experimental results show that PSBF produces belief states with competing accuracy: In the synthetic processes, PSBF achieved an accuracy that was on average better or comparable to the accuracy of the alternative methods. In the storage system, PSBF was able to complete a statistically equivalent number of tasks compared to the other methods, indicating that its accuracy was equivalent or comparable to the accuracy of the alternative methods. Furthermore, the experimental results show that PSBF performed the faith actualizations significantly faster than the alternative methods: In the synthetic processes, PSBF, which did not use parallel processes, outperformed BK by up to 64% in the largest process (XL), while PSBF took too much time to achieve an accuracy comparable to PSBF. Specifically, the results show that the computational gains can significantly increase with both the degree of passivity and the size of the process, as the passivity of the higher degree of the passivity of the devolved one can significantly exceed the passivity of the higher degree of the passivity of the devolved system (compared to 49% of the higher degree of the passivity of the alternative method)."}, {"heading": "7. No Free Lunch for PSBF", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "8. Conclusion", "text": "Deriving from the state of a stochastic process can be a difficult technical challenge in complex systems with large state spaces. To develop efficient solutions, the key is to identify a specific structure in the process, such as the topology and parameterization of dynamic Bayesian networks that can be used to make the filter task more tractable. To this end, this article explored the idea of automatic detection and exploitation of causal structures to accelerate the filter task. We looked at a specific type of causal relationship that causes state variables to cause changes in other states. To demonstrate the potential of exploiting passivity, we developed a novel filtering method that uses a factored belief in state representation and uses passivity to perform selective updates."}, {"heading": "Acknowledgements", "text": "This article is the result of a long debate on the topic presented and benefited from a number of discussions and suggestions. In particular, the authors would like to thank anonymous reviewers from the conferences NIPS '12 and UAI' 13, as well as the Journal of AI Research, the participants of the workshop \"Advances in Causal Inference\" at UAI '15 and our colleagues at the School of Informatics at the University of Edinburgh. Furthermore, the authors acknowledge the financial support of the German National Academic Foundation, the UK Engineering and Physical Sciences Research Council (grant number EP / H012338 / 1) and the European Commission (TOMSY Grant Agreement 270436)."}, {"heading": "Appendix A. Proof of Theorem 1", "text": "To prove Theorem 1 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s s s s s s \u00b2 s s \u00b2 s \u00b2 s \u00b2 s s s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s \u00b2 s s s \u00b2 s \u00b2 s s s \u00b2 s \u00b2 s s \u00b2 s \u00b2 s) s"}, {"heading": "Appendix B. Proof of Theorem 2", "text": "To prove theorem 2, we first consider the following proposition: 1. If all xt + 1i-Ck are marginally independent of all yt + 1j-Y-t + 1-in-t, then we can provide a compact proof for theorem 2: Theorem 2. If all xt + 1i-Ck propositions are marginally independent of all yt + 1j-Y-t + 1-in-t, then we can provide a compact proof for theorem 2: Proof 2. If all xt + 1i-Ck propositions are marginally independent of all yt + 1j-y-t + 1-in-t, then applies: bt + 1k (sk) = b-t + 1k (sk). Proof."}, {"heading": "Appendix C. Mixture of Gaussians", "text": "Algorithm 4 provides a simple procedure that randomly generates a mixture of Gaussians (i.e. a series of normal distributions) for the synthetic processes in Section 6.1. The algorithm takes the number n of state variables as input and returns a set G of Gaussians whose means are in the set {1,..., n}. The number of Gaussians, their means and their deviations are automatically selected so that a good \"coverage\" of state variables is achieved while the (visual) overlap of Gaussians is minimized. See Figure 7 for an example. Algorithm 4 MixtureOfGaussians (n) 1: Input: Number of state variables n2: Parameters: \u03bb 4, \u03c3min 5: Parameter, \u03c3min 5: max. (R): n10 3: Output: Mixing of Gaussians G4: G (max."}], "references": [{"title": "Optimal control of Markov processes with incomplete state information", "author": ["K. Astrom"], "venue": "Journal of Mathematical Analysis and Applications,", "citeRegEx": "Astrom,? \\Q1965\\E", "shortCiteRegEx": "Astrom", "year": 1965}, {"title": "Decision-theoretic planning: structural assumptions and computational leverage", "author": ["C. Boutilier", "T. Dean", "S. Hanks"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Boutilier et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Boutilier et al\\.", "year": 1999}, {"title": "Context-specific independence in Bayesian networks", "author": ["C. Boutilier", "N. Friedman", "M. Goldszmidt", "D. Koller"], "venue": "In Proceedings of the 12th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Boutilier et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Boutilier et al\\.", "year": 1996}, {"title": "Tractable inference for complex stochastic processes", "author": ["X. Boyen", "D. Koller"], "venue": "In Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Boyen and Koller,? \\Q1998\\E", "shortCiteRegEx": "Boyen and Koller", "year": 1998}, {"title": "Exploiting the architecture of dynamic systems", "author": ["X. Boyen", "D. Koller"], "venue": "In Proceedings of the 16th National Conference on Artificial Intelligence,", "citeRegEx": "Boyen and Koller,? \\Q1999\\E", "shortCiteRegEx": "Boyen and Koller", "year": 1999}, {"title": "A heuristic variable grid solution method for POMDPs", "author": ["R. Brafman"], "venue": "In Proceedings of the 14th National Conference on Artificial Intelligence,", "citeRegEx": "Brafman,? \\Q1997\\E", "shortCiteRegEx": "Brafman", "year": 1997}, {"title": "Future challenges of coordinating hundreds of autonomous vehicles in distribution facilities", "author": ["R. D\u2019Andrea", "P. Wurman"], "venue": "In Proceedings of the IEEE International Conference on Technologies for Practical Robot Applications,", "citeRegEx": "D.Andrea and Wurman,? \\Q2008\\E", "shortCiteRegEx": "D.Andrea and Wurman", "year": 2008}, {"title": "A model for reasoning about persistence and causation", "author": ["T. Dean", "K. Kanazawa"], "venue": "Computational Intelligence,", "citeRegEx": "Dean and Kanazawa,? \\Q1989\\E", "shortCiteRegEx": "Dean and Kanazawa", "year": 1989}, {"title": "Market-based multirobot coordination: a survey and analysis", "author": ["M. Dias", "R. Zlot", "N. Kalra", "A. Stentz"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Dias et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dias et al\\.", "year": 2006}, {"title": "Sequential Monte Carlo Methods in Practice", "author": ["A. Doucet", "N. de Freitas", "N. Gordon"], "venue": null, "citeRegEx": "Doucet et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Doucet et al\\.", "year": 2001}, {"title": "Rao-Blackwellised particle filtering for dynamic Bayesian networks", "author": ["A. Doucet", "N. De Freitas", "K. Murphy", "S. Russell"], "venue": "In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Doucet et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Doucet et al\\.", "year": 2000}, {"title": "d-separation: from theorems to algorithms", "author": ["D. Geiger", "T. Verma", "J. Pearl"], "venue": "In Proceedings of the 5th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Geiger et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Geiger et al\\.", "year": 1989}, {"title": "Novel approach to nonlinear/non-Gaussian Bayesian state estimation", "author": ["N. Gordon", "D. Salmond", "A. Smith"], "venue": "In IEE Proceedings F (Radar and Signal Processing),", "citeRegEx": "Gordon et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 1993}, {"title": "A formal basis for the heuristic determination of minimum cost paths", "author": ["P. Hart", "N. Nilsson", "B. Raphael"], "venue": "In IEEE Transactions on Systems Science and Cybernetics,", "citeRegEx": "Hart et al\\.,? \\Q1968\\E", "shortCiteRegEx": "Hart et al\\.", "year": 1968}, {"title": "Value-function approximations for partially observable Markov decision processes", "author": ["M. Hauskrecht"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Hauskrecht,? \\Q2000\\E", "shortCiteRegEx": "Hauskrecht", "year": 2000}, {"title": "Causal independence for knowledge acquisition and inference", "author": ["D. Heckerman"], "venue": "In Proceedings of the 9th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Heckerman,? \\Q1993\\E", "shortCiteRegEx": "Heckerman", "year": 1993}, {"title": "A new look at causal independence", "author": ["D. Heckerman", "J. Breese"], "venue": "In Proceedings of the 10th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Heckerman and Breese,? \\Q1994\\E", "shortCiteRegEx": "Heckerman and Breese", "year": 1994}, {"title": "Planning and acting in partially observable stochastic domains", "author": ["L. Kaelbling", "M. Littman", "A. Cassandra"], "venue": "Artificial intelligence,", "citeRegEx": "Kaelbling et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kaelbling et al\\.", "year": 1998}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "Koller and Friedman,? \\Q2009\\E", "shortCiteRegEx": "Koller and Friedman", "year": 2009}, {"title": "On information and sufficiency", "author": ["S. Kullback", "R. Leibler"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Kullback and Leibler,? \\Q1951\\E", "shortCiteRegEx": "Kullback and Leibler", "year": 1951}, {"title": "Local computations with probabilities on graphical structures and their application to expert systems", "author": ["S. Lauritzen", "D. Spiegelhalter"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "Lauritzen and Spiegelhalter,? \\Q1988\\E", "shortCiteRegEx": "Lauritzen and Spiegelhalter", "year": 1988}, {"title": "Computationally feasible bounds for partially observed Markov decision processes", "author": ["W. Lovejoy"], "venue": "Operations Research,", "citeRegEx": "Lovejoy,? \\Q1991\\E", "shortCiteRegEx": "Lovejoy", "year": 1991}, {"title": "Causality in natural, technical, and social systems", "author": ["K. Mainzer"], "venue": "European Review,", "citeRegEx": "Mainzer,? \\Q2010\\E", "shortCiteRegEx": "Mainzer", "year": 2010}, {"title": "The Bayes net toolbox for Matlab", "author": ["K. Murphy"], "venue": "Computing Science and Statistics,", "citeRegEx": "Murphy,? \\Q2001\\E", "shortCiteRegEx": "Murphy", "year": 2001}, {"title": "The factored frontier algorithm for approximate inference in DBNs", "author": ["K. Murphy", "Y. Weiss"], "venue": "In Proceedings of the 17th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Murphy and Weiss,? \\Q2001\\E", "shortCiteRegEx": "Murphy and Weiss", "year": 2001}, {"title": "Dynamic Bayesian Networks: Representation, Inference and Learning", "author": ["K. Murphy"], "venue": "Ph.D. thesis,", "citeRegEx": "Murphy,? \\Q2002\\E", "shortCiteRegEx": "Murphy", "year": 2002}, {"title": "Factored particles for scalable monitoring", "author": ["B. Ng", "L. Peshkin", "A. Pfeffer"], "venue": "In Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Ng et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ng et al\\.", "year": 2002}, {"title": "Learning symbolic models of stochastic domains", "author": ["H. Pasula", "L. Zettlemoyer", "L. Kaelbling"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Pasula et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pasula et al\\.", "year": 2007}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Causality: Models, Reasoning, and Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q2000\\E", "shortCiteRegEx": "Pearl", "year": 2000}, {"title": "Point-based value iteration: an anytime algorithm for POMDPs", "author": ["J. Pineau", "G. Gordon", "S. Thrun"], "venue": "In Proceedings of the 18th International Joint Conference on Artificial Intelligence,", "citeRegEx": "Pineau et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Pineau et al\\.", "year": 2003}, {"title": "Exploiting contextual independence in probabilistic inference", "author": ["D. Poole", "N. Zhang"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Poole and Zhang,? \\Q2003\\E", "shortCiteRegEx": "Poole and Zhang", "year": 2003}, {"title": "Value-directed belief state approximation for POMDPs", "author": ["P. Poupart", "C. Boutilier"], "venue": "In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Poupart and Boutilier,? \\Q2000\\E", "shortCiteRegEx": "Poupart and Boutilier", "year": 2000}, {"title": "Vector-space analysis of belief-state approximation for POMDPs", "author": ["P. Poupart", "C. Boutilier"], "venue": "In Proceedings of the 17th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Poupart and Boutilier,? \\Q2001\\E", "shortCiteRegEx": "Poupart and Boutilier", "year": 2001}, {"title": "Value-directed compression of POMDPs", "author": ["P. Poupart", "C. Boutilier"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Poupart and Boutilier,? \\Q2002\\E", "shortCiteRegEx": "Poupart and Boutilier", "year": 2002}, {"title": "Finding approximate POMDP solutions through belief compression", "author": ["N. Roy", "G. Gordon", "S. Thrun"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Roy et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Roy et al\\.", "year": 2005}, {"title": "Point-based POMDP algorithms: improved analysis and implementation", "author": ["T. Smith", "R. Simmons"], "venue": "In Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Smith and Simmons,? \\Q2005\\E", "shortCiteRegEx": "Smith and Simmons", "year": 2005}, {"title": "The Optimal Control of Partially Observable Markov Processes", "author": ["E. Sondik"], "venue": "Ph.D. thesis,", "citeRegEx": "Sondik,? \\Q1971\\E", "shortCiteRegEx": "Sondik", "year": 1971}, {"title": "A generalization of noisy-or model", "author": ["S. Srinivas"], "venue": "In Proceedings of the 9th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Srinivas,? \\Q1993\\E", "shortCiteRegEx": "Srinivas", "year": 1993}, {"title": "BI-POMDP: bounded, incremental partially-observable Markovmodel planning", "author": ["R. Washington"], "venue": "In Recent Advances in AI Planning,", "citeRegEx": "Washington,? \\Q1997\\E", "shortCiteRegEx": "Washington", "year": 1997}, {"title": "No free lunch theorems for search", "author": ["D. Wolpert", "W. Macready"], "venue": "Tech. rep. SFI-TR95-02-010, Santa Fe Institute", "citeRegEx": "Wolpert and Macready,? \\Q1995\\E", "shortCiteRegEx": "Wolpert and Macready", "year": 1995}, {"title": "No free lunch theorems for optimization", "author": ["D. Wolpert", "W. Macready"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "Wolpert and Macready,? \\Q1997\\E", "shortCiteRegEx": "Wolpert and Macready", "year": 1997}, {"title": "Coordinating hundreds of cooperative, autonomous vehicles in warehouses", "author": ["P. Wurman", "R. D\u2019Andrea", "M. Mountz"], "venue": "AI Magazine,", "citeRegEx": "Wurman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wurman et al\\.", "year": 2008}, {"title": "Exploiting causal independence in Bayesian network inference", "author": ["N. Zhang", "D. Poole"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Zhang and Poole,? \\Q1996\\E", "shortCiteRegEx": "Zhang and Poole", "year": 1996}, {"title": "An improved grid-based approximation algorithm for POMDPs", "author": ["R. Zhou", "E. Hansen"], "venue": "In Proceedings of the 17th International Joint Conference on Artificial Intelligence,", "citeRegEx": "Zhou and Hansen,? \\Q2001\\E", "shortCiteRegEx": "Zhou and Hansen", "year": 2001}], "referenceMentions": [{"referenceID": 28, "context": "A number of exact and approximate inference methods exist for Bayesian networks (see, e.g., Koller & Friedman, 2009; Pearl, 1988) which can be used for filtering in DBNs, by applying them to the \u201cunrolled\u201d DBN in which the t+ 1 slice is repeated for each observed time step, or via a successive update in which the current posterior (belief state) is used", "startOffset": 80, "endOffset": 129}, {"referenceID": 37, "context": "In this article, we are interested in the application of DBNs as representations of actions in partially observed decision processes, such as POMDPs (Kaelbling, Littman, & Cassandra, 1998; Sondik, 1971) and their many variants.", "startOffset": 149, "endOffset": 202}, {"referenceID": 29, "context": "In many cases, decision processes exhibit high degrees of causal structure (Pearl, 2000), by which we mean that a change in one part of the process may cause a change in another part.", "startOffset": 75, "endOffset": 88}, {"referenceID": 22, "context": "It is worth pointing out that passivity occurs naturally and frequently in many planning domains, especially in robotic and other physical systems (Mainzer, 2010).", "startOffset": 147, "endOffset": 162}, {"referenceID": 28, "context": "The authors show that their method is equivalent to a single iteration of loopy belief propagation (LBP) (Pearl, 1988).", "startOffset": 105, "endOffset": 118}, {"referenceID": 21, "context": "Murphy and Weiss (2001) propose a filtering method called factored frontier (FF).", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "Therefore, the analysis of approximation errors by Boyen and Koller (1998) also applies to PSBF, as we show in Section 5 as well as in our experiments.", "startOffset": 51, "endOffset": 75}, {"referenceID": 17, "context": "The methods discussed in the preceding subsection can be used for belief filtering in decision processes, including POMDPs (Kaelbling et al., 1998; Sondik, 1971).", "startOffset": 123, "endOffset": 161}, {"referenceID": 37, "context": "The methods discussed in the preceding subsection can be used for belief filtering in decision processes, including POMDPs (Kaelbling et al., 1998; Sondik, 1971).", "startOffset": 123, "endOffset": 161}, {"referenceID": 14, "context": "combined methods, including reachability-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), pointbased methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods (Roy, Gordon, & Thrun, 2005; Poupart & Boutilier, 2002).", "startOffset": 55, "endOffset": 91}, {"referenceID": 39, "context": "combined methods, including reachability-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), pointbased methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods (Roy, Gordon, & Thrun, 2005; Poupart & Boutilier, 2002).", "startOffset": 55, "endOffset": 91}, {"referenceID": 5, "context": "combined methods, including reachability-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), pointbased methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods (Roy, Gordon, & Thrun, 2005; Poupart & Boutilier, 2002).", "startOffset": 112, "endOffset": 163}, {"referenceID": 21, "context": "combined methods, including reachability-based methods (Hauskrecht, 2000; Washington, 1997), grid-based methods (Zhou & Hansen, 2001; Brafman, 1997; Lovejoy, 1991), pointbased methods (Smith & Simmons, 2005; Pineau, Gordon, & Thrun, 2003), and compression methods (Roy, Gordon, & Thrun, 2005; Poupart & Boutilier, 2002).", "startOffset": 112, "endOffset": 163}, {"referenceID": 15, "context": "Other notable examples include causal independence (e.g. Heckerman & Breese, 1994; Heckerman, 1993) and context-specific independence (Boutilier, Friedman, Goldszmidt, & Koller, 1996).", "startOffset": 51, "endOffset": 99}, {"referenceID": 38, "context": "This allows for a compact parameterisation via operators such as \u201cnoisy-or\u201d (Srinivas, 1993; Pearl, 1988), and it can be used to enhance inference (Zhang & Poole, 1996).", "startOffset": 76, "endOffset": 105}, {"referenceID": 28, "context": "This allows for a compact parameterisation via operators such as \u201cnoisy-or\u201d (Srinivas, 1993; Pearl, 1988), and it can be used to enhance inference (Zhang & Poole, 1996).", "startOffset": 76, "endOffset": 105}, {"referenceID": 2, "context": "This can allow for a further reduction of parameters (Boutilier et al., 1996)", "startOffset": 53, "endOffset": 77}, {"referenceID": 17, "context": "This framework is compatible with many decision models used in the artificial intelligence literature, including POMDPs (Kaelbling et al., 1998; Sondik, 1971) and its many variants.", "startOffset": 120, "endOffset": 158}, {"referenceID": 37, "context": "This framework is compatible with many decision models used in the artificial intelligence literature, including POMDPs (Kaelbling et al., 1998; Sondik, 1971) and its many variants.", "startOffset": 120, "endOffset": 158}, {"referenceID": 2, "context": "3, passivity can be shown to be a special kind of context-specific independence (CSI) (Boutilier et al., 1996) applied to DBNs.", "startOffset": 86, "endOffset": 110}, {"referenceID": 29, "context": "Despite satisfying clause (ii), the state variables x 1 and x t+1 2 from Example 3 are in fact not passive, for the following two reasons: Firstly, passivity is a causal relation and as such it must imply a causal order (Pearl, 2000).", "startOffset": 220, "endOffset": 233}, {"referenceID": 11, "context": "However, it is clear that if the variables in a cluster Ck are marginally independent of the observation variables Y t+1 (this can be determined using d-separation (Geiger et al., 1989), or simply by checking if there is a directed path from Ck to Y t+1), then there is no need to perform the observation step for the corresponding belief factor bk.", "startOffset": 164, "endOffset": 185}, {"referenceID": 3, "context": "Boyen and Koller (1998) provide a useful analysis of the error bound of any filtering method which uses a factored belief state representation.", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "Similar to Boyen and Koller (1998), we define the approximation error incurred by PSBF relative to the exact belief state.", "startOffset": 11, "endOffset": 35}, {"referenceID": 3, "context": "Finally, the main result in the work of Boyen and Koller (1998), here restated in the context of our work in Theorem 3, essentially states that the approximation error of PSBF (measured in terms of relative entropy) is bounded by the mixing rates of the process:", "startOffset": 40, "endOffset": 64}, {"referenceID": 12, "context": "PSBF is compared with a selection of alternative methods, including PF (Gordon et al., 1993), RBPF (Doucet et al.", "startOffset": 71, "endOffset": 92}, {"referenceID": 10, "context": ", 1993), RBPF (Doucet et al., 2000), BK (Boyen & Koller, 1998), and FF (Murphy & Weiss, 2001); see Section 2 for a discussion of these methods.", "startOffset": 14, "endOffset": 35}, {"referenceID": 23, "context": "13, where we used the Matlab toolbox BNT (Murphy, 2001) to implement BK and FF.", "startOffset": 41, "endOffset": 55}, {"referenceID": 10, "context": "It is an open question how to group state variables into \u201csampled\u201d and \u201cexact\u201d variables (Doucet et al., 2000).", "startOffset": 89, "endOffset": 110}, {"referenceID": 42, "context": "To this end, we consider a multi-robot warehouse system in the style of Kiva (Wurman et al., 2008), in which the robots\u2019 task is to transport goods within the warehouse (cf.", "startOffset": 77, "endOffset": 98}, {"referenceID": 29, "context": "Such systems typically exhibit a number of features: First of all, robotic systems usually have some causal structure (e.g. Mainzer, 2010; Pearl, 2000).", "startOffset": 118, "endOffset": 151}], "year": 2016, "abstractText": "Dynamic Bayesian networks (DBNs) are a general model for stochastic processes with partially observed states. Belief filtering in DBNs is the task of inferring the belief state (i.e. the probability distribution over process states) based on incomplete and noisy observations. This can be a hard problem in complex processes with large state spaces. In this article, we explore the idea of accelerating the filtering task by automatically exploiting causality in the process. We consider a specific type of causal relation, called passivity, which pertains to how state variables cause changes in other variables. We present the Passivity-based Selective Belief Filtering (PSBF) method, which maintains a factored belief representation and exploits passivity to perform selective updates over the belief factors. PSBF produces exact belief states under certain assumptions and approximate belief states otherwise, where the approximation error is bounded by the degree of uncertainty in the process. We show empirically, in synthetic processes with varying sizes and degrees of passivity, that PSBF is faster than several alternative methods while achieving competitive accuracy. Furthermore, we demonstrate how passivity occurs naturally in a complex system such as a multi-robot warehouse, and how PSBF can exploit this to accelerate the filtering task.", "creator": "LaTeX with hyperref package"}}}