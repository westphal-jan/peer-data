{"id": "1402.0452", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Feb-2014", "title": "A Lower Bound for the Variance of Estimators for Nakagami m Distribution", "abstract": "Recently, we have proposed a maximum likelihood iterative algorithm for estimation of the parameters of the Nakagami-m distribution. This technique performs better than state of art estimation techniques for this distribution. This could be of particular use in low data or block based estimation problems. In these scenarios, the estimator should be able to give accurate estimates in the mean square sense with less amounts of data. Also, the estimates should improve with the increase in number of blocks received. In this paper, we see through our simulations, that our proposal is well designed for such requirements. Further, it is well known in the literature that an efficient estimator does not exist for Nakagami-m distribution. In this paper, we derive a theoretical expression for the variance of our proposed estimator. We find that this expression clearly fits the experimental curve for the variance of the proposed estimator. This expression is pretty close to the cramer-rao lower bound(CRLB).", "histories": [["v1", "Mon, 3 Feb 2014 18:20:46 GMT  (135kb)", "http://arxiv.org/abs/1402.0452v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["rangeet mitra", "amit kumar mishra", "tarun choubisa"], "accepted": false, "id": "1402.0452"}, "pdf": {"name": "1402.0452.pdf", "metadata": {"source": "CRF", "title": "A Lower Bound for the Variance of Estimators for Nakagami-m Distribution", "authors": ["Rangeet Mitra", "Amit Kumar Mishra", "Tarun Choubisa"], "emails": ["mitra.rangeet@gmail.com", "amit.india@gmail.com", "choubisa.tarun@gmail.com"], "sections": [{"heading": null, "text": "The problem with estimators is that it requires a large number of samples to assess the distribution of the Nakagami-m. Thus, it is a multi-layered distribution that is used to model a variety of physical phenomena in communication technology. An algorithm for estimating the parameters of the Nakagami-m distribution was recently proposed in [1]. However, many basic papers such as [2] have also addressed this issue. The types of estimators proposed in the literature can be catagorized into two types: a) moment-based distribution [3] - [2] maximum algebraic probability [9] methods. In [9], the authors examined many existing parameter estimators for the Nakagami-m distribution, which belongs to both of the above categories of estimators."}, {"heading": "III. SIMULATION CONDITIONS", "text": "In this section we give a description of our simulation, which is designed to compare our algorithm with the state of the art. At one time, we get a limited parallel data block. The (\"competing\") algorithms used must infer from a subset of such limited data blocks. A desirable feature of an estimation algorithm in such a case is the increased learning ability with the number of blocks it sees (apart from less Mean Squared Error (MSE)). Furthermore, under such limited data conditions, we can gladly use a moving average estimator (which is the simplest and most recursive approach to smoothing) to smooth the estimates. However, if the algorithm used has errors from factors such as truncation of the Taylor's series, these errors will continue from block to block. This intuition is captured by our algorithm (which is the simplest and most recursive approach to smoothing) to smooth the estimates. Our numerical algorithm is never based on multiple blocks, and therefore it is unlikely to have a stimulus capability."}, {"heading": "A. Heuristics Considered", "text": "Since the iterative equations given in [1] are not convex, they may be susceptible to local minima. Therefore, we need to run the algorithms several times and set central measurements (mean / median / mode) of the obtained values. To help all estimators learn better (and also facilitate comparison with equal conditions), the estimated values obtained by all the techniques considered in the next section are averaged over the blocks by the known recursive filter (i.e. the recursively calculated mean of the sample)."}, {"heading": "IV. COMPARISON OF ALL THE ESTIMATORS", "text": "Figure 1 shows that our estimator learns from the number of blocks he sees, i.e. his performance is between the CRLB of the individual block and that of the whole block. Also, his performance is better than the estimators proposed in [2] (based on first and second order Taylor approximations) and corresponds to the moment-based estimator in most m-regimes. Therefore, our algorithm has sufficient credibility in scenarios where block data processing is common such as Orthogonal Frequency Division Multiplexing (OFDM) and the data is limited. For completeness, the normalized variance diagrams are also in Figure 2. In Figures 3 and 4, we compare the performance of all estimators in setting 20X7 block size (i.e. in relation to Sec. III, the ith block is size 20 and N = 7)."}, {"heading": "V. A POSSIBLE PRACTICAL APPLICATION", "text": "Take the case of Orthogonal Frequency Division Multiplexing (OFDM): After the FFT on the receiver, we get a block of data that is converted to serial form via a parallel-to-serial converter (P / S). If the number of points obtained in each conversion is lower, the state-of-the-art variance of the estimators increases (apart from the errors mentioned above due to algebraic approximations as in [2]). In such cases, we have to use an algorithm that a) is exactly b) iterative (for robustness and tracking of stationary). In addition, one of the secondary goals of our algorithm is to omit the role of the P / S converter before estimating the parameters for detection."}, {"heading": "VI. CONCLUSION", "text": "In this paper, we found that our proposed algorithm performs better than some of the popular estimators. We give a theoretical expression for the variance of our estimator in Appendix A. We see that the variance of our estimates obtained through simulations is very close to the theoretical expression."}, {"heading": "VII. REVIEW OF HIDDEN MARKOV RANDOM FIELDS(HMRF) AS APPLIED TO IMAGE SEGMENTATION", "text": "In essence, the image segmentation algorithm in [10] has the following assumptions: Let us derive the number of image pixels and the number of labels that are similarly initialized by k-mean algorithm in [10] and later derived by (expectation maximization) EM algorithms. Then, for a specific set of similarly initialized x, p (y), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x), x (x, x, x, x (x), x (x, x, x, x, x, x, x, x (x), x (x), x (x), x (x, x, x, x, x (x), x, x (x), x (x), x (x, x, x, x (x), x (x), x (x, x, x (x), x (x, x, x (x), x (x), x (x, x, x, x (x), x (x, x), x (x (x), x (x), x (x, x (x), x (x, x, x, x, x), x (x (x), x (x, x), x (x (x), x (x), x (x (x), x (x (x), x (x, x), x (x, x (x, x, x), x (x (x), x (x (x), x (x, x), x (x (x, x, x, x, x), x (x (x), x (x, x), x, x (x), x (x (x, x, x, x, x, x), x (x (x, x), x (x, x, x), x (x, x, x"}, {"heading": "IX. SEGMENTATION RESULTS", "text": "A 600X338 RGB image was taken and deliberately scaled down to 30X30 to see performance comparisons in limited data, then blurred by a 3X3 Gaussian blur. After segmentation, the image is scaled to 160X120 to make it easier to see. Gaussian-based HMRF and Nakagami-m HMRF performance are compared. We can see from Figure 5 (a) that the top of the tower is truncated in the process of segmentation. Figure 5 (b) shows the original (enlarged) image, but the entire tower is maintained in 5 (c) even after Nakagami-m segmentation. \u2212 We can also see a better segment result in the case of the \"Charminar\" image. 5 (d), 5 (e), 5 (f).APPENDIXWe know that the protocol (m) has a logging function."}], "references": [{"title": "Maximum likelihood estimate of parameters of nakagami-m distribution", "author": ["R. Mitra", "A. Mishra", "T. Choubisa"], "venue": "Communications, Devices and Intelligent Systems (CODIS), 2012 International Conference on, 2012, pp. 9\u201312.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Maximum-Likelihood Based Estimation of the Nakagami m Parameter", "author": ["J. Cheng", "S. Member", "N.C. Beaulieu"], "venue": "vol. 5, no. 3, pp. 101\u2013103, 2001.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Generalized moment estimators for the Nakagami fading parameter", "author": ["J. Cheng", "N. Beaulieu"], "venue": "IEEE Communications Letters, vol. 6, no. 4, pp. 144\u2013146, Apr. 2002. [Online]. Available: http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=996038", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Novel Nakagami- m Parameter Estimator for Noisy Channel Samples", "author": ["Y. Chen", "S. Member", "N.C. Beaulieu"], "venue": "vol. 9, no. 5, pp. 417\u2013419, 2005.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "Estimation of Nakagami-m Fading Channel Parameters With Application to Optimized Transmitter Diversity Systems", "author": ["Y.-C. Ko", "M.-S. Alouini"], "venue": "vol. 2, no. 2, pp. 250\u2013259, 2003.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Estimators Using Noisy Channel Samples for Fading Distribution Parameters", "author": ["Y. Chen", "S. Member", "N.C. Beaulieu"], "venue": "vol. 53, no. 8, pp. 1274\u20131277, 2005.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Estimation of Nakagami Distribution Parameters Based on Signal Samples Corrupted with Multiplicative and Additive Disturbances", "author": ["H. Nasuf"], "venue": "vol. 2, no. September, pp. 12\u201314, 2007.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Generalized Method of Moments Estimation of the Nakagami- m Fading Parameter", "author": ["N. Wang", "S. Member", "X. Song", "S. Member", "J. Cheng"], "venue": "vol. 11, no. 9, pp. 3316\u20133325, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "A Note on the Estimation of Nakagami-m Fading Parameter", "author": ["Q.T. Zhang", "S. Member"], "venue": "vol. 6, no. 6, pp. 237\u2013238, 2002.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Hmrf-em-image: Implementation of the hidden markov random field model and its expectation-maximization algorithm", "author": ["Q. Wang"], "venue": "CoRR, vol. abs/1207.3510, 2012.  (a) Performance of Gaussian likelihood based Segmentation (b) Original Image (c) Performance of Nakagami-m likelihood based Segmentation  (d) Performance of Gaussian likelihood based Segmentation (e) Original Image (f) Performance of Nakagami-m likelihood based Segmentation Fig. 5.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "An algorithm for estimation of the parameters of Nakagami-m distribution has been recently proposed in [1].", "startOffset": 103, "endOffset": 106}, {"referenceID": 1, "context": "However many seminal papers like [2] have adressed this topic as well.", "startOffset": 33, "endOffset": 36}, {"referenceID": 2, "context": "The types of estimators proposed in the literature can be catagorised into two types: a)moment-based [3]\u2013[8] b) algebraic maximal likelihood [2], [9] methods.", "startOffset": 101, "endOffset": 104}, {"referenceID": 7, "context": "The types of estimators proposed in the literature can be catagorised into two types: a)moment-based [3]\u2013[8] b) algebraic maximal likelihood [2], [9] methods.", "startOffset": 105, "endOffset": 108}, {"referenceID": 1, "context": "The types of estimators proposed in the literature can be catagorised into two types: a)moment-based [3]\u2013[8] b) algebraic maximal likelihood [2], [9] methods.", "startOffset": 141, "endOffset": 144}, {"referenceID": 8, "context": "The types of estimators proposed in the literature can be catagorised into two types: a)moment-based [3]\u2013[8] b) algebraic maximal likelihood [2], [9] methods.", "startOffset": 146, "endOffset": 149}, {"referenceID": 8, "context": "In [9] the authors have studied many preexisting parameter estimators for the Nakagami-m distribution which belonged to both of the above mentioned category of estimators.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "An interesting work, [9], concludes that none of the many estimators discussed in it gives better performance than the Greenwood and Durand estimator [9] (which will be one of the many algorithms against which we will compare our approach in this paper).", "startOffset": 21, "endOffset": 24}, {"referenceID": 8, "context": "An interesting work, [9], concludes that none of the many estimators discussed in it gives better performance than the Greenwood and Durand estimator [9] (which will be one of the many algorithms against which we will compare our approach in this paper).", "startOffset": 150, "endOffset": 153}, {"referenceID": 3, "context": "Also, [4], [6] deal with parameter estimation of noisy Nakagami-m signals.", "startOffset": 6, "endOffset": 9}, {"referenceID": 5, "context": "Also, [4], [6] deal with parameter estimation of noisy Nakagami-m signals.", "startOffset": 11, "endOffset": 14}, {"referenceID": 0, "context": "The suitability of our approach in [1] against these previously existing algorithms has not been tested.", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "a) It performs better than other estimators with low amounts of data in highly testing scenarios; and, b) as it is an online algorithm which considers one sample at a time the parameter \u2206 in [2] is zero.", "startOffset": 191, "endOffset": 194}, {"referenceID": 0, "context": "Details of the derivation are provided in [1].", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "As the iterative equations given in [1] are non-convex, they may be susceptible to local minima.", "startOffset": 36, "endOffset": 39}, {"referenceID": 1, "context": "Also its performance is better than the estimators proposed in [2] (which were based on first order and second order Taylor approximations).", "startOffset": 63, "endOffset": 66}, {"referenceID": 8, "context": "Also its performance is better than the Greenwood and Durand estimators given in [9](which were the most superior in that paper) and equivalent to the moment based estimator in most of the m regimes.", "startOffset": 81, "endOffset": 84}, {"referenceID": 1, "context": "When the number of points obtained in each conversion is less, the variance of state of art estimators increases (apart from the pre-mentioned errors stemming from algebraic approximations as in [2]).", "startOffset": 195, "endOffset": 198}, {"referenceID": 9, "context": "REVIEW OF HIDDEN MARKOV RANDOM FIELDS(HMRF) AS APPLIED TO IMAGE SEGMENTATION Basically in the project in [10], the image segmentation algorithm has the following assumptions: Let y be the set of image pixels and x be the set of labels which are initialized similarly by k-means algorithm and are later inferred again by (Expectation-Maximization) EM algorithm.", "startOffset": 105, "endOffset": 109}, {"referenceID": 9, "context": "xa and xb are two neighboring pixels connected by a Markov graph as in [10] forming a clique.", "startOffset": 71, "endOffset": 75}, {"referenceID": 0, "context": "This situation occurs iff the equations in [1] are exactly solved.", "startOffset": 43, "endOffset": 46}], "year": 2014, "abstractText": "Recently we have proposed a maximum-likelihood iterative algorithm for estimation of parameters of the Nakagamim distribution. This technique performs better than state of art estimation techniques for this distribution. This could be of particular use in low-data/block based estimation problems. In these scenarios, the estimator should be able to give accurate estimates (in the mean square sense) with less amount of data. Also, the estimates should improve with increase in number of blocks received. In this paper, we see through our simulations, that our proposal is well designed for meeting such requirements. Further, it is well known in the literature that an efficient estimator does not exist for the Nakagami-m distribution. In this paper, we also derive a theoretical expression for the variance of our proposed estimator. We find that this expression clearly fits the experimental curve for the variance of the proposed estimator. This expression is pretty close to the Cramer Rao Lower Bound (CRLB).", "creator": "LaTeX with hyperref package"}}}