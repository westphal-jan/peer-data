{"id": "1402.0556", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2014", "title": "Generating Extractive Summaries of Scientific Paradigms", "abstract": "Researchers and scientists increasingly find themselves in the position of having to quickly understand large amounts of technical material. Our goal is to effectively serve this need by using bibliometric text mining and summarization techniques to generate summaries of scientific literature. We show how we can use citations to produce automatically generated, readily consumable, technical extractive summaries. We first propose C-LexRank, a model for summarizing single scientific articles based on citations, which employs community detection and extracts salient information-rich sentences. Next, we further extend our experiments to summarize a set of papers, which cover the same scientific topic. We generate extractive summaries of a set of Question Answering (QA) and Dependency Parsing (DP) papers, their abstracts, and their citation sentences and show that citations have unique information amenable to creating a summary.", "histories": [["v1", "Tue, 4 Feb 2014 01:33:10 GMT  (637kb)", "http://arxiv.org/abs/1402.0556v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["vahed qazvinian", "dragomir r radev", "saif m mohammad", "bonnie dorr", "david zajic", "michael whidby", "taesun moon"], "accepted": false, "id": "1402.0556"}, "pdf": {"name": "1402.0556.pdf", "metadata": {"source": "CRF", "title": "Generating Extractive Summaries of Scientific Paradigms", "authors": ["Vahed Qazvinian", "Dragomir R. Radev", "Saif M. Mohammad", "Bonnie Dorr", "David Zajic", "Michael Whidby", "Taesun Moon"], "emails": ["vahed@umich.edu", "radev@umich.edu", "saif.mohammad@nrc-cnrc.gc.ca", "bonnie@umiacs.umd.edu", "dmzajic@umiacs.umd.edu", "mawhidby@umd.edu", "tsmoon@umiacs.umd.edu"], "sections": [{"heading": "1. Introduction", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "1.1 Background", "text": "Automatically generating extractive technical summaries differs significantly from traditional multi-document summaries. Below, we describe the primary characteristics of an extractive technical summary and present different types of input texts that we have used to create extractive technical summaries."}, {"heading": "1.1.1 Technical Extractive Summaries", "text": "In the case of multi-document summaries, the goal is to produce a readable representation of multiple documents, while in the case of technical summaries, the goal is to convey the most important characteristics and basic fundamentals of a particular field, early and late developments, important contributions and results, conflicting positions that can reverse trends or start new sub-areas, and basic definitions and examples that allow a quick understanding of a field by non-experts. A prototype example of a technical summary is that of \"chapter notes,\" i.e., short (50-500 words) descriptions of sub-areas found at the end of chapters of textbooks, such as Jurafsky and Martin (2008). One could imagine producing such descriptions automatically and refining them for use in an actual textbook."}, {"heading": "1.1.2 Scholarly Texts", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want. If they are able to move, this is not the case."}, {"heading": "2. Related Work", "text": "In this section, we review related previous work in two categories: First, we review previous research on citation analysis, and second, we discuss previous work on capturing diversity in automatic summaries of texts."}, {"heading": "2.1 Citation Analysis", "text": "In fact, the majority of them will be able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "2.2 Leveraging Diversity in Summarization", "text": "This year, it has come to the point that it will only be a matter of time before it is ready, until it is ready."}, {"heading": "3. Citation-Based Summarization", "text": "The ACL Anthology Network3 (AAN) is a manually curated resource built on top of the ACL Anthology4 (Bird, Dale, Dorr, Gibson, Joseph, Kan, Lee, Powley, Radev, & Tan, 2008).AAN includes all work published by ACL and related organizations, as well as the Computational Linguistics Journal over a four-decade period, and includes other valuable metadata such as author affiliations, citation and collaboration networks, and various centralization measures (Radev, Muthukrishnan, & Qazvinian, 2009; Joseph & Radev, 2007)."}, {"heading": "3.1 Citation Analysis", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...)"}, {"heading": "3.2 C-LexRank", "text": "In this section, we describe C-LexRank as a method of extracting sentences that cover a variety of factoids. Our method works by modelling the set of quotations as a network of sentences and identifying sentence communities that cover similar factoids. Once a good division of sentences is done, we extract distinctive sentences from different communities. Figure 1 illustrates a representative example that illustrates the process of C-LexRank."}, {"heading": "3.2.1 Citation Summary Network", "text": "In the first step (as shown in Figure 1 (a)), we model the sentences that cite a particular paper with a network in which vertices represent quoting sentences, and undirected weighted edges show the degree of semantic affinity between vertices, which is usually quantified by a measure of similarity. We call this network the Citation Summary Network of an article. Ideally, the similarity function should assign high values to sentence pairs that have the same factoids, and assign low values to sentences that talk about different contributions of the target paper. Previously, Qazvinian and Radev (2008) investigated 7 different similarity measurements, including TF-IDF with different IDF databases, longest common sub-sequence, generation probability (Erkan, 2006), and the Levenstein distance on a training set of quotations. They showed that the cosmic similarity that TF-IDF vectors use has higher similarities to pairs that contain the same factoid."}, {"heading": "3.2.2 Community Structure", "text": "In the second phase of our work, we try to determine the size of the communities in which we find ourselves."}, {"heading": "3.2.3 Ranking", "text": "The third step of the ranking is in Figure 1 (c) mentioning that the sentences mentioned in the sequence of rankings in the sequence of rankings in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of absence in the rule of"}, {"heading": "4. Other Methods", "text": "In our experiments in Section 5, we compare C-LexRank with a number of other summation systems. We compare C-LexRank with a random summary to find a lower limit on pyramid values in our experiments. We use LexRank and C-RR as two variants of CLexRank to investigate the usefulness of community recognition and selection of prominent vertices in C-LexRank. We evaluate DivRank as a modern graph-based summation system that uses diversity as well as MMR as a widely used diversity-based summation system. Finally, we use Multiple Alternate Sentence Compression Summarizer (MASCS) as a system that not only relies on extraction, but creates a list of candidates by applying predefined sentence compression rules."}, {"heading": "4.1 Random", "text": "This method simply selects quotations in random order. Since a quoting sentence may not contain information about the work cited (as in the last sentence in Table 2), randomization has the disadvantage of selecting quotations that do not contain valuable information. Furthermore, the random selection process is more prone to redundant summaries, since sentences that deal with the same factoid can be selected."}, {"heading": "4.2 LexRank", "text": "One of the systems with which we compare C-LexRank is LexRank (Erkan & Radev, 2004).It works by first creating a graph of all documents (di) in a cluster.The edges between the corresponding vertices (di) represent the cosinal similarity between them if the cosinal value is above a threshold (0.10 according to Erkan & Radev, 2004).Once the network is established, the system finds the most central sentences by performing a random jump on the graph. p (dj) = (1 \u2212 \u03bb) 1 | D | + \u03bb di (di) P (di \u2192 dj) (10) Equation 10 shows that the probability that the random change would visit dj depends on a random jump element, as well as on the probability that the random walk will visit each of its neighbors (di), times the transition probability between di and dj, P (di \u2192 dj).The comparison of C-LexRank summaries is as we can derive from lexRank summaries that are different from lexRank summaries."}, {"heading": "4.3 MMR", "text": "Maximum Marginal Relevance (MMR) is proposed by Carbonell and Goldstein (1998) and is a widely used algorithm for generating summaries that reflect the diversity of perspectives in the source documents (Das & Martins, 2007). MMR uses the pair cosinal similarity matrix and greedily selects sentences that are least similar to those already contained in the summary, in particular MMR = argminDi, D \u2212 A [max Dj, A Sim (Tue, Dj)] (11), where A is the set of documents in the summary, initialized to A = \u2205. In Equation 11, a sentence Di that is not in Summary A is chosen so that its closest similarity to summary sentences maxDj, A Sim (Tue, Dj) is minimal among all the unselected sentences."}, {"heading": "4.4 DivRank", "text": "We compare C-LexRank to a state-of-the-art graph-based summary system that uses diversity, DivRank. DivRank is based on the calculation of the stationary distribution of vertices using a modified random walk model. Unlike other time-homogeneous random walks (e.g. PageRank), DivRank does not assume that the transition probability from one vertice to another will remain constant over time.DivRank uses a vertex-reinforced random walk model to evaluate vertices based on diversity-based centrality.The basic assumption in DivRank is that the transition probability from one vertice to another is amplified by the number of previous visits to the target vertice (Mei et al., 2010).In particular, let us assume that pT (u, v) is the transition probability from one vertice to another, is probable from a point to a transition point to a probability."}, {"heading": "4.5 MASCS", "text": "The last summing system we use as a starting point is Multiple Alternate Sentence Compression Summarizer (MASCS) (Zajic, Dorr, Lin, & Schwartz, 2007). Similar to previous base systems, the goal of MASCS is to leverage diversity in the summary. MASCS performs pre-processing of sentences that convert them into new sentences, thereby extending the pool of candidates available for inclusion in a summary beyond the sentences that occur in source documents, making MASCS somewhat non-extractive. Furthermore, the pre-processing used in MASCS for these experiments has been specifically adapted to the genre of citations from scientific papers (Whidby, 2012). MASCS is a summing system that uses trimmers (Zajic et al., 2007) compression candidates for compression."}, {"heading": "5. Experiments", "text": "We used the 30 sets of quotations listed in Table 1 and used C-LexRank to create two extractive summaries of varying lengths (100 and 200 words) for each sentence. In addition to C-LexRank and C-RR, we conducted the same experiments with the basic methods described in Section 4, most of which aim to exploit diversity in the summary."}, {"heading": "5.1 Evaluation", "text": "To evaluate our system, we use the pyramid evaluation method (Nenkova & Passonneau, 2004).Each factoid in the citations to a paper corresponds to a unit of summary content (SCU) in (Nenkova & Passonneau, 2004).The value given by the pyramid method for a summary is the ratio of the sum of the weights of its factoids to the sum of the weights of an optimal summary.This value ranges from 0 to 1, and high values indicate that the summary content contains more weighted factoids.If a factoid appears in more citations than another factoid, it is more important and should therefore be assigned a higher weight.To weigh the factoids, we build a pyramid, and each factoid falls into a series. Each level indicates the number of sentences that a factoid appears in the pyramid."}, {"heading": "5.2 Results and Discussion", "text": "Table 6 shows the average pyramid value of summaries produced using different methods of varying lengths. Longer summaries result in higher pyramid values because the amount of information they cover is greater than shorter summaries. For the random sentence extraction base, we repeat the experiment with 100 different randomly generated seed values and give the average pyramid value of these summaries in Table 6. This table shows that C-LexRank outperforms all other methods that use diversity, as well as random summaries and LexRank. Results in this table also suggest that the use of LexRank within each cluster is critical for selecting outstanding citations, as the average pyramid values of C-RR, where sentences are selected in order, are lower."}, {"heading": "5.2.1 Effect of Community Detection", "text": "The modularity-based clustering method described in Section 3.2.2, which works by maximizing modularity in a cluster, will always produce at least 2 clusters. Intuitively, in a network in which all vertices of the same community are mapped, the fraction of the edges embedded within that community is the expected value of the same set in a network in which edges are randomly placed, resulting in Q getting its lower limit, Q = 0.However, in the hypothetical case where all vertices of the same community are mapped, the fraction of the edges embedded within that community shows the expected value of the same quantity in a network in which edges are randomly placed."}, {"heading": "5.2.2 Salient Vertex Extraction", "text": "The selection of representative sets (vertices) from different clusters is done using LexRank in the C-LexRank algorithm. Specifically, for each cluster, C-LexRank first extracts a subgraph of the network that represents vertices and edges in that cluster, and then uses LexRank to assign an emphasis value to each vertice. An alternative idea might be to select sentences from clusters randomly (C-RR). In C-RR, we randomly traverse clusters and randomly select a previously unselected sentence from the cluster to add a summary. Comparing C-LexRank with C-RR allows us to understand the effect of highlighting selection within communities. Selecting vertices that are not good representatives of the cluster can result in the selection of sentences that do not cover contributions of the target paper (e.g. sentence 9 from Table 2 - vertice 200 in Figure 3), because the summaries are higher than the summaries (Table C), in fact, when viewed at a higher percentage, they show a higher percentage."}, {"heading": "6. Summaries of Scientific Topics", "text": "In previous sections, we have described C-LexRank as a method of identifying communities of citations that discuss the same scientific papers. We have shown that C-LexRank is effective at summarizing contributions from individual scientific papers. However, the ultimate goal of our work is to investigate whether citations contain summary information and also to build an end-to-end system that receives a query representing a scientific topic (e.g., \"Dependency Parsing\") and creates an automatic quote-based summary of the given topic. In this section, we expand our experiments to include the use of the tools for automatic summary of scientific topics explained in previous sections. Our evaluation experiments on extractive summary generation are based on a series of papers in the research area of Question Answering (QA) and another set of papers on Dependency Parsing (DP). The two sets of papers were compiled by selecting all papers in AAN \"Anson Parsing\" (which were)."}, {"heading": "6.1 Data Preparation", "text": "Our goal is to determine whether citations actually contain useful information to insert into a summary, and if so, how much of that information is not available in the original papers and their summaries. To do this, we evaluate each of the automatically generated summaries using two different approaches: nugget-based pyramid evaluation and ROUGE. Recall-oriented understudy for gisting evaluation (ROUGE) is a metric that evaluates automatic summaries by comparing them with a set of human written references (Lin, 2004).Two sets of gold standard data were manually generated from the QS and DP citations or summaries: 8 (1) We asked three annotations9 with background in Natural Language Processing to identify important nuggets of information worth including in a summary. (2) We asked four NLP researchers to summarize the QS and DP records with 250 words."}, {"heading": "6.1.1 Nugget Annotations", "text": "For our initial evaluation approach, we used a nugget-based evaluation method (Voorhees, 2003; Nenkova & Passonneau, 2004; Hildebrandt, Katz, & Lin, 2004; Lin & DemnerFushman, 2006); we asked three commentators with a background in natural language processing to review the quotations and / or abstract sentences for each of the papers in the QA and DP sentences; and manually prioritized lists of 2-8 \"factoids,\" or major contributions, supplied by each paper; each factoid was assigned a weight based on the frequency with which it was assigned by annotators and priority; and our automatically generated summaries were then based on the number and weight of nuggets they covered."}, {"heading": "6.1.2 Expert Summaries", "text": "In addition to the nugget notes, we asked four NLP researchers to compose 250-word summaries of the QA quotation set, the QA abstract set, and the DP quotation set. Table 8 indicates the pyramid values of the 250-word summaries manually created by experts, and the summaries were evaluated using the nuggets from the QA quotations, QA abstracts, and DP quotes. Average of their results (listed in the outermost column) can be considered a good value to be sought by the automatic summation methods. Table 9 also presents ROUGE results (Lin, 2004) for each expert-written 250-word summary (e.g. Human1 versus all others, and so on), and the average (last column) could be considered a ceiling for the performance of the automatic summation systems. 11. Results obtained with other weighting schemes were weighted against each other, with multiple priorities and multiple NLP scores."}, {"heading": "6.2 Automatic Extractive Summaries", "text": "In fact, most of them will be able to move to another world in which they are able to move, and in which they are able to move."}, {"heading": "7. Conclusion", "text": "In this paper, we explored the usefulness of direct summaries of citations (sets of sentences that quote a paper) in automatically generating technical summaries. We proposed C-LexRank, a graph-based summary model, and created summaries of 30 individual scientific articles selected from 6 different topics in the ACL Anthology Network (AAN). We also created summaries of a set of Question Answering (QA) and Dependency Parsing (DP) papers, their summaries and citations using four state-of-the-art summary systems (C-LexRank, C-RR, LexRank and MASCS). We then used two different approaches, nugget-based pyramid and ROUGE, to evaluate the summaries. Results from both approaches and all four summaries show that both citations and summaries have unique summarizable information."}, {"heading": "8. Acknowledgments", "text": "We would like to thank Ahmed Hassan, Rahul Jha, Pradeep Muthukrishan, and Arzucan O \ufffd zgu for comments and Melissa Egan for preliminary developments; we are also grateful to Ben Shneiderman, Judith Klavans, and Jimmy Lin for fruitful discussions; and the anonymous critics for insightful readings and constructive guidance; the following authors, Vahed Qazvinian, Dragomir R. Radev, Saif M. Mohammad, Bonnie Dorr, David Zajic, and Michael Whidby, were partially supported by the National Science Foundation under grant number IIS-0705832 (iOPENER: Information Organization for PENning Expositions on Research) awarded to the University of Michigan and the University of Maryland. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. The following authors, Michael Whidby and Taesun Moon, have been expressed, in part, by the Advanced Intelligence material, the Business and the U.S. Government Conclusions expressed in this document or Recommendations."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "Researchers and scientists increasingly find themselves in the position of having to quickly understand large amounts of technical material. Our goal is to effectively serve this need by using bibliometric text mining and summarization techniques to generate summaries of scientific literature. We show how we can use citations to produce automatically generated, readily consumable, technical extractive summaries. We first propose C-LexRank, a model for summarizing single scientific articles based on citations, which employs community detection and extracts salient information-rich sentences. Next, we further extend our experiments to summarize a set of papers, which cover the same scientific topic. We generate extractive summaries of a set of Question Answering (QA) and Dependency Parsing (DP) papers, their abstracts, and their citation sentences and show that citations have unique information amenable to creating a summary.", "creator": "TeX"}}}