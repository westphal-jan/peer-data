{"id": "1402.0574", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2014", "title": "Learning to Predict from Textual Data", "abstract": "Given a current news event, we tackle the problem of generating plausible predictions of future events it might cause. We present a new methodology for modeling and predicting such future news events using machine learning and data mining techniques. Our Pundit algorithm generalizes examples of causality pairs to infer a causality predictor. To obtain precisely labeled causality examples, we mine 150 years of news articles and apply semantic natural language modeling techniques to headlines containing certain predefined causality patterns. For generalization, the model uses a vast number of world knowledge ontologies. Empirical evaluation on real news articles shows that our Pundit algorithm performs as well as non-expert humans.", "histories": [["v1", "Tue, 4 Feb 2014 01:39:12 GMT  (1391kb)", "http://arxiv.org/abs/1402.0574v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.IR", "authors": ["kira radinsky", "sagie davidovich", "shaul markovitch"], "accepted": false, "id": "1402.0574"}, "pdf": {"name": "1402.0574.pdf", "metadata": {"source": "CRF", "title": "Learning to Predict from Textual Data", "authors": ["Kira Radinsky", "Sagie Davidovich", "Shaul Markovitch"], "emails": ["kirar@cs.technion.ac.il", "mesagie@gmail.com", "shaulm@cs.technion.ac.il"], "sections": [{"heading": "1. Introduction", "text": "Causality has been studied since antiquity, e.g. by Aristotle, but the modern perception of the virtual world of causality has been influenced primarily by the work of David Hume (1711-1776), who described causality as the strongest and most important associative relationship that lies at the core of our perception and reasoning about the world, as \"it is constantly assumed that there is a connection between the present fact and what is derived from it.\" Causality is also important for the design of computerized agents. If an agent who is in a complex environment plans his actions, there will be reasons for future changes in the environment. Some of these changes are a result of his own actions, but many others are a result of different chain of events that are not necessarily related to the agent. The process of observing an event and arguing about future events that could be caused by it is called causative reasons. In the past, computerized agents could not operate more complex environments."}, {"heading": "2. Learning and Predicting Causality", "text": "In this section, we describe the pundit algorithm for learning and predicting causalities, starting with an overview of the learning and prediction process. During the training, the learning algorithm obtains pairs of causality events, which are extracted from historical message archives (Section 3). Subsequently, the algorithm generalizes the given examples based on world knowledge and generates an abstraction tree (Section 2.4). For each node in the AT, a prediction rule is generated from the examples in the node (Section 2.5) (Section 2.6). During the prediction phase, the algorithm then matches the given new event with nodes in the AT, and the corresponding rule is applied to it to generate possible effect events (Section 2.6). These events are then filtered (Section 2.7) and an effect event is output."}, {"heading": "2.1 Event Representation", "text": "The basic element of causal reasoning is an event. The Tracking and Detection (TDT) community (Allan, 2002) has defined an event that takes place at a certain time and place, along with all the necessary preconditions and inevitable consequences. \"Other philosophical theories consider events as examples of characteristics in times (Kim, 1993). For example, Caesar's death is a different event from Caesar's death, as the objects exemplify ownership of time 44 BC. These theories impose the structure of events in which a change in one of the elements leads to another. Shakespeare's death is a different event from Caesar's death, as the objects that represent property."}, {"heading": "2.2 Learning Problem Definition", "text": "Let Ev be the universe of all possible events. Let f: Ev \u00b7 Ev \u2192 {0, 1} be the function f (e1, e2) = {1, if e1 otherwise causes e2.0. We designate f + = {(e1, e2) | f (e1, e2) = 1}. We assume that we are given a number of possible positive examples E f +. Our goal is not only to test whether an event pair is a plausible cause-effect pair through f, but to generate for a given event e the events it can cause. To this end, we define g: Ev \u2192 2Ev as g (e) = {e \u2032 | f (e, e \u2032) = 1}; that is, to create the set of events it can cause in an event."}, {"heading": "2.3 Generalizing Over Objects and Actions", "text": "This year it is so far that it will only take one year to reach an agreement."}, {"heading": "2.4 Generalizing Events", "text": "To provide strong support for the generalization, we would like to find similar events that can be generalized to a single abstract event. In our example, we would like to conclude that both < earthquakes in Turkey, destruction > and < earthquakes in Australia, destruction > are examples of the same group of events. Therefore, we would like to group the events in such a way that events with similar causes and effects are bundled. As with all cluster methods, a distance measurement between objects should be defined. Let's leave ei = < P i, Oi1,., ti > and ej = < P j, Oj1,."}, {"heading": "2.5 Causality Prediction Rule Generation", "text": "The final stage of learning is the creation of rules that allow us to make a prediction about a cause event. < < p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p \"p > p\" p > p \"p > p\" p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p \"p\" p > p > p > p > p \"p > p > p > p > p > p\" p \"p\" p > p \"p\" p > p \"p\" p > p \"p\" p \"p > p\" p \"p\" p \"> p\" p \"p\" p \"> p\" p \"p\" p \"p\" > p \"p\" p \"p\" p \"> p\" p \"p\" p \"p\" > p \"p\" p \"p\" > p \"p\" p \"p\" p \"> p\" p \"p\" p \"> p\" p \"p\" p \"p\" > p \"p\" p \"p\" p \"> p\" p \"p\" p \"> p\" p \"p\" p \"p\" p \"p\" p \"> p\" p \"p\" p \"p\" > p \"p\" p \"p\" p \"p\" > p \"p\" p \"p\" p \"p\" > p \"p\" p \"p\" p \"> p\" p \"p\" p \"p\" p \"p\" p \"> p\" p \"p\" > p \"p\" p \"p\" p \"p\" > p \"p\" p \"p\" p \"> p\" p \"p\" > p \"p\" p \"p\" p \"p\" > p \"p\" p \"p\" p \"p\" p \"> p\" p \"p\" p \"p\" > p \"p\" p \"p\" p \"p\" p \"p\" > p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\""}, {"heading": "2.6 Prediction", "text": "Considering a trained model, it can be applied to a new event e = < P i, O1,.., O4, t > to produce its effects. The process is divided into two main steps - propagating the event in the search guideline to retrieve a series of customized nodes and applying the rules of each customized node to generate the possible effects. Considering a new event, Pundit traverses the AT starting from the root. For each node in the search guideline, the algorithm calculates the similarity (SIM (ei, ej)) of the input event to the respective of the children at that node, and expands these children with better similarity than their parents. This idea can be intuitively stated as an attempt to find the nodes that are least common to the new event, but still similar. The complete algorithm is illustrated in Figure 5."}, {"heading": "2.7 Pruning Implausible Effects", "text": "In some cases, the system has produced implausible predictions. For example, for the event < lightning kills 5 people >, the system is arrested >. This prediction is based on generalized training examples in which people who have killed other people are arrested. < Man kills a person who is arrested. However, if we determine how logical an event is, we can avoid these false predictions. In this section, we discuss how to filter them out. The goal of our prediction is to make predictions about future events."}, {"heading": "3. Implementation Details", "text": "In the previous section, we introduced a high-level algorithm that requires training examples T, knowledge of events GO, and event action classes P. One of the major challenges of this work was to build a scalable system to meet these requirements. We present a system that mines news sources to extract events, constructs its canonical semantic model, and builds a causality graph on top of it. The system combed through several dynamic information sources for more than four months (see Section 3.1 for details). The largest source of information was the NYT archive, on the basis of which optical character recognition (OCR) was carried out. The total data collected spans more than 150 consecutive years (1851-2009). To generalize the objects, the system automatically reads web content and extracts world knowledge. Knowledge was mined from structured and semi-structured publicly available information repositories."}, {"heading": "3.1 World Knowledge Mining", "text": "The Go entity graph consists of concepts from Wikipedia, ConceptNet (Liu & Singh, 2004), WordNet (Miller, 1995), Yago (Suchanek, Kasneci, & Weikum, 2007), and OpenCyc; the billions of labeled edges of the Go graph are the predicates of these ontologies. In this section, we describe the process by which this knowledge graph is created, and the search system that builds on it. Our system creates the entity graph by collecting the above-mentioned content, processing feeds, and processing formatted records (e.g. Wikipedia), and our crawler archives these documents in raw format and transforms them into the RDF (Resource Description Framework) format (Lassila, Swick, Wide, & Consortium, 1998), linking the concepts together by humans as part of the Linked Data Project (Bizer et al., 2009)."}, {"heading": "3.2 Causality Event Mining and Extraction", "text": "Because the amount of temporal data is extremely large and spans millions of articles, the goal of obtaining humanly annotated examples cannot be achieved. Therefore, we offer an automatic method to extract labeled examples of causality from dynamic contents. In this work, we used the NYT archive for the years 1851 and 2009, and the BBC - over 14 million articles in total (see statistics in Table 1). Extracting causal relationships between events in the text is a tough task. The state of precision of this task is about 37% (Do, Chan, & Roth, 2011). Our hypothesis is that most information relating to an event is found, which is more structured and therefore easier to analyze."}, {"heading": "4. Experimental Evaluation", "text": "In this section, we describe a series of experiments that have been conducted to assess the ability of our algorithms to predict causality. First, we evaluate the precision of our algorithm, continue the analysis of each part of the algorithm separately, and conclude with a qualitative assessment."}, {"heading": "4.1 Prediction Evaluation", "text": "In fact, it is as if most of us are able to abide by the rules that they have imposed on themselves. (...) It is as if they were able to change the rules. (...) It is as if they were able to change the rules. (...) It is as if they were able to change the rules. (...) It is as if they were able to change the rules. (...) It is as if they were able to change the rules. (...) It is as if they are able to change the rules. (...) It is as if they are able to change the rules. (...) It is as if they are able to change the rules, to change the rules. (...) () () (() () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () () () () () ()) () () () () () () () ()) () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () () () () () (() () () (() () () (() () () ((() () (() (() () () () (((() () (() () () (() () () (() () (() (() () (((() () () (() () () ((() () () ((() () () (() (() ((()"}, {"heading": "4.2 Component Analysis", "text": "In this section we report on the results of our empirical analysis of the different parts of the algorithm."}, {"heading": "4.2.1 Evaluation of the Extraction Process", "text": "In Section 3.1, we described a process for extracting causalities from the messages. These pairs are mainly used as a training set for the learning algorithm. This process consists of two main parts: causality identification and extraction. We conduct a series of experiments to assess the quality of this process."}, {"heading": "4.2.2 Evaluation of the Event Similarity Algorithm", "text": "Both the learning and prediction algorithms rely heavily on the similarity function of the event described in Section 2.4. To evaluate the quality of this function, a random sample of 30 events from the training data found the most similar event of all the past data (corresponding to the similarity function) for each. Subsequently, a human evaluator was asked to rate the similarity of these events on a scale of 1-5. We repeated the experiment and replaced the average aggregator function f with minimum and maximum functions. Results are shown in Table 7. The overall precision of the average function was high (3.9). Furthermore, the average function performed significantly better (confirmed by a t-test) than above the minimum and maximum. This result indicates that distance functions aggregating across multiple objects of the structured event (rather than selecting only the minimum or maximum of one of the events) provide the highest performance."}, {"heading": "4.2.3 The Importance of Abstraction", "text": "Considering a cause-event whose effect we would like to predict, we use the algorithm described in Section 2.4 to identify similar generalized events. To evaluate the importance of this phase, we compile an alternative matching algorithm similar to the approach of the closest neighbors (as in the work of Gerber, Gordon, & Sagae, 2010) that matches the cause-event with the cause-events of the training data. Instead of creating an abstraction tree, the algorithm simply finds the next cause in the past based on text similarity. We then evaluate the matching results using the TF-IDF measurement. We applied both our original algorithm and this baseline algorithm to the 50 events used for the prediction. For each event, we asked a human evaluator to compare the prediction of the original and baseline algorithms. Results showed that in 83% of the cases, predictions were classified as more plausible than the next neighbor's prediction."}, {"heading": "4.2.4 Analysis of Rule Generation Application", "text": "In order to make an adequate prediction of the given cause event, a learned rule is applied as described in Section 2.5. We observe that in 31% of the predictions a non-trivial rule was generated and applied (i.e. a non-zero rule that does not simply output the effect it observed in the matching cause-effect pair example), and from these predictions the application correctly predicted and produced a plausible object in the effect in more than 90% of the cases. These results suggest that generalization and rule generation techniques are indispensable for the performance of the algorithm."}, {"heading": "4.2.5 Analysis of Pruning Implausible Causation", "text": "To eliminate situations where a generated prediction is implausible, we developed an algorithm (Section 2.7) that prevents implausible predictions. We randomly selected 200 predictions from the algorithm predictions based on the human-characterized events extracted from the Wikinews articles (see Section 4.1). A human was asked to label predictions that were considered implausible. Subsequently, we applied our filter rules to the 200 predictions as well. The algorithm found 15% of the predictions to be implausible with 70% accuracy and 90% recall in terms of human labeling. A qualitative example of a filtered prediction is \"explosion results\" for the causal event \"explosion in Afghanistan kills two.\""}, {"heading": "4.3 Qualitative Analysis", "text": "For a better understanding of the strengths and weaknesses of the 1993 algorithm, we now present some examples of results. Given the event \"Louisiana Flood\" (31 million), the algorithm predicted that [number] people will flee. The prediction process is illustrated in Figure 11.1. Raw Data: The above predictions are based on the following raw news articles: (a) 150,000 flee as a hurricane near the coast of North Carolina. (b) One million people flee as a powerful storm hits the coast of Texas. (c) Thousands flee as a storm whips coast of Florida. (d) Thousands flee as a severe storm move southwest. (2. Causality pair extraction: The \"as\" template was used to process the above headlines into the following structured events: (a) event near (action); hurricane (actor); coast (object attributes); North Carolina Object Attributes (Carolina Effect); (Carolina Effect Effect); (instrument); (attribute); (attribute); (attribute); (attribute)."}, {"heading": "4.4 Discussion", "text": "In our experiments, however, each validation step required human intervention. For example, by confirming that a prediction has taken place in the future messages. To perform a complete on-demand experiment, one should apply the algorithm to all headlines reported on a given day, and measure the appearance of all corresponding predictions in future messages. Unfortunately, performing human validation in such a large prediction room was difficult. We leave the task of conducting experiments to a rough estimate of the call-up of future work. It is common practice to compare system performance with previous systems that tackle the same problem. However, the ambitious task we undertook in this work had no immediate foundations to compare it with. That is, there was no comparable system neither in the order of magnitude nor in the ability to take an arbitrary event in natural language, and produce the effects on an event in natural language."}, {"heading": "5. Related Work", "text": "We are not aware of any work that attempts to accomplish the task we face: receiving arbitrary news events in natural language and predicting events that can cause them. However, several papers deal with related tasks. Generally, our work does not focus on better techniques of information extraction or causality extraction, but rather on how this information can be used to predict. We present novel methods of combining world knowledge with methods of event extraction to present coherent events, and present new methods of rule extraction and generalization that use this knowledge."}, {"heading": "5.1 Prediction from Web Behavior, Books and Social Media", "text": "Several papers focused on the use of search engine queries for prediction in traditional media (Radinsky, Davidovich, & Markovitch, 2008) and blogs (Adar, Weld, Bershad, & Gribble, 2007).Ginsberg et al. (2009) used queries to predict H1N1 influenza outbreaks. In the context of causality detection, Gordon, Bejan, and Sagae (2011) present a methodology for mining blogs to extract healthy causality.The evaluation is based on a human-designated dataset in which each test consists of one fact and two possible effects.Using point-to-point information for personal blog stories, the authors select the best prediction candidate. The work differs from ours in that the authors focus on personal common sense and do not take into account whether their predictions have actually occurred. Other papers focused on predicting web content that is changing itself."}, {"heading": "5.2 Textual Entailment", "text": "A text t should include a text hypothesis h if the readers agree that the meaning of t can be divided into three main categories: detection, generation, and extraction. In this section, we offer a brief summary of the first two categories. For a more detailed overview, we refer the reader to the study by Androutsopoulos and Malakasiotis (2010). Then, we discuss the specific task of causal extraction from text in Section 5.3.4."}, {"heading": "5.2.1 Textual Entailment recognition", "text": "Some approaches match the text to logical expressions (with some semantic enrichment, such as using WordNet) and perform logical checks, usually using theory checkers (Raina, Ng, & Manning, 2005; Bos & Markert, 2005; Tatu & Moldovan, 2005); others assign the two texts to a vector space model, in which each word is mapped to strongly contiguous words in the corpus (Mitchell & Lapata, 2008), and then apply similarity measurements via these vectors."}, {"heading": "5.2.2 Textual Entailment Generation", "text": "Androutsopoulos and Malakasiotis (2010) mention that there are no benchmarks to evaluate this task, and the most common and costly approach is to evaluate the use of human judges. We also encountered this difficulty in our own task and performed human evaluation techniques. TE-generation methods can be divided into two types: those that use machine translation techniques and those that use template-based techniques try to calculate the most likely set of translations by using a training corpus and performing human evaluation techniques. Quirk, Brockett and Dolan (2004) group news articles referring to the same event, select pairs of similar sentences and apply the techniques already mentioned. Other methods use template-based approaches on large corpus, such as the web system, some search engine sentences that are based on Idan."}, {"heading": "5.3 Information Extraction", "text": "Information extraction is the study of the automatic extraction of information from unstructured sources. We categorize the types of information that are extracted into three types: entities, relationships between entities, and superordinate structures such as tables and lists. The tasks that are most closely related to ours are the extraction of entities and the extraction of relationships; moreover, we refer the reader to the study of Sarawagi (2008). The first task, similar to our process of extracting concepts, deals with the extraction of noun phrases from text. In the second task, in which a document and a relationship are given as input, the problem is to extract all the entity pairs in the document to which this relationship applies. While the above work deals with only one element of our problem - the extraction of information that is necessary to understand a venom causality, we attempt to execute an actual causality prediction - to claim this important information, but not to execute it."}, {"heading": "5.3.1 Entity Extraction", "text": "There are two categories of methods for extracting entities - rules-based and statistical methods: rules-based methods (Riloff, 1993; Riloff & Jones, 1999; Jayram, Krishnamurthy, Raghavan, Vaithyanathan, & Zhu, 2006; Shen, Doan, Naughton, & Ramakrishnan, 2007; Ciravegna, 2001; Maynard, Tablan, Ursu, Cunningham, & Wilks, 2001; Hobbs, Bear, Israel, & Tyson, 1993) define contextual patterns consisting of a regular expression of entity properties in the text (e.g. the entity word, part-of-speech tagging)."}, {"heading": "5.3.2 Relation Extraction", "text": "Most methods have been developed in recent years from large text corpora (Schubert, 2002) and, in particular, from various web resources, such as general web content (Banko et al., 2007; Carlson et al., 2010; Hoffmann, Zhang, & Weld, 2010), blogs (Jayram et al., 2006), Wikipedia (Suchanek et al., 2007; Kambhatla, 2004; Suchanek, 2006), and rules-based methods (Section 5.3.3). Given two entities, the first task in this area is to classify their relationship; many function-based methods (Jiang & Zhai, 2007; Kambhatla, 2004; Suchanek, 2006) and rules-based methods (Aitken, Chen, Su, & Marshall, 2004; Jayram et al., 2006; Shen et al., 2007) have been developed for this task."}, {"heading": "5.3.3 Temporal Information Extraction", "text": "The Time Information Extraction Task deals with the extraction and arrangement of events from many events over time. Time information extraction can be categorized into three main subtasks - predicting the temporal sequence of events or time expressions described in the text, predicting the relationship between these events, and identifying when the document was written. This task has proven important in many applications of natural language processing, such as answering questions, information extraction, machine translation, and text summary, all of which require more than mere surface understanding. Most of these approaches (Ling & Weld, 2010; Mani, Schiffman, & Zhang, 2003; Lapata & Lascarides, 2006; Chambers et al., 2007; Tatu & Srikanth, 2008; Yoshikawa, Riedel, Asahara, & Matsumoto, 2009) learn classifiers that predict the temporal order of events from a pair of events."}, {"heading": "5.3.4 Causality Pattern Extraction and Recognition", "text": "In the first phase of our learning process, we extract causality pairs from the text. Causality extraction has been discussed in the literature in the past and can be divided into the following subgroups: 1. Use of handmade domain-specific patterns. Some studies deal with causality extraction using specific domain knowledge. Kaplan and Berry-Rogghe (1991) used scientific texts to create a handmade set of suggestions that were later applied to new texts to extract causality. These methods require handmade domain knowledge that is problematic for real-world tasks, especially in large quantities. 2. Use of handmade linguistic patterns. These works take a more general approach by applying linguistic patterns to extract causality. Garcia (1997) manually identified 23 causal verb groups (e.g. to lead, execute, to include, to trigger a sentence, etc.)."}, {"heading": "5.4 Learning Causality", "text": "We draw part of our algorithmic motivation from working in the machine learning community. In this section, we give a partial overview of the most important areas of machine learning that are relevant to our work."}, {"heading": "5.4.1 Bayesian Causal Inference", "text": "The functional causal model (Pearl, 2000) is based on a series of observational models X1... Xn, which represent the vertices of a directed acyclic graph G. The semantics of the graph is that the parents of a node are its directed causes. It has been shown that it fulfills Reichenbach's principle of common cause, which states that for a node Z with children X, Y, if X and Y are statistically dependent on each other, then there is a Z that influences both causally. Similar to a Bajesian network, this model fulfills several conditions: (1) Local causal Markov condition: A node is statistically independent of non-descendants due to its parents; (2) Global causal Markov condition: separation criterion; (3) Factorization criterion: P (X1..., Xn) = causal Markov condition: A node is statistically independent of non-descendants; (Xi | the conclusive work from the theoretical literature)."}, {"heading": "5.4.2 Structured Learning", "text": "An important problem in the field of machine learning is structured learning, where the input or output of the classifier is a complex structure, such as a relationship domain in which each object is related to each other either temporally or in terms of its characteristics. Our task is similar to structured learning by also using structured input (structured events given as input) and producing a structured event as output. Many generative models have been developed, including hidden Markov models, Markov logic networks and conditional random fields, etc. Other approaches use transformations or cores that unite all objects, ignore the structure and then feed it into a structured standard classifier, such as nuclearized conditional random fields (Lafferty, Zhu, & Liu, 2004), Markov networks with maximum margin (Taskar, Guestrin, & Koller, 2003) and others (Bakir, Hofmann, Scholkopf, Smola, 2007, Tashu, & Vattkar, when dealing with most problems)."}, {"heading": "5.4.3 Learning from Positive Examples (One Class Classification)", "text": "Since our system is fed only with examples of the species \"a causes b,\" and not examples of the species \"a does not cause b,\" we must address the problem of learning from positive examples, which is a challenge to most multi-layered learning mechanisms requiring both negative and positive examples. Some theoretical studies of the ability to learn only from positive, unlabeled data are provided in the work of Denis (1998) (probably approximately correct (PAC) learning) and Muggleton (1996) (Bavarian Learning). Most of the papers (Tax, 2001; Manevitz & Yousef, 2000; Manevitz, Yousef, Christianini, ShaweTaylor, & Williamson, 2001) in this area develop algorithms that use single-class SVM (Vapnik, 1995) and learn support only using positive distribution, constructing decision boundaries around the positive examples to distinguish them from any possible negative data. Tax and Duin (1991) use a hyperspherical 2001 with a defined radius of a few points in front of the positive description."}, {"heading": "6. Conclusions", "text": "This year, the time has come for us to be able to try to find a solution that we are able to find, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution. \""}], "references": [{"title": "Why we search: visualizing and predicting user behavior", "author": ["E. Adar", "D.S. Weld", "B.N. Bershad", "S.D. Gribble"], "venue": "In Proceedings of the International Conference on the World Wide Web (WWW)", "citeRegEx": "Adar et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Adar et al\\.", "year": 2007}, {"title": "Mining reference tables for automatic text segmentation", "author": ["E. Agichtein", "V. Ganti"], "venue": "In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)", "citeRegEx": "Agichtein and Ganti,? \\Q2004\\E", "shortCiteRegEx": "Agichtein and Ganti", "year": 2004}, {"title": "Snowball: extracting relations from large plain-text collections", "author": ["E. Agichtein", "L. Gravano"], "venue": "In Proceedings of Joint Conference on Digital Libraries (JCDL),", "citeRegEx": "Agichtein and Gravano,? \\Q2000\\E", "shortCiteRegEx": "Agichtein and Gravano", "year": 2000}, {"title": "Unified analysis of streaming news", "author": ["A. Ahmed", "Q. Ho", "J. Eisenstein", "E.P. Xing", "A.J. Smola", "C.H. Teo"], "venue": "In Proceedings of the International Conference on the World Wide Web (WWW)", "citeRegEx": "Ahmed et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ahmed et al\\.", "year": 2011}, {"title": "Learning information extraction rules: An inductive logic programming approach", "author": ["J. Aitken"], "venue": "Proceedings of the 15th European Conference on Artificial Intelligence (ECAI), pp. 355\u2013359.", "citeRegEx": "Aitken,? 2002", "shortCiteRegEx": "Aitken", "year": 2002}, {"title": "Topic Detection and Tracking: Event-based Information Organization, Vol. 12", "author": ["J. Allan"], "venue": null, "citeRegEx": "Allan,? \\Q2002\\E", "shortCiteRegEx": "Allan", "year": 2002}, {"title": "Hybrid models for future event prediction", "author": ["G. Amodeo", "R. Blanco", "U. Brefeld"], "venue": "In Proceedings of the ACM Conference on Information and Knowledge Management (CIKM)", "citeRegEx": "Amodeo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Amodeo et al\\.", "year": 2011}, {"title": "A survey of paraphrasing and textual entailment methods", "author": ["I. Androutsopoulos", "P. Malakasiotis"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Androutsopoulos and Malakasiotis,? \\Q2010\\E", "shortCiteRegEx": "Androutsopoulos and Malakasiotis", "year": 2010}, {"title": "Predicting the future with social media", "author": ["S. Asur", "B.A. Huberman"], "venue": "In ArxiV", "citeRegEx": "Asur and Huberman,? \\Q2010\\E", "shortCiteRegEx": "Asur and Huberman", "year": 2010}, {"title": "Predicting Structured Data", "author": ["G.H. Bakir", "T. Hofmann", "B. Sch\u00f6lkopf", "A.J. Smola", "B. Taskar", "S.V.N. Vishwanathan"], "venue": null, "citeRegEx": "Bakir et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bakir et al\\.", "year": 2007}, {"title": "Open information extraction from the web", "author": ["M. Banko", "M.J. Cafarella", "S. Soderl", "M. Broadhead", "O. Etzioni"], "venue": "In Proceedings of the International Joint Conferences on Artificial Intelligence (IJCAI)", "citeRegEx": "Banko et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Banko et al\\.", "year": 2007}, {"title": "Linked data \u2013 the story so far. International Journal on Semantic Web and Information Systems (IJSWIS)", "author": ["C. Bizer", "T. Heath", "T. Berners-Lee"], "venue": null, "citeRegEx": "Bizer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bizer et al\\.", "year": 2009}, {"title": "The berlin sparql benchmark", "author": ["C. Bizer", "A. Schultz"], "venue": "International Journal on Semantic Web and Information Systems (IJSWIS)", "citeRegEx": "Bizer and Schultz,? \\Q2009\\E", "shortCiteRegEx": "Bizer and Schultz", "year": 2009}, {"title": "Causal Relation Extraction", "author": ["E. Blanco", "N. Castell", "D. Moldovan"], "venue": "In Proceedings of the International Conference on Language Resources and Evaluation (LREC)", "citeRegEx": "Blanco et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Blanco et al\\.", "year": 2008}, {"title": "Automatic text segmentation for extracting structured records", "author": ["V. Borkar", "K. Deshmukh", "S. Sarawagi"], "venue": "In Proceedings of ACM SIGMOD International Conference on Management of Data (KDD)", "citeRegEx": "Borkar et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Borkar et al\\.", "year": 2001}, {"title": "Recognising textual entailment with logical inference", "author": ["J. Bos", "K. Markert"], "venue": "In Proceedings of the Human Language Technology Conference Conference on Empirical Methods in Natural Language Processing (HLT EMNLP)", "citeRegEx": "Bos and Markert,? \\Q2005\\E", "shortCiteRegEx": "Bos and Markert", "year": 2005}, {"title": "Learning to extract relations from the web using minimal supervision", "author": ["R. Bunescu", "R. Mooney"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Bunescu and Mooney,? \\Q2007\\E", "shortCiteRegEx": "Bunescu and Mooney", "year": 2007}, {"title": "A shortest path dependency kernel for relation extraction", "author": ["R.C. Bunescu", "R.J. Mooney"], "venue": "In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT EMNLP),", "citeRegEx": "Bunescu and Mooney,? \\Q2005\\E", "shortCiteRegEx": "Bunescu and Mooney", "year": 2005}, {"title": "Assessing the impact of frame semantics on textual entailment", "author": ["A. Burchardt", "M. Pennacchiotti", "S. Thater", "M. Pinkal"], "venue": "Natural Language Engineering,", "citeRegEx": "Burchardt et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Burchardt et al\\.", "year": 2009}, {"title": "Relational learning of pattern-match rules for information extraction", "author": ["M.E. Califf", "R.J. Mooney"], "venue": "In Proceedings of the Sixteenth National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Califf and Mooney,? \\Q1999\\E", "shortCiteRegEx": "Califf and Mooney", "year": 1999}, {"title": "Toward an architecture for never-ending language learning", "author": ["A. Carlson", "J. Betteridge", "B. Kisiel", "B. Settles", "E. Hruschka", "T. Mitchell"], "venue": "In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)", "citeRegEx": "Carlson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Template-Based Information Extraction without the Templates", "author": ["N. Chambers", "D. Jurafsky"], "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Chambers and Jurafsky,? \\Q2011\\E", "shortCiteRegEx": "Chambers and Jurafsky", "year": 2011}, {"title": "Classifying temporal relations between events. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL) (Poster)", "author": ["N. Chambers", "S. Wang", "D. Jurafsky"], "venue": null, "citeRegEx": "Chambers et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Chambers et al\\.", "year": 2007}, {"title": "Extracting causation knowledge from natural language texts", "author": ["K. Chan", "W. Lam"], "venue": "International Journal of Information Security (IJIS),", "citeRegEx": "Chan and Lam,? \\Q2005\\E", "shortCiteRegEx": "Chan and Lam", "year": 2005}, {"title": "Large, multilingual, broadcast news corpora for cooperative research in topic detection and tracking: The tdt-2 and tdt-3 corpus efforts", "author": ["C. Cieri", "D. Graff", "M. Liberman", "N. Martey", "S. Strassel"], "venue": "In Proceedings of the International Conference on Language Resources and Evaluation (LREC)", "citeRegEx": "Cieri et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Cieri et al\\.", "year": 2000}, {"title": "Adaptive information extraction from text by rule induction and generalisation", "author": ["F. Ciravegna"], "venue": "Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI).", "citeRegEx": "Ciravegna,? 2001", "shortCiteRegEx": "Ciravegna", "year": 2001}, {"title": "Dependency tree kernels for relation extraction", "author": ["A. Culotta", "J. Sorensen"], "venue": "In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Culotta and Sorensen,? \\Q2004\\E", "shortCiteRegEx": "Culotta and Sorensen", "year": 2004}, {"title": "Investigating regular sense extensions based on intersective levin classes", "author": ["H.T. Dang", "M. Palmer", "J. Rosenzweig"], "venue": "In Proceedings of the International Conference on Computational Linguistics (COLING)", "citeRegEx": "Dang et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Dang et al\\.", "year": 1998}, {"title": "PAC learning from positive statistical queries", "author": ["F. Denis"], "venue": "Proceedings of the International Conference on Algorithmic Learning Theory (ALT), pp. 112\u2013126.", "citeRegEx": "Denis,? 1998", "shortCiteRegEx": "Denis", "year": 1998}, {"title": "Minimally supervised event causality identification", "author": ["Q. Do", "Y. Chan", "D. Roth"], "venue": "In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP)", "citeRegEx": "Do et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Do et al\\.", "year": 2011}, {"title": "Cluster analysis and display of genome-wide expression", "author": ["M.B. Eisen", "P.T. Spellman", "P.O. Brown", "D. Botstein"], "venue": "patterns. PNAS,", "citeRegEx": "Eisen et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Eisen et al\\.", "year": 1998}, {"title": "Coatis, an NLP system to locate expressions of actions connected by causality links", "author": ["D. Garcia"], "venue": "Proceedings of Knowledge Engineering and Knowledge Management by the Masses (EKAW).", "citeRegEx": "Garcia,? 1997", "shortCiteRegEx": "Garcia", "year": 1997}, {"title": "Open-domain commonsense reasoning using discourse relations from a corpus of weblog stories", "author": ["M. Gerber", "A.S. Gordon", "K. Sagae"], "venue": "In Proceedings of Formalisms and Methodology", "citeRegEx": "Gerber et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gerber et al\\.", "year": 2010}, {"title": "Detecting influenza epidemics using search engine query data", "author": ["J. Ginsberg", "M.H. Mohebbi", "R.S. Patel", "L. Brammer", "M.S. Smolinski", "L. Brilliant"], "venue": null, "citeRegEx": "Ginsberg et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ginsberg et al\\.", "year": 2009}, {"title": "Text mining for causal relations", "author": ["R. Girju", "D. Moldovan"], "venue": "In Proceedings of the Annual International Conference of the Florida Artificial Intelligence Research Society (FLAIRS),", "citeRegEx": "Girju and Moldovan,? \\Q2002\\E", "shortCiteRegEx": "Girju and Moldovan", "year": 2002}, {"title": "Shallow semantic parsing based on framenet, verbnet and propbank", "author": ["Giuglea", "A.-M", "A. Moschitti"], "venue": "In Proceedings of the the 17th European Conference on Artificial Intelligence (ECAI", "citeRegEx": "Giuglea et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Giuglea et al\\.", "year": 2006}, {"title": "A probabilistic classification approach for lexical textual entailment", "author": ["O. Glickman", "I. Dagan", "M. Koppel"], "venue": "In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)", "citeRegEx": "Glickman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Glickman et al\\.", "year": 2005}, {"title": "Commonsense causal reasoning using millions of personal stories", "author": ["A.S. Gordon", "C.A. Bejan", "K. Sagae"], "venue": "In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)", "citeRegEx": "Gordon et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 2011}, {"title": "Robust textual inference via graph matching", "author": ["A.D. Haghighi"], "venue": "Proceedings of the Human Language Technology Conference Conference on Empirical Methods in Natural Language Processing (HLT EMNLP).", "citeRegEx": "Haghighi,? 2005", "shortCiteRegEx": "Haghighi", "year": 2005}, {"title": "Using discourse commitments to recognize textual entailment", "author": ["A. Hickl"], "venue": "Proceedings of the International Conference on Computational Linguistics (COLING).", "citeRegEx": "Hickl,? 2008", "shortCiteRegEx": "Hickl", "year": 2008}, {"title": "Fastus: A finite-state processor for information extraction from real-world text", "author": ["J.R. Hobbs", "J. Bear", "D. Israel", "M. Tyson"], "venue": "In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Hobbs et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Hobbs et al\\.", "year": 1993}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (HLT)", "author": ["R. Hoffmann", "C. Zhang", "X. Ling", "L. Zettlemoyer", "D.S. Weld"], "venue": null, "citeRegEx": "Hoffmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "Learning 5000 relational extractors", "author": ["R. Hoffmann", "C. Zhang", "D.S. Weld"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Hoffmann et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2010}, {"title": "Scaling web-based acquisition of entailment relations", "author": ["I.S. Idan", "H. Tanev", "I. Dagan"], "venue": "In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP),", "citeRegEx": "Idan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Idan et al\\.", "year": 2004}, {"title": "Extracting collective expectations about the future from large text collections", "author": ["A. Jatowt", "C. Yeung"], "venue": "In Proceedings of the ACM Conference on Information and Knowledge Management (CIKM)", "citeRegEx": "Jatowt and Yeung,? \\Q2011\\E", "shortCiteRegEx": "Jatowt and Yeung", "year": 2011}, {"title": "Avatar information extraction system", "author": ["T.S. Jayram", "R. Krishnamurthy", "S. Raghavan", "S. Vaithyanathan", "H. Zhu"], "venue": "IEEE Data Engineering Bulletin,", "citeRegEx": "Jayram et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Jayram et al\\.", "year": 2006}, {"title": "A probabilistic model for online document clustering with application to novelty detection", "author": ["Z.G. Jian Zhang", "Y. Yang"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS)", "citeRegEx": "Zhang and Yang,? \\Q2004\\E", "shortCiteRegEx": "Zhang and Yang", "year": 2004}, {"title": "A systematic exploration of the feature space for relation extraction", "author": ["J. Jiang", "C. Zhai"], "venue": "In Proceedings of the Human Language Technologies and the Conference of the North American Chapter of the Association for Computational Linguistics (HLT NAACL),", "citeRegEx": "Jiang and Zhai,? \\Q2007\\E", "shortCiteRegEx": "Jiang and Zhai", "year": 2007}, {"title": "Structured output prediction with support vector machines", "author": ["T. Joachims"], "venue": "Yeung, D.-Y., Kwok, J., Fred, A., Roli, F., & de Ridder, D. (Eds.), Structural, Syntactic, and Statistical Pattern Recognition, Vol. 4109 of Lecture Notes in Computer Science, pp. 1\u20137. Springer Berlin / Heidelberg.", "citeRegEx": "Joachims,? 2006", "shortCiteRegEx": "Joachims", "year": 2006}, {"title": "Movie reviews and revenues: An experiment in text regression. In Proceedings of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT)", "author": ["M. Joshi", "D. Das", "K. Gimpel", "N.A. Smith"], "venue": null, "citeRegEx": "Joshi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2010}, {"title": "Combining lexical, syntactic and semantic features with maximum entropy models for information extraction", "author": ["N. Kambhatla"], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), pp. 178\u2013181.", "citeRegEx": "Kambhatla,? 2004", "shortCiteRegEx": "Kambhatla", "year": 2004}, {"title": "Knowledge-based acquisition of causal relationships in text", "author": ["R. Kaplan", "G. Berry-Rogghe"], "venue": "Knowledge Acquisition,", "citeRegEx": "Kaplan and Berry.Rogghe,? \\Q1991\\E", "shortCiteRegEx": "Kaplan and Berry.Rogghe", "year": 1991}, {"title": "Extracting causal knowledge from a medical database using graphical patterns", "author": ["C. Khoo", "S. Chan", "Y. Niu"], "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Khoo et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Khoo et al\\.", "year": 2000}, {"title": "Supervenience and mind", "author": ["J. Kim"], "venue": "Selected Philosophical Essays.", "citeRegEx": "Kim,? 1993", "shortCiteRegEx": "Kim", "year": 1993}, {"title": "Extending verbnet with novel verb classes", "author": ["K. Kipper"], "venue": "Proceedings of the International Conference on Language Resources and Evaluation (LREC).", "citeRegEx": "Kipper,? 2006", "shortCiteRegEx": "Kipper", "year": 2006}, {"title": "Crowdsourcing user studies with mechanical turk", "author": ["A. Kittur", "H. Chi", "B. Suh"], "venue": "In Proceedings of the ACM CHI Conference on Human Factors in Computing Systems is the premier International Conference of human-computer interaction (CHI)", "citeRegEx": "Kittur et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kittur et al\\.", "year": 2008}, {"title": "Temporal dynamics of on-line information systems", "author": ["J. Kleinberg"], "venue": "Data Stream Management: Processing High-Speed Data Streams. Springer.", "citeRegEx": "Kleinberg,? 2006", "shortCiteRegEx": "Kleinberg", "year": 2006}, {"title": "Bursty and hierarchical structure in streams", "author": ["J. Kleinberg"], "venue": "Proceedings of the Annual ACM SIGKDD Conference (KDD).", "citeRegEx": "Kleinberg,? 2002", "shortCiteRegEx": "Kleinberg", "year": 2002}, {"title": "Kernel conditional random fields: Representation and clique selection", "author": ["J. Lafferty", "X. Zhu", "Y. Liu"], "venue": "In The 21st International Conference on Machine Learning (ICML)", "citeRegEx": "Lafferty et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2004}, {"title": "Informality judgment at sentence level and experiments with formality score", "author": ["S. Lahiri", "P. Mitra", "X. Lu"], "venue": "In Proceedings of the 12th International Conference on Computational Linguistics and Intelligent Text Processing (CICLing)", "citeRegEx": "Lahiri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lahiri et al\\.", "year": 2011}, {"title": "The measurement of observer agreement for categorical data", "author": ["Landis"], "venue": null, "citeRegEx": "Landis,? \\Q1977\\E", "shortCiteRegEx": "Landis", "year": 1977}, {"title": "Learning sentence-internal temporal relations", "author": ["M. Lapata", "A. Lascarides"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Lapata and Lascarides,? \\Q2006\\E", "shortCiteRegEx": "Lapata and Lascarides", "year": 2006}, {"title": "An algorithm for pronominal anaphora resolution", "author": ["S. Lappin", "H. Leass"], "venue": "Computational Linguistics,", "citeRegEx": "Lappin and Leass,? \\Q1994\\E", "shortCiteRegEx": "Lappin and Leass", "year": 1994}, {"title": "Resource description framework (rdf) model and syntax specification", "author": ["O. Lassila", "R.R. Swick", "W. Wide", "W. Consortium"], "venue": null, "citeRegEx": "Lassila et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Lassila et al\\.", "year": 1998}, {"title": "Building Large Knowledge-Based Systems: Representation and Inference in the Cyc Project", "author": ["D.B. Lenat", "R.V. Guha"], "venue": null, "citeRegEx": "Lenat and Guha,? \\Q1990\\E", "shortCiteRegEx": "Lenat and Guha", "year": 1990}, {"title": "A preliminary analysis of causative verbs in english", "author": ["B. Levin", "M.R. Hovav"], "venue": "Lingua,", "citeRegEx": "Levin and Hovav,? \\Q1994\\E", "shortCiteRegEx": "Levin and Hovav", "year": 1994}, {"title": "Dirt-discovery of inference rules from text", "author": ["D. Lin", "P. Pantel"], "venue": "In Proceedings of the Annual ACM SIGKDD Conference (KDD)", "citeRegEx": "Lin and Pantel,? \\Q2001\\E", "shortCiteRegEx": "Lin and Pantel", "year": 2001}, {"title": "Temporal information extraction", "author": ["X. Ling", "D. Weld"], "venue": "In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)", "citeRegEx": "Ling and Weld,? \\Q2010\\E", "shortCiteRegEx": "Ling and Weld", "year": 2010}, {"title": "Conceptnet: A practical commonsense reasoning toolkit", "author": ["H. Liu", "P. Singh"], "venue": "BT Technology Journal,", "citeRegEx": "Liu and Singh,? \\Q2004\\E", "shortCiteRegEx": "Liu and Singh", "year": 2004}, {"title": "Document classification on neural networks using only positive examples", "author": ["L.M. Manevitz", "M. Yousef"], "venue": "In Proceedings of 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),", "citeRegEx": "Manevitz and Yousef,? \\Q2000\\E", "shortCiteRegEx": "Manevitz and Yousef", "year": 2000}, {"title": "One-class svms for document classification", "author": ["L.M. Manevitz", "M. Yousef", "N. Cristianini", "J. Shawe-Taylor", "B. Williamson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Manevitz et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Manevitz et al\\.", "year": 2001}, {"title": "Inferring temporal ordering of events in news. In Proceedings of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT)", "author": ["I. Mani", "B. Schiffman", "J. Zhang"], "venue": null, "citeRegEx": "Mani et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Mani et al\\.", "year": 2003}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["M. Marneffe", "B. MacCartney", "C. Manning"], "venue": "In Proceedings of the International Conference on Language Resources and Evaluation (LREC)", "citeRegEx": "Marneffe et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2006}, {"title": "Named entity recognition from diverse text types", "author": ["D. Maynard", "V. Tablan", "C. Ursu", "H. Cunningham", "Y. Wilks"], "venue": "In Recent Advances in Natural Language Processing Conference (RANLP),", "citeRegEx": "Maynard et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Maynard et al\\.", "year": 2001}, {"title": "Extracting gene pathway relations using a hybrid grammar: The arizona relation", "author": ["D.M. Mcdonald", "H. Chen", "H. Su", "B.B. Marshall"], "venue": "parser. Bioinformatics,", "citeRegEx": "Mcdonald et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Mcdonald et al\\.", "year": 2004}, {"title": "Quantitative analysis of culture using millions of digitized books", "author": ["J. Michel", "Y. Shen", "A. Aiden", "A. Veres", "M. Gray", "Google Books Team", "J. Pickett", "D. Hoiberg", "D. Clancy", "P. Norvig", "J. Orwant", "S. Pinker", "M. Nowak", "E. Aiden"], "venue": null, "citeRegEx": "Michel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Michel et al\\.", "year": 2011}, {"title": "Wordnet: A lexical database for english", "author": ["G. Miller"], "venue": "Journal of Communications of the ACM (CACM), 38, 39\u201341.", "citeRegEx": "Miller,? 1995", "shortCiteRegEx": "Miller", "year": 1995}, {"title": "Predicting movie sales from blogger sentiment", "author": ["G. Mishne"], "venue": "Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI) Spring Symposium.", "citeRegEx": "Mishne,? 2006", "shortCiteRegEx": "Mishne", "year": 2006}, {"title": "Vector-based models of semantic composition", "author": ["J. Mitchell", "M. Lapata"], "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Mitchell and Lapata,? \\Q2008\\E", "shortCiteRegEx": "Mitchell and Lapata", "year": 2008}, {"title": "Learning from positive data", "author": ["S. Muggleton"], "venue": "Proceedings of the Inductive Logic Programming Workshop, pp. 358\u2013376.", "citeRegEx": "Muggleton,? 1996", "shortCiteRegEx": "Muggleton", "year": 1996}, {"title": "Joint distant and direct supervision for relation extraction", "author": ["Nguyen", "T.-V. T", "A. Moschitti"], "venue": "In Proceedings of the The 5th International Joint Conference on Natural Language Processing (IJCNLP)", "citeRegEx": "Nguyen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2011}, {"title": "Convolution kernels on constituent, dependency and sequential structures for relation extraction", "author": ["Nguyen", "T.-V. T", "A. Moschitti", "G. Riccardi"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Nguyen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2009}, {"title": "Causality: Models, Reasoning, and Inference", "author": ["J. Pearl"], "venue": "Cambridge University Press.", "citeRegEx": "Pearl,? 2000", "shortCiteRegEx": "Pearl", "year": 2000}, {"title": "Monolingual machine translation for paraphrase generation", "author": ["C. Quirk", "C. Brockett", "W. Dolan"], "venue": "In Proceedings the Conference on Empirical Methods on Natural Language Processing (EMNLP),", "citeRegEx": "Quirk et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Quirk et al\\.", "year": 2004}, {"title": "Development and application of a metric to semantic nets", "author": ["R. Rada", "H. Mili", "E. Bicknell", "M. Blettner"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "Rada et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Rada et al\\.", "year": 1989}, {"title": "Predicting the news of tomorrow using patterns in web search queries", "author": ["K. Radinsky", "S. Davidovich", "S. Markovitch"], "venue": "In Proceedings of the IEEE/WIC International Conference on Web Intelligence (WI)", "citeRegEx": "Radinsky et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Radinsky et al\\.", "year": 2008}, {"title": "Robust textual inference via learning and abductive reasoning", "author": ["R. Raina", "A.Y. Ng", "C.D. Manning"], "venue": "In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)", "citeRegEx": "Raina et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Raina et al\\.", "year": 2005}, {"title": "Automatic derivation of surface text patterns for a maximum entropy based question answering system", "author": ["D. Ravichandran", "A. Ittycheriah", "S. Roukos"], "venue": "In Proceedings of the North American Chapter of the Association for Computational Linguistics: Short Papers (NAACL Short),", "citeRegEx": "Ravichandran et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Ravichandran et al\\.", "year": 2003}, {"title": "Automatically constructing a dictionary for information extraction tasks", "author": ["E. Riloff"], "venue": "Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI), pp. 811\u2013816.", "citeRegEx": "Riloff,? 1993", "shortCiteRegEx": "Riloff", "year": 1993}, {"title": "Automatically Generating Extraction Patterns from Untagged Text", "author": ["E. Riloff"], "venue": "Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI).", "citeRegEx": "Riloff,? 1996", "shortCiteRegEx": "Riloff", "year": 1996}, {"title": "Learning dictionaries for information extraction by multi-level bootstrapping", "author": ["E. Riloff", "R. Jones"], "venue": "In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)", "citeRegEx": "Riloff and Jones,? \\Q1999\\E", "shortCiteRegEx": "Riloff and Jones", "year": 1999}, {"title": "Using corpus statistics on entities to improve semisupervised relation extraction from the web", "author": ["B. Rosenfeld", "R. Feldman"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Rosenfeld and Feldman,? \\Q2007\\E", "shortCiteRegEx": "Rosenfeld and Feldman", "year": 2007}, {"title": "Information extraction", "author": ["S. Sarawagi"], "venue": "Foundations and Trends in Databases, 1 (3), 261\u2013377.", "citeRegEx": "Sarawagi,? 2008", "shortCiteRegEx": "Sarawagi", "year": 2008}, {"title": "Support vector method for novelty detection", "author": ["B. Sch\u00f6lkopf", "R. Williamson", "A. Smola", "J. Shawe-Taylor", "J. Platt"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Sch\u00f6lkopf et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Sch\u00f6lkopf et al\\.", "year": 2000}, {"title": "Sv estimation of a distribution\u2019s support", "author": ["B. Sch\u00f6lkopf", "R.C. Williamson", "A. Smola", "J. Shawe-Taylor"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS)", "citeRegEx": "Sch\u00f6lkopf et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Sch\u00f6lkopf et al\\.", "year": 1999}, {"title": "Can we derive general world knowledge from texts", "author": ["L. Schubert"], "venue": "Proceedings of the Second Conference on Human Language Technology (HLT).", "citeRegEx": "Schubert,? 2002", "shortCiteRegEx": "Schubert", "year": 2002}, {"title": "Connecting the dots between news articles", "author": ["D. Shahaf", "C. Guestrin"], "venue": "In Proceedings of the Annual ACM SIGKDD Conference (KDD)", "citeRegEx": "Shahaf and Guestrin,? \\Q2010\\E", "shortCiteRegEx": "Shahaf and Guestrin", "year": 2010}, {"title": "Declarative information extraction using datalog with embedded extraction predicates", "author": ["W. Shen", "A. Doan", "J.F. Naughton", "R. Ramakrishnan"], "venue": "In Proceedings of the Conference on Very Large Data Bases (VLDB),", "citeRegEx": "Shen et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2007}, {"title": "Putting pieces together: Combining framenet, verbnet and wordnet for robust semantic parsing", "author": ["L. Shi", "R. Mihalcea"], "venue": "In Proceedings of the Sixth International Conference on Intelligent Text Processing and Computational Linguistics (CICLing),", "citeRegEx": "Shi and Mihalcea,? \\Q2005\\E", "shortCiteRegEx": "Shi and Mihalcea", "year": 2005}, {"title": "Preemptive information extraction using unrestricted relation discovery. In Proceedings of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT)", "author": ["Y. Shinyama", "S. Sekine"], "venue": null, "citeRegEx": "Shinyama and Sekine,? \\Q2006\\E", "shortCiteRegEx": "Shinyama and Sekine", "year": 2006}, {"title": "Extracting action and event semantics from web text", "author": ["A. Sil", "F. Huang", "A. Yates"], "venue": "In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI) Fall Symposium on Commonsense Knowledge", "citeRegEx": "Sil et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sil et al\\.", "year": 2010}, {"title": "Learning information extraction rules for semi-structured and free text", "author": ["S. Soderland"], "venue": "Machine Learning, 34.", "citeRegEx": "Soderland,? 1999", "shortCiteRegEx": "Soderland", "year": 1999}, {"title": "Wikirelate! computing semantic relatedness using wikipedia", "author": ["M. Strube", "S.P. Ponzetto"], "venue": "In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)", "citeRegEx": "Strube and Ponzetto,? \\Q2006\\E", "shortCiteRegEx": "Strube and Ponzetto", "year": 2006}, {"title": "Combining linguistic and statistical analysis to extract relations from web documents", "author": ["F.M. Suchanek"], "venue": "Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), pp. 712\u2013717.", "citeRegEx": "Suchanek,? 2006", "shortCiteRegEx": "Suchanek", "year": 2006}, {"title": "Yago: a core of semantic knowledge", "author": ["F.M. Suchanek", "G. Kasneci", "G. Weikum"], "venue": "In Proceedings of the International Conference on the World Wide Web (WWW)", "citeRegEx": "Suchanek et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Suchanek et al\\.", "year": 2007}, {"title": "Max-margin markov networks", "author": ["B. Taskar", "C. Guestrin", "D. Koller"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS)", "citeRegEx": "Taskar et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Taskar et al\\.", "year": 2003}, {"title": "A semantic approach to recognizing textual entailment", "author": ["M. Tatu", "D. Moldovan"], "venue": "In Proceedings of the Human Language Technology Conference Conference on Empirical Methods in Natural Language Processing (HLT EMNLP)", "citeRegEx": "Tatu and Moldovan,? \\Q2005\\E", "shortCiteRegEx": "Tatu and Moldovan", "year": 2005}, {"title": "Experiments with reasoning for temporal relations between events", "author": ["M. Tatu", "M. Srikanth"], "venue": "In Proceedings of the International Conference on Computational Linguistics (COLING)", "citeRegEx": "Tatu and Srikanth,? \\Q2008\\E", "shortCiteRegEx": "Tatu and Srikanth", "year": 2008}, {"title": "One class classification", "author": ["D. Tax"], "venue": "PhD thesis, Delft University of Technology.", "citeRegEx": "Tax,? 2001", "shortCiteRegEx": "Tax", "year": 2001}, {"title": "Support vector domain description", "author": ["D.M.J. Tax", "R.P.W. Duin"], "venue": "Pattern Recognition Letters,", "citeRegEx": "Tax and Duin,? \\Q1991\\E", "shortCiteRegEx": "Tax and Duin", "year": 1991}, {"title": "Expressing implicit semantic relations without supervision", "author": ["P.D. Turney"], "venue": "Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Turney,? 2006", "shortCiteRegEx": "Turney", "year": 2006}, {"title": "The Nature of Statistical Learning Theory", "author": ["V. Vapnik"], "venue": "Springer-Verlag, NY, USA.", "citeRegEx": "Vapnik,? 1995", "shortCiteRegEx": "Vapnik", "year": 1995}, {"title": "Understanding interobserver agreement: The kappa statistic", "author": ["A.J. Viera", "J.M. Garrett"], "venue": "Family Medicine,", "citeRegEx": "Viera and Garrett,? \\Q2005\\E", "shortCiteRegEx": "Viera and Garrett", "year": 2005}, {"title": "A re-examination of dependency path kernels for relation extraction", "author": ["M. Wang"], "venue": "Proceedings of the Third International Joint Conference on Natural Language Processing (ACL IJCNLP).", "citeRegEx": "Wang,? 2008", "shortCiteRegEx": "Wang", "year": 2008}, {"title": "Models of causation and causal verbs", "author": ["P. Wolff", "G. Song", "D. Driscoll"], "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Wolff et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Wolff et al\\.", "year": 2002}, {"title": "A study on retrospective and online event detection", "author": ["Y. Yang", "T. Pierce", "J. Carbonell"], "venue": "In Proceedings of ACM SIGIR Special Interest Group on Information Retrieval (SIGIR)", "citeRegEx": "Yang et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Yang et al\\.", "year": 1998}, {"title": "Studying how the past is remembered: Towards computational history through large scale text mining", "author": ["C. Yeung", "A. Jatowt"], "venue": "In Proceedings of the ACM Conference on Information and Knowledge Management (CIKM)", "citeRegEx": "Yeung and Jatowt,? \\Q2011\\E", "shortCiteRegEx": "Yeung and Jatowt", "year": 2011}, {"title": "Jointly identifying temporal relations with markov logic", "author": ["K. Yoshikawa", "S. Riedel", "M. Asahara", "Y. Matsumoto"], "venue": "In Proceedings of the Third International Joint Conference on Natural Language Processing (ACL IJCNLP)", "citeRegEx": "Yoshikawa et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yoshikawa et al\\.", "year": 2009}, {"title": "A machine learning approach to textual entailment recognition", "author": ["F.M. Zanzotto", "M. Pennacchiotti", "A. Moschitti"], "venue": "Natural Language Engineering,", "citeRegEx": "Zanzotto et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Zanzotto et al\\.", "year": 2009}, {"title": "Kernel methods for relation extraction", "author": ["D. Zelenko", "C. Aone", "A. Richardella"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Zelenko et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Zelenko et al\\.", "year": 2003}, {"title": "A composite kernel to extract relations between entities with both flat and structured features", "author": ["M. Zhang", "J. Zhang", "J. Su", "G. Zhou"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Zhang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2006}, {"title": "Extracting relations with integrated information using kernel methods", "author": ["S. Zhao", "R. Grishman"], "venue": "In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Zhao and Grishman,? \\Q2005\\E", "shortCiteRegEx": "Zhao and Grishman", "year": 2005}], "referenceMentions": [{"referenceID": 34, "context": ", Banko, Cafarella, Soderl, Broadhead, & Etzioni, 2007; Carlson, Betteridge, Kisiel, Settles, Hruschka, & Mitchell, 2010), little has been done in the area of causality extraction, with the works of Khoo, Chan, and Niu (2000) and Girju and Moldovan (2002) being notable exceptions.", "startOffset": 230, "endOffset": 256}, {"referenceID": 5, "context": "The Topic Tracking and Detection (TDT) community (Allan, 2002) has defined an event as \u201ca particular thing that happens at a specific time and place, along with all necessary preconditions and unavoidable consequences.", "startOffset": 49, "endOffset": 62}, {"referenceID": 53, "context": "Other philosophical theories consider events as exemplifications of properties by objects at times (Kim, 1993).", "startOffset": 99, "endOffset": 110}, {"referenceID": 31, "context": "The second approach describes events in a syntax-driven manner, where the event text is transformed into syntax-based components, such as noun phrases (Garcia, 1997; Khoo et al., 2000; Girju & Moldovan, 2002; Chan & Lam, 2005).", "startOffset": 151, "endOffset": 226}, {"referenceID": 52, "context": "The second approach describes events in a syntax-driven manner, where the event text is transformed into syntax-based components, such as noun phrases (Garcia, 1997; Khoo et al., 2000; Girju & Moldovan, 2002; Chan & Lam, 2005).", "startOffset": 151, "endOffset": 226}, {"referenceID": 51, "context": "Other philosophical theories consider events as exemplifications of properties by objects at times (Kim, 1993). For example, Caesar\u2019s death at 44 BC is Caesar\u2019s exemplification of the property of dying at time 44 BC. Those theories impose structure on events, where a change in one of the elements yields a different event. For example, Shakespear\u2019s death is a different event from Caesar\u2019s death, as the objects exemplifying the property are different. In this section, we will discuss a way to represent events following Kim\u2019s (1993) exemplification theory that will allow us to easily compare them, generalize them, and reason about them.", "startOffset": 100, "endOffset": 536}, {"referenceID": 53, "context": "This approach is inspired by Kim\u2019s (1993) property-exemplification of events theory.", "startOffset": 29, "endOffset": 42}, {"referenceID": 54, "context": "Specifically, we use the VerbNet (Kipper, 2006) ontology, which is one of the largest English verb lexicons.", "startOffset": 33, "endOffset": 47}, {"referenceID": 76, "context": "It has mapping to many other online resources, such as Wordnet (Miller, 1995).", "startOffset": 63, "endOffset": 77}, {"referenceID": 10, "context": "These methods usually estimate the prior probability of a relation by examining the frequency of its pattern in a large corpus, such as the Web (Banko et al., 2007).", "startOffset": 144, "endOffset": 164}, {"referenceID": 76, "context": "The entity graph Go is composed of concepts from Wikipedia, ConceptNet (Liu & Singh, 2004), WordNet (Miller, 1995), Yago (Suchanek, Kasneci, & Weikum, 2007), and OpenCyc; the billion labeled edges of the graph Go are the predicates of those ontologies.", "startOffset": 100, "endOffset": 114}, {"referenceID": 11, "context": "The concepts are interlinked by humans as part of the Linked Data project (Bizer et al., 2009).", "startOffset": 74, "endOffset": 94}, {"referenceID": 11, "context": "The concepts are interlinked by humans as part of the Linked Data project (Bizer et al., 2009). The goal of Bizer et al.\u2019s (2009) Linked Data project is to extend the Web by interlinking multiple datasets as RDF and by setting RDF links between data items from different data sources.", "startOffset": 75, "endOffset": 130}, {"referenceID": 76, "context": "Root forms of inflected words are extracted using a morphological analyzer derived from WordNet (Miller, 1995) stemmer.", "startOffset": 96, "endOffset": 110}, {"referenceID": 54, "context": "The class of the verb is identified using the VerbNet vocabulary (Kipper, 2006), e.", "startOffset": 65, "endOffset": 79}, {"referenceID": 72, "context": "If no template can be matched, the sentence is transformed into a typed-dependency graph of grammatical relations (Marneffe et al., 2006).", "startOffset": 114, "endOffset": 137}, {"referenceID": 77, "context": "Social media were used to predict riots (Kalev, 2011) and movie box office sales (Asur & Huberman, 2010; Joshi, Das, Gimpel, & Smith, 2010; Mishne, 2006).", "startOffset": 81, "endOffset": 153}, {"referenceID": 33, "context": "Ginsberg et al. (2009) used queries for predicting H1N1 influenza outbreaks.", "startOffset": 0, "endOffset": 23}, {"referenceID": 33, "context": "Ginsberg et al. (2009) used queries for predicting H1N1 influenza outbreaks. In the context of causality recognition, Gordon, Bejan, and Sagae (2011) present a methodology for mining blogs to extract common-sense causality.", "startOffset": 0, "endOffset": 150}, {"referenceID": 33, "context": "Ginsberg et al. (2009) used queries for predicting H1N1 influenza outbreaks. In the context of causality recognition, Gordon, Bejan, and Sagae (2011) present a methodology for mining blogs to extract common-sense causality. The evaluation is done on a human-labeled dataset where each test consists of a fact and two possible effects. Applying point-mutual information to personal blog stories, the authors select the best prediction candidate. The work differs from ours in that the authors focus on personal commonsense mining and do not consider whether their predictions actually occurred. Other works focused on predicting Web content change itself. For example, Kleinberg (2002, 2006) developed general techniques for summarizing the temporal dynamics of textual content and for identifying bursts of terms within content. Similarly, Amodeo, Blanco, and Brefeld (2011) built a time series model over publication dates of documents relevant to a query in order to predict future bursts.", "startOffset": 0, "endOffset": 875}, {"referenceID": 7, "context": "For a more detailed overview we refer the reader to the survey by Androutsopoulos and Malakasiotis (2010). We then discuss the specific task of causality extraction from text in Section 5.", "startOffset": 66, "endOffset": 106}, {"referenceID": 38, "context": "Similarly, other methods measure the semantic distance similarity between the words in text (Haghighi, 2005), usually exploiting", "startOffset": 92, "endOffset": 108}, {"referenceID": 39, "context": "The last set of approaches represents the two texts in a single feature vector and trains a machine learning algorithm, which later, given two new texts represented via a vector, can determine whether they entail each other (Bos & Markert, 2005; Burchardt, Pennacchiotti, Thater, & Pinkal, 2009; Hickl, 2008).", "startOffset": 224, "endOffset": 308}, {"referenceID": 38, "context": "Other features usually include polarity (Haghighi, 2005), whether the theorem prover managed to prove entailment (Bos & Markert, 2005), or tagging of the named entities to the categories people, organizations, or locations.", "startOffset": 40, "endOffset": 56}, {"referenceID": 36, "context": "For example, Glickman et al. (2005) show a naive Bayes classifier trained on lexical features, i.", "startOffset": 13, "endOffset": 36}, {"referenceID": 7, "context": "Androutsopoulos and Malakasiotis (2010) mention that no benchmarks exist to evaluate this task, and the most common and costly approach is to evaluate using human judges.", "startOffset": 0, "endOffset": 40}, {"referenceID": 7, "context": "Androutsopoulos and Malakasiotis (2010) mention that no benchmarks exist to evaluate this task, and the most common and costly approach is to evaluate using human judges. We also encountered this difficulty in our own task, and performed human evaluation. TE generation methods can be divided into two types: those that use machine translation techniques and those that use template-based techniques. Those that use machine translation techniques try to calculate the set of transformations with the highest probability, using a training corpus. Quirk, Brockett, and Dolan (2004) cluster news articles referring to the same event, select pairs of similar sentences, and apply the aforementioned techniques.", "startOffset": 0, "endOffset": 580}, {"referenceID": 92, "context": "The most closely related tasks to ours are those of entity extraction and relation extraction; for the rest we refer the reader to the survey by Sarawagi (2008). The former task, similar to our process of extracting concepts, deals with extracting noun phrases from text.", "startOffset": 145, "endOffset": 161}, {"referenceID": 88, "context": "Rule-based methods (Riloff, 1993; Riloff & Jones, 1999; Jayram, Krishnamurthy, Raghavan, Vaithyanathan, & Zhu, 2006; Shen, Doan, Naughton, & Ramakrishnan, 2007; Ciravegna, 2001; Maynard, Tablan, Ursu, Cunningham, & Wilks, 2001; Hobbs, Bear, Israel, & Tyson, 1993) define contextual patterns consisting a regular expression over features of the entities in the text (e.", "startOffset": 19, "endOffset": 263}, {"referenceID": 25, "context": "Rule-based methods (Riloff, 1993; Riloff & Jones, 1999; Jayram, Krishnamurthy, Raghavan, Vaithyanathan, & Zhu, 2006; Shen, Doan, Naughton, & Ramakrishnan, 2007; Ciravegna, 2001; Maynard, Tablan, Ursu, Cunningham, & Wilks, 2001; Hobbs, Bear, Israel, & Tyson, 1993) define contextual patterns consisting a regular expression over features of the entities in the text (e.", "startOffset": 19, "endOffset": 263}, {"referenceID": 25, "context": "Those rules are either manually coded by a domain expert or learned using bottom-up (Ciravegna, 2001; Califf & Mooney, 1999) or top-down learners (Soderland, 1999).", "startOffset": 84, "endOffset": 124}, {"referenceID": 101, "context": "Those rules are either manually coded by a domain expert or learned using bottom-up (Ciravegna, 2001; Califf & Mooney, 1999) or top-down learners (Soderland, 1999).", "startOffset": 146, "endOffset": 163}, {"referenceID": 95, "context": "Relation extraction has been developed widely in the last years from large text corpora (Schubert, 2002) and, in particular, from different Web resources, such as general Web content (Banko et al.", "startOffset": 88, "endOffset": 104}, {"referenceID": 10, "context": "Relation extraction has been developed widely in the last years from large text corpora (Schubert, 2002) and, in particular, from different Web resources, such as general Web content (Banko et al., 2007; Carlson et al., 2010; Hoffmann, Zhang, & Weld, 2010), blogs (Jayram et al.", "startOffset": 183, "endOffset": 256}, {"referenceID": 20, "context": "Relation extraction has been developed widely in the last years from large text corpora (Schubert, 2002) and, in particular, from different Web resources, such as general Web content (Banko et al., 2007; Carlson et al., 2010; Hoffmann, Zhang, & Weld, 2010), blogs (Jayram et al.", "startOffset": 183, "endOffset": 256}, {"referenceID": 45, "context": ", 2010; Hoffmann, Zhang, & Weld, 2010), blogs (Jayram et al., 2006), Wikipedia (Suchanek et al.", "startOffset": 46, "endOffset": 67}, {"referenceID": 104, "context": ", 2006), Wikipedia (Suchanek et al., 2007), and news articles (e.", "startOffset": 19, "endOffset": 42}, {"referenceID": 50, "context": "Many feature-based methods (Jiang & Zhai, 2007; Kambhatla, 2004; Suchanek, 2006) and rule-based methods (Aitken, 2002; Mcdonald, Chen, Su, & Marshall, 2004; Jayram et al.", "startOffset": 27, "endOffset": 80}, {"referenceID": 103, "context": "Many feature-based methods (Jiang & Zhai, 2007; Kambhatla, 2004; Suchanek, 2006) and rule-based methods (Aitken, 2002; Mcdonald, Chen, Su, & Marshall, 2004; Jayram et al.", "startOffset": 27, "endOffset": 80}, {"referenceID": 4, "context": "Many feature-based methods (Jiang & Zhai, 2007; Kambhatla, 2004; Suchanek, 2006) and rule-based methods (Aitken, 2002; Mcdonald, Chen, Su, & Marshall, 2004; Jayram et al., 2006; Shen et al., 2007) have been developed for this task.", "startOffset": 104, "endOffset": 196}, {"referenceID": 45, "context": "Many feature-based methods (Jiang & Zhai, 2007; Kambhatla, 2004; Suchanek, 2006) and rule-based methods (Aitken, 2002; Mcdonald, Chen, Su, & Marshall, 2004; Jayram et al., 2006; Shen et al., 2007) have been developed for this task.", "startOffset": 104, "endOffset": 196}, {"referenceID": 97, "context": "Many feature-based methods (Jiang & Zhai, 2007; Kambhatla, 2004; Suchanek, 2006) and rule-based methods (Aitken, 2002; Mcdonald, Chen, Su, & Marshall, 2004; Jayram et al., 2006; Shen et al., 2007) have been developed for this task.", "startOffset": 104, "endOffset": 196}, {"referenceID": 113, "context": "Labeled training examples, from which those feature are extracted, are then fed into a machine learning classifier, sometimes using transformations such as kernels (Zhao & Grishman, 2005; Zhang, Zhang, Su, & Zhou, 2006; Zelenko, Aone, & Richardella, 2003; Wang, 2008; Culotta & Sorensen, 2004; Bunescu & Mooney, 2005; Nguyen, Moschitti, & Riccardi, 2009), which, given new unseen entities, will be able to classify them into those categories.", "startOffset": 164, "endOffset": 354}, {"referenceID": 10, "context": "Most works in this domain focus on large collections, such as the Web, where labeling all entities and relations is infeasible (Agichtein & Gravano, 2000; Banko et al., 2007; Bunescu & Mooney, 2007; Rosenfeld & Feldman, 2007; Shinyama & Sekine, 2006; Turney, 2006).", "startOffset": 127, "endOffset": 264}, {"referenceID": 110, "context": "Most works in this domain focus on large collections, such as the Web, where labeling all entities and relations is infeasible (Agichtein & Gravano, 2000; Banko et al., 2007; Bunescu & Mooney, 2007; Rosenfeld & Feldman, 2007; Shinyama & Sekine, 2006; Turney, 2006).", "startOffset": 127, "endOffset": 264}, {"referenceID": 22, "context": "Most of these approaches (Ling & Weld, 2010; Mani, Schiffman, & Zhang, 2003; Lapata & Lascarides, 2006; Chambers et al., 2007; Tatu & Srikanth, 2008; Yoshikawa, Riedel, Asahara, & Matsumoto, 2009) learn classifiers that predict a temporal order of a pair of events from predefined features of the pair.", "startOffset": 25, "endOffset": 196}, {"referenceID": 5, "context": "This area includes several tasks (Allan, 2002).", "startOffset": 33, "endOffset": 46}, {"referenceID": 5, "context": "This area includes several tasks (Allan, 2002). In all of them, multiple, heterogenous new sources are used, including audio. The story segmentation task aims to segment data into its constituent stories. The topic tracking task \u2013 e.g., the work by Shahaf and Guestrin (2010) \u2013 aims to find all stories discussing a certain topic.", "startOffset": 34, "endOffset": 276}, {"referenceID": 5, "context": "This area includes several tasks (Allan, 2002). In all of them, multiple, heterogenous new sources are used, including audio. The story segmentation task aims to segment data into its constituent stories. The topic tracking task \u2013 e.g., the work by Shahaf and Guestrin (2010) \u2013 aims to find all stories discussing a certain topic. A subtask of this is the link detection task which, given a pair of stories, aims to classify whether they are on the same topic. The topic detection task \u2013 e.g. the works by Ahmed, Ho, Eisenstein, Xing, Smola, and Teo (2011) and Yang, Pierce, and Carbonell (1998) \u2013 aims to detect clusters of topic-cohesive stories in a stream of topics.", "startOffset": 34, "endOffset": 557}, {"referenceID": 5, "context": "This area includes several tasks (Allan, 2002). In all of them, multiple, heterogenous new sources are used, including audio. The story segmentation task aims to segment data into its constituent stories. The topic tracking task \u2013 e.g., the work by Shahaf and Guestrin (2010) \u2013 aims to find all stories discussing a certain topic. A subtask of this is the link detection task which, given a pair of stories, aims to classify whether they are on the same topic. The topic detection task \u2013 e.g. the works by Ahmed, Ho, Eisenstein, Xing, Smola, and Teo (2011) and Yang, Pierce, and Carbonell (1998) \u2013 aims to detect clusters of topic-cohesive stories in a stream of topics.", "startOffset": 34, "endOffset": 596}, {"referenceID": 51, "context": "Kaplan and Berry-Rogghe (1991) used scientific texts to create a manually designed set of propositions which were later applied on", "startOffset": 0, "endOffset": 31}, {"referenceID": 31, "context": "For example, Garcia (1997) manually identified 23 causative verb groups (e.", "startOffset": 13, "endOffset": 27}, {"referenceID": 31, "context": "For example, Garcia (1997) manually identified 23 causative verb groups (e.g., to result in, to lead to, etc.). If a sentence contained one of those verbs, it was classified as containing a causation relation. A precision of 85% was reported. Khoo et al. (2000) used manually extracted graphical patterns based on syntactic parse trees, reporting accuracy of about 68% on an English medical database.", "startOffset": 13, "endOffset": 262}, {"referenceID": 31, "context": "For example, Garcia (1997) manually identified 23 causative verb groups (e.g., to result in, to lead to, etc.). If a sentence contained one of those verbs, it was classified as containing a causation relation. A precision of 85% was reported. Khoo et al. (2000) used manually extracted graphical patterns based on syntactic parse trees, reporting accuracy of about 68% on an English medical database. Similarly, Girju and Moldovan (2002) defined lexicon-syntactic patterns (pairs of noun phrases with a causative verb in between) with additional semantic constraints.", "startOffset": 13, "endOffset": 438}, {"referenceID": 13, "context": "For example, Blanco et al. (2008) and Sil et al.", "startOffset": 13, "endOffset": 34}, {"referenceID": 13, "context": "For example, Blanco et al. (2008) and Sil et al. (2010) use syntactic patterns as features that are later fed into classifiers, whose output is whether the text implies causality or the cause and effect themselves.", "startOffset": 13, "endOffset": 56}, {"referenceID": 89, "context": "There have been many works on design inference rules to discover extraction patterns for a given relation using training examples (Riloff, 1996; Riloff & Jones, 1999; Agichtein & Gravano, 2000; Lin & Pantel, 2001).", "startOffset": 130, "endOffset": 213}, {"referenceID": 23, "context": "Specifically, Chan and Lam (2005) dealt with the problem of creating syntactic patterns for cause-effect extraction.", "startOffset": 14, "endOffset": 34}, {"referenceID": 82, "context": "The functional causal model (Pearl, 2000) assumes a set of observables X1 .", "startOffset": 28, "endOffset": 41}, {"referenceID": 48, "context": ", structured support vector machines (Joachims, 2006).", "startOffset": 37, "endOffset": 53}, {"referenceID": 108, "context": "Most works (Tax, 2001; Manevitz & Yousef, 2000; Manevitz, Yousef, Cristianini, ShaweTaylor, & Williamson, 2001) in this domain develop algorithms that use one-class SVM (Vapnik, 1995) and learn the support using only positive distribution.", "startOffset": 11, "endOffset": 111}, {"referenceID": 111, "context": "Most works (Tax, 2001; Manevitz & Yousef, 2000; Manevitz, Yousef, Cristianini, ShaweTaylor, & Williamson, 2001) in this domain develop algorithms that use one-class SVM (Vapnik, 1995) and learn the support using only positive distribution.", "startOffset": 169, "endOffset": 183}, {"referenceID": 108, "context": "Some also use kernel tricks before finding this sphere (Tax, 2001).", "startOffset": 55, "endOffset": 66}, {"referenceID": 28, "context": "Some theoretical studies of the possibility of learning from only positive unlabeled data are provided in the work by Denis (1998) (probably approximately correct (PAC) learning) and Muggleton (1996) (Bayesian learning).", "startOffset": 118, "endOffset": 131}, {"referenceID": 28, "context": "Some theoretical studies of the possibility of learning from only positive unlabeled data are provided in the work by Denis (1998) (probably approximately correct (PAC) learning) and Muggleton (1996) (Bayesian learning).", "startOffset": 118, "endOffset": 200}, {"referenceID": 28, "context": "Some theoretical studies of the possibility of learning from only positive unlabeled data are provided in the work by Denis (1998) (probably approximately correct (PAC) learning) and Muggleton (1996) (Bayesian learning). Most works (Tax, 2001; Manevitz & Yousef, 2000; Manevitz, Yousef, Cristianini, ShaweTaylor, & Williamson, 2001) in this domain develop algorithms that use one-class SVM (Vapnik, 1995) and learn the support using only positive distribution. They construct decision boundaries around the positive examples to differentiate them from all possible negative data. Tax and Duin (1991) use a hyper-sphere with some defined radius around some of the positive class points (support vector data description method).", "startOffset": 118, "endOffset": 600}, {"referenceID": 29, "context": ", as proposed by Do et al. (2011) can provide higher analysis of the data from the entire text rather than just the titles.", "startOffset": 17, "endOffset": 34}], "year": 2012, "abstractText": "Given a current news event, we tackle the problem of generating plausible predictions of future events it might cause. We present a new methodology for modeling and predicting such future news events using machine learning and data mining techniques. Our Pundit algorithm generalizes examples of causality pairs to infer a causality predictor. To obtain precisely labeled causality examples, we mine 150 years of news articles and apply semantic natural language modeling techniques to headlines containing certain predefined causality patterns. For generalization, the model uses a vast number of world knowledge ontologies. Empirical evaluation on real news articles shows that our Pundit algorithm performs as well as non-expert humans.", "creator": "TeX"}}}