{"id": "1402.0578", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2014", "title": "Natural Language Inference for Arabic Using Extended Tree Edit Distance with Subtrees", "abstract": "Many natural language processing (NLP) applications require the computation of similarities between pairs of syntactic or semantic trees. Many researchers have used tree edit distance for this task, but this technique suffers from the drawback that it deals with single node operations only. We have extended the standard tree edit distance algorithm to deal with subtree transformation operations as well as single nodes. The extended algorithm with subtree operations, TED+ST, is more effective and flexible than the standard algorithm, especially for applications that pay attention to relations among nodes (e.g. in linguistic trees, deleting a modifier subtree should be cheaper than the sum of deleting its components individually). We describe the use of TED+ST for checking entailment between two Arabic text snippets. The preliminary results of using TED+ST were encouraging when compared with two string-based approaches and with the standard algorithm.", "histories": [["v1", "Tue, 4 Feb 2014 01:40:42 GMT  (431kb)", "http://arxiv.org/abs/1402.0578v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["maytham alabbas", "allan ramsay"], "accepted": false, "id": "1402.0578"}, "pdf": {"name": "1402.0578.pdf", "metadata": {"source": "CRF", "title": "Natural Language Inference for Arabic Using Extended Tree Edit Distance with Subtrees", "authors": ["Maytham Alabbas", "Allan Ramsay"], "emails": ["maytham.alabbas@gmail.com", "Allan.Ramsay@manchester.ac.uk"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of us are able to move to another world, to move to another world, to move to another world, to move to another world."}, {"heading": "2. Zhang-Shasha\u2019s TED Algorithm", "text": "In fact, the fact is that most of them are able to outdo themselves and that they are able to outdo themselves. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "3. Extended TED with Subtree Operations", "text": "The main weakness of the ZS-TED algorithm is that it is unable to perform sub-tree transformations (i.e. delete sub-tree, insert sub-tree, and replace sub-tree).The output of ZSTED is the lowest cost sequence of operations on individual nodes. We expand it to find the lowest cost sequence of operations on nodes and sub-trees, TED + ST, as follows: 1. Run ZS-TED and calculate the default alignment from the results (algorithm 1); 2. Go over the alignment and sub-tree operations. Where a sequence of identical operations applies to a set of nodes from a sub-tree, they are replaced by a single operation, the cost of which is determined by an appropriate function of the cost of each node (algorithm 2).A variety of functions could be applied here, depending on the application."}, {"heading": "3.1 Find a Sequence of Subtree Edit Operations", "text": "The key to this algorithm is that we need to find maximum sequences of identical operations corresponding to the sub-trees (i.e. the root of a sub-tree corresponds to a sub-tree if the following conditions are met: (i) the first node is a leaf; (ii) the most leftmost part of the last node in the sequence (i.e. the root of a sub-tree) is the same as the first node in the sequence. These two conditions can be checked in constant time, as the smallest siblings of a node can be determined in advance. We can therefore find maximum sequences corresponding to the sub-trees by scanning forward through the sequence of sub-trees to find sequences of identical operations, and then scanning backwards until we find the point at which they cover a sub-tree."}, {"heading": "4. Matching Dependency Trees", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able, in which they are able to integrate themselves, and in which they are able, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they are able to change, in which they are able to change"}, {"heading": "5. Dataset Preparation", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "6. Experiments", "text": "To verify the effectiveness of TED + ST, we used it to interweave between P-H and S-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B-B"}, {"heading": "6.1 Binary Decision (\u2018yes\u2019 and \u2018no\u2019)", "text": "The results of these experiments in terms of precision (P), callback (R) and F-score (F) are shown in the table."}, {"heading": "6.2 Making a Three-way Decision (\u2018yes,\u2019 \u2018no\u2019 and \u2018unknown\u2019)", "text": "For this task, we use two thresholds, one to trigger a positive response if the cost of matching is lower than the lower threshold (higher than the higher threshold for the bag-of-words algorithm) and the other to trigger a negative response if the cost of matching is higher (mutatis mutandis for the bag-of-words), otherwise the result will be \"unknown.\" The reason for a three-way decision is to operate systems to make more precise distinctions. Note that here we are not compatible between {h includes p, h and p, h contradicts p}, but between {h includes p, I do not know if h includes p, h does not p}. This is a more subtle distinction that reflects the confidence of the system in its assessment, but it can be extremely useful when deciding how to respond to its decision. The results of this experiment are in terms of precision (R) of the reset (R) and (R) of the Score."}, {"heading": "7. Conclusion", "text": "We have introduced an extended version, TED + ST, of the Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree Tree"}, {"heading": "Acknowledgments", "text": "We would like to thank the reviewers for their valuable comments, especially the reviewer who suggested that the approach be evaluated in both an English and an Arabic dataset. Additional work has strengthened our belief in the robustness of the approach to an extent we did not foresee. We would like to thank our commentators for the time and effort they put into commenting on our experimental dataset. Maytham Alabbas owes his deepest gratitude to the Iraqi Ministry of Higher Education and Scientific Research for the financial support of his doctoral thesis. Allan Ramsay's contribution to this work was partially supported by the Qatar National Research Fund (NPRP 09 - 046 - 6 - 001 scholarship)."}], "references": [{"title": "ArbTE: Arabic textual entailment", "author": ["M. Alabbas"], "venue": "In Proceedings of the Second Student Research Workshop associated with RANLP", "citeRegEx": "Alabbas,? \\Q2011\\E", "shortCiteRegEx": "Alabbas", "year": 2011}, {"title": "Evaluation of combining data-driven dependency parsers for Arabic", "author": ["M. Alabbas", "A. Ramsay"], "venue": "In Proceeding of 5th Language & Technology Conference: Human Language Technologies", "citeRegEx": "Alabbas and Ramsay,? \\Q2011\\E", "shortCiteRegEx": "Alabbas and Ramsay", "year": 2011}, {"title": "Evaluation of dependency parsers for long Arabic sentences", "author": ["M. Alabbas", "A. Ramsay"], "venue": "In Proceeding of International Conference on Semantic Technology and Information Retrieval", "citeRegEx": "Alabbas and Ramsay,? \\Q2011\\E", "shortCiteRegEx": "Alabbas and Ramsay", "year": 2011}, {"title": "Arabic treebank: from phrase-structure trees to dependency trees", "author": ["M. Alabbas", "A. Ramsay"], "venue": "In META-RESEARCH Workshop on Advanced Treebanking at the 8th International Conference on Language Resources and Evaluation (LREC),", "citeRegEx": "Alabbas and Ramsay,? \\Q2012\\E", "shortCiteRegEx": "Alabbas and Ramsay", "year": 2012}, {"title": "Combining black-box taggers and parsers for modern standard Arabic", "author": ["M. Alabbas", "A. Ramsay"], "venue": "In Federated Conference on Computer Science and Information Systems", "citeRegEx": "Alabbas and Ramsay,? \\Q2012\\E", "shortCiteRegEx": "Alabbas and Ramsay", "year": 2012}, {"title": "Improved POS-tagging for Arabic by combining diverse taggers", "author": ["M. Alabbas", "A. Ramsay"], "venue": "In Proceedings of 8th Artificial Intelligence Applications and Innovations (AIAI),", "citeRegEx": "Alabbas and Ramsay,? \\Q2012\\E", "shortCiteRegEx": "Alabbas and Ramsay", "year": 2012}, {"title": "A survey on tree edit distance and related problems", "author": ["P. Bille"], "venue": "Theoretical Computer Science,", "citeRegEx": "Bille,? \\Q2005\\E", "shortCiteRegEx": "Bille", "year": 2005}, {"title": "Introducing the Arabic WordNet project", "author": ["W. Black", "S. Elkateb", "H. Rodriguez", "M. Alkhalifa", "P. Vossen", "A. Pease", "C. Fellbaum"], "venue": "In Proceedings of the 3rd International WordNet Conference", "citeRegEx": "Black et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Black et al\\.", "year": 2006}, {"title": "Generating an entailment corpus from news headlines", "author": ["J. Burger", "L. Ferro"], "venue": "In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment,", "citeRegEx": "Burger and Ferro,? \\Q2005\\E", "shortCiteRegEx": "Burger and Ferro", "year": 2005}, {"title": "Probabilistic textual entailment: generic applied modeling of language variability", "author": ["I. Dagan", "O. Glickman"], "venue": "In PASCAL Workshop on Learning Methods for Text Understanding and Mining,", "citeRegEx": "Dagan and Glickman,? \\Q2004\\E", "shortCiteRegEx": "Dagan and Glickman", "year": 2004}, {"title": "The PASCAL recognising textual entailment challenge", "author": ["I. Dagan", "O. Glickman", "B. Magnini"], "venue": "Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment,", "citeRegEx": "Dagan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dagan et al\\.", "year": 2006}, {"title": "An optimal decomposition algorithm for tree edit distance", "author": ["E. Demaine", "S. Mozes", "B. Rossman", "O. Weimann"], "venue": "ACM Transactions on Algorithms (TALG),", "citeRegEx": "Demaine et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Demaine et al\\.", "year": 2009}, {"title": "Second generation tools (AMIRA 2.0): fast and robust tokenization, POS tagging, and base phrase chunking", "author": ["M. Diab"], "venue": "In Proceedings of the 2nd International Conference on Arabic Language Resources and Tools,", "citeRegEx": "Diab,? \\Q2009\\E", "shortCiteRegEx": "Diab", "year": 2009}, {"title": "Introduction to Arabic Natural Language Processing. Synthesis Lectures on Human Language Technologies", "author": ["N. Habash"], "venue": null, "citeRegEx": "Habash,? \\Q2010\\E", "shortCiteRegEx": "Habash", "year": 2010}, {"title": "MADA+TOKAN: a toolkit for Arabic tokenization, diacritization, morphological disambiguation, POS tagging, stemming and lemmatization", "author": ["N. Habash", "O. Rambow", "R. Roth"], "venue": "In Proceedings of the 2nd International Conference on Arabic Language Resources and Tools,", "citeRegEx": "Habash et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2009}, {"title": "On Arabic transliteration", "author": ["N. Habash", "A. Soudi", "T. Buckwalter"], "venue": "Arabic Computational Morphology,", "citeRegEx": "Habash et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Habash et al\\.", "year": 2007}, {"title": "Tree edit models for recognizing textual entailments, paraphrases, and answers to questions", "author": ["M. Heilman", "N. Smith"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Heilman and Smith,? \\Q2010\\E", "shortCiteRegEx": "Heilman and Smith", "year": 2010}, {"title": "The handbook of pragmatics, chap. Abduction in Natural Language Understanding, pp. 724\u2013740", "author": ["J.R. Hobbs"], "venue": null, "citeRegEx": "Hobbs,? \\Q2005\\E", "shortCiteRegEx": "Hobbs", "year": 2005}, {"title": "Computing the edit-distance between unrooted ordered trees", "author": ["P. Klein"], "venue": "In Proceedings of the 6th Annual European Symposium on Algorithms (ESA", "citeRegEx": "Klein,? \\Q1998\\E", "shortCiteRegEx": "Klein", "year": 1998}, {"title": "Recognizing Textual Entailment with Tree Edit Distance: application to Question Answering and Information Extraction", "author": ["M. Kouylekov"], "venue": "Ph.D. thesis, DIT,", "citeRegEx": "Kouylekov,? \\Q2006\\E", "shortCiteRegEx": "Kouylekov", "year": 2006}, {"title": "Recognizing textual entailment with tree edit distance algorithms", "author": ["M. Kouylekov", "B. Magnini"], "venue": "In Proceedings of the1st Challenge Workshop Recognising Textual Entailment,", "citeRegEx": "Kouylekov and Magnini,? \\Q2005\\E", "shortCiteRegEx": "Kouylekov and Magnini", "year": 2005}, {"title": "Dependency-based evaluation of minipar", "author": ["D. Lin"], "venue": "In Workshop on the Evaluation of Parsing systems,", "citeRegEx": "Lin,? \\Q1998\\E", "shortCiteRegEx": "Lin", "year": 1998}, {"title": "Developing an Arabic treebank: methods, guidelines, procedures, and tools", "author": ["M. Maamouri", "A. Bies"], "venue": "In Proceedings of the Workshop on Computational Approaches to Arabic Script-based Languages,", "citeRegEx": "Maamouri and Bies,? \\Q2004\\E", "shortCiteRegEx": "Maamouri and Bies", "year": 2004}, {"title": "Natural Language Inference", "author": ["B. MacCartney"], "venue": "Ph.D. thesis,", "citeRegEx": "MacCartney,? \\Q2009\\E", "shortCiteRegEx": "MacCartney", "year": 2009}, {"title": "Multilingual dependency parsing with a two-stage discriminative parser", "author": ["R. McDonald", "K. Lerman", "F. Pereira"], "venue": "In 10th Conference on Computational Natural Language Learning (CoNLL-X),", "citeRegEx": "McDonald et al\\.,? \\Q2006\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2006}, {"title": "Optimizing textual entailment recognition using particle swarm optimization", "author": ["Y. Mehdad", "B. Magnini"], "venue": "In Proceedings of the 2009 Workshop on Applied Textual Inference (TextInfer", "citeRegEx": "Mehdad and Magnini,? \\Q2009\\E", "shortCiteRegEx": "Mehdad and Magnini", "year": 2009}, {"title": "MaltParser: a language-independent system for data-driven dependency parsing", "author": ["J. Nivre", "J. Hall", "J. Nilsson", "A. Chanev", "G. Eryigit", "S. K\u00fcbler", "S. Marinov", "E. Marsi"], "venue": "Natural Language Engineering,", "citeRegEx": "Nivre et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nivre et al\\.", "year": 2007}, {"title": "RTED: a robust algorithm for the tree edit distance", "author": ["M. Pawlik", "N. Augsten"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "Pawlik and Augsten,? \\Q2011\\E", "shortCiteRegEx": "Pawlik and Augsten", "year": 2011}, {"title": "Natural language inference via dependency tree mapping: An application to question answering", "author": ["V. Punyakanok", "D. Roth", "W. Yih"], "venue": "Computational Linguistics,", "citeRegEx": "Punyakanok et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Punyakanok et al\\.", "year": 2004}, {"title": "Bootstrapping a lexicon-free tagger for Arabic", "author": ["A. Ramsay", "Y. Sabtan"], "venue": "In Proceedings of the 9th Conference on Language Engineering", "citeRegEx": "Ramsay and Sabtan,? \\Q2009\\E", "shortCiteRegEx": "Ramsay and Sabtan", "year": 2009}, {"title": "The tree-to-tree editing problem", "author": ["S. Selkow"], "venue": "Information Processing Letters,", "citeRegEx": "Selkow,? \\Q1977\\E", "shortCiteRegEx": "Selkow", "year": 1977}, {"title": "Prague Arabic dependency treebank: a word on the million words", "author": ["O. Smr\u017e", "V. Bielicky", "I. Kou\u0159ilov\u00e1", "J. Kr\u00e1\u010dmar", "J. Haji\u010d", "P. Zem\u00e1nek"], "venue": "In Proceedings of the Workshop on Arabic and Local Languages (LREC", "citeRegEx": "Smr\u017e et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Smr\u017e et al\\.", "year": 2008}, {"title": "The tree-to-tree correction problem", "author": ["K. Tai"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Tai,? \\Q1979\\E", "shortCiteRegEx": "Tai", "year": 1979}, {"title": "Simple fast algorithms for the editing distance between trees and related problems", "author": ["K. Zhang", "D. Shasha"], "venue": "SIAM Journal of Computing,", "citeRegEx": "Zhang and Shasha,? \\Q1989\\E", "shortCiteRegEx": "Zhang and Shasha", "year": 1989}], "referenceMentions": [{"referenceID": 30, "context": "There have been numerous approaches to calculating edit distance between trees, as reported by Selkow (1977), Tai", "startOffset": 95, "endOffset": 109}, {"referenceID": 0, "context": "Our ultimate goal is to develop an NLI system for Arabic (Alabbas, 2011).", "startOffset": 57, "endOffset": 72}, {"referenceID": 23, "context": "The challenges of NLI are quite different from those encountered in formal deduction: the emphasis is on informal reasoning, lexical semantic knowledge, and variability of linguistic expression, rather than on long chains of formal reasoning (MacCartney, 2009).", "startOffset": 242, "endOffset": 260}, {"referenceID": 19, "context": "A popular method that has been used in recent years for such tasks is the use of tree edit distance, which compares sentence pairs by finding a minimal cost sequence of editing operations to transform a tree representation of one sentence into a tree for the other (Kouylekov, 2006; Heilman & Smith, 2010).", "startOffset": 265, "endOffset": 305}, {"referenceID": 19, "context": "However, one of the main drawbacks of tree edit distance is that transformation operations are applied solely on single nodes (Kouylekov, 2006).", "startOffset": 126, "endOffset": 143}, {"referenceID": 25, "context": "(1979), Zhang and Shasha (1989), Klein (1998), Demaine, Mozes, Rossman, and Weimann (2009) and Pawlik and Augsten (2011).", "startOffset": 8, "endOffset": 32}, {"referenceID": 15, "context": "(1979), Zhang and Shasha (1989), Klein (1998), Demaine, Mozes, Rossman, and Weimann (2009) and Pawlik and Augsten (2011).", "startOffset": 33, "endOffset": 46}, {"referenceID": 15, "context": "(1979), Zhang and Shasha (1989), Klein (1998), Demaine, Mozes, Rossman, and Weimann (2009) and Pawlik and Augsten (2011).", "startOffset": 33, "endOffset": 91}, {"referenceID": 15, "context": "(1979), Zhang and Shasha (1989), Klein (1998), Demaine, Mozes, Rossman, and Weimann (2009) and Pawlik and Augsten (2011). We have chosen to work with Zhang-Shasha\u2019s algorithm (Zhang & Shasha, 1989) because the intermediate structures produced by this algorithm allow us to detect and respond to operations on subtrees.", "startOffset": 33, "endOffset": 121}, {"referenceID": 0, "context": "Our ultimate goal is to develop an NLI system for Arabic (Alabbas, 2011).1 NLI is the problem of determining whether a natural language hypothesis h can reasonably be inferred from a natural language premise p. The challenges of NLI are quite different from those encountered in formal deduction: the emphasis is on informal reasoning, lexical semantic knowledge, and variability of linguistic expression, rather than on long chains of formal reasoning (MacCartney, 2009). A more recent, and better-known, formulation of the NLI task is the recognising textual entailment challenge (RTE), described by Dagan and Glickman (2004) as a task of determining, for two text snippets premise p and hypothesis h, whether \u201c.", "startOffset": 58, "endOffset": 628}, {"referenceID": 0, "context": "Our ultimate goal is to develop an NLI system for Arabic (Alabbas, 2011).1 NLI is the problem of determining whether a natural language hypothesis h can reasonably be inferred from a natural language premise p. The challenges of NLI are quite different from those encountered in formal deduction: the emphasis is on informal reasoning, lexical semantic knowledge, and variability of linguistic expression, rather than on long chains of formal reasoning (MacCartney, 2009). A more recent, and better-known, formulation of the NLI task is the recognising textual entailment challenge (RTE), described by Dagan and Glickman (2004) as a task of determining, for two text snippets premise p and hypothesis h, whether \u201c. . . typically, a human reading p would infer that h is most likely true.\u201d According to these authors, entailment holds if the truth of h, as interpreted by a typical language user, can be inferred from the meaning of p. A popular method that has been used in recent years for such tasks is the use of tree edit distance, which compares sentence pairs by finding a minimal cost sequence of editing operations to transform a tree representation of one sentence into a tree for the other (Kouylekov, 2006; Heilman & Smith, 2010). Approximate tree matching of this kind allows users to match parts of two trees, rather than demanding a complete match of every element of each tree. However, one of the main drawbacks of tree edit distance is that transformation operations are applied solely on single nodes (Kouylekov, 2006). Kouylekov and Magnini (2005) used the standard tree edit distance, which uses transformation operations (insert, delete and exchange) solely on single nodes, to check the entailment between two dependency trees.", "startOffset": 58, "endOffset": 1567}, {"referenceID": 0, "context": "Our ultimate goal is to develop an NLI system for Arabic (Alabbas, 2011).1 NLI is the problem of determining whether a natural language hypothesis h can reasonably be inferred from a natural language premise p. The challenges of NLI are quite different from those encountered in formal deduction: the emphasis is on informal reasoning, lexical semantic knowledge, and variability of linguistic expression, rather than on long chains of formal reasoning (MacCartney, 2009). A more recent, and better-known, formulation of the NLI task is the recognising textual entailment challenge (RTE), described by Dagan and Glickman (2004) as a task of determining, for two text snippets premise p and hypothesis h, whether \u201c. . . typically, a human reading p would infer that h is most likely true.\u201d According to these authors, entailment holds if the truth of h, as interpreted by a typical language user, can be inferred from the meaning of p. A popular method that has been used in recent years for such tasks is the use of tree edit distance, which compares sentence pairs by finding a minimal cost sequence of editing operations to transform a tree representation of one sentence into a tree for the other (Kouylekov, 2006; Heilman & Smith, 2010). Approximate tree matching of this kind allows users to match parts of two trees, rather than demanding a complete match of every element of each tree. However, one of the main drawbacks of tree edit distance is that transformation operations are applied solely on single nodes (Kouylekov, 2006). Kouylekov and Magnini (2005) used the standard tree edit distance, which uses transformation operations (insert, delete and exchange) solely on single nodes, to check the entailment between two dependency trees. On the other hand, Heilman and Smith (2010) extended the available operations in standard tree edit distance to INSERT-CHILD, INSERT-PARENT, DELETE-LEAF, DELETE-&-MERGE, RELABEL-NODE and RELABEL-EDGE.", "startOffset": 58, "endOffset": 1794}, {"referenceID": 6, "context": "All these editing operations are illustrated in Figure 1 (Bille, 2005).", "startOffset": 57, "endOffset": 70}, {"referenceID": 6, "context": "This section contains a brief recapitulation of this algorithm\u2013a more detailed description is given by Bille (2005). Ordered trees are trees in which the left-to-right order among siblings is significant.", "startOffset": 103, "endOffset": 116}, {"referenceID": 19, "context": "The keyroots of a tree are decided in advance, permitting the algorithm to distinguish between tree distance (the distance between two nodes when considered in the context of their left siblings in the trees T1 and T2) and forest distance (the distance between two nodes considered separately from their siblings and ancestors but not from their descendants) (Kouylekov, 2006).", "startOffset": 359, "endOffset": 376}, {"referenceID": 19, "context": "Because the nodes are numbered according to the postorder traversal, the algorithm proceeds in the following steps (Kouylekov, 2006): (i) the mappings from all leaf keyroots are determined; (ii) the mappings for all keyroots at the next higher level are decided recursively; and (iii) the root mapping is found.", "startOffset": 115, "endOffset": 132}, {"referenceID": 6, "context": "Bille (2005) provides detailed worked examples of the calculation of the costs of transforming one tree into another.", "startOffset": 0, "endOffset": 13}, {"referenceID": 33, "context": "For simplicity here, we assume that the each single operation will cost 1 except that matching will cost 0, as described by Zhang and Shasha (1989).", "startOffset": 124, "endOffset": 148}, {"referenceID": 18, "context": "Klein\u2019s O(nlogn) algorithm (Klein, 1998), Demaine et al.", "startOffset": 27, "endOffset": 40}, {"referenceID": 28, "context": "These costs are an updated version of the costs used by Punyakanok et al. (2004).3 These authors found that using tree edit distance gives better results than bag-of-word scoring methods, when they applied them for question answering.", "startOffset": 56, "endOffset": 81}, {"referenceID": 17, "context": "We follow Hobbs (2005) in assuming that if W1 has a sense which is a hyponym of some sense of W2 then a sentence involving W1 will entail a similar sentence involving W2 as shown in (1).", "startOffset": 10, "endOffset": 23}, {"referenceID": 12, "context": "We have carried out a number of experiments with state-of-the-art taggers such as AMIRA (Diab, 2009), MADA (Habash, Rambow, & Roth, 2009) and an in-house maximumlikelihood (MXL) tagger (Ramsay & Sabtan, 2009) and parsers such as MALTParser (Nivre, Hall, Nilsson, Chanev, Eryigit, K\u00fcbler, Marinov, & Marsi, 2007) and MSTParser (McDonald, Lerman, & Pereira, 2006).", "startOffset": 88, "endOffset": 100}, {"referenceID": 21, "context": "Because the tree edit distance algorithms work with dependency tree analyses of the input texts, we have used a set that have been analysed using Minipar (Lin, 1998), downloaded from http://u.", "startOffset": 154, "endOffset": 165}, {"referenceID": 13, "context": "We also intend to use other Arabic lexical resources, such as OpenOffice Arabic dictionary and MS Word Arabic dictionary, to provide us with more information about relations between words, because the information in AWN, while very useful, is sparse in comparison to PWN (Habash, 2010).", "startOffset": 271, "endOffset": 285}], "year": 2013, "abstractText": "Many natural language processing (NLP) applications require the computation of similarities between pairs of syntactic or semantic trees. Many researchers have used tree edit distance for this task, but this technique suffers from the drawback that it deals with single node operations only. We have extended the standard tree edit distance algorithm to deal with subtree transformation operations as well as single nodes. The extended algorithm with subtree operations, TED+ST, is more effective and flexible than the standard algorithm, especially for applications that pay attention to relations among nodes (e.g. in linguistic trees, deleting a modifier subtree should be cheaper than the sum of deleting its components individually). We describe the use of TED+ST for checking entailment between two Arabic text snippets. The preliminary results of using TED+ST were encouraging when compared with two string-based approaches and with the standard algorithm.", "creator": "dvips(k) 5.99 Copyright 2010 Radical Eye Software"}}}