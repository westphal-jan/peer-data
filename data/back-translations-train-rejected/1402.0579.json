{"id": "1402.0579", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2014", "title": "Probabilistic Planning for Continuous Dynamic Systems under Bounded Risk", "abstract": "This paper presents a model-based planner called the Probabilistic Sulu Planner or the p-Sulu Planner, which controls stochastic systems in a goal directed manner within user-specified risk bounds. The objective of the p-Sulu Planner is to allow users to command continuous, stochastic systems, such as unmanned aerial and space vehicles, in a manner that is both intuitive and safe. To this end, we first develop a new plan representation called a chance-constrained qualitative state plan (CCQSP), through which users can specify the desired evolution of the plant state as well as the acceptable level of risk. An example of a CCQSP statement is go to A through B within 30 minutes, with less than 0.001% probability of failure.\" We then develop the p-Sulu Planner, which can tractably solve a CCQSP planning problem. In order to enable CCQSP planning, we develop the following two capabilities in this paper: 1) risk-sensitive planning with risk bounds, and 2) goal-directed planning in a continuous domain with temporal constraints. The first capability is to ensures that the probability of failure is bounded. The second capability is essential for the planner to solve problems with a continuous state space such as vehicle path planning. We demonstrate the capabilities of the p-Sulu Planner by simulations on two real-world scenarios: the path planning and scheduling of a personal aerial vehicle as well as the space rendezvous of an autonomous cargo spacecraft.", "histories": [["v1", "Tue, 4 Feb 2014 01:41:20 GMT  (3050kb)", "http://arxiv.org/abs/1402.0579v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["masahiro ono", "brian c williams", "l blackmore"], "accepted": false, "id": "1402.0579"}, "pdf": {"name": "1402.0579.pdf", "metadata": {"source": "CRF", "title": "Probabilistic Planning for Continuous Dynamic Systems under Bounded Risk", "authors": ["Masahiro Ono", "Brian C. Williams", "Lars Blackmore"], "emails": ["ONO@APPI.KEIO.AC.JP", "WILLIAMS@MIT.EDU", "LARS.BLACKMORE@SPACEX.COM"], "sections": [{"heading": "1. Introduction", "text": "A motivating example for this article is Boeing's concept of a future air passenger transportation system (PTS) as illustrated in Figure 1. The PTS consists of a fleet of small personal aircraft (PAV) enabling flexible point-to-point transportation of individuals and families. c 2013 AI Access Foundation. All Rights Reserved. To ensure safety, the PTS should be highly automated. In 2004, a pilot error was cited as the main cause of 75.5% of fatal general air accidents in the U.S., according to the 2005 Joseph T. Nall Report (Aircraft Owners and Pilots Association Air Safety Foundation, 2005). Automated route planning, planning, collision avoidance, and traffic management will significantly improve the safety and efficiency of the PTS. Challenges for operating such a system include explicitly adapting to environmental uncertainties, such as storms and turbulence, while we are meeting the three complicated needs of the complex uncertainties there."}, {"heading": "1.1 Overview of the Planner", "text": "In this section, the inputs and outputs of the p-Sulu planner are described informally and strictly defined in Section 2."}, {"heading": "1.1.1 INPUTS", "text": "The p-Sulu Planner plans a control sequence based on the current state, which is typically estimated by loud sensor measurements. Therefore, the p-Sulu Planner uses the probability distribution, instead of point estimation, of the current state as a starting condition. Stochastic Plant Model In the control community, the planning problem is to generate a sequence of control episodes that trigger a physical system called the plant. The action model for a plant is typically a system of real equations about control, state, and observable variables. The pSulu Planner takes as input a linear stochastic plant model that specifies probabilistic state transitions in a continuous range. This is a stochastic extension of the continuous plant model used by Le Chios aute and Williams. In this paper, we limit our focus to Gaussian distributed uncertainties."}, {"heading": "1.1.2 OUTPUT", "text": "Executable control sequence The p-Sulu scheduler plans over a finite horizon. One of the two outputs of the p-Sulu scheduler is an executable control sequence over the horizon that meets all the limitations set by entering CCQSP. In the case of the PTS scenario, the trigger data of the vehicle, such as acceleration and conductor angles, are leading to the nominal paths shown in Figure 2. In order for the control sequence to be executable, it must be dynamically feasible. For example, the curvature of the PAV path must not exceed the maneuverability of the vehicles. The other output of the p-Sulu scheduler is the optimal schedule, a series of execution time steps for events in the input of CCQSP that minimize a predetermined cost function. In the case of the PTS scenario shown in Figure 3, a schedule defines when the scenic region must be left and when the execution of events must take place in the input of QSP."}, {"heading": "1.2 Approach", "text": "The p-Sulu Planner has to solve a very difficult problem of generating an executable control sequence for a CCQSP, which involves both the combinatorial optimization of a discrete schedule and the nonconvex optimization of a continuous control sequence. Our approach in this article is to develop the p-Sulu Planner in three technical steps, which we call \"spirals.\" In the first spiral, which is described in Section 4, we solve a specific case of the CCQSP planning problem, where the feasible state space is convex (e.g. the route planning problem without obstacles) and the schedule is fixed, as in Figure 4- (a).This problem can be transformed into a convex optimization problem by the risk allocation approach presented in our previous work (Ono & Williams, 2008a).We obtain a feasible, near-optimal solution to the CCQSP planning problem by developing the convex optimization problem by means of a two-point black space optimization in 2009."}, {"heading": "1.3 Related Work", "text": "Remember that the CCQSP planning problem is characterized by the use of time-evolved objectives, continuous states and measures, stochastic optimal solutions, and random constraints. While the planning and control disciplines explore aspects of this problem, its solution overall is novel, and our approach to efficiently solving this problem is novel. More specifically, there is an extensive literature on planning with discrete measures to achieve temporally extended goals (TEGs), such as TLPlan overall is novel, and our approach to efficient risk distribution is novel (Kvarnstrom & Doherty, 2000), which treats TEGs as temporary domain control and conceives the search space by advancing the temporary formula. However, since these TEG planners adopt discrete state spaces, they cannot handle problems with continuous states and effective recited effects without discretification."}, {"heading": "1.4 Innovations", "text": "The p-Sulu Planner is activated by six innovations presented in this article. Firstly, to enable users to intuitively control stochastic systems, we are developing a new type of plan, CCQSP (Section 2.4.3). Secondly, to dissect a random restriction via a disjunctive clause into a disjunction of individual random restrictions, we are introducing the risk selection approach (Section 5.4.2). Thirdly, to achieve lower limits for industry and bound search in NIRA, we are developing Fixed Risk Relief (FRR), a linear program to alleviate partial problems (Section 5.4.2). Fourth, to minimize the search space for the optimal schedule by introducing a new forward review method that efficiently limits the impracticable allocation of execution times (Section 6.2)."}, {"heading": "2. Problem Statement", "text": "Remember that the p-Sulu Planner takes as input a linear stochastic plant model that specifies the effects of actions; an initial state description that describes a distribution over initial states; a CCQSP that specifies the desired development of state variables as well as acceptable risk levels; and an objective function. Its output is an executable control sequence and an optimal schedule. Planning takes place over a finite horizon, as the p-Sulu Planner is associated with optimal control of the finite horizon. First, we define the variables used in the problem formulations. Then, we define elements of the inputs and outputs."}, {"heading": "2.1 Definition of Time Step", "text": "We consider a series of discrete finite time steps t = 0, 1, 2, \u00b7 \u00b7 \u00b7 N with a fixed time interval \u2206 T, where integer N is the size of the planning horizon. Since the time interval \u2206 T can take any positive real value, it is sufficient to consider time steps with only integer indices to approximate the dynamics of the system. We use the term \"time step\" for an integer index of discredited time steps, while we use the term \"time\" for a real time. We define the sentences T and T \u2212 as follows: T: = {0, 1, 2, \u00b7 N}. (1) T \u2212: = {0, 1, 2, \u00b7 \u00b7 N \u2212 1}. (2) We limit the scope of this article to a discrete time-stochastic system. This is because the optimization of a control sequence for a continuous time-chastic system repeatedly requires the solution of a stochastic differential equation."}, {"heading": "2.2 Definitions of Events", "text": "An event denotes the beginning or the end of an episode of behavior in our plot. Definition 1. An event is an instance executed in T. We define two special events, the start event e0 and the end event eE. Without loss of universality, we assume that e0 is executed at t = 0. The end event eE represents the termination of the entire plan."}, {"heading": "2.3 Definitions of Variables", "text": "Variables used in our problem formulation include a discrete schedule, a continuous state vector, and a continuous control vector. Formally, we define an event and a schedule as follows: Definition 2. An execution time step s (e), \u00b7 \u00b7 s (eE)] is a sequence of execution time steps of all events e. Finally, a partial schedule represents a partial time step: = [s (e), s (e1), \u00b7 \u00b7 s (eE)] is a sequence of execution time steps of all events e. By definition, the start event is executed to t = 0 i.e, s (e0) = 0. After the notation of a schedule, we refer to the execution time of an event e."}, {"heading": "2.4 Definitions of Inputs", "text": "This subsection defines the four inputs of the p-Sulu planner: an initial condition, a stochastic plant model, a CCQSP, and an objective function."}, {"heading": "2.4.1 INITIAL CONDITION", "text": "The faith state at the beginning of the plan is represented by an initial state which is assumed to have a Gaussian distribution with a known mean x-0 and a covariance matrix \u0445x0: x0 \u0445 N (x-0, \u0445x0). (3) The parameters in (3) are specified by an initial condition defined as follows: Definition 5. An initial condition I is a pair I = 0 x-0, \u0394x0 \u0445, where x-0 is the mean initial state and \u0445x0 is the covariance matrix of the initial state."}, {"heading": "2.4.2 STOCHASTIC PLANT MODEL", "text": "In fact, it is so that it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, and in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way it is about a way and in which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about a way and in which it is about which it is about which it is about a way and in which it is about which it is about which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about which it is about which it is about which it is about a way and which it is about which it is about which it is about which it is about a way and in which it is about which it is about which it is about which it is about which it is"}, {"heading": "2.4.3 CHANCE-CONSTRAINED QUALITATIVE STATE PLAN (CCQSP)", "text": "It is a time-flexible plan that indicates the desired evolution of the plant state. QSP's activities are referred to as episodes and specify plant state constraints. CCQSP is an extension of QSPs to stochastic plans that include a series of episodes that include a series of episodes that include a series of episodes, T is a set of simple time constraints, and C is a set of random constraints. The four elements of a CCQSP are defined exactly at a moment. Like a QSP, a CCQSP can be graphically represented by displaying the discrete events in E."}, {"heading": "2.4.4 OBJECTIVE FUNCTION", "text": "In this section, we formally define objective functionality. Definition 12. An objective function J: UN \u00b7 XN \u00b7 SF 7 \u2022 R is a real-evaluated function via the nominal control sequence u-N \u2212 1, the nominal state sequence x-1: N, and the plan s. We assume that J is a convex function via x-1: N and u-1: N \u2212 1. A typical example of an objective function is the square sum of control inputs that total control efforts must be minimized: J (u-1, x-1: N, x-1: N-1) = N \u2212 1 [u-2]. Another example is the square sum of control inputs that requires total control efforts to be minimized: J (u-N \u2212 1, x-1: N-1, x-2]."}, {"heading": "2.5 Definitions of Outputs", "text": "The output of the p-Sulu scheduler is an optimal solution consisting of an optimal control sequence u-0: N \u2212 1 \u00d1 UN and an optimal schedule s-SF.Definition 13. The optimal solution is a pair u-0: N \u2212 1, s.-The solution fulfills all constraints in the given CCQSP (definition 7), the initial condition I and the stochastic plant model M. The solution minimizes the given objective function J (u0: N \u2212 1, x-1: N, s) (definition 12)."}, {"heading": "2.6 Problem Statement", "text": "We now formally define the CCQSP planning problem. Problem 1: CCQSP planning problem With a stochastic plant model M = A0: N \u2212 1, B0: N \u2212 1, 1: N \u2212 1, an initial condition I = 0, 1: 0, a CCQSP P = E, A, T, C, and an objective function J (u0: N \u2212 1, x 1: N, s), a CCQSP planning problem is to find an optimal solution, namely for M, I, P, and J. We find that the p-Sulu planner is an approximately optimal solution to problem 1. The p-Sulu planner uses two approximations, namely risk allocation (Section 4.1.1) and risk selection (Section 5.1.1), for the sake of computational traceability."}, {"heading": "3. Problem Encoding", "text": "In this section, the CCQSP planning problem described in the previous section is converted into a mathematical programming problem. Sections 4-6 then deal with solving this mathematical problem. Remember that we build our CCQSP planner, the p-Sulu planner, in three spirals. First, we present the problem of coding a general CCQSP planning problem with a non-convex state space and a flexible schedule (Figure 4- (c)) in Section 3.1. Then, we present the coding of the two special cases of the CCQSP planning problem in Sections 3.2 and 3.3: one with a non-convex state space and a fixed schedule (Figure 4- (b)) and one with a convex state space and a fixed schedule (Figure 4- (a))."}, {"heading": "3.1 Encoding of a CCQSP Planning Problem with a Non-convex State Space and Flexible Schedule", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1.1 ENCODING OF FEASIBLE REGIONS", "text": "To turn problem 1 into a mathematical programming problem, the geometric constraint must be changed to (11), (2), (2), (2), (3), (3), (3), (3), (3), (3), (4), (4), (4), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5, 5, (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5, (5), (5, (5), (5), (5, (5), (5), (5), (5, (5, (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5, (5), (5,"}, {"heading": "3.1.2 CCQSP PLANNING PROBLEM ENCODING", "text": "Using (3), (4), (5), (6) and (19), a CCQSP planning problem (problem 1) solved in the third spiral is encoded as follows: Problem 2: General CCQSP planning problem u (0: N \u2212 1, sJ (u0: N \u2212 1, x 1: N, s) (20) s.t. s SF (21) xt + 1 = Atxt + Bt\u00b5U (ut) + wt, t T \u2212 (22) ut = u t + Kt (xt \u2212 x t), t T \u2212 (23) c C Pr i Ic (s), i hTc, i, jxti \u2212 gc, i t T \u2212 (22) ut = u t + Kt (xt \u2212 x t), c c (24) x0 N (x 0), wt i Jc, i, i, jxti \u2212 gc, i, j t T \u2212 (22) ut = u + t (Kxt) \u2212 x."}, {"heading": "3.2 Encoding of a CCQSP Planning Problem with a Non-convex State Space and Fixed Schedule", "text": "A limited version of a CCQSP scheduling problem with a fixed schedule, which is solved in the second spiral, can be obtained by fixing s in problem 2 as follows: Problem 3: CCQSP scheduling problem with a fixed schedule J (s) = min u 0: N \u2212 1J (u0: N \u2212 1, x 1: N) (26) s.t. xt + 1 = Atxt + Bt\u00b5U (ut) + wt, t t T \u2212 (27) ut = u t + Kt (xt \u2212 x t), t T \u2212 (28), c C Pr i Ic (s) j Jc, i hTc, i, jxti \u2212 gc, i, j 0 1 \u2212 c, (29) x0 N (x 0, x0), wt J \u2212 gc, i c, jxti \u2212 gc, i, j p 1 \u2212 c, (29) x0 N (x 0, x0), c c c c \"."}, {"heading": "3.3 Encoding of a CCQSP Planning Problem with a Convex State Space and Fixed Schedule", "text": "A more restrictive version of a CCQSP planning problem with a fixed schedule and a convex state space solved in the first spiral can be obtained by eliminating the inconsistencies in the random constraints in problem 3 as follows: Problem 4: CCQSP planning problem with a fixed schedule and a convex state spacing u: N \u2212 1J (u0: N \u2212 1, x \u00b2 1: N) (31) xt + 1 = Atxt + Bt\u00b5U (ut) + wt, T \u2212 (32) ut = u-t + Kt (xt \u2212 x \u00b2 t), T \u2212 (33), T \u2212 c-C Pr-i-Ic (s) hTc, ixti \u2212 gc, i \u2264 0 \u2212 1 \u2212 c (34) x0 \u2012 N (x \u00b2 0, x \u00b2 N (0, x \u00b2 N), T \u2212 (35) section 4 solves problem 4."}, {"heading": "4. CCQSP Planning with a Convex State Space and a Fixed Schedule", "text": "This section presents the solution methods for problem 4, which is the CCQSP planning problem with a convex state space and a fixed timetable, as shown in Figure 4- (a). If there are no obstacles in the environment and execution time steps are set to achieve time-evolved goals, the CCQSP planning problem is reduced to a convex randomized problem of optimum control of the limited horizon (Ono & Williams, 2008a, 2008b; Blackmore & Ono, 2009).Although an optimal solution to the near-convex optimization problem is not exactly the optimal solution to the original problem of convex randomization of the limited horizon, its sub-optimization is much smaller than previous approaches."}, {"heading": "4.1 Deterministic Approximation of Problem 4", "text": "To assess whether a common random restriction (34) is met, an integral of a multivariate probability distribution over an arbitrary region must be calculated, since the probability in (34) includes several constraints, and such an integral cannot be obtained in a closed form. We solve this problem by splitting the insoluble common random restriction (34) into a series of individual random constraints, each containing only a univariate probability distribution. A key feature of an individual random restriction is that it can be converted into an equivalent deterministic restriction that can be analytically evaluated."}, {"heading": "4.1.1 RISK ALLOCATION APPROACH", "text": "The fragmentation can be considered as an allocation of risk. By fragmentation, the risk of common random restriction is distributed among the individual random restrictions. There are many practicable risk allocations. The problem is to find a risk allocation that leads to the minimum cost. We offer readers an intuitive understanding of risk allocation based on the example below. Racing cars, for example, consider a racing driver example shown in Figure 7. The dynamics of the vehicle have Gaussian distributed uncertainty. The task is to plan a path that minimizes the time to reach the target, with the guarantee that the likelihood of hitting a wall during the race is less than 0.1% (random restriction). Planning the control sequence is equivalent to planning the nominal path shown as the solid lines in Figure 7. To limit the likelihood of hitting a wall, a driver would exhibit a good safety formation in Figure 7."}, {"heading": "4.1.2 DECOMPOSITION OF CONJUNCTIVE JOINT CHANCE CONSTRAINTS THROUGH RISK ALLOCATION", "text": "We derive the mathematical representation of risk allocation by reformulating each random restriction into a conjunction of risk allocation using a conjunction of constraints. Ono and Williams (2008a) originally developed the concept of risk allocation. Let Ci be a suggestion that is either true or false, and then the following problem applies: Lemma 1.Pr [N \u00b2 i = 1 Ci] \u2265 1 \u2212 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 The mathematical representation of risk allocation mathematical N \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 answer to the question \u2212 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 answer."}, {"heading": "4.1.3 CONSERVATISM OF RISK ALLOCATION APPROACH", "text": "As already mentioned, the risk allocation approach gives a conservative approximation to the original random restriction. This subsection usually evaluates the level of conservatism of risk allocation. Since (39) is a sufficient but not necessary condition for (34), Pfail is less than or equal to the risk-based solution in general: \"Pfail.\" Therefore, the conservatism introduced by risk allocation is presented as \"Pfail.\" The best scenario for the risk allocation approach is when the violations of all restrictions are mutually exclusive, meaning that a solution that violates a restriction always meets all other restrictions. In this case, (39) a necessary and sufficient condition for (34), and thus risk allocation does not imply conservatism."}, {"heading": "4.1.4 CONVERSION TO DETERMINISTIC CONSTRAINTS", "text": "Each individual random constraint in (39) contains only one linear constraint. In addition, hTc, ixti has a univariate Gaussian distribution. The following problem transforms an individual random constraint into an equivalent deterministic constraint that includes the mean of state variables instead of the random state variables: Lemma 2. The following two conditions are equivalent. Pr [hTc, ixti \u2212 gc, i \u2264 0] \u2265 1 \u2212 \u03b4c, i \u21d4 hTc, ix ti \u2212 gc, i \u2264 \u2212 mc, i \u2264 \u2212 mc, i (\u0441c, i) wheremc, i (\u0441c, i) = \u2212 \u221a 2hTc, i\u0445x, tihc, i \u2212 erf \u2212 1 (40) Note that erf \u2212 1 is the inflation function of the Gti function, which deals with the variant distribution of the universal function and the variant distribution of the universal matrix."}, {"heading": "4.1.5 RISK ALLOCATION APPROACH FOR THE CLOSED-LOOP CONTROL POLICY", "text": "If we get the risks of actuator saturation under control (i.e., Kt = 0 in (6)), there is a risk of actuator saturation (40).Although it is theoretically possible to deduce from the non-Gaussian distribution, it is very difficult in our case, since the inverse of the cumulative distribution of xti cannot be obtained in a closed form. Our solution to this problem is summarized in Lemma 3 below, which allows us to assume that xti is distributed and to use hence (40), even if there is a possibility of actuator saturation."}, {"heading": "4.2 Convex Programming Solution to Problem 4", "text": "With term 3 we replace the stochastic optimization problem, problem 4, by the deterministic convex optimization problem: Problem 5: Deterministic approach of the problem 4min u 1: N, \u03b4c, i 0, t, i 0 J (u1: N, x 1: N) (47) s.t. t T \u2212, x t + 1 = Atx t + Btut (48) c C i Ic (s) hTc, ix ti \u2212 gc, i \u2212 mc, i \u2212 mc, i \u2212 mc, i (49) t t i IU t \u2212 gU, iu t \u2212 gU, i \u2212 mU, i t t, i (t, i) c C i \u2212 gc, i \u2212 mc, i c (s) c Ic (s), i + Tmax."}, {"heading": "5. CCQSP Planning with a Non-convex State Space", "text": "Next, we look at the second spiral, which consists of problem 3 in Section 3.2, a variant of the CCQSP planning problem that involves a fixed timetable and non-convex constraints such as obstacles as shown in Figure 4- (b). Again, this is encoded as a random optimization problem, but the addition of obstacle avoidance constraints requires disjunctive state constraints. Therefore, the problem results in a non-convex opportunity optimization. This section leads to a novel algorithm called Non-convex Iterative Risk Allocation (NIRA) that optimally solves a deterministic approach to the problem. The solution to a CCQSP planning problem with a non-convex state space is twofold."}, {"heading": "5.1 Deterministic Approximation", "text": "As in section 4, we first get a deterministic approach to problem 3."}, {"heading": "5.1.1 RISK SELECTION APPROACH", "text": "Deterministic approximation is achieved by dividing the non-convex common random restriction (29) by risk allocation and risk selection into a series of individual random constraints. To explain the concept of risk selection intuitively. For example, racing car We consider the example shown in Figure 8, where a vehicle with uncertain dynamics plans a path that minimizes the time to reach the target. The vehicle is allowed to choose one of the two routes shown in Figure 8. We set a random restriction that limits the chance of impact during the mission to 0.1%. Satisfaction with the random restriction can be guaranteed by the process that follows. First, for each of the routes we find a safety margin that limits the probability of a crash along the entire route to 0.1%, from start to finish. Then we let the vehicle plan a nominal path that operates within the safety margins. Since both routes have a safety margin, the probability of a crash is not limited to the total random restriction during the 0.1."}, {"heading": "5.1.2 DECOMPOSITION OF CONJUNCTIVE JOINT CHANCE CONSTRAINT THROUGH RISK SELECTION", "text": "In this subsection we derive the mathematical representation of the risk selection. Let Ci be a sentence that is either true or false. Then the following problem applies: The following inequality always applies: The following inequality applies: the same inequality applies to the following inequality: the same inequality applies to the same inequality: the same inequality applies to the same inequality: the same inequality applies to the same inequality: the same inequality applies to the same inequality: the same inequality applies to the same inequality: the same inequality applies to the same inequality: the same inequality applies to the same inequality: the same inequality applies to the same inequality: the same inequality applies to the same inequality: the following restriction is a sufficient condition for the same inequality: the same inequality for the same inequality: the same inequality: the same inequality: the same inequality: the same inequality: the same: the same inequality: the same."}, {"heading": "5.1.3 DETERMINISTIC APPROXIMATION OF PROBLEM 3", "text": "Using Korolla 2, the non-convexe, fixed-time CCQSP planning problem (problem 3) is approximated by the following deterministic konvexe optimization problem. For later convenience, we refer to each part of the optimization problem as O (objective function), M (plant model), C (random constraints for states), D (random constraints for control inputs), and R (risk allocation constraints).Problem 6: Deterministic approximation of the problem 3min u 1: N, 2: 0, i: 0, i: 0 (O:) J (u1: N, x: 1: N) (55) s.t. (M:) Bottle T \u2212, x: T + 1 = Atx + Btut (56) (C: Problem C: i i i i Ic (s), i Ic (s), i hTc, i \u2212 gc, i, i, i, i \u2212 c, i, i, j c, c, c, c, c, i, c, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, c, c, c, c, c, c, c, i, i, i, i, i, i, i, i, i, i, i, i, i."}, {"heading": "5.2 NIRA: Branch and Bound-Based Solution to Problem 6", "text": "Remember that NIRA optimally solves problem 6 through a branch-and-bound algorithm. The default branch-and-bound solution to problems with disjunctive nonlinear constraints, such as the one in problem 6, is to use a boundary approach that constructs the nonlinear convex relaxed subproblems by removing all non-convex constraints below the corresponding disjunction. This approach was used by Balas (1979) and Li and Williams (2005) for another problem known as disjunctive linear programming, the subproblems of which are LPs instead of convex programming. However, although the standard branch-and-bound algorithm is guaranteed to find a globally optimal solution to problem 6, its computation time is slow because the algorithm has to solve numerous nonlinear subproblems in order to compute relaxed boundaries."}, {"heading": "5.2.1 THE NIRA ALGORITHM OVERVIEW", "text": "The answer to the question whether the solution is a problem that occurs in the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue of the queue"}, {"heading": "5.3 Branching", "text": "This subsection explains how NIRA constructs the root subproblem (line 3 of algorithm 1), as well as how it expands the nodes (line 21 of algorithm 1).The root subproblem is a convex optimal CCQSP planning problem with no random constraints. When a node is expanded, the sub-problems of its child nodes are constructed by adding a constraint in a disjunction to the parent subproblem. To simplify the notation, let Cc, i, j represent every single random constraint (57) in problem 6: Cc, i, j: = {True (if hTc, i, j \u2212 gc, i, jx-mc, i, j (\u0441c, i)) (otherwise)."}, {"heading": "5.3.1 WALK-THROUGH EXAMPLE", "text": "First, we present a continuous example to explain the branching procedure intuitively. An example of problem 6, which contains four individual random constraints: Using this notation defined above, the set of individual random constraints (57) is presented as follows: (C1,1,1), (i), (C1,2,1), (C1,2,2) (61), (a), shows a tree achieved by dividing the original problem into relaxed partial problems; the sub-problems corresponding to the four leaf nodes of the tree (Nos. 4-7 in Figure 9- (a), exhaust all conjunctive (i.e., convex) combinations under the random constraints (61); the sub-problems corresponding to the three branch problems (Nos. 1 problems in Figure 9b) obtain all conjunctive (i.e., convex) combinations between the random constraints (61)."}, {"heading": "5.3.2 RELAXED CONVEX SUBPROBLEM", "text": "The formulation of the relaxed convex sub-problems is given in problem 7. We present the index j as j (c, i), because the convex relaxation selects only one disjunction for each disjunction specified by (c, i). Let Ic set a series of indices for i. We call J-SP the optimal objective value of the relaxed sub-problem. (Problem 7:) Convex relaxed sub-problem of NIRAJ-SP = minu-1: N, \u03b4c, i-0, t, i-0 (O:) J \"(u1: N, x-1: N) s.t. (M:) Relaxed sub-problem of NIRAJ-SP = minu-1 = Atx-T + Btut (C:)."}, {"heading": "5.3.3 CONSTRUCTION OF ROOT SUBPROBLEM", "text": "The root subproblem is a special case of the above problem 7, where Ic is an empty set for all c-C. The function represented in algorithm 2 is used in line 3 of the NIRA algorithm (algorithm 1) to construct the root subproblem of the branch and boundary tree. Note that in algorithm 2 we use an object-oriented notation, such as Subproblem.O, to represent the objective function O of the subproblem, and the resulting root subproblem is as follows:"}, {"heading": "5.3.4 EXPANSION OF SUBPROBLEMS", "text": "To create a child subproblem of a subproblem, the function described in algorithm 3 is used in line 21 of the NIRA algorithm (algorithm 1) and adds the individual random constraint specified by the indexes (c, i, j) as a conjunction. Note that the resulting child subproblem is still a convex optimization because the individual random constraint is added subjunctivally. The NIRA algorithm (algorithm 1) lists child nodes for all disjunctions in Jc, i (lines 20-23). Algorithm 2 Construction of the root subproblem of the NIRA function obtainRootSubproblem (problem) provides root problem 1: rootSubproblem.O 2: rootSubproblem.M: rootSubproblem.M: rootSubproblem.M: rootSubproblem.D: for c-Subproblem.D: c-Subotproble.R.R.R.R.T: Subproble.R.R.R.R.C: Subproble.R.R.C: Subproble.R.R.R.C:.R.R.C:.R.R.R.C:.R.R.R.C:.R.R.R.C:.R.R.C:.R.R.C:.R.R.C:.R.R.R.C."}, {"heading": "5.4 Bounding", "text": "In this section we present two implementations of the obtained LowerBound function in line 8 of algorithm 1: The first uses the optimal solution of the convex partial problems (problem 7) as lower limits. This approach typically leads to a large computation time. The second solution solves an LP relaxation of the convex partial problems, which is called Fixed Risk Relaxation (FRR). FRR dramatically shortens the computation time compared to the first implementation. The NIRA algorithm uses the second implementation."}, {"heading": "5.4.1 SIMPLE BOUNDING", "text": "Algorithm 4 shows the simplest way to reach lower limits. It simply solves the convex relaxed subproblems (problem 7) using the methods described in Section 4.2. The optimal objective value of a relaxed subproblem indicates a lower limit of the optimal objective value of all underlying subproblems. For example, the optimal solution of the relaxed subproblem at node 2 \u2032 in Figure 9- (b) indicates a lower limit of the objective value of the subproblems at nodes 4 and 5. This is because the limitations of the relaxed subproblems are always a subset of the limitations of the subproblems below. Note that optimization problems are formulated as minimizations. However, despite the simplicity of this approach, its computation time is slow because the algorithm has to solve a variety of subproblems. For example, a simple path planning requires a problem with algorithm 4 A simple implementation of the obtainLowerBound function in line 8 of the algorithm Lowerbounds function is tied to a number of subproblems (a number of Lowerbounds)."}, {"heading": "5.4.2 FIXED RISK RELAXATION", "text": "The new risk elaxation (FRR) is able to solve this problem (see section 7.1.1 for an example). If the objective function is linear, an objective function can be approximated by a convex linear function. Hence, in many cases, the FRRs of the subjective function, which can be solved very efficiently. Fixed risk elaxation of problem 7 is as follows: Problem 8: Fixed Risk Relaxation of problem 7: Problem 7: Problem 7: Problem 7: Problem 8: Problem 8: Problem 7: Problem 8: Problem 8: Problem 8: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: Problem 7: The objective function can become an objective function."}, {"heading": "6. CCQSP Planning with a Flexible Schedule", "text": "This section introduces the full p-Sulu scheduler, which efficiently solves the general CCQSP scheduling problem with a flexible schedule and a non-convex state space (problem 2 in Section 3.1.2). The problem is to find a schedule of events that meets simple time constraints and a nominal control sequence. (problem 2 in Section 3.1.2) Our approach is to first generate a workable schedule and then extend it to a control sequence for that schedule, while improving the candidate lists iteratively using branches and boundaries. (We build the p-Sulu Planner on the NIRA algorithm presented in the previous section. (Recall that NIRA optimizes the nominal control sequence.)"}, {"heading": "6.1 Algorithm Overview", "text": "Our approach is again to use a branch-and-bound algorithm. In branch-and-bound search, the p-Sulu Planner incrementally assigns an execution time step to each event in order to find the schedule that minimizes J-Planner and NIRA in (67). The objective function is evaluated by solving the fixed plan CCQSP scheduling problem using the NIRA algorithm. Although the combination of the two branch-and-bound searches in the p-Sulu Planner and NIRA search is in practice equivalent, we treat them separately for the simplicity of the explanation.As shown in Figure 12, branch-and-bound searches for an optimal schedule are based on incremental allocation of execution times to each event in a first manner. Each node of the search tree corresponds to a partial schedule (definition 2) that assigns execution steps to a subset of events in the CCSP."}, {"heading": "6.2 Branching", "text": "Algorithm 7 outlines the implementation of the expand () function in algorithm 6. It takes a partial schedule \u03c3 as input and adds a series of schedules to the queue that assign an execution time step to an additional event e \u00b2. In other words, the domain of the newly added schedules E\u03c3 has another assigned event than the domain of the input part plan E\u03c3. Details of algorithm 7 are explained in the following parts of this subsection."}, {"heading": "6.2.1 ENUMERATION OF FEASIBLE TIME STEP ASSIGNMENTS USING D-GRAPH", "text": "To achieve this, we use a d-graph to translate the boundaries between two events into the boundaries of the execution time of each event. A d-graph is a direct graph in which the weights of the edges represent the shortest distances between the nodes, as shown in Figure 11 - (b). To get the d-graph representation, we first translate the simple time constraints into a directed graph, as shown in Figure 11 - (a). The weight of an edge between two nodes (events) corresponds to the maximum duration of time from the origin node to the target node, as specified by the corresponding simple time constraint."}, {"heading": "6.2.2 EFFICIENT VARIABLE ORDERING OF BRANCH-AND-BOUND SEARCH", "text": "When selecting the next event to assign a time step in line 3 of algorithm 7, two variable order heuristics prove effective in reducing the computation time.The first heuristics is based on the observation that partial problems of the bifurcated algorithm are particularly difficult to solve if the episodes in A (E\u03c3) contain non-convex state constraints. \"Remain in R2\\ C\" (2D level minus obstacle C) episode in Figure 10 is an example of such non-convex episodes. Therefore, an effective approach is to reduce the computation time of the bifurcated plan while minimizing the number of non-convex partial problems in the bifurcated process."}, {"heading": "6.3 Bounding", "text": "Next, we introduce the implementation of the obtained LowerBound () function in line 8 of algorithm 6. The algorithm obtains the lower limit by solving a relaxed CCQSP planning problem with a fixed subscheme. Algorithm 8 outlines the implementation of the obtained LowerBound () function. It takes a partial schedule as input and prints the lower limit of the objective function and the optimal control sequence, compared to the partial schedule. It constructs a relaxed optimization problem that includes only episodes whose start and end events are assigned to both execution time steps (line 1). If the optimization problem does not include convex constraints, the NIRA algorithm is used to obtain the solution of the problem (line 3). Otherwise, we solve the FRR of the convective optimizing problem to obtain the lower limit (line 5)."}, {"heading": "6.3.1 RELAXED OPTIMIZATION PROBLEM WITH PARTIAL SCHEDULE", "text": "We look at a relaxed optimization problem as follows: Problem 9: Relaxed Optimization Problem for a Partiel Schedule \u03c3J (\u03c3) = min u0: N \u2212 1 \u0445 UNJ (u0: N \u2212 1, x: N \u00b2, \u03c3) (68) s.t. Problem T \u2212, xt + 1 = Atx \u00b2 t + Btut (69), c \u00b2, c \u00b2 s, c \u00b2 s, a \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c \u00b2 s, c, c \u00b2 s, c \u00b2 s, c, c \u00b2 c, c, c, c \u00b2 c, c, c, c, c \u00b2 s, c, c, c, c \u00b2 s, c, c, c, c, c \u00b2 c, c, c, c, c \u00b2 s, c, c, c, c, c, c, c, c, c, s, c, c, c, c, c, c, c, c, c, c, s, c, c, c, c, c, c, s, c, c, c, c, c, s, c, c, c, s, c, c, c, c, c, s, c, c, c, c, 1, c, 1, c, 1, c, c, 1, c, c, 1, c, c, 1, c, c, c, 1, c, c, 1, c, c, c, 1, c, c, 1, c, c, 1, 1, c, c, c, 1, c, c, c, c, c, 1, 1, c, c, 1, c, c, c, c, c, 1, c, 1, c, 1, c, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1"}, {"heading": "6.3.2 FURTHER BOUNDING WITH FRR", "text": "If the relaxed sub-problem (problem 9) is convex, then the p-Sulu planner solves the FRR of the sub-problem instead of solving it exactly with NIRA to achieve a lower limit more efficiently (line 5 of algorithm 8). Many practical execution problems of the CCQSP have only one episode that has a non-convex, workable region. Thus, for example, in the CCQSP planning problem in Figures 2 and 3 only the \"safe region\" (R2 minus the obstacles) is non-convex, while \"Provincetown\" (start region), \"Scenic region\" and \"Bedford\" (target region) are convex. In such a case, sub-problems are solved precisely at the leaf nodes, and their lower limits are always evaluated by approximate solutions of the FRRs of the sub-problems at the non-leaf nodes."}, {"heading": "7. Results", "text": "In this section, we demonstrate empirically that the p-Sulu Planner can efficiently operate different systems within the prescribed risk limit. First, we present the simulation settings in Section 7.1. Section 7.2 presents the simulation results of the NIRA algorithm and confirms our claim that it can efficiently calculate a practicable and near-optimal solution. Section 7.3 demonstrates the p-Sulu Planner on two different benchmark problems. The simulation results underscore the ability of the p-Sulu Planner to operate within the user-defined risk limit. Section 7.4 sets the p-Sulu Planner to the PTS scenarios, while Section 7.5 applies the p-Sulu Planner to the space rendezvous of an autonomous cargo spacecraft to the International Space Station."}, {"heading": "7.1 Simulation Settings", "text": "Remember that the p-Sulu scheduler, as explained in Section 2.4, requires four inputs: a stochastic plant model M, an initial condition I, a CCQSP P, and an objective function J. This section specifies M and J, which are commonly used for all problems in Sections 7.2-7.4. We specify P and I for each problem in the corresponding section."}, {"heading": "7.1.1 STOCHASTIC PLANT MODEL", "text": "This section explains the plant model used in sections 7.2 - 7.4. Section 7.5 uses another plant model described in detail in Section 7.5.2. We consider a point-mass double integrator plant as shown in (72) - (73). Parameters such as umax, vmax, \u03c32 and \u2206 T are specified separately for each problem. This plant model is generally accepted in literature on unmanned aerial vehicles (UAV) as a path plan (Kuwata & How, 2011; Le \u0301 aute, \"2005; Wang, Yadav, & Balakrishnan, 2007). Our state vector xt consists of positions and velocities in x- and y-directions, while the control vector consists of the accelerations: xt: = [x y vx vy] T, ut: = [ax ay] T. The plant model is specified by the following matrices: A = 1 0 x 0 x 0 x 0 0 0."}, {"heading": "7.1.2 OBJECTIVE FUNCTION", "text": "In sections 7.2.3, 7.3 and 7.4, the cost function is the Manhattan standard of control input over the planning horizon, as follows: J (x-ti, U, s) = T- \u2211 t = 1 (| ux, t-ux, t-uy, t-uy).This cost function represents the total change in momentum, which is roughly proportional to the fuel consumption of an aircraft. Note that a minimization problem with the piecemeal linear cost function is equivalent to the following minimization problem with linear cost function and additional linear limitations, by replacing flat variables \u00b5x, t-uy, t-ux, t-ux, t-quuy, t-minT = 1 (\u00b5x, t + \u00b5y, t) s.t. t-T, \u00b5x, t-ux, t-ul, t-\u00b5x, t-ux, t-ux, t-ux, t-ux, t-uy, t-uy, uy, ut, ut, ut, t-y, t-t, t-t, t-t-t, t-t-t, t-t-t, t-t-t, t-t-t, t-ut, t-t, t-t-t, t-t, t-t-t, t-t-t, t-t-ut, t, t-t, t-t-t, t-t-t, t-t, t-t-t, t-t-t, t-t-t, t-t, t-t, t-t-t, t-t-t, t-t-t, t-t, t-t-t, t-t, t-t-t, t-t, t-t-t-t, t-t-t-t, t-t-t, t-t, t-t, t-t-t, t, t-t-t, t-t-t, t, t-t-t, t, t-t-ut, t, t, t, t-t-t, t-t, t, t-t-t, t, t-t-t, t, t-t, t-"}, {"heading": "7.1.3 COMPUTING ENVIRONMENT", "text": "All simulations except the simulations in Section 7.2 are performed on a computer with an Intel Xeon dual-core 2.40 GHz processor and 16 GB of RAM. Algorithms are implemented in C / C + + and run on Debian 5.0.8 OS. Simulations in Section 7.2 are performed on a computer with an Intel Core i7 quad-core 2.67 GHz processor and 8 GB of RAM. Algorithms are implemented in Matlab and run on the Windows 7 operating system. We used IBM ILOG CPLEX Optimization Solver Academic Edition Version 12.2 as linear program solver and SNOPT Version 7.2-9 as convex optimization solver."}, {"heading": "7.2 NIRA Simulation Results", "text": "We first compare the statistical performance of NIRA with the state of the art. Remember that NIRA is a solution to CCQSP planning problems with non-convex state constraints and a fixed schedule (problem 3) and is used as a subroutine in the p-Sulu scheduler."}, {"heading": "7.2.1 COMPARED ALGORITHMS", "text": "There are two existing algorithms that can solve the same problem: 1. Fixed risk allocation (Blackmore et al., 2006) - This approach fixes risk allocation to a uniform value. As a result, problem 6, assuming that the cost function is linear, can be reformulated as a mixed-integer linear programming problem (MILP) that can be efficiently solved by a MILP solver, such as CPLEX.2. Particle control (Blackmore, 2006) - Particle control is a random sample-based method that uses a finite number of samples to approximate the common random constraints. The control sequence is optimized so that the number of samples that violate restrictions is smaller than \u0445cNp, where Np is the total number of samples. The optimization problem is reformulated in MILP, assuming that the cost function is linear."}, {"heading": "7.2.2 PROBLEM SETTINGS", "text": "We compare NIRAs with closed circuits and open circuits with the two algorithms in the case of a problem of 2-D route planning with a random location of an obstacle, as shown in Figure 13. A vehicle starts from [0, 0] and travels to the destination at [1.0, 1.0], evading a rectangular obstacle. An obstacle with edge length 0.6 is placed at a random location within the square area with its corners at [0, 0], [1, 0] and [0, 1]. We consider ten time steps with the time interval \u2206 t = 1.0. We demand that the mean state be t = 10 at [1.0, 1.0]. The risk limit is set to \u0394= 0.01. We set the standard deviation of the fault as \u03c3 = 0.01. We use the square cost function specified in (74). The steady state LQR gain will be present for the closed loop NIRA with Q = 4 and the IR - 1000In which are identifiable."}, {"heading": "7.2.3 PERFORMANCE COMPARISON", "text": "The solution of the NIRA algorithm used by the p-Sulu Planner to solve this problem is not exactly an optimal solution to problem 3, since risk allocation (Section 4.1.1) and risk selection (Section 5.1.1) are closed. We provide empirical evidence that our risk allocation / selection leads to a solution that is much closer to the optimal solution than the previous art, while the satisfaction of the original constraint (29) is guaranteed. We evaluate the suboptimality of the solutions by the difference between the risk commitment, 0, 01 and the resulting probability of constraint, Pfail, estimated by a Monte Carlo simulation. 1 \u2212 Pfail is equal to the left-sided value of (29)."}, {"heading": "7.2.4 OPTIMAL PLANNING WITH EXPECTED COST", "text": "Next, we will demonstrate the ability of the p-Sulu planner to handle the expected costs for the same route planning problem outlined above, rather than the expected costs of the expected course. Specifically, we will consider the expected square cost function shown in (74). However, when performing open loop planning, this cost function can be converted into a function of nominal control inputs with a constant term by using the equality (15). However, when performing closed loop planning, this equality is not accurate due to the saturation of the control system. Nevertheless, we will use (15) as an approximation of the expected costs as explained in Section 2.4.4. In this subsection, we will empirically evaluate the error of this approximation. Table 2 compares the approximate expected cost functional value achieved by the NIRA closed loop with the actual expected costs estimated by the Monte Carlo simulation with one million samples."}, {"heading": "7.2.5 COMPARISON WITH MDP", "text": "Next, we compared NIRA with an MDP formulation. In the interest of the tractability of the MDP, we consider a single integrator dynamics with a two-dimensional state space and a two-dimensional control that indicates the speed of a vehicle. The rest of the problem is the same, except that the state space is converted into a 100-by-100 grid. We implement an endless horizon MDP-based planner that imposes a penalty for failure and minimizes the cost of an explicit state. The MDP-based planner considers the cost as follows: E [t] t \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s."}, {"heading": "7.3 The p-Sulu Planner Simulation Results", "text": "Next, we present the simulation results of the p-Sulu planner on two problems to illustrate its planning capability with time constraints and to evaluate empirically the scalability of p-Sulu."}, {"heading": "7.3.1 PATH PLANNING WITH OBSTACLES", "text": "In this simulation, we test the p-Sulu Planner on a path planning problem in the environment shown in Figure 17. Entering CCQSP is in Figure 16. The CCQSP requires a vehicle to reach the target region within 15 minutes by going through Waypoint 1 and Waypoint 2 with the time restrictions shown in Figure 16. It also imposes two random constraints on: one that requires the vehicle to achieve the time-developed objectives with 90% certainty, and another that requires the vehicle to limit the likelihood of violating the obstacles for \u2206 obs. We set \u2206 t = 1 and \u03c32 = 0.0025.Figure 17 shows the plans generated by the p-Sulu Planner with three different risk limits: \u2206 obs = 10%, 0.1% and 0.001%. The calculation times were 79.9 seconds, 86.4 seconds, and 88.1 seconds, respectively. Figure 17 shows the plan generated by Sulu, a planner who is planning a planner who is not looking at an explicit planner."}, {"heading": "7.3.2 PATH PLANNING IN AN INDOOR ENVIRONMENT", "text": "Next, we give the p-Sulu planner the CCQSP shown in Figure 18, which simulates a route planning problem in an interior. A vehicle must reach the destination region on the other side of the room within three to five seconds. \"Stay in a safe region\" episode requires the vehicle to be inside the room and outside the obstacle during the five-second planning horizon. CCQSP sets two random constraints shown in Figure 18. We set \u2206 t = 0.5 and \u03c32 = 5.0 \u00d7 10 \u2212 5. Faced with this CCQSP, the planner is faced with the choice of driving directly to the destination by crossing the narrow passage between the left wall and the obstacle, minimizing the path length, but carrying a higher risk of violation of restrictions; making a detour around the right side of the obstacle carries less risk, but leads to a longer path. Figure 19 shows the performance of the p-Sulu planner on the planner, while he chooses 10% and 1% quantities."}, {"heading": "7.3.3 SCALABILITY ANALYSIS", "text": "In this subsection, we perform an empirical analysis of the scalability of the p-Sulu planner as the environment becomes increasingly constrained. As shown in Figure 20, we have measured the computation time to solve a planning problem with different numbers of obstacles and waypoints. In all simulations, the path starts at [0, 12] and ends in a square region centered at [24, 12. Figure 20 shows twenty simulation results with zero to three obstacles and zero to four waypoints. Obstacles and waypoints are represented in the figure by blue and red squares respectively, the positions of the center of the obstacles are [6, 12], [12, 12] and [18, 12], while the positions of the center of the waypoints [9, 9], [9, 15], [15, 15] and [15, 9]."}, {"heading": "7.4 PTS Scenarios", "text": "Next, we use the p-Sulu Planner for PTS scenarios, the robotic air taxi system introduced in Section 1."}, {"heading": "7.4.1 SCENARIOS", "text": "We look at three scenarios presented by the CCQSPs in Figure 21. Scenarios 1 and 2 are similar to the scenic flight scenario presented at the beginning of this paper (see Figure 1). Scenario 1, a personal aircraft (PAV) takes off from runway 71 of Provincetown Municipal Airport (KPVC) in Provincetown, Massachusetts, and lands on runway 23 of Hanscom Field (KBED) in Bedford, Massachusetts. The vehicle must remain within the promising region for a minimum of 2 minutes and a maximum of 10 minutes. The entire flight must last more than 13 minutes and less than 15 minutes. Scenario 2 is the same as Scenario 1, except for the runways used for take-off and landing. Scenario 3 simulates a leisure flight off the Massachusetts coast. Scenario 1 has a probability, a probability, a probability."}, {"heading": "7.4.2 PLANT PARAMETERS", "text": "We set umax = 250 m / s, which corresponds to the maximum cruising speed of private jet aircraft such as Gulfstream V. The maximum acceleration is determined by the maximum shore angle. Assuming that an aircraft flies at constant speed, the lateral acceleration a, depending on the shore angle, is given as follows: a = g \u00b7 tan\u0442, where g is the acceleration of gravity. Typically, passenger aircraft limit the shore angle to 25 degrees for passenger comfort, even if the aircraft is able to rotate with a larger shore angle. Therefore, we use: umax = 9.8 m / s2 \u00b7 tan (25 \u0445) = 4.6 m / s2.We set \u03c3 = 100 m and \u0394T = 60 seconds."}, {"heading": "7.4.3 SIMULATION RESULTS", "text": "In all scenarios, all episode requirements in the CCQSPs in Figure 21 are met within the specified time and random constraints.Table 4 compares the performance of Sulu and the p-Sulu planner. As expected, Sulu's plans result in excessive error probabilities in all scenarios. This is because Sulu does not take into account uncertainties in the planning process, even though the PAV is subject to interference in reality. On the other hand, the p-Sulu planner successfully limits the likelihood of failure within the user-defined risk limits for all three scenarios. Furthermore, although the p-Sulu planner significantly reduces the risk of failure, its costs are higher than Sulu's by only 9.5 - 12.8%. Such an ability to limit the risk while maximizing the efficiency of the planner is a desirable feature for PTS that allows a real plan for transport.As Sulu planner assumes several minutes for the typical plan we assume the sulu passengers will need in the table."}, {"heading": "7.5 Space Rendezvous Scenario", "text": "The p-Sulu planner is a general planner whose application is not limited to a specific plant model. In order to demonstrate the universality of the planner, we used the p-Sulu planner on a system whose plant model is clearly different from PTSD. Specifically, we chose an autonomous space rendezvous scenario for the H-II Transfer Vehicle (HTV) shown in Figure 23. HTV is an unmanned cargo aircraft developed by the Japanese space agency JAXA, which is used to supply the International Space Station (ISS). A collision of the vehicle with the ISS can lead to a fatal catastrophe, even if the collision velocity is low. For example, in August 1994, the unmanned Progress M34 resupply aircraft collided with the Mir space station in a failed attempt to automatically meet and dock."}, {"heading": "7.5.1 HTV RENDEZVOUS SEQUENCE", "text": "In HTV's autonomous rendezvous mission, the final approach phase begins from the Approach Initiation (AI) point, which is 5 km behind the ISS, as shown in Figure 24. Firstly, HTV moves to the R-Bar Initiation (RI) point, which is 500 m below the ISS, guided by relative GPS navigation. On the RI side, HTV switches navigation mode to the Rendezvous Point (RVS) navigation. In RVS navigation, HTV measures exactly the distance to the reflector positioned on the Earth (earth-oriented) side of the ISS. Then, it goes to the HTV point (Hold Point), which is 300 m below the ISS. It is necessary to perform a 180 degree yaw zone."}, {"heading": "7.5.2 ORBITAL DYNAMICS", "text": "The rendezvous can be regarded as a two-body problem where a chaser spacecraft (e.g. HTV) moves in relation to a target spacecraft (e.g. ISS) that is in a circular orbit. In such a problem, it is convenient to describe the motion of the chaser spacecraft with a rotating frame fixed on the target spacecraft used as a Hill coordinate system (Schaub & Junkins, 2003). As shown in Figure 24, we take into account the x-axis pointing from the center of the Earth and the axis of the Earth along the theoretical speed of the target spacecraft. As the HTV orbit is within the x-y plane, we consider the z-axis. It is known that the relative motion of the tracking space in the Hill coordinate system is described by the following Clohessy-Wiltshire equation (CW): x-2."}, {"heading": "7.5.3 OBJECTIVE FUNCTION", "text": "We use an objective function J, which requires the p-Sulu planner to minimize fuel consumption (Wertz & Wiley J. Larson, 1999).The total fuel consumption is the sum of the fuel consumption of reaction jets in x and y direction for all time steps. Therefore, our objective function is described as follows: J (u0: N) = \"Vx +\" Vy = \"(N \u2212 1)\" T 0 \"(Fx | + | Fy | dt = k = N \u2212 1)\" T \"0\" (T \u2212 1) \"T\" 0 \"(T \u2212 T \u00b7 k) ux,\" kdt = \"Vx +\" Vy = \"(N \u2212 1)\" T \"0\" (T \u2212 1), kdt = \"T\" k \"(N \u2212 k) uy.\""}, {"heading": "7.5.4 SIMULATION RESULT", "text": "Figure 27 shows the planning outcome of the p-Sulu planner. We compare the result with Sulu, but also with a nominal planning approach in which we assume that HTV will move from AI to RI with a two-track transition (the so-called \"CW Guidance Law\") (Matsumoto, Dubowsky, Jacobsen, & Ohkami, 2003; Vallado, 2001). From RI to CB, it follows a pre-determined path that passes through the center of the safety zone, as shown in Figure 27- (b), at constant velocity. As shown in Figure 27, the optimal paths generated by the p-Sulu planner and Sulu are not straight. Such curved paths use the Coriolis effect to minimize fuel consumption.Table 5 compares the performance of the three Sulli planning approaches, with the two rows showing the probabilities of plan failure with the two probabilities shown in Figure 25."}, {"heading": "8. Conclusions", "text": "This article introduced a model-based planner, the p-Sulu Planner, which operates within a custom risk. p-Sulu Planner optimizes a continuous control sequence and a discrete schedule, which provides for input of a continuous stochastic plant model, a newly developed landscaping, a random qualitative state plan. A CCQSP includes time-related objectives, simple time constraints, and random problems, which define the acceptable risk problems of the user in sub-areas of the plan. Our approach to the development of the p-Sulu Planner was twofold. In the first step, we developed an efficient algorithm called non-convex itinventing."}, {"heading": "Acknowledgments", "text": "This paper is based on work partially supported by The Boeing Company under grant number MITBA-GTA-1 and the National Science Foundation under grant number IIS-1017992. Any opinions, findings, conclusions or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the funding agencies. We thank Michael Kerstetter, Scott Smith, Ronald Provine and Hui Li of The Boeing Company for their support. We also thank Robert Irwin for advising on the design."}], "references": [{"title": "A robust model predictive control algorithm for incrementally conic uncertain/nonlinear systems", "author": ["B. Acikmese", "J.M. Carson III", "D.S. Bayard"], "venue": "International Journal of Robust and Nonlinear Control,", "citeRegEx": "Acikmese et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Acikmese et al\\.", "year": 2011}, {"title": "2005 Joseph T", "author": ["Aircraft Owners", "Pilots Association Air Safety Foundation"], "venue": "Nall Report - accident trands and factors for 2004..", "citeRegEx": "Owners and Foundation,? 2005", "shortCiteRegEx": "Owners and Foundation", "year": 2005}, {"title": "Constrained Markov decision processes", "author": ["E. Altman"], "venue": "Stochastic modeling. Chapman & Hall/CRC.", "citeRegEx": "Altman,? 1999", "shortCiteRegEx": "Altman", "year": 1999}, {"title": "The benefits of relaxing punctuality", "author": ["R. Alur", "T. Feder", "T.A. Henzinger"], "venue": "Journal of the ACM,", "citeRegEx": "Alur et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Alur et al\\.", "year": 1996}, {"title": "Planning for temporally extended goals", "author": ["F. Bacchus", "F. Kabanza"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "Bacchus and Kabanza,? \\Q1998\\E", "shortCiteRegEx": "Bacchus and Kabanza", "year": 1998}, {"title": "Disjunctive programming", "author": ["E. Balas"], "venue": "Annals of Discrete Mathematics.", "citeRegEx": "Balas,? 1979", "shortCiteRegEx": "Balas", "year": 1979}, {"title": "Dynamic Programming and Optimal Control Volume I (Third Edition)", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific.", "citeRegEx": "Bertsekas,? 2005", "shortCiteRegEx": "Bertsekas", "year": 2005}, {"title": "Neuro-Dynamic Programming (1st edition)", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": "Athena Scientific", "citeRegEx": "Bertsekas and Tsitsiklis,? \\Q1996\\E", "shortCiteRegEx": "Bertsekas and Tsitsiklis", "year": 1996}, {"title": "A probabilistic particle control approach to optimal, robust predictive control", "author": ["L. Blackmore"], "venue": "Proceedings of the AIAA Guidance, Navigation and Control Conference.", "citeRegEx": "Blackmore,? 2006", "shortCiteRegEx": "Blackmore", "year": 2006}, {"title": "A probabilistic approach to optimal robust path planning with obstacles", "author": ["L. Blackmore", "H. Li", "B.C. Williams"], "venue": "In Proceedings of American Control Conference", "citeRegEx": "Blackmore et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Blackmore et al\\.", "year": 2006}, {"title": "Convex chance constrained predictive control without sampling", "author": ["L. Blackmore", "M. Ono"], "venue": "In Proceedings of the AIAA Guidance, Navigation and Control Conference", "citeRegEx": "Blackmore and Ono,? \\Q2009\\E", "shortCiteRegEx": "Blackmore and Ono", "year": 2009}, {"title": "Exact solutions to time-dependent MDPs", "author": ["J.A. Boyan", "M.L. Littman"], "venue": "In in Advances in Neural Information Processing Systems,", "citeRegEx": "Boyan and Littman,? \\Q2000\\E", "shortCiteRegEx": "Boyan and Littman", "year": 2000}, {"title": "Generalization in reinforcement learning: Safely approximating the value function", "author": ["J.A. Boyan", "A.W. Moore"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Boyan and Moore,? \\Q1995\\E", "shortCiteRegEx": "Boyan and Moore", "year": 1995}, {"title": "Collision avoidance in satellite clusters", "author": ["M.E. Campbell", "B. Udrea"], "venue": "In Proceedings of the American Control Conference", "citeRegEx": "Campbell and Udrea,? \\Q2002\\E", "shortCiteRegEx": "Campbell and Udrea", "year": 2002}, {"title": "Colin: Planning with continuous linear numeric change", "author": ["A.J. Coles", "A. Coles", "M. Fox", "D. Long"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "Coles et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Coles et al\\.", "year": 2012}, {"title": "Constraint Processing", "author": ["R. Dechter"], "venue": "Elsevier.", "citeRegEx": "Dechter,? 2003", "shortCiteRegEx": "Dechter", "year": 2003}, {"title": "Temporal constraint networks", "author": ["R. Dechter", "I. Meiri", "J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "Dechter et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Dechter et al\\.", "year": 1991}, {"title": "Stationary deterministic policies for constrained MDPs with multiple rewards, costs, and discount factors", "author": ["D. Dolgov", "E. Durfee"], "venue": "Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence", "citeRegEx": "Dolgov and Durfee,? \\Q2005\\E", "shortCiteRegEx": "Dolgov and Durfee", "year": 2005}, {"title": "Dynamic programming for structured continuous markov decision problems", "author": ["Z. Feng", "R. Dearden", "N. Meuleau", "R. Washington"], "venue": "In Proceedings of the Proceedings of the Twentieth Conference Annual Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Feng et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2004}, {"title": "Risk-sensitive control on an infinite time horizon", "author": ["W. Fleming", "W. McEneaney"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "Fleming and McEneaney,? \\Q1995\\E", "shortCiteRegEx": "Fleming and McEneaney", "year": 1995}, {"title": "Modelling mixed discrete-continuous domains for planning", "author": ["M. Fox", "D. Long"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Fox and Long,? \\Q2006\\E", "shortCiteRegEx": "Fox and Long", "year": 2006}, {"title": "Risk-sensitive reinforcement learning applied to control under constraints", "author": ["P. Geibel", "F. Wysotzki"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Geibel and Wysotzki,? \\Q2005\\E", "shortCiteRegEx": "Geibel and Wysotzki", "year": 2005}, {"title": "Optimization over state feedback policies for robust control with constraints", "author": ["P.J. Goulart", "E.C. Kerrigan", "J.M. Maciejowski"], "venue": "Automatica, 42(4),", "citeRegEx": "Goulart et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Goulart et al\\.", "year": 2006}, {"title": "Robust execution of temporally flexible plans for bipedal walking devices", "author": ["A.G. Hofmann", "B.C. Williams"], "venue": "In Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS-06)", "citeRegEx": "Hofmann and Williams,? \\Q2006\\E", "shortCiteRegEx": "Hofmann and Williams", "year": 2006}, {"title": "Optimal stochastic linear systems with exponential performance criteria and their relation to deterministic differential games", "author": ["D. Jacobson"], "venue": "Automatic Control, IEEE Transactions on, 18(2), 124 \u2013 131.", "citeRegEx": "Jacobson,? 1973", "shortCiteRegEx": "Jacobson", "year": 1973}, {"title": "HTV-1 mission press kit", "author": ["Japan Aerospace Exploration Agency"], "venue": "Available on-line at http: //www.jaxa.jp/countdown/h2bf1/pdf/presskit_htv_e.pdf.", "citeRegEx": "Agency,? 2009", "shortCiteRegEx": "Agency", "year": 2009}, {"title": "Cooperative distributed robust trajectory optimization using receding horizon MILP", "author": ["Y. Kuwata", "J.P. How"], "venue": "IEEE Transactions on Control Systems Technology,", "citeRegEx": "Kuwata and How,? \\Q2011\\E", "shortCiteRegEx": "Kuwata and How", "year": 2011}, {"title": "Real-time trajectory design for unmanned aerial vehicles using receding horizon control", "author": ["Y. Kuwata"], "venue": "Master\u2019s thesis, Massachusetts Institute of Technology.", "citeRegEx": "Kuwata,? 2003", "shortCiteRegEx": "Kuwata", "year": 2003}, {"title": "Talplanner: A temporal logic based forward chaining planner", "author": ["J. Kvarnstrom", "P. Doherty"], "venue": "Annals of Mathematics and Artificial Intelligence", "citeRegEx": "Kvarnstrom and Doherty,? \\Q2000\\E", "shortCiteRegEx": "Kvarnstrom and Doherty", "year": 2000}, {"title": "Least-squares policy iteration", "author": ["M.G. Lagoudakis", "R. Parr"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Lagoudakis and Parr,? \\Q2003\\E", "shortCiteRegEx": "Lagoudakis and Parr", "year": 2003}, {"title": "Coordinating agile systems through the model-based execution of temporal plans", "author": ["T. L\u00e9aut\u00e9"], "venue": "Master\u2019s thesis, Massachusetts Institute of Technology.", "citeRegEx": "L\u00e9aut\u00e9,? 2005", "shortCiteRegEx": "L\u00e9aut\u00e9", "year": 2005}, {"title": "Coordinating agile systems through the model-based execution of temporal plans", "author": ["T. L\u00e9aut\u00e9", "B.C. Williams"], "venue": "In Proceedings of the Twentieth National Conference on Artificial Intelligence (AAAI)", "citeRegEx": "L\u00e9aut\u00e9 and Williams,? \\Q2005\\E", "shortCiteRegEx": "L\u00e9aut\u00e9 and Williams", "year": 2005}, {"title": "Generalized conflict learning for hybrid discrete linear optimization", "author": ["H. Li", "B.C. Williams"], "venue": "In Proc. 11th International Conf. on Principles and Practice of Constraint Programming", "citeRegEx": "Li and Williams,? \\Q2005\\E", "shortCiteRegEx": "Li and Williams", "year": 2005}, {"title": "Kongming: A Generative Planner for Hybrid Systems with Temporally Extended Goals", "author": ["H.X. Li"], "venue": "Ph.D. thesis, Massachusetts Institute of Technology.", "citeRegEx": "Li,? 2010", "shortCiteRegEx": "Li", "year": 2010}, {"title": "Fly-by approach and guidance for uncontrolled rotating satellite capture", "author": ["S. Matsumoto", "S. Dubowsky", "S. Jacobsen", "Y. Ohkami"], "venue": "In Proceedings of AIAA Guidance,", "citeRegEx": "Matsumoto et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Matsumoto et al\\.", "year": 2003}, {"title": "Convex approximations of chance constrained programs", "author": ["A. Nemirovski", "A. Shapiro"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nemirovski and Shapiro,? \\Q2006\\E", "shortCiteRegEx": "Nemirovski and Shapiro", "year": 2006}, {"title": "A tractable approximation of chance constrained stochastic MPC based on affine disturbance feedback", "author": ["F. Oldewurtel", "C.N. Jones", "M. Morari"], "venue": "In Proceedings of Conference on Decision and Control", "citeRegEx": "Oldewurtel et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Oldewurtel et al\\.", "year": 2008}, {"title": "Closed-loop chance-constrained MPC with probabilistic resolvability", "author": ["M. Ono"], "venue": "Proceedings of the IEEE Conference on Decision and Control.", "citeRegEx": "Ono,? 2012", "shortCiteRegEx": "Ono", "year": 2012}, {"title": "Risk-sensitive plan execution for connected sustainable home", "author": ["M. Ono", "W. Graybill", "B.C. Williams"], "venue": "In Proceedings of the 4th ACM Workshop On Embedded Systems (BuildSys)", "citeRegEx": "Ono et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ono et al\\.", "year": 2012}, {"title": "An efficient motion planning algorithm for stochastic dynamic systems with constraints on probability of failure", "author": ["M. Ono", "B.C. Williams"], "venue": "In Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence (AAAI-08)", "citeRegEx": "Ono and Williams,? \\Q2008\\E", "shortCiteRegEx": "Ono and Williams", "year": 2008}, {"title": "Iterative risk allocation: A new approach to robust model predictive control with a joint chance constraint", "author": ["M. Ono", "B.C. Williams"], "venue": "In Proceedings of 47th IEEE Conference on Decision and Control", "citeRegEx": "Ono and Williams,? \\Q2008\\E", "shortCiteRegEx": "Ono and Williams", "year": 2008}, {"title": "The use of discrete moment bounds in probabilistic constrained stochastic programming models", "author": ["A. Pr\u00e9kopa"], "venue": "Annals of Operations Research, 85, 21\u201338.", "citeRegEx": "Pr\u00e9kopa,? 1999", "shortCiteRegEx": "Pr\u00e9kopa", "year": 1999}, {"title": "Robust stable model predictive control with constraint tightening", "author": ["A. Richards", "J. How"], "venue": "In American Control Conference,", "citeRegEx": "Richards and How,? \\Q2006\\E", "shortCiteRegEx": "Richards and How", "year": 2006}, {"title": "Relational dynamic influence diagram language (RDDL): Language description", "author": ["S. Sanner"], "venue": "Available at http://users.cecs.anu.edu.au/ \u0303ssanner/IPPC_2011/RDDL. pdf.", "citeRegEx": "Sanner,? 2011", "shortCiteRegEx": "Sanner", "year": 2011}, {"title": "Analytical mechanics of space systems", "author": ["H. Schaub", "J.L. Junkins"], "venue": "American Institute of Aeronautics and Astronautics,", "citeRegEx": "Schaub and Junkins,? \\Q2003\\E", "shortCiteRegEx": "Schaub and Junkins", "year": 2003}, {"title": "Metrology sensor characterization and pointing control for the formation interferometer testbed (fit)", "author": ["J. Shields", "S. Sirlin", "M. Wette"], "venue": "In Proceedings of IEEE Aerospace Conference", "citeRegEx": "Shields et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Shields et al\\.", "year": 2002}, {"title": "Distributed estimation, communication and control for deep space formations", "author": ["R. Smith", "F. Hadaegh"], "venue": "IET Control Theory and Applications", "citeRegEx": "Smith and Hadaegh,? \\Q2007\\E", "shortCiteRegEx": "Smith and Hadaegh", "year": 2007}, {"title": "The H\u221e Control Problem: A State Space Approach", "author": ["A. Stoorvogel"], "venue": "Prentice Hall. Vallado, D. A. (2001). Fundamentals of Astrodynamics and Applications, Second Edition. Microcosm Press.", "citeRegEx": "Stoorvogel,? 1992", "shortCiteRegEx": "Stoorvogel", "year": 1992}, {"title": "Stochastic inequality constrained closed-loop model predictive control with application to chemical process operation", "author": ["D.H. van Hessem"], "venue": "Ph.D. thesis,", "citeRegEx": "Hessem,? \\Q2004\\E", "shortCiteRegEx": "Hessem", "year": 2004}, {"title": "Cooperative uav formation flying with obstacle/collision avoidance", "author": ["X. Wang", "V. Yadav", "S.N. Balakrishnan"], "venue": "IEEE Transactions on Control Systems", "citeRegEx": "Wang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2007}, {"title": "Space Mission Analysis and Design (Third Edition). Microcosm/Springer", "author": ["J.R. Wertz", "Wiley J. Larson"], "venue": null, "citeRegEx": "Wertz et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Wertz et al\\.", "year": 1999}, {"title": "PPDDL1.0: An extension to pddl for expressing planning domains with probabilistic effects", "author": ["H.L.S. Younes", "M.L. Littman"], "venue": null, "citeRegEx": "Younes and Littman,? \\Q2004\\E", "shortCiteRegEx": "Younes and Littman", "year": 2004}], "referenceMentions": [{"referenceID": 33, "context": "Journal of Artificial Intelligence Research 46 (2013) 511-577 Submitted 12/12; published 03/13", "startOffset": 27, "endOffset": 54}, {"referenceID": 27, "context": "This is a stochastic extension of the continuous plant model used by L\u00e9aut\u00e9 and Williams (2005). In this paper we limit our focus to Gaussian-distributed uncertainty.", "startOffset": 69, "endOffset": 96}, {"referenceID": 27, "context": "This is a stochastic extension of the continuous plant model used by L\u00e9aut\u00e9 and Williams (2005). In this paper we limit our focus to Gaussian-distributed uncertainty. Chance-constrained qualitative state plan (CCQSP) In order to provide users with an intuitive way to command stochastic systems, we develop a new plan representation called a chanceconstrained qualitative state plan (CCQSP). It is an extension of qualitative state plan (QSP), developed and used by L\u00e9aut\u00e9 and Williams (2005), Hofmann and Williams (2006), and Blackmore, Li, and Williams (2006).", "startOffset": 69, "endOffset": 493}, {"referenceID": 21, "context": "It is an extension of qualitative state plan (QSP), developed and used by L\u00e9aut\u00e9 and Williams (2005), Hofmann and Williams (2006), and Blackmore, Li, and Williams (2006).", "startOffset": 102, "endOffset": 130}, {"referenceID": 8, "context": "It is an extension of qualitative state plan (QSP), developed and used by L\u00e9aut\u00e9 and Williams (2005), Hofmann and Williams (2006), and Blackmore, Li, and Williams (2006). CCQSP specifies a desired evolution of the plant state over time, and is defined by a set of discrete events, a set of episodes, which impose constraints on the plant state evolution, a set of temporal constraints between events, and a set of chance constraints that specify reliability constraints on the success of sets of episodes in the plan.", "startOffset": 135, "endOffset": 170}, {"referenceID": 33, "context": "TLPlan uses a version of metric interval temporal logic (MITL) (Alur, Feder, & Henzinger, 1996) applied to discrete states, while the p-Sulu Planner uses qualitative state plans (QSPs) (L\u00e9aut\u00e9 & Williams, 2005; Hofmann & Williams, 2006; Li, 2010) over continuous states.", "startOffset": 185, "endOffset": 246}, {"referenceID": 33, "context": "Kongming (Li, 2010) provides a generative planning capability for hybrid", "startOffset": 9, "endOffset": 19}, {"referenceID": 30, "context": "TLPlan uses a version of metric interval temporal logic (MITL) (Alur, Feder, & Henzinger, 1996) applied to discrete states, while the p-Sulu Planner uses qualitative state plans (QSPs) (L\u00e9aut\u00e9 & Williams, 2005; Hofmann & Williams, 2006; Li, 2010) over continuous states. Li (2010) shows that, for a given state space, any QSP can be expressed in MITL.", "startOffset": 186, "endOffset": 281}, {"referenceID": 43, "context": "Probabilistic PDDL (Younes & Littman, 2004) and the Relational Dynamic influence Diagram Language (RDDL) (Sanner, 2011) can handle stochastic systems.", "startOffset": 105, "endOffset": 119}, {"referenceID": 2, "context": "The constrained MDP approach (Altman, 1999) can explicitly impose constraints.", "startOffset": 29, "endOffset": 43}, {"referenceID": 29, "context": "These planners adapt to the effects of uncertainty, but do not explicitly reason about the effects of uncertainty during planning. For example, Sulu employs a receding horizon approach, which continuously replans the control sequence using the latest measurements. Chekhov\u2019s flow tube representation of feasible policies allows the executive to generate new control sequences in response to disturbances on-line. The p-Sulu Planner is distinct from these continuous planners in that it plans with a model of uncertainty in dynamics, instead of just reacting to it. Its plan guarantees the user-specified probability of success by explicitly reasoning about the effects of uncertainty. In AI planning literatures, a planning domain description language, PDDL+, supports mixed discrete-continuous planning domains (Fox& Long, 2006). Probabilistic PDDL (Younes & Littman, 2004) and the Relational Dynamic influence Diagram Language (RDDL) (Sanner, 2011) can handle stochastic systems. Recently, Coles, Coles, Fox, and Long (2012) developed a forward-chaining heuristic search planner named COLIN, which can deal with continuous linear change and durationdependent effects.", "startOffset": 66, "endOffset": 1027}, {"referenceID": 9, "context": "The time-dependent MDP developed by Boyan and Littman (2000) can handle continuous time by encoding time in the state.", "startOffset": 36, "endOffset": 61}, {"referenceID": 2, "context": "The constrained MDP approach (Altman, 1999) can explicitly impose constraints. Dolgov and Durfee (2005) showed that stationary deterministic policies for constrained MDPs can be obtained by solving a mixed integer linear program (MILP).", "startOffset": 30, "endOffset": 104}, {"referenceID": 47, "context": "For example, the celebrated H\u221e control method minimizes the effect of disturbances on the output of a system while guaranteeing the stability of the system (Stoorvogel, 1992).", "startOffset": 156, "endOffset": 174}, {"referenceID": 24, "context": "Risk-sensitive control approaches allow users to choose the level of risk averseness through the minimization of an expected exponentiated cost function (Jacobson, 1973; Fleming & McEneaney, 1995).", "startOffset": 153, "endOffset": 196}, {"referenceID": 19, "context": "As far as the authors know, the risk-sensitive reinforcement learning approach proposed by Geibel and Wysotzki (2005) is the only work that considers chance constraints in the MDP framework.", "startOffset": 91, "endOffset": 118}, {"referenceID": 19, "context": "As far as the authors know, the risk-sensitive reinforcement learning approach proposed by Geibel and Wysotzki (2005) is the only work that considers chance constraints in the MDP framework. They developed a reinforcement learning algorithm for MDPs with a constraint on the probability of entering error states. Our work is distinct from theirs in that the p-Sulu Planner is goal-directed, by which we mean that it achieves time-evolved goals within user-specified temporal constraints. To summarize, no prior MDP work supports continuous state and actions in combination with general continuous noise on transitions while ensuring that the probability of failure is bounded. Risk-sensitive control methods in a continuous domain have been extensively studied in the discipline of control theory. For example, the celebrated H\u221e control method minimizes the effect of disturbances on the output of a system while guaranteeing the stability of the system (Stoorvogel, 1992). Risk-sensitive control approaches allow users to choose the level of risk averseness through the minimization of an expected exponentiated cost function (Jacobson, 1973; Fleming & McEneaney, 1995). However, these approaches do not address chance constraints and optimal scheduling. Several methods have been proposed for solving stochastic optimal control problems over continuous variables with chance constraints. The method proposed by van Hessem (2004) turns a stochastic problem into a deterministic problem using a very conservative ellipsoidal relaxation.", "startOffset": 91, "endOffset": 1431}, {"referenceID": 8, "context": "Blackmore (2006) proposes a sampling-based method called Particle Control, which evaluates joint chance constraints by a Monte-Carlo simulation, instead of using a conservative bound.", "startOffset": 0, "endOffset": 17}, {"referenceID": 8, "context": "Blackmore (2006) proposes a sampling-based method called Particle Control, which evaluates joint chance constraints by a Monte-Carlo simulation, instead of using a conservative bound. As a result, the stochastic planning problem is reduced to a MILP problem. Although it has a theoretical guarantee that it can obtain the exactly optimal solution when an infinite number of samples are used, computation time is an issue. Blackmore et al. (2006) and Nemirovski and Shapiro (2006) employed Boole\u2019s inequality to decompose a joint chance constraint into individual chance constraints.", "startOffset": 0, "endOffset": 446}, {"referenceID": 8, "context": "Blackmore (2006) proposes a sampling-based method called Particle Control, which evaluates joint chance constraints by a Monte-Carlo simulation, instead of using a conservative bound. As a result, the stochastic planning problem is reduced to a MILP problem. Although it has a theoretical guarantee that it can obtain the exactly optimal solution when an infinite number of samples are used, computation time is an issue. Blackmore et al. (2006) and Nemirovski and Shapiro (2006) employed Boole\u2019s inequality to decompose a joint chance constraint into individual chance constraints.", "startOffset": 0, "endOffset": 480}, {"referenceID": 6, "context": "Such a feedback gain can be found by using standard control techniques, such as a linear quadratic regulator (LQR) (Bertsekas, 2005).", "startOffset": 115, "endOffset": 132}, {"referenceID": 36, "context": "This approach is often used for robust and stochastic model predictive controls (Goulart, Kerrigan, & Maciejowski, 2006; Oldewurtel et al., 2008; Ono, 2012).", "startOffset": 80, "endOffset": 156}, {"referenceID": 37, "context": "This approach is often used for robust and stochastic model predictive controls (Goulart, Kerrigan, & Maciejowski, 2006; Oldewurtel et al., 2008; Ono, 2012).", "startOffset": 80, "endOffset": 156}, {"referenceID": 20, "context": "(8) A closed-loop control approach has been employed by Geibel and Wysotzki (2005) and Oldewurtel et al.", "startOffset": 56, "endOffset": 83}, {"referenceID": 20, "context": "(8) A closed-loop control approach has been employed by Geibel and Wysotzki (2005) and Oldewurtel et al. (2008) in the context of chance-constrained optimal control and shown that it significantly improves performance.", "startOffset": 56, "endOffset": 112}, {"referenceID": 16, "context": "Temporal constraint A CCQSP includes simple temporal constraints (STCs) (Dechter et al., 1991), which impose upper and lower bounds on the duration of episodes and on the temporal distances between two events in E .", "startOffset": 72, "endOffset": 94}, {"referenceID": 21, "context": "A similar problem encoding is also employed in the chance-constraint MDP proposed by Geibel and Wysotzki (2005). However, our encoding differs from Geibel and Wysotzki in two respects: 1) we optimize not only the continuous control sequence u0:N\u22121 but also the discrete schedule s with temporal constraints; 2) we allow joint chance constraints, which require the satisfaction of multiple state constraints for a given probability.", "startOffset": 85, "endOffset": 112}, {"referenceID": 37, "context": "The reformulation was initially presented by Pr\u00e9kopa (1999) and introduced to chance-constrained optimal control by Ono and Williams (2008b).", "startOffset": 45, "endOffset": 60}, {"referenceID": 33, "context": "The reformulation was initially presented by Pr\u00e9kopa (1999) and introduced to chance-constrained optimal control by Ono and Williams (2008b). The concept of risk allocation was originally developed by Ono and Williams (2008a).", "startOffset": 127, "endOffset": 141}, {"referenceID": 33, "context": "The reformulation was initially presented by Pr\u00e9kopa (1999) and introduced to chance-constrained optimal control by Ono and Williams (2008b). The concept of risk allocation was originally developed by Ono and Williams (2008a). Let Ci be a proposition that is either true or false.", "startOffset": 127, "endOffset": 226}, {"referenceID": 33, "context": "This completes the proof of Lemma 3 We note that Lemma 3 is a probabilistic extension of the closed-loop robust model predictive control (RMPC) methods proposed by Acikmese, Carson III, and Bayard (2011) and Richards and How (2006).", "startOffset": 69, "endOffset": 204}, {"referenceID": 33, "context": "This completes the proof of Lemma 3 We note that Lemma 3 is a probabilistic extension of the closed-loop robust model predictive control (RMPC) methods proposed by Acikmese, Carson III, and Bayard (2011) and Richards and How (2006). These methods avoid the risk of actuator saturation by imposing tightened control constraints on \u016bt.", "startOffset": 69, "endOffset": 232}, {"referenceID": 8, "context": "Furthermore, Blackmore and Ono (2009) showed that an optimal solution to Problem 5 is a near-optimal solution to Problem 4.", "startOffset": 13, "endOffset": 38}, {"referenceID": 5, "context": "This approach was used by Balas (1979) and Li andWilliams (2005) for a different problem known as disjunctive linear programming, whose subproblems are LPs instead of convex programmings.", "startOffset": 26, "endOffset": 39}, {"referenceID": 5, "context": "This approach was used by Balas (1979) and Li andWilliams (2005) for a different problem known as disjunctive linear programming, whose subproblems are LPs instead of convex programmings.", "startOffset": 26, "endOffset": 65}, {"referenceID": 15, "context": "Figure 11-(a) is the distance graph representation of the simple temporal constraints (Dechter, 2003) of the CCQSP.", "startOffset": 86, "endOffset": 101}, {"referenceID": 16, "context": "The d-graph (Figure 11-(b)) is obtained from the distance graph (Figure 11-(a)) by running an all-pair shortest-path algorithm (Dechter et al., 1991).", "startOffset": 127, "endOffset": 149}, {"referenceID": 15, "context": "It is shown by Dechter et al. (1991) that the set of feasible execution times for an event e is bounded by the distance between e and e0 on the dgraph.", "startOffset": 15, "endOffset": 37}, {"referenceID": 15, "context": "Dechter et al. (1991) showed that dmax e\u2032 (\u03c3) corresponds to the upper bound of the feasible execution time for an unassigned event e\u2032, while dmin eE (\u03c3) corresponds to the negative of the lower bound.", "startOffset": 0, "endOffset": 22}, {"referenceID": 30, "context": "This plant model is commonly assumed in literatures on unmanned aerial vehicle (UAV) path planning (Kuwata & How, 2011; L\u00e9aut\u00e9, 2005; Wang, Yadav, & Balakrishnan, 2007).", "startOffset": 99, "endOffset": 168}, {"referenceID": 9, "context": "Fixed risk allocation (Blackmore et al., 2006) - This approach fixes the risk allocation to a uniform value.", "startOffset": 22, "endOffset": 46}, {"referenceID": 8, "context": "Particle Control (Blackmore, 2006) - Particle Control is a sampling-based method, which uses a finite number of samples to approximate the joint chance constraints.", "startOffset": 17, "endOffset": 34}, {"referenceID": 27, "context": "This issue can be addressed by a constraint-tightening method (Kuwata, 2003).", "startOffset": 62, "endOffset": 76}, {"referenceID": 33, "context": "3 SCALABILITY ANALYSIS In this subsection we conduct an empirical analysis of the scalability of the p-Sulu Planner, as the environment becomes increasingly constrained.. As shown in Figure 20, we measured the computation time to solve a path planning problem with different numbers of obstacles and waypoints. In all simulations, the path starts at [0, 12] and ends in a square region centered at [24, 12]. Figure 20 shows twenty simulation results, with zero to three obstacles and zero to four waypoints. Obstacles and waypoints are represented by blue and red squares in the figure, respectively. The positions of the center of the obstacles are [6, 12], [12, 12], and [18, 12], while the positions of the center of the waypoints are [9, 9], [9, 15], [15, 15], and [15, 9]. The computation time is shown in the caption of each subfigure in Figure 20. By comparing the results in Figure 20 horizontally, we observe exponential growth in computation time with the number of obstacles. This result is expected since the number of disjunctive clauses in the state constraint of the p-Sulu Planner increases exponentially with the number of obstacles. Building a tractable extension of the p-Sulu Planner for a large number of obstacles is future work. On the other hand, by comparing the results vertically, we find that the computation time with the same number of obstacles and different number of waypoints stays in the same order of magnitude. This is because adding an extra waypoint only increases the number of conjunctive clauses in the state constraints. In the remaining sections we describe the application of psulu to two real world problems, air vehicle and space vehicle control. A third application, building energy management, using a variant of the p-Sulu Planner, is reported by Ono, Graybill, and Williams (2012).", "startOffset": 9, "endOffset": 1832}, {"referenceID": 25, "context": "Please refer to the report by Japan Aerospace Exploration Agency (2009) for the details of the rendezvous sequence.", "startOffset": 58, "endOffset": 72}], "year": 2013, "abstractText": "This paper presents a model-based planner called the Probabilistic Sulu Planner or the p-Sulu Planner, which controls stochastic systems in a goal directed manner within user-specified risk bounds. The objective of the p-Sulu Planner is to allow users to command continuous, stochastic systems, such as unmanned aerial and space vehicles, in a manner that is both intuitive and safe. To this end, we first develop a new plan representation called a chance-constrained qualitative state plan (CCQSP), through which users can specify the desired evolution of the plant state as well as the acceptable level of risk. An example of a CCQSP statement is \u201cgo to A through B within 30 minutes, with less than 0.001% probability of failure.\u201d We then develop the p-Sulu Planner, which can tractably solve a CCQSP planning problem. In order to enable CCQSP planning, we develop the following two capabilities in this paper: 1) risk-sensitive planning with risk bounds, and 2) goal-directed planning in a continuous domain with temporal constraints. The first capability is to ensures that the probability of failure is bounded. The second capability is essential for the planner to solve problems with a continuous state space such as vehicle path planning. We demonstrate the capabilities of the p-Sulu Planner by simulations on two real-world scenarios: the path planning and scheduling of a personal aerial vehicle as well as the space rendezvous of an autonomous cargo spacecraft.", "creator": " TeX output 2013.09.27:1252"}}}