{"id": "1402.1668", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2014", "title": "Evaluation of YTEX and MetaMap for clinical concept recognition", "abstract": "We used MetaMap and YTEX as a basis for the construc- tion of two separate systems to participate in the 2013 ShARe/CLEF eHealth Task 1[9], the recognition of clinical concepts. No modifications were directly made to these systems, but output concepts were filtered using stop concepts, stop concept text and UMLS semantic type. Con- cept boundaries were also adjusted using a small collection of rules to increase precision on the strict task. Overall MetaMap had better per- formance than YTEX on the strict task, primarily due to a 20% perfor- mance improvement in precision. In the relaxed task YTEX had better performance in both precision and recall giving it an overall F-Score 4.6% higher than MetaMap on the test data. Our results also indicated a 1.3% higher accuracy for YTEX in UMLS CUI mapping.", "histories": [["v1", "Fri, 7 Feb 2014 15:33:44 GMT  (24kb)", "http://arxiv.org/abs/1402.1668v1", "6 pages, working notes to the ShareClef eHealth 2013 Shared Task"]], "COMMENTS": "6 pages, working notes to the ShareClef eHealth 2013 Shared Task", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["john david osborne", "binod gyawali", "thamar solorio"], "accepted": false, "id": "1402.1668"}, "pdf": {"name": "1402.1668.pdf", "metadata": {"source": "CRF", "title": "Evaluation of YTEX and MetaMap for clinical concept recognition", "authors": ["John David Osborne", "Binod Gyawali"], "emails": ["ozborn@uab.edu,", "gyawali@uab.edu,", "solorio@uab.edu,"], "sections": [{"heading": null, "text": "ar Xiv: 140 2.16 68v1 [cs.IR] 7 Feb 2Keywords: clinical concept recognition, MetaMap, YTEX, evaluation, information extraction"}, {"heading": "1 Introduction", "text": "Mapping natural language text to a defined dictionary of concepts is one of the main tasks of information extraction, and a variety of software has been written to solve this problem. We informally evaluated a small set of open source and freely available software for this task before selecting MetaMap [2] and YTEX [6] for a more formal evaluation. Our goal was to find off-the-shelf software that could find disease mentions in clinical text and is robust in clinical terms, as well as document structure and syntax. Although MetaMap was designed for publication, it continues to be based on clinical texts, often as a standard of comparison. Although YTEX has received comparatively little attention, it is based on the more popular cTAKES [8] system, which was developed for the Mayo Clinic and is designed specifically for clinical text. We downloaded and informally evaluated cTAKES, but the text search analogous to Yc.2 was found by adding Luc.2 components to Luc.2"}, {"heading": "2 Methodology", "text": "The CORAL.1 system uses the 2012 version of MetaMap for concept recognition, whereas the CORAL.2 system uses YTEX 0.8. MetaMap was called using the MetaMap UIMA annotator to enable integration into our NLP framework, which is also based on UIMA [5]. YTEX was run as a standalone system, and then a custom UIMA annotator was used to transfer the results from the YTEX database into a format compatible with our system. Matches from both systems were then processed in the same manner, running an identical set of annotators, and processing included filtering to remove high-level stop concepts (20 in total) that were not typically used or useful for fine-grained concept detection. Two such examples are \"disease\" (C0012634) and \"injury\" (0561777)."}, {"heading": "2.1 Parameter Settings", "text": "For YTEX, default settings were used, including a concept window of length 10 and the default setting INTRINSIC as a semantic similarity metric. MetaMap was executed with the included literal disambiguation server (-y option) and limited permitted concepts to the SNOMED CT R \u00a9 and RXNORM vocabularies. This is implicitly included in the default configuration of YTEX, which indexes these two vocabularies by default."}, {"heading": "2.2 Patient Tracking List (PTL) Data Set", "text": "Before performing the data for the ShareClef task, we evaluated both MetaMap and YTEX using PTL notes from the University of Alabama at Birmingham Health System. PTL documents consisted of a summary of the patient's condition, with most of the text written in the form of texts and some complete sentences; an exact breakdown was not calculated; the document was irregularly formatted, but highly structured so that, unlike ShareClef analysis, only disease mentions were analyzed in the corresponding \"problem\" sections of the PTL document; document segmentation was performed using a complex, manually derived regular expression to identify the beginning and end of the problem section; the same term was used for both YTEX and MetaMap. In total, there are 68 such commented PTL documents with 603 commented units, of which 223 are problems. Annotation was performed by two annotators (including a 99% doctor-observed overtones) and one Coha."}, {"heading": "3 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Concept Boundary Detection Results", "text": "The results for the detection of concept boundaries (task 1a) are shown in Table 1 and Table 2 for training and test data.The detection of limits was difficult for both systems, in part because neither MetaMap nor YTEX was able to comment on discontinuous concept boundaries, which limited the effectiveness of both systems and effectively capped maximum performance. Furthermore, MetaMap tended to contain additional text (mainly prepositions and modifiers) that the ShareClef annotators did not use. YTEX precision was significantly reduced by the inclusion of simple nouns when the annotators expected a compound noun. As a result, YTEX performed poorly in the strict task compared to MetaMap. 4The results were harder to compare for task 1b, the assignment of text to CUIs. The PTL results (shown in Table 3) do not include accuracy data, nor do the negative TL file misrepresent accuracy data, such as the negative TL sharpens in the file."}, {"heading": "4 Discussion", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "5 Acknowledgements", "text": "This project was supported by the UAB Center for Clinical and Translational Sciences - grant number UL1 RR025777 of the National Center for Research Resources of the NIH and the Office of the Vice President of Information Technology of the UAB."}], "references": [{"title": "MetaMap Candidate Retrieval", "author": ["A.R. Aronson"], "venue": "Technical Report, Lister Hill National Center for Biomedical Communications, National Library of Medicine", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2001}, {"title": "An overview of MetaMap: historical perspective and recent advances", "author": ["A.R. Aronson", "F.M. Lang"], "venue": "J. Am. Med. Inform. Ass. 17 229\u2013236", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "An adapted Lesk algorithm for word sense disambiguation using WordNet", "author": ["S. Banerjee", "T. Pedersen"], "venue": "Computational linguistics and intelligent text processing. 136\u2013145", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Assessing agreement on classification tasks: the kappa statistic", "author": ["J. Carletta"], "venue": "Comp. Ling. 22 249\u2013254", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1996}, {"title": "UIMA: an architectural approach to unstructured information processing in the corporate research environment", "author": ["D. Ferrucci", "A. Lally"], "venue": "Nat. Lang. Eng. 10 327\u2013348", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "The Yale cTAKES extensions for document classification: architecture and application", "author": ["V. Garla", "V.L. Re III", "Z. Dorey-Stein", "F. Kidwai", "M. Scotch", "J. Womack", "A. Justice", "C. Brandt"], "venue": "J. Am. Med. Inform. Ass. 18 614\u2013620", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Knowledge-based biomedical word sense disambiguation: an evaluation and application to clinical document classification", "author": ["V.N. Garla", "C. Brandt"], "venue": "2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology (HISB) 22\u201322", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications", "author": ["G.K. Savova", "J.J. Masanz", "P.V. Ogren", "J. Zheng", "S. Sohn", "K.C. Kipper-Schuler", "C.G. Chute"], "venue": "J. Am. Med. Inform. Ass. 17 507\u2013513", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Three Shared Tasks on Clinical Natural Language Processing", "author": ["H Suominen", "S Salantera", "S Velupillai"], "venue": "Proceedings of CLEF 2013 To appear.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 8, "context": "We used MetaMap and YTEX as a basis for the construction of two separate systems to participate in the 2013 ShARe/CLEF eHealth Task 1[9], the recognition of clinical concepts.", "startOffset": 133, "endOffset": 136}, {"referenceID": 1, "context": "We informally assessed a small set of open source and freely available software for this task, before selecting MetaMap [2] and YTEX [6] for a more formal evaluation.", "startOffset": 120, "endOffset": 123}, {"referenceID": 5, "context": "We informally assessed a small set of open source and freely available software for this task, before selecting MetaMap [2] and YTEX [6] for a more formal evaluation.", "startOffset": 133, "endOffset": 136}, {"referenceID": 7, "context": "Although YTEX has received comparatively little attention, it is based on the more popular cTAKES [8] system developed for the Mayo Clinic and is specifically designed for clinical text.", "startOffset": 98, "endOffset": 101}, {"referenceID": 6, "context": "Recently YTEX has improved on cTAKES dictionary lookup by adding a sense disambiguation component [7] that allows the most appropriate concept for that text.", "startOffset": 98, "endOffset": 101}, {"referenceID": 2, "context": "It uses the adapted Lesk Method [3]", "startOffset": 32, "endOffset": 35}, {"referenceID": 0, "context": "to compute semantic similarly over a context window, whereas MetaMap uses a series of weighted heuristics to select the appropriate candidate [1].", "startOffset": 142, "endOffset": 145}, {"referenceID": 4, "context": "MetaMap was called using the MetaMap UIMA annotator to allow for integration into our NLP framework which is also UIMA [5] based.", "startOffset": 119, "endOffset": 122}, {"referenceID": 3, "context": "9% (uncorrected Cohen\u2019s kappa) [4].", "startOffset": 31, "endOffset": 34}, {"referenceID": 6, "context": "An earlier evaluation of YTEX sense disambiguation [7] revealed that no single semantic similarity performed best on all datasets and that parameter could have been adjusted to the training set.", "startOffset": 51, "endOffset": 54}], "year": 2014, "abstractText": "We used MetaMap and YTEX as a basis for the construction of two separate systems to participate in the 2013 ShARe/CLEF eHealth Task 1[9], the recognition of clinical concepts. No modifications were directly made to these systems, but output concepts were filtered using stop concepts, stop concept text and UMLS semantic type. Concept boundaries were also adjusted using a small collection of rules to increase precision on the strict task. Overall MetaMap had better performance than YTEX on the strict task, primarily due to a 20% performance improvement in precision. In the relaxed task YTEX had better performance in both precision and recall giving it an overall F-Score 4.6% higher than MetaMap on the test data. Our results also indicated a 1.3% higher accuracy for YTEX in UMLS CUI mapping.", "creator": "LaTeX with hyperref package"}}}