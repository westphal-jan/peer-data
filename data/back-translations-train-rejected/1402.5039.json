{"id": "1402.5039", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2014", "title": "Interpreting social cues to generate credible affective reactions of virtual job interviewers", "abstract": "The goal of this paper is to present a scenario-based serious-game simulation platform that supports social training and coaching in the context of job interviews. It relies on the use of virtual agents that are capable to react in real time to a human interlocutor's expressed affects, through the detection of non-verbal cues, their analysis and their interpretation in the context of the job interview situation. Our system build affective states and beliefs about a real user in interaction with a virtual character. To this end, we rely on real-time social cue recognition, communicative performance computation and affective computation/decision from the recruiter. Indeed, building a credible job interview simulation with a reactive virtual agent requires to perceive the applicant in order to understand its reactions and adapt to his performance.", "histories": [["v1", "Thu, 20 Feb 2014 15:38:43 GMT  (487kb,D)", "https://arxiv.org/abs/1402.5039v1", null], ["v2", "Tue, 25 Feb 2014 11:04:53 GMT  (541kb,D)", "http://arxiv.org/abs/1402.5039v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CY", "authors": ["haza\u007fel jones", "nicolas sabouret", "ionut damian", "tobias baur", "elisabeth", "r\\'e", "ka\\'ska porayska-pomsta", "paola rizzo"], "accepted": false, "id": "1402.5039"}, "pdf": {"name": "1402.5039.pdf", "metadata": {"source": "CRF", "title": "Interpreting social cues to generate credible affective reactions of virtual job interviewers", "authors": ["Haza\u00ebl Jones", "Nicolas Sabouret", "Ionut Damian", "Tobias Baur", "Elisabeth Andr\u00e9", "Ka\u015bka Porayska-Pomsta", "Paola Rizzo"], "emails": ["hazael.jones@lip6.fr", "nicolas.sabouret@limsi.fr", "andre}@hcm-lab.de", "P.Rizzo}@ioe.ac.uk"], "sections": [{"heading": null, "text": "Categories and Subject Descriptions I.6.5 [Computer Methods]: Simulation and Modeling - Model Development; J.4 [Computer Applications]: Social and Behavioral Sciences General Terms Keywords Theory Perceptions, Social Stimuli, Communication Performance, Affective Model, Job Interview."}, {"heading": "1. INTRODUCTION", "text": "According to Eurostat 1, 5.5 million of the 16-25 year old European youth were unemployed in March 2012, representing 22.6% of the youngest population in the world, which is 1ec.europa.eu / eurostat10 points above the total population. These statistics highlight European youth unemployment as a significant problem. NEETs often lack confidence and the essential social skills needed to look for and secure work. Young unemployed people often find it difficult to present themselves in a good light to potential employers, which can expose them to a further risk of marginalisation. Social coaching workshops organised by youth associations across Europe are a common approach to help people acquire and improve their social skills, especially in the context of job interviews. However, this is an expensive and time-consuming approach based on the availability of trained skilled workers."}, {"heading": "2. STATE OF THE ART", "text": "Several research projects have already considered the use of virtual agents to help people improve their social skills and, more generally, their emotional intelligence [16, 34, 3]. However, while existing approaches use a reactive approach to user input, our efforts focus on deriving an affective response from the virtual recruiter based on the analysis of the user's beliefs and social cues."}, {"heading": "2.1 Social Cue Recognition", "text": "The use of signal processing techniques to recognize behavioral patterns is not a new idea (for an overview see [36]). However, most research to date has focused on a reduced number of modalities such as speech [37] or facial expression [40] to derive user states, with little attention paid to gestures or postures [20, 22]. Furthermore, signal processing work is aimed at offline analysis of recordings, not interactive real-time applications. An interesting example is the public training system presented by Batrinca et al. [5], in which the user is able to practice public speaking with the help of a virtual crowd. However, the behavioral analysis proposed by the user does not take place in real-time during the interaction, but post-hoc and offline. This means that the system is unable to react to the user's behavior because they interact with the system."}, {"heading": "2.2 Job interview assessment based on social cues", "text": "Several researchers show that different interaction scenarios, including job interviews, negotiations, or group meetings, are strongly influenced by the non-verbal behaviors of the interactors. Therefore, current research in this area increasingly focuses on the relationship between non-verbal behavior and the outcome of interactions. [11] Specifically, for job interviews, [3] explored how the success of simulated job interviews can also be predicted by conversation guidance, speech mirroring, speech activity, and prosodic emphasis. Social skills training has influenced several computer-aided simulation environments in areas that involve bullying at school [21], intercultural communication, and job interviews [30]. However, in the case of job applications, one major difficulty is that the interviewees tend to suppress their emotions and avoid social behaviors that can cause the unpleasant impression of a job to be so pronounced in the job interviews that most interview situations have a negative impact on the interviewee's feelings."}, {"heading": "2.3 Affects and Theory of Mind", "text": "Several approaches to building credible virtual people have been proposed in the field of affective calculation [26], including cognitive models of emotion [28, 25], models of personality [29] and social relationships [27]. To the best of our knowledge, however, no computational model of social attitudes has been proposed. However, social attitudes are socially conditioned expressions of an agent's personality, as manifested in his or her behaviors and emotional representations. Social conditioning is derived from the specific social and cultural norms of a particular community or situational context. For example, social attitudes provide the recruiter with information about the personality and feelings of the interviewee toward the job. This information influences the way the virtual recruiter progresses the interview and how he or she perceives the suitability of the interviewee for the job. Many of the processes involved in interpreting the beliefs and emotions of the TARDIS user are linked to the subjective process and relate to the studies of the mind and vice versa. [26]"}, {"heading": "3. ARCHITECTURE OVERVIEW", "text": "The TARDIS architecture consists of five main components, as shown in Figure 1. The Social Cue Recognition (SCR). This module recognizes and recognizes various social approaches produced by the teens during the simulated interviews, and sends the detected clues to the online user model. To facilitate detection, the module requires the use of various sensors, such as microphones or cameras. In this paper, we focus on the audio clues perceived with the help of a head-mounted microphone. This module receives information about the young person's social clues detected by the SCR module, it calculates a performance index based on the average values of audio-social clues that can be considered suitable for a job interview, and it sends this information to the affective core, as described in Section 6.The Interview Scenario. This component provides the virtual candidates with the expectations they should have regarding the interviewing and emotions."}, {"heading": "4. SOCIAL CUE RECOGNITION", "text": "The Social Cue Recognition Module is based on the Social Signal Interpretation Framework [38]. SSI provides an interface to various sensor devices as well as a variety of tools for real-time acquisition and pre-processing of data on human behavior. The functionality of the module in terms of detecting physical social stimuli, such as gestures, postures or facial expressions, was presented in our previous paper [12, 6, 7]. In this paper, we focus on detecting, analyzing and interpreting the audio stimuli. Table 1 summarizes the relevant stimuli. As a first step in detecting social stimuli, the raw data coming from the sensors are filtered and transformed using an SSI pipeline and various third-party libraries, such as PRAAT [8] and OpenSMILE [14]."}, {"heading": "5. USING AUDIO CUES TO COMPUTE COMMUNICATIVE PERFORMANCE", "text": "The online user model currently being implemented compares the audio signals generated by the users with a series of expected or desirable signals, i.e. audio signals deemed suitable for each part of a job interview. Based on this comparison, the model calculates an index between the values of \u2212 1 (negative performance) and + 1 (positive performance) and sends it to the affective core. 0 represents a neutral performance. The index is a weighted sum of the differences between each desired value and the actual value that the young person has in terms of speech duration, speech rate, speech volume, pause before the speech, etc. The following examples of expected signals are: \u2022 Interview questions that are more complex or sensitive in nature, e.g. \"do you have any weaknesses?\" requires an answer that goes beyond a simple \"yes\" or \"no.\" An appropriate answer should be worked out, and therefore a short conversation duration should not be used as an answer to a complex question such as is presented as an example."}, {"heading": "6. AFFECTIVE & DECISIONAL CORE", "text": "The perception module and the scenario module provide the input to this module, a performance index of the young person in the range [\u2212 1, + 1], which is used to calculate personnel effects and decisions."}, {"heading": "6.1 Affective Core", "text": "6.1.1 Overview of the model The Affective Module is based on a set of rules that calculate the actual emotions; for emotions, moods and attitudes for the virtual recruiter, based on the contextual information provided by the scenario and the perceived affects (emotions, moods and attitudes) of the participant. The calculation of the emotions of the virtual agent is based on the OCC model [28] and the calculation of the agent's moods is based on the ALMA model [15]. The details of the calculation of the emotions and attitudes of the virtual agent are not presented in this essay; it can be found in [19]. The affective core receives a performance index as input. The performance index, which falls within the range of [\u2212 1, + 1] represents the overall performance of the youngster (his attitude, his affects, his mood performance). The determined (d) performance is referred to as Pd. Similarly, a set of expected (power) indices is received."}, {"heading": "6.2 Decisional Core", "text": "In this interaction, inputs (affective states of the user) are given by non-verbal signals derived from the social signal interpretation. It can be used on various simulations that include the interaction of a person with a virtual agent: teaching, education, training, among others. The common feature of these simulations is the use of questions by the agent. Our model considers the use of questions to manage the context of the person's answers using the TARDIS.To summarize, our thinking model has three main characteristics: \u2022 The theory of the mind is about a real person who interacts with the system \u2022 It centers on affective states interpretation of the person prior to the simulation \u2022 It uses the context of the questions to analyze user responses. 6.2.1 Context management labels are given to the questions / sets of the virtual figure to interpret the answers / reactions of the person in relation to certain topics."}, {"heading": "7. CONCLUSION", "text": "In this article, we propose a pipeline for calculating the affective responses in a virtual recruiter based on user behavior. To this end, we use the SSI framework [38] to detect the social signals of the user in real time. Social signals are then transmitted to an online user model, which then calculates a performance index of user behavior. Based on the performance index and scenario, the effects of the virtual recruiter are calculated and a ToM approach allows to think about the user's preferences. As part of the TARDIS training system, which is designed to help young job seekers acquire relevant social skills in the job interview, the pipeline will allow the virtual recruiter to respond in real time and adapt to user behavior, generating credible interactions. As part of our future work, we aim to conduct studies to evaluate the functionality of the methods described and to validate our usability by, for example, validating the technical characteristics of the pipeline."}, {"heading": "Acknowledgment", "text": "The research that led to this paper was funded by the Seventh Framework Programme of the European Union for the Information Society and the Media FP7-ICT-2011-7 under Funding Agreement 288578."}, {"heading": "8. REFERENCES", "text": "[1] K Anderson, E Andre \u0301, T Baur, S Bernardini, M Chollet, E Chryssafidou, I Damian, C Ennis, A Egges, P Gebhard, Hazaeel Jones, Magalie Andre Ochs, Catherine Pelachaud, K Porayska-Pomsta, Rizzo Paola, and Nicolas Sabouret. [2] The TARDIS framework: intelligent virtual agents for social coaching in job interviews. Results of the Tenth International Conference on Advances in Computer Entertainment Technology (ACE-13). Enschede, The Netherlands. LNCS 8253, 2013. [2] Richard D. Arvey and James E. Campion. The Employment Interview: A Summary and Review of Recent Research. Personnel Psychology, 35 (2): 281-322, 1982. [3] Ruth Aylett, Ana Paiva, Joao Dias, Lynne Hall."}], "references": [{"title": "The TARDIS framework: intelligent virtual agents for social coaching in job interviews", "author": ["K Anderson", "E Andr\u00e9", "T Baur", "S Bernardini", "M Chollet", "E Chryssafidou", "I Damian", "C Ennis", "A Egges", "P Gebhard", "Haza\u00ebl Jones", "Magalie Ochs", "Catherine Pelachaud", "K Porayska-Pomsta", "Rizzo Paola", "Nicolas Sabouret"], "venue": "Proceedings of the Tenth International Conference on Advances in Computer Entertainment Technology (ACE-13). Enschede, the Netherlands. LNCS 8253,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "The employment interview: A summary and review of recent research", "author": ["Richard D. Arvey", "James E. Campion"], "venue": "Personnel Psychology,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1982}, {"title": "Affective agents for education against bullying", "author": ["Ruth Aylett", "Ana Paiva", "Joao Dias", "Lynne Hall", "Sarah Woods"], "venue": "In Affective Information Processing,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Cicero towards a multimodal virtual audience platform for public speaking training", "author": ["Ligia Batrinca", "Giota Stratou", "Ari Shapiro", "Louis-Philippe Morency", "Stefan Scherer"], "venue": "Intelligent Virtual Agents,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "A job interview simulation: Social cue-based interaction with a virtual character", "author": ["Tobias Baur", "Ionut Damian", "Patrick Gebhard", "Ka\u015bka Porayska-Pomsta", "Elisabeth Andr\u00e9"], "venue": "In Proceedings of the IEEE/ASE International Conference on Social Computing (SocialCom", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Nova: Automated analysis of nonverbal signals in social interactions", "author": ["Tobias Baur", "Ionut Damian", "Florian Lingenfelser", "Johannes Wagner", "Elisabeth Andr\u00e9"], "venue": "In Human Behavior Understanding,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Praat: doing phonetics by computer [computer program", "author": ["Paul Boersma", "David Weenink"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "A two-level BDI-agent model for theory of mind and its use in social manipulation", "author": ["Tibor Bosse", "Zulfiqar A Memon", "Jan Treur"], "venue": "AISB", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Social Exclusion and the Transition from School to Work: The Case of Young People Not in Education, Employment, or Training (NEET)", "author": ["John Bynner", "Samantha Parsons"], "venue": "Journal of Vocational Behavior,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "Thin slices of negotiation: predicting outcomes from conversational dynamics within the first 5 minutes", "author": ["Jared Curhan", "Alex Pentland"], "venue": "Journal of Applied Psychology,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Investigating social cue-based interaction in digital learning games", "author": ["Ionut Damian", "Tobias Baur", "Elisabeth Andr\u00e9"], "venue": "In Proc. of the 8th International Conference on the Foundations of Digital Games. SASDG,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "A logic of emotions: from appraisal to coping", "author": ["Mehdi Dastani", "Emiliano Lorini"], "venue": "In Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems - Volume 2,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Opensmile: the munich versatile and fast open-source audio feature extractor", "author": ["Florian Eyben", "Martin W\u00f6llmer", "Bj\u00f6rn Schuller"], "venue": "In Proceedings of the international conference on Multimedia, MM", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "ALMA - A Layered Model of Affect", "author": ["Patrick Gebhard"], "venue": "Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Social intelligence: The new science of human relationships", "author": ["Daniel Goleman"], "venue": "Bantam,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "What emotional reactions can tell us about the nature of others: An appraisal perspective on person perception", "author": ["Shlomo Hareli", "Ursula Hess"], "venue": "Cognition  & Emotion,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Mach: My automated conversation coach", "author": ["Mohammed Ehsan Hoque", "Matthieu Courgeon", "J Martin", "Bilge Mutlu", "Rosalind W Picard"], "venue": "In International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "TARDIS - A simulation platform with an affective virtual recruiter for job interviews", "author": ["Haza\u00ebl Jones", "Nicolas Sabouret"], "venue": "In IDGEI (Intelligent Digital Games for Empowerment and Inclusion),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Multimodal affect recognition in learning environments", "author": ["Ashish Kapoor", "Rosalind W. Picard"], "venue": "In Proceedings of the 13th annual ACM international conference on Multimedia,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Natural interaction with culturally adaptive virtual characters", "author": ["Felix Kistler", "Birgit Endrass", "Ionut Damian", "Chi T Dang", "Elisabeth Andr\u00e9"], "venue": "Journal on Multimodal User Interfaces,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Form as a cue in the automatic recognition of non-acted affective body expressions", "author": ["Andrea Kleinsmith", "Nadia Bianchi-Berthouze"], "venue": "In Proceedings of the 4th international conference on Affective computing and intelligent interaction - Volume Part I,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Interpersonal circumplex", "author": ["T Leary"], "venue": "Journal of Personality Assessment,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1996}, {"title": "ToMM, ToBy, and agency: Core architecture and domain specificity", "author": ["Alan M Leslie"], "venue": "Mapping the mind Domain specificity in cognition and culture,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1994}, {"title": "Expressive behaviors for virtual worlds", "author": ["Stacy Marsella", "Jonathan Gratch", "J Rickel"], "venue": "Lifelike Characters Tools Affective Functions and Applications,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2003}, {"title": "Understanding the Intentions of Others: Re-Enactment of Intended Acts by 18-Month-Old Children", "author": ["A N Meltzoff"], "venue": "Developmental Psychology,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1995}, {"title": "Simulation of the Dynamics of Non-Player Characters", "author": ["Magalie Ochs", "Nicolas Sabouret", "Vincent Corruble"], "venue": "Emotions and Social Relations in Games. IEEE Transactions on Computational Intelligence and AI in Games,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "The Cognitive Structure of Emotions", "author": ["Andrew Ortony", "Gerald L Clore", "Allan Collins"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1988}, {"title": "Social role awareness in animated agents", "author": ["Helmut Prendinger", "Mitsuru Ishizuka"], "venue": "Proceedings of the fifth international conference on Autonomous agents AGENTS", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2001}, {"title": "The empathic companion: A character-based interface that addresses users\u2019 affective states", "author": ["Helmut Prendinger", "Mitsuru Ishizuka"], "venue": "Applied Artificial Intelligence,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2005}, {"title": "PsychSim : Modeling Theory of Mind with Decision-Theoretic Agents", "author": ["David V Pynadath", "Stacy C Marsella"], "venue": "Information Sciences,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2005}, {"title": "Be Cool!\u2019: Emotional costs of hiding feelings in a job interview", "author": ["Monika Sieverding"], "venue": "Journal of Selection and Assessment,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}, {"title": "The influence of individuals on situations: Implications for understanding the links between personality and social behavior", "author": ["Mark Snyder"], "venue": "Journal of Personality,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1983}, {"title": "Playing with virtual peers: bootstrapping contingent discourse in children with autism", "author": ["Andrea Tartaro", "Justine Cassell"], "venue": "In Proceedings of the 8th international conference on International conference for the learning sciences-Volume", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2008}, {"title": "Comparison of professional versus student ratings of job interviewee behavior", "author": ["Thomas V. McGovern", "Barbara W. Jones", "Susan E. Morris"], "venue": "Journal of Counseling Psychology,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1979}, {"title": "Bridging the gap between social animal and unsocial machine: A survey of social signal processing", "author": ["A. Vinciarelli", "M. Pantic", "D. Heylen", "C. Pelachaud", "I. Poggi", "F. D\u2019Errico", "M. Schroeder"], "venue": "Affective Computing, IEEE Transactions on,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2012}, {"title": "Comparing feature sets for acted and spontaneous speech in view of automatic emotion recognition", "author": ["T. Vogt", "E. Andre"], "venue": "In Multimedia and Expo,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2005}, {"title": "The social signal interpretation (SSI) framework multimodal signal processing and recognition in real-time", "author": ["Johannes Wagner", "Florian Lingenfelser", "Tobias Baur", "Ionut Damian", "Felix Kistler", "Elisabeth Andr\u00e9"], "venue": "In Proceedings of the 21st ACM International Conference on Multimedia,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2013}, {"title": "Effects of mood on high elaboration attitude change: The mediating role of likelihood judgments", "author": ["Duane T Wegener", "Richard E Petty", "David J Klein"], "venue": "European Journal of Social Psychology,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1994}, {"title": "A survey of affect recognition methods: Audio, visual, and spontaneous expressions", "author": ["Zhihong Zeng", "M. Pantic", "G.I. Roisman", "T.S. Huang"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2009}], "referenceMentions": [{"referenceID": 8, "context": "NEETs often lack self-confidence and the essential social skills needed to seek and secure employment [10].", "startOffset": 102, "endOffset": 106}, {"referenceID": 0, "context": "TARDIS [1] is a project funded by the FP7, whose aim is to build a scenario-based serious-game simulation platform that supports social training and coaching in the context of job interviews.", "startOffset": 7, "endOffset": 10}, {"referenceID": 14, "context": "Several research projects have already considered using virtual agents to help humans improve their social skills and, more generally, their emotional intelligence [16, 34, 3].", "startOffset": 164, "endOffset": 175}, {"referenceID": 32, "context": "Several research projects have already considered using virtual agents to help humans improve their social skills and, more generally, their emotional intelligence [16, 34, 3].", "startOffset": 164, "endOffset": 175}, {"referenceID": 2, "context": "Several research projects have already considered using virtual agents to help humans improve their social skills and, more generally, their emotional intelligence [16, 34, 3].", "startOffset": 164, "endOffset": 175}, {"referenceID": 34, "context": "Using signal processing techniques to detect behavioural patterns is not a new idea (for an overview see [36]).", "startOffset": 105, "endOffset": 109}, {"referenceID": 35, "context": "However, most research to date focused on a reduced number of modalities, such as speech [37] or facial expressions [40], to infer user states, with little attention having been paid to gestures or postures [20, 22].", "startOffset": 89, "endOffset": 93}, {"referenceID": 38, "context": "However, most research to date focused on a reduced number of modalities, such as speech [37] or facial expressions [40], to infer user states, with little attention having been paid to gestures or postures [20, 22].", "startOffset": 116, "endOffset": 120}, {"referenceID": 18, "context": "However, most research to date focused on a reduced number of modalities, such as speech [37] or facial expressions [40], to infer user states, with little attention having been paid to gestures or postures [20, 22].", "startOffset": 207, "endOffset": 215}, {"referenceID": 20, "context": "However, most research to date focused on a reduced number of modalities, such as speech [37] or facial expressions [40], to infer user states, with little attention having been paid to gestures or postures [20, 22].", "startOffset": 207, "endOffset": 215}, {"referenceID": 3, "context": "[5], where the user is able to practice public speaking with the help of a virtual crowd.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "[18].", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "For instance [35] and [2] found that the assessment of candidates by job interviewers is significantly influenced by social cues such as tone of voice, eye gaze contact and body movement.", "startOffset": 13, "endOffset": 17}, {"referenceID": 1, "context": "For instance [35] and [2] found that the assessment of candidates by job interviewers is significantly influenced by social cues such as tone of voice, eye gaze contact and body movement.", "startOffset": 22, "endOffset": 25}, {"referenceID": 9, "context": "Specifically to job interviews, [11] studied how the success of simulated job interviews can also be predicted by conversational engagement, vocal mirroring, speech activity, and prosodic emphasis.", "startOffset": 32, "endOffset": 36}, {"referenceID": 2, "context": "The training of social skills has informed several computerbased simulation environments for domains that include bullying at school [3], intercultural communication [21] and job interviews [30].", "startOffset": 133, "endOffset": 136}, {"referenceID": 19, "context": "The training of social skills has informed several computerbased simulation environments for domains that include bullying at school [3], intercultural communication [21] and job interviews [30].", "startOffset": 166, "endOffset": 170}, {"referenceID": 28, "context": "The training of social skills has informed several computerbased simulation environments for domains that include bullying at school [3], intercultural communication [21] and job interviews [30].", "startOffset": 190, "endOffset": 194}, {"referenceID": 30, "context": "Emotional expression in job interviews is heavily governed by display rules, and most job applicants feel obliged to hide their feelings, especially if those feelings are negative [32].", "startOffset": 180, "endOffset": 184}, {"referenceID": 26, "context": "Several approaches to building credible virtual humans have been proposed in the domain of affective computing, including cognitive models of emotions [28, 25], models of personality [29] and of social relations [27].", "startOffset": 151, "endOffset": 159}, {"referenceID": 23, "context": "Several approaches to building credible virtual humans have been proposed in the domain of affective computing, including cognitive models of emotions [28, 25], models of personality [29] and of social relations [27].", "startOffset": 151, "endOffset": 159}, {"referenceID": 27, "context": "Several approaches to building credible virtual humans have been proposed in the domain of affective computing, including cognitive models of emotions [28, 25], models of personality [29] and of social relations [27].", "startOffset": 183, "endOffset": 187}, {"referenceID": 25, "context": "Several approaches to building credible virtual humans have been proposed in the domain of affective computing, including cognitive models of emotions [28, 25], models of personality [29] and of social relations [27].", "startOffset": 212, "endOffset": 216}, {"referenceID": 24, "context": "Many of the processes involved in interpreting the beliefs and emotions of the TARDIS\u2019 users are cognate with and draw from the studies related to Theory of Mind [26] and reverse appraisal [17].", "startOffset": 162, "endOffset": 166}, {"referenceID": 15, "context": "Many of the processes involved in interpreting the beliefs and emotions of the TARDIS\u2019 users are cognate with and draw from the studies related to Theory of Mind [26] and reverse appraisal [17].", "startOffset": 189, "endOffset": 193}, {"referenceID": 22, "context": "Theory of mind (ToM) [24, 4], is the ability of a person to attribute mental states (beliefs, intentions, desires and affects) to others.", "startOffset": 21, "endOffset": 28}, {"referenceID": 7, "context": "Numerous studies have been conducted in relation to the reasoning process of an agent about the cognitive process of another agent [9, 13].", "startOffset": 131, "endOffset": 138}, {"referenceID": 11, "context": "Numerous studies have been conducted in relation to the reasoning process of an agent about the cognitive process of another agent [9, 13].", "startOffset": 131, "endOffset": 138}, {"referenceID": 29, "context": "As a way of illustrating the novelty of our approach, consider for example Pynadath\u2019s approach [31], where an agent has subjective beliefs about others.", "startOffset": 95, "endOffset": 99}, {"referenceID": 36, "context": "The Social Cue Recognition module is based on the Social Signal Interpretation framework [38].", "startOffset": 89, "endOffset": 93}, {"referenceID": 10, "context": "The functionality of the module regarding the recognition of body social cues, such as gestures, postures or facial expressions, has been presented in our previous work [12, 6, 7].", "startOffset": 169, "endOffset": 179}, {"referenceID": 4, "context": "The functionality of the module regarding the recognition of body social cues, such as gestures, postures or facial expressions, has been presented in our previous work [12, 6, 7].", "startOffset": 169, "endOffset": 179}, {"referenceID": 5, "context": "The functionality of the module regarding the recognition of body social cues, such as gestures, postures or facial expressions, has been presented in our previous work [12, 6, 7].", "startOffset": 169, "endOffset": 179}, {"referenceID": 6, "context": "As a first step in the recognition of social cues, the raw data coming from the sensors is filtered and transformed with the help of an SSI pipeline and various third party libraries, such as PRAAT [8] and OpenSMILE [14].", "startOffset": 198, "endOffset": 201}, {"referenceID": 12, "context": "As a first step in the recognition of social cues, the raw data coming from the sensors is filtered and transformed with the help of an SSI pipeline and various third party libraries, such as PRAAT [8] and OpenSMILE [14].", "startOffset": 216, "endOffset": 220}, {"referenceID": 6, "context": "jitter, shimmer, voice breaks, harmonicity Quality-of-voice features [8] computed from pitch", "startOffset": 69, "endOffset": 72}, {"referenceID": 6, "context": "speech rate Rate of user\u2019s speech [8]", "startOffset": 34, "endOffset": 37}, {"referenceID": 26, "context": "The computation of the virtual agent\u2019s emotions is based on the OCC model [28] and the computation of the agent\u2019s moods is based on the ALMA model [15].", "startOffset": 74, "endOffset": 78}, {"referenceID": 13, "context": "The computation of the virtual agent\u2019s emotions is based on the OCC model [28] and the computation of the agent\u2019s moods is based on the ALMA model [15].", "startOffset": 147, "endOffset": 151}, {"referenceID": 17, "context": "moods will not be presented in this paper; it can be found in [19].", "startOffset": 62, "endOffset": 66}, {"referenceID": 0, "context": "Formally,in our model, all affects of the recruiter correspond to a value in the interval of [0, 1] and we use A to denote the set of all affects.", "startOffset": 93, "endOffset": 99}, {"referenceID": 17, "context": "All these rules are described in [19].", "startOffset": 33, "endOffset": 37}, {"referenceID": 26, "context": "The emotions are a simple subset of the OCC model [28] that was selected based on what practitioners, acting as recruiters, expressed during the mock interviews analysed.", "startOffset": 50, "endOffset": 54}, {"referenceID": 13, "context": "The moods originated from the ALMA model [15] are defined on 3 dimensions (Pleasure, Arousal and Dominance), but we limited them to the positive dominance zone (since recruiters do not show submissive moods in the context of job interviews).", "startOffset": 41, "endOffset": 45}, {"referenceID": 13, "context": "The computation of moods is based on emotions following ALMA [15].", "startOffset": 61, "endOffset": 65}, {"referenceID": 17, "context": "More details about the mood computation can be found in [19].", "startOffset": 56, "endOffset": 60}, {"referenceID": 31, "context": "The way we compute attitudes follow this principle: an agent can adopt an attitude according to its personality [33] or according to its actual mood [39].", "startOffset": 112, "endOffset": 116}, {"referenceID": 37, "context": "The way we compute attitudes follow this principle: an agent can adopt an attitude according to its personality [33] or according to its actual mood [39].", "startOffset": 149, "endOffset": 153}, {"referenceID": 21, "context": "Social attitudes used can be defined on Leary circumplex [23].", "startOffset": 57, "endOffset": 61}, {"referenceID": 36, "context": "To this end, we employ the use of the SSI framework[38] to recognize user social cue in real time.", "startOffset": 51, "endOffset": 55}], "year": 2014, "abstractText": "In this paper we describe a mechanism of generating credible affective reactions in a virtual recruiter during an interaction with a user. This is done using communicative performance computation based on the behaviours of the user as detected by a recognition module. The proposed software pipeline is part of the TARDIS system which aims to aid young job seekers in acquiring job interview related social skills. In this context, our system enables the virtual recruiter to realistically adapt and react to the user in real-time.", "creator": "LaTeX with hyperref package"}}}