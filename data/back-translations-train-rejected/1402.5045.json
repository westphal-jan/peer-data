{"id": "1402.5045", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2014", "title": "Expressing social attitudes in virtual agents for social training games", "abstract": "The use of virtual agents in social coaching has increased rapidly in the last decade. In order to train the user in different situations than can occur in real life, the virtual agent should be able to express different social attitudes. In this paper, we propose a model of social attitudes that enables a virtual agent to reason on the appropriate social attitude to express during the interaction with a user given the course of the interaction, but also the emotions, mood and personality of the agent. Moreover, the model enables the virtual agent to display its social attitude through its non-verbal behaviour. The proposed model has been developed in the context of job interview simulation. The methodology used to develop such a model combined a theoretical and an empirical approach. Indeed, the model is based both on the literature in Human and Social Sciences on social attitudes but also on the analysis of an audiovisual corpus of job interviews and on post-hoc interviews with the recruiters on their expressed attitudes during the job interview.", "histories": [["v1", "Thu, 20 Feb 2014 15:41:26 GMT  (1222kb,D)", "http://arxiv.org/abs/1402.5045v1", null]], "reviews": [], "SUBJECTS": "cs.HC cs.AI cs.CY", "authors": ["nicolas sabouret", "haza\\\"el jones", "magalie ochs", "mathieu chollet", "catherine pelachaud"], "accepted": false, "id": "1402.5045"}, "pdf": {"name": "1402.5045.pdf", "metadata": {"source": "CRF", "title": "Expressing social attitudes in virtual agents for social training games", "authors": ["Nicolas Sabouret", "Haza\u00ebl Jones", "Magalie Ochs", "Mathieu Chollet", "Catherine Pelachaud"], "emails": ["nicolas.sabouret@limsi.fr", "hazael.jones@lip6.fr", "magalie.ochs@telecom-paristech.fr", "mathieu.chollet@telecom-paristech.fr", "catherine.pelachaud@telecom-paristech.fr"], "sections": [{"heading": null, "text": "Tags Social Attitudes, Emotions, Affective Computing, Virtual Agent, Non-verbal Behavior"}, {"heading": "1. INTRODUCTION", "text": "However, it is an expensive and time-consuming approach based on the availability of trained professionals and people's willingness to explore their social strengths and weaknesses in front of others. Virtual agents have grown rapidly in social coaching over the past decade. Projects such as Tartaroand Cassell's [3] provide evidence that virtual agents can help people improve their social skills and, more generally, their emotional intelligence. Most of these models of virtual agents in the social coaching domain have focused on the simulation of emotions."}, {"heading": "2. RELATED WORK AND THEORETICAL BACKGROUND", "text": "A social attitude can be defined as \"an affective style that develops spontaneously or is used strategically in the interaction with a person.\" [23] Social attitudes can be described by categories, but they can also be represented along two dimensions: friendliness and dominance, as in the interpersonal environment introduced by Leary [18]. Several research has shown that a positive attitude is influenced by one's own affective state (e.g., one's emotions and moods [11]) and the course of interaction (e.g., the affective response of the other [32]). Wegener et al. show that a positive mood can help influence a change in attitude in the interlocutor, and that people tend to feel more likely to relate to interlocutors who are in a positive mood."}, {"heading": "3. GENERAL ARCHITECTURE", "text": "Our approach is to provide users with a simulation platform that enables them to defend themselves against a virtual agent."}, {"heading": "4. CORPUS", "text": "We have assembled a corpus of real interpersonal interaction between professional recruiters and interviewed job seekers (e.g. virtual behavior).The recordings consisted of creating a situation of job interviews between 5 recruiters and 9 interviewees. The setting was the same in all videos. The recruiter and the interviewee sat on each side of a table. A single camera covering the entire scene recorded the dyad from the side, resulting in a corpus of 9 videos of a job interview, each lasting 15 to 20 minutes. We discarded 4 videos because the recruiter was not visible due to the bad position of the camera. Of the 5 remaining videos, we have so far commented 3, for a total of 50 minutes and 10 seconds.The nonverbal behaviors of the recruiter during the job interview were commented on. We also comment on information about the interaction: the turn that assumes (i.e., who speaks), the topic of the discussion (i.e. document-related or general), perceived impact of the interviewee on the interviewee (e.g.)."}, {"heading": "5. REASONING ABOUT ATTITUDES", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Overview of the model", "text": "The affective module is based on a set of rules that calculate categories of emotions, moods and attitudes for the virtual recruiter (we interact) (26), based on the contextual information given by the scenario and the perceived affects (emotions, moods and attitudes). Although the virtual emotions of the virtual agent are based on the OCC model (20) and the calculation of the agent's moods is based on the ALMA model [12], the details of the calculation of emotions and moods are not presented in this essay; it can be found in [16]. Formally, all the affects in our model correspond to the variables that take the values at intervals [0, 1] and we denounce a set of affects (moods and attitudes) with which we identify a set of positive affects (joy, focused, etc.) and a set of negative influences (distress, fear, anxiety, etc.)."}, {"heading": "5.2 Attitude on interpersonal circumplex", "text": "The non-verbal behavioural model of our agent, which is presented in the next section, does not work directly with the categories identified in the phase of awakening knowledge of the corpus collection. On the contrary, it uses continuous values; it relies on the note of the corpus, which uses the friendly and dominant dimensions of interpersonal circumference. [18] In order to transform the attitudes represented by categories into continuous dimensional values, we rely on the work of Isbister [15], summarised in Fig. 2. Our attitudes are shown in red on the circumference line, on the line from the centre of the circumplex outwards. The position on this line is based on the intensity of the attitudes. When several attitudes are triggered simultaneously, we calculate the global attitude (i.e. the posture that emerges) as an average of the associated vectors of the various attitudes."}, {"heading": "5.3 Evaluation of the affective model", "text": "In order to evaluate the affective support module, we compare the affects calculated from the affective module with the manual annotation of the emotions from the application corpus. To perform such an evaluation, we randomly select a video of this corpus. The affective states of the interviewee and the social attitudes of the applicant were commented on manually. Our evaluation consists in comparing whether the affective module calculates social attitudes for the applicant that are identical (i.e. similar in terms of dimensional representation) to the advertiser's manually commented social attitudes in the video? Let's briefly describe the sequence of 8 speaker turns in the video we use for the evaluation: in the first 4 questions / answers, the interviewee turns confidently and gives the applicant good answers (positive perceived affects)."}, {"heading": "6. EXPRESSION OF ATTITUDES", "text": "Research has shown that non-verbal behaviours mediate an interpersonal attitude (see Section 2. However, it is not enough to view signals independently of the other surrounding signals: a smile is a sign of kindness, but a smile preceded by head and eye disinclination mediates subservience [17]. It is also important to take into account how signals from the virtual agent and signals from the user are sequenced (e.g. for mimicry). To give a virtual agent the ability to convey attitudes, we take a body-based approach to find out how attitudes are expressed through signal sequences. Instead of finding a direct mapping of attitudes to behavioural sequences, we are interested in describing when a behavioural sequence changes the perception of associated attitudes. It allows us to understand how attitudes evolve through interaction through the dynamic representation of non-verbal attitudes."}, {"heading": "6.1 Extraction of sequences from the corpus", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "6.2 Sequences selection for attitude expression", "text": "The original role of this module is to integrate communicative intentions into various signals, such as gestures or facial expressions. In addition, we extend the module so that it plans a sequence of signals that convey a chosen posture. As shown in Figure 1, it obtains adjustment values calculated by the Affective Module in the form of a pair of values, Friendly and Dominance. The behavioural planner then calculates a sequence of \"Friendly\" (an, an \u2212 1) and \"Dominance\" (an, an \u2212 1), with the differences between the chosen posture in the last dialogue expressing a sequence of \"\u2212 1 and the new sequence of\" Dominance. \"The behavioural planner then selects the sequence of sequences that correspond to the setting variation. In addition, we look for a non-verbal sequence that will be feasible in the current context."}, {"heading": "7. CONCLUDING REMARKS", "text": "Unlike classical reactive models, our approach combines an affective rationalist who generates affects for the virtual character with a sequence selection mechanism based on a domain corpus commented on in two dimensions: dominance and kindness. The methodology we propose involves several stages, from capturing and commenting on the corpus, decrypting knowledge with experts for the definition of rules, implementing behaviors, and sequence selection based on the internal affects generated. The originality of our model is twofold: first, we rely on an affective model that sets expectations for user effects, compares it to the perceptions of the user and calculates the effects of agents accordingly. All affects were developed after knowledge has elicited interpretation phases with domain experts. Second, the expression of social attitudes takes into account not only the signals to convey such attitudes, but also the behavioral behaviors we previously communicated in most of the components."}, {"heading": "8. REFERENCES", "text": "[1] K. Anderson, E. Andre \u0301, T. Baur, S. Bernardini, M. Chollet, E. Chryssafidou, I. Damian, C. Ennis, A. Egges, P. Gebhard, H. Jones, C. Pelachaud, K. Porayska-Pomsta, R. Paola, and N. Sabouret. [2] M. Argyle. Bodily Communication. University paperbacks. Methuen, 1988. [3] R. Aylett, A. Paiva, J. Dias, L. Hall, and S. Woods. Affective agents for education against bullying. In Affective Information Processing, pp. 75-90. Springer, 2009."}], "references": [{"title": "The TARDIS framework: intelligent virtual agents for social coaching in job interviews", "author": ["K. Anderson", "E. Andr\u00e9", "T. Baur", "S. Bernardini", "M. Chollet", "E. Chryssafidou", "I. Damian", "C. Ennis", "A. Egges", "P. Gebhard", "H. Jones", "M. Ochs", "C. Pelachaud", "K. Porayska-Pomsta", "R. Paola", "N. Sabouret"], "venue": "In Proceedings of the Tenth International Conference on Advances in Computer Entertainment Technology (ACE-13). Enschede, the Netherlands", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Bodily Communication", "author": ["M. Argyle"], "venue": "University paperbacks. Methuen", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1988}, {"title": "Affective agents for education against bullying", "author": ["R. Aylett", "A. Paiva", "J. Dias", "L. Hall", "S. Woods"], "venue": "Affective Information Processing, pages 75\u201390. Springer", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "A framework for interpersonal attitude and non-verbal communication in improvisational visual media production", "author": ["D. Ballin", "M. Gillies", "B. Crabtree"], "venue": "1st European Conference on Visual Media Production", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Cicero - towards a multimodal virtual audience platform for public speaking training", "author": ["L.M. Batrinca", "G. Stratou", "A. Shapiro", "L.-P. Morency", "S. Scherer"], "venue": "Proc. 2013 International Conference on Intelligent Virtual Agents, pages 116\u2013128", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "and M", "author": ["J.K. Burgoon", "D.B. Buller", "J.L. Hale"], "venue": "A. de Turck. Relational Messages Associated with Nonverbal Behaviors. Human Communication Research, 10(3):351\u2013378", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1984}, {"title": "Beliefs about the nonverbal expression of social power", "author": ["D.R. Carney", "J.A. Hall", "L.S. LeBeau"], "venue": "Journal of Nonverbal Behavior, 29(2):105\u2013123", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "A multimodal corpus for the study of non-verbal behavior expressing interpersonal stances", "author": ["M. Chollet", "M. Ochs", "C. Pelachaud"], "venue": "In IVA\u201913 Workshop Multimodal Corpora,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Revised NEO Personality Inventory (NEO PI-R) and NEO Five-Factor Inventory (NEO FFI): Professional Manual", "author": ["P.T. Costa", "R.R. MacCrae"], "venue": "Psychological Assessment Resources", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1992}, {"title": "Protein sequence classification through relevant sequence mining and bayes classifiers", "author": ["P. Ferreira", "P. Azevedo"], "venue": "C. Bento, A. Cardoso, and G. Dias, editors, Progress in Artificial Intelligence, volume 3808 of Lecture Notes in Computer Science, pages 236\u2013247. Springer Berlin Heidelberg", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "The influence of mood on perceptions of social interactions", "author": ["J.P. Forgas", "G.H. Bower", "S.E. Krantz"], "venue": "Journal of Experimental Social Psychology, 20(6):497\u2013513", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1984}, {"title": "ALMA - A Layered Model of Affect", "author": ["P. Gebhard"], "venue": "Artificial Intelligence, pages 0\u20137", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Social intelligence: The new science of human relationships", "author": ["D. Goleman"], "venue": "Bantam", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "MACH: My Automated Conversation coacH", "author": ["M. Hoque", "M. Courgeon", "J.-C. Martin", "B. Mutlu", "R. Picard"], "venue": "Proc. 2013 ACM international joint conference on Pervasive and ubiquitous computing. ACM Press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Better Game Characters by Design: A Psychological Approach (The Morgan Kaufmann Series in Interactive 3D Technology)", "author": ["K. Isbister"], "venue": "Morgan Kaufmann Publishers Inc.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "TARDIS - A simulation platform with an affective virtual recruiter for job interviews", "author": ["H. Jones", "N. Sabouret"], "venue": "IDGEI (Intelligent Digital Games for Empowerment and Inclusion)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Signs of appeasement: Evidence for the distinct displays of embarrassment", "author": ["D. Keltner"], "venue": "amusement, and shame. Journal of Personality and Social Psychology, 68:441\u2013454", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1995}, {"title": "Interpersonal diagnosis of personality: a functional theory and methodology for personality evaluation", "author": ["T. Leary"], "venue": "Methodology", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1957}, {"title": "Mining multimodal sequential patterns: a case study on affect detection", "author": ["H.P. Mart\u0301\u0131nez", "G.N. Yannakakis"], "venue": "In Proceedings of the 13th international conference on multimodal interfaces,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "The Cognitive Structure of Emotions", "author": ["A. Ortony", "G.L. Clore", "A. Collins"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1988}, {"title": "S", "author": ["K. Porayska-Pomsta", "M. Mavrikis"], "venue": "D\u2019Mello, C. Conati, and R. Baker. Knowledge elicitation methods for affect modelling in education. International Journal of Artificial Intelligence in Education", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "From a user-created corpus of virtual agent\u2019s non-verbal behaviour to a computational model of interpersonal attitudes", "author": ["B. Ravenet", "M. Ochs", "C. Pelachaud"], "venue": "International Conference on Intelligent Virtual Agent ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Appraisal considered as a process of multilevel sequential checking", "author": ["K.R. Scherer"], "venue": "Appraisal processes in emotion: Theory, methods, research, pages 92\u2013120", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "M", "author": ["M. Schr\u00f6der", "E. Bevacqua", "R. Cowie", "F. Eyben", "H. Gunes", "D. Heylen"], "venue": "ter Maat, G. McKeown, S. Pammi, M. Pantic, C. Pelachaud, B. Schuller, E. de Sevin, M. F. Valstar, and M. W\u00f6llmer. Building autonomous sensitive artificial listeners. T. Affective Computing, 3(2):165\u2013183", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Be Cool!\u2019: Emotional costs of hiding feelings in a job interview", "author": ["M. Sieverding"], "venue": "International Journal of Selection and Assessment, 17(4)", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "The influence of individuals on situations: Implications for understanding the links between personality and social behavior", "author": ["M. Snyder"], "venue": "Journal of Personality, 51(3):497\u2013516", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1983}, {"title": "Mining sequential patterns: Generalizations and performance improvements", "author": ["R. Srikant", "R. Agrawal"], "venue": "P. Apers, M. Bouzeghoub, and G. Gardarin, editors, Advances in Database Technology (EDBT) 96, volume 1057 of Lecture Notes in Computer Science, pages 1\u201317. Springer Berlin Heidelberg", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1996}, {"title": "Introduction to Data Mining", "author": ["P.-N. Tan", "M. Steinbach", "V. Kumar"], "venue": "(First Edition). Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2005}, {"title": "Playing with virtual peers: bootstrapping contingent discourse in children with autism", "author": ["A. Tartaro", "J. Cassell"], "venue": "Proceedings of the 8th international conference on International conference for the learning sciences-Volume 2, pages 382\u2013389. International Society of the Learning Sciences", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2008}, {"title": "The Buss and Perry Aggression Questionnaire and its relations to values", "author": ["P.F. Tremblay", "L.A. Ewart"], "venue": "the Big Five, provoking hypothetical situations, alcohol consumption patterns, and alcohol expectancies. Personality and Individual Differences, 38(2):337\u2013346", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2005}, {"title": "The social signal interpretation (ssi) framework-multimodal signal processing and recognition in real-time", "author": ["J. Wagner", "F. Lingenfelser", "T. Baur", "I. Damian", "F. Kistler", "E. Andr\u00e9"], "venue": "Proceedings of the 21st ACM International Conference on Multimedia, Barcelona, Spain", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Effects of mood on high elaboration attitude change: The mediating role of likelihood judgments", "author": ["D.T. Wegener", "R.E. Petty", "D.J. Klein"], "venue": "European Journal of Social Psychology, 24(1):25\u201343", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1994}], "referenceMentions": [{"referenceID": 28, "context": "Projects such as those by Tartaro and Cassell [29] or e-Circus [3] provide evidence that virtual agents can help humans improve their social skills and, more generally, their emotional intelligence [13].", "startOffset": 46, "endOffset": 50}, {"referenceID": 2, "context": "Projects such as those by Tartaro and Cassell [29] or e-Circus [3] provide evidence that virtual agents can help humans improve their social skills and, more generally, their emotional intelligence [13].", "startOffset": 63, "endOffset": 66}, {"referenceID": 12, "context": "Projects such as those by Tartaro and Cassell [29] or e-Circus [3] provide evidence that virtual agents can help humans improve their social skills and, more generally, their emotional intelligence [13].", "startOffset": 198, "endOffset": 202}, {"referenceID": 28, "context": "Most of these models of virtual agent in social coaching domain have focused on the simulation of emotions [29, 3, 14].", "startOffset": 107, "endOffset": 118}, {"referenceID": 2, "context": "Most of these models of virtual agent in social coaching domain have focused on the simulation of emotions [29, 3, 14].", "startOffset": 107, "endOffset": 118}, {"referenceID": 13, "context": "Most of these models of virtual agent in social coaching domain have focused on the simulation of emotions [29, 3, 14].", "startOffset": 107, "endOffset": 118}, {"referenceID": 22, "context": "being polite, distant, cold, warm, supportive, contemptuous)\u201d [23].", "startOffset": 62, "endOffset": 66}, {"referenceID": 25, "context": "As highlighted in [26, 32], one\u2019s social attitude depends on one\u2019s personality but also one\u2019s moods that is directly influenced by the course of the interaction.", "startOffset": 18, "endOffset": 26}, {"referenceID": 31, "context": "As highlighted in [26, 32], one\u2019s social attitude depends on one\u2019s personality but also one\u2019s moods that is directly influenced by the course of the interaction.", "startOffset": 18, "endOffset": 26}, {"referenceID": 1, "context": "One\u2019s social attitude is mainly conveyed by one\u2019s non-verbal behaviour [2].", "startOffset": 71, "endOffset": 74}, {"referenceID": 22, "context": "A social attitude can be defined as \u201can affective style that spontaneously develops or is strategically employed in the interaction with a person\u201d [23].", "startOffset": 147, "endOffset": 151}, {"referenceID": 17, "context": "Social attitudes can be described by categories, but also can be represented along 2 dimensions: friendliness and dominance as in the interpersonal circumplex introduced by Leary [18].", "startOffset": 179, "endOffset": 183}, {"referenceID": 10, "context": "his emotions and moods [11]) and the course of the interaction (e.", "startOffset": 23, "endOffset": 27}, {"referenceID": 31, "context": "the affective reaction of the other [32]).", "startOffset": 36, "endOffset": 40}, {"referenceID": 31, "context": "For instance in [32], Wegener et al.", "startOffset": 16, "endOffset": 20}, {"referenceID": 13, "context": "More recently, several applications of intelligent virtual agents and affective models in the context of job interviews have been proposed [14, 5, 1].", "startOffset": 139, "endOffset": 149}, {"referenceID": 4, "context": "More recently, several applications of intelligent virtual agents and affective models in the context of job interviews have been proposed [14, 5, 1].", "startOffset": 139, "endOffset": 149}, {"referenceID": 0, "context": "More recently, several applications of intelligent virtual agents and affective models in the context of job interviews have been proposed [14, 5, 1].", "startOffset": 139, "endOffset": 149}, {"referenceID": 5, "context": "Several research in Human and Social Sciences has shown that most modalities of the body are involved when conveying attitudes: smiles can be signs of friendliness[6], performing large gestures may be a sign of dominance, and a head directed upwards can be interpreted with a dominant attitude [7].", "startOffset": 163, "endOffset": 166}, {"referenceID": 6, "context": "Several research in Human and Social Sciences has shown that most modalities of the body are involved when conveying attitudes: smiles can be signs of friendliness[6], performing large gestures may be a sign of dominance, and a head directed upwards can be interpreted with a dominant attitude [7].", "startOffset": 294, "endOffset": 297}, {"referenceID": 16, "context": "For example, it is only by looking at the sequencing of smile, gaze and head aversion that we can differentiate between amusement, shame and embarrassment, affects expressing different values of dominance [17].", "startOffset": 205, "endOffset": 209}, {"referenceID": 3, "context": "For instance, in [4], postures corresponding to a given attitude were automatically generated for a dyad of agents.", "startOffset": 17, "endOffset": 20}, {"referenceID": 21, "context": "[22] proposed a user-created corpus-based methodology for choosing the behaviours of an agent conveying an attitude along with a communicative intention.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "In [25], a study shows that people who tried to suppress or hide negative emotions during a job interview are considered more competent by evaluators.", "startOffset": 3, "endOffset": 7}, {"referenceID": 30, "context": "In our work, we use the SSI framework [31] that recognizes the user\u2019s emotions expressed through his voice and his facial expressions.", "startOffset": 38, "endOffset": 42}, {"referenceID": 23, "context": "The Animation Module is based on the SEMAINE platform [24], which includes an international common multi-modal behaviour generation framework.", "startOffset": 54, "endOffset": 58}, {"referenceID": 7, "context": "The coding scheme, the resulting annotations, and the inter-annotators agreements are described in more details in [8].", "startOffset": 115, "endOffset": 118}, {"referenceID": 20, "context": "In addition to these videos, post-hoc interviews with the recruiters were used to elicit knowledge about the expectations and mental states during the interview, following the methodology proposed by [21].", "startOffset": 200, "endOffset": 204}, {"referenceID": 19, "context": "The computation of the virtual agent\u2019s emotions is based on the OCC model [20] and the computation of the agent\u2019s moods is based on the ALMA model [12].", "startOffset": 74, "endOffset": 78}, {"referenceID": 11, "context": "The computation of the virtual agent\u2019s emotions is based on the OCC model [20] and the computation of the agent\u2019s moods is based on the ALMA model [12].", "startOffset": 147, "endOffset": 151}, {"referenceID": 15, "context": "The details of the computation of emotions and moods will not be presented in this paper; it can be found in [16].", "startOffset": 109, "endOffset": 113}, {"referenceID": 0, "context": "Formally, all affects in our model correspond to variables taking values in the interval [0, 1] and we denote A the set of all affects (moods, emotions and attitudes), with A the set of positive affects (joy, focused, etc) and A\u2212 the set of negative ones (distress, anxious, etc).", "startOffset": 89, "endOffset": 95}, {"referenceID": 15, "context": "All these rules are described in [16].", "startOffset": 33, "endOffset": 37}, {"referenceID": 19, "context": "The emotions are a simple subset of the OCC model [20] that was selected based on what practitionners expressed, to different degrees, during the mock interviews.", "startOffset": 50, "endOffset": 54}, {"referenceID": 11, "context": "The moods originated from the ALMA model [12], limited to the positive dominance zone (since recruiters do not show submissive moods in the context of job interviews) with an additional distinction between bored and disdaintful, that correspond to two subspaces of (P-,A-,D+) zone that were distinguished during", "startOffset": 41, "endOffset": 45}, {"referenceID": 11, "context": "The computation of moods is based on emotions following ALMA [12].", "startOffset": 61, "endOffset": 65}, {"referenceID": 15, "context": "More details can be found in [16].", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "his emotions and moods [11]) and the course of the interaction (e.", "startOffset": 23, "endOffset": 27}, {"referenceID": 31, "context": "the affective reaction of the other [32]).", "startOffset": 36, "endOffset": 40}, {"referenceID": 31, "context": "For instance in [32], Wegener et al.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "Relations between attitudes and personality [26] and moods and attitudes [32, 11] has been exhibit in literature.", "startOffset": 44, "endOffset": 48}, {"referenceID": 31, "context": "Relations between attitudes and personality [26] and moods and attitudes [32, 11] has been exhibit in literature.", "startOffset": 73, "endOffset": 81}, {"referenceID": 10, "context": "Relations between attitudes and personality [26] and moods and attitudes [32, 11] has been exhibit in literature.", "startOffset": 73, "endOffset": 81}, {"referenceID": 25, "context": "For the computation of the influence of personality on attitude, based on [26], we propose to use the five model [9] to represent the virtual recruiter\u2019s personality using 5 quantitative dimensions (Openness (O), Conscientiousness (C), Extraversion (E), Agreeableness (A) and Neuroticism (N)).", "startOffset": 74, "endOffset": 78}, {"referenceID": 8, "context": "For the computation of the influence of personality on attitude, based on [26], we propose to use the five model [9] to represent the virtual recruiter\u2019s personality using 5 quantitative dimensions (Openness (O), Conscientiousness (C), Extraversion (E), Agreeableness (A) and Neuroticism (N)).", "startOffset": 113, "endOffset": 116}, {"referenceID": 25, "context": "The way we compute attitudes follow this principle: an agent can adopt an attitude according to its personality [26] or according to its actual mood [32].", "startOffset": 112, "endOffset": 116}, {"referenceID": 31, "context": "The way we compute attitudes follow this principle: an agent can adopt an attitude according to its personality [26] or according to its actual mood [32].", "startOffset": 149, "endOffset": 153}, {"referenceID": 8, "context": "According to [9], friendly attitudes are more present in agreeable persons.", "startOffset": 13, "endOffset": 16}, {"referenceID": 14, "context": "Moreover, according to [15], positive and aroused moods are associated to the friendly quadrant.", "startOffset": 23, "endOffset": 27}, {"referenceID": 29, "context": "According to [30], aggressive attitudes are more present in non-agreeable and neurotistic personalities and is correlated to the hostile mood.", "startOffset": 13, "endOffset": 17}, {"referenceID": 17, "context": "On the contrary, it makes use of continuous values; it relies on the annotation of corpus which uses the Friendly and Dominant dimensions of the interpersonal circumplex [18].", "startOffset": 170, "endOffset": 174}, {"referenceID": 14, "context": "To convert the attitudes represented by categories into continuous values of dimensions, we rely on the work by Isbister [15], summarized in Fig.", "startOffset": 121, "endOffset": 125}, {"referenceID": 16, "context": "by head and gaze aversion conveys submissiveness [17].", "startOffset": 49, "endOffset": 53}, {"referenceID": 26, "context": "In order to extract significant sequences of non-verbal signals conveying interpersonal attitudes from our corpus, we use a frequent sequence mining technique [27].", "startOffset": 159, "endOffset": 163}, {"referenceID": 9, "context": "Such techniques have been widely used in protein classification [10], and recent work have used these techniques in multimodal contexts: in a video game context, Martinez and Yannakakis studied the sequences of user keystrokes, game related events and user physiological signals [19].", "startOffset": 64, "endOffset": 68}, {"referenceID": 18, "context": "Such techniques have been widely used in protein classification [10], and recent work have used these techniques in multimodal contexts: in a video game context, Martinez and Yannakakis studied the sequences of user keystrokes, game related events and user physiological signals [19].", "startOffset": 279, "endOffset": 283}, {"referenceID": 7, "context": "More details can be found in [8].", "startOffset": 29, "endOffset": 32}, {"referenceID": 26, "context": "We used the commonly used Generalized Sequence Pattern (GSP) frequent sequence mining algorithm described in [27].", "startOffset": 109, "endOffset": 113}, {"referenceID": 27, "context": "Based on [28], we choose to compute confidence and lift quality measures for every sequence.", "startOffset": 9, "endOffset": 13}], "year": 2014, "abstractText": "The use of virtual agents in social coaching has increased rapidly in the last decade. In order to train the user in different situations than can occur in real life, the virtual agent should be able to express different social attitudes. In this paper, we propose a model of social attitudes that enables a virtual agent to reason on the appropriate social attitude to express during the interaction with a user given the course of the interaction, but also the emotions, mood and personality of the agent. Moreover, the model enables the virtual agent to display its social attitude through its non-verbal behaviour. The proposed model has been developed in the context of job interview simulation. The methodology used to develop such a model combined a theoretical and an empirical approach. Indeed, the model is based both on the literature in Human and Social Sciences on social attitudes but also on the analysis of an audiovisual corpus of job interviews and on post-hoc interviews with the recruiters on their expressed attitudes during the job interview.", "creator": "LaTeX with hyperref package"}}}