{"id": "1402.5886", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2014", "title": "Near Optimal Bayesian Active Learning for Decision Making", "abstract": "How should we gather information to make effective decisions? We address Bayesian active learning and experimental design problems, where we sequentially select tests to reduce uncertainty about a set of hypotheses. Instead of minimizing uncertainty per se, we consider a set of overlapping decision regions of these hypotheses. Our goal is to drive uncertainty into a single decision region as quickly as possible.", "histories": [["v1", "Mon, 24 Feb 2014 16:59:21 GMT  (6536kb,D)", "http://arxiv.org/abs/1402.5886v1", "Extended version of work appearing in the International conference on Artificial Intelligence and Statistics (AISTATS) 2014"]], "COMMENTS": "Extended version of work appearing in the International conference on Artificial Intelligence and Statistics (AISTATS) 2014", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["shervin javdani", "yuxin chen", "amin karbasi", "reas krause", "j", "rew bagnell", "siddhartha srinivasa"], "accepted": false, "id": "1402.5886"}, "pdf": {"name": "1402.5886.pdf", "metadata": {"source": "META", "title": "Near Optimal Bayesian Active Learning for Decision Making", "authors": ["Shervin Javdani", "Yuxin Chen", "Amin Karbasi", "Andreas Krause", "J. Andrew Bagnell", "Siddhartha Srinivasa"], "emails": [], "sections": [{"heading": null, "text": "Instead of minimizing uncertainty per se, we are looking at a number of overlapping decision regions of these hypotheses. Our goal is to shift uncertainty to a single decision region as quickly as possible. We are identifying necessary and sufficient conditions for the correct identification of a decision region that contains all hypotheses consistent with the observations. We are developing a novel hyperedge cutting algorithm (HEC) for this problem and proving that it competes with the insoluble optimal policy. Our efficient implementation of the algorithm is based on the calculation of subsets of completely homogeneous symmetric polynomials. Finally, we are demonstrating its effectiveness in two practical applications: approximately comparison-based learning and active localization using a robot manipulator."}, {"heading": "1 Introduction", "text": "In fact, it is such that most of them are in a position to outdo themselves, namely in the way in which they do it: in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in the way in which they do it, in which they do what they do, in which they do what they do, in which they do it, in which they do, in which they do it, in which they do it, in which they do it, in which they do it, in which they do it, in which they do it, in which they do it, in which they do it, in which they do what they do it, in which they do it, in which they do it, in which they do it, in which they do what they do it, in which they do it, in which they do it, in which they do what they do, in which they do it, in which they do it, in which they do what they do, in which they do it, in which they do what they do it, in which they do what they do, in which they do it, in which they do what they do it, in which they do what they do it, in which they do it, in which they do, in which they do what they do it, in which they do it, in which they do it, in which they do what they do, in which they do it, in which they do it, in which they do what they do it, in which they do it, in which they do it, in which they do what they do it, in which they do, in which they do it, in which they do, in which they do it, in which they do it, in which they do it, in which they do not, they do not, they do it, in which they do not, they do it, in which they do, they do"}, {"heading": "2 Problem Statement", "text": "We formalize our active learning problem by assuming a prior probability distribution (t1). (tm) We assume that we make a series of hypotheses (e.g., the patient's condition, the location of the target). (tm) We assume that we perform a specific hypotheses test. (tm) We assume that we perform a series of tests. (t1) We assume that a series of tests (e.g., medical tests that we have performed) function as h: T \u2192 O mapping tests to outcomes. (t1) We assume that we perform a series of tests T = {t1,.) We have performed a series of tests. (tm) We have performed a series of tests. (e.g., medical tests that we have shown the user, the robot moves), and have observed their results. (tm) Our evidence is captured by a set of test results."}, {"heading": "3.1 Overview", "text": "Our key strategy is to transform the DRD problem (2) into an alternative representation - another hypergraph for dividing decision regions. Observing certain test results corresponds to downweighting or cutting hyperedges in this hypergraph. The design is designed so that cutting all hyperedges is a necessary and sufficient prerequisite to drive all uncertainties into a single decision region. Subsequently, we demonstrate that a simple greedy algorithm that selects tests to maximize (as expected) hyperedge weight reduction implements policies that compete with the optimal (persistent) policy for problem (2). In Section 4, we show how this greedy algorithm can be efficiently implemented."}, {"heading": "3.2 Splitting hypergraph construction", "text": "It is a question of the extent to which it is actually a purely ethnic group that is able to survive itself, and of the extent to which it is able to survive itself. (...) It is a question of the extent to which it is able to survive itself. (...) It is a question of the extent to which it is able to survive itself. (...) It is a question of the extent to which it is able to survive itself. \"(...) It is a question of the extent to which it is able to survive itself."}, {"heading": "3.5 Theoretical Analysis", "text": "The key finding behind our analysis is that the marginal gain \u2206 (t | S) fulfills two properties: adaptive monotonicity and adaptive submodularity, which were introduced by Golovin and Krause (2011) and are associated with certain sequential decision problems. Formally, adaptive monotonicity simply means that the benefit of each test is not negative; and the second, slightly more subtle property - adaptive submodularity - states that the marginal gain of a specified test t-T and proof S-T can never increase because we gain additional evidence. Formally, whenever a test is performed, it must be stated that this problem (t | S) has its properties - adaptive submodularity."}, {"heading": "4 Efficient Implementation", "text": "Our HEC algorithm calculates for each test in T (t | S) and greedily selects one at each time step. Naively, it calculates this quantity by constructing the splitting hypergraphs for each possible observation and adding the edge weights. This is mathematically expensive, since creating the diagram requires enumerating all multisets of order k and checking whether each region contains them all, resulting in a runtime of O (| G | k). However, we can quickly trim back checks and iteratively consider multisets of growing cardinality in our calculation using the following fact: Algorithm 1 Hyperedge Weight method Hyperedge Weight (H, k) Calculate the subregions G from H W (G) Initialize the queue Q1 with each subregion g (G) for all k-k records of the superset."}, {"heading": "4.1 Utilizing Complete Homogeneous Symmetric Polynomials", "text": "We are, the sum of, the sum of, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the"}, {"heading": "5 Experiments", "text": "In this section, we evaluate HEC empirically using the two applications - approximately comparative learning and touch-based localization with a robot-assisted end effector. We compare HEC with five baselines, the first two being variants of algorithms for the specialized versions of the DRD problem described above - generalized binary search (Nowak, 2009) and equivalence class edge cutting (Golovin et al., 2010). For generalized binary search (GBS), we assign each hypothesis to its own decision region and run HEC on that hypothesis-region mapping until only one hypothesis remains. To apply equivalence class edge cutting (EC2), decision regions must be resolved. Thus, we randomly assign each hypothesis to one of the decision regions to which it belongs, and execute EC2 until only one of these new regions remains."}, {"heading": "5.1 Approximate comparison-based learning", "text": "In fact, it is that we are able to assert ourselves, that we are able, that we are able, that we are able to hide ourselves, and that we are able, that we will be able, that we will be able, that we will be able, that we will be able."}, {"heading": "5.2 Touch Based localization", "text": "We evaluate HEC using a simple example of robot manipulation. Our task is to press a button with the finger of a robotic end effector. Each of these decisions will be successful on a subset of hypotheses that correspond to a decision region. Decision regions may overlap because a button with many decision actions can be pressed. See Fig. 5. All hypotheses are not contained in a single decision region, so we perform tests to reduce uncertainty. These tests correspond to guarded movements (Will andGrossman, 1975), where the end effector moves along a path until contact is detected. After sampling the hypotheses, hypotheses are updated by eliminating object locations that may not have produced hypotheses, e.g. when they are far away. Our goal is to find the shortest sequence of tests that, once performed, provide a single choice."}, {"heading": "6 Conclusions", "text": "In this paper, we have addressed the problem of active learning to facilitate decision-making; we have defined the problem of decision-making region determination (DRD), which requires that, at the end of information gathering, all remaining hypotheses are limited to a single decision region (i.e. do not require further distinction from the point of view of decision-making); to solve this problem, we have proposed an equivalent representation in the form of a hypergraph; we have demonstrated that the removal of all edges in this hypergraph is a necessary and sufficient prerequisite for success, which suggests a natural objective function; we have shown that this goal satisfies adaptive monotonicity and adaptive submodularity; this insight has enabled us to demonstrate that a greedy policy for the removal of hyperedges (HEC) provides a guarantee of approximation to optimal policy; and finally, that we can use a certain polynomic deterrent and a more rapid algorithmic homogeneity in calculating each iteration."}, {"heading": "Acknowledgements", "text": "This work was partially supported by Intel Embedded Computing ISTC, NSF Grant No. 0946825, NSF-IIS1227495, DARPA MSEE FA8650-11-1-7156, ERC StG 307036 and a Microsoft Research Faculty Fellowship."}, {"heading": "7 Appendix", "text": "In this section, we provide evidence for theorems cited throughout the essay."}, {"heading": "7.1 k for bounds", "text": "We start by showing that we have solved the DRD problem for a properly defined k, the DRD problem (V (S). \"R.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S.\" S. \"S\" S. \"S.\" S. \"S.\" S. \"S\" S. \"S\" S. \"S.\" S \"S.\" S \"S\" S. \"S\" S. \"S\" S \"S.\" S \"S\" S. \"S\" S \"S\" S. \"S.\" S \"S\" S. \"S.\" S \"S\" S \"S.\" S \"S\" S \"S.\" S \"S\" S \"S.\" S \"S\" S \"S.\" S \"S\" S \"S\" S. \"S\" S \"S\" S. \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S. \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S. \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S. \"S\" S \"S\" S \"S.\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S"}, {"heading": "7.3 Theorem 2: strong adaptive monotonicity and adaptive submodularity", "text": "We start with the representation of our formulas which we (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n (S) n n (S) n n (S) n n (S) n (S) n n (S) n n (S) n n n (S) n n (S) n (S n n (S) n n n (S) n (S) n n n (S) n n (S) n n (S) n n (S) n n (S) n (S) n n (S) n (S) n (S) n (S n (S) n (S) n (S) n (S n) n (S n (S) n (S n) n (S n (S) n (S n) n (S n) n) n (S n (S n (S n) n) n (S n) n (S n (S n) n (S n) n (S n) n (S n) n (S n n (S n) n n (S n) n) n (S n) n (S n n (S n n (S n) n) n (S n (S n) n (S n) n n (S n (S n) n n (S n) n n) n (S n (S n n (S n (S n) n) n (S) n) n n (S n (S) n (S) n (S) n n n n) n) n) n) n) n) n (S n (S n n n (S n (S) n n) n"}, {"heading": "7.4 Theorem 3: Greedy Performance Bound", "text": "We would like to apply the theorem 5.8 of Golovin and Krause (2011). We have already demonstrated adaptive submodularity and strong adaptive monotonicity in paragraph 7.3. The theorem also requires the cases to certify themselves, which means that if the policy knows that it has reached the highest possible objective value immediately, it does so. See Golovin and Krause (2011) for details. Since our goal is equivalent for all remaining hypotheses in V (S), our function is fHEC self-certifying. The performance limit now follows directly from the theorem 5.8 of Golovin and Krause (2011). To apply the theorem, we had to define two constants: a limit at the maximum value of fHEC (S), Q = 1, and the minimum can change our objective function, corresponding to the distance of a hyperedge."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "How should we gather information to make effective decisions? We address Bayesian active learning and experimental design problems, where we sequentially select tests to reduce uncertainty about a set of hypotheses. Instead ofminimizing uncertainty per se, we consider a set of overlapping decision regions of these hypotheses. Our goal is to drive uncertainty into a single decision region as quickly as possible. We identify necessary and sufficient conditions for correctly identifying a decision region that contains all hypotheses consistent with observations. We develop a novel Hyperedge Cutting (HEC) algorithm for this problem, and prove that is competitive with the intractable optimal policy. Our efficient implementation of the algorithm relies on computing subsets of the complete homogeneous symmetric polynomials. Finally, we demonstrate its effectiveness on two practical applications: approximate comparison-based learning and active localization using a robotmanipulator.", "creator": "LaTeX with hyperref package"}}}