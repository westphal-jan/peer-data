{"id": "1402.6779", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2014", "title": "Resourceful Contextual Bandits", "abstract": "We study contextual bandits with ancillary constraints on resources, which are common in real-world applications such as choosing ads or dynamic pricing of items. We design the first algorithm for solving these problems, and prove a regret guarantee with near-optimal statistical properties.", "histories": [["v1", "Thu, 27 Feb 2014 03:17:19 GMT  (51kb)", "https://arxiv.org/abs/1402.6779v1", null], ["v2", "Thu, 10 Apr 2014 22:00:13 GMT  (42kb)", "http://arxiv.org/abs/1402.6779v2", "Added some details to one of the proofs"], ["v3", "Mon, 19 May 2014 23:01:03 GMT  (55kb)", "http://arxiv.org/abs/1402.6779v3", "This is the full version of a paper in COLT 2014. Version history: (V2) Added some details to one of the proofs, (v3) a big revision following comments from COLT reviewers (but no new results)"], ["v4", "Tue, 1 Jul 2014 14:55:01 GMT  (56kb)", "http://arxiv.org/abs/1402.6779v4", "This is the full version of a paper in COLT 2014. Version history: (v2) Added some details to one of the proofs, (v3) a big revision following comments from COLT reviewers (but no new results), (v4) edits in related work, minor edits elsewhere"], ["v5", "Mon, 13 Jul 2015 00:12:19 GMT  (57kb)", "http://arxiv.org/abs/1402.6779v5", "This is the full version of a paper in COLT 2014. Version history: (v2) Added some details to one of the proofs, (v3) a big revision following comments from COLT reviewers (but no new results), (v4) edits in related work, minor edits elsewhere. (v5) A correction for Theorem 3, corollary for contextual dynamic pricing with discretization; updated follow-up work &amp; open questions"], ["v6", "Fri, 31 Jul 2015 18:31:27 GMT  (57kb)", "http://arxiv.org/abs/1402.6779v6", "This is the full version of a paper in COLT 2014. Version history: (v2) Added some details to one of the proofs, (v3) a big revision following comments from COLT reviewers (but no new results), (v4) edits in related work, minor edits elsewhere. (v6) A correction for Theorem 3, corollary for contextual dynamic pricing with discretization; updated follow-up work &amp; open questions"]], "reviews": [], "SUBJECTS": "cs.LG cs.DS cs.GT", "authors": ["ashwinkumar badanidiyuru", "john langford", "aleksandrs slivkins"], "accepted": false, "id": "1402.6779"}, "pdf": {"name": "1402.6779.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Ashwinkumar Badanidiyuru", "John Langford", "Aleksandrs Slivkins", "A. Slivkins", "BADANIDIYURU LANGFORD SLIVKINS"], "emails": ["ASHWINKUMARBV@GMAIL.COM", "JCL@MICROSOFT.COM", "SLIVKINS@MICROSOFT.COM"], "sections": [{"heading": null, "text": "ar Xiv: 140 2.67 79v6 [cs.LG] 3 1"}, {"heading": "1. Introduction", "text": "In fact, most people who work for people's rights have the same rights, have the same rights as the majority of people who work for people's rights, have the same rights, have the same rights as the majority of people who work for people's rights, have the same rights as the majority of people who work for people's rights, have the same rights as the majority of people who work for people's rights, have the same rights as the majority of people who work for people's rights, have the same rights as the majority of people who work for people's rights, have the same rights of people, the same rights to people's rights, the same rights of people, the same rights of people, the same rights of people, the same rights of the same rights of others, the same rights of the same rights of others, the same rights of the same rights of the same rights of the same rights of the same rights."}, {"heading": "2. Related work", "text": "There are a number of approaches that have been examined in the literature, see Bubeck and Cesa-Bianchi, 2012; Dudik et al., 2011; Slidik et al., 2011 and 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012., 2012."}, {"heading": "3. Problem formulation and preliminaries", "text": "We consider an online setting in which in each round an algorithm measures the expected total remuneration. We are only interested in a specific set of possible contexts. X and selects an action from a finite set of known measures. The world then defines a reward r [0, 1] and the resource consumption. There are d resources that can be consumed, and the resource consumption is defined by numbers. [0, 1] So the world defines the vector (r; c1,., cd) that we call the result vector; this vector can depend on the chosen action and the round. There is a known hard restriction Bi + on the consumption of each resource i. We call it a resource vector i. The algorithm stops at the earliest time when any budget restriction is violated; its total reward is the sum of rewards in all rounds that are strictly preceded the distribution."}, {"heading": "3.1. Linear approximation and the benchmark", "text": "As a by-product, we will (effectively) reduce our benchmark OPT to the best fixed distribution via policies. P's value is the total reward of this algorithm, in anticipation of the outcome distribution. As the value of ALP is difficult to accurately characterize, we approach this approach (Babaioff et al., 2015; Badanidiyuru et al., 2013a) for non-contextual distribution. We use a linear approach in which all rewards and consumption are deterministic and time. Let r (P, \u00b5) and ci (P, \u00b5) be the expected pro-round remuneration and expected pro-round consumption of resources for a policy in which all rewards and consumption are deterministic."}, {"heading": "5. Correctness of the algorithm", "text": "We have to prove that in each round, one P-Ft (5), and equations (6-7) for all policies p-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x"}, {"heading": "6. Regret analysis: proof of Theorem 1", "text": "We provide the main steps of evidence; the details can be found in section 7. Leave it and expect the maximum deviations within the confidence region.Lemma 9 For all two expected results, which will be calculated in round t. It and a distribution P-Conv (t): | ci (P, p) \u2212 ci (P, p). First, we have the deviations within the confidence region.Lemma 9 For each resource i (10) | r (P, p). It and a distribution P-Conv (t): | ci (P, p). \u2212 ci (P, p)."}, {"heading": "7. Regret analysis: remaining details for the proof of Theorem 1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1. Proof of Lemma 10", "text": "We look at two cases, depending on whether it is a case or not. \u2212 For all two expected outcomes: The higher the probability, the higher the probability that a disaster will occur. \u2212 For all two cases, the higher the probability that a disaster will occur, the higher the probability that a disaster will occur. \u2212 For all other cases, the higher the probability that a disaster will occur, the higher the probability that a disaster will occur. \u2212 For all other cases, the higher the probability that a disaster will occur, the higher the probability that a disaster will occur. \u2212 For all other cases, the higher the probability that a disaster will occur. \u2212 For all other cases, the higher the probability that a disaster will occur. \u2212 For all other cases, the higher the probability, the higher the higher the probability that a disaster will occur."}, {"heading": "7.2. Remainder of the proof after Lemma 12", "text": "We begin with the claims in Equation (15).We begin with the claims in Equation (15).We begin with the claims in Equation (17).We begin with the claims in Equity (20).We begin with the claims in Equity (17).We begin with the claims in Equity (20).We begin with the claims in Equity (20).We begin with the claims in Equity (17).We begin with the claims in Equity (20) and Lemma 12. We get the desired bond in Equity (20) and Lemma 12. We get the desired bond in Equity (20) and Lemma 12. We get the desired bond in Equity (20) and Lemma 12."}, {"heading": "8. Lower bound: proof of Theorem 2", "text": "In fact, we prove a stronger theorem, which implies theorem 2. Theorem 18 Attach each tuple (K, T, B) such that K [2, T] and B \u2264 \u221a KT / 2. Any algorithm for RCB leads to regret (OPT) in the worst case scenario over all problems with K actions, time horizon T, smallest budget B, and politics stipulates such that OPT (VP) \u2264 B. We use the following problem (which follows from simple probability arguments). Lemma 19 Consider two collections of n balls I1 and I2, each numbered from 1 to n. Let I1 consist of all red balls, while I2 consists of n \u2212 1 red balls and 1 green ball (with randomly selected labels). In this setting, an algorithm is distinguished from one of Ii with replacement. The algorithm is allowed to look first at the number and then decide whether it is uniform."}, {"heading": "9. Discretization for contextual dynamic pricing (proof of Theorem 3)", "text": "We look at the contextual dynamic pricing with B copies of a single product. The scope of action consists of all prices p (0, 1). We obtain remorse limits relative to an arbitrary policy p (2). Preliminariate. Let us state the contextual sales rate (p) as contextual sales rate (p) and context x (p) that S (p) x (x) will not be increased for all contexts x (p). The assumption of the Lipschitz claims is expressed as follows: \"S (p) x)\" (p). - \"L\" (p) - \"p\" (p \"x) for all contexts called x, (22) for some constant L.\" For a (possibly randomized) policy p \"x.\" We define the contextual sales rate S (x) = Ep. \""}, {"heading": "10. Conclusions and open questions", "text": "We define a very general setting for contextual bandits with resource constraints in a way that poses an important question for answering this question. We design an algorithm for this problem and derive from it a regret that provides the optimal root-T scale in terms of the time horizon T and the optimal extension of the policy in terms of the way we look at it, and from that we derive a specific correlation for contextual dynamic pricing with a single product; we obtain a regret that is applied to an arbitrary policy. Finally, we deduce a partially lower limit that makes a stark difference between the non-contextual conversions. These results set the stage for further studies of RCB as they are debated.The main question left open by this work to combine detectable regrets and computationally efficient implementation (CE). While we focus on the statistical properties, we believe that we are unlikely to achieve optimal implementations of our techniques to almost CE."}], "references": [{"title": "Contextual bandit learning under the realizability assumption", "author": ["Alekh Agarwal", "Miroslav Dudik", "Satyen Kale", "John Langford"], "venue": "In 15th Intl. Conf. on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Agarwal et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2012}, {"title": "Taming the monster: A fast and simple algorithm for contextual bandits", "author": ["Alekh Agarwal", "Daniel Hsu", "Satyen Kale", "John Langford", "Lihong Li", "Robert Schapire"], "venue": "In 31st Intl. Conf. on Machine Learning (ICML),", "citeRegEx": "Agarwal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2014}, {"title": "Bandits with concave rewards and convex knapsacks", "author": ["Shipra Agrawal", "Nikhil R. Devanur"], "venue": "In 15th ACM Conf. on Economics and Computation (ACM EC),", "citeRegEx": "Agrawal and Devanur.,? \\Q2014\\E", "shortCiteRegEx": "Agrawal and Devanur.", "year": 2014}, {"title": "Linear contextual bandits with global constraints and objective", "author": ["Shipra Agrawal", "Nikhil R. Devanur"], "venue": "Jul 2015. e-report,", "citeRegEx": "Agrawal and Devanur.,? \\Q2015\\E", "shortCiteRegEx": "Agrawal and Devanur.", "year": 2015}, {"title": "Contextual bandits with global constraints and objective", "author": ["Shipra Agrawal", "Nikhil R. Devanur", "Lihong Li"], "venue": "Jun 2015. e-report,", "citeRegEx": "Agrawal et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 2015}, {"title": "Using confidence bounds for exploitation-exploration trade-offs", "author": ["Peter Auer"], "venue": "J. of Machine Learning Research (JMLR),", "citeRegEx": "Auer.,? \\Q2002\\E", "shortCiteRegEx": "Auer.", "year": 2002}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire"], "venue": "SIAM J. Comput.,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Dynamic pricing with limited supply", "author": ["Moshe Babaioff", "Shaddin Dughmi", "Robert D. Kleinberg", "Aleksandrs Slivkins"], "venue": "ACM Trans. on Economics and Computation,", "citeRegEx": "Babaioff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Babaioff et al\\.", "year": 2015}, {"title": "Learning on a budget: posted price mechanisms for online procurement", "author": ["Ashwinkumar Badanidiyuru", "Robert Kleinberg", "Yaron Singer"], "venue": "In 13th ACM Conf. on Electronic Commerce (EC),", "citeRegEx": "Badanidiyuru et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Badanidiyuru et al\\.", "year": 2012}, {"title": "Bandits with knapsacks", "author": ["Ashwinkumar Badanidiyuru", "Robert Kleinberg", "Aleksandrs Slivkins"], "venue": "In 54th IEEE Symp. on Foundations of Computer Science (FOCS),", "citeRegEx": "Badanidiyuru et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Badanidiyuru et al\\.", "year": 2013}, {"title": "Bandits with knapsacks", "author": ["Ashwinkumar Badanidiyuru", "Robert Kleinberg", "Aleksandrs Slivkins"], "venue": "A technical report on arxiv.org.,", "citeRegEx": "Badanidiyuru et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Badanidiyuru et al\\.", "year": 2013}, {"title": "Dynamic pricing without knowing the demand function: Risk bounds and near-optimal algorithms", "author": ["Omar Besbes", "Assaf Zeevi"], "venue": "Operations Research,", "citeRegEx": "Besbes and Zeevi.,? \\Q2009\\E", "shortCiteRegEx": "Besbes and Zeevi.", "year": 2009}, {"title": "On the minimax complexity of pricing in a changing environment", "author": ["Omar Besbes", "Assaf Zeevi"], "venue": "Operations Reseach,", "citeRegEx": "Besbes and Zeevi.,? \\Q2011\\E", "shortCiteRegEx": "Besbes and Zeevi.", "year": 2011}, {"title": "Blind network revenue management", "author": ["Omar Besbes", "Assaf J. Zeevi"], "venue": "Operations Research,", "citeRegEx": "Besbes and Zeevi.,? \\Q2012\\E", "shortCiteRegEx": "Besbes and Zeevi.", "year": 2012}, {"title": "Contextual bandit algorithms with supervised learning guarantees", "author": ["Alina Beygelzimer", "John Langford", "Lihong Li", "Lev Reyzin", "Robert E. Schapire"], "venue": "In 14th Intl. Conf. on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Beygelzimer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2011}, {"title": "Regret Analysis of Stochastic and Nonstochastic Multiarmed Bandit Problems", "author": ["S\u00e9bastien Bubeck", "Nicolo Cesa-Bianchi"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Bubeck and Cesa.Bianchi.,? \\Q2012\\E", "shortCiteRegEx": "Bubeck and Cesa.Bianchi.", "year": 2012}, {"title": "The best of both worlds: stochastic and adversarial bandits", "author": ["S\u00e9bastien Bubeck", "Aleksandrs Slivkins"], "venue": "In 25th Conf. on Learning Theory (COLT),", "citeRegEx": "Bubeck and Slivkins.,? \\Q2012\\E", "shortCiteRegEx": "Bubeck and Slivkins.", "year": 2012}, {"title": "The spending constraint model for market equilibrium: Algorithmic, existence and uniqueness results", "author": ["Nikhil Devanur", "Vijay Vazirani"], "venue": "In 36th ACM Symp. on Theory of Computing (STOC),", "citeRegEx": "Devanur and Vazirani.,? \\Q2004\\E", "shortCiteRegEx": "Devanur and Vazirani.", "year": 2004}, {"title": "The AdWords problem: Online keyword matching with budgeted bidders under random permutations", "author": ["Nikhil R. Devanur", "Thomas P. Hayes"], "venue": "In 10th ACM Conf. on Electronic Commerce (EC),", "citeRegEx": "Devanur and Hayes.,? \\Q2009\\E", "shortCiteRegEx": "Devanur and Hayes.", "year": 2009}, {"title": "Near optimal online algorithms and fast approximation algorithms for resource allocation problems", "author": ["Nikhil R. Devanur", "Kamal Jain", "Balasubramanian Sivan", "Christopher A. Wilkens"], "venue": "In 12th ACM Conf. on Electronic Commerce (EC),", "citeRegEx": "Devanur et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Devanur et al\\.", "year": 2011}, {"title": "Efficient optimal leanring for contextual bandits", "author": ["Miroslav Dudik", "Daniel Hsu", "Satyen Kale", "Nikos Karampatziakis", "John Langford", "Lev Reyzin", "Tong Zhang"], "venue": "In 27th Conf. on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Dudik et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dudik et al\\.", "year": 2011}, {"title": "On tail probabilities for martingales", "author": ["D.A. Freedman"], "venue": "The Annals of Probability,", "citeRegEx": "Freedman.,? \\Q1975\\E", "shortCiteRegEx": "Freedman.", "year": 1975}, {"title": "Multi-Armed Bandit Allocation Indices", "author": ["John Gittins", "Kevin Glazebrook", "Richard Weber"], "venue": null, "citeRegEx": "Gittins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gittins et al\\.", "year": 2011}, {"title": "Multi-armed Bandits with Metric Switching Costs", "author": ["Sudipta Guha", "Kamesh Munagala"], "venue": "In 36th Intl. Colloquium on Automata, Languages and Programming (ICALP),", "citeRegEx": "Guha and Munagala.,? \\Q2007\\E", "shortCiteRegEx": "Guha and Munagala.", "year": 2007}, {"title": "Approximation algorithms for restless bandit problems", "author": ["Sudipta Guha", "Kamesh Munagala", "Peng Shi"], "venue": "IEEE FOCS 2007 and ACM-SIAM SODA", "citeRegEx": "Guha et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Guha et al\\.", "year": 2010}, {"title": "Approximation algorithms for correlated knapsacks and non-martingale bandits", "author": ["Anupam Gupta", "Ravishankar Krishnaswamy", "Marco Molinaro", "R. Ravi"], "venue": "In 52nd IEEE Symp. on Foundations of Computer Science (FOCS),", "citeRegEx": "Gupta et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gupta et al\\.", "year": 2011}, {"title": "Continuous time associative bandit problems", "author": ["Andr\u00e1s Gy\u00f6rgy", "Levente Kocsis", "Ivett Szab\u00f3", "Csaba Szepesv\u00e1ri"], "venue": "In 20th Intl. Joint Conf. on Artificial Intelligence (IJCAI),", "citeRegEx": "Gy\u00f6rgy et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gy\u00f6rgy et al\\.", "year": 2007}, {"title": "Sharp dichotomies for regret minimization in metric spaces", "author": ["Robert Kleinberg", "Aleksandrs Slivkins"], "venue": "In 21st ACM-SIAM Symp. on Discrete Algorithms (SODA),", "citeRegEx": "Kleinberg and Slivkins.,? \\Q2010\\E", "shortCiteRegEx": "Kleinberg and Slivkins.", "year": 2010}, {"title": "Multi-armed bandits in metric spaces", "author": ["Robert Kleinberg", "Aleksandrs Slivkins", "Eli Upfal"], "venue": "In 40th ACM Symp. on Theory of Computing (STOC),", "citeRegEx": "Kleinberg et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kleinberg et al\\.", "year": 2008}, {"title": "The Epoch-Greedy Algorithm for Contextual Multi-armed Bandits", "author": ["John Langford", "Tong Zhang"], "venue": "In 21st Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Langford and Zhang.,? \\Q2007\\E", "shortCiteRegEx": "Langford and Zhang.", "year": 2007}, {"title": "Tighter bounds for multi-armed bandits with expert advice", "author": ["Brendan McMahan", "Matthew Streeter"], "venue": "In 22nd Conf. on Learning Theory (COLT),", "citeRegEx": "McMahan and Streeter.,? \\Q2009\\E", "shortCiteRegEx": "McMahan and Streeter.", "year": 2009}, {"title": "Truthful incentives in crowdsourcing tasks using regret minimization mechanisms", "author": ["Adish Singla", "Andreas Krause"], "venue": "In 22nd Intl. World Wide Web Conf. (WWW),", "citeRegEx": "Singla and Krause.,? \\Q2013\\E", "shortCiteRegEx": "Singla and Krause.", "year": 2013}, {"title": "On general minimax theorems", "author": ["Maurice Sion"], "venue": "Pac. J. Math.,", "citeRegEx": "Sion.,? \\Q1958\\E", "shortCiteRegEx": "Sion.", "year": 1958}, {"title": "Dynamic ad allocation: Bandits with budgets", "author": ["Aleksandrs Slivkins"], "venue": "A technical report on arxiv.org/abs/1306.0155,", "citeRegEx": "Slivkins.,? \\Q2013\\E", "shortCiteRegEx": "Slivkins.", "year": 2013}, {"title": "markets: Theoretical challenges", "author": ["William R. Thompson"], "venue": "SIGecom Exchanges,", "citeRegEx": "Thompson.,? \\Q2013\\E", "shortCiteRegEx": "Thompson.", "year": 2013}, {"title": "Dynamic pricing with limited supply. The algorithm is a monopolistic seller with a limited inventory. In the basic version, there is a limited supply of identical items. In each round, a new customer arrives, the algorithm picks a price, and offers one item for sale at this price", "author": ["Badanidiyuru"], "venue": null, "citeRegEx": "Badanidiyuru,? \\Q2013\\E", "shortCiteRegEx": "Badanidiyuru", "year": 2013}], "referenceMentions": [{"referenceID": 17, "context": "We consider very general settings for both contextual bandits (arbitrary policy sets, Dudik et al. (2011)) and bandits with resource constraints (bandits with knapsacks, Badanidiyuru et al.", "startOffset": 86, "endOffset": 106}, {"referenceID": 8, "context": "(2011)) and bandits with resource constraints (bandits with knapsacks, Badanidiyuru et al. (2013a)), and prove a regret guarantee with near-optimal statistical properties.", "startOffset": 71, "endOffset": 99}, {"referenceID": 20, "context": "We define resourceful contextual bandits (in short: RCB), a common generalization of two general models for contextual bandits and bandits with resource constraints: respectively, contextual bandits with arbitrary policy sets (e.g., Langford and Zhang, 2007; Dudik et al., 2011) and bandits with knapsacks (Badanidiyuru et al.", "startOffset": 226, "endOffset": 278}, {"referenceID": 20, "context": "The \u221a log |\u03a0| term in Theorem 1 is unavoidable (Dudik et al., 2011).", "startOffset": 47, "endOffset": 67}, {"referenceID": 8, "context": "In fact, Badanidiyuru et al. (2013a) provide a complimentary \u03a9( \u221a KT ) lower bound for this regime, which holds in a very strong sense: for any given tuple (K,B, OPT(\u03a0), T ).", "startOffset": 9, "endOffset": 37}, {"referenceID": 27, "context": "Such \u201cinformation-theoretical\u201d results are common for the first solutions to new, broad problem formulations (e.g. Kleinberg et al., 2008; Kleinberg and Slivkins, 2010; Dudik et al., 2011).", "startOffset": 109, "endOffset": 188}, {"referenceID": 20, "context": "Such \u201cinformation-theoretical\u201d results are common for the first solutions to new, broad problem formulations (e.g. Kleinberg et al., 2008; Kleinberg and Slivkins, 2010; Dudik et al., 2011).", "startOffset": 109, "endOffset": 188}, {"referenceID": 6, "context": "In particular, in the prior work for RCB without resource constraints there exists an algorithm with \u00d5( \u221a KT ) regret (Auer et al., 2002; Dudik et al., 2011), but for all known computationally efficient algorithms regret scales with T as T 2/3 (Langford and Zhang, 2007).", "startOffset": 118, "endOffset": 157}, {"referenceID": 20, "context": "In particular, in the prior work for RCB without resource constraints there exists an algorithm with \u00d5( \u221a KT ) regret (Auer et al., 2002; Dudik et al., 2011), but for all known computationally efficient algorithms regret scales with T as T 2/3 (Langford and Zhang, 2007).", "startOffset": 118, "endOffset": 157}, {"referenceID": 29, "context": ", 2011), but for all known computationally efficient algorithms regret scales with T as T 2/3 (Langford and Zhang, 2007).", "startOffset": 94, "endOffset": 120}, {"referenceID": 7, "context": "The optimal regret is then O(B2/3), even for an arbitrary budget B and even without the Lipscitz assumption (Babaioff et al., 2015).", "startOffset": 108, "endOffset": 131}, {"referenceID": 10, "context": "This regret bound is most interesting for the important regime B \u2265 \u03a9(T ) (studied, for example, in Besbes and Zeevi (2009, 2011); Wang et al. (2014)).", "startOffset": 99, "endOffset": 149}, {"referenceID": 11, "context": "Lipschitz demands is a common assumption in some of the prior work on (non-contextual) dynamic pricing, even with a single product (Besbes and Zeevi, 2009; Wang et al., 2014).", "startOffset": 131, "endOffset": 174}, {"referenceID": 7, "context": "However, the optimal algorithm for the single-product case (Babaioff et al., 2015) does not need this assumption.", "startOffset": 59, "endOffset": 82}, {"referenceID": 8, "context": "In particular, the main results in Badanidiyuru et al. (2013a) directly apply to this reduced problem.", "startOffset": 35, "endOffset": 63}, {"referenceID": 22, "context": "Multi-armed bandits have been studied since Thompson (1933) in Operations Research, Economics, and several branches of Computer Science, see (Gittins et al., 2011; Bubeck and Cesa-Bianchi, 2012) for background.", "startOffset": 141, "endOffset": 194}, {"referenceID": 15, "context": "Multi-armed bandits have been studied since Thompson (1933) in Operations Research, Economics, and several branches of Computer Science, see (Gittins et al., 2011; Bubeck and Cesa-Bianchi, 2012) for background.", "startOffset": 141, "endOffset": 194}, {"referenceID": 5, "context": "Contextual Bandits (Auer, 2002; Langford and Zhang, 2007) add contextual side information which can be used in prediction.", "startOffset": 19, "endOffset": 57}, {"referenceID": 29, "context": "Contextual Bandits (Auer, 2002; Langford and Zhang, 2007) add contextual side information which can be used in prediction.", "startOffset": 19, "endOffset": 57}, {"referenceID": 15, "context": "Several versions have been studied in the literature, see (Bubeck and Cesa-Bianchi, 2012; Dudik et al., 2011; Slivkins, 2014) for a discussion.", "startOffset": 58, "endOffset": 125}, {"referenceID": 20, "context": "Several versions have been studied in the literature, see (Bubeck and Cesa-Bianchi, 2012; Dudik et al., 2011; Slivkins, 2014) for a discussion.", "startOffset": 58, "endOffset": 125}, {"referenceID": 6, "context": "For contextual bandits with policy sets, there exist two broad families of solutions, based on multiplicative weight algorithms (Auer et al., 2002; McMahan and Streeter, 2009; Beygelzimer et al., 2011) or confidence intervals (Dudik et al.", "startOffset": 128, "endOffset": 201}, {"referenceID": 30, "context": "For contextual bandits with policy sets, there exist two broad families of solutions, based on multiplicative weight algorithms (Auer et al., 2002; McMahan and Streeter, 2009; Beygelzimer et al., 2011) or confidence intervals (Dudik et al.", "startOffset": 128, "endOffset": 201}, {"referenceID": 14, "context": "For contextual bandits with policy sets, there exist two broad families of solutions, based on multiplicative weight algorithms (Auer et al., 2002; McMahan and Streeter, 2009; Beygelzimer et al., 2011) or confidence intervals (Dudik et al.", "startOffset": 128, "endOffset": 201}, {"referenceID": 20, "context": ", 2011) or confidence intervals (Dudik et al., 2011; Agarwal et al., 2012).", "startOffset": 32, "endOffset": 74}, {"referenceID": 0, "context": ", 2011) or confidence intervals (Dudik et al., 2011; Agarwal et al., 2012).", "startOffset": 32, "endOffset": 74}, {"referenceID": 7, "context": "Prior work on resource-constrained bandits includes dynamic pricing with limited supply (Babaioff et al., 2015; Besbes and Zeevi, 2009, 2012), dynamic procurement on a budget (Badanidiyuru et al.", "startOffset": 88, "endOffset": 141}, {"referenceID": 8, "context": ", 2015; Besbes and Zeevi, 2009, 2012), dynamic procurement on a budget (Badanidiyuru et al., 2012; Singla and Krause, 2013; Slivkins and Vaughan, 2013), dynamic ad allocation with advertisers\u2019 budgets (Slivkins, 2013), and bandits with a single deterministic resource (Guha and Munagala, 2007; Gupta et al.", "startOffset": 71, "endOffset": 151}, {"referenceID": 31, "context": ", 2015; Besbes and Zeevi, 2009, 2012), dynamic procurement on a budget (Badanidiyuru et al., 2012; Singla and Krause, 2013; Slivkins and Vaughan, 2013), dynamic ad allocation with advertisers\u2019 budgets (Slivkins, 2013), and bandits with a single deterministic resource (Guha and Munagala, 2007; Gupta et al.", "startOffset": 71, "endOffset": 151}, {"referenceID": 33, "context": ", 2012; Singla and Krause, 2013; Slivkins and Vaughan, 2013), dynamic ad allocation with advertisers\u2019 budgets (Slivkins, 2013), and bandits with a single deterministic resource (Guha and Munagala, 2007; Gupta et al.", "startOffset": 110, "endOffset": 126}, {"referenceID": 23, "context": ", 2012; Singla and Krause, 2013; Slivkins and Vaughan, 2013), dynamic ad allocation with advertisers\u2019 budgets (Slivkins, 2013), and bandits with a single deterministic resource (Guha and Munagala, 2007; Gupta et al., 2011; Tran-Thanh et al., 2010, 2012).", "startOffset": 177, "endOffset": 253}, {"referenceID": 25, "context": ", 2012; Singla and Krause, 2013; Slivkins and Vaughan, 2013), dynamic ad allocation with advertisers\u2019 budgets (Slivkins, 2013), and bandits with a single deterministic resource (Guha and Munagala, 2007; Gupta et al., 2011; Tran-Thanh et al., 2010, 2012).", "startOffset": 177, "endOffset": 253}, {"referenceID": 26, "context": "To the best of our knowledge, the only prior work that explicitly considered contextual bandits with resource constraints is (Gy\u00f6rgy et al., 2007).", "startOffset": 125, "endOffset": 146}, {"referenceID": 19, "context": "Our setting can be seen as a contextual bandit version of stochastic packing (e.g. Devanur and Hayes, 2009; Devanur et al., 2011).", "startOffset": 77, "endOffset": 129}, {"referenceID": 10, "context": "Multi-armed bandits have been studied since Thompson (1933) in Operations Research, Economics, and several branches of Computer Science, see (Gittins et al.", "startOffset": 44, "endOffset": 60}, {"referenceID": 0, "context": ", 2011; Agarwal et al., 2012). We rework the confidence interval approach, incorporating and extending the ideas from the work on resource-constrained bandits (Badanidiyuru et al., 2013a). Prior work on resource-constrained bandits includes dynamic pricing with limited supply (Babaioff et al., 2015; Besbes and Zeevi, 2009, 2012), dynamic procurement on a budget (Badanidiyuru et al., 2012; Singla and Krause, 2013; Slivkins and Vaughan, 2013), dynamic ad allocation with advertisers\u2019 budgets (Slivkins, 2013), and bandits with a single deterministic resource (Guha and Munagala, 2007; Gupta et al., 2011; Tran-Thanh et al., 2010, 2012). Badanidiyuru et al. (2013a) define and optimally solve a common generalization of all these settings: the non-contextual version of RCB.", "startOffset": 8, "endOffset": 667}, {"referenceID": 0, "context": ", 2011; Agarwal et al., 2012). We rework the confidence interval approach, incorporating and extending the ideas from the work on resource-constrained bandits (Badanidiyuru et al., 2013a). Prior work on resource-constrained bandits includes dynamic pricing with limited supply (Babaioff et al., 2015; Besbes and Zeevi, 2009, 2012), dynamic procurement on a budget (Badanidiyuru et al., 2012; Singla and Krause, 2013; Slivkins and Vaughan, 2013), dynamic ad allocation with advertisers\u2019 budgets (Slivkins, 2013), and bandits with a single deterministic resource (Guha and Munagala, 2007; Gupta et al., 2011; Tran-Thanh et al., 2010, 2012). Badanidiyuru et al. (2013a) define and optimally solve a common generalization of all these settings: the non-contextual version of RCB. An extensive discussion of these and other applications, including applications to repeated auctions and network routing, can be found in (Badanidiyuru et al., 2013a). To the best of our knowledge, the only prior work that explicitly considered contextual bandits with resource constraints is (Gy\u00f6rgy et al., 2007). This paper considers a somewhat incomparable setting with arbitrary policy sets and a single constrained resource: time, whose consumption is stochastic and depends on the context and the chosen action. Gy\u00f6rgy et al. (2007) design an algorithm whose regret scales O(f(t) log t) for any time t, where f is any positive diverging function and the constant in O() depends on the problem instance and on f .", "startOffset": 8, "endOffset": 1316}, {"referenceID": 24, "context": "While we approximate our benchmark OPT(\u03a0) with a linear program optimum, our algorithm and analysis are conceptually very different from the vast literature on approximately solving linear programs, and in particular from LP-based work on bandit problems such as Guha et al. (2010).", "startOffset": 263, "endOffset": 282}, {"referenceID": 2, "context": "Agrawal and Devanur (2014) study a model for contextual bandits with resource constraints that is incomparable with ours.", "startOffset": 0, "endOffset": 27}, {"referenceID": 2, "context": "Agrawal and Devanur (2014) also claimed an extension to contexts that change over time, which has subsequently been retracted (see Footnote 1 in Agrawal and Devanur (2015)).", "startOffset": 0, "endOffset": 27}, {"referenceID": 2, "context": "Agrawal and Devanur (2014) also claimed an extension to contexts that change over time, which has subsequently been retracted (see Footnote 1 in Agrawal and Devanur (2015)).", "startOffset": 0, "endOffset": 172}, {"referenceID": 2, "context": "Agrawal and Devanur (2014) also claimed an extension to contexts that change over time, which has subsequently been retracted (see Footnote 1 in Agrawal and Devanur (2015)). This extension constitutes the main result in Agrawal and Devanur (2015) (which is subsequent work relative to the present paper).", "startOffset": 0, "endOffset": 247}, {"referenceID": 7, "context": "As the value of P is difficult to characterize exactly, we approximate it (generalizing the approach from (Babaioff et al., 2015; Badanidiyuru et al., 2013a) for the non-contextual version).", "startOffset": 106, "endOffset": 157}, {"referenceID": 8, "context": "Lemma 4 and Lemma 5 are proved for the non-contextual version of RCB in Badanidiyuru et al. (2013a). The general case can be reduced to the non-contextual version via a standard reduction where actions in the new problem correspond to policies in \u03a0 in the original problem.", "startOffset": 72, "endOffset": 100}, {"referenceID": 8, "context": "Lemma 4 and Lemma 5 are proved for the non-contextual version of RCB in Badanidiyuru et al. (2013a). The general case can be reduced to the non-contextual version via a standard reduction where actions in the new problem correspond to policies in \u03a0 in the original problem. For Lemma 5, Badanidiyuru et al. (2013a) obtain an LP-perfect distribution by mixing an LP-optimal distribution with the \u201cnull action\u201d; this is why we allow the null action in the setting.", "startOffset": 72, "endOffset": 315}, {"referenceID": 20, "context": "In what follows we extend the minimax argument from Dudik et al. (2011). Our proof works for any q0 \u2208 [0, 1 2 ] and any compact and convex set F \u2282 F\u03a0.", "startOffset": 52, "endOffset": 72}, {"referenceID": 32, "context": "We use a min-max argument: noting that f is a convex function of P and a concave function of Z , by the Sion\u2019s minimax theorem (Sion, 1958) we have that", "startOffset": 127, "endOffset": 139}, {"referenceID": 21, "context": "To analyze Equations (6-7), we will use Bernstein\u2019s inequality for martingales (Freedman, 1975), via the following formulation from Bubeck and Slivkins (2012):", "startOffset": 79, "endOffset": 95}, {"referenceID": 16, "context": "To analyze Equations (6-7), we will use Bernstein\u2019s inequality for martingales (Freedman, 1975), via the following formulation from Bubeck and Slivkins (2012):", "startOffset": 132, "endOffset": 159}, {"referenceID": 8, "context": "Proof Using a trivial reduction to the non-contextual case (when a policy corresponds to an action in the bandits-with-knapsacks problem), one can use a generic discretization result from Badanidiyuru et al. (2013a). According to this result (specialized to contextual dynamic pricing), it suffices to prove that for each policy \u03c0 \u2208 \u03a6\u03b4 the following two properties hold: (P1) S(\u03c0\u01eb) \u2265 S(\u03c0), (P2) r(\u03c0\u01eb)/S(\u03c0\u01eb) \u2265 r(\u03c0)/S(\u03c0) \u2212 \u01eb(1 + L\u03b4\u22122), as long as S(\u03c0\u01eb) > 0.", "startOffset": 188, "endOffset": 216}, {"referenceID": 1, "context": "This question has been resolved in the positive in a simultaneous and independent work (Agarwal et al., 2014).", "startOffset": 87, "endOffset": 109}, {"referenceID": 4, "context": "Very recently, a follow-up paper (Agrawal et al., 2015) has", "startOffset": 33, "endOffset": 55}, {"referenceID": 0, "context": "achieved the corresponding advance on RCB, by combing the techniques from Agarwal et al. (2014) and Agrawal and Devanur (2014) (which, in turn, builds on Badanidiyuru et al.", "startOffset": 74, "endOffset": 96}, {"referenceID": 0, "context": "achieved the corresponding advance on RCB, by combing the techniques from Agarwal et al. (2014) and Agrawal and Devanur (2014) (which, in turn, builds on Badanidiyuru et al.", "startOffset": 74, "endOffset": 127}, {"referenceID": 0, "context": "achieved the corresponding advance on RCB, by combing the techniques from Agarwal et al. (2014) and Agrawal and Devanur (2014) (which, in turn, builds on Badanidiyuru et al. (2013a)).", "startOffset": 74, "endOffset": 182}, {"referenceID": 7, "context": "Then, ignoring logarithmic factors, we obtain regret OPT(\u03a0) \u221a T/B, whereas the lower bound in Badanidiyuru et al. (2013a) is OPT(\u03a0)/ \u221a B.", "startOffset": 94, "endOffset": 122}, {"referenceID": 7, "context": "Likewise, for contextual dynamic pricing with a single product, there is a gap between our algorithmic result (Theorem 3) and the B2/3 lower bound for the non-contextual case from Babaioff et al. (2015). In both cases, both upper and lower bounds can potentially be improved.", "startOffset": 180, "endOffset": 203}, {"referenceID": 7, "context": "Likewise, for contextual dynamic pricing with a single product, there is a gap between our algorithmic result (Theorem 3) and the B2/3 lower bound for the non-contextual case from Babaioff et al. (2015). In both cases, both upper and lower bounds can potentially be improved. Third, for special cases when actions correspond to prices one would like to extend the discretization approach beyond contextual dynamic pricing with a single product. However, this is problematic even without contexts: essentially, nothing is known whenever one has multiple resource constraints, and even with a single resource constraint (besides time) the solutions are very non-trivial; see Badanidiyuru et al. (2013a) for more discussion.", "startOffset": 180, "endOffset": 701}, {"referenceID": 4, "context": "This extension has been addressed, among other results, in the follow-up paper (Agrawal et al., 2015).", "startOffset": 79, "endOffset": 101}], "year": 2015, "abstractText": "We study contextual bandits with ancillary constraints on resources, which are common in realworld applications such as choosing ads or dynamic pricing of items. We design the first algorithm for solving these problems that handles constrained resources other than time, and improves over a trivial reduction to the non-contextual case. We consider very general settings for both contextual bandits (arbitrary policy sets, Dudik et al. (2011)) and bandits with resource constraints (bandits with knapsacks, Badanidiyuru et al. (2013a)), and prove a regret guarantee with near-optimal statistical properties.", "creator": "LaTeX with hyperref package"}}}