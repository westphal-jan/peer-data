{"id": "1402.7001", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2014", "title": "Marginalizing Corrupted Features", "abstract": "The goal of machine learning is to develop predictors that generalize well to test data. Ideally, this is achieved by training on an almost infinitely large training data set that captures all variations in the data distribution. In practical learning settings, however, we do not have infinite data and our predictors may overfit. Overfitting may be combatted, for example, by adding a regularizer to the training objective or by defining a prior over the model parameters and performing Bayesian inference. In this paper, we propose a third, alternative approach to combat overfitting: we extend the training set with infinitely many artificial training examples that are obtained by corrupting the original training data. We show that this approach is practical and efficient for a range of predictors and corruption models. Our approach, called marginalized corrupted features (MCF), trains robust predictors by minimizing the expected value of the loss function under the corruption model. We show empirically on a variety of data sets that MCF classifiers can be trained efficiently, may generalize substantially better to test data, and are also more robust to feature deletion at test time.", "histories": [["v1", "Thu, 27 Feb 2014 18:31:33 GMT  (2669kb,D)", "http://arxiv.org/abs/1402.7001v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["laurens van der maaten", "minmin chen", "stephen tyree", "kilian weinberger"], "accepted": false, "id": "1402.7001"}, "pdf": {"name": "1402.7001.pdf", "metadata": {"source": "CRF", "title": "Marginalizing Corrupted Features", "authors": ["Laurens van der Maaten", "Minmin Chen", "Kilian Q. Weinberger"], "emails": ["lvdmaaten@gmail.com", "m.chen@criteo.com", "swtyree@wustl.edu", "kilian@wustl.edu"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them are able to survive on their own, and are therefore unable to survive on their own."}, {"heading": "2. Related work", "text": "There are two motives for training a classifier with MCF: 1. to reduce the effects of overadjustment during training and 2. to combat the effects of data corruption during testing. Both motivations are related to different work areas, and both are discussed in this section."}, {"heading": "2.1 Corruption during training", "text": "The first publication by Burges and Scholkopf (1997) inspired various work areas that explicitly corrupt training data during training. Most prominently, Vincent et al. (2008, 2010) propose randomly hiding features in training data used as input for autoencoders, while the desired results (the original training data) remain unchanged; the resulting denociation of the autoencoder model is now often used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied to the hidden units of neural networks as a form of regulation (Hinton et al., 2012). Since autoencoders are non-linear, marginalization via corrupting distribution cannot be performed analytically (Mesnil et al., 2011), and blankout corruption is increasingly applied to the form of neural networks (Hinonal regulation, 2012)."}, {"heading": "2.2 Corruption during testing", "text": "Several previous studies have considered implicit approaches to data sets susceptible to corruption during the test period (also referred to as the \"nightmare in the test period\" scenario), most of which suggest minimizing loss under a contrary worst-case scenario. In particular, Globerson and Roweis (2006) propose a Minimax formulation in which loss is minimized under the assumption of maximum \"damage\" from corruption. In contrast, Dekel and Shamir (2008) propose a linear formulation that minimizes approximation to the same quantity for margin-based predictors. Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis et al.) also use Minimax approaches that minimize losses under a worst-case scenario, but focus on a slightly different corruption model that adds a uniform constant."}, {"heading": "3. Learning with Marginalized Corrupted Features (MCF)", "text": "In fact, it is so that it is a matter of a way in which people are able to put themselves in the centre. (...) In fact, it is so that they are able to put themselves in the centre of attention. (...) It is so that they put themselves in the centre. (...) It is so that they are able to put themselves in the centre of attention. (...) It is so that they are able to put themselves in the centre. (...) It is as if they are able to put themselves in the centre. (...) It is so that they are able to put themselves in the centre of attention. (...) It is so that they are able to put themselves in the centre. (...)"}, {"heading": "3.1 Quadratic loss", "text": "Assuming a linear model is defined by a vector w and a target variable y (for regression, y is continuous; for binary classification, y = 1), the expected value of the quadratic distribution p (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x (x) x x x) x x x x x x (x) x x x x x x (x) x x x x (x) x x x x x x x (x) x x x x x x (x) x x x x x x (x) x x x x x x x x (x) x x x x x x (x) x x x x x x x x x x (x) x x x x x x x x (x) x x x x x x x (x) x x x x x x x x x x x (x x x) x x x x x x x x x x x x x x x (x) x x x x x x x x x x x x x x x x (x x x x) x x x x x x x x x x x x x x x (x x x x) x x x x x x x x x x x x x x x x (x x x x) x x x x x x x (x x x x x x x x x x x x x x x) x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "3.2 Exponential loss", "text": "While the above equation can be recognized as a product of momentary functionality, they seem less suitable for use in classification. (...) The expected value of exponential loss (...) is not given. (...) The expected value of exponential loss (...) is not given. (...) The expected value of exponential loss (...) is not given. (...) The expected value of exponential loss (...) is not given. (...) The loss (...) is not given. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...).). (...). (...). (...).). (...). (...). (...).). (...).). (...).). (...).). (...). (...). (...).). (...).). (...). (...). (...).). (...).). (...). (...). (...).). (...).). (...). (...). (...). (...). (...). (...). (...).). (...). (...).). (...). (...). (...).). (...).).). (...). (...). (...).). (...).). (...). (...). (...). (...).).). (...).)."}, {"heading": "4. MCF for Logistic Loss", "text": "In the case of logistical loss, the solution to the expected loss (4) cannot be calculated in a closed form. Instead, we derive an approximation and two practical limits for the expected logistical loss, all of which can be used in practice as substitute functions for the loss. In this section, we will follow the framework of Wager et al. (2013), which is clearer than our previously used derivative (van der Maaten et al. (2013) and leads to a nice interpretation of the MCF as an adaptive regulator. We will focus on binary classification in our derivatives below, but our results can easily be extended to multi-class logistic losses. (Generally, this is achieved by redefining the labels y as being vectors of the form y, {0, 1} K with Kk = 1 yk = 1; and by defining the loss as a logarithm of the softmax probability of correct prediction.)"}, {"heading": "4.1 MCF Regularizer", "text": "Assuming that labels y (\u2212 1, + 1} define the logistic regression model as a generalized linear model, p (y | x; w) = exp (yw > x) exp (\u2212 w > x) + exp (w > x).The negative log probability or logistic loss of an instance pair (x, y) under this model can be described as: L (x, y, w) = \u2212 yw > x + A (w > x) with: A (w > x) = log [exp (\u2212 w > x) + exp (w > x)]. (17) Here A (w > x) is the log partition function that is independent of the label y. Note that we have assumed that corruption can be unbiased (i.e. E [x] that it can be unbiased (x] = x), we can insert it into the expected loss (17) and get >; 2. >; n (n = n)."}, {"heading": "4.2 Quadratic Approximation", "text": "A quadratic approximation of the expected logistic loss can be achieved by deriving a secondary Taylor expansion from A (w > x) by w > x and calculating the expectation (Wager et al., 2013).The resulting quadratic approximation of the expected logistic loss is then: L (D; w) \u2248 1 N \u00b2 n = 1 [\u2212 ynw > xn + A (w > xn) + 1 2 x 2A (w > xn); 2 V [w > x; n] p (x > n) p (19) = 1N N \u00b2 n \u00b2 n \u00b2 n \u00b2 n \u00b2 n (L (xn, yn, w) + 1 x \u00b2 2A (w > xn) x \u00b2 n (w > xn) p (w > x)."}, {"heading": "4.3 Jensen\u2019s upper bound", "text": "As an alternative to the square approach, we can obtain an effective upper limit for the expected logistical loss under the corrupting distribution (= x) (= 24), which states that since log (\u00b7) is a concave function, E [log (z) \u2264 log (E [z]]] + E [exp (w > x)], (23), where all expectations are under the corrupting distribution p (x > x). \u2212 exp (\u2212 x) [exp (\u2212 w > x)]], [exp (w > x)], where all expectations are under the corrupting distribution p (x). \u2212 exp (\u2212 x), which is a slightly easier way to reach the upper limit to L (D; w) can be achieved by redefining the labels (0, 1), and reformulating (18) as: L (D; w) N (n)."}, {"heading": "4.4 Variational bound", "text": "In fact, Jensen's inequality is not the only limit from which one can derive an upper limit for the logistical loss of the MCF. In particular, we also consider variation limits of the form: L (D; w) = 1 N [log (1 + exp (\u2212 ynw > x-n))] p (x-ynw > x-n) = min \u03bb [0,1] 1N [n] = 1 (E [n] 1 N [n] p (x-ynw > x-n) + E [log (exp (n > x-n)) (1 + exp (\u2212 ynw > x-n)))))."}, {"heading": "4.5 Graphical model interpretation", "text": "Finally, minimizing the MCF logistics loss can also be interpreted as training the parameters of the simple Bayesian network in Figure 2 on the maximum probability. In this network, p (x) denotes a corrupting distribution, and p (y) | x) includes a simple linear logistic regressor: p (y) | x) = 1 / (1 + exp (\u2212 yw > x)). Marginalizing the corrupt data x provides us with: p (yn | xn) = E [11 + exp (\u2212 ynw > x)] p (x) n | exp (\u2212 yw > x))."}, {"heading": "5. Experiments", "text": "We evaluate MCF predictions on the basis of word count characteristics with blankout and Poisson corruption."}, {"heading": "5.1 Document classification", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "5.2 Image classification", "text": "We perform image classification experiments with MCF on the CIFAR-10 dataset (Krizhevsky, 2009), which is a subset of the 80 million tiny images (Torralba et al., 2008). The dataset contains RGB images with 10 classes of size 32 \u00d7 32, and consists of a fixed set of 50, 000 images and a fixed test set of 10, 000 images. We follow the experimental setup of Coates et al. (2011): we select the training images and extract a set of 7 image patches on which we apply clustering (with k = 2048) to construct a code book of prototype image patches."}, {"heading": "5.3 Analysis of DNA", "text": "This year, it has come to the point where it only takes one year for it to come to a conclusion."}, {"heading": "5.4 Nightmare at test time", "text": "To test the performance of our MCF predictors with blankout corruption under the \"Nightmare in the Test Time\" scenarios, we conduct experiments on the MNIST data set of handwritten digital images. The MNIST data set contains N = 60,000 training and 10,000 test scenarios of size D = 28 x 28 = 784 pixels and includes K = 10 classes.Setup. We compare the performance of our MCF predictors (using blankout corruption) with that of standard predictors that use l1 or l2-regulated square versions in which a certain percentage of pixels are randomly hidden, i.e. we compare the performance of our MCF predictors (using blankout corruption) with the use of standard predictors that use l1 or l2-regulated square, exponential, logistic, and hinge loss. As we have previously used the CF upper limit of the MF and Loss Predictors to determine the optimum CF predictors."}, {"heading": "6. Discussion and Conclusion", "text": "It is about the question of whether and how such a development can occur. (...) It is about the question of whether and to what extent the United States will be able to change the world. (...) It is about the question of how far the United States are able to change the world. (...) It is about the question of how far they are able to change the world. (...) It is about the question of how far the United States are able to change the world. (...) It is about the question of how far they are able to change the world. (...) \"It is about the world.\" (...) \"It is about the world.\" (...) \"It is about the world.\" (...) \"It is about the world.\" (...) \"(...\" It is about the world. \"(...)\" (...) It is about the world. (...) It is about the world. (...) It is about the world. \"(...\" It is about the world. \"(...) It is about the world.\" (... \"It is about the world.\" (...) It is about the world. (... \"It is about the world.\" It is about the world. \"(...) It is about the world. (...\" It is about the world. (...) It is about the world. (... \"It is about the world. (...) It is about the world. (... It is about. (...) It is about the world.\" It is about the world. \""}, {"heading": "Acknowledgements", "text": "The authors thank Fei Sha, Wouter Kouw, Max Welling and Lawrence Saul for helpful discussions. In particular, the variable ceiling for the logistical loss of Lawrence Saul has been proposed. Laurens van der Maaten thanks for the support of the Dutch Organisation for Scientific Research (NWO; funding 612.001.301), the EU-FP7 SSPNET and INSIDDE projects and the AAL project SALIG + +. Kilian Weinberger, Minmin Chen and Stephen Tyree are supported by NSF grants 1149882 and 1137211."}, {"heading": "Appendix A. Overview of loss functions", "text": "Table 4 gives an overview of all the MCF loss functions discussed in the thesis. Table 5 lists the associated gradients required for learning. To get an overview of the moment-generating functions and their gradients, we refer to Table 2.4. For the square loss of MCF, the optimal parameters can be determined via the closed solution in (6)."}, {"heading": "Appendix B. Numerical stability", "text": "When using dropout, the upper limit of the expected logistic loss is numerically unstable, in particular, the upper limit assumes the following form for multi-class classification: L-D (D; w) = \u2212 N-N-N = 1-D d = 1 (qd + (1 \u2212 qd) exp (y > nwdxnd))). (32) As is usual in logistic regression, we can evaluate this expression by expressing the nominator and denominator in the log domain, making a log shift and exponentializing both sides: L-D (D; w) = \u2212 N-N = 1 log exp (s + q-D = 1 log [qd + (1 \u2212 qd) exp (y > nwdxnd)."}], "references": [{"title": "Competing in the dark: An efficient algorithm for bandit linear optimization", "author": ["J. Abernethy", "E. Hazan", "A. Rakhlin"], "venue": "In Proceedings of the Conference on Learning Theory,", "citeRegEx": "Abernethy et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Abernethy et al\\.", "year": 2008}, {"title": "The relationship between variable selection and data augmentation and a method for prediction", "author": ["D.M. Allen"], "venue": null, "citeRegEx": "Allen.,? \\Q1974\\E", "shortCiteRegEx": "Allen.", "year": 1974}, {"title": "A second order cone programming formulation for classifying missing data", "author": ["C. Bhattacharyya", "K.S. Pannagadatta", "A.J. Smola"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bhattacharyya et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bhattacharyya et al\\.", "year": 2004}, {"title": "Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification", "author": ["J. Blitzer", "M. Dredze", "F. Pereira"], "venue": "In Association for Computational Linguistics,", "citeRegEx": "Blitzer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Blitzer et al\\.", "year": 2007}, {"title": "Convex optimization", "author": ["S.P. Boyd", "L. Vandenberghe"], "venue": null, "citeRegEx": "Boyd and Vandenberghe.,? \\Q2004\\E", "shortCiteRegEx": "Boyd and Vandenberghe.", "year": 2004}, {"title": "Improving the accuracy and speed of support vector machines", "author": ["C.J.C. Burges", "B. Sch\u00f6lkopf"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Burges and Sch\u00f6lkopf.,? \\Q1997\\E", "shortCiteRegEx": "Burges and Sch\u00f6lkopf.", "year": 1997}, {"title": "Online learning of noisy data with kernels", "author": ["N. Cesa-Bianchi", "S. Shalev-Shwartz", "O. Shamir"], "venue": "In Proceedings of the Conference on Learning Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2010}, {"title": "Online learning of noisy data", "author": ["N. Cesa-Bianchi", "S. Shalev-Shwartz", "O. Shamir"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2011}, {"title": "Vicinal risk minimization", "author": ["O. Chapelle", "J. Weston", "L. Bottou", "V. Vapnik"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Chapelle et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2000}, {"title": "Max-margin classification of data with absent features", "author": ["G. Chechik", "G. Heitz", "G. Elidan", "P. Abbeel", "D. Koller"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Chechik et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chechik et al\\.", "year": 2008}, {"title": "Marginalized denoising autoencoders for domain adaptation", "author": ["M. Chen", "Z. Xu", "K.Q. Weinberger", "F. Sha"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Chen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Fast image tagging", "author": ["M. Chen", "A. Zheng", "K.Q. Weinberger"], "venue": "In Proceedings of 30th International Conference on Machine Learning,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["A. Coates", "H. Lee", "A.Y. Ng"], "venue": "In Proceedings of the International Conference on Artificial Intelligence & Statistics, JMLR W&CP", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "Nearest neighbor pattern classification", "author": ["T. Cover", "P. Hart"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cover and Hart.,? \\Q1967\\E", "shortCiteRegEx": "Cover and Hart.", "year": 1967}, {"title": "Frustratingly easy domain adaptation", "author": ["H. Daum\u00e9 III"], "venue": "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,", "citeRegEx": "III.,? \\Q2007\\E", "shortCiteRegEx": "III.", "year": 2007}, {"title": "Learning to classify with missing and corrupted features", "author": ["O. Dekel", "O. Shamir"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Dekel and Shamir.,? \\Q2008\\E", "shortCiteRegEx": "Dekel and Shamir.", "year": 2008}, {"title": "Online convex optimization in the bandit setting: Gradient descent without a gradient", "author": ["A. Flaxman", "A. Kalai", "H. McMahan"], "venue": "In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "Flaxman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Flaxman et al\\.", "year": 2005}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "In Proceedings of the Second European Conference on Computational Learning Theory,", "citeRegEx": "Freund and Schapire.,? \\Q1995\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1995}, {"title": "Nightmare at test time: Robust learning by feature deletion", "author": ["A. Globerson", "S. Roweis"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Globerson and Roweis.,? \\Q2006\\E", "shortCiteRegEx": "Globerson and Roweis.", "year": 2006}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Glorot et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "Trace lasso: A trace norm regularization for correlated designs", "author": ["E. Grave", "G. Obozinski", "F. Bach"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Grave et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Grave et al\\.", "year": 2011}, {"title": "Speedboost: Anytime prediction with uniform near-optimality", "author": ["A. Grubb", "J.A. Bagnell"], "venue": "In Proceedings of the International Conference on Artificial Intelligence & Statistics (AISTATS),", "citeRegEx": "Grubb and Bagnell.,? \\Q2012\\E", "shortCiteRegEx": "Grubb and Bagnell.", "year": 2012}, {"title": "Invariant pattern recognition by semidefinite programming machines", "author": ["R. Herbrich", "T. Graepel"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Herbrich and Graepel.,? \\Q2004\\E", "shortCiteRegEx": "Herbrich and Graepel.", "year": 2004}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R.R. Salakhutdinov"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Technical report, University of Toronto,", "citeRegEx": "Krizhevsky.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky.", "year": 2009}, {"title": "Estimating a kernel Fisher discriminant in the presence of label noise", "author": ["N.D. Lawrence", "B. Sch\u00f6lkopf"], "venue": "In Proceedings of the International Conference in Machine Learning,", "citeRegEx": "Lawrence and Sch\u00f6lkopf.,? \\Q2001\\E", "shortCiteRegEx": "Lawrence and Sch\u00f6lkopf.", "year": 2001}, {"title": "Probabilistic error correction for RNA sequencing", "author": ["H.S. Le", "M.H. Schulz", "B.M. McCauley", "V.F. Hinman", "Z. Bar-Joseph"], "venue": "Nucleic Acids Research,", "citeRegEx": "Le et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Le et al\\.", "year": 2013}, {"title": "Optimal brain damage", "author": ["Y. LeCun", "J.S. Denker", "S.A. Solla"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "LeCun et al\\.,? \\Q1990\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1990}, {"title": "A simple geometric interpretation of svm using stochastic adversaries", "author": ["R. Livni", "K. Crammer", "A. Globerson"], "venue": "In Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AI-STATS),", "citeRegEx": "Livni et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Livni et al\\.", "year": 2012}, {"title": "Steerable playlist generation by learning song similarity from radio station playlists", "author": ["F. Maillet", "D. Eck", "G. Desjardins", "P. Lamere"], "venue": "In Proceedings of the International Society for Music Information Retrieval Conference,", "citeRegEx": "Maillet et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Maillet et al\\.", "year": 2009}, {"title": "A PAC-Bayesian tutorial with a dropout", "author": ["D. McAllester"], "venue": null, "citeRegEx": "McAllester.,? \\Q2013\\E", "shortCiteRegEx": "McAllester.", "year": 2013}, {"title": "Unsupervised and transfer learning challenge: a deep learning approach", "author": ["G. Mesnil", "Y. Dauphin", "X. Glorot", "S. Rifai", "Y. Bengio", "I. Goodfellow", "E. Lavoie", "X. Muller", "G. Desjardins", "D. Warde-Farley", "P. Vincent", "A. Courville", "J. Bergstra"], "venue": "JMLR: Workshop and Conference Proceedings,", "citeRegEx": "Mesnil et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mesnil et al\\.", "year": 2011}, {"title": "Training knowledge-based neural networks to recognize genes in DNA sequences", "author": ["M.O. Noordewier", "G.G. Towell", "J.W. Shavlik"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Noordewier et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Noordewier et al\\.", "year": 1991}, {"title": "On estimation of a probability density function and mode", "author": ["E. Parzen"], "venue": "Annals of Mathematical Statistics,", "citeRegEx": "Parzen.,? \\Q1962\\E", "shortCiteRegEx": "Parzen.", "year": 1962}, {"title": "Modeling pixel means and covariances using factorized thirdorder Boltzmann machines", "author": ["M. Ranzato", "G.E. Hinton"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Ranzato and Hinton.,? \\Q2010\\E", "shortCiteRegEx": "Ranzato and Hinton.", "year": 2010}, {"title": "Learning with missing features", "author": ["A. Rostamizadeh", "A. Agarwal", "P. Bartlett"], "venue": "In Proceedings of Uncertainty in Artificial Intelligence,", "citeRegEx": "Rostamizadeh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rostamizadeh et al\\.", "year": 2011}, {"title": "Shallow parsing with Conditional Random Fields", "author": ["F. Sha", "F. Pereira"], "venue": "In Proceedings of Human Language Technology \u2013 NAACL", "citeRegEx": "Sha and Pereira.,? \\Q2003\\E", "shortCiteRegEx": "Sha and Pereira.", "year": 2003}, {"title": "A tutorial on conformal prediction", "author": ["G. Shafer", "V. Vovk"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Shafer and Vovk.,? \\Q2008\\E", "shortCiteRegEx": "Shafer and Vovk.", "year": 2008}, {"title": "Second order cone programming approaches for handling missing and uncertain data", "author": ["P.K. Shivaswamy", "C. Bhattacharyya", "A.J. Smola"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Shivaswamy et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Shivaswamy et al\\.", "year": 2006}, {"title": "Feature bagging: Preventing weight undertraining in structured discriminative learning", "author": ["C. Sutton", "M. Sindelar", "A. McCallum"], "venue": "Technical Report IR-402,", "citeRegEx": "Sutton et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 2005}, {"title": "Convex learning with invariances", "author": ["C.H. Teo", "A. Globerson", "S. Roweis", "A. Smola"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Teo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Teo et al\\.", "year": 2008}, {"title": "80 million tiny images: A large dataset for non-parametric object and scene recognition", "author": ["A. Torralba", "R. Fergus", "W.T. Freeman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Torralba et al\\.,? \\Q1958\\E", "shortCiteRegEx": "Torralba et al\\.", "year": 1958}, {"title": "Robust support vector machines for classification and computational issues", "author": ["T. Trafalis", "R. Gilbert"], "venue": "Optimization Methods and Software,", "citeRegEx": "Trafalis and Gilbert.,? \\Q2007\\E", "shortCiteRegEx": "Trafalis and Gilbert.", "year": 2007}, {"title": "Learning by marginalizing corrupted features", "author": ["L.J.P. van der Maaten", "M. Chen", "S. Tyree", "K.Q. Weinberger"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Maaten et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2013}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["P. Vincent", "H. Larochelle", "Y. Bengio", "P.A. Manzagol"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Vincent et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2008}, {"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["P. Vincent", "H. Larochelle", "I. Lajoie", "Y. Bengio", "P.-A. Manzagol"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Vincent et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2010}, {"title": "Dropout training as adaptive regularization", "author": ["S. Wager", "S. Wang", "P. Liang"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Wager et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wager et al\\.", "year": 2013}, {"title": "Feature noising for log-linear structured prediction", "author": ["S. Wang", "M. Wang", "S. Wager", "P. Liang", "C.D. Manning"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Wang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "Robustness and regularization of support vector machines", "author": ["H. Xu", "C. Caramanis", "S. Mannor"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Xu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2009}, {"title": "Error correction of next-generation sequencing data and reliable estimation of HIV quasispecies", "author": ["O. Zagordi", "R. Klein", "M. D\u00e4umer", "N. Beerenwinkel"], "venue": "Nucleic Acids Research,", "citeRegEx": "Zagordi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zagordi et al\\.", "year": 2010}, {"title": "Multi-class AdaBoost", "author": ["J. Zhu", "S. Rosset", "H. Zou", "T. Hastie"], "venue": "Technical Report 430, Department of Statistics, University of Michigan,", "citeRegEx": "Zhu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 13, "context": "In such a hypothetical scenario, it is impossible to overfit models; and even high-variance models, such as the nearest neighbor classifier (Cover and Hart, 1967), become close to optimal (viz.", "startOffset": 140, "endOffset": 162}, {"referenceID": 33, "context": "The Gaussian corruption model is mainly of interest for continuous-valued data sets; special cases of MCF with Gaussian corruption have already been studied in the context of Parzen density estimation (Parzen, 1962) and in the context of vicinal risk minimization (Chapelle et al.", "startOffset": 201, "endOffset": 215}, {"referenceID": 8, "context": "The Gaussian corruption model is mainly of interest for continuous-valued data sets; special cases of MCF with Gaussian corruption have already been studied in the context of Parzen density estimation (Parzen, 1962) and in the context of vicinal risk minimization (Chapelle et al., 2000).", "startOffset": 264, "endOffset": 287}, {"referenceID": 5, "context": "Burges and Sch\u00f6lkopf (1997) explicitly augment the training set with additional examples that are corrupted through similar transformations.", "startOffset": 0, "endOffset": 28}, {"referenceID": 18, "context": "Blankout corruption is also of interest in the \u201cnightmare at test time\u201d scenario (Globerson and Roweis, 2006) in which some of the features are deleted during testing, e.", "startOffset": 81, "endOffset": 109}, {"referenceID": 2, "context": "Different from previous work (Bhattacharyya et al., 2004; Globerson and Roweis, 2006; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007), our setting focuses on random feature removal and not on the (in practice much rarer) worst-case adversarial setting.", "startOffset": 29, "endOffset": 138}, {"referenceID": 18, "context": "Different from previous work (Bhattacharyya et al., 2004; Globerson and Roweis, 2006; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007), our setting focuses on random feature removal and not on the (in practice much rarer) worst-case adversarial setting.", "startOffset": 29, "endOffset": 138}, {"referenceID": 38, "context": "Different from previous work (Bhattacharyya et al., 2004; Globerson and Roweis, 2006; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007), our setting focuses on random feature removal and not on the (in practice much rarer) worst-case adversarial setting.", "startOffset": 29, "endOffset": 138}, {"referenceID": 42, "context": "Different from previous work (Bhattacharyya et al., 2004; Globerson and Roweis, 2006; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007), our setting focuses on random feature removal and not on the (in practice much rarer) worst-case adversarial setting.", "startOffset": 29, "endOffset": 138}, {"referenceID": 29, "context": "The resulting denoising autoencoder model is now commonly used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al.", "startOffset": 100, "endOffset": 164}, {"referenceID": 19, "context": "The resulting denoising autoencoder model is now commonly used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al.", "startOffset": 100, "endOffset": 164}, {"referenceID": 31, "context": "The resulting denoising autoencoder model is now commonly used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al.", "startOffset": 100, "endOffset": 164}, {"referenceID": 23, "context": ", 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al., 2012).", "startOffset": 129, "endOffset": 150}, {"referenceID": 10, "context": "Linear denoising autoencoders (Chen et al., 2012) can be viewed as a special case of MCF that aim to minimize the expected value of the reconstruction error under blankout corruption\u2014 and which are stacked in multiple layers.", "startOffset": 30, "endOffset": 49}, {"referenceID": 16, "context": "In online learning and bandit problems, various studies have shown that it is possible to learn from data that are subject to a (possibly unknown) corrupting distribution (Flaxman et al., 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010).", "startOffset": 171, "endOffset": 244}, {"referenceID": 0, "context": "In online learning and bandit problems, various studies have shown that it is possible to learn from data that are subject to a (possibly unknown) corrupting distribution (Flaxman et al., 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010).", "startOffset": 171, "endOffset": 244}, {"referenceID": 6, "context": "In online learning and bandit problems, various studies have shown that it is possible to learn from data that are subject to a (possibly unknown) corrupting distribution (Flaxman et al., 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010).", "startOffset": 171, "endOffset": 244}, {"referenceID": 4, "context": "The initial publication by Burges and Sch\u00f6lkopf (1997) has inspired various lines of work that explicitly corrupt training data during training.", "startOffset": 27, "endOffset": 55}, {"referenceID": 4, "context": "The initial publication by Burges and Sch\u00f6lkopf (1997) has inspired various lines of work that explicitly corrupt training data during training. Most prominently, Vincent et al. (2008, 2010) propose to randomly blank out features in the training data that is used as input to autoencoders, whilst leaving the desired output (the original training data) unaltered. The resulting denoising autoencoder model is now commonly used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al., 2012). Since autoencoders are non-linear, the marginalization over the corrupting distribution cannot be performed analytically in such models. Linear denoising autoencoders (Chen et al., 2012) can be viewed as a special case of MCF that aim to minimize the expected value of the reconstruction error under blankout corruption\u2014 and which are stacked in multiple layers. Herbrich and Graepel (2004) propose an elegant generalization of SVMs that learns to be invariant to polynomial input transformations via a semi-definite programming formulation.", "startOffset": 27, "endOffset": 1064}, {"referenceID": 0, "context": ", 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010). For instance, Cesa-Bianchi et al. (2011) show that noise in the data does not affect the convergence rate of online learners.", "startOffset": 8, "endOffset": 101}, {"referenceID": 0, "context": ", 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010). For instance, Cesa-Bianchi et al. (2011) show that noise in the data does not affect the convergence rate of online learners. A similar regret bound is proven by Rostamizadeh et al. (2011) for online learning under the presence of randomly missing features (i.", "startOffset": 8, "endOffset": 249}, {"referenceID": 2, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature.", "startOffset": 14, "endOffset": 112}, {"referenceID": 38, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature.", "startOffset": 14, "endOffset": 112}, {"referenceID": 42, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature.", "startOffset": 14, "endOffset": 112}, {"referenceID": 48, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature.", "startOffset": 14, "endOffset": 112}, {"referenceID": 15, "context": "In particular, Globerson and Roweis (2006) propose a minimax-formulation in which the loss is minimized assuming maximum \u201cdamage\u201d through corruption.", "startOffset": 15, "endOffset": 43}, {"referenceID": 13, "context": "By contrast, Dekel and Shamir (2008) propose a linear-programming formulation that minimizes an approximation to the same quantity for margin-based predictors.", "startOffset": 13, "endOffset": 37}, {"referenceID": 2, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature. Livni et al. (2012) consider a scenario in which an adversarial chooses the corrupting distribution from the set of all distributions with a pre-specified variance as to increase the expected loss under the corruption as much as possible.", "startOffset": 15, "endOffset": 347}, {"referenceID": 2, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature. Livni et al. (2012) consider a scenario in which an adversarial chooses the corrupting distribution from the set of all distributions with a pre-specified variance as to increase the expected loss under the corruption as much as possible. Chechik et al. (2008) propose an algorithm that maximizes the margin in the subspace of the observed features for each training instance to be robust against random feature deletion.", "startOffset": 15, "endOffset": 588}, {"referenceID": 2, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature. Livni et al. (2012) consider a scenario in which an adversarial chooses the corrupting distribution from the set of all distributions with a pre-specified variance as to increase the expected loss under the corruption as much as possible. Chechik et al. (2008) propose an algorithm that maximizes the margin in the subspace of the observed features for each training instance to be robust against random feature deletion. Teo et al. (2008) generalize the worst-case scenario from simple feature corruption to obtain invariances to transformations such as image rotations or translations.", "startOffset": 15, "endOffset": 767}, {"referenceID": 22, "context": "eral prior formulations on learning with invariants as special cases, most prominently, the formulation of Herbrich and Graepel (2004). Such previous work differs from our approach in that it focuses on adversarial scenarios and does not consider the corruption analytically in expectation.", "startOffset": 107, "endOffset": 135}, {"referenceID": 18, "context": "In the nightmare at test-time scenario, introduced by Globerson and Roweis (2006), there is an expectation that corruption will appear during test-time.", "startOffset": 54, "endOffset": 82}, {"referenceID": 5, "context": "A simple approach to approximately learn from the distribution p(x\u0303|x)P(x) is to follow the spirit of Burges and Sch\u00f6lkopf (1997) and corrupt each training sample M times, following (1).", "startOffset": 102, "endOffset": 130}, {"referenceID": 23, "context": "Such approaches have recently become popular, in particular, in the deep-learning community as a way to regularize deep networks (Hinton et al., 2012).", "startOffset": 129, "endOffset": 150}, {"referenceID": 8, "context": "For such a Gaussian corruption model, we obtain the standard l2-regularized quadratic loss with regularization parameter \u03c32 that is used in ridge regression as special case (Chapelle et al., 2000):", "startOffset": 173, "endOffset": 196}, {"referenceID": 20, "context": "Similar data-dependent regularizers have previously been studied by Grave et al. (2011). Poisson corruption.", "startOffset": 68, "endOffset": 88}, {"referenceID": 1, "context": "A nice property of linear models employing quadratic loss is that they allow us to compute the leave-one-out error of the model from only the training predictions \u0177n (Allen, 1974).", "startOffset": 166, "endOffset": 179}, {"referenceID": 1, "context": ", yN ], and use the simple fact that \u0177\u2212n n = \u2211N m=1Hnmzm (see Allen (1974) for details) we obtain: \u0177n \u2212 \u0177\u2212n n = N \u2211", "startOffset": 62, "endOffset": 75}, {"referenceID": 17, "context": ", in AdaBoost (Freund and Schapire, 1995).", "startOffset": 14, "endOffset": 41}, {"referenceID": 50, "context": "The derivation of (14) can readily be extended to a multi-class exponential loss with K classes by replacing the weight vector w by a D \u00d7K weight matrix W, and by replacing the labels y by label vectors y = {1,\u2212 1 K\u22121} with \u2211K k=1 yk = 0 (Zhu et al., 2006).", "startOffset": 238, "endOffset": 256}, {"referenceID": 36, "context": "Motivated by Sha and Pereira (2003), we used an L-BFGS optimizer to minimize MCF exponential loss in this study.", "startOffset": 13, "endOffset": 36}, {"referenceID": 45, "context": "In this section we follow the framework of Wager et al. (2013), which is clearer than our previously used derivation (van der Maaten et al.", "startOffset": 43, "endOffset": 63}, {"referenceID": 43, "context": "(2013), which is clearer than our previously used derivation (van der Maaten et al. (2013)) and leads to a nice interpretation of MCF as an adaptive regularizer.", "startOffset": 70, "endOffset": 91}, {"referenceID": 46, "context": "2 Quadratic Approximation A quadratic approximation to the expected logistic loss can be obtained by deriving a second-order Taylor expansion of A(w>x\u0303) around w>x and working out the expectation (Wager et al., 2013).", "startOffset": 196, "endOffset": 216}, {"referenceID": 37, "context": "In classification, corrupting test data provides a natural way to measure the uncertainty of a prediction, even when the original predictor was non-probabilistic (much like conformal prediction; Shafer and Vovk (2008)).", "startOffset": 195, "endOffset": 218}, {"referenceID": 3, "context": "Specifically, we focus on three data sets: the Dmoz data set, the Reuters data set, and the Amazon review benchmark set (Blitzer et al., 2007).", "startOffset": 120, "endOffset": 142}, {"referenceID": 3, "context": "Specifically, we focus on three data sets: the Dmoz data set, the Reuters data set, and the Amazon review benchmark set (Blitzer et al., 2007). Data sets. The Dmoz open directory (http://www.dmoz.org) contains a large collection of webpages arranged into a tree hierarchy. We use a subset consisting of N = 8, 980 webpages from the K = 16 categories in the top level of the hierarchy. Each webpage is represented by a bag-of-words representation with D = 16, 498 words. The Reuters document classification data set consists of N = 8, 293 news articles that appeared on the Reuters newswire in 1987 belonging to K = 65 topics (documents corresponding to multiple topics were removed from the data). The bag-of-words representation contains D = 18, 933 words for each document. The four Amazon data sets consist of approximately N = 6, 000 reviews of four types of products: books, DVDs, electronics, and kitchen appliances. Each review is represented by a bag-of-words representation of the D = 20, 000 most common words. On the Dmoz and Reuters data sets, the task is to classify the documents into one of the predefined categories. On the Amazon data set, the task is to decide whether a review is positive or negative. Setup. On the Dmoz and Reuters data sets, we use fixed 75%/25% training/test splits. On the Amazon data set, we follow the experimental setup of Blitzer et al. (2007) by using a predefined division of the data into approximately 2, 000 training examples and about 4, 000 test examples (the exact numbers vary slightly between tasks).", "startOffset": 121, "endOffset": 1388}, {"referenceID": 24, "context": "2 Image classification We perform image-classification experiments with MCF on the CIFAR-10 data set (Krizhevsky, 2009), which is a subset of the 80 million tiny images (Torralba et al.", "startOffset": 101, "endOffset": 119}, {"referenceID": 12, "context": "We follow the experimental setup of Coates et al. (2011): we whiten the training images and extract a set of 7 \u00d7 7 image patches on which we apply k-means clustering (with k = 2048) to construct a codebook of prototypical image patches.", "startOffset": 36, "endOffset": 57}, {"referenceID": 12, "context": "We follow the experimental setup of Coates et al. (2011): we whiten the training images and extract a set of 7 \u00d7 7 image patches on which we apply k-means clustering (with k = 2048) to construct a codebook of prototypical image patches. Next, we slide a 7 \u00d7 7 pixel window over each image and identify the nearest prototype in the codebook for each window location. We construct an image descriptor by subdividing the image into four equally sized quadrants and counting the number of times each prototype occurs in each quadrant, which leads to a descriptor of dimensionality D = 4 \u00d7 2048. This way of extracting the image features is referred to by Coates et al. (2011) as k-means with hard assignment, average pooling, patch size 7 \u00d7 7, and stride 1.", "startOffset": 36, "endOffset": 672}, {"referenceID": 34, "context": "Although our focus in this section is to merely illustrate the potential of MCF on image classification tasks, it is worth noting that the best results in Table 3 match those of a highly non-linear mean-covariance RBMs trained on the same data (Ranzato and Hinton, 2010), despite our use of very simple visual features and of linear classifiers.", "startOffset": 244, "endOffset": 270}, {"referenceID": 12, "context": "8% accuracy reported by Coates et al. (2011) with exactly the same experimental setup (except for exponential loss).", "startOffset": 24, "endOffset": 45}, {"referenceID": 31, "context": "We perform experiments on the data set constructed by Noordewier et al. (1991). The data set comprises 3190 examples of three classes: it contains 767 examples of acceptors, 768 examples of donors, and 1655 negative examples.", "startOffset": 54, "endOffset": 79}, {"referenceID": 26, "context": ", Le et al. (2013); Zagordi et al.", "startOffset": 2, "endOffset": 19}, {"referenceID": 26, "context": ", Le et al. (2013); Zagordi et al. (2010)).", "startOffset": 2, "endOffset": 42}, {"referenceID": 26, "context": "Both types of knowledge are available for modern DNA sequencing processes (Le et al., 2013; Zagordi et al., 2010).", "startOffset": 74, "endOffset": 113}, {"referenceID": 49, "context": "Both types of knowledge are available for modern DNA sequencing processes (Le et al., 2013; Zagordi et al., 2010).", "startOffset": 74, "endOffset": 113}, {"referenceID": 32, "context": "However, since no information on the coverage and sequencing error distribution is available for our data set (Noordewier et al., 1991), we leave such extensions of the DNA experiments to future work.", "startOffset": 110, "endOffset": 135}, {"referenceID": 18, "context": "In addition to the comparisons with standard predictors, we also compare the performance of MCF with that of FDROP (Globerson and Roweis, 2006), which is a state-of-the-art algorithm for the \u201cnightmare at test time\u201d setting that minimizes the hinge loss under an adversarial worst-case scenario (see section 2).", "startOffset": 115, "endOffset": 143}, {"referenceID": 18, "context": "Classification errors of standard and MCF predictors with a blankout corruption model \u2013 trained using three different losses \u2013 and of FDROP (Globerson and Roweis, 2006) on the MNIST data set using the \u201cnightmare at test time\u201d scenario.", "startOffset": 140, "endOffset": 168}, {"referenceID": 3, "context": "We are thus assuming a transductive learning setting, which is a common assumption in many learning scenarios with domain shift (Blitzer et al., 2007; Daum\u00e9 III, 2007).", "startOffset": 128, "endOffset": 167}, {"referenceID": 16, "context": "Following the experimental setting of Globerson and Roweis (2006), we perform the crossvalidation for each deletion percentage independently, i.", "startOffset": 38, "endOffset": 66}, {"referenceID": 39, "context": "Further, MCF with blankout corruption also appears to prevent weight undertraining (Sutton et al., 2005): it encourages the weight on each feature to be non-zero, in case this particular feature survives the corruption.", "startOffset": 83, "endOffset": 104}, {"referenceID": 15, "context": "Learning with MCF is quite different from previous approaches for this setting (Dekel and Shamir, 2008; Globerson and Roweis, 2006).", "startOffset": 79, "endOffset": 131}, {"referenceID": 18, "context": "Learning with MCF is quite different from previous approaches for this setting (Dekel and Shamir, 2008; Globerson and Roweis, 2006).", "startOffset": 79, "endOffset": 131}, {"referenceID": 3, "context": "The strong performance of MCF in the \u201cnightmare at test-time\u201d scenario suggest it be well suited for learning under domain shift (Blitzer et al., 2007; Daum\u00e9 III, 2007).", "startOffset": 129, "endOffset": 168}, {"referenceID": 47, "context": "Another interesting direction for future work is to investigate extensions of MCF to structured prediction (Wang et al., 2013), as well as to investigate if MCF can be employed for kernel machines.", "startOffset": 107, "endOffset": 126}, {"referenceID": 27, "context": "Further, MCF could be used in the training of neural networks with a single layer of hidden units: blankout noise on the hidden nodes can improve the performance of the networks (LeCun et al., 1990; Hinton et al., 2012) and can be marginalized out analytically.", "startOffset": 178, "endOffset": 219}, {"referenceID": 23, "context": "Further, MCF could be used in the training of neural networks with a single layer of hidden units: blankout noise on the hidden nodes can improve the performance of the networks (LeCun et al., 1990; Hinton et al., 2012) and can be marginalized out analytically.", "startOffset": 178, "endOffset": 219}, {"referenceID": 21, "context": "Moreover, classifiers trained using MCF-blankout may be very well suited for application in anytime classification scenarios (Grubb and Bagnell, 2012), as they are optimized to work well on all possible subsets of features.", "startOffset": 125, "endOffset": 150}, {"referenceID": 25, "context": "A final interesting direction would be to investigate the effect of marginalizing corrupted labels or target values (Lawrence and Sch\u00f6lkopf, 2001; Chen et al., 2013).", "startOffset": 116, "endOffset": 165}, {"referenceID": 11, "context": "A final interesting direction would be to investigate the effect of marginalizing corrupted labels or target values (Lawrence and Sch\u00f6lkopf, 2001; Chen et al., 2013).", "startOffset": 116, "endOffset": 165}, {"referenceID": 3, "context": "The strong performance of MCF in the \u201cnightmare at test-time\u201d scenario suggest it be well suited for learning under domain shift (Blitzer et al., 2007; Daum\u00e9 III, 2007). In particular, as the corrupting distribution may be used to shift the data distribution in the source domain towards the data distribution in the target domain \u2014 potentially, by learning the parameters of the corrupting distribution using maximum likelihood. We leave such investigations for future work. Another interesting direction for future work is to investigate extensions of MCF to structured prediction (Wang et al., 2013), as well as to investigate if MCF can be employed for kernel machines. We also plan to explore in more detail what corruption models p(x\u0303|x) are useful for what types of data. Further, MCF could be used in the training of neural networks with a single layer of hidden units: blankout noise on the hidden nodes can improve the performance of the networks (LeCun et al., 1990; Hinton et al., 2012) and can be marginalized out analytically. Moreover, classifiers trained using MCF-blankout may be very well suited for application in anytime classification scenarios (Grubb and Bagnell, 2012), as they are optimized to work well on all possible subsets of features. Another interesting direction for future work is to investigate the theoretical properties of learning with MCF. Xu et al. (2009) have derived generalization bounds for learning with corruption under the worst-case scenario (i.", "startOffset": 130, "endOffset": 1395}, {"referenceID": 3, "context": "The strong performance of MCF in the \u201cnightmare at test-time\u201d scenario suggest it be well suited for learning under domain shift (Blitzer et al., 2007; Daum\u00e9 III, 2007). In particular, as the corrupting distribution may be used to shift the data distribution in the source domain towards the data distribution in the target domain \u2014 potentially, by learning the parameters of the corrupting distribution using maximum likelihood. We leave such investigations for future work. Another interesting direction for future work is to investigate extensions of MCF to structured prediction (Wang et al., 2013), as well as to investigate if MCF can be employed for kernel machines. We also plan to explore in more detail what corruption models p(x\u0303|x) are useful for what types of data. Further, MCF could be used in the training of neural networks with a single layer of hidden units: blankout noise on the hidden nodes can improve the performance of the networks (LeCun et al., 1990; Hinton et al., 2012) and can be marginalized out analytically. Moreover, classifiers trained using MCF-blankout may be very well suited for application in anytime classification scenarios (Grubb and Bagnell, 2012), as they are optimized to work well on all possible subsets of features. Another interesting direction for future work is to investigate the theoretical properties of learning with MCF. Xu et al. (2009) have derived generalization bounds for learning with corruption under the worst-case scenario (i.e. for the related models discussed in Section 2), and McAllester (2013) recently derived a PAC-Bayesian bound for learning linear models with blankout in the average-case scenario; however, generic bounds for learning with MCF do not yet exist.", "startOffset": 130, "endOffset": 1565}], "year": 2014, "abstractText": "The goal of machine learning is to develop predictors that generalize well to test data. Ideally, this is achieved by training on an almost infinitely large training data set that captures all variations in the data distribution. In practical learning settings, however, we do not have infinite data and our predictors may overfit. Overfitting may be combatted, for example, by adding a regularizer to the training objective or by defining a prior over the model parameters and performing Bayesian inference. In this paper, we propose a third, alternative approach to combat overfitting: we extend the training set with infinitely many artificial training examples that are obtained by corrupting the original training data. We show that this approach is practical and efficient for a range of predictors and corruption models. Our approach, called marginalized corrupted features (MCF), trains robust predictors by minimizing the expected value of the loss function under the corruption model. We show empirically on a variety of data sets that MCF classifiers can be trained efficiently, may generalize substantially better to test data, and are also more robust to feature deletion at test time.", "creator": "LaTeX with hyperref package"}}}