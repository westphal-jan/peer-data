{"id": "1403.0778", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Mar-2014", "title": "Dynamic Move Chains -- a Forward Pruning Approach to Tree Search in Computer Chess", "abstract": "This paper proposes a new mechanism for pruning a search game-tree in computer chess. The algorithm stores and then reuses chains or sequences of moves, built up from previous searches. These move sequences have a built-in forward-pruning mechanism that can radically reduce the search space. A typical search process might retrieve a move from a Transposition Table, where the decision of what move to retrieve would be based on the position itself. This algorithm stores move sequences based on what previous sequences were better, or caused cutoffs. This is therefore position independent and so it could also be useful in games with imperfect information or uncertainty, where the whole situation is not known at any one time. Over a small set of tests, the algorithm was shown to clearly out-perform Transposition Tables, both in terms of search reduction and game-play results.", "histories": [["v1", "Tue, 4 Mar 2014 13:07:48 GMT  (703kb)", "http://arxiv.org/abs/1403.0778v1", "Published"]], "COMMENTS": "Published", "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["kieran greer"], "accepted": false, "id": "1403.0778"}, "pdf": {"name": "1403.0778.pdf", "metadata": {"source": "META", "title": "DCS Paper", "authors": ["Kieran Greer"], "emails": [], "sections": [{"heading": null, "text": "The algorithm then stores and uses chains or sequences of moves built from previous searches, which have a built-in forward truncation mechanism that can radically reduce the search space. A typical search process could retrieve a move from a transposition table, where the decision to retrieve a move would be based on the position itself. This algorithm stores sequences of moves based on previous sequences that were better or caused failures, so this is independent of location and could therefore be useful in games with imperfect information or uncertainty where the whole situation is not known at any time. A small group of tests showed that the algorithm clearly performs transposition tables, both in terms of search reduction and game results. Index terms - Dynamic move sequence, tree search, artificial intelligence, game theory."}, {"heading": "1 Introduction", "text": "The context is to optimize the search process for the game of the computer player. Sequences of moves are returned during the search for the chessboard tree that causes a cut, or it is determined that certain parts of the tree do not need to be searched for. These moves are usually stored in transposition tables. [12] Instead, they can be stored in a dynamic concatenation structure that is used in other parts of the search process to reduce the size of the search tree. They can be used in the same way as transposition tables by returning an already searched sequence of moves that eliminates the need to search for the tree structure that is used in other parts of the search process to reduce the size of the search tree."}, {"heading": "2 Chessmaps Heuristic", "text": "The neural network is taught to recognize into which areas of the board a piece should be moved, based on which areas of the board controls each side. In fact, the move is calculated based on which squares each side controls, or influences after it has moved, increasing the influence of the long distance on each piece. Neural network move is trained on Grandmaster or master games. Chess position is converted into a board that defines which squares control each side and this is then used as input for training the neural network. The move played in this position is converted into the squares moves that the move has played, influences. These are the squares that attack the moves and these are used as output that the neural network then tries to detect. The theory behind this is that there is a defined relationship between the squares that a player controls and the squares that the player moves, or the areas that the player plans or plans to detect a network."}, {"heading": "3 Dynamic Move Sequences", "text": "Two of the most popular experience-based approaches to minimizing the search process are the History Heuristic [11] and Transposition Tables [11] [12]. Tests have shown that using combinations of heuristics can produce a search reduction close to the minimum tree for an alpha \u03b2 search. This means that it is almost possible to produce the same search tree size that would produce a perfect arrangement, because parts of the search tree can be removed without any part of the search process being searched, with a result that has already been stored and is therefore attractive in its compact form. It can represent all movements in a single 64-square board array. Transposition tables can become very large and therefore require an indexing system to find the position that relates to them."}, {"heading": "4 Related Work", "text": "They rely more on program optimization and speed to search for more positions and thus get a more accurate score. However, there are also a number of strong AI-related programs, some of which are listed here. However, a summary of recent advances in AI gameplay can be found in [5]. KnightCaps [1] is possibly one of the best AI attempts to play computer chess, based on its skill level. It uses a variation of the Temporal Differential Machine Learning Algorithm called TDLeaf. The core idea of TD learning is that we adapt predictions to suit each other, more accurately, predictions of the trait that can be achieved through deeper searches, or evaluations of models that are closer to the known result. The same mechanisms were used in the NeuroChess program. Blondie25 [4] is an example of another chess program that uses an evolutionary method to learn."}, {"heading": "5 Testing", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Search to fixed depth for different algorithm versions", "text": "This series of tests attempts to apply three different search algorithms on the same set of positions, but to fixed depths of 5 or 6 times for each position. The search process automatically applies \u03b2 a minimum window and iterative indentation to each search that is performed. As well as this, the three tested algorithms contain either the Chessmaps heuristic per se, the Chessmaps heuristic and transposition tables, with 1000000 entries for each page; or the Chessmaps heuristic with dynamic train sequences. Table 1 gives the results of the test searches. The first line of the numbers are the actual search results, while the second line is the percentage difference between Chessmaps alone and the other mechanism with which it is compared. The reduction series describes the amount of additional search depth that either the transposition tables or the train chains produce only via the chess charts heuristic. The transposition tables that are implemented as part of the Chessmaps program."}, {"heading": "5.2 Playing Different Algorithms Against Each Other", "text": "In these tests, the Chessmaps algorithm with transposition tables was pitted against the Chessmaps algorithm with dynamic traction chains. Both versions also used an iterative deepening search with minimal window. There is also a random opening selector so that each game started from a different position. Tests were conducted over 100 games - 50 with chessmaps plus transposition tables as white and 50 with chessmaps plus traction chains as white. Each side was allowed to play for 30 minutes per game, with the results presented in Table 2. These results are not intended to be definitive, but should show that the new search algorithm is a viable alternative, with the idea of using dynamic traction chains as a solid one. These results also show that the use of dynamic traction sequences with chessmaps achieves heuristic results with the Chessmaps tables, with the version of the traction chains winning more games."}, {"heading": "6 Future Work", "text": "The dynamics of the movement is a bit like dynamic chunking, or tactical chunks, where a player would recognize and play combinations that he / she has seen before. Transposition tables are not 100% accurate because the hash function maps different positions to each entry, so there is also a certain generalization. In this case, the tables are sequences that can be thought of as tactical chunks. Why compare them to a tactical chunk? The goal of these chunks is to indicate relevant moves in a position. Tactics are about movements, not about position ratings and such moving sequences that might be good, as chunks of tactical knowledge. It is also worth noting that many games are played with imperfect information, which is not always available."}, {"heading": "7 Conclusions", "text": "These tests are based on a relatively small number of examples, but they show the potential of the algorithm and confirm that dynamic traction chains are at least reliable. That is, they can be added to a search process and used without returning unreliable moves. Playing against the algorithm also confirms that it is not likely to make a bad move more often than any other algorithm. In this respect, train sequences or chains are thus a viable alternative to transposition tables. They also offer a compact solution for indexing trains and offer new possibilities for exploring other more knowledge-based or smarter types of computer chess. The biggest danger is probably simply the loss of evaluation quality due to the reduction in search. Most of the traction chains generated were only at depth 1, but could be at depth 3 or 4, for example. So it is the ability to dynamically update them, the similarity between positions in a search and the rest search search that keeps the search result accurate."}, {"heading": "8 References", "text": "[1] Baxter J., Tridgell A., Weaver L., (1998), KnightCap: A chess program that learns by combingTD (lambda) with gametree search, Proceedings of the Fifteenth International Conference on Machine Learning, pp. 28-36. [2] Bonet, B., and Geffner, H., (2006), Learning depth-first search: A unified approach to heuristicsearch in deterministic and non-deterministic settings, and its application to MDPs. In Long, D.; Smith, S. F.; Borrajo, D.; and Mc-Cluskey, L., Proceedings of the Sixteenth International Conference on Automated Planning and Scheduling, pp. 142-151. [3] Fernandez, A. and Salmeron, A., A., (2008), BayesChess: A computer chess program based onBayesian networks, Pattern Recognitions Letters - Ellevier."}], "references": [{"title": "KnightCap: A chess program that learns by combining TD(lambda) with gametree search", "author": ["J. Baxter", "A. Tridgell", "L. Weaver"], "venue": "Proceedings of the Fifteenth International Conference on Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Learning depth-first search: A unified approach to heuristic search in deterministic and non-deterministic settings, and its application to MDPs", "author": ["B. Bonet", "H. Geffner"], "venue": "Proceedings of the Sixteenth International Conference on Automated Planning and Scheduling,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "BayesChess: A computer chess program based on Bayesian networks, Pattern Recognition Letters \u2013 Elsevier", "author": ["A. Fernandez", "A. Salmeron"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "A Self-Learning Evolutionary Chess Program", "author": ["D.B. Fogel", "T.J. Hays", "S.L. Hahn", "J. Quon"], "venue": "Proceedings of the IEEE,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Recent advances in machine learning and game playing", "author": ["J. F\u00fcrnkranz"], "venue": "OGAI Journal,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Machine Learning in Computer Chess: The Next Generation", "author": ["J. F\u00fcrnkranz"], "venue": "ICCA Journal,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1995}, {"title": "Combining Online and Offline Knowledge in UCT", "author": ["S. Gelly", "D. Silver"], "venue": "Proceedings of the 24th International Conference on Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Computer Chess Move Ordering Schemes Using Move Influence", "author": ["K. Greer"], "venue": "Artificial Intelligence Journal,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2000}, {"title": "What Computer Chess Still Has to Teach Us - The Game that Will not Go, electronic", "author": ["A. Iqbal"], "venue": "Journal of Computer Science and Information Technology (eJCSIT),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "An Evolutionary Approach for the Tuning of a Chess Evaluation Function using Population Dynamics", "author": ["G. Kendall", "G. Whitwell"], "venue": "Proceedings of the 2001 IEEE Congress on Evolutionary Computation, Seoul,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "The History Heuristic and other Alpha-Beta Search encancements in Practice", "author": ["J. Schaeffer"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1989}, {"title": "New Advances in Alpha-Beta Searching", "author": ["J. Schaeffer", "A. Plaat"], "venue": "Proceedings of the 25th Computer Science Conference.  DCS", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1996}, {"title": "Learning to Play the Game of Chess", "author": ["S. Thrun"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1995}, {"title": "Modifications of UCT and sequence-like simulations for Monte- Carlo Go", "author": ["Y. Wang", "S. Gelly"], "venue": "IEEE Symposium on Computational Intelligence and Games, Honolulu,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}], "referenceMentions": [{"referenceID": 10, "context": "These move sequences are usually stored in Transposition Tables [11][12], but instead, they can be stored in a dynamic linking structure and used in other parts of the search process to reduce the search tree size.", "startOffset": 64, "endOffset": 68}, {"referenceID": 11, "context": "These move sequences are usually stored in Transposition Tables [11][12], but instead, they can be stored in a dynamic linking structure and used in other parts of the search process to reduce the search tree size.", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "The Chessmaps heuristic [8] was created as part of a DPhil research project that was completed in 1998.", "startOffset": 24, "endOffset": 27}, {"referenceID": 2, "context": "Exactly this argument, along with some other points made in this paper, are also written or thought about in [3] and [9].", "startOffset": 109, "endOffset": 112}, {"referenceID": 8, "context": "Exactly this argument, along with some other points made in this paper, are also written or thought about in [3] and [9].", "startOffset": 117, "endOffset": 120}, {"referenceID": 7, "context": "The Chessmaps Heuristic [8] uses a neural network as a positional evaluator for a search heuristic.", "startOffset": 24, "endOffset": 27}, {"referenceID": 10, "context": "Test results showed that it would reduce the search by more than the History Heuristic [11], but because of its additional computational requirements, it would use more time to search for a move and would ultimately be inferior.", "startOffset": 87, "endOffset": 91}, {"referenceID": 10, "context": "Two of the most popular experience-based approaches to minimising the search process are the History Heuristic [11] and Transposition Tables [11][12].", "startOffset": 111, "endOffset": 115}, {"referenceID": 10, "context": "Two of the most popular experience-based approaches to minimising the search process are the History Heuristic [11] and Transposition Tables [11][12].", "startOffset": 141, "endOffset": 145}, {"referenceID": 11, "context": "Two of the most popular experience-based approaches to minimising the search process are the History Heuristic [11] and Transposition Tables [11][12].", "startOffset": 145, "endOffset": 149}, {"referenceID": 4, "context": "A summary of recent advances in AI game-playing can be found in [5].", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "KnightCaps [1] is possibly one of the best AI attempts at playing computer chess, based on its playing strength.", "startOffset": 11, "endOffset": 14}, {"referenceID": 11, "context": "The same mechanism was also used in the NeuroChess program [12].", "startOffset": 59, "endOffset": 63}, {"referenceID": 3, "context": "Blondie25 [4] is an example of another chess game-playing program that uses an evolutionary method to learn to play, as does [9].", "startOffset": 10, "endOffset": 13}, {"referenceID": 8, "context": "Blondie25 [4] is an example of another chess game-playing program that uses an evolutionary method to learn to play, as does [9].", "startOffset": 125, "endOffset": 128}, {"referenceID": 2, "context": "In [3] they use a", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "While not directly related to computer chess, the paper [2] describes recent advances in dynamic search processes.", "startOffset": 56, "endOffset": 59}, {"referenceID": 6, "context": "The dynamic moves approach probably also has similar intentions to the UCT search algorithms [7][14].", "startOffset": 93, "endOffset": 96}, {"referenceID": 13, "context": "The dynamic moves approach probably also has similar intentions to the UCT search algorithms [7][14].", "startOffset": 96, "endOffset": 100}, {"referenceID": 6, "context": "The paper [7] describes how TD learning is offline, while UCT is online.", "startOffset": 10, "endOffset": 13}, {"referenceID": 5, "context": "It is argued that stronger players are able to recognise these features, or chunks of knowledge [6], and use them better to analyse a position and determine what the best move might be.", "startOffset": 96, "endOffset": 99}], "year": 2013, "abstractText": "This paper proposes a new mechanism for pruning a search game-tree in computer chess. The algorithm stores and then reuses chains or sequences of moves, built up from previous searches. These move sequences have a built-in forward-pruning mechanism that can radically reduce the search space. A typical search process might retrieve a move from a Transposition Table, where the decision of what move to retrieve would be based on the position itself. This algorithm stores move sequences based on what previous sequences were better, or caused cutoffs. This is therefore position independent and so it could also be useful in games with imperfect information or uncertainty, where the whole situation is not known at any one time. Over a small set of tests, the algorithm was shown to clearly out-perform Transposition Tables, both in terms of search reduction and game-play results.", "creator": "Microsoft Word - chess_link.docx"}}}