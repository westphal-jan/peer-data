{"id": "1403.1310", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2014", "title": "AntiPlag: Plagiarism Detection on Electronic Submissions of Text Based Assignments", "abstract": "Plagiarism is one of the growing issues in academia and is always a concern in Universities and other academic institutions. The situation is becoming even worse with the availability of ample resources on the web. This paper focuses on creating an effective and fast tool for plagiarism detection for text based electronic assignments. Our plagiarism detection tool named AntiPlag is developed using the tri-gram sequence matching technique. Three sets of text based assignments were tested by AntiPlag and the results were compared against an existing commercial plagiarism detection tool. AntiPlag showed better results in terms of false positives compared to the commercial tool due to the pre-processing steps performed in AntiPlag. In addition, to improve the detection latency, AntiPlag applies a data clustering technique making it four times faster than the commercial tool considered. AntiPlag could be used to isolate plagiarized text based assignments from non-plagiarised assignments easily. Therefore, we present AntiPlag, a fast and effective tool for plagiarism detection on text based electronic assignments.", "histories": [["v1", "Thu, 6 Mar 2014 01:16:01 GMT  (331kb)", "http://arxiv.org/abs/1403.1310v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL cs.DL", "authors": ["m a c jiffriya", "m a c akmal jahan", "r g ragel", "s deegalla"], "accepted": false, "id": "1403.1310"}, "pdf": {"name": "1403.1310.pdf", "metadata": {"source": "CRF", "title": "AntiPlag: Plagiarism Detection on Electronic Submissions of Text Based Assignments", "authors": ["Akmal Jahan", "Roshan G Ragel", "Sampath Deegalla"], "emails": [], "sections": [{"heading": null, "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live."}, {"heading": "III. METHODOLOGY", "text": "AntiPlag is developed using the tri-gram sequence matching technique using a scripting language. The electronic assignments were pre-processed before being sent through a cluster algorithm. We are using clustering here as an approach to speed up the process of plagiarism detection and claim it as one of the contributions. Therefore, we have developed two versions of AntiPlag, one of which clusters and the other does not. Later, we compared the effects of clustering on detection latency by running the tests with the two versions of AntiPlag. The step following clustering is the construction and analysis of tri-gram analysis. Tri-gram analysis is used to measure pairs of similarities between the assignments tested, and the results are presented to the user as percentages representing similarities."}, {"heading": "A. Data Collection and File Conversion", "text": "Electronic text-based mappings are collected as three isolated records, which differ in format and have been converted to plaintext formats to keep all documents in the same format for fair treatment."}, {"heading": "B. Pre-processing", "text": "We consider the pre-processing step we performed to be an important step in the detection of plagiarism. The purpose of pre-processing is to create suitable data to be entered into the detection processes and to increase the effectiveness of the plagiarism detection tool. The corpus consists of a mixture of lowercase and uppercase letters. All uppercase letters in the corpus have been converted to lowercase letters to eliminate the sensitivity of uppercase letters from the corpus. All diagrams, images and images in the corpus have been removed, and the separators in the corpus and stopwords have been identified and removed from the corpus."}, {"heading": "C. Tri-gram Construction", "text": "A tri-gram consists of three consecutive word sequences in each line. Tri-gram sequences are formed from the pre-processed assignments. Tri-grams were constructed by extracting tri-gram sequences from the corpus. Figure 2 shows the formation of tri-grams for an example sentence."}, {"heading": "D. Similarity Measure", "text": "The tri-gram sequences of each pair of assignments are compared to a tri-gram sequence match and the similarity is measured in percent, so the measurement is that the higher the percentage, the higher the similarity."}, {"heading": "E. Clustering", "text": "In order to improve the detection latency of AntiPlag, a clustering approach was applied to the data sets in order to form suitable clusters using the WEKA tool. WEKA is an open source tool for capturing data mining algorithms [21].In the clustering approach, the data sets were passed to preprocessing. String-to-word vector was used to convert string attributes into a series of words. K-Means algorithm was applied to the data set because it has several advantages over document clusters [19] [20]. The minimum frequency is changed and the data set is evaluated using the KMeans algorithm with different cluster numbers K. From the experimental results for the data sets, the appropriate cluster number K was selected, which is based on the percentage of incorrectly clustered instances of the assignments."}, {"heading": "F. Stemming", "text": "A stemming technique is applied to the datasets to convert the bag of words into their word root to test how strongly the stemming process influences plagiarism performance. PorterStemming algorithm [26] is used to stem everything. Stemming datasets are tested again on the AntiPlag tool and the two results are compared."}, {"heading": "IV. RESULTS AND DISCUSSION", "text": "Figures 3, 4 and 5 represent the maximum percentage of plagiarism of each task in AntiPlag and Plagiarism Checker X for Data-Set1, Data-Set2 and Data-Set3, respectively. AntiPlag showed better results in proper detection than Plagiarism Checker X for all three sets due to the pre-processing steps used in AntiPlag.Set3. All assignments in the three sets are contained and the rows were tested for AntiPlag Tool. Data set containment results are compared with the results of the original data sets obtained without containment. Figures 6, 7 and 8 represent the percentage of plagiarism detections in AntiPlag with containment and no containment of data sets."}, {"heading": "3 28 34 17, 18, 33, 39", "text": "24 9 18 According to Table I, the assignment numbers 5, 6, 7, 10, 13, 15, 21, 24, 27, and 29 in Data Set1 are heavily plagiarized, while the assignment numbers 1, 2, 4, 5, 10, 12, 20, 21, 25, 26, 27, 30, 32, 33, and 35 in Data Set2 are heavily plagiarized compared to the other tasks. In Data Set3, the assignment numbers 5, 6, 9, 15, 16, 26, 34, and 41 are approximately not plagiarized, and others are heavily plagiarized. Figures 9, 10, and 11 show percentages of plagiarism in some randomly selected assignment pairs of Data Set1, Data Set2, and Data Set3 are not plagiarized, and others are highly plagiarized."}, {"heading": "V. CONCLUSIONS", "text": "We present a plagiarism detection tool called AntiPlag, where it is optimized and improved by the clustering approach. AntiPlag is fast and able to automatically compare all two types of assignments at once. Furthermore, we have proven through experiments that the cluster-based AntiPlag is an effective, simple and fast tool for detecting plagiarism. \"An Overview,\" International Conference on Computer System and Technologies - CompSysTech 07 ACM ISBN: 978-954-50-9, 2007. [2] Butakov S, Scherbinin.V \"The toolbox for local and global plagiarism detection.\" Computer and Education, Volume 52, Issue 4, pp.781-788, May 2009]."}], "references": [{"title": "Computer-Based Plagiarism Detection Methods and Tools: An Overview", "author": ["R. Lukashenko", "V. Graudina", "J Grundspenkis"], "venue": "International Conference on Computer System and Technologies- CompSysTech\u201907 ACM ISBN: 978-954-964-50-9,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Scherbinin.V \u201cThe toolbox for local and global plagiarism detection", "author": ["S Butakov"], "venue": "Computer and Education,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Plagiarism and its detection in programming languages\u201d,2008", "author": ["Sanjay Goel", "Deepak Rao"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Metrics based plagiarism monitoring", "author": ["Edward L. Jones"], "venue": "6th Annual CCSC Northeastern Conference, Middlebury,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2001}, {"title": "Finding plagiarisms among a set of programs with JPlag", "author": ["Lutz Prechelt", "Guido Malpohl", "Michael Philippsen"], "venue": "Journal of Universal Computer Science,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Winnowing: local algorithms for document fingerprinting", "author": ["S. Schleimer", "D.S. Wilkerson", "A. Aiken"], "venue": "Proceedings of SIGMOD \u201903, pp. 76\u201385", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Plagiarism in programming assignments", "author": ["M.S. Joy", "M. Luck"], "venue": "IEEE Transactions on Education, 42(2):pp.129\u2013133", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1999}, {"title": "Culwine, \u201cClassification of Plagiarism Detection Engines", "author": ["Thomas Lancaster", "Fintan"], "venue": "Higher Education Academy Subject Network for Information & Computer Sciences,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Plagiarism Detection based on studying correlation between Author, Title, and Content", "author": ["Abeer Al Jarrah", "Izzat Alsmadi", "Zakariya Za\u2019atreh"], "venue": "International Conference on Information Communication System (CICS),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Learning Management System Technologies and Software solution for online Teaching: Tools and Application", "author": ["Yefim Kats"], "venue": "Information Science Reference Hershey \u2013 New York,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Are We Ready For Large Scale Use of Plagiarism Detection Tool?", "author": ["Ruth Barrett", "James Malcolm", "Caroline Lyon"], "venue": "4th Annual LTSN-ICS Conference, NUI Galway, LTSN Center for information and Computer Sciences,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "A Study of Plagiarism Detection Tools and Technologies", "author": ["Sindhu L", "Bindu Baby Thomas", "Sumam Mary Idicula"], "venue": "International Journal of Advanced Research In Technology, IJART,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Demonstration of the Ferret Plagiarism Detector", "author": ["Peter C.R. Lane", "Caroline M. Lyon", "James A. Malcolm"], "venue": "In proceeding of the 2 International Conference,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "A theoretical basis to the automated detection of copying between texts, and its practical implementation in the Ferret plagiarism and collusion detector", "author": ["Caroline Lyon", "Ruth Barrett", "James Malcolm"], "venue": "The First Plagiarism Conference,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Plagiarism Detection on the Student Assignment from Internet using Words n-grams Fingerprints", "author": ["Imam Much Ibnu Subroto", "Ali Selamatz"], "venue": "Postgraduate Annual Research Seminar,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Plagiarism Detection in Obfuscated Documents Using an N-gram Technique", "author": ["Tom\u00e1\u0161 Ku\u02c7ce\u02c7cka"], "venue": "Information Sciences and Technologies Bulletin of the ACM Slovakia, Special Section on Student Research in Informatics and Information Technologies,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Litoriya \u201cComparision the various clustering algorithms of weka tools", "author": ["Narendra Sharma", "Aman Bajpi", "Ratnesh"], "venue": "International journal of emerging Technology and Advanced Engineering,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Doja, \u201cK-Means clustering using weka interface", "author": ["I. Sapna Jain", "M.N.M. Afshar Aalam"], "venue": "Proceeding of the 4th National Conference,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "A Study on WEKA Tool for Data Preprocessing, Classification and Clustering", "author": ["Swasti Singhal", "Monika Jena"], "venue": "International Journal of Innovative Technology and Exploring Engineering (IJITEE),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "4% within four years period (1993 \u2013 1997) [1] and in another study by Butakov and Scherbinin concludes that more than 90.", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "0% of high school students are involved in plagiarism [2].", "startOffset": 54, "endOffset": 57}, {"referenceID": 2, "context": "Some such tools are Plagio Guard [3][4], JPlag [5], Moss [6], Saxon [9], Detecta Copius [7], Sherlock [8], Copy/Paste Detector (CPD) and Big Brother [9].", "startOffset": 33, "endOffset": 36}, {"referenceID": 3, "context": "Some such tools are Plagio Guard [3][4], JPlag [5], Moss [6], Saxon [9], Detecta Copius [7], Sherlock [8], Copy/Paste Detector (CPD) and Big Brother [9].", "startOffset": 36, "endOffset": 39}, {"referenceID": 4, "context": "Some such tools are Plagio Guard [3][4], JPlag [5], Moss [6], Saxon [9], Detecta Copius [7], Sherlock [8], Copy/Paste Detector (CPD) and Big Brother [9].", "startOffset": 47, "endOffset": 50}, {"referenceID": 5, "context": "Some such tools are Plagio Guard [3][4], JPlag [5], Moss [6], Saxon [9], Detecta Copius [7], Sherlock [8], Copy/Paste Detector (CPD) and Big Brother [9].", "startOffset": 57, "endOffset": 60}, {"referenceID": 7, "context": "Some such tools are Plagio Guard [3][4], JPlag [5], Moss [6], Saxon [9], Detecta Copius [7], Sherlock [8], Copy/Paste Detector (CPD) and Big Brother [9].", "startOffset": 68, "endOffset": 71}, {"referenceID": 6, "context": "Some such tools are Plagio Guard [3][4], JPlag [5], Moss [6], Saxon [9], Detecta Copius [7], Sherlock [8], Copy/Paste Detector (CPD) and Big Brother [9].", "startOffset": 102, "endOffset": 105}, {"referenceID": 7, "context": "Some such tools are Plagio Guard [3][4], JPlag [5], Moss [6], Saxon [9], Detecta Copius [7], Sherlock [8], Copy/Paste Detector (CPD) and Big Brother [9].", "startOffset": 149, "endOffset": 152}, {"referenceID": 8, "context": "Recently there are several text based plagiarism detection tools that support detecting only intra-corpal plagiarism such as Dupli Checker [23] and Article Checker [24] or detecting only extracorpal plagiarism such as Anti-P [10] or both such as Plagiarism Checker X [25], Turnitin [22] and Ferret [9].", "startOffset": 225, "endOffset": 229}, {"referenceID": 7, "context": "Recently there are several text based plagiarism detection tools that support detecting only intra-corpal plagiarism such as Dupli Checker [23] and Article Checker [24] or detecting only extracorpal plagiarism such as Anti-P [10] or both such as Plagiarism Checker X [25], Turnitin [22] and Ferret [9].", "startOffset": 298, "endOffset": 301}, {"referenceID": 9, "context": "In extra-corpal plagiarism detection, the test material is compared with material from outside such as the web resources, whereas intra-corpal plagiarism detection is performed by comparing materials within the learning community, thus original and plagiarized materials are found at the same place [11].", "startOffset": 299, "endOffset": 303}, {"referenceID": 10, "context": "Even though Turnitin supports both extra-corpal and intra-corpal plagiarism detection it does not provide a free service [12][13].", "startOffset": 121, "endOffset": 125}, {"referenceID": 11, "context": "Even though Turnitin supports both extra-corpal and intra-corpal plagiarism detection it does not provide a free service [12][13].", "startOffset": 125, "endOffset": 129}, {"referenceID": 7, "context": "Similarly Plagiarism Detector, Plagiarism Checker X, CopyCatch [9], WORDCheck [9], CopyFind [9] and Ferret [14][15] are standalone application software for text based plagiarism detection.", "startOffset": 63, "endOffset": 66}, {"referenceID": 7, "context": "Similarly Plagiarism Detector, Plagiarism Checker X, CopyCatch [9], WORDCheck [9], CopyFind [9] and Ferret [14][15] are standalone application software for text based plagiarism detection.", "startOffset": 78, "endOffset": 81}, {"referenceID": 7, "context": "Similarly Plagiarism Detector, Plagiarism Checker X, CopyCatch [9], WORDCheck [9], CopyFind [9] and Ferret [14][15] are standalone application software for text based plagiarism detection.", "startOffset": 92, "endOffset": 95}, {"referenceID": 12, "context": "Similarly Plagiarism Detector, Plagiarism Checker X, CopyCatch [9], WORDCheck [9], CopyFind [9] and Ferret [14][15] are standalone application software for text based plagiarism detection.", "startOffset": 107, "endOffset": 111}, {"referenceID": 13, "context": "Similarly Plagiarism Detector, Plagiarism Checker X, CopyCatch [9], WORDCheck [9], CopyFind [9] and Ferret [14][15] are standalone application software for text based plagiarism detection.", "startOffset": 111, "endOffset": 115}, {"referenceID": 14, "context": "Most of the researchers use N-gram technique as a base and improve it in variety of text based applications [16][17].", "startOffset": 108, "endOffset": 112}, {"referenceID": 15, "context": "Most of the researchers use N-gram technique as a base and improve it in variety of text based applications [16][17].", "startOffset": 112, "endOffset": 116}, {"referenceID": 9, "context": "In information retrieval, precision and recall make much sense in calculating accuracy [11].", "startOffset": 87, "endOffset": 91}, {"referenceID": 18, "context": "WEKA is an open source tool with collection of data mining algorithms [21].", "startOffset": 70, "endOffset": 74}, {"referenceID": 16, "context": "K-Means algorithm was applied to the dataset since it has several advantages over document clustering [19][20].", "startOffset": 102, "endOffset": 106}, {"referenceID": 17, "context": "K-Means algorithm was applied to the dataset since it has several advantages over document clustering [19][20].", "startOffset": 106, "endOffset": 110}], "year": 2013, "abstractText": "Plagiarism is one of the growing issues in academia and is always a concern in Universities and other academic institutions. The situation is becoming even worse with the availability of ample resources on the web. This paper focuses on creating an effective and fast tool for plagiarism detection for text based electronic assignments. Our plagiarism detection tool named AntiPlag is developed using the tri-gram sequence matching technique. Three sets of text based assignments were tested by AntiPlag and the results were compared against an existing commercial plagiarism detection tool. AntiPlag showed better results in terms of false positives compared to the commercial tool due to the pre-processing steps performed in AntiPlag. In addition, to improve the detection latency, AntiPlag applies a data clustering technique making it four times faster than the commercial tool considered. AntiPlag could be used to isolate plagiarized text based assignments from non-plagiarised assignments easily. Therefore, we present AntiPlag, a fast and effective tool for plagiarism detection on text based electronic assignments.", "creator": "'Certified by IEEE PDFeXpress at 11/22/2013 5:58:05 AM'"}}}