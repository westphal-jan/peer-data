{"id": "1403.1329", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2014", "title": "Integer Programming Relaxations for Integrated Clustering and Outlier Detection", "abstract": "In this paper we present methods for exemplar based clustering with outlier selection based on the facility location formulation. Given a distance function and the number of outliers to be found, the methods automatically determine the number of clusters and outliers. We formulate the problem as an integer program to which we present relaxations that allow for solutions that scale to large data sets. The advantages of combining clustering and outlier selection include: (i) the resulting clusters tend to be compact and semantically coherent (ii) the clusters are more robust against data perturbations and (iii) the outliers are contextualised by the clusters and more interpretable, i.e. it is easier to distinguish between outliers which are the result of data errors from those that may be indicative of a new pattern emergent in the data. We present and contrast three relaxations to the integer program formulation: (i) a linear programming formulation (LP) (ii) an extension of affinity propagation to outlier detection (APOC) and (iii) a Lagrangian duality based formulation (LD). Evaluation on synthetic as well as real data shows the quality and scalability of these different methods.", "histories": [["v1", "Thu, 6 Mar 2014 02:42:22 GMT  (1636kb,D)", "http://arxiv.org/abs/1403.1329v1", "10 pages, 10 figures"]], "COMMENTS": "10 pages, 10 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["lionel ott", "linsey pang", "fabio ramos", "david howe", "sanjay chawla"], "accepted": false, "id": "1403.1329"}, "pdf": {"name": "1403.1329.pdf", "metadata": {"source": "CRF", "title": "Integer Programming Relaxations for Integrated Clustering and Outlier Detection", "authors": ["Lionel Ott", "Linsey Pang", "Fabio Ramos", "David Howe", "Sanjay Chawla"], "emails": ["lott4241@uni.sydney.edu.au"], "sections": [{"heading": "1. INTRODUCTION", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are not able to survive themselves. (...) Most of them are not able to survive themselves. (...)"}, {"heading": "2. PROBLEM FORMULATION", "text": "In view of the allocation cost matrix dij and the cluster creation costs ci, we define the task of cluster and outlier selection as the problem of allocation to the binary example indicators yi, outlier indicators oi and point allocations xij, which minimizes the following energy function: min \u2211 i ciyi + \u2211 i \u2211 x dijxij, (1) subject toxij \u2264 yj (2) oi + \u2211 jxij = 1 (3) \u2211 i oi = '(4) xij, yj, oi \u04410, 1}. (5) In order to obtain a valid solution, a number of limitations have been imposed: \u2022 Points can only be allocated to valid examples equation. (2) \u2022 each point must be allocated to exactly another point or declared an outlier equation. (3) \u2022 exact \"outliers must be selected as outliers.\" (4) Only integer solutions are permitted to define total criteria (this problem forces us to select the outlier)."}, {"heading": "3. METHODS", "text": "We start with a linear programming formulation that is known to provide the optimal response when the solution is integer. Next, we propose an extension of affinity distribution, which is a conceptually beautiful method. Finally, we propose a method based on Lagrange's duality, which is highly scalable, while obtaining results that are very close to the optimum found by LP."}, {"heading": "3.1 Linear Programming Relaxation", "text": "The first method we present is based on linear programming and serves as the basis for the other two methods. In order to solve the integer program described in Section 2, we must relax it. If the solution for this relaxed formulation is integer, i.e. all assignments are either 0 or 1, we have found the optimal solution. The relaxed linear program has the following form: min \u2211 i \u2211 j xijdij (6) are subject to toxij \u2264 xii (7) \u2211 j + \u2211 koik = 1 (8) \u2211 i oik = 1 (9) 0 \u2264 xij, oik \u2264 1 \u0445 i, j, k (10), where dij is again the distance between point i and j. This is followed by Komodakis et al. [2008] with additional constraints to enforce the outlier selection. We point out here that Equation (6) uses the diagonal to indicate the copy selection, since it maps the affinity propagation more easily."}, {"heading": "3.2 Affinity Propagation Outlier Clustering", "text": "The Extension to affinity propagation, based on the binary variable model [Givoni and Frey, 2009], solves the integer program of Section 2 by displaying it as a factor graph, represented in Figure 2. This factor graph is solved by the propagation of faith and is based on the following energy function: max. (max.) changing messages of Section 2. (x: j) changing messages of Section 2. (x: j) changing messages of Section 2. (x: j) changing messages of Section 2. (x: j) changing messages of Section 3. (x:) changing messages of Section 3. (x:) changing messages of Section 3. (x:) changing messages of Solls. (x:) Solls."}, {"heading": "3.3 Lagrangian Duality", "text": "s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s"}, {"heading": "1 O \u2190 0; // Outlier indicators", "text": "2 y \u2190 0; / / Example indicators 3 L \u2190 \u2205; / / Set of (i, \u03bbi) pairs 4 S \u2190 \u2205; / / Assignment pairs (i, j) 5 x \u2190 0; / / Assignments / / Selection of outliers 6 for each i-point {1,.., N} 7 L \u2190 L-point (i, \u03bbi); 8 End 9 L \u2190 Sort (L); 10 for each i-point {1,.., L} 11 OLi, 1 \u2190 1; 12 End / / Outliers and outliers 13 for each j-point {1,..., N} 14 \u00b5j-point cj; 15 for each i-point {1,., N} 16 q-point dist (i, j) - (i, j) - (i, j -) (j) (i), j - (i)."}, {"heading": "3.4 Comparisons", "text": "Now that we have outlined the various methods we want to use to give an overview of the advantages and disadvantages of these, Table 1 presents itself as a quick overview of the different properties of the proposed methods, which are discussed in detail. Firstly, the speed of APOC and LD clearly outpace LP by a large margin, and secondly, if LP finds a solution equivalent to IP, i.e., we know that FLOLP \u2264 FLOLD \u2264 FLOIP (36) [Bertsimas and Weismantel, 2005]. Besides, if LP finds a solution equivalent to IP, then FLOLP = FLOIP."}, {"heading": "4. EXPERIMENTS", "text": "This year it has come to the point where it will be able to take the lead, \"he said in an interview with the Deutsche Presse-Agentur.\" We have never lost as much time as this year, \"he said.\" But we are not yet to the point where we will be able to get angry. \""}, {"heading": "4.2 Hurricane Data", "text": "We use hurricane data from 1970 to 2010 provided by the National Oceanic and Atmospheric Administration (NOAA) in this experiment. To compare the overall shape of these tracks, we use the discrete Fre \ufffd chet distance [Pus and Mannila, 1994], which intuitively measures the minimum distance required to connect points on two curves, i.e. structurally similar curves have a low value. Before calculating the Fre \ufffd chet distance between two curves, we move their starting points to the same place. This means that we compare their shapes, not their global location. If we cluster the 700 tracks using the LD method with '= 20, we obtain clusters that move in a similar direction to that shown in Figure 7 b) and c)."}, {"heading": "4.3 MNIST Data", "text": "The MNIST dataset, introduced by LeCun et al. [1998], contains 28 x 28 pixel images of handwritten digits. We extract characteristics from these images by presenting them as 768 dimensional vectors, which are reduced to 25 dimensions by PCA. In Figure 9, we show exemplary results obtained by processing 10,000 digits using the LD method. Figure 9 c) contains a subset of the outliers selected by the method. These outliers have different properties that make them useful outliers, such as: thick lines, incomplete, unidentifiable or ambiguous digits. To investigate the influence of cluster creation costs, we conduct the experiment with different values."}, {"heading": "4.4 Natural Scenes Data", "text": "In this section we apply APOC to the detection of outliers in image collections. Our data set consists of images from mountain regions with outliers in the form of cars and coffee cups. The distance between images is calculated from color histograms and local binary patterns [Ojala et al., 2002] histograms using the Bhattacharyya distance. If we give the correct number of outliers, APOC and LD find all images belonging to our two outliers and group the remaining images according to their appearance. Figure 10 shows outliers in the first two rows and examples belonging to the three clusters found in subsequent rows of APOC. The three clusters contain images that largely differ in color and mood. The first cluster contains images with muted greens and browns, the second cluster has images with outliers in the first two rows and examples that belong to the three clusters found in the subsequent rows of APC."}, {"heading": "5. RELATED WORK", "text": "The problem of outlier detection has been extensively explored in both statistics and data mining, where the data mining perspective is focused directly on outliers and then determines their usefulness. Investigation of outlier detection in data mining has been driven by the work of Knorr and Ng, who have identified and evaluated outliers, while the data mining perspective is focused directly on outliers. Investigation of outlier detection in data mining has been driven by the work of Knorr and Ng."}, {"heading": "6. CONCLUSION", "text": "The proposed optimization problem forces valid clusters and the selection of a fixed number of outliers. We then described three ways to solve the optimization problem using (i) linear programming, (ii) affinity propagation with outlier detection, and (iii) lagrange duality. Experiments with synthetic and real data show how joint optimization outperforms two-step approaches like k-Means. Furthermore, experimental results suggest that the results obtained using APOC and LD come very close to the optimal solution in a fraction of the computational time. Finally, we describe the modifications to the LD method required for processing large data sets."}], "references": [{"title": "k-means++: The Advantages of Careful Seeding", "author": ["D. Arthur", "S. Vassilvitskii"], "venue": "In ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "Arthur and Vassilvitskii.,? \\Q2007\\E", "shortCiteRegEx": "Arthur and Vassilvitskii.", "year": 2007}, {"title": "Mining distance-based outliers in near linear time with randomization and a simple pruning rule", "author": ["S. Bay", "M. Schwabacher"], "venue": "In Int. Conf. on Knowledge Discovery and Data Mining,", "citeRegEx": "Bay and Schwabacher.,? \\Q2003\\E", "shortCiteRegEx": "Bay and Schwabacher.", "year": 2003}, {"title": "Optimization over Integers", "author": ["D. Bertsimas", "R. Weismantel"], "venue": "Dynamic Ideas Belmont,", "citeRegEx": "Bertsimas and Weismantel.,? \\Q2005\\E", "shortCiteRegEx": "Bertsimas and Weismantel.", "year": 2005}, {"title": "LOF: Identifying Density-Based Local Outliers", "author": ["M. Breunig", "H. Kriegel", "R. Ng", "J. Sander"], "venue": "In Int. Conf. on Management of Data,", "citeRegEx": "Breunig et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Breunig et al\\.", "year": 2000}, {"title": "Anomaly detection: A survey", "author": ["V. Chandola", "A. Banerjee", "V. Kumar"], "venue": "ACM Computing Surveys,", "citeRegEx": "Chandola et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chandola et al\\.", "year": 2009}, {"title": "Algorithms for Facility Location Problems with Outliers", "author": ["M. Charikar", "S. Khuller", "D.M. Mount", "G. Narasimhan"], "venue": "In Proc. of the ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "Charikar et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Charikar et al\\.", "year": 2001}, {"title": "k-means\u2013: A Unified Approach to Clustering and Outlier Detection", "author": ["S. Chawla", "A. Gionis"], "venue": "In SIAM International Conference on Data Mining,", "citeRegEx": "Chawla and Gionis.,? \\Q2013\\E", "shortCiteRegEx": "Chawla and Gionis.", "year": 2013}, {"title": "SLOM: A new measure for local spatial outliers", "author": ["S. Chawla", "P. Sun"], "venue": "Knowledge and Information Systems,", "citeRegEx": "Chawla and Sun.,? \\Q2006\\E", "shortCiteRegEx": "Chawla and Sun.", "year": 2006}, {"title": "A constant factor approximation algorithm for k-median clustering with outliers", "author": ["K. Chen"], "venue": "In Proc. of the ACMSIAM Symposium on Discrete Algorithms,", "citeRegEx": "Chen.,? \\Q2008\\E", "shortCiteRegEx": "Chen.", "year": 2008}, {"title": "A Fast Algorithm for Robust Principal Components Based on Projection Pursuit", "author": ["C. Croux", "A. Ruiz-Gazen"], "venue": "In Proc. in Computational Statistics,", "citeRegEx": "Croux and Ruiz.Gazen.,? \\Q1996\\E", "shortCiteRegEx": "Croux and Ruiz.Gazen.", "year": 1996}, {"title": "Trimmed k-means: an attempt to robustify quantizers", "author": ["J. Cuesta-Albertos", "A. Gordaliza", "C. Matr\u00e1n"], "venue": "The Annals of Statistics,", "citeRegEx": "Cuesta.Albertos et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Cuesta.Albertos et al\\.", "year": 1997}, {"title": "Computing Discrete Fr\u00e9chet Distance", "author": ["T. Eiter", "H. Mannila"], "venue": "Technical report, Technische Universita\u0308t Wien,", "citeRegEx": "Eiter and Mannila.,? \\Q1994\\E", "shortCiteRegEx": "Eiter and Mannila.", "year": 1994}, {"title": "Clustering by Passing Messages Between Data Points", "author": ["B. Frey", "D. Dueck"], "venue": "Science,", "citeRegEx": "Frey and Dueck.,? \\Q2007\\E", "shortCiteRegEx": "Frey and Dueck.", "year": 2007}, {"title": "MayoIscar. A Review of Robust Clustering Methods", "author": ["L. Gar\u0107\u0131a-Escudero", "A. Gordaliza", "C. Matr\u00e1n"], "venue": "Advances in Data Analysis Classification,", "citeRegEx": "Gar\u0107\u0131a.Escudero et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gar\u0107\u0131a.Escudero et al\\.", "year": 2010}, {"title": "A Binary Variable Model for Affinity Propagation", "author": ["I. Givoni", "B. Frey"], "venue": "Neural Computation,", "citeRegEx": "Givoni and Frey.,? \\Q2009\\E", "shortCiteRegEx": "Givoni and Frey.", "year": 2009}, {"title": "Identification of Outliers", "author": ["D. Hawkins"], "venue": null, "citeRegEx": "Hawkins.,? \\Q1980\\E", "shortCiteRegEx": "Hawkins.", "year": 1980}, {"title": "Dissolution point and isolation robustness: Robustness criteria for general cluster analysis methods", "author": ["C. Hennig"], "venue": "Journal of Multivariate Analysis,", "citeRegEx": "Hennig.,? \\Q2008\\E", "shortCiteRegEx": "Hennig.", "year": 2008}, {"title": "A Unified Notion of Outliers: Properties and Computation", "author": ["E. Knorr", "R. Ng"], "venue": "In Int. Conf. on Knowledge Discovery and Data Mining,", "citeRegEx": "Knorr and Ng.,? \\Q1997\\E", "shortCiteRegEx": "Knorr and Ng.", "year": 1997}, {"title": "Clustering via LP-based Stabilities", "author": ["N. Komodakis", "N. Paragios", "G. Tziritas"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Komodakis et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Komodakis et al\\.", "year": 2008}, {"title": "Factor Graphs and the Sum-Product Algorithm", "author": ["F.R. Kschischang", "B.J. Frey", "H.-A. Loeliger"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Kschischang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Kschischang et al\\.", "year": 2001}, {"title": "Gradientbased learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns", "author": ["T. Ojala", "M. Pietikainen", "T. Maenpaa"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Ojala et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ojala et al\\.", "year": 2002}, {"title": "LOCI: Fast outlier detection using the local correlation integral", "author": ["S. Papadimitriou", "H. Kitagawa", "P. Gibbons", "C. Faloutsos"], "venue": "In Int. Conf. on Data Engineering,", "citeRegEx": "Papadimitriou et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Papadimitriou et al\\.", "year": 2003}, {"title": "Efficient Algorithms for Mining Outliers from Large Data Sets", "author": ["S. Ramaswamy", "R. Rastogi", "K. Shim"], "venue": "In Int. Conf. on Management of Data,", "citeRegEx": "Ramaswamy et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Ramaswamy et al\\.", "year": 2000}, {"title": "V-Measure: A conditional entropy-based external cluster evaluation measure", "author": ["A. Rosenberg", "J. Hirschberg"], "venue": "In Proc. of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Rosenberg and Hirschberg.,? \\Q2007\\E", "shortCiteRegEx": "Rosenberg and Hirschberg.", "year": 2007}, {"title": "A fast algorithm for the minimum covariance determinant estimator", "author": ["P. Rousseeuw", "K. Driessen"], "venue": null, "citeRegEx": "Rousseeuw and Driessen.,? \\Q1999\\E", "shortCiteRegEx": "Rousseeuw and Driessen.", "year": 1999}, {"title": "MAP Estimation, Linear Programming and Belief Propagation with Convex Free Energies", "author": ["Y. Weiss", "C. Yanover", "T. Meltzer"], "venue": "In Proc. of the Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Weiss et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Weiss et al\\.", "year": 2007}, {"title": "Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices by Convex Optimization", "author": ["J. Wright", "A. Ganesh", "S. Rao", "Y. Peng", "Y. Ma"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Wright et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Wright et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 4, "context": "INTRODUCTION Clustering and outlier detection are often studied and investigated as two separate problems [Chandola et al., 2009].", "startOffset": 106, "endOffset": 129}, {"referenceID": 25, "context": "The resulting variance-covariance matrix can be integrated into the Mahalanobis distance and used as part of a chi-square test to identify multivariate outliers [Rousseeuw and Driessen, 1999].", "startOffset": 161, "endOffset": 191}, {"referenceID": 7, "context": "For example, Chen [2008] has considered and proposed a constant factor approximation algorithm for the k-median with outliers problem: Given n data points and parameters k and `, the objective is to remove a set of ` points such that the cost of k-median clustering on the remaining n \u2212 ` points is minimised.", "startOffset": 13, "endOffset": 25}, {"referenceID": 5, "context": "Earlier Charikar et al. [2001], have proposed a bi-criteria approximation algorithm for the facility location with outliers problem.", "startOffset": 8, "endOffset": 31}, {"referenceID": 10, "context": "Trimmed k-means [Cuesta-Albertos et al., 1997] is a special case of k-means-- with k = 1.", "startOffset": 16, "endOffset": 46}, {"referenceID": 12, "context": "We propose three methods to solve this, each with their benefits and drawbacks: (i) affinity propagation [Frey and Dueck, 2007] extension to outlier detection, (ii) linear programming and (iii) Lagrangian duality relaxation.", "startOffset": 105, "endOffset": 127}, {"referenceID": 6, "context": "More recently, Chawla and Gionis [2013] have proposed kmeans-- a practical and scalable algorithm for the k-means with outlier problem.", "startOffset": 15, "endOffset": 40}, {"referenceID": 18, "context": "This follows Komodakis et al. [2008] with additional constraints", "startOffset": 13, "endOffset": 37}, {"referenceID": 14, "context": "2 Affinity Propagation Outlier Clustering The extension to affinity propagation, based on the binary variable model [Givoni and Frey, 2009], solves the integer program of Section 2 by representing it as a factor graph, shown in Figure 2.", "startOffset": 116, "endOffset": 139}, {"referenceID": 19, "context": "The energy function is optimised with the max-sum algorithm [Kschischang et al., 2001], which allows the recovery of the maximum a posteriori (MAP) assignments of the xij and oik variables.", "startOffset": 60, "endOffset": 86}, {"referenceID": 2, "context": "We now solve this relaxed problem using the idea of Bertsimas and Weismantel [2005] by finding valid assignments that attempt to minimise Eq.", "startOffset": 52, "endOffset": 84}, {"referenceID": 2, "context": "This is guaranteed to converge [Bertsimas and Weismantel, 2005] if a step function is used for which the following holds: \u221e \u2211", "startOffset": 31, "endOffset": 63}, {"referenceID": 2, "context": "[Bertsimas and Weismantel, 2005].", "startOffset": 0, "endOffset": 32}, {"referenceID": 26, "context": "While such guarantees can be given for certain types of structures with belief propagation [Weiss et al., 2007] it is unclear how they apply to the special case of APOC.", "startOffset": 91, "endOffset": 111}, {"referenceID": 0, "context": "We compare APOC and LD against k-means-- using kmeans++ [Arthur and Vassilvitskii, 2007] to select the initial centres.", "startOffset": 56, "endOffset": 88}, {"referenceID": 3, "context": "Local outlier factor [Breunig et al., 2000] (LOF) measures the outlier quality of a point.", "startOffset": 21, "endOffset": 43}, {"referenceID": 24, "context": "V-Measure [Rosenberg and Hirschberg, 2007] indicates the quality of the overall clustering solution.", "startOffset": 10, "endOffset": 42}, {"referenceID": 11, "context": "In order to compare the overall shape of these traces we use the discrete Fr\u00e9chet distance [Eiter and Mannila, 1994].", "startOffset": 91, "endOffset": 116}, {"referenceID": 20, "context": "3 MNIST Data The MNIST dataset, introduced by LeCun et al. [1998], contains 28 \u00d7 28 pixel images of handwritten digits.", "startOffset": 46, "endOffset": 66}, {"referenceID": 21, "context": "The distance between images is computed from colour histograms and local binary pattern [Ojala et al., 2002] histograms using the Bhattacharyya distance.", "startOffset": 88, "endOffset": 108}, {"referenceID": 2, "context": "The problem of outlier detection has been extensively researched in both statistics and data mining [Chandola et al., 2009, Hawkins, 1980]. However, both communities have different perspectives. The statistical perspective is to design models which are robust against outliers. In the process, outliers are discovered and evaluated. The data mining perspective is to directly mine for outliers and then determine their usefulness. The study of outlier detection in data mining was pioneered by the work of Knorr and Ng [1997] who proposed a definition of distance-based outliers which relaxed strict distributional assumptions and was readily generalisable to multi-dimensional data sets.", "startOffset": 101, "endOffset": 526}, {"referenceID": 1, "context": "Following Knorr and Ng, several variations and algorithms have been proposed to detect distance-based outliers [Bay and Schwabacher, 2003, Ramaswamy et al., 2000]. However, the outliers detected by these methods are global outliers, i.e., the \u201coutlierness\u201d is with respect to the whole dataset. Breunig et al. [2000] have argued that in some situations local outliers are more important than global outliers and cannot be easily detected by standard distance-based techniques.", "startOffset": 112, "endOffset": 317}, {"referenceID": 25, "context": "The MCD (as noted in the Introduction), is one prominent approach where the problem of outliers was tightly integrated in an optimisation framework [Rousseeuw and Driessen, 1999].", "startOffset": 148, "endOffset": 178}, {"referenceID": 6, "context": "The k-means-- approach extended the idea of MCD to include clustering [Chawla and Gionis, 2013].", "startOffset": 70, "endOffset": 95}], "year": 2014, "abstractText": "In this paper we present methods for exemplar based clustering with outlier selection based on the facility location formulation. Given a distance function and the number of outliers to be found, the methods automatically determine the number of clusters and outliers. We formulate the problem as an integer program to which we present relaxations that allow for solutions that scale to large data sets. The advantages of combining clustering and outlier selection include: (i) the resulting clusters tend to be compact and semantically coherent (ii) the clusters are more robust against data perturbations and (iii) the outliers are contextualised by the clusters and more interpretable, i.e. it is easier to distinguish between outliers which are the result of data errors from those that may be indicative of a new pattern emergent in the data. We present and contrast three relaxations to the integer program formulation: (i) a linear programming formulation (LP) (ii) an extension of affinity propagation to outlier detection (APOC) and (iii) a Lagrangian duality based formulation (LD). Evaluation on synthetic as well as real data shows the quality and scalability of these different methods.", "creator": "LaTeX with hyperref package"}}}