{"id": "1403.1353", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2014", "title": "Collaborative Representation for Classification, Sparse or Non-sparse?", "abstract": "Sparse representation based classification (SRC) has been proved to be a simple, effective and robust solution to face recognition. As it gets popular, doubts on the necessity of enforcing sparsity starts coming up, and primary experimental results showed that simply changing the $l_1$-norm based regularization to the computationally much more efficient $l_2$-norm based non-sparse version would lead to a similar or even better performance. However, that's not always the case. Given a new classification task, it's still unclear which regularization strategy (i.e., making the coefficients sparse or non-sparse) is a better choice without trying both for comparison. In this paper, we present as far as we know the first study on solving this issue, based on plenty of diverse classification experiments. We propose a scoring function for pre-selecting the regularization strategy using only the dataset size, the feature dimensionality and a discrimination score derived from a given feature representation. Moreover, we show that when dictionary learning is taking into account, non-sparse representation has a more significant superiority to sparse representation. This work is expected to enrich our understanding of sparse/non-sparse collaborative representation for classification and motivate further research activities.", "histories": [["v1", "Thu, 6 Mar 2014 05:44:32 GMT  (107kb)", "http://arxiv.org/abs/1403.1353v1", "8 pages, 1 figure"]], "COMMENTS": "8 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["yang wu", "vansteenberge jarich", "masayuki mukunoki", "michihiko minoh"], "accepted": false, "id": "1403.1353"}, "pdf": {"name": "1403.1353.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 140 3.13 53v1 [cs.CV] 6 Mar 201 4Index Terms - sparse representation, collaborative representation, regulation, dictionary learning, pattern classification"}, {"heading": "1 INTRODUCTION", "text": "This year it is more than ever before."}, {"heading": "2 RELATED WORK", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Comparison between CRC l1 and CRC l2", "text": "According to the proposal of the CRC l2, Zhang et.al. [4] conducted further experiments to compare the CRC l1 with the CRC l2, together with their robust versions for dealing with occlusions / corruption. They concluded that the relative superiority between them depends on the characteristic dimensionality of the data. It was assumed that high dimensionality corresponds to a high discriminatory force, and in this case, the coefficients tend to be naturally and passively sparse, even without sparse regulation, so CRC l2 can do a better job than CRC l1. If the dimension is very small, it leads to the opposite result. While we agree with the point that CRC l2 prefers a higher dimension, we do not think that the relative superiority depends only on the characteristic dimensionality. Note that the assumption of the correspondence between characteristic dimensionality and data discrimination force will result in the contrary. While we agree that CRC l2 prefers a higher dimension, we do not think that the relative superiority depends only on the characteristic dimensionality of CRC l1."}, {"heading": "2.2 Comparison on extended CRC models", "text": "The debate between sparse and non-sparse collaborative representation is not limited to the simplest CRBs l1 and l2 models. Recently, another generic dictionary was added, called Extended SRC (ESRC) [7], which is based on a third-party data set for dealing with variations within the class. As the additional dictionary may be able to cover the potentially large variations between the test sample and corresponding training samples from the same class, ESRC can be applied to single-shot recognition problems where only a single training sample is available for each class. Later, a non-sparse version of the Extended CRC (ECRC) [5] was published. The only difference between ECRC and ESRC is that ECRC instead of the L1 standard is used for co-regulation l2norm. Experimental results on several widely used facial recognition data sets show that the third-party models are much more effective than the ECRC's two, although the third-party models are much more effective and both."}, {"heading": "2.3 An important unexplored area: dictionary learning", "text": "There is another important and influential direction for improving collaborative representation models - dictionary learning (DL), i.e. learning a discriminatory dictionary from the training data, rather than using it directly as a dictionary. In general, dictionary learning can significantly improve the discrimination and generalization capabilities of CRC models without relying on other additional data. A whole series of publications on DL can be found for sparse representation, but as far as we know, no such model has ever been proposed for a non-sparse representation. Existing DL models can be roughly grouped into three categories: making the dictionary discriminatory, learning a discriminatory model for classification with coefficients, and at the same time optimizing the dictionary and coefficient classification models. The first group [8], [9] follow the CRC l1 classification model by using only the class-specific reconstruction error and directly targeting a discriminatory dictionary."}, {"heading": "3 COLLABORATIVE REPRESENTATION AND DICTIONARY LEARNING", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Sparse representation", "text": "Suppose a training data set X = [X1,.., XL] is given, where n denotes the total number of samples; d denotes their characteristic dimension; L denotes the number of classes; and Xi denotes the ni-samples of class i. The SRC (i.e. the SRC l1) seeks to reconstruct the test sample y-Rd by a linear combination of all training samples X, while minimizing the L1 standard spareness of the reconstruction coefficients. The coding model can be formulated as follows: \u03b1 = Argmine number y-X\u03b1-22 + \u03bb1-\u03b1-2 1 1, (1), where \u03b1 = [\u03b1-1,...] are the combined reconstruction coefficients corresponding to the training samples of different classes, and \u03bb1 is a regulatory parameter for weighting the regulation of \u03b1. For classification, CRC l1 calculates the representation for each residence class i-y (subsequently)."}, {"heading": "3.2 Non-sparse representation", "text": "According to the most recent arguments from [3], in the SRC (i.e. CRC l1) model, collaborative representation with all classes, but not the regulatory term of the l1 standard, really contributes to good facial recognition performance. (3) The biggest advantage of this exchange is the dramatic reduction in computing costs, since this new convex optimization problem has a closed solution. (XTX + \u03bb1 \u00b7 I) \u2212 1 XTy. (4) More attractive is this solution only a linear projection of y, and the projector P = (XTX + \u03bb1 \u00b7 I) \u2212 1XT has no closed solution. \u2212 P can be pre-calculated based on training data, so that it does not require a smaller projection of y."}, {"heading": "3.3 Dictionary learning", "text": "Instead of using the training data itself as a reconstruction dictionary, the dictionary's learning techniques strive to learn from the training data into a compact but comprehensive dictionary so that it can be scaled up to large amounts of training samples while being as discriminatory as possible. A general dictionary learning model is: < D *, W *, A * > = arg min D, W, A {r (X, D, A) + \u03bb1, A * 2 p + \u03bb2f (W, A)}, (6) where D = [D1,.., DL], Rd \u00b7 K is the learned dictionary from X (usually K \u2264 n); A denotes the reconstruction coefficients via D for X; W denotes the learned parameters of the discriminatory model f (W, A) for classification with A; r (X, D, A) is the discriminatory reconstruction model defined by D (the discriminatory one)."}, {"heading": "4 DICTIONARY LEARNING FOR NON-SPARSE REPRESENTATION", "text": "The proposed DL-NSCR model inherits the design of the term r (X, D, A) from FDDL [13], but discards its time-consuming term f (W, A) to keep the model light. Note that there is a major difference from other existing dictionary learning models: it adopts the computationally efficient l2 standard (in matrix format) to regulate A."}, {"heading": "4.1 Learning model", "text": "In DL-NSCR, r (X, D, A) is designed as follows: r (X, D, A) = \u0445X-DA-2 F + L-i = 1-3 Xi-DiA i-3 + L-1 = 1, j 6 = i-3 DiA i-2 F, (7) where the first term denotes the Frobenius standard 1 and Aij the coefficients which correspond to the sub-dictionary Di of class i for the samples from Xj (i.e. the columns of Aij correspond to class j). In this model, the first term is the general reconstruction error (which ensures that D can represent well X); the second term is the class-specific reconstruction error (which forces Di to be able to represent Xi well); and the third term is the confusion factor (which restricts the ability of Di to reconstruct samples from any other class V-V, V-V, V-V, V-V, V-V, V-V, V, V-A, A, A-A, A-A, X, V-D, V-V-D, V-V-V, V-D, V-V-V, V-V, V-V-V, V-V, V-V-V, V-V, V-V, V-V, V-D, V-D, V-V-V-V, V-V-V, V-V-V, V-V, V-V, V-V, V-V-V-V, V-V-V, V-V-V, V, V-D, V-V-D, V-V-V-V-V, V-V, V-V-V, V-V-D, V-V-V-V-V, V-V, V-V-V-V, V-V, V-V-V, V-V, V-V-V, V-V-V-V, V-V-V, V-V, V, V-V-V-V, V-V-V, V, V-V-V-V-V, V, V-V, V-V-V-V, V-V-V-"}, {"heading": "4.2 Optimization", "text": "Similar to other dictionary learning algorithms, the optimization of DL-NSCR takes place iteratively between optimization A and optimization D until the iteration converges."}, {"heading": "4.2.1 Initialization", "text": "We use principle component analysis to initialize Di with examples from class I. However, it is also acceptable to initialize with random numbers, which will only cost a few more iterations."}, {"heading": "4.2.2 Optimizing A given a fixed D", "text": "Given the fact that the Frobenius standard is degradable, the optimization of A is equivalent to the optimization of Ai for each i-matrix {1,..., L} independently of each other as follows. A-standard i = argmin Ai-Xi \u2212 DAi-2 F + 1 km \u00b2 DS\\ iS T\\ iAi-2F + 1 km \u00b2 Xi \u2212 DSiS T i-2F + 1, Si \u2212 1, Si + 1, \u00b7, SL], (10) where Si-1 m = 1 km \u00b2 KiIKi \u00b7 Ki \u00b7 Ki \u00b7 Lm = i + 1 Km \u00b2 Km \u00b7 \u00b7 \u00b7 \u00b7 Ki, S\\ i = [S1, \u00b7, SL], Si, Si\\ i, Si, Si, Si, Si, Si, Si, Si, Si = 1 Km \u2212 \u00b7 Ki, Si, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si, Si = 1 Ki, Si = 1 Ki, Si, Si, Si, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si, Si, Si, Si = 1 Ki, Si, Si, Si = 1 Ki, Si, Si, Si, Si, Si = 1 Ki, Si, Si = 1 Ki, Si, Si, Si = 1 Ki, Si,"}, {"heading": "4.2.3 Optimizing D given a fixed A", "text": "In the fixation of A, the term \u03bb1-A-2 F becomes a constant, but D is still impossible to be optimized as a whole, since the objective function in Eq.8 has two terms, which are functions of subdictionaries Di, i-DiVi-2 F, (14) where Ui = [X \u2212 D\\ iA\\ i, Xi, Od \u00b7 (n \u2212 ni), Vi = [Ai, Aii, A i\\ i]. (15) In Eq.15, D\\ i denotes all Djs with j 6 = i and A\\ i denotes the corresponding coefficients (i.e. without Ai), Vi = [Ai, Aii, A\\ i]. In Eq.15, D\\ i denotes all Djs with j 6 = i and A\\ i denotes the optimization, which is an actualization (i.e., without Ai)."}, {"heading": "4.3 Classification model", "text": "After learning D, we can use it to solve both individual and specified classification problems, which are all covered in our experiments. In classifying individual samples, we follow the CRC in reconstructing any sample y to D with its reconstruction coefficients obtained by solving \u03b1 = Argmin \u03b1 - D\u03b1 2 2 2 + \u03bb1 - \u03b1 2, (17), the closed solution of which is \u03b1 = (DTD + \u03bb1 \u00b7 I) - 1DTy. Then, y is classified by C (y) = Argminiri (y) withri (y) = (y) - Di\u03b1 - i 2 2 / 3 - (I) - 2. (18) With specified classification, we have a similar reconstruction model that simply replaces y with a series of test samples Y, and the reconstruction coefficients for Y are A - (DTD + 1 \u00b7 I) \u2212 1DTY. Then we classify Y (C) (Y) - 1) - 3."}, {"heading": "5 EXPERIMENTS AND RESULTS", "text": "We conduct our experiments using five visual detection tasks using nine public benchmark data sets, selected to cover different scenarios: face detection in a controlled environment, texture detection with a focus on texture information, sheet categorisation based on shape information, food categorisation with a wealth of widely varying colour, texture and shape information, and appearance-based re-identification of people in an uncontrolled environment. In addition, we follow [15], [16] a variation in the number of samples per class for 2 of the 3 Reid identification data sets received, each with three different values, to investigate how this factor affects the performance of the models tested. Therefore, there are completely 13 different data settings for experiments. Such large and varied experiments expand the scope of collaborative representation from face detection to general recognition / classification tasks with different statistics, properties and feature representations."}, {"heading": "5.1 Datasets and settings", "text": "In fact, it is as if most people are able to determine for themselves what they want and what they want. (...) It is not as if people are able to decide what they want and what they do not want. (...) It is as if they do not want them to do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. (...) It is as if they do it. \"(...) It is as if they do it, as if they do it. (...) It is as if they do it, if they do it. (...) It is as if they do it. (...) It is as if they do it, if they do it."}, {"heading": "5.2 Sparse or non-sparse representation?", "text": "This year is the highest in the history of the country."}, {"heading": "5.3 Dictionary learning", "text": "We compare the simple dictionary learning model for sparse representation (DL-NSCR) with CRC l2, CRC l1, and the most influential dictionary learning models for sparse representation, which are generally more complex than DL-NSCR, ScoreScore including FDDL [13], LC-KSVD [12], and DL-COPAR [14]. The results shown in Table 2 clearly show that even DL-NSCR can significantly increase the performance of CRC l2 in 12 of the 13 data sets, and that it also outperforms all competitors in 4 of the 5 classification tasks, except for the person's recognition task. The relatively lower performance boost of DL-NSCR in re-identification data sets is probably due to the difficulty of the data limiting the room for improvement (all MPD rates on these data sets are lower than those for the other data sets). Although it is interesting that DLNSCR is considered to be valuable in the two sets, MDS and LIDS only, the two of which are fully included in the two sets."}, {"heading": "5.4 Complexity and running time", "text": "DL-NSCR uses an alternative optimization model that provides theoretical guarantees for global convergence and local qlinear (faster than linear) convergence velocity. [24] In our experiments, it always converges in several steps. Considering that each iteration contains only basic matrix operations, it is easy to determine the complexity for training and testing DL-NSCR. Specifically, the complexity for Training O (((K + n) dKL + K3L + K2n), and for Tests O (((d + K + L) KL)) shows that DL-NSCR scales less linearly with d, L, and n, but almost proportional to K3. Thus, if the K is given, it scales well with d and n. Table 3 shows the actual runtime for all affected methods based on four representative datasets. Clearly, DL-NSCR is the fastest dictionary learning model, and its test time is also comparable to the most economical."}, {"heading": "6 CONCLUSION AND FUTURE WORK", "text": "We have shown a promising scoring feature for preselecting sparse or non-sparse collaborative representation models. DLNSCR, the simple dictionary learning model for sparse collaborative representation, has proven its superiority over sparse and non-sparse collaborative representation models and those state-of-the-art dictionary learning models for sparse representation. There is still much room for further improvement with better dictionary learning models, and it will be very interesting to make a more comprehensive comparison between them and existing dictionary learning models."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was supported by the \"R & D Programme for the Implementation of Crime and Counter-Terrorism Technologies for a Safe Society,\" funds for the integrated promotion of welfare reform, and research and development by the Japanese Ministry of Education, Culture, Sport, Science and Technology."}], "references": [{"title": "Robust face recognition via sparse representation", "author": ["J. Wright", "A. Yang", "A. Ganesh", "S. Sastry", "Y. Ma"], "venue": "IEEE Trans. Pattern Anal. Machine Intell, vol. 31, no. 2, pp. 210\u2013227, 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Sparse representation for computer vision and pattern recognition", "author": ["J. Wright", "Y. Ma", "J. Mairal", "G. Spairo", "T. Huang", "S. Yan"], "venue": "Proceedings of the IEEE, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Sparse representation or collaborative representation: which helps face recognition?", "author": ["L. Zhang", "M. Yang", "X. Feng"], "venue": "in Proc. Internat. Conf. on Computer Vision (ICCV),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Collaborative representation based classification for face recognition", "author": ["L. Zhang", "M. Yang", "X. Feng", "Y. Ma", "D. Zhang"], "venue": "CoRR, vol. abs/1204.2358, 2012, arXiv: 1204.2358.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Extended crc: Face recognition with a single training image per person via intraclass variant dictionary", "author": ["G. Lin", "M. Xie", "L. Mao"], "venue": "IEICE TRANS. on Information and Systems, vol. E96-D, no. 10, pp. 2290\u20132293, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive and weighted collaborative representations for image classification", "author": ["R. Timofte", "L.V. Gool"], "venue": "Pattern Recog. Lett, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Extended src: Undersampled face recognition via intraclass variant dictionary", "author": ["W. Deng", "J. Hu", "J. Guo"], "venue": "IEEE Trans. Pattern Anal. Machine Intell, vol. 34, no. 9, pp. 1864\u20131870, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1864}, {"title": "Metaface learning for sparse representation based face recognition", "author": ["M. Yang", "L. Zhang", "J. Yang", "D. Zhang"], "venue": "IEEE Internat. Conf. on Image Processing (ICIP), 2010, pp. 1601 \u20131604.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Classification and clustering via dictionary learning with structured incoherence and shared features", "author": ["I. Ramirez", "P. Sprechmann", "G. Sapiro"], "venue": "IEEE Conf. On Computer Vision And Pattern Recognition (CVPR), 2010, pp. 3501 \u20133508.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Supervised dictionary learning", "author": ["J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro", "A. Zisserman"], "venue": "Neural Information Processing Systems (NIPS), 2009, pp. 1033\u20131040.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Discriminative k-svd for dictionary learning in face recognition", "author": ["Q. Zhang", "B. Li"], "venue": "IEEE Conf. On Computer Vision And Pattern Recognition (CVPR), 2010, pp. 2691 \u20132698.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning a discriminative dictionary for sparse coding via label consistent k-svd", "author": ["Z. Jiang", "Z. Lin", "L. Davis"], "venue": "IEEE Conf. On Computer Vision And Pattern Recognition (CVPR), 2011.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Fisher discrimination dictionary learning for sparse representation", "author": ["M. Yang", "L. Zhang", "X. Feng", "D. Zhang"], "venue": "Proc. Internat. Conf. on Computer Vision (ICCV), 2011, pp. 543 \u2013550.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "A dictionary learning approach for classification: Separating the particularity and the commonality", "author": ["S. Kong", "D. Wang"], "venue": "European Conf. on Computer Vision (ECCV), 2012.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Boosted human reidentification using riemannian manifolds", "author": ["S. Bak", "E. Corvee", "F. Bremond", "M. Thonnat"], "venue": "Image and Vision Computing, vol. 30, no. 6-7, pp. 443 \u2013 452, 2012.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Collaborative sparse approximation for multiple-shot across-camera person reidentification", "author": ["Y. Wu", "M. Minoh", "M. Mukunoki", "W. Li", "S. Lao"], "venue": "IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), 2012, pp. 209 \u2013214.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "From few to many: illumination cone models for face recognition under variable lighting and pose", "author": ["A. Georghiades", "P. Belhumeur", "D. Kriegman"], "venue": "IEEE Trans. Pattern Anal. Machine Intell, pp. 643 \u2013660, 2001.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2001}, {"title": "The ar face database", "author": ["A. Martinez", "R. Benavente"], "venue": "CVC Technical Report 24, June 1998.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1998}, {"title": "Pairwise rotation invariant cooccurrence local binary pattern", "author": ["X. Qi", "R. Xiao", "J. Guo", "L. Zhang"], "venue": "European Conf. on Computer Vision (ECCV), 2012, pp. 158\u2013171.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Centrist: A visual descriptor for scene categorization", "author": ["J. Wu", "J. Rehg"], "venue": "IEEE Trans. Pattern Anal. Machine Intell, vol. 33, no. 8, pp. 1489\u20131501, 2011.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Food recognition using statistics of pairwise local features", "author": ["S. Yang", "M. Chen", "D. Pomerleau", "R. Sukthankar"], "venue": "IEEE Conf. On Computer Vision And Pattern Recognition (CVPR), 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Custom pictorial structures for re-identification", "author": ["D.S. Cheng", "M. Cristani", "M. Stoppa", "L. Bazzani", "V. Murino"], "venue": "British Machine Vision Conference (BMVC), 2011.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust object recognition via third-party collaborative representation", "author": ["Y. Wu", "M. Minoh", "M. Mukunoki", "S. Lao"], "venue": "Internat. Conf. on Pattern Recognition (ICPR), November 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Convergence of alternating optimization", "author": ["J.C. Bezdek", "R.J. Hathaway"], "venue": "Neural, Parallel Sci. Comput., vol. 11, no. 4, pp. 351\u2013368, 2003.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Recently, a simple approach called sparse representation based classification (SRC) [1], has shown quite impressive results on face recognition and also some other classification tasks [2].", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "Recently, a simple approach called sparse representation based classification (SRC) [1], has shown quite impressive results on face recognition and also some other classification tasks [2].", "startOffset": 185, "endOffset": 188}, {"referenceID": 1, "context": "The main weakness of SRC is that it has two preconditions for ensuring a good performance [2]: the training samples need to be carefully controlled and the number of samples per class has to be sufficiently large, and there is a lack of quantitative criteria for verifying whether they are satisfied or not.", "startOffset": 90, "endOffset": 93}, {"referenceID": 2, "context": "Later research argued that SRC\u2019s success lies in the collaborative representation using all the training samples, but not the l1-norm based regularization which makes the representation coefficients sparse [3].", "startOffset": 206, "endOffset": 209}, {"referenceID": 3, "context": "Though experiments on both CRC l2 itself [4] and its extensions [5] have shown their superiority to the sparse representation competitors, there are counterexamples reported as well [4], [6].", "startOffset": 41, "endOffset": 44}, {"referenceID": 4, "context": "Though experiments on both CRC l2 itself [4] and its extensions [5] have shown their superiority to the sparse representation competitors, there are counterexamples reported as well [4], [6].", "startOffset": 64, "endOffset": 67}, {"referenceID": 3, "context": "Though experiments on both CRC l2 itself [4] and its extensions [5] have shown their superiority to the sparse representation competitors, there are counterexamples reported as well [4], [6].", "startOffset": 182, "endOffset": 185}, {"referenceID": 5, "context": "Though experiments on both CRC l2 itself [4] and its extensions [5] have shown their superiority to the sparse representation competitors, there are counterexamples reported as well [4], [6].", "startOffset": 187, "endOffset": 190}, {"referenceID": 3, "context": "[4] have done more experiments on comparing CRC l1 with CRC l2, along with their robust versions for handling occlusions/corruptions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "\u2019s work [4] is unreliable, because you may have arbitrarily different features with quite different discrimination abilities for a given dimensionality.", "startOffset": 8, "endOffset": 11}, {"referenceID": 5, "context": "Even when the same feature vectors are projected into different spaces using certain dimension reduction approach, there are still counterexamples to the effectiveness of using dimensionality as the indicator, as shown in [6].", "startOffset": 222, "endOffset": 225}, {"referenceID": 6, "context": "Recently, a model called Extended SRC (ESRC) [7] added another generic dictionary based on a thirdparty dataset for handling the within-class variations.", "startOffset": 45, "endOffset": 48}, {"referenceID": 4, "context": "Later on, a non-sparse version Extended CRC (ECRC) [5] was published.", "startOffset": 51, "endOffset": 54}, {"referenceID": 7, "context": "The first group [8], [9] follow the classification model of CRC l1 in using only the class-specific reconstruction error, directly targeting a discriminative dictionary.", "startOffset": 16, "endOffset": 19}, {"referenceID": 8, "context": "The first group [8], [9] follow the classification model of CRC l1 in using only the class-specific reconstruction error, directly targeting a discriminative dictionary.", "startOffset": 21, "endOffset": 24}, {"referenceID": 9, "context": "The second group try to learn discriminative classification models on the sparse representation coefficients, including logistic regression [10] and linear regression (D-KSVD [11] and LC-KSVD [12] which adds one more linear regression term to D-KSVD to further enhance the label consistency within each class).", "startOffset": 140, "endOffset": 144}, {"referenceID": 10, "context": "The second group try to learn discriminative classification models on the sparse representation coefficients, including logistic regression [10] and linear regression (D-KSVD [11] and LC-KSVD [12] which adds one more linear regression term to D-KSVD to further enhance the label consistency within each class).", "startOffset": 175, "endOffset": 179}, {"referenceID": 11, "context": "The second group try to learn discriminative classification models on the sparse representation coefficients, including logistic regression [10] and linear regression (D-KSVD [11] and LC-KSVD [12] which adds one more linear regression term to D-KSVD to further enhance the label consistency within each class).", "startOffset": 192, "endOffset": 196}, {"referenceID": 12, "context": "The third group so far contain only one representative work called Fisher discrimination dictionary learning (FDDL) [13].", "startOffset": 116, "endOffset": 120}, {"referenceID": 13, "context": "Very recently, a new model called DL-COPAR [14] developed the idea proposed in DLSI [9] on exploring the common bases of subdictionaries by explicitly separating the particularity (classspecific sub-dictionaries) and commonality (a common subdictionary) in dictionary learning.", "startOffset": 43, "endOffset": 47}, {"referenceID": 8, "context": "Very recently, a new model called DL-COPAR [14] developed the idea proposed in DLSI [9] on exploring the common bases of subdictionaries by explicitly separating the particularity (classspecific sub-dictionaries) and commonality (a common subdictionary) in dictionary learning.", "startOffset": 84, "endOffset": 87}, {"referenceID": 8, "context": "Meanwhile, it also inherited the incoherence term from [9] and the third part of the fidelity term in FDDL to make the class-specific sub-dictionaries as discriminative as possible.", "startOffset": 55, "endOffset": 58}, {"referenceID": 2, "context": "According to the recent arguments from [3], in the SRC (i.", "startOffset": 39, "endOffset": 42}, {"referenceID": 12, "context": ", DL] \u2208 R is the learned dictionary from X (usually K \u2264 n); A denotes the reconstruction coefficients over D for X ; W denotes the learned parameters of the discriminative model f(W,A) for classification with A; r(X,D,A) is the discriminative reconstruction model defined over D (called the discriminative fidelity in [13]); and \u03bb1 and \u03bb2 are trade-off parameters.", "startOffset": 318, "endOffset": 322}, {"referenceID": 12, "context": "The proposed DL-NSCR model inherits the design of the r(X,D,A) term from FDDL [13], but discards its timeconsuming f(W,A) term to keep the model light.", "startOffset": 78, "endOffset": 82}, {"referenceID": 14, "context": "Besides that, we follow [15], [16] on varying the number of samples per class for 2 of the 3 adopted reidentification datasets with 3 different values for each of them to investigate how this factor influences the performance of the tested models.", "startOffset": 24, "endOffset": 28}, {"referenceID": 15, "context": "Besides that, we follow [15], [16] on varying the number of samples per class for 2 of the 3 adopted reidentification datasets with 3 different values for each of them to investigate how this factor influences the performance of the tested models.", "startOffset": 30, "endOffset": 34}, {"referenceID": 16, "context": "For face recognition, we choose two widely-used datasets: Extended Yale B [17] and AR [18].", "startOffset": 74, "endOffset": 78}, {"referenceID": 17, "context": "For face recognition, we choose two widely-used datasets: Extended Yale B [17] and AR [18].", "startOffset": 86, "endOffset": 90}, {"referenceID": 0, "context": "We preprocessed the data according to [1]: using cropped images with a size of 198 \u00d7 168 pixels; randomly selecting half of the samples for training and testing (about 32 samples per person); projecting each image into a 504-dimensional feature space using a random matrix generated from a zeromean normal distribution with its rows normalized (by l2norm).", "startOffset": 38, "endOffset": 41}, {"referenceID": 11, "context": "The size of the class-specific dictionary Ki for all the dictionary learning models was set to 15, so K = 570, as suggested by [12].", "startOffset": 127, "endOffset": 131}, {"referenceID": 0, "context": "Following [1] and [13], we use a subset of 100 subjects (50 male and 50 female) with only 14 images containing illumination and expression changes for each of them (7 from session 1 for training and another 7 from session 2 for testing).", "startOffset": 10, "endOffset": 13}, {"referenceID": 12, "context": "Following [1] and [13], we use a subset of 100 subjects (50 male and 50 female) with only 14 images containing illumination and expression changes for each of them (7 from session 1 for training and another 7 from session 2 for testing).", "startOffset": 18, "endOffset": 22}, {"referenceID": 18, "context": "We adopt the 1180-dimensional PRI-CoLBP0 feature descriptor proposed in [19] due to its high performances.", "startOffset": 72, "endOffset": 76}, {"referenceID": 19, "context": "Following the state-of-the-art model spatial PACT [20], we have 25 images per class sampled for training and the rest left for testing.", "startOffset": 50, "endOffset": 54}, {"referenceID": 20, "context": "[21], we focus on the same set of 61 categories of specific food items with background removed.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "We experiment on three recently built datasets \u201ciLIDS-MA\u201d, \u201ciLIDS-AA\u201d [15] and CAVIAR4REID[22].", "startOffset": 70, "endOffset": 74}, {"referenceID": 21, "context": "We experiment on three recently built datasets \u201ciLIDS-MA\u201d, \u201ciLIDS-AA\u201d [15] and CAVIAR4REID[22].", "startOffset": 90, "endOffset": 94}, {"referenceID": 21, "context": "We follow [22] on training with 22 specified subjects and testing on the other 50 subjects.", "startOffset": 10, "endOffset": 14}, {"referenceID": 15, "context": "Like [16], we perform multipleshot re-identification and treat it as a set-based classification problem.", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "We used exactly the same 400-dimensional color and texture histograms based features as adopted in [23] for all the methods.", "startOffset": 99, "endOffset": 103}, {"referenceID": 12, "context": "including FDDL [13], LC-KSVD [12], and DL-COPAR [14].", "startOffset": 15, "endOffset": 19}, {"referenceID": 11, "context": "including FDDL [13], LC-KSVD [12], and DL-COPAR [14].", "startOffset": 29, "endOffset": 33}, {"referenceID": 13, "context": "including FDDL [13], LC-KSVD [12], and DL-COPAR [14].", "startOffset": 48, "endOffset": 52}, {"referenceID": 23, "context": "DL-NSCR takes an alternative optimization model which has theoretical guarantee for global convergence and local qlinear (faster than linear) convergence speed [24].", "startOffset": 160, "endOffset": 164}], "year": 2014, "abstractText": "Sparse representation based classification (SRC) has been proved to be a simple, effective and robust solution to face recognition. As it gets popular, doubts on the necessity of enforcing sparsity starts coming up, and primary experimental results showed that simply changing the l1-norm based regularization to the computationally much more efficient l2-norm based non-sparse version would lead to a similar or even better performance. However, that\u2019s not always the case. Given a new classification task, it\u2019s still unclear which regularization strategy (i.e., making the coefficients sparse or non-sparse) is a better choice without trying both for comparison. In this paper, we present as far as we know the first study on solving this issue, based on plenty of diverse classification experiments. We propose a scoring function for pre-selecting the regularization strategy using only the dataset size, the feature dimensionality and a discrimination score derived from a given feature representation. Moreover, we show that when dictionary learning is taking into account, non-sparse representation has a more significant superiority to sparse representation. This work is expected to enrich our understanding of sparse/non-sparse collaborative representation for classification and motivate further research activities.", "creator": "LaTeX with hyperref package"}}}