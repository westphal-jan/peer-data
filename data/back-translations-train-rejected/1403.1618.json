{"id": "1403.1618", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2014", "title": "Design a Persian Automated Plagiarism Detector (AMZPPD)", "abstract": "Currently there are lots of plagiarism detection approaches. But few of them implemented and adapted for Persian languages. In this paper, our work on designing and implementation of a plagiarism detection system based on pre-processing and NLP technics will be described. And the results of testing on a corpus will be presented.", "histories": [["v1", "Thu, 6 Mar 2014 22:57:29 GMT  (141kb)", "http://arxiv.org/abs/1403.1618v1", "3 pages, Published with International Journal of Engineering Trends and Technology (IJETT)Published with International Journal of Engineering Trends and Technology (IJETT)"]], "COMMENTS": "3 pages, Published with International Journal of Engineering Trends and Technology (IJETT)Published with International Journal of Engineering Trends and Technology (IJETT)", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["maryam mahmoodi", "mohammad mahmoodi varnamkhasti"], "accepted": false, "id": "1403.1618"}, "pdf": {"name": "1403.1618.pdf", "metadata": {"source": "CRF", "title": "Design a Persian Automated Plagiarism Detector (AMZPPD)", "authors": ["Maryam Mahmoodi", "Mohammad Mahmoodi Varnamkhasti"], "emails": [], "sections": [{"heading": null, "text": "ISSN: 2231-5381 http: / / www.ijettjournal.org Page 465I. INTRODUCTION Today, the Internet makes document and information sharing very easy, and as a result, plagiarism in written texts is a real problem today in most academic environments. Many methods and approaches have been developed to automatically detect plagiarism, especially in the English language. But for the Persian language, there is little work. In this work, therefore, the goal is to implement an accurate system of plagiarism detection with the purpose of short paragraphs.II. ARTICHETURE OF METHODOLOGY In this section, we have described our system methodology, which determines how similar two suspicious texts are. In [1] a new multi-level framework has been introduced, adapted to the Persian language in our work and used as the main idea:"}, {"heading": "A. Pre-Processing Stage", "text": "At this stage, some pre-processing techniques are used to extract individual words from the structured text and to remove unnecessary things that make it difficult to see similarities. In Section III, techniques and their techniques and the meaning of each one in Persian are described."}, {"heading": "B. Similarity comparison Stage", "text": "At this stage, one of these comparative methods is used to compare two strings of words produced in the previous phase: 2 gram similarity measures (used with Jaccard or Clough & Stevenson) 3 gram similarity measures (used with Jaccard or Clough & Stevenson) Longest joint sub-sequence C. Dictatorship level Using numbers generated at vulnerable stages, one of these judgments is derived: Clean (non-plagiarism): based on the participants \"own knowledge, since the original texts were not given. Heavy revision: rewriting the original by paraphrasing and restructuring. Easy revision: slight modification of the original text by replacing words with synonyms and making some grammatical changes. Close copy: copy-and-paste from the original text. [1] This can be achieved by individual criteria or multi-criteria analysis."}, {"heading": "A. Normalizing", "text": "A Persian normalizer removes additional spaces, organizes virtual spaces (for example, correct letter combinations from \"\u0441\u0430\u043d\u0438\" to \"\u0441\u0430\u043d\u0438\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u0442\u0438\"), resolves the problem of the words \"\u043d\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u043e\u0441\u0442\u0438\" and \"\u0438.\" This pre-processing technology is very important in Persian because most texts do not adhere to correct orthography, and it can lead to difficulties in recognizing similarity."}, {"heading": "B. Stop-word Removal", "text": "This technique eliminates common words (articles, prepositions, determinants,...), such as \"\u0435\u0439,\" \"\u0435\u0442,\" \"\u0435\u0442.\" These words sometimes have little impact on the meaning, but sometimes play an important role in the text. Two types of deep and flat stop word removal tables have been tested to find out the actual effects of this technique."}, {"heading": "C. Sentence segmentation", "text": "Divide the text in the document into sentences and enable line-by-line processing in the subsequent tests [1]."}, {"heading": "D. Tokenization", "text": "Token (words, punctuation marks, etc.) Limits in sentences [1].ISSN: 2231-5381 http: / / www.ijettjournal.org page 466"}, {"heading": "E. Stemming", "text": "Sometimes people change the shape of a word to hide their plagiarism. Let's say these two sentences: \"The shape of a word changes to hide its plagiarism.\" And \"the shape of a word changes.\" In this case, the similarity tester makes mistakes when words are not converted into trunks."}, {"heading": "F. Lemmatization", "text": "Turn words into their basic dictionary forms to generalize comparative analysis [1]. Sometimes lemmatization is mistaken for stammering, but there is an essential difference. Stammering only works with single words without knowledge of the context and therefore cannot distinguish between words with several different meanings [2]."}, {"heading": "G. Number Replacement", "text": "This replaces any number with a dummy. (\"#\" for example) The reason for this is that in some scientific reports dishonest persons can simply carefully modify the numbers in order to defraud the system."}, {"heading": "H. Synonymy Recognition", "text": "The motivation to recognize synonyms stems from the fact that people try to hide plagiarism by replacing words with appropriate synonyms [2]. In Persian, recognizing synonyms is very important because every word has many synonyms, and sometimes synonyms are the foreign equivalent of words in Persian script. For example, \"envirios\" can be used instead of \"envirios\" to mislead the plagiarism detector."}, {"heading": "I. Part-of-Speech tagging", "text": "Assign grammatical markers to each word, such as \"noun,\" \"verb,\" etc., to identify cases where words have been replaced, but the style remains similar in terms of grammatical categories [1].IV. SIMILARITY-COMPARISON At the end of the first stage, we have two word strings: one of the original text and one of the suspicious text. These sequences have been cleaned up using some of the above techniques and can be checked using one of these comparison methods:"}, {"heading": "A. N-grams + Jaccard similarity coefficient", "text": "If S (A) is the set of n-grams of the original text and S (A) is the set of n-grams of suspicious text. The Jaccard similarity coefficient is defined as:"}, {"heading": "B. N-grams + Clough & Stevenson metric", "text": "Under similar conditions with Part A Clough & Stevenson metric defined as [1, 3]:"}, {"heading": "C. LCS", "text": "To determine the best possible combination, we tested most of the possible ones in Table1 and Table2 are the information of the Top10 combinations.To test different combinations, we first developed a Persian corpus such as [3], which is available at the following address: http: / / amzmohammad.com / AMZPPD / CPPD.tarTABLE I AVERAGE RESULTS OF SAMPLE COMBINATIONSC ombiantio nAverage similarity score Clean HeavyRevision Light Revision Copy1 0.0019 0.003 0.039 0,198 2 0.004 0.016 0,112 0,294 3 0.002 0.003 0.038 0,124 0,314 5 0.0043 0.0075 0.000,003 0,0190,022 0.0240,022 0.0247 0,024 0,024 0,0307 0.030 0,038 0,030 0,030 0,030 0,030 0,030 030 030 030 030 0,030 0,030 0,030 0,030 0,030 030 0,030 0,030 0,030 030 0,030 0,030 0,030 030 0,030 0,030 030 0,030 0,030 0,030."}, {"heading": "9 Y D Y Y N Y Y Y N LCS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10 Y D Y Y Y Y Y Y Y LCS", "text": "These ten combinations are chosen because they show significant differences in the values achieved in the different groups.VI. CHOOSE THE BEST COMBINATION The criterion is the coefficient of dispersion. This is the ratio of variance to mean in each group (judgment), VII. CONCLUSION In this work we have shown that the influence of the NLP technique and the processes on Persian Plagiarism Disctionaccuracy is significant, but due to the spelling problems and perhaps the ambiguities of the language, this influence is less than English. The result of this work is that Python, NLTK and HAZM library are being implemented and are under review and development in some academic environments. Under the project name AMZPPD: http: / / amzmohammad.com / AMZPPD / REFERENCES."}], "references": [{"title": "Using Natural Language Processing for Automatic Detection of Plagiarism", "author": ["M. Chong", "L. Specia", "R Mitkov"], "venue": "Proceedings of the 4th International Plagiarism Conference,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Influence of Text Pre-processing on Plagiarism Detection", "author": ["Ceska", "Zdenek", "Fox", "Chris", "The"], "venue": "(eds.) International Conference on Recent Advances in Natural Language Processing", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Developing a corpus of plagiarized short answers", "author": ["P. Clough", "M Stevenson"], "venue": "Language Resources and Evaluation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Automatic Conceptual Analysis for Plagiarism Detection", "author": ["H. Dreher"], "venue": "In Issues in Informing Science and Information Technology,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Plagiarism Detection Based on Singular Value Decomposition", "author": ["Z. Ceska"], "venue": "Advances in Natural Language Processing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Foundations of statistical natural language processing. Reading: MIT Press,1990", "author": ["C. Manning", "H Schutze"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1990}, {"title": "MOSS: A System for Detecting Software Plagiarism", "author": ["A Aiken"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}], "referenceMentions": [{"referenceID": 0, "context": "In [1], a multi\u2013stage new framework introduced that is adapted to Persian language in our work and used as the main Idea:", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "[1]", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Split text in the document into sentences and thereby allowing line-by-line processing in the subsequent tests [1].", "startOffset": 111, "endOffset": 114}, {"referenceID": 0, "context": ") boundaries in sentences[1].", "startOffset": 25, "endOffset": 28}, {"referenceID": 0, "context": "Transform words into their dictionary base forms in order to generalize the comparison analysis [1].", "startOffset": 96, "endOffset": 99}, {"referenceID": 1, "context": "Stemming operates only with single words without any knowledge of the context, and therefore cannot distinguish among words having several different meanings [2].", "startOffset": 158, "endOffset": 161}, {"referenceID": 1, "context": "The motivation for using synonymy recognition comes from considering human behaviour, whereby people may seek to hide plagiarism by replacing words with appropriate synonyms [2].", "startOffset": 174, "endOffset": 177}, {"referenceID": 0, "context": ", for detecting cases where words have been replaced, but the style in terms of grammatical categories remains similar[1].", "startOffset": 118, "endOffset": 121}, {"referenceID": 0, "context": "N-grams + Clough & Stevenson metric In similar conditions with part A Clough & Stevenson metric defined as [1, 3]:", "startOffset": 107, "endOffset": 113}, {"referenceID": 2, "context": "N-grams + Clough & Stevenson metric In similar conditions with part A Clough & Stevenson metric defined as [1, 3]:", "startOffset": 107, "endOffset": 113}, {"referenceID": 2, "context": "For testing different combinations we first developed a Persian Corpus just like [3] that is available at: http://amzmohammad.", "startOffset": 81, "endOffset": 84}], "year": 2014, "abstractText": "Currently there are lots of plagiarism detection approaches. But few of them implemented and adapted for Persian languages. In this paper, our work on designing and implementation of a plagiarism detection system based on preprocessing and NLP technics will be described. And the results of testing on a corpus will be presented. Keywords\u2014 External Plagiarism, Plagiarism, Copy detection, natural language processing, Artificial intelligence , Persian language.", "creator": null}}}