{"id": "1404.4108", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2014", "title": "Representation as a Service", "abstract": "We envision a machine learning service provider facing a continuous stream of problems with the same input domain, but with output domains that may differ. Clients present the provider with problems implicitly, by labeling a few example inputs, and then ask the provider to train models which reasonably extend their labelings to novel inputs. The provider wants to avoid constraining its users to a set of common labels, so it does not assume any particular correspondence between labels for a new task and labels for previously encountered tasks. To perform well in this setting, the provider needs a representation of the input domain which, in expectation, permits effective models for new problems to be learned efficiently from a small number of examples. While this bears a resemblance to settings considered in previous work on multitask and lifelong learning, our non-assumption of inter-task label correspondence leads to a novel algorithm: Lifelong Learner of Discriminative Representations (LLDR), which explicitly minimizes a proxy for the intra-task small-sample generalization error. We examine the relative benefits of our approach on a diverse set of real-world datasets in three significant scenarios: representation learning, multitask learning and lifelong learning.", "histories": [["v1", "Mon, 24 Feb 2014 15:17:39 GMT  (62kb,D)", "http://arxiv.org/abs/1404.4108v1", "6 pages, 4 figures"], ["v2", "Wed, 9 Jul 2014 07:17:54 GMT  (1033kb,D)", "http://arxiv.org/abs/1404.4108v2", "8 pages"]], "COMMENTS": "6 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ouais alsharif", "philip bachman", "joelle pineau"], "accepted": false, "id": "1404.4108"}, "pdf": {"name": "1404.4108.pdf", "metadata": {"source": "META", "title": "Lifelong Learning of Discriminative Representations", "authors": ["Ouais Alsharif", "Philip Bachman", "Joelle Pineau"], "emails": ["ouais.alsharif@mail.mcgill.ca,", "phil.bachman@gmail.com,", "jpineau@cs.mcgill.ca"], "sections": [{"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to move to another world in which they are able to find themselves."}, {"heading": "2 The Lifelong Learning Problem", "text": "We begin with the definition of environment E = (Q, X), which includes an input domain X and a task distribution Q. Q is a distribution over tasks Ti, where each task includes Ti = (Yi, Di, Li, Gi): \u2022 An output domain Yi. \u2022 A distribution Di over X \u00b7 Yi. \u2022 A generalization of functional Gi (f), for all functions f: X \u2192 Yi, for all functions f: Yi, with Gi (f) = E (x, y).For the environments we are looking at, X = Rd for some finite d > 0. For the classification tasks, Yi is the discrete space of relevant labels, and Li (y, y \u2032) is the indicator function I {y \u00b2."}, {"heading": "3 Related Works", "text": "The key motivation for lifelong learning is the idea that information derived from past tasks can be used to improve future tasks. (...) A similar motivation (coupled with a contemporary approach) motivates most work on multitasal learning processes. (...) The authors provide a listing of multitasal learning methods, all of which are based on some structure by which information is shared between tasks. (...) The ubiquity of the common learning approach continues to the present tasks. (...) The various structures used to induce information include neural network-based features (Baxter 1995), learned distance metrics (Thrun 1996b), Bayesian priors (Xue et al. 2007), and many others."}, {"heading": "4 Method", "text": "The general idea of our model is to capture a parametric function and gather an unlimited collection of functions. (...) With a \"meta\" algorithm that tries to make the output of f more effective as input. (...) To make the output of f-algorithmAt the task, we will try to make the output of f-algorithmAt the task of Tt3. (...) With the notation defined in Section 2, we will make the task of f-algorithmAt the task. (...) We will try to make the output of f-algorithmAt the task. (...) We will use the notation defined in Section 2. (...) We will try to make the output of f-algorithmAt the task. (...) We will make the output of f-algorithmAt the task. (...)"}, {"heading": "5 Evaluation", "text": "We evaluate our method in three different contexts: 1. As a representation learner: These experiments show whether our algorithm can learn representations that are well suited to approximate the functioning of a small sample; 2. As a multi-task learner: These experiments show how our algorithm compares with a large number of training tasks and a large number of test tasks that differ from the training tasks; 3. As a lifelong learner: These experiments show how our algorithm performs in lifelong learning with a large number of training tasks and a large number of test tasks that differ from the training tasks. Experiments in scenarios 1 and 3 have three phases: 1. Presentation learning: algorithms encounter task streams to train the common intertask structure; 2. Function approximation: Each algorithm is presented with a small sample of described data from a new task; and a function approximator is trained on the described data that is distorted by the common structure that is learned in 1.3."}, {"heading": "Representation Learning Experiments", "text": "This year, it is time for us to take the lead and conquer the world."}, {"heading": "Multitask Learning Experiments", "text": "This section examines how our algorithm performs in multi-task learning, where the number of training tasks is fixed and test tasks are the same as training tasks. We compare our algorithm with state-of-the-art multi-task learning algorithms on datasets common in the multi-task learning community. We show empirically that our model, although not designed for multi-task learning and does not require task correspondence, is favorable compared to modern multi-task learners on these benchmarks. We compare LLDR with three multi-task learning algorithms: ELLA (Ruvolo and Eaton 2013), GOMTL (Kumar and Daume III 2012) and OMTL (Saha et al. 2011) and Standard Single Task Learning (STL), on datasets from Landmine (Xue et al. 2007) and London schools (Kumar and Daume III 2012)."}, {"heading": "Datasets", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Landmine Detection", "text": "This dataset is a binary classification dataset (mine or no mine) containing x 15k points unevenly distributed across 29 regions with 9 characteristics per sample. These are four moment-based characteristics, three correlation-based characteristics, one characteristic of the energy ratio and one characteristic of spatial variance. Similar to (Ruvolo and Eaton 2013), we treat each region as a different task."}, {"heading": "London Schools Data", "text": "This dataset is a regression dataset that contains information about the 15k students who are unequally distributed across 139 schools and their exam results. The features for this task are as follows: four school-specific categorical variables and three student-specific categorical variables. Similar to (Ruvolo and Eaton 2013) and (Kumar and Thumb III 2012), we encode the categorical variables as a single binary attribute and add exam years and terms leading to 27 characteristics per student."}, {"heading": "Training Methodology", "text": "For OMTL and GOMTL, we use the results of (Ruvolo and Eaton 2013), which optimize the hyperparameters for each method on a validation set. For ELLA, we optimized the hyperparameters on a validation set. For LLDR, we optimized the learning rates on a validation set. The general structure of the LLDR was like for the representation of learning experiments, but with logistic regression, which was replaced by linear regression for the task at London schools. For the landmine task, performance is measured as the mean of the Area Under Curve (AUC) for OMTL and GOMTL, in addition to the accuracy for ELLA and LLDR5. For London schools, performance is measured as the mean RMSE. Despite the class distortion in the landmine datasets, we believe that accuracy in our context is a more reasonable metric than the other methods designed as a benchmark."}, {"heading": "Lifelong Learning Experiments", "text": "We are now comparing how our algorithm behaves in the context of lifelong learning with many training tasks when tested on tasks that are not seen in training. We are comparing with ELLA (Ruvolo and Eaton 2013) and multinomial logistic regression.5We have not been able to reproduce the results for OMTL and GOMTL, so we limit our accuracy comparisons to ELLA and STLTable 1: Comparison of LLDR, ELLA, OMTL and GOMTL on the datasets of landmines and London schools. N / A data indicate that OMTL does not work for regression problems. AUC results for OMTL and GOMTL are the averages from (Ruvolo and Eaton 2013). For classification problems, the results are in the range under Curve and the bracketed results are the mean accuracy. For regression, the results for OMTL and GOMTL are the averages from Ruvolo and Eaton 2013."}, {"heading": "Datasets", "text": "CIFAR 100 This dataset (Krizhevsky 2009) contains 50k training samples and 10k test samples from 100 different classes. The samples are 32 x 32 color images. We prepare the data by converting it to grayscale, applying contrast normalization and projecting it onto the first 10 main components. We would use a higher dimensionality, but ELLA scales poorly in this respect."}, {"heading": "20 Newsgroups", "text": "This dataset contains 19k documents from 20 classes. We pre-processed the data by removing stopwords, encoding documents as word bags and then displaying them using LDA (Lead, Ng and Jordan 2003) with 10 topics."}, {"heading": "Training Methodology", "text": "Similar to the representative learning experiments, each data set is divided into three distinct parts: The first part is for training the feature extractor, the second part is for training the functional approximator during the test phase, and the third part is for performance evaluation. The sizes of these data sets are (40,000, 10,000, 10,000) and (9314, 2000, 7532) for the CIFAR 100 and the 20 newsgroups dataset, respectively. Both algorithms are trained on a set of 1000 k-path classification problems randomly selected from the series of (| C | k) problems, with | C | the number of classes available for the respective datasets and k = 5. Our algorithm had the same instantiation between the groups of data as in Learning 2AR / ELAR, as shown clearly in Learning LA / ELAR. Each data set is divided into three parts: The first part is for training the feature extractor, the second part is for training the functional approximator during the test phase, and the third part is for performance evaluation."}, {"heading": "6 Discussion", "text": "We introduced the problem of lifelong learning without task correspondence and presented a flexible framework that solves this problem by optimizing a feature extractor whose output works well for future tasks. Our method allows us to learn new hypotheses efficiently with relatively few samples and allows us to avoid adopting a task correspondence. The flexibility of the proposed framework lies in its modularity, since the function approximator can be a classifier or a regressor. In addition, the feature extractor can be adapted to different domains and scenarios where possible feature extractors include convolutionary neural networks, increased stumps, etc. We tested our framework in three relevant scenarios. As a presentation learner, multitask learner, and lifelong learner. In the case of performance learning, we show empirically that our model outperforms classical methods when it is trained on a single task and on multiple tasks, new tasks and performing tasks in multiple scenarios."}], "references": [{"title": "A framework for learning predictive structures from multiple tasks and unlabeled data", "author": ["R.K. Ando", "T. Zhang"], "venue": "The Journal of Machine Learning Research 6:1817\u20131853.", "citeRegEx": "Ando and Zhang,? 2005", "shortCiteRegEx": "Ando and Zhang", "year": 2005}, {"title": "Learning internal representations", "author": ["J. Baxter"], "venue": "In Proceedings of the Eighth International Conference on Computational Learning Theory, 311\u2013320. ACM Press.", "citeRegEx": "Baxter,? 1995", "shortCiteRegEx": "Baxter", "year": 1995}, {"title": "A model of inductive bias learning", "author": ["J. Baxter"], "venue": "J. Artif. Intell. Res.(JAIR) 12:149\u2013198.", "citeRegEx": "Baxter,? 2000", "shortCiteRegEx": "Baxter", "year": 2000}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "the Journal of machine Learning research 3:993\u20131022.", "citeRegEx": "Blei et al\\.,? 2003", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Toward an architecture for never-ending language learning", "author": ["A. Carlson", "J. Betteridge", "B. Kisiel", "B. Settles", "E.R. Hruschka Jr", "T.M. Mitchell"], "venue": "AAAI.", "citeRegEx": "Carlson et al\\.,? 2010", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Multitask learning", "author": ["R. Caruana"], "venue": "Machine learning 28(1):41\u201375.", "citeRegEx": "Caruana,? 1997", "shortCiteRegEx": "Caruana", "year": 1997}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["R. Collobert", "J. Weston"], "venue": "Proceedings of the 25th international conference on Machine learning, 160\u2013167. ACM.", "citeRegEx": "Collobert and Weston,? 2008", "shortCiteRegEx": "Collobert and Weston", "year": 2008}, {"title": "Deep sparse rectifier networks", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "Proceedings of the 14th International Conference on Artificial Intelligence and Statistics. JMLR W&CP Volume, volume 15, 315\u2013323.", "citeRegEx": "Glorot et al\\.,? 2011", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": null, "citeRegEx": "Krizhevsky,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky", "year": 2009}, {"title": "Learning task grouping and overlap in multi-task learning", "author": ["A. Kumar", "H. Daume III"], "venue": "arXiv preprint arXiv:1206.6417.", "citeRegEx": "Kumar and III,? 2012", "shortCiteRegEx": "Kumar and III", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE 86(11):2278\u20132324.", "citeRegEx": "LeCun et al\\.,? 1998", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Ella: An efficient lifelong learning algorithm", "author": ["P. Ruvolo", "E. Eaton"], "venue": "ICML.", "citeRegEx": "Ruvolo and Eaton,? 2013", "shortCiteRegEx": "Ruvolo and Eaton", "year": 2013}, {"title": "Online learning of multiple tasks and their relationships", "author": ["A. Saha", "P. Rai", "H.D. Iii", "S. Venkatasubramanian"], "venue": "International Conference on Artificial Intelligence and Statistics, 643\u2013651.", "citeRegEx": "Saha et al\\.,? 2011", "shortCiteRegEx": "Saha et al\\.", "year": 2011}, {"title": "Computationally efficient multi-task learning with least-squares probabilistic classifiers", "author": ["J. Simm", "M. Sugiyama", "T. Kato"], "venue": "Information and Media Technologies 6(2):508\u2013515.", "citeRegEx": "Simm et al\\.,? 2011", "shortCiteRegEx": "Simm et al\\.", "year": 2011}, {"title": "Lifelong learning: A case study", "author": ["S. Thrun"], "venue": "Technical report, DTIC Document.", "citeRegEx": "Thrun,? 1995", "shortCiteRegEx": "Thrun", "year": 1995}, {"title": "Discovering structure in multiple learning tasks: The tc algorithm", "author": ["S. Thrun"], "venue": "ICML.", "citeRegEx": "Thrun,? 1996a", "shortCiteRegEx": "Thrun", "year": 1996}, {"title": "Learning to learn: Introduction", "author": ["S. Thrun"], "venue": "In Learning To Learn. Citeseer.", "citeRegEx": "Thrun,? 1996b", "shortCiteRegEx": "Thrun", "year": 1996}, {"title": "Multi-task learning for classification with dirichlet process priors", "author": ["Y. Xue", "X. Liao", "L. Carin", "B. Krishnapuram"], "venue": "The Journal of Machine Learning Research 8:35\u201363.", "citeRegEx": "Xue et al\\.,? 2007", "shortCiteRegEx": "Xue et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 14, "context": "The machine learning community has long been aware of the importance of lifelong learning (Thrun 1995; 1996b; Carlson et al. 2010).", "startOffset": 90, "endOffset": 130}, {"referenceID": 4, "context": "The machine learning community has long been aware of the importance of lifelong learning (Thrun 1995; 1996b; Carlson et al. 2010).", "startOffset": 90, "endOffset": 130}, {"referenceID": 5, "context": "Lifelong learning is distinct from multitask learning (Caruana 1997) in the sense that it focuses on improving generalization performance for new tasks with minimal amounts of training data, rather than focusing on improving generalization performance for a fixed collection of tasks defined a priori.", "startOffset": 54, "endOffset": 68}, {"referenceID": 2, "context": "Our model is motivated by an idea adapted from (Baxter 2000): a lifelong learner should use information from past tasks to learn a representation that is simple enough to allow for effective generalization on new tasks with minimal training data, yet flexible enough to accommodate a relatively diverse set of tasks.", "startOffset": 47, "endOffset": 60}, {"referenceID": 15, "context": "In (Thrun 1996a), the authors provide a listing of multitask and lifelong learning methods.", "startOffset": 3, "endOffset": 16}, {"referenceID": 1, "context": "The various structures used to induce information sharing include neural network-based feature transformations (Baxter 1995), learned distance metrics (Thrun 1996b), Bayesian priors (Xue et al.", "startOffset": 111, "endOffset": 124}, {"referenceID": 16, "context": "The various structures used to induce information sharing include neural network-based feature transformations (Baxter 1995), learned distance metrics (Thrun 1996b), Bayesian priors (Xue et al.", "startOffset": 151, "endOffset": 164}, {"referenceID": 17, "context": "The various structures used to induce information sharing include neural network-based feature transformations (Baxter 1995), learned distance metrics (Thrun 1996b), Bayesian priors (Xue et al. 2007), and many others.", "startOffset": 182, "endOffset": 199}, {"referenceID": 11, "context": "In particular, (Ruvolo and Eaton 2013) presents an algorithm for online multitask learning composed of two parts: a linear function approximator fw(x) = w >x where w \u2208 R, and a dictionary L \u2208 Rd\u00d7k containing k d-dimensional basis functions.", "startOffset": 15, "endOffset": 38}, {"referenceID": 11, "context": "Additionally, the linearity of fw assumed by ELLA, as presented in (Ruvolo and Eaton 2013), limits the space of tasks where ELLA might perform well to tasks on which a linear approximator could conceivably perform well given enough training observations.", "startOffset": 67, "endOffset": 90}, {"referenceID": 12, "context": "In (Saha et al. 2011), the authors also propose an online method for multitask learning, called OMTL, based on the perceptron algorithm.", "startOffset": 3, "endOffset": 21}, {"referenceID": 11, "context": "Though, as pointed out by (Ruvolo and Eaton 2013), the perceptron algorithm tends to underperform other linear methods (e.", "startOffset": 26, "endOffset": 49}, {"referenceID": 2, "context": "On the theoretical side, (Baxter 2000) provides PAC bounds for a setting very similar to the one described in Section 2.", "startOffset": 25, "endOffset": 38}, {"referenceID": 6, "context": "Modern examples of this approach include (Collobert and Weston 2008) and the wining entry in the Merck Molecular Activity Challenge in 2012.", "startOffset": 41, "endOffset": 68}, {"referenceID": 11, "context": "We note that among the algorithms we\u2019ve just mentioned, only ELLA (Ruvolo and Eaton 2013) can operate without the task correspondence assumption.", "startOffset": 66, "endOffset": 89}, {"referenceID": 6, "context": "g (Collobert and Weston 2008).", "startOffset": 2, "endOffset": 29}, {"referenceID": 10, "context": "Experiments in this section use the well-known MNIST dataset (LeCun et al. 1998).", "startOffset": 61, "endOffset": 80}, {"referenceID": 11, "context": "We compare LLDR to three multitask learning algorithms: ELLA (Ruvolo and Eaton 2013), GOMTL (Kumar and Daume III 2012), and OMTL (Saha et al.", "startOffset": 61, "endOffset": 84}, {"referenceID": 12, "context": "We compare LLDR to three multitask learning algorithms: ELLA (Ruvolo and Eaton 2013), GOMTL (Kumar and Daume III 2012), and OMTL (Saha et al. 2011), and standard single task learning (STL), on the landmine (Xue et al.", "startOffset": 129, "endOffset": 147}, {"referenceID": 17, "context": "2011), and standard single task learning (STL), on the landmine (Xue et al. 2007) and London schools datasets (Kumar and Daume III 2012).", "startOffset": 64, "endOffset": 81}, {"referenceID": 11, "context": "Similar to (Ruvolo and Eaton 2013), we treat every region as a different task.", "startOffset": 11, "endOffset": 34}, {"referenceID": 11, "context": "Similar to (Ruvolo and Eaton 2013) and (Kumar and Daume III 2012), we encode the categorical variables as one-hot binary features and add examination year and bias terms leading to 27 features per student.", "startOffset": 11, "endOffset": 34}, {"referenceID": 11, "context": "We follow the methodology used by (Ruvolo and Eaton 2013).", "startOffset": 34, "endOffset": 57}, {"referenceID": 11, "context": "For OMTL and GOMTL we use the results from (Ruvolo and Eaton 2013) which optimize the hyperparameters for each method on a validation set.", "startOffset": 43, "endOffset": 66}, {"referenceID": 11, "context": "We compare to ELLA (Ruvolo and Eaton 2013) and single-task multinomial logistic regression.", "startOffset": 19, "endOffset": 42}, {"referenceID": 11, "context": "The AUC results for OMTL and GOMTL are the mean results from (Ruvolo and Eaton 2013).", "startOffset": 61, "endOffset": 84}, {"referenceID": 8, "context": "CIFAR 100 This dataset (Krizhevsky 2009) contains 50k training samples and 10k testing samples from 100 different classes.", "startOffset": 23, "endOffset": 40}], "year": 2017, "abstractText": "We envision a machine learning service provider facing a continuous stream of problems with the same input domain, but with output domains that may differ. Clients present the provider with problems implicitly, by labeling a few example inputs, and then ask the provider to train models which reasonably extend their labelings to novel inputs. The provider wants to avoid constraining its users to a set of common labels, so it does not assume any particular correspondence between labels for a new task and labels for previously encountered tasks. To perform well in this setting, the provider needs a representation of the input domain which, in expectation, permits effective models for new problems to be learned efficiently from a small number of examples. While this bears a resemblance to settings considered in previous work on multitask and lifelong learning, our non-assumption of inter-task label correspondence leads to a novel algorithm: Lifelong Learner of Discriminative Representations (LLDR), which explicitly minimizes a proxy for the intra-task small-sample generalization error. We examine the relative benefits of our approach on a diverse set of real-world datasets in three significant scenarios: representation learning, multitask learning and lifelong learning.", "creator": "TeX"}}}