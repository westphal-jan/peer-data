{"id": "1405.0647", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-May-2014", "title": "Feature Selection On Boolean Symbolic Objects", "abstract": "With the boom in IT technology, the data sets used in application are more and more larger and are described by a huge number of attributes, therefore, the feature selection become an important discipline in Knowledge discovery and data mining, allowing the experts to select the most relevant features to improve the quality of their studies and to reduce the time processing of their algorithm. In addition to that, the data used by the applications become richer. They are now represented by a set of complex and structured objects, instead of simple numerical matrixes. The purpose of our algorithm is to do feature selection on rich data, called Boolean Symbolic Objects (BSOs). These objects are described by multivalued features. The BSOs are considered as higher level units which can model complex data, such as cluster of individuals, aggregated data or taxonomies. In this paper we will introduce a new feature selection criterion for BSOs, and we will explain how we improved its complexity.", "histories": [["v1", "Sun, 4 May 2014 05:02:53 GMT  (837kb)", "http://arxiv.org/abs/1405.0647v1", "20 pages, 10 figures"]], "COMMENTS": "20 pages, 10 figures", "reviews": [], "SUBJECTS": "cs.IR cs.AI", "authors": ["djamal ziani"], "accepted": false, "id": "1405.0647"}, "pdf": {"name": "1405.0647.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["BOOLEAN SYMBOLIC", "Djamal Ziani"], "emails": ["dziani@ksu.edu.sa"], "sections": [{"heading": null, "text": "With the boom in IT technology, the data sets used in the application are getting larger and are being described by a large number of attributes, so feature selection is becoming an important discipline in knowledge discovery and data mining, allowing experts to select the most relevant characteristics to improve the quality of their studies and reduce the time processing of their algorithm. In addition, the data used by the applications is becoming richer. They are now represented by a series of complex and structured objects, instead of simple numerical matrices. The purpose of our algorithm is to feature selection of rich data, called Boolean Symbolic Objects (BSOs). These objects are described by multi-value characteristics. BSOs are considered as superordinate units that can model complex data, such as clusters of individuals, aggregated data or taxonomies. In this paper, we introduce a new feature selection criterion for BSOs, and we explain how to improve their complexity."}, {"heading": "1. INTRODUCTION", "text": "To facilitate differentiation between objects, experts use feature selection algorithms to select a subset of characteristics that are most discriminatory without compromising the reliability of the data. The problem of feature selection has often been addressed in classical data analysis (e.g. discriminant analysis); many techniques or algorithms have been proposed [1].In classical data analysis, the data is represented by an array of individual \u00d7 variables, and the goal of the distinction is to distinguish between classes of individuals. As databases grow, it becomes very important to combine this data by using a complex type called symbolic object [2] [3].The feature selection algorithms on symbolic objects require a complex calculation, since the processed data can represent classes of real individuals and each variable is not limited to a value, but can point to a distribution of values [4]. Therefore, our study will focus on two main elements: the choice of a good algorithm and the improvement of the dissimilarity of numerical values."}, {"heading": "2. SYMBOLIC OBJECTS", "text": "Before introducing the algorithm, we give some definitions of symbolic objects [5]: Y = virtual object = virtual object = virtual object ({y1,..., yn} is the set of variables; O = {O1,..., On] is the set of areas in which each variable takes its value; Y = virtual object (w1,..., wp) is the set of elementary observed objects; Y = large (O1, high) is the set of all possible elementary observed objects. An elementary event is represented by the symbolic expression ei = [yi = vi] in which vi-Oi, and it is defined by ei: [true, false] as ei (w) = true \u2192 yi (w)."}, {"heading": "2.1. Notion of discrimination", "text": "Since the criteria of our feature selection algorithm are based on discrimination, we explain the discrimination of symbolic objects using the following symbolic objects: a1 = [age = [25.45] * [weight = [65.80 [] a2 = [age = [15.35] * [weight =] 80.90] * a3 = [age = [20.35] * [weight = [70.85]. There are two types of discrimination, Boolean and partial: Boolean or total discrimination between symbolic objects means that there is an empty intersection between the existing virtual objects. We have this with the objects a2 and the objects a3. See Figure 1. The discrimination between these two is equal to 1 (maximum).The partial discrimination between symbolic objects means that there is an intersection between the existing virtual objects. We have this with the objects a1 and the objects a3. See Figure 2."}, {"heading": "2.2. Dissimilarity measures", "text": "In the literature, we can find many measures of complexity, but only a few can be taken into account when working with symbolic objects data. In this section, we will consider some of the measures of discrimination used for symbolic objects. We will evaluate the measures of dissimilarity based on the following criteria: mathematical properties: dissimilation (an object is similar to itself), and symmetrical (if s is a measure of similarity) = s (aj, ai)) Type of characteristic: qualitative, quantitative Boolean or partial discrimination Complexity of dissimilation. We will use the same notation for all measures. Let's Govil, vjl be the values taken by the variable yl in the assertion ai and aj. Let's (.) calculate either the length if the characteristic is of an interval type, or the number of elements contained in a set of categorical characteristics."}, {"heading": "3. SELECTION CRITERIA", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Discrimination Power", "text": "Let A be a set of assertions, n is the number of assertions in A, Y is a set of variables, K is the set of assertion pairs K = AxA, and P (Y) is the set of subsets of Y. The function comp used in (1) indicates the existence or non-existence of an intersection between two objects. We say that two assertions ai and aj are discriminated against by a variable y if and only if comp (vil, vjl) = 1. The discriminatory force of a variable yl on the set K, denoted by DP (yl, K), is equal to the number of assertion pairs discriminated against by the variable yl: i.e., where is the set of integers. (7)"}, {"heading": "3.2. Original Discrimination Power", "text": "The original discriminatory force referred to as ODP, a variable yl that refers to a set of variable Yp, is equal to the number of pairs of claims discriminated against by yl and not discriminated against by any variable of Yp. This means that the external max in the expression limits the function to zero or a positive value for each pair of claims. Example 4: Based on the claims a1, a2 and a3 of Example 3, we obtain: ODP (size, hair, K) = 2."}, {"heading": "4. MINSET ALGORITHM", "text": "In the literature we find very few algorithms that can handle the selection of symbols for symbolic objects. We can quote, the algorithm of Ichino [11] uses geometric thickness criterion to select the characteristics, the algorithm of Nagabhushan et al. [12] and Kiranagi et al. [13] Select characteristics for clustering objects with similarity between symbolic objects, and the algorithm of Chouakria et al. [14] is for principal components we will focus on the algorithm of Vignes [6], as it is the only algorithm that makes the feature selection of symbolic objects with the purpose of distinguishing between objects. And, in this paper, we will mention a new algorithm called Minset Plus based on the improvement of minset algorithms. To discriminate the objects that are variable, which are variable."}, {"heading": "5 MINSET-PLUS ALGORITHM", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Critics of Minset Algorithm", "text": "In order to calculate them, the algorithm k \u00b7 (1 + p) must perform the function compwhere k = card (K) and p = card (Yp) times. The calculation is performed with k versions of the function comp. The discovery of some mathematical properties associated with the function ODP and DP has enabled us to significantly reduce the time complexity of the algorithm (see Section 6). The outlines of the object class are often blurred because they depend on the subjectivity of the experts; therefore, the Boolean distinction between object classes is a strong hypothesis that may worsen the finality of the study. In this case, we must introduce a new comparison function that can be based on a partial distinction between symbolic objects."}, {"heading": "5.2. Definition of the new discrimination function", "text": "The new discrimination function between symbolic objects is calculated by the g function, which can calculate both Boolean and partial discrimination. [15] This partial discrimination concept was introduced in the Minset-Plus algorithm to prevent the information provided by the variable from being neglected when there is no total discrimination. The g function, which calculates partial discrimination, is defined as follows: (10)"}, {"heading": "5.3. Use of mathematical properties to reduce complexity", "text": "Before demonstrating some useful mathematical properties of the ODP and DP functions, let us give some definitions: (11), (12), (13), (Property 1The following property allows us to calculate the discriminatory power of a number of variables using the selected power of the old selected variable and the original discriminatory power of the current selected variable, with the advantage of not calculating the discriminatory power of the selected variable at every step. (14)"}, {"heading": "5.4. Discrimination matrix", "text": "We can see that the calculation of DP and DP functions is based on the calculation of DP and DP (DP) n. (This happens repeatedly in each step. In addition, we know that the g function includes and operations between a number of values, and these operations are not simple operations. Therefore, we must find a way to avoid the calculation of the same thing many times. We will save the old calculations to reuse them in further algorithmic steps.This idea can be achieved by introducing a discrimination matrix. This discrimination matrix allows us to calculate only one time, and throughout all the steps of the algorithm we will use the matrix to perform all the necessary operations.This is a tremendous optimization of time complexity. Also, the size of this matrix is not large, it is: K is not a large number, since we have to keep it with classes of individuals.Example 5: Let us Y = {y1, y2, y5}, DyA and DY (D.DP)"}, {"heading": "5.5. Algorithm operations using discrimination matrix", "text": "To select the variables, the Minset Plus algorithm uses the same steps as in Section 4. However, since the operations used in each step are different and less complex based on the discrimination matrix, in order to select a new variable in each step, we must calculate the maximum discrimination value for each variable selected. We know that the value is stored in the discrimination matrix, exactly in the case that corresponds to the row y1 and the column (ai, aj). Since we calculate the maximum discrimination value for a set of variables, this value is stored in the casecorrelation to the column (ai, aj), and the line Max Yd will only subtract numbers and make a comparison to find the maximum of the redundant variables in each step, we only have to calculate for each pair d (ai, aj), the subtraction of the value of the case that corresponds to the column."}, {"heading": "6 APPLICATION", "text": "In order to test and validate the result of our algorithm, two categories of experiments were performed: In the first experiment, we tested the algorithm on real data sets and validated some of the results of feature selection with an expert. The purpose of the second experiment is to perform an automatic quality test. The experiment was performed on the basis of a simulated data set. On the basis of some quality indicators, we compare the results of the minset and the minset plus algorithm."}, {"heading": "6.1. Real Datasets Experiment", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1.1. UCI Machine Learning Repository Datasets", "text": "The data sets in this experiment come from the UCI Machine Learning Repository [16]. We used our program Symbolic Object Generator to generate the symbolic objects that represent the clusters of individuals of these data sets (see Section 6.2 for more details on this program). Table 4 describes the data sets. NOTICE: The missing values are treated by using a substitution with a central tendency measure. The columns used in Table 4 to describe the data sets are: \"Attribute Number\" indicates the number of attributes that describe the symbolic objects of the data set. \"Individual Number\" indicates the number of individuals used in the validation tests of the data sets. \"SO Number\" indicates the number of symbolic objects contained in the data sets. \"Cluster Discrimination Discrimination\" indicates the percentage of discrimination between the clusters. All clusters of data sets are 100% Discrimination by Extent. \""}, {"heading": "6.1.2. Expert Validation for Biological datasets", "text": "The expert evaluation of the Minset Plus results was conducted on biological datasets used by Lebbe [17] and described in Table 7. These datasets present a small percentage of overlaps, which means that the symbolic objects of these datasets are well distinguished, and the overlapping behavior is selected in (17). (17) Table 8 indicates the names of the variables selected by Minset-Plus and Minset Algorithm for more details on the data see [6]. Aquatic insectextremity of the abdomen, articulated legs free, mouthparts, type of lateral abdominal bronchia, lifestyle, prolegs, extrety of prolegs, development stage extrety of the abdomen, articulated legs free, type of lateral abdominal bronchia, lifestyle, extrety of prolegsSiphonophores number of crests, stomatocyte, form of crests, form of crests, of form of crests. \""}, {"heading": "6.2. Automatic Quality Test", "text": "In order to perform automatic quality control, we have designed and developed a complete system (see Figure 4).This system includes the following modules: Individual Data Generator: If the data sets of symbolic objects do not have a set of individuals for testing, we use the Individual Data Generator module to generate symbolic data. This module uses the domains of descriptive variables, and the values taken by variables in the symbolic objects to generate the individuals. Symbolic Objects Generator: It is a module used to generate symbolic objects from given individual units. Each individual should be associated with one or many clusters. We provide an input parameter for each variable that specifies which we have as output of the generated symbolic objects (arc objects, categorical, set of numerical values, intervals of all possible values)."}, {"heading": "6.2.1. Quality Test", "text": "Plus the number of selected variables: we create fifteen symbolic object records with overlapping percentages that we have selected for selected persons. Plus the number of selected variables: Plus the number of selected variables, the overlapping percentages are low, but Minset and Minset Plus algorithm select the same number of variables when we increase the percentage of overlap. Also, the number of selected variables decreases dramatically with the increase in the overlapping percentage. If we have reached 16% of the overlapping percentages, no variable has been selected. On the other hand, the number of selected variables of the Minset Plus algorithm is slightly decreased; and sometimes it is stationary for multiple percentages of overlapping. This proves that the selection criteria used by Minset Plus algorithm are more appropriate than those used by Minset Plus algorithm when we do with overlapping clusters."}, {"heading": "6.2.2. Complexity Test", "text": "We compared the time execution of Minset-Plus with the time execution of Minset-Partial (it is the algorithm Minset, but using partial discrimination as the selection criterion. This means that this algorithm does not use the mathematical properties and discrimination matrix used by Minset-Plus to reduce complexity. This test shows that the mathematical properties and discrimination matrix used in the Minset-Plus algorithm have an effect on the reduction of the complexity of the algorithm. The selection criterion based on partial discrimination uses complex operations, so we noticed that the complexity increases exponentially when we increase the number of symbolic objects (see the time execution of Minset-Partial in Fig. 9). Meanwhile, the time execution of Minset-Plus has grown slowly when we run the time execution of Minset-Plus with the time execution of Minset-Plus we run the time execution of Minset-Partial-Partial by comparing the last parity of Partial-slow, where we compare the last parity of Partial-Partial-10."}, {"heading": "7. CONCLUSIONS", "text": "In this article, we introduced the Minset-Plus algorithm, which is an extension and improvement of the Minset algorithm. Minset-Plus is an algorithm for selecting discrimination variables on a number of symbolic objects. The use of partial discrimination enables a profound and better processing of the selection of variables. Based on the discovery of some mathematical properties on ODP and DP functions and the use of the discrimination matrix, we have obtained a huge improvement in the complexity of the algorithm. The quality of the selected variables is closely based on the function \"g\" defined in (10) and on some parameters that the expert can introduce into the algorithm to refine the selection of variables. Therefore, in order to evaluate the robustness of this function and measure the quality of the variables selected, in our next research, we will enter automatic validation using expert input. In addition, we plan to integrate the Minset-Plus algorithm with databases, and this could happen by implementing the algorithm in an algorithm."}, {"heading": "ACKNOWLEDGEMENTS", "text": "The authors thank the King Saud University, the College of Computer and Information Sciences and the Research Center for their support. Author Djamal Ziani was an assistant at the King Saud University in Computer Sciences and Information Systems College from 2009 until now. Researcher in the CCIS King Saud University Data Management Group. He received his Master's degree in Computer Science from the University of Valenciennes France in 1992 and his PhD in Computer Science from the University of Paris Dauphine, France in 1996."}], "references": [{"title": "Towards integrating feature selection algorithms for classification and clustering", "author": ["Liu Huan", "Yu Lei"], "venue": "IEEE Transactions on Knowledge and Data Engineering, Vol. 17,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Symbolic Data Analysis and the SODAS software", "author": ["E. Diday", "M. Noirhomme"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Symbolic Data Analysis: Conceptual Statistics and Data Mining, Wiley series in computational statistics", "author": ["L. Billard", "E. Diday"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "S\u00e9lection d\u2019un sous ensemble de descripteurs maximalement discriminant dans une base de connaissances, 3ieme journ\u00e9e Symbolic-Numerique, Paris, pp", "author": ["J. Lebbe", "R. Vignes"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1992}, {"title": "An introduction to Symbolic Data Analysis and the Sodas Software", "author": ["E. Diday", "F. Esposito"], "venue": "IDA. International Journal on Intelligent Data Analysis\u201d. Volume 7,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Caract\u00e9risation automatique de groupes biologiques", "author": ["R. Vignes"], "venue": "Doctorate thesis of Paris VI University,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1991}, {"title": "An Attractive Leader Approach Based Clustering for Non- Symmetric Proximity", "author": ["B.B. Kiranagi", "D.S. Guru"], "venue": "Proceedings of the International Conference on Signal Processing, Communications and Networking, IEEE - ICSCN '07,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Proximity coefficients between boolean symbolic objects", "author": ["F.A.T. De Carvalho"], "venue": "New Approaches in Classification and Data Analysis,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1994}, {"title": "Generalized Minkowski metrics for mixed feature-type data analysis", "author": ["M. Ichino", "H. Yaguchi"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "A new Feature Selection Method to Extract Functional Structures from Multidimensional Symbolic Data, IEICE transactions on information and systems 81.6", "author": ["M. Ichino"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1998}, {"title": "Dimensionality reduction of symbolic data", "author": ["P. Nagabhushan", "K.C. Gowda", "E. Diday"], "venue": "Journal of Pattern Recognition Letters,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "Unsupervised feature selection scheme for clustering of symbolic data using the multivalued type similarity measure", "author": ["B.B. Kiranagi", "D.S. Guru", "N. Gudivada Venkat"], "venue": "Proceedings of the Second Workshop on Feature Selection for Data Mining, Bethesda,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Extension of the principal component analysis to interval Data", "author": ["Chouakria", "E. Diday", "P. Cazes"], "venue": "Proceedings of New Techniques and Technologies for Statistics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1995}, {"title": "Recherche de sous-ensemble minimaux de variables a partir d\u2019objets symboliques", "author": ["D. Ziani", "Z. Khalil", "R. Vignes"], "venue": "Actes of 5th international conference IPMU,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1994}, {"title": "Repr\u00e9sentation de concepts en biologie et en medicine: Introduction a l\u2019analyse de connaissances et a l\u2019identification assist\u00e9 par ordinateur", "author": ["J. Lebbe"], "venue": "Doctorate thesis of Paris VI University,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1991}], "referenceMentions": [{"referenceID": 0, "context": ", discriminant analysis); many techniques or algorithms have been proposed [1].", "startOffset": 75, "endOffset": 78}, {"referenceID": 1, "context": "With the growth of databases, it becomes very important to summarize these data by using a complex type called symbolic object [2] [3].", "startOffset": 127, "endOffset": 130}, {"referenceID": 2, "context": "With the growth of databases, it becomes very important to summarize these data by using a complex type called symbolic object [2] [3].", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "The feature selection algorithms on symbolic objects need complex calculation, since the data processed may represent classes of real individuals and each variable is not limited to one value, but may indicate a distribution of values [4].", "startOffset": 235, "endOffset": 238}, {"referenceID": 4, "context": "Before we present the algorithm, we will give some definitions of symbolic objects [5]: Y= {y1,.", "startOffset": 83, "endOffset": 86}, {"referenceID": 13, "context": "Notion of discrimination Since our feature selection algorithm criteria are based on discrimination, let us explain the discrimination on symbolic objects through the following symbolic objects: a1=[ age = [25,45]] \u2227 [weight = [65,80[ ] a2=[ age = [15,35]] \u2227 [weight = ]80,90] ] a3=[ age = [20,35]] \u2227 [weight = [70,85] ].", "startOffset": 248, "endOffset": 255}, {"referenceID": 5, "context": "\uf0b7 Vignes indice of dissimilarity [6]", "startOffset": 33, "endOffset": 36}, {"referenceID": 6, "context": "\uf0b7 Kiranagi and Guru\u2019s dissimilarity measure [7]", "startOffset": 44, "endOffset": 47}, {"referenceID": 7, "context": "\uf0b7 De Carvalho\u2019s dissimilarity measure based on potential description [8]", "startOffset": 69, "endOffset": 72}, {"referenceID": 8, "context": "\uf0b7 Ichino and Yaguchi\u2019s first formulation of a dissimilarity measure [9]", "startOffset": 68, "endOffset": 71}, {"referenceID": 9, "context": "We can cite, the algorithm of Ichino [11] uses geometrical thickness criterion to select the features, the algorithm of Nagabhushan et al.", "startOffset": 37, "endOffset": 41}, {"referenceID": 10, "context": "[12] and Kiranagi et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] select features for clustering objects using similarity between symbolic objects, and the algorithm of Chouakria et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] is for principal components.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "In our paper, we will concentrate on the algorithm of Vignes [6] called Minset, since it is the only algorithm doing feature selection on symbolic object with the purpose to discriminate between objects.", "startOffset": 61, "endOffset": 64}, {"referenceID": 13, "context": "This function can calculate both boolean and partial discrimination [15].", "startOffset": 68, "endOffset": 72}, {"referenceID": 14, "context": "Expert Validation for Biological datasets The expert assessment of Minset-Plus result has been done on datasets in biology used by Lebbe [17] and described in the Table 7.", "startOffset": 137, "endOffset": 141}, {"referenceID": 5, "context": "The Table 8 gives the names of variables selected by Minset-Plus and Minset algorithm for more details about the data see [6].", "startOffset": 122, "endOffset": 125}], "year": 2013, "abstractText": "With the boom in IT technology, the data sets used in application are more and more larger and are described by a huge number of attributes, therefore, the feature selection become an important discipline in Knowledge discovery and data mining, allowing the experts to select the most relevant features to improve the quality of their studies and to reduce the time processing of their algorithm. In addition to that, the data used by the applications become richer. They are now represented by a set of complex and structured objects, instead of simple numerical matrixes. The purpose of our algorithm is to do feature selection on rich data, called Boolean Symbolic Objects (BSOs). These objects are described by multivalued features. The BSOs are considered as higher level units which can model complex data, such as cluster of individuals, aggregated data or taxonomies. In this paper we will introduce a new feature selection criterion for BSOs, and we will explain how we improved its complexity.", "creator": "Microsoft\u00ae Office Word 2007"}}}