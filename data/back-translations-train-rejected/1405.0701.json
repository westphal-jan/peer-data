{"id": "1405.0701", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-May-2014", "title": "\"Translation can't change a name\": Using Multilingual Data for Named Entity Recognition", "abstract": "Named Entities (NEs) are often written with no orthographic changes across different languages that share a common alphabet. We show that this can be leveraged so as to improve named entity recognition (NER) by using unsupervised word clusters from secondary languages as features in state-of-the-art discriminative NER systems. We observe significant increases in performance, finding that person and location identification is particularly improved, and that phylogenetically close languages provide more valuable features than more distant languages.", "histories": [["v1", "Sun, 4 May 2014 14:23:53 GMT  (19kb,D)", "http://arxiv.org/abs/1405.0701v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["manaal faruqui"], "accepted": false, "id": "1405.0701"}, "pdf": {"name": "1405.0701.pdf", "metadata": {"source": "CRF", "title": "\u201cTranslation can\u2019t change a name\u201d: Using Multilingual Data for Named Entity Recognition", "authors": ["Manaal Faruqui"], "emails": ["mfaruqui@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "A major reason for this is the unavailability of manually labeled training data for these languages. In this paper, we address this problem by showing that even in the absence of huge amounts of training data for a particular language, unlabeled data from the same language and from other languages can be used to improve existing NER systems. Our approach follows a semi-monitored environment in which, in addition to a small amount of training data, we assume the availability of large amounts of unlabeled data from other languages written in a similar or the same font to the target language. Our approach follows a semi-monitored setting in which we assume the availability of large amounts of training data."}, {"heading": "2 Methodology", "text": "Our methodology for using secondary language data to train NER for the target language consists of two steps: (1) training word clusters of unlabeled secondary language data, (2) use the word clusters as characteristics in training the target language NER together with labeled target language data. Since designated units are not a closed word class, it is very likely that during the test period a designated unit will be encountered that was not present in the training data. To address this problem of rarity, word clusters (trained on a large, unlabeled corpus) are used as characteristics in sequence tagging problems (Clark, 2003; Faruqui and Pado, 2010; Ta \ufffd ckstro \ufffd m et al., 2012). Therefore, an undescribed unit may belong to the same word cluster as some of the seen units that reinforce the classifier's belief that it is indeed a designated unit, which improves the performance of the classifier."}, {"heading": "3 Experimental Setup", "text": "Tools: We use Stanford Named Entity Recognition system1, which uses a linear chain conditional random field to predict the most likely sequence of NE labels (Finkel and Manning, 2009). It uses a variety of characteristics, including the word, lema and POS tag of the current word and its context, ngram characteristics and word form. This system also supports the inclusion of distributional similarity characteristics, such as those we want to use in the form of word clusters. For word clusters, we use the (Clark, 2003) System2, which, in addition to standard distributional similarity characteristics, also uses morphological information about a word that uses a characteristic HMM model to identify similar words, giving it the ability to group unknown words in morphologically complex Dutch."}, {"heading": "4 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Training on monolingual clusters", "text": "Table 2 shows the F1 score of NER systems when trained with word clusters from five different languages (one after the other), and the best results are obtained when word clusters of the same language are used, and in all cases, these results are statistically highly significant (p < 0.01) according to a McNemar test (Dietterich, 1998).For English, the use of German word clusters helps to improve its performance by 1.3 F1 points, which is statistically highly significant. We observe a consistent significant improvement (p < 0.05) using3http: / / www.cnts.ua.ac.be / conll2003 / ner / 4http: / www.cnts.ua.ac.be / conll2002 / ner / 5http: / www.statmt.org / wmt12 / translation-task.htmlword cluster from French, Spanish and Czech. For a highly complex German language, we can find that any improvement from other languages is significant: wmt12 / wmtstatt.org / wmthtlword / Czech."}, {"heading": "4.2 Training on multilingual clusters", "text": "To do this, we merge the word clusters from different languages by (1) keeping all the words of the respective language intact (2) importing only those words from the secondary language that are not present in the original language (thus improving memory); while importing a foreign word, it is assigned to the word cluster that has the maximum number of words in common with its current cluster; with this technique, we merge all word clusters from different languages (German, English, French, Spanish & Czech) into a multilingual word cluster; Table 3 shows the performance of multilingual word clusters that have trained NERs against the base line of NERs. In all cases, the multilingual leadership-trained NERs perform significantly better than the base groups of NERs and also perform better than the NERs that are trained only with monolingual word clusters (see Table 2)."}, {"heading": "4.3 Training on out-of-domain clusters", "text": "The designated non-ferrous training data for all languages we use comes from the Newswire domain. Therefore, the message comment data (see paragraph 3) we use for word clustering is indomain data. As we cannot always expect to receive domain data, we use Word cluster 6 from a large collection of English tweets with approximately 850 million tokens bundled into 1000 classes for generalization purposes (Owoputi et al., 2013). Table 4 shows the performance of NER systems trained with the Twitter word clusters. Again, we achieve a highly significant improvement for English, German and French; however, the improvements achieved with out-of-domain data are less than those with indomain data. 6http: / / www.ark.cs.cmu.edu / TweetNLP /"}, {"heading": "4.4 Analysis", "text": "To verify our hypothesis that certain NEs, in particular the names of persons and places, could not undergo orthographic changes while being transferred to similar languages, we consider the categorical improvement of NER systems when trained using word clusters of a language (except itself) that yields the best results over the base model. For example, in Spanish NER, we compare the base model with the model trained using French word clusters. Table 5 shows the kateo-annoyingly improvement in the F1 value of NER systems. For all languages, the best improvement is achieved for the LOC or the PER class. On average, the highest improvement is achieved for PER, followed by LOC and least for the MISC category. The reason for the poor improvement in the MISC category is that it contains predominantly linguistically inflated forms of own nouns such as Italian, Irish, Palestinian, etc., which translate into different lexical forms in different languages."}, {"heading": "5 Related Work", "text": "Our work is primarily inspired by Faruqui and Pado \u0301 (2010), which show that a significant improvement in the performance of the German NER system can be achieved through the use of unsupervised German word clusters. NE systems have been trained using the same technique for other languages such as English (Finkel and Manning, 2009), Croatian (Glavas, et al., 2012) and Slovenian (Ljubes, ic et al., 2012). Further approaches to improving NE include transferring the linguistic structure from one language to another (Ta \u00bc ckstro \u00bc m et al., 2012; Faruqui and Dyer, 2013) by aligning word clusters across languages. Green et al. (2011) takes advantage of the fact that NEs maintain their form across languages and attempts to group NEs across language contexts. In a broader perspective, this can be described as a problem of resource division between different languages. Languages that are closely related such as Hindi and Urdu."}, {"heading": "6 Conclusion", "text": "We have shown that a statistically significant improvement in the performance of the NE system for a given language can be achieved by supplementing the training data with word clusters from a secondary language (s) written using the same alphabet.The amount of help provided by this secondary language depends on how similar the secondary language of the given language is phylogenetically and also on the domain of the data from which the word clusters are derived.This performance improvement occurs because many of the NE, especially personal names and place names in another language, remain the same, and therefore the word class information of such an OOV word is helpful in predicting its NE class."}], "references": [{"title": "Multilingual resource sharing across both related and unrelated languages: An implemented, open-source framework for practical natural language generation", "author": ["Bateman et al.2005] J. Bateman", "I. Kruijff-Korbayov", "G.-J. Kruijff"], "venue": "Research on Language", "citeRegEx": "Bateman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Bateman et al\\.", "year": 2005}, {"title": "Classbased n-gram models of natural language", "author": ["Brown et al.1992] P.F. Brown", "P.V. deSouza", "R.L. Mercer", "V.J.D. Pietra", "J.C. Lai"], "venue": "Comput. Linguist.,", "citeRegEx": "Brown et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "Combining distributional and morphological information for part of speech induction", "author": ["A. Clark"], "venue": "In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics - Volume", "citeRegEx": "Clark.,? \\Q2003\\E", "shortCiteRegEx": "Clark.", "year": 2003}, {"title": "Unsupervised part-of-speech tagging with bilingual graph-based projections", "author": ["Das", "Petrov2011] D. Das", "S. Petrov"], "venue": "Proceedings of the Association for Computational Linguistics", "citeRegEx": "Das et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Das et al\\.", "year": 2011}, {"title": "Word sense disambiguation within a multilingual framework", "author": ["M.T. Diab"], "venue": "Ph.D. thesis, University of Maryland at College", "citeRegEx": "Diab.,? \\Q2003\\E", "shortCiteRegEx": "Diab.", "year": 2003}, {"title": "Approximate statistical tests for comparing supervised classification learning algorithms", "author": ["T.G. Dietterich"], "venue": "Neural Computation,", "citeRegEx": "Dietterich.,? \\Q1998\\E", "shortCiteRegEx": "Dietterich.", "year": 1998}, {"title": "An information theoretic approach to bilingual word clustering", "author": ["Faruqui", "Dyer2013] M. Faruqui", "C. Dyer"], "venue": "In Proceedings of ACL", "citeRegEx": "Faruqui et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2013}, {"title": "Training and Evaluating a German Named Entity Recognizer with Semantic Generalization", "author": ["Faruqui", "Pad\u00f32010] M. Faruqui", "S. Pad\u00f3"], "venue": "In Proceedings of KONVENS", "citeRegEx": "Faruqui et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2010}, {"title": "Nested named entity recognition", "author": ["Finkel", "Manning2009] J.R. Finkel", "C.D. Manning"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1,", "citeRegEx": "Finkel et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Finkel et al\\.", "year": 2009}, {"title": "Croner: A state-of-the-art named entity recognition and classification for croatian", "author": ["Glava\u0161 et al.2012] G. Glava\u0161", "M. Karan", "F. \u0160aric", "J. \u0160najder", "J. Mijic", "A. \u0160ilic", "B.D. Ba\u0161ic"], "venue": null, "citeRegEx": "Glava\u0161 et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Glava\u0161 et al\\.", "year": 2012}, {"title": "Entity clustering across languages", "author": ["Green et al.2011] S. Green", "N. Andrews", "M. Gormley", "M. Dredze", "C. Manning"], "venue": null, "citeRegEx": "Green et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Green et al\\.", "year": 2011}, {"title": "Combining orthogonal monolingual and multilingual sources of evidence for all words wsd", "author": ["Guo", "Diab2010] W. Guo", "M. Diab"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Guo et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2010}, {"title": "Bootstrapping parsers via syntactic projection across parallel texts", "author": ["R. Hwa", "P. Resnik", "A. Weinberg", "C.I. Cabezas", "O. Kolak"], "venue": "Natural Language Engineering,", "citeRegEx": "Hwa et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hwa et al\\.", "year": 2005}, {"title": "Forming word classes by statistical clustering for statistical language modelling", "author": ["Kneser", "Ney1993] R. Kneser", "H. Ney"], "venue": "In R. Khler and B. Rieger, editors, Contributions to Quantitative Linguistics,", "citeRegEx": "Kneser et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Kneser et al\\.", "year": 1993}, {"title": "Simple semi-supervised dependency parsing", "author": ["Koo et al.2008] T. Koo", "X. Carreras", "M. Collins"], "venue": "In Proc. of ACL", "citeRegEx": "Koo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2008}, {"title": "Building named entity recognition models for croatian and slovene", "author": ["Ljube\u0161ic et al.2012] N. Ljube\u0161ic", "M. Stupar", "T. Juric"], "venue": null, "citeRegEx": "Ljube\u0161ic et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ljube\u0161ic et al\\.", "year": 2012}, {"title": "Improved part-of-speech tagging for online conversational text with word clusters", "author": ["Owoputi et al.2013] O. Owoputi", "B. OConnor", "C. Dyer", "K. Gimpel", "N. Schneider", "N.A. Smith"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Owoputi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Owoputi et al\\.", "year": 2013}, {"title": "Probabilistic Models of Nonprojective Dependency Trees", "author": ["Smith", "Smith2007] D.A. Smith", "N.A. Smith"], "venue": "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Lan-", "citeRegEx": "Smith et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2007}, {"title": "Unsupervised multilingual learning for pos tagging", "author": ["Snyder et al.2008] B. Snyder", "T. Naseem", "J. Eisenstein", "R. Barzilay"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Snyder et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Snyder et al\\.", "year": 2008}, {"title": "Adding more languages improves unsupervised multilingual part-of-speech tagging: a bayesian non-parametric approach", "author": ["Snyder et al.2009] B. Snyder", "T. Naseem", "J. Eisenstein", "R. Barzilay"], "venue": "In Proceedings NAACL", "citeRegEx": "Snyder et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Snyder et al\\.", "year": 2009}, {"title": "Cross-lingual word clusters for direct transfer of linguistic structure", "author": ["R. McDonald", "J. Uszkoreit"], "venue": "In The 2012 Conference of the North American Chapter of the Association for Computational Linguistics:", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? \\Q2012\\E", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2012}, {"title": "Introduction to the conll-2003 shared task: Language-independent named entity recognition", "author": ["Tjong Kim Sang", "F. De Meulder"], "venue": "Proceedings of CoNLL-2003,", "citeRegEx": "Sang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Sang et al\\.", "year": 2003}, {"title": "Introduction to the conll-2002 shared task: Language-independent named entity recognition", "author": [], "venue": "In Proceedings of CoNLL-2002,", "citeRegEx": "Sang.,? \\Q2002\\E", "shortCiteRegEx": "Sang.", "year": 2002}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["Turian et al.2010] J. Turian", "L. Ratinov", "Y. Bengio"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Turian et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Urdu and hindi: Translation and sharing of linguistic resources", "author": ["V. Chenthamarakshan", "N. Kambhatla"], "venue": "In Coling 2010: Posters,", "citeRegEx": "Visweswariah et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Visweswariah et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 1, "context": "Word clustering is widely used to reduce the number of parameters in statistical models which leads to improved generalization (Brown et al., 1992; Kneser and Ney, 1993; Koo et al., 2008).", "startOffset": 127, "endOffset": 187}, {"referenceID": 14, "context": "Word clustering is widely used to reduce the number of parameters in statistical models which leads to improved generalization (Brown et al., 1992; Kneser and Ney, 1993; Koo et al., 2008).", "startOffset": 127, "endOffset": 187}, {"referenceID": 23, "context": "Word clusters can effectively capture syntactic, semantic, or distributional regularities among the words belonging to the group (Turian et al., 2010).", "startOffset": 129, "endOffset": 150}, {"referenceID": 2, "context": "To encounter this sparsity problem, word clusters (trained on a large unlabeled corpus) are used as features in the sequence tagging problems (Clark, 2003; Faruqui and Pad\u00f3, 2010; T\u00e4ckstr\u00f6m et al., 2012).", "startOffset": 142, "endOffset": 203}, {"referenceID": 20, "context": "To encounter this sparsity problem, word clusters (trained on a large unlabeled corpus) are used as features in the sequence tagging problems (Clark, 2003; Faruqui and Pad\u00f3, 2010; T\u00e4ckstr\u00f6m et al., 2012).", "startOffset": 142, "endOffset": 203}, {"referenceID": 2, "context": "For word clustering, we use the (Clark, 2003) system2 which in addition to the standard distributional similarity features also uses morphological information about a word using a characterbased HMM model for identifying similar words .", "startOffset": 32, "endOffset": 45}, {"referenceID": 1, "context": "tributional similarity based approaches (Brown et al., 1992).", "startOffset": 40, "endOffset": 60}, {"referenceID": 5, "context": "McNemar\u2019s test (Dietterich, 1998).", "startOffset": 15, "endOffset": 33}, {"referenceID": 16, "context": "850 million tokens clustered into 1000 classes for generalization (Owoputi et al., 2013).", "startOffset": 66, "endOffset": 88}, {"referenceID": 9, "context": "other languages like English (Finkel and Manning, 2009), Croatian (Glava\u0161 et al., 2012) and Slovene (Ljube\u0161ic et al.", "startOffset": 66, "endOffset": 87}, {"referenceID": 15, "context": ", 2012) and Slovene (Ljube\u0161ic et al., 2012).", "startOffset": 20, "endOffset": 43}, {"referenceID": 20, "context": "Other approaches to enhance NER include that of transfer of linguistic structure from one language to another (T\u00e4ckstr\u00f6m et al., 2012; Faruqui and Dyer, 2013) by aligning word clusters across languages.", "startOffset": 110, "endOffset": 158}, {"referenceID": 9, "context": "other languages like English (Finkel and Manning, 2009), Croatian (Glava\u0161 et al., 2012) and Slovene (Ljube\u0161ic et al., 2012). Other approaches to enhance NER include that of transfer of linguistic structure from one language to another (T\u00e4ckstr\u00f6m et al., 2012; Faruqui and Dyer, 2013) by aligning word clusters across languages. Green et al. (2011) exploits the fact that NEs retain their shape across languages and tries to group NEs across language together.", "startOffset": 67, "endOffset": 348}, {"referenceID": 0, "context": "In a broader perspective this can be framed as a problem of resource sharing (Bateman et al., 2005) among different languages.", "startOffset": 77, "endOffset": 99}, {"referenceID": 24, "context": "closely related like Hindi and Urdu benefit from sharing resources for NLP tasks (Visweswariah et al., 2010).", "startOffset": 81, "endOffset": 108}, {"referenceID": 12, "context": "Guo and Diab, 2010) and cross-lingual annotation projection applied to bootstrapping parsers (Hwa et al., 2005; Smith and Smith, 2007).", "startOffset": 93, "endOffset": 134}, {"referenceID": 18, "context": "Multilingual guidance has also been used for training Part-ofSpeech (POS) taggers (Snyder et al., 2008; Snyder et al., 2009; Das and Petrov, 2011).", "startOffset": 82, "endOffset": 146}, {"referenceID": 19, "context": "Multilingual guidance has also been used for training Part-ofSpeech (POS) taggers (Snyder et al., 2008; Snyder et al., 2009; Das and Petrov, 2011).", "startOffset": 82, "endOffset": 146}], "year": 2014, "abstractText": "Named Entities (NEs) are often written with no orthographic changes across different languages that share a common alphabet. We show that this can be leveraged so as to improve named entity recognition (NER) by using unsupervised word clusters from secondary languages as features in state-of-the-art discriminative NER systems. We observe significant increases in performance, finding that person and location identification is particularly improved, and that phylogenetically close languages provide more valuable features than more distant languages.", "creator": "LaTeX with hyperref package"}}}