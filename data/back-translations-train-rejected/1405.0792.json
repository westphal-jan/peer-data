{"id": "1405.0792", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2014", "title": "On Exact Learning Monotone DNF from Membership Queries", "abstract": "In this paper, we study the problem of learning a monotone DNF with at most $s$ terms of size (number of variables in each term) at most $r$ ($s$ term $r$-MDNF) from membership queries. This problem is equivalent to the problem of learning a general hypergraph using hyperedge-detecting queries, a problem motivated by applications arising in chemical reactions and genome sequencing.", "histories": [["v1", "Mon, 5 May 2014 06:49:05 GMT  (14kb)", "http://arxiv.org/abs/1405.0792v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["hasan abasi", "nader h bshouty", "hanna mazzawi"], "accepted": false, "id": "1405.0792"}, "pdf": {"name": "1405.0792.pdf", "metadata": {"source": "CRF", "title": "On Exact Learning Monotone DNF from Membership Queries", "authors": ["Hasan Abasi", "Nader H. Bshouty"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 140 5.07 92v1 [cs.LG] We first present new lower limits for this problem, and then present deterministic and randomized adaptive algorithms with near-optimal query complexity. All the algorithms we present in this paper are temporally linear in query complexity and number of variables n. Moreover, all the algorithms we present in this paper are asymptotically narrow for fixed r and / or s."}, {"heading": "1 Introduction", "text": "We look at the problem of learning a monotonous DNF with a maximum of s terms, with each monotonous term containing a maximum of r variables (s-term r-MDNF) from member requests [1]. This corresponds to the problem of learning a general hypergraph using hyperedge-detecting queries, a problem motivated by applications occurring in chemical reaction and genome sequencing."}, {"heading": "1.1 Learning Hypergraph", "text": "A hypergraph is H = (V, E), where V is the set of corners and E 2V is the set of edges. The dimension of the hypergraph H is the cardinality of the largest sentence in E. In a sentence S V, the question of edge recognition QH (S) is answered with \"yes\" or \"no,\" indicating whether S contains all corners of at least one edge of H. Our learning problem is akin to learning a hidden hypergraph of dimension r by edge recognition. This problem has many applications in chemical reactions and genome sequencing. In chemical reactions, we get a series of chemicals, some of which react and others do not. If several chemicals are combined in a test tube, a reaction can be detected if and only if at least one group of the chemicals in the tube reacts. The aim is to find out which sets react with as few experiments as possible."}, {"heading": "1.2 Previous Results", "text": "In [5] Angluin and Chen presented a deterministic optimal adaptive learning algorithm for learning the s-term 2-MDNF. In [4] Angluin and Chen specified a randomized algorithm for s-term r / 2 + rs logn (the size of each term is exactly r) that makes O (24rs \u00b7 poly (r, log n))) membership requests. In [s-Term r-MDNF, where r \u2264 s is used, they specified a randomized learning algorithm that makes O (2r + r2 / 2s1 + r / 2 \u00b7 poly (log n)) membership requests. Literature has also focused on learning some subclasses of s-Term 2-MDNF. These classes have specific applications for genome sequencing. See [13, 7, 3, 4, 5] in this essay, we are all interested in learning the s-Term 2-MDNF formulas."}, {"heading": "1.3 Our Results", "text": "In this essay, we distinguish between two cases: s \u2265 r and s < r. For s < r, we first log the lower limit O (((r / s) s \u2212 1 + rs log n) and then give three algorithms. Algorithm I is a deterministic algorithm that queries O (rs \u2212 1 + rs log n) membership queries. Algorithm II is a deterministic algorithm that queries O (s \u2212 N (s \u2212 1; r) + rs log n) membership queries where N (s \u2212 1; r); sr) the size of (sr \u2212 1, r) -cover free family (see subsection 2.2 for the definition of coverage free), which can be constructed linearly in its size. A (s \u2212 1, r) -cover free family of size (r / s) algorithm is known."}, {"heading": "2 Definitions and Notations", "text": "For a vector w we use wi to denote the ith entry of w. For a positive integer j = = \u00b7 \u00b7 \u00b7 \u00b7 function j = = \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 function of {0, 1}. For an assignment a {0, 1} n we say that f in a (or a in f (a) \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 function from {0, 1} n to {0, 1} n is zero in S, if for each xi-S, a is zero in xi. Denote Xn = {x1,., xn}.For a boolean function f (xn), xn) which is f."}, {"heading": "2.1 Learning Model", "text": "Let's take a teacher (or a black box) who has a target function f: {0, 1} n \u2192 {0, 1}, that is the s-term r-MDNF. The teacher can answer membership requests, i.e., if he receives a 0, 1} n, he returns f (a). A learning algorithm is an algorithm that can ask the teacher membership requests. The goal of the learning algorithm is to learn f accurately with minimum number of membership requests and optimal time complexity. In our algorithms, for a function, we refer to f MQf as the oracle that answers membership requests, i.e. for a 0, 1} n, MQf (a) = f (a)."}, {"heading": "2.2 Cover-Free Families", "text": "The problem (n, (s, r) -blank family [12] corresponds to the following problem: A (n, (s, r) -blank family is a group A {0, 1} n, so that for each 1 \u2264 i1 < i2 < \u00b7 < id \u2264 n, where d = s + r and for each J [d] of size | J | = s there is such a group that aik = 0 for all k J and aij = 1 for all j 6 J. Use N (s; r); n) to denote the minimum size of such a group. The lower limits in [16] areN (s; r); n) \u2265 (s + r) log (s + rs) (s + rs) log n). It is known that a group of randomm = O (s), a group of randomm = O (s), a group of min (r, s) (s) (s) (s + rs) log n, a log of -z)."}, {"heading": "3 Lower Bounds", "text": "In this section we show some lower limits."}, {"heading": "3.1 General Lower Bound", "text": "In this section, we will prove that information theory is a lower limit for learning a class C from membership requests, and a lower limit for any randomized learning algorithm. We believe that this is a folkloric result, but we could not find proof of it in the literature. First, we will give the following information theory lower limit for the deterministic learning algorithm: Lemma 2. Let C be any class of Boolean function. Let C be any class of Boolean function. Then log a randomized learning algorithm (and therefore Las Vegas) that learns C with a probability of at least 3 / 4."}, {"heading": "3.2 Two Lower Bounds", "text": "In this section we specify two lower limits, the first is of [4] and the second follows with the same techniques used in [9]. In [4] Angluin and Chen have proven that theorem 4. Let r and s be integers. Let k and two integers be such that s > r, s \u2265 (k2) + 1.Any (Monte Carlo) random learning algorithm for the class of the s term r-MDNF query at least k \u2212 1 membership. In particular, if s > > r we query the lower limit r / 2) membership. Also, for each integer where (2) r + 1 \u2264 s < (12) rwe have the lower limit r \u2212 1.We now point to the lower limit, theorem 5. Let r and s integer and k."}, {"heading": "4 Optimal Algorithms for Monotone DNF", "text": "In this section, we present the algorithms (algorithm I-V) that learn the class of the s-term r-MDNF. First, we introduce a simple algorithm that learns a term, then we specify three algorithms (algorithm I-III) for case r > s and two algorithms (algorithm IV-V) for case s \u2265 r."}, {"heading": "4.1 Learning One Monotone Term", "text": "In this section we will prove the following result.Lemma 6. Let us let f (x) = M1 (M2) = M2 (M2) \u00b7 \u00b7 \u00b7 Ms be the target function where each Mi is at most a monotonous term of size. Let us suppose g (x) = M1 (M2) \u00b7 \u00b7 Ms \"and h (x) = Ms\" + 1 \"Ms\" + 2 \"\u00b7 \u00b7 Ms. If a is a task so that g (a) = 0 and h (a) = 1, then a monotonous term can be found in h (x). First, if the number of ones in a is 2r, then we can find a b (b) = 0 for each b. Our algorithm finds a minterm b (a) of f and therefore b is a minterm of h.First, if the number of ones in a is 2r, then we can find a minterm by finding each bit in one that changes the value of f and get a minterm."}, {"heading": "4.2 The case r > s", "text": "In this section we present three algorithms, two deterministic and one randomized, starting with the deterministic algorithm."}, {"heading": "4.2.1 Deterministic Algorithm", "text": "M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-M2-"}, {"heading": "4.2.2 Randomized Algorithm", "text": "Our third algorithm, Algorithm III, is a randomized algorithm. It is essentially algorithm II, where a (rs, (s \u2212 1, r)) -CFF A is constructed randomly, as in (1). Note that a (rs, (s \u2212 1, r) -CFF is also a (| V |, (s \u2212, r) -CFF, so it can be used in any round of the algorithm. The algorithm fails if there is a new term that has not been found, and this only happens if A is not (rs, (s \u2212 1, r) -CFF. So the failure probability is the same. By (1), a Monte Carlo randomized algorithm with query complexity O (\u221a s (s + rs) (r log r + log 1\u043c) + rs logn) is obtained."}, {"heading": "4.3 The case r < s", "text": "In this section we present two algorithms: Algorithm IV is deterministic and Algorithm V is randomized."}, {"heading": "4.3.1 Deterministic Algorithm", "text": "In this section, we introduce algorithm IV, which is used when r < s. In this case, we prove the following: Theorem 9. There is a deterministic learning algorithm for the class of s-term r-MDNF, that asksO (((3e) r (rs) r / 2 + 1.5 + rs log n), membership requests. Before proving this theorem, we first prove the ability to learn in simpler settings. We prove the following terms: M (x1, x2,.). Let us leave f (xn) = 1.5 + rs log n) \u00b7 \u00b7 Ms is the target s-term r-MDNF. Let's support the learning algorithm knows some of the terms h = M1. \u00b7 Ms \u2212 Ms \u2212 and knows that Ms \u2212 1 is of size r."}, {"heading": "4.3.2 Randomized Algorithm", "text": "In this section we give a randomized algorithm for case s > r. The randomized algorithm is the same as the deterministic one, except that each CFF is randomly constructed as in (1) with probability of success 1 \u2212 \u03b4 / s. We select d = 1 and get (r \u221a dsi) N (((((r \u2212 i) \u221a s / d; (r \u2212 i))); rs) \u2264 (er \u221a si) i \u221a r (e (s + 1)) r \u2212 i (2s log rs + log s\u03b4) \u2264 er2r \u2212 i (ri) i \u221a rsr / 2 (s log s + log (1 / \u03b4)) and then i = 1 (r \u221a dsi) N ((((r \u2212 i) \u221a s / d; (r \u2212 i)); rs) \u2264 r (3e) rsr / 2 (s log s + log (1 / \u03b4))."}, {"heading": "5 Conclusion and Open Problems", "text": "In this paper, we have presented an almost optimal adaptive exact learning algorithm for the class of the s-semester r-MDNF. When r and s are fixed, the boundaries are asymptotically narrow. Some gaps occur between the lower and upper boundaries. For r \u2265 s, the gap is cs for a constant c and for r \u2264 s, the gap is rr / 2. It is interesting to close these gaps. A better deterministic construction of CFF leads to better deterministic algorithms. Another difficult problem is to find narrow boundaries for the non-adaptive learning of this class."}], "references": [{"title": "Queries and Concept Learning", "author": ["D. Angluin"], "venue": "Machine Learning", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1987}, {"title": "Learning a Hidden Subgraph", "author": ["A. Alon", "V. Asodi"], "venue": "SIAM J. Discrete Math", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Learning a Hidden Matching", "author": ["N. Alon", "R. Beigel", "S. Kasif", "S. Rudich", "B. Sudakov"], "venue": "SIAM J. Comput", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Learning a Hidden Hypergraph", "author": ["D. Angluin", "J. Chen"], "venue": "Journal of Machine Learning Research", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Learning a hidden graph using O(log n) queries per edge", "author": ["D. Angluin", "J. Chen"], "venue": "J. Comput. Syst. Sci", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Algorithmic construction of sets for krestrictions", "author": ["N. Alon", "D. Moshkovitz", "S. Safra"], "venue": "ACM Transactions on Algorithms,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "An optimal procedure for gap closing in whole genome shotgun sequencing", "author": ["R. Beigel", "N. Alon", "S. Kasif", "M. Serkan Apaydin", "L. Fortnow"], "venue": "RECOMB", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Testers and their Applications", "author": ["N.H. Bshouty"], "venue": "Electronic Collouium on Computational Complexity (ECCC) 19:11,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Asking Questions to Minimize Errors", "author": ["N.H. Bshouty", "S.A. Goldman", "Thomas R. Hancock", "Sleiman Matar"], "venue": "J. Comput. Syst. Sci", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1996}, {"title": "Attribute-Efficient Learning in Query and Mistakebound Models", "author": ["N.H. Bshouty", "L. Hellerstein"], "venue": "COLT", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1996}, {"title": "Efficient Computation of Representative Sets with Applications in Parameterized and Exact Algorithms", "author": ["F.V. Fomin", "D. Lokshtanov", "S. Saurabh"], "venue": "SODA", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Nonrandom binary superimposed codes", "author": ["W.H. Kautz", "R.C. Singleton"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1964}, {"title": "Reconstructing a Hamiltonian Cycle by Querying the Graph: Application to DNA Physical Mapping", "author": ["V. Grebinski", "G. Kucherov"], "venue": "Discrete Applied Mathematics", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Families of k-independent sets", "author": ["D.J. Kleitman", "J. Spencer"], "venue": "Discrete Mathematics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1972}, {"title": "Splitters and Near-optimal Derandomization", "author": ["M. Naor", "L.J. Schulman", "A. Srinivasan"], "venue": "FOCS 95,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1995}, {"title": "Some New Bounds for Cover-free Families", "author": ["D.R. Stinson", "R. Wei", "L. Zhu"], "venue": "Journal of Combinatorial Theory, Series A,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "1 Introduction We consider the problem of learning a monotone DNF with at most s terms, where each monotone term contains at most r variables (s term r-MDNF) from membership queries [1].", "startOffset": 182, "endOffset": 185}, {"referenceID": 4, "context": "The time needed to compute which experiments to do is a secondary consideration, though it is polynomial for the algorithms we present [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 12, "context": "See [13, 7, 3, 2, 4, 5] for more details and other applications.", "startOffset": 4, "endOffset": 23}, {"referenceID": 6, "context": "See [13, 7, 3, 2, 4, 5] for more details and other applications.", "startOffset": 4, "endOffset": 23}, {"referenceID": 2, "context": "See [13, 7, 3, 2, 4, 5] for more details and other applications.", "startOffset": 4, "endOffset": 23}, {"referenceID": 1, "context": "See [13, 7, 3, 2, 4, 5] for more details and other applications.", "startOffset": 4, "endOffset": 23}, {"referenceID": 3, "context": "See [13, 7, 3, 2, 4, 5] for more details and other applications.", "startOffset": 4, "endOffset": 23}, {"referenceID": 4, "context": "See [13, 7, 3, 2, 4, 5] for more details and other applications.", "startOffset": 4, "endOffset": 23}, {"referenceID": 4, "context": "2 Previous Results In [5], Angluin and Chen presented an deterministic optimal adaptive learning algorithm for learning s-term 2-MDNF.", "startOffset": 22, "endOffset": 25}, {"referenceID": 3, "context": "In [4], Angluin and Chen gave a randomized algorithm for s-term r-uniform MDNF (the size of each term is exactly r) that asks O(24rs \u00b7 poly(r, log n)) membership queries.", "startOffset": 3, "endOffset": 6}, {"referenceID": 12, "context": "See [13, 7, 3, 2, 4, 5].", "startOffset": 4, "endOffset": 23}, {"referenceID": 6, "context": "See [13, 7, 3, 2, 4, 5].", "startOffset": 4, "endOffset": 23}, {"referenceID": 2, "context": "See [13, 7, 3, 2, 4, 5].", "startOffset": 4, "endOffset": 23}, {"referenceID": 1, "context": "See [13, 7, 3, 2, 4, 5].", "startOffset": 4, "endOffset": 23}, {"referenceID": 3, "context": "See [13, 7, 3, 2, 4, 5].", "startOffset": 4, "endOffset": 23}, {"referenceID": 4, "context": "See [13, 7, 3, 2, 4, 5].", "startOffset": 4, "endOffset": 23}, {"referenceID": 4, "context": "For the case s \u2265 r, Angluin and Chen, [5], gave the lower bound \u03a9((2s/r)r/2 + rs log n).", "startOffset": 38, "endOffset": 41}, {"referenceID": 11, "context": "2 Cover-Free Families The problem (n, (s, r))-cover-free family [12] is equivalent to the following problem: A (n, (s, r))-cover-free family is a set A \u2286 {0, 1}n such that for", "startOffset": 64, "endOffset": 68}, {"referenceID": 15, "context": "The lower bounds in [16] are", "startOffset": 20, "endOffset": 24}, {"referenceID": 7, "context": "In [8], Bshouty gave a deterministic construction of (n, (s, r))-CFF of size C := min((2e)r, (2e)s) log n = (", "startOffset": 3, "endOffset": 6}, {"referenceID": 10, "context": "in [11] gave a construction of size D := (", "startOffset": 3, "endOffset": 7}, {"referenceID": 3, "context": "The first is from [4] and the second follows using the same techniques used in [9].", "startOffset": 18, "endOffset": 21}, {"referenceID": 8, "context": "The first is from [4] and the second follows using the same techniques used in [9].", "startOffset": 79, "endOffset": 82}, {"referenceID": 3, "context": "In [4], Angluin and Chen proved, Theorem 4.", "startOffset": 3, "endOffset": 6}], "year": 2014, "abstractText": "In this paper, we study the problem of learning a monotone DNF with at most s terms of size (number of variables in each term) at most r (s term r-MDNF) from membership queries. This problem is equivalent to the problem of learning a general hypergraph using hyperedge-detecting queries, a problem motivated by applications arising in chemical reactions and genome sequencing. We first present new lower bounds for this problem and then present deterministic and randomized adaptive algorithms with query complexities that are almost optimal. All the algorithms we present in this paper run in time linear in the query complexity and the number of variables n. In addition, all of the algorithms we present in this paper are asymptotically tight for fixed r and/or s.", "creator": "LaTeX with hyperref package"}}}