{"id": "1405.0868", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2014", "title": "Finding Inner Outliers in High Dimensional Space", "abstract": "Outlier detection in a large-scale database is a significant and complex issue in knowledge discovering field. As the data distributions are obscure and uncertain in high dimensional space, most existing solutions try to solve the issue taking into account the two intuitive points: first, outliers are extremely far away from other points in high dimensional space; second, outliers are detected obviously different in projected-dimensional subspaces. However, for a complicated case that outliers are hidden inside the normal points in all dimensions, existing detection methods fail to find such inner outliers. In this paper, we propose a method with twice dimension-projections, which integrates primary subspace outlier detection and secondary point-projection between subspaces, and sums up the multiple weight values for each point. The points are computed with local density ratio separately in twice-projected dimensions. After the process, outliers are those points scoring the largest values of weight. The proposed method succeeds to find all inner outliers on the synthetic test datasets with the dimension varying from 100 to 10000. The experimental results also show that the proposed algorithm can work in low dimensional space and can achieve perfect performance in high dimensional space. As for this reason, our proposed approach has considerable potential to apply it in multimedia applications helping to process images or video with large-scale attributes.", "histories": [["v1", "Mon, 5 May 2014 12:01:14 GMT  (776kb)", "http://arxiv.org/abs/1405.0868v1", "9 pages, 9 Figures, 3 tables"]], "COMMENTS": "9 pages, 9 Figures, 3 tables", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["zhana bao"], "accepted": false, "id": "1405.0868"}, "pdf": {"name": "1405.0868.pdf", "metadata": {"source": "CRF", "title": "Finding Inner Outliers in High Dimensional Space", "authors": ["Zhana ABSTRACT"], "emails": [], "sections": [{"heading": null, "text": "Since the data distributions in high-dimensional space are opaque and uncertain, most existing solutions attempt to solve the problem taking into account the two intuitive points: First, outliers are extremely far removed from other points in high-dimensional space; second, outliers are obviously detected differently in projected, dimensional sub-spaces. However, in a complicated case where outliers are hidden in normal points in all dimensions, existing detection methods fail to find such inner outliers. In this paper, we propose a two-dimensional projection method that integrates primary outlier detection of sub-space and secondary point projection between the sub-spaces and summarizes the multiple weight values for each point. The points are calculated separately in double projected dimensions using the local density ratio. After the process, outliers are the points that achieve the greatest weight values."}, {"heading": "1. INTRODUCTION", "text": "This year, it is only a matter of time before that happens, until that happens, until an agreement is reached."}, {"heading": "2. RELATED WORKS", "text": "In the last ten years, we have been dealing with outliers in the following four groups. Methods in the first group are based on measurement of outliers. Normal values are with this method. Obviously, the points are larger than those in the second group."}, {"heading": "3. PROPOSED METHOD", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 General Idea", "text": "In fact, it is such that we shall be able to move into another world, in which we shall find ourselves in another world, in which we shall be able to change the world, in which we shall be able to live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which we shall live, in which shall live, in which we shall live, in which"}, {"heading": "3.2 Definitions and Data Structures", "text": "In this section, we present the new outlier definitions projected in our proposal, and we present necessary definitions to describe our outlier algorithms."}, {"heading": "3.3 Projected Cell Density", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "3.4 Algorithm", "text": "The detailed algorithm is shown in Figure 3, where the dataset contains n points with m dimension, and K is the number of outliers. The algorithm in Figure 3 is written in pseudo-R code. The cn is an input parameter, and the average cell density is achieved by calculation. We use the Matrix PointInfo and the Matrix CellInfo to capture the starting point and the cell data, such as point ID, cell ID and dimension ID. The PtCellid is original cell ID is used to envision the temporary cell ID In projected dimensions. The various cell ID of the point are used to establish connection between the original dimensions and the projected dimensions."}, {"heading": "4. Evaluation", "text": "The experiments and evaluations on two-dimensional data are given in Section 4.1 by comparing our proposal with the methods proposed so far, and those on high-dimensional data in Section 4.2. All experiments were conducted on MacBook Pro with 2.53GHz Intel Core 2 CPU and 4G memory. The proposed algorithm was implemented in R language on Mac OS. Normally, we need to find some test data such as experimental data or practical data to evaluate the proposed method. However, it is difficult to define which points are exact outliers and how the noise data affects the result in the real data sets, especially in the case of more than 100-dimensional datasets. Therefore, we have decided to generate a set of data to evaluate our proposal. The data sets generated include outliers and normal points according to Hawkins \"definition. The rules for generating high-dimensional artificial datasets in this paper are listed in the following section: Normal and Outlier in the Region."}, {"heading": "4.1 Two-Dimensional Data Experiment", "text": "In the two-dimensional experiment, we create 43 points, including 40 normal points and 3 outliers as in Figure 4. According to this figure, the half normal points in a region from 5 to 10 are randomly distributed in both dimensions, and the other half is randomly distributed in a region from 16 to 21 in both dimensions.The 3 points are placed as outliers in the middle of both regions, as they do not belong to a cluster of normal points. On the other hand, the purpose of designing a two-dimensional data distribution is to check our proposal whether it is effective or not even in low-dimensional space. As shown in Figure 4, the mean outlier is far removed from normal points in each dimension. Therefore, this outlier can be detected in step 1 as described in Section 3.3. Since the other two outliers are mixed with normal points in each dimension, these outliers can only be detected in the projected dimension as shorter than the algorithm proposed in Figure 3.3."}, {"heading": "4.2 High Dimensional data Experiment", "text": "In fact, we are in a position to go in search of a solution that is capable of what we are in and that is capable of finding a solution that is capable of what we are capable of, that we are in a position, that we are in, that we are in a position, that we are in a position, that we are in a position, that we are in, that we are in a position, that we are able to find the solution that we are in a position, that we are in."}, {"heading": "5. CONCLUSION", "text": "In this paper, we propose a new algorithm for outlier detection in high-dimensional space. In the experiments, our algorithm has performed better in high-dimensional datasets compared to the LOF approach. In other words, the \"curse of dimensionality\" problem has been solved to some extent in our proposed algorithm. Furthermore, our proposed solution has provided a general framework for solving similar high-dimensional problems. Therefore, many existing methods or new methods can be applied within this framework. Our proposed algorithm is a general approach to finding anomaly data in a large-scale database. Therefore, it can be applied to the multimedia field, e.g. the discovery of some remarkable images from billions of images and the designation of the new annotation on these images. This is a basic task for the Image Notation Method. The high-dimensional Data Recognition Method provides a CD."}, {"heading": "6. REFERENCES", "text": "In fact, it is such that most people are able to survive themselves, if they go into another world, if they go into another world, if they go into another world, if they go into another world, if they go into another world, if they go back to another world, if they find themselves in another world, if they go back to another world, if they go back to another world, if they go back to another world, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live them, if they live them, if they live them, if they live them, if they live them, if they live in them, if they live in them, if they live in them, if they live in them, if they go to another world, if they go to another world, if they go to another world, if they go to another world, if they go to another world, if they go to another world, if they go to another world, if they go to another world, if they go to another world, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they live in them, if they"}], "references": [{"title": "Identification of Outliers", "author": ["D. Hawkins"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1980}, {"title": "LOF: Indetify density-based local outliers", "author": ["Markus M.Breunig", "Hans-Peter Kriegel", "Raymond T.Ng", "Jorg Sander"], "venue": "LOF PCD  the Proceedings of the 2000 ACM SIGMOD international conference on Management of data(SIGMOD'00)", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2000}, {"title": "Outlier detection for high dimensional data", "author": ["Charu C.Aggarwal", "Philip S.Yu"], "venue": "In Proceedings of the 2001 ACM SIGMOD international conference on Management of data (SIGMOD '01),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2001}, {"title": "Outlier Mining in Large High-Dimensional Data Sets", "author": ["Fabrizio Angiulli", "Clara Pizzuti"], "venue": "IEEE Trans. on Knowl. and Data Eng. VOL 17, NO", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "LOCI: fast outlier detection using the local correlation integral", "author": ["Spiros Papadimitriou", "Hiroyuki Kitagawa", "Phillip B.Gibbons"], "venue": "IEEE 19 Internaitonal conference on data engineering", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Robust information theoretic clustering", "author": ["Christian Bohm", "Christos Faloutsos"], "venue": "In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining(KDD", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Outlier-robust clustering using independent components", "author": ["Christian Bohm", "Christos Faloutsos"], "venue": "Proceedings of the 2008 ACM SIGMOD international conference on Management of data", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "CURIO: A fast outlier and outlier cluster detection algorithm for larger datasets. AIDM '07", "author": ["Aaron Ceglar", "John F.Roddick", "David M.W.Powers"], "venue": "Proceedings of the 2nd international workshop on Integrating artificial intelligence and data mining,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Outlier detection by active learning. InProceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '06)", "author": ["Naoki Abe", "Bianca Zadrozny", "John Langford"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "Subspace clusting for high dimensional data: a review", "author": ["Lance Parsons", "Ehtesham Haque", "Huan Liu"], "venue": "ACM SIGKDD Explorations Newsletter-Special issue on learning from imbalanced datasets. Volume 6 Issue", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Optimal gridclustering:Towards breaking the curse of dimensionality in high dimensional clustering", "author": ["Alexander Hinneburg", "Daniel A. Keim"], "venue": "The 25 VLDB conference", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "Multiple outelier detection in multivariate data using self-organizing maps title", "author": ["Ashok K. Nag", "Amit Mitra"], "venue": "Computational Statistics", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "The self-organizing map", "author": ["Teuvo kohonen"], "venue": "Proceedings of the IEEE,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1990}, {"title": "Outlier Identification in High Dimensions", "author": ["Peter Filzmoser", "Ricardo Maronna", "Mark Werner"], "venue": "Computational Statistics & Data Analysis. Vol", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Fast Mining of Distance-Based Outliers in High-Dimensional Dataset", "author": ["Amol Ghoting"], "venue": "IEEE Trans. on Knowl. and Data Eng", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "Statistical outlier detection using direct density ratio estimation", "author": ["Shohei Hido"], "venue": "Knowledge and Information Systems. vol.26,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "Though many researchers have mentioned various outlier definitions, the most cited definition is Hawkins\u2019: an outlier is an observation that deviates so much from other observations as to arouse suspicion that it generated by a different mechanism [1].", "startOffset": 248, "endOffset": 251}, {"referenceID": 3, "context": "The first solution includes Hilout[4], LOCI[6], GridLOF[19], ABOD[5], etc.", "startOffset": 34, "endOffset": 37}, {"referenceID": 4, "context": "The first solution includes Hilout[4], LOCI[6], GridLOF[19], ABOD[5], etc.", "startOffset": 43, "endOffset": 46}, {"referenceID": 2, "context": "The second solution includes Aggarwal\u2019s Fraction[3], GLS-SOD[10], CURIO[9], SPOT[13], Grid-Clustering[19], etc.", "startOffset": 48, "endOffset": 51}, {"referenceID": 7, "context": "The second solution includes Aggarwal\u2019s Fraction[3], GLS-SOD[10], CURIO[9], SPOT[13], Grid-Clustering[19], etc.", "startOffset": 71, "endOffset": 74}, {"referenceID": 1, "context": "The most used method is based on local density-LOF[2].", "startOffset": 50, "endOffset": 53}, {"referenceID": 2, "context": "The Aggarwal\u2019s method [3] belongs to this group.", "startOffset": 22, "endOffset": 25}, {"referenceID": 11, "context": "The methods in the third group are the outlier detection with dimension deduction, such as SOM (Self-Organizing Map) [17, 18], mapping several dimensions to two dimensions, and then detecting outliers in two dimensional space.", "startOffset": 117, "endOffset": 125}, {"referenceID": 12, "context": "The methods in the third group are the outlier detection with dimension deduction, such as SOM (Self-Organizing Map) [17, 18], mapping several dimensions to two dimensions, and then detecting outliers in two dimensional space.", "startOffset": 117, "endOffset": 125}, {"referenceID": 5, "context": "The forth group includes other methods such as ABOD [5] and RIC[7, 8].", "startOffset": 63, "endOffset": 69}, {"referenceID": 6, "context": "The forth group includes other methods such as ABOD [5] and RIC[7, 8].", "startOffset": 63, "endOffset": 69}, {"referenceID": 1, "context": "To evaluate the experimental results, we compare our proposal with the well known algorithm LOF[2] and LOCI[6].", "startOffset": 95, "endOffset": 98}, {"referenceID": 4, "context": "To evaluate the experimental results, we compare our proposal with the well known algorithm LOF[2] and LOCI[6].", "startOffset": 107, "endOffset": 110}, {"referenceID": 0, "context": "In order to generate suitable experimental datasets, we refer to Hawkins\u2019outlier definition [1] and Kriegel\u2019s dataset model [4].", "startOffset": 92, "endOffset": 95}, {"referenceID": 3, "context": "In order to generate suitable experimental datasets, we refer to Hawkins\u2019outlier definition [1] and Kriegel\u2019s dataset model [4].", "startOffset": 124, "endOffset": 127}], "year": 2014, "abstractText": "Outlier detection in a large-scale database is a significant and complex issue in knowledge discovering field. As the data distributions are obscure and uncertain in high dimensional space, most existing solutions try to solve the issue taking into account the two intuitive points: first, outliers are extremely far away from other points in high dimensional space; second, outliers are detected obviously different in projected-dimensional subspaces. However, for a complicated case that outliers are hidden inside the normal points in all dimensions, existing detection methods fail to find such inner outliers. In this paper, we propose a method with twice dimension-projections, which integrates primary subspace outlier detection and secondary point-projection between subspaces, and sums up the multiple weight values for each point. The points are computed with local density ratio separately in twice-projected dimensions. After the process, outliers are those points scoring the largest values of weight. The proposed method succeeds to find all inner outliers on the synthetic test datasets with the dimension varying from 100 to 10000. The experimental results also show that the proposed algorithm can work in low dimensional space and can achieve perfect performance in high dimensional space. As for this reason, our proposed approach has considerable potential to apply it in multimedia applications helping to process images or video with large-scale attributes.", "creator": "Microsoft\u00ae Word 2010"}}}