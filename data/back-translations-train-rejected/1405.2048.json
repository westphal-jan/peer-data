{"id": "1405.2048", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2014", "title": "Learning Alternative Name Spellings", "abstract": "Name matching is a key component of systems for entity resolution or record linkage. Alternative spellings of the same names are a com- mon occurrence in many applications. We use the largest collection of genealogy person records in the world together with user search query logs to build name matching models. The procedure for building a crowd-sourced training set is outlined together with the presentation of our method. We cast the problem of learning alternative spellings as a machine translation problem at the character level. We use in- formation retrieval evaluation methodology to show that this method substantially outperforms on our data a number of standard well known phonetic and string similarity methods in terms of precision and re- call. Additionally, we rigorously compare the performance of standard methods when compared with each other. Our result can lead to a significant practical impact in entity resolution applications.", "histories": [["v1", "Wed, 7 May 2014 19:47:51 GMT  (727kb,D)", "http://arxiv.org/abs/1405.2048v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["jeffrey sukharev", "leonid zhukov", "alexandrin popescul"], "accepted": false, "id": "1405.2048"}, "pdf": {"name": "1405.2048.pdf", "metadata": {"source": "CRF", "title": "Learning Alternative Name Spellings", "authors": ["Jeffrey Sukharev", "Leonid Zhukov", "Alexandrin Popescul"], "emails": ["jsukharev@ancestry.com", "lzhukov@ancestry.com", "apopescul@ancestry.com"], "sections": [{"heading": "1 Introduction", "text": "This year, as never before in the history of a country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a city, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country"}, {"heading": "2 Previous work", "text": "The classical reference in the field of record linkage is an essay by Fellegi and Sunter published in 1969. [14] In their work, the authors carefully set out the theory of record matching, which defines the terms positive disposition (link and non-link) and negative disposition (possible link), and showed that the rule of optimal record matching would minimize the possibility of neglecting a positive disposition for fixed error levels. Since this groundbreaking work, there has been an increase in work in this area. In the interest of brevity, we refer the reader to the excellent survey article by Winkler from 2006 [32] and the comprehensive work by Christen [10], which has just been published. Given the explosive growth of data coming from web applications, it is imperative to discover the best methods for record matching in terms of accuracy and speed. Historically, methods focusing on name comparisons could be divided into two classes of: sequence-23 and sequence-Sunter."}, {"heading": "2.1 Sequential Character methods", "text": "The key concept of phonetic methods is the mapping of n-grams of characters into phonetic equivalents. Outputting the use of these methods on string pairs is a binary decision and not a degree of similarity. The most well-known methods from this class are Soundex [28], and NYSIIS [30]. While these methods prove useful to improve the performance of data matching applications, they do not solve the problem of relevance ranking of alternative spellings, which are of great importance to search engines when using alternative name letters."}, {"heading": "2.2 Bag-of-words methods", "text": "In the last ten years, numerous studies have been published on the subject of the use of vocabulary bags for recording links [23]. The cosinal similarity of the term frequency of inverse document frequency (TFIDF) weighted vectors is one of the most popular methods of its kind. Typical vectors consist of single words or n-grams. The main deficiency of the cosinal similarity TFIDF is that this method requires exact matches between fields. To alleviate this problem, Kosinus similarity SoftTFIDF was introduced by Cohen et. al. [11]. In addition to counting identical fields occurring in both vectors, SoftTFIDF compares and tracks \"similar\" fields in both vectors. Bilenko et. al. [3] showed how machine learning methods could be successfully applied to learn the combined field similarity. They trained an SVM classifier using feature vectors and then converted the learned word classifier into the individual data sets we consider more reliable in the first place."}, {"heading": "2.3 Spelling correction and Machine Translation literature", "text": "The basic idea was to find the best possible correction by optimizing the product of the language model (a previous probability of letters / phrases / words in a given language) and the proofreading model (the probability that one word will be spelled as another). [17] In recent decades, machine translation methods have gained considerable traction and recently found their way into the problem of spell-checking. In 2007, Bhagat et. al. [2] introduced a positive letter-based method for identifying alternative name letters and language processing books. [17] In recent decades, machine translation methods have gained significant traction and recently found their way into the problem of name-correcting."}, {"heading": "3 Datasets", "text": "This year, it has come to the point where one feels able to drown the aforementioned lcihsrcnlrVo in order to stir and stir it."}, {"heading": "4 Methods", "text": "\"The problem of the search for the best alternative name is that we see ourselves in a position to maximize the probability.\" (tname) \"We,\" as it is said in the translation, \"must\" be in the way. \"(tname)\" We, \"\" we, \"\" we, \"\" we, \"\" we, \"\" we, \"\" we, \"\" we, \"\" we, \"\" \"we,\" \"we,\" \"we,\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we,\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we,\" \"we,\" \"\" we, \"\" we, \"\" we, \"\" we, \"\" we, \"\" \"we,\" \"we,\" \"we,\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we,\" \"\" we, \"\" \"we."}, {"heading": "5 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Data Preparation", "text": "Since we were dealing with user-generated data, we had to develop an algorithm for handling the data and creating a training set for high security. We outlined the following procedure: 13operations \"Search\" ops type% \"Records\" ops type% deletes 32.18% 38.18% insert 33.91% 20.65% replaced 33.91% 41.47% 14T h o o u g h o dT h o o g o d"}, {"heading": "5.2 Experiments and results", "text": "Comparing phonetic methods with similarity measurements and machine translation methods is not easy. Phonetic methods only allow binary reactions (match or mismatch) when applied to name pairs. Therefore, it is impossible to evaluate positive matches without introducing additional ranking criteria. Our Machine Translation (MT) method produces a result that we use in the ranking. Similarity methods produce a similarity value that is also used in the ranking. To get a meaningful comparison of these methods with phonetic methods, we had to apply statistics while collecting processing data. In addition, we developed a uniform methodology that could be applied to all the types of methods listed. In all of our experiments, we used 10-fold cross-validation to evaluate how the results of predictions are generalized to evaluate previously unseen data. We divided each dataset (\"search\" and \"records\") into ten folds."}, {"heading": "5.3 Implementation details", "text": "We imported our records / tree records into CDH4 Cloudera Hadoop and filtered all our records using Hive / Python scripts and Java implementations. The Christian-implemented Febrl library [9] was used to calculate phonetic codes and string similarity values. 18Country Unique Names England 9341 Germany 5679 France 1233 Ireland 981 Scotland 647 Russia 448 Italy 426 Switzerland 377 Norway 376 Netherlands 300 Other 3779Table 4: \"Records\" Country Number Unique Names England 6690 Germany 1323 Ireland 900 France 631 Scotland 468 Russia 241 Italy 157 Sweden 109 Poland 90 Switzerland 83 Other 727Table 5: \"Search\" Record"}, {"heading": "6 Discussion and Conclusion", "text": "In this paper, we presented a novel approach to the problem of alternative name spelling. We used a well-known methodology for comparing alternative name spelling methods and presented our results as accurate call charts that clearly indicate that machine translation methods appear to be superior to other methods, but also show the ranking of other known methods. We demonstrated our results using a unique Ancestry.com dataset created by millions of motivated users who are \"experts\" in the labeling of the datasets. The main conclusion of this work is that machine translation methods we used to find a ranking of alternative spellings for surnames far outperformed all other methods we tried. Our results also showed that the NYSIIS phonetic method did not perform as well as our data on other phonetic algorithms and the phonetic method Phonex."}], "references": [{"title": "Phonetic models for generating spelling variants", "author": ["R. Bhagat", "E.H. Hovy"], "venue": "M. M. Veloso, editor, IJCAI, pages 1570\u20131575,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Adaptive name matching in information integration", "author": ["M. Bilenko", "R. Mooney", "W. Cohen", "P. Ravikumar", "S. Fienberg"], "venue": "Intelligent Systems, IEEE, 18(5):16\u201323,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "Adaptive duplicate detection using learnable string similarity measures", "author": ["M. Bilenko", "R.J. Mooney"], "venue": "In Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-2003, pages 39\u201348,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Use of latent semantic indexing to identify name variants in large data collections", "author": ["R.B. Bradford"], "venue": "ISI, pages 27\u201332,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "A statistical approach to machine translation", "author": ["P.F. Brown", "J. Cocke", "S.A.D. Pietra", "V.J.D. Pietra", "F. Jelinek", "J.D. Lafferty", "R.L. Mercer", "P.S. Roossin"], "venue": "Comput. Linguist., 16(2):79\u201385, June", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1990}, {"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["P.F. Brown", "V.J. Pietra", "S.A.D. Pietra", "R.L. Mercer"], "venue": "Computational Linguistics, 19:263\u2013311,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1993}, {"title": "A comparison of personal name matching: Techniques and practical issues", "author": ["P. Christen"], "venue": "Data Mining Workshops, 2006. ICDM Workshops 2006. Sixth IEEE International Conference on, pages 290\u2013294. IEEE,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Febrl \u2013 an open source data cleaning, deduplication and record linkage system with a graphical user interface (demonstration session", "author": ["P. Christen"], "venue": "In ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD\u201908, pages 1065\u20131068,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "Data Matching: Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection", "author": ["P. Christen"], "venue": "Data-centric systems and applications. Springer,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "A comparison of string distance metrics for name-matching tasks", "author": ["W.W. Cohen", "P. Ravikumar", "S.E. Fienberg"], "venue": "pages 73\u201378,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "Maximum likelihood from incomplete data via the em algorithm", "author": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pages 1\u201338,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1977}, {"title": "IRSTLM: an open source toolkit for handling large scale language models", "author": ["M. Federico", "N. Bertoldi", "M. Cettolo"], "venue": "INTERSPEECH, pages 1618\u20131621. ISCA,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "A theory for record linkage", "author": ["I.P. Fellegi", "A.B. Sunter"], "venue": "Journal of the American Statistical Association, 64(328):1183\u20131210,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1969}, {"title": "The CMA evolution strategy", "author": ["N. Hansen"], "venue": "A tutorial,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Advances in record-linkage methodology as applied to matching the 1985 census of Tampa, Florida", "author": ["M.A. Jaro"], "venue": "Journal of the American Statistical Association, 84(406):414\u2013420,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1989}, {"title": "Speech and language processing: An introduction to speech recognition", "author": ["D. Jurafsky", "J.H. Martin"], "venue": "Computational Linguistics and Natural Language Processing. 2nd Edn., Prentice Hall, ISBN, 10(0131873210):794\u2013800,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "A spelling correction program based on a noisy channel model", "author": ["M.D. Kernighan", "K.W. Church", "W.A. Gale"], "venue": "Proceedings of the 13th conference on Computational linguistics-Volume 2, pages 205\u2013210. Association for Computational Linguistics,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1990}, {"title": "Moses: Open source toolkit for statistical machine translation", "author": ["P. Koehn", "H. Hoang", "A. Birch", "C. Callison-Burch", "M. Federico", "N. Bertoldi", "B. Cowan", "W. Shen", "C. Moran", "R. Zens", "C. Dyer", "O. Bojar", "A. Constantin", "E. Herbst"], "venue": "Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL \u201907, pages 177\u2013180, Stroudsburg, PA, USA,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Binary codes capable of correcting deletions, insertions and reversals", "author": ["V.I. Levenshtein"], "venue": "Soviet Physics Doklady, 10(8):707\u2013710, February", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1966}, {"title": "Confidence Bands for ROC Curves: Methods and an Empirical Study", "author": ["S.A. Macskassy", "F.J. Provost"], "venue": "ROC Analysis in Artificial Intelligence, pages 61\u201370,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "A conditional random field for discriminatively-trained finite-state string edit distance", "author": ["A. McCallum", "K. Bellare", "F.C.N. Pereira"], "venue": "UAI, pages 388\u2013395. AUAI Press,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2005}, {"title": "Robust similarity measures for named entities matching", "author": ["E. Moreau", "F. Yvon", "O. Cappe"], "venue": "D. Scott and H. Uszkoreit, editors, COL- ING, pages 593\u2013600,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "A systematic comparison of various statistical alignment models", "author": ["F.J. Och", "H. Ney"], "venue": "Computational Linguistics, 29(1):19\u201351,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "Retrieval effectiveness of proper name search methods", "author": ["U. Pfeifer", "T. Poersch", "N. Fuhr"], "venue": "Information Processing and Management, pages 667\u2013679,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1996}, {"title": "Hanging on the metaphone", "author": ["L. Philips"], "venue": "Computer Language Magazine, 7(12):39\u201344, December", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1990}, {"title": "Learning string edit distance", "author": ["E.S. Ristad", "P.N. Yianilos"], "venue": "CoRR, cmp-lg/9610005,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1996}, {"title": "Soundex", "author": ["R. Russell"], "venue": "U.S. Patent 1,261,167, 04", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1918}, {"title": "A mathematical theory of communication", "author": ["C. Shannon"], "venue": "Bell System Technical Journal, 27:379\u2013423, 623\u2013656, July, October", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1948}, {"title": "Name search techniques", "author": ["R.L. Taft"], "venue": "Technical Report Special Report No. 1, New York State Identification and Intelligence System, Albany, NY, February", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1970}, {"title": "String comparator metrics and enhanced decision rules in the fellegi-sunter model of record linkage", "author": ["W.E. Winkler"], "venue": "Proceedings of the Section on Survey Research, pages 354\u2013359,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1990}, {"title": "Overview of record linkage and current research directions", "author": ["W.E. Winkler"], "venue": "Technical report, Bureau of the Census,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 12, "context": "The classic reference in the field of record linkage is a paper by Fellegi and Sunter [14] published in 1969.", "startOffset": 86, "endOffset": 90}, {"referenceID": 30, "context": "In the interest of brevity we direct the reader to the outstanding 2006 survey paper by Winkler [32] and to the comprehensive work by Christen [10] published just recently.", "startOffset": 96, "endOffset": 100}, {"referenceID": 8, "context": "In the interest of brevity we direct the reader to the outstanding 2006 survey paper by Winkler [32] and to the comprehensive work by Christen [10] published just recently.", "startOffset": 143, "endOffset": 147}, {"referenceID": 21, "context": "Historically, methods focusing on name matching could be separated into two classes: sequential character methods and bag-of-words methods [23].", "startOffset": 139, "endOffset": 143}, {"referenceID": 26, "context": "The bestknown method from this class is Soundex [28].", "startOffset": 48, "endOffset": 52}, {"referenceID": 26, "context": "Popular methods include Soundex [28], Double Metaphon [26], and NYSIIS [30].", "startOffset": 32, "endOffset": 36}, {"referenceID": 24, "context": "Popular methods include Soundex [28], Double Metaphon [26], and NYSIIS [30].", "startOffset": 54, "endOffset": 58}, {"referenceID": 28, "context": "Popular methods include Soundex [28], Double Metaphon [26], and NYSIIS [30].", "startOffset": 71, "endOffset": 75}, {"referenceID": 18, "context": "Similarity method based on edit distance (the Levenshtein distance, as it is also known [20]) is the most well-known method of this type.", "startOffset": 88, "endOffset": 92}, {"referenceID": 14, "context": "Other common similarity measures include the Jaro [16] method which takes into account the number and order of common characters between two strings and the Jaro-Winkler [31] method which extends Jaro by accounting for the common prefixes in both strings [3], [10].", "startOffset": 50, "endOffset": 54}, {"referenceID": 29, "context": "Other common similarity measures include the Jaro [16] method which takes into account the number and order of common characters between two strings and the Jaro-Winkler [31] method which extends Jaro by accounting for the common prefixes in both strings [3], [10].", "startOffset": 170, "endOffset": 174}, {"referenceID": 1, "context": "Other common similarity measures include the Jaro [16] method which takes into account the number and order of common characters between two strings and the Jaro-Winkler [31] method which extends Jaro by accounting for the common prefixes in both strings [3], [10].", "startOffset": 255, "endOffset": 258}, {"referenceID": 8, "context": "Other common similarity measures include the Jaro [16] method which takes into account the number and order of common characters between two strings and the Jaro-Winkler [31] method which extends Jaro by accounting for the common prefixes in both strings [3], [10].", "startOffset": 260, "endOffset": 264}, {"referenceID": 3, "context": "In 2013 Bradford [5] published a paper dealing with alternative name spelling generation.", "startOffset": 17, "endOffset": 20}, {"referenceID": 21, "context": "There were numerous studies published on the topic of applying bags of words to record linkage over the last decade [23].", "startOffset": 116, "endOffset": 120}, {"referenceID": 9, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[3] showed how machine learning methods could be successfully employed for learning the combined field similarity.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "[18] in their short paper proposed a method for spelling corrections based on noisy channels.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] In the last several decades machine translation methods have gained significant traction and recently found their way into the problem of name matching.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[2] implemented a transducer based method for finding alternative name spellings by employing a graphemesto-phonemes framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "Their method involved running EM (expectation maximization) algorithm, first presented by Dempster [12], to align text from the CMU dictionary with their phoneme sequence equivalents.", "startOffset": 99, "endOffset": 103}, {"referenceID": 23, "context": "Using both-ways translation models and language models, the authors were able to generate alternative phoneme sequences (pronunciations), given a character string name, and then each of these sequences was converted into an alternative character sequence [25].", "startOffset": 255, "endOffset": 259}, {"referenceID": 25, "context": "In 1996 Ristad and Yianilos [27] presented an interesting solution where they learned the cost of edit distance operations, which are normally all set to one in static edit distance algorithms.", "startOffset": 28, "endOffset": 32}, {"referenceID": 2, "context": "[4] improved on Ristad and Yianilos\u2019s learned edit distance model by including affine gaps.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "[22] in 2005 approached the same problem from the different angle.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "Instead of using generative models like [27] and [4] they have used discriminative method, conditional random fields (CRF), where they have been able to use both positive and negative string pairs for training.", "startOffset": 40, "endOffset": 44}, {"referenceID": 2, "context": "Instead of using generative models like [27] and [4] they have used discriminative method, conditional random fields (CRF), where they have been able to use both positive and negative string pairs for training.", "startOffset": 49, "endOffset": 52}, {"referenceID": 4, "context": "Following the traditions of statistical machine translation methods [6] this probability can be expressed using Bayes\u2019 rule as", "startOffset": 68, "endOffset": 71}, {"referenceID": 27, "context": "\u201dName model\u201d can be estimated using character n-grams language model representation by finding the probabilities using the chain rule [29]):", "startOffset": 134, "endOffset": 138}, {"referenceID": 4, "context": "P (sname|tname) allows us to get a theoretically good translation even if underlying probabilities are not that accurate [6].", "startOffset": 121, "endOffset": 124}, {"referenceID": 17, "context": "For training of our language and alignment models we have chosen the Moses software package which is a widely known open-source statistical machine translation software package [19].", "startOffset": 177, "endOffset": 181}, {"referenceID": 11, "context": "We used IRSTLM [13], a statistical language model tool for this purpose.", "startOffset": 15, "endOffset": 19}, {"referenceID": 22, "context": "Alignment model building: Moses uses the GIZA++ package for statistical character-alignment [24] character (Word)-alignment tools typically implement one of Brown\u2019s IBM generative models [7] that are being used for determining translation rules for source language to the target language (including fertility rules: maximum number of target characters generated from one source character and so on) We created alignment model, for each of the 2-gram through 6-gram language models created in the previous step.", "startOffset": 92, "endOffset": 96}, {"referenceID": 5, "context": "Alignment model building: Moses uses the GIZA++ package for statistical character-alignment [24] character (Word)-alignment tools typically implement one of Brown\u2019s IBM generative models [7] that are being used for determining translation rules for source language to the target language (including fertility rules: maximum number of target characters generated from one source character and so on) We created alignment model, for each of the 2-gram through 6-gram language models created in the previous step.", "startOffset": 187, "endOffset": 190}, {"referenceID": 19, "context": "Inspired by the work of [21] we designed our own methodology for robust statistical comparisons of our precision-recall curves.", "startOffset": 24, "endOffset": 28}, {"referenceID": 13, "context": "The eigenvectors of the covariance matrix \u03a3 are used as directions of the principal axes of the Gaussian ellipses [15].", "startOffset": 114, "endOffset": 118}, {"referenceID": 28, "context": "NYSIIS phonetic method, first introduced by Taft in 1970 [30] significantly outperforms other phonetic methods.", "startOffset": 57, "endOffset": 61}, {"referenceID": 7, "context": "The Febrl library [9] implemented by Christen was used for calculating phonetic codes and string similarity values.", "startOffset": 18, "endOffset": 21}, {"referenceID": 6, "context": "Our finding regarding phonetic methods performance went against findings reported by Christen in his 2006 paper [8].", "startOffset": 112, "endOffset": 115}], "year": 2014, "abstractText": "Name matching is a key component of systems for entity resolution or record linkage. Alternative spellings of the same names are a common occurrence in many applications. We use the largest collection of genealogy person records in the world together with user search query logs to build name matching models. The procedure for building a crowd-sourced training set is outlined together with the presentation of our method. We cast the problem of learning alternative spellings as a machine translation problem at the character level. We use information retrieval evaluation methodology to show that this method substantially outperforms on our data a number of standard well known phonetic and string similarity methods in terms of precision and recall. Additionally, we rigorously compare the performance of standard methods when compared with each other. Our result can lead to a significant practical impact in entity resolution applications.", "creator": "LaTeX with hyperref package"}}}