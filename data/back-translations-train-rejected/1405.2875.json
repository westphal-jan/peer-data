{"id": "1405.2875", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-May-2014", "title": "Adaptive Contract Design for Crowdsourcing Markets: Bandit Algorithms for Repeated Principal-Agent Problems", "abstract": "Crowdsourcing markets have emerged as a popular platform for matching available workers with tasks to complete. The payment for a particular task is typically set by the task's requester, and may be adjusted based on the quality of the completed work, for example, through the use of \"bonus\" payments. In this paper, we study the requester's problem of dynamically adjusting quality-contingent payments for tasks. We consider a multi-round version of the well-known principal-agent model, whereby in each round a worker makes a strategic choice of the effort level which is not directly observable by the requester. In particular, our formulation significantly generalizes the budget-free online task pricing problems studied in prior work.", "histories": [["v1", "Mon, 12 May 2014 18:52:28 GMT  (164kb)", "https://arxiv.org/abs/1405.2875v1", "This is the full version of a paper in the ACM Conference on Economics and Computation (ACM-EC), 2014"], ["v2", "Wed, 2 Sep 2015 04:21:07 GMT  (166kb)", "http://arxiv.org/abs/1405.2875v2", "This is the full version of a paper in the ACM Conference on Economics and Computation (ACM-EC), 2014"]], "COMMENTS": "This is the full version of a paper in the ACM Conference on Economics and Computation (ACM-EC), 2014", "reviews": [], "SUBJECTS": "cs.DS cs.GT cs.LG", "authors": ["chien-ju ho", "aleksandrs slivkins", "jennifer wortman vaughan"], "accepted": false, "id": "1405.2875"}, "pdf": {"name": "1405.2875.pdf", "metadata": {"source": "CRF", "title": "Adaptive Contract Design for Crowdsourcing Markets: Bandit Algorithms for Repeated Principal-Agent Problems\u2217", "authors": ["Chien-Ju Ho", "Aleksandrs Slivkins", "Jennifer Wortman Vaughan"], "emails": ["cjho@ucla.edu.", "slivkins@microsoft.com.", "jenn@microsoft.com."], "sections": [{"heading": null, "text": "ar Xiv: 140 5.28 75v2 [cs.DS] 2S epWe treat this problem as a multi-armed bandit problem, with each \"arm\" representing a potential contract. To cope with the large (and indeed infinite) number of weapons, we propose a new algorithm, AgnosticZooming, which splits the contract area into a limited number of regions, effectively treating each region as a single arm. This discrediting is adaptively refined so that more promising regions of the contract area are eventually discredited more finely. We analyze this algorithm and show that it achieves a sublinear regret over time horizon and significantly improves non-adaptive discrediting (which is the only competing approach in the literature). Our results advance the state of the art on several different topics: the theory of crowdsourcing markets, principal-agent problems, multi-armed bandits, and dynamic pricing."}, {"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Our setting: the dynamic contract design problem", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "2.1 Discussion", "text": "This is important in practice, as the quality of the work submitted is typically difficult to judge in a very fine granularity. Although, in practice, it is difficult to comply with the dynamic pricing problem of Kleinberg and Leighton (2003a), this limitation is not without its generality: there are problem instances where monotonous contracts are not optimal; see Appendix A for an example. Furthermore, it is not clear whether monotonous contracts under monotonous contracts are optimal. Our benchmark OPT (Xcand) is relative to a given Xcand sentence, which is typically a limited discrediting of the contract space."}, {"heading": "3.1 Discretization of the action space", "text": "In each round, the AgnosticZooming algorithm divides the action space into several regions and selects between these regions, effectively treating each region as a \"meta arm.\" In this section, we discuss which subsets of the action space are used as regions and introduce some useful terms and characteristics of such subareas. Incremental space and cells. To describe our approach to discretization, it is useful to think of contracts in terms of incremental payments \u2212 in particular, we present each monotonous contract x: O \u2192 [0, \u221e) as vector x [0, \u221e) m, where m represents the number of non-incremental results and x\u03c0 = x (\u03c0 \u2212 1) \u2265 0 for each non-incremental result x. (Let's call this by convention 0 is the zero result and x (0) = 0. We call this vector the incremental representation of the contract x, and denote it incr (x)."}, {"heading": "3.2 Description of the algorithm", "text": "The algorithm maintains a series of active cells that cover incremental space at all times. Initially, there is only one active cell that covers the entire incremental space. At each turn, the algorithm will select an active cell that uses an active cell Ct and activates all relevant quadrants of cell C, with the quadrants of cell C being randomly sampled in uniform under the anchors of that cell. After considering the feedback, the algorithm can choose whether to zoom in the cell Ct, remove the Ct from the set of active cells, and activate all relevant quadrants of cell C, defining the quadrants of cell C as half the size for which one of the corners is the center of C. In the reissue of this section, we specify how the cell Ct is selected (the selection rule), and how the algorithm decides whether it is zoomed in the cell."}, {"heading": "3.3 Proof of Lemma 3.1 (virtual width)", "text": "\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "4 Regret bounds and discussion", "text": "We present the main regret of an expected usability difference between an optimal candidate and an optimal contract: \"We are the expected cumulative utility of algorithms (x).We represent the main regret of an optimal usability of algorithms (x).We represent the main need of algorithms (x).We represent the main need of algorithms (x).We represent the main need of algorithms (x).We represent the main need of algorithms (xcand).We represent the main need of algorithms (xcand).U is the expected utility of algorithms (x).U is the expected utility of algorithms (x).U is the expected utility of algorithms (xcand).U is the expected cumulative utility of algorithms (x).X The difference in the expected utility between an optimal candidate and an optimal candidate (xcand).U is the expected cumulative utility of algorithms (x)."}, {"heading": "4.1 Comparison to prior work", "text": "One approach from the previous paper that is directly applicable to dynamic contract design is non-adaptive discrediting. This is an algorithm called NonAdaptive, which can apply an off-the-shelf algorithm that a number of contract contenders Xcand as arms.7 For concreteness, and following on from the previous paper [Kleinberg and Leighton, 2003a, Kleinberg et al., 2008] we use a well-known UCB1 algorithm [Auer et al, 2002] as off-the-shelf MAB algorithms. To compare AgnosticZooming with NonAdaptive, it is useful to derive several worst-case corollaries of Theorem 4.1, replacing the Nacional (XLose) with various (loose) ceilings. 8Corollary 4.3, the regret of AgnosticZooming can be considered as an upper limit."}, {"heading": "5 A special case: the \u201chigh-low example\u201d", "text": "We apply the machinery in Section 4 to a special case, and we show that AgnosticZooming works significantly better than NonAdaptive.The most basic special case is when there is only a non-zero result. Essentially, each worker makes a strategic decision whether to accept or reject a particular task (where \"reject\" corresponds to the zero effort level), and this choice is fully observable. We will call it Dynamic Task, which is fully specified by the price p for the non-zero result. Quotation distribution is accepted by the function S (p) = Pr, so that the corresponding expected benefit U (p) = S (p \u2212 p), where v is the value for the non-zero result."}, {"heading": "5.1 Proofs", "text": "Consider a contract x (low) = b = > p (high) = p (high) = p (high) = p (high) and a worker of the type (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (high) p (p (high) p) p (high) p (high) p (high) p (high) p)."}, {"heading": "6 Proof of the main regret bound (Theorem 4.1)", "text": "We now prove the main result of Section 4. Our high-level approach is to define a clean execution of an algorithm as execution in which some highly probable events are met, and deduce limits of regret that depend on clean execution. Analysis of clean execution does not include \"probabilistic\" arguments. This approach tends to simplify regret analyses. We start by listing some simple invariants that are forced by AgnosticZooming: Invariant 6.1. In each round t of each execution of AgnosticZooming: (a) All active cells are relevant, (b) Each candidate contract is contained in an active cell, (c) Wt (C) \u2264 5 radt (C) for each active compound cell C. Note that the zoom rule is indispensable to ensure Invariant 6.1 (c)."}, {"heading": "6.1 Analysis of the randomness", "text": "5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5."}, {"heading": "6.2 Analysis of a clean execution", "text": "The rest of the analysis focuses on a clean version. Remember that Ct is the cell selected by the algorithm in the round. (dt) In each clean version there is an active cell, call it a C-shaped cell that contains x-shaped version. We claim that it is (C-shaped) T-shaped version (x-shaped version). We consider two cases depending on whether C-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) T-shaped (dt-shaped) (dt-shaped (dt-shaped) T-shaped (dt-shaped)."}, {"heading": "7 Simulations", "text": "We evaluate the performance of AgnosticZooming through simulations. AgnosticZooming is compared with two versions of NonAdaptive, each using two standard bandit algorithms. (We find such changes beneficial in practice for both algorithms; this observation is consistent with previous work [Radlinski et al., 2008, Slivkins et al., 2013]. All three algorithms are executed with Xcand (Xcand), where the granularity of discrediting is advantageous.Setup. We consider a version of the high-low example as shown in Section 5. We set the quantum values to V (high) = 3. The probability that we will achieve high results is high."}, {"heading": "8 Application to dynamic task pricing", "text": "We will discuss dynamic task allocation, which can be considered a special case of dynamic contract design in which there is exactly a non-zero result. We will identify an important family of problem examples for which AgnosticZooming out-performs NonAdaptive.Some background. The problem of dynamic task definition, in its most basic version, is defined as follows: There is a principle (buyer) that interacts sequentially with multiple agents (vendors). In each round, an agent with an item comes up for sale. The principal price for that item, and the agent agrees to sell if and only if he does so, where ct [0, 1] is the private cost of the agent for that item. The principal derives the value for each purchased item; its utility is the value of purchased items minus the payment. The time horizon T (the number of rounds) is known. Each private cost ct is an independent sample of any fixed distribution, called offer distribution."}, {"heading": "9 Related work", "text": "In fact, most of them are able to play by the rules that they have set themselves in order to play by the rules that they have played by."}, {"heading": "10 Conclusions", "text": "It is a question of whether it is a matter of a way that does not improve itself in a certain way in a certain way in a certain way in a certain way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in both a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way and a different way in a different way in a different way in a different way in a different way and a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way in a different way."}, {"heading": "A Monotone contracts may not be optimal", "text": "In this section, we provide an example of a problem situation for which all monotonous contracts are suboptimal (at least if we limit attention to only those contracts with non-negative benefits).In this example, there are three non-zero results (i.e. 0.5 m = 3) and two non-zero performance levels, \"low\" effort and \"high\" effort, which we call e and \"high\" expenditure. There is only one labor rate. Since there is only one labor rate \u2212 we drop the subscript when describing the cost function c. We leave c (e) = 0, and leave c (eh) a positive value of less than 0.5 (v (2) \u2212 v (1) -v (1).If an employee chooses a low expenditure, the result is equally likely 1 or 3. If the employee chooses a high expenditure, it is equally likely that it is 2 or 3. It is easy to verify that this type of zero."}], "references": [{"title": "The continuum-armed bandit problem", "author": ["Rajeev Agrawal"], "venue": "SIAM J. Control and Optimization,", "citeRegEx": "Agrawal.,? \\Q1926\\E", "shortCiteRegEx": "Agrawal.", "year": 1926}, {"title": "Bandits with concave rewards and convex knapsacks", "author": ["Shipra Agrawal", "Nikhil R. Devanur"], "venue": null, "citeRegEx": "Agrawal and Devanur.,? \\Q1995\\E", "shortCiteRegEx": "Agrawal and Devanur.", "year": 1995}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Paul Fischer"], "venue": null, "citeRegEx": "Auer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2015}, {"title": "Nicol\u00f2 Cesa-Bianchi and G\u00e1bor Lugosi. Prediction, learning, and games", "author": ["Conitzer", "Nikesh Garera"], "venue": "Intl. Conf. on Algorithmic Learning Theory (ALT),", "citeRegEx": "Conitzer and Garera.,? \\Q2013\\E", "shortCiteRegEx": "Conitzer and Garera.", "year": 2013}, {"title": "Efficient optimal leanring for contextual bandits", "author": ["Miroslav Dudik", "Daniel Hsu", "Satyen Kale", "Nikos Karampatziakis", "John Langford", "Lev Reyzin", "Tong Zhang"], "venue": "In 27th Conf. on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Dudik et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dudik et al\\.", "year": 2011}, {"title": "The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond", "author": ["Aur\u00e9lien Garivier", "Olivier Capp\u00e9"], "venue": "In 24th Conf. on Learning Theory (COLT),", "citeRegEx": "Garivier and Capp\u00e9.,? \\Q2011\\E", "shortCiteRegEx": "Garivier and Capp\u00e9.", "year": 2011}, {"title": "A game-theoretic analysis of rank-order mechanisms for user-generated content", "author": ["Arpita Ghosh", "Patrick Hummel"], "venue": "In EC,", "citeRegEx": "Ghosh and Hummel.,? \\Q2011\\E", "shortCiteRegEx": "Ghosh and Hummel.", "year": 2011}, {"title": "Learning and incentives in user-generated content: Multi-armed bandits with endogenous arms", "author": ["Arpita Ghosh", "Patrick Hummel"], "venue": "In ICTS,", "citeRegEx": "Ghosh and Hummel.,? \\Q2013\\E", "shortCiteRegEx": "Ghosh and Hummel.", "year": 2013}, {"title": "Incentivizing high-quality user-generated content", "author": ["Arpita Ghosh", "Preston McAfee"], "venue": "In WWW,", "citeRegEx": "Ghosh and McAfee.,? \\Q2011\\E", "shortCiteRegEx": "Ghosh and McAfee.", "year": 2011}, {"title": "Multi-Armed Bandit Allocation Indices", "author": ["John Gittins", "Kevin Glazebrook", "Richard Weber"], "venue": null, "citeRegEx": "Gittins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gittins et al\\.", "year": 2011}, {"title": "You\u2019re hired! an examination of crowdsourcing incentive models in human resource tasks", "author": ["Christopher G. Harris"], "venue": "In CSDM,", "citeRegEx": "Harris.,? \\Q2011\\E", "shortCiteRegEx": "Harris.", "year": 2011}, {"title": "Towards social norm design for crowdsourcing markets", "author": ["Chien-Ju Ho", "Yu Zhang", "Jennifer Wortman Vaughan", "Mihaela van der Schaar"], "venue": "HCOMP,", "citeRegEx": "Ho et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ho et al\\.", "year": 2012}, {"title": "Incentivizing high quality crowdwork", "author": ["Chien-Ju Ho", "Aleksandrs Slivkins", "Siddharth Suri", "Jennifer Wortman Vaughan"], "venue": "In 24th Intl. World Wide Web Conf. (WWW),", "citeRegEx": "Ho et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ho et al\\.", "year": 2015}, {"title": "The labor economics of paid crowdsourcing", "author": ["John J. Horton", "Lydia B. Chilton"], "venue": "In EC,", "citeRegEx": "Horton and Chilton.,? \\Q2010\\E", "shortCiteRegEx": "Horton and Chilton.", "year": 2010}, {"title": "Designing incentives for online question-and-answer forums", "author": ["Shaili Jain", "Yiling Chen", "David Parkes"], "venue": "Games and Economic Behavior,", "citeRegEx": "Jain et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jain et al\\.", "year": 2012}, {"title": "Nearly tight bounds for the continuum-armed bandit problem", "author": ["Robert Kleinberg"], "venue": "In 18th Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Kleinberg.,? \\Q2004\\E", "shortCiteRegEx": "Kleinberg.", "year": 2004}, {"title": "The value of knowing a demand curve: Bounds on regret for online posted-price auctions", "author": ["Robert Kleinberg", "Tom Leighton"], "venue": "IEEE Symp. on Foundations of Computer Science (FOCS),", "citeRegEx": "Kleinberg and Leighton.,? \\Q2003\\E", "shortCiteRegEx": "Kleinberg and Leighton.", "year": 2003}, {"title": "Multi-armed bandits in metric spaces", "author": ["Robert Kleinberg", "Aleksandrs Slivkins", "Eli Upfal"], "venue": "In 40th ACM Symp. on Theory of Computing (STOC),", "citeRegEx": "Kleinberg et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kleinberg et al\\.", "year": 2008}, {"title": "The value of knowing a demand curve: Bounds on regret for online posted-price auctions", "author": ["Robert D. Kleinberg", "Frank T. Leighton"], "venue": "In IEEE Symp. on Foundations of Computer Science (FOCS),", "citeRegEx": "Kleinberg and Leighton.,? \\Q2003\\E", "shortCiteRegEx": "Kleinberg and Leighton.", "year": 2003}, {"title": "Bandit Based Monte-Carlo Planning", "author": ["Levente Kocsis", "Csaba Szepesvari"], "venue": "European Conf. on Machine Learning (ECML),", "citeRegEx": "Kocsis and Szepesvari.,? \\Q2006\\E", "shortCiteRegEx": "Kocsis and Szepesvari.", "year": 2006}, {"title": "The Theory of Incentives: The Principal-Agent Model", "author": ["Jean-Jacques Laffont", "David Martimort"], "venue": null, "citeRegEx": "Laffont and Martimort.,? \\Q2002\\E", "shortCiteRegEx": "Laffont and Martimort.", "year": 2002}, {"title": "Asymptotically efficient Adaptive Allocation Rules", "author": ["Tze Leung Lai", "Herbert Robbins"], "venue": "Advances in Applied Mathematics,", "citeRegEx": "Lai and Robbins.,? \\Q1985\\E", "shortCiteRegEx": "Lai and Robbins.", "year": 1985}, {"title": "Optimal linear contracts with heterogeneous agents", "author": ["Armando Levy", "Tomislav Vukina"], "venue": "In European Review of Agricultural Economics,", "citeRegEx": "Levy and Vukina.,? \\Q2002\\E", "shortCiteRegEx": "Levy and Vukina.", "year": 2002}, {"title": "Financial incentives and the \u201cperformance of crowds", "author": ["Winter Mason", "Duncan Watts"], "venue": "HCOMP,", "citeRegEx": "Mason and Watts.,? \\Q2009\\E", "shortCiteRegEx": "Mason and Watts.", "year": 2009}, {"title": "Reputation-based incentive protocols in crowdsourcing applications", "author": ["Yu Zhang", "Mihaela van der Schaar"], "venue": null, "citeRegEx": "Zhang and Schaar.,? \\Q2013\\E", "shortCiteRegEx": "Zhang and Schaar.", "year": 2013}], "referenceMentions": [{"referenceID": 20, "context": "First, our model can be viewed as a multi-round version of the classical principal-agent model from contract theory [Laffont and Martimort, 2002].", "startOffset": 116, "endOffset": 145}, {"referenceID": 17, "context": "The closest line of work is that on Lipschitz MAB [Kleinberg et al., 2008], in which the algorithm is given a distance function on the arms, and the expected rewards of the arms are assumed to satisfy Lipschitz-continuity (or a relaxation thereof) with respect to this distance function, [Agrawal, 1995, Kleinberg, 2004, Auer et al.", "startOffset": 50, "endOffset": 74}, {"referenceID": 15, "context": "[Kleinberg and Leighton, 2003b, Badanidiyuru et al., 2012, Singer and Mittal, 2013, Singla and Krause, 2013, Badanidiyuru et al., 2013]. In particular, Badanidiyuru et al. [2012] and Singla and Krause [2013] study a version of our setting with simple, single-price contracts (independent of the output), where the focus is on dealing with a global budget constraint.", "startOffset": 1, "endOffset": 179}, {"referenceID": 15, "context": "[Kleinberg and Leighton, 2003b, Badanidiyuru et al., 2012, Singer and Mittal, 2013, Singla and Krause, 2013, Badanidiyuru et al., 2013]. In particular, Badanidiyuru et al. [2012] and Singla and Krause [2013] study a version of our setting with simple, single-price contracts (independent of the output), where the focus is on dealing with a global budget constraint.", "startOffset": 1, "endOffset": 208}, {"referenceID": 20, "context": "As described above, this is a version of the standard principal-agent model [Laffont and Martimort, 2002].", "startOffset": 76, "endOffset": 105}, {"referenceID": 15, "context": "The special case m = 1 is equivalent to the dynamic pricing problem from Kleinberg and Leighton [2003a]; we obtain improved results for it, too.", "startOffset": 73, "endOffset": 104}, {"referenceID": 4, "context": ", Dudik et al. [2011].", "startOffset": 2, "endOffset": 22}, {"referenceID": 15, "context": "The width dimension is similar to the \u201czooming dimension\u201d in Kleinberg et al. [2008] and \u201cnear-optimality dimension\u201d in Bubeck et al.", "startOffset": 61, "endOffset": 85}, {"referenceID": 15, "context": "The width dimension is similar to the \u201czooming dimension\u201d in Kleinberg et al. [2008] and \u201cnear-optimality dimension\u201d in Bubeck et al. [2011a] in the work on \u201cbandits in metric spaces\u201d.", "startOffset": 61, "endOffset": 142}, {"referenceID": 15, "context": "If an algorithm is given this function D (call such algorithm D-aware), the machinery from \u201cbandits in metric spaces\u201d Kleinberg et al. [2008], Bubeck et al.", "startOffset": 118, "endOffset": 142}, {"referenceID": 15, "context": "If an algorithm is given this function D (call such algorithm D-aware), the machinery from \u201cbandits in metric spaces\u201d Kleinberg et al. [2008], Bubeck et al. [2011a] can be used to perform adaptive discretization and obtain a significant advantage over NonAdaptive.", "startOffset": 118, "endOffset": 165}, {"referenceID": 15, "context": "Given this shape of D, let us state the regret bounds for D-aware algorithms in Kleinberg et al. [2008] and Bubeck et al.", "startOffset": 80, "endOffset": 104}, {"referenceID": 15, "context": "Given this shape of D, let us state the regret bounds for D-aware algorithms in Kleinberg et al. [2008] and Bubeck et al. [2011a]. To simplify the notation, we assume that the action space is restricted to Xcand.", "startOffset": 80, "endOffset": 130}, {"referenceID": 15, "context": "For a more precise comparison, we focus on the results in Kleinberg et al. [2008] .", "startOffset": 58, "endOffset": 82}, {"referenceID": 15, "context": "For a more precise comparison, we focus on the results in Kleinberg et al. [2008] . (The regret bounds in Bubeck et al. [2011a] are very similar in spirit, but are stated in terms of a slightly different structure.", "startOffset": 58, "endOffset": 128}, {"referenceID": 15, "context": "For a more precise comparison, we focus on the results in Kleinberg et al. [2008] . (The regret bounds in Bubeck et al. [2011a] are very similar in spirit, but are stated in terms of a slightly different structure.) The \u201ccovering-type\u201d regret bound in Kleinberg et al. [2008] focuses on balls of radius at most \u01eb according to distance D, so that N\u2217 \u01eb (Y ) is the smallest number of such balls that is sufficient to cover Y .", "startOffset": 58, "endOffset": 276}, {"referenceID": 15, "context": "We can upper-bound the discretization error using a standard approach from the work on dynamic pricing Kleinberg and Leighton [2003b]. Fix discretization granularity \u03c8 > 0.", "startOffset": 103, "endOffset": 134}, {"referenceID": 15, "context": "Worst-case regret bounds are implicit in prior work on dynamic inventory-pricing [Kleinberg and Leighton, 2003a].13 Let NonAdaptive(\u03c8) denote algorithm NonAdaptive with Xcand = Xcand(\u03c8). Then, by the analysis in Kleinberg and Leighton [2003a], NonAdaptive(\u03c8) achieves regret R(T ) = \u00d5(\u03c8T + \u03c8\u22122).", "startOffset": 82, "endOffset": 243}, {"referenceID": 15, "context": "The algorithmic result for dynamic task pricing is an easy modification of the analysis in Kleinberg and Leighton [2003a] for dynamic inventory-pricing.", "startOffset": 91, "endOffset": 122}, {"referenceID": 15, "context": "The algorithmic result for dynamic task pricing is an easy modification of the analysis in Kleinberg and Leighton [2003a] for dynamic inventory-pricing. The lower bound in in Kleinberg and Leighton [2003a] can also be \u201ctranslated\u201d from dynamic inventory-pricing to dynamic task pricing without introducing any new ideas.", "startOffset": 91, "endOffset": 206}, {"referenceID": 20, "context": "Our model can be viewed as an extension of the classic principal-agent model from contract theory [Laffont and Martimort, 2002].", "startOffset": 98, "endOffset": 127}, {"referenceID": 20, "context": "Most existing literature on the principal-agent problem with adverse selection focuses on applying the revelation principle [Laffont and Martimort, 2002].", "startOffset": 124, "endOffset": 153}, {"referenceID": 20, "context": "Our model can be viewed as an extension of the classic principal-agent model from contract theory [Laffont and Martimort, 2002]. In the most basic version of the classic model, a single principal interacts with a single agent whose type (specified by a cost function and production function, as described in Section 2) is generally assumed to be known. The principal specifies a contract mapping outcomes to payments that the principal commits to make to the agent. The agent then chooses an action (i.e., effort level) that stochastically results in an outcome in order to maximize his expected utility given the contract. The principal observes the outcome, but cannot directly observe the agent\u2019s effort level, creating a moral hazard problem. The goal of the principal is to design a contract to maximize her own expected utility, which is the difference between the utility she receives from the outcome and the payment she makes. This maximization can be written as a constrained optimization problem, and it can be shown that linear contracts are optimal. The adverse selection variation of the principal-agent problem relaxes the assumption that the agent\u2019s type is known. Most existing literature on the principal-agent problem with adverse selection focuses on applying the revelation principle [Laffont and Martimort, 2002]. In this setting, the principal offers a menu of contracts, and the contract chosen by the agent reveals the agent\u2019s type. The problem of selecting a menu of contracts that maximizes the principal\u2019s expected utility can again be formulated as a constrained optimization. Our work differs from the classic setting in that we consider a principal interacting with multiple agents, and the principal may adjust her contract over time in an online manner. Several other authors have considered extensions of the classic model to multiple agents. Levy and Vukina [2002] show that with multiple agents it is optimal to set individual linear contracts for each agent rather than a single uniform contract for all agents, but offer a variety of descriptive explanations for why it is more common to see uniform contracts in practice.", "startOffset": 99, "endOffset": 1900}, {"referenceID": 20, "context": "Our model can be viewed as an extension of the classic principal-agent model from contract theory [Laffont and Martimort, 2002]. In the most basic version of the classic model, a single principal interacts with a single agent whose type (specified by a cost function and production function, as described in Section 2) is generally assumed to be known. The principal specifies a contract mapping outcomes to payments that the principal commits to make to the agent. The agent then chooses an action (i.e., effort level) that stochastically results in an outcome in order to maximize his expected utility given the contract. The principal observes the outcome, but cannot directly observe the agent\u2019s effort level, creating a moral hazard problem. The goal of the principal is to design a contract to maximize her own expected utility, which is the difference between the utility she receives from the outcome and the payment she makes. This maximization can be written as a constrained optimization problem, and it can be shown that linear contracts are optimal. The adverse selection variation of the principal-agent problem relaxes the assumption that the agent\u2019s type is known. Most existing literature on the principal-agent problem with adverse selection focuses on applying the revelation principle [Laffont and Martimort, 2002]. In this setting, the principal offers a menu of contracts, and the contract chosen by the agent reveals the agent\u2019s type. The problem of selecting a menu of contracts that maximizes the principal\u2019s expected utility can again be formulated as a constrained optimization. Our work differs from the classic setting in that we consider a principal interacting with multiple agents, and the principal may adjust her contract over time in an online manner. Several other authors have considered extensions of the classic model to multiple agents. Levy and Vukina [2002] show that with multiple agents it is optimal to set individual linear contracts for each agent rather than a single uniform contract for all agents, but offer a variety of descriptive explanations for why it is more common to see uniform contracts in practice. Babaioff et al. [2006] consider a setting in which one principal interacts with multiple agents, but observes only a single outcome which is a function of all agents\u2019 effort levels.", "startOffset": 99, "endOffset": 2184}, {"referenceID": 20, "context": "Our model can be viewed as an extension of the classic principal-agent model from contract theory [Laffont and Martimort, 2002]. In the most basic version of the classic model, a single principal interacts with a single agent whose type (specified by a cost function and production function, as described in Section 2) is generally assumed to be known. The principal specifies a contract mapping outcomes to payments that the principal commits to make to the agent. The agent then chooses an action (i.e., effort level) that stochastically results in an outcome in order to maximize his expected utility given the contract. The principal observes the outcome, but cannot directly observe the agent\u2019s effort level, creating a moral hazard problem. The goal of the principal is to design a contract to maximize her own expected utility, which is the difference between the utility she receives from the outcome and the payment she makes. This maximization can be written as a constrained optimization problem, and it can be shown that linear contracts are optimal. The adverse selection variation of the principal-agent problem relaxes the assumption that the agent\u2019s type is known. Most existing literature on the principal-agent problem with adverse selection focuses on applying the revelation principle [Laffont and Martimort, 2002]. In this setting, the principal offers a menu of contracts, and the contract chosen by the agent reveals the agent\u2019s type. The problem of selecting a menu of contracts that maximizes the principal\u2019s expected utility can again be formulated as a constrained optimization. Our work differs from the classic setting in that we consider a principal interacting with multiple agents, and the principal may adjust her contract over time in an online manner. Several other authors have considered extensions of the classic model to multiple agents. Levy and Vukina [2002] show that with multiple agents it is optimal to set individual linear contracts for each agent rather than a single uniform contract for all agents, but offer a variety of descriptive explanations for why it is more common to see uniform contracts in practice. Babaioff et al. [2006] consider a setting in which one principal interacts with multiple agents, but observes only a single outcome which is a function of all agents\u2019 effort levels. Misra et al. [2012] consider a variant in which the algorithm must decide both how to set a uniform contract for many agents and how to select a subset of agents to hire.", "startOffset": 99, "endOffset": 2363}, {"referenceID": 3, "context": "Conitzer and Garera [2006] studies the online principal agent problem with a similar setting to ours.", "startOffset": 0, "endOffset": 27}, {"referenceID": 3, "context": "Conitzer and Garera [2006] studies the online principal agent problem with a similar setting to ours. However, they focus on empirically comparing different online algorithms, including bandit approaches with uniform discretization, gradient ascent, and Bayesian update approaches to the problem. Our goal is to provide an algorithm with nice theoretical guarantees. Bohren and Kravitz [2013] studies the setting when the outcome is unverifiable.", "startOffset": 0, "endOffset": 393}, {"referenceID": 8, "context": "Jain et al. [2012] explore ways in which to award virtual points to users in online question-and-answer forums to improve the quality of answers.", "startOffset": 0, "endOffset": 19}, {"referenceID": 6, "context": "Ghosh and Hummel [2011, 2013] and Ghosh and McAfee [2011] study how to distribute user generated content (e.", "startOffset": 0, "endOffset": 58}, {"referenceID": 6, "context": "Ghosh and Hummel [2011, 2013] and Ghosh and McAfee [2011] study how to distribute user generated content (e.g., Youtube videos) to users to encourage the production of high-quality internet content by people who are motivated by attention. Ho et al. [2012] and Zhang and van der Schaar [2012] consider the design of two-sided reputation systems to encourage good behavior from both workers and requesters in crowdsourcing markets.", "startOffset": 0, "endOffset": 257}, {"referenceID": 6, "context": "Ghosh and Hummel [2011, 2013] and Ghosh and McAfee [2011] study how to distribute user generated content (e.g., Youtube videos) to users to encourage the production of high-quality internet content by people who are motivated by attention. Ho et al. [2012] and Zhang and van der Schaar [2012] consider the design of two-sided reputation systems to encourage good behavior from both workers and requesters in crowdsourcing markets.", "startOffset": 0, "endOffset": 293}, {"referenceID": 6, "context": "Ghosh and Hummel [2011, 2013] and Ghosh and McAfee [2011] study how to distribute user generated content (e.g., Youtube videos) to users to encourage the production of high-quality internet content by people who are motivated by attention. Ho et al. [2012] and Zhang and van der Schaar [2012] consider the design of two-sided reputation systems to encourage good behavior from both workers and requesters in crowdsourcing markets. While we also consider crowdsourcing markets, our work differs in that it focuses on how to design contracts, perhaps the most natural incentive scheme, to incentivize workers to exert effort. The problem closest to ours which has been studied in the context of crowdsourcing systems is the online task pricing problem in which a requester has an unlimited supply of tasks to be completed and a budget B to spend on them [Badanidiyuru et al., 2012, Singer and Mittal, 2013]. Workers with private costs arrive online, and the requester sets a single price for each arriving worker. The goal is to learn the optimal single fixed price over time. Our work can be viewed as a generalization of the task pricing problem, which is a special case of our setting with the number of non-null outcomes m fixed at 1. There has also been empirical work examining how workers\u2019 behavior varies based on the financial incentives offered in crowdsourcing markets. Mason and Watts [2009] study how workers react to changes of performance-independent financial incentives.", "startOffset": 0, "endOffset": 1402}, {"referenceID": 6, "context": "Ghosh and Hummel [2011, 2013] and Ghosh and McAfee [2011] study how to distribute user generated content (e.g., Youtube videos) to users to encourage the production of high-quality internet content by people who are motivated by attention. Ho et al. [2012] and Zhang and van der Schaar [2012] consider the design of two-sided reputation systems to encourage good behavior from both workers and requesters in crowdsourcing markets. While we also consider crowdsourcing markets, our work differs in that it focuses on how to design contracts, perhaps the most natural incentive scheme, to incentivize workers to exert effort. The problem closest to ours which has been studied in the context of crowdsourcing systems is the online task pricing problem in which a requester has an unlimited supply of tasks to be completed and a budget B to spend on them [Badanidiyuru et al., 2012, Singer and Mittal, 2013]. Workers with private costs arrive online, and the requester sets a single price for each arriving worker. The goal is to learn the optimal single fixed price over time. Our work can be viewed as a generalization of the task pricing problem, which is a special case of our setting with the number of non-null outcomes m fixed at 1. There has also been empirical work examining how workers\u2019 behavior varies based on the financial incentives offered in crowdsourcing markets. Mason and Watts [2009] study how workers react to changes of performance-independent financial incentives. In their study, increasing financial incentives increases the number of tasks workers complete, but not the quality of their output. Yin et al. [2013] provide a potential explanation for this phenomenon using the concept of \u201canchoring effect\u201d: a worker\u2019s cost for completing a task is influenced by the first price the worker sees for this task.", "startOffset": 0, "endOffset": 1637}, {"referenceID": 6, "context": "Ghosh and Hummel [2011, 2013] and Ghosh and McAfee [2011] study how to distribute user generated content (e.g., Youtube videos) to users to encourage the production of high-quality internet content by people who are motivated by attention. Ho et al. [2012] and Zhang and van der Schaar [2012] consider the design of two-sided reputation systems to encourage good behavior from both workers and requesters in crowdsourcing markets. While we also consider crowdsourcing markets, our work differs in that it focuses on how to design contracts, perhaps the most natural incentive scheme, to incentivize workers to exert effort. The problem closest to ours which has been studied in the context of crowdsourcing systems is the online task pricing problem in which a requester has an unlimited supply of tasks to be completed and a budget B to spend on them [Badanidiyuru et al., 2012, Singer and Mittal, 2013]. Workers with private costs arrive online, and the requester sets a single price for each arriving worker. The goal is to learn the optimal single fixed price over time. Our work can be viewed as a generalization of the task pricing problem, which is a special case of our setting with the number of non-null outcomes m fixed at 1. There has also been empirical work examining how workers\u2019 behavior varies based on the financial incentives offered in crowdsourcing markets. Mason and Watts [2009] study how workers react to changes of performance-independent financial incentives. In their study, increasing financial incentives increases the number of tasks workers complete, but not the quality of their output. Yin et al. [2013] provide a potential explanation for this phenomenon using the concept of \u201canchoring effect\u201d: a worker\u2019s cost for completing a task is influenced by the first price the worker sees for this task. Horton and Chilton [2010] run experiments to estimate workers\u2019 reservation wage for completing tasks.", "startOffset": 0, "endOffset": 1858}, {"referenceID": 10, "context": "Harris [2011] runs MTurk experiments on resume screening, where workers can get a bonus if they perform well.", "startOffset": 0, "endOffset": 14}, {"referenceID": 10, "context": "Harris [2011] runs MTurk experiments on resume screening, where workers can get a bonus if they perform well. He concludes that the quality of work is better with PBPs than with uniform payments. Yin et al. [2013] show that varying the magnitude of the bonus does not have much effect in certain settings.", "startOffset": 0, "endOffset": 214}, {"referenceID": 10, "context": "Harris [2011] runs MTurk experiments on resume screening, where workers can get a bonus if they perform well. He concludes that the quality of work is better with PBPs than with uniform payments. Yin et al. [2013] show that varying the magnitude of the bonus does not have much effect in certain settings. Ho et al. [2015] perform a more comprehensive set of experiments aimed at determining whether, when, and why PBPs increase the quality of submitted work.", "startOffset": 0, "endOffset": 323}, {"referenceID": 10, "context": "Harris [2011] runs MTurk experiments on resume screening, where workers can get a bonus if they perform well. He concludes that the quality of work is better with PBPs than with uniform payments. Yin et al. [2013] show that varying the magnitude of the bonus does not have much effect in certain settings. Ho et al. [2015] perform a more comprehensive set of experiments aimed at determining whether, when, and why PBPs increase the quality of submitted work. Their results suggest that PBPs can increase quality on tasks for which increased time or effort leads to higher quality work. Their results also suggest that workers may interpret a contract as performance-based even if it is not stated as such (since requesters always have the option to reject work). Based on this evidence, they propose a new model of worker behavior that extends the principal-agent model to explicitly reflect workers\u2019 subjective beliefs about their likelihood of being paid. Overall, previous empirical work demonstrates that workers in crowdsourcing markets do respond to the change of financial incentives, but that their behavior does not always follow the traditional rational-worker model \u2014 similar to people in any real-world market. In our work, we start our analysis with the rational-worker assumption ubiquitous in economic theory, but demonstrate that our results can still hold without these assumptions as long as the collective worker behavior satisfies some natural properties (namely, as long as Lemma 3.1 holds). We note that our results hold under the generalized worker model proposed by Ho et al. [2015], which is consistent with their experimental evidence as discussed above.", "startOffset": 0, "endOffset": 1608}, {"referenceID": 7, "context": "A survey of prior work on MAB is beyond the scope of this paper; the reader is encouraged to refer to Cesa-Bianchi and Lugosi [2006] or Bubeck and Cesa-Bianchi [2012] for background on prior-independent MAB, and to Gittins et al. [2011] for background on Bayesian MAB.", "startOffset": 215, "endOffset": 237}, {"referenceID": 1, "context": "The basic formulation (with a small number of arms) is well-understood [Lai and Robbins, 1985, Auer et al., 2002, Bubeck and Cesa-Bianchi, 2012]. To handle problems with a large or infinite number of arms, one typically needs side information on similarity between arms. A typical way to model this side information, called Lipschitz MAB Kleinberg et al. [2008], is that an algorithm is given a distance function on the arms, and the expected rewards are assumed to satisfy Lipschitz-continuity (or a relaxation thereof) with respect this distance function, e.", "startOffset": 95, "endOffset": 362}, {"referenceID": 19, "context": "For example, in applications to web search and advertising it is natural to assume that an algorithm can only observe a tree-shaped taxonomy on arms [Kocsis and Szepesvari, 2006, Munos and Coquelin, 2007, Pandey et al., 2007, Slivkins, 2011, Bull, 2013]. In particular, Slivkins [2011] and Bull [2013] explicitly reconstruct (the relevant parts of) the metric space defined by the taxonomy.", "startOffset": 150, "endOffset": 286}, {"referenceID": 19, "context": "For example, in applications to web search and advertising it is natural to assume that an algorithm can only observe a tree-shaped taxonomy on arms [Kocsis and Szepesvari, 2006, Munos and Coquelin, 2007, Pandey et al., 2007, Slivkins, 2011, Bull, 2013]. In particular, Slivkins [2011] and Bull [2013] explicitly reconstruct (the relevant parts of) the metric space defined by the taxonomy.", "startOffset": 150, "endOffset": 302}, {"referenceID": 19, "context": "For example, in applications to web search and advertising it is natural to assume that an algorithm can only observe a tree-shaped taxonomy on arms [Kocsis and Szepesvari, 2006, Munos and Coquelin, 2007, Pandey et al., 2007, Slivkins, 2011, Bull, 2013]. In particular, Slivkins [2011] and Bull [2013] explicitly reconstruct (the relevant parts of) the metric space defined by the taxonomy. In a different direction, Bubeck et al. [2011b] study a version of Lipschitz MAB where the Lipschitz constant is not known, and essentially recover the performance of NonAdaptive for this setting.", "startOffset": 150, "endOffset": 439}, {"referenceID": 13, "context": "[2003] and Kleinberg and Leighton [2003a] and continued by several others [Besbes and Zeevi, 2009, Babaioff et al.", "startOffset": 11, "endOffset": 42}, {"referenceID": 13, "context": "[2003] and Kleinberg and Leighton [2003a] and continued by several others [Besbes and Zeevi, 2009, Babaioff et al., 2015, Besbes and Zeevi, 2012, Wang et al., 2014, Badanidiyuru et al., 2013, 2014]. Further, Badanidiyuru et al. [2012] and Singla and Krause [2013] studied the version in which the principal buys items, or equivalently commissions tasks; we call this version dynamic task pricing.", "startOffset": 11, "endOffset": 235}, {"referenceID": 13, "context": "[2003] and Kleinberg and Leighton [2003a] and continued by several others [Besbes and Zeevi, 2009, Babaioff et al., 2015, Besbes and Zeevi, 2012, Wang et al., 2014, Badanidiyuru et al., 2013, 2014]. Further, Badanidiyuru et al. [2012] and Singla and Krause [2013] studied the version in which the principal buys items, or equivalently commissions tasks; we call this version dynamic task pricing.", "startOffset": 11, "endOffset": 264}, {"referenceID": 0, "context": "[2014] and Agrawal and Devanur [2014] is concurrent and independent work with respect to the conference publication of this paper, and Agrawal et al.", "startOffset": 11, "endOffset": 38}, {"referenceID": 0, "context": "[2014] and Agrawal and Devanur [2014] is concurrent and independent work with respect to the conference publication of this paper, and Agrawal et al. [2015] is subsequent work.", "startOffset": 11, "endOffset": 157}, {"referenceID": 5, "context": "First, it can use the information from C in a more sophisticated way, similar to the more sophisticated indices for the basic K-armed bandit problem; for example, see Garivier and Capp\u00e9 [2011]. Second, the index can incorporate information from other cells.", "startOffset": 167, "endOffset": 193}], "year": 2014, "abstractText": "Crowdsourcing markets have emerged as a popular platform for matching available workers with tasks to complete. The payment for a particular task is typically set by the task\u2019s requester, and may be adjusted based on the quality of the completed work, for example, through the use of \u201cbonus\u201d payments. In this paper, we study the requester\u2019s problem of dynamically adjusting quality-contingent payments for tasks. We consider a multi-round version of the well-known principal-agent model, whereby in each round a worker makes a strategic choice of the effort level which is not directly observable by the requester. In particular, our formulation significantly generalizes the budget-free online task pricing problems studied in prior work. We treat this problem as a multi-armed bandit problem, with each \u201carm\u201d representing a potential contract. To cope with the large (and in fact, infinite) number of arms, we propose a new algorithm, AgnosticZooming, which discretizes the contract space into a finite number of regions, effectively treating each region as a single arm. This discretization is adaptively refined, so that more promising regions of the contract space are eventually discretized more finely. We analyze this algorithm, showing that it achieves regret sublinear in the time horizon and substantially improves over non-adaptive discretization (which is the only competing approach in the literature). Our results advance the state of art on several different topics: the theory of crowdsourcing markets, principal-agent problems, multi-armed bandits, and dynamic pricing. ACM Categories and subject descriptors: F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems; F.1.2 [Computation by Abstract Devices]: Modes of Computation\u2014Online computation; J.4 [Social and Behavioral Sciences]: Economics", "creator": "gnuplot 4.2 patchlevel 6 "}}}