{"id": "1405.3382", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-May-2014", "title": "Active Mining of Parallel Video Streams", "abstract": "The practicality of a video surveillance system is adversely limited by the amount of queries that can be placed on human resources and their vigilance in response. To transcend this limitation, a major effort under way is to include software that (fully or at least semi) automatically mines video footage, reducing the burden imposed to the system. Herein, we propose a semi-supervised incremental learning framework for evolving visual streams in order to develop a robust and flexible track classification system. Our proposed method learns from consecutive batches by updating an ensemble in each time. It tries to strike a balance between performance of the system and amount of data which needs to be labelled. As no restriction is considered, the system can address many practical problems in an evolving multi-camera scenario, such as concept drift, class evolution and various length of video streams which have not been addressed before. Experiments were performed on synthetic as well as real-world visual data in non-stationary environments, showing high accuracy with fairly little human collaboration.", "histories": [["v1", "Wed, 14 May 2014 07:00:38 GMT  (730kb,D)", "http://arxiv.org/abs/1405.3382v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["samaneh khoshrou", "jaime s cardoso", "luis f teixeira"], "accepted": false, "id": "1405.3382"}, "pdf": {"name": "1405.3382.pdf", "metadata": {"source": "CRF", "title": "Active Mining of Parallel Video Streams", "authors": ["Samaneh Khoshrou", "Jaime S. Cardoso", "Lu\u0131\u0301s F. Teixeira"], "emails": ["samaneh.khoshrou@inescporto.pt", "jaime.cardoso@inescporto.pt", "lft@fe.up.pt"], "sections": [{"heading": null, "text": "Keyword CCTV \u00b7 Parallel Streams \u00b7 Active LearningS. Khoshrou, J. S. Cardoso INESC TEC (formerly INESC Porto) Rua Doutor Roberto Frias 378, 4200-465 Porto Tel.: + 351-222094000 E-mail: samaneh.khoshrou @ inescporto.pt jaime.cardoso @ inescporto.ptL. F. Teixeira Faculdade de de de Engenharia da Universidade do Porto (FEUP) Rua Doutor Roberto Frias 378, 4200-465 Porto Tel.: + 351-225081400 E-mail: lft @ fe.up.pt"}, {"heading": "1 Introduction", "text": "The fact is that most people are able to move to another world, in which they are able, in which they are able to move, in which they are able, in which they are able to move, in which they are able, in which they are able, in which they are able to move, in which they are able, in which they are able to move, in which they are able to move, in which they are able, in which they are able to move."}, {"heading": "2 Never Ending Visual Information Learning", "text": "In this area, we are able to go in search of new paths that will lead us into the future, \"he told the Deutsche Presse-Agentur in an interview with the Deutsche Presse-Agentur.\" We have to go in search of new paths, \"he said.\" We have to go in search of new paths. \"He added:\" We have to go in search of new paths. \"He added:\" We have to go in search of new paths. \"He added:\" We have to go in search of new paths. \"He added:\" We have to go in search of new paths. \""}, {"heading": "2.1.1 Batch Label Prediction", "text": "A batch Dmtt is a temporal sequence of frames D mt t, f > j = > problems where f exceeds 1 to the batch size B. The composite model, Ht \u2212 1, can be used to directly predict p (Ck | D mi t, f, Ht \u2212 1), but not p (Ck | D mi t, Ht \u2212 1). The batch (multiframe) Bayesian inference requires conditional independence dencep (Dmit | Ck, Ht \u2212 1) = p (Dmit, 1, \u00b7, D mi t, B | Ck, Ht \u2212 1) = p (Dmit, 1 | Ck, Ht \u2212 1) \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 Cp (D mi t, B \u2212 Ck, Ht \u2212 1) = p (Dmit, 1, Ht \u2212 1) = p (D mi t, Ht, Ht, Ht \u2212 t, Ht, t, t, t \u2212 c, c, c, Ht, c, c, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t, t \u2212, t, t, t, t, t, t, t, t, t, t \u2212, t, t, t, t, t, t, t, t, t, t \u2212, t, t, t, t, t, t, t, t, t, t, t, t, t, t \u2212, t, t, t, t, t, t, t, t, t, t, t, B \u2212, t."}, {"heading": "2.1.2 The Batch Confidence Level Estimation", "text": "\"We have a class in which we are the first and second most likely class.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\" We. \"\" \"We.\" \"\" \"We.\" \"\" \"We.\" \"\" \"We.\" \"\" \"\" \"\" \"\" We. \"\" \"\" \"\" We. \"\" \"\" \"\" \"\" We. \"\" \"\" \".\" \"\" \"\" We. \".\" \"\". \"\" \"\" We. \".\" \"\" \"\". \"\" \"\" \"We.\" \"\" \".\" \"\" \"..\" \"\" \"..\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \"\". \"\". \"\". \"\". \"\" \".\" \".\" \".\" \"\". \"\" \".\" \"\""}, {"heading": "2.1.3 Multiclass Classifier", "text": "We assume that all frames belonging to a batch originate from the same object (and the underlying tracking system does not mix identities in the time span), and therefore the frames within a batch correspond to observations of the same class. Consider that the M batches correspond to L < M labels in the current time span (some batches may have the same label). We need a classifier that can approximate the a posteriori probability function p (ck | D mi t, f), which gives the probability of the frame belonging to a particular class ck, since D mi t, f has been observed. A standard method to address this problem is to apply discriminatory approaches that directly predict the conditional probability. Alternatively, generative approaches find the common distribution p (with, f, ck) and then use Bayes's rule to form the conditional distribution from the generative model."}, {"heading": "2.1.4 The Composite Model Structure and Update", "text": "The composite model Ht in the NEVIL framework is an interplay of classifiers ht, which are trained incrementally (without access to previous data) on incoming time frames of data as described above. The individual models ht are combined with a weighted majority decision, with weights being dynamically updated with respect to the design time of the classifiers. The prediction that the composite model Ht issues for a given frame Dmit, f isp (Ck | D mi t, f, Ht) = t \u2211 '= 1Wt'h' (CK | D mi t, f), where h '(.) is the multi-class classifier trained at TS', Wt 'is the weight assigned to the classifier' adjusted to time. The weights are updated and normalized and selected at each time frame to give more recognition to newer insights. The weights are derived from a geometric series 1pt,..., 1 p2, 1, normalized by the sum of probabilities (Wt = 1)."}, {"heading": "3 Experimental Methodology", "text": "In fact, the fact is that most of them are able to move to a different world in which they are able to live and live than in another country in which they live."}, {"heading": "4 Results", "text": "In fact, it is such that we are in a position to enter into another world, in which we are in a position, in which we are located, and in which we are in a position, in which we are located, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we, in which we live, in which we, in which we live, in which we, in which we, in which we, in which we live, in which we, in which we, in which we, in which we live, in which we, in which we, in which we, in which we, in which we live, in which we, in which we live, in which we, in which we, in which we live, in which we live, in which we live, in which we, in which we live, in which we, in which we live, in which we live, in which we, in which we live, in which we, in which we live, in which we, in which we live, in which we live, in which we, in which we live, in which we, in which we live, in which we, in which we, in which we live, in which we, in which we, in which we live, in which we, in which we, in which we live, in which we, in which we, in which we, in which we, we, in which we live, we, in which we, in which we, in which we, in which we, we, in which we, in which we live, we, in which we, we, in which we, we, in which we, in which we, in which we, in which we, in which we, in which we, we, we, in which we live, we, in which we, in which we, in which we, in which we, in which we, in which we, in which we, we, we, in which we"}, {"heading": "5 Conclusions", "text": "In this paper, we deal with the problem of learning visual flows generated in a multi-camera scenario. We consider the problem to be the dismantling of parallel high-dimensional data. Inspired by active learning strategies, an oracle in our proposed framework (NEVIL) delivers labeled lots; multiple scales of information are used to determine when the oracle is used. As the learners have bottlenecks in each learning pipeline, different groups of classifiers have been studied and experimentally evaluated. We conducted the experiments on both synthetic and real data sets. In synthetic scenarios where low-dimensional clean data are available, the application of the geometric mean and the modified self-confident measure provide the best and most cost-effective (in terms of annotation costs) results. However, to obtain the highest accuracy from noisy visual data, we must use arithmetic averages for compact information and modified margins to apply the most informative."}], "references": [{"title": "StreamKM++: A clustering algorithms for data streams", "author": ["MR Ackermann", "C Lammersen", "M M\u00e4rtens", "C Raupach", "C Sohler", "K Swierkot"], "venue": "Journal of Experimental Algorithmics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "On combining classifiers using sum and product rules. Pattern Recognition Letters", "author": ["LA Alexandre", "AC Campilho", "M Kamel"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Person identification in webcam images:an application of semisupervised learning", "author": ["M Balcan", "A Blum", "PP Choi", "J Lafferty", "B Pantano", "MR Rwebangira", "X Zhu"], "venue": "In: International Conference on Machine Learning Workshop on Learning from Partially Classified Training Data,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Online choice of active learning algorithms", "author": ["Y Baram", "R El-Yaniv", "K Luz"], "venue": "Journal of Machine Learning Research", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Online clustering of parallel data streams. Data Knowledge Engineering", "author": ["J Beringer", "E H\u00fcllermeier"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Pattern Recognition and Machine Learning (Information Science and Statistics)", "author": ["CM Bishop"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Filling the gap in quality assessment of video object tracking", "author": ["P Carvalho", "JS Cardoso", "L Corte-Real"], "venue": "Image and Vision Computing", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "LIBSVM: A library for support vector machines", "author": ["CC Chang", "CJ Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Tracking multiple people with a multi-camera system", "author": ["T hsun Chang", "S Gong"], "venue": "IEEE Workshop on Multi-Object Tracking", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "A clustering algorithm for multiple data streams based on spectral component similarity", "author": ["L Chen", "L Zou", "L Tu"], "venue": "Information Sciences", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Clustering parallel data streams. Data Mining and Knowledge Discovery in Real Life Applications I-Tech Education and Publishing", "author": ["Y Chen"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Semisupervised text classification using partitioned em", "author": ["G Cong", "WS Lee", "H Wu", "B Liu"], "venue": "In: 11th International Conference on Database Systems for Advanced Applications,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2004}, {"title": "Statistical comparisons of classifiers over multiple data sets", "author": ["J Dem\u0161ar"], "venue": "Journal of Machine Learning Research", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Issues in automated visual surveillance", "author": ["AR Dick", "MJ Brooks"], "venue": "Proc. VIIth Digital Image,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "Incremental learning of concept drift in nonstationary environments", "author": ["R Elwell", "R Polikar"], "venue": "IEEE Transactions on Neural Networks", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Liblinear: A library for large linear classification", "author": ["RE Fan", "KW Chang", "CJ Hsieh", "XR Wang", "CJ Lin"], "venue": "Journal of Machine Learning Research", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Realworld semi-supervised learning of pos-taggers for low-resource languages", "author": ["D Garrette", "J Mielens", "J Baldridge"], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL-2013),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "A visualization framework for team sports captured using multiple static cameras", "author": ["R Hamid", "RK Kumar", "JK Hodgins", "IA Essa"], "venue": "Computer Vision and Image Understanding", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Appearance modeling for tracking in multiple non-overlapping cameras", "author": ["O Javed"], "venue": "IEEE International Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Automated Multi-Camera Surveillance: Algorithms and Practice", "author": ["O Javed", "M Shah"], "venue": "The International Series in Video Computing,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "On the need for time series data mining benchmarks: A survey and empirical demonstration. Data Mining Knowledge Discovery", "author": ["E Keogh", "S Kasetty"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2003}, {"title": "A survey of recent trends in one class classification. In: Coyle L,  Active Mining of Parallel Video Streams", "author": ["SS Khan", "M GMadden"], "venue": "Freyne J (eds) Artificial Intelligence and Cognitive Science, Lecture Notes in Computer Science,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "On combining classifiers", "author": ["J Kittler", "M Hatef", "RPW Duin", "J Matas"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1998}, {"title": "Dynamic weighted majority: An ensemble method for drifting concepts", "author": ["JZ Kolter", "MA Maloof"], "venue": "Journal of Machine Learning Research", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "Intercamera association of multi-target tracks by online learned appearance affinity models", "author": ["CH Kuo", "C Huang", "R Nevatia"], "venue": "Proceedings of the 11th European Conference on Computer Vision: Part I, Springer-Verlag, Berlin, Heidelberg,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Unsupervised improvement of visual detectors using co-training", "author": ["A Levin", "PA Viola", "Y Freund"], "venue": "Ninth IEEE International Conference on Computer Vision,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2003}, {"title": "Semi-supervised learning for natural language", "author": ["P Liang"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2005}, {"title": "Classification and novel class detection in data streams with active mining", "author": ["MM Masud", "J Gao", "L Khan", "J Han", "BM Thuraisingham"], "venue": "PacificAsia Conference Advances in Knowledge Discovery and Data Mining,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "Classification and novel class detection in concept-drifting data streams under time constraints", "author": ["MM Masud", "J Gao", "L Khan", "J Han", "BM Thuraisingham"], "venue": "IEEE Transactions on Knowledge Data Engineering", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2011}, {"title": "Vehicle tracking across nonoverlapping cameras using joint kinematic and appearance features", "author": ["BC Matei", "HS Sawhney", "S Samarasekera"], "venue": "Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Incremental learning of feature space and classifier for face recognition", "author": ["S Ozawa", "SL Toh", "S Abe", "S Pang", "N Kasabov"], "venue": "Neural Networks", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2005}, {"title": "Localization and trajectory reconstruction in surveillance cameras with nonoverlapping views", "author": ["R Pflugfelder", "H Bischof"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}, {"title": "Active learning with feedback on both features and instances", "author": ["H Raghavan", "O Madani", "R Jones", "P Kaelbling"], "venue": "Journal of Machine Learning Research", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2006}, {"title": "Hierarchical clustering of time-series data streams", "author": ["PP Rodrigues", "J Gama", "JP Pedroso"], "venue": "IEEE Transaction on Knowledge Data Engineering", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Semi-supervised self-training of object detection models", "author": ["C Rosenberg", "M Hebert", "H Schneiderman"], "venue": "Seventh IEEE Workshop on Applications of Computer Vision,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2005}, {"title": "Active learning literature survey", "author": ["B Settles"], "venue": "Tech. Rep. 1648,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Unsupervised learning of discriminative edge measures for vehicle matching between non-overlapping cameras", "author": ["Y Shan", "HS Sawhney", "R Kumar"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2005}, {"title": "Semi-automatic video annotation based on active learning with multiple complementary predictors", "author": ["Y Song", "X sheng Hua", "L rong Dai", "M Wang"], "venue": "Proceedings of ACM SIGMM International Workshop on Multimedia Information Retrieval,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2005}, {"title": "Tracking-based semisupervised learning", "author": ["A Teichman", "S Thrun"], "venue": "Proceedings of Robotics: Science and Systems,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2011}, {"title": "Video object matching across multiple independent views using local descriptors and adaptive learning", "author": ["LF Teixeira", "L Corte-Real"], "venue": "Pattern Recognition Letters", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2009}, {"title": "Automatic description of object appearances in a wide-area surveillance scenario", "author": ["LF Teixeira", "P Carvalho", "JS Cardoso", "L Corte-Real"], "venue": "IEEE International Conference on Image Processing,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2012}, {"title": "Semi-supervised kernel density estimation for video annotation", "author": ["M Wang", "XS Hua", "T Mei", "R Hong", "G Qi", "Y Song", "LR Dai"], "venue": "Comput Vis Image Underst", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2009}, {"title": "Intelligent multi-camera video surveillance: A review", "author": ["X Wang"], "venue": "Pattern Recognition Letters", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2013}, {"title": "An online-optimized incremental learning framework for video semantic classification", "author": ["J Wu"], "venue": "ACM International Conference on Multimedia,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2004}, {"title": "Semisupervised multi-instance multi-label learning for video annotation", "author": ["XS Xu", "Y Jiang", "X Xue", "ZH Zhou"], "venue": "Proceedings of the 20th ACM International Conference on Multimedia,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2012}], "referenceMentions": [{"referenceID": 13, "context": "Recording for hours, days, and possibly years provides massive amount of information coming from an evolving environment in where traditional learning methods fail to reflect evolution taking place [15].", "startOffset": 198, "endOffset": 202}, {"referenceID": 39, "context": "Moreover, accompanying person A with person B or C, group movement (both are identified as a single object) and prolonged occlusion might occur, which might lead to track loss or mistaken identities [42].", "startOffset": 199, "endOffset": 203}, {"referenceID": 27, "context": "To reduce costs of annotation, semi-supervised learning (SSL) approaches have been extensively explored in limited labelled and usually abundant un-labelled data scenarios [29, 12, 18, 28]; however deploying SSL for evolving visual data in a non-stationary environments (where both concept drift and class evolution are present) is still an unexplored area.", "startOffset": 172, "endOffset": 188}, {"referenceID": 11, "context": "To reduce costs of annotation, semi-supervised learning (SSL) approaches have been extensively explored in limited labelled and usually abundant un-labelled data scenarios [29, 12, 18, 28]; however deploying SSL for evolving visual data in a non-stationary environments (where both concept drift and class evolution are present) is still an unexplored area.", "startOffset": 172, "endOffset": 188}, {"referenceID": 16, "context": "To reduce costs of annotation, semi-supervised learning (SSL) approaches have been extensively explored in limited labelled and usually abundant un-labelled data scenarios [29, 12, 18, 28]; however deploying SSL for evolving visual data in a non-stationary environments (where both concept drift and class evolution are present) is still an unexplored area.", "startOffset": 172, "endOffset": 188}, {"referenceID": 26, "context": "To reduce costs of annotation, semi-supervised learning (SSL) approaches have been extensively explored in limited labelled and usually abundant un-labelled data scenarios [29, 12, 18, 28]; however deploying SSL for evolving visual data in a non-stationary environments (where both concept drift and class evolution are present) is still an unexplored area.", "startOffset": 172, "endOffset": 188}, {"referenceID": 3, "context": "Several researchers have shown that the meticulous selection of instances that need to be labelled (mostly addressed in active learning (AL) strategies) could lead to better performance with less effort [4, 34].", "startOffset": 203, "endOffset": 210}, {"referenceID": 32, "context": "Several researchers have shown that the meticulous selection of instances that need to be labelled (mostly addressed in active learning (AL) strategies) could lead to better performance with less effort [4, 34].", "startOffset": 203, "endOffset": 210}, {"referenceID": 8, "context": "Considerable body of multi-camera surveillance research assume that adjacent camera view have overlap [9, 26, 19, 45], whereas [20, 38, 21, 33, 31] require non-overlapping views.", "startOffset": 102, "endOffset": 117}, {"referenceID": 24, "context": "Considerable body of multi-camera surveillance research assume that adjacent camera view have overlap [9, 26, 19, 45], whereas [20, 38, 21, 33, 31] require non-overlapping views.", "startOffset": 102, "endOffset": 117}, {"referenceID": 17, "context": "Considerable body of multi-camera surveillance research assume that adjacent camera view have overlap [9, 26, 19, 45], whereas [20, 38, 21, 33, 31] require non-overlapping views.", "startOffset": 102, "endOffset": 117}, {"referenceID": 42, "context": "Considerable body of multi-camera surveillance research assume that adjacent camera view have overlap [9, 26, 19, 45], whereas [20, 38, 21, 33, 31] require non-overlapping views.", "startOffset": 102, "endOffset": 117}, {"referenceID": 18, "context": "Considerable body of multi-camera surveillance research assume that adjacent camera view have overlap [9, 26, 19, 45], whereas [20, 38, 21, 33, 31] require non-overlapping views.", "startOffset": 127, "endOffset": 147}, {"referenceID": 36, "context": "Considerable body of multi-camera surveillance research assume that adjacent camera view have overlap [9, 26, 19, 45], whereas [20, 38, 21, 33, 31] require non-overlapping views.", "startOffset": 127, "endOffset": 147}, {"referenceID": 19, "context": "Considerable body of multi-camera surveillance research assume that adjacent camera view have overlap [9, 26, 19, 45], whereas [20, 38, 21, 33, 31] require non-overlapping views.", "startOffset": 127, "endOffset": 147}, {"referenceID": 31, "context": "Considerable body of multi-camera surveillance research assume that adjacent camera view have overlap [9, 26, 19, 45], whereas [20, 38, 21, 33, 31] require non-overlapping views.", "startOffset": 127, "endOffset": 147}, {"referenceID": 29, "context": "Considerable body of multi-camera surveillance research assume that adjacent camera view have overlap [9, 26, 19, 45], whereas [20, 38, 21, 33, 31] require non-overlapping views.", "startOffset": 127, "endOffset": 147}, {"referenceID": 30, "context": "Much of the learning literature is concerned with a stationary environment, where fixed and known number of categories to be recognized and enough resources (labelled data, memory and computational power) are available [32, 46].", "startOffset": 219, "endOffset": 227}, {"referenceID": 43, "context": "Much of the learning literature is concerned with a stationary environment, where fixed and known number of categories to be recognized and enough resources (labelled data, memory and computational power) are available [32, 46].", "startOffset": 219, "endOffset": 227}, {"referenceID": 37, "context": "various SSL methods have been proposed for video annotation [39, 44, 47].", "startOffset": 60, "endOffset": 72}, {"referenceID": 41, "context": "various SSL methods have been proposed for video annotation [39, 44, 47].", "startOffset": 60, "endOffset": 72}, {"referenceID": 44, "context": "various SSL methods have been proposed for video annotation [39, 44, 47].", "startOffset": 60, "endOffset": 72}, {"referenceID": 2, "context": "In [3], the person identification task is posed as a graph-based semi-supervised learning problem, where only a few low quality webcam images are labelled.", "startOffset": 3, "endOffset": 6}, {"referenceID": 38, "context": "The classification of objects that have been segmented and tracked without the use of a class-specific tracker, has been addressed with an SSL algorithm in [41].", "startOffset": 156, "endOffset": 160}, {"referenceID": 0, "context": "Ensemble-based approaches constitute a widely popular group of these algorithms to handle concept drift [1, 25] and in some recent works class evolution [16], as well.", "startOffset": 104, "endOffset": 111}, {"referenceID": 23, "context": "Ensemble-based approaches constitute a widely popular group of these algorithms to handle concept drift [1, 25] and in some recent works class evolution [16], as well.", "startOffset": 104, "endOffset": 111}, {"referenceID": 14, "context": "Ensemble-based approaches constitute a widely popular group of these algorithms to handle concept drift [1, 25] and in some recent works class evolution [16], as well.", "startOffset": 153, "endOffset": 157}, {"referenceID": 14, "context": "NSE [16] is one of the latest ensemblebased classification methods in literature, that generates a classifier using each batch of training data and applies a dynamic weighting strategy to define the share of each ensemble in the overall decision.", "startOffset": 4, "endOffset": 8}, {"referenceID": 28, "context": "Masud in [30] proposed an online clustering algorithm for single stream that employs an active strategy in order to minimize oracle collaboration.", "startOffset": 9, "endOffset": 13}, {"referenceID": 20, "context": "The methods that have been proposed [22, 5, 35, 11, 10], require equal length streams coming from a fixed number of sources.", "startOffset": 36, "endOffset": 55}, {"referenceID": 4, "context": "The methods that have been proposed [22, 5, 35, 11, 10], require equal length streams coming from a fixed number of sources.", "startOffset": 36, "endOffset": 55}, {"referenceID": 33, "context": "The methods that have been proposed [22, 5, 35, 11, 10], require equal length streams coming from a fixed number of sources.", "startOffset": 36, "endOffset": 55}, {"referenceID": 10, "context": "The methods that have been proposed [22, 5, 35, 11, 10], require equal length streams coming from a fixed number of sources.", "startOffset": 36, "endOffset": 55}, {"referenceID": 9, "context": "The methods that have been proposed [22, 5, 35, 11, 10], require equal length streams coming from a fixed number of sources.", "startOffset": 36, "endOffset": 55}, {"referenceID": 30, "context": "[32, 46] \u00d7 \u00d7 \u221a \u00d7 SL Constrained MD", "startOffset": 0, "endOffset": 8}, {"referenceID": 43, "context": "[32, 46] \u00d7 \u00d7 \u221a \u00d7 SL Constrained MD", "startOffset": 0, "endOffset": 8}, {"referenceID": 0, "context": "[1] \u00d7 \u00d7 \u221a \u00d7 SL Unconstrained MD", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "[16] \u00d7 \u00d7 \u221a \u221a SL Unconstrained MD", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[30] \u00d7 \u00d7 \u221a \u221a SSL Constrained MD", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[25] \u00d7 \u00d7 \u221a \u00d7 Clustering Unconstrained MD", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5, 35, 11, 10] \u221a \u00d7 \u221a \u221a Clustering Constrained 1D", "startOffset": 0, "endOffset": 15}, {"referenceID": 33, "context": "[5, 35, 11, 10] \u221a \u00d7 \u221a \u221a Clustering Constrained 1D", "startOffset": 0, "endOffset": 15}, {"referenceID": 10, "context": "[5, 35, 11, 10] \u221a \u00d7 \u221a \u221a Clustering Constrained 1D", "startOffset": 0, "endOffset": 15}, {"referenceID": 9, "context": "[5, 35, 11, 10] \u221a \u00d7 \u221a \u221a Clustering Constrained 1D", "startOffset": 0, "endOffset": 15}, {"referenceID": 1, "context": "Considering that, per frame, the composite model produces approximations to the a posteriori probabilities of each class, different combination rules can be considered to build the batch prediction from the individual frame predictions [2, 24].", "startOffset": 236, "endOffset": 243}, {"referenceID": 22, "context": "Considering that, per frame, the composite model produces approximations to the a posteriori probabilities of each class, different combination rules can be considered to build the batch prediction from the individual frame predictions [2, 24].", "startOffset": 236, "endOffset": 243}, {"referenceID": 1, "context": "In fact some authors have shown that the arithmetic mean outperforms the geometric mean in the presence of strong noise [2, 24].", "startOffset": 120, "endOffset": 127}, {"referenceID": 22, "context": "In fact some authors have shown that the arithmetic mean outperforms the geometric mean in the presence of strong noise [2, 24].", "startOffset": 120, "endOffset": 127}, {"referenceID": 35, "context": "Various criteria have been introduced as uncertainty measures in literature for a probabilistic framework [37].", "startOffset": 106, "endOffset": 110}, {"referenceID": 35, "context": "Thus, it effectively \u201cthrows away\u201d information about the remaining label distribution [37].", "startOffset": 86, "endOffset": 90}, {"referenceID": 35, "context": "Batches with small margins are more ambiguous, thus knowing the true label would help the model discriminate more effectively between them [37].", "startOffset": 139, "endOffset": 143}, {"referenceID": 5, "context": "In this case, and although probabilities play no role in the design of the discriminant function, it is still possible to get estimated for the conditional probabilities [6].", "startOffset": 170, "endOffset": 173}, {"referenceID": 21, "context": "We resort to one-class classifiers for these time slots, also known as unary classification, to distinguish the single class present in the training set (the batches in the time slot) from all other possible classes [23].", "startOffset": 216, "endOffset": 220}, {"referenceID": 14, "context": "This process is similar to the one used in [16].", "startOffset": 43, "endOffset": 47}, {"referenceID": 40, "context": "We employ an automatic tracking approach [43] to track objects in the scene and generate streams of bounding boxes, which define the tracked objects\u2019 positions.", "startOffset": 41, "endOffset": 45}, {"referenceID": 39, "context": "An hierarchical bag-of-visterms method is applied to represent the tracked objects, resulting in a descriptor vector of size 11110 for each frame (refer to [42] for additional details).", "startOffset": 156, "endOffset": 160}, {"referenceID": 7, "context": "We chose the following methods: Gaussian Mixture Models (GMM) and Naive Bayes as generative approaches, Support Vector Machines (SVM) [8] as one of the most popular discriminant function and logistic regression [17] as a member of discriminative approaches family.", "startOffset": 134, "endOffset": 137}, {"referenceID": 15, "context": "We chose the following methods: Gaussian Mixture Models (GMM) and Naive Bayes as generative approaches, Support Vector Machines (SVM) [8] as one of the most popular discriminant function and logistic regression [17] as a member of discriminative approaches family.", "startOffset": 211, "endOffset": 215}, {"referenceID": 12, "context": "We applied Friedman test [14] that provides a non-parametric rank based statistical significance test.", "startOffset": 25, "endOffset": 29}], "year": 2014, "abstractText": "The practicality of a video surveillance system is adversely limited by the amount of queries that can be placed on human resources and their vigilance in response. To transcend this limitation, a major effort under way is to include software that (fully or at least semi) automatically mines video footage, reducing the burden imposed to the system. Herein, we propose a semi-supervised incremental learning framework for evolving visual streams in order to develop a robust and flexible track classification system. Our proposed method learns from consecutive batches by updating an ensemble in each time. It tries to strike a balance between performance of the system and amount of data which needs to be labelled. As no restriction is considered, the system can address many practical problems in an evolving multi-camera scenario, such as concept drift, class evolution and various length of video streams which have not been addressed before. Experiments were performed on synthetic as well as real-world visual data in non-stationary environments, showing high accuracy with fairly little human collaboration.", "creator": "LaTeX with hyperref package"}}}