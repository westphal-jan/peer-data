{"id": "1405.3487", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-May-2014", "title": "COCOpf: An Algorithm Portfolio Framework", "abstract": "Algorithm portfolios represent a strategy of composing multiple heuristic algorithms, each suited to a different class of problems, within a single general solver that will choose the best suited algorithm for each input. This approach recently gained popularity especially for solving combinatoric problems, but optimization applications are still emerging. The COCO platform of the BBOB workshop series is the current standard way to measure performance of continuous black-box optimization algorithms.", "histories": [["v1", "Wed, 14 May 2014 13:26:57 GMT  (1127kb)", "http://arxiv.org/abs/1405.3487v1", "POSTER2014. arXiv admin note: text overlap witharXiv:1206.5780by other authors without attribution"]], "COMMENTS": "POSTER2014. arXiv admin note: text overlap witharXiv:1206.5780by other authors without attribution", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["petr baudi\\v{s}"], "accepted": false, "id": "1405.3487"}, "pdf": {"name": "1405.3487.pdf", "metadata": {"source": "CRF", "title": "COCOpf: An Algorithm Portfolio Framework", "authors": ["Petr Baudi\u0161"], "emails": ["pasky@ucw.cz"], "sections": [{"heading": null, "text": "This year, it will only be once before such an outcome is achieved."}, {"heading": "About Author. . .", "text": "Petr Baudis holds a bachelor's and master's degree in Theoretical Computer Science from Charles University in Prague. In his master's thesis \"MCTS with Information Sharing,\" he presented a state-of-the-art computer go program. He is currently a doctoral student at the Czech Technical University with a major interest in algorithm portfolios and Monte Carlo tree search applications."}], "references": [{"title": "A limited memory algorithm for bound constrained optimization", "author": ["BYRD R. H", "LU P", "NOCEDAL J", "ZHU"], "venue": "SIAM Journal on Scientific Computing 16,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1995}, {"title": "Realparameter black-box optimization benchmarking 2009: Presentation of the noiseless functions", "author": ["S. FINCK", "N. HANSEN", "R. ROS", "A. AUGER"], "venue": "Research Center PPE,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "The CMA evolution strategy: a comparing review", "author": ["N. HANSEN"], "venue": "Advances on estimation of distribution algorithms,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "AND ROS, R. Real-parameter black-box optimization benchmarking 2012", "author": ["N. HANSEN", "A. AUGER", "S. FINCK"], "venue": "Experimental setup. Tech. rep., INRIA,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Real-parameter black-box optimization benchmarking 2009: Noiseless functions definitions", "author": ["N. HANSEN", "S. FINCK", "R. ROS", "A. AUGER"], "venue": "Tech. Rep. RR-6829,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "SciPy: Open source scientific tools for Python, 2001", "author": ["E. JONES", "T. OLIPHANT", "P PETERSON"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Algorithm selection for combinatorial search problems: A survey", "author": ["L. KOTTHOFF"], "venue": "AI Magazine", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "A software package for sequential quadratic programming", "author": ["D. KRAFT"], "venue": "DFVLR Obersfaffeuhofen,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1988}, {"title": "The algorithm selection problem on the continuous optimization domain", "author": ["M. MU\u00d1OZ", "M. KIRLEY", "S. HALGAMUGE"], "venue": "In Computational Intelligence in Intelligent Data Analysis,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "A simplex method for function minimization", "author": ["J.A. NELDER", "R. MEAD"], "venue": "The Computer Journal 7,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1965}, {"title": "An efficient method for finding the minimum of a function of several variables without calculating derivatives", "author": ["M.J. POWELL"], "venue": "The computer journal 7,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1964}, {"title": "Differential evolution vs. the functions of the second ICEO", "author": ["K. PRICE"], "venue": "In Proceedings of the IEEE International Congress on Evolutionary Computation", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1997}, {"title": "The algorithm selection problem", "author": ["J.R. RICE"], "venue": "Advances in Computers", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1976}, {"title": "Self-adaptive multimethod search for global optimization in real-parameter spaces", "author": ["J.A. VRUGT", "B.A. ROBINSON", "J.M. HYMAN"], "venue": "IEEE Trans. on Evolutionary Computation 13,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Global optimization by basinhopping and the lowest energy structures of lennard-jones clusters containing up to 110 atoms", "author": ["D.J. WALES", "J.P.K. DOYE"], "venue": "The Journal of Physical Chemistry A 101,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1997}, {"title": "Direct search methods: Once scorned, now respectable", "author": ["M.H. WRIGHT"], "venue": "Pitman Research Notes in Math. Series", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1996}, {"title": "Algorithm 778: L-bfgs-b: Fortran subroutines for large-scale bound-constrained optimization", "author": ["C. ZHU", "R.H. BYRD", "P. LU", "J. NOCEDAL"], "venue": "ACM Transactions on Mathematical Software (TOMS) 23,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1997}], "referenceMentions": [{"referenceID": 3, "context": "The COCO platform [6] [5] of the BBOB workshop series is the current standard way to measure performance of continuous black-box optimization algorithms.", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "As a demonstration, we measure the performance of stock SciPy [8] optimization algorithms and the popular CMA algorithm [4] alone and in a portfolio with two simple selection strategies.", "startOffset": 62, "endOffset": 65}, {"referenceID": 2, "context": "As a demonstration, we measure the performance of stock SciPy [8] optimization algorithms and the popular CMA algorithm [4] alone and in a portfolio with two simple selection strategies.", "startOffset": 120, "endOffset": 123}, {"referenceID": 12, "context": "Introduction The problem of Algorithm Selection is not new [16], but has only recently gained traction in particular in the field of combinatoric problem solvers.", "startOffset": 59, "endOffset": 63}, {"referenceID": 6, "context": "[9] There are multiple ways to approach the issue, in our work we adopt the abstraction of algorithm portfolios.", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "the AMALGAMSO algorithm [17], or in offline methods based chiefly on exploratory landscape analysis [11].", "startOffset": 24, "endOffset": 28}, {"referenceID": 8, "context": "the AMALGAMSO algorithm [17], or in offline methods based chiefly on exploratory landscape analysis [11].", "startOffset": 100, "endOffset": 104}, {"referenceID": 3, "context": "The currently accepted de-facto standard for benchmarking optimization methods is the COmparing Continuous Optimisers COCO platform [6] [5] that was originally developed for the BBOB workshop series.", "startOffset": 136, "endOffset": 139}, {"referenceID": 5, "context": "We are in part motivated by the convenient availability of optimization algorithms distributed along the popular SciPy library [8].", "startOffset": 127, "endOffset": 130}, {"referenceID": 5, "context": "13 [8] that are available for direct use:4", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "[12] [19] \u2022 Powell implements a tweaked version of the Powell\u2019s conjugate direction method.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[12] [19] \u2022 Powell implements a tweaked version of the Powell\u2019s conjugate direction method.", "startOffset": 5, "endOffset": 9}, {"referenceID": 10, "context": "[14] \u2022 CG is a nonlinear conjugate gradient method using the Fletcher-Reeves method.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1] [20] \u2022 SLSQP implements Sequential Least SQuares Programming [10] with inequalities as the box constraints.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "[1] [20] \u2022 SLSQP implements Sequential Least SQuares Programming [10] with inequalities as the box constraints.", "startOffset": 4, "endOffset": 8}, {"referenceID": 7, "context": "[1] [20] \u2022 SLSQP implements Sequential Least SQuares Programming [10] with inequalities as the box constraints.", "startOffset": 65, "endOffset": 69}, {"referenceID": 14, "context": "All of these SciPy minimizers perform local minimization; to achieve global optimization, we wrap them in the \u201cBasin Hopping\u201d restart strategy [18] (also provided by SciPy), which is conceptually similar to Simulated Annealing with a fixed temperature.", "startOffset": 143, "endOffset": 147}, {"referenceID": 2, "context": "To improve the portfolio performance on more difficult functions, we also included the popular CMA algorithm [4] (in the \u201cproduction\u201c version of its official reference Python implementation), i.", "startOffset": 109, "endOffset": 112}, {"referenceID": 3, "context": "Results Results from experiments according to [5] on the benchmark functions given in [2, 7] are presented in Figures 2, 3 and 4.", "startOffset": 46, "endOffset": 49}, {"referenceID": 1, "context": "Results Results from experiments according to [5] on the benchmark functions given in [2, 7] are presented in Figures 2, 3 and 4.", "startOffset": 86, "endOffset": 92}, {"referenceID": 4, "context": "Results Results from experiments according to [5] on the benchmark functions given in [2, 7] are presented in Figures 2, 3 and 4.", "startOffset": 86, "endOffset": 92}, {"referenceID": 3, "context": "6 The expected running time (ERT) used in the figures depends on a given target function value, ft = fopt+\u2206f , and is computed over all relevant trials as the number of function evaluations executed during each trial while the best function value did not reach ft, summed over all trials and divided by the number of trials that actually reached ft [5, 15].", "startOffset": 349, "endOffset": 356}, {"referenceID": 11, "context": "6 The expected running time (ERT) used in the figures depends on a given target function value, ft = fopt+\u2206f , and is computed over all relevant trials as the number of function evaluations executed during each trial while the best function value did not reach ft, summed over all trials and divided by the number of trials that actually reached ft [5, 15].", "startOffset": 349, "endOffset": 356}], "year": 2014, "abstractText": "Algorithm portfolios represent a strategy of composing multiple heuristic algorithms, each suited to a different class of problems, within a single general solver that will choose the best suited algorithm for each input. This approach recently gained popularity especially for solving combinatoric problems, but optimization applications are still emerging. The COCO platform [6] [5] of the BBOB workshop series is the current standard way to measure performance of continuous black-box optimization algorithms. As an extension to the COCO platform, we present the Python-based COCOpf framework that allows composing portfolios of optimization algorithms and running experiments with different selection strategies. In our framework, we focus on black-box algorithm portfolio and online adaptive selection. As a demonstration, we measure the performance of stock SciPy [8] optimization algorithms and the popular CMA algorithm [4] alone and in a portfolio with two simple selection strategies. We confirm that even a naive selection strategy can provide improved performance across problem classes.", "creator": "LaTeX with hyperref package"}}}