{"id": "1405.3843", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-May-2014", "title": "Logistic Regression: Tight Bounds for Stochastic and Online Optimization", "abstract": "The logistic loss function is often advocated in machine learning and statistics as a smooth and strictly convex surrogate for the 0-1 loss. In this paper we investigate the question of whether these smoothness and convexity properties make the logistic loss preferable to other widely considered options such as the hinge loss. We show that in contrast to known asymptotic bounds, as long as the number of prediction/optimization iterations is sub exponential, the logistic loss provides no improvement over a generic non-smooth loss function such as the hinge loss. In particular we show that the convergence rate of stochastic logistic optimization is bounded from below by a polynomial in the diameter of the decision set and the number of prediction iterations, and provide a matching tight upper bound. This resolves the COLT open problem of McMahan and Streeter (2012).", "histories": [["v1", "Thu, 15 May 2014 13:29:27 GMT  (27kb)", "http://arxiv.org/abs/1405.3843v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["elad hazan", "tomer koren", "kfir y levy"], "accepted": false, "id": "1405.3843"}, "pdf": {"name": "1405.3843.pdf", "metadata": {"source": "CRF", "title": "Logistic Regression: Tight Bounds for Stochastic and Online Optimization\u2217", "authors": ["Elad Hazan", "Tomer Koren", "Kfir Y. Levy"], "emails": ["ehazan@ie.technion.ac.il,", "tomerk@technion.ac.il,", "kfiryl@tx.technion.ac.il."], "sections": [{"heading": null, "text": "ar Xiv: 140 5.38 43v1 [cs.LG] 1 5"}, {"heading": "1 Introduction", "text": "In many cases, such as estimating the click rate in web advertising, and predicting whether a patient has a particular disease, the logistical loss is often the loss of choice. It appeals as a convex substitute for the 0-1 loss and as a tool that not only provides categorical predictions, but is also able to estimate the underlying probabilities of the categories (see Langford (2009), Bulatov (2007) and Collins et al. (2002) have shown that logistical regression is strongly associated with boosting. A long-standing debate in the machine learning community has been the optimal choice of the surrogate loss function for binary prediction problems (see Langford (2009), Bulatov (2007)). The arguments in support of logistic loss are strongly linked to its smoothness and strict cyclical characteristics, which, unlike other loss functions (such as hinge loss), allow the research leading to these results to be funded from the Seventh Framework Programme of the European Union (FP7) 2007-2013."}, {"heading": "2 Setting and Background", "text": "This section formalizes the settings of stochastic logistic regression and online logistic regression and provides the necessary background information on both problems."}, {"heading": "2.1 Stochastic Logistic Regression", "text": "In the problem of stochastic logistic regression, there is an unknown distribution D over the instances x-w (W-W). For the sake of simplicity, we assume that the optimization algorithm is to minimize the expected loss of a linear predictor w-Rn, L (w) = Ex-D [(w, x)], (1), which is the logistic loss function1, (w, x) = log (1 + exp (x \u00b7 w))), which expresses the negative log probability of the instance x under the logit model. While we can try to optimize L (w) over the entire Euclidean space, for generalization purposes we usually limit the optimization range to a limited amount. In this thesis, we focus on optimizing the expected loss over the set W = {w-Rn: \"w-D,\" the euclidean ball of radius D. We define the excessive loss of a linear predictor as the expected W-W-W (W-W-W-W) loss of the W-W-W-W-W-W."}, {"heading": "2.2 Online Logistic Regression", "text": "Another optimization framework we are considering is the online logistics optimization, which we formalize as the following game between a player and an opponent. In each round, the opponent first selects an instance xt-Rn, the player then selects a linear predictor wt-W = {w-Rn: w-Rn-D}, observes xt and incurs losses (wt, xt) = log (1 + exp (xt \u00b7 wt)). For simplicity's sake, we assume again that \"xt-1 for all t.\" The goal of the player is to minimize his regret with respect to a fixed prediction from the set W, which is defined as RegretT = T-t = 1 (wt, xt) \u2212 min w-t-WT-t = 1 (w-t, xt)."}, {"heading": "2.3 Information-theoretic Tools", "text": "Theorem 1. Let us assume that a biased coin is either p or p + B, where p + B (0, 1 2] is given. Any algorithm that correctly identifies coin bias with a probability of at least 3 / 4 requires no less than p / 162 rolls. The theorem applies to both deterministic and randomized algorithms; in the case of random algorithms, the probability is given both with respect to the underlying distribution of samples and to the randomization of the algorithm. Proof theorem 1 is for completeness in Appendix A."}, {"heading": "3 Lower Bounds for Logistic Regression", "text": "In this section, we deduce lower limits for the convergence rate of stochastic logistic regression. To provide clarity, we reduce the number of observations T that are required to achieve an excessive loss of maximum \u0430, which we translate directly into a limit for the convergence rate. The lower limits of stochastic optimization are then used to obtain corresponding limits for online adjustment. In Section 3.1, we set a lower limit for the one-dimensional case, in Section 3.2, we set another lower limit for the multidimensional case, and in Section 3.3, we present our lower limits for online adjustment."}, {"heading": "3.1 One-dimensional Lower Bound for Stochastic Optimization", "text": "We show that any algorithm for one-dimensional stochastic optimization with logistical loss must observe at least two probable cases before it provides an instance with an expected excessive loss. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 This leads directly to a convergence rate of \u20ac(D2 / 3 / T 2 / 3). For each algorithm A, there is a distribution D for which the expected excessive loss of A production is at least two percent (D2 / 3 / T 2 / 3). The proof for theorem 2 is provided at the end of this section; here we give an informal proof of a distribution D for which the expected excessive loss of A production is at least two percent (D2 / 3 / T 2 / 3)."}, {"heading": "3.2 Multidimensional Lower Bound for Stochastic Optimization", "text": "We now construct two distributions via instance vectors of unit R2, and prove that any algorithm that achieves an expected excess of losses at both distributions has at least one loss of (D / 2). (D / 2) This leads directly to a convergence rate of (D / T). For n > 2 dimensions, we can embed the same construction into the unit of Rn, so that our fixed budget is greater than one. (D / 2) The main theorem of this section is the following: Theorem 4. Consider the multidimensional stochastic logistic regression associated with D / 2 and a fixed sample budget T = O (eD). There is a distribution D like the expected surplus of A's production is at least one (D / T).Theorem 4 is proved at the end of this section. We will provide an informal description of the distributions that choose between the set ranges."}, {"heading": "3.3 Lower Bounds for Online Optimization", "text": "In section 3, we have shown two lower limits for the convergence rate of stochastic logistic regression: the standard conversion from stack to stack (Cesa-Bianchi et al., 2004) shows that any online algorithm that achieves a regret of R (T) can be used to achieve a convergence rate of R (T) / T for stochastic optimization. Consequently, the lower limits mentioned in theorems 2 and 4 imply the following: Conclusion 7. Consider the one-dimensional online logistic regression setting with T = O (eD). For each algorithm A, there is a sequence of loss functions, so that A suffers a regret of at least L (D2 / 3T 1 / 3). Conclusion 8. Consider the multidimensional online logistic regression setting with T = O (eD), D \u2265 2. For each algorithm A, there is a sequence of losses of at least L (D2 / 3T 1 / 3), so that T suffers a loss of L."}, {"heading": "4 Upper Bound for One-dimensional Regression", "text": "In this section, we consider the online regression (1 + 3 T / 3) in a dimension in which we obtain the following guarantees: RegretT = T = 1log (1 + extwt). (1 + extwt). (1 + extwt). (1 + extwt). (1 + extwt). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1. (1). (1). (1. (1.). (1. (1.). (1. (1.). (1.). (1. (1.). (1.). (1. (1.). (1.). (1. (1.). (1.). (1. (1.). (1.). (1.). (1. (1.). (1.). (1.). (1. (1.). (1. (1.).). (1. (1.). (1.). (1. (1.). (1.). (1.). (1. (1.). (1.).). (1.). (1. (1. (1.).). (1. (1. (1.). (1.). (1.). (1. (1. (1.). (.). (1.). (1. (1. (1.). (1.). (1.). (1.). (1.). (1. (1.). (1.). (1. (1.). (1. (1.).). (1. (1.). ("}, {"heading": "5 Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Proof of Theorem 3", "text": "We assume that the following values apply: D + D = 40e \u2212 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b (D = 4b = 4b = 4b = 4b = 4b = 4b = 4b (D = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b \u2212 \u2212 \u2212 \u2212 \u2212 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b 4b = 4b = 4b = 4b \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b = 4b \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 4b = 4b = 4b = 4b = 4b \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 4b = 4b = 4b = 4b = 4b ="}, {"heading": "5.2 Proof of Theorem 5", "text": "The proof: We assume that the following is sufficient to show that 0 (0) we 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0) = 0 (0). We want to show that w0 (0) = 0 (0, 0.9D) = 0 (0, 0.9D) = 0 (0) = 0 (0, 0.9D) = 0 (0) = 0 (0, 0.9D) is the global minimizer of L0 (0); since L0 (w) we are sufficient to show that we (0) = 0 (0, 0.9D) = 0 (0) = 0 (0, 0.9D) = 0 (0) = 0 (0, 0.9D) = 0 (0)."}, {"heading": "5.3 Proof of Theorem 9", "text": "Since the approximate losses in the EQ. (4) the uppermost differences between these two factors cannot be taken into account, it is sufficient to set the lower limit for the regret of the people in the EQ. (4) the lower limit for the regret of the people in the EQ. (4) the lower limit for the losses in the EQ. (4) the lower limit for the regret of the people in the EQ. (4) the lower limit for the losses in the EQ. (4) the lower limit for the losses in the EQ. (4) the lower limit for the losses in the EQ. (4) the lower limit for the lower difference in the EQ. (1) the lower difference in the EQ. (1) the lower difference in the EQ. (1) the lower difference in the EQ. (1) the lower difference in the EQ. (1) the lower difference in the EQ. (1) the lower (1) the difference in the EQ."}, {"heading": "5.3.3 Concluding the proof", "text": "According to sections 5.3.1 and 5.3.2, the regret of algorithm 1 is higher limited by: RegretT \u2264 48D log (T + 1) + 24DT 1 / 3 + 480D3T 1 / 3 + D16 T 1 / 3, where the last term is due to regulation."}, {"heading": "5.4 Proof of Theorem 12", "text": "(\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log\") (\"Log (\") (\"Log\") (\") (\" Log (\") (\" Log) (\") (\") (\"Log\") (\") (\") (\"(\") (\") (\") (\"(\") (\") (\") (\") (\") (\") (\") (\") (\" (\") (\") (\"(\") (\") (\" (\") (\") (\"(\") (\") (\") (\"(\") (\") (\") (\"(\") (\") (\" (\") (\") (\") (\") (\"(\") (\") (\") (\") (\") (\") (\") (\") (\") (\") (\") (\"(\") \"(\") (\")\" (\")\" (\")\" (\"(\") \"(\") \"(\" (\")\" (\")\" (\")\" (\"(\") \"(\") \"(\" (\")\" (\"(\") (\")\" (\"(\" (\")\" (\")\" (\") (\" (\") (\" (\") (\") (\") (\" (\"(\") (\") (\" (\") (\") (\"(\") (\"(\") (\") (\" (\") (\" (\") (\") (\") (\" (\"(\") (\") (\") (\") (\" (\") (\" (\") (\") (\"(\") (\"(\") (\"(\") (\") (\") (\") (\" ("}, {"heading": "6 Summary and Open Questions", "text": "As a result, we have also solved the open COLT 2012 problem of McMahan and Streeter (2012). Our lower limits can be extended to the multidimensional environment where cases are normalized and labels are binary. Our results suggest that second-order methods may perform poorly in practical logistical regression problems. In fact, in deriving our lower limits, we have constructed a distribution across cases where the induced expected loss function is approximately linear around its optimum. An interesting feature of our results is that our regret / convergence limits apply to a limited range of T and differ from the known asymptotic limits."}, {"heading": "A Proof of Theorem 1", "text": "Suppose a randomized algorithm A decides on one of the coins based on m-tosses, and specifies by DA the conditional distribution of the algorithm for its decision based on m-coin tosses. \u2212 We also allow Dp, Dp + \u2264 to specify the respective Bernoulli distributions corresponding to a single roll; let Dmp, Dmp + \u0432 be the product distributions of a sequence of m-independent tosses, and let Dmp, A, Dp +, A be the common distributions based on the sequence of m-independent tosses and the decision of the randomized algorithm. \u2212 For proof we need the following standard dilemma. \u2212 Lemma 16. For all events B in the room of m-independent tosses and the decision of the algorithm: Dmp, A (B) \u2212 Dmp +, A (B) \u2212 inequality, A (B), B \u2212 unity. \u2212 p: For proof, we need the following standard dilemma: Lemon A, Lemon A \u2212 unequal 16. \u2212 Unity B, B \u2212 unequal, B \u2212 unequal. \u2212 Unity."}], "references": [{"title": "Adaptivity of averaged stochastic gradient descent to local strong convexity for logistic regression", "author": ["F. Bach"], "venue": "arXiv preprint arXiv:1303.6149,", "citeRegEx": "Bach.,? \\Q2013\\E", "shortCiteRegEx": "Bach.", "year": 2013}, {"title": "Non-strongly-convex smooth stochastic approximation with convergence rate O(1/n)", "author": ["F. Bach", "E. Moulines"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Bach and Moulines.,? \\Q2013\\E", "shortCiteRegEx": "Bach and Moulines.", "year": 2013}, {"title": "Log loss or hinge loss? http://yaroslavvb.blogspot.co.il/2007/06/log-loss-or-hinge-l", "author": ["Y. Bulatov"], "venue": null, "citeRegEx": "Bulatov.,? \\Q2007\\E", "shortCiteRegEx": "Bulatov.", "year": 2007}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["N. Cesa-Bianchi", "A. Conconi", "C. Gentile"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2004}, {"title": "Logistic regression, adaboost and bregman distances", "author": ["M. Collins", "R.E. Schapire", "Y. Singer"], "venue": "Machine Learning,", "citeRegEx": "Collins et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Collins et al\\.", "year": 2002}, {"title": "Additive logistic regression: a statistical view of boosting", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": "The annals of statistics,", "citeRegEx": "Friedman et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2000}, {"title": "A survey: The convex optimization approach to regret minimization", "author": ["E. Hazan"], "venue": "Optimization for Machine Learning,", "citeRegEx": "Hazan.,? \\Q2011\\E", "shortCiteRegEx": "Hazan.", "year": 2011}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["E. Hazan", "A. Agarwal", "S. Kale"], "venue": "Machine Learning,", "citeRegEx": "Hazan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 3, "context": "Moreover, Friedman et al. (2000) and Collins et al.", "startOffset": 10, "endOffset": 33}, {"referenceID": 3, "context": "(2000) and Collins et al. (2002) have shown that logistic regression is strongly connected to boosting.", "startOffset": 11, "endOffset": 33}, {"referenceID": 3, "context": "(2000) and Collins et al. (2002) have shown that logistic regression is strongly connected to boosting. A long standing debate in the machine learning community has been the optimal choice of surrogate loss function for binary prediction problems (see Langford (2009), Bulatov (2007)).", "startOffset": 11, "endOffset": 268}, {"referenceID": 2, "context": "A long standing debate in the machine learning community has been the optimal choice of surrogate loss function for binary prediction problems (see Langford (2009), Bulatov (2007)).", "startOffset": 165, "endOffset": 180}, {"referenceID": 7, "context": "Thus, the Online Newton Step algorithm (Hazan et al., 2007) can be applied to the logistic regression problem and gives a convergence rate of \u00d5(en/T ) over T iterations.", "startOffset": 39, "endOffset": 59}, {"referenceID": 0, "context": "Bach (2013), relying on a property called \u201cgeneralized self-concordance\u201d, gave an algorithm with convergence rate ofO(D4/\u03bc\u2217T ), where \u03bc\u2217 is the smallest eigenvalue of the Hessian at the optimal point.", "startOffset": 0, "endOffset": 12}, {"referenceID": 0, "context": "Bach (2013), relying on a property called \u201cgeneralized self-concordance\u201d, gave an algorithm with convergence rate ofO(D4/\u03bc\u2217T ), where \u03bc\u2217 is the smallest eigenvalue of the Hessian at the optimal point. This translates to a O(poly(D)/T ) rate whenever the expected loss function is \u201clocally strongly convex\u201d at the optimum. More recently, Bach and Moulines (2013) extended this result and presented an elegant algorithm that attains a rate of the form O(\u03c1Dn/T ), without assuming strong convexity (neither global or local) \u2014 but rather depending on a certain data-dependent constant \u03c1.", "startOffset": 0, "endOffset": 362}, {"referenceID": 0, "context": "Bach (2013), relying on a property called \u201cgeneralized self-concordance\u201d, gave an algorithm with convergence rate ofO(D4/\u03bc\u2217T ), where \u03bc\u2217 is the smallest eigenvalue of the Hessian at the optimal point. This translates to a O(poly(D)/T ) rate whenever the expected loss function is \u201clocally strongly convex\u201d at the optimum. More recently, Bach and Moulines (2013) extended this result and presented an elegant algorithm that attains a rate of the form O(\u03c1Dn/T ), without assuming strong convexity (neither global or local) \u2014 but rather depending on a certain data-dependent constant \u03c1. In this paper, we resolve the above question and give tight characterization of the achievable convergence rates for logistic regression. We show that as long as the target accuracy \u01eb is not exponentially small in D, a rate of the form \u00d5(poly(D)/T ) is not attainable. Specifically, we prove a lower bound of \u03a9( \u221a D/T ) on the convergence rate, that can also be achieved (up to a \u221a D factor) by stochastic gradient descent algorithms. In particular, this shows that in the worst case, the magnitude of data-dependent parameters used in previous works are exponentially large in the diameter D. The latter lower bound only applies for multidimensional regression (i.e., when n \u2265 2); surprisingly, in one-dimensional logistic regression we find a rate of \u0398(T\u22122/3) to be tight. As far as we know, this is the first natural setting demonstrating such a phase transition in the optimal convergence rates, with respect to the dimensionality of the problem. We also consider the closely-related online optimization setting, where on each round t = 1, 2, . . . , T an adversary chooses a certain logistic function and our goal is to minimize the T -round regret, with respect to the best fixed decision chosen with the benefit of hindsight. In this setting, McMahan and Streeter (2012) investigated the one-dimensional case and showed that if the adversary is restricted to pick binary (i.", "startOffset": 0, "endOffset": 1862}, {"referenceID": 0, "context": "Bach (2013), relying on a property called \u201cgeneralized self-concordance\u201d, gave an algorithm with convergence rate ofO(D4/\u03bc\u2217T ), where \u03bc\u2217 is the smallest eigenvalue of the Hessian at the optimal point. This translates to a O(poly(D)/T ) rate whenever the expected loss function is \u201clocally strongly convex\u201d at the optimum. More recently, Bach and Moulines (2013) extended this result and presented an elegant algorithm that attains a rate of the form O(\u03c1Dn/T ), without assuming strong convexity (neither global or local) \u2014 but rather depending on a certain data-dependent constant \u03c1. In this paper, we resolve the above question and give tight characterization of the achievable convergence rates for logistic regression. We show that as long as the target accuracy \u01eb is not exponentially small in D, a rate of the form \u00d5(poly(D)/T ) is not attainable. Specifically, we prove a lower bound of \u03a9( \u221a D/T ) on the convergence rate, that can also be achieved (up to a \u221a D factor) by stochastic gradient descent algorithms. In particular, this shows that in the worst case, the magnitude of data-dependent parameters used in previous works are exponentially large in the diameter D. The latter lower bound only applies for multidimensional regression (i.e., when n \u2265 2); surprisingly, in one-dimensional logistic regression we find a rate of \u0398(T\u22122/3) to be tight. As far as we know, this is the first natural setting demonstrating such a phase transition in the optimal convergence rates, with respect to the dimensionality of the problem. We also consider the closely-related online optimization setting, where on each round t = 1, 2, . . . , T an adversary chooses a certain logistic function and our goal is to minimize the T -round regret, with respect to the best fixed decision chosen with the benefit of hindsight. In this setting, McMahan and Streeter (2012) investigated the one-dimensional case and showed that if the adversary is restricted to pick binary (i.e. \u00b11) labels, a simple followthe-leader algorithm attains a regret bound of O( \u221a D + log T ). This discovery led them to conjecture that bounds of the form O(poly(D) log T ) should be achievable in the general multi-dimensional case with continuous labels set. Our results extend to the online optimization setup and resolve the COLT 2012 open problem of McMahan and Streeter (2012) on the negative side.", "startOffset": 0, "endOffset": 2349}, {"referenceID": 7, "context": "As opposed to previous works that utilize approximate losses based on local structure (Zinkevich, 2003; Hazan et al., 2007), we find it necessary to employ approximations that rely on the global structure of the logistic loss.", "startOffset": 86, "endOffset": 123}, {"referenceID": 3, "context": "Standard online-to-batch conversion (Cesa-Bianchi et al., 2004) shows that any online algorithm attaining a regret of R(T ) can be used to attain a convergence rate of R(T )/T for stochastic optimization.", "startOffset": 36, "endOffset": 63}, {"referenceID": 3, "context": "Using standard online-to-batch conversion techniques Cesa-Bianchi et al. (2004), we can translate the upper bound given in the above lemma to an upper bound for stochastic optimization.", "startOffset": 53, "endOffset": 80}, {"referenceID": 6, "context": "Following Zinkevich (2003) and Hazan et al. (2007), we approximate the losses received by the adversary, and use the approximate losses in a follow-the-regularized-leader (FTRL) procedure in order to choose the predictors.", "startOffset": 31, "endOffset": 51}, {"referenceID": 6, "context": "First note the following lemma due to Zinkevich (2003) (proof is found in Hazan et al. (2007)): Lemma 11.", "startOffset": 74, "endOffset": 94}, {"referenceID": 6, "context": "The expression for ut in Algorithm 2 is useful since it enables us to calculate the differences |ut\u22121\u2212 ut|, which upper bound the differences between predictors: |wt\u22121 \u2212wt|; these differences are useful in bounding the regret of FTRL as seen in the next lemma due to Kalai and Vempala (2005) (proof can be found in Hazan (2011) or in Shalev-Shwartz (2011)):", "startOffset": 315, "endOffset": 328}, {"referenceID": 6, "context": "The expression for ut in Algorithm 2 is useful since it enables us to calculate the differences |ut\u22121\u2212 ut|, which upper bound the differences between predictors: |wt\u22121 \u2212wt|; these differences are useful in bounding the regret of FTRL as seen in the next lemma due to Kalai and Vempala (2005) (proof can be found in Hazan (2011) or in Shalev-Shwartz (2011)):", "startOffset": 315, "endOffset": 356}, {"referenceID": 6, "context": "where we used \u03b2 = 1/8D together with the following lemma, taken from Hazan et al. (2007): Lemma 14.", "startOffset": 69, "endOffset": 89}, {"referenceID": 6, "context": "To prove l\u0303t(w) \u2264 lt(w), we require the following lemma from Hazan et al. (2007): Lemma 15.", "startOffset": 61, "endOffset": 81}, {"referenceID": 6, "context": "To prove l\u0303t(w) \u2264 lt(w), we require the following lemma from Hazan et al. (2007): Lemma 15. For a function f : K \u2192 R, where K has diameter D, such that \u2200w \u2208 K, ||\u2207f(w)|| \u2264 G, and e\u2212\u03b1f(w) is concave, the following holds for \u03b3 = 1 2 min{ 1 4GD , \u03b1}: f(w) \u2265 f(w0) +\u2207f(w0) (w \u2212 w0) + \u03b3 2 (\u2207f(w0) (w \u2212 w0)), \u2200w,w0 \u2208 K In Hazan et al. (2007) it is also shown that for one dimensional functions, if \u03b1 \u2264 minw\u2208K f \u2032\u2032(w) ( f \u2032(w) )2 , then e\u2212\u03b1f(w) is concave in K.", "startOffset": 61, "endOffset": 336}], "year": 2014, "abstractText": "The logistic loss function is often advocated in machine learning and statistics as a smooth and strictly convex surrogate for the 0-1 loss. In this paper we investigate the question of whether these smoothness and convexity properties make the logistic loss preferable to other widely considered options such as the hinge loss. We show that in contrast to known asymptotic bounds, as long as the number of prediction/optimization iterations is sub exponential, the logistic loss provides no improvement over a generic non-smooth loss function such as the hinge loss. In particular we show that the convergence rate of stochastic logistic optimization is bounded from below by a polynomial in the diameter of the decision set and the number of prediction iterations, and provide a matching tight upper bound. This resolves the COLT open problem of McMahan and Streeter (2012).", "creator": "LaTeX with hyperref package"}}}