{"id": "1405.4364", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2014", "title": "Thematically Reinforced Explicit Semantic Analysis", "abstract": "We present an extended, thematically reinforced version of Gabrilovich and Markovitch's Explicit Semantic Analysis (ESA), where we obtain thematic information through the category structure of Wikipedia. For this we first define a notion of categorical tfidf which measures the relevance of terms in categories. Using this measure as a weight we calculate a maximal spanning tree of the Wikipedia corpus considered as a directed graph of pages and categories. This tree provides us with a unique path of \"most related categories\" between each page and the top of the hierarchy. We reinforce tfidf of words in a page by aggregating it with categorical tfidfs of the nodes of these paths, and define a thematically reinforced ESA semantic relatedness measure which is more robust than standard ESA and less sensitive to noise caused by out-of-context words. We apply our method to the French Wikipedia corpus, evaluate it through a text classification on a 37.5 MB corpus of 20 French newsgroups and obtain a precision increase of 9-10% compared with standard ESA.", "histories": [["v1", "Sat, 17 May 2014 07:58:58 GMT  (155kb,D)", "http://arxiv.org/abs/1405.4364v1", "13 pages, 2 figures, presented at CICLing 2013"]], "COMMENTS": "13 pages, 2 figures, presented at CICLing 2013", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yannis haralambous", "vitaly klyuev"], "accepted": false, "id": "1405.4364"}, "pdf": {"name": "1405.4364.pdf", "metadata": {"source": "CRF", "title": "Thematically Reinforced Explicit Semantic Analysis", "authors": ["Yannis Haralambous"], "emails": ["yannis.haralambous@telecom-bretagne.eu", "vkluev@u-aizu.ac.jp"], "sections": [{"heading": "1 Introduction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1.1 Explicit Semantic Analysis", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live."}, {"heading": "1.2 Wikipedia Categories", "text": "A Wikipedia page can belong to one or more categories. Categories are represented by specific pages with the prefix \"Category:\"; these pages, in turn, can belong to other categories, so that we get a directed graph structure whose nodes can be standard pages (outgoing edges only) or categories (incoming and outgoing edges). A page can belong to several categories and there is no ranking of its semantic relevance. Therefore, in order to be able to use categories, we first need an algorithm to determine the individual semantically most relevant category, and for this we use ESA. The Wikipedia category graph has been extensively examined in [5] (for the English corpus)."}, {"heading": "1.3 Related Work", "text": "In fact it is so that most of us are in a position to surpass ourselves, namely in the manner and manner in which they do it: in the manner and manner in which they do it, in the manner and manner in which they do it, in the manner and manner in which they do it, in the manner in which they do it, in the manner and manner in which they do it, in the manner in which they do it, in the manner in which they do it, in the manner in which they do it, in which they do it, in which they do it, in the manner and manner in which they do it, in which they do it, in which they do it to themselves, in which they do it to themselves, and in the manner in which they do it, in which they do it to themselves, and in which they do it to themselves, and in which they do it to themselves, and in which they do it to themselves, in which they do it to themselves, and in which they do it to themselves, in which they do it to themselves, in which they do it in which they do it in themselves, and in which they do it in themselves, in which they do it in which they do it in themselves, and in which they do it in which they do it in themselves, and in which they do it in which they do it in themselves, and in which they do it in which they do it in which they do it in themselves, and in which they do it in which they do it in which they do it in themselves, and in which they do it in which they do it in themselves, and in which they do it in which they do it in which they do it in themselves, and in which they do it in which they do it in which they do it in themselves, and in which they do it in which they do it in themselves, and in which they do it in which they do it in which they do it in which they do it in themselves, and in which they do it in which they do it in which they do it in themselves, and in which they do it in which they do it in which they do it in themselves, and in which they do it in which they do it in which they do it in which they do it in themselves and in which they do it in which they do it in themselves, and in which they do it in which they do it in which they do it in which"}, {"heading": "2 Thematic Reinforcement", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Standard Tfidf, Concept Vector and ESA Measure", "text": "First, let's formalize the default ESA model. 1LetW is the Wikipedia corpus truncated according to the standard ESA methodology. The tfidf tp (w) of the word w on page p is defined as: tp (w): = (1 + log (fp (w))) \u00b7 log # W \u2211 p (= document frequency) of w, where fp (w) is the frequency of w on page p. Then, we define the \"concept vector\" w of the word w asw: = p (= document frequency) of w, is the number of Wikipedia pages containing."}, {"heading": "2.2 Categorical Tfidf", "text": "Let c be a Wikipedia category. We define F (c) as the set of all pages p ending with c.Definition 1 - either p belongs to c, - or p belongs to c1, and there a sequence of subcategory relationships c1 \u2192 c2 \u2192 \u00b7 \u00b7 \u00b7 c ending with c.Definition 1. Let w (p) be a word of p (w), tp (w) be default tfidf in p and c be a category of W. We define the categorical tfidf tc (w) of w for category c as follows: tc (w): = 1 + log p (c) fp (w) \u00b7 log # W 1 + p (c) W\\ F (c) w-1. The difference to tfidf defined by [6] lies in the calculation of df: Unsteadof p (W) w-p (w), which is the set of pages w contained in the entire Wikipedia corpus, let us focus on those W (W) that are equal to the unit W (namely W)."}, {"heading": "2.3 Vectors of Pages and Categories", "text": "We define the page vector p as the normalized sum of concept vectors of its words, weighted by their tfidfs: d: = \u2211 w-p tp (w) \u00b7 w-p tp (w) \u00b7 w-p tp (w) \u00b7 w-p. Likewise, we let c be a category of Wikipedia, we define the category vector c asc: = \u0445 w-F (c) tc (w) \u00b7 w-w-F (c) \u00b7 w-w-w-t. where w-F (c) means that there is a page p, so that p-F (c) and w-p exist."}, {"heading": "2.4 Wikipedia Arborification", "text": "Definition 2 Let p be a Wikipedia page and c, c \u2032 Wikipedia categories. Let p \u2192 c be the affiliation of page d to category c, and c \u2192 c \u2032 be the subcategory relationship between c and c. \"We define the weight of the semantic relationship of these relationships asp (p \u2192 c) = < p (c\" c \") = < c\" >, where <. > is the Euclidean scalar product of two vectors. This product is equal to cosmic metrics, since the vectors are all uniform. With this property, we also have the ability to be in (p) [0, 1].The relationships taken into account in Definition 2 correspond to the scalar product of two vectors. Let W \"be the weighted Wikipedia diagrams (whose vertices are pages and categories whose edges are memberships of pages and inclusions of categories)."}, {"heading": "2.5 Thematically Reinforced ESA", "text": "In fact, a word in a particular page may have a high tfidf value just because it occurred once or twice, which does not guarantee a significant semantic proximity between the word and the page. But if the word also occurs in ancestral categories (and therefore on other pages belonging to the same category), then we have greater chances of semantic meaning. Definition 3 Let p be a Wikipedia page, w be a word w-p, tp (w) the default tfidf of w in p, (p) i be the sequence of ancestors of p, and (i) i be a decreasing sequence of positive real numbers converging to 0. We define the thematically enhanced tfidf tp, p (w) astp, p (w) i (w) and i-i a decreasing sequence of positive real numbers converging to 0."}, {"heading": "In other words, it is the usual concept vector definition, but using thematically reinforced tfidf.", "text": "With these tools we can define our extended version of ESA as follows: Definition 5 With the notations of Definition 3 and w, w \"W, we define the thematically enhanced semantic relation measurement of ESA as follows: \u00b5\u03bb\" (w, w \"): = < w\u0435,\" w \"\u03bb,\" w \"\u03bb\" >..."}, {"heading": "In other words, it is the usual ESA measure definition, but using thematically reinforced concept vectors and tfidf.", "text": "algorithm, such as Dijkstra. This was already proposed in [7], but only for the metric of the number of edges; in our case we would rather use the measure given by the weight of the graph. Log distribution of the incoming degrees Log distribution of the outgoing degrees"}, {"heading": "3 Corpus", "text": "We decided to work on the French Wikipedia corpus (version of December 31, 2011), which is smaller than the English corpus and to our knowledge has not yet been used for the ESA. In order to adapt the ESA to the French Wikipedia, we have followed the same steps as [1] and [10], except for one: We have promoted the origin of lemmatization in order to avoid loss of information due to the bad origin of inflected words. (In English, the deviation is negligible, so that the ancestry can be done directly.) Originally, the authors [1] reduced the English Wikipedia corpus from 2005 to 132,689 pages, in order to avoid the loss of information due to the bad origin of inflected words. (In our case, the delimitation of the minimum size of pages to 125 (nonstop, lemmatized and clear) words, 15 incoming and 15 outgoing links, we received a number of Wikipedia pages that are comparable to the original ESA implementation, namely 1,128,759 pages in total, out of 1,244,459 categories."}, {"heading": "4 Evaluation", "text": "\"We need to extend the methods to WS-353, defining a set of 352 English word pairs whose semantic relationality has been evaluated by 15-16 human judges.\" So their criterion is the Spearman correlation coefficient between the rank of the pairs obtained by ESA and the average of human judgments obtained. Our first attempt was to translate these pairs into French, but the result was rather disappointing. 5We therefore chose to evaluate our implementation of ESA in a more traditional way by performing a text classification task. We extracted a total of 20,000 French language messages from the 20 most popular French news groups. The characteristics of our rating corpus can be seen in Table 1, where the second column represents the number of messages for a given group, the third the number of words and the fourth, the number of distinctive words also found in Wikipedia. To perform the text classification, we need to expand the number of corpus documents. \""}, {"heading": "5 Conclusion and Hints for Further Research", "text": "By reinforcing the thematic context of words on Wikipedia pages achieved through the category structure, we claim to be able to improve the performance of the ESA measurement. We evaluated our method using a text classification task based on messages from the 20 most popular French-language newsgroups: Thematic reinforcement enabled us to improve classification accuracy by 9-10%. Here are some pointers for the research to be carried out: 1. we suggest Wikipedia users the term \"most relevant category\" and use their feedback to improve the system; 2. if we take the \"most relevant category\" for each page, we do not take into account by how much it is better than the others. If there are small differences in the semantic relevance weight between categories, one could imagine alternative \"slightly worse\" between trees and compare the results; 3. by comparing the relevance between alternative \"most relevant\" categories for the same page, one could quantify the \"global potential\" of the Wikipedia correlation between individual pages."}], "references": [{"title": "Computing semantic relatedness using Wikipediabased explicit semantic analysis", "author": ["E. Gabrilovich", "S. Markovitch"], "venue": "IJCAI\u201907: Proceedings of the 20th international joint conference on Artifical intelligence", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Computer information retrieval using latent semantic structure (1989) US Patent 4,839,853", "author": ["S.C. Deerwester", "S.T. Dumais", "G.W. Furnas", "R.A. Harshman", "T.K. Landauer", "K.E. Lochbaum", "L.A. Streeter"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1989}, {"title": "A Semantic Relatedness Measure Based on Combined Encyclopedic, Ontological and Collocational Knowledge", "author": ["Y. Haralambous", "V. Klyuev"], "venue": "International Joint Conference on Natural Language Processing, Chiang-Mai, Thailand", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Insights into explicit semantic analysis", "author": ["T. Gottron", "M. Anderka", "B. Stein"], "venue": "CIKM \u201911: Proceedings of the 20th ACM international conference on Information and knowledge management.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Analysis of the Wikipedia category graph for NLP applications", "author": ["T. Zesch", "I. Gurevych"], "venue": "Workshop TextGraphs-2 : Graph-Based Algorithms for Natural Language Processing.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Extended explicit semantic analysis for calculating semantic relatedness of web resources", "author": ["P. Scholl", "D. B\u00f6hnstedt", "R.D. Gar\u0107\u0131a", "C. Rensing", "R. Steinmetz"], "venue": "EC-TEL\u201910: Proceedings of the 5th European conference on Technology enhanced learning conference on Sustaining TEL: from innovation to learning and practice, Springer", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Constitution d\u2019une ressource s\u00e9mantique issue du treillis des cat\u00e9gories de wikipedia", "author": ["O. Collin", "B. Gaillard", "J.L. Bouraoui"], "venue": "TALN 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Combining local context and WordNet similarity for word sense identification", "author": ["C. Leacock", "M. Chodorow"], "venue": "In Fellbaum, C., ed.: WordNet, an electronic lexical database, The MIT Press", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1998}, {"title": "Efficient algorithms for finding minimum spanning trees in undirected and directed graphs", "author": ["H.N. Gabow", "Z. Galil", "T. Spencer", "R.E. Tarjan"], "venue": "Combinatorica 6", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1986}, {"title": "Improving search result clustering by integrating semantic information from Wikipedia", "author": ["\u00c7all\u0131", "c."], "venue": "Master\u2019s thesis, Middle East Technical University, Ankara", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Networks", "author": ["M. Newman"], "venue": "An Introduction. Oxford University Press", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Mining meaning from Wikipedia", "author": ["O. Medelyan", "C. Legg", "D. Milne", "I.H. Witten"], "venue": "International Journal of Human-Computer Studies 67(9)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Making large-scale SVM learning practical", "author": ["T. Joachims"], "venue": "In Sch\u00f6lkopf, B., Burges, C., Smola, A., eds.: Advances in Kernel Methods - Support Vector Learning, MIT Press", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1999}], "referenceMentions": [{"referenceID": 0, "context": "Gabrilovich & Markovitch [1] introduce the semantic relatedness measure ESA (= Explicit Semantic Analysis, as opposed to the classical method of Latent Semantic Analysis [2]).", "startOffset": 25, "endOffset": 28}, {"referenceID": 1, "context": "Gabrilovich & Markovitch [1] introduce the semantic relatedness measure ESA (= Explicit Semantic Analysis, as opposed to the classical method of Latent Semantic Analysis [2]).", "startOffset": 170, "endOffset": 173}, {"referenceID": 2, "context": "Thus, Haralambous & Klyuev [3] note that ESA has poor performance when the relation between words is mainly ontological.", "startOffset": 27, "endOffset": 30}, {"referenceID": 2, "context": "As pointed out in [3], an ontological component, obtained from a WordNet-based measure, can, at least partially, fill this gap.", "startOffset": 18, "endOffset": 21}, {"referenceID": 3, "context": "[4], who argue that the choice of Wikipedia is irrelevant, and that any corpus of comparable size would give the same results.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Wikipedia\u2019s category graph has been studied thoroughly in [5] (for the English corpus).", "startOffset": 58, "endOffset": 61}, {"referenceID": 5, "context": "[6] also enhance the performance of ESA using categories.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "In [7], the authors examine the problem of inconsistency of Wikipedia\u2019s category graph and propose a shortest path approach (based on the number of edges) between a page and the category \u201cArticle,\u201d which is at the top of the hierarchy.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "The shortest path provides them with a semantic and thematic hierarchy and they calculate similarity as shortest length between vertices on these paths, a technique already used in WordNet [8].", "startOffset": 189, "endOffset": 192}, {"referenceID": 0, "context": "1 are from [1].", "startOffset": 11, "endOffset": 14}, {"referenceID": 5, "context": "The difference with the tfidf defined by [6] is in the calculation of df: instead of \u2211 p\u2208W w\u2208p 1, that is the amount of pages containing w in the entire Wikipedia", "startOffset": 41, "endOffset": 44}, {"referenceID": 0, "context": "By this property we also have Im(p) \u2282 [0, 1].", "startOffset": 38, "endOffset": 44}, {"referenceID": 6, "context": "This has already been proposed in [7], but for the metric of the number of edges; in our case we would rather use the measure given by the weight of the graph.", "startOffset": 34, "endOffset": 37}, {"referenceID": 0, "context": "To adapt ESA to French Wikipedia, we followed the same steps as [1] and [10] except for one: we have preceded stemming by lemmatization, to avoid loss of information due to poor stemming of inflected words.", "startOffset": 64, "endOffset": 67}, {"referenceID": 9, "context": "To adapt ESA to French Wikipedia, we followed the same steps as [1] and [10] except for one: we have preceded stemming by lemmatization, to avoid loss of information due to poor stemming of inflected words.", "startOffset": 72, "endOffset": 76}, {"referenceID": 0, "context": "Originally, the authors of [1] pruned the 2005 English Wikipedia corpus down to 132,689 pages.", "startOffset": 27, "endOffset": 30}, {"referenceID": 11, "context": "Indeed, according to [12], \u201ccycles are not encouraged but may be tolerated in rare cases.", "startOffset": 21, "endOffset": 25}, {"referenceID": 0, "context": "Gabrilovich and Markovitch [1] evaluate their method on WS-353, a set of 352 English word pairs, the semantic relatedness of which has been evaluated by 15\u2013 16 human judges.", "startOffset": 27, "endOffset": 30}, {"referenceID": 12, "context": "We applied the linear multi-class SVM classifier SVM [13] to the set of these vectors and the corresponding document classes, and after a tenfold cross-validation, we obtained an average precision of 65.", "startOffset": 53, "endOffset": 57}, {"referenceID": 2, "context": "aggregate the thematically reinforced measure with collocational and ontological components, as in [3]; 5.", "startOffset": 99, "endOffset": 102}], "year": 2014, "abstractText": "We present an extended, thematically reinforced version of Gabrilovich and Markovitch\u2019s Explicit Semantic Analysis (ESA), where we obtain thematic information through the category structure of Wikipedia. For this we first define a notion of categorical tfidf which measures the relevance of terms in categories. Using this measure as a weight we calculate a maximal spanning tree of the Wikipedia corpus considered as a directed graph of pages and categories. This tree provides us with a unique path of \u201cmost related categories\u201d between each page and the top of the hierarchy. We reinforce tfidf of words in a page by aggregating it with categorical tfidfs of the nodes of these paths, and define a thematically reinforced ESA semantic relatedness measure which is more robust than standard ESA and less sensitive to noise caused by out-of-context words. We apply our method to the French Wikipedia corpus, evaluate it through a text classification on a 37.5 MB corpus of 20 French newsgroups and obtain a precision increase of 9\u201310% compared with standard ESA.", "creator": "LaTeX with hyperref package"}}}