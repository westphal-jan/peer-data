{"id": "1405.5147", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2014", "title": "Predicting Online Video Engagement Using Clickstreams", "abstract": "In the nascent days of e-content delivery, having a superior product was enough to give companies an edge against the competition. With today's fiercely competitive market, one needs to be multiple steps ahead, especially when it comes to understanding consumers. Focusing on a large set of web portals owned and managed by a private communications company, we propose methods by which these sites' clickstream data can be used to provide a deep understanding of their visitors, as well as their interests and preferences. We further expand the use of this data to show that it can be effectively used to predict user engagement to video streams.", "histories": [["v1", "Tue, 20 May 2014 16:32:59 GMT  (866kb,D)", "http://arxiv.org/abs/1405.5147v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.IR", "authors": ["everaldo aguiar", "saurabh nagrecha", "nitesh v chawla"], "accepted": false, "id": "1405.5147"}, "pdf": {"name": "1405.5147.pdf", "metadata": {"source": "CRF", "title": "Predicting Online Video Engagement Using Clickstreams", "authors": ["Everaldo Aguiar", "Saurabh Nagrecha", "Nitesh V. Chawla"], "emails": ["eaguiar@nd.edu", "snagrech@nd.edu", "nchawla@nd.edu"], "sections": [{"heading": "Author Keywords", "text": "Clickstream; predictive analysis; online video; user engagement."}, {"heading": "ACM Classification Keywords", "text": "I.5.2. Pattern Recognition: Design Methodology"}, {"heading": "INTRODUCTION", "text": "The constant growth of the volume, availability and functionality of the web brings not only a variety of challenges and risks, but also a number of opportunities. While there has been a number of great advances in the area of time, one that has received a considerable amount of attention in recent years is that the online activities of users are continuously recorded and analyzed."}, {"heading": "RELATED WORK", "text": "The interest in analyzing users \"online activity is as old as the provision of consumable content itself, and this issue has aroused interest in several areas, namely marketing, psychology and computer science.Since user activity provides an immense amount of measurable secondary data, various models have been proposed to predict several aspects of their behavior.User interaction has been studied at various levels - from eye tracking [8] to broader patterns of the path within a site [1,22]. Simple duration and dwell time [4] can be used to predict when a user leaves the site. User classification [21] can be used to identify what the user specifically seeks and even to change the site [16], depending on the user's defined taste of that particular user profile. Personalized content based on click history has been implemented and widely adopted by commercial content providers [6, 19] but with the distribution of video enrichment on the Internet, we have been able to actively examine the way that user content has been influenced by [7] and the way that we have been able to use it."}, {"heading": "CLICKSTREAM DATA REPRESENTATION", "text": "Clickstream data consists of a \"virtual trail\" that users leave behind as they interact with a particular system, website, or application. Specifically, data describing the state of a user's current session is recorded each time a click is made, and the aggregation of that data results in a clickstream that can be used to reconstruct all the actions of the user while he or she is using the given product.Although applicable to a variety of scenarios, collecting and analyzing clickstreams in the context of web-based tools and websites has become particularly popular. As Srivastava et al. [25] emphasizes, analyzing such information has potential applications in a number of areas such as website personalization and modification, system improvement, business intelligence, and usage characterization."}, {"heading": "Our Dataset", "text": "The data we used for this study was provided to us by a major US communications company operating in the radio, TV, newspaper and online media. They manage a few dozen websites, all of which are embedded in the form of clickstream captures. Next, we describe in detail the key features of this data set. User activity is recorded by numerous servers across the country and linked at the end of the day in the form of daily \"dumps.\" We used 59 of these files, which covered the period from December 4, 2012 to January 31, 2013. Overall, these files contain an increase of 65 million clicks."}, {"heading": "METHODS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Identification of Video Exit Instances", "text": "When a user watches a video, a separate log entry is made that corresponds to the point in time when he or she has completed viewing a certain percentage of the video, while a player ID remains constant. As a result, the clickstream log reflects a cumulative history of the viewer's progress within that video. By filtering the data to get only clicks that match video instances, and then by IP address, we get the total video viewing activity of each IP. From this modified record, we isolate an individual \"video view table\" by specifying the player ID. This table is then sorted chronologically and filtered by session time exceeded. The last entry corresponds to the viewer's starting point. This gives us a unique session for a visit. Combined with the current session data and data from cookies, we retrieve the unique historical surfing patterns of the user. It is worth noting that we treat the video as if the user leaves the cookie fresh, without our analyzing it."}, {"heading": "Feature Selection", "text": "Using various methods for selecting features, we reduced the size of our dataset from the original 161 features to the 12 best descriptors, including features such as IP, location, content annotations, and referrer information. Of the 161 features in a typical video exit instance, 40 are mutually redundant, and 32 are constant in value. This motivates the need to find a set of features that represent the best descriptor of the target class (in this case, the percent of the video that the user watches before leaving) [14]. We examined various methods for selecting features that support mixed data types and ranked the top features. One should expect these features to include measurable features that influence their interest in video.Different methods for selecting features aim to remove redundant and irrelevant features using different statistical means that have their respective strengths. [Although a popular choice in machine learning is the relational choice], the choice of these attributes was not taken into account on the basis of the detailed attributes."}, {"heading": "Chi Squared", "text": "The chi-square method (\u03c72) measures how much deviation is seen in the observed data from the case in which class value and attribute are independent of each other. It evaluates whether attribute and class occurrence are randomly related or have any relationship."}, {"heading": "Information Gain", "text": "Gain of information [23] measures how much entropy is lost if the attribute is present or absent."}, {"heading": "Gain Ratio", "text": "Information gain prefers attributes with many values over those with fewer values, the gain ratio [24] compensates for this by taking into account the splitting portion caused by the feature."}, {"heading": "One R", "text": "An R formulates a series of simple relationships between the characteristics and classifies the characteristics based on the accuracy of these rules."}, {"heading": "Symmetric Uncertainty", "text": "Symmetrical uncertainty [26, 10] targets attributes that correlate well with the class but have little correlation. The results of these selection methods are summarized in Table 2. The attributes in the table are those that consistently appear in the top 10%. These are the attributes that most affect the video output.The time of viewing influences the point in time when people tend to leave the video. IP address associated with location and ISP indicate who is watching the video and thus provide a personalized facet of the prediction. The number of pages viewed by a person and the frequency of visits can be perceived as an expression of the person's interest in the page. \"The speaker who brought the viewer to the page can influence the engagement of the viewer; a viewer who comes from a social network interacts differently from the one who had the page in his browser as a bookmark.\" The entry point determines the title of the video, the first page the viewer has seen the actual interest in it; the viewer likely to have seen the actual content in the section."}, {"heading": "Classification", "text": "In our data set, we note that this is represented by 5 different markers that correspond to the percentage of the video that the user has watched before leaving the video. We formulate two classification tasks - to predict how many percent of the video is viewed and whether the user leaves the video \"early\" (before reaching 50% of the video). This prediction task includes 5 classes. As it is relevant to users who leave the video early, we assume that users who left the video at the beginning or watched 25% of the video left \"early.\" As described above, this would correspond to users who have seen 0 to 49% of the video. We can refine the problem as a binary prediction of these \"early exits.\" The classes would then be a fusion of the aforementioned 5 classes, combining the first two to form the \"early exits\" and the latter 3 those who have decided not to leave the video early."}, {"heading": "Naive Bayes", "text": "Among the simplest and most primitive classification algorithms, this probabilistic method is based on the Bayes theorem [2] and strong underlying assumptions of independence. This means that each attribute independently contributes to the class outcome."}, {"heading": "C4.5 Decision trees", "text": "C4.5 Decision Trees [24] work by building a tree structure in which split operations on each node are performed on the basis of information gain values for each characteristic of the dataset and the respective class. At each level, the attribute with the highest information gain is selected as the basis for the split criterion. Repeated Incremental Pruning to Produce Error Reduction RIPPER [5] is a rules-based classification tree learner. It is algorithmically faster than C4.5 and has a complexity of O (n (n)) 2) as opposed to the complexity of the order O (n3) of C4.5. RIPPER constructs a first set of rules and then optimizes it iteratively according to a tunable parameter. It is implemented in Weka under the \"JRip class.\""}, {"heading": "Random forests", "text": "Random forests [3] combine several tree predictors into an overall ensemble. New instances that are classified are pushed by the trees, and each tree reports a classification. The \"forest\" then decides which label to assign to this new instance based on the total number of votes given by the number of trees."}, {"heading": "Decision Tables", "text": "Decision table classifiers [18] are constructed by concatenating a series of rules derived from the set of characteristics with corresponding class results. This method has as its main advantages the fact that it is easy to interpret and particularly efficient."}, {"heading": "Random Subspaces", "text": "The Random Subspace Method [17] is an ensemble classifier whose individual classifiers work on random subsets of the character set. Predictions of the individual classifiers are combined using the posterior probabilities of each class in the constituent classifiers. This method looks at the classification problem from different perspectives by randomly combining the selection of characteristics."}, {"heading": "Stacking", "text": "Stacking [27] is a meta-classification scheme that uses an overall ensemble of classifiers and performs the learning task on two levels. First, the classifiers are trained in the overall ensemble based on the data, then the meta-classifier learns from their predictions and the training labels of the data."}, {"heading": "Key Performance Indices / Metrics Utilized", "text": "To obtain these predictions, we perform a 10-fold cross-validation of the available data using different classification methods. 10-fold cross-validation randomly divides the data into 10 subsets and makes predictions for each of these subsets. These predictions are then summarized to provide the overall performance of the classifier, which we measured based on the accuracy and range under the Receiver Operating Characteristics Curve (AUROC), all of which are described below. Each of these metrics represents different aspects of the prediction results."}, {"heading": "Accuracy", "text": "The accuracy of a classifier is perhaps the simplest measure of its performance. It represents the percentage of total instances that have been correctly classified. We want this to be as high as possible. The starting point for the accuracy is that of a completely random prediction. For a binary classification problem, this would be 50%, and for a 5 class problem, it would be 20%. Any classifier that provides statistically higher accuracy than these baselines is considered better than a random predictor."}, {"heading": "Receiver Operating Characteristics (ROC) curves", "text": "A system designed to increase accuracy does not necessarily make it a good predictor. Relying on accuracy alone does not provide insight into the nature of misclassified instances. ROC curves [11] are a way to quickly compare multiple classifiers. The goal of a classifier in ROC space is to be as close to the upper left corner as possible. In ROC space, if the curve of one classifier is closer to the upper left corner than that of another, superior performance is assumed."}, {"heading": "EXPERIMENTAL RESULTS", "text": "We evaluated the performance of each of the classifiers used with a 10-fold cross-validation for both multiclass and binary classification predictions. Table 3 summarizes the results of all experiments."}, {"heading": "Multiclass Prediction", "text": "We see that the stacked classifiers performed slightly better in terms of sheer accuracy than other methods and achieved an accuracy of 56.9%. However, in terms of AUROC, Naive Bayes performed significantly better, closely followed by Decision Tables. These simple classifiers may not have the best accuracy, but they do outperform the others."}, {"heading": "Binary Class Prediction", "text": "In this second scenario, we associate a semantic meaning with the drop-off percentage point and predict whether or not the user will drop out prematurely, and this refinement of the problem gives us much better performance across the board. For example, stacked classifiers achieve a remarkable 84.6% accuracy when predicting which users will leave their video streams prematurely. As was the case with the multiclass problem, we saw once again that decision tables and naive bayes outperform other classifiers when it comes to AUROC values. Although stacked classifiers offer higher accuracy, they are not as good at predicting early drop-offs as decision tables or naive bayes. This still reflects the general trends observed in the multiclass problem, as we have merely merged classes, but the underlying data remains the same. In both multiclasses and binary class predictors, more complicated classifiers are observed, which are more straightforward."}, {"heading": "CONCLUSIONS", "text": "We demonstrated how clickstream data can be used to predict \"early outputs\" in online videos, and by creating appropriate models, we were able to determine with high accuracy which video streaming sessions are likely to end prematurely. In addition, we compared and compared the performance of a number of classifiers, highlighting those we thought were most appropriate for this problem, and knowing such information would allow content providers to personalize the distribution of their media to increase user retention and thus business value."}], "references": [{"title": "Clickstream clustering using weighted longest common subsequences", "author": ["A. Banerjee", "J. Ghosh"], "venue": "In Proceedings of the web mining workshop at the 1st SIAM conference on data mining,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "A model of web site browsing behavior estimated on clickstream data", "author": ["R.E. Bucklin", "C. Sismeiro"], "venue": "Journal of Marketing Research", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Fast effective rule induction", "author": ["W.W. Cohen"], "venue": "In ICML, vol", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1995}, {"title": "Google news personalization: scalable online collaborative filtering", "author": ["A.S. Das", "M. Datar", "A. Garg", "S. Rajaram"], "venue": "In Proceedings of the 16th international conference on World Wide Web,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Understanding the impact of video quality on user engagement", "author": ["F. Dobrian", "V. Sekar", "A. Awan", "I. Stoica", "D.A. Joseph", "A. Ganjam", "J. Zhan", "H. Zhang"], "venue": "SIGCOMM-Computer Communication Review 41,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Internet advertising: Is anybody watching", "author": ["X. Dreze", "Hussherr", "F.-X"], "venue": "Journal of interactive marketing 17,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Is combining classifiers with stacking better than selecting the best one", "author": ["S. D\u017eeroski", "B. \u017denko"], "venue": "Machine learning 54,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Machine learning-based text mining for biomedical information analysis", "author": ["Eom", "J.-H", "Zhang", "B.-T"], "venue": "Genomics & Informatics", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "An introduction to roc analysis", "author": ["T. Fawcett"], "venue": "Pattern recognition letters 27,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "An Extensive Empirical Study of Feature Selection Metrics for Text Classification", "author": ["G. Forman"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "An introduction to variable and feature selection", "author": ["I. Guyon", "A. Elisseeff"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Correlation-based Feature Selection for Machine Learning", "author": ["M.A. Hall"], "venue": "PhD thesis, The University of Waikato,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "The random subspace method for constructing decision forests", "author": ["T.K. Ho"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on 20,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1998}, {"title": "The power of decision tables", "author": ["R. Kohavi"], "venue": "In Machine Learning: ECML-95. Springer,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1995}, {"title": "Personalized news recommendation based on click behavior", "author": ["J. Liu", "P. Dolan", "E.R. Pedersen"], "venue": "In Proceedings of the 15th international conference on Intelligent user interfaces,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Automatic Personalization Based on Web Usage Mining", "author": ["B. Mobasher", "R. Cooley", "J. Srivastava"], "venue": "Communications of the ACM 43,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2000}, {"title": "Buying, searching, or browsing: Differentiating between online shoppers using in-store navigational clickstream", "author": ["W.W. Moe"], "venue": "Journal of Consumer Psychology", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "Modeling online browsing and path analysis using clickstream data", "author": ["A.L. Montgomery", "S. Li", "K. Srinivasan", "J.C. Liechty"], "venue": "Marketing Science 23,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2004}, {"title": "Induction of decision trees", "author": ["J.R. Quinlan"], "venue": "Machine Learning 1,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1986}, {"title": "Web usage mining: Discovery and applications of usage patterns from web data", "author": ["J. Srivastava", "R. Cooley", "M. Deshpande", "Tan", "P.-N"], "venue": "ACM SIGKDD Explorations Newsletter", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2000}, {"title": "Data Mining: Practical Machine Learning Tools and Techniques", "author": ["I.H. Witten", "E. Frank"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "Stacked generalization", "author": ["D.H. Wolpert"], "venue": "Neural networks 5,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1992}, {"title": "A comparative study on feature selection in text categorization", "author": ["Y. Yang", "J.O. Pedersen"], "venue": "In ICML, vol", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1997}], "referenceMentions": [{"referenceID": 15, "context": "As described in [20], the browsing behavior of individual users can be recorded at the granularity of mouse clicks with little to no work needing to be done.", "startOffset": 16, "endOffset": 20}, {"referenceID": 5, "context": "User interaction has been studied at various levels\u2014 from gaze tracking [8] to broader patterns of path traversal within a website [1, 22].", "startOffset": 72, "endOffset": 75}, {"referenceID": 0, "context": "User interaction has been studied at various levels\u2014 from gaze tracking [8] to broader patterns of path traversal within a website [1, 22].", "startOffset": 131, "endOffset": 138}, {"referenceID": 17, "context": "User interaction has been studied at various levels\u2014 from gaze tracking [8] to broader patterns of path traversal within a website [1, 22].", "startOffset": 131, "endOffset": 138}, {"referenceID": 1, "context": "Simple duration and dwell-time [4] can be used to predict when a user exits the site.", "startOffset": 31, "endOffset": 34}, {"referenceID": 16, "context": "User classification [21] can be used to identify what the user is specifically looking for and even morph the website [16] according to the custom tastes of that particular user profile.", "startOffset": 20, "endOffset": 24}, {"referenceID": 3, "context": "Personalized content based on click history has been implemented and widely adopted by commercial content providers [6, 19].", "startOffset": 116, "endOffset": 123}, {"referenceID": 14, "context": "Personalized content based on click history has been implemented and widely adopted by commercial content providers [6, 19].", "startOffset": 116, "endOffset": 123}, {"referenceID": 4, "context": "Studies like [7] have measured the role of video content quality in influencing user engagement, but did not utilize clickstreams to contextualize the video views.", "startOffset": 13, "endOffset": 16}, {"referenceID": 19, "context": "[25], the analysis of such information Figure 2.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "This motivates the need to find a set of features that is the best descriptor of the target class (in this case, the percent of video the user watches before exiting) [14].", "startOffset": 167, "endOffset": 171}, {"referenceID": 11, "context": "Though a popular choice in machine learning, correlation based feature selection (CFS) was not considered due to the sparse nature of the data [15].", "startOffset": 143, "endOffset": 147}, {"referenceID": 22, "context": "A more detailed study of these can be found in [28, 12].", "startOffset": 47, "endOffset": 55}, {"referenceID": 9, "context": "A more detailed study of these can be found in [28, 12].", "startOffset": 47, "endOffset": 55}, {"referenceID": 18, "context": "Information Gain Information gain [23] measures how much entropy is lost when the feature is present vs.", "startOffset": 34, "endOffset": 38}, {"referenceID": 20, "context": "Symmetric uncertainty [26, 10] targets attributes which correlate well with the class but have little intercorrelation.", "startOffset": 22, "endOffset": 30}, {"referenceID": 7, "context": "Symmetric uncertainty [26, 10] targets attributes which correlate well with the class but have little intercorrelation.", "startOffset": 22, "endOffset": 30}, {"referenceID": 2, "context": "Repeated Incremental Pruning to Produce Error Reduction RIPPER [5] is a rule based classification tree learner.", "startOffset": 63, "endOffset": 66}, {"referenceID": 13, "context": "Decision Table classifiers [18] are built by concatenating a series of rules derived from the feature set to corresponding class outcomes.", "startOffset": 27, "endOffset": 31}, {"referenceID": 12, "context": "The random subspace method [17] is an ensemble classifier whose individual classifiers operate on random subsets of the feature set.", "startOffset": 27, "endOffset": 31}, {"referenceID": 21, "context": "Stacking [27] is a meta-classification scheme which employs an ensemble of classifiers and performs the learning task on two levels.", "startOffset": 9, "endOffset": 13}, {"referenceID": 8, "context": "ROC curves [11] are a way to quickly compare multiple classifiers.", "startOffset": 11, "endOffset": 15}, {"referenceID": 6, "context": "This is documented in [9], showing that stacking does not always outperform the best classifier.", "startOffset": 22, "endOffset": 25}], "year": 2014, "abstractText": "In the nascent days of e-content delivery, having a superior product was enough to give companies an edge against the competition. With today\u2019s fiercely competitive market, one needs to be multiple steps ahead, especially when it comes to understanding consumers. Focusing on a large set of web portals owned and managed by a private communications company, we propose methods by which these sites\u2019 clickstream data can be used to provide a deep understanding of their visitors, as well as their interests and preferences. We further expand the use of this data to show that it can be effectively used to predict user engagement to video streams. Author", "creator": "LaTeX with hyperref package"}}}