{"id": "1405.5172", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2014", "title": "Opposition Based ElectromagnetismLike for Global Optimization", "abstract": "Electromagnetismlike Optimization (EMO) is a global optimization algorithm, particularly well suited to solve problems featuring nonlinear and multimodal cost functions. EMO employs searcher agents that emulate a population of charged particles which interact to each other according to electromagnetisms laws of attraction and repulsion. However, EMO usually requires a large number of iterations for a local search procedure; any reduction or cancelling over such number, critically perturb other issues such as convergence, exploration, population diversity and accuracy. This paper presents an enhanced EMO algorithm called OBEMO, which employs the Opposition-Based Learning (OBL) approach to accelerate the global convergence speed. OBL is a machine intelligence strategy which considers the current candidate solution and its opposite value at the same time, achieving a faster exploration of the search space. The proposed OBEMO method significantly reduces the required computational effort yet avoiding any detriment to the good search capabilities of the original EMO algorithm. Experiments are conducted over a comprehensive set of benchmark functions, showing that OBEMO obtains promising performance for most of the discussed test problems.", "histories": [["v1", "Tue, 20 May 2014 17:52:57 GMT  (537kb)", "http://arxiv.org/abs/1405.5172v1", "27 Pages"]], "COMMENTS": "27 Pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["erik cuevas", "diego oliva", "daniel zaldivar", "marco perez", "gonzalo pajares"], "accepted": false, "id": "1405.5172"}, "pdf": {"name": "1405.5172.pdf", "metadata": {"source": "CRF", "title": "Opposition-Based Electromagnetism-Like for Global Optimization", "authors": ["Erik Cuevas", "Diego Oliva", "Daniel Zaldivar", "Gonzalo Pajares"], "emails": ["marco.perez}@cucei.udg.mx", "doliva@estumail.ucm.es,", "pajares@fdi.ucm.es", "erik.cuevas@cucei.udg.mx"], "sections": [{"heading": null, "text": "This is a pre-printed copy that has been approved for publication in the International Journal of Innovative Computing, Information and Control1problems with Nonlinear and Multimodal Cost Functions. EMO employs search agents who emulate a population of charged particles that interact with each other according to the laws of attraction and repulsion of electromagnetism. However, EMO usually requires a large number of iterations for a local search method; any reduction or cancellation of this number significantly disrupts other issues such as convergence, exploration, population diversity and accuracy. This paper presents an improved EMO algorithm called OBEMO that applies the opposition-based learning (OBL) approach to accelerate global convergence speed. OBL is a machine intelligence strategy that simultaneously looks at the current candidate solution and its opposite value and achieves faster exploration of the search space. The proposed OBEMO method significantly reduces the amount of effort required to perform the initial search algorithms, but significantly avoids the need for computational complexity of the original EMO."}, {"heading": "1. Introduction", "text": "This year, it has come to the point that it has never come as far as it has this year."}, {"heading": "2. Electromagnetism - Like Optimization Algorithm (EMO)", "text": "The EMO algorithm is a simple and direct search algorithm inspired by the phenomenon of electromagnetism. It is based on a specific population and the optimization of global multimodal functions. Compared to GA, it does not use crossover or mutation operators to explore feasible regions; instead, it implements a collective gravitational repulsion mechanism, which reduces the computing costs in terms of memory allocation and execution time. Furthermore, no gradient information is required, since it uses a decimal system that is clearly opposed to GA. Few particles are required to achieve convergence, as already stated in [11].EMO algorithm effectively addresses a special class of optimization problems in the form of: [] ulx xf,) (min, (1) This is a pre-printed copy for publication in the International Journal of Innovative Computing, Information and Control5where [{],}, 1,2 | u, xu..."}, {"heading": "2.1 Initialization", "text": "First, the population of m-solutions is randomly generated in the initial state. Each n-dimensional solution is considered to be a charged particle with an even distribution between the highest (u) and lowest (l) limits, so the optimal particle (solution) is defined by the objective function to be optimized, and the procedure ends when all m-samples are evaluated and the sample (particle) with the best functional value is selected."}, {"heading": "2.2 Local Search", "text": "The local search method is used to collect local information in the neighborhood of a candidate solution. It allows for better exploration and population diversity for the algorithm. This is a pre-printed copy, which is for publication in the International Journal of Innovative Computing, Information and Control6Taking into account a predetermined number of iterations known as ITER, and a practicable neighborhood search, the procedure iterates as follows: dot pg is assigned to a temporary dot t to store the initial information. Next, for a given coordinate d a random number (1\u03bb) is selected and combined with a step length that moves the dot along the direction d, with a randomly determined sign (2\u03bb). If dot observes better performance over the iteration number ITER, dot pg is replaced by t and the eighteenth neighborhood search for dot pg is terminated, otherwise pg is performed."}, {"heading": "2.3 Total force vector computation", "text": "The total force vector calculation is based on the principle of superposition (fig. 2) from the theory of electromagnetism, which states: \"The force exerted on a point over other points is inversely proportional to the distance between the points and directly proportional to the product of its charge.\" [41] The particle moves according to the resulting coulomb force generated between the particles as a charge-like value. In the EMO implementation, the charge for each particle is determined by its fitness value as follows: () () () 1exp, p, p, p, f, f, f, f, p, \u2212 x, g, (2) where n represents the dimension of pg and m the population size. A higher-dimensional problem usually requires a larger population. (2) The particle that has the best fitness function value is designated as the best particle by receiving the highest charge and attracting other particles."}, {"heading": "2.4. Movement", "text": "The change of the d-coordinate for each particle p is calculated with respect to the resulting force as follows: () () \"if 0,\" if 0 p p p p p p d d d d p p p p pd d d d d d d d d d d d d d d d d d d g g g g p best dg F g l F\u03bb + \u22c5 \"\u2212 > =\" if 0 p p p p p p p p p p p p p p p p pd d d d d d d d d d d d d d d d d g g g g g g g g g g g g g g g g g g g g g g g g g g g g g g p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p (p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p if p p p p p p p p p p p p p p p p p p p p p p p p as p p p p p p p p as if if p as if (as if (as a p p p p p p p p p p as a p p p p p p p p p p p p p p p p p p p p p p p p p p p p"}, {"heading": "3. Opposition - based Learning (OBL).", "text": "Opposition-based learning [33] is a new concept of computational intelligence that has been used to effectively improve several soft computing algorithms [42,43]. The approach simultaneously evaluates aThis, a pre-print copy that has been approved for publication in the International Journal of Innovative Computing, Information and Control9solution x and the opposite solution x for a given problem, which offers a renewed chance to find a candidate solution closer to the global optimum [34]."}, {"heading": "3.1 Opposite number", "text": "Let [], x l u \u0442 be a real number, where l and u are the lowest and highest limit, respectively. The contrast of x is defined by: x u l x = + \u2212 (6)"}, {"heading": "3.2 Opposite point", "text": "Similarly, the definition of the opposite number to higher dimensions is generalized as follows: Let 1 2 (,,) nx x x = x K be a point within a n-dimensional space, where 1 2,,, nx x x R-K and [], i ix l u, 1,2,,, i n-K. The opposite point 1 2 (,,,,) nx x x x = x K is defined by: i i i i i x u l x = + \u2212 (7)"}, {"heading": "3.3 Opposition-based optimization", "text": "Metaheuristic methods begin by considering some initial solutions (initial population) and try to improve them towards an optimal solution (s); the process of searching ends when some predefined criteria are met; in the absence of a priori information about the solution, random assumptions can usually be taken into account; the computation time, including properties of the algorithm, depends on the removal of these initial assumptions from the optimal solution; the probability of starting with a closer (fitter) solution can be increased by simultaneously checking the opposite solution; thus, the fitter one (conjecture or opposite conjecture) can be chosen as the initial solution following the fact that according to the probability theory, 50% of the time a conjecture is further away from the solution than its opposite conjecture [35]; on the basis of the closer of the two conjectures (as assessed by their fitness values), the potential is a pre-printing option that has been accepted."}, {"heading": "4. Opposition-based Electromagnetism-like Optimization (OBEMO)", "text": "Similar to all metaheuristic-based optimization algorithms, two steps are fundamental to the EMO algorithm: population initialization and generation by evolutionary operators. In this approach, the OBL scheme is integrated to improve both steps. However, the original EMO is considered the most important algorithm, while the opposition procedures are embedded in the EMO to accelerate its convergence rate. Figure 5 shows a comparison of the data flow between the EMO and the OBEMO algorithm. The new advanced opposition procedures are explained below. This is a preprint version that has been approved for publication in the International Journal of Innovative Computing, Information and Control12 subsections."}, {"heading": "4.1 Opposition-Based Population Initialization", "text": "In population-based meta-heuristics techniques, random number generation is the common choice to form an initial population without a priori knowledge. Therefore, as mentioned in Section 3, it is possible to obtain fitter initial candidate solutions by using OBL, although no a priori knowledge of the solution (s) is available. The following steps explain the general procedures.1) Initialize population X, where P N represents the number of particles. 2) Calculate the opposite population byj ji i i i i x u l x = + \u2212 1,2,; i n = K 1,2,,, P j N = K (8), where j i x and j i x denote the ith parameter of the jth particle of the population and its counterparticle. 3) Select the P N fittest elements from {} x X X as the initial population."}, {"heading": "4.2 Opposition-based production for new Generation", "text": "Based on the current population, the OBL strategy can be reused to create new populations. In this method, the opposite population is calculated and the fittest individuals are selected from the union of the current population and the opposing population. The following steps summarize the OBEMO implementation as follows: Step 1. Generate P N initial random particles hx to generate the particle vector X, using 1.2, P h N, K. This is a pre-printed copy for publication in the International Journal of Innovative Computing, Information and Control13Step 2. Apply the OBL strategy by looking at the P N particles from the vector X and generating the opposite vector X by Eq. 7.Step 3. Select the P N fittest particles from the vector X after () f. These particles build the initial population 0X. Step 4. Calculate the local search method for each particle of 0X as follows."}, {"heading": "5. Experimental results", "text": "To test the performance of the algorithm, the proposed OBEMO is compared with the standard EMO and other state-of-the-art EMO-based algorithms. In this section, the experimental results are discussed in the following sections: (5.1) Test Problems (5.2) Parameter settings for the participating EMO algorithms (5.3) Results and discussions"}, {"heading": "5.1. Test problems", "text": "For the experimental study, a comprehensive set of benchmark problems was selected, comprising 14 different global optimization tests. Depending on their use in performance analysis, the functions are divided into two different groups: original test functions (1 9f \u2212) and multidimensional functions (10 14f \u2212). Each function in this paper is considered a minimization problem. the original test functions shown in Table 1 are consistent with the set of numerical benchmark functions presented in the original EMO paper under [16]. Since such a set is also used by the vast majority of new EMO-based approaches, its use in our experimental study facilitates comparison with similar work. \u2212 Further details \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 n \u2212 n \u2212 n \u2212 n \u2212 n \u2212 n [44]. The main challenge of an EMO-based approach is to avoid the computer-based complexity resulting from the large number of iterations required during the local search process."}, {"heading": "5.2. Parameter settings for the involved EMO algorithms", "text": "The experimental set aims to compare four EMO-based algorithms, including the proposed OBEMO parameter. All algorithms face 14 benchmark problems. The algorithms are listed below: - Standard EMO algorithm [16]; - Hybridization of EMO with Descent Search (HEMO) [17]; - Specified Pattern EMO (FEMO) [30]; - The proposed approach OBEMO.For the original EMO algorithm described in [16] and the proposed OBEMO, the parameter set is configured taking into account the following parameters: 0.001 = \u03b4 and LISTER = 4. For the HEMO, the following experimental parameters are taken into account: max 10LsIt =, 0.0001r\u03b5 = and 0.0001\u03b3 =. Such values can be assumed to be the best configuration set according to [17]."}, {"heading": "5.3. Results and discussions", "text": "This year, it is less than a year since the US experienced such a boom."}, {"heading": "6. Conclusions", "text": "The OBL is a machine intelligence strategy that simultaneously takes into account an up-to-date estimate and its equivalent in order to achieve a quick approximation of a given candidate solution. Standard EMO is improved by using two OBL steps: population initialization and new generation production. The advanced algorithm significantly reduces the computing effort required, but avoids any disadvantage to the good search capabilities of the original EMO algorithm. This is a print template accepted for publication in the International Journal of Innovative Computing, Information and Control22A with 14 benchmark test functions. Results are supported by a statistically significant framework (Wilcoxon test [45-47]) to show that the OBEMO is as accurate as the standard EMO optimization set, but requires a shorter number of iterations."}], "references": [{"title": "An efficient global optimization approach for rough set based dimensionality reduction", "author": ["Songbo Tan", "Xueqi Cheng", "Hongbo Xu"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "A new approach to global optimization motivated by parliamentary political competitions", "author": ["Ali Borji", "Mandana Hamidi"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Error-tolerant minimum finding with DNA computing", "author": ["Chia-Ning Yang", "Kuo-Si Huang", "Chang-Biau Yang", "Chie-Yao Hsu"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "An optimization model based decision support system for distributed energy systems planning. International Journal of Innovative Computing, Information and Control, 7(5(B)), 2011, 2651-2668", "author": ["Weijun Gao", "Hongbo Ren"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Multistage portfolio optimization with var as risk", "author": ["Chunhui Xu", "Jie Wang", "Naoki Shiba"], "venue": "measure. International Journal of Innovative Computing, Information and Control,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "A performance comparison between genetic algorithms and particle swarm optimization applied in constructing equity portfolios", "author": ["Jui-Fang Chang"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Optimization of linear observations for the stationary kalman filter based on a generalized water filling theorem", "author": ["Yoshiki Takeuchi"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "A numerical scheme for approximate optimal control of nonlinear hybrid systems", "author": ["Akbar H. Borzabadi", "Mohammad E. Sadjadi", "Behzad Moshiri"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Adaptation in Natural and Artificial Systems, University of Michigan Press", "author": ["J.H. Holland"], "venue": "Ann Arbor, MI,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1975}, {"title": "Positive feedback as a search strategy", "author": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "venue": "Technical Report", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1991}, {"title": "Differential Evolution a Practical Approach to Global Optimization, Springer", "author": ["K. Price", "R. Storn", "A. Lampinen"], "venue": "Natural Computing Series,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Teams of intelligent agents which learn using artificial immune systems", "author": ["Colin Fyfe", "Lakhmi Jain"], "venue": "Journal of Network and Computer Applications,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "An idea based on honey bee swarm for numerical optimization, technical report- TR06,Erciyes University, Engineering Faculty", "author": ["D. Karaboga"], "venue": "Computer Engineering Department", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Filter modeling using Gravitational Search Algorithm", "author": ["E. Rashedia", "H. Nezamabadi-pour", "S. Saryazdi"], "venue": "Engineering Applications of Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "An Electromagnetism-like Mechanism for Global Optimization", "author": ["S. \u0130lker Birbil", "Shu-Cherng Fang"], "venue": "Journal of Global Optimization,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2003}, {"title": "Hybridizing the electromagnetism-like algorithm with descent search for solving engineering design problems", "author": ["A. Rocha", "E. Fernandes"], "venue": "International Journal of Computer Mathematics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Modified movement force vector in an electromagnetism-like mechanism for global optimization", "author": ["A. Rocha", "E. Fernandes"], "venue": "Optimization Methods & Software", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Multi-objective inventory control using electromagnetism-like metaheuristic", "author": ["C.S. Tsou", "C.H. Kao"], "venue": "International Journal of Production Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "An electromagnetism algorithm of neural network analysis an application to textile retail operation", "author": ["P. Wu", "Y. Wen-Hung", "W. Nai-Chieh"], "venue": "Journal of the Chinese Institute of Industrial Engineers,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "On the convergence of a population-based global optimization algorithm", "author": ["S.I. Birbil", "S.C. Fang", "R.L. Sheu"], "venue": "Journal of Global Optimization,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}, {"title": "Electromagnetism-like mechanism and simulated annealing algorithms for flowshop scheduling problems minimizing the total weighted tardiness and makespan", "author": ["B. Naderi", "R. Tavakkoli-Moghaddam", "M. Khalili"], "venue": "Knowledge-Based Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Peak to average power ratio reduction of multicarrier transmission systems using electromagnetism-like method", "author": ["Ho-Lung Hung", "Yung-Fa Huang"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "A new Hybrid Electromagnetism-like Algorithm for capacitated vehicle routing problems", "author": ["A. Yurtkuran", "E. Emel"], "venue": "Expert Systems with Applications,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Kun-Chou, Array pattern optimization using electromagnetism-like algorithm", "author": ["L.J. Jhen-Yan"], "venue": "AEU - International Journal of Electronics and Communications,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "An electromagnetism algorithm of neural network analysis an application to textile retail operation", "author": ["P. Wu", "Y. Wen-Hung", "W. Nai-Chieh"], "venue": "Journal of the Chinese Institute of Industrial Engineers,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2004}, {"title": "Fractional-order PID controller optimization via improved electromagnetismlike algorithm", "author": ["C.H. Lee", "F.K. Chang"], "venue": "Expert Systems with Applications,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "Circle detection using electromagnetism optimization", "author": ["E. Cuevas", "D. Oliva", "D. Zaldivar", "M. P\u00e9rez-Cisneros", "H. Sossa"], "venue": "Information Sciences", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Revised electromagnetism-like mechanism for flow path design of unidirectional AGV systems", "author": ["Xianping Guan", "Xianzhong Dai", "Jun Li"], "venue": "International Journal of Production Research", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "Numerical Experiments with a Population Shrinking Strategy within a Electromagnetism-like Algorithm", "author": ["Ana Maria A.C. Rocha", "Edite Fernandes"], "venue": "Journal of Mathematics and Computers in Simulation", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Numerical study of augmented Lagrangian algorithms for constrained global optimization", "author": ["Ana Maria A.C. Rocha", "Edite Fernandes"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "A hybrid of electromagnetismlike mechanism and back-propagation algorithms for recurrent neural fuzzy systems design", "author": ["Ching-Hung Lee", "Fu-Kai Chang", "Che-Ting Kuo", "Hao-Hang Chang"], "venue": "International Journal of Systems Science,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "Opposition-based learning: a new scheme for machine intelligence", "author": ["H.R. Tizhoosh"], "venue": "Proceedings of international conference on computational intelligence for modeling control and automation,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2005}, {"title": "A Novel Population Initialization Method for Accelerating Evolutionary Algorithms, Computers and Mathematics with Applications, Volume", "author": ["S.Rahnamayn", "H.R.Tizhoosh", "M.Salama"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2007}, {"title": "Opposition versus randomness in soft computing techniques", "author": ["S Rahnamayan", "HR Tizhoosh", "MMA. Salama"], "venue": "Elsevier J Appl. Soft Comput", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "Enhanced opposition-based differential evolution for solving high-dimensional continuous optimization problems", "author": ["Hui Wang", "Zhijian Wu", "Shahryar Rahnamayan"], "venue": "Soft Comput", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2010}, {"title": "A novel function optimization approach using opposition based genetic algorithm with gene excitation", "author": ["Muhammad Amjad Iqbal", "Naveed Kazim Khan", "Hasan Multaba", "A. Rauf Baig"], "venue": "International Journal of Innovative Computing, Information and Control,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "Opposition-based differential evolution", "author": ["S Rahnamayan", "HR Tizhoosh", "MMA. Salama"], "venue": "IEEE Trans Evol Comput", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2008}, {"title": "Enhancing particle swarm optimization using generalized opposition-based learning", "author": ["Hui Wanga", "Zhijian Wua", "Shahryar Rahnamayan", "Yong Liu", "Mario Ventresca"], "venue": "Information Sciences", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2011}, {"title": "A novel opposition-based gravitational search algorithm for combined economic and emission dispatch problems of power systems", "author": ["Binod Shaw", "V. Mukherjee", "S.P. Ghoshal"], "venue": "Electrical Power and Energy Systems", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2012}, {"title": "Opposition-based reinforcement learning", "author": ["Tizhoosh HR"], "venue": "J Adv Comput Intell Intell Inform", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2006}, {"title": "Opposition-based Q(k) algorithm", "author": ["M Shokri", "HR Tizhoosh", "M. Kamel"], "venue": "Proc IEEE world congr comput intell;", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2006}, {"title": "The global optimization problem: An introduction", "author": ["Dixon", "L.C.W", "G. P Szeg\u00f6"], "venue": "Towards Global Optimization 2,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 1978}, {"title": "A study on the use of non-parametric tests for analyzing the evolutionary algorithms\u2019 behaviour: a case study on the CEC\u20192005 Special session on real parameter optimization", "author": ["S Garcia", "D Molina", "M Lozano", "F Herrera"], "venue": "J Heurist. doi:10.1007/s10732-008-9080-4", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2008}, {"title": "Performance Evaluation of Memetic Approaches in 3D Reconstruction of Forensic Objects", "author": ["J. Santamar\u00eda", "O. Cord\u00f3n", "S. Damas", "J.M. Garc\u00eda-Torres", "A. Quirin"], "venue": "Soft Computing,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 25, "endOffset": 30}, {"referenceID": 1, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 25, "endOffset": 30}, {"referenceID": 2, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 81, "endOffset": 84}, {"referenceID": 3, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 98, "endOffset": 101}, {"referenceID": 4, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 113, "endOffset": 118}, {"referenceID": 5, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 113, "endOffset": 118}, {"referenceID": 6, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 179, "endOffset": 184}, {"referenceID": 7, "context": "Global Optimization (GO) [1,2] has issued applications for many areas of science [3], engineering [4], economics [5,6] and others whose definition requires mathematical modelling [7,8].", "startOffset": 179, "endOffset": 184}, {"referenceID": 8, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 141, "endOffset": 144}, {"referenceID": 9, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 216, "endOffset": 220}, {"referenceID": 10, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 250, "endOffset": 254}, {"referenceID": 11, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 288, "endOffset": 292}, {"referenceID": 12, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 319, "endOffset": 323}, {"referenceID": 13, "context": "Some other metaheuristic optimization algorithms have been recently proposed to solve optimization problems, such as Genetic Algorithms (GA) [9], Particle Swarm Optimization (PSO) [10], Ant Colony Optimization (ACO) [11], Differential Evolution (DE) [12], Artificial Immune Systems (AIS) [13] and Artificial Bee Colony [14] and Gravitational Search Algorithm (GSA) [15].", "startOffset": 365, "endOffset": 369}, {"referenceID": 14, "context": "Electromagnetism-like algorithm (EMO) is a relatively new population-based meta-heuristic algorithm which was firstly introduced by Birbil and Fang [16] to solve continuous optimization models using bounded variables.", "startOffset": 148, "endOffset": 152}, {"referenceID": 15, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 150, "endOffset": 157}, {"referenceID": 16, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 150, "endOffset": 157}, {"referenceID": 17, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 150, "endOffset": 157}, {"referenceID": 18, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 150, "endOffset": 157}, {"referenceID": 19, "context": "Although the EMO algorithm shares some characteristics with PSO and ACO, recent works have exhibited its better accuracy regarding optimal parameters [17-20], yet showing convergence [21].", "startOffset": 183, "endOffset": 187}, {"referenceID": 20, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 112, "endOffset": 116}, {"referenceID": 21, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 133, "endOffset": 137}, {"referenceID": 22, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 155, "endOffset": 159}, {"referenceID": 23, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 200, "endOffset": 204}, {"referenceID": 24, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 230, "endOffset": 234}, {"referenceID": 25, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 251, "endOffset": 255}, {"referenceID": 26, "context": "EMO has been successfully applied to solve different sorts of engineering problems such as flow-shop scheduling [22], communications [23], vehicle routing [24], array pattern optimization in circuits [25], neural network training [26] control systems [27] and image processing [28].", "startOffset": 277, "endOffset": 281}, {"referenceID": 27, "context": "In [29] where Guan et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "In [30] and [31], authors include a new local search method which is based on a fixed search pattern and a shrinking strategy that aims to reduce the population size as the iterative process progresses.", "startOffset": 3, "endOffset": 7}, {"referenceID": 29, "context": "In [30] and [31], authors include a new local search method which is based on a fixed search pattern and a shrinking strategy that aims to reduce the population size as the iterative process progresses.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "Additionally, in [17], a modified local search phase that employs the gradient descent method is adopted to enhance its computational complexity.", "startOffset": 17, "endOffset": 21}, {"referenceID": 25, "context": "Although all these approaches have improved the computational time which is required by the original EMO algorithm, recent works [27,32] have demonstrated that reducing or simplifying EMO\u2019s local search processes also affects other important properties, such as convergence, exploration, population diversity and accuracy.", "startOffset": 129, "endOffset": 136}, {"referenceID": 30, "context": "Although all these approaches have improved the computational time which is required by the original EMO algorithm, recent works [27,32] have demonstrated that reducing or simplifying EMO\u2019s local search processes also affects other important properties, such as convergence, exploration, population diversity and accuracy.", "startOffset": 129, "endOffset": 136}, {"referenceID": 31, "context": "On the other hand, the opposition-based learning (OBL), that has been initially proposed in [33], is a machine intelligence strategy which considers the current estimate and its correspondent opposite value (i.", "startOffset": 92, "endOffset": 96}, {"referenceID": 32, "context": "It has been mathematically proved [34-36] that an opposite candidate solution holds a higher probability for approaching the global optimum solution than a given random candidate, yet quicker.", "startOffset": 34, "endOffset": 41}, {"referenceID": 33, "context": "It has been mathematically proved [34-36] that an opposite candidate solution holds a higher probability for approaching the global optimum solution than a given random candidate, yet quicker.", "startOffset": 34, "endOffset": 41}, {"referenceID": 34, "context": "It has been mathematically proved [34-36] that an opposite candidate solution holds a higher probability for approaching the global optimum solution than a given random candidate, yet quicker.", "startOffset": 34, "endOffset": 41}, {"referenceID": 35, "context": "Recently, the concept of opposition has been used to accelerate metaheuristic-based algorithms such as GA [37], DE [38], PSO [39] and GSA [40].", "startOffset": 106, "endOffset": 110}, {"referenceID": 36, "context": "Recently, the concept of opposition has been used to accelerate metaheuristic-based algorithms such as GA [37], DE [38], PSO [39] and GSA [40].", "startOffset": 115, "endOffset": 119}, {"referenceID": 37, "context": "Recently, the concept of opposition has been used to accelerate metaheuristic-based algorithms such as GA [37], DE [38], PSO [39] and GSA [40].", "startOffset": 125, "endOffset": 129}, {"referenceID": 38, "context": "Recently, the concept of opposition has been used to accelerate metaheuristic-based algorithms such as GA [37], DE [38], PSO [39] and GSA [40].", "startOffset": 138, "endOffset": 142}, {"referenceID": 6, "context": "Comparisons to the original EMO and others state-of-the-art EMO-based algorithms [7] demonstrate that the OBEMO technique is faster for all test functions, yet delivering a higher accuracy.", "startOffset": 81, "endOffset": 84}, {"referenceID": 9, "context": "Few particles are required to reach converge as has been already demonstrated in [11].", "startOffset": 81, "endOffset": 85}, {"referenceID": 5, "context": "EMO algorithm has four phases [6]: initialization, local search, computation of the total force vector and movement.", "startOffset": 30, "endOffset": 33}, {"referenceID": 15, "context": "Nevertheless, recent works [17,32] have shown that eliminating, reducing or simplifying the local search process affects significantly the convergence, exploration, population diversity and accuracy of the EMO algorithm.", "startOffset": 27, "endOffset": 34}, {"referenceID": 30, "context": "Nevertheless, recent works [17,32] have shown that eliminating, reducing or simplifying the local search process affects significantly the convergence, exploration, population diversity and accuracy of the EMO algorithm.", "startOffset": 27, "endOffset": 34}, {"referenceID": 31, "context": "Opposition-based Learning [33] is a new concept in computational intelligence that has been employed to effectively enhance several soft computing algorithms [42,43].", "startOffset": 26, "endOffset": 30}, {"referenceID": 39, "context": "Opposition-based Learning [33] is a new concept in computational intelligence that has been employed to effectively enhance several soft computing algorithms [42,43].", "startOffset": 158, "endOffset": 165}, {"referenceID": 40, "context": "Opposition-based Learning [33] is a new concept in computational intelligence that has been employed to effectively enhance several soft computing algorithms [42,43].", "startOffset": 158, "endOffset": 165}, {"referenceID": 32, "context": "This is a preprint copy that has been accepted for publication in International Journal of Innovative Computing, Information and Control 9 solution x and its opposite solution x for a given problem, providing a renewed chance to find a candidate solution lying closer to the global optimum [34].", "startOffset": 290, "endOffset": 294}, {"referenceID": 33, "context": "By doing so, the fitter one (guess or opposite guess) can be chosen as an initial solution following the fact that, according to probability theory, 50% of the time a guess is further from the solution than its opposite guess [35].", "startOffset": 226, "endOffset": 230}, {"referenceID": 14, "context": "The original test functions, which are shown in Table 1, agree to the set of numerical benchmark functions presented by the original EMO paper at [16].", "startOffset": 146, "endOffset": 150}, {"referenceID": 41, "context": "More details can be found in [44].", "startOffset": 29, "endOffset": 33}, {"referenceID": 30, "context": "2 exp cos(2 ) 20 n n i i i i f x x n n \u03c0 = = \uf8eb \uf8f6 \uf8eb \uf8f6 = \u2212 \u2212 \u2212 + \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ed \uf8f8 \uf8ed \uf8f8 \u2211 \u2211 x 30 [ 32,32] \u2212 0", "startOffset": 92, "endOffset": 100}, {"referenceID": 30, "context": "2 exp cos(2 ) 20 n n i i i i f x x n n \u03c0 = = \uf8eb \uf8f6 \uf8eb \uf8f6 = \u2212 \u2212 \u2212 + \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ed \uf8f8 \uf8ed \uf8f8 \u2211 \u2211 x 30 [ 32,32] \u2212 0", "startOffset": 92, "endOffset": 100}, {"referenceID": 14, "context": "The algorithms are listed below: - Standard EMO algorithm [16]; - Hybridizing EMO with descent search (HEMO) [17]; - EMO with fixed search pattern (FEMO) [30]; - The proposed approach OBEMO.", "startOffset": 58, "endOffset": 62}, {"referenceID": 15, "context": "The algorithms are listed below: - Standard EMO algorithm [16]; - Hybridizing EMO with descent search (HEMO) [17]; - EMO with fixed search pattern (FEMO) [30]; - The proposed approach OBEMO.", "startOffset": 109, "endOffset": 113}, {"referenceID": 28, "context": "The algorithms are listed below: - Standard EMO algorithm [16]; - Hybridizing EMO with descent search (HEMO) [17]; - EMO with fixed search pattern (FEMO) [30]; - The proposed approach OBEMO.", "startOffset": 154, "endOffset": 158}, {"referenceID": 14, "context": "For the original EMO algorithm described in [16] and the proposed OBEMO, the parameter set is configured considering: 0.", "startOffset": 44, "endOffset": 48}, {"referenceID": 15, "context": "Such values can be assumed as the best configuration set according to [17].", "startOffset": 70, "endOffset": 74}, {"referenceID": 42, "context": "In order to statistically analyse the results in Table 3, a non-parametric significance proof known as the Wilcoxon\u2019s rank test [45-47] has been conducted.", "startOffset": 128, "endOffset": 135}, {"referenceID": 43, "context": "In order to statistically analyse the results in Table 3, a non-parametric significance proof known as the Wilcoxon\u2019s rank test [45-47] has been conducted.", "startOffset": 128, "endOffset": 135}, {"referenceID": 42, "context": "Results are supported by a statistically significant framework (Wilcoxon test [45-47]) to demonstrate that the OBEMO is as accurate as the standard EMO yet requiring a shorter number of iterations.", "startOffset": 78, "endOffset": 85}, {"referenceID": 43, "context": "Results are supported by a statistically significant framework (Wilcoxon test [45-47]) to demonstrate that the OBEMO is as accurate as the standard EMO yet requiring a shorter number of iterations.", "startOffset": 78, "endOffset": 85}, {"referenceID": 6, "context": "Likewise, it is as fast as others state-of-the-art EMO-based algorithms such as HEMO [7] and FEMO [30], still keeping the original accuracy.", "startOffset": 85, "endOffset": 88}, {"referenceID": 28, "context": "Likewise, it is as fast as others state-of-the-art EMO-based algorithms such as HEMO [7] and FEMO [30], still keeping the original accuracy.", "startOffset": 98, "endOffset": 102}], "year": 2014, "abstractText": "* Erik Cuevas 1 , + Diego Oliva, * Daniel Zaldivar, * Marco P\u00e9rez-Cisneros and + Gonzalo Pajares Departamento de Ciencias Computacionales Universidad de Guadalajara, CUCEI Av. Revoluci\u00f3n 1500, Guadalajara, Jal, M\u00e9xico {erik.cuevas, daniel.zaldivar, marco.perez}@cucei.udg.mx Dpto. Ingenier\u00eda del Software e Inteligencia Artificial, Facultad Inform\u00e1tica, Universidad Complutense, Av. Complutense S/N, 28040, Madrid, Spain doliva@estumail.ucm.es, pajares@fdi.ucm.es", "creator": "PDFCreator Version 1.2.0"}}}