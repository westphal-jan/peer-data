{"id": "1405.5208", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2014", "title": "A Tutorial on Dual Decomposition and Lagrangian Relaxation for Inference in Natural Language Processing", "abstract": "Dual decomposition, and more generally Lagrangian relaxation, is a classical method for combinatorial optimization; it has recently been applied to several inference problems in natural language processing (NLP). This tutorial gives an overview of the technique. We describe example algorithms, describe formal guarantees for the method, and describe practical issues in implementing the algorithms. While our examples are predominantly drawn from the NLP literature, the material should be of general relevance to inference problems in machine learning. A central theme of this tutorial is that Lagrangian relaxation is naturally applied in conjunction with a broad class of combinatorial algorithms, allowing inference in models that go significantly beyond previous work on Lagrangian relaxation for inference in graphical models.", "histories": [["v1", "Thu, 23 Jan 2014 02:50:15 GMT  (490kb)", "http://arxiv.org/abs/1405.5208v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["alexander m rush", "michael collins"], "accepted": false, "id": "1405.5208"}, "pdf": {"name": "1405.5208.pdf", "metadata": {"source": "CRF", "title": "A Tutorial on Dual Decomposition and Lagrangian Relaxation for Inference in Natural Language Processing", "authors": ["Alexander M. Rush", "Michael Collins"], "emails": ["SRUSH@CSAIL.MIT.EDU", "MCOLLINS@CS.COLUMBIA.EDU"], "sections": [{"heading": null, "text": "This tutorial gives an overview of the technique. We describe sample algorithms, describe formal guarantees for the method, and describe practical problems in implementing the algorithms. Although our examples come predominantly from the NLP literature, the material for inference problems in machine learning should be of general relevance. A central theme of this tutorial is that Lagrangian relaxation is naturally applied in conjunction with a broad class of combinatorial algorithms, which allows conclusions to be drawn in models that go far beyond previous work on Lagrangian relaxation to draw conclusions from graphical models."}, {"heading": "1. Introduction", "text": "In many areas of statistical language processing, the task is to relate some input masks x (e.g. a string) to some structured output forms (e.g. a parser tree). This figure is often defined as simple output forms. (1), where Y is a finite set of possible structures for input x, and h: Y \u2192 R is a function that maps a score h (y) to each y in Y. For example, X would be a sentence, and Y would be the set of all possible output sequences for x; in parser formation, a sentence and Y would be the number of all parser trees for x; in machine translation, x would be a set of all possible translations for x. The problem of determining y is called a decoding problem. The size of Y typically grows exponentially in relation to the size of the input x, which is a complete search for possible translations for x."}, {"heading": "2. Related Work", "text": "This tutorial is based on ideas from the areas of combinatorial optimization, machine learning and natural language processing. In this section, we give a summary of the work from these areas that is relevant for the methods we describe."}, {"heading": "2.1 Combinatorial Optimization", "text": "Lagrange's relaxation (LR) is a widely used method of combinatorial optimization, dating back to the pioneering work of Held and Karp (1971) on the problem of the traveling salesman; see the work of Lemare \u0301 chal (2001) and Fisher (1981) on LR methods and the Korte and Vygen textbook (2008) on combinatorial optimization; the decomposition of linear and integer linear programs is also a fundamental technique in the optimization community (Dantzig & Wolfe, 1960; Everett III, 1963); there is a very direct relationship between LR algorithms and linear programming loosenings of combinatorial optimization problems; see again the Korte and Vygen textbook."}, {"heading": "2.2 Belief Propagation, and Linear Programming Relaxations for Inference in MRFs", "text": "For tree-structured MRFs, the Max product propagation (Max product BP) provides exact solutions. (Max product BP is a form of dynamic programming closely related to the Viterbi algorithm.) For general MRFs, where the underlying graph may contain cycles, the MAP problem is NP-hard: This has led researchers to consider a number of approximate inference algorithms. Early work considers Loopy variants of the Max product BP (see, for example, Felzenszwalb & Huttenlocher, 2006, for the application of the Loopy-Max product BP to problems in computer vision); however, these methods are heuristic, lacking formal optimizations. Recent work considers methods based on linear programming (LP) as a loosening of the MAP problem."}, {"heading": "2.3 Combinatorial Algorithms in Belief Propagation", "text": "A central idea in the algorithms we describe is the use of combinatorial algorithms other than maxproduct BP. This idea is closely related to previous work on the use of combinatorial algorithms within the propagation of belief, either for the MAP inference problem (Duchi, Tarlow, Elidan, & Koller, 2007) or for the calculation of marginals (Smith & Eisner, 2008), which generalize loopy BP in a way that allows the use of combinatorial algorithms."}, {"heading": "2.4 Linear Programs for Decoding in Natural Language Processing", "text": "Dual decomposition and Lagrange's relaxation are closely related to integer linear programming (ILP) approach, and linear programming relaxations of ILP problems. Several authors used integer linear programming directly to solve challenging problems in NLP. Germann, Jahr, Knight, Marcu, and Yamada (2001) use ILP to test the search error of a greedy phrase-based translation system using short sentences. Roth and Yih (2005) formulate a problem with limited consequence labeling as ILP and decode it with an all-purpose solver. Lacoste-Julien, Taskar, Klein, and Jordan (2006) describe a quadratic assignment problem for bilingual alignment and then decode it with the help of an ILP solver. Both the work of Riedel and Clarke (2006) and Martins, Smith, and Xing (2009) formulate non-projective dependency sparing as ILP and we use Riedel decode a general problem with ILP."}, {"heading": "3. Lagrangian Relaxation and Dual Decomposition", "text": "This section gives first a formal description of Lagran relaxation and then a description of dual decomposition, an important special case of Lagran relaxation. The descriptions we give are intentionally short. The material in this section is not essential for the rest of this essay and can be safely skipped by the reader or reproduced in a second reading. Nevertheless, the descriptions here can be useful for those who want to immediately see a formal treatment of Lagran relaxation and dual decomposition. All the algorithms in this essay are special cases within the framework described in this section."}, {"heading": "3.1 Lagrangian Relaxation", "text": "We assume that the problem is in the Eq. In some cases it could be a hard problem that is associated with any vector y."}, {"heading": "3.2 Dual Decomposition", "text": "We give a formal description of the dual decomposition. As we will see, the dual decomposition is a special case of Lagranger relaxation; 4 however, it is important enough to fulfill the purposes of this tutorial to justify its own description. Again, this section is intentionally short and can be safely skipped. Furthermore, we assume that we have a second finite set of methods with which we have an associated vector-Z problem. (2) The decoding problem is then a vector in Rd. (1) In addition, we assume that we have a second finite set of Rd. (1), with each vector e.g. (2) associated vector e.g. (2) The decoding problem is then to findargmax y y y y. (1) + e.g. (2) We assume that Ay + Cz. (2)"}, {"heading": "4. An Example: Integration of a Parser and a Finite-State Tagger", "text": "The classic approach to this problem is to use a dynamic programming algorithm based on the construction of Bar-Hillel, Perles and Shamir (1964) for the intersection of a context-free language and a finite state language. The dual decomposition algorithm has advantages over exhaustive dynamic programming, both in terms of efficiency and simplicity. We will use this dual decomposition algorithm as a running example in this tutorial. We will first give a formal definition of the problem, describe the motivation for the problem and describe the classic approach of dynamic programming."}, {"heading": "4.1 Definition of the Problem", "text": "Consider the problem of mapping an input record x to a parse tree y 2. Define zi as the set of all parsector trees for x. the parsector problem is that the sum of the two parsector trees (1) is the sum of the parsector trees: First, the score for y under a weighted context-free grammar \u2212 \u2212 and secondly, the score for the part of the speech (POS) is the sequence in y under a finite word stem y y. We consider the case in which h (y) is the score for the speech model as a whole. Formally, we define h (y) the score for the spoken component model. The functions f, g, and l are defined as follows: 1. f (y) is the score for y under a context-free grammar (WCFG). A WCFG consists of a context-free function with a set of rules and a set of grammar."}, {"heading": "4.2 The Dual Decomposition Algorithm", "text": "We assume that it will be a way in which there will be some kind of situation in which we will z (i, t) = 1, if the tag sequence has a tag sequence in position i, 0 otherwise has a tag sequence. (4, A) = 1: SNPNUnitedVPVfliesNPDsomeAlargeNjet United1 flow2, 2 large4 V D No.2 Definition of the problem of all possible problem solutions for the PPDDD We assume that we will introduce the problem for the PDD. (1) We assume that the tag sequence is in position i, 0 otherwise. (4, A) = 1: SNPNUnitedVPDsomeAlargeNjet United1 flow2, 3 large4 V D No.2 Definition of the problem in the series of POS (1, 2). (4, A) = 1: SNPNUnitVedFlies2 Flies2, Nitge2."}, {"heading": "4.3 Relationship of the Approach to Section 3", "text": "It is easy to verify that the approach we describe is an instance of the dual decomposition framework described in Section 3.2. Set Y is the set of all parses for the input set; set Z is the set of all POS sequences for the input set. Each parse tree y-Rd is represented as a vector, so that f (y) = y \u00b7 \u03b8 (1) for some \u03b8 (1) \u0445 Rd: There are a number of ways to represent parse trees as vectors, see, for example, the work of Rush et al. (2010). Likewise, each tag sequence z-Rd \u2032 is represented as a vector, so that g (z) = z \u00b7 \u03b8 (2) for some \u03b8 (2) and \"Rd.\" The constraints (i, t) = z (i, t) for all (i, t) and (z) by linear constraints Ay + Cz = bfor appropriate decisions of A, C and b can be encoded."}, {"heading": "4.4 An Example Run of the Algorithm", "text": "For the sake of simplicity, we assume that the increment \u03b4k equals 1 for all iterations k. We take the input set, United flies a large jet. First, the algorithm specifies u (i, t) = 0 for all (i, t). For our example, decoding with these initial weights leads to the two hypothesesSNPAUnitedNFliesDsomeAlargeVPVjet United1 flow2 some3 large4 jet5N V A NThese two structures have different POS tags at three positions highlighted in red, so the two structures do not match. We then update the u (i, t) variables based on these differences and give new values as follows: u (1, A) = u (2, N) = u (5, V) = \u2212 1u (1, N) = u (2, N) = u (5, N)."}, {"heading": "5. Formal Properties", "text": "We will now give some formal characteristics of the algorithm described in the previous section. We will first describe three important theorems relating to the algorithm, and then describe links between the algorithm and the optimization methods for subgradients."}, {"heading": "5.1 Three Theorems", "text": "We remember that the problem we are trying to solve, (optimization problem 1) isargmax y, z-z f (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) max (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x x x x (s) x x x x (s) x x (s) x x x (s) x x (s) x (s) x (s) x (s) x (s) x (s) x (s) x) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (s) x (z) x (z) x (z) x (x) x (z (x) x) x (z (x) x) x (z (x) x) x (z (x) x (x) x (x) x (z (x) x) x (x (x) x (x) x (z (x) x) x (x (x) x)"}, {"heading": "5.2 Subgradients", "text": "The proof of d-convergence as defined in Theorem 4 is based on the fact that the algorithm in Figure 2 is an undergradient algorithm to minimize the dual object L (u). Undergradient algorithms are a generalization of methods of gradient descent; however, they can be used to minimize convex functions that are not differentiable. This section describes how the algorithm in Figure 2 is derived as a subgradient algorithm (i) as defined as follows: L (u) = max y-Z L (u) = max y-Z-Z L (u) = max y-Z L (u) = max y-Z f (y)."}, {"heading": "6. Other Examples", "text": "In this section we describe further examples of dual decomposition algorithms. Our first example, also from the work of Rush et al. (2010), is a dual decomposition algorithm that combines two parsing models. Our second example, also from the work of Komodakis et al. (2007, 2011), is a dual decomposition algorithm for inference in Markov random fields. Finally, we describe the algorithm of Held and Karp (1971) for the problem of the driving salesman and the algorithm of Chang and Collins (2011) for decoding phrase-based translation models."}, {"heading": "6.1 Combined Constituency and Dependency Parsing", "text": "(2010) we describe an algorithm for searching for the highest scoring of lexicalized context dependencies (2008). (2010) We describe an algorithm for searching for the highest scoring of lexicalized context dependencies (2008). (2008) We define an example of a lexicalized context dependency (1997). We consider Y as the set of all lexicalized trees for the input set, and f (y) as the value of the tree y under a lexicalized parsing model - specifically f (y) is the log probability of y under the Collins model (1997). Under this model, each lexicalized rule in y receives a log probability, and the log probability of y is the sum of the log probabilities for the rules it adopts. Our second model is a dependency model."}, {"heading": "6.2 The MAP Problem for Pairwise Markov Random Fields", "text": "In this section we describe the dual resolution algorithm from the work of Komodakis et al. (2007, 2011) for finding the MAP solution in pairwise, binary, MRFs problem is limited to the case where potential functions consider pairs of random variables as if generalizing the method to non-pairwise MRFs values is straightforward. A commonly used approach to the MAP problem is to use loopy max product-related beliefs. The dual composition of algorithms has advantages in terms of stronger formal guarantees, as described in Section 5.10."}, {"heading": "6.3 The Held and Karp Algorithm for TSPs", "text": "Our next example is the approach of Held and Karp (1971) for the next section) and the encryption of algorithms (TSPs), which is known for its original paper on Lagrangian Relaxation. This algorithm is not an instance of dual decomplications. Instead of using two or more combinatorial algorithms, it is a very useful technique that extends our scope to algorithms that make use of single combinatorial algorithms, which in turn are involved with Lagrange multipliers. While the use of two or more combinatorial algorithms, as seen in dual decompositions, is very useful is the extension of our scope to algorithms that make use of individual combinatorial algorithms. For NLP decoding algorithms that use a single combinatorial algorithms, see the Chang and Collins algorithms (2011) for decoding phrase models in the translation algorithms section (we describe in the next section)."}, {"heading": "6.4 Phrase-Based Translation", "text": "Next, we will consider a Lagrangian relaxation algorithm, described in the work of Chang and Collins (2011), for decoding phrase-based translation models (Koehn, Och, & Marcu, 2003). Input to a phrase-based translation model is a source-language sentence with n words, x = x1. The output is a sentence in the target language. The examples in this section will use German as the source language and English as the target language. We will also need to take this criticism seriously as a running example. A key component of a phrase-based translation model is a phrase-based lexicon that pairs sequences of words in the target language. For example, lexical entries that are relevant to the German sentence shown above (we must) (we must) (we must)."}, {"heading": "7. Practical Issues", "text": "We describe diagnoses that can be used to track the progress of the algorithm in minimizing the dual solution and in providing a primary solution; we describe methods for selecting the step variables, \u03b4k, in the algorithm; and we describe heuristics that can be used in cases where the algorithm does not provide an exact solution. We will continue to use the algorithm from Section 4 as a running example, although our observations are easily generalized to other stock-based relativization algorithms. The first thing to note is that each iteration of the algorithm produces a number of useful terms, in particular: \u2022 The solutions y (k) and z (k)."}, {"heading": "7.1 An Example Run of the Algorithm", "text": "Figure 7 shows a sequence of the subgradient algorithm for machine translation decoding described in the work of Rush and Collins (2011). The behavior is typical of cases where the algorithm e-converges to find an exact solution. We show the dual value L (u (k)) for each iteration and the value for f (y (k)) + g (l (k)) for each iteration. Some important points are as follows: \u2022 Since L (u) provides an upper limit for f (y) + g (z) + g (k))) for each iteration. \u2022 In this example, we have e-convergence to an exact solution where we have L (u (k) = f (y (k)) + g (z (k))."}, {"heading": "7.2 Choice of the Step Sizes \u03b4k", "text": "Figure 9 shows the convergence of the algorithm for various step size decisions, where we have decided to keep the step size constant with each iteration. We immediately see a potential dilemma. If the step size is too small (\u03b4 = 0.0005), the convergence is smooth - the dual value decreases monotonously - but the convergence is slow. If the step size is too large (\u03b4 = 0.01), the convergence is much faster in the early stages of the algorithm, but the dual value then fluctuates quite irregularly. In practice, it is often very difficult to choose a constant step size that provides good convergence properties in both early and late iterations of the algorithm. Instead, we have found that we often find improved convergence properties in defining the step size \u0441k, which decreases with increasing k. One way is to use a definition such as \u0441k = k or c = ltk / k where a constant is."}, {"heading": "7.3 Recovering Approximate Solutions", "text": "Figure 10 shows a run of the algorithm in which we fail to bring the e-convergence to an exact solution. In Section 9.4, we will describe a possible strategy, namely the streamlining of the relaxation that can be used to achieve an exact solution in these cases. Another obvious strategy, which is approximate, is simply to choose the best primary solution generated after k-iterations of the algorithm, for some fixed k: i.e., y (k \u2032), l (k \u2032)), where \u2032 = argmax k \u2032 f (y (k \u2032)) + g (l (y (k \u2032)) -30-25-20-15-10-500 10 20 30 40 40 50 60 70V alueRoundBest Primal Current dual Figure 10: Graph that can be used to describe the dual value L (k \u2032) + g (y (k \u2032)) and the primary value f (k \u2032) + g (l (y (k))) + g (l (k))."}, {"heading": "7.4 Early Stopping", "text": "In practice, this strategy can sometimes produce a high-quality solution, albeit without a certificate of optimism, faster than executing the algorithm for e-convergence. Figure 11 shows diagrams for two problems: the non-projective analysis of dependence (Koo et al., 2010) and the combined analysis of constituencies and dependencies (Rush et al., 2010). In any case, we show how three quantities vary with the number of iterations of the algorithm: the first quantity is the percentage of cases in which the algorithm converges, resulting in an exact solution, with a certificate of optimism. In a combined constituency and dependency analysis, it takes about 50 iterations for most (over 95%) cases in which e-convergence is achieved; the second algorithm approaches 1000 iterations. In addition, we show graphs showing the quality of the optimal choice and dependency analysis (over 95%) before we call up the first Iteration."}, {"heading": "8. Alternatives to Subgradient Optimization", "text": "This year, it has reached the stage where it will be able to put itself at the forefront in order to embark on the path to the future."}, {"heading": "9. The Relationship to Linear Programming Relaxations", "text": "This section describes the close relationship between the dual decomposition algorithm and linear programming relations. This link is very useful for understanding the behavior of the algorithm and, in particular, for understanding the cases where the algorithm does not e-converge to find an exact solution. In addition, strategies for \"streamlining\" the algorithm until an exact solution is found are proposed."}, {"heading": "9.1 The Linear Programming Relaxation", "text": "\u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2, \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2."}, {"heading": "9.2 The Dual of the New Optimization Problem", "text": "We will now describe the dual problem for the linear program in Eqs. 29 and 30. This in turn will be a function M (u) of a vector of dual variables u = (i, t). A decisive result will be that the two dual functions M (u) and L (u) are identical. Our new lagrangian isM (u, \u03b1, \u03b2) = (y) + (z) + (z) + (z) + (z) + x (z) + x (z) + x (z) + x (z) + x (z) + x (z) = x (i, t)."}, {"heading": "9.3 An Example", "text": "Through this example we will also illustrate what happens if the algorithm is not able to e-converge. We assume that there are three possible parse trees, Y = {y1, y2, y3} and three possible tag sequences, Z = {z1, z2, z3}, represented in Figure 12. We will write distributions about these sentences as vectors, such as z = [0, 0, 1] or \u03b2 = [0,5, 0,5, 0]. Let us now consider pairs of vectors (\u03b1, \u03b2) that satisfy the constraints in equation. Figure 13 illustrates two possible solutions that we call (\u03b11, \u03b21), is 1 = [0, 0, 1], \u03b21 = [0, 1], \u03b21 = [0, 1]. It is easy to verify that under this definition y y 1yy (1, c) = 1zz (1, c)."}, {"heading": "9.4 Fixing E-Convergence: Tightening Approaches", "text": "We now describe a \"streamlining\" approach that can be used to solve the problem of non-convergence cited in the previous examples. We introduce new variables y (i, t1, t2) for i (1, t2) for i (1, t1) for i (1, t2) for i (1, t2) for i (1, t2) for i (1), t1, t2) for i (i, t1, t2) for i, t2) for i (i, t1) and y (i + 1, t2) for i (1, t2) otherwise. Thus, the new variable label becomes bigrams. Likewise, we introduce variables z (i, t2) for tag sequences z. We now define the set of constraints for us (i, t) = z (i, t) for all i (i, t) for all i."}, {"heading": "9.5 Compact Linear Programs", "text": "The LP relaxations we have described have a very large set of variables: that is, one variable for each member of Y and Z. In most cases of interest, the sets Y and Z will be exponential. In this section, we describe how to derive equivalent linear programs with much fewer variables. This is a problem of practical interest: for many problems, we have found it beneficial to implement the underlying LP relaxation within a generic LP solver as a way to debug dual deposition algorithms. This is handy with the compact LPs we describe in this section, but is clearly impractical with the exponentially large linear programs described in the previous section. Let's first consider the abstract description of the Lagrange relaxation given in Section 3."}, {"heading": "Q = {y \u2208 Rd : Cy = e, y \u2265 0 and Ay = b}", "text": "Since d, p, and q are all polynomial in size, the resulting linear program is polynomial in size. In this sense, it is \"compact.\" The remaining question is whether a characterization of the form of Eq. \"37 exists, and if so, how it is defined. Remember that we have made the assumption that for each value of Commerce, argmax y\" y \"(38) a combinatorial algorithm can be used. For many combinatorial algorithms, there are LP formulations that are polynomial in size: These formulations lead directly to definitions of C and e.15 For example, Martin, Rardin, and Campbell (1990) give such a construction for dynamic programming algorithms, which includes parsing algorithms for weighted context-free grammars, the Viterbi algorithms, and other dynamic programs used in NLP."}, {"heading": "9.6 Summary", "text": "In summary, the key points of this section were as follows: \u2022 We introduced a linear programming problem that was a loosening of our original problem. The L (u) function proved to be the dual of this linear programming relaxation. \u2022 In cases where the optimal solution to the underlying LP is fractionated, the subgradient method will still d-converge to minu L (u). However, the primary solutions (y (k), z (k))) will switch between different solutions that do not meet the y (i, t) = z (i, t) constraints. \u2022 In practice, streamlining methods can be used to improve convergence. These methods selectively introduce constraints to improve convergence (k) and / or z (k) constraints, increasing the cost of increased complexity in searching for y (k) and / or z (k) constraints."}, {"heading": "10. Conclusions", "text": "LR methods use combinatorial algorithms in combination with linear constraints introduced by Lagrange multipliers: iterative methods are used to minimize the resulting dual target. LR algorithms are simple and efficient and typically involve repeated applications of the underlying combinatorial algorithm in conjunction with simple additive updates of Lagrange multipliers. They have well-understood formal characteristics: the dual target is an upper limit on the score for the optimal primary solution; there are close links to linear programming relaxations; and, most importantly, they have the potential to provide an exact solution to the original inference problem with a certificate of optimizability. Experiments on multiple NLP problems have shown the effectiveness of LR algorithms for conclusions: LR methods are often much more efficient than existing exact methods and have stronger formal guarantees than those used in practice at risk."}, {"heading": "Acknowledgments", "text": "Tommi Jaakkola and David Sontag introduced us to dual decomposition and Lagrangian relaxation to draw conclusions about probability models; this work would not have been possible without them. We benefited from many discussions with Yin-Wen Chang, Terry Koo, and Roi Reichart, who collaborated with Tommi and David on our work on dual decomposition / Lagrangian relaxation for NLP. We also thank Shay Cohen, Yoav Goldberg, Mark Johnson, Andre Martins, Ryan McDonald, and Slav Petrov for feedback on earlier drafts of this work. Columbia University is grateful for the support of the Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no. FA8750-09-C-0181. Alexander Rush was supported by a National Science Foundation Graduate Research Fellowship."}, {"heading": "Appendix A. Proofs", "text": "In this section we derive different results for the combined parsing and tagging problem. Remember that in this case the Lagrangian (u, y, z) = f (u) + g (z) + g (u, y) = u (u, max) (u, max) (u) (u) (u, t (i, t) \u2212 z (i, t) and that the dual target is L (u) = maxy Y, z (u, y, z). Here n is the number of words in the sentence, and T is a finite series of partial speech days. We first prove that L (u) is a convex function; we then derive the expression for subgradients of L (u, y); we then give a convergence theorem for the algorithms in Figure 2, which is a subaudience for the minimization of L (u).Finally, we give evidence for the provexity of L (u)."}], "references": [{"title": "A comparison of loopy belief propagation and dual decomposition for integrated ccg supertagging and parsing", "author": ["M. Auli", "A. Lopez"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Auli and Lopez,? \\Q2011\\E", "shortCiteRegEx": "Auli and Lopez", "year": 2011}, {"title": "On formal properties of simple phrase structure grammars", "author": ["Y. Bar-Hillel", "M. Perles", "E. Shamir"], "venue": "In Language and Information: Selected Essays on their Theory and Application,", "citeRegEx": "Bar.Hillel et al\\.,? \\Q1964\\E", "shortCiteRegEx": "Bar.Hillel et al\\.", "year": 1964}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": null, "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "Subgradient Methods. Course Notes for EE364b, Stanford University, Winter 2006-07", "author": ["S. Boyd", "A. Mutapcic"], "venue": null, "citeRegEx": "Boyd and Mutapcic,? \\Q2007\\E", "shortCiteRegEx": "Boyd and Mutapcic", "year": 2007}, {"title": "Exact Decoding of Phrase-based Translation Models through Lagrangian Relaxation", "author": ["Y. Chang", "M. Collins"], "venue": "In To appear proc. of EMNLP", "citeRegEx": "Chang and Collins,? \\Q2011\\E", "shortCiteRegEx": "Chang and Collins", "year": 2011}, {"title": "Three Generative, Lexicalised Models for Statistical Parsing", "author": ["M. Collins"], "venue": "In Proc. ACL,", "citeRegEx": "Collins,? \\Q1997\\E", "shortCiteRegEx": "Collins", "year": 1997}, {"title": "Decomposition principle for linear programs", "author": ["G. Dantzig", "P. Wolfe"], "venue": "In Operations research,", "citeRegEx": "Dantzig and Wolfe,? \\Q1960\\E", "shortCiteRegEx": "Dantzig and Wolfe", "year": 1960}, {"title": "An exact dual decomposition algorithm for shallow semantic parsing with constraints", "author": ["D. Das", "A. Martins", "N. Smith"], "venue": "Proceedings of* SEM.[ii,", "citeRegEx": "Das et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Das et al\\.", "year": 2012}, {"title": "Model-Based Aligner Combination Using Dual Decomposition", "author": ["J. DeNero", "K. Macherey"], "venue": "In Proc. ACL", "citeRegEx": "DeNero and Macherey,? \\Q2011\\E", "shortCiteRegEx": "DeNero and Macherey", "year": 2011}, {"title": "Using combinatorial optimization within maxproduct belief propagation", "author": ["J. Duchi", "D. Tarlow", "G. Elidan", "D. Koller"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "Duchi et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2007}, {"title": "Generalized lagrange multiplier method for solving problems of optimum allocation of resources", "author": ["III H. Everett"], "venue": "Operations Research,", "citeRegEx": "Everett,? \\Q1963\\E", "shortCiteRegEx": "Everett", "year": 1963}, {"title": "Efficient belief propagation for early vision", "author": ["P. Felzenszwalb", "D. Huttenlocher"], "venue": "International journal of computer vision,", "citeRegEx": "Felzenszwalb and Huttenlocher,? \\Q2006\\E", "shortCiteRegEx": "Felzenszwalb and Huttenlocher", "year": 2006}, {"title": "The lagrangian relaxation method for solving integer programming problems", "author": ["M.L. Fisher"], "venue": "Management Science,", "citeRegEx": "Fisher,? \\Q1981\\E", "shortCiteRegEx": "Fisher", "year": 1981}, {"title": "Fast decoding and optimal decoding for machine translation", "author": ["U. Germann", "M. Jahr", "K. Knight", "D. Marcu", "K. Yamada"], "venue": "In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Germann et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Germann et al\\.", "year": 2001}, {"title": "Fixing max-product: Convergent message passing algorithms for map lp-relaxations", "author": ["A. Globerson", "T. Jaakkola"], "venue": null, "citeRegEx": "Globerson and Jaakkola,? \\Q2007\\E", "shortCiteRegEx": "Globerson and Jaakkola", "year": 2007}, {"title": "Coordination structure analysis using dual decomposition", "author": ["A. Hanamoto", "T. Matsuzaki", "J. Tsujii"], "venue": "In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Hanamoto et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hanamoto et al\\.", "year": 2012}, {"title": "The traveling-salesman problem and minimum spanning trees: Part ii", "author": ["M. Held", "R.M. Karp"], "venue": "Mathematical Programming,", "citeRegEx": "Held and Karp,? \\Q1971\\E", "shortCiteRegEx": "Held and Karp", "year": 1971}, {"title": "Lagrangian relaxation for map estimation in graphical models", "author": ["J. Johnson", "D. Malioutov", "A. Willsky"], "venue": "In 45th Annual Allerton Conference on Communication, Control and Computing", "citeRegEx": "Johnson et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2007}, {"title": "Fast and smooth: Accelerated dual decomposition for MAP inference", "author": ["V. Jojic", "S. Gould", "D. Koller"], "venue": "In Proceedings of International Conference on Machine Learning (ICML)", "citeRegEx": "Jojic et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jojic et al\\.", "year": 2010}, {"title": "Fast exact inference with a factored model for natural language parsing", "author": ["D. Klein", "C. Manning"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Klein and Manning,? \\Q2002\\E", "shortCiteRegEx": "Klein and Manning", "year": 2002}, {"title": "Statistical phrase-based translation", "author": ["P. Koehn", "F.J. Och", "D. Marcu"], "venue": "In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistic s on Human Language Technology,", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Convergent tree-reweighted message passing for energy minimization", "author": ["V. Kolmogorov"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Kolmogorov,? \\Q2006\\E", "shortCiteRegEx": "Kolmogorov", "year": 2006}, {"title": "MRF Optimization via Dual Decomposition: Message-Passing Revisited", "author": ["N. Komodakis", "N. Paragios", "G. Tziritas"], "venue": "In Proc. ICCV", "citeRegEx": "Komodakis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Komodakis et al\\.", "year": 2007}, {"title": "Mrf energy minimization and beyond via dual decomposition", "author": ["N. Komodakis", "N. Paragios", "G. Tziritas"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Komodakis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Komodakis et al\\.", "year": 2011}, {"title": "Simple semi-supervised dependency parsing", "author": ["T. Koo", "X. Carreras", "M. Collins"], "venue": "In Proc. ACL/HLT", "citeRegEx": "Koo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2008}, {"title": "Dual decomposition for parsing with non-projective head", "author": ["T. Koo", "A.M. Rush", "M. Collins", "T. Jaakkola", "D. Sontag"], "venue": null, "citeRegEx": "Koo et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Koo et al\\.", "year": 2010}, {"title": "Combinatorial Optimization: Theory and Algorithms", "author": ["B. Korte", "J. Vygen"], "venue": null, "citeRegEx": "Korte and Vygen,? \\Q2008\\E", "shortCiteRegEx": "Korte and Vygen", "year": 2008}, {"title": "Word alignment via quadratic assignment", "author": ["S. Lacoste-Julien", "B. Taskar", "D. Klein", "M. Jordan"], "venue": "In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,", "citeRegEx": "Lacoste.Julien et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lacoste.Julien et al\\.", "year": 2006}, {"title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data", "author": ["J. Lafferty", "A. McCallum", "F. Pereira"], "venue": "In Proc. ICML,", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Lagrangian Relaxation", "author": ["C. Lemar\u00e9chal"], "venue": null, "citeRegEx": "Lemar\u00e9chal,? \\Q2001\\E", "shortCiteRegEx": "Lemar\u00e9chal", "year": 2001}, {"title": "Polyhedral characterization of discrete dynamic programming", "author": ["R. Martin", "R. Rardin", "B. Campbell"], "venue": "Operations research,", "citeRegEx": "Martin et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Martin et al\\.", "year": 1990}, {"title": "The Geometry of Constrained Structured Prediction: Applications to Inference and Learning of Natural Language Syntax", "author": ["A. Martins"], "venue": "Ph.D. thesis", "citeRegEx": "Martins,? \\Q2012\\E", "shortCiteRegEx": "Martins", "year": 2012}, {"title": "An augmented lagrangian approach to constrained map inference", "author": ["A. Martins", "M. Figueiredo", "P. Aguiar", "N. Smith", "E. Xing"], "venue": "In International Conference on Machine Learning", "citeRegEx": "Martins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2011}, {"title": "Concise Integer Linear Programming Formulations for Dependency Parsing", "author": ["A. Martins", "N. Smith", "E. Xing"], "venue": "In Proc. ACL,", "citeRegEx": "Martins et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2009}, {"title": "Dual decomposition with many overlapping components", "author": ["A. Martins", "N. Smith", "M. Figueiredo", "P. Aguiar"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Martins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2011}, {"title": "Discriminative Training and Spanning Tree Algorithms for Dependency Parsing", "author": ["R. McDonald"], "venue": "Ph.D. thesis,", "citeRegEx": "McDonald,? \\Q2006\\E", "shortCiteRegEx": "McDonald", "year": 2006}, {"title": "An alternating direction method for dual map lp relaxation", "author": ["O. Meshi", "A. Globerson"], "venue": "Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Meshi and Globerson,? \\Q2011\\E", "shortCiteRegEx": "Meshi and Globerson", "year": 2011}, {"title": "Approximate primal solutions and rate analysis for dual subgradient methods", "author": ["A. Nedi\u0107", "A. Ozdaglar"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nedi\u0107 and Ozdaglar,? \\Q2009\\E", "shortCiteRegEx": "Nedi\u0107 and Ozdaglar", "year": 2009}, {"title": "Smooth minimization of non-smooth functions", "author": ["Y. Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov,? \\Q2005\\E", "shortCiteRegEx": "Nesterov", "year": 2005}, {"title": "Implicitly intersecting weighted automata using dual decomposition", "author": ["M.J. Paul", "J. Eisner"], "venue": "In Proc. NAACL", "citeRegEx": "Paul and Eisner,? \\Q2012\\E", "shortCiteRegEx": "Paul and Eisner", "year": 2012}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference (2nd edition)", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Incremental integer linear programming for non-projective dependency parsing", "author": ["S. Riedel", "J. Clarke"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Riedel and Clarke,? \\Q2006\\E", "shortCiteRegEx": "Riedel and Clarke", "year": 2006}, {"title": "Fast and robust joint models for biomedical event extraction", "author": ["S. Riedel", "A. McCallum"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Riedel and McCallum,? \\Q2011\\E", "shortCiteRegEx": "Riedel and McCallum", "year": 2011}, {"title": "Integer linear programming inference for conditional random fields", "author": ["D. Roth", "W. Yih"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Roth and Yih,? \\Q2005\\E", "shortCiteRegEx": "Roth and Yih", "year": 2005}, {"title": "Improved parsing and pos tagging using inter-sentence consistency constraints", "author": ["A. Rush", "R. Reichart", "M. Collins", "A. Globerson"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Rush et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rush et al\\.", "year": 2012}, {"title": "Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation", "author": ["A. Rush", "M. Collins"], "venue": "In Proc. ACL", "citeRegEx": "Rush and Collins,? \\Q2011\\E", "shortCiteRegEx": "Rush and Collins", "year": 2011}, {"title": "On Dual Decomposition and Linear Programming Relaxations for Natural Language Processing", "author": ["A. Rush", "D. Sontag", "M. Collins", "T. Jaakkola"], "venue": "In Proc. EMNLP", "citeRegEx": "Rush et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rush et al\\.", "year": 2010}, {"title": "Minimization Methods for Non-differentiable Functions", "author": ["N.Z. Shor"], "venue": null, "citeRegEx": "Shor,? \\Q1985\\E", "shortCiteRegEx": "Shor", "year": 1985}, {"title": "Dependency parsing by belief propagation", "author": ["D. Smith", "J. Eisner"], "venue": "In Proc. EMNLP,", "citeRegEx": "Smith and Eisner,? \\Q2008\\E", "shortCiteRegEx": "Smith and Eisner", "year": 2008}, {"title": "Introduction to dual decomposition for inference", "author": ["D. Sontag", "A. Globerson", "T. Jaakkola"], "venue": null, "citeRegEx": "Sontag et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sontag et al\\.", "year": 2010}, {"title": "Tightening LP relaxations for MAP using message passing", "author": ["D. Sontag", "T. Meltzer", "A. Globerson", "T. Jaakkola", "Y. Weiss"], "venue": "In Proc. UAI", "citeRegEx": "Sontag et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sontag et al\\.", "year": 2008}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["K. Toutanova", "D. Klein", "C.D. Manning", "Y. Singer"], "venue": "In HLT-NAACL", "citeRegEx": "Toutanova et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2003}, {"title": "MAP estimation via agreement on trees: message-passing and linear programming", "author": ["M. Wainwright", "T. Jaakkola", "A. Willsky"], "venue": "In IEEE Transactions on Information Theory,", "citeRegEx": "Wainwright et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Wainwright et al\\.", "year": 2005}, {"title": "Linear Programming Relaxations and Belief Propagation\u2013An Empirical Study", "author": ["C. Yanover", "T. Meltzer", "Y. Weiss"], "venue": "In The Journal of Machine Learning Research,", "citeRegEx": "Yanover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Yanover et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 46, "context": "More recently, decoding algorithms have been derived for several models in statistical NLP, including models that combine a weighted context-free grammar (WCFG) with a finite-state tagger (Rush, Sontag, Collins, & Jaakkola, 2010); models that combine a lexicalized WCFG with a discriminative dependency parsing model (Rush et al., 2010); head-automata models for non-projective dependency parsing (Koo, Rush, Collins, Jaakkola, & Sontag, 2010); alignment models for statistical machine translation (DeNero & Macherey, 2011); models for event extraction (Riedel & McCallum, 2011); models for combined CCG parsing and supertagging (Auli & Lopez, 2011); phrase-based models for statistical machine translation (Chang & Collins, 2011); syntaxbased models for statistical machine translation (Rush & Collins, 2011); models for semantic parsing (Das, Martins, & Smith, 2012); models for parsing and tagging that make use of document-level constraints (Rush, Reichart, Collins, & Globerson, 2012); models for the coordination problem in natural language parsing (Hanamoto, Matsuzaki, & Tsujii, 2012); and models based on the intersection of weighted automata (Paul & Eisner, 2012).", "startOffset": 317, "endOffset": 336}, {"referenceID": 15, "context": "Lagrangian relaxation has a long history in the combinatorial optimization literature, going back to the seminal work of Held and Karp (1971), who derive a relaxation algorithm for the traveling salesman problem.", "startOffset": 121, "endOffset": 142}, {"referenceID": 14, "context": "1 Combinatorial Optimization Lagrangian relaxation (LR) is a widely used method in combinatorial optimization, going back to the seminal work of Held and Karp (1971) on the traveling salesman problem.", "startOffset": 145, "endOffset": 166}, {"referenceID": 14, "context": "1 Combinatorial Optimization Lagrangian relaxation (LR) is a widely used method in combinatorial optimization, going back to the seminal work of Held and Karp (1971) on the traveling salesman problem. See the work of Lemar\u00e9chal (2001) and Fisher (1981) for surveys of LR methods, and the textbook of Korte and Vygen (2008) for background on combinatorial optimization.", "startOffset": 145, "endOffset": 235}, {"referenceID": 11, "context": "See the work of Lemar\u00e9chal (2001) and Fisher (1981) for surveys of LR methods, and the textbook of Korte and Vygen (2008) for background on combinatorial optimization.", "startOffset": 38, "endOffset": 52}, {"referenceID": 11, "context": "See the work of Lemar\u00e9chal (2001) and Fisher (1981) for surveys of LR methods, and the textbook of Korte and Vygen (2008) for background on combinatorial optimization.", "startOffset": 38, "endOffset": 122}, {"referenceID": 40, "context": "For tree-structured MRFs, max-product belief propagation (max-product BP) (Pearl, 1988) gives exact solutions.", "startOffset": 74, "endOffset": 87}, {"referenceID": 40, "context": "For tree-structured MRFs, max-product belief propagation (max-product BP) (Pearl, 1988) gives exact solutions. (Max-product BP is a form of dynamic programming, which is closely related to the Viterbi algorithm.) For general MRFs where the underlying graph may contain cycles, the MAP problem is NP-hard: this has led researchers to consider a number of approximate inference algorithms. Early work considered loopy variants of max-product BP (see for example Felzenszwalb & Huttenlocher, 2006, for the application of loopy max-product BP to problems in computer vision); however, these methods are heuristic, lacking formal guarantees. More recent work has considered methods based on linear programming (LP) relaxations of the MAP problem. See the work of Yanover, Meltzer, and Weiss (2006), or section 1.", "startOffset": 75, "endOffset": 793}, {"referenceID": 40, "context": "For tree-structured MRFs, max-product belief propagation (max-product BP) (Pearl, 1988) gives exact solutions. (Max-product BP is a form of dynamic programming, which is closely related to the Viterbi algorithm.) For general MRFs where the underlying graph may contain cycles, the MAP problem is NP-hard: this has led researchers to consider a number of approximate inference algorithms. Early work considered loopy variants of max-product BP (see for example Felzenszwalb & Huttenlocher, 2006, for the application of loopy max-product BP to problems in computer vision); however, these methods are heuristic, lacking formal guarantees. More recent work has considered methods based on linear programming (LP) relaxations of the MAP problem. See the work of Yanover, Meltzer, and Weiss (2006), or section 1.6 of the work of Sontag, Globerson, and Jaakkola (2010), for a description.", "startOffset": 75, "endOffset": 863}, {"referenceID": 38, "context": "Roth and Yih (2005) formulate a constrained sequence labeling problem as an ILP and decode using a general-purpose solver.", "startOffset": 0, "endOffset": 20}, {"referenceID": 38, "context": "Roth and Yih (2005) formulate a constrained sequence labeling problem as an ILP and decode using a general-purpose solver. Lacoste-Julien, Taskar, Klein, and Jordan (2006) describe a quadratic assignment problem for bilingual word alignment and then decode using an ILP solver.", "startOffset": 0, "endOffset": 172}, {"referenceID": 37, "context": "Both the work of Riedel and Clarke (2006) and Martins, Smith, and Xing (2009) formulates higher-order non-projective dependency parsing as an ILP.", "startOffset": 17, "endOffset": 42}, {"referenceID": 31, "context": "Both the work of Riedel and Clarke (2006) and Martins, Smith, and Xing (2009) formulates higher-order non-projective dependency parsing as an ILP.", "startOffset": 46, "endOffset": 78}, {"referenceID": 44, "context": "See the work of Rush et al. (2010) for a detailed treatment of both of these examples.", "startOffset": 16, "endOffset": 35}, {"referenceID": 12, "context": "In addition, Lagrangian relaxation appears to be a more standard term in the combinatorial optimization literature: for example the textbook of Korte and Vygen (2008) has a description of Lagrangian relaxation but no mention of dual decomposition; there are several tutorials on Lagrangian relaxation in the combinatorial optimization literature (e.g., see Lemar\u00e9chal, 2001; Fisher, 1981), but we have found it more difficult to find direct treatments of dual decompositon.", "startOffset": 346, "endOffset": 388}, {"referenceID": 15, "context": "However, in our view dual decomposition is more naturally viewed as a special case of Lagrangian relaxation, in particular because the methods described in this tutorial go back to the work of Held and Karp (1971) (see section 6.", "startOffset": 193, "endOffset": 214}, {"referenceID": 15, "context": "However, in our view dual decomposition is more naturally viewed as a special case of Lagrangian relaxation, in particular because the methods described in this tutorial go back to the work of Held and Karp (1971) (see section 6.3), which makes use of a single combinatorial algorithm. In addition, Lagrangian relaxation appears to be a more standard term in the combinatorial optimization literature: for example the textbook of Korte and Vygen (2008) has a description of Lagrangian relaxation but no mention of dual decomposition; there are several tutorials on Lagrangian relaxation in the combinatorial optimization literature (e.", "startOffset": 193, "endOffset": 453}, {"referenceID": 22, "context": "The generalization to more than two components is relatively straightforward; for example see the work of Komodakis et al. (2007, 2011), see also the work of Martins, Smith, Figueiredo, and Aguiar (2011).", "startOffset": 106, "endOffset": 204}, {"referenceID": 1, "context": "8 is to construct a new context-free grammar that introduces sensitivity to surface bigrams (Bar-Hillel et al., 1964).", "startOffset": 92, "endOffset": 117}, {"referenceID": 1, "context": "8 is to construct a new context-free grammar that introduces sensitivity to surface bigrams (Bar-Hillel et al., 1964). Roughly speaking, in this approach (assuming a first-order tagging model) rules such as VP\u2192 V NP are replaced with rules such as VPN,N \u2192 VN,V NPV,N (10) where each non-terminal (e.g., NP) is replaced with a non-terminal that tracks the preceding and last POS tag relative to that non-terminal. For example, NPV,N represents a NP that dominates a sub-tree whose preceding POS tag was V, and whose last POS tag is N. The weights on the new rules are just context-free weights from f(y). Furthermore, rules such as V\u2192 flies are replaced with rules such as VN,V \u2192 flies The weights on these rules are the context-free weights from f(y) plus the bigram tag weights from g(z), in this example for the bigram N V. A dynamic programming parsing algorithm\u2014for example the CKY algorithm\u2014can then be used to find the highest scoring structure under the new grammar. This approach is guaranteed to give an exact solution to the problem in Eq. 8; however it is often very inefficient. We have greatly increased the size of the grammar by introducing the refined non-terminals, and this leads to significantly slower parsing performance. As one example, consider the case where the underlying grammar is a CFG in Chomsky-normal form, with G non-terminals, and where we use a 2nd order (trigram) tagging model, with T possible part-of-speech tags. Define n to be the length of the input sentence. Parsing with the grammar alone would take O(G3n3) time, for example using the CKY algorithm. In contrast, the construction of Bar-Hillel et al. (1964) 6.", "startOffset": 93, "endOffset": 1652}, {"referenceID": 1, "context": "If the number of iterations k is relatively small, the algorithm can be much more efficient than using the construction of Bar-Hillel et al. (1964). As discussed before, assuming a context-free grammar in Chomsky normal form, and a trigram tagger with T tags, the CKY parsing algorithm takes O(G3n3) time, and the Viterbi algorithm for tagging takes O(T 3n) time.", "startOffset": 123, "endOffset": 148}, {"referenceID": 44, "context": "Each parse tree y \u2208 Rd is represented as a vector such that f(y) = y \u00b7\u03b8(1) for some \u03b8(1) \u2208 Rd: there are a number of ways of representing parse trees as vectors, see the work of Rush et al. (2010) for one example.", "startOffset": 178, "endOffset": 197}, {"referenceID": 44, "context": "Figure 3: Convergence results from the work of Rush et al. (2010) for integration of a probabilistic parser and a POS tagger, using dual decomposition.", "startOffset": 47, "endOffset": 66}, {"referenceID": 5, "context": "(2010) describe experiments using this algorithm to integrate the probabilistic parser of Collins (1997) with the POS tagger of Toutanova, Klein, Manning, and Singer (2003).", "startOffset": 90, "endOffset": 105}, {"referenceID": 5, "context": "(2010) describe experiments using this algorithm to integrate the probabilistic parser of Collins (1997) with the POS tagger of Toutanova, Klein, Manning, and Singer (2003). (In these experiments the stepsize \u03b4k is not held constant, but is instead set using the strategy described in section 7.", "startOffset": 90, "endOffset": 173}, {"referenceID": 47, "context": "Proof: See the work of Shor (1985). See also Appendix A.", "startOffset": 23, "endOffset": 35}, {"referenceID": 39, "context": "Our first example, also from the work of Rush et al. (2010), is a dual decomposition algorithm that combines two parsing models.", "startOffset": 41, "endOffset": 60}, {"referenceID": 14, "context": "Finally, we describe the algorithm of Held and Karp (1971) for the traveling salesman problem, and the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models.", "startOffset": 38, "endOffset": 59}, {"referenceID": 4, "context": "Finally, we describe the algorithm of Held and Karp (1971) for the traveling salesman problem, and the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models.", "startOffset": 116, "endOffset": 141}, {"referenceID": 43, "context": "1 Combined Constituency and Dependency Parsing Rush et al. (2010) describe an algorithm for finding the highest scoring lexicalized context-free parse tree for an input sentence, under a combination of two models: a lexicalized probabilistic context-free grammar, and a discriminative dependency parsing model.", "startOffset": 47, "endOffset": 66}, {"referenceID": 5, "context": "We take Y to be the set of all lexicalized trees for the input sentence, and f(y) to be the score of the tree y under a lexicalized parsing model\u2014specifically, f(y) is the log-probability of y under the model of Collins (1997). Under this model, each lexicalized rule in y receives a score that is a log probability, and the log probability of y is a sum of the log probabilities for the rules that it contains.", "startOffset": 212, "endOffset": 227}, {"referenceID": 44, "context": "Figure 5: Convergence results from the work of Rush et al. (2010) for integration of a lexicalized probabilistic context-free grammar, and a discriminative dependency parsing model.", "startOffset": 47, "endOffset": 66}, {"referenceID": 5, "context": "We use the discriminative dependency parsing model of Koo, Carreras, and Collins (2008) (see also McDonald, 2006).", "startOffset": 73, "endOffset": 88}, {"referenceID": 4, "context": "The motivation for this problem is that it will allow us to inject information from the dependency parsing model g(z) into the lexicalized parsing model of Collins (1997); Rush et al.", "startOffset": 156, "endOffset": 171}, {"referenceID": 4, "context": "The motivation for this problem is that it will allow us to inject information from the dependency parsing model g(z) into the lexicalized parsing model of Collins (1997); Rush et al. (2010) show that this gives significant improvements in parsing accuracy.", "startOffset": 156, "endOffset": 191}, {"referenceID": 1, "context": "The problem can be again solved exactly using a dynamic programming approach, where a dynamic program is created that is an intersection of the two models (there is a clear analogy to the Bar-Hillel et al. (1964) method for construction of a dynamic program for the intersection of a PCFG and an HMM).", "startOffset": 188, "endOffset": 213}, {"referenceID": 40, "context": "Rush et al. (2010) describe experiments with this algorithm.", "startOffset": 0, "endOffset": 19}, {"referenceID": 5, "context": "The method gives significant gains in parsing accuracy over the model of Collins (1997), and significant gains over a baseline method that simply forces the lexicalized CFG parser to have the same dependency structure as the first-best output from the dependency parser.", "startOffset": 73, "endOffset": 88}, {"referenceID": 5, "context": "The method gives significant gains in parsing accuracy over the model of Collins (1997), and significant gains over a baseline method that simply forces the lexicalized CFG parser to have the same dependency structure as the first-best output from the dependency parser.10 6.2 The MAP Problem for Pairwise Markov Random Fields Markov random fields (MRFs), and more generally graphical models, are widely used in machine learning and statistics. The MAP problem in MRFs\u2014 the problem of finding the most likely setting of the random variables in an MRF\u2014is an inference problem of central importance. In this section we describe the dual decomposition algorithm from the work of Komodakis et al. (2007, 2011) for finding the MAP solution in pairwise, binary, MRFs. Pairwise MRFs are limited to the case where potential functions consider pairs of random variables, as opposed to larger subsets; however, the generalization of the method to non-pairwise MRFs is straightforward. A commonly used approach for the MAP problem in MRFs is to use loopy max-product belief propagation. The dual decomposition algorithm has advantages in terms of stronger formal guarantees, as described in section 5. 10. Note that Klein and Manning (2002) describe a method for combination of a dependency parser with a constituent based parser, where the score for an entire structure is again the sum of scores under two models.", "startOffset": 73, "endOffset": 1230}, {"referenceID": 16, "context": "Figure 6: An illustration of the approach of Held and Karp (1971). On the left is a tour of the vertices 1 .", "startOffset": 45, "endOffset": 66}, {"referenceID": 14, "context": "3 The Held and Karp Algorithm for TSPs Our next example is the approach of Held and Karp (1971) for traveling salesman problems (TSPs), which is notable for being the original paper on Lagrangian relaxation.", "startOffset": 6, "endOffset": 96}, {"referenceID": 4, "context": "For NLP decoding algorithms that leverage a single combinatorial algorithm, see the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models (we describe this algorithm in the next section), and the algorithm of Rush and Collins (2011) for decoding of syntax-based translation models.", "startOffset": 97, "endOffset": 122}, {"referenceID": 4, "context": "For NLP decoding algorithms that leverage a single combinatorial algorithm, see the algorithm of Chang and Collins (2011) for decoding of phrase-based translation models (we describe this algorithm in the next section), and the algorithm of Rush and Collins (2011) for decoding of syntax-based translation models.", "startOffset": 97, "endOffset": 265}, {"referenceID": 16, "context": "12 A key idea in the work of Held and Karp (1971) is that of a 1-tree, which, like a tour, is a subset of E.", "startOffset": 29, "endOffset": 50}, {"referenceID": 4, "context": "4 Phrase-Based Translation We next consider a Lagrangian relaxation algorithm, described in the work of Chang and Collins (2011), for decoding of phrase-based translation models (Koehn, Och, & Marcu, 2003).", "startOffset": 104, "endOffset": 129}, {"referenceID": 4, "context": "The description we have given here is a sketch: Chang and Collins (2011) describe details of the method, including a slightly more involved dynamic program that gives a tighter relaxation than the method we have described here, and a tightening method that incrementally adds constraints when the method does not initially e-converge.", "startOffset": 48, "endOffset": 73}, {"referenceID": 5, "context": "Figure 7: Graph showing the dual value L(u(k)) and primal value f(y(k)) + g(l(y(k))), versus iteration number k, for the subgradient algorithm on a translation example from the work of Rush and Collins (2011).", "startOffset": 194, "endOffset": 209}, {"referenceID": 5, "context": "1 An Example Run of the Algorithm Figure 7 shows a run of the subgradient algorithm for the decoding approach for machine translation described in the work of Rush and Collins (2011). The behavior is typical of cases where the algorithm e-converges to an exact solution.", "startOffset": 168, "endOffset": 183}, {"referenceID": 5, "context": "Figure 8: The graph on the left shows the best dual value Lk and the best primal value p \u2217 k, versus iteration number k, for the subgradient algorithm on a translation example from the work of Rush and Collins (2011). The graph on the right shows Lk \u2212 pk plotted against k.", "startOffset": 202, "endOffset": 217}, {"referenceID": 5, "context": "Figure 10: Graph showing the dual value L(u(k)) and primal value f(y(k)) + g(l(y(k))), versus iteration number k, for the subgradient algorithm on a translation example from the work of Rush and Collins (2011), where the method does not e-converge to an exact solution.", "startOffset": 195, "endOffset": 210}, {"referenceID": 24, "context": "Figure 11: Figures showing effects of early stopping for the non-projective parsing algorithm of Koo et al. (2010) (left graph) and combined constituency and dependency parsing (right graph).", "startOffset": 97, "endOffset": 115}, {"referenceID": 25, "context": "Figure 11 shows graphs for two problems: non-projective dependency parsing (Koo et al., 2010), and combined constituency and dependency", "startOffset": 75, "endOffset": 93}, {"referenceID": 46, "context": "parsing (Rush et al., 2010).", "startOffset": 8, "endOffset": 27}, {"referenceID": 21, "context": "Following the work of Kolmogorov (2006), we use TRW-E to refer to the edge-based variant of TRW, and TRW-T to refer to the tree-based algorithm.", "startOffset": 22, "endOffset": 40}, {"referenceID": 21, "context": "Following the work of Kolmogorov (2006), we use TRW-E to refer to the edge-based variant of TRW, and TRW-T to refer to the tree-based algorithm. Kolmogorov (2006) derives a further variant, TRW-S (the \u201cS\u201d refers to the sequential nature of the algorithm).", "startOffset": 22, "endOffset": 163}, {"referenceID": 21, "context": "Following the work of Kolmogorov (2006), we use TRW-E to refer to the edge-based variant of TRW, and TRW-T to refer to the tree-based algorithm. Kolmogorov (2006) derives a further variant, TRW-S (the \u201cS\u201d refers to the sequential nature of the algorithm). All three algorithms\u2014TRW-E, TRW-T, and TRW-S\u2014are motivated by the LP relaxation for MRFs, but none of them have a guarantee of converging to the optimal value of the LP. TRW-S has the strongest guarantee of the three algorithms, namely that it monotonically improves the dual value, but it may not converge to the optimal dual value. Yanover et al. (2006) describe experiments comparing TRW-based algorithms to generic LP solvers for MRF problems (specifically, the LP solver they use is CPLEX13).", "startOffset": 22, "endOffset": 612}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al.", "startOffset": 147, "endOffset": 177}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods.", "startOffset": 147, "endOffset": 215}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition.", "startOffset": 147, "endOffset": 1256}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition.", "startOffset": 147, "endOffset": 1342}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al.", "startOffset": 147, "endOffset": 1562}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm.", "startOffset": 147, "endOffset": 1685}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM).", "startOffset": 147, "endOffset": 2021}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM.", "startOffset": 147, "endOffset": 2205}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the objective with a quadratic penalty term representing the amount of constraint violation. ADMM is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP.", "startOffset": 147, "endOffset": 2605}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the objective with a quadratic penalty term representing the amount of constraint violation. ADMM is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP. A challenge of ADMM is that the extra quadratic term may complicate sub-problem decoding, for example it is not clear how to directly decode the parsing problems presented in this work with a quadratic term in the objective. Several alternative approaches have been proposed: Martins et al. (2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al.", "startOffset": 147, "endOffset": 3062}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the objective with a quadratic penalty term representing the amount of constraint violation. ADMM is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP. A challenge of ADMM is that the extra quadratic term may complicate sub-problem decoding, for example it is not clear how to directly decode the parsing problems presented in this work with a quadratic term in the objective. Several alternative approaches have been proposed: Martins et al. (2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al.", "startOffset": 147, "endOffset": 3163}, {"referenceID": 13, "context": "Another important class of algorithms for optimizing the dual of the LP are block coordinate descent algorithms: for example the MPLP algorithm of Globerson and Jaakkola (2007). See the work of Sontag et al. (2010) for a discussion of these methods. Like TRW-S, the MPLP algorithm is guaranteed to monotonically improve the dual value, but is not guaranteed to converge to the global optimum of the MRF LP. In several experimental settings, the MPLP algorithm produces better dual values in early iterations than subgradient methods, but can get stuck at a non-optimal solution (Jojic, Gould, & Koller, 2010; Martins, Figueiredo, Aguiar, Smith, & Xing, 2011; Meshi & Globerson, 2011). Another complication of MPLP is that it requires computing max-marginals for the sub-problems at each iteration instead of MAP assignments. Max-marginals may be slower to compute in practice, and for some combinatorial problems computation may be asymptotically slower. (For example, for the directed spanning tree models from Koo et al., 2010, the MAP problem can be solved in O(n2) time where n is the length of the input sentence, but we are not aware of an algorithm that solves the max-marginal problem in better than O(n4) time.) In other work, Jojic et al. (2010) describe an accelerated method for MRF inference, using the method of Nesterov (2005) to smooth the objective in the underlying decomposition. The method has a relatively fast rate of convergence (O(1/ ) time to reach a solution that is -close to optimal). Experiments from the work of Jojic et al. (2010) show a decrease in the number of iterations required compared to subgradient; however in the work of Martins et al. (2011) the accelerated method requires more iterations than the subgradient algorithm. In both sets of experiments, MPLP makes more initial progress than either method. Accelerated subgradient also requires computing subproblem marginals, which has similar disadvantages as MPLP\u2019s requirement of max-marginals. Recently, Martins et al. (2011) proposed an augmented Lagrangian method for inference using the alternating direction method of multipliers (ADMM). See the tutorial of Boyd, Parikh, Chu, Peleato, and Eckstein (2011) on ADMM. The augmented Lagrangian method further extends the objective with a quadratic penalty term representing the amount of constraint violation. ADMM is a method for optimizing this augmented problem that is able to maintain similar decomposibility properties as dual decomposition. Like the subgradient method, ADMM is guaranteed to find the optimum of the LP relaxation. Martins et al. (2011) show empirically that ADMM requires a comparable number of iterations to MPLP to find a good primal solution, while still being guaranteed to optimize the LP. A challenge of ADMM is that the extra quadratic term may complicate sub-problem decoding, for example it is not clear how to directly decode the parsing problems presented in this work with a quadratic term in the objective. Several alternative approaches have been proposed: Martins et al. (2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al.", "startOffset": 147, "endOffset": 3244}, {"referenceID": 7, "context": "(2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al. (2012) use an iterative active set method that utilizes MAP solutions of the original sub-problems to solve the quadratic version.", "startOffset": 193, "endOffset": 211}, {"referenceID": 7, "context": "(2011) binarize the combinatorial sub-problems into binary-valued factor graphs; Meshi and Globerson (2011) avoid the problem by instead applying ADMM to the dual of the LP; Martins (2012) and Das et al. (2012) use an iterative active set method that utilizes MAP solutions of the original sub-problems to solve the quadratic version. Martins (2012) also describes recent results on ADMM that give a O(1/ ) bound for relaxed primal convergence.", "startOffset": 193, "endOffset": 350}, {"referenceID": 26, "context": "This follows immediately by results from linear programming duality see the textbook of Korte and Vygen (2008) for more details.", "startOffset": 88, "endOffset": 111}, {"referenceID": 1, "context": "Thus we end up with an algorithm that is at least as expensive as integration of a bigram HMM with a PCFG using the construction of Bar-Hillel et al. (1964).14 A second approach, which may be more efficient, is as follows.", "startOffset": 132, "endOffset": 157}, {"referenceID": 1, "context": "If g(z) is defined through a bigram HMM, then clearly nothing has been gained in efficiency over the Bar-Hillel et al. (1964) method.", "startOffset": 101, "endOffset": 126}, {"referenceID": 1, "context": "In that case, we might add bigram constraints at only a few positions in the sentence: in practice the CKY decoding algorithm will only need to introduce the Bar-Hillel et al. (1964) machinery at these selected points, which can be much more efficient that introducing all constraints.", "startOffset": 158, "endOffset": 183}, {"referenceID": 4, "context": "For examples of methods that tighten dual decomposition/Lagrangian relaxation techniques using additional constraints, see the work of Sontag, Meltzer, Globerson, Jaakkola, and Weiss (2008), Rush and Collins (2011), Chang and Collins (2011), and Das et al.", "startOffset": 200, "endOffset": 215}, {"referenceID": 4, "context": "For examples of methods that tighten dual decomposition/Lagrangian relaxation techniques using additional constraints, see the work of Sontag, Meltzer, Globerson, Jaakkola, and Weiss (2008), Rush and Collins (2011), Chang and Collins (2011), and Das et al.", "startOffset": 216, "endOffset": 241}, {"referenceID": 4, "context": "For examples of methods that tighten dual decomposition/Lagrangian relaxation techniques using additional constraints, see the work of Sontag, Meltzer, Globerson, Jaakkola, and Weiss (2008), Rush and Collins (2011), Chang and Collins (2011), and Das et al. (2012). This is related to previous work on non-projective dependency parsing (Riedel & Clarke, 2006) that incrementally adds constraints to an integer linear program solver.", "startOffset": 216, "endOffset": 264}, {"referenceID": 30, "context": "Martins et al. (2009) make use of a construction for directed spanning trees (see also Magnanti & Wolsey, 1994), and apply it to nonprojective dependency parsing.", "startOffset": 0, "endOffset": 22}, {"referenceID": 26, "context": "Korte and Vygen (2008) describe many other such constructions.", "startOffset": 0, "endOffset": 23}, {"referenceID": 44, "context": "n, t \u2208 T , y(i, t) = z(i, t) Rush et al. (2010) give a full description of the compact LP for this problem: we give a sketch here.", "startOffset": 29, "endOffset": 48}, {"referenceID": 44, "context": "n, t \u2208 T , y(i, t) = z(i, t) Rush et al. (2010) give a full description of the compact LP for this problem: we give a sketch here. 15. There is one subtlety here: in some cases additional auxilliary variables may need to be introduced. See for example the spanning tree construction of Magnanti and Wolsey (1994). However the number of auxilliary variables is generally polynomial in number, hence this is benign.", "startOffset": 29, "endOffset": 313}, {"referenceID": 44, "context": "Rush et al. (2010) describe this construction in detail for the case where a weighted CFG is combined with a finite-state tagger.", "startOffset": 0, "endOffset": 19}], "year": 2012, "abstractText": "Dual decomposition, and more generally Lagrangian relaxation, is a classical method for combinatorial optimization; it has recently been applied to several inference problems in natural language processing (NLP). This tutorial gives an overview of the technique. We describe example algorithms, describe formal guarantees for the method, and describe practical issues in implementing the algorithms. While our examples are predominantly drawn from the NLP literature, the material should be of general relevance to inference problems in machine learning. A central theme of this tutorial is that Lagrangian relaxation is naturally applied in conjunction with a broad class of combinatorial algorithms, allowing inference in models that go significantly beyond previous work on Lagrangian relaxation for inference in graphical models.", "creator": "TeX"}}}