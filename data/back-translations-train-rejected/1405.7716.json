{"id": "1405.7716", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2014", "title": "Experimental Demonstration of Array-level Learning with Phase Change Synaptic Devices", "abstract": "The computational performance of the biological brain has long attracted significant interest and has led to inspirations in operating principles, algorithms, and architectures for computing and signal processing. In this work, we focus on hardware implementation of brain-like learning in a brain-inspired architecture. We demonstrate, in hardware, that 2-D crossbar arrays of phase change synaptic devices can achieve associative learning and perform pattern recognition. Device and array-level studies using an experimental 10x10 array of phase change synaptic devices have shown that pattern recognition is robust against synaptic resistance variations and large variations can be tolerated by increasing the number of training iterations. Our measurements show that increase in initial variation from 9 % to 60 % causes required training iterations to increase from 1 to 11.", "histories": [["v1", "Thu, 29 May 2014 20:22:00 GMT  (1389kb)", "http://arxiv.org/abs/1405.7716v1", "IEDM 2013"], ["v2", "Tue, 3 Jun 2014 05:45:54 GMT  (4626kb)", "http://arxiv.org/abs/1405.7716v2", "IEDM 2013"]], "COMMENTS": "IEDM 2013", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["s burc eryilmaz", "duygu kuzum", "rakesh g d jeyasingh", "sangbum kim", "matthew brightsky", "chung lam", "h -s philip wong"], "accepted": false, "id": "1405.7716"}, "pdf": {"name": "1405.7716.pdf", "metadata": {"source": "CRF", "title": "Experimental Demonstration of Array-level Learning with Phase Change Synaptic Devices", "authors": ["S. Burc Eryilmaz", "Duygu Kuzum", "Rakesh G. D. Jeyasingh", "SangBum Kim", "Matthew BrightSky", "Chung Lam", "Philip Wong"], "emails": ["eryilmaz@stanford.edu,"], "sections": [{"heading": null, "text": "I. The introduction of synaptic electronics is an emerging field of research aimed at developing electronic systems that mimic the computational energy efficiency and fault tolerance of the biological brain in a compact space [1]. Until now, synaptic electronics research has primarily focused on implementing synaptic plasticity at the component level and simulations at the array or chip level [2-4]. Recent studies on brain imaging suggest that neural connections in the form of folding 2D sheets of parallel neural fibers intersecting at right angles [6] are present. The brain's reticular connectivity is best emulated with two terminal synaptic devices using a 2D or layered 3D cross bar architecture (Figure 1)."}, {"heading": "II. Synaptic Array", "text": "In the experiments, 10 x 10 PCM cell arrays with selection transistors were used (Fig. 2) [7,8]. Ten bit lines (BL) and ten word lines (WL) are connected to the uppermost electrode of the device or the gate of the selection transistors. Microscope image of the array and TEM image of a single device [7,8] are shown in Fig. 3 (left) and (right) respectively. Typical DC switching and pulse switching characteristics of a single device, which are randomly selected from one of the arrays, are shown in Fig. 4 and 5 respectively. Setting and resetting pulses with amplitudes of 1 V and 1.5 V and with (50 ns / 300 ns / 1 \u00b5s) and (20 ns / 50 ns / 5 ns) increase / width of Wig cells is achieved by uniform pulse distribution (with simultaneous use of PCM cells)."}, {"heading": "III. Array-level Learning", "text": "The cross bar array consists of 100 synaptic devices and 10 relapsed connected neurons (Fig. 2). Integrated and fiery neurons are implemented by computer control and PCM cells are used as synaptic devices between neurons. The input terminal of each neuron is connected to a BL node, while the output terminal of each neuron is connected to a WL node (Fig. 8). In the learning phase, synaptic weights are updated via a simple form of lever plasticity. Synapses between coactive neurons firing in the same 100 \u03bcs time frame become stronger. Otherwise, the synaptic weight does not change. If a neuron does not fire, it integrates the current from all inputs triggered by the spy neurons on this iteration."}, {"heading": "IV. Resistance Variation", "text": "To investigate the effects of resistance variation on pattern recognition performance, two arrays of high (60%) and low (9%) resistance are used. Figure 11 shows the initial resistance distribution for Array I (high variation) and Array II (low variation). High variation is achieved by first applying the same RESET pulse to each cell to bring it into partial RESET state, and low variation is achieved by selecting the pulse amplitudes for each cell individually and bringing it into full RESET state. Neurons from both synaptic arrays are stimulated with patterns 1 and 2 during learning periods. Figure 11 shows darker cells showing synapses that become stronger after 11 training periods."}, {"heading": "V. Conclusion", "text": "In hardware experiments, we have demonstrated that synaptic networks can implement robust pattern recognition through brain-like learning, and test patterns have been shown to be stored and associatively retrieved via Hebbic plasticity similar to the biological brain. Initial resistance fluctuations can be tolerated by adding more training periods and consuming more energy. Demonstrating robust brain-inspired learning in a small synaptic array is an important step toward building large-scale computing systems with computing efficiency at the brain level, and our work, inspired by network-like brain networking, could lead to more biologically plausible brain prosthetics in the future."}, {"heading": "Acknowledgments", "text": "This work is supported in part by SONIC, one of six STARnet centers, a program of the Semiconductor Research Corporation sponsored by MARCO and DARPA, the Nanoelectronics Research Initiative (NRI) of the Semiconductor Research Corporation (SRC) through the NSF / NRI Supplement to the NSF NSEC Center for Probing the Nanoscale (CPN), and members of the Stanford Non-Volatile Memory Technology Research Initiative (NMTRI)."}], "references": [{"title": "Nanotechnology", "author": ["D. Kuzum", "S. Yu", "H.-S. Philip Wong"], "venue": "24, 382001 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Nano Letters", "author": ["D. Kuzum", "R.G.D. Jeyasingh", "B Lee", "H.S.P. Wong"], "venue": "pp. 2179-2186 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Pattern recall. Red squares represent spiking neurons for every epoch. Both arrays with low and high initial resistance distribution were able to recall pattern 1 successfully (note the recall of neuron #6). Array II recalls the original pattern after 1 epochs while Array I needs 11 epochs to recall the original pattern", "author": ["F. G"], "venue": "Close et al., IEDM,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "space [1].", "startOffset": 6, "endOffset": 9}, {"referenceID": 1, "context": "To date, synaptic electronics research has primarily focused on device level implementations of synaptic plasticity and array or chip level simulations [2-4].", "startOffset": 152, "endOffset": 157}, {"referenceID": 1, "context": "Nanoscale devices based on phase change memory, PCM (Ge2Sb2Te5), have been shown to mimic biological synapses [2-4].", "startOffset": 110, "endOffset": 115}, {"referenceID": 2, "context": "Array pad microscope image (left) and single memory cell schematic and TEM image (right) [7,8].", "startOffset": 89, "endOffset": 94}, {"referenceID": 2, "context": "2) [7,8].", "startOffset": 3, "endOffset": 8}, {"referenceID": 2, "context": "Microscope image of the array and TEM image of a single device [7,8] are shown in Figure 3(left) and (right), respectively.", "startOffset": 63, "endOffset": 68}, {"referenceID": 1, "context": "By adjusting pulse amplitudes and widths, it is possible to implement more gradual switching using PCM cells [2,3].", "startOffset": 109, "endOffset": 114}], "year": 2013, "abstractText": "The computational performance of the biological brain has long attracted significant interest and has led to inspirations in operating principles, algorithms, and architectures for computing and signal processing. In this work, we focus on hardware implementation of brain-like learning in a braininspired architecture. We demonstrate, in hardware, that 2-D crossbar arrays of phase change synaptic devices can achieve associative learning and perform pattern recognition. Device and array-level studies using an experimental 10\u00d710 array of phase change synaptic devices have shown that pattern recognition is robust against synaptic resistance variations and large variations can be tolerated by increasing the number of training iterations. Our measurements show that increase in initial variation from 9 % to 60 % causes required training iterations to increase from 1 to 11.", "creator": "InControl Productions, Inc."}}}