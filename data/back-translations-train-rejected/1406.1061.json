{"id": "1406.1061", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jun-2014", "title": "A Methodology for Empirical Analysis of LOD Datasets", "abstract": "CoCoE stands for Complexity, Coherence and Entropy, and presents an extensible methodology for empirical analysis of Linked Open Data (i.e., RDF graphs). CoCoE can offer answers to questions like: Is dataset A better than B for knowledge discovery since it is more complex and informative?, Is dataset X better than Y for simple value lookups due its flatter structure?, etc. In order to address such questions, we introduce a set of well-founded measures based on complementary notions from distributional semantics, network analysis and information theory. These measures are part of a specific implementation of the CoCoE methodology that is available for download. Last but not least, we illustrate CoCoE by its application to selected biomedical RDF datasets.", "histories": [["v1", "Wed, 4 Jun 2014 14:45:43 GMT  (296kb,D)", "http://arxiv.org/abs/1406.1061v1", "A current working draft of the paper submitted to the ISWC'14 conference (track information available here:this http URL)"]], "COMMENTS": "A current working draft of the paper submitted to the ISWC'14 conference (track information available here:this http URL)", "reviews": [], "SUBJECTS": "cs.AI cs.SI", "authors": ["vit novacek"], "accepted": false, "id": "1406.1061"}, "pdf": {"name": "1406.1061.pdf", "metadata": {"source": "CRF", "title": "CoCoE: A Methodology for Empirical Analysis of LOD Datasets", "authors": ["V\u0131\u0301t Nov\u00e1\u010dek"], "emails": ["vit.novacek@deri.org"], "sections": [{"heading": "1 Introduction", "text": "As the LOD cloud grows, people are increasingly faced with the problem of choosing the right data sets that cannot be used entirely for their purposes. Data publishers typically provide descriptions that may indicate a possible use of their data sets, but such alleged descriptions can often be too flat, subjective or vague. Our main goal is to provide resources for comparing RDF data sets along several well-founded criteria, thus identifying the most appropriate data sets that can be used in specific use cases. To motivate and illustrate our contribution from a practical perspective, we envision a novel method of discovering drug side effects. Rob knows that the most successful methods typically define and train a model to detect unknown drug side effects."}, {"heading": "2 Related Work", "text": "The distribution representation of RDF data we use builds on our previous work [3]. We have recently introduced the notion of heuristic quasi-random migration and its empirical analysis in [5], which, however, deals with different types of data, manually curated taxonomies, and pre-defined gold standards. The paper extends this work into a generally applicable methodology for analyzing RDF data sets, using only the data itself. The clustering method presented here is based on principles similar to K-hop clustering [6]. Another related approach is non-parametric hierarchical link clustering [7], which uses more general and complex datasets than our simple methodology, but its Python implementation we have experimentally tested to be irrevocable in our use in our experiments. A comprehensive overview of semantic similarity similarities, the CoDF, the CodDF and the CodE were used in our experiments, the CodDF were used in the CodE, the CodE were used in our experiments."}, {"heading": "3 Methods", "text": "In this section, we first present various EDF data representations that underlie the CoCoE methodology, then describe the cluster method for calculating taxonomies required for certain CoCoE measurements, then describe the concept of heuristic quasi-random migration, followed by details on the CoCoE measurements, and finally explain how the measurements are to be interpreted."}, {"heading": "3.1 Representations of RDF Datasets", "text": "We assume that an RDF dataset consisting of tripels (s, p, o) referring to a set of URIs and letters (s, o), there are a set of nodes (s, o) in the datasets and objects that we do not distinguish between URI and literal objects in the current implementation of CoCoE, as we are interested in the most generically schema-independent features of the datasets."}, {"heading": "3.2 Nonparametric Hierarchical Clustering", "text": "In order to calculate many of the CoCoE metrics, we have to deal with the RDF data. (In some areas, however, it is necessary to develop a hierarchical cluster structure (i.e., taxonomy) based on the graph representations of the individual areas. (i.e., taxonomy) We calculate two taxonomies based on the Gw, Gs representations, or Gs representations, which are directly based on the data, while Ts representations represent the taxonomy by the entity similarities.The most specific (i.e., level)"}, {"heading": "3.3 Heuristic Quasi-Random Walks", "text": "The hsci-eaJnllhsrdcnlhsrteeaeaD nvo rf\u00fc ide eeirmnmnlrteeaeVnln nvo nvo nlrllteeoiKn, a \"nn so i.rsE eDr\" iW \"nvo rf\u00fc ide eeirmnmnnllrteeaeVnn nvo ende eeirmnso nvo eeirdne eeirmnnlrnne errrrlrrrrrrrlnne eeirlnne nlrlrlrllnne nlrlrlllllrrnu, n\" nvo os os os eeeeeeeeeeeos-rrrrno, \"irn rrrrrno\" iugnnlrnlrmngnei mnei, \"eos eeeeeeeeew-rrrrn rrrrno,\" irrn \"irn\" irn \"irrrrno\" irno \"irn\" irn \"irnlrnlrno\" irn \"irn\" irn \"irnr\" irnlrnlrnlrno \"irno\" irno \"irnrno\" irno \"irno\" irnlrno \"irno\" irno \"eos\" eeeeos eeeeeew eeeeeeeew-rnrnrn \"mnrn\" irn mno \"irnrn\" irn \"irno\" irno \"irno\" irno \"irno\" irn irn irn \"irn\" irn \"irn\" irn \"irn\" irno \"irn\" irno \"ir"}, {"heading": "3.4 CoCoE Measures", "text": "The first type of measures is based on the complexity of graph representations. We distinguish between local and global complexities. The global measures are associated with the graphs as a whole, and we calculate specific graph sizes, average shortest paths, and node distributions along the paths. The local measures associated with graph sizes are: (A) hull sizes in the nodes; (C) average component sizes in the nodes; (D) average cluster sizes of graph sizes in the node sizes w.r.t. The coherences of graph sizes in the biconnected components; (C) average component sizes in the nodes; (D) average cluster sizes of graph sizes in the node sizes."}, {"heading": "3.5 Interpreting the Measures", "text": "In general, high complexity means a lot of potentially useful structural information, but also more expensive searches (e.g. queries) due to high branching factors between the nodes and vice versa. High coherence means that any exploration of the dataset is generally more focused on the topics dealt with, while low coherence tends to indicate the happy character of a dataset in which research tends to lead through many different topics. Finally, high entropy means more information and also less predictable distributions of topics along the nodes in walks and envelopes, with balanced cluster cardinalities. Low entropy means high predictability of node topics (in other words, strongly outlined cluster cardinalities). Possible combinations of measures can be listed as follows:"}, {"heading": "4 Experiments", "text": "In this section, we first present settings of experiments with CoCoE that are applied to samples of RDF datasets, then report on the results of the experiments and discuss their interpretation. Note that the implementation of the CoCoE methodology used in the experiments, including the corresponding data and scripts, is available at http: / / goo.gl / Wxnb3B."}, {"heading": "4.1 Datasets and Settings", "text": "The datasets we used were: 1. DrugBank - information on marketed medicines, including indications, chemical and molecular characteristics, manufacturers, protein bindings, etc.; 2. SIDER - information on drug side effects; 3. Diseasome - a network of disorders and associated genes; 4. All - a set of DrugBank, SIDER and diseasome datasets for which we have compiled a knowledge base of relevant biomedical linked open data [13]. One of the main purposes of the knowledge base is to extract traits that are applicable to the formation of models for the discovery of adverse effects. In this context, we were interested in knowledge base characteristics that correspond to the isolated and merged datasets."}, {"heading": "4.2 Results", "text": "This year it is more than ever before."}, {"heading": "4.3 Interpreting the Results", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "5 Conclusions and Future Work", "text": "We have presented CoCoE, a well-founded methodology for empirical analysis of LOD datasets; we have also described a publicly available implementation of the methodology; the experimental results showed the usefulness of CoCoE as it provided a meaningful automated evaluation of biomedical datasets, consistent with the intentions of the authors and maintainers of the datasets; our future work includes more scalable cluster and graph transmission algorithms that would make CoCoE easily applicable to even the largest LOD datasets such as DBpedia or Uniprot; we would also like to experiment with other implementations of the methodology, notably using and formally analyzing different similarities and clusters; and another interesting research topic is investigating the correlation between the performance of certain SPARQL query types and certain CoCoE ranges of measurements that could provide valuable insights for Warter and users of SPARQL endpoints."}], "references": [{"title": "Novel data-mining methodologies for adverse drug event discovery and analysis", "author": ["R. Harpaz", "W. DuMouchel", "N.H. Shah", "D. Madigan", "P. Ryan", "C. Friedman"], "venue": "Clinical Pharmacology & Therapeutics 91(6)", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Social Network Analysis: Methods and Applications", "author": ["S. Wasserman", "K. Faust"], "venue": "Cambridge University Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1994}, {"title": "Getting the meaning right: A complementary distributional layer for the web semantics", "author": ["V. Nov\u00e1\u010dek", "S. Handschuh", "S. Decker"], "venue": "Proceedings of ISWC\u201911, Springer", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Semantic similarity in biomedical ontologies", "author": ["C. Pesquita", "D. Faria", "A.O. Falco", "P. Lord", "F.M. Couto"], "venue": "PLoS Computational Biololgy 5(7)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "SKIMMR: Facilitating knowledge discovery in life sciences by machine-aided skim reading", "author": ["V. Nov\u00e1\u010dek", "G.A. Burns"], "venue": "PeerJ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Connectivity based k-hop clustering in wireless networks", "author": ["F.G. Nocetti", "J.S. Gonzalez", "I. Stojmenovic"], "venue": "Telecommunication systems 22(1-4)", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Link communities reveal multiscale complexity in networks", "author": ["Y.Y. Ahn", "J.P. Bagrow", "S. Lehmann"], "venue": "Nature 466(7307)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Introducing RDF graph summary with application to assisted SPARQL formulation", "author": ["S. Campinas", "T.E. Perry", "D. Ceccarelli", "R. Delbru", "G. Tummarello"], "venue": "Proceedings of DEXA\u201912, IEEE", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "RDFStats - an extensible RDF statistics generator and library", "author": ["A. Langegger", "W. W\u00f6\u00df"], "venue": "DEXA Workshops.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning from linked open data usage: Patterns & metrics", "author": ["K. M\u00f6ller", "M. Hausenblas", "R. Cyganiak", "S. Handschuh"], "venue": "Proceedings of the WebSci\u201910, Web Science Trust", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "RDF Analytics: Lenses over Semantic Graphs", "author": ["D. Colazzo", "F. Goasdou\u00e9", "I. Manolescu", "A. Roatis"], "venue": "Proceedings of WWW\u201914, ACM", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Statistics for Research", "author": ["S. Dowdy", "S. Weardon", "D. Chilko"], "venue": "Wiley", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Supporting knowledge discovery by linking diverse biomedical data", "author": ["A.T. Abdelrahman", "E. Munoz", "V. Nov\u00e1\u010dek", "P.Y. Vandenbussche"], "venue": "AMIA\u201914 Abstracts, AMIA", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Rob knows that the most successful methods typically define and train a model in order to discover unknown side effects of drugs using their known features [1].", "startOffset": 156, "endOffset": 159}, {"referenceID": 1, "context": "For the complexity measures, we use network analysis algorithms [2].", "startOffset": 64, "endOffset": 67}, {"referenceID": 2, "context": "Firstly, we need a distributional representation of the RDF data [3], which describes each entity (subject or object) by a vector that represents its meaning based on the entities linked to it.", "startOffset": 65, "endOffset": 68}, {"referenceID": 3, "context": "These two structures allow for representing coherence using various types of semantic similarities based on the vector space representation and the taxonomy structure, such as cosine or Wu-Palmer [4].", "startOffset": 196, "endOffset": 199}, {"referenceID": 2, "context": "The distributional representation of RDF data we use builds on our previous work [3].", "startOffset": 81, "endOffset": 84}, {"referenceID": 4, "context": "We have recently introduced the notion of heuristic quasi-random walks and their empirical analysis in [5], which, however, deals with different", "startOffset": 103, "endOffset": 106}, {"referenceID": 5, "context": "The clustering method introduced here builds on principles similar to k-hop clustering [6].", "startOffset": 87, "endOffset": 90}, {"referenceID": 6, "context": "Another related approach is nonparametric hierarchical link clustering [7], which is more general and sophisticated than our simple method, yet its Python implementation we have experimented with proved to be intractable when used in our experiments.", "startOffset": 71, "endOffset": 74}, {"referenceID": 3, "context": "A comprehensive overview of semantic similarity measures applicable in CoCoE is provided in [4].", "startOffset": 92, "endOffset": 95}, {"referenceID": 7, "context": "The most relevant tools and approaches for RDF data analysis are [8,9,10,11].", "startOffset": 65, "endOffset": 76}, {"referenceID": 8, "context": "The most relevant tools and approaches for RDF data analysis are [8,9,10,11].", "startOffset": 65, "endOffset": 76}, {"referenceID": 9, "context": "The most relevant tools and approaches for RDF data analysis are [8,9,10,11].", "startOffset": 65, "endOffset": 76}, {"referenceID": 10, "context": "The most relevant tools and approaches for RDF data analysis are [8,9,10,11].", "startOffset": 65, "endOffset": 76}, {"referenceID": 8, "context": "Perhaps closest to our work is [9] that computes a set of statistics and histograms for a given RDF dataset.", "startOffset": 31, "endOffset": 34}, {"referenceID": 7, "context": "Graph summaries [8] propose high-level abstractions of RDF data intended to facilitate formulation of SPARQL queries, which is orthogonal to our approach aimed at quantitative characteristics of the data itself.", "startOffset": 16, "endOffset": 19}, {"referenceID": 9, "context": "Usage-based RDF data analysis [10] provides insights into common patterns of utilising RDF data by agents, but does not offer means for actually analysing the data.", "startOffset": 30, "endOffset": 34}, {"referenceID": 10, "context": "Finally, the recent approach [11] is useful for knowledge discovery in RDF data based on user-defined query patterns and analytical perspectives.", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "Our approach complements [11] by characterising application-independent features of RDF datasets taken as a whole.", "startOffset": 25, "endOffset": 29}, {"referenceID": 11, "context": "In the experiments presented here, we used a simple method for ranking and filtering out the columns \u2013 the \u03c7 statistic [12], which can be used for computing divergence of specific observations from expected values.", "startOffset": 119, "endOffset": 123}, {"referenceID": 3, "context": "The formula we use is essentially based on a popular Wu-Palmer similarity measure [4].", "startOffset": 82, "endOffset": 85}, {"referenceID": 12, "context": "The dataset selection was motivated by our recent work in adverse drug effect discovery, for which we have been compiling a knowledge base from relevant biomedical Linked Open Data [13].", "startOffset": 181, "endOffset": 185}, {"referenceID": 12, "context": "Therefore we decided to use the knowledge bases being created in [13] as a test case for CoCoE.", "startOffset": 65, "endOffset": 69}, {"referenceID": 1, "context": "All graphs have so called small world property [2], as their densities are rather small and yet there is very little separation between any two nodes in the graph in general.", "startOffset": 47, "endOffset": 50}], "year": 2014, "abstractText": "CoCoE stands for Complexity, Coherence and Entropy, and presents an extensible methodology for empirical analysis of Linked Open Data (i.e., RDF graphs). CoCoE can offer answers to questions like: Is dataset A better than B for knowledge discovery since it is more complex and informative?, Is dataset X better than Y for simple value lookups due its flatter structure?, etc. In order to address such questions, we introduce a set of well-founded measures based on complementary notions from distributional semantics, network analysis and information theory. These measures are part of a specific implementation of the CoCoE methodology that is available for download. Last but not least, we illustrate CoCoE by its application to selected biomedical RDF datasets.", "creator": "LaTeX with hyperref package"}}}