{"id": "1406.1241", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jun-2014", "title": "The Best Templates Match Technique For Example Based Machine Translation", "abstract": "It has been proved that large scale realistic Knowledge Based Machine Translation applications require acquisition of huge knowledge about language and about the world. This knowledge is encoded in computational grammars, lexicons and domain models. Another approach which avoids the need for collecting and analyzing massive knowledge, is the Example Based approach, which is the topic of this paper. We show through the paper that using Example Based in its native form is not suitable for translating into Arabic. Therefore a modification to the basic approach is presented to improve the accuracy of the translation process. The basic idea of the new approach is to improve the technique by which template-based approaches select the appropriate templates.", "histories": [["v1", "Wed, 4 Jun 2014 23:56:08 GMT  (679kb)", "http://arxiv.org/abs/1406.1241v1", "Eleventh International Conference on Artificial Intelligence Applications, 2003"]], "COMMENTS": "Eleventh International Conference on Artificial Intelligence Applications, 2003", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["t el-shishtawy", "a el-sammak"], "accepted": false, "id": "1406.1241"}, "pdf": {"name": "1406.1241.pdf", "metadata": {"source": "CRF", "title": "The Best Templates Match Technique For Example Based Machine Translation", "authors": ["T. El-Shishtawy"], "emails": ["shishtawy@hotmail.com", "sammaka@ipa.edu.sa"], "sections": [{"heading": null, "text": "Applications require the acquisition of vast knowledge about language and the world. This knowledge is encoded in computer-aided grammars, lexicographs and domain models. Another approach - which avoids the need to collect and analyze massive knowledge - is the example-based approach that is the subject of this paper.We demonstrate through the work that the use of examples in their mother tongue is not suitable for translating into Arabic. Therefore, a modification of the basic approach is presented to improve the accuracy of the translation process.The basic idea of the new approach is to improve the technique by which template-based approaches select the appropriate templates. It is based on extraction from a parallel bilingual corpus of all possible templates that can match parts of the source set. These templates are selected as suitable candidates for the source set by selecting the appropriate template-based templates. The corresponding templates are also represented by Arabic and a graphic."}, {"heading": "1. Introduction", "text": "Automatic translation between human languages (\"machine translation\") is a scientific dream of enormous social, political and scientific importance. It was one of the earliest applications proposed for digital computers, but turning this dream into reality proved to be much more difficult. And, despite many problems, some degree of automatic translation is available today, and it is likely that over the next decade, the majority of routine technical and business translations will be carried out using some automatic translation tools [1]. Unfortunately, the Arabic language is not involved in the progress in the field of machine translation. There are very few systems, but they lack an open architecture of the underlying theoretical foundations of the Arabic language. This lack - hidden or overlooked - does not give a good picture of the state of the Arabic language. It has been proven that large-scale realistic, knowledge-based applications of machine translation (KBMT) require the acquisition of enormous knowledge about language and the world. This knowledge is codified in domains and lexicographics [2]."}, {"heading": "2. Example Based Machine Translation (EBMT)", "text": "Due to the increasing availability of large quantities of machine-readable text material, a number of research groups are exploring the possibilities of \"empirical\" approaches to machine translation. Exemplary translation is essentially translation by analogy. An exemplary machine translation system (EBMT) obtains a set of sentences in the source language (from which one translates) and their corresponding translations in the target language, and uses these examples to translate other, similar source language sentences into the target language [5]. The basic premise is that if a previously translated sentence occurs again, the same translation is likely to be correct again [6]. It takes advantage of an aligned parallel corpora with a large number of short-term text structures (Scania Corpora) to produce translation equivalents between English and Swedish. In the \"translation by analogy,\" or \"exemplary-based\" approach, there are no mapping rules, only procedures that include an overlap with accompaniments."}, {"heading": "3. The Best-Template Match Approach", "text": "Another approach to example-based translation is to use a template-based model instead of a string-based model. In this approach, the system relies on template-based syntactical synchronization of the English sentence entered and the templates stored in a database. Once synchronization takes place, the system gradually changes the corresponding Arabic part to produce a correct translation. It has the advantage that you need few examples in the bilingual parallel corpus archive to generate good translations. The template-based translation approach suffers from the problem of inaccurate or poor selection of templates for the source sentence, which affects the accuracy of the translation process. The proposed new approach is motivated to improve translation accuracy by selecting the appropriate template-based approaches. In our current work, we use a pre-built bilingual sentence that is bilingual in parallel. [9] This corpus is organized as a composition of Chunk's English language and its corresponding Arabic templates."}, {"heading": "4. The Proposed Model", "text": "The algorithm of the proposed translation model is presented in Figure (1). It begins with a morphological analysis (word category and lexical attributes) of the given English sentence. This valuable information is used to extract all possible English chunk templates that might match possible tags of the given English sentence. The extracted templates are obtained by using the English-Arabic parallel corpus. Subsequently, the occurrence of each word of the given sentence within the candidate templates is tested. A correspondence matrix represents the result of this test. The corresponding matrix is tuned by removing useless templates and adding dummy templates. Template groups are extracted from the tuned correspondence matrix. Each group represents a possible path that covers all words of the given sentence. These paths are represented by a directed graph. The shortest path in the Arabic graphical template is described as a chain of templates, the English chunk chain is best represented by the suggested model."}, {"heading": "4.1 Analysis of Source Sentence", "text": "The given English sentence is analyzed with the following algorithm: The input sentence is in word days. For each word in the English dictionary, the word is searched for [10]. If it is found, extract the word lexical attributes, i.e. (category, time span, number, gender,...) Otherwise, remove a prefix from the word (if found) and otherwise remove a suffix from the word (if found) and repeat."}, {"heading": "4.2 Extracting all Possible Template Chunks", "text": "The word order (word category and its lexical attributes) that constitutes the input sentence of the English sentence (w1 w2 w3... wn) is applied to the following algorithm to extract all possible parts of the template: a. start with the first word as a possible piece. b. Search the bilingual corpus for match and extract the corresponding Arabic chunkc. Add the next words one by one to the possible piece. and repeat the search. (b) until the end of the piece. d. Exclude the first word from the sentence and repeat (b) and (c).. e. Repeat (d) until the last word. The output blocks consist of one or more consecutive words of the entered English sentence and take the form: Ch _ tem1 = {w1}, Ch _ tem2 = {w1, w2}, wtemh _ w =....."}, {"heading": "4.3 Searching for English chunks", "text": "At this stage, we look for all possible sentence templates in the bilingual corpus. This can be achieved by matching the extracted English sentence templates with those in the bilingual parallel corpus. If the corpus template matches the current sentence template exactly, the English chunk and the corresponding Arabic template are stored."}, {"heading": "4.4 Constructing the Correspondence Matrix", "text": "The next step in our approach is to verify the existence of the English chunks within the Anglo-Arabic parallel corpus.The result of the found chunks and their word coverage is then represented by a correspondence matrix. The correspondence matrix represents the coverage of the found English chunks with the sentence words.In other words, the contribution of each template chunks would be evaluated by describing the role of each template in representing a part of the given sentence. This relationship is best described by a correspondence matrix. The matrix rows represent the chunks templates of the candidates. The matrix columns represent the word patterns of the given sentence. The matrix cells take the values \"1\" or \"0\" according to the presence or absence of each word pattern within the found chunk template. The relationship between chunks and words is too many; i.e., the word pattern can cover more than one."}, {"heading": "4.5 Building the directed graph", "text": "In the graph, each node represents one word of the input set and each branch represents a candidate chunk. The directed graph representing the corresponding matrix is shown in Figure (2), where d1, d2,... define dummy chunks, 1,2,3,... represent words of the input set and are Ch _ tem1, Ch _ tem2,... template chunks. The problem of complete translation is now reduced to finding an optimal path through the graph from the first node to the last node (words). However, in many real cases, there is discontinuity of the graph. For example, pronouns not found in parallel corpus can lead to such a gap. To solve this problem, we insert dummy chunks on all dead nodes that are nodes without output branch (chunk). Dummy chunk connects dead nodes to their nearest adjacent nodes."}, {"heading": "4.6 Selecting the optimum Path", "text": "Looking at the directed chart, you might find that there is more than one possible path of chunk templates that can cover the entire word pattern of the given set. All possible paths would be represented by an output table. Each line represents a possible path of chunk templates. Table (2) summarizes all possible paths of the previous chart. The optimal path is selected as the shortest path with minimum dummy chunks. Looking at various experimental cases, we found the following criteria: - Longer chunks are preferred - paths with minimum number of dummies are preferred. To implement these criteria, we use a simple heuristics that offers the advantage of completing paths without dummy chunks. If there is more than one path without dummy chunks, we select the shortest path that contains minimum number of chunks. In cases where dummies are present in all paths, we select the path with the least number of dummy chunks."}, {"heading": "4.7 Extracting the corresponding Arabic templates", "text": "The goal of this phase is to extract the Arabic templates that match the English chunk templates of the selected path, which could be achieved by consulting the Bilingual Parallel Corpus. The extracted Arabic chunk templates are stored in the same order as the selected path. Table (3) shows the resulting Arabic chunk templates that match the English ones. During the extraction, dummies on both sides remain unchanged. In fact, dummies represent unfound words in parallel corpus, which may be due to pronouns or incomplete corpus. These unfound words are presented as English words within the translated sentence."}, {"heading": "4.8 Generating the Target Sentence", "text": "A generation module is required to replace Arabic templates with actual Arabic chunks. Inputs at this stage are the English chunks and the corresponding Arabic templates. In fact, Arabic chunks cannot be produced by word-to-word replacement of the English chunks due to the differences between English and Arabic surface structures. Therefore, the Arabic template takes the form of a command that, when applied to Arabic words, produces the correct translation. Normally, the Arabic template takes the form of the following command: \"add [xx], class [yy], add [zz]\" Where xx & zz are optional and represent any added words or prefix and suffixes part of the word yy, where yy is mandatory and describe the Arabic word category. The following algorithm is used to generate the Arabic chunks: For each English add chunk doIf Chunk is dummy thenCopy it to Arabic chunkElseeach English template Get corresponding to Arabic-exthe Arabic translation butt-the \""}, {"heading": "5. Example 1", "text": "Suppose the English phrase to be translated is \"the proteins are necessary for building our bodies.\""}, {"heading": "5.1 Analyzing the English sentence", "text": "Word LexicalAttributethe artproteins n [pl, f] are [p, pl] necessary supplement for building preparation v [ing] our Poss [pl, m, 1] body n [pl, f]"}, {"heading": "5.2 Extracting all Possible Template Chunks", "text": "All Possible English Template Chunksart [def] art [def] n [pl, f] art [def] n [pl, f] be [p, f] art [def] n [pl, f] be [p, pl] adj art [def] n [pl, f] be [p, pl] adj art [def] n [p, pl] poss [poss] p [poss, p] poss [poss, p] poss [poss, p, 1] art [pl] n [p, pl] pref] n [pl, pl] prep, pr [p, pl] prep, pr, pm [p, pl] be [p, pl] prep, pr, pr, pr [poss] prep, pr, poss [poss, p] poss [poss, p] poss [poss, p] poss, p, pr, pr] poss [poss, p, p, pr] prep, poss [poss] n [poss, poss] prep, poss [poss] prep, poss [poss], poss [poss, poss] poss [poss, poss, p, p, p] poss, poss, poss, p, poss, p, poss] prep, pr, poss [poss] prep, poss [poss, poss] prep, poss [poss] prep, poss, poss [poss] prep, poss [poss] prep, poss, poss [poss] prep, poss, poss, poss, poss, poss] prep, poss [poss, poss] prep, poss [poss] prep, poss [poss, poss, poss] prep, poss [poss, poss] prep, poss [poss] prep, poss [poss, poss] prep, poss [poss] prep, poss [poss, poss] prep, poss"}, {"heading": "5.3 Searching for English chunks", "text": "No English piece of English temples1 for prep v [ing] 2 for prep v [ing] 3 for prep v [ing] 4 girls n [pl, f] 5 the mineral art [def] n [pl, f] 6 for feeding prep v [ing] 7 the protein art [def] n [pl, f] 8 the necessary adj 9 for building prep v [ing] 10 our body throws [pl, m, 1] n [pl, f] 11 the carbohydrate art [def] n [pl, f] 12 the fat art [def] n [pl, f] 13 the necessary adj 14 the vitamin art [def] n [pl, f] n [pl]"}, {"heading": "5.4 Constructing the Correspondence Matrix", "text": "No English template w1 w2 w3 w4 w5 w6 w7 w8the proteins are necessary for building our bodies art [def] n [pl, f] be [p, pl] adj prep v [ing] poss [pl, m, 1] n [pl, f] 1 prep v [ing] 2 prep v [ing] 3 prep v [ing] 4 n [pl, f] 5 art [def] n [pl, f] 6 prep v [ing] 7 art [def] n [pl] n [pl, f] f] 8 adj 9 prep v [ing] 10 poss [pl, m, 1] n [pl, f] 11 art [def] n [pl] n [def] n [pl, f] 7 adj14 art [def] n (def] n [def] n, f [wl wat, f [wat, f, f at [wl] 11 art [wl, f] wat [wat, f [wat] 11 art], f n [wat [wl, f] wat [wat [wl, f, f] wat [wat] 11 art], wat [wat] n, wat [wat] wat [wl, wat] n, wat [wat] n, wat [wl, wat] n, wat [wat] n, wat, wat [wat] n, wat [wat] n, wat, wat [wat] wat] n, wat, wat [wat] n, wat, wat [wat] n, wat, wat [wat] n, wat, wat [wl, wat] n, wat, wat [wat] n, wat, wat [wat] n, wat, wat [wl, wat] n, wat [wat] n, wat, wat [wl, wat] n, wat, wat [wat] n, wat, wat, wat, wat, wl, wl,"}, {"heading": "5.5 Selecting the Optimum Path", "text": "Fortunately, in this example, only one possible chunk template path can cover the entire word pattern of the given sentence, due to the positive effects of the pruning process applied to the correspondence matrix. This last path is considered to be the best template path representing the given set. Best template path Chunk5 + Chunk15 + Chunk8 + Chunk1 + Chunk10"}, {"heading": "5.6 Extracting the corresponding Arabic templates", "text": "No English Chunk Template Path Arabic Chunk Templates 1 prep v [ing] (prep1) (v1 [source]) 5 art [def] n [pl, f] (add [\u0644\u0442] n1 [pmean]) 8 adj (adj1 [s, f]) 10 poss [pl, m, 1] n [pl, f] (n1 [pmean] add [\u0627\u0439]) 15 Dummy Dummy"}, {"heading": "5.7 Generating the Target Sentence", "text": "No Arabic template Arabic chunk1 (prep1) (v1 [source])."}, {"heading": "6. Example 2", "text": "+ 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21 + 21"}], "references": [{"title": "Multi- Purpose Development and Operation Environments for Natural Language Generation", "author": ["Nirenburg S", "P. Shell", "A. Cohen", "P. Cousseau", "D. Grannes", "McNeilly C"], "venue": "Proceedings of the Third Conference on Natural Language Applications. Trento,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1992}, {"title": "Providing Machine Tractable Dictionary Tools", "author": ["Y. Wilks", "D. Fass", "C. Guo", "J. McDonald", "T. Plate", "Slator B"], "venue": "Machine Translation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1990}, {"title": "From N-Grams to Collocations: An Evaluation of Xtract", "author": ["F. Smadja"], "venue": "Proceedings of 29th ACL Meeting. Berkeley,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1991}, {"title": "A framework of a mechanical translation between Japanese and English by analogy principle", "author": ["M Nagao"], "venue": "In: A. Elithorn and R. Banerji (eds.) Artificial and Human Intelligence. NATO Publications,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1984}, {"title": "Extraction of Translation Equivalents from Parallel Corpora,", "author": ["J Tiedemann"], "venue": "The 11th Nordic Conference on Computational Linguistics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "Example-Based MT (EBMT)", "author": ["Bob Frederking"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "A Full-Text Experiment in Example- Based Machine Translation", "author": ["Nirenburg S", "S. Beale", "C. Domashnev"], "venue": "Publications of School of Computer Science, Carnegie Mellon University, 1998.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1998}, {"title": "An Experiment for Automatic Alignment of Arabic-English Parallel Corpus", "author": ["T El-Shishtawy"], "venue": "Egyptian Computer Society Magazine,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "This knowledge is encoded in computational grammars, lexicons and domain models [2].", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": "Some researchers seek ways of bringing down the price of knowledge acquisition by applying ways of automatically or semi-automatically extracting relevant information from machine-readable dictionaries [3] or text corpora [4].", "startOffset": 202, "endOffset": 205}, {"referenceID": 2, "context": "Some researchers seek ways of bringing down the price of knowledge acquisition by applying ways of automatically or semi-automatically extracting relevant information from machine-readable dictionaries [3] or text corpora [4].", "startOffset": 222, "endOffset": 225}, {"referenceID": 3, "context": "An Example-Based Machine Translation (EBMT) system is given a set of sentences in the source language (from which one is translating) and their corresponding translations in the target language, and uses those examples to translate other, similar source-language sentences into the target language [5].", "startOffset": 298, "endOffset": 301}, {"referenceID": 4, "context": "The basic premise is that, if a previously translated sentence occurs again, the same translation is likely to be correct again [6].", "startOffset": 128, "endOffset": 131}, {"referenceID": 5, "context": "This gives a translation template, which can then be filled in by word-for-word translation [7].", "startOffset": 92, "endOffset": 95}, {"referenceID": 6, "context": "3 A main system which is based on EBMT is the Pangloss MT project [8] which translates from Spanish to English.", "startOffset": 66, "endOffset": 69}, {"referenceID": 7, "context": "In the current work, we make use of a pre-built parallel bilingual corpus [9].", "startOffset": 74, "endOffset": 77}], "year": 2014, "abstractText": "It has been proved that large-scale realistic Knowledge Based Machine Translation (KBMT) applications require acquisition of huge knowledge about language and about the world. This knowledge is encoded in computational grammars, lexicons and domain models. Another approach \u2013 which avoids the need for collecting and analyzing massive knowledgeis the Example Based approach, which is the topic of this paper. We show through the paper that using Example Based in its native form is not suitable for translating into Arabic. Therefore a modification to the basic approach is presented to improve the accuracy of the translation process. The basic idea of the new approach is to improve the technique by which template-based approaches select the appropriate templates. It relies on extracting, from a parallel Bilingual Corpus, all possible templates that could match parts of the source sentence. These templates are selected as suitable candidate chunks for the source sentence. The corresponding Arabic templates are also extracted and represented by a diredted graph. Each branch represents one possible string of templates candidate to represent the target sentence. The shortest continuous path or the most probable tree branch is selected to represent the target sentence. Finally the Arabic translation of the selected tree branch is generated.", "creator": "Microsoft\u00ae Word 2010"}}}