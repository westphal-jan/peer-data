{"id": "1406.1509", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2014", "title": "Systematic N-tuple Networks for Position Evaluation: Exceeding 90% in the Othello League", "abstract": "N-tuple networks have been successfully used as position evaluation functions for board games such as Othello or Connect Four. The effectiveness of such networks depends on their architecture, which is determined by the placement of constituent n-tuples, sequences of board locations, providing input to the network. The most popular method of placing n-tuples consists in randomly generating a small number of long, snake-shaped board location sequences. In comparison, we show that learning n-tuple networks is significantly more effective if they involve a large number of systematically placed, short, straight n-tuples. Moreover, we demonstrate that in order to obtain the best performance and the steepest learning curve for Othello it is enough to use n-tuples of size just 2, yielding a network consisting of only 288 weights. The best such network evolved in this study has been evaluated in the online Othello League, obtaining the performance of nearly 96% --- more than any other player to date.", "histories": [["v1", "Thu, 5 Jun 2014 20:10:48 GMT  (318kb,D)", "http://arxiv.org/abs/1406.1509v1", "8 pages, 7 figures, 4 tables"], ["v2", "Tue, 24 Jun 2014 10:06:29 GMT  (318kb,D)", "http://arxiv.org/abs/1406.1509v2", "Fixed a typo ($\\eps=0.01$ instead of $\\eps=0.1$ on page 8"], ["v3", "Wed, 25 Jun 2014 20:12:19 GMT  (318kb,D)", "http://arxiv.org/abs/1406.1509v3", "Added technical report number"]], "COMMENTS": "8 pages, 7 figures, 4 tables", "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.LG", "authors": ["wojciech ja\\'skowski"], "accepted": false, "id": "1406.1509"}, "pdf": {"name": "1406.1509.pdf", "metadata": {"source": "CRF", "title": "Systematic N-tuple Networks for Position Evaluation: Exceeding 90% in the Othello League", "authors": ["Wojciech Ja\u015bkowski"], "emails": ["wjaskowski@cs.put.poznan.pl"], "sections": [{"heading": null, "text": "In fact, it is the case that most of them are able to abide by the rules they have given themselves. - Most of them are able to abide by the rules. - Most of them are able to abide by the rules. - Most of them are able to abide by the rules. - Most of them are able to abide by the rules. - Most of them are able to abide by the rules. - Most of them are able to abide by the rules. - Most of them are able to abide by the rules. - Most of them are able to abide by the rules. - Most of them are able to abide by the rules. - Most of them are able to abide by the rules."}, {"heading": "A. Othello", "text": "Othello (also known as Reversi) is a deterministic, perfect two-player information strategy game played on a board measuring 8 x 8 cm. There are 64 pieces that are black on one side and white on the other. The game begins with two white and two black pieces that form an oblique cross in the middle of the board. Players take turns placing a piece with its color up on the board. A legal move consists of placing a piece on a square so that it forms a vertical, horizontal or diagonal line with the figure of another player, with a continuous, non-empty sequence of opposing pieces between them (see Figure 1), which are reversed after placing the piece. The player happens when and only when he cannot make a legal move. The game ends when both players pass by one another. Then the player has more pieces with their color up wins.ar Xiv: 140 6,15 09v1 [cs.NE] Ju1 is not legal [cs.N5 Ju201 on O20428 and Othello is not having 11]."}, {"heading": "B. Position Evaluation Functions", "text": "For this reason, our players are simple state evaluators in a single-layer setup: given the current state of the board, a player generates all legal moves and applies the position evaluation function to the resulting states. The most desirable measured state determines the move to be played. Ties are resolved randomly. The simplest position evaluation function is the position evaluation counter (WPC), a linearly weighted board function. It assigns a weight wrc to a board location (r, c) and uses scalar products to determine the usefulness of a board state b = (brc) r, c = 1... 8: f (b) = 1 8: f (b) = 1 8: c = 1: c = 1 wrcbrc, where bij 0 is in the case of an empty board state b = (c = 8), c = 8 (in the case of a board field c = 1: 1), where c = 1: 1: 1 (b = 1)."}, {"heading": "C. Othello Position Evaluation Function League", "text": "Other popular features include neural networks and N-tuple networks. In order to allow direct comparison between different position assessment functions and algorithms that are able to learn their parameters, Lucas and Runarsson [18] have launched the Othello Position Evaluation Function League 1. Othello League, or Othello League for short, is an online ranking of Othello 1-ply State Evaluator players. Players who submit to the league are rated against SWH (the standard WPC Heuristic Player). Both the game itself and the players are deterministic (with the exception of the rare situation in which at least two positions have the same rating value). In order to provide a more continuous performance measurement, the Othello League introduces a marginalization of Othello. Both players are forced to make random moves with the probability of = 0.1. As1http: / algovales.ac..uk / aguthello the probability of Othello being determined by the league with two Othello points being played in Othello: Leagu..uk / 80thello, with the probability of Othello being played once in the series."}, {"heading": "D. N-tuple Network", "text": "The most functioning evaluation function in the league of Othello is the n-tuple network [16]. N-tuple networks were first applied to the problem of optical character recognition by Bledsoe and Browning [21]. For games, it was first used by Buro under the name of tabular value functions [5] and later popularized by Lucas [6]. According to Szubert et al. the N-tuple network consists of m ni-tuples where ni-tuples is size. For a given board position b, it returns the sum of the values returned by the individual n-tuples, and the ability to realize nonlinear mappings to higher dimensional spaces. \"[7].N-tuple network consists of m-tuples where ni-tuples is size."}, {"heading": "E. N-tuple Network Architecture", "text": "Due to the spatial nature of game boards, n-tuples are usually consecutive snake networks, although this is not a formal requirement. If each n-tuples in a network is of the same size, we call it an m-tuples network, with m-3n weights. Apart from the selection of n-tuples, an important design question of the n-tuples network architecture is the location of the individual n-tuples on the board [7].1) Random Snake-shaped n-tuple Network: Therefore, it is surprising that so many studies in game strategy learning are associated with randomly generated snake networks n-tuples, n-tuples networks. Lucas [6] creates individual n-tuples by starting from a random board location and then taking a random walk of 6 steps in each of the eight orthogonal or diagonal directions. Repeated locations were ignored, so the resulting quadtuples are from 2 to 6."}, {"heading": "F. Learning to Play Both Sides", "text": "If an individual player defined by his score function is to play both as black and as white, he must interpret the result of the score function as complementary, depending on the color he is playing. There are three methods that serve this purpose.The first is the double function (e.g. [23]), which simply uses two separate functions: one for playing white and the other for playing black. It allows to completely separate the strategy for white and black players. However, its disadvantage is that twice as many weights must be learned and the experience that is learned when playing as black is not used when playing as white and vice versa. Output delegation and board inversion (e.g. [9]) are alternatives to the double function. They only use a single set of weights, which reduces the search space and enables the transfer of experience between white and black players. When using the score output output, black chooses the move that leads to a position with the maximum value of the score function, while white chooses the move, which is best used to play the position on the board with a minimum number of pieces. If a board with a black figure is used, it is best to play it on the board with a black figure."}, {"heading": "III. EXPERIMENTS AND RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Common Settings", "text": "1) Evolutionary setup: In order to compare different network architectures, we performed several computational experiments. In each of these experiments, the weights of n-tuple networks were learned (10 + 90) evolutionary strategy [24] over 5000 generations; the weights of individuals in the original population were determined from the [\u2212 0.1, 0.1] interval; the evolutionary strategy used Gaussian mutation \u03c3 = 1.0; the fitness of the individual was calculated using the performance measurement of the Othello League, which was estimated at over 1000 double games (cf. II-C). Overall, 1010 games were played in each evolutionary run, making our experiments exceptionally large compared to the previous studies. For example, in a recent study of n-tuple networks [7] 3 x 106 games were played; despite the use of the much simpler WPC representation, Samothrakis et al. [16] The results of our experiments were exceptionally high compared to the previous studies."}, {"heading": "B. Preliminary: Board Inversion vs. Output Negation", "text": "Figure 4 shows the results of learning with board inversion versus output negation for representatives of both types of Ntuple Networks architectures: Rand-8 \u00b7 4 with 8 \u00b7 43 = 648 and All-1 with 10 \u00b7 31 = 30 weights. The figure shows that board inversion outperforms output negation regardless of the player architecture, which confirms an earlier study of the two methods for preference learning [9]. The differences between the methods are statistically significant (see also the detailed results in Table IV). In addition, visual verification of the violin diagrams shows that board inversion leads to more robust learning as the variance of performance is lower. Therefore, in the following experiments we will only apply board inversion."}, {"heading": "C. All Short Straight vs. Random Long Snake-shaped N-tuples", "text": "In the main experiment, we compare n-tuple networks, which consist of all possible short straight n-tuples (all-2, all-3 and all-4), with long random serpentine networks (rand-10 \u00d7 3, rand-8 \u00d7 4 and rand-7 \u00d7 5). However, we have chosen the number of ntuples and their size to make the number of weights equal in the corresponding architectures, or, if not, similar (see Table II). The results of the experiment are presented in Figure 5 as violin plots. Statistical analysis of three pairs with equal or similar number of weights shows that: \u2022 all-2 is better than rand-10 \u00d7 3, \u2022 all-3 is better than rand-8 \u00d7 4, and \u2022 all-4 is better than rand-7 \u00d7 5. Let us note that the differences in performance are considerable: for the pair all-2 vs. rand-10 \u00d7 3, where the difference in performance is lowest."}, {"heading": "E. Othello League Results", "text": "The best player achieved in this study consists of all 2-tuples; his performance is 0.9592 with 95% confidence delta of \u00b1 0.0012. This result is significantly higher than the best results reported up to this point in the Othello League (see III). Also note how small it is (in terms of the number of weights) compared to other players in the league. Unfortunately, the online Othello League only accepts players who use output negation; it does not allow board inversion. Therefore, our player could not play the Othello League.In order to be accepted in the Othello League, we also conducted some experiments with output negation. The best output negation player we were able to develop was submitted under the name wj-1-2-3-tuples. It consists of all straight 1, 2 and 3-tuples games that are unable to evaluate the total performance of 966 weights as a whole."}, {"heading": "IV. DISCUSSION: THE MORE WEIGHTS, THE WORSE FOR EVOLUTION?", "text": "We have shown that among all * methods, the more weight, the worse results are obtained; the same is true for the edge * methods (see Figure 5). This finding confirms those of Szubert et al. [7], who found that between the networks rand-12 \u00d7 6 (8748 weights), rand-9 \u00d7 5 (2187 weights) and rand-7 \u00d7 4 (567 weights), the latter (co-) evolutionary algorithm achieves the best results, and the authors found that this effect is due to the increased dimensionality of the search space, for which \"the weight mutation operator is not efficient enough to make rapid progress.\" Although we do not dispute this claim, our results suggest that the number of weights in a network is not the only performance factor. All-4 has 1701 weights, which makes the dimensionality of its search space significantly higher than that of rand-10 \u00d7 3 and rand-8 \u00d7 4, the total weights in a network being 648, or the change being the 648 respectively."}, {"heading": "V. CONCLUSIONS", "text": "We have shown that a network of all kinds of systematically generated short n-tuples leads to a much better game than long random serpentine tuples originally used by Lucas [11]. Using a simple network of all kinds of straight 2-tuples (with only 288 weights), we were able to beat the best result in the online Othello league (which usually has many times more weights). Furthermore, our results suggest that tuples longer than 2 offer no advantage, which also leads to a slower learning rate. This is surprising, since capturing opposing figures in Othello requires a series of at least three parts (e.g. white, black, white). Let us emphasize that our result was obtained in an intensive computer experiment involving 5000 generations, an order of magnitude larger than other studies in this area. However, it remains to be seen whether they also apply to different experimental settings."}, {"heading": "ACKNOWLEDGMENT", "text": "This work was made possible by the grant number DEC-2013 / 09 / D {37} {36} {44} {44} {44 44} {27} {12 13} {52 53} {22 30} {50 51} {10 11} {33 41} {17 25} {2 8 {41 42} {13 21} {45 46} {45 46} {10 18} {21 22} {17 18 {17 18} {42 50} {{10} {37 46} {10 {19 19 {19 19} {19 {19 19} {19 {19 19} {44} {44 51} {44 51 51 51} {2 8 {25 34} {25 34} {25 26} {12 20} {19 19 {11} {44} {44 {44 {44} {44 {44 {44 38} {44 {44 38} {44 38} {44 {44 38} {44 {44} {44 51} {44 51 51 {44 51} {44 51 51 51} {{44 51 51 51 51} {2 8 {42 51 51 51 51 51 51 51 51} {50 {50 {50} {50 {50} {50 {50} {50 {45 45 45 {38 38 36 36 36 36 {36} {36 36 {36} {36 {36} {44 {44} {44 {44} {44 {44 38} {44 {44 38} {44 38} {44} {44 {44} {44 51 51} {44 51 51} {44 51 51} {44 51 51 51} {44 51 51 51} {44 51 51} {44 51 51 51} {44 51 51 51} {44 51 51 51 51 51} {44 51 51 51 51 51} {44 51 51 51 51 51 51} {53 53 53 53 53 53 53} {50 {50 {50} 50 {50 {50} 50 {50} 50 {50 {50} 50 {50} 50 {45 {45 {45 {50} 52 52 52 52 36 36} 36 36 36 36 36} 36 36 {36} 36} 36 {36 {36} 44 {44 {36} 36} 44 {44 {44 {44} {44} {44 {44} {44} {44 {44} {44} {44} {44} {44"}], "references": [{"title": "XXII. Programming a computer for playing chess", "author": ["C.E. Shannon"], "venue": "Philosophical magazine, vol. 41, no. 314, pp. 256\u2013275, 1950.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1950}, {"title": "Some studies in machine learning using the game of checkers", "author": ["A.L. Samuel"], "venue": "IBM Journal of Research and Development, vol. 3, no. 3, pp. 211\u2013229, 1959.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1959}, {"title": "A knowledge-based approach of connect-four", "author": ["L.V. Allis"], "venue": "Vrije Universiteit, Subfaculteit Wiskunde en Informatica,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1988}, {"title": "Experiments with Multi-ProbCut and a new high-quality evaluation function for Othello", "author": ["M. Buro"], "venue": "Games in AI Research, pp. 77\u201396, 2000.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "An evaluation function for othello based on statistics", "author": ["\u2014\u2014"], "venue": "NEC, Princeton, NJ, NECI 31, Tech. Rep., 1997", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1997}, {"title": "Learning to play Othello with n-tuple systems", "author": ["S. Lucas"], "venue": "Australian Journal of Intelligent Information . . . , no. 4, pp. 1\u201320, 2008", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "On Scalability, Generalization, and Hybridization of Coevolutionary Learning: a Case Study for Othello", "author": ["M. Szubert", "W. Ja\u015bkowski", "K. Krawiec"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Using Resource-Limited Nash Memory to Improve an Othello Evaluation Function", "author": ["E.P. Manning", "A. Othello"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 2, no. 1, pp. 40\u201353, 2010.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Preference Learning for Move Prediction and Evaluation Function Approximation in Othello", "author": ["T. Runarsson", "S. Lucas"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Searching for solutions in games and artificial intelligence", "author": ["V.L. Allis"], "venue": "Ph.D. dissertation, University of Limburg, Maastricht, The Netherlands, 1994.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1994}, {"title": "Learning to play Othello with N-tuple systems", "author": ["S.M. Lucas"], "venue": "Australian Journal of Intelligent Information Processing Systems, Special Issue on Game Technology, vol. 9, no. 4, pp. 01\u201320, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "An Othello evaluation function based on Temporal Difference Learning using probability of winning", "author": ["Y. Osaki", "K. Shibahara", "Y. Tajima", "Y. Kotani"], "venue": "2008 IEEE Symposium On Computational Intelligence and Games, pp. 205\u2013211, Dec. 2008", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Using resource-limited nash memory to improve an othello evaluation function", "author": ["E.P. Manning"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on, vol. 2, no. 1, pp. 40 \u201353, march 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving Generalization Performance in Co-Evolutionary Learning", "author": ["S.Y. Chong", "P. Tino", "D.C. Ku", "Y. Xin"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 16, no. 1, pp. 70\u201385, 2012", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Neural-Fitted TD-Leaf Learning for Playing Othello With Structured Neural Networks", "author": ["S. van den Dries", "M.A. Wiering"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 23, no. 11, pp. 1701\u20131713, Nov. 2012", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Coevolving Game-Playing Agents: Measuring Performance and Intransitivities", "author": ["S. Samothrakis", "S. Lucas", "T. Runarsson", "D. Robles"], "venue": "IEEE Transactions on Evolutionary Computation, no. 99, pp. 1\u201315, 2012", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-criteria comparison of coevolution and temporal difference learning on othello", "author": ["W. Ja\u015bkowski", "M. Szubert", "P. Liskowski"], "venue": "EvoGames, ser. Lectures Notes in Computer Science, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Temporal difference learning versus co-evolution for acquiring othello position evaluation", "author": ["S.M. Lucas", "T.P. Runarsson"], "venue": "IEEE Symposium on Computational Intelligence and Games. IEEE, 2006, pp. 52\u201359.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Coevolutionary Temporal Difference Learning for Othello", "author": ["M. Szubert", "W. Ja\u015bkowski", "K. Krawiec"], "venue": "IEEE Symposium on Computational Intelligence and Games, 2009, Conference proceedings (article), pp. 104\u2013111", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Strategy acquisition for the game", "author": ["T. Yoshioka", "S. Ishii", "M. Ito"], "venue": "Strategy Acquisition for the Game \"Othello\" Based on Reinforcement Learning, vol. 82, no. 12, pp. 1618\u20131626, 1999.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "Pattern recognition and reading by machine", "author": ["W.W. Bledsoe", "I. Browning"], "venue": "Proc. Eastern Joint Comput. Conf., 1959, pp. 225\u2013232.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1959}, {"title": "Learning n-tuple networks for othello by coevolutionary gradient search", "author": ["K. Krawiec", "M. Szubert"], "venue": "GECCO 2011 Proceedings, N. K. et al, Ed., ACM. ACM, 2011, pp. 355\u2013362.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Reinforcement Learning with Ntuples on the Game Connect-4", "author": ["M. Thill", "P. Koch", "W. Konen"], "venue": "Parallel Problem Solving from Nature - PPSN XII, ser. Lecture Notes in Computer Science, C. A. C. Coello, V. Cutello, K. Deb, S. Forrest, G. Nicosia, and M. Pavone, Eds., vol. 7491. Springer, 2012, pp. 184\u2013194.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Evolution strategies\u2013a comprehensive introduction", "author": ["H.-G. Beyer", "H.-P. Schwefel"], "venue": "Natural computing, vol. 1, no. 1, pp. 3\u201352, 2002.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2002}, {"title": "Improving coevolution by random sampling", "author": ["W. Ja\u015bkowski", "P. Liskowski", "M. Szubert", "K. Krawiec"], "venue": "GECCO\u201913: Proceedings of the 15th annual conference on Genetic and Evolutionary Computation, C. Blum, Ed. Amsterdam, The Netherlands: ACM, July 2013, pp. 1141\u20131148.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Since the early works of Claude Shannon on Chess [1] and Arthur Samuel on Checkers [2], a lot of research have been conducted in the area of board games towards finding either perfect players (Connect-4, [3]), or stronger than human players (Othello, [4]).", "startOffset": 49, "endOffset": 52}, {"referenceID": 1, "context": "Since the early works of Claude Shannon on Chess [1] and Arthur Samuel on Checkers [2], a lot of research have been conducted in the area of board games towards finding either perfect players (Connect-4, [3]), or stronger than human players (Othello, [4]).", "startOffset": 83, "endOffset": 86}, {"referenceID": 2, "context": "Since the early works of Claude Shannon on Chess [1] and Arthur Samuel on Checkers [2], a lot of research have been conducted in the area of board games towards finding either perfect players (Connect-4, [3]), or stronger than human players (Othello, [4]).", "startOffset": 204, "endOffset": 207}, {"referenceID": 3, "context": "Since the early works of Claude Shannon on Chess [1] and Arthur Samuel on Checkers [2], a lot of research have been conducted in the area of board games towards finding either perfect players (Connect-4, [3]), or stronger than human players (Othello, [4]).", "startOffset": 251, "endOffset": 254}, {"referenceID": 4, "context": "In the context of Othello, one of the most successful position evaluation functions is tabular value function [5] or n-tuple network [6].", "startOffset": 110, "endOffset": 113}, {"referenceID": 5, "context": "In the context of Othello, one of the most successful position evaluation functions is tabular value function [5] or n-tuple network [6].", "startOffset": 133, "endOffset": 136}, {"referenceID": 6, "context": "The effectiveness of n-tuple network highly depends on the placement of n-tuples [7].", "startOffset": 81, "endOffset": 84}, {"referenceID": 7, "context": "Typically, n-tuples architectures consist of a small number of long, randomly generated, snakeshaped n-tuples [8], [7], [9].", "startOffset": 110, "endOffset": 113}, {"referenceID": 6, "context": "Typically, n-tuples architectures consist of a small number of long, randomly generated, snakeshaped n-tuples [8], [7], [9].", "startOffset": 115, "endOffset": 118}, {"referenceID": 8, "context": "Typically, n-tuples architectures consist of a small number of long, randomly generated, snakeshaped n-tuples [8], [7], [9].", "startOffset": 120, "endOffset": 123}, {"referenceID": 9, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 57, "endOffset": 61}, {"referenceID": 10, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 188, "endOffset": 192}, {"referenceID": 11, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 194, "endOffset": 198}, {"referenceID": 12, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 200, "endOffset": 204}, {"referenceID": 13, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 206, "endOffset": 210}, {"referenceID": 14, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 212, "endOffset": 216}, {"referenceID": 15, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 218, "endOffset": 222}, {"referenceID": 6, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 224, "endOffset": 227}, {"referenceID": 16, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 229, "endOffset": 233}, {"referenceID": 17, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 66, "endOffset": 70}, {"referenceID": 5, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 72, "endOffset": 75}, {"referenceID": 18, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 83, "endOffset": 87}, {"referenceID": 15, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 89, "endOffset": 93}, {"referenceID": 6, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 95, "endOffset": 98}, {"referenceID": 19, "context": "[20], are presented in Table I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "To allow direct comparison between various position evaluation functions and algorithms capable of learning their parameters, Lucas and Runarsson [18] have appointed the Othello Position Evaluation Function League 1.", "startOffset": 146, "endOffset": 150}, {"referenceID": 17, "context": "However, it was argued that the ability to play -Othello is highly correlated with the ability to play Othello [18].", "startOffset": 111, "endOffset": 115}, {"referenceID": 15, "context": "The best performing evaluation function in the Othello League is n-tuple network [16].", "startOffset": 81, "endOffset": 85}, {"referenceID": 20, "context": "N-tuple networks have been first applied to optical character recognition problem by Bledsoe and Browning [21].", "startOffset": 106, "endOffset": 110}, {"referenceID": 4, "context": "For games, it have been used first by Buro under the name of tabular value functions [5], and later popularized by Lucas [6].", "startOffset": 85, "endOffset": 88}, {"referenceID": 5, "context": "For games, it have been used first by Buro under the name of tabular value functions [5], and later popularized by Lucas [6].", "startOffset": 121, "endOffset": 124}, {"referenceID": 6, "context": "their main advantages of n-tuple networks \u201cinclude conceptual simplicity, speed of operation, and capability of realizing nonlinear mappings to spaces of higher dimensionality\u201d [7].", "startOffset": 177, "endOffset": 180}, {"referenceID": 10, "context": "The effectiveness of n-tuple networks is improved by using symmetric sampling, which exploits the inherent symmetries of the Othello board [11].", "startOffset": 139, "endOffset": 143}, {"referenceID": 6, "context": "Apart from choosing n and m, an important design issue of n-tuples network architecture is the location of individual n-tuples on the board [7].", "startOffset": 140, "endOffset": 143}, {"referenceID": 5, "context": "Lucas [6] generated individual n-tuples by starting from a random board location, then taking a random walk of 6 steps in any of the eight orthogonal or diagonal directions.", "startOffset": 6, "endOffset": 9}, {"referenceID": 21, "context": "The same method Krawiec and Szubert used for generating 7\u00d7 4, 9\u00d7 5 and 12\u00d7 6-tuple networks [22], [7], and Thill et al.", "startOffset": 92, "endOffset": 96}, {"referenceID": 6, "context": "The same method Krawiec and Szubert used for generating 7\u00d7 4, 9\u00d7 5 and 12\u00d7 6-tuple networks [22], [7], and Thill et al.", "startOffset": 98, "endOffset": 101}, {"referenceID": 22, "context": "[23] for generating 70\u00d7 8 tuple networks playing Connect Four.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "3) Other Approaches: Logistello [4], computer player, which beat the human Othello world champion in 1997, used 11 n-tuples of n \u2208 {3, 10}, hand-crafted by an expert.", "startOffset": 32, "endOffset": 35}, {"referenceID": 7, "context": "External knowledge has also been used by Manning [8], who, generated a diverse 12 \u00d7 6-tuple network using random inputs method from Breiman\u2019s Random Forests basing on a set of 10 000 labeled random games.", "startOffset": 49, "endOffset": 52}, {"referenceID": 22, "context": ", [23]), which simply employs two separate functions: one for playing white and the other for playing black.", "startOffset": 2, "endOffset": 6}, {"referenceID": 8, "context": ", [9]) are alternatives to doubled function.", "startOffset": 2, "endOffset": 5}, {"referenceID": 23, "context": "In each of them the weights of n-tuple networks have been learned by (10 + 90) evolution strategy [24] for 5000 generations.", "startOffset": 98, "endOffset": 102}, {"referenceID": 6, "context": "For example, in a recent study concerning n-tuple networks [7] 3\u00d7106 games were played.", "startOffset": 59, "endOffset": 62}, {"referenceID": 15, "context": "[16] performed 10 games per run.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "The figure shows that board inversion surpasses output negation regardless of the player architecture, which confirms a previous study of the two methods for preference learning [9].", "startOffset": 178, "endOffset": 181}, {"referenceID": 6, "context": "2011-01-30 epTDLmpx_12x6 [7] n-tuple network 3240 0.", "startOffset": 25, "endOffset": 28}, {"referenceID": 6, "context": "2011-01-25 epTDLxover [7] n-tuple network 4698 0.", "startOffset": 22, "endOffset": 25}, {"referenceID": 6, "context": "The performances of all-2 and wj-1-2-3-tuples players have been estimated using 50 000 double games, and the performance of epTDLmpx_12x6 has been reported in [7].", "startOffset": 159, "endOffset": 162}, {"referenceID": 13, "context": "When evaluated against random WPC players (the expected utility measure [14], [25]), the best all-2 player obtains a score of only 0.", "startOffset": 72, "endOffset": 76}, {"referenceID": 24, "context": "When evaluated against random WPC players (the expected utility measure [14], [25]), the best all-2 player obtains a score of only 0.", "startOffset": 78, "endOffset": 82}, {"referenceID": 6, "context": "99 [26], [7].", "startOffset": 9, "endOffset": 12}, {"referenceID": 6, "context": "[7], who found out that among the networks of rand-12\u00d7 6 (8748 weights), rand-9 \u00d7 5 (2187 weights), and rand-7 \u00d7 4 (567 weights), it is the latter that allows (co)evolutionary algorithm for obtaining best results.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Finally, let us notice that an alternative to a fixed n-tuple network architecture is a self-adaptive one, which can change in response to variation operators [7], such as mutation or crossover.", "startOffset": 159, "endOffset": 162}, {"referenceID": 10, "context": "We have shown that a network consisting of all possible, systematically generated, short n-tuples leads to a significantly better play than long random snake-shaped tuples originally used by Lucas [11].", "startOffset": 197, "endOffset": 201}], "year": 2017, "abstractText": "N-tuple networks have been successfully used as position evaluation functions for board games such as Othello or Connect Four. The effectiveness of such networks depends on their architecture, which is determined by the placement of constituent n-tuples, sequences of board locations, providing input to the network. The most popular method of placing ntuples consists in randomly generating a small number of long, snake-shaped board location sequences. In comparison, we show that learning n-tuple networks is significantly more effective if they involve a large number of systematically placed, short, straight n-tuples. Moreover, we demonstrate that in order to obtain the best performance and the steepest learning curve for Othello it is enough to use n-tuples of size just 2, yielding a network consisting of only 288 weights. The best such network evolved in this study has been evaluated in the online Othello League, obtaining the performance of nearly 96% \u2014 more than any other player to date.", "creator": "LaTeX with hyperref package"}}}