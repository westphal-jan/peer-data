{"id": "1406.2419", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2014", "title": "Why do linear SVMs trained on HOG features perform so well?", "abstract": "Linear Support Vector Machines trained on HOG features are now a de facto standard across many visual perception tasks. Their popularisation can largely be attributed to the step-change in performance they brought to pedestrian detection, and their subsequent successes in deformable parts models. This paper explores the interactions that make the HOG-SVM symbiosis perform so well. By connecting the feature extraction and learning processes rather than treating them as disparate plugins, we show that HOG features can be viewed as doing two things: (i) inducing capacity in, and (ii) adding prior to a linear SVM trained on pixels. From this perspective, preserving second-order statistics and locality of interactions are key to good performance. We demonstrate surprising accuracy on expression recognition and pedestrian detection tasks, by assuming only the importance of preserving such local second-order interactions.", "histories": [["v1", "Tue, 10 Jun 2014 04:34:43 GMT  (1827kb,D)", "http://arxiv.org/abs/1406.2419v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["hilton bristow", "simon lucey"], "accepted": false, "id": "1406.2419"}, "pdf": {"name": "1406.2419.pdf", "metadata": {"source": "META", "title": "Why do linear SVMs trained on HOG features perform so well?", "authors": ["Hilton Bristow", "Simon Lucey"], "emails": [], "sections": [{"heading": "1. Introduction", "text": "Although visual object detectors have improved by leaps and bounds in the last decade, they are still largely based on the same underlying principles: linear support vector machines (SVMs) trained on features of the histogram of the oriented gradient (HOG). When the HOG features were introduced, they improved existing methods for pedestrian detection by an order of magnitude [5]. Since then, the HOG SVM pipeline has been used in the deformable submodel of [9], its derivatives and high-performance of the PASCAL VOC challenge. A keyword search for \"HOG\" and \"SVM\" on the PASCAL results page in 2012 yields 25 and 18 hits respectively. HOG is now complicated in detecting pipelines in almost every visual recognition / classification task [5, 7, 20, 21]. In this essay, we scroll back through the layers of complexity of HOG features to understand what lies behind these interactions, in particular."}, {"heading": "2. Representing HOG features as a linear", "text": "An illustration of this pipeline is shown in Figure 1. This type of representation has proved particularly successful in tolerating non-rigid changes in object geometry while maintaining high selectivity [8]. The exact choice of non-linear function is discretionary, but Dalal and Triggs try f (x) = | x (x) = x (x) (x). Both functions remove the edge direction and leave only one function of magnitude. In this paper, we opt for the square of edge directions. Our choice is motivated by a number of reasons. Firstly, the square function leads to greater flexibility in the manipulation that we show in our later reformulation. Secondly, there are advocates of the square function (referred to as \"square\" or \"pooling\")."}, {"heading": "3. Capacity of the Classifier", "text": "If the projection matrix L is used in a classification setting for support vectors, it can be included in the matrix, w \u0445 = arg min w, \u0394i \u2265 01 2 wT (LTL) \u2212 1w + C l \u2211 i = 1 \u0448i (6) is subject to yiw T (xi) > 1 \u2212 \u043fi, i = 1... lleaving as a data term only interactions between the weights w and the Kronecker expansion of the image. Note 1 If the weighting is the identity matrix (i.e. L = I), the equation (6) is reduced to an SVM with a simple square core. Thus, the first part of the HOG history induced before it can be quantified as square. Therefore, the weighting matrix is intrinsically an SVM at the edge of a square core."}, {"heading": "4. Secord-Order Interactions", "text": "The term (x x) in Equation (4) can alternatively be written as follows: (x x) = vec (xxT), (7) which is the vectorized covariance matrix of all pixel interactions. [19] showed that the covariance of a local image distribution is often sufficient to distinguish it from other distributions. However, calculating a full-fledged covariance matrix is often difficult. [10] To get around this problem by assuming the standard background image statistics (a translated image is still an image) and limiting the range of interactions between pixels. Simoncelli [18] showed that these assumptions are reasonable, since correlations between pixels quickly fall with distance (see Figure 2). To improve conditioning and prevent the classification x x x from being the most common group of local pixel interactions."}, {"heading": "5. Local Second-Order Interactions", "text": "Consider two classes A and B. Class A represents the distribution of all natural images. Class B represents a noise distribution that has the same frequency spectrum as natural images, namely 1f [18]. Both distributions are normalized. We sample 25,000 training and test examples from each class and train two classifiers: one while maintaining raw pixel information and one while maintaining second-order local pixel interactions. The goal of the classifiers is to predict \"natural\" or \"noise\" (i.e. the distributions overlap). By maintaining local square interactions of the pixels, the classifier does not distinguish between the two distributions. There is no information in the spatial or Fourier domain to separate the classes (i.e. the distributions overlap). By maintaining local square interactions of the pixels, however, the classifier can almost perfectly distinguish natural from synthetic ones."}, {"heading": "6. Replacing prior with posterior:", "text": "The image that we obtained before the publication of the report is essential to achieve a good generalization performance. However, we know that the entire space of deformation does not need to be used to make informed decisions. This is usually a reasonable assumption that we have to make, since the measurement of the rear area is unfeasible. Take, for example, the task of detecting pedestrians. The entire space of deformation does not need to be scanned in order to make informed decisions. This is a reasonable assumption as the measurement of the rear area is impracticable. Full detection of the rear area includes all possible combinations of pose, clothing, lighting, gender, background and other characteristics."}, {"heading": "7. Methods", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "8. Discussion", "text": "We started work on the premise that HOG characteristics embody interactions required for good detection performance, and their popularity and success among current object detection benchmarks support this, at least empirically. Building on the work of [3], we demonstrated that HOG characteristics can be reformulated as affinity weighting at the edge of a square core SVM. Two messages can be derived from this: (i) a square classifier has sufficient capacities to allow visual object classes to be distinguished, and (ii) the actual image is previously captured by the weighting matrix. We conducted an experiment in which classifiers were entrusted with distinguishing between \"natural\" and \"noise\" images, and found that the square classifier, which preserves only local pixel interactions, was able to separate the two classes, suggesting that the structure of two-local middle ages can be exploited more naturally."}, {"heading": "9. Conclusions", "text": "We believe that preserving second-order local interactions is at the heart of their success, based on similar insights within the human visual system. With these simple assumptions combined with large amounts of training data, it is possible to learn a classifier that performs well in a limited recognition task, and within the defaults of a HOG-based classifier that is specifically tailored to an image before being used in a person-recognition experiment. As the size of the data sets continues to grow, we will be able to rely less and less on prior assumptions and instead rely on the data models we use. Second-order local interactions are one of the simplest encoders of natural image statistics to ensure that such models are capable of making informed predictions."}], "references": [{"title": "Quadratic polynomials learn better image features", "author": ["J. Bergstra", "G. Desjardins", "P. Lamblin", "Y. Bengio"], "venue": "Technical report, Universite de Montreal,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers", "author": ["S. Boyd"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "V1-Inspired features induce a weighted margin in SVMs", "author": ["H. Bristow", "S. Lucey"], "venue": "European Conference on Computer Vision (ECCV),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Normalization as a canonical neural computation", "author": ["M. Carandini", "D.J. Heeger"], "venue": "Nature reviews. Neuroscience,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Uncertainty Relation for Resolution in Space, Spatial Frequency, and Orientation Optimized by Two-Dimensional Visual Cortical Filters", "author": ["J. Daugman"], "venue": "Optical Society of America,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1985}, {"title": "Face recognition using Histograms of Oriented Gradients", "author": ["O. D\u00e9niz", "G. Bueno", "J. Salido", "F. De la Torre"], "venue": "Pattern Recognition Letters,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "How does the brain solve visual object recognition", "author": ["J.J. DiCarlo", "D. Zoccolan", "N.C. Rust"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Object detection with discriminatively trained part-based models", "author": ["P.F. Felzenszwalb", "R.B. Girshick", "D. McAllester", "D. Ramanan"], "venue": "Pattern Analysis and Machine Learning (PAMI),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Discriminative decorrelation for clustering and classification", "author": ["B. Hariharan", "J. Malik", "D. Ramanan"], "venue": "European Conference on Computer Vision (ECCV),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Learning multiple layers of representation", "author": ["G.E. Hinton"], "venue": "Trends in Cognitive Sciences,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "A dual coordinate descent method for large-scale linear SVM", "author": ["C.-J. Hsieh", "K.-W. Chang", "C.-J. Lin", "S.S. Keerthi", "S. Sundararajan"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Complex cell pooling and the statistics of natural", "author": ["A. Hyv\u00e4rinen", "U. K\u00f6ster"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Learning invariant features through topographic filter maps. Computer Vision and Pattern Recognition", "author": ["K. Kavukcuoglu", "M. Ranzato", "R. Fergus"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Learning convolutional feature hierarchies for visual recognition", "author": ["K. Kavukcuoglu", "P. Sermanet", "Y.-l. Boureau", "K. Gregor", "M. Mathieu", "Y. LeCun"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Natural Image Statistics and Neural Representation", "author": ["E. Simoncelli", "B. Olshausen"], "venue": "Annual Review of Neuroscience,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2001}, {"title": "Region covariance: A fast descriptor for detection and classification", "author": ["O. Tuzel", "F. Porikli", "P. Meer"], "venue": "European Conference on Computer Vision (ECCV),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}, {"title": "Sun database: Largescale scene recognition from abbey to zoo", "author": ["J. Xiao", "J. Hays", "K. Ehinger"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Articulated pose estimation with flexible mixtures-of-parts", "author": ["Y. Yang", "D. Ramanan"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Face recognition across pose: A review", "author": ["X. Zhang", "Y. Gao"], "venue": "Pattern Recognition,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Do We Need More Training Data or Better Models for Object Detection", "author": ["X. Zhu", "C. Vondrick", "D. Ramanan", "C. Fowlkes"], "venue": "British Machine Vision Conference (BMVC),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}], "referenceMentions": [{"referenceID": 4, "context": "When HOG features were introduced, they improved upon existing methods for pedestrian detection by an order of magnitude [5].", "startOffset": 121, "endOffset": 124}, {"referenceID": 8, "context": "Since then, the HOG-SVM pipeline has been used in the deformable parts model of [9], its derivatives, and high achievers of the PASCAL VOC challenge.", "startOffset": 80, "endOffset": 83}, {"referenceID": 4, "context": "HOG is now complicit in detection pipelines across almost every visual detection/classification task [5, 7, 20, 21].", "startOffset": 101, "endOffset": 115}, {"referenceID": 6, "context": "HOG is now complicit in detection pipelines across almost every visual detection/classification task [5, 7, 20, 21].", "startOffset": 101, "endOffset": 115}, {"referenceID": 19, "context": "HOG is now complicit in detection pipelines across almost every visual detection/classification task [5, 7, 20, 21].", "startOffset": 101, "endOffset": 115}, {"referenceID": 20, "context": "HOG is now complicit in detection pipelines across almost every visual detection/classification task [5, 7, 20, 21].", "startOffset": 101, "endOffset": 115}, {"referenceID": 7, "context": "This type of representation has proven particularly successful at being tolerant to non-rigid changes in object geometry whilst maintaining high selectivity [8].", "startOffset": 157, "endOffset": 160}, {"referenceID": 0, "context": "Second, there are proponents of the squaring function (referred to as \u201csquare\u201d or \u201cL2\u201d pooling) in convolutional network literature [1, 14], whose architectures have a similar pipeline to HOG features per layer, and have shown exciting results on large-scale visual recognition challenges [16].", "startOffset": 132, "endOffset": 139}, {"referenceID": 13, "context": "Second, there are proponents of the squaring function (referred to as \u201csquare\u201d or \u201cL2\u201d pooling) in convolutional network literature [1, 14], whose architectures have a similar pipeline to HOG features per layer, and have shown exciting results on large-scale visual recognition challenges [16].", "startOffset": 132, "endOffset": 139}, {"referenceID": 15, "context": "Second, there are proponents of the squaring function (referred to as \u201csquare\u201d or \u201cL2\u201d pooling) in convolutional network literature [1, 14], whose architectures have a similar pipeline to HOG features per layer, and have shown exciting results on large-scale visual recognition challenges [16].", "startOffset": 289, "endOffset": 293}, {"referenceID": 12, "context": "Finally, the square function has a good basis in statistical models of the primary visual cortex [13].", "startOffset": 97, "endOffset": 101}, {"referenceID": 2, "context": "Following the notation of [3], the transform from pixels to output in HOG features can be written as,", "startOffset": 26, "endOffset": 29}, {"referenceID": 5, "context": "where a vectorized input image x \u2208 R is convolved with an oriented edge filter gf [6], rectified through the Hadamard operator (pointwise square), then finally blurred with b and downsampled by the sparse selection matrix D to achieve pooling/histogramming.", "startOffset": 82, "endOffset": 85}, {"referenceID": 2, "context": "We showed previously in [3] that each sub-descriptor can be expressed in the form,", "startOffset": 24, "endOffset": 27}, {"referenceID": 18, "context": "[19] showed that the covariance of a local image distribution is often enough to discriminate it from other distributions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] circumvent this problem by assuming stationarity of background image statistics (a translated image is still an image), as well as limiting the bandwidth of interactions between pixels.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Simoncelli [18] showed that these assumptions are reasonable, since correlations between pixels fall quickly with distance (see Figure 2).", "startOffset": 11, "endOffset": 15}, {"referenceID": 17, "context": "Class B represents a noise distribution which has the same frequency spectrum as natural images, namely 1 f [18].", "startOffset": 108, "endOffset": 112}, {"referenceID": 10, "context": "Learned Features: It is the firm belief of many that learned features are the way forward [11].", "startOffset": 90, "endOffset": 94}, {"referenceID": 14, "context": "Convolutional network literature has heavily relied on learned features for a number of years already [15, 17].", "startOffset": 102, "endOffset": 110}, {"referenceID": 16, "context": "Convolutional network literature has heavily relied on learned features for a number of years already [15, 17].", "startOffset": 102, "endOffset": 110}, {"referenceID": 8, "context": "[9] with 18 orientations and a spatial aggregation size of 4.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Contrast Normalization: So far we have neglected to mention contrast normalization, the final stage in the HOG feature extraction pipeline, and a component that has traditionally received much attention, particularly in neuroscience literature [4].", "startOffset": 244, "endOffset": 247}, {"referenceID": 1, "context": "To train on such a large amount of data, we implemented a parallel support vector machine [2] with a dual coordinate descent method as the main solver [12].", "startOffset": 90, "endOffset": 93}, {"referenceID": 11, "context": "To train on such a large amount of data, we implemented a parallel support vector machine [2] with a dual coordinate descent method as the main solver [12].", "startOffset": 151, "endOffset": 155}, {"referenceID": 22, "context": "[23] talk about the saturation of HOG at length, noting that more data sometimes decreases its performance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Synthesizing variation used to be quite popular in some vision circles, particularly face recognition through the use of AAMs [22], however it seems to have gone out of fashion in object recognition.", "startOffset": 126, "endOffset": 130}, {"referenceID": 2, "context": "Expanding on the work of [3], we showed that HOG features can be reformulated as an affine weighting on the margin of a quadratic kernel SVM.", "startOffset": 25, "endOffset": 28}], "year": 2014, "abstractText": "Linear Support Vector Machines trained on HOG features are now a de facto standard across many visual perception tasks. Their popularisation can largely be attributed to the step-change in performance they brought to pedestrian detection, and their subsequent successes in deformable parts models. This paper explores the interactions that make the HOG-SVM symbiosis perform so well. By connecting the feature extraction and learning processes rather than treating them as disparate plugins, we show that HOG features can be viewed as doing two things: (i) inducing capacity in, and (ii) adding prior to a linear SVM trained on pixels. From this perspective, preserving second-order statistics and locality of interactions are key to good performance. We demonstrate surprising accuracy on expression recognition and pedestrian detection tasks, by assuming only the importance of preserving such local second-order interactions.", "creator": "LaTeX"}}}