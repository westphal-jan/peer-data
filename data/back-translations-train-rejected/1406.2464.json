{"id": "1406.2464", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2014", "title": "Music and Vocal Separation Using Multi-Band Modulation Based Features", "abstract": "The potential use of non-linear speech features has not been investigated for music analysis although other commonly used speech features like Mel Frequency Ceptral Coefficients (MFCC) and pitch have been used extensively. In this paper, we assume an audio signal to be a sum of modulated sinusoidal and then use the energy separation algorithm to decompose the audio into amplitude and frequency modulation components using the non-linear Teager-Kaiser energy operator. We first identify the distribution of these non-linear features for music only and voice only segments in the audio signal in different Mel spaced frequency bands and show that they have the ability to discriminate. The proposed method based on Kullback-Leibler divergence measure is evaluated using a set of Indian classical songs from three different artists. Experimental results show that the discrimination ability is evident in certain low and mid frequency bands (200 - 1500 Hz).", "histories": [["v1", "Tue, 10 Jun 2014 08:29:58 GMT  (103kb,D)", "http://arxiv.org/abs/1406.2464v1", "5 pages, 5 figures, 2010 IEEE Symposium on Industrial Electronics Applications (ISIEA)"]], "COMMENTS": "5 pages, 5 figures, 2010 IEEE Symposium on Industrial Electronics Applications (ISIEA)", "reviews": [], "SUBJECTS": "cs.SD cs.AI", "authors": ["sunil kumar kopparapu", "meghna pandharipande", "g sita"], "accepted": false, "id": "1406.2464"}, "pdf": {"name": "1406.2464.pdf", "metadata": {"source": "CRF", "title": "Music and Vocal Separation Using Multi-Band Modulation Based Features", "authors": ["Sunil Kumar Kopparapu", "Meghna Pandharipande"], "emails": ["Meghna.Pandharipande}@TCS.Com"], "sections": [{"heading": null, "text": "In fact, it is such that most of them are able to survive themselves without there being a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is a process in which there is"}, {"heading": "II. MODULATION BASED FEATURE EXTRACTION", "text": "The audio signal x (t) is a non-linear, temporally varying, and can be considered an AM FM model (as mentioned in [13]) x (t) = a (t) cos (\u03c6 (t)))) (1), where a (t) is the time of varying amplitude and \u03c6 (t) is defined (as mentioned in [13]) x (t) = a (t) cos (t), where a (t) is the maximum frequency deviation from the spectral, | q (t) | p (t) and p (0) is some arbitrary constant phase equalization. The angular frequency of speech varying over time is defined as asoral (t) def = d) dt (t) = dt (t) = the frequency of speech is (t) = c (3) Note that (1) has both an AM and an FM signal, which we call x (t) an AM signal FM."}, {"heading": "III. EXPERIMENTAL RESULTS AND DISCUSSION", "text": "We used the various audio segments (with a total length of about 475 s of the audio stream) to filter the audio into the first three bands. For each of these filtered signals we calculated the non-linear instantaneous features. We limited our analysis to the bottom three filter bands as in our preliminary investigations, we found that the discriminatory power in these three bands is evident."}, {"heading": "IV. CONCLUSIONS", "text": "The use of non-linear speech characteristics has not been used for music and speech classification until now, although it has been used in some areas of speech recognition and speaker identification. In this paper, we used the instantaneous frequency calculated using band-filtered speech signals to distinguish speech from voice. We initially assumed a sum of modulated sinusoidal models for audio signals and investigated the performance of instantaneous frequency modulation characteristics in distinguishing speech and music segments. We used gabor filters to limit the analysis to a limited number of carrier frequencies, which are nothing more than the mid frequencies of bandpass filters. We first observed that the distribution of the instantaneous frequency characteristic across three bands (centered on 240, 738 and 1361) is able to distinguish voice from music. This observation was used to classify the audio stream in music and voice segments."}, {"heading": "ACKNOWLEDGMENT", "text": "The authors would like to thank the members of TCS Innovation Labs - Mumbai for the great working environment."}], "references": [{"title": "Locating singing voice segments to improve artist classification of music", "author": ["A.L. Berenzweig", "D.P.W. Ellis"], "venue": "pp. 21\u201324, Oct. 2001.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2001}, {"title": "Singer identification in popular music recordings using voice coding features", "author": ["Y.E. Kim", "B. Whitman"], "venue": "in Proc. 5th International Conf. on Music Information Retrieval, Nagoya, Japan, Oct. 2004.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Swara indentification for South Indian classical music", "author": ["R. Sridhar", "T.V. Geetha"], "venue": "ICIT Proceedings of the 9th International Conference on Information Technology. IEEE Computer Society, 2006, pp. 143\u2013144.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Vocal detection in music with support vector machines", "author": ["G.R. Mathieu Ramona", "B.David"], "venue": "Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference, 2008, pp. 1885\u2013 1888.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Speech-music segmentation system for speech recognition", "author": ["C. Demir", "M. Dogan"], "venue": "Signal Processing and Communications Applications Conference, 2009. SIU 2009. IEEE 17th, 2009, pp. 624\u2013627.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Feature extraction for speech and music discrimination", "author": ["J.R. Huiyu Zhou", "Sadka A.", "B. Univ."], "venue": "Content-Based Multimedia Indexing, 2008. CBMI 2008. International Workshop, 2008, pp. 170\u2013173.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "On-line speech/music segmentation for broadcast news domain", "author": ["M.V.D. Kos", "M. Grasic", "Z K."], "venue": "Systems, Signals and Image Processing, 2009. IWSSIP 2009. 16th International Conference, 2009, pp. 1\u20134.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "A robust and computationally efficient speech/music discriminator", "author": ["L. Barbedo", "Jayme Garcia Arnal", "Amauri"], "venue": "New Paltz,NY, pp. 571\u2013 588, 2006.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "A wavelet-based parameterization for speech/music discrimination", "author": ["D.F.E. Didiot", "I. Illina", "O.M. Loria"], "venue": "Computer Speech and Language Volume 24, Issue 2, 2010, pp. 341\u2013357.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Am-fm separation using auditory-motivated filters", "author": ["T.F. Quatieri", "T.E. Hanna", "G.C. O-Leary"], "venue": "IEEE Trans. Speech and Audio Proc., vol. 5, pp. 465\u2013480, Sep. 1997.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1997}, {"title": "Information Transmission, Modulation, and Noise", "author": ["M. Schwartz"], "venue": "New York: McGraw-Hill,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1980}, {"title": "Nonlinear Analyses and Algorithms for Speech Processing, International Conference on Non-Linear Speech Processing, NOLISP", "author": ["M. Fa\u00fandez-Zanuy", "L. Janer-Garc\u0131\u0301a", "A. Esposito", "A. Satu\u00e9-Villar", "J. Roure", "V. Espinosa-Duro", "Eds"], "venue": "Revised Selected Papers, ser. Lecture Notes in Computer Science,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Energy separation in signal modulations with applications to speech analysis", "author": ["P. Maraso", "J.F. Kaiser", "T.F. Quatieri"], "venue": "IEEE Trans. Signal Proc., vol. 41, pp. 3024\u20133051, 1993.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1993}, {"title": "Speaker identification based on nonlinear speech models", "author": ["S. Wenndt", "S. Shamsander"], "venue": "in 29th Asilomar Conference on Signals, Systems and Computers, 1995, p. 1031.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1995}, {"title": "Vocal fold pathology assessment using am auto-correlation analysis of the teager energy operator", "author": ["L.G.C. John", "J.H.L. Hansen", "J.F. Kaiser"], "venue": "in Fourth Int. Conf. Spoken Language, vol. 2, 1996, pp. 757 \u2013 760.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1996}, {"title": "Emotion classification of mandarin speech based on teo nonlinear features", "author": ["G. Hui", "C. Shanguang", "S. Guangchuan"], "venue": "Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing, ACIS International Conference on, vol. 3, pp. 394\u2013398, 2007.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Continuous energy demodulation methods and application to speech analysis", "author": ["D. Dimitriadis", "P. Maragos"], "venue": "Speech Communication, vol. 48, pp. 819\u2013837, 2006.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "Robust am-fm features for speech recognition", "author": ["D. Dimitriadis", "P. Maragos", "A. Potamianos"], "venue": "IEEE Signal Process. Lett., vol. 12, pp. 621\u2013 624, 2005.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Nonlinear feature based classification of speech under stress", "author": ["J.H.H. Guojun Zhou", "J.F. Kaiser"], "venue": "IEEE Trans. Signal Proc., vol. 9, p. 203, March 2001.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2001}, {"title": "Frequency distribution based weighted sub-band approach for classification of emotional/stressful content in speech", "author": ["R. Mandar", "H. John"], "venue": "in EUROSPEECH-2003, 2003, pp. 721\u2013724.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Early work in this area includes the work carried out by Berenzweig and Ellis [1] where they suggest the use of an", "startOffset": 78, "endOffset": 81}, {"referenceID": 1, "context": "Kim and Whitman [2] filter the audio signal using a bandpass filter and then used hormonicity as a measure to detect vocal regions and separate them from music.", "startOffset": 16, "endOffset": 19}, {"referenceID": 2, "context": "More recently, Sridhar and Geetha [3], identified swaras in South Indian classical", "startOffset": 34, "endOffset": 37}, {"referenceID": 3, "context": "Ramona et al [4] use support vector machine to separate singing voice from pure instrumental region while Demir and others [5] use hidden Markov model (HMM) based acoustic models to", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "Ramona et al [4] use support vector machine to separate singing voice from pure instrumental region while Demir and others [5] use hidden Markov model (HMM) based acoustic models to", "startOffset": 123, "endOffset": 126}, {"referenceID": 5, "context": "Zhou [6] discriminates voice and music using novel spectral feature like averaged cepstrum.", "startOffset": 5, "endOffset": 8}, {"referenceID": 6, "context": "and Kos et al [7] on-line segment speech music for broadcast news domain using Mel-Frequency Cepstral Coefficients Variance (MFCCV).", "startOffset": 14, "endOffset": 17}, {"referenceID": 7, "context": "Barbedo and others [8] propose a mechanism to discriminate speech and music signal by extracting four features and then combining them linearly into a unique parameter.", "startOffset": 19, "endOffset": 22}, {"referenceID": 8, "context": "Didiot [9] propose a wavelet based signal decomposition instead of Fourier Transform for discriminating speech and", "startOffset": 7, "endOffset": 10}, {"referenceID": 9, "context": "Modulation of the amplitude and/or frequency of a sine wave has been used extensively in communication systems for transmitting information [10], [11].", "startOffset": 140, "endOffset": 144}, {"referenceID": 10, "context": "Modulation of the amplitude and/or frequency of a sine wave has been used extensively in communication systems for transmitting information [10], [11].", "startOffset": 146, "endOffset": 150}, {"referenceID": 11, "context": "Use of nonlinear analysis for speech processing [12] has of late received attention specifically for speaker recogni-", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "proposed by Quatieri et al [10] and Teager energy based algorithms proposed by Dimitrios et al [13].", "startOffset": 27, "endOffset": 31}, {"referenceID": 12, "context": "proposed by Quatieri et al [10] and Teager energy based algorithms proposed by Dimitrios et al [13].", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": "Features derived using non-linear speech framework could reveal the potential of alternative speech models in various speech applications such as speaker identification [14], vocal fold pathology assessment", "startOffset": 169, "endOffset": 173}, {"referenceID": 14, "context": "[15] and even emotion classification [16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[15] and even emotion classification [16].", "startOffset": 37, "endOffset": 41}, {"referenceID": 16, "context": "Dimitrios et al [17] have used these AM-FM features for phoneme classification and speech recognition tasks [18].", "startOffset": 16, "endOffset": 20}, {"referenceID": 17, "context": "Dimitrios et al [17] have used these AM-FM features for phoneme classification and speech recognition tasks [18].", "startOffset": 108, "endOffset": 112}, {"referenceID": 12, "context": "In this paper, we use Teager energy based algorithm [13] to", "startOffset": 52, "endOffset": 56}, {"referenceID": 12, "context": "Audio signal x(t) is non-linear, time-varying and can be looked upon as a AM-FM model as follows (as mentioned in [13])", "startOffset": 114, "endOffset": 118}, {"referenceID": 17, "context": "It has been shown that this non-linear modeling of speech helps in extraction of robust features for speech [18].", "startOffset": 108, "endOffset": 112}, {"referenceID": 9, "context": "Such AM-FM signals are very frequently used in communication systems [10].", "startOffset": 69, "endOffset": 73}, {"referenceID": 9, "context": "One of the ways to estimate a(t) and \u03c9i(t), is to first isolate individual resonance by bandpass filtering the speech signal around its formants and then estimating amplitude and frequency modulating signals of each resonance based on an \u201denergy-tracking operator\u201d as described in [10].", "startOffset": 281, "endOffset": 285}, {"referenceID": 18, "context": "In the discrete form as is applicable to most speech processing systems [19] (5) can be written as", "startOffset": 72, "endOffset": 76}, {"referenceID": 12, "context": "\u03c8 is the main ingredient of the first Energy Separation Algorithm (ESA) developed in [13] and used for signal and speech AM-FM demodulation.", "startOffset": 85, "endOffset": 89}, {"referenceID": 12, "context": "In practice the speech signal is bandpass filtered using Gabor filters because of their optimal time-frequency discriminability [13], namely, s (t) = x (t) \u2217 g (t) (10)", "startOffset": 128, "endOffset": 132}, {"referenceID": 16, "context": "instantaneous amplitude and instantaneous frequencies around different resonance frequencies of the speech signal have been studied for various applications in speech processing area such as phoneme classification, speech recognition [17], [18], assessment of vocal fold pathology [15], stress detection [20].", "startOffset": 234, "endOffset": 238}, {"referenceID": 17, "context": "instantaneous amplitude and instantaneous frequencies around different resonance frequencies of the speech signal have been studied for various applications in speech processing area such as phoneme classification, speech recognition [17], [18], assessment of vocal fold pathology [15], stress detection [20].", "startOffset": 240, "endOffset": 244}, {"referenceID": 14, "context": "instantaneous amplitude and instantaneous frequencies around different resonance frequencies of the speech signal have been studied for various applications in speech processing area such as phoneme classification, speech recognition [17], [18], assessment of vocal fold pathology [15], stress detection [20].", "startOffset": 281, "endOffset": 285}, {"referenceID": 19, "context": "instantaneous amplitude and instantaneous frequencies around different resonance frequencies of the speech signal have been studied for various applications in speech processing area such as phoneme classification, speech recognition [17], [18], assessment of vocal fold pathology [15], stress detection [20].", "startOffset": 304, "endOffset": 308}, {"referenceID": 16, "context": "use the Mel spaced Gabor filter-bank [17] to filter the audio into the first three bands.", "startOffset": 37, "endOffset": 41}], "year": 2014, "abstractText": "The potential use of non-linear speech features has not been investigated for music analysis although other commonly used speech features like Mel Frequency Ceptral Coefficients (MFCC) and pitch have been used extensively. In this paper, we assume an audio signal to be a sum of modulated sinusoidal and then use the energy separation algorithm to decompose the audio into amplitude and frequency modulation components using the non-linear Teager-Kaiser energy operator. We first identify the distribution of these non-linear features for music only and voice only segments in the audio signal in different Mel spaced frequency bands and show that they have the ability to discriminate. The proposed method based on Kullback-Leibler divergence measure is evaluated using a set of Indian classical songs from three different artists. Experimental results show that the discrimination ability is evident in certain low and mid frequency bands (200 1500 Hz).", "creator": "LaTeX with hyperref package"}}}