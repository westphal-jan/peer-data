{"id": "1406.6130", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2014", "title": "Generalized Mixability via Entropic Duality", "abstract": "Mixability is a property of a loss which characterizes when fast convergence is possible in the game of prediction with expert advice. We show that a key property of mixability generalizes, and the exp and log operations present in the usual theory are not as special as one might have thought. In doing this we introduce a more general notion of $\\Phi$-mixability where $\\Phi$ is a general entropy (\\ie, any convex function on probabilities). We show how a property shared by the convex dual of any such entropy yields a natural algorithm (the minimizer of a regret bound) which, analogous to the classical aggregating algorithm, is guaranteed a constant regret when used with $\\Phi$-mixable losses. We characterize precisely which $\\Phi$ have $\\Phi$-mixable losses and put forward a number of conjectures about the optimality and relationships between different choices of entropy.", "histories": [["v1", "Tue, 24 Jun 2014 03:31:16 GMT  (231kb,D)", "http://arxiv.org/abs/1406.6130v1", "20 pages, 1 figure. Supersedes the work inarXiv:1403.2433[cs.LG]"]], "COMMENTS": "20 pages, 1 figure. Supersedes the work inarXiv:1403.2433[cs.LG]", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mark d reid", "rafael m frongillo", "robert c williamson", "nishant mehta"], "accepted": false, "id": "1406.6130"}, "pdf": {"name": "1406.6130.pdf", "metadata": {"source": "CRF", "title": "Generalized Mixability via Entropic Duality", "authors": ["Mark D. Reid", "Rafael M. Frongillo", "Robert C. Williamson", "Nishant Mehta"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "The combination or aggregation of predictions is central to machine learning. Traditional Bayesian updates can be seen as a special way of aggregating information that takes into account previous information. Notions of \"mixability,\" which play a key role in predicting with expert advice, provide a more general way to aggregate by incorporating a loss function to evaluate predictions. Vovk [1] has shown that its more general \"aggregation algorithm\" reduces to Bayesian updates when using log losses. However, there is an implicit design variable in the mixability that has not been fully utilized so far. The aggregation algorithm utilizes a distance between the current distribution and a previous one that serves as a regulator. Specifically, the aggregation algorithm uses KL divergence. We consider the general setting of an arbitrary loss and an arbitrary generalization algorithm (we can reproduce a technical divergence in the result) to be more generalized."}, {"heading": "1.1 Mixability in Prediction With Expert Advice Games", "text": "A prediction with expert advice is defined by the loss, a collection of experts that the player must compete against, and a fixed number of rounds. In each round, the experts reveal their predictions to the player, and then the player makes a prediction. An observation is then revealed to the expert, and the player and all receive a penalty determined by the loss. The goal of the player is to keep his total loss close to the best expert once all rounds are completed. \u2212 The difference between the total loss of the player and the total loss of the best expert is called regret and is the typical focus of the analysis of this style of play. In particular, we are interested in when the regret is constant, that is, regardless of the number of rounds played. \u2212 Formally, X is considered a set of possible observations and allows A to make a series of actions or predictions that the experts and players can make. A loss': A \u2192 RX assigns the penalty to x (a) to make a prediction."}, {"heading": "1.2 Contributions", "text": "The most important contributions of this paper are the following: We provide a new general definition (definition 2) of miscibility and an induced generalized aggregate algorithm (definition 3) and show (theorem 2) that prediction with expert advice using a \u03a6-miscible loss and the associated generalized aggregate algorithm is guaranteed to exhibit constant regret. Evidence shows that the log and Exp functions that arise in the classical aggregate algorithm are not peculiarities in themselves, but rather are a translational invariant property of the convex conjugate and entropy \u03a6, defined on a probability simplex, which is the decisive property that leads to permanent regret. We characterize (theorem 4) for which entropies exist, namely via the Legendre property. We show that the miscibility of a loss is directly related to the Bayes risk, which may best be expressed in terms of the classical situation (which may be expressed in terms of the loss of the theorem)."}, {"heading": "1.3 Related Work", "text": "The starting point for the miscibility and the aggregating algorithm is the work of [3, 2]. The general attitude of the prediction with expert advice is summarized in [4, chapters 2 and 3] where one can find a series of results that examine different aggregation schemes and different assumptions about losses (exp-concave, miscible).The variants of the aggregating algorithm have been studied for classically miscible losses, with a trade-off between the density of bound (in a constant factor) and the computational complexity [6].The weakly miscible losses are a generalization of miscible losses. They have been noted in [7], where there is a variant of the aggregating algorithm, the regret for some constant C. Vovk [1, in \u00a7 2.2] makes the observation that its aggregation algorithm reduces to Bayean mixtures."}, {"heading": "2 Generalized Mixability and Aggregation via Convex Duality", "text": "In this section we present our generalizations of miscibility and aggregation algorithm. A feature of our approach is the way in which the generalized aggregation algorithm falls out of the definition of general miscibility as a mixer of the mixing boundary. Our approach is based on concepts and results from convex analysis. Terms that are not defined below can be found in a reference such as [11]."}, {"heading": "2.1 Definitions and Notation", "text": "A Convexed Function of a Convexed Function of a Convexed Function of a Convexed Function of a Convexed Function of a Convexed Function of a Convexed Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Controlled Contro"}, {"heading": "2.2 \u03a6-Mixability and the Generalized Aggregating Algorithm", "text": "For convenience, we will use \"A\" to denote a collection of expert forecasts and \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" A, \"\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, A, A, \"A, A, A,\" A, \"A, A, A, A, A,\" A, A, A, A, A, A, A, A, A, A, A, A, \"A, A, A,\" A, A, A, A, A, \"A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A,"}, {"heading": "3 Properties of \u03a6-mixability", "text": "In this section, we note a number of key properties of \u03a6 miscibility, the most important of which is that \u03a6 miscibility implies constant regret. We also show that \u03a6 miscibility is not an empty concept for \u03a6, with the exception of Shannon entropy, by showing that every legend \u03a6 is afflicted with \u0438 miscible losses and that this is a necessary condition for the existence of such losses."}, {"heading": "3.1 \u03a6-mixability Implies Constant Regret", "text": "Theorem 2: \"If\" A \u2192 RX \"is not miscible, then there is a family of strategies parameterized by.\" Q, \"which plays a sequence of.\".1 \"for each sequence of observations x1,.., xT \u00b2 -X and sequence of expert predictions A1,.., AT \u00b2 -A. (8) The proof is in Appendix A.2 and is a direct sequence of.\" 2 \"and the translation invariance of.\" 2. \"The standard concept of miscibility is restored when.\" H \"for.\" 0 andH \"for.\" 0 andH \"the Shannon entropy to.\" D. \"In this case, Theorem 1 becomes a sequence of.\" X \"and.\" 11, the uniform distribution over. \"D.\""}, {"heading": "3.2 \u03a6-Mixability of Proper Losses and Their Bayes Risks", "text": "Entropies are known to be closely associated with the Bayes risk, which is referred to as correct losses or correct rules of value. [15, 16] Here are the predictions distributions of the results, i.e., the points in \"X.\" To emphasize this, we will use p, p and P instead of a, a and A. When a loss is used to designate actions, \"x, p and RX will be used to assign a penalty\" x (p) to aprediction p. \"(p) > It is said that its expected value is minimized below x, p and A. That is, for all p, p and x we haveEx-p.\" (p) = < p, p) > p. \"(p) > F.\" (p) > F. \"is the Bayes is the Bayes risk of\" and is necessarily concave [5], thereby F. \""}, {"heading": "3.3 Characterizing and Comparing \u03a6-mixability", "text": "Although Theorem 2 restores the already known constant regret about Shannonmixable losses, it is natural to ask whether the result for other entropies is empty or not. The next theorem answers these two questions by showing that the existence of \"non-trivial,\" \"miscible\" losses for others other than Shannon entropy is closely related to the behavior of the gradient of an entropy at the border of simplicity. Specifically, it states that an entropy is \"legendary\" [21] when: a) \"non-trivial,\" \"non-miscible\" losses exist, and b) that mixtures exist \"when these losses exist for each microb at the border of entropy.\" We will say that a loss is not trivial if there are clear actions that are optimal for different outcomes (see A.4 for formal definition)."}, {"heading": "4 Conclusions and Open Questions", "text": "The main purpose of this work was to shed new light on miscibility by inserting it into the broader concept of \"miscibility,\" showing that the constant limits of regret that mixing losses exhibit are due to the translation immutability of entropic duals.2 Inequality in (4) is reduced to 0 \u2264 inf\u00b5 \u2032 D\u0445 (\u00b5, \"\u00b5), which is true of all Bregman divergences and therefore also applies to any\" mixable \"loss.The definitions and technical mechanisms presented here allow us to ask precise questions about entropies and the optimality of their associated aggregate algorithms."}, {"heading": "4.1 Are All Legendre Entropies \u201cEquivalent\u201d?", "text": "Since Theorem 4 shows the existence of \u03a6-miscible losses, a natural question concerns the relationship between the loss quantities that are miscible for different options of \u03a6. For example: Are there losses that are H-miscible but not S\u03b1-miscible, or vice versa? We suspect that essentially all legendary entropies \u00b2 have the same and miscible losses up to a scalable factor. Guesstimate 1: Let's be an entropy on \u0445 and \"be a \u0445-miscible loss.\" If \"legendary entropy\" is on \u0445, then there is a \u03b7 > 0 that is such that \"\u03b7 \u2212 1\u0445-miscible.\" This means that the scaling of these losses is derived from the observation that mixings, \"x = \u03b7 \u2212 1 Mix\u0438,\" xand that the function \u03b7 > 0 behaves like a constant loss and will therefore be miscible. This means that \"make mixing larger than\" this one, but it should be \u2212 in reality."}, {"heading": "4.2 Asymptotic Behaviour", "text": "There is a lower limit due to Vovk [3] for general losses, \"indicating that if one is allowed to vary the number of rounds T and the number of experts K = | \u0432 |, then no limit of regret can be better than the optimal limit of regret reached by the mixability with Shannon. Specifically, for a set loss\" with optimal mixability with Shannon constant probability, \"we assume that in some cases we have a limit of regret between form (logK) and dependence on K, as well as a strategy L for the learner that supposedly meets this limit of regret. Vovk's lower limit indicates that for these two cases there is an instantiation of prediction with expert guessing game with T that is large enough and K approximately exponentially in T (and both are still limited), for which the alleged regret is limited at the end of the game cannot hold, with a probability of not zero. The regime in which Vovk's e limit logically indicates that the best atable limit is the number of regrettable in the game."}, {"heading": "4.3 Is There An \u201cOptimal\u201d Entropy?", "text": "Since we believe that \"the miscibility for Legendre\" can yield the same amount of losses (so we can ask if, for a fixed loss, \"some\" have better regret limits than others. \"These limits collectively depend on the greatest\" miscibility, \"which is\" miscible \"and has the value of\" regret. \"However, we can say that one entropy dominates another when its optimal regret for a particular loss is better.\" Relying on the definition of the maximum miscibility constant of Lemma 4, we can determine a quantity of more direct interest: the best regret can be obtained with a scaled copy of. \"Recall that\" is the best miscibility, then one can obtain the best miscibility from an algorithm. \""}, {"heading": "Acknowledgments", "text": "We would like to thank Matus Telgarsky for helping with constrained duals, Brendan van Rooyen for stating that there are no square, miscible losses, and Harish Guruprasad for identifying an error in an earlier \"proof\" of quasi-convexity of proper losses. Mark Reid is supported by an ARC Discovery Early Career Research Award (DE130101605) and part of this work was developed during his visit to Microsoft Research. NICTA is funded by the Australian government and as the ARC ICT Centre of Excellence."}, {"heading": "A Appendix", "text": "To show this, we must point out that the definition of the dual system (v + p) + p (p) + p (p) + p (p) = p) p (p) p (p) p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p. \"p\" p \"p\" p \"p\" p \"p.\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p."}], "references": [{"title": "Competitive on-line statistics", "author": ["Volodya Vovk"], "venue": "International Statistical Review,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Aggregating strategies", "author": ["Volodya Vovk"], "venue": "Proceedings of the Third Annual Workshop on Computational Learning Theory (COLT),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1990}, {"title": "A game of prediction with expert advice", "author": ["Volodya Vovk"], "venue": "In Proceedings of the Eighth Annual Conference on Computational Learning Theory,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1995}, {"title": "Prediction, learning, and games", "author": ["Nicolo Cesa-Bianchi"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Mixability is bayes risk curvature relative to log loss", "author": ["Tim van Erven", "Mark D Reid", "Robert C Williamson"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Averaging expert predictions", "author": ["Jyrki Kivinen", "Manfred K Warmuth"], "venue": "In Computational Learning Theory,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "The weak aggregating algorithm and weak mixability", "author": ["Yuri Kalnishkan", "Michael V. Vyugin"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Exponentiated gradient versus gradient descent for linear predictors", "author": ["Jyrki Kivinen", "Manfred K Warmuth"], "venue": "Information and Computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "Relative loss bounds for on-line density estimation with the exponential family of distributions", "author": ["Katy S Azoury", "Manfred K Warmuth"], "venue": "Machine Learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "Mirror descent and nonlinear projected subgradient methods for convex optimization", "author": ["Amir Beck", "Marc Teboulle"], "venue": "Operations Research Letters,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Fundamentals of convex analysis", "author": ["J.B. Hiriart-Urruty", "C. Lemar\u00e9chal"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "Comparison of shannon, renyi and tsallis entropy used in decision trees", "author": ["Tomasz Maszczyk", "W\u0142odzis\u0142aw Duch"], "venue": "In Artificial Intelligence and Soft Computing\u2013", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "R\\\u2019enyi divergence and kullback-leibler divergence", "author": ["Tim Van Erven", "Peter Harremo\u00ebs"], "venue": "arXiv preprint arXiv:1206.2459,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Bayesian conditionalisation and the principle of minimum information", "author": ["Peter M Williams"], "venue": "British Journal for the Philosophy of Science,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1980}, {"title": "The geometry of proper scoring rules", "author": ["A Philip Dawid"], "venue": "Annals of the Institute of Statistical Mathematics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Strictly proper scoring rules, prediction, and estimation", "author": ["Tilmann Gneiting", "Adrian E Raftery"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Composite multiclass losses", "author": ["Elodie Vernet", "Robert C Williamson", "Mark D Reid"], "venue": "In NIPS,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Elicitation of personal probabilities and expectations", "author": ["Leonard J Savage"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1971}, {"title": "Stochastic finance, volume 27 of de gruyter studies", "author": ["Hans F\u00f6llmer", "Alexander Schied"], "venue": "in mathematics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "Sequential prediction of individual sequences under general loss functions", "author": ["David Haussler", "Jyrki Kivinen", "Manfred K Warmuth"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}, {"title": "Convex analysis", "author": ["R.T. Rockafellar"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1997}], "referenceMentions": [{"referenceID": 0, "context": "As shown by Vovk [1], his more general \u201caggregating algorithm\u201d reduces to Bayesian updating when log loss is used.", "startOffset": 17, "endOffset": 20}, {"referenceID": 1, "context": "In [2, 3], Vovk showed that if the loss for a game satisfies a condition called mixability then a player making predictions using the aggregating algorithm (AA) will achieve constant regret.", "startOffset": 3, "endOffset": 9}, {"referenceID": 2, "context": "In [2, 3], Vovk showed that if the loss for a game satisfies a condition called mixability then a player making predictions using the aggregating algorithm (AA) will achieve constant regret.", "startOffset": 3, "endOffset": 9}, {"referenceID": 2, "context": "Theorem 1 (Mixability implies constant regret [3]).", "startOffset": 46, "endOffset": 49}, {"referenceID": 4, "context": "We show that \u03a6-mixability of a loss can be expressed directly in terms of the Bayes risk associated with the loss (Definition 4 and Theorem 3), reflecting the situation that holds for classical mixability [5].", "startOffset": 205, "endOffset": 208}, {"referenceID": 2, "context": "The starting point for mixability and the aggregating algorithm is the work of [3, 2].", "startOffset": 79, "endOffset": 85}, {"referenceID": 1, "context": "The starting point for mixability and the aggregating algorithm is the work of [3, 2].", "startOffset": 79, "endOffset": 85}, {"referenceID": 5, "context": "Variants of the aggregating algorithm have been studied for classically mixable losses, with a trade-off between tightness of the bound (in a constant factor) and the computational complexity [6].", "startOffset": 192, "endOffset": 195}, {"referenceID": 6, "context": "They have been studied in [7] where it is shown there exists a variant of the aggregating algorithm that achieves regret C \u221a T for some constant C.", "startOffset": 26, "endOffset": 29}, {"referenceID": 7, "context": "The general form of updating we propose is similar to that considered by Kivinen and Warmuth [8] who consider finding a vector w minimizing d(w, s) + \u03b7L(yt, w \u00b7xt) where s is some starting vector, (xt, yt) is the instance/label observation at round t and L is a loss.", "startOffset": 93, "endOffset": 96}, {"referenceID": 9, "context": "The analysis of mirror descent [10] shows that it achieves constant regret when the entropic regularizer is", "startOffset": 31, "endOffset": 35}, {"referenceID": 3, "context": "See for example the discussion of potential based methods in [4] and other references later in the paper.", "startOffset": 61, "endOffset": 64}, {"referenceID": 10, "context": "Terms not defined below can be found in a reference such as [11].", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "[12, 13]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 12, "context": "[12, 13]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 10, "context": "[11]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "For differentiable \u03a6, it is known [11] that the supremum defining \u03a6\u2217 is attained at \u03bc = \u2207\u03a6\u2217(v).", "startOffset": 34, "endOffset": 38}, {"referenceID": 13, "context": "In the special case when \u03a6 is Shannon entropy, ` is log loss, and expert predictions A\u03b8 \u2208 \u2206X are distributions over X such an optimization is equivalent to Bayesian updating [14].", "startOffset": 174, "endOffset": 178}, {"referenceID": 9, "context": "The GAA is therefore closely related to mirror descent techniques [10].", "startOffset": 66, "endOffset": 70}, {"referenceID": 14, "context": "Entropies are known to be closely related to the Bayes risk of what are called proper losses or proper scoring rules [15, 16].", "startOffset": 117, "endOffset": 125}, {"referenceID": 15, "context": "Entropies are known to be closely related to the Bayes risk of what are called proper losses or proper scoring rules [15, 16].", "startOffset": 117, "endOffset": 125}, {"referenceID": 4, "context": "That is, for all p, p\u0302 \u2208 \u2206X we have Ex\u223cp [`x(p\u0302)] = \u3008p, `(p\u0302)\u3009 \u2265 \u3008p, `(p)\u3009 =: \u2212F (p) where \u2212F ` is the Bayes risk of ` and is necessarily concave [5], thus making F ` : \u2206X \u2192 R convex and thus an entropy.", "startOffset": 146, "endOffset": 149}, {"referenceID": 16, "context": "The correspondence also goes the other way: given any convex function F : \u2206X \u2192 R we can construct a unique proper loss [17].", "startOffset": 119, "endOffset": 123}, {"referenceID": 17, "context": "The following representation can be traced back to [18] but is expressed here using convex duality.", "startOffset": 51, "endOffset": 55}, {"referenceID": 4, "context": "This is similar in spirit to the result in [5] which shows that the original mixability (for \u03a6 = H) can be expressed in terms of the relative curvature of Shannon entropy and the loss\u2019s Bayes risk.", "startOffset": 43, "endOffset": 46}, {"referenceID": 18, "context": "Although this definition appears complicated due to the handling of vectors in R and R, it has a natural interpretation in terms of risk measures from mathematical finance [19].", "startOffset": 172, "endOffset": 176}, {"referenceID": 19, "context": "The entropic form of mixability in (10) shares some similarities with expressions for the classical mixability constants given in [20] for binary outcome games and in [5] for general games.", "startOffset": 130, "endOffset": 134}, {"referenceID": 4, "context": "The entropic form of mixability in (10) shares some similarities with expressions for the classical mixability constants given in [20] for binary outcome games and in [5] for general games.", "startOffset": 167, "endOffset": 170}, {"referenceID": 4, "context": "It is also arguably more efficient since the optimization in [5] for non-binary outcomes requires inverting a Hessian matrix at each point in the optimization.", "startOffset": 61, "endOffset": 64}, {"referenceID": 20, "context": "Specifically, an entropy \u03a6 is said to be Legendre [21] if: a) \u03a6 is strictly convex in int(\u2206\u0398); and b) \u2016\u2207\u03a6(\u03bc)\u2016 \u2192 \u221e as \u03bc\u2192 \u03bcb for any \u03bcb on the boundary of \u2206\u0398.", "startOffset": 50, "endOffset": 54}, {"referenceID": 2, "context": "There is a lower bound due to Vovk [3] for general losses ` which shows that if one is allowed to vary the number of rounds T and the number of experts K = |\u0398|, then no regret bound can be better than the optimal regret bound obtained by Shannon mixability.", "startOffset": 35, "endOffset": 38}, {"referenceID": 19, "context": "Indeed, there is a lower bound for general losses ` that shows the regret of the best possible algorithm on games using ` must grow like \u03a9(log2K) [20].", "startOffset": 146, "endOffset": 150}], "year": 2014, "abstractText": "Mixability is a property of a loss which characterizes when fast convergence is possible in the game of prediction with expert advice. We show that a key property of mixability generalizes, and the exp and log operations present in the usual theory are not as special as one might have thought. In doing this we introduce a more general notion of \u03a6-mixability where \u03a6 is a general entropy (i.e., any convex function on probabilities). We show how a property shared by the convex dual of any such entropy yields a natural algorithm (the minimizer of a regret bound) which, analogous to the classical aggregating algorithm, is guaranteed a constant regret when used with \u03a6-mixable losses. We characterize precisely which \u03a6 have \u03a6-mixable losses and put forward a number of conjectures about the optimality and relationships between different choices of entropy.", "creator": "LaTeX with hyperref package"}}}