{"id": "1406.7157", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2014", "title": "An Incentive Compatible Multi-Armed-Bandit Crowdsourcing Mechanism with Quality Assurance", "abstract": "Consider a requester who wishes to crowdsource a series of identical binary labeling tasks from a pool of workers so as to achieve an assured accuracy for each task, in a cost optimal way. The workers are heterogeneous with unknown but fixed qualities and moreover their costs are private. The problem is to select an optimal subset of the workers to work on each task so that the outcome obtained from aggregating labels from them guarantees a target accuracy. This problem is challenging because the requester not only has to learn the qualities of the workers but also elicit their true costs. We develop a novel multi-armed bandit (MAB) mechanism for solving this problem. We propose a framework, {\\em Assured Accuracy Bandit (AAB)}, which leads to an adaptive, exploration separated MAB algorithm, {\\em Strategic Constrained Confidence Bound (CCB-S)}. We derive an upper bound on the number of exploration steps which depends on the target accuracy and true qualities. We show that our CCB-S algorithm produces an ex-post monotone allocation rule which can be transformed into an ex-post incentive compatible and ex-post individually rational mechanism that learns qualities of the workers and guarantees the target accuracy in a cost optimal way.", "histories": [["v1", "Fri, 27 Jun 2014 11:59:47 GMT  (52kb,D)", "https://arxiv.org/abs/1406.7157v1", null], ["v2", "Thu, 9 Oct 2014 06:37:12 GMT  (53kb,D)", "http://arxiv.org/abs/1406.7157v2", null], ["v3", "Wed, 17 Jun 2015 15:18:31 GMT  (700kb,D)", "http://arxiv.org/abs/1406.7157v3", null]], "reviews": [], "SUBJECTS": "cs.GT cs.LG", "authors": ["shweta jain", "sujit gujar", "satyanath bhat", "onno zoeter", "y narahari"], "accepted": false, "id": "1406.7157"}, "pdf": {"name": "1406.7157.pdf", "metadata": {"source": "CRF", "title": "An Incentive Compatible Multi-Armed-Bandit Crowdsourcing Mechanism with Quality Assurance", "authors": ["Shweta Jain", "Sujit Gujar", "Satyanath Bhat", "Onno Zoeter", "Y. Narahari"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Just think of the fact that most of them are able to survive themselves, and that they are able to survive themselves. Most of them are not able to survive themselves, because they are not able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves, because they are able to survive themselves. Most of them are not able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves, because they are not able to survive themselves. Most of them are able to survive themselves. Most of them are able to survive themselves, because they are not able to survive themselves."}, {"heading": "1.1 Contributions", "text": "The above discussion highlights the need to design a new approach to solve the problem of selecting a subset of strategic workers in order to achieve target accuracy in a cost-effective manner. This paper solves such a problem for the first time by modelling this problem within the framework of the multi-armed bandit mechanism. We consider two versions of this problem: (1) a non-strategic version in which the costs are known and the qualities of the workers must be learned, and (2) a strategic version in which the costs must also be truthfully highlighted. In particular, the following are our contributions in this paper. \u2022 We propose a novel framework, Assured Accuracy Bandit (AAB), in which we formulate an optimization problem. \u2022 We offer a lower limit on the regret that any MAB algorithm must suffer within the framework of AAB (Theorem 3.1). We are considering two versions of AAB."}, {"heading": "1.1.1 Organization", "text": "The paper is structured as follows: We present a summary of the relevant work in Section 2. In Section 3, we present a general formulation of the problem. Next, we present our model in two different phases. First, we discuss the non-strategic model in Section 4, and next, in Section 5, we discuss the strategic version using the mechanism design. In Section 6, we provide an extension of the strategic version to a more practical environment, in which we provide conditions under which an approximate solution to the optimization problem can be included and workers in the strategic environment can be eliminated, thereby avoiding higher costs in the exploration steps. In this section, we also compare our algorithm with a variant of the traditional MAB algorithm, namely a money-hungry algorithm through simulations. Future work and conclusions are provided in Section 7."}, {"heading": "2 Related Work", "text": "In fact, it is not that it is a self-representation, as is the case in most other countries. It is not that it is a self-representation, it is not that it is a self-representation, it is that it is a self-representation, it is that it is a self-representation, it is that it is a self-representation, it is that it is a self-representation, it is that it is a self-representation, it is not that it is a self-representation, it is that it is a self-representation, it is that it is a self-representation, it is that it is a self-representation, it is that it is a self-representation, it is that it is a self-representation. It is that it is as if it is a self-representation, it is a self-representation. It is that it is a self-representation, it is a self-representation."}, {"heading": "3 The Model", "text": "By homogeneous or similar binary marking tasks, we mean that the quality of each worker is the same for all tasks. We assume that the workers are not spammers and their service quality is at least 0.5. The quality of each worker i is assumed to be independent of the qualities of other workers. A worker i incurs costs equal to CIS R, which are kept private and can be strategically reported by the workers. Let 1 \u2212 \u03b1 be the target accuracy level (\u03b1 is the threshold level) provided by the applicant, who determines the balance between the costs and accuracy to be achieved for a given task. We consider binary classification tasks where the labels are either zero or one. Our model is summarized in Figure 1.Comments. The error in this task depends on the likelihood that the workers will acquire the following characteristics, which we describe as an abstraction."}, {"heading": "3.1 Error Probability Function", "text": "Let fS (q) be any function that represents the error probability (i.e. (1 \u2212 fS (q)) accuracy) when selecting a set of S with the quality profile q = (q1, q2,..., qn). The problem we are trying to solve in this work is to minimize the cost while at the same time meeting the limitation that fS (q) < \u03b1 is where (1 \u2212 \u03b1) is the target accuracy level. Depending on the aggregation rule and the requirements of the requirement, different error probability functions could be defined. Our framework and solution approach are general and work for any error probability function that fulfills the following properties: \u2022 Monotonicity: The error probability function fS (q) is called monotonous when properties are defined for all quality profiles q and q \u00b2 properties so that, if they are properties that act on a certain probability."}, {"heading": "3.1.1 Examples of error probability functions", "text": "Leave S the selected group of players {1, 2,., s with the quality profile q = q = q (so that q1 \u2264 q2 \u2264 (.), to which we assign a certain task. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 For the assessment of convenience, we drop t and drop y = q = q = q = q = q = q (so that we are by the worker i = 1, 2,. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 P = 1, y = 2, otherwise. (1) y s) the vector of the reported designations from group S. Then the predicted designation y, if a majority voting rule is used as a rule of aggregation, is given by: y = 1, if the convenience i = 0.0, otherwise. (1) Example 3.1 The probability of the most likely result leading to an error is given by [25]: P (q) = max y (S) = max y (S)."}, {"heading": "3.2 Assured Accuracy Bandit (AAB) Framework", "text": "It should be remembered that a task t {1,.., T} must be performed with a certain accuracy, which the applicant provides sequentially at the optimal cost. Therefore, the aim of the applicant is to select for each task t a group of workers St, so that the error probability function is lower than the threshold level. At the same time, the applicant must ensure that the tasks are performed optimally in terms of cost. Therefore, for each task t we must solve the following optimization problem by repeatedly imposing tasks on the workers. Furthermore, in solving the optimization problem, the applicant must ensure that the limitation in (3) regarding the true characteristics of the workers is a priori not known and must therefore be learned."}, {"heading": "3.2.1 Regret in AAB Framework", "text": "The performance of an MAB algorithm is typically measured by the regret it achieves. Regret in a MAB framework is defined as the reward difference between the learning algorithm and the optimal algorithm. We will see later that our algorithm is designed so that for each task t the constraint given by (3) is satisfied with the probability (1 \u2212 \u00b5), where \u00b5 is the confidence parameter with which the constraint is satisfied. Thus, we can define the regret of an algorithm A if the constraint is satisfied with the following conditions: R (A) = T \u2211 t = 1 \u2211 i \u0445 ci \u2212 T \u0445 i \u0432 ci, (4) St is the set selected by algorithm A for task t, S \u0445 is the optimal set with known qualifications. Since the constraint for each task is satisfied with probability (1 \u2212 \u00b5), we can also achieve the overall expected regret by: E [R (A)] = (1 ci) as a restriction to the small constraint on the satisfaction."}, {"heading": "3.3 Lower Bound on the Regret", "text": "We start with an important property called \u2206 \u2212 separated property, which we assume to be a quality profile q = = q = q = q = q = q = q = q = q = q = q = q = q = 2 (= 1) q2 (= 2) q2 (= 1) q2 (= 1) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2) q2 (= 2) q2 (2) q2 = 2 (2) q2 (2) q2 = 2 (2) q2 (2) q2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (= 2) q2) q2 (= 2) q2 (= 2) q2 (= 2) q2) q2 (= 2) q2 (= 2) q2 (2) q2) q2 (= 2) q2 (= 2) q2 (= 2) q2 (2) q2), \"(2) q2 (2) q2),\" (2), \"q2 (2) (2) q2),\" q2 (2) (2) (2) q2) q2 (2), \"(2)."}, {"heading": "3.4 Related MAB Algorithms", "text": "There are different MAB algorithms for different related settings. Here we list the two algorithms that come closest to our setting."}, {"heading": "3.4.1 The UCB Algorithm", "text": "The UCB algorithm proposed by Auer et al. [3] works on the classic MAB problem, in which only one arm is pulled at a time. This algorithm maintains an upper trust limit on each arm (hence the name UCB), which depends on both its empirical reward and the exploration factor to give the arm sufficient traction; the algorithm achieves a remorse of O (lnT) and it is the best possible remorse that can be achieved. An extension of multiple delivery consists in pulling the arms in the increasing order of their upper trust limit."}, {"heading": "3.4.2 The CUCB Algorithm", "text": "The CUCB algorithm [13] generalizes UCB to the combinatorial setting, pulling a subset of the arms each time and revealing the rewards of all the selected arms. The algorithm works for general nonlinear reward functions as long as monotonicity and limited smoothing properties are satisfied by the reward functions. The general idea of the algorithm is to select the subset in such a way that the reward is maximized in relation to the upper confidence limits of all arms, similar to the UCB algorithm, which selects a single arm with the highest confidence limit. The CUCB algorithm achieves a regret of O (lnT). The AAB framework treats an unknown stochastic constraint given by fS (q) < \u03b1, as opposed to the CUCB algorithm, where the reward function is stochastical with known constraints. We have now made some realistic assumptions for the AB model, which we have made in our algorithm."}, {"heading": "3.5 Assumptions", "text": "We assume that the error probability function meets the assumptions of monotonicity and limited smoothness. These assumptions are natural and are fulfilled by many interesting error probability functions. \u2022 We assume that the true label will be adhered to once the task is completed. \u2022 To substantiate this assumption, we recall the trading example given in the introductory section, where the company and customers can realize the true label at the end of the day, e.g. in intraday trading. \u2022 We assume that if all workers are selected, the limitation regarding the true qualities is always met. Thus, if qualities are only partially learned, the algorithm can select the full set and fulfill the limitation."}, {"heading": "4 Non Strategic Version", "text": "We solve a general optimization problem according to Equation (3) with unknown qualities that need to be learned over time. As workers receive their labels according to the true qualities, the limitation with respect to the true qualities must be met. As these qualities are unknown to the applicant, he must ensure that the limitation is met with high probability. Note that our algorithm operates within a general framework with each aggregation rule and with each error probability function that meets the monotonicity and the limited smoothing properties. Therefore, the algorithm uses the aggregation rule as a black box. Definition 4.1 (aggregate) An aggregation function takes the loud labels of the selected set as input and produces a label y that best captures the respective configuration. We call the aggregation rule a monogenous label. The aggregation function should ensure that the resulting error probability (CCfunction and non-feature) is equal for each strategic label."}, {"heading": "4.1 CCB-NS Algorithm", "text": "The CCB-NS algorithm (shown in algorithm 1) works according to the principle of the UCB algorithm (Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q (Q = Q = Q = Q = Q = Q = Q Q = Q = Q Q = Q (Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q (Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q"}, {"heading": "4.2 Regret Analysis of CCB-NS", "text": "In this section, we aim to define the number of non-optimal rounds for the CCB-NS algorithm, which is represented in Algorithm 1.Definition 4.2 (non-optimal subset). We say that in round t, a set of St \u2212 \u2212 \u2212 n selected by the algorithm is a sub-optimal subset if the algorithm selects a set that meets the constraint for each task with a high probability. (Definition 4.3 (non-optimal round:) We say that a round t is a non-optimal number of rounds in which the algorithm selects a sub-optimal number of S-steps. As the algorithm selects a set that meets the constraint for each task with a high probability, we can regret the total by determining the number of rounds in which the algorithm selects a sub-optimal set of St i.e. C (St) > C (S) > NS (S). If C (St) = C (Reference for each task with a high probability, then we get zero rounds (S) with a \u2212 n."}, {"heading": "5 Strategic Version", "text": "In this section, we propose an algorithm we call CCB-S that fulfills a certain monotony property, and then present an implementation of the mechanism design. We will first describe the game theory version of the problem discussed in the previous section."}, {"heading": "5.1 The Model", "text": "The actual cost of an employee i of ci and the reported cost of an employee i of c. (A) The evaluation of an employee i is given by vi = \u2212 ci. (A) The evaluation of an employee i (A) is given by vi = \u2212 ci. (A) The evaluation of an employee i (A) is given by vi = \u2212 ci. (A) The evaluation of an employee i (A) is given by us (A). (A) The evaluation of an employee i (A) is given by us (A). (A) The evaluation of an employee i (A) is given by us (A). (A) The evaluation of an employee i (A) is given by other workers i (A)."}, {"heading": "5.2 The CCB-S Algorithm", "text": "As we have seen in the previous section, we need the monotonicity of an allotment rule for the compatibility of incentives. In CCB-NS, if the selected sentence St in step 8 does not meet the constraint with q \u2212 \u2212 in step 10, we add agents to meet the constraint. This step does not take into account strategic costs and thus results in a violation of the monotonicity. Therefore, we design a new algorithm that will achieve the necessary monotonicity.To ensure the truthfulness, we modify the CCB-NS algorithm to select all workers when the constraint in terms of the lower confidence limit is not met (step 10). We present CCB-S in algorithm 2. We then show that the allocation rule given by the algorithm is ex-post monotonous, so we can apply the results from [5] to achieve an ex-post incentive compatible and ex-post individual mechanism."}, {"heading": "5.3 Analysis of MCCB\u2212S", "text": "Since we use an exploration-separate allocation rule, a natural way to ensure truthfulness is that we can apply the classic VCG mechanism (VCG system). In order to develop an ex-post compatible and ex-post individual rational method, it is sufficient to design an ex-post monotone allocation rule that cannot be determined by the algorithm. Thus, we will show that our algorithm can achieve ex-post monotonicity and thus achieve an ex-post rational task."}, {"heading": "6 Practical Aspects and Experimental Results", "text": "A naive implementation of the CCB-NS algorithm and the CCB-S algorithm can lead to two problems: 1) computational complexity of the underlying optimization problem 2) high exploration costs for the CCB-S algorithm. In practice, the underlying optimization problems are often well-researched combinatorial problems. Therefore, we may still be able to use the AAB framework to solve the complexity concerns through efficient approximation algorithms that meet the later defined monotonicity. In this section, we consider the majority rule as an aggregation rule and solve Example 3.2 by formulating it as a minimal tornister problem. The minimal tornister problem is NP-hard, but there are polynomial time algorithms that result in a factor of 2."}, {"heading": "6.1 Working with Approximate Solutions", "text": "The key to the approximate algorithm in the AAB framework is to show its monotonicity in the cost algorithm. The CCB-S algorithm that uses the solution of the monotonous algorithm specifies a monotonous algorithm location rule that is indispensable for incentive compatibility.Definition 6.1 (monotonous algorithm) An algorithm is supposed to be monotonous if the algorithm algorithm allocation is A monotonous in the cost, i.e. if two input examples (c, q) and (c +, q) are such that ci < c + i, for some i and cj = c + j \u0432j 6 = i, then Ai (c +, q) = 1 \u21d2 Ai (c, q) algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm-approximate algorithm algorithm algorithm algorithm algorithm algorithm algorithm-approximate algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm-approximate algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm-approximate algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm-approximate algorithm algorithm algorithm algorithm algorithm algorithm-approximate algorithm algorithm algorithm algorithm algorithm algorithm is algorithm algorithm algorithm algorithm algorithm algorithm-approximate algorithm algorithm algorithm algorithm-approximate algorithm algorithm algorithm algorithm algorithm if"}, {"heading": "6.2 An Illustrative Example with Low Regret", "text": "From example 3.2, if all workers have qualities of at least 23, i.e. qi > 2 / 3 and = 1 / 6, then the optimization problem of the minimization of costs and the satisfaction of the accuracy limit of \u03b1 remains. < p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p p > p p > p p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p >"}, {"heading": "6.2.2 Elimination Strategy with Greedy Algorithm GA", "text": "Let us suppose that we have (if appropriate relabelling) c1 a) - 1) - c2 a) - 2 - (2) - (2) - (3) - (3) - (3) - (3) -) - (3) - (4) - (4) - (4) - (4) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) - (5) (5) (5) - (5) (5) (5) - (5) (5) (5) - (5 - (5) (5) (5) - (5 - (5) (5) (5) - (5 - (5) (5) (5) (5) - (5 - (5) (5) (5) - (5 - (5) (5) (5) (5 - (5) (5) (5) - (5) (5) (5 - (5) - (5) (5) (5) (5 - (5) (5) (5 - (5) (5) (5 - (5) (5) (5 - (5) - (5 - (5) (5 - (5) (5 - (5) (5 - (5) (5 - (5) (5) (5 - (5) (5) (5 - (5 - (5) - (5) (5 - (5) (5 - (5) (5 - (5) - (5) (5 - (5) (5) (5 - (5) (5) (5 - (5 - (5) (5 - (5) - (5) (5 - (5) (5) (5 - (5 - (5) (5) (5 - (5) (5 - (5 - (5) - (5) (5 - (5) - (5) (5 - (5)"}, {"heading": "6.3 Simulation Results", "text": "In this section, we will compare the effectiveness of the proposed algorithms through simulations. For simulations, we will use the minimum knapsack problem described in the previous section, which is solved with the help of the greedy algorithm. \u2212 We will compare the regrets of four algorithms, namely CCB-NS, CCB-S, CCB-SE and a variant of the greedy algorithm. \u2212 The greedy algorithm [3] solves the classic, multi-armed bandit problem, which involves selecting the only best arm. In the classic version, a random arm is examined with the probability and the optimal arm (with the highest empirical means) is selected with the probability. \u2212 We will extend the algorithm to the AAB setting, by examining all workers with the probability and probability (1 \u2212 \u03b5t), we will select the minimum cost worker who meets the target qualities."}, {"heading": "7 Summary and Future Work", "text": "Motivated by the need for a mechanism where the worker qualities are not a priori known and their costs are private information, we considered the problem of selecting an optimal subset of workers, so that the result achieved by aggregating labels of the selected workers reaches a target accuracy level. We proposed a novel framework, Assured Accuracy Bandit (AAB), and developed an algorithm, Strategic Constrained Confidence Bound (CCB-S) for the same, which also leads to an ex-post incentive compatible and ex-post individually rational mechanism. We set limits on the number of exploration steps that depend on the target accuracy level and true qualifications. Often, the optimization problem that needs to be solved for each task exhibits exponential time complexity. In most cases, there are efficient, uncompromised algorithms to solve the optimization problem. If these algorithms are monotoners, then the algorithms can be combined with interesting algorithms for CCQ, then the algorithms can become a CCQ."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "<lb>Consider a requester who wishes to crowdsource a series of identical<lb>binary labeling tasks to a pool of workers so as to achieve an assured accu-<lb>racy for each task, in a cost optimal way. The workers are heterogeneous<lb>with unknown but fixed qualities and their costs are private. The problem<lb>is to select for each task an optimal subset of workers so that the outcome<lb>obtained after aggregating the labels from the selected workers guaran-<lb>tees a target accuracy level. The problem is a challenging one even in a<lb>non strategic setting since the accuracy of aggregated label depends on<lb>unknown qualities. We develop a novel multi-armed bandit (MAB) mech-<lb>anism for solving this problem. First, we propose a framework, Assured<lb>Accuracy Bandit (AAB), which leads to a MAB algorithm, Constrained<lb>Confidence Bound for a Non Strategic setting (CCB-NS). We derive an<lb>upper bound on the number of time steps the algorithm chooses a sub-<lb>optimal set that depends on the target accuracy level and true qualities.<lb>A more challenging situation arises when the requester not only has to<lb>learn the qualities of the workers but also elicit their true costs. We mod-<lb>ify the CCB-NS algorithm to obtain an adaptive exploration separated<lb>algorithm which we call Constrained Confidence Bound for a Strategic<lb>setting (CCB-S). CCB-S algorithm produces an ex-post monotone alloca-<lb>tion rule and thus can be transformed into an ex-post incentive compatible<lb>and ex-post individually rational mechanism that learns the qualities of<lb>the workers and guarantees a given target accuracy level in a cost optimal<lb>way. We also provide a lower bound on the number of times any algo-<lb>rithm should select a sub-optimal set and we see that the lower bound<lb>matches our upper bound upto a constant factor. We provide insights<lb>on the practical implementation of this framework through an illustrative<lb>example and we show the efficacy of our algorithms through simulations.", "creator": "LaTeX with hyperref package"}}}