{"id": "1406.7314", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2014", "title": "On the Use of Different Feature Extraction Methods for Linear and Non Linear kernels", "abstract": "The speech feature extraction has been a key focus in robust speech recognition research; it significantly affects the recognition performance. In this paper, we first study a set of different features extraction methods such as linear predictive coding (LPC), mel frequency cepstral coefficient (MFCC) and perceptual linear prediction (PLP) with several features normalization techniques like rasta filtering and cepstral mean subtraction (CMS). Based on this, a comparative evaluation of these features is performed on the task of text independent speaker identification using a combination between gaussian mixture models (GMM) and linear and non-linear kernels based on support vector machine (SVM).", "histories": [["v1", "Fri, 27 Jun 2014 20:56:00 GMT  (268kb)", "http://arxiv.org/abs/1406.7314v1", "8 pages, 3 Figures"]], "COMMENTS": "8 pages, 3 Figures", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["imen trabelsi", "dorra ben ayed"], "accepted": false, "id": "1406.7314"}, "pdf": {"name": "1406.7314.pdf", "metadata": {"source": "CRF", "title": "On the Use of Different Feature Extraction Methods for Linear and Non Linear kernels", "authors": ["Imen TRABELSI", "Dorra BEN AYED"], "emails": ["trabelsi.imen1@gmail.com", "Dorra.mezghani@isi.rnu.tn", "dorrainsat@yahoo.fr"], "sections": [{"heading": null, "text": "- 1 -INTRODUCTIONIn this paper, we highlight some of the most important related research, techniques and approaches that have emerged to extract the appropriate characteristic parameters. Currently, there are two major approaches to characteristic extraction: the modeling of human voice production and the modeling of the perception system. In the first model, the voice evolved primarily to produce speech for conversation, in the second model, hearing evolved to recognize these noises. Therefore, we attempt to classify characteristic extraction among these two models. To improve the performance and robustness of automatic speech recognition, preprocessing and filtering are often used in speech characteristic extraction. In this essay, we encourage the use of extraction characteristic techniques for text-independent loudspeaker identification systems using the GMM supervector in a support vector machine (SVM)."}, {"heading": "1. Different speech feature", "text": "The extraction of traits in ASR is the calculation of a sequence of trait vectors that provides a compact representation of the given speech signal. Production and perception of speech are human activities, a speaker can be presented as an encoder in a speech production process, and the listener can be presented as a decoder in a speech perception process.Figure 1 shows the complete process of speech production and perception from the formulation of a speaker's message to the generation of the speech signal to the understanding of the message by the listener. Between human auditory and linguistic production systems, some research believes that the auditory system came first, other research uses the speech production model as the main focus [URS 02]. It is the acoustic speech signal that mediates between the two systems. Therefore, it is only natural to expect that the characteristics of the acoustic signal can also say about the human speech production system and the human auditory system."}, {"heading": "1.1. Features based on speech production", "text": "The mechanism of speech consists of four processes: speech processing, in which the content of an utterance is somehow represented in the brain; generation of motor commands to the vocal organs; articulation movement for the production of speech by the vocal organs based on these motor commands; and the emission of air sent from the lungs in the form of speech [HON 03]. These structures are capable of generating and shaping a variety of waveforms, which can generally be categorized into spoken and unspoken ways of speaking; these properties describe the properties of the acoustic signal resulting from it. Based on our knowledge of the language production mechanisms, we are able to extract a series of characteristics that best represent a particular phoneme."}, {"heading": "1.2. Features based on perception system", "text": "In fact, most people in the world are able to understand the language and understand what they are doing. (...) Most people in the world do not understand what they are doing. (...) Most people in the world do not know what they are doing. (...) Most people in the world do not know what they are doing. (...) Most people in the world do not know what they are doing. (...) People in the world do not know what they are doing. (...) People in the world do not know what they are doing. (...) People in the world do not know what they are doing. (...) People in the world do not know what they are doing. (...) People in the world do not know what they are doing. (...)"}, {"heading": "2. Pre-processing", "text": "The part of speech preprocessing is the basic signal processing that is applied before extracting features from the speech signal, conditioning the raw speech signal and preparing it for subsequent manipulations. Frequently used preprocessing techniques are presented as follows."}, {"heading": "2.1. Digitalization", "text": "It is the first step in voice processing voice recording, requiring a microphone coupled with an analog-to-digital converter to receive, scan and convert the voice signal into digital voice.The analog voice signal is digitized at a sampling rate of 8 KHZ in digital telephony and 10 KHZ, 12 KHZ or 16 KHZ in non-telecommunications applications."}, {"heading": "2.2. End Point Detection", "text": "This step is based on the evaluation of the signal energy. A speech signal can be divided into three parts: speech segment, silence segment and background noise. To separate them, we call speech endpoint recognition algorithms. Afterwards, the unnecessary parts were removed."}, {"heading": "2.3. Pre-emphasis", "text": "The digitized voice signal Y [n] is sent to a finite impulse response (FIR) filter:] 1n [x] n [x] n [Y (2) 0.19.0 (3) where x [n] is the input voice signal and Y [n] is the output signal and \u03b1 is an adjustable parameter. The aim of the pre-emphasis is to compensate for the radio frequency portion suppressed during the human sound production mechanism. Furthermore, it can amplify the importance of radio frequency shapes."}, {"heading": "2.4. Frame blocking", "text": "The continuous preemphasis signal Y is divided into overlapping frames of N samples. Frame duration is typically between 10 and 30 ms short time intervals to ensure the quasi-stationary of the signal with optional overlap of [1 / 3 1 / 2] of the frame size."}, {"heading": "2.5. Windowing", "text": "After framing, window techniques are applied to reduce the effect of discontinuity in each frame and around the edges of the frame.Each frame must be multiplied by a window technique, there are different types of window functions, such as rectangular, hammering, barlett, Sainsbury, Kaiser, Bohman, Chebyshev, hanning and Gaussian windows. Most popular is the hammering window w (n), defined by:) cos (a) a1 () a, n (w 1Nn2 (4) 1Nn0 (5) Different values of a correspond to different curves for the hammering windowsThen the signal in a frame is S [n] after hammering windows: w [n] n [Y] n [S (6)"}, {"heading": "3. Post Processing", "text": "This section discusses the various methods proposed for the normalization of characteristics."}, {"heading": "3.1. Cepstral Mean Subtraction -CMS", "text": "The algorithm calculates a long-term mean of the feature vectors and subtracts the mean from the cepstral vectors of this expression and then generates a normalized cepstrum vector. CMS avoids low frequency noise, which is further amplified, but the average configuration information of the speaker can also be lost [FUR 81]."}, {"heading": "3.2. Cepstral variance normalization -CVN", "text": "Normalization of ceptral variance is also referred to as mean and variance normalization (MVN) [JAI 01], since CVN is often used in conjunction with CMS. Mean and variance of the ceptral coefficients are assumed to be invariant in CVN analysis. Therefore, excluding these properties would lead to the removal of irrelevant information, such as the effects of inconsistent environments."}, {"heading": "3.3. RASTA-filtering", "text": "Rasta filtering was proposed by Hermansky and Morgan for robust speech recognition [HER 94]. Initially, it was introduced to support pre-processing of Perceptual Linear Prediction (PLP), using band-pass filtering in the log spectral range. It was also applied to other cepstral feature-based preprocessing with logspectral and cepstral domain filtering. Rasta filtering then eliminates slow channel fluctuations and makes PLP more resistant to linear spectral distortion [HER 91]. This technique has proven to be a successful channel normalization technique in automatic speech recognition."}, {"heading": "3.4. Feature warping", "text": "This method, also known as cumulative distribution mapping [CHOI 06], consists of mapping the observed ceptral feature distribution to a predefined target distribution via a sliding window with zero and unit variance [PEL 03].This technique is a real-time equivalent to histogram compensation in image processing, where a feature distribution is assigned to a target distribution. This feature processing method has been successfully applied to loudspeaker recognition because it is robust against channel mismatches, additive noise, and to a certain extent against nonlinear effects attributed to the distortion of mobile phones [PEL 03] [BAR 03]."}, {"heading": "3.5. Short-time Gaussianization", "text": "This is achieved by an iterative scheme in each iteration; a global linear transformation is applied to the characteristics to make them more dependent or decorated in the new attribute space before they are assigned to an ideal distribution, such as the standard normal distribution [CHEN 00]. This linear transformation can be estimated by the algorithm of expectation maximization (EM) [DEM 77].- 5 -"}, {"heading": "4. Experimental evaluation of different features with application in speaker identification", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. System Conditions", "text": "Our base system is a text-independent loudspeaker recognition task based on the hybrid GMM / SVM system [BOU 09a], [BOU 09b]. The purpose of this study is to evaluate the performance of different acoustic characteristics when training data and test data are in a clean environment to show the differences between them. Experiments were conducted under the experimental conditions described in Table 2. Number of utterances per loudspeaker 8 sets of draught number per loudspeaker 2 sets for testIn our experiments we evaluated several different feature measurements, including MFCCs on the Mel scale, Perceptual Linear Prediction (PLP), Linear Predictive Coding (LPC) both with and without their first and second derivatives and combined with normalization techniques."}, {"heading": "IR (%) = \u00d7", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "100 (7)", "text": "Specifications of the input audio stream on the acoustic preprocessor are summarized as follows (in Table 3). Table 3. Level Value Preprocessing Sampling Rate Endpoint Detection Pre-Emphasis Frame Duration Frame Shift Window 16 KHZ Energy-Based VAD 1 - 0.95 16 ms 8ms Hamming"}, {"heading": "4.2. GMM-UBM baseline System", "text": "The basic system was a GMM UBM [REY 95]. The modeling of the loudspeakers consists of two steps: A general universal background model UBM is trained using acoustic data from different loudspeakers to model the acoustics of the language.The UBM, which consists of 128 mixtures, is trained using the EM algorithm with a vector quantization prediction (KMEANS).And a target loudspeaker model is adapted from the UBM by the Bayesian adaptation MAP [REY 00] by adapting the UBM average.All Gaussian mean vectors are brought together to obtain a GMM supervector [CAM 06].The GMM supervector can be thought of as a mapping between an expression and a high-dimensional vector. The process is shown in Figure2.We produced GMM supervector per expression using MAP adaptation."}, {"heading": "4.3. Support vector machine in the GMM space", "text": "GMM-Supervector and SVM combine both generative and discriminatory methods and lead to the generative SVM cores based on the probability distribution estimation.In our case, SVM being used in the GMMs means supervector space [SCH 96], as shown in Figure 3.SVMs perform a nonlinear imaging from an entrance room to an SVM expansion space.The most important design component in an SVM is the kernel, which is an internal product in the SVM attribute space.In our experiments we have used two different core functions, the first corresponding to the linear GMM-SVM kernel. The last component is the nonlinear GMM-SVM cores based on the radial basic function- 6 - (RBF).The kernel in the equation (8), (9) and the evaluation are best implemented with the LIBSVM-SVM kernel library."}, {"heading": "4.4. Experiments results", "text": "Our motivation was to analyze how much performance rates in loudspeaker identification depend on the choice of feature extraction techniques and the core functions that train SVMs.4.4.1. MFCC variants Table 4 shows the performance of our GMM SVM system based on a different combination of MFCC.We observed that the IR is identical for MFCC, MFCC + Delta and MFCC + Energy. This IR is 100%, but when MFCC is combined with Delta and Delta Delta Delta, our system achieves an IR between 92, 85% and 96, 42%, with the best performance in this case reported by the linear core. When MFCC is used with its Delta, Delta and Energy, the IR obtained is approximately 96.42% for both linear and RBF cores. While IR is most significantly degraded when MFCC is clearly associated with RF BBPLPLPLP core, the ELP-PLP variants show the decrease of 42%."}, {"heading": "5. Conclusion", "text": "A major problem with the speech recognition system is the choice of the appropriate functionality to describe the original voice signal in an abstract and faithful way. We have proposed a hybrid GMM-SVM system to represent the current knowledge in the area of trait extraction, speech preprocessing and normalization methods for the task of speaker identification. We have proposed a hybrid GMM-SVM system. We have assessed the performance of this combination with different characteristics and two different kernels. Then, a comparative study was conducted to investigate the best choice of the core function and the best input functionality. First, we conclude that MFCC and LPC exceed the PLP. We also conclude that the inclusion of delta and acceleration coefficients has a negative impact on ASR performance without LPC. We therefore conclude that rasta filters and CMS do not improve accuracy. This is because the data in TIMIT with high-quality desktop microphone tests has not been recorded between a seat microphone environment and a train."}], "references": [{"title": "Feature and score normalization for speaker verification of cellular data", "author": ["C. Barras", "J.L. Gauvain"], "venue": "Proceedings of IEEE ICASSP, vol. 2, p. 49-52", "citeRegEx": "BAR 03", "shortCiteRegEx": null, "year": 2003}, {"title": "Robust Text Independent Speaker Identification Using Hybrid GMM-SVM System", "author": ["S. Zribi Boujelbene", "D. Ben Ayed Mezghani", "N. Ellouze"], "venue": "Journal of Convergence Information Technology \u2013 JDCTA,", "citeRegEx": "Boujelbene et al\\.,? \\Q1975\\E", "shortCiteRegEx": "Boujelbene et al\\.", "year": 1975}, {"title": "Support Vector Machines approaches and its application to speaker identification", "author": ["S. Zribi Boujelbene", "D. Ben Ayed Mezghani", "N. Ellouze"], "venue": "IEEE International Conference on Digital Eco-Systems and Technologies DEST-09,", "citeRegEx": "Boujelbene et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Boujelbene et al\\.", "year": 2009}, {"title": "and A", "author": ["W.M. Campbell", "D.E. Sturim", "D.A. Reynolds"], "venue": "Solomonoff, \"SVM based speaker verification using a GMM-supervector kernel and NAP variability compensation,\" Proc. Int. Conf. Acoustics, Speech, and Signal Processing", "citeRegEx": "CAM 06", "shortCiteRegEx": null, "year": 2006}, {"title": "Lin", "author": ["C.-C. Chang", "C.-J"], "venue": "LIBSVM: a library for support vector machines,", "citeRegEx": "CHA 01", "shortCiteRegEx": null, "year": 2001}, {"title": "A Noise Robust Front-end for Speech Recognition Using Hough Transform and Cumulative Distribution Mapping", "author": ["E.H.C. Choi"], "venue": "18th International Conference on Pattern Recognition, vol. 4, p 286-289", "citeRegEx": "CHOI 06", "shortCiteRegEx": null, "year": 2006}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "Cepstral analysis technique for automatic speaker verification", "author": ["S. Furui"], "venue": "IEEE Trans. Acoust. Speech Signal Processing,", "citeRegEx": "Furui,? \\Q1981\\E", "shortCiteRegEx": "Furui", "year": 1981}, {"title": "Perceptual linear predictive (PLP) analysis of speech", "author": ["H. Hermansky"], "venue": "J. Acoustic Soc. Amer., vol. 87, no. 4, pp. 1738-1752, Apr.", "citeRegEx": "HER 90", "shortCiteRegEx": null, "year": 1990}, {"title": "Rasta plp speech analysis", "author": ["H. Hermansky", "N. Morgan", "A. Bayya", "P. Kohn"], "venue": "International Computer Science Institute,", "citeRegEx": "Hermansky et al\\.,? \\Q1947\\E", "shortCiteRegEx": "Hermansky et al\\.", "year": 1947}, {"title": "RASTA processing of speech", "author": ["H. Hermansky", "N. Morgan"], "venue": "Acoustics, Speech and Signal Processing, IEEE Transactions, vol. 2, no. 4", "citeRegEx": "HER 94", "shortCiteRegEx": null, "year": 1994}, {"title": "Should recognizers have ears", "author": ["H. Hermansky"], "venue": "Speech Communication, vol. 25, no. 1-3, pp. 327", "citeRegEx": "HER 98", "shortCiteRegEx": null, "year": 1998}, {"title": "Improved mean and variance normalization for robust speech recognition", "author": ["P. Jain", "H. Hermansky"], "venue": "Proc. ICASSP", "citeRegEx": "JAI 01", "shortCiteRegEx": null, "year": 2001}, {"title": "S", "author": ["D. Kim"], "venue": "Lee \"Auditory processing of speech signals for robust speech recognition on realworld noisy environment\", IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESING, vol. 7, no. 1", "citeRegEx": "KIM 99", "shortCiteRegEx": null, "year": 1999}, {"title": "Speech production knowledge in automatic speech recognition", "author": ["S. King", "al"], "venue": "JASA,", "citeRegEx": "King and al.,? \\Q2007\\E", "shortCiteRegEx": "King and al.", "year": 2007}, {"title": "Combining acoustic and articulatory feature information for robust speech recognition", "author": ["K. Kirchhoff", "G.A. Fink", "G. Sagerer"], "venue": "Speech Communication, vol. 37, pp. 303\u2013319", "citeRegEx": "KIR 00", "shortCiteRegEx": null, "year": 2000}, {"title": "Linear Prediction: A Tutorial Review", "author": ["J.J. Makhoul"], "venue": "Proc. IEEE, Vol. 63, pp. 561-580,", "citeRegEx": "Mak 75", "shortCiteRegEx": null, "year": 1975}, {"title": "Robust Automatic Speaker Recognition", "author": ["J.W. Pelecanos"], "venue": "PhD thesis, Queensland University of Technology", "citeRegEx": "PEL 03", "shortCiteRegEx": null, "year": 2003}, {"title": "Digital Processing of Speech Signals", "author": ["L.R. Rabiner", "R.W. Schafer"], "venue": "Prentice-Hall, Signal Processing Series, Englewood Cliffs, NJ", "citeRegEx": "RAB 78", "shortCiteRegEx": null, "year": 1978}, {"title": "Robust textindependent speaker identification using Gaussian mixture speaker models", "author": ["D. Reynolds", "R. Rose"], "venue": "\" IEEE Trans. Speech Audio Proc., vol. 3, no. 1, pp. 72\u201383", "citeRegEx": "REY 95", "shortCiteRegEx": null, "year": 1995}, {"title": "Speaker verification using adapted gaussian mixture models", "author": ["D. Reynolds", "T. Quatieri", "R. Dunn"], "venue": "DSP, vo. 10, no. 1-3, pp. 19\u201341", "citeRegEx": "REY 00", "shortCiteRegEx": null, "year": 2000}, {"title": "Speaker Identification via Support Vector Machies", "author": ["M. Schmidt", "H. Gish"], "venue": "ICASSP, 105-108", "citeRegEx": "SCH 96", "shortCiteRegEx": null, "year": 1996}, {"title": "Triphone Clustering in Finnish Continuous Speech Recognition", "author": ["M. Ursin"], "venue": "Master Thesis, Department of Computer Science, Helsinki University of Technology, Finland", "citeRegEx": "URS 02", "shortCiteRegEx": null, "year": 2002}], "referenceMentions": [{"referenceID": 22, "context": "Between human auditory and speech production systems, some researches believe that the auditory system came first, other researches uses the speech production model as the primary focus [URS 02].", "startOffset": 186, "endOffset": 194}, {"referenceID": 15, "context": "Articulatory features Articulatory features (AFs) have attracted interest from the speech recognition community for more than a decade for many reasons [KIN 07] [KIR 00].", "startOffset": 161, "endOffset": 169}, {"referenceID": 16, "context": "Linear Predictive Coding - LPC Linear predictive analysis of speech were introduced in late 1960s and become the predominant technique for estimating the basic parameters of speech [MAK 75].", "startOffset": 181, "endOffset": 189}, {"referenceID": 13, "context": "The mechanical vibrations are then transuded into activity signals on the auditory nerves corresponding to a feature extraction process [KIM 99].", "startOffset": 136, "endOffset": 144}, {"referenceID": 11, "context": "In fact the question of the imitation of the human auditory system characteristics for ASR has been subject of discussion and some researches believe that the analysis based on the effective peripheral auditory processing is the most robust front end in noise [HER 98].", "startOffset": 260, "endOffset": 268}, {"referenceID": 8, "context": "Perceptual Linear Prediction -PLP Hermansky [HER 90] introduced a new technique, perceptual linear predictive (PLP) analysis.", "startOffset": 44, "endOffset": 52}, {"referenceID": 12, "context": "Cepstral variance normalization -CVN Cepstral variance normalization is also known as the mean and variance normalization (MVN) [JAI 01] because CVN is often used in conjunction with CMS.", "startOffset": 128, "endOffset": 136}, {"referenceID": 10, "context": "RASTA-filtering Rasta-filtering was proposed for robust speech recognition by Hermansky and Morgan [HER 94].", "startOffset": 99, "endOffset": 107}, {"referenceID": 5, "context": "Feature warping Also known as cumulative distribution mapping [CHOI 06].", "startOffset": 62, "endOffset": 71}, {"referenceID": 17, "context": "It consists of mapping the observed cepstral feature distribution to a predefined target distribution over a sliding window with zero mean and unit variance [PEL 03].", "startOffset": 157, "endOffset": 165}, {"referenceID": 17, "context": "This feature processing technique has successfully been applied to speaker recognition because it is robust to channel mismatch, additive noise and to some extent, nonlinear effects attributed to handset distortion [PEL 03] [BAR 03].", "startOffset": 215, "endOffset": 223}, {"referenceID": 0, "context": "This feature processing technique has successfully been applied to speaker recognition because it is robust to channel mismatch, additive noise and to some extent, nonlinear effects attributed to handset distortion [PEL 03] [BAR 03].", "startOffset": 224, "endOffset": 232}, {"referenceID": 19, "context": "GMM-UBM baseline System The baseline system was a GMM UBM [REY 95].", "startOffset": 58, "endOffset": 66}, {"referenceID": 20, "context": "And a target speaker model is adapted by Bayesian adaptation MAP [REY 00] from the UBM by adjusting the UBM means.", "startOffset": 65, "endOffset": 73}, {"referenceID": 3, "context": "All Gaussian means vectors are pooled together to get one GMM Supervector [CAM 06].", "startOffset": 74, "endOffset": 82}, {"referenceID": 21, "context": "In our case, SVM is applied in the GMMs means supervector space [SCH 96] as shown in figure 3.", "startOffset": 64, "endOffset": 72}, {"referenceID": 4, "context": "The Kernel in equation (8), (9) and scoring are implemented using the library LIBSVM [CHA 01].", "startOffset": 85, "endOffset": 93}], "year": 2012, "abstractText": "The speech feature extraction has been a key focus in robust speech recognition research; it significantly affects the recognition performance. In this paper, we first study a set of different features extraction methods such as linear predictive coding (LPC), mel frequency cepstral coefficient (MFCC) and perceptual linear prediction (PLP) with several features normalization techniques like rasta filtering and cepstral mean subtraction (CMS). Based on this, a comparative evaluation of these features is performed on the task of text independent speaker identification using a combination between gaussian mixture models (GMM) and linear and non-linear kernels based on support vector machine (SVM).", "creator": "Microsoft Word - TrabelsiArticle.doc"}}}