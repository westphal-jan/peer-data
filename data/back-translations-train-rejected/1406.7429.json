{"id": "1406.7429", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jun-2014", "title": "Comparison of SVM Optimization Techniques in the Primal", "abstract": "This paper examines the efficacy of different optimization techniques in a primal formulation of a support vector machine (SVM). Three main techniques are compared. The dataset used to compare all three techniques was the Sentiment Analysis on Movie Reviews dataset, from kaggle.com.", "histories": [["v1", "Sat, 28 Jun 2014 18:59:44 GMT  (14kb)", "http://arxiv.org/abs/1406.7429v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jonathan katzman", "diane duros"], "accepted": false, "id": "1406.7429"}, "pdf": {"name": "1406.7429.pdf", "metadata": {"source": "CRF", "title": "Comparison of SVM Optimization Techniques in the Primal", "authors": ["Diane Duros"], "emails": ["dduros1@gmail.com", "jonathan.d.katzman@gmail.com"], "sections": [{"heading": null, "text": "ar Xiv: 140 6.74 29v1 [cs.LG] 2 8Ju nThis paper examines the effectiveness of various optimization techniques in a primary formulation of a support vector machine (SVM). Three main techniques are compared: The dataset used to compare all three techniques was the dataset Sentiment Analysis on Movie Reviews from kaggle.com."}, {"heading": "1 Introduction", "text": "Most SVM literature determines the primary optimization and then moves on to dual formulation without providing significant details about the formation of an SVM based on the primary optimization problem. Learning an SVM is typically considered a limited quadratic programming problem. our goal is to analyze three different primary optimization methods in the context of a large text-based dataset. In the face of a training set {(xi, yi)} 1 \u2264 i \u2264 n, xi-R, yi-1}, the primary optimization problem is: minw, b | w | | | 2 + C n \u0445 i = 1\u0432Piunder Constraints yi (w \u00b7 xi + b) > 1; \u043fi, \u0441i > 0 (1) We use a hard margin SVM where C = 0 - that is, we want every data point outside the margin to lie around the hyperplane."}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Data", "text": "We got our data from the problem \"Sentiment Analysis on Movie Reviews\" from kaggle.com. The data comes from the Rotten Tomatoes dataset and consists of phrases associated with sentiment labels where the sentiment labels are {0: negative, 1: somewhat negative, 2: neutral, 3: somewhat positive, 4: positive}. Initially, we switched the labels to binary labels where an original label of 3 or 4 was considered positive and 2 or below became a negative label. Later, we developed a multiclassSVM to handle the non-binary labels. In addition to folding the labels, we also had a number of options for processing our data. We ignored punctuations such as \",\" noting that it was unlikely to contribute significantly to the mood, while it often occurred in both positive and negative phrases. We also ignored the distinctions between the small size of our data and the small size of our spelling of at least 1800000 words."}, {"heading": "2.2 Features", "text": "There are two possibilities: binary characters (where the attribute indicates the existence of a word in a phrase) and continuous characters (where the attribute indicates the frequency of a word in a phrase). We have as many attributes for each instance as there are words in the corpus (18226), but each attribute vector is sparse, as we can see in Table 2.1. Since there are an average of 6.85 words per phrase (data instance), the other 18220 elements of the attribute vector will be 0. We have not introduced attribute selection to use only the most important attributes, as we believe that the attribute selection would not be able to maintain an equilibrium between reducing the number of attributes and retaining the information for each phrase (if we removed too many words, many phrases would remove most or perhaps all of their words and become useless)."}, {"heading": "3 SVMs", "text": "We decided to approach this dataset with SVMs because they provide a framework for different optimization methods and generalize to multi-class data. This also allowed us to build on the work we had done in the classroom by using the gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient gradient grading as a starting point for comparison with our other optimization methods.SVMs are binary linear classifiers. In training, they create a hyper-plane between two data classes where the hyperplane maximizes the margin between the two classes, and the main assumption we made about our data is that they are linearly separable. As our data is text-based, one example that could cause nonlinear separability is sarcasm: Let's say that a reviewer is a \"positive\" word sarcastic. \"Our optimizers return the coefficients of the hyperplane that maximizes the margin where we have as many coefficients as we have a general function w (the) (the L is the objective)."}, {"heading": "3.1 Multi-class SVM", "text": "In order to classify the data into 5 classes, we had to expand our SVM to handle more than just binary labels. Since two-class problems are easier to solve, we create several pairs of SVMs for multi-class classification, using the \"one-on-one\" method [6]. To enforce ordinal ranking (0 < 1 < 2 < 3 < 4) instead of calculating pairs of SVMs between all pairs, we have created only pairs of SVMs for label pairs {(0.1), (1.2), (2.3), (3.4)}. In this way, we never attempt to classify between classes that are not directly related to rank inequality. Once each pair of SVMs is trained, there is an additional training step according to a user-defined optimization method. For predicting in the binary SVM, we calculate E (W), with W representing the weights that are trained by the SVM (if an E is true)."}, {"heading": "4 Primal Optimization Methods", "text": "Many SVM packages optimize the dual form of SVM, but we have decided to explore different methods for optimizing the primal problem. In a linear SVM, both the primal and the dual convex are square programs, so there is an exact solution. Chapelle shows not only that the primal optimization methods achieve the same result, but that, if an approximate solution is desired, the primal optimization is superior [2]. The dual program solves for a vector that is as long as the number of training distances, and the primal optimization program solves for a vector that is as long as the number of features. As shown in Table 2.1, we have 150,000 distances, but only 18,000 features, so the primal problem is more efficient to solve for our database. We investigated three different optimization methods: gradient descent, Newton approximation, and stostic gradient (we use the gas loss of the peg2)."}, {"heading": "4.1 Gradient Descent", "text": "We use the gradient of a function as a starting point to compare our two more complex methods.The gradient is a classical optimization technique, since the gradient of a function points in the direction of the greatest increase, and therefore the negative gradient points in the direction of the greatest decrease. The update step is used: w \u2032 = w \u2212 \u03b7 L (x, y; w) (2), where \u03b7 is the learning rate, L (x, y; w) is the loss function for a data point given the current hyperplane coefficients w. We used a standard step size (learning rate) of.001. we sacrificed the runtime and used a small step size to not exceed the minimum and miss it. In this method, we use the entire training set to calculate the gradient. [5] Loss function The loss function used is square loss (which is differentiable anywhere other than the hinge loss), the loss of 2 punishments of training errors, the maximum (L = 1) of the number of the running distance (\u2212 xi)."}, {"heading": "4.2 Newton\u2019s Approximation", "text": "As we have seen in Chapelle, we can write (1) as an unlimited optimization function: \u03bb\u03b2TK\u03b2 + n, that we (1) as an unlimited optimization function (1), that we (1) as an unlimited optimization function (1), and Ki is the column of a kernel K.Loss Function (2), then the loss function we apply is square loss, the L2 punishment for training errors, L (yi, f (xi))) = max (0, 1 \u2212 yif (xi)) 2If the loss at a point xi is not zero, then it is a support vector. The gradient of (3) in relation to the L2 (1).K\u03b2 + KI0 (KI0))) and the session isH = 2 (K + K0K).We can combine these to see that after the Newton update step1, \u03b2 = (I 0K) \u2212 KIY (4)."}, {"heading": "4.3 Stochastic Subgradient", "text": "The stochastic method of the sub-gradient that we have implemented is the Pegasos algorithm by Shalev-Shwartz et al., which is a stochastic method of gradient descent that also has a projection step. To be minimized, the goal is the Pegasos algorithm by Shalev-Shwartz et al. (x, y) (6) For each iteration, we select a random subset of training examples and update the weight vector with the subgradient of the objective function evaluated on the subset. Then, we project the vector onto a sphere with a radius of 1 / 2 m, as the optimal weight vector must lie in that sphere (see menu)."}, {"heading": "5 Code", "text": "We created an SVM framework in Python and a custom DataParser. Our SVM class uses an optimization object as input, with the optimizer calculating the weights for the SVM according to the optimization function encoded in the object. We did not use SVM packets and used the numpy packet only for evaluation purposes."}, {"heading": "5.1 Evaluation", "text": "For evaluation, we created a CrossValidationTester so that we could train and test on the training dataset from kaggle.com. For each lap, the CrossValidationTester randomly assigns the data, then selects 10% to be omitted for testing purposes, while the rest is used for training the model; we used a default value of 10 laps, and then determined the accuracy and timing results across the laps. The only model we did not use was the Newton approximation because it took too long to run."}, {"heading": "6 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Cross Validation Results", "text": "To find the best accuracy for each algorithm, we tested different parameter settings. For gradient lineage, we iterated over the set of learning rates {.01,.02,.03,.05,.1,.2,.3,.4, 1, 2, 3, 5} to find the optimal learning rate, using this value to determine the number of iterations required for convergence. Likewise, for the Pegasos method, we iterated over the set of ball diameters {.001,.01,.1, 10} to determine the optimal size of the sample and the number of iterations. The optimal parameters for each algorithm are available in the results file that we provide with our project. For each parameter setting, we performed 10-fold cross validation to determine the average accuracy and runtime."}, {"heading": "6.2 Comparison to Proposal", "text": "We revised our proposal not to focus on solving the kaggle.com problem, but to use the dataset to explore various optimization techniques, and our performance was still somewhat in line with what we had originally planned, which was to first create a binary SVM classifier and then expand it to a multi-class SVM classifier. We successfully created both. However, instead of examining different characteristic representations of our data, we examined various primary optimization techniques. Our goal was to implement three different algorithms, and we achieved this goal."}], "references": [{"title": "Sgd-qn: Careful quasi-newton stochastic gradient descent", "author": ["Antoine Bordes", "L\u00e9on Bottou", "Patrick Gallinari"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Training a support vector machine in the primal", "author": ["Olivier Chapelle"], "venue": "Neural Computation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Online learning with kernels", "author": ["Jyrki Kivinen", "Alex J Smola", "Robert C Williamson"], "venue": "Ad-  vances in neural information processing systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Laplacian support vector machines trained in the primal", "author": ["Stefano Melacci", "Mikhail Belkin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "one against one or one against all: Which one is better for handwriting recognition with svms", "author": ["Jonathan Milgram", "Mohamed Cheriet", "Robert Sabourin"], "venue": "In Tenth International Workshop on Frontiers in Handwriting Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Stochastic Subgradient Approach for Solving Linear Support Vector Machines\u2013An Overview", "author": ["Jan Rupnik"], "venue": "SiKDD,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Pegasos: Primal estimated sub-gradient solver for svm", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro"], "venue": "In Proceedings of the 24th International Conference on Machine Learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}], "referenceMentions": [{"referenceID": 2, "context": "Other algorithms that are related to these are the NORMA algorithm[3], which is another application of stochastic gradient descent, and SGD-QN [1], which combines stochastic gradient descent with a quasi-Newton method.", "startOffset": 66, "endOffset": 69}, {"referenceID": 0, "context": "Other algorithms that are related to these are the NORMA algorithm[3], which is another application of stochastic gradient descent, and SGD-QN [1], which combines stochastic gradient descent with a quasi-Newton method.", "startOffset": 143, "endOffset": 146}, {"referenceID": 1, "context": "Other previous work in Newton\u2019s method [2] has used the USPS dataset, which is significantly smaller than our data set.", "startOffset": 39, "endOffset": 42}, {"referenceID": 4, "context": "Since two-class problems are easier to solve, we will generate multiple pairwise SVMs for multi-class classification, using the \u201cone against one\u201d method [6].", "startOffset": 153, "endOffset": 156}, {"referenceID": 1, "context": "Chapelle shows not only do the primal and dual optimization methods reach the same result, but that when an approximate solution is desired, primal optimization is superior[2].", "startOffset": 172, "endOffset": 175}, {"referenceID": 1, "context": "Since the hinge loss is nondifferentiable, Chapelle considered smooth loss functions instead of the hinge loss[2], while the Pegasos algorithm[8] uses sub-gradients.", "startOffset": 110, "endOffset": 113}, {"referenceID": 6, "context": "Since the hinge loss is nondifferentiable, Chapelle considered smooth loss functions instead of the hinge loss[2], while the Pegasos algorithm[8] uses sub-gradients.", "startOffset": 142, "endOffset": 145}], "year": 2014, "abstractText": "This paper examines the efficacy of different optimization techniques in a primal formulation of a support vector machine (SVM). Three main techniques are compared. The dataset used to compare all three techniques was the Sentiment Analysis on Movie Reviews dataset, from kaggle.com.", "creator": "LaTeX with hyperref package"}}}