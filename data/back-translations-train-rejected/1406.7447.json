{"id": "1406.7447", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jun-2014", "title": "Unimodal Bandits without Smoothness", "abstract": "We consider stochastic bandit problems with a continuum set of arms and where the expected reward is a continuous and unimodal function of the arm. No further assumption is made regarding the smoothness and the structure of the expected reward function. We propose Stochastic Pentachotomy (SP), an algorithm for which we derive finite-time regret upper bounds. In particular, we show that, for any expected reward function $\\mu$ that behaves as $\\mu(x)=\\mu(x^\\star)-C|x-x^\\star|^\\xi$ locally around its maximizer $x^\\star$ for some $\\xi, C&gt;0$, the SP algorithm is order-optimal, i.e., its regret scales as $O(\\sqrt{T\\log(T)})$ when the time horizon $T$ grows large. This regret scaling is achieved without the knowledge of $\\xi$ and $C$. Our algorithm is based on asymptotically optimal sequential statistical tests used to successively prune an interval that contains the best arm with high probability. To our knowledge, the SP algorithm constitutes the first sequential arm selection rule that achieves a regret scaling as $O(\\sqrt{T})$ up to a logarithmic factor for non-smooth expected reward functions, as well as for smooth functions with unknown smoothness.", "histories": [["v1", "Sat, 28 Jun 2014 23:45:30 GMT  (42kb,D)", "https://arxiv.org/abs/1406.7447v1", "22 pages"], ["v2", "Fri, 6 Mar 2015 13:24:33 GMT  (144kb,D)", "http://arxiv.org/abs/1406.7447v2", "25 pages"]], "COMMENTS": "22 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["richard combes", "alexandre proutiere"], "accepted": false, "id": "1406.7447"}, "pdf": {"name": "1406.7447.pdf", "metadata": {"source": "CRF", "title": "Unimodal Bandits without Smoothness", "authors": ["Richard Combes", "Alexandre Prouti\u00e8re"], "emails": [], "sections": [{"heading": null, "text": "\u221a T log (T)) or O (\u221a log (T) / T) when the time horizon T expands. These scales are made without the knowledge of \u0430 and C. Our algorithm is based on asymptotically optimal sequential statistical tests, which are used to successively shorten an interval that contains the best arm with a high probability. To our knowledge, the SP algorithm is the first sequential arm selection rule that achieves a scaling from repentance and optimization errors as O (\u221a T) or O (1 / \u221a T) to a logarithmic factor for non-smooth expected reward functions and smooth functions with unknown smoothness."}, {"heading": "1 Introduction", "text": "This paper looks at the problem of stochastic unimodal optimization with bandit feedback, which is a generalization of the classic multi-armed bandit problem solved by Lai and Robbins [19]. The problem is defined by a continuous and unimodal expected reward function defined at the interval [0, 1]. For this problem, we consider algorithms that repeatedly select an arm x [0, 1], and receive a noisy reward for medium \u00b5 (x). The performance of an algorithm is characterized by its regret and optimization error up to the time horizon T. Regret is the difference between the average cumulative reward that one would receive if the function \u00b5 were known [0,1], and the actual average cumulative reward that we achieve."}, {"heading": "2 Problem Formulation and Notation", "text": "We consider persistent bandit problems where the group of arms is the interval [0, 1], and where the expected reward (\u03b2 \u03b2 \u03b2) is a continuous and unimodal function of the arm. Specifically, x? exists in such a way that x 7 \u2192 \u00b5 (x) strictly increases (or decreases) in [0, x?] (or in [x?, 1]). We define the set of such functions with U. Let us define \u00b5? = \u00b5 (x?). The time runs in rounds indexed by n = 1, 2,... When arm x is selected in round n, the observed reward dXn (x) is a random variable whose expectation (x) and distribution (x) is."}, {"heading": "3 Stochastic Polychotomy Algorithms", "text": "Here we present a family of sequential arm selection rules called stochastic polychotomy (SP), which consist of a successively narrowing of an interval in [0, 1] while ensuring that the best arm x? remains in this interval with a high probability. < < < < < <"}, {"heading": "3.2 IT\u20323: A Computationally Efficient Sequential Test", "text": "Next, we present IT \u2032 3, a sequential test that is mathematically simpler than IT3. IT \u2032 3 is not asymptotically optimal, but its implementation is much simpler than that of IT3. Its rationale includes the calculation of an explicit lower limit of functions iu, u, u, 1, 2, and therefore IT \u2032 3 does not require a calculation iu. For \u2265 0, we define the function KL?,: R2 \u2192 R as: KL?, (\u00b51, \u00b52) = 1 {\u00b51 < \u00b52} [KL (\u00b51 +, \u00b51 + \u00b52 2 \u2212) + KL (\u00b52 \u2212, \u00b51 + \u00b52 2 2 +). and KL? (\u00b51, \u00b52) = KL?, 0 (\u00b51, \u00b52) = 1 (\u00b52). The sequential test is defined by: for any n \u2264 s, (i) If t, KL?, 0 (\u00b51, \u00b52)."}, {"heading": "4 Performance Analysis of the Stochastic Pentachotomy Algorithm", "text": "In this section, we will analyze the performance of the stochastic pentachotomy algorithm. To this end, we will first examine how the interval trimming subroutines ICT (for K \u2265 3) and IT \u2032 3 perform.4.1 Minimax Risk and Length of ICT Let us perform a sequential test for the interval trimming analysis (max.).The risk is then the likelihood of an interval occurring that does not contain the optimal arm, i.e, Risk Management (\u00b5) = 2 u = 1 {\u00b5 Bu} P\u00b5 (Sample = u]. The minimized risk of such a test is then defined as: The minimized likelihood of a test not being completed (\u00b5). Note that a test (almost certainly) has a risk equal to 0, but its length would then be maximum.The analysis of the performance of a test consists in characterizing the trade between its risk and its length."}, {"heading": "4.2 Regret Upper Bounds of the SP algorithm", "text": "Next, we analyze the regret of the stochastic pentachotomy algorithm. We refer to the behavior of SP algorithms using the blinkered subdivisions IT-3 (instead of IT3 for SP). Remember that the successive narrowing of the subdivisions IT3, the risk is always the same (as defined in Algorithm 1). We first derive an upper limit that is valid for all \u00b5-U and all time horizons. To simplify the representation, our limits on Bernoulli rewards are stated and proven, but the analysis can be extended to other exponential distribution families."}, {"heading": "4.3 Optimization error of the SP algorithm", "text": "We close this section by setting an upper limit for the optimization error of the SP and SP 'algorithms. Theorem 4.6 Let us assume that the algorithm \u03c0 = SP or \u03c0 = SP' is parameterized by \u03b3 > 1 / 2. For all \u00b5-U (C1, C2), the optimization error below \u03c0 suffices: E\u03c0 (T) \u2264 C2 C1a\u044b \u221a 24f (T) T (\u0432 \u2212 2\u0445 \u2212 1) + 3T \u2212 \u03b3\u00b5? log (TC1\u0432 \u2212) \u2022 log (1 / \u0432) = O (\u221a log (T) / T), where a\u0442 = 4 \u2212 minute (1, 2\u0432 \u2212 1) and where the parameter associated with \u00b5 in definition 4.4 is."}, {"heading": "5 Fundamental Performance Limits for Interval Trimming Subroutines", "text": "The lower limit is valid for any time horizon that contrasts with the asymptotic lower limits normally derived in the Bandit literature (see e.g. [19]). The proof for this lower limit is based on an elegant information theory argument that exploits the log sum inequality to derive lower limits of the KL divergence number. Theorem 5.1 Let us perform a sequential test for interval circumcision with minimal risk."}, {"heading": "6 Numerical Experiments", "text": "In this section, we will briefly examine the performance of SP (using the parameter \u03b3 = 0.6) and compare it with that of two other algorithms, namely KL-UCB (\u03b4) and KW. KL-UCB (\u03b4) consists in applying the CLUCB algorithm [12] to the discrete rate of reward {0, \u03b4, 2\u03b4,..., 1. KW is the algorithm proposed in [9]. More precisely, the performance of LSE [24] is not reported here, since it is generally exceeded by KL-UCB (\u03b4), as shown in [7]. We consider two reward functions to be satisfactory if the reward functions satisfy our assumptions, namely with the help of K = 2 or more precisely: \u00b5 (x) = 1 \u2212 1 / 2 \u2212 x |) for the x function [0, 1]. The first function is indistinguishable in its maximizer, while the second function is only square."}, {"heading": "7 Conclusion", "text": "In this paper, we have presented the first optimal algorithms of order for one-dimensional, continuous unimodal bandit problems, which explicitly do not take into account the structure or smoothness of the expected reward function. In a certain way, the proposed algorithm learns and adapts its sequential decisions to the smoothness of the function. Future work will focus on applying the techniques with which our algorithms are applied to other structured bandits with continuum weapons (i.e. Lipschitz or convex bandits). We would also like to extend our analysis to the case that the amount of weapons is in a higher dimension."}, {"heading": "A Additional numerical experiments", "text": "Figure 5 compares the regrets of the different algorithms for a triangular reward function \u00b5 (x) = 1 \u2212 (2 | 1 / 2 \u2212 x |) and illustrates a typical run of the SP \u2032 algorithm for such a reward function with time horizons T = 106 and \u03b3 = 0.6."}, {"heading": "B Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.1 Proof of Theorem 4.1", "text": "(K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K (K) (K) (K) (K (K) (K) (K) (K) (K) (K (K) (K) (K) (K) (K) (K (K) (K) (K) (K (K) (K) (K) (K (K) (K) (K (K) (K (K) (K) (K (K) (K (K) (K) (K (K) (K (K (K) (K) (K (K (K) (K (K (K) (K) (K (K) (K) (K (K (K) (K (K) (K (K) (K (K) (K (K) (K) (K) (K (K) (K (K) (K (K) (K) (K (K) (K) (K) (K) (K (K) (K) (K (K) (K (K (K) (K"}, {"heading": "B.2 Proof of Theorem 4.2", "text": "\u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2"}, {"heading": "B.3 Proof of Theorem 4.3", "text": "We present the following notations: The algorithm runs in phases where each phase corresponds to a call of IT3 (or IT); we define the interval after the N-th call of IT3, where I0 = [0, 1] defines the duration of the N-th call of IT3; we define the event: A-N-0-th call of IT3, which corresponds to the first N-th calls of IT3, where the first N calls of IT3 returned an interval containing the optimal arm x; we call it the addition of A. The regret due to the sample paths in Ac is limited above \u00b5; the regret due to the N-th phase of IT3-th calls of IT3, the upper phase of E-x-x."}, {"heading": "B.4 Proof of Theorem 4.5", "text": "Proposition 1 for all digits (C1, C2): (a) digit (a) digit (a) digit (a) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit (c) digit. (c) digit (c) digit (c) digit (c) digit (c) digit. (c) digit (c) digit (c) digit (c) digit (c) digit. (c) digit (c) digit (c) (c) digit (c) (c) (c) digit. (c) digit. (c) digit. (c) digit. (c) digit. (c) (c) digit. (c) (c). () (c) (). () (). () (c)."}, {"heading": "B.5 Proof of Theorem 4.6", "text": "The proof runs along the same lines as the detection of IT3, with the result that we define the two phases in which we define the individual phases, each phase according to a call to IT3 (or IT 2). We define the two phases in which we define the individual phases. We define the two phases in which we define the individual phases. We define the individual phases. We define the individual phases in which we define the individual phases. We define the individual phases in which we define the individual phases. We define the individual phases. We define the individual phases. We define the individual phases. We define the individual phases. We define the individual phases. We define the individual phases. We define the individual phases. We define the individual phases. We define the individual phases. We define the intervals according to IT3 (or IT 2). We define the intervals."}, {"heading": "B.6 Proof of Theorem 5.1", "text": "Without loss of universality, we work with a fixed sequence test. We specify the probability distribution of Y (s) = (X1 (x (1)),.., Xs (x (s)) the observed rewards from round 1 to round s. We specify the probability distribution of Y (s) below \u00b5 and \u03bb. (4) Consider the event S = 1. Since the sequence test has a minimal risk, which is smaller than the risk of round 1, and we have disregarded P\u03bb [S = 1]. (4) Consider the event S = 1. Since the sequence test has a minimal risk, which is smaller than the risk of round 1, and we have disregarded Pig [S = 1]."}, {"heading": "B.7 Proof of Corollary 5.2", "text": "Let us denote \u03b2s = P\u00b5 [Ss = 1], where Ss is the final decision taken under test results. Since \u03b2s \u2192 s \u2192 \u221e \u03b2 > 0 s0 exists, so we have for all s \u2265 s0 \u03b2s \u2265 s \u2212 \u03b3. Since \u03c7s has a minimaximum risk \u03b1 = s \u2212 \u03b3, for all s \u2265 s0, using theorem 5.1, we get: inf \u03bb B1 K \u00b2 k = 1 E [tk (s)] KL (\u00b5 (xk), \u03bb (xk)))) \u2265 KL2 (\u03b2s, \u03b1) = KL2 (\u03b2s, s \u2212 \u03b3). (6) Now, by definition of KL2, we have: KL2 (\u03b2s, s \u2212 \u03b3) = \u03b2s log (\u03b2s) + \u03b2s \u00b2 s \u00b2 + \u03b2s \u00b2 that we have the protocol (\u03b2s) + (1 \u2212 \u03b2s)."}, {"heading": "B.8 Proof of Corollary 5.3", "text": "The proof is constructive: we have a function \u00b5, so that P\u00b5 [S\u0432 6 = 0] \u2265 1 / 2. Without loss of universality, we will consider interval I = [0, 1]. Let us consider the function \u00b5 (x) = 1 \u2212 2 | 1 / 2 \u2212 x |. \u00b5 is clearly unimodal, with x? = 1 / 2 and \u00b5? = 1. Let us assume a contradiction. Let us consider a test such that P\u00b5 [S\u0432 6 = 0] \u2265 1 / 2. Since u \u00b2 (0, 1, 2} exists, there is one such that P\u00b5 [sample = u] \u2265 1 / 4. Without loss of universality, let us consider u = 1. Leave > 0, and define the function \u03bb, which is linear at intervals {[x1, x2], [x2, x3], [\u03b1, (\u03b1], (x2, (x4) / 2], [x4], [x4] & x4, x4, x4, x4, proximal]."}, {"heading": "B.9 Technical results", "text": "Lemma B.2 gives a lower limit of the KL divergence of probability measures using the Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q) Q (Q)). Then: KL (P) x (P) x (P) x (P) x (P) x (P) x (P) x) x (P) x (P) x (P) x (P) x (P) x (P) x (P) x). We have that f) x (A) x (P) x (P) x) x (P) x), so that f) x. We define p, q) the density of P, Q (Q) in relation to measurement m. We remember the derivation of the log sum inequality."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "<lb>We consider stochastic bandit problems with a continuous set of arms and where the expected re-<lb>ward is a continuous and unimodal function of the arm. No further assumption is made regarding<lb>the smoothness and the structure of the expected reward function. For these problems, we propose<lb>the Stochastic Pentachotomy (SP) algorithm, and derive finite-time upper bounds on its regret and<lb>optimization error. In particular, we show that, for any expected reward function \u03bc that behaves as<lb>\u03bc(x) = \u03bc(x)\u2212 C|x\u2212 x| locally around its maximizer x for some \u03be, C > 0, the SP algorithm is<lb>order-optimal. Namely its regret and optimization error scale as O(<lb>\u221a<lb>T log(T )) and O(<lb>\u221a<lb>log(T )/T ),<lb>respectively, when the time horizon T grows large. These scalings are achieved without the knowledge<lb>of \u03be and C. Our algorithm is based on asymptotically optimal sequential statistical tests used to suc-<lb>cessively trim an interval that contains the best arm with high probability. To our knowledge, the SP<lb>algorithm constitutes the first sequential arm selection rule that achieves a regret and optimization error<lb>scaling as O(<lb>\u221a<lb>T ) and O(1/<lb>\u221a<lb>T ), respectively, up to a logarithmic factor for non-smooth expected<lb>reward functions, as well as for smooth functions with unknown smoothness.", "creator": "LaTeX with hyperref package"}}}