{"id": "1407.1082", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jul-2014", "title": "Online Submodular Maximization under a Matroid Constraint with Application to Learning Assignments", "abstract": "Which ads should we display in sponsored search in order to maximize our revenue? How should we dynamically rank information sources to maximize the value of the ranking? These applications exhibit strong diminishing returns: Redundancy decreases the marginal utility of each ad or information source. We show that these and other problems can be formalized as repeatedly selecting an assignment of items to positions to maximize a sequence of monotone submodular functions that arrive one by one. We present an efficient algorithm for this general problem and analyze it in the no-regret model. Our algorithm possesses strong theoretical guarantees, such as a performance ratio that converges to the optimal constant of 1 - 1/e. We empirically evaluate our algorithm on two real-world online optimization problems on the web: ad allocation with submodular utilities, and dynamically ranking blogs to detect information cascades. Finally, we present a second algorithm that handles the more general case in which the feasible sets are given by a matroid constraint, while still maintaining a 1 - 1/e asymptotic performance ratio.", "histories": [["v1", "Thu, 3 Jul 2014 23:06:10 GMT  (110kb,D)", "http://arxiv.org/abs/1407.1082v1", "20 pages"]], "COMMENTS": "20 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["daniel golovin", "reas krause", "matthew streeter"], "accepted": false, "id": "1407.1082"}, "pdf": {"name": "1407.1082.pdf", "metadata": {"source": "CRF", "title": "Online Submodular Maximization under a Matroid Constraint with Application to Learning Assignments", "authors": ["Daniel Golovin", "Andreas Krause", "Matthew Streeter"], "emails": ["GOLOVIN@GMAIL.COM", "KRAUSEA@ETHZ.CH", "MATT@DUOLINGO.COM"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of us are able to put ourselves in a different world, in which they get lost in another world, in which they get lost in another world, in which they get lost in another world, in which they find themselves in another world, in which they find themselves in another world, in which they find themselves in another world, in which they do not find themselves again, in which they do not find themselves again, in which they live themselves, in which they find themselves, in which they live themselves, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "2. The assignment learning problem", "text": "We consider the problems we have to be feasible if we assign most items to a position, and must refer to each item (such as an ad) in order to maximize a user function (such as the revenue from clicking on the ads). We address both the offline problem, where the utility function is defined in advance, and the online problem, in which a sequence of utility functions can be achieved over time, and we must repeatedly select a new mapping to maximize cumulative use. The offline problem we have will give us sets P1, P2,.., PK, where PK is the set of items that can be placed in position k. We assume that these sets are disjoint. One mapping is a subset S, where P1, P2, P2, and PK is the set of all items."}, {"heading": "3. An approximation algorithm for the offline problem", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 The locally greedy algorithm", "text": "A simple approach to the assignment problem is the following greedy procedure: The algorithm goes through all K positions (in a fixed, arbitrary order); for position k, it simply selects the element that increases the total value as much as possible, i.e. it selects S + e for S + e, i.e., it does not matter what order is chosen over the positions, this so-called greedy algorithm produces an assignment that gets at least half of the optimal value (Fisher et al., 1978); in fact, the following more general result applies. We will use this problem in the analysis of our improved offline algorithm, which calls the localgreedy algorithm subroutine.V Suppose f ad f: 2V \u2192 R."}, {"heading": "3.2 An algorithm with optimal approximation ratio", "text": "We present an algorithm that achieves the optimal approximation rate of 1 \u2212 1 / e, which means an improvement of the 12 approximation units for the locally greedy algorithms. Our algorithm associates with each partition Pk a color from a palette [C] of C colors, where we use the notation [n] = {1, 2,., n}. For each sentence S V \u00b7 [C] and vector ~ c = (c1,., cK), defined example ~ c (S) = 1 {x).Pk: (x, ck).S}.In view of a series of S (item, color) pairs that we can think of as labeling each element with one or more colors, a sentence returns containing each element x that is labeled with whatever color."}, {"heading": "4. An algorithm for online learning of assignments", "text": "\"We have not managed to find a solution.\" \"We have made it.\" \"We have made it.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\". \"\" We. \"\". \"\" We. \"\" \".\" \".\" \"\" We. \"\" \".\" \"\" \".\" \"\" \"\". \"\" \"\". \"\" \"\".. \"\" \"\". \".\". \".\". \".\". \"\". \"\". \"\" \".\" \".\" \"\". \"\" \"\". \"\" \"\" \".\" \"\". \"\" \".\" \".\". \".\" \"\". \".\" \"\" \".\". \".\" \".\" \".\" \".\". \"\". \"\". \".\" \"\". \"\". \"\" \".\" \".\" \"\". \"\" \".\". \"\". \"\". \".\". \"\". \"\". \"\". \".\" \".\" \".\" \"\" \".\". \".\" \".\". \".\" \"\". \".\" \".\" \"\". \".\" \".\" \".\" \".\". \".\" \"\". \".\" \"\" \".\". \".\" \".\" \".\" \".\". \"\". \".\" \".\" \".\" \".\" \"\". \"\" \".\". \"\". \"\" \"\". \".\" \".\" \".\". \".\" \".\" \"\". \"\". \"\". \".\". \"\". \"\". \"\" \".\". \"\" \".\". \".\" \".\". \".\". \"\". \"\" \".\" \"\" \"\". \"\". \"\". \".\". \"\". \"\". \"\" \".\". \".\" \".\". \"\". \".\". \".\". \"\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \""}, {"heading": "5. Handling arbitary matroid constraints", "text": "Our offline problem is known as maximizing a monotonous submodular function that is subject to a (simple) partitioned matroid constraint in surgical research and theoretical computer science. Investigation of this problem culminated in Vondra \u0301 k's elegant (1 \u2212 1 / e) approximation algorithm (2008) and an unconditional lower limit by Mirrokni et al. (2008). However, the CONTINUOUSGREEDY algorithm, called the CONTINUUSGREEDY algorithm, cannot be applied directly to our problem because it requires the ability to test f (\u00b7) on impracticable sets S / VP. In our context, this means that it must have the ability to ask (for example) revenue when ads a1 and a2 are placed in position # 1, while at the same time being able to provide an answer to questions that we cannot fully answer."}, {"heading": "5.1 Background: Matroid Constraints and the Continuous Greedy Algorithm", "text": "A matroidM = (V, I) is a special case with a so-called simple matroid roid constraint, that is, it is as if there is a problem (V, I). (D, I). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D. (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D)."}, {"heading": "5.2 The Online Continuous Greedy Algorithm", "text": "In this section we develop an online version of the CONTINUOUSGREEDY algorithms. We begin with an observation that the (random) variant of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (settlement) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement of the (random) settlement."}, {"heading": "5.2.1 ANALYSIS OF THE CONTINUOUS GREEDY ALGORITHM WITH NOISE", "text": "Streeter and Golovin are then interpreted as a noisy version of the problem."}, {"heading": "5.2.2 THE META-ACTIONS ANALYSIS OF THE ONLINE CONTINUOUS GREEDY ALGORITHM", "text": "In analogy to the individual case, we can define the T decisions made by the algorithm as follows: \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"Q =\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"Q\" = \"Q\" Q \"=\" Q \"Q\" = \"Q\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"Q\" = \"Q\" = \"Q\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"Q\" = \"Q\" = \"Q\" = \"Q\" Q \"=\" Q \"=\" Q \"=\" Q \"Q\" = \"Q\" = \"Q\" = \"Q\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" = \"Q\" = \"Q\" = \"Q\" = \"=\" Q \"=\" Q \"=\" Q \"=\" = \"Q\" = \"Q\" = \"Q\" = \"Q\" = \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q \"=\" Q = \"Q\" = \"=\" Q = \"Q\" = \"Q =\" Q = \"Q =\" Q \"=\" Q \"=\" Q = \"Q =\" Q \"=\" Q = \"Q\" = \"Q =\" Q = \"Q =\" Q = \"Q =\" Q \"=\" Q = \"Q =\" Q = \"Q =\" Q = \"Q =\" Q \"Q =\" Q \"Q =\" Q = \"Q\" Q = \"Q =\" Q = \"Q =\" Q = \"Q =\" Q \"Q\" Q \""}, {"heading": "5.2.3 GENERATING FEEDBACK: HOW TO ESTIMATE THE MARGINAL", "text": "We could follow Calinescu et al. (2011) and take sufficient samples to ensure that the estimates for \"F\" (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (\"Y\") (V) (V) (V) (V). \"(V).\" (V) (V). \"(V) (V).\" (V). \"(V).\" (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V). (V) (V). (V). (V). (V). (V). (V). (V). (V). (V). (V) (V) (V) (V) (. (. (V). (V) (V). (V) (V). (V) (V). (V). (V). (V) (. (. (V) (V). (V) (V). (V) (V). (. (. (.). (. (V). (2011) (2011) (2011) (2011) (2011) (2011) (2011) (2011) (2011"}, {"heading": "5.2.4 USING ONLINE CONTINUOUS GREEDY FOR THE OFFLINE PROBLEM", "text": "The ONLINECONTINUOUSGREEDY algorithm does not guarantee remorse for arbitrary sequences of targets {ft} t \u2265 0. Our analysis also suggests that it can be used to solve the original offline problem, maxS, I f (S), faster than the original (offline) CONTINUOUSGREEDY algorithm (maxS). As described in (Calinescu et al., 2011), CONTINUOUSGREEDY has a runtime of order O (n8) plus the time required to evaluate f on O (n7) arguments where the O notation suppresses logarithmic factors. Calinescu et al. (2011) describes this high complexity as \"mainly due to the number of random samples necessary to achieve high probability limits\" and suggests that these \"can be significantly reduced by more careful implementation and analysis.\""}, {"heading": "6. Evaluation", "text": "We evaluate TGONLINE experimentally using two applications: Learn to evaluate blogs that are effective at detecting cascades of information, and allocate advertising to maximize revenue."}, {"heading": "6.1 Online learning of diverse blog rankings", "text": "We look at the problem of ranking a number of blogs and news sources on the Web \u3002 Our approach is therefore based on the following idea: A blogger writes a posting, and after some time, other posts will result in us having a different way of providing information about the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the results in the way we get the way we get the results in the way we get the way we get the results in the way we get the way we get the results in the way we get the way we get the results in the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the results in the way we get the way we get the way we get the results in the way we get the way we get the results in the way we get the way we get the results in the way we get the way we get the way we get the results in the way we get the results in the way we get the way we get the way we get the way we get the results in the way we get the way we get the way"}, {"heading": "6.2 Online ad display", "text": "We evaluate TGONLINE for sponsored search ad selection problem in a simple Markovian model that includes the value of various results and complex position dependence between clicks. In this model, each user u is defined by two sets of probabilities: pclick (a) for each ad a) A, and pabandon (k) for each position k [K]. If an assignment of ads {a1, a2,.., aK} where ak takes the position k, the user scans the positions in increasing order. For each position k, the user clicks ak with probability types pclick (ak) and leaves the results page forever. Otherwise, with probability (1 \u2212 pclick (ak)) \u00b7 pabandon (k), the user loses interest and gives up the results without clicking on anything. Finally, with probability (1 \u2212 pclick (ak) and pabandon (k) is an optimal algorithm ()."}, {"heading": "7. Related Work", "text": "An earlier version of this paper appeared as Streeter et al. (2009) (also Golovin et al. (2009)).The present article is greatly expanded, including a new algorithm for online optimization of arbitrary matroids. For a general introduction to the literature on submodular functional maximization (including offline versions of the problems we are investigating) see Vondra \u0301 k (2007) and the study of Krause and Golovin (2014).For an overview of applications of the submodularity of machine learning and artificial intelligence, however, see Krause and Guestrin (2011).In the online environment, the most closely related work is that of Streeter and Golovin (2008).As we see them, sequences of monotonous submodular reward functions that arrive online and develop an online algorithm that uses multi-armed bandit algorithms as subroutines. The main difference to our work is that, as in Radski et al al al al al al al al al al."}, {"heading": "8. Conclusions", "text": "In this paper, we demonstrated that important issues, such as ad representation in sponsored search and the calculation of various rankings of information sources on the Web, require optimized assignments using submodular supply functionality. We developed an efficient algorithm, TABULARGREEDY, that achieves the optimal approximation ratio of (1 \u2212 1 / e) for this NP hardware optimization problem. We also developed an online algorithm, TGONLINE, that asymptotically achieves no (1 \u2212 1 / e) regret about the problem of repeatedly selecting informative assignments under the Full Information and Bandit Feedback settings settings. We demonstrated that our algorithm surpasses previous work on two real problems, namely online ranking of informative blogs and ad assignments. Finally, we developed ONLINECONTINUOUSGREEDY, an online algorithm that can handle more general matroid constraints but still not (1 \u2212 1) regret."}, {"heading": "Appendix A: Proofs", "text": "The difference between the two lemmas is that in contrast to Lemma 1, Lemma 12 we have the possibility that each Arg max in the locally greedy algorithm is evaluated with an additive error. \u2212 k We need this result when analyzing TGONLINE later on.Lemma 12 Let f: P \u2192 R \u2265 0 be a function of the form f (S) = f0 (S) + f \u00b2 K = 1 fk (S), where f0: 2 V \u00b2 R \u00b2 s is monotonously submodular, and fk: P \u00b2 R \u00b2 0 is a function of the form f (S) = f0 (S) + p \u00b2 K = 1 fk (S), where f0: 2 V \u00b2 R \u00b2 s is monotonously submodular, and fk: P \u00b2 s \u00b2 s arbitrary for k \u00b2 s = 0."}], "references": [{"title": "Sponsored search auctions with Markovian users", "author": ["Gagan Aggarwal", "Jon Feldman", "S. Muthukrishnan", "Martin P\u00e1l"], "venue": "In WINE,", "citeRegEx": "Aggarwal et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Aggarwal et al\\.", "year": 2008}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "From external to internal regret", "author": ["Avrim Blum", "Yishay Mansour"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Blum and Mansour.,? \\Q2007\\E", "shortCiteRegEx": "Blum and Mansour.", "year": 2007}, {"title": "Maximizing a submodular set function subject to a matroid constraint", "author": ["Gruia Calinescu", "Chandra Chekuri", "Martin P\u00e1l", "Jan Vondr\u00e1k"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Calinescu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Calinescu et al\\.", "year": 2011}, {"title": "How to use expert advice", "author": ["Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "David Haussler", "David P. Helmbold", "Robert E. Schapire", "Manfred K. Warmuth"], "venue": "J. ACM,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 1997}, {"title": "Contextual sequence prediction with application to control library optimization", "author": ["Debadeepta Dey", "Tian Yu Liu", "Martial Hebert", "J Andrew Bagnell"], "venue": null, "citeRegEx": "Dey et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dey et al\\.", "year": 2013}, {"title": "Internet advertising and the generalized second price auction: Selling billions of dollars worth of keywords", "author": ["Benjamin Edelman", "Michael Ostrovsky", "Michael Schwarz"], "venue": "American Economic Review,", "citeRegEx": "Edelman et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Edelman et al\\.", "year": 2007}, {"title": "Algorithmic methods for sponsored search advertising", "author": ["Jon Feldman", "S. Muthukrishnan"], "venue": "Performance Modeling and Engineering", "citeRegEx": "Feldman and Muthukrishnan.,? \\Q2008\\E", "shortCiteRegEx": "Feldman and Muthukrishnan.", "year": 2008}, {"title": "An analysis of approximations for maximizing submodular set functions - II", "author": ["Marshall L. Fisher", "George L. Nemhauser", "Laurence A. Wolsey"], "venue": "Mathematical Programming Study,", "citeRegEx": "Fisher et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Fisher et al\\.", "year": 1978}, {"title": "Online learning of assignments that maximize submodular functions", "author": ["Daniel Golovin", "Andreas Krause", "Matthew Streeter"], "venue": "CoRR, abs/0908.0772,", "citeRegEx": "Golovin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Golovin et al\\.", "year": 2009}, {"title": "Playing games with approximation algorithms", "author": ["Sham M. Kakade", "Adam Tauman Kalai", "Katrina Ligett"], "venue": "In STOC,", "citeRegEx": "Kakade et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2007}, {"title": "Efficient algorithms for online decision problems", "author": ["Adam Kalai", "Santosh Vempala"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Kalai and Vempala.,? \\Q2005\\E", "shortCiteRegEx": "Kalai and Vempala.", "year": 2005}, {"title": "Submodular function maximization. In Tractability: Practical Approaches to Hard Problems (to appear)", "author": ["Andreas Krause", "Daniel Golovin"], "venue": "URL files/krause12survey.pdf", "citeRegEx": "Krause and Golovin.,? \\Q2014\\E", "shortCiteRegEx": "Krause and Golovin.", "year": 2014}, {"title": "Submodularity and its applications in optimized information gathering", "author": ["Andreas Krause", "Carlos Guestrin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Krause and Guestrin.,? \\Q2011\\E", "shortCiteRegEx": "Krause and Guestrin.", "year": 2011}, {"title": "Sponsored search auctions", "author": ["S\u00e9bastien Lahaie", "David M. Pennock", "Amin Saberi", "Rakesh V. Vohra"], "venue": null, "citeRegEx": "Lahaie et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Lahaie et al\\.", "year": 2007}, {"title": "Cost-effective outbreak detection in networks", "author": ["Jure Leskovec", "Andreas Krause", "Carlos Guestrin", "Christos Faloutsos", "Jeanne VanBriesen", "Natalie Glance"], "venue": "In KDD,", "citeRegEx": "Leskovec et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2007}, {"title": "Tight information-theoretic lower bounds for welfare maximization in combinatorial auctions", "author": ["Vahab Mirrokni", "Michael Schapira", "Jan Vondr\u00e1k"], "venue": "In EC,", "citeRegEx": "Mirrokni et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mirrokni et al\\.", "year": 2008}, {"title": "An analysis of approximations for maximizing submodular set functions - I", "author": ["George L. Nemhauser", "Laurence A. Wolsey", "Marshall L. Fisher"], "venue": "Mathematical Programming,", "citeRegEx": "Nemhauser et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Nemhauser et al\\.", "year": 1978}, {"title": "Learning diverse rankings with multi-armed bandits", "author": ["Filip Radlinski", "Robert Kleinberg", "Thorsten Joachims"], "venue": "In ICML,", "citeRegEx": "Radlinski et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Radlinski et al\\.", "year": 2008}, {"title": "Learning policies for contextual submodular prediction", "author": ["Stephane Ross", "Jiaji Zhou", "Yisong Yue", "Debadeepta Dey", "Drew Bagnell"], "venue": "In Proceedings of The 30th International Conference on Machine Learning,", "citeRegEx": "Ross et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2013}, {"title": "Combinatorial optimization : polyhedra and efficiency. Volume B: Matroids, Trees, Stable Sets, chapters 39-69", "author": ["Alexander Schrijver"], "venue": null, "citeRegEx": "Schrijver.,? \\Q2003\\E", "shortCiteRegEx": "Schrijver.", "year": 2003}, {"title": "An online algorithm for maximizing submodular functions", "author": ["Matthew Streeter", "Daniel Golovin"], "venue": "Technical Report CMU-CS-07-171,", "citeRegEx": "Streeter and Golovin.,? \\Q2007\\E", "shortCiteRegEx": "Streeter and Golovin.", "year": 2007}, {"title": "An online algorithm for maximizing submodular functions", "author": ["Matthew Streeter", "Daniel Golovin"], "venue": "In NIPS,", "citeRegEx": "Streeter and Golovin.,? \\Q2008\\E", "shortCiteRegEx": "Streeter and Golovin.", "year": 2008}, {"title": "Online learning of assignments", "author": ["Matthew Streeter", "Daniel Golovin", "Andreas Krause"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Streeter et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Streeter et al\\.", "year": 2009}, {"title": "Submodularity in Combinatorial Optimization", "author": ["Jan Vondr\u00e1k"], "venue": "PhD thesis, Charles University, Prague, Czech Republic,", "citeRegEx": "Vondr\u00e1k.,? \\Q2007\\E", "shortCiteRegEx": "Vondr\u00e1k.", "year": 2007}, {"title": "Optimal approximation for the submodular welfare problem in the value oracle model", "author": ["Jan Vondr\u00e1k"], "venue": "In STOC,", "citeRegEx": "Vondr\u00e1k.,? \\Q2008\\E", "shortCiteRegEx": "Vondr\u00e1k.", "year": 2008}], "referenceMentions": [{"referenceID": 1, "context": "When there is only one position, this problem becomes the well-studied multi-armed bandit problem (Auer et al., 2002).", "startOffset": 98, "endOffset": 117}, {"referenceID": 6, "context": "For example, online advertising models with click-through-rates (Edelman et al., 2007) make an assumption of this form.", "startOffset": 64, "endOffset": 86}, {"referenceID": 18, "context": "More recently, there have been attempts to incorporate the value of diversity in the reward function (Radlinski et al., 2008).", "startOffset": 101, "endOffset": 125}, {"referenceID": 23, "context": "An earlier version of this work appeared as Streeter et al. (2009).", "startOffset": 44, "endOffset": 67}, {"referenceID": 3, "context": "The problem of maximizing a submodular function subject to arbitrary matroid constraints was recently resolved by Calinescu et al. (2011), who provided an algorithm with optimal (under reasonable complexity assumptions) approximation guarantees.", "startOffset": 114, "endOffset": 138}, {"referenceID": 16, "context": "In fact, Mirrokni et al. (2008) show that any algorithm that is guaranteed to obtain a solution within a factor of (1\u22121/e+ ) of the optimal value requires exponentially many evaluations", "startOffset": 9, "endOffset": 32}, {"referenceID": 7, "context": "See Feldman and Muthukrishnan (2008) and Lahaie et al.", "startOffset": 4, "endOffset": 37}, {"referenceID": 7, "context": "See Feldman and Muthukrishnan (2008) and Lahaie et al. (2007) for more details on sponsored search ad allocation.", "startOffset": 4, "endOffset": 62}, {"referenceID": 7, "context": "See Feldman and Muthukrishnan (2008) and Lahaie et al. (2007) for more details on sponsored search ad allocation. Note that in both of these cases, the (expected) reward of a set S of (ad, position) pairs is \u2211 (a,k)\u2208S g(a, k) for some nonnegative function g. It is easy to verify that such a reward function is monotone submodular. Thus, we can capture this model in our framework by setting Pk = A\u00d7 {k}, where A is the set of ads. Another subsumed model, for web search, appears in Radlinski et al. (2008); it assumes that each user is interested in a particular set of results, and any list of results that intersects this set generates a unit of value; all other lists generate no value, and the ordering of results is irrelevant.", "startOffset": 4, "endOffset": 507}, {"referenceID": 7, "context": "See Feldman and Muthukrishnan (2008) and Lahaie et al. (2007) for more details on sponsored search ad allocation. Note that in both of these cases, the (expected) reward of a set S of (ad, position) pairs is \u2211 (a,k)\u2208S g(a, k) for some nonnegative function g. It is easy to verify that such a reward function is monotone submodular. Thus, we can capture this model in our framework by setting Pk = A\u00d7 {k}, where A is the set of ads. Another subsumed model, for web search, appears in Radlinski et al. (2008); it assumes that each user is interested in a particular set of results, and any list of results that intersects this set generates a unit of value; all other lists generate no value, and the ordering of results is irrelevant. Again, the reward function is monotone submodular. In this setting, it is desirable to display a diverse set of results in order to maximize the likelihood that at least one of them will interest the user. Our model is flexible in that we can handle position-dependent effects and diversity considerations simultaneously. For example, we can handle the case that each user u is interested in a particular set Au of ads and looks at a set Iu of positions, and the reward of an assignment S is any monotone-increasing concave function g of |S \u2229 (Au \u00d7 Iu)|. If Iu = {1, 2, . . . , k} and g(x) = x, this models the case where the quality is the number of relevant result that appear in the first k positions. If Iu equals all positions and g(x) = min {x, 1} we recover the model of Radlinski et al. (2008).", "startOffset": 4, "endOffset": 1536}, {"referenceID": 8, "context": "Perhaps surprisingly, no matter which ordering over the positions is chosen, this so-called locally greedy algorithm produces an assignment that obtains at least half the optimal value (Fisher et al., 1978).", "startOffset": 185, "endOffset": 206}, {"referenceID": 3, "context": "In the limit as C \u2192\u221e, TABULARGREEDY can intuitively be viewed as an algorithm for a continuous extension of the problem followed by a rounding procedure, in the same spirit as Vondr\u00e1k\u2019s CONTINUOUSGREEDY algorithm (Calinescu et al., 2011).", "startOffset": 213, "endOffset": 237}, {"referenceID": 17, "context": "The latter process, in turn, can be shown to be equivalent to a greedy algorithm for maximizing a (different) submodular function subject to a cardinality constraint, which implies that it achieves a 1\u2212 1/e approximation ratio (Nemhauser et al., 1978).", "startOffset": 227, "endOffset": 251}, {"referenceID": 17, "context": "For problems with this special property, it is known that the locally greedy algorithm obtains an approximation ratio of \u03b2(C) = 1\u2212 (1\u2212 1 C ) C (Nemhauser et al., 1978).", "startOffset": 143, "endOffset": 167}, {"referenceID": 17, "context": "For problems with this special property, it is known that the locally greedy algorithm obtains an approximation ratio of \u03b2(C) = 1\u2212 (1\u2212 1 C ) C (Nemhauser et al., 1978). Theorem 6 of Streeter and Golovin (2007) extends this result to handle additive error, and yields", "startOffset": 144, "endOffset": 210}, {"referenceID": 18, "context": "A similar approach was used by Radlinski et al. (2008) and Streeter and Golovin (2008) to obtain an online algorithm for different (simpler) online problems.", "startOffset": 31, "endOffset": 55}, {"referenceID": 18, "context": "A similar approach was used by Radlinski et al. (2008) and Streeter and Golovin (2008) to obtain an online algorithm for different (simpler) online problems.", "startOffset": 31, "endOffset": 87}, {"referenceID": 4, "context": "1 If TGONLINE is run with randomized weighted majority (Cesa-Bianchi et al., 1997) as the subroutine, then", "startOffset": 55, "endOffset": 82}, {"referenceID": 2, "context": "For example, Blum and Mansour (2007) consider online problems in which we are given time-selection functions I1, I2, .", "startOffset": 13, "endOffset": 37}, {"referenceID": 3, "context": "Vondr\u00e1k\u2019s algorithm, called the CONTINUOUSGREEDY algorithm, has also been extended to handle arbitrary matroid constraints (Calinescu et al., 2011).", "startOffset": 123, "endOffset": 147}, {"referenceID": 22, "context": "The study of this problem culminated in the elegant (1\u2212 1/e) approximation algorithm of Vondr\u00e1k (2008) and a matching unconditional lower bound of Mirrokni et al.", "startOffset": 88, "endOffset": 103}, {"referenceID": 15, "context": "The study of this problem culminated in the elegant (1\u2212 1/e) approximation algorithm of Vondr\u00e1k (2008) and a matching unconditional lower bound of Mirrokni et al. (2008). Vondr\u00e1k\u2019s algorithm, called the CONTINUOUSGREEDY algorithm, has also been extended to handle arbitrary matroid constraints (Calinescu et al.", "startOffset": 147, "endOffset": 170}, {"referenceID": 20, "context": "Schrijver (2003). We are interested in problems of the form", "startOffset": 0, "endOffset": 17}, {"referenceID": 3, "context": "To obtain a (1 \u2212 1/e) approximation to Problem (2), Calinescu et al. (2011) use Vondr\u00e1k\u2019s CONTINUOUSGREEDY algorithm.", "startOffset": 52, "endOffset": 76}, {"referenceID": 23, "context": "However, Vondr\u00e1k (2008) shows how a (1\u2212 1/e) approximation may be obtained as follows.", "startOffset": 9, "endOffset": 24}, {"referenceID": 3, "context": "For technical reasons, Calinescu et al. (2011) replace all occurrences of the gradient\u2207F (y) in the continuous process with a related quantity called the marginal, \u2206F (y) \u2208 R\u22650, defined coordinate-wise by (\u2206F (y))v = E [f(Sy \u222a {v})\u2212 f(Sy)] = (1\u2212 yv)(\u2207F (y))v.", "startOffset": 23, "endOffset": 47}, {"referenceID": 3, "context": "For technical reasons, Calinescu et al. (2011) replace all occurrences of the gradient\u2207F (y) in the continuous process with a related quantity called the marginal, \u2206F (y) \u2208 R\u22650, defined coordinate-wise by (\u2206F (y))v = E [f(Sy \u222a {v})\u2212 f(Sy)] = (1\u2212 yv)(\u2207F (y))v. The second complication arises because \u2206F (y) cannot be computed exactly given oracle access to f , but must be estimated via random sampling. Calinescu et al. (2011) choose to take enough samples are taken so that by Chernoff bounds it is likely that the estimate of each coordinate of \u2206F (y(t)) for each iteration t \u2208 {0, \u03b4, 2\u03b4, .", "startOffset": 23, "endOffset": 427}, {"referenceID": 23, "context": "Algorithm: Continuous Greedy (Vondr\u00e1k (2008); Calinescu et al.", "startOffset": 30, "endOffset": 45}, {"referenceID": 3, "context": "Algorithm: Continuous Greedy (Vondr\u00e1k (2008); Calinescu et al. (2011)) Input: matroidM = (V, I), monotone submodular f : 2V \u2192 R\u22650, \u03b4 \u2208 {1/n : n \u2208 N}, \u03c1 \u2208 N", "startOffset": 46, "endOffset": 70}, {"referenceID": 3, "context": "For default parameters, Calinescu et al. (2011) select \u03b4 = 1/9d where d = max {|S| : S \u2208 I} is the rank ofM, and \u03c1 = 10 \u03b42 (1 + ln |V|) samples per marginal coordinate.", "startOffset": 24, "endOffset": 48}, {"referenceID": 3, "context": "Refer to (Calinescu et al., 2011) for details.", "startOffset": 9, "endOffset": 33}, {"referenceID": 3, "context": "We begin with an observation that the (randomized variant of the) pipage rounding scheme in Calinescu et al. (2011) is oblivious, in the sense that it does not require access to the objective function.", "startOffset": 92, "endOffset": 116}, {"referenceID": 3, "context": "We begin with an observation that the (randomized variant of the) pipage rounding scheme in Calinescu et al. (2011) is oblivious, in the sense that it does not require access to the objective function. This was emphasized by Calinescu et al. (2011), who point out its advantage in settings where we have only approximate-oracle access to f .", "startOffset": 92, "endOffset": 249}, {"referenceID": 11, "context": "For this, the follow the perturbed leader algorithm (Kalai and Vempala, 2005) is suitable.", "startOffset": 52, "endOffset": 77}, {"referenceID": 21, "context": "1 ANALYSIS OF THE CONTINUOUS GREEDY ALGORITHM WITH NOISE Streeter and Golovin (2008) introduced an analysis framework based on \u201cmeta-actions\u201d, in which an online process over T rounds is interpreted as a single run in a combined instance of a suitable offline problem with objective \u2211T t=1 Ft, in which the algorithm makes errors.", "startOffset": 57, "endOffset": 85}, {"referenceID": 3, "context": "That H is monotone submodular follows easily from the facts that \u2202F \u2202yu \u2265 0 and \u2202 F \u2202yu\u2202yv \u2264 0 (Calinescu et al., 2011).", "startOffset": 95, "endOffset": 119}, {"referenceID": 3, "context": "That H is monotone submodular follows easily from the facts that \u2202F \u2202yu \u2265 0 and \u2202 F \u2202yu\u2202yv \u2264 0 (Calinescu et al., 2011). Hence from Theorem 6 of Streeter and Golovin (2007), which bounds the performance of a noisy version of the locally greedy algorithm for precisely this problem, we obtain", "startOffset": 96, "endOffset": 173}, {"referenceID": 3, "context": "We bound this source of error as in Lemma 4, using a slight variation of an argument of Calinescu et al. (2011).", "startOffset": 88, "endOffset": 112}, {"referenceID": 11, "context": "1 of Kalai and Vempala (2005)), suitably tailored for our purposes, is O(d \u221a ngT ) where d is the rank ofM, n = |V|, and g = maxt,v ft({v}) is an upper bound for each coordinate of \u2206Ft.", "startOffset": 5, "endOffset": 30}, {"referenceID": 3, "context": "3 GENERATING FEEDBACK: HOW TO ESTIMATE THE MARGINAL We could follow Calinescu et al. (2011) and take sufficiently many samples to ensure that with high probability the estimates for \u2206F (y(\u03c4 \u2212 \u03b4)) are sharp.", "startOffset": 68, "endOffset": 92}, {"referenceID": 21, "context": "Lemma 10 (Lemma 5 of Streeter and Golovin (2007)) Let E be a no-regret algorithm that incurs a worst-case expected regret R(T ) over T rounds in the full-information feedback model.", "startOffset": 21, "endOffset": 49}, {"referenceID": 3, "context": "As described in (Calinescu et al., 2011), CONTINUOUSGREEDY has a running time of order \u00d5(n) plus the time required to evaluate f on \u00d5(n) arguments, where the \u00d5 notation suppresses logarithmic factors.", "startOffset": 16, "endOffset": 40}, {"referenceID": 3, "context": "As described in (Calinescu et al., 2011), CONTINUOUSGREEDY has a running time of order \u00d5(n) plus the time required to evaluate f on \u00d5(n) arguments, where the \u00d5 notation suppresses logarithmic factors. Calinescu et al. (2011) describe this high complexity as being \u201cmostly due to the number of random samples necessary to achieve high probability bounds\u201d and suggest that this \u201ccan be substantially reduced by a more careful implementation and analysis.", "startOffset": 17, "endOffset": 225}, {"referenceID": 15, "context": "In Leskovec et al. (2007) it is shown how one can formalize this notion of utility using a monotone submodular function that measures the informativeness of a subset of blogs.", "startOffset": 3, "endOffset": 26}, {"referenceID": 15, "context": "The work by Leskovec et al. (2007) leaves two major shortcomings: Firstly, they select a set of blogs rather than a ranking, which is of practical importance for the presentation on a web service.", "startOffset": 12, "endOffset": 35}, {"referenceID": 15, "context": "The work by Leskovec et al. (2007) leaves two major shortcomings: Firstly, they select a set of blogs rather than a ranking, which is of practical importance for the presentation on a web service. Secondly, they do not address the problem of sequential prediction, where the set of blogs must be updated dynamically over time. In this paper, we address these shortcomings. Results on offline blog ranking. In order to model the blog ranking problem, we adopt the assumption that different users have different attention spans: Each user will only consider blogs appearing in a particular subset of positions. In our experiments, we assume that the probability that a user is willing to look at position k is proportional to \u03b3, for some discount factor 0 < \u03b3 < 1. More formally, let g be the monotone submodular function measuring the informativeness of any set of blogs, defined as in Leskovec et al. (2007). Let Pk = B\u00d7{k}, where B is the set of blogs.", "startOffset": 12, "endOffset": 908}, {"referenceID": 15, "context": "The work by Leskovec et al. (2007) leaves two major shortcomings: Firstly, they select a set of blogs rather than a ranking, which is of practical importance for the presentation on a web service. Secondly, they do not address the problem of sequential prediction, where the set of blogs must be updated dynamically over time. In this paper, we address these shortcomings. Results on offline blog ranking. In order to model the blog ranking problem, we adopt the assumption that different users have different attention spans: Each user will only consider blogs appearing in a particular subset of positions. In our experiments, we assume that the probability that a user is willing to look at position k is proportional to \u03b3, for some discount factor 0 < \u03b3 < 1. More formally, let g be the monotone submodular function measuring the informativeness of any set of blogs, defined as in Leskovec et al. (2007). Let Pk = B\u00d7{k}, where B is the set of blogs. Given an assignment S \u2208 P , let S = S \u2229{P1 \u222a P2 \u222a . . . \u222a Pk} be the assignment of blogs to positions 1 through k. We define the discounted value of the assignment S as f(S) = \u2211K k=1 \u03b3 k ( g(S)\u2212 g(S[k\u22121]) ) . It can be seen that f : 2V \u2192 R\u22650 is monotone submodular. For our experiments, we use the data set of Leskovec et al. (2007), consisting of 45,192 blogs, 16,551 cascades, and 2 million postings collected during 12 months of 2006.", "startOffset": 12, "endOffset": 1287}, {"referenceID": 15, "context": "The work by Leskovec et al. (2007) leaves two major shortcomings: Firstly, they select a set of blogs rather than a ranking, which is of practical importance for the presentation on a web service. Secondly, they do not address the problem of sequential prediction, where the set of blogs must be updated dynamically over time. In this paper, we address these shortcomings. Results on offline blog ranking. In order to model the blog ranking problem, we adopt the assumption that different users have different attention spans: Each user will only consider blogs appearing in a particular subset of positions. In our experiments, we assume that the probability that a user is willing to look at position k is proportional to \u03b3, for some discount factor 0 < \u03b3 < 1. More formally, let g be the monotone submodular function measuring the informativeness of any set of blogs, defined as in Leskovec et al. (2007). Let Pk = B\u00d7{k}, where B is the set of blogs. Given an assignment S \u2208 P , let S = S \u2229{P1 \u222a P2 \u222a . . . \u222a Pk} be the assignment of blogs to positions 1 through k. We define the discounted value of the assignment S as f(S) = \u2211K k=1 \u03b3 k ( g(S)\u2212 g(S[k\u22121]) ) . It can be seen that f : 2V \u2192 R\u22650 is monotone submodular. For our experiments, we use the data set of Leskovec et al. (2007), consisting of 45,192 blogs, 16,551 cascades, and 2 million postings collected during 12 months of 2006. We use the population affected objective of Leskovec et al. (2007), and use a discount factor of \u03b3 = 0.", "startOffset": 12, "endOffset": 1459}, {"referenceID": 18, "context": "Note that C = 1 corresponds to the online algorithm of Radlinski et al. (2008) and Streeter and Golovin (2008).", "startOffset": 55, "endOffset": 79}, {"referenceID": 18, "context": "Note that C = 1 corresponds to the online algorithm of Radlinski et al. (2008) and Streeter and Golovin (2008).", "startOffset": 55, "endOffset": 111}, {"referenceID": 17, "context": "TGONLINE with C = 4 to the online algorithm of Radlinski et al. (2008); Streeter and Golovin (2008), based on the average of 100 experiments.", "startOffset": 47, "endOffset": 71}, {"referenceID": 17, "context": "TGONLINE with C = 4 to the online algorithm of Radlinski et al. (2008); Streeter and Golovin (2008), based on the average of 100 experiments.", "startOffset": 47, "endOffset": 100}, {"referenceID": 0, "context": "A slightly different Markov model of user behavior which is efficiently solvable was considered in Aggarwal et al. (2008). In that model, pclick and pabandon are the same for all users, and pabandon is a function of the ad in the slot currently being scanned rather than its index.", "startOffset": 99, "endOffset": 122}, {"referenceID": 14, "context": "Related Work An earlier version of this work appeared as Streeter et al. (2009) (also Golovin et al.", "startOffset": 57, "endOffset": 80}, {"referenceID": 8, "context": "(2009) (also Golovin et al. (2009)).", "startOffset": 13, "endOffset": 35}, {"referenceID": 8, "context": "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondr\u00e1k (2007) and the survey by Krause and Golovin (2014).", "startOffset": 13, "endOffset": 314}, {"referenceID": 8, "context": "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondr\u00e1k (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011).", "startOffset": 13, "endOffset": 358}, {"referenceID": 8, "context": "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondr\u00e1k (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011). In the online setting, the most closely related work is that of Streeter and Golovin (2008).", "startOffset": 13, "endOffset": 488}, {"referenceID": 8, "context": "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondr\u00e1k (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011). In the online setting, the most closely related work is that of Streeter and Golovin (2008). Like us, they consider sequences of monotone submodular reward functions that arrive online, and develop an online algorithm that uses multi-armed bandit algorithms as subroutines.", "startOffset": 13, "endOffset": 581}, {"referenceID": 8, "context": "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondr\u00e1k (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011). In the online setting, the most closely related work is that of Streeter and Golovin (2008). Like us, they consider sequences of monotone submodular reward functions that arrive online, and develop an online algorithm that uses multi-armed bandit algorithms as subroutines. The key difference from our work is that, as in Radlinski et al. (2008), they are concerned with selecting a set of K items rather than the more general problem of selecting an assignment of items to positions addressed in this paper.", "startOffset": 13, "endOffset": 835}, {"referenceID": 8, "context": "(2009) (also Golovin et al. (2009)). The present article is significantly extended, including a new algorithm for online optimization over arbitrary matroids. For a general introduction to the literature on submodular function maximization (including offline versions of the problems we study), see Vondr\u00e1k (2007) and the survey by Krause and Golovin (2014). For an overview of applications of submodularity to machine learning and artificial intelligence, see Krause and Guestrin (2011). In the online setting, the most closely related work is that of Streeter and Golovin (2008). Like us, they consider sequences of monotone submodular reward functions that arrive online, and develop an online algorithm that uses multi-armed bandit algorithms as subroutines. The key difference from our work is that, as in Radlinski et al. (2008), they are concerned with selecting a set of K items rather than the more general problem of selecting an assignment of items to positions addressed in this paper. Kakade et al. (2007) considered the general problem of using \u03b1-approximation algorithms to construct no \u03b1-regret online algorithms, and essentially proved it could be done for the class of linear optimization problems in which the cost function has the form c(S,w) for a solution S and weight vector w, and c(S,w) is linear in w.", "startOffset": 13, "endOffset": 1019}, {"referenceID": 5, "context": "Since the earlier version of this paper appeared, subsequent research has produced algorithms that incorporate context into their decisions: Dey et al. (2013) developed an algorithm for contextual optimization of sequences of actions, and used it to optimize control libraries used for various robotic planning tasks.", "startOffset": 141, "endOffset": 159}, {"referenceID": 10, "context": "Of course, it is possible to linearize a submodular function by using a separate dimension for every possible function argument, but this results in an exponential number of dimensions, which leads to exponentially worse convergence time and regret bounds for the algorithms in Kakade et al. (2007) relative to TGONLINE.", "startOffset": 278, "endOffset": 299}], "year": 2014, "abstractText": "Which ads should we display in sponsored search in order to maximize our revenue? How should we dynamically rank information sources to maximize the value of the ranking? These applications exhibit strong diminishing returns: Redundancy decreases the marginal utility of each ad or information source. We show that these and other problems can be formalized as repeatedly selecting an assignment of items to positions to maximize a sequence of monotone submodular functions that arrive one by one. We present an efficient algorithm for this general problem and analyze it in the no-regret model. Our algorithm possesses strong theoretical guarantees, such as a performance ratio that converges to the optimal constant of 1 \u2212 1/e. We empirically evaluate our algorithm on two real-world online optimization problems on the web: ad allocation with submodular utilities, and dynamically ranking blogs to detect information cascades. Finally, we present a second algorithm that handles the more general case in which the feasible sets are given by a matroid constraint, while still maintaining a 1\u2212 1/e asymptotic performance ratio.", "creator": "LaTeX with hyperref package"}}}