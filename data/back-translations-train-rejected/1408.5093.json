{"id": "1408.5093", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2014", "title": "Caffe: Convolutional Architecture for Fast Feature Embedding", "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU ($\\approx$ 2.5 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.", "histories": [["v1", "Fri, 20 Jun 2014 23:00:32 GMT  (4046kb,D)", "http://arxiv.org/abs/1408.5093v1", "Tech report for the Caffe software atthis http URL"]], "COMMENTS": "Tech report for the Caffe software atthis http URL", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["yangqing jia", "evan shelhamer", "jeff donahue", "sergey karayev", "jonathan long", "ross girshick", "sergio guadarrama", "trevor darrell"], "accepted": false, "id": "1408.5093"}, "pdf": {"name": "1408.5093.pdf", "metadata": {"source": "CRF", "title": "Caffe: Convolutional Architecture for Fast Feature Embedding", "authors": ["Yangqing Jia", "Evan Shelhamer", "Jeff Donahue", "Sergey Karayev", "Jonathan Long", "Ross Girshick", "Sergio Guadarrama", "Trevor Darrell"], "emails": ["jiayq@eecs.berkeley.edu", "shelhamer@eecs.berkeley.edu", "jdonahue@eecs.berkeley.edu", "sergeyk@eecs.berkeley.edu", "jonlong@eecs.berkeley.edu", "rbg@eecs.berkeley.edu", "sguada@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "sections": [{"heading": null, "text": "Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It supports ongoing research projects, large-scale industrial applications, and startup prototypes in the fields of vision, language, and multimedia.Categories and Subject Descriptors I.5.1 [Pattern Recognition]: [Applications-Computer Vision]; D.2.2 [Software Engineering]: [Design Tools and Techniques-Software libraries]; I.5.1 [Pattern Recognition]: [Models-Neural Nets] General Terms Algorithms, Design, Experimental Keywords Open Source, Computer Vision, Neural Networks, Parallel Computation, Machine Learning \u2012 Corresponding Authors. The work was conducted during Yangqing Jia's doctoral studies in Berkeley. He is currently a research scientist at Google, 1600 Amphitheatre Pkwy, Mountain View, CA 94043.."}, {"heading": "1. INTRODUCTION", "text": "In fact, we see ourselves in a position to create the aforementioned brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated brainconsecrated braintecnteeaeBn."}, {"heading": "2. HIGHLIGHTS OF CAFFE", "text": "Caffe provides a complete toolkit for training, testing, finetuning and providing models, with well-documented examples for all of these tasks. As such, it is an ideal starting point for researchers and other developers who want to jump into cutting-edge machine learning, while at the same time being probably the fastest implementation of these algorithms available, making it immediately useful for industrial use. Modularity. The software is designed to be as modular as possible from the outset, allowing for rapid expansion to new data formats, network layers and loss functions. Many layers and loss functions are already implemented, and numerous examples show how they are assembled into traceable detection systems for various tasks. Separation of representation and implementation. Caffe model definitions are written as trusted files using the protocol buffer language. Caffe supports network architectures in the form of arbitrary acyc graphs."}, {"heading": "2.1 Comparison to related software", "text": "Although our list is incomplete, we have compiled the toolkits that are, to the best of our knowledge, the most noteworthy. Caffe differs from other contemporary CNN frameworks in two ways: (1) its implementation is fully C + + based, making it easier to integrate with existing C + + systems and interfaces common in the industry; the CPU mode removes the barrier of specialized hardware for deployment and experimentation once a model is trained; (2) off-the-shelf reference models are provided to quickly experiment with cutting-edge results without the need for costly re-learning; and by fine-tuning to related tasks, such as those studied by [2], these models provide a warm-up for new research and applications; and, crucially, we publish not only the trained models, but also the recipes and code to reproduce them."}, {"heading": "3. ARCHITECTURE", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Data Storage", "text": "Caffe stores and communicates data in four-dimensional arrays, called blobs. Blobs provide a unified storage interface where images (or other data), parameters, or parameter updates are stored. Blobs hide the computational and thought effort of mixed CPU / GPU operation by synchronizing them from the CPU host to the GPU device when needed. In practice, data is loaded from the hard drive to a block in the CPU code, invokes a CUDA kernel to perform the GPU calculation, and moves the block to the next level, ignoring low-level details while maintaining a high level of performance. Storage on the host and the device is allocated (inertia) as needed for efficient memory usage. Models are stored on the hard drive as Google Protocol Buffers1, which have several important features: minimal serial data format, compatible with multiple languages, and a human-readable data base."}, {"heading": "3.2 Layers", "text": "A caffe layer is the essence of a neural network layer: it takes one or more blobs as input and delivers one or more blobs as output. Layers have two central responsibilities for the operation of the network as a whole: a forward pass that takes the inputs and produces the outputs, and a reverse pass that takes the gradient in terms of output and calculates the gradients in terms of parameters and inputs, which in turn are propagated back to earlier layers. Caffe offers a full range of layer types, including: folding, pooling, internal products, non-linear such as rectified linear and logistic, local reaction normalization, elementary operations and losses such as softmax and hinge. These are all types required for state-of-the-art visual tasks."}, {"heading": "3.3 Networks and Run Mode", "text": "The Caffe models are end-to-end machine learning systems. A typical network starts with a layer of data loaded from the hard disk and ends with a loss layer that calculates the target for a task such as classification or reconstruction. The network is run on a CPU or GPU by setting a single switch. Layers have appropriate CPU and GPU routines that provide identical results (with tests to prove this). The CPU / GPU switch is seamless and independent of the model definition."}, {"heading": "3.4 Training A Network", "text": "Figure 1 shows a typical example of a caffe network (for the MNIST digit classification) during training: A data layer fetches the images and labels1https: / / code.google.com / p / protobuf / 2https: / / code.google.com / p / leveldb / from the hard disk, guides it through several layers such as folding, pooling, and rectified linear transformations, and transfers the final prediction into a classification loss layer that generates the loss and gradients that train the entire network. This example can be found in the caffe source code in examples / lenet / lenet _ train.prototxt. The data is processed into mini batches that traverse the network sequentially. Decisive for the training are loss of learning speed, dynamics, and stop-and-resume snapshots, all of which are implemented and documented."}, {"heading": "4. APPLICATIONS AND EXAMPLES", "text": "In the first six months following publication, the number of job-related redundancies doubled compared to previous years."}, {"heading": "5. AVAILABILITY", "text": "The source code will be released under BSD license on GitHub.5. Details of the project, step-by-step tutorials and prepared models are on the start page.6 Development is under Linux and OS X, and users have reported on versions of Windows. A public Amazon EC2 instance will be available shortly."}, {"heading": "6. ACKNOWLEDGEMENTS", "text": "We would like to thank NVIDIA for the GPU donation, the BVLC sponsors (http: / / bvlc.eecs.berkeley.edu /) and our open source community."}, {"heading": "7. REFERENCES", "text": "[1] R. Collobert, K. Kavukcuoglu, and C. Farabet. Torch7: AMATLAB-like environment for machine learning. In BigLearn, NIPS Workshop, 2011. [2] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In ICML, 2014. [3] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In CVPR, 2014. [4] I. Goodfellow, D. Warde-Farley, P. Lamblin, V. Dumoulin H. Mirza, R. Pascanu, J. Bergstra, F. Bastien, and Y."}], "references": [{"title": "Torch7: A MATLAB-like environment for machine learning", "author": ["R. Collobert", "K. Kavukcuoglu", "C. Farabet"], "venue": "BigLearn, NIPS Workshop", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "ICML", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "CVPR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Pylearn2: a machine learning research library", "author": ["I. Goodfellow", "D. Warde-Farley", "P. Lamblin", "V. Dumoulin", "M. Mirza", "R. Pascanu", "J. Bergstra", "F. Bastien", "Y. Bengio"], "venue": "arXiv preprint 1308.4214", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Open-vocabulary object retrieval", "author": ["S. Guadarrama", "E. Rodner", "K. Saenko", "N. Zhang", "R. Farrell", "J. Donahue", "T. Darrell"], "venue": "RSS", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Recognizing image style", "author": ["S. Karayev", "M. Trentacoste", "H. Han", "A. Agarwala", "T. Darrell", "A. Hertzmann", "H. Winnemoeller"], "venue": "arXiv preprint 1311.3715", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "cuda-convnet", "author": ["A. Krizhevsky"], "venue": "https://code.google.com/p/cuda-convnet/", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "NIPS", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Overfeat: Integrated recognition", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "localization and detection using convolutional networks. In ICLR", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "K", "author": ["J. Uijlings"], "venue": "van de Sande, T. Gevers, and A. Smeulders. Selective search for object recognition. IJCV", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Panda: Pose aligned networks for deep attribute modeling", "author": ["N. Zhang", "M. Paluri", "M. Ranzato", "T. Darrell", "L. Bourdev"], "venue": "CVPR", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 7, "context": "While performance of conventional, handcrafted features has plateaued in recent years, new developments in deep compositional architectures have kept performance levels rising [8].", "startOffset": 176, "endOffset": 179}, {"referenceID": 6, "context": "cuda-convnet [7] unspecified C++ Python discontinued", "startOffset": 13, "endOffset": 16}, {"referenceID": 1, "context": "Decaf [2] BSD Python discontinued", "startOffset": 6, "endOffset": 9}, {"referenceID": 8, "context": "OverFeat [9] unspecified Lua C++,Python centralized", "startOffset": 9, "endOffset": 12}, {"referenceID": 3, "context": "Theano/Pylearn2 [4] BSD Python distributed", "startOffset": 16, "endOffset": 19}, {"referenceID": 0, "context": "Torch7 [1] BSD Lua distributed", "startOffset": 7, "endOffset": 10}, {"referenceID": 7, "context": "Caffe provides (for academic and non-commercial use\u2014not BSD license) reference models for visual tasks, including the landmark \u201cAlexNet\u201d ImageNet model [8] with variations and the R-CNN detection model [3].", "startOffset": 152, "endOffset": 155}, {"referenceID": 2, "context": "Caffe provides (for academic and non-commercial use\u2014not BSD license) reference models for visual tasks, including the landmark \u201cAlexNet\u201d ImageNet model [8] with variations and the R-CNN detection model [3].", "startOffset": 202, "endOffset": 205}, {"referenceID": 1, "context": "By finetuning for related tasks, such as those explored by [2], these models provide a warmstart to new research and applications.", "startOffset": 59, "endOffset": 62}, {"referenceID": 1, "context": "This capability is essential for tasks such as knowledge transfer [2], object detection [3], and object retrieval [5].", "startOffset": 66, "endOffset": 69}, {"referenceID": 2, "context": "This capability is essential for tasks such as knowledge transfer [2], object detection [3], and object retrieval [5].", "startOffset": 88, "endOffset": 91}, {"referenceID": 4, "context": "This capability is essential for tasks such as knowledge transfer [2], object detection [3], and object retrieval [5].", "startOffset": 114, "endOffset": 117}, {"referenceID": 10, "context": "Members of Berkeley EECS have also collaborated with several industry partners such as Facebook [11] and Adobe [6], using Caffe or its direct precursor (Decaf) to obtain state-of-the-art results.", "startOffset": 96, "endOffset": 100}, {"referenceID": 5, "context": "Members of Berkeley EECS have also collaborated with several industry partners such as Facebook [11] and Adobe [6], using Caffe or its direct precursor (Decaf) to obtain state-of-the-art results.", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "The resulting network has been applied to open vocabulary object retrieval [5].", "startOffset": 75, "endOffset": 78}, {"referenceID": 1, "context": "These features can be used \u201cdownstream\u201d in other vision tasks with great success [2].", "startOffset": 81, "endOffset": 84}, {"referenceID": 5, "context": "have shown promising results finding images of different styles such as \u201cVintage\u201d and \u201cRomantic\u201d using Caffe features (Figure 4) [6].", "startOffset": 129, "endOffset": 132}, {"referenceID": 2, "context": "Object Detection Most notably, Caffe has enabled us to obtain by far the best performance on object detection, evaluated on the hardest academic datasets: the PASCAL VOC 2007-2012 and the ImageNet 2013 Detection challenge [3].", "startOffset": 222, "endOffset": 225}, {"referenceID": 2, "context": "[3] have combined Caffe together with techniques such as Selective Search [10] to effectively perform simultaneous localization and recognition in natural images.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[3] have combined Caffe together with techniques such as Selective Search [10] to effectively perform simultaneous localization and recognition in natural images.", "startOffset": 74, "endOffset": 78}], "year": 2014, "abstractText": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying generalpurpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (\u2248 2.5 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.", "creator": "LaTeX with hyperref package"}}}