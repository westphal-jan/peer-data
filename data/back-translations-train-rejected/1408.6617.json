{"id": "1408.6617", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Aug-2014", "title": "Task-group Relatedness and Generalization Bounds for Regularized Multi-task Learning", "abstract": "In this paper, we study the generalization performance of regularized multi-task learning (RMTL) in a vector-valued framework, where MTL is considered as a learning process for vector-valued functions. We are mainly concerned with two theoretical questions: 1) under what conditions does RMTL perform better with a smaller task sample size than STL? 2) under what conditions is RMTL generalizable and can guarantee the consistency of each task during simultaneous learning?", "histories": [["v1", "Thu, 28 Aug 2014 03:27:27 GMT  (26kb)", "http://arxiv.org/abs/1408.6617v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chao zhang", "dacheng tao", "tao hu", "xiang li"], "accepted": false, "id": "1408.6617"}, "pdf": {"name": "1408.6617.pdf", "metadata": {"source": "CRF", "title": "Task-group Relatedness and Generalization Bounds for Regularized Multi-task Learning", "authors": ["Chao Zhang", "Dacheng Tao", "Tao Hu", "Xiang Li"], "emails": ["chao.zhang@dlut.edu.cn).", "dacheng.tao@gmail.com).", "hutaomath@foxmail.com).", "lixiangalixiang@gmail.com)."], "sections": [{"heading": null, "text": "ar Xiv: 140 8.66 17v1 [cs.LG] 2 8A ugKeywords: multi-task learning, generalization bound, task relatedness, consistency, vectorrated function"}, {"heading": "1 Introduction", "text": "There is much empirical evidence that task relationship information improves multitask learning (MTL) over single task learning (STL) in multiple related tasks (MRI) scenarios. * C. Zhang is with the School of Mathematical Sciences, Dalian University of Technology, Dalian, Liaoning, 116024, P.R. China. (E-mail: chao.zhang @ dlut.edu.cn) \u2020 D. Tao is with the Centre for Quantum Computation & Intelligent Systems, FEIT, University of Technology, Sydney, 2007, Australia. (E-mail: dacheng.tao @ gmail.com) He is with the School of Mathematical Sciences, Capital Normal University, 100048, P.R. China. (E-mail: hutaomath @ foxmail.com)."}, {"heading": "1.1 Overview of Main Results", "text": "This year, more than ever before in the history of a country in which it is a country in which it is a country in which it is not a country but a country in which it is only a country, but a country in which it is a country, a country, a country, a country, a country, a country, a country and a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a"}, {"heading": "1.2 Organization of the Paper", "text": "The remainder of this paper is structured as follows: Section 2 formalizes the main research findings covered in this paper, including the probability and generalization limits for RMTL; Section 3 presents two quantities for measuring the correlation of working groups; and Section 4 introduces CPUEN to measure the complexity of the vector-weighted function classes; Section 5 presents the main results, along with a method for verifying the validity of MTL; Section 6 discusses the results of generalization performance on the basis of covariance information from MRTs; and the last section concludes the paper. In the appendix, we first present the deviation and symmetry imbalances for the vector-weighted framework (Parts A & B); and finally, the evidence of the main results in Part C."}, {"heading": "2 Problem Setup", "text": "We will first formalize the most important research work covered in this paper, including the probability and generalization limits for RMTL."}, {"heading": "2.1 Regularized Multi-task Learning", "text": "Considering a space of X-RI, X [m] can be the input space of the m-th task = = probability distribution D [m] on X and Y [m].RJ is the corresponding output space (1 \u2264 m \u2264 M).Leave g [m] \u043d: X [m] \u2192 Y [m] the corresponding labeling function. Also label the m-th task as Z [m]: = X [m] \u00b7 Y [m].RK with K = I + J. In MTL, G [1], \u00b7, G [M].M function classes corresponding to the learning tasks Z [1], \u00b7, Z [m]. MTL is expected to find M functions g [1], \u00b7, g [M] from G [M] at the same time."}, {"heading": "2.2 Notations of Vector Operations", "text": "For the following discussion, some notations of vector operations must first be described. Given are two vectors, x = (x [1], \u00b7 \u00b7 \u00b7, x [M] T and y = (y [1], \u00b7 \u00b7, y [M]) T, let | x |: = (| x [1] |, \u00b7, | x [M] |) T and designate the expression x > y (resp. x \u2265 y) as x [m] > y [m] (resp. x [m] \u2265 y [m] (resp. 1 \u2264 y [m]) for any 1 \u2264 m M. Likewise, we designate x < y (resp. x \u2264 y) as x [m] < y [m] (resp. x [m] \u2264 y [m]) for each 1 \u2264 m m m. In addition, (one [1], \u00b7 \u00b7 \u00b7 \u00b7 m [m] [v], one [g] [g] = 1 g] (g] (g], (g] = 1 g]), (m) = 1 g)."}, {"heading": "2.3 Task-joint Probability and Generalization Bounds", "text": "Generally, the boundaries of generalization for STL refer to the upper boundaries of supremumsup g [Gr] G | E (Gr] f (Gr] f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (Gr) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e) f (e (e) f (e) f (e) f (e) f (e (e) f (e) f (e) f (e) f (e) f (e (e) f (e) f (e) f (e) f (e (e) (e (e) (e (e) (e) (e) f (e (e) f (e) (e) f (e (e) (e (e) (e) (e) (e) (e (e) (e) (e (e) (e) (e) (e) (e) (e) (e (e (e) (e) (e) (e (e) (e (e) (e) (e (e) (e) (e (e) (e (e) (e) (e) (e) (e (e) (e) (e (e) (e) (e) (e (e)"}, {"heading": "3 Measures of Task-group Relatedness", "text": "Some existing work on task dependence already describes the relationship between two individual tasks, for example the F-related [5, 4] notion and covariances [23]. In the MTL it is also necessary to consider the relationship between two task groups. At this point we present two measurements of task dependence: the observed Discrepancy Dependency Measurement (ODDM) and the empirical Discrepancy Dependency Measurement (EDDM)."}, {"heading": "3.1 ODDM", "text": "In probability theory, the dependence between two events A and B based on the quantity Pr'A'B '- Pr'A' - Pr'B's is positively dependent if the conditional probability of Pr'A'B's is greater than the probability of Pr'A's (i.e., Pr'A'B's) - and they are negatively dependent if the inequality is reversed [6, 22]. We introduce ODDM and EDDM to measure the relativization between two task ranges in MTL based on quantity. Definition 3.1 Given M tasks Z [1] \u00b7 M] and a regulated vector-weighted function class FRc, let you see M's is set an index and a subset of M's with the cardinality of m."}, {"heading": "3.2 EDDM", "text": "Since this work focuses on the ERM-based RMTL, we must also consider the asymptotic behavior of dependence between two working groups when sample size N goes into infinity. Definition 3.2 According to the notations in definition 3.1 and Z [m] N: = {z] n: = [m] n N i.i.d. samples from each task Z [m] (1 \u2264 m \u2264 M), EDDM is defined as N FRc: = Pr [m] N: = [m] n Pr [t] n [m] n [m] n [m] n [m] n [m] n [m]."}, {"heading": "3.3 Empirically Computing ODDM and EDDM", "text": "Due to the fact that Pr {A | B} = Pr {A} / Pr {B} and Pr {A} = E1 {A}, ODDM \u03c6F (\u0432 [m], \u0432) can be empirically calculated in the following way. If {z [m] n Nn = 1 i.i.d. samples from problem Z [m] (1 \u2264 m \u2264 M) are used, we designate [m] j (1 \u2264 j \u2264 J), throuk (1 \u2264 k \u2264 K) and \u03b8p (1 \u2264 p \u2264 P) as observations from events A [m], B [m] and B [m]."}, {"heading": "4 Cartesian Product-based Uniform Entropy Numbers", "text": "The complexity measurements of the function classes play an important role in learning theory. Since these essay studies MTL cannot be applied (or at least cannot be applied directly to the vector evaluation scenario) in the vector evaluation framework (EN evaluation framework), the classical measurements such as the vapnikChervonenkis dimension (VC) and the coverage number are not applicable (or at least cannot be applied directly to the vector evaluation scenario). (Example: Ben-David and Borbely [4] have used an extended version of the vector-weighted function classes to investigate the generalization properties of the multi-task classification. (Here we present the Cartesian product-based uniform entropy number (CPUEN) to measure the complexity of the vector-weighted function classes. (First, we briefly outline the definitions of the coverage number and the uniform entropy number (CPUEN) in order to measure the complexity of the vector-weighted function classes."}, {"heading": "5 Generalization Bounds of RegularizedMulti-task Learn-", "text": "ingIn this section, we present the generalization limits of RMTL and discuss how the working group relates to the generalization properties of RMTL. Furthermore, we specify a sufficient condition for the consistency of each task in MRTs."}, {"heading": "5.1 Two Special Cases", "text": "Before the formal discussion, we first linked the probabilities of two special events: firstly, that all tasks have large empirical discrepancies, and secondly, that all tasks have small empirical discrepancies. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "5.2 Main Results", "text": "Based on these two specific cases, we obtain the generalization limits of RMTL = land use (land use) and a sufficient condition for the consistency of each task (land use) in the simultaneous learning process for MRTs.Theorem 5.3 Following the notes of theorem 5.1 (land use), it then provides the following aspects: (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use), (land use, (land use), (land use), (land use (land use), (land use), (land use (land use), (land use), (land use (land use), land use (land use), (land use (land use), land use (land use), land use (land use (land use), land use (land use), land use (land use (land use), land use (land use (land use), land use (land use (land use), land use (land use (land use), land use (land use (land use), land use (land use (land use), land use (land use (land use), land use (land use (land use), land use (land use (land use (land use), land use (land use), land use (land use (land use (land use), land use (land use), land use (land use (land use), land use (land use (land use), land use (land use (land use), land use (land use (land use (land use), land use (land use), (land use (land use (land use (land use), land use (land use (land use), land use (land use), land use (land use), land use (land use), land use (land use (land use (land use), land use"}, {"heading": "6 Generalization Bounds with Covariance Information", "text": "As discussed in Section 3, since ODDM recognizes the dependence between two task groups, the boundary (13) cannot reflect how the individual relationship between two tasks affects the generalization performance of RMTL for more than two tasks. Here, we consider the generalization results based on the covariance information between all two tasks. Theorem 6.1 Follow the notations of Theorem 5.1. The generalization condition of RMTL for more than two tasks is given."}, {"heading": "7 Conclusion", "text": "In this thesis, we apply the vector-weighted framework to study the generalization performance of RMTL and analyze the relationship between the workgroup orientation and the properties of RMTL. In particular, we introduce two types of workgroup orientation: ODDM and EDDM, and we present CPUEN to measure the complexity of the regulated vector-weighted functional class FRc. By applying the specific deviation and symmetry inequalities to the vector-weighted frames, we obtain the generalization limit for RMTL and provide a sufficient condition to guarantee the consistency of each task in the simultaneous learning process of MRTs. Finally, we show that the theoretical results of this paper can investigate whether the task settings are suitable for the RMTL mechanism. Based on the theoretical results, we understand the relationship between the generalization properties of RMTL and the workgroup orientation as follows the validity of MDM in relation to the size of MDM is not required."}, {"heading": "A Deviation Inequalities for Random Vectors", "text": "In order to obtain the generalization limits for RMTL, we must take into account the deviation inequalities for random vectors. Furthermore, it follows from [9]: Let us leave sn = (s [1] n, \u00b7 \u00b7 \u00b7, s [m] n) T-RM (1 \u2264 n \u2264 N) n i.i.d. random vectors such as this M = 1s [m] n \u2264 1, for n = 1, \u00b7 \u00b7 \u00b7, N, (24) and s [m] n \u2265 0, for 1 \u2264 n and 1 \u2264 m \u2264 M. (25) Note that the components s [1] n, \u00b7, s [M] n are not necessarily independent of sn. Mean \u00b5 = (\u00b5 [1], \u00b7 \u00b7 \u00b7, \u00b5 [M] T of random vectors sn and 1 \u2264 m) [f] s [m] s [m] s [m] s [m] n, for 1 \u2264 ehm \u00b7 n, \u00b5 = (\u00b5 [1], \u00b7 \u00b7 \u00b7, \u00b5 [M] T of random vectors sn and 1 \u2264 m)."}, {"heading": "B Symmetrization Inequalities for Random Vectors", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.1 Chebyshev Inequalities for Random Vectors", "text": "Definition B.1 Let us suppose Z [1], \u00b7 \u00b7, Z [M] are M distributions to R. Let us suppose that Z [1], \u00b7 \u00b7, M] is an index set and [m] is a subset of what is the cardinality of m. For each group [m] and each group [1], \u00b7 \u00b7, [M], T > 0, definition [m]: = Pr {s [i] > [i], i [m], i [m], i [m], i [m], i [m] and each group (i], i [i [i], i [m], i [m], i [i], i [i [i], i [i], i [i], i] is the non-negative random variable of the task Z [i], and [m] stands for the complementary group of M], i [m], i [m], i [m], i [m], i), i), [m [m], is random, i] is the non-negative task, i, i-i, i] is the task."}, {"heading": "B.2 Symmetrization Inequalities", "text": "By applying ODDM, we can develop the symmetry imbalance for MTL as follows: Theorem B.1 assumes that F is a vector-weighted function class with the range [a, b]. For each of these two categories, Pr (sup f) f [f] f [f) f [f) f [f) f [f] f [f) f [f) f [f) f [f) f [f) f [f) f [f) f [f) f [f) f (f) f) f (f) f (f) f (f) f) f (f) f (f) f) f (f) f) f (f) f) f (f) f) f (f) f) f (f) f (f) f) f (f) f) f (f) f (f) f) f (f) f (f) f) f (f) f (f) f) f (f) f (f) f (f) f) f (f) f (f) f (f) f (f) f (f) f (f) f (f) f (f) f (f) f (f) f (f) [f) f (f) f (f) f) f (f) [f) f) f (f) f (f) f (f) [f) f (f) [f) f) f (f) [f) f) f (f) f) f (f) f (f) f) f (f (f) f) f (f) f (f) f (f) f) f (f) f (f (f) f) f (f) f (f) f (f) f) f (f (f) f (f) f (f) f (f) f) f (f (f) f (f) f (f (f) f (f) f) f (f (f) f) f (f (f) f (f (f (f) f) f (f) f) f (f (f (f) f) f (f) f) f (f (f) f) f (f (f (f) f) f (f (f) f)"}, {"heading": "C Proofs of Main Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C.1 Proof of Lemma A.1", "text": "The detection of Lemma A.1. Leave t = \u2212 \u2212 p = 1 N = 1 sn \u2212 p = 1 step = 1 step = 1 step = 1 step = 1 step = 1. The event (t | > p) contains 2M possibilities: for each 1 \u2264 m \u2264 M there are m components of the vector t, so that t [ik] > [ik] (1 \u2264 k \u2264 m) and the rest of the case is that t [ik] < \u2212 p [ik] (1 \u2264 k \u2264 M \u2212 m). For convenience we also refer to {Pi} 2 M i = 1 as the collection of all 2 M possibilities. According to Theorem 1 in [9], the following result applies to each possibility Pi (1 \u2264 i \u2264 i \u2264 2M): Pr {Pi} 2 M i = 1 m = 1 p [m] p [m] p [m] (39), where p [m] p [m] p [m] = p [m] = 1 x \u2212 m [] (m] (m] [m] [m])."}, {"heading": "C.2 Proof of Lemma B.1", "text": "Proof for Lemma B.1. Given M tasks (1), \u00b7 \u00b7, Z [M] and a vector-rated functional class F, let me (1), (2), (2), (2), (2), (2), (2), (3), (4), (4), (4), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5, (5), (5), (5), (5, (5), (5), (5, (5), (5, (5), (5), (5, (5), (5), (5), (5), (5, (5, (5), (5, (5), (5), (5, (5), (5), (5, (5), (5), (5, (5), (5, (5), (5, (5), (5), (5), (5, (5), (5),"}, {"heading": "C.3 Proof of Lemma B.2", "text": "The proof for Lemma B.2. The event s 6 (m) contains the following possibilities: \u2022 P [1]: There is only one index (i) = 1 (1), \u00b7, i [m] = 1 (i), which satisfies s [i] > i [i]; \u2022 P [m]: there is only m (1 < m) indexes (1), \u00b7, i [m] = 1 (m), which satisfies s [k] > ics (1) (1 \u2264 k); \u2022 P [M]: s [m] > [m]. Therefore, we have Pr {s 6 (m) = Pr {P [1] + \u00b7 Pr {P] (M]}. (46) According to Chebyshev's inequality and (42), we have Pr (1) [P [2] = M < m \u00b2 s [m] [s] [s] [s] [s] [s] [m] [m] [m] [m] [m [m] m [m], i] >]."}, {"heading": "C.4 Proof of Theorem B.1", "text": "The proof for theorem B.1. Let fN = (f =), f = (f =), f = (f =), f = (f =), f = (f =), f = (f =), f = (f =), f = (f =), f = (f =), f = (f =), f = (f = f =), f = (f = f =), f = (f =), f = (f =), f = (f =), f = (f =), f = (f = f =), f = (f = (f =), f = (f = f =), f = (f = f =), f = (f =), f = (f = (f =), f = (f =), f =, f =, f =, f =, f = (f =, f =, f = (f =), f = (f = (f =), f = (f =), f = (f =, f = (f =), f = (f = (f =), f = (f =), f = (f = (f =), f = (f = (f =), f = (f =), f = (f = (f =), f = (f = (f =), f = (f = (f =), f = (f =, f = (f = (f =), f =, f = (f =, f = (f = (f =), f = (f =), f =, f =, f =, f =, f =, f =, f = (f =, f = f = (f =, f =, f =, f = f =, f = f = (f =, f =, f =, f = (f = f =, f =, f = (f), f =, f =, f = f = (f =, f = (f), f =, f =, f =, f =, f = (f =, f =, f = (f =, f = (f), f = (f), f =, f =, f = (f =, f = (f"}, {"heading": "C.5 Proof of Theorem B.2", "text": "The proof for theorem B.2. Let fN = (f-1, \u00b7 \u00b7, f-M) T be the vector-weighted function, the supremum sup-f-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E E E-E-E-E-E E E-E-E E"}, {"heading": "C.6 Proof of Theorem 5.1", "text": "The proof for Theorem 5,1. For any variable (1 \u2264 m) applies: For any variable with equal probability of any value. (...) For any variable with equal probability of any value. (...) For any variable with equal probability of any value. (...) For any variable with equal probability. (...) For any variable with equal probability. (...) For each variable with equal probability. (...) Nn = 1 and one variable. (...) For each variable. (...) N = 1 and one variable. (...) N = 1 and one variable. (...) For each variable. (...)"}, {"heading": "C.7 Proof of Theorem 5.2", "text": "Before the formal proof is provided, we present a necessary lemma.Lemma C1 = = [1] n, \u00b7, s [M] n, [1] n, [2] n, [2] n, [2] n, [2] n, [2] n, [2] n, [2] n, [3] n, [4] n, [4] n, [7] n, [7] n, [8] n, [8] n, [8] n, [8, 8, 8, 8, n] n, 8, 8 n, 8, 8 n, 8 n, 8 n, 8 n, 8 n, 8 n, 8 n, 8, 8 n, 8 n, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,"}, {"heading": "C.8 Proof of Theorem 5.3", "text": "The proof of the theorem 5,3. Means tN = (t [1], \u00b7 \u00b7, t [M]) T with t [i]: = [i] f [i] \u2212 E [i] Nf [i]. The event tN 6 \u2264 [i] contains the following possibilities: \u2022 P [1]: There is only one index {i] = [1] that satisfies that t [i] > [i] [i]; \u2022 P [m]: there are indices (1 < m < M) {i [1], \u00b7, i [m] = [m], which satisfies that t [ik] > [ik] (1 \u2264 k \u2264 m); \u2022 P [M]: t [m] > m [m] indices {i [1], \u00b7, i [m]. Thus, we have Pr {tN 6 \u2264 \u00b2 = Pr {P [1] + \u00b7 tes] [P] [m]."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "In this paper, we study the generalization performance of regularized multi-task learning<lb>(RMTL) in a vector-valued framework, where MTL is considered as a learning process for<lb>vector-valued functions. We are mainly concerned with two theoretical questions: 1) under<lb>what conditions does RMTL perform better with a smaller task sample size than STL? 2)<lb>under what conditions is RMTL generalizable and can guarantee the consistency of each<lb>task during simultaneous learning? In particular, we investigate two types of task-group<lb>relatedness: the observed discrepancy-dependence measure (ODDM) and the empirical<lb>discrepancy-dependence measure (EDDM), both of which detect the dependence between<lb>two groups of multiple related tasks (MRTs). We then introduce the Cartesian product-<lb>based uniform entropy number (CPUEN) to measure the complexities of vector-valued<lb>function classes. By applying the specific deviation and the symmetrization inequalities<lb>to the vector-valued framework, we obtain the generalization bound for RMTL, which<lb>is the upper bound of the joint probability of the event that there is at least one task<lb>with a large empirical discrepancy between the expected and empirical risks. Finally, we<lb>present a sufficient condition to guarantee the consistency of each task in the simultaneous<lb>learning process, and we discuss how task relatedness affects the generalization performance<lb>of RMTL. Our theoretical findings answer the aforementioned two questions.", "creator": "LaTeX with hyperref package"}}}