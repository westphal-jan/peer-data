{"id": "1409.0763", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Sep-2014", "title": "Data classification using the Dempster-Shafer method", "abstract": "In this paper, the Dempster-Shafer method is employed as the theoretical basis for creating data classification systems. Testing is carried out using three popular (multiple attribute) benchmark datasets that have two, three and four classes. In each case, a subset of the available data is used for training to establish thresholds, limits or likelihoods of class membership for each attribute, and hence create mass functions that establish probability of class membership for each attribute of the test data. Classification of each data item is achieved by combination of these probabilities via Dempster's Rule of Combination. Results for the first two datasets show extremely high classification accuracy that is competitive with other popular methods. The third dataset is non-numerical and difficult to classify, but good results can be achieved provided the system and mass functions are designed carefully and the right attributes are chosen for combination. In all cases the Dempster-Shafer method provides comparable performance to other more popular algorithms, but the overhead of generating accurate mass functions increases the complexity with the addition of new attributes. Overall, the results suggest that the D-S approach provides a suitable framework for the design of classification systems and that automating the mass function design and calculation would increase the viability of the algorithm for complex classification problems.", "histories": [["v1", "Tue, 2 Sep 2014 15:49:40 GMT  (650kb)", "http://arxiv.org/abs/1409.0763v1", "Journal of Experimental &amp; Theoretical Artificial Intelligence, ahead-of-print, 2014"]], "COMMENTS": "Journal of Experimental &amp; Theoretical Artificial Intelligence, ahead-of-print, 2014", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["qi chen", "amanda whitbrook", "uwe aickelin", "chris roadknight"], "accepted": false, "id": "1409.0763"}, "pdf": {"name": "1409.0763.pdf", "metadata": {"source": "CRF", "title": "Data Classification Using the Dempster-Shafer Method", "authors": ["Qi Chen", "Amanda Whitbrook", "Uwe Aickelin", "Chris Roadknight"], "emails": ["cmr>@cs.nott.ac.uk,"], "sections": [{"heading": null, "text": "In this paper, the Dempster-Shafer method is used as the theoretical basis for the creation of data classification systems. Tests are performed using three popular (multiple) benchmark datasets comprising two, three and four classes. In each case, a subset of available data is used for training to determine thresholds, boundaries or probabilities of class belonging for each attribute, thus creating mass functions that determine the likelihood of class belonging for each attribute of the test data. Classification of each data element is achieved by combining these probabilities via Dempster's combination rule. Results for the first two datasets show an extremely high classification accuracy that competes with other popular methods. In all cases, the Dempster-Shafer method offers more popular algorithms than others, but good results can be obtained provided that the system and mass functions are carefully designed and the right attributes for the combination."}, {"heading": "1. Introduction", "text": "The ability to group complex data into a limited number of classes is important in data mining and means that more useful decisions can be made based on the information available. For example, in the field of medical diagnostics, it is essential to apply methods that can accurately distinguish between anomalous and normal data. Systems that categorize data in this way are commonly referred to as classifiers and fall into two different types: statistical and artificial intelligence (AI) methods. Examples of AI methods include blurred classifiers [13], support vector machines [14] and k-next-door techniques [15]. Here, Dempster's Combination Rule (DRC), a statistical method, is seen as a tool for classification. DRC is a generalization of a specific case of Bayes theorem that involves combining independent sets of probability mappings to form a single one."}, {"heading": "2. The Dempster-Shafer (D-S) theory", "text": "D-S is a mathematical evidence theory based on belief functions and plausible reasoning. It was introduced in the 1960s by Arthur Dempster [2] as a mechanism for arguing under epistemic (knowledge) uncertainties and developed in the 1970s by Glenn Shafer [3]. The theory contains several different models, for example the Transferable Belief Model (TBM), which refers to the degree of belief for a question from subjective probabilities for a related question. Also available is Dempster's Combination Rule (DRC), which attempts to combine probabilities when they are based on independent evidence. The D-S theory uses the same basic domain as probability theory, but is relevant for situations in which there are non-random uncertainties, e.g. when data are collected from partially reliable sources. It is therefore suitable for problems in which the actual state of things is only known that it belongs to a subset of possible states, Selection 2, Selection Selection, Selection, and Conflict Selection Selection, Section, Section 4, which contains some fundamental problem, SelectionD."}, {"heading": "2.1. Basic mathematical terminology and the TBM", "text": "The D-S theory begins by starting from a differentiating frame (\u0432), which represents a finite series of mutually exclusive prostheses and hypotheses (alternatives) over a particular problem domain. It is the set of all states considered. For example, if: (1) then}, {2), {2), the set consisting of all possible diseases. The individual elements of the power set represent prostheses in the domain that may be of interest. [2], {2], {2), the individual elements of the power set represent prostheses in the domain that may be of interest. For example, the thesis \"the disease is contagious\" leads to elements that are contagious and contains only those states in which this statement is true.The theory of proofs attributes a mass value to each part of the power set."}, {"heading": "2.2. Dempster\u2019s rule of combination", "text": "In this case, the combined mass function of m1 and m2 (the common mass) would be expressed as m1,2, where:), () () (212.1 AmmAm values = (10) and () (1), () (21) (21) (21) (21) (21) (21) (21) (21) (CB KCmBmK (12) Equation (11) essentially emphasizes the agreement between multiple sources of information and ignores conflicting evidence by using a normalization factor equal to 1-K. The normalization factor attests any mass associated with a conflict with the zero amount, although this can often yield counterintuitive results when the conflict level is high, see Section 2.3.As an example of a DRC calculation, the values for the masses (1) and the hypothesis for the masses (1) and masses (2) are set."}, {"heading": "2.3. Advantages and disadvantages of D-S", "text": "The systems described in this paper are all based on the theory presented in sections 2.1 and 2.2, but D-S-based systems have a wide range and flexibility in terms of system design, which means that classifiers can be created that are very well suited to solving a particular problem. In particular, there are no fixed rules on how mass functions should be constructed, but it can be argued that mass functions that are as simple or as complex as desired, and DRC can be applied many times with different strategies. This allows the creation of systems that are tailored to a particular problem, but it can be argued that it is a disadvantage as it does not allow the generalization of results."}, {"heading": "2.4. Review of D-S applications", "text": "D-S theory has so far proven to be a powerful combination tool, but to date most research efforts have been focused on combining the results of a number of different classification techniques: for example, in [30] the results from a Bayesian network classifier and a fuzzy logic-based classifier are combined, and in [31] the D-S theory is then used in conjunction with a neural network method and applied to a fault diagnostic problem in induction motors; the DRC acts as a data fusion tool, i.e. eight faulty conditions are first classified with the neutral network and the classification information is then converted into mass function assignments, which are then combined with DRC, reducing diagnostic uncertainty. Al-Ani and Deriche [32] also propose a classification combination method based on the D-S approach, suggesting that the success of the D-S methodology consists of combining more powerful evidence with more powerful classification capabilities."}, {"heading": "3. The application of D-S to data classification", "text": "As discussed in Section 2.3, D-S theory provides a general framework for creating classification systems. This framework can be expressed as a series of steps that need to be taken, namely: 1. Define the framework of distinction (BA). This is the set of all possible hypotheses related to the given data set and identifies the classes to which the data must be assigned. 2. Determine which data attributes are important for determining class affiliation and discard the others. Generally, the framework of distinction and the selected attributes (their number and their data types) will provide loose guidelines for designing mass functions and the structure of DRC combinations. 3. Check the selected attributes and their data values within a subset of the data to design mass functions for each attribute. These functions are used to assign mass values to the appropriate hypotheses."}, {"heading": "4. Experiments with the WBCD", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Description of the data", "text": "The WBCD is a standard benchmark dataset from the UCI Machine Learning Repository [1]. It contains 699 data positions, of which 241 are malicious (abnormal data) and 458 are benign (normal data).The data consists of nine attributes (A, B, C, D, E, F, G, H and I), all of which are normalized integers in the range 1 to 10, with smaller values tending to indicate normality and larger values tending to indicate anomaly.The biological meaning of these attributes is summarized in Table 2.The WBCD is chosen because it is a popular dataset with published performance results for a number of other methods, which facilitates a simple comparison of the D-S approach with other algorithms, see Section 4.3. In particular, it is worth noting that there are 16 data positions that have a missing (i.e. unavailable) attribute value. The D-based approach has the ability to address this missing i.i.e."}, {"heading": "4.2. The classification approach", "text": "For the WBCD, the framework of distinction is {normal, abnormal}, with normal definition of a benign item and abnormal definition of a malicious item. Ten-fold cross-validation is used, i.e. the data set is randomly divided into ten subsets of approximately the same size (a subset of size is either 69 or 70), and for each run, the data of one subset is used as test data, and the data of the other nine subsets are used as training data. Training consists in obtaining the modified median thresholds t to build the mass functions. The complete data set size is 699, so that the training data size is either 630 or 629. For each attribute, the training data values are sorted from small to large, and since the proportional distribution of the WBCD attribute is 65.5% (normal: abnormal), the 413-th value of each attribute is selected as the modified median threshold."}, {"heading": "4.3. Experimental results for the WBCD", "text": "The graph shows that the individual attributes A (Ca = 86.0%), D (Ca = 85.7%) and I (Ca = 79.3%) perform worst when only one attribute is used at a time. However, when these three attributes are combined with DRC, a Ca value of 90.7% is achieved, i.e. a value greater than that indicated by the attributes B (single Ca = 92.7%), C (single Ca = 92.1%) and F (single Ca = 91.3%), giving a Ca value of 95.7%, i.e. a value indicated by any of the constituent attributes. Furthermore, the 10-fold checked result of using all nine attributes (Ca = 97.6%) is better than any other combination."}, {"heading": "5. Experiments with the Iris Plant dataset", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Description of the data", "text": "The IPD is another standard benchmark problem for UCI datasets [1]. It has fewer attributes and more classes than the WBCD, making it an ideal choice to test the robustness of the D-S approach when applied to such problems. It comprises 150 datasets with the following four numerical attributes: cup length, cup width, petal length, and petal width (all in cm). The classes are the plant species, namely Iris Setosa, Iris Versicolor, or Iris Virginica, with each class containing 50 instances."}, {"heading": "5.2. The classification approach", "text": "The framework of distinction for the IPD is {Setosa, Versicolor, Virginica}, although this classification level is specified for each classification level, and the first step chosen allows for seven possible hypotheses: \u2022 {Setosa} = Class 1 \u2022 {Versicolor} = Class 2 \u2022 {Virginica} = Class 3 \u2022 {Setosa, Versicolor, Virginica} \u2022 {Setosa, Versicolor, Virginica} As for the WBCD, a tenfold cross-validation is used, i.e. the data set is randomly divided into ten subsets of the same size, with nine out of ten subsets containing training data and the remaining subsets used as test data. Again, the training data is used to build the mass functions, but since there are three classes, this is a slightly more complex process than before. Firstly, the maximum and minimum values for each class are based on an attribute of the training class, and the overlap between these classes is used to obtain the boundaries for each classification class."}, {"heading": "5.3. Experimental results for the IPD", "text": "Ten runs based on both steps of the approach give an average classification accuracy Ca of 95.47%. Table 3 illustrates three of these ten attempts (randomly selected) and provides detailed error information. The column headings of Table 3 are explained below: \u2022 ID - Item identification number: o 1-50 = Setosa, o 51-100 = Versicolor, o 101-150 = Virginica. \u2022 Correct (1.) - The number of items correctly classified in the first step. \u2022 Error (1.) - The number of items caused in the first step. \u2022 Split (1.) - The number of items not in a single class after the first step. \u2022 Error (2.) - The number of items caused by the second step. Table 3 shows that items 71, 86, 107 and 120 are incorrectly classified in all three runs."}, {"heading": "6. Experiments with the Duke Outage dataset", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1. Description of the data", "text": "The Duke Outage Dataset (DOD) is a protocol of power failures (either complete power failure or voltage drop) that occurred in the U.S. between 1994 and 2002. One of the main reasons for these records is their use as a diagnostic system to help engineers determine the cause of failure (for example, equipment failure, animal contact, trees, lightning, etc.) so that the response and recovery process can be mounted quickly and reliably. In this case, the dataset is used as a means to test the application of the D-S methodology to non-numerical data. It is also selected because it has proved difficult in previously published work [19, 20] using different methods, i.e. both good true positive rates and good true negative rates are difficult to achieve for all data classes. This may be partly because the DOD is an unbalanced dataset where 6.99% of the lightning-related errors are traced back to 20.03% due to a fall in Taylor, also due to 29.40% remaining trees, and 43.40% due to a fall in Taylor."}, {"heading": "6.2. The classification approach", "text": "rf\u00fc ide rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the reG the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf the rf\u00fc the rf the rf the rf the rf\u00fc the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the rf the r"}, {"heading": "6.3. Experimental results using the Duke Outage dataset", "text": "The last six rows show the data when different attribute combinations are used for each individual model. Tables 8 and 9 show that the results with all six attributes are quite poor, with few values exceeding 0.50. This is probably because some of the attributes are very weak, and their inclusion in the combined system seems to have a significant effect on overall performance."}, {"heading": "6.4. Optimization of the mass functions and results", "text": "jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj"}, {"heading": "7. Conclusions", "text": "This work used D-S theory (in particular mass functions and DRC) as a framework for creating classification algorithms and applied it to three standard benchmark datasets, the WBCD datasets, the iris datasets, and a portion of the WBCD datasets. Results were obtained by considering thresholds for other popular methods and using sigmoid models. In this case, classification was a simple one-step process, with accuracy much higher than all datasets were considered (97.6%), and the result was better than the other published results."}], "references": [{"title": "Upper and lower probabilities induced by a multivalued mapping", "author": ["A.P. Dempster"], "venue": "Ann. Math. Statist", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1967}, {"title": "A Mathematical Theory of Evidence", "author": ["G. Shafer"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1976}, {"title": "Sensor and Data Fusion: A Tool for Information Assessment and Decision Making", "author": ["K.A. Lawrence"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Approximations for efficient computation in the theory of evidence", "author": ["B. Tessem"], "venue": "Artificial Intelligence", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1993}, {"title": "A computationally efficient approximation of Dempster-Shafer theory", "author": ["F. Voorbraak"], "venue": "Internat. J. Man-Machine Stud", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1989}, {"title": "On the Dempster\u2013Shafer framework and new combination rules", "author": ["R.R. Yager"], "venue": "Information Sciences", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1987}, {"title": "Combining belief functions when evidence conflicts", "author": ["C.K. Murphy"], "venue": "Decision Support Systems", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2000}, {"title": "Breast cancer detection using rank nearest neighbor classification rules", "author": ["S. C", "Bagui", "S. Bagui", "K. Pal", "N.R. Pal"], "venue": "Pattern Recognition", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "A neuro-fuzzy method to learn fuzzy classification rules from data", "author": ["D. Nauk", "R. Kruse"], "venue": "Fuzzy sets and Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "A new approach for handling the Iris Data classification problem", "author": ["S. Chen", "Y. Fang"], "venue": "International Journal of Applied Science and Engineering", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "A simple view of the Dempster-Shafer theory of evidence and its implication for the rule of combination", "author": ["L.A. Zadeh"], "venue": "AI Magazine", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1986}, {"title": "Proximal Support vector machine classifiers\u201d, Machine Learning", "author": ["G. Fung", "O. Mangasarian"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Combining the results of several neural network classifiers", "author": ["G. Rogova"], "venue": "Neural Networks", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1994}, {"title": "Methods of combining multiple classifiers and their applications to handwriting recognition", "author": ["L. Xu", "A. Krzyzak", "C.Y. Suen"], "venue": "IEEE Transactions on Systems Man and Cybernetics", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1992}, {"title": "Power distribution outage cause identification with imbalanced data using artificial immune recognition system (AIRS) algorithm", "author": ["L. Xu", "M-Y. Chow", "J. Timmis", "L.S. Taylor"], "venue": "IEEE Transactions on Power Systems", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Power distribution fault cause identification with imbalanced data using the data mining based fuzzy classification E-algorithm", "author": ["L. Xu", "M-Y. Chow", "L.S. Taylor"], "venue": "IEEE Transactions on Power Systems 22 (1) (2007) 164-171.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "A classification approach for power distribution systems fault cause identification", "author": ["L. Xu", "M-Y. Chow"], "venue": "IEEE Transactions on Power Systems", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "A novel approach for distribution fault analysis, IEEE Trans. Power Deliv", "author": ["M-Y. Chow", "L.S. Taylor"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1993}, {"title": "Analysis and prevention of animal-caused faults in power distribution systems", "author": ["M-Y. Chow", "L.S. Taylor"], "venue": "IEEE Trans. Power Del", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1995}, {"title": "Recognizing animal-caused faults in power distribution systems using artificial neural networks", "author": ["M-Y. Chow", "S.O. Yee", "L.S. Taylor"], "venue": "IEEE Trans. Power Del", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1993}, {"title": "Analysis of Tree-Caused Faults in Power Distribution Systems", "author": ["L. Xu", "M-Y. Chow", "L.S. Taylor"], "venue": "Proceedings of the 35th North American Power Symposium,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Power distribution outage cause identification using fuzzy artificial immune recognition systems (FAIRS) algorithm", "author": ["L. Xu", "M-Y. Chow", "J. Timmis"], "venue": "Proceedings of IEEE PES General Meeting,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "Power distribution system fault diagnosis using hybrid algorithm of fuzzy classification and artificial immune systems", "author": ["L. Xu", "M-Y. Chow"], "venue": "in: B. Prasad (Ed.) Soft Computing Applications in Industry,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "Machine learning for the detection of oil spills in radar images", "author": ["M. Kubat", "R. Holte", "S. Matwin"], "venue": "Machine Learning", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1998}, {"title": "Anomaly Detection Using the Dempster-Shafer Method", "author": ["Q. Chen", "U. Aickelin"], "venue": "Proceedings of the International Conference on Data Mining (DMIN2006), Las Vegas,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2006}, {"title": "Optimization by simulated annealing", "author": ["S. Kirkpatrick", "C.D. Gelatt", "Jr.", "M.P. Vecchi"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1983}, {"title": "Application of Dempster-Shafer theory in fault diagnosis of induction motors using vibration and current signals", "author": ["B-S. Yang", "K.J. Kim"], "venue": "Mechanical Systems and Signal Processing", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2006}, {"title": "A new technique for combining multiple classifiers using the Dempster-Shafer theory of evidence", "author": ["A. Al-Ani", "M. Deriche"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2002}, {"title": "Combination of acoustic classifiers based on Dempster-Shafer theory of evidence", "author": ["F. Valente", "H. Hermansky"], "venue": "Proceedings of IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP)", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2007}, {"title": "Application of Dempster-Shafer theory in condition monitoring applications: A case study", "author": ["C.R. Parikh", "M.J. Pont", "N.B. Jones"], "venue": "Pattern Recognition Letter", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2001}, {"title": "Dempster-Shafer theory for intrusion detection in ah hoc networks", "author": ["T.M. Chen", "V. Venkataramanan"], "venue": "IEEE Internet Computing", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2005}, {"title": "A Mathematical Theory of Evidence", "author": ["G. Shafer"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1976}, {"title": "An empirical study of the naive bayes classifier", "author": ["I. Rish"], "venue": "Proceedings of IJCAI-01 Workshop on Empirical Methods in Artificial Intelligence", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2001}], "referenceMentions": [{"referenceID": 11, "context": "Examples of AI methods include fuzzy classifiers [13], support vector machines [14], and k-nearest neighbour techniques [15].", "startOffset": 79, "endOffset": 83}, {"referenceID": 12, "context": "The method has previously been used for combining results from several different classifiers [16, 17].", "startOffset": 93, "endOffset": 101}, {"referenceID": 13, "context": "The method has previously been used for combining results from several different classifiers [16, 17].", "startOffset": 93, "endOffset": 101}, {"referenceID": 14, "context": "Sections 4, 5, and 6 provide information about the three standard benchmark problems, the Wisconsin Breast Cancer Dataset (WBCD) [1], the Iris Plant Dataset (IPD) [1], and the Duke Outage Dataset (DOD) [18-26] respectively.", "startOffset": 202, "endOffset": 209}, {"referenceID": 15, "context": "Sections 4, 5, and 6 provide information about the three standard benchmark problems, the Wisconsin Breast Cancer Dataset (WBCD) [1], the Iris Plant Dataset (IPD) [1], and the Duke Outage Dataset (DOD) [18-26] respectively.", "startOffset": 202, "endOffset": 209}, {"referenceID": 16, "context": "Sections 4, 5, and 6 provide information about the three standard benchmark problems, the Wisconsin Breast Cancer Dataset (WBCD) [1], the Iris Plant Dataset (IPD) [1], and the Duke Outage Dataset (DOD) [18-26] respectively.", "startOffset": 202, "endOffset": 209}, {"referenceID": 17, "context": "Sections 4, 5, and 6 provide information about the three standard benchmark problems, the Wisconsin Breast Cancer Dataset (WBCD) [1], the Iris Plant Dataset (IPD) [1], and the Duke Outage Dataset (DOD) [18-26] respectively.", "startOffset": 202, "endOffset": 209}, {"referenceID": 18, "context": "Sections 4, 5, and 6 provide information about the three standard benchmark problems, the Wisconsin Breast Cancer Dataset (WBCD) [1], the Iris Plant Dataset (IPD) [1], and the Duke Outage Dataset (DOD) [18-26] respectively.", "startOffset": 202, "endOffset": 209}, {"referenceID": 19, "context": "Sections 4, 5, and 6 provide information about the three standard benchmark problems, the Wisconsin Breast Cancer Dataset (WBCD) [1], the Iris Plant Dataset (IPD) [1], and the Duke Outage Dataset (DOD) [18-26] respectively.", "startOffset": 202, "endOffset": 209}, {"referenceID": 20, "context": "Sections 4, 5, and 6 provide information about the three standard benchmark problems, the Wisconsin Breast Cancer Dataset (WBCD) [1], the Iris Plant Dataset (IPD) [1], and the Duke Outage Dataset (DOD) [18-26] respectively.", "startOffset": 202, "endOffset": 209}, {"referenceID": 21, "context": "Sections 4, 5, and 6 provide information about the three standard benchmark problems, the Wisconsin Breast Cancer Dataset (WBCD) [1], the Iris Plant Dataset (IPD) [1], and the Duke Outage Dataset (DOD) [18-26] respectively.", "startOffset": 202, "endOffset": 209}, {"referenceID": 22, "context": "Sections 4, 5, and 6 provide information about the three standard benchmark problems, the Wisconsin Breast Cancer Dataset (WBCD) [1], the Iris Plant Dataset (IPD) [1], and the Duke Outage Dataset (DOD) [18-26] respectively.", "startOffset": 202, "endOffset": 209}, {"referenceID": 0, "context": "It was introduced in the 1960's as a mechanism for reasoning under epistemic (knowledge) uncertainty by Arthur Dempster [2], and developed in", "startOffset": 120, "endOffset": 123}, {"referenceID": 1, "context": "the 1970's by Glenn Shafer [3].", "startOffset": 27, "endOffset": 30}, {"referenceID": 1, "context": "The quantity m(A) is the measure of the probability that is committed exactly to A [3].", "startOffset": 83, "endOffset": 86}, {"referenceID": 2, "context": "The uncertainty interval for a given hypothesis [4].", "startOffset": 48, "endOffset": 51}, {"referenceID": 3, "context": "To overcome this, various algorithms have been suggested, such as [5] and [6], which reduce the number of focal elements in the mass functions involved.", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "To overcome this, various algorithms have been suggested, such as [5] and [6], which reduce the number of focal elements in the mass functions involved.", "startOffset": 74, "endOffset": 77}, {"referenceID": 10, "context": "Zadeh (1986) [12] was the first to describe the conflicting beliefs management problem.", "startOffset": 13, "endOffset": 17}, {"referenceID": 5, "context": "Some alternative combination rules that attempt to reduce the conflicting beliefs management problem have also been proposed, as in [7] and [8], but none have yet been accepted as a standard method.", "startOffset": 132, "endOffset": 135}, {"referenceID": 6, "context": "Some alternative combination rules that attempt to reduce the conflicting beliefs management problem have also been proposed, as in [7] and [8], but none have yet been accepted as a standard method.", "startOffset": 140, "endOffset": 143}, {"referenceID": 25, "context": "For example, in [30] the results from a Bayesian network classifier and a fuzzy logic-based classifier are combined and in [31] the D-S theory is used in conjunction with a neural network methodology and applied to a fault diagnosis problem in induction motors.", "startOffset": 16, "endOffset": 20}, {"referenceID": 26, "context": "Al-Ani and Deriche [32] also propose a classifier combination method based on the D-S approach.", "startOffset": 19, "endOffset": 23}, {"referenceID": 27, "context": "Valente and Hermansky [33] also suggest a DRC methodology that combines the outputs from various neural network classifiers, but in their work it is applied to a multi-stream speech recognition problem.", "startOffset": 22, "endOffset": 26}, {"referenceID": 28, "context": "[34] present a new method of implementing D-S for condition monitoring and fault diagnosis, using a predictive accuracy rate for the mass functions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "In other D-S related work, Chen and Venkataramanan [35] show that Bayesian inference requires much more information than the D-S theory, for example a priori and conditional probabilities.", "startOffset": 51, "endOffset": 55}, {"referenceID": 30, "context": "Further details on construction of suitable architectures may be found in [36] and [37].", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Further details on construction of suitable architectures may be found in [36] and [37].", "startOffset": 83, "endOffset": 87}, {"referenceID": 7, "context": "This is an advantage over other approaches, for example [9] and [10], which would have to exclude the 16 items with missing values.", "startOffset": 56, "endOffset": 59}, {"referenceID": 8, "context": "This is an advantage over other approaches, for example [9] and [10], which would have to exclude the 16 items with missing values.", "startOffset": 64, "endOffset": 68}, {"referenceID": 7, "context": "6% proves highly competitive with other algorithms, for example [9] uses a generalized rank nearest neighbour rule and achieves a classification rate of 96.", "startOffset": 64, "endOffset": 67}, {"referenceID": 8, "context": "Nauk and Kruse [10] use a fuzzy classification method, with a best classification rate of 96.", "startOffset": 15, "endOffset": 19}, {"referenceID": 9, "context": "33% [11], and the results of the Naive Bayes approach, which achieves 96% when ten-fold cross validated.", "startOffset": 4, "endOffset": 8}, {"referenceID": 15, "context": "It is also selected because it has proved difficult to classify accurately in previously published work [19, 20] using different methods, i.", "startOffset": 104, "endOffset": 112}, {"referenceID": 16, "context": "It is also selected because it has proved difficult to classify accurately in previously published work [19, 20] using different methods, i.", "startOffset": 104, "endOffset": 112}, {"referenceID": 20, "context": "There are a total of 33 attributes in each outage record of the DOD, although, based on the statistical significance tests of Xu and Chow [24] and Chow and Taylor [22], only ten of these are considered influential for determining the cause of the fault.", "startOffset": 138, "endOffset": 142}, {"referenceID": 18, "context": "There are a total of 33 attributes in each outage record of the DOD, although, based on the statistical significance tests of Xu and Chow [24] and Chow and Taylor [22], only ten of these are considered influential for determining the cause of the fault.", "startOffset": 163, "endOffset": 167}, {"referenceID": 14, "context": "To facilitate this, the ten influential attributes listed in Table 5 are reduced to six attributes following [18].", "startOffset": 109, "endOffset": 113}, {"referenceID": 16, "context": "The classification strategy is shown as a flow chart in Figure 8, and has a flow structure based on the Artificial Neural Network (ANN) system described in [20], which proves to be far superior to a system that performs only one set of classification results for membership of the four classes.", "startOffset": 156, "endOffset": 160}, {"referenceID": 16, "context": "The likelihood measure is used when assigning mass values as [20] and [21] have shown that this provides useful information for outage fault identification when used with other methods.", "startOffset": 61, "endOffset": 65}, {"referenceID": 17, "context": "The likelihood measure is used when assigning mass values as [20] and [21] have shown that this provides useful information for outage fault identification when used with other methods.", "startOffset": 70, "endOffset": 74}, {"referenceID": 23, "context": "for imbalanced datasets [27] is used instead.", "startOffset": 24, "endOffset": 28}, {"referenceID": 16, "context": "The latter consist of an Artificial Neural Network (ANN) [20], an Artificial Immune Recognition System (AIRS) [18], a fuzzy algorithm called the EAlgorithm [19] and a Fuzzy Artificial Immune Recognition System (FAIRS) [25]).", "startOffset": 57, "endOffset": 61}, {"referenceID": 14, "context": "The latter consist of an Artificial Neural Network (ANN) [20], an Artificial Immune Recognition System (AIRS) [18], a fuzzy algorithm called the EAlgorithm [19] and a Fuzzy Artificial Immune Recognition System (FAIRS) [25]).", "startOffset": 110, "endOffset": 114}, {"referenceID": 15, "context": "The latter consist of an Artificial Neural Network (ANN) [20], an Artificial Immune Recognition System (AIRS) [18], a fuzzy algorithm called the EAlgorithm [19] and a Fuzzy Artificial Immune Recognition System (FAIRS) [25]).", "startOffset": 156, "endOffset": 160}, {"referenceID": 21, "context": "The latter consist of an Artificial Neural Network (ANN) [20], an Artificial Immune Recognition System (AIRS) [18], a fuzzy algorithm called the EAlgorithm [19] and a Fuzzy Artificial Immune Recognition System (FAIRS) [25]).", "startOffset": 218, "endOffset": 222}, {"referenceID": 24, "context": "Full details of the SA process and pseudo code for generating new \u03b1 and \u03b2 values are provided in [28].", "startOffset": 97, "endOffset": 101}], "year": 2014, "abstractText": "In this paper, the Dempster-Shafer method is employed as the theoretical basis for creating data classification systems. Testing is carried out using three popular (multiple attribute) benchmark datasets that have two, three and four classes. In each case, a subset of the available data is used for training to establish thresholds, limits or likelihoods of class membership for each attribute, and hence create mass functions that establish probability of class membership for each attribute of the test data. Classification of each data item is achieved by combination of these probabilities via Dempster\u2019s Rule of Combination. Results for the first two datasets show extremely high classification accuracy that is competitive with other popular methods. The third dataset is non-numerical and difficult to classify, but good results can be achieved provided the system and mass functions are designed carefully and the right attributes are chosen for combination. In all cases the Dempster-Shafer method provides comparable performance to other more popular algorithms, but the overhead of generating accurate mass functions increases the complexity with the addition of new attributes. Overall, the results suggest that the D-S approach provides a suitable framework for the design of classification systems and that automating the mass function design and calculation would increase the viability of the algorithm for complex classification problems.", "creator": "PrimoPDF http://www.primopdf.com"}}}