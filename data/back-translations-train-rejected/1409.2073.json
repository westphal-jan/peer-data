{"id": "1409.2073", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2014", "title": "An NLP Assistant for Clide", "abstract": "This report describes an NLP assistant for the collaborative development environment Clide, that supports the development of NLP applications by providing easy access to some common NLP data structures. The assistant visualizes text fragments and their dependencies by displaying the semantic graph of a sentence, the coreference chain of a paragraph and mined triples that are extracted from a paragraph's semantic graphs and linked using its coreference chain. Using this information and a logic programming library, we create an NLP database which is used by a series of queries to mine the triples. The algorithm is tested by translating a natural language text describing a graph to an actual graph that is shown as an annotation in the text editor.", "histories": [["v1", "Sun, 7 Sep 2014 02:31:03 GMT  (225kb,D)", "http://arxiv.org/abs/1409.2073v1", "Bachelor Report"]], "COMMENTS": "Bachelor Report", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tobias kortkamp"], "accepted": false, "id": "1409.2073"}, "pdf": {"name": "1409.2073.pdf", "metadata": {"source": "META", "title": "An NLP Assistant for Clide", "authors": ["Tobias Kortkamp"], "emails": [], "sections": [{"heading": null, "text": "Department 3: Mathematics and Computer ScienceBachelor ReportAn NLP Assistant for ClideTobias KortkampMatriculation No. 2491982Monday, May 26, 2014First Expert: Prof. Dr. Rolf DrechslerSecond Expert: Dr. Berthold HoffmannFurther Consultants: Dr. Mathias Soeken and Dipl.-Inf. Martin Ringar Xiv: 140 9,20 73v1 [cs.CL] 7 Sep 201 4Declaration of Self-sufficiency herewith I hereby declare that I have done this work independently, not submitted it for testing purposes and have not used any other means than those indicated. Any knowingly used text extracts, quotes or contents of other authors have been clearly marked as such. Bremen, May 26, 2014Tobias Kortkamp5"}, {"heading": "1 Introduction 7", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Basics 13", "text": "2.1 Clowns................................................................................................................................"}, {"heading": "3 Approach 17", "text": "In the second half of the second quarter there was an open strike. In the second half of the third quarter there was an open strike. In the second half of the second quarter there was an open strike. In the second half of the third quarter there was an open strike. In the second half of the third quarter there was an open strike."}, {"heading": "4 Triples 35", "text": "4.1 Triple construction workers..................................................................................................................................."}, {"heading": "5 Use case: Graph creation from a natural language specification 51", "text": ""}, {"heading": "6 Contents", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A Part of Speech Tags 59", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "1. Introduction 9", "text": "In Chapter 5, we describe a sample application that uses the extracted ontology. We extend clide-nlp to create graphs from natural language specifications using ontology. Figure 1.3 shows a sample graph."}, {"heading": "1. Introduction 11", "text": "132. Basics This chapter presents some of the concepts needed to understand this report.clide-nlp is implemented in Clojure. First, we give a brief overview of Clojure and its core.logic logic programming library. We close this chapter with a brief introduction to CoreNLP, the NLP framework used by clide-nlp."}, {"heading": "2.1. Clojure", "text": "Clojure provides a REPL that allows us to patch new code into a running system, allowing a small \"thought code feedback loop\" [7]. Clojure builds on the JVM and has good interoperability support with Java libraries, which allows us to use all existing Java NLP libraries (1 is 1 and [1 2 3] is [1 2 3]). Clojure's macros can be used to expand the language when needed, which is heavily used by core.logic, which provides logic programming for Clojure. The following table summarizes the aspects of Clojure syntax that are important for reading this report."}, {"heading": "14 2.1. Clojure", "text": "Connecting directly to Scala from Java is already a challenge, and connecting to Scala from Clojure adds an additional complication.The work involves writing the components that use Clide directly in Scala and using Clojure's runtime interface to call Clojure code from Scala. For more information on Clojure, see [6, 7]."}, {"heading": "2.1.1. Logic programming with core.logic", "text": "core.logic9 adds logical programming capabilities to Clojure. It is based on miniKanq, a logical programming library for Scheme developed by William E. Byrd as part of his doctoral thesis [2]. Since core.logic is a library for Clojure, we can freely mix functional and logical programming and use core.logic when we need it and Clojure uses functional programming aspects otherwise [21]. We summarize the most important functions and macros of core.logic here: Type Example Description Run a query (execute indirectly [q]. Run a core.logic query by trying to unify avalue with q. Returns a list of all possible values for qCreate logical variables (fresh [a b].) Generates two unbound logical variables a and b unnamed logical variables a and b unnamed variable (lvar)."}, {"heading": "2. Basics 15", "text": "The representation of the core.logic code shown here is based on the code presentation in [2, 8] q. The representation of the actual code < x > \u0445 < x > o A target is written with a suffix o to distinguish it from already defined functions on the functional programming side, while it becomes clear that they have the same result in both paradigms [2]. E.g. the disadvantages in core.logic and the disadvantages in Clojurerun * conde conde The branched macros have an additional suffix to distinguish them from the built-in cond.conda conda conda (= 6 \u2261! = The reasoned schema [8] provides a good introduction to miniKanren and in the extension also core.logic.10Example. We create a new knowledge base and populate it with three facts about Animale.Relation Child Name Animal Cat Felix Cat Mittens Animal Mittens Dog Waldoc."}, {"heading": "2.1.2. Tawny-OWL", "text": "Tawny-OWL11 is a clojure library that provides a domain-specific language for creating OWL ontologies [13]. clide-nlp uses Tawny-OWL to create OWL ontologies from its custom ontologies, which it extracts from texts (see Section 4.3)."}, {"heading": "2.2. CoreNLP", "text": "CoreNLP is an NLP framework created by the NLP group at Stanford University.12 It includes several components that facilitate the development of NLP applications or algorithms. Clide-nlp uses CoreNLP's dependency parser and its core resolution system.12 The dependency parser makes the underlying sentence structures visible in the form of grammatical relationships between sentence parts [4]. The output of this component can be modelled as a graph, with the grammatical relationships being the edges of the graph and the nodes. We call this graph semantic graphs in this report. Examples of semantic graphs are available in Section 4.1 and Section 3.3. Grammatic relationships are described in [5]. The dependency parser can break down prepositions and coordinations in grammatical relationships [4, 5]."}, {"heading": "3.1. Architecture", "text": "Figure 3.1 shows how data streams between components in clide-nlp.Clide wizards must provide a subclass of AssistantServer. AssistantServer supports connecting and receiving messages from Clide built-in and abstracts the underlying Akka implementation.clide-nlp calls its AssistantServer subclass AsyncAssistantServer. It receives events for file changes and cursor movements. All file changes are forwarded to the reconciliator, which uses transparent references. We pass them the current state of a file and return an updated version of that state. The AsyncAssistantServer instance is responsible for storing this state and retrieving it if necessary. The AsyncAssistantServer sets the reconciliation state and cursor position of the change in a queue used by the annotation loop. The annotation loop reads a status (and position) from a specific point in time and queue."}, {"heading": "18 3.2. Reconciler", "text": "The commentators who make Clide notes use the Compromiser's lazy NLP notes (see Section 3.2). The combination of lazy Clide notes and lazy NLP notes guarantees that clide-nlp only works when it really needs to."}, {"heading": "3.2. Reconciler", "text": "Clide-nlp is a collaborative editing environment. Multiple users can change the text of the current file at any time. Therefore, clide-nlp needs a way to integrate these text changes into its own data model.In traditional IDEs, the process that incorporates changes into its data models is called reconciliation. Clide itself does not provide built-in support for Yes / No compatibility. Clide-nlp needs to provide this support itself."}, {"heading": "3. Approach 19", "text": "The Reconciliator has several related tasks that are performed in the following order: 1. Divide the input text into separate blocks 2. Repeat clide deltas to integrate text changes and highlight all blocks that have changed. 3. Calculate NLP annotations for each modified block."}, {"heading": "3.2.1. Chunking", "text": "clide-nlp splits an input text into several parts to minimize the time needed to (recalculate) the NLP annotations and simplify testing. In the implementation provided with this report, clide-nlp splits an input text at the string \"\\ n----\\ n.\" Example: The cat eats the mouse. ---- The mouse is dead. It is divided into 3 parts: 1. The cat eats the mouse. ---- ----3. The mouse is dead. Each chunk has an associated span. A span is the offset interval from the beginning of the text. In the example above, Chunk 1 has a span of [0, 25) and Chunk 2 is called a chunk separator. Since a chunk is just a disk of input text, more complicated chunks are possible before the input text, and in fact it would be more realistic and unsimplified than the currently implemented one."}, {"heading": "20 3.2. Reconciler", "text": "Example: The Java comment / * * * This is a comment * / can be written as S = \"/ * * *.\" \"This is a comment\" \"This is a comment\" / \"The substring T =\" This is a comment \"has the range [7, 24) in S. If we replace all special characters that CoreNLP does not understand with spaces, we get the string\" S \"=\" This is a comment. \"The range of\" T in S \"is still [7, 24]."}, {"heading": "3.2.2. Incorporating text changes", "text": "In Clide, text changes are described as a list of operations describing the steps required to transform an old version of a text into a new version. [20] There are three operations [20]: \u2022 Retain (s) \u2022 Insert (s) \u2022 Delete (s) Since Clide is written in Scala Retain, insertion and deletion are implemented using uppercase scale.14 While it is possible to work with these classes in Clojure, it is easier to translate them to use Clojure's data structures.The translation is simple. For each operation, Retain (s) is translated by [: retain n] Insert (s) Delete (s) by [: Delete n] Example. The operations [Keep (5), Insert (\"Hello\"), Retain (15)] are translated into Clojure data [: retain n]."}, {"heading": "3. Approach 21", "text": "This will not move the cursor because it is relative to the original text. \u2022 [: delete n] deletes the next n characters at the current cursor position and moves the cursor n characters ahead.Example. Given the input text \"This's a test.\" and the operations [[: keep 9] [: insert \"the\"] [: delete 1] [: keep 6], we get the text \"This's the test.\" After the reconciliator has split a text into several chunks, there are some other concerns about addresses.The changes to a text may exist within a chunner, i.e. between two chunks A and B15, in which there are two possible scenarios: a."}, {"heading": "3.2.3. Chunk annotations", "text": "Note that the graph in Figure 3.2 shows how the annotations depend on each other. Note that the graph is the central nexus of Clide-nlp, which pulls all its parts together, mirroring every aspect of Clide-nlp in it. The annotations have the following meaning: Text,: Corenlp Pipeline The inputs of the graph are a pre-constructed CoreNLP pipeline16 and the text of the piece.: Corenlp annotation A CoreNLP annotation is created on the basis of the input text. The annotations provide access to all the primitive NLP constructs that merge the text of the piece.: Corenlp annotation A Corenlp annotation A CoreNLP pipeline is created on the basis of the input text."}, {"heading": "22 3.2. Reconciler", "text": ": semantic-graphs Extract all semantic graphs from the annotation and create a Clojure representations of them. In CoreNLP, the class representing nodes in a semantic graph is called IndexedWord. All IndexedWord instances are mapped to a Word map for later use (see Section 3.3.2).: coref-chain-map Extracts all Coreference clusters from the CoreNLP annotation (see Section 3.3.3).: Sentences Extract information about each set of input text from the annotation and create a list of record cards (see Section 3.3.1).: Knowledge-base Creates a knowledge base for core.logic from the Coref Chain Map and semantic graphs. The process is described in Section 3.4.: Triples Runs Triple Builder on the Knowledge Base, the useful information from the semantic Coref Extract Graphs List and semantic Chain the e.p."}, {"heading": "3. Approach 23", "text": "Unlike the triples extracted from: triples, the subject and object of the grouped triples are a list of related words that can comprise multiple sentences (the entire text) rather than just one sentence. See Section 4.2 for more details.: reified-triples Multiple grouped triples can all have the same subject or the same object groups.: reified-triples assigns a unique name to each group, i.e. the groups become real (matured) by giving them a name (see Section 4.2).: reified-triples-knowledge-base Adds the matured triples to the knowledge base for applications that do not want to search the triples sequentially.: Draw A comment introduced in detail in Chapter 4.2. It tries to draw a graph specified in the input text and warn against simple ambiguous sentences if the triples do not want to be searched sequentially.: Draw a comment that is introduced in detail in Chapter 5. Notation:"}, {"heading": "3.3. Integration of CoreNLP", "text": "clide-nlp does not attempt to rely on the data structures of CoreNLP, because the data structures must participate in core.logic unification. It is problematic due to the changing nature of the data structures of CoreNLP, which extend them to reliably support unification. In addition, there are inconsistencies in the use of 0- or 1-based indexes in the data structures of CoreNLP. This is corrected when building clip-nlp data structures and allows for easier matching of the different data structures based on record and token indexs.All data structures are implemented using clojure datasets. Recordings are mature maps that merge into Java classes. They implement the correct interfaces so that they can be treated as maps, which we will do from that time.We present each dataset by \u2022 providing a brief description of its use in the text, by including its actual descriptions, and we will provide the examples of each with a \u2022 17."}, {"heading": "24 3.3. Integration of CoreNLP", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.3.1. Accessing sentences of a text", "text": "While accessing individual sentences in a text is not important for the core task of clide-nlp (extracting an ontology from a text), we need them to create client annotations that refer to a whole sentence (see Section 3.5).Sentence Maps have the following keys:: index The index of the sentence starts at 0: span The 0-based character index span [a, b) of the sentence. The sentence starts at offset a and reaches up to offset b.: text The text of the sentence. Example: The text \"Felix is a cat. Waldo is a dog. Tweety is a bird.\" yields the following sentence maps: 18: Index 0: span [0, 15): Text Felix is a cat.: Index 1: span [16, 31): Text Waldo is a dog.: Index 2: span [32, 49): Text Tweety is a bird."}, {"heading": "3.3.2. Word maps", "text": "Semantic graph nodes are an integral part of the Triple Builders introduced in Chapter 4.The class of semantic graph nodes in CoreNLP is called IndexedWord. The information provided by an IndexedWord object is used to create a Word map with the following keys:: sentence The sentence index to which this Word map refers. This corresponds to the sentence index \": Index value.: index The index of the word mark starts continuously at 1. CoreNLP starts counting tokens.: span The 0-based character index extends [a, b) of the word card.: tag The word part tag.: lemma The word dilemma.: token The word mark. 18When checking the span, remember to include the spaces between sentences!"}, {"heading": "3. Approach 25", "text": "Example: The semantic graph for the input text \"Felix is a cat.\" has the following Word Maps: cat NNFelix NNP a DTis VBZnsubj detcop: sentence 0: index 1: span [0, 5): tag NNP: lemma Felix: token Felix: sentence 0: index 2: span [6, 8): tag VBZ: lemma be: token is: sentence 0: index 3: span [9, 10): tag DT: lemma a: token a: sentence 0: index 4: span [11, 14): tag NN: lemma cat: token cat"}, {"heading": "3.3.3. Coreferences", "text": "clide-nlp uses the CoreNLP coreference resolution system to determine which entities in a text are similar to other entities in a text. Corereferences are grouped in clusters. A cluster consists of mentions, and we map them to mention cards with the following keys::: cluster-id The coreference cluster id the mentions card is part of.: sentence The index of the record containing this mentions card refers to the tokens in CoreNLP that start at 1 and end at index b before the word card. The indices are 0-based and match the index of a record card as follows: Index and the record value of a record card: sentence.: Index span [a, b) refers to the tokens that start at the word card and end at index b before the word card. The indices are again 1-based, but we do not need to match the record card and the index: the record card."}, {"heading": "26 3.4. Building an NLP knowledge base", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.4. Building an NLP knowledge base", "text": "This section describes how to insert the data structures introduced in Section 3.3 into a core.loq database. Since q database.Chapter 4 takes full advantage of the knowledge base and provides usage examples. First, we need to define the relationships we want to provide. They will be described later in detail. clide-nlps knowledge base provides the following relationships: (word-map w) provides access to word maps (semantic graph maps). (depending on dep reln gov) provides access to semantic graph edges. (just like w1 w2) manages to treat the word maps w1 and w2 as a reference to the same word. Next, we need to insert facts into the knowledge base. Given an input text 1. for each word w of a semantic graph of a set of text, we insert the fact (word-map w) one (word w).2. for each relative graph of a set depends on a semantic graph (n)."}, {"heading": "3. Approach 27", "text": "(tag-w tags) suceeds iff w has one of the tags in the vector tags q. (verb-w) succesces iff w is a verb, i.e. if it has one of the tags VB, VBD, VBG, VBN, VBP or VBZ. (noun-w) successuits iff w is a noun or pronoun, i.e. if it has one of the tags NNP, NN, NNS. PRP or PRP $. (wh-word-w) succeses iff-word19, i.e. if it has one of the tags WDT, WP, WP $or WRB.tag, the basis for implementing all of these targets is a variable. Tag-word ig-ig can be defined in the following way: 1 (defn-tag-2 [succesmap w-tags] 3 (fresh-map w).tag-gramcy w {: tag} 6 (member-tags-dependent set of a noun) if it is a noun, if it is a noun."}, {"heading": "28 3.4. Building an NLP knowledge base", "text": "The words as instances of the same word cluster. The same should be commutative, so that the order of w1 or w2 does not matter. If (the same as w1 w2) succeeds, (the same as w2 w1) succeeds, too. Since w1 and w2 are instances of the same word group, and we like that the word groups are a concrete thing, we want to limit them to including only pronouns, nouns, or determinants. Including adjectives, for example, does not make sense because they are properties of word groups. Verbs are used between two or more word groups (the same is important for grouping triples (see Section 4.2). There are several aspects of this when we can consider two word cards as the same. To be included in the same relationship, the word maps w1 and w2 must have an index that fulfills at least one of the following rules: \u2022 w1 and w2 must be assigned to the same cluster of cores."}, {"heading": "3. Approach 29", "text": "By including compound nouns in same-as, we ensure that each word of a compound nouns is later associated with the same word group (see Section 4.2). \u2022 w1 and w2 must be linked with each other by a wh-word. Word maps linked with a wh-word can be found with the following query: 1 (run * [w1 w2] 2 (fresh [w] 3 (wh-word * w1) 4 (depends on w1 \"nsubj\" w) 5 (depends w (lvar) w2))))) CoreNLP's correlation system does not include wh-words in its mentions. Some triples found by the triples in Chapter 4 have a wh-word as a subject, and we must make sure that they can be merged with the other groups and do not form a separate group."}, {"heading": "3.5. Clide annotations", "text": "Clide annotations are used to provide extensive information about specific parts of a text. They are currently static and non-interactive 21. For example, there is no way to jump from an annotation to a specific word in the document, which limits their usefulness but does not prevent them from being helpful. They follow the same model as the operations sent by Clide (see Section 3.2.2) and are presented as a list of annotation operations known as an annotation stream. In Clide, they are simply called annotations, but we use the term annotation stream to distinguish them from the annotation lists they contain."}, {"heading": "3.5.1. Annotation streams", "text": "There are two types of operations: \u2022 Plain (n) \u2022 Annotate (n, annotations), where n is the length of the annotations, and Annotation is a list of tuples (type, content), where the type of annotations is a string containing the actual annotation content. To apply an annotation content, we must maintain a cursor position starting at 0. The annotations are applied by applying each action sequentially and then mutating the cursor position. 21This means that you cannot interact with the annotation itself, because the annotation content of the cursor position is retained."}, {"heading": "3.5.2. Annotation levels", "text": "While Clide annotations can comment on any part of a text, it is useful to distinguish between different levels of annotation in clide-nlp: Text Annotates the whole textChunk Annotates a chunk (as defined in Section 3.2) Word Annotates a single wordSentence Annotates a whole satenceEvery annotation in clide-nlp, except for a text-level annotation, is relative to a piece. In this way, we keep annotation creation as simple as possible."}, {"heading": "3. Approach 31", "text": "As described in Section 3.2, a chunk has an associated span that specifies the text position of the chunk within the global text, and the internal span of a chunk starts at 0. CoreNLP never sees all the text at once, but only sees the texts of each chunk separately, so all spreads returned by CoreNLP also start at 0.22. Consequently, the NLP knowledge base is also local. Since the annotations created by clide-nlp use all CoreNLP annotations or the NLP knowledge base, ideally we should use local chunk offsets when creating annotation streams. Later, we project their local chunk offsets to offsets that Clide can correctly interpret."}, {"heading": "3.5.3. Annotations provided by clide-nlp", "text": "In this section, we describe each of the annotations provided by Clide-nlp by showing an example of how they appear in Clide. The annotations use another of the annotations in Chunk as described in Section 3.2. There may be some overlap in their names, but they should be treated as separate entities; the names are presented to the user of Clide who can enable them one by one (see the names on the left with the \"eyes\" in Figure 1.1).chunk delimiters Level: TextHighlights the chunk delimiters are described in Section 3.2. This makes the chunkers decisions visible."}, {"heading": "4.1. Triple builders", "text": "A subject usually does something (predicate) with an object. Each subject and object is directly linked to a word map. However, with predicates this is not always possible, because there are predicates that are implied by the semantic graph (see the semantic graphs nsubj-amod or possessive).These predicates are derived and written with a colon prefix (e.g.: be) to distinguish them from the Word Map predicates. While the triple builders only extract information from semantic graphs, they could be extended to information from ontologies such as WordNet [16], VerbOcean [3] or DBpedia [1] to further limit the triples that are found."}, {"heading": "36 4.1. Triple builders", "text": "Note that a triple structure can be successful several times and thus find more than one triple object. nsubj-amodcat NNeats VBZhungry JThe DTnsubjdet amodInput text The hungry cat eats.Query (fresh [subj adj] (noun) (depends on adj \"amod\" subj) (\u2261 triple [subj: be adj])) Triples foundcat: be hungryThe meaning of a subject can be modified with an adjective modifier (amod) [5]. This triple builder captures the fact that cat refers not only to a cat, but to a hungry cat. Since there is no node in the graph that can assume the role of a predicate, we introduce a derived predicate: be instead.nsubj-pred-dobjthe DTIt PRP mouse NNeats Vnj subjectivity of the triple object (the subject) directly depends on the activity of the triple object."}, {"heading": "4. Triples 37", "text": "nsubj-VBeats VBZcat NNThe DTdetnsubjInput text The cat eats.Query (fresh [subj vb] (noun: be vb]) (tag-vb [\"VBZ\" \"VBD\" \"VBP\"]) (depends subj \"nsubj\" vb) (\u2261 triple [subj: be vb])) Triples foundcat: be eatSome sentences have intransitive verbs24 and no object, but they might contain useful information. Here, we capture the fact that the cat eats. To do this, the verb becomes our triple object and we use a derivative predicate: be. This reflects the behavior used for adjectives, e.g. in the triple builder nsubj-amod. We limit ourselves to sentences with verbs that are in the past tense (tag VBD) or singular present (tags VBP and VZ)."}, {"heading": "38 4.1. Triple builders", "text": "nsubj-adj-cop full is qualified with often.nsubj-pred-acomplooks VBZThe DTcat NNfull JJnsubjdetadvmodcopInput text The cat is often full.Query (fresh [subject predicate advmod cop] (depends subject \"nsubj\" predicate) (depends advmod \"advmod\" predicate) (conda [(verb-adj-cop) (\u2261 triple [subject predicate advmod])))) Triples foundfull: be oftenIn combinations with nsubj-adj-cop you will find additional descriptions of an adjective, but also additional properties of subjects. Following e.g. the triple builders nsubj-amod or nsubj-VB,: be is used as our predicate again."}, {"heading": "4. Triples 39", "text": "nsubj-pred-xcompenter VBto TOmanaged VBDHe PRPthe DThouse NNnsubj xcompdetaux dobjInput text He managed to enter the house. Query (fresh [subject activity xcomp object relationship] (subject subject \"nsubj\" activity dependent) (subject \"xcomp\" activity dependent object relationship xcomp) (member \"relationship\" [\"advmod\" \"\" dobj \"]) (conde [(subject dependency\" nsubj \"activity xcomp]) ((subject dependency\" xcomp \"activity)). Triples found out that he managed to enter the house is an open clauses supplement (xcomp) of the administration. The input does not have its own subject, but refers to the subject of the managed (He). There are two useful triples that can be extracted from the graph."}, {"heading": "40 4.1. Triple builders", "text": "agent-ccomp-dobjyou PRPY NNdo VBPthat INis VBZX NNknown VBNIt PRPnsubjccompmarkagent auxpass nsubjpassdobjInput text It is known by X that you do YQuery (fresh [agent object predicate ccomp] (depends agent \"agent\" predicate) (depends ccomp \"ccomp\" predicate) (depends object \"dobj\" ccomp) (increasing triple [agent: about object]))) Triples foundx: about yThis triple builder extracts the fact that X is talking about Y. Since there is no direct graph here that we could use for the predicate, we introduce another derivative predicate: about. All other information from this sentence is collected by other triple builders."}, {"heading": "4. Triples 41", "text": "\"We must ask ourselves whether we are able to exist in the world.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \"\" \"We.\" \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\""}, {"heading": "44 4.2. Reifying triples", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2. Reifying triples", "text": "There is no way that we can know whether the instances relate to the same entity or to different entities. If we use the same - as the relationship we are building in Section 3.4, we can group the subjects and objects of the triples with any other words in the knowledge base that can be treated as a reference to the same entity, and reify the triples. If we apply the same - as to any subject and object of our triples table, our table might look like Table 4.2, where the subjects and objects are replaced by the groups of words to which the original word belongs. Example. Consider the coreference clusters found by CoreNLP for our input text. This gives us an approximation of what the same - as relationship looks like: Node Noname: [2: 4-6] Node End."}, {"heading": "4. Triples 45", "text": "Example: In Table 4.2, the predicate connection appears several times as (potentially different) word maps. In Table 4.3, we have reduced them all to a single: connect. To allow clients access to the reified triple relationship, we update the knowledge base from Section 3.4 to include a new relationship: (Triple t) Triple is a simple relationship, and we simply add to it every triple we have found. Clients can then access all information from the triple relationship by merging with t. An reified triple card is a map with the following scheme: {: subject {: symbol word group name: group vector of word maps}: predicate predicate predicate: object same layout as: subject}"}, {"heading": "46 4.2. Reifying triples", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4. Triples 47", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "48 4.2. Reifying triples", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4. Triples 49", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.3. Exporting an OWL ontology", "text": "In fact, it is a very rare disease, and it is only a very rare disease."}, {"heading": "52 5.1. Triple walks", "text": "Example: Extracting triples from the sets of knots A and B. Knots A and B have a distance of 5 cm and the set of knots A and B are connected with a distance of 5 cm."}, {"heading": "5.1. Triple walks", "text": "We define some auxiliary goals that allow us to define a path that follows a chain of triples and allows us to essentially find pattern matches within that chain. (Subject \u2192 t & Clauses) A theme path succeeds if t = (S0, P0, O0) fulfills each of the clauses. T is three times what we begin with. A clause can be a predicate and object tuple or a 3 tuple, the last element being a partial match of a word map in the S0 word group. We guide the subject t through each of the clauses, as illustrated in Figure 5.1."}, {"heading": "5. Use case: Graph creation from a natural language specification 53", "text": "Example: We define the following theme path to find an edge: S0: start O1, where a Word Map in S0 must match {: lemma \"Edge\"} S0: at O1 S0: go O2 S0: to O2We use O1 and O2 in several clauses to ensure that the clauses only match the same object group. If we look at Table 4.3, we find a triple for which the path is successful: t = (edge-test-0,: start, node-start-0) edge-test-0: start node-0 edge-test-0: at node-0 edge-test-0: go end-node-test-0: to end-node-0We can run that walk with subjecto \u2192 inside a core.logic query: 1 (subjecto \u2192 t 2 [: start O1 {: lemma \"Edge\"}] 3 [: at O1] 4 [: go] If the part-to-will, \"and\" will-2."}, {"heading": "54 5.1. Triple walks", "text": "Example. We define an object walk to determine the distance between the nodes of our edge. We assume that the previous object walk was successful with t = (S0, P0, O0). O0: have O3, where a word map in O3 must match {: lemma \"distance\"} O3: from O4 O4: be O5, where a word map in O5 must match {: tag \"CD.\" The walk is successful if we start with the triple t = (edge-test-0,: start, node-start-0) and follow the triples: node-start-0: have distance-0: of cm-2cm-2: be num-10-0We can perform this walk with objective \u2192 within a grain. Logic query: 1 (object \u2192 t 2 [: have O3 {: lemma \"distance\"}] 3 [: of O4] [: be] logical objects {5: Otag} and {5: \"if they are logical objects\" and \"3\")."}, {"heading": "5. Use case: Graph creation from a natural language specification 55", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.2. Implementation", "text": "The general process follows these steps: 1. Collect nodes 2. Collect edges 3. Check found edges for inconsistencies 4. Check for individual nodes. Each level could send warnings about inconsistencies that we need to present to the user later. The nodes and edge collecting steps use subject and object walks to extract the information we need to create a graph. Example. If we combine the object walk with the subject walk in our previous examples, we get an edge with the distance between their nodes: \u2022 Group S0 = Kantenest-0 contains the edge label (test) \u2022 Group O5 = Num-10-0 is the edge length \u2022 Group O4 = cm-2 contains the edge length of the unitAn edge or node, the label between its nodes is extracted by displaying the word that is next to it in the original text."}, {"heading": "56 5.2. Implementation", "text": "This year it is more than ever before in the history of the city, where it is so far that it is a place, where it is a place, where it is a place."}, {"heading": "66 Bibliography", "text": "[13] Lord, P. The Semantic Web takes Wing: Programming Ontologies with Tawny-Oak Conference for American Ring 2010 arXiv preprint arXiv: 1303.0213 (2013). [14] L\u00fcth, C., and Ring, M. A web interface for Isabelle: The Next Generation. In Intelligent Computer Mathematics. Springer, 2013, pp. 326-329. [15] Marcus, M. P., Marcinkiewicz, M. A., and Santorini, B. Building a large annotated corpus of English: The Penn Treebank. Computational linguistics 19, 2 (1993), 313-330. [16] Miller, G. A. WordNet: A Lexical Database for English. Communications of the ACM 38, 11 (1995), 39-41. [17] Raghunathan, K., Lee, H., Rangarajan, S., Chambers, N., Surdeanu, Jurafsky, D., and Manning, A multi-inclusive."}], "references": [{"title": "DBpedia: A Nucleus for a Web of Open Data", "author": ["S. Auer", "C. Bizer", "G. Kobilarov", "J. Lehmann", "R. Cyganiak", "Z. Ives"], "venue": "In The Semantic Web. Springer,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Relational programming in miniKanren: Techniques, applications, and implementations", "author": ["W.E. Byrd"], "venue": "PhD thesis, Indiana University,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "VerbOcean: Mining the Web for Fine-Grained Semantic Verb Relations", "author": ["T. Chklovski", "P. Pantel"], "venue": "In EMNLP (2004),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["De Marneffe", "M.-C", "B. MacCartney", "Manning", "C. D"], "venue": "In Proceedings of LREC (2006),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Stanford typed dependencies manual", "author": ["de Marneffe", "M.-C", "C.D. Manning"], "venue": "Revised in December 2013 for the Stanford Parser v", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "The Joy of Clojure: Thinking the Clojure Way", "author": ["M. Fogus", "C. Houser"], "venue": "Manning Publications Co.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "The Reasoned Schemer", "author": ["D.P. Friedman", "W.E. Byrd", "O. Kiselyov"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "OWL 2 Web Ontology Language: New Features and Rationale", "author": ["C. Golbreich", "E.K. Wallace", "P.F. Patel-Schneider"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Semantic Web: Grundlagen", "author": ["P. Hitzler"], "venue": "eXamen.press. Springer-Verlag, Berlin,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Stanford\u2019s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task", "author": ["H. Lee", "Y. Peirsman", "A. Chang", "N. Chambers", "M. Surdeanu", "D. Jurafsky"], "venue": "In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "The Semantic Web takes Wing: Programming Ontologies with Tawny-OWL", "author": ["P. Lord"], "venue": "arXiv preprint arXiv:1303.0213", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "A web interface for Isabelle: The Next Generation", "author": ["C. L\u00fcth", "M. Ring"], "venue": "In Intelligent Computer Mathematics. Springer,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Building a large annotated corpus of English: The Penn Treebank", "author": ["M.P. Marcus", "M.A. Marcinkiewicz", "B. Santorini"], "venue": "Computational linguistics 19,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1993}, {"title": "WordNet: A Lexical Database for English", "author": ["G.A. Miller"], "venue": "Communications of the ACM 38,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "A multi-pass sieve for coreference resolution", "author": ["K. Raghunathan", "H. Lee", "S. Rangarajan", "N. Chambers", "M. Surdeanu", "D. Jurafsky", "C. Manning"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "The life and death of discourse entities: Identifying singleton mentions", "author": ["M. Recasens", "de Marneffe", "M.-C", "C. Potts"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Eine webbasierte Entwicklungsumgebung f\u00fcr den interaktiven Theorembeweiser Isabelle", "author": ["M. Ring"], "venue": "Diplomarbeit, Universita\u0308t Bremen,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Collaborative Interactive Theorem Proving with Clide", "author": ["M. Ring", "C. L\u00fcth"], "venue": "In Proceedings of ITP", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Using Clojure in Linguistic Computing", "author": ["Z. Varj\u00fa", "R. Littauer", "P. Ernis"], "venue": "In Proceedings of the 5th European Lisp Symposium", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "The Cucumber Book: Behaviour-driven Development for Testers and Developers", "author": ["M. Wynne", "A. Hellesoy"], "venue": "Pragmatic Bookshelf,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}], "referenceMentions": [{"referenceID": 19, "context": "Scenarios consist of steps and each step is parsed using a user provided regular expression [22].", "startOffset": 92, "endOffset": 96}, {"referenceID": 11, "context": "It was originally intended to be a web-based development environment for Isabelle4 only [14, 19].", "startOffset": 88, "endOffset": 96}, {"referenceID": 16, "context": "It was originally intended to be a web-based development environment for Isabelle4 only [14, 19].", "startOffset": 88, "endOffset": 96}, {"referenceID": 16, "context": "In contrast with previous Isabelle interfaces, it provides better visualization of the prover\u2019s results than traditional and sequential REPL5-based interfaces through leveraging Web technologies like HTML5 and JavaScript [19].", "startOffset": 221, "endOffset": 225}, {"referenceID": 17, "context": "It has since undergone further development and has evolved to facilitate collaborative editing of documents with support for other languages besides Isabelle [20].", "startOffset": 158, "endOffset": 162}, {"referenceID": 17, "context": "It uses an approach called Universal Collaboration where an assistant is seen as just an additional collaborator by the system [20].", "startOffset": 127, "endOffset": 131}, {"referenceID": 17, "context": "While Clide is distributive and asynchronous in nature, it provides an interface that can be used to implement assistants \u201cin a simple, synchronous manner\u201d [20].", "startOffset": 156, "endOffset": 160}, {"referenceID": 5, "context": "Clojure provides a REPL which allows us to patch in new code into a running system, enabling a small \u201cthought-code-feedback loop\u201d [7].", "startOffset": 130, "endOffset": 133}, {"referenceID": 0, "context": "It provides built-in persistent data structures with their own reader syntax, that are immutable and have clear and intuitive value equality semantics (1 is 1 and [1 2 3] is [1 2 3]).", "startOffset": 163, "endOffset": 170}, {"referenceID": 1, "context": "It provides built-in persistent data structures with their own reader syntax, that are immutable and have clear and intuitive value equality semantics (1 is 1 and [1 2 3] is [1 2 3]).", "startOffset": 163, "endOffset": 170}, {"referenceID": 2, "context": "It provides built-in persistent data structures with their own reader syntax, that are immutable and have clear and intuitive value equality semantics (1 is 1 and [1 2 3] is [1 2 3]).", "startOffset": 163, "endOffset": 170}, {"referenceID": 0, "context": "It provides built-in persistent data structures with their own reader syntax, that are immutable and have clear and intuitive value equality semantics (1 is 1 and [1 2 3] is [1 2 3]).", "startOffset": 174, "endOffset": 181}, {"referenceID": 1, "context": "It provides built-in persistent data structures with their own reader syntax, that are immutable and have clear and intuitive value equality semantics (1 is 1 and [1 2 3] is [1 2 3]).", "startOffset": 174, "endOffset": 181}, {"referenceID": 2, "context": "It provides built-in persistent data structures with their own reader syntax, that are immutable and have clear and intuitive value equality semantics (1 is 1 and [1 2 3] is [1 2 3]).", "startOffset": 174, "endOffset": 181}, {"referenceID": 18, "context": "This allows us to leverage all existing Java NLP libraries [6, 21].", "startOffset": 59, "endOffset": 66}, {"referenceID": 5, "context": "More information on Clojure is available in [6, 7].", "startOffset": 44, "endOffset": 50}, {"referenceID": 1, "context": "Byrd as part of his PhD thesis [2].", "startOffset": 31, "endOffset": 34}, {"referenceID": 18, "context": "logic when we need it and use Clojure functional programming aspects otherwise [21].", "startOffset": 79, "endOffset": 83}, {"referenceID": 0, "context": "List membership (member\u25e6 q [1 2 3]) A goal that succeeds if q is bound to value that is in the vector [1 2 3] Extract a logic variable\u2019s value inside a query (project [q] .", "startOffset": 27, "endOffset": 34}, {"referenceID": 1, "context": "List membership (member\u25e6 q [1 2 3]) A goal that succeeds if q is bound to value that is in the vector [1 2 3] Extract a logic variable\u2019s value inside a query (project [q] .", "startOffset": 27, "endOffset": 34}, {"referenceID": 2, "context": "List membership (member\u25e6 q [1 2 3]) A goal that succeeds if q is bound to value that is in the vector [1 2 3] Extract a logic variable\u2019s value inside a query (project [q] .", "startOffset": 27, "endOffset": 34}, {"referenceID": 0, "context": "List membership (member\u25e6 q [1 2 3]) A goal that succeeds if q is bound to value that is in the vector [1 2 3] Extract a logic variable\u2019s value inside a query (project [q] .", "startOffset": 102, "endOffset": 109}, {"referenceID": 1, "context": "List membership (member\u25e6 q [1 2 3]) A goal that succeeds if q is bound to value that is in the vector [1 2 3] Extract a logic variable\u2019s value inside a query (project [q] .", "startOffset": 102, "endOffset": 109}, {"referenceID": 2, "context": "List membership (member\u25e6 q [1 2 3]) A goal that succeeds if q is bound to value that is in the vector [1 2 3] Extract a logic variable\u2019s value inside a query (project [q] .", "startOffset": 102, "endOffset": 109}, {"referenceID": 0, "context": "Domain constraint (in q (interval 1 10)) Makes sure that q is bound to a value in the interval [1, 10].", "startOffset": 95, "endOffset": 102}, {"referenceID": 8, "context": "Domain constraint (in q (interval 1 10)) Makes sure that q is bound to a value in the interval [1, 10].", "startOffset": 95, "endOffset": 102}, {"referenceID": 1, "context": "logic code shown here is based on the code presentation in [2, 8].", "startOffset": 59, "endOffset": 65}, {"referenceID": 6, "context": "logic code shown here is based on the code presentation in [2, 8].", "startOffset": 59, "endOffset": 65}, {"referenceID": 1, "context": "Presentation Actual code <x>\u25e6 <x>o A goal is written with a suffix o to distinguish it from already defined functions on the functional programming side, while making clear that they have the same outcome in both paradigms [2].", "startOffset": 223, "endOffset": 226}, {"referenceID": 6, "context": "conda conda \u2261 == 6\u2261 != The Reasoned Schemer [8] provides a good introduction to miniKanren and in extension also core.", "startOffset": 44, "endOffset": 47}, {"referenceID": 10, "context": "Tawny-OWL Tawny-OWL11 is a Clojure library that provides a domain specific language for building OWL ontologies [13].", "startOffset": 112, "endOffset": 116}, {"referenceID": 8, "context": "querying them via SparQL [10].", "startOffset": 25, "endOffset": 29}, {"referenceID": 3, "context": "The dependency parser makes the underlying structures of sentences visible in the form of grammatical relations between sentence parts [4].", "startOffset": 135, "endOffset": 138}, {"referenceID": 4, "context": "The grammatical relations are described in [5].", "startOffset": 43, "endOffset": 46}, {"referenceID": 3, "context": "The dependency parser can collapse prepositions and coordinations into grammatical relations [4, 5].", "startOffset": 93, "endOffset": 99}, {"referenceID": 4, "context": "The dependency parser can collapse prepositions and coordinations into grammatical relations [4, 5].", "startOffset": 93, "endOffset": 99}, {"referenceID": 12, "context": "Its tagset is based on the POS tagset used by the Penn Treebank, described in [15].", "startOffset": 78, "endOffset": 82}, {"referenceID": 9, "context": "It was introduced in [11, 12, 17, 18].", "startOffset": 21, "endOffset": 37}, {"referenceID": 14, "context": "It was introduced in [11, 12, 17, 18].", "startOffset": 21, "endOffset": 37}, {"referenceID": 15, "context": "It was introduced in [11, 12, 17, 18].", "startOffset": 21, "endOffset": 37}, {"referenceID": 9, "context": "It competed in the CoNLL Shared Task 2011, where it achieved the highest score in both the closed and open tracks [12].", "startOffset": 114, "endOffset": 118}, {"referenceID": 17, "context": "There are three operations [20]: \u2022 Retain(n) \u2022 Insert(s) \u2022 Delete(n) Since Clide is written in Scala Retain, Insert and Delete are implemented using Scala case classes.", "startOffset": 27, "endOffset": 31}, {"referenceID": 4, "context": "relation can be either a string containing a typed dependency relation (see [5]) or if the relation is a collapsed relation, a vector of the first and second part of the relation (e.", "startOffset": 76, "endOffset": 79}, {"referenceID": 4, "context": "nn is the noun compound modifier dependency relation that asserts that one noun modifies another noun [5].", "startOffset": 102, "endOffset": 105}, {"referenceID": 17, "context": "Ignoring annotations, we can treat :plain and :annotate as :retain operations [20].", "startOffset": 78, "endOffset": 82}, {"referenceID": 13, "context": "While the triple builders only extracts information from semantic graphs, they could be extended to include information from ontologies like WordNet [16], VerbOcean [3] or DBpedia [1] to further constrain the triples that are found.", "startOffset": 149, "endOffset": 153}, {"referenceID": 2, "context": "While the triple builders only extracts information from semantic graphs, they could be extended to include information from ontologies like WordNet [16], VerbOcean [3] or DBpedia [1] to further constrain the triples that are found.", "startOffset": 165, "endOffset": 168}, {"referenceID": 0, "context": "While the triple builders only extracts information from semantic graphs, they could be extended to include information from ontologies like WordNet [16], VerbOcean [3] or DBpedia [1] to further constrain the triples that are found.", "startOffset": 180, "endOffset": 183}, {"referenceID": 4, "context": "The meaning of a subject can be modified with an adjectival modifier (amod) [5].", "startOffset": 76, "endOffset": 79}, {"referenceID": 4, "context": "Verbs and adjectives have an acomp (adjectival complement) relation, if an adjective can be treated as the verb\u2019s object [5].", "startOffset": 121, "endOffset": 124}, {"referenceID": 4, "context": "enter does not have its own subject but refers to the subject of managed (He) [5].", "startOffset": 78, "endOffset": 81}, {"referenceID": 4, "context": "An agent is \u201cintroduced by the preposition by\u201d [5].", "startOffset": 47, "endOffset": 50}, {"referenceID": 4, "context": "This triple builder captures numeric modifiers (num) [5] of nouns, e.", "startOffset": 53, "endOffset": 56}, {"referenceID": 7, "context": "OWL 2 introduces a feature called punning [9] where we create an individual for each of our classes and then use object properties on these individuals to describe relationships between the classes.", "startOffset": 42, "endOffset": 45}, {"referenceID": 12, "context": "The part of speech tags used by CoreNLP are based on the tags used by the Penn Treebank [15].", "startOffset": 88, "endOffset": 92}], "year": 2014, "abstractText": null, "creator": "LaTeX with hyperref package"}}}