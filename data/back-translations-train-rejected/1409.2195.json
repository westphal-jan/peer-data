{"id": "1409.2195", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2014", "title": "Analyzing the Language of Food on Social Media", "abstract": "We investigate the predictive power behind the language of food on social media. We collect a corpus of over three million food-related posts from Twitter and demonstrate that many latent population characteristics can be directly predicted from this data: overweight rate, diabetes rate, political leaning, and home geographical location of authors. For all tasks, our language-based models significantly outperform the majority- class baselines. Performance is further improved with more complex natural language processing, such as topic modeling. We analyze which textual features have most predictive power for these datasets, providing insight into the connections between the language of food, geographic locale, and community characteristics. Lastly, we design and implement an online system for real-time query and visualization of the dataset. Visualization tools, such as geo-referenced heatmaps, semantics-preserving wordclouds and temporal histograms, allow us to discover more complex, global patterns mirrored in the language of food.", "histories": [["v1", "Mon, 8 Sep 2014 03:07:54 GMT  (8527kb,D)", "https://arxiv.org/abs/1409.2195v1", null], ["v2", "Thu, 11 Sep 2014 17:35:02 GMT  (8519kb,D)", "http://arxiv.org/abs/1409.2195v2", "An extended abstract of this paper will appear in IEEE Big Data 2014"]], "reviews": [], "SUBJECTS": "cs.CL cs.CY cs.SI", "authors": ["daniel fried", "mihai surdeanu", "stephen kobourov", "melanie hingle", "dane bell"], "accepted": false, "id": "1409.2195"}, "pdf": {"name": "1409.2195.pdf", "metadata": {"source": "CRF", "title": "Analyzing the Language of Food on Social Media", "authors": ["Daniel Fried", "Mihai Surdeanu", "Stephen Kobourov", "Melanie Hingle", "Dane Bell"], "emails": ["dane}@email.arizona.edu"], "sections": [{"heading": null, "text": "I. INTRODUCTIONOur diet reflects our identities; the food we eat is influenced by our lifestyle, habits, education, cultural and family heritage; in addition to our current self-assessment, our eating habits shape who we will be by influencing our health and well-being; the purpose of this work is to understand whether information about individuals \"diets, which is reflected in the language they use to describe their diet, can convey latent information about a community, such as their location, likelihood of diabetes, and even political preferences; this information can be used for a variety of purposes, from improving public health to better targeted marketing. In this work, we use Twitter as a language source for food. The informal, colloquial nature of Twitter posts, as well as the ease of access to data, make it possible to assemble a large body that describes the type of food consumed and the context of discussion."}, {"heading": "II. DATA", "text": "In our collection, the average length of a tweet is limited to 8.7 million words displayed after breakfast1, making it well suited for studying the eating habits of individuals on a large scale. To identify and collect tweets about food, we have queried Twitter's public streaming pattern API21http: / / www.pewinternet.org / 2014 / 01 / 08 / social-media-update-2013 / twitter-users / 2https: / / dev.twitter.com / docs / api / streaming. Note: Twitter limits the number of possible tweets returned by the streaming API to a fraction of the total number of tweets available at a given time. ar Xiv: 140 9.21 95v2 [cs.CL] 1 1Se p20 14for posts containing hashtags relating to meals (Table I). We have collected approximately 3.5 million tweets containing at least one of these hashtags, from the period between October 2, 2013 and May 29, 2014, which are very limited."}, {"heading": "III. TASKS", "text": "To understand the predictive power of the language of food, we implement several prediction tasks using the tweets in the above dataset as a single input. We group these tasks into two categories: characteristic predictions at the state level and local predictions."}, {"heading": "A. Predicting State-Level Characteristics", "text": "Here we predict three aggregated traits for US states, using traits extracted from tweets from individuals in each state. (1) Diabetes Rate: This is the percentage of adults in each state who have been told by a doctor that they have diabetes. Data in this sentence are converted into a binary dependent variable by the D.C. Republican Obesity Commission and the Uninsured Candidates (KCMU) \"s 2012 analysis of the Center for Disease Control's Behavioral Risk Factor Surveillance System (BRFSS), considering whether a state's diabetes rate is above or below the national median. The median diabetes rate is 9.7%, and the range is 6.0% in Alaska to 13.0% in West Virginia. For example, Alabama has a diabetes rate of 12.3%, which is above the national median of 9.7%, so it is labeled as high diabetes, while Alaska has a rate of 7.0%."}, {"heading": "B. Predicting Locales", "text": "To investigate the connection between the language of the food and the geographical location, we try to predict the location of a group of tweets, using only the text of the tweets as input. We predict locations at different levels: city, state, and region. It is important to note that, in order to focus our analysis on the predictive power of the language of the food, we remove as many state and city names from the tweets as possible to avoid trivial correlations (see Section IV-A).1) City: The locations in the city prediction task are the 15 most populous cities in the US.72) State: Places in the state prediction task are the 50 US states plus Washington, D.C. As discussed in the previous section, both city and state labels are associated with tweets by analyzing the author's self-reported location in the metadata. 3) Region: The last variant of the prediction task is the city prediction task, the predictive task of the region is the beneficial state of the USA."}, {"heading": "IV. FEATURE DESCRIPTIONS", "text": "We use two types of traits: lexical (from tweet words) and current (from words that occur in similar contexts)."}, {"heading": "A. Lexical Features", "text": "We take the simple approach of presenting each locality as a bag of words composed of all tweets in that group. Each word becomes a trait whose value corresponds to the number of times it occurs in all tweets in that locality. We link the tweets with Stanford CoreNLP software. An additional step before processing removes the following tokens: (a) tokens that do not contain alphanumeric characters or punctuation (to reduce noise); (b) stopwords and words that occur once (to reduce the data size); and, most importantly, (c) URLs, usernames (preceded by an @ symbol) and words and hashtags that name the state and city 10 (to avoid trivial correlations, such as # TX, that show a tweet from Texas). We also experiment with open versus closed vocabularies. For open vocabularies, we use two configurations: all words that are generated by the step above, to include a more comprehensive vocabulary, or just a tag."}, {"heading": "B. Topic Model Features", "text": "Topic models provide a method of deriving the topics present in tweets, which are presented as groups of words that tend to appear in similar contexts (e.g., a topic learned from the model we call the American Nutrition Topic includes chicken, baked tweets, beans, and fried, among other terms).The use of topics as traits is beneficial for a few reasons: (1) Topics provide a9http: / / en.wikipedia.org / list of U.S. cities by population, along with common nicknames such as \"# sanfran\" for San Francisco.11http: / www.lingolex.com / spanishfood / a-b.htm 12http: / www.enchantedlearning.com / wort.shtmlMethod that we are very economical when dealing with the addresses of 140 related documents (DA)."}, {"heading": "V. RESULTS", "text": "We present empirical results for both categories of tasks presented in the previous section: predicting characteristics at the state level and predicting localities. We also analyze the effectiveness of food language for these prediction tasks by examining the most important textual characteristics in the classification models and the importance of open versus closed vocabulary."}, {"heading": "A. State-Level Characteristics", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to"}, {"heading": "B. City Prediction", "text": "For the first local prediction task, we focus on the identification of cities. Table IV shows the accuracy of the various characteristics available for this task. Input for this task is 15 cities, so the accuracy of the random prediction is 6.67%. As in the previous task, each set of characteristics improves significantly over this basic task. The significant improvement in the closed food vocabulary alone (Food) above the baseline shows that the nutrition in each of these 15 cities is significant enough to have some predictive power. However, diets alone are not enough to fully identify the cities, and we see that more context is useful for this task: adding hashtags significantly helps (Food) to indicate the accuracy of food (53.33%), and adding topical characteristics to a number of lexical characteristics in San Francisco."}, {"heading": "C. State Prediction", "text": "Table VII lists the results of the state prediction task. There are 51 possible locations in this task, from the 50 US states plus Washington, D.C., so that the random prediction basis achieves an accuracy of 1.96%. As in all previous experiments, the state prediction model significantly improves with each set of characteristics we have tried, compared to this baseline. The model achieves its lowest accuracy, 33.33%, by using the set of food words without current characteristics (food). Unlike the urban prediction task, but similar to the characteristic prediction task at the federal level, the model is most accurate when using the unfiltered tweets with current characteristics (All Words + LDA) and achieves an accuracy of 66.67%. This suggests that the closed food vocabulary is not sufficient for optimal performance in this task, and the larger food-related context is required for optimal performance. Table VIII analyzes the effect of the number of tweets available on the prediction task."}, {"heading": "D. Region Prediction", "text": "The final localization task predicts the four most important geographic regions of the United States: the Midwest, Northeast, South, and West (Section III-B3), using tweets from each region. High geographic granularity (each region contains an average of about a dozen states) simplifies the tweet-based task in a sense, as there are fewer possible nutrition classification tools now, but the task is made more difficult due to the variation in nutrition and tweet lexical content within these geographical regions. However, the random prediction baseline in this task reaches an accuracy of 25%. However, three of the feature sets achieve an accuracy of 75%, with only the graphical representation of a single region being misclassified.17 We also see that for all feature sets except the closed food lexical characteristics, lexical features result in a more accurate region classification above the baseline, supplementing 16https: / sitesgoogle.com / 17twitter.com / 17food are only set data."}, {"heading": "A. Top Terms by State", "text": "The first of these tools, the term visualizer (fig. 2), performs a simple keyword analysis of the tweets available for each US state. We extract all the terms contained in a list of about 800 food-related words (see para. IV-A), and evaluate them using tf-idf, treating all tweets normalized to a particular state as a single document: The score of each term is the number of times it has occurred within a state multiplied by the logarithm of the inverse percentage of the number of states in which it has occurred [10]."}, {"heading": "B. Temporal Histograms", "text": "Approximately 71% of the collected tweets (2,503,351) come from users who have listed their time zone. We calculate the time locally for the user at which the tweet was posted. The time visualization tool (fig. 4) allows us to query these time-localized tweets for phrases and generate histograms at different times: time of day, day of the week or month of the year. On the weekly scale, it is easy to see that while breakfast is more or less consistent throughout the week, brunch is much more common on weekends, especially on Sundays. On the daily scale, there are wine peaks at 8 p.m., while beer follows a bi-modal distribution, with two peaks of roughly the same size at 1 and 8 p.m."}, {"heading": "C. Tweet Location Maps", "text": "Approximately 10% of the tweets collected (362,978) have geolocation information - the longitude and latitude of the user at the time of posting the tweet. We use this meta-information to build a system to query and display global geographic maps of tweets. It allows users to search for phrases or LDA topics and displays geographical charts or heat maps that show the locations of all tweets that match the query. This system allows for the discovery of broad geographical trends in the data. For example, Figure 5 shows heat maps created from queries for multiple LDA topics for foods of different geographical origin. These topics may reflect migration patterns to the U.S. or worldwide, e.g. the Italian food theme has high intensity in Italy and New York City (Figure 5a), and the Vietnamese food theme has high intensity in Vietnam and Southern California (Figure 5b). The Full Breakfast theme, which mirrors a traditional egg-based, British and Western breakfast spread throughout the United States and throughout Spain."}, {"heading": "D. Parallel Word Clouds", "text": "Word clouds provide a space-saving way to summarize text by highlighting important words. Semantic-preserving word clouds also add the feature of placing related words (such as those that often occur next to each other) close together. [2] Our parallel word clouds continue to focus on comparing and contrasting two or more text groups: words are scaled by importance, related words are close to each other, and important words that occur in both groups are located in the same places in all clouds (quote hidden for review). Fig. 7 shows such parallel word clouds for weekday versus weekend tweets highlighting different trends: family, brunch and even breakfast are in the foreground on weekends; work and night are common on weekdays (in red); and finally, restaurant and fun are present on weekends (in blue)."}, {"heading": "VII. RELATED WORK", "text": "Previous work has used text analysis of Twitter posts to examine different and global population patterns, including the study of temporal changes in mood [7] and correlations between religious expression and sensation [19]. Several other papers predict latent characteristics of individuals and communities based on social media posts and metadata. Rao et al. [18] predict how gender, age, regional origin, and political orientation will affect individual Twitter users based on tweets and a number of hand-constructed linguistic functions. Burger et al. [4] and Bamman et al. [1] predict that gender will use their tweets and additional meta information, such as name, self-description, and their social network. Jurafsky et al al al al al. [9] analyze a corpus of restaurant reviews and predict restaurant reviews, such as feelings, narratives, and self-portrayal.Paul and Dredze [16] apply the Ailment Topect Model to 1.5 million tweets about health-related diseases and menus."}, {"heading": "VIII. CONCLUSION AND FUTURE WORK", "text": "This work empirically demonstrates that food and food discussions are a large part of who we are. We are developing a system to capture a large corpus of food-related tweets and use these tweets to predict many latent population traits: obesity and diabetes rates, political learning, and author geography. In addition, we are integrating multiple visualization tools that summarize and query this data and allow us to detect more complex geographical / temporal trends driven by the language of food, such as potential migration patterns. Our analysis shows that the language of food alone is extremely powerful. For example, for most prediction tasks, a coherent vocabulary of only 800 foods approaches the peak performance achieved by using all of the tweets. Perhaps most important, our analysis of the prediction models we learn provides data-based insights into correlations between the language of food and the understudied population characteristics."}], "references": [{"title": "Gender identity and lexical variation in social media", "author": ["D. Bamman", "J. Eisenstein", "T. Schnoebelen"], "venue": "Journal of Sociolinguistics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Experimental comparison of semantic word clouds", "author": ["L. Barth", "S.G. Kobourov", "S. Pupyrev"], "venue": "In SEA,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Discriminating gender on twitter. In EMNLP, pages 1301\u20131309", "author": ["J.D. Burger", "J. Henderson", "G. Kim", "G. Zarrella"], "venue": "Association for Computational Linguistics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "A latent variable model for geographic lexical variation", "author": ["J. Eisenstein", "B. O\u2019Connor", "N.A. Smith", "E.P. Xing"], "venue": "In EMNLP,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Mapping the geographical diffusion of new words", "author": ["J. Eisenstein", "B. O\u2019Connor", "N.A. Smith", "E.P. Xing"], "venue": "arXiv preprint arXiv:1210.5268,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Diurnal and seasonal mood vary with work, sleep, and daylength across diverse cultures", "author": ["S.A. Golder", "M.W. Macy"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Collection and visualization of dietary behavior and reasons for eating using a popular and free social media software application", "author": ["M. Hingle", "D. Yoon", "J.F.S.G. Kobourov", "M. Schneider", "D. Falk", "R. Burd"], "venue": "Journal of Medical Internet Research (JMIR),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Narrative framing of consumer sentiment in online restaurant reviews", "author": ["D. Jurafsky", "V. Chahuneau", "B. Routledge", "N. Smith"], "venue": "First Monday,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Introduction to Information Retrieval", "author": ["C.D. Manning", "P. Raghavan", "H. Sch\u00fctze"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Scalable distributed event detection for twitter", "author": ["R. McCreadie", "C. Macdonald", "I. Ounis", "M. Osborne", "S. Petrovic"], "venue": "In Int. Conf. on Big Data,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Using twitter to examine smoking behavior and perceptions of emerging tobacco products", "author": ["M. Mysl\u0131\u0301n", "S.-H. Zhu", "W. Chapman", "M. Conway"], "venue": "J Med Internet Res,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Real-time sharing and expression of migraine headache suffering on Twitter: A cross-sectional infodemiology study", "author": ["D.T. Nascimento", "F.M. DosSantos", "T. Danciu", "M. DeBoer", "H. van Holsbeeck", "R.S. Lucas", "C. Aiello", "L. Khatib", "A.M. Bender", "J.-K. Zubieta", "F.A. DaSilva"], "venue": "J Med Internet Res,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "The royal birth of 2013: Analysing and visualising public sentiment in the uk using twitter", "author": ["V.D. Nguyen", "B. Varghese", "A. Barker"], "venue": "In Int. Conf. on Big Data,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "A mixture model of demographic lexical variation", "author": ["B. OConnor", "J. Eisenstein", "E.P. Xing", "N.A. Smith"], "venue": "In Proc. of NIPS workshop on machine learning in computational social science,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "You are what you tweet: Analyzing Twitter for public health", "author": ["M.J. Paul", "M. Dredze"], "venue": "In ICWSM,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "It\u2019s not you, it\u2019s me: Detecting flirting and its misperception in speed-dates", "author": ["R. Ranganath", "D. Jurafsky", "D. McFarland"], "venue": "In EMNLP,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Classifying latent user attributes in Twitter", "author": ["D. Rao", "D. Yarowsky", "A. Shreevats", "M. Gupta"], "venue": "In 2nd Intl. Workshop on Search and mining user-generated contents,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Happy tweets: Christians are happier, more socially connected, and less analytical than atheists on Twitter", "author": ["R.S. Ritter", "J.L. Preston", "I. Hernandez"], "venue": "Social Psychological and Personality Science,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Characterizing geographic variation in well-being using tweets", "author": ["H. Schwartz", "J. Eichstaedt", "M. Kern", "L. Dziurzynski", "M. Agrawal", "G. Park", "S. Lakshmikanth", "S. Jha", "M. Seligman", "L. Ungar"], "venue": "In 7th Intl. AAAI ICWSM,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["R. Socher", "A. Perelygin", "J. Wu", "J. Chuang", "C.D. Manning", "A. Ng", "C. Potts"], "venue": "In EMNLP. Association for Computational Linguistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Statistical Learning Theory", "author": ["V.N. Vapnik"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}, {"title": "Detecting disease outbreaks in mass gatherings using internet data", "author": ["E. Yom-Tov", "D. Borsa", "J.I. Cox", "A.R. McKendry"], "venue": "J Med Internet Res,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}], "referenceMentions": [{"referenceID": 9, "context": "Terms are ranked using term frequency\u2013inverse document frequency (tf-idf) [10] to discount words that occur frequently across all states, and give priority to those words that are highly representative of a state.", "startOffset": 74, "endOffset": 78}, {"referenceID": 21, "context": "We used Support Vector Machines (SVM) with a linear kernel [22] for classification.", "startOffset": 59, "endOffset": 63}, {"referenceID": 2, "context": "We use Latent Dirichlet Allocation (LDA) [3] to learn a set of topics from the food tweets in an unsupervised fashion.", "startOffset": 41, "endOffset": 44}, {"referenceID": 20, "context": ", based on deep learning [21], in future work.", "startOffset": 25, "endOffset": 29}, {"referenceID": 16, "context": "[17], showing that the types of pronouns used by an individual are associated with a host of traits such as gender and intention.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "IV-A) and rank them using tf-idf, treating all tweets normalized to a given state as a single document: each term\u2019s score is the number of times it occurred within a state, multiplied by the logarithm of the inverse proportion of the number of states it occurred in [10].", "startOffset": 266, "endOffset": 270}, {"referenceID": 1, "context": ", those that frequently co-occur) are placed close to each other [2].", "startOffset": 65, "endOffset": 68}, {"referenceID": 6, "context": "Previous work has used textual analysis of Twitter posts to study diverse and global populations, including investigating temporal changes in mood [7] and correlations between religious expression and sentiment [19].", "startOffset": 147, "endOffset": 150}, {"referenceID": 18, "context": "Previous work has used textual analysis of Twitter posts to study diverse and global populations, including investigating temporal changes in mood [7] and correlations between religious expression and sentiment [19].", "startOffset": 211, "endOffset": 215}, {"referenceID": 17, "context": "[18] predict gender, age, regional origin, and political orientation for individual Twitter users, using tweets and a set of hand-constructed linguistic features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[4] and Bamman et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1] predict users\u2019 gender using their tweets and additional meta information, such as name, self description, and their social network.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] analyze a corpus of restaurant reviews and predict restaurant ratings using linguistic features such as sentiment, narrative, and self-portrayal.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "Paul and Dredze [16] apply the Ailment Topic Aspect Model to 1.", "startOffset": 16, "endOffset": 20}, {"referenceID": 19, "context": "[20] use Twitter to predict public health and well-being statistics on a state-wide level.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] use Twitter together with analytical software to capture real-time food consumption and diet-related behavior.", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "[13] evaluate self-reported migraine headache suffering using over 20,000 migrane-related tweets over a seven-day period, finding different peaking hours on weekdays and weekends.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] show how Twitter can be used to discover possible outbreaks of communicable diseases at large public gatherings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] use machine classification of tobacco-related Twitter posts to detect tobacco-relevant posts and sentiment towards tobacco products.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] create a generative model of word use from demographic traits, and show clusters of Twitter users with common lexicons.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5], [6] show that despite the global diffusion of social media, geographic regions have distinct word and topic use on Twitter.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[5], [6] show that despite the global diffusion of social media, geographic regions have distinct word and topic use on Twitter.", "startOffset": 5, "endOffset": 8}, {"referenceID": 10, "context": "[11] develop a system for detecting newsworthy events and clustering tweets in real-time.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] produce geographic visualizations of tweet sentiment using machine learning classifiers and the tweets\u2019 location metadata.", "startOffset": 0, "endOffset": 4}], "year": 2014, "abstractText": "We investigate the predictive power behind the language of food on social media. We collect a corpus of over three million food-related posts from Twitter and demonstrate that many latent population characteristics can be directly predicted from this data: overweight rate, diabetes rate, political leaning, and home geographical location of authors. For all tasks, our language-based models significantly outperform the majorityclass baselines. Performance is further improved with more complex natural language processing, such as topic modeling. We analyze which textual features have most predictive power for these datasets, providing insight into the connections between the language of food, geographic locale, and community characteristics. Lastly, we design and implement an online system for real-time query and visualization of the dataset. Visualization tools, such as geo-referenced heatmaps, semantics-preserving wordclouds and temporal histograms, allow us to discover more complex, global patterns mirrored in the language of food.", "creator": "LaTeX with hyperref package"}}}