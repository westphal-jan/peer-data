{"id": "1409.3005", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Sep-2014", "title": "A Study of Association Measures and their Combination for Arabic MWT Extraction", "abstract": "Automatic Multi-Word Term (MWT) extraction is a very important issue to many applications, such as information retrieval, question answering, and text categorization. Although many methods have been used for MWT extraction in English and other European languages, few studies have been applied to Arabic. In this paper, we propose a novel, hybrid method which combines linguistic and statistical approaches for Arabic Multi-Word Term extraction. The main contribution of our method is to consider contextual information and both termhood and unithood for association measures at the statistical filtering step. In addition, our technique takes into account the problem of MWT variation in the linguistic filtering step. The performance of the proposed statistical measure (NLC-value) is evaluated using an Arabic environment corpus by comparing it with some existing competitors. Experimental results show that our NLC-value measure outperforms the other ones in term of precision for both bi-grams and tri-grams.", "histories": [["v1", "Wed, 10 Sep 2014 09:52:41 GMT  (948kb,D)", "http://arxiv.org/abs/1409.3005v1", "This paper have been presented and published in 10th International Conference on Terminology and Artificial Intelligence Proceedings"]], "COMMENTS": "This paper have been presented and published in 10th International Conference on Terminology and Artificial Intelligence Proceedings", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["abdelkader el mahdaouy", "sa\\\"id el alaoui ouatik", "eric gaussier"], "accepted": false, "id": "1409.3005"}, "pdf": {"name": "1409.3005.pdf", "metadata": {"source": "CRF", "title": "A Study of Association Measures and their Combination for Arabic MWT Extraction", "authors": ["Abdelkader El Mahdaouy", "Eric Gaussier"], "emails": ["a.mahdaouy@hotmail.fr", "ouatik@yahoo.com", "eric.gaussier@imag.fr"], "sections": [{"heading": "1 Introduction", "text": "The aim of the MWT acquisition process is to extract specific domain concepts from specific linguistic corpora (Korkontzelos et al., 2008). Extracting MWTs is critical for terminology acquisition because they are less ambiguous and less polysemous than individual word concepts, and because their internal structure encodes useful semantic relationships (Wen et al., 2008). There are three main approaches to MWT extraction. The first uses linguistic filters. The second relies on statistical measures based on termhood and / or unithood. Termhood refers to \"the degree to which a linguistic entity is associated with a specific domain concept,\" and the unithood. \""}, {"heading": "2 Related Work", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "3 Proposed Method", "text": "Our method for obtaining MWT candidates comprises two main steps: the linguistic filter and the statistical filter."}, {"heading": "3.1 Linguistic Filter", "text": "Several methods for Arabic POS tagging systems have been developed in the literature. We have used the method proposed by (Diab, 2009) because it works with over 96% accuracy and allows a number of variable user settings. The underlying system uses Support Vector Machine (SVM). Figure (1) illustrates the global scheme of our linguistic filter. As a first step, our method marks the corpus using the AMIRA toolkit (Diab POS Tagger), which is trained by Penn Arabic TreeBank (PATB) to tag each word in the corpus. Subsequently, the sequence marker marks selected files in the corpus and uses syntactic patterns that comply with the rules of grammar."}, {"heading": "3.2 Statistical Filter", "text": "In this step, we apply a number of statistical measures to rank the list of candidate MWTs, which is not extracted by the linguistic filter. The main objective of our statistical filter is to take into account both the number of terms and the unit measures. C-value measures the number of words of a candidate based on several characteristics: number of terms, term nesting and term length. It is defined as: C-value (a) = {log2 (a) \u00b7 f (a), if a term is not nested, log2 (a) \u00b7 g (a) \u00b7 value of terms (a) \u2212 g (a)), otherwise (1), where the length is defined in words of the candidate term a, f (a) is the number of occurrences of a and: g (a) = 1 Ta | Ta value b (b)."}, {"heading": "4 Term variation", "text": "As mentioned in the previous section, we have addressed the problem of term variation in the linguistic step. Our method takes into account four types of variations: graphic variants, flexible variants, morphosyntactic variants and syntactic variants. Graphic variants relate to orthographic errors that occurred when writing a certain letter (\",\" \"\u00a9\" and \"), which are very common in Arabic. In addition, some letters undergo a slight written change that does not necessarily change the meaning of the word. For example, the letter\" \u00a9 \"is replaced by another letter,\" at the end of a MWT, \"as for\" Aymyk wlt, \"which leads to\" Y \u00b6 Aymyk wlt, \"which means\" chemical pollution. \"Inflammatory variants are due to the use of different forms for the words\" MWT, \"which constitute a MWT; these different forms are related to gender and the number of adjectives, such as\" in Xwwl \"(pollution of the sea) and\" 1."}, {"heading": "5 Experiments and Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 The Corpus", "text": "In the absence of a standardized domain-specific Arabic corpus, we have established a new corpus to evaluate our approach, specializing in the environmental field and exhibiting characteristics similar to those described (Boulak Needle et al., 2008; Bounhas et al., 2009; Al Khatib et al., 2010).The corpus contains 1666 files containing 53,569 different symbols (without stopwords) extracted from the website \"Al-Khat Alakhdar\" 1. It addresses various environmental issues such as environmental pollution, noise, water purification, soil degradation, forest protection, climate change and natural disasters."}, {"heading": "5.2 Evaluation and Results", "text": "As a matter of fact, most of them will be able to move to the USA to remain where they are: to the USA, to Europe, to the USA, to the USA, to Europe, to Europe, to the USA, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to Europe, to Europe, to the USA, to Europe, to the USA and to the USA, to Europe and to the USA, to Europe and to the USA, to Europe, to Europe and to the USA, to Europe and to the USA, to Europe and to the USA, to Europe and to the USA, to Europe and to the USA, to Europe and to the USA, to Europe and to Europe, to Europe and to Europe, to Europe, to Europe and to Europe, to Europe, to Europe, to Europe, to Europe, to Europe, to Europe, to Europe, to Europe, to Europe, to Europe, to Europe, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to Europe, to the USA, to Europe, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to the USA, to Europe, to Europe, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to Europe, to the USA, to the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA,"}, {"heading": "6 Conclusion", "text": "In this thesis, we have presented a hybrid method for the Arabic MWT capture, which uses existing linguistic and statistical approaches. In a first step, we apply linguistic filters to extract MWT candidates based on syntactic patterns using a sequence identification component. Subsequently, MWT variants are identified by a morphological analysis of the extracted MWT on the basis of light origin. In a statistical step, we have proposed a novel statistical metric, the NLCvalue, which consists of the ranking of the MWT candidates taking into account contextual information and both term- and unithood-statistical metrics. Experimental results show that our method exceeds the previous ones in terms of the quality of the extracted MWTs. Finally, the combination of the best association measures, contextual information and both term- and unithood-statistical metrics is carried out."}], "references": [{"title": "Al-Taani A, and Abu-Al-Rub S", "author": ["Al-Taani"], "venue": null, "citeRegEx": "Al.Taani,? \\Q2009\\E", "shortCiteRegEx": "Al.Taani", "year": 2009}, {"title": "Using statistics in lexical analy", "author": ["D. Hindle"], "venue": null, "citeRegEx": "Hindle,? \\Q1991\\E", "shortCiteRegEx": "Hindle", "year": 1991}, {"title": "The C-Value/NC-Value Method", "author": ["T. Tsujii"], "venue": null, "citeRegEx": "Tsujii,? \\Q1998\\E", "shortCiteRegEx": "Tsujii", "year": 1998}, {"title": "Ti", "author": ["T Vu", "A Aw"], "venue": "and Zhang M.", "citeRegEx": "Vu et al.2008", "shortCiteRegEx": null, "year": 2008}, {"title": "Yoshida T", "author": ["Z Wen"], "venue": "and Xijin T.", "citeRegEx": "Wen et al.2007", "shortCiteRegEx": null, "year": 2007}, {"title": "Yoshida T", "author": ["Z Wen"], "venue": "and Xijin T.", "citeRegEx": "Wen et al.2008", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [], "year": 2014, "abstractText": "Automatic Multi-Word Term (MWT) extraction is a very important issue to many applications, such as information retrieval, question answering, and text categorization. Although many methods have been used for MWT extraction in English and other European languages, few studies have been applied to Arabic. In this paper, we propose a novel, hybrid method which combines linguistic and statistical approaches for Arabic Multi-Word Term extraction. The main contribution of our method is to consider contextual information and both termhood and unithood for association measures at the statistical filtering step. In addition, our technique takes into account the problem of MWT variation in the linguistic filtering step. The performance of the proposed statistical measure (NLC-value) is evaluated using an Arabic environment corpus by comparing it with some existing competitors. Experimental results show that our NLC-value measure outperforms the other ones in term of precision for both bi-grams and tri-grams.", "creator": "LaTeX with hyperref package"}}}