{"id": "1409.3512", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Sep-2014", "title": "Word Sense Disambiguation using WSD specific Wordnet of Polysemy Words", "abstract": "This paper presents a new model of WordNet that is used to disambiguate the correct sense of polysemy word based on the clue words. The related words for each sense of a polysemy word as well as single sense word are referred to as the clue words. The conventional WordNet organizes nouns, verbs, adjectives and adverbs together into sets of synonyms called synsets each expressing a different concept. In contrast to the structure of WordNet, we developed a new model of WordNet that organizes the different senses of polysemy words as well as the single sense words based on the clue words. These clue words for each sense of a polysemy word as well as for single sense word are used to disambiguate the correct meaning of the polysemy word in the given context using knowledge based Word Sense Disambiguation (WSD) algorithms. The clue word can be a noun, verb, adjective or adverb.", "histories": [["v1", "Wed, 10 Sep 2014 19:01:18 GMT  (294kb)", "http://arxiv.org/abs/1409.3512v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["udaya raj dhungana", "subarna shakya", "kabita baral", "bharat sharma"], "accepted": false, "id": "1409.3512"}, "pdf": {"name": "1409.3512.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["POLYSEMY WORDS", "Udaya Raj Dhungana", "Subarna Shakya", "Kabita Baral", "Bharat Sharma"], "emails": ["udayas.epost@gmail.com", "drss@ioe.edu.np", "vharatsharma@yahoo.com", "kabitabaral@yahoo.com"], "sections": [{"heading": null, "text": "This paper introduces a new model of WordNet that is used to disambiguate the correct meaning of polysemitic words based on cluster words. Conventional WordNet organizes nouns, verbs, adjectives and adverbs into synonyms called synsets, each expressing a different concept. In contrast to the structure of WordNet, we developed a new model of WordNet that organizes the different senses of polysemitic words as well as the nouns based on cluster words. These cluster words are used for each sense of a polysemic word as well as for a single-meaning word to disambiguate the correct meaning of the polysemic word in a given context using knowledge-based word sense disambiguation (WSD) algorithms."}, {"heading": "1. INTRODUCTION", "text": "Words that express two or more different meanings when used in different contexts are referred to as polysemy or multi-sense networks. In order to translate the correct meaning of the polysemic word, the machine must first know the context in which the polysemic word was used, and only then can the machine determine the correct meaning of the word in that context and translate the meaning of that word into the correct word in another language. The process of searching for the correct meaning of the polysemic word by means of the machine by analyzing the context in which the polysemic word was used is referred to as Word Sense Disambiguation (WSD). Although various methods have been tested to find the correct meaning of the polysemic word, accuracy at a satisfactory level has not yet been achieved."}, {"heading": "2. RELATED TASKS", "text": "In 1986, Lesk Michael [4] developed an algorithm called the Reading Algorithm to identify meaning polysemy words. He used the overlap of word definition from the Oxford Advanced Learner's Dictionary of Current English (OALD) to clarify the word Senses. Banerjee and Pedersen [5] adapted the original Reading Algorithm to use the lexical database WordNet. They used Senseval-2 Word Sense Disambiguation exercise to evaluate their system and the overall accuracy was found to be 32%. To compare two glosses, they used the longest sequence of one or more consecutive words occurring in both glosses. For each overlap, a square of the number of words in the overlap is calculated and the final score is the sum of all overlaps. Sinha M. et. [6] developed automatic WSD for Hindi language using Hindi WordNet using Hindi Net."}, {"heading": "3. STATEMENT OF RESEARCH PROBLEM", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Problem Statement", "text": "From the analysis of many research papers on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], it has been found that WordNet is a very useful resource to use for the definition of the sense of the word. However, it is not exactly suitable for a knowledge-based, overlapping selection of WSD approaches. The reason for this is that WordNet was built for general purposes in NLP tasks, but is not focused on WSD. WordNet contains an enormous amount of information for words arranged in semantic relation. In all WSD methods, WordNet is used to take a large number of words to disambiguate the meaning of multi-meaning words."}, {"heading": "3.2. Solution Approach", "text": "What we need is that the organization of ambiguous words should be organized in such a way that it should contain only those words that are sufficient to decipher the various meanings of an ambiguous word, and that it should not reintroduce ambiguity, as is the case with the use of WordNet. Although WordNet is a very useful lexical resource that can be used to decipher the various meanings of an ambiguous word, it still has some limitations on its use in WSD algorithms, as discussed in the previous section. Therefore, in order to dramatically improve the accuracy of the knowledge-based selection of WSD algorithms, we need to develop a new logical model that organizes the words in such a way that it correctly and efficiently breaks down the meanings of an ambiguous word, resulting in greater accuracy than can be achieved through the use of WordNetworks. Unlike WordNet, we have organized the various meanings of an ambiguous word as well as a single meaning."}, {"heading": "3.2.1. Algorithm", "text": "The algorithm is very simple: First, we find a collection of clues for each sense of a polysemic word. The number of clues for a polysemic word corresponds to the number of different senses of polysemy. Suppose this cluster of words is T1, T2, T3,..., Tn, where n is the number of different senses that the polysemic word has. Then we find the collection of words (say C) from the context window."}, {"heading": "4. INTENDS", "text": "The main objectives of this research include: 1. Organizing the senses of polysemitic words based on clues; 2. Developing a new model of WordNet based on clues for both polysemitic and meaningless words; and 3. To test whether the traditional or the new model of WordNet is used, the WSD algorithm provides the higher accuracy."}, {"heading": "5. HYPOTHESIS", "text": "Traditional WordNet is a very useful resource for language learning and language processing tasks. However, it is not suitable for knowledge-based WSD algorithms to achieve greater accuracy. We believe that organizing the different senses of polysemitic words and contextual words increases accuracy. In addition, it reduces the computing effort for the system and saves system memory during processing."}, {"heading": "6. RESEARCH METHODOLOGY", "text": "Depending on the nature of our research, we used experimental research strategies. We used the algorithm and test data already developed by [3] to test our new model of WordNet for WSD. Based on the research question, we conducted two experiments with different settings. In the first experiment, we used the system developed by [3] using the conventional Nepalese WordNet example. In the second experiment, we simply replaced the conventional sample of Nepalese WordNet with our new model of WordNet, which was organized with reference points and kept all other settings constant as in the first experiment."}, {"heading": "6.1. Experiment 1", "text": "Lexical Resource: In the first experiment, we used the conventional example Nepali WordNet, developed by [3]. This conventional example Nepali WordNet contains 348 words, including 59 polyseme words. The words in this WordNet are like in the English WordNet. Experimental Setting: In this setting, we included the synthesis, luster, example and hypernym of each word from the collection of context words to form the definitive collection of context words, and compared these words with the collective words of each target word to determine overlapping. On average, the number of examples for each word provided in this case is more than four. Also, we did not include the target word in the collection of context words."}, {"heading": "6.2. Experiment 2", "text": "Lexical Resource: In this second experiment, we used our new model of WordNet, which focuses on ambiguities in the meaning of the word. Experiment Setting: The experiment setting is the same as the one in Experiment 1, except that we have replaced the conventional example of Nepalese WordNet with our new model of WordNet, which is organized with reference words."}, {"heading": "7. RESULT AND DISCUSSIONS", "text": "In Experiment 1, we found that the polysemic words in 184 sets of 201 tests are correctly ambiguous. At this point, the accuracy of the system using conventional examples from Nepal WordNet is found to be 88.059%. In Experiment 2, we found that the polysemic words in 184 sets of 201 tests are correctly ambiguous. At this point, the accuracy of the system is recognized as 91.543%. Accuracy of the system with our new model of WordNet, which is specific to WSD, is increased by 3.484%. Accuracy of the words obtained in the two experiments is demonstrated by the use of synonyms."}, {"heading": "ACKNOWLEDGEMENTS", "text": "We would like to express our sincere gratitude to Madan Puraskar Pustakalaya (MPP), Patan Dhoka, Lalitpur for providing the Nepalese corpus and the Nepalese online dictionary, which were the main resources of this research. We are also grateful to Mr. Balram Prasain, lecturer at Tribhuwan University for his valuable help in this research."}], "references": [{"title": "Word sense disambiguation: The state of the art", "author": ["N. Ide", "J. V\u00e9ronis"], "venue": "Computational Linguistics, pp. 1\u201340, 1998.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1998}, {"title": "Introduction to wordnet: An on-line lexical database", "author": ["G.A. Miller", "R. Beckwith", "C. Fellbaum", "D. Gross", "K.J. Miller"], "venue": "International Journal of Lexicography, 1998.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "Word sense disambiguation in nepali language", "author": ["U.R. Dhungana", "S. Shakya"], "venue": "The Fourth International Conference on Digital Information and Communication Technology and Its Application (DICTAP2014), Bangkok, Thailand, 2014, pp. 46\u201350.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from a ice cream cone", "author": ["M.E. Lesk"], "venue": "SIGDOC Conference, Toronto, Ontario, Canada, 1986.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1986}, {"title": "An adapted lesk algorithm for word sense disambiguation using wordnet", "author": ["S. Banerjee", "T. Pedersen"], "venue": "Third International Conference on Intelligent Text Processing and Computational Linguistics, Gelbukh, 2002.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Hindi word sense disambiguation", "author": ["M. Sinha", "M.K. Reddy", "P. Bhattacharyya", "P. Pandey", "L. Kashyap"], "venue": "Master\u2019s thesis, Indian Institute of Technology Bombay, Mumbai, India, 2004.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Resources for nepali word sense disambiguation", "author": ["N. Shrestha", "A.V.H. Patrick", "S.K. Bista"], "venue": "IEEE International conference on Natural Language Processing and Knowledge Engineering (IEEE NLP-KE\u201908), Beijing, China, 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Hindi wordnet", "author": ["P. Bhattacharyya", "P. Pande", "L. Lupu"], "venue": "Indian Institute of Technology Bombay, Mumbai, India, Tech. Rep., 2008.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Nepali word sense disambiguation using lesk algorithm", "author": ["N. Shrestha", "A.V.H. Patrick", "S.K. Bista"], "venue": "Master\u2019s thesis, Kathmandu University, Dhulikhel, Kavre, Nepal, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "The knowledge-based approaches use the resources such as dictionaries thesauri, ontology, collocation etc to disambiguate a word in a given context [1].", "startOffset": 148, "endOffset": 151}, {"referenceID": 1, "context": "WordNet is a lexical database developed at Princeton University for English language [2].", "startOffset": 85, "endOffset": 88}, {"referenceID": 2, "context": "However, the collection of related words from synset, gloss and different level of hypernym that are taken from the WordNet contains only very few words that can be used to disambiguate the correct sense of a polysemy word in the given context [3].", "startOffset": 244, "endOffset": 247}, {"referenceID": 2, "context": "Moreover, according to [3] as we go increasing the levels of hypernym to collect the related words, the sense of the words becomes more general and the two different senses of a polysemy word are found to have the same hypernym.", "startOffset": 23, "endOffset": 26}, {"referenceID": 3, "context": "In 1986, Lesk Michael [4] developed an algorithm called Lesk algorithm to identify senses of polysemy words.", "startOffset": 22, "endOffset": 25}, {"referenceID": 4, "context": "Banerjee and Pedersen [5] adapted the original Lesk algorithm to use the lexical database WordNet.", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "[6] developed automatic WSD for Hindi language using Hindi WordNet at IIT Bombay.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "In [7], Shrestha N.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "In [3], Dhungana and Shakya used the adapted Lesk algorithm to disambiguate the polysemy word in Nepali language.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "41%, in compared to the accuracy of the system developed by [7].", "startOffset": 60, "endOffset": 63}, {"referenceID": 7, "context": "Therefore, \u092a\u093e\u0924 is a hypernymy and \u092c\u0947\u0932\u092a\u0924\u094d\u0930 is hyponymy [8].", "startOffset": 54, "endOffset": 57}, {"referenceID": 3, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], it was noticed that the WordNet is very useful resource to use for word sense disambiguation.", "startOffset": 64, "endOffset": 67}, {"referenceID": 4, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], it was noticed that the WordNet is very useful resource to use for word sense disambiguation.", "startOffset": 69, "endOffset": 72}, {"referenceID": 5, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], it was noticed that the WordNet is very useful resource to use for word sense disambiguation.", "startOffset": 74, "endOffset": 77}, {"referenceID": 6, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], it was noticed that the WordNet is very useful resource to use for word sense disambiguation.", "startOffset": 79, "endOffset": 82}, {"referenceID": 8, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], it was noticed that the WordNet is very useful resource to use for word sense disambiguation.", "startOffset": 84, "endOffset": 87}, {"referenceID": 2, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], it was noticed that the WordNet is very useful resource to use for word sense disambiguation.", "startOffset": 92, "endOffset": 95}, {"referenceID": 2, "context": "Another important point noticed from [3] is that when deeper levels of the hypernymy from the WordNet are used, the correctly disambiguated polysemy words are also incorrectly disambiguated.", "startOffset": 37, "endOffset": 40}, {"referenceID": 2, "context": "We used the algorithm and test data already developed by [3] to test our new model of WordNet for WSD.", "startOffset": 57, "endOffset": 60}, {"referenceID": 2, "context": "In first experiment, we used the system developed by [3] using the conventional sample Nepali WordNet.", "startOffset": 53, "endOffset": 56}, {"referenceID": 2, "context": "Lexical Resource: In first experiment, we used the conventional sample Nepali WordNet developed by [3].", "startOffset": 99, "endOffset": 102}, {"referenceID": 2, "context": "After setting the two experiments, we executed the experiments using the test data developed by [3].", "startOffset": 96, "endOffset": 99}, {"referenceID": 1, "context": "It groups the nouns, verbs, adjectives and adverbs together into synonym sets, each expressing a distinct concept [2].", "startOffset": 114, "endOffset": 117}, {"referenceID": 3, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], we have noticed that the WordNet is not exactly suitable to use with knowledge-based, overlap selection WSD approaches.", "startOffset": 64, "endOffset": 67}, {"referenceID": 4, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], we have noticed that the WordNet is not exactly suitable to use with knowledge-based, overlap selection WSD approaches.", "startOffset": 69, "endOffset": 72}, {"referenceID": 5, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], we have noticed that the WordNet is not exactly suitable to use with knowledge-based, overlap selection WSD approaches.", "startOffset": 74, "endOffset": 77}, {"referenceID": 6, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], we have noticed that the WordNet is not exactly suitable to use with knowledge-based, overlap selection WSD approaches.", "startOffset": 79, "endOffset": 82}, {"referenceID": 8, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], we have noticed that the WordNet is not exactly suitable to use with knowledge-based, overlap selection WSD approaches.", "startOffset": 84, "endOffset": 87}, {"referenceID": 2, "context": "From analyzing many research works on WSD using WordNet such as [4], [5], [6], [7], [9] and [3], we have noticed that the WordNet is not exactly suitable to use with knowledge-based, overlap selection WSD approaches.", "startOffset": 92, "endOffset": 95}, {"referenceID": 2, "context": "484% in compare with the accuracy of the system in [3].", "startOffset": 51, "endOffset": 54}], "year": 2014, "abstractText": "This paper presents a new model of WordNet that is used to disambiguate the correct sense of polysemy word based on the clue words. The related words for each sense of a polysemy word as well as single sense word are referred to as the clue words. The conventional WordNet organizes nouns, verbs, adjectives and adverbs together into sets of synonyms called synsets each expressing a different concept. In contrast to the structure of WordNet, we developed a new model of WordNet that organizes the different senses of polysemy words as well as the single sense words based on the clue words. These clue words for each sense of a polysemy word as well as for single sense word are used to disambiguate the correct meaning of the polysemy word in the given context using knowledge based Word Sense Disambiguation (WSD) algorithms. The clue word can be a noun, verb, adjective or adverb.", "creator": "Microsoft\u00ae Office Word 2007"}}}