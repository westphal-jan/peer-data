{"id": "1409.3717", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2014", "title": "Probabilistic Selection in AgentSpeak(L)", "abstract": "Agent programming is mostly a symbolic discipline and, as such, draws little benefits from probabilistic areas as machine learning and graphical models. However, the greatest objective of agent research is the achievement of autonomy in dynamical and complex environments --- a goal that implies embracing uncertainty and therefore the entailed representations, algorithms and techniques. This paper proposes an innovative and conflict free two layer approach to agent programming that uses already established methods and tools from both symbolic and probabilistic artificial intelligence. Moreover, this framework is illustrated by means of a widely used agent programming example, GoldMiners.", "histories": [["v1", "Fri, 12 Sep 2014 12:27:44 GMT  (12kb)", "http://arxiv.org/abs/1409.3717v1", "8 pages, 3 figures"]], "COMMENTS": "8 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.MA cs.AI", "authors": ["francisco coelho", "vitor nogueira"], "accepted": false, "id": "1409.3717"}, "pdf": {"name": "1409.3717.pdf", "metadata": {"source": "CRF", "title": "Probabilistic Selection in AGENTSPEAK(L)", "authors": ["Francisco Coelho", "Vitor Nogueira"], "emails": ["fc@di.uevora.pt", "vbn@di.uevora.pt"], "sections": [{"heading": null, "text": "ar Xiv: 140 9,37 17v1 [cs.MA] 1 2Se p20 14"}, {"heading": "1 INTRODUCTION", "text": "Complex and dynamic environments, such as the physical world in which robots must immerse themselves, impose a degree of uncertainty that calls into question the vocation to symbolic processing. However, while certain aspects of such tasks require a probabilistic approach - currently expressed in Machine Learning (ML) and Probabilistic Graphical Models (PGMs) [1] - much of agent programming can be better managed through declarative programming (e.g. PROLOG) and, in particular, beliefs, desires, and intentions (BDI) for autonomous agents that are part of symbolic AI."}, {"heading": "2 STATE OF THE ART", "text": "Although the symbolic and probable areas of AI are in fact to different and often antagonistic cultures and perspectives, they are not necessarily incompatible. Bridges between them are built on the basis of distribution semantics [2] or markov random fields [3] and the extension of logic programming languages with the probability of the probability of programming (PLP) with logical and relative representations (SRL)."}, {"heading": "3 PROBABILISTIC SELECTIONS", "text": "Currently, the problem of extending ASL data structures with probabilistic features is being addressed by different authors [18, 19, 20, 21, 22], but has not yet been fully solved. An alternative and less intrusive application of probabilistic AI to ASL targets processes rather than data. Restrictive probabilistic techniques for calculating ASL selection functions (events, options, and intentions 1, as in Figure 1) promise a1. Newer versions of JASON include an inbox, an outbox, and a selection messaging function. Number of advantages: \u2022 Selection functions usually have natural formulations of optimization problems, which are handled well in many cases by probabilistic algorithms; \u2022 Since their calculations are not specified (in ASL or JASON), probabilistic techniques can be used without compromising prior work; \u2022 symbolic and probabilistic AI roles are clearly separated from each other, but carry both simultaneously to symbolic behavior in ASL, using both of the over- agents."}, {"heading": "3.1 PROBLEM STATEMENT", "text": "In this context, it should be noted that the solution to the problems is not a purely formal solution, but a solution that seeks to find a solution that meets the needs of the individual."}, {"heading": "3.2 RESOLUTION PATH", "text": "In view of the GOLDMINERS scenario, the miners \"selection function is described using an influence chart shown in Figure 3. Deposited gold coins define a supply node and the range of action is extracted from active intentions.The miners\" coordination protocol is presented from the discovery of a new piece of gold to the termination of the deposit of that gold.The resulting benefit function can then be used by the MEU principle to select the optimal one from the available measures (the heads of the instantiated plans in the intention stacks).Nodes in the influence chart represent conditional probability distributions (CPDs) to be coordinated within the framework of the resolution proposed here. Once the influence diagram is defined, existing Java PGM libraries supporting influence diagrams (e.g. SAMIAM) generate a (static) selection function that can be inserted into the agent's JASON."}, {"heading": "4 CONCLUSION", "text": "Looking ahead, there are two things to consider: \u2022 \"real-time\" and \"offline\" symbolic / probable levels interact; \u2022 usefulness / trade-offs; \u2022 multi-agent applications; In the weighing process, communication between symbolic and probable levels is critical. For example, a process in which diagrams are influenced at the probability level (e.g. BN) can be structured from the set of symbolic plans and beliefs, while other forms of mutual \"offline\" influence are considered."}, {"heading": "ACKNOWLEDGEMENTS", "text": "The people around us, the flow of experiences, the internet."}], "references": [{"title": "Probabilistic graphical models: principles and techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "A statistical learning method for logic programs with distribution semantics", "author": ["T. Sato"], "venue": "Proceedings of the 12th International Conference on Logic Programming (ICLP\u201995), Citeseer, 1995.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1995}, {"title": "Unifying logical and statistical AI", "author": ["P. Domingos", "S. Kok", "H. Poon", "M. Richardson", "P. Singla"], "venue": "AAAI, vol. 6, pp. 2\u20137, 2006.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "A general MCMC method for bayesian inference in logic-based probabilistic modeling", "author": ["T. Sato"], "venue": "Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Two, pp. 1472\u20131477, AAAI Press, 2011. 6", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Inside-outside probability computation for belief propagation", "author": ["T. Sato"], "venue": "IJ- CAI, pp. 2605\u20132610, 2007.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Inference and learning in probabilistic logic programs using weighted boolean formulas", "author": ["D. Fierens", "G.V. den Broeck", "J. Renkens", "D. Shterionov", "B. Gutmann", "I. Thon", "G. Janssens", "L.D. Raedt"], "venue": "arXiv, p. 1304.6810, 04 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Inference in probabilistic logic programs using weighted CNF\u2019s", "author": ["D. Fierens", "G.V. d. Broeck", "I. Thon", "B. Gutmann", "L. De Raedt"], "venue": "arXiv, p. 1202.3719, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning the parameters of probabilistic logic programs from interpretations", "author": ["B. Gutmann", "I. Thon", "L. De Raedt"], "venue": "Machine Learning and Knowledge Discovery in Databases, pp. 581\u2013596, Springer, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Programming multi-agent systems in AgentSpeak using Jason", "author": ["R.H. Bordini", "J.F. H\u00fcbner", "M. Wooldridge"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "AgentSpeak (L): BDI agents speak out in a logical computable language", "author": ["A.S. Rao"], "venue": "Agents Breaking Away, pp. 42\u201355, Springer, 1996.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "Semantics for the Jason variant of AgentSpeak (plan failure and some internal actions)", "author": ["R.H. Bordini", "J.F. H\u00fcbner"], "venue": "ECAI, pp. 635\u2013640, 2010.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "BDI agent programming in AgentSpeak using Jason", "author": ["R.H. Bordini", "J.F. H\u00fcbner"], "venue": "Computational logic in multi-agent systems, pp. 143\u2013164, Springer, 2006.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "AgentSpeak (XL): Efficient intention selection in BDI agents via decision-theoretic task scheduling", "author": ["R.H. Bordini", "A.L. Bazzan", "R. de O Jannone", "D.M. Basso", "R.M. Vicari", "V.R. Lesser"], "venue": "Proceedings of the first international joint conference on Autonomous agents and multiagent systems: part 3, pp. 1294\u2013 1302, ACM, 2002.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "Using Jason to implement a team of gold miners", "author": ["R.H. Bordini", "J.F. H\u00fcbner", "D.M. Tralamazza"], "venue": "Computational Logic in Multi-Agent Systems, pp. 304\u2013 313, Springer, 2007.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Developing a team of gold miners using jason", "author": ["J.F. H\u00fcbner", "R.H. Bordini"], "venue": "Programming Multi-Agent Systems, pp. 241\u2013245, Springer, 2008.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "The second contest on multi-agent systems based on computational logic", "author": ["M. Dastani", "J. Dix", "P. Nov\u00e1k"], "venue": "Computational Logic in Multi-Agent Systems, pp. 266\u2013283, Springer, 2007.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Special issue about multi-agentcontest II", "author": ["T. Behrens", "J. Dix", "M. K\u00f6ster", "J. H\u00fcbner"], "venue": "Annals of Mathematics and Artificial Intelligence, vol. 61, 2011.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Alternatives to threshold-based desire selection in bayesian BDI agents", "author": ["B. Luz", "F. Meneguzzi", "R. Vicari"], "venue": "1st International Workshop on Engineering Multi-Agent Systems, pp. 208\u2013223, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Deliberation process in a BDI model with bayesian networks", "author": ["M.S. Fagundes", "R.M. Vicari", "H. Coelho"], "venue": "Agent Computing and Multi-Agent Systems, pp. 207\u2013218, Springer, 2009. 7", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Integrating BDI model and Bayesian Networks", "author": ["M.S. Fagundes"], "venue": "Master\u2019s thesis, Universidade Federal do Rio Grande do Sul, 2007.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Insertion of probabilistic knowledge into BDI agents construction modeled in bayesian networks", "author": ["G.L. Kieling", "R.M. Vicari"], "venue": "Complex, Intelligent and Software Intensive Systems (CISIS), 2011 International Conference on, pp. 115\u2013 122, IEEE, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "AgentSpeak(PL): A new programming language for BDI agents with integrated bayesian network model", "author": ["D.G. Silva", "J.C. Gluz"], "venue": "Information Science and Applications (ICISA), 2011 International Conference on, pp. 1\u20137, IEEE, 2011.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "WEKA \u2014 experiences with a java open-source project", "author": ["R.R. Bouckaert", "E. Frank", "M.A. Hall", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "The Journal of Machine Learning Research, pp. 2533\u20132541, 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Data Mining: Practical machine learning tools and techniques", "author": ["I.H. Witten", "E. Frank"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2005}, {"title": "Weka: Practical machine learning tools and techniques with java implementations", "author": ["R. Dimov", "M. Feld", "D.M. Kipp", "D.A. Ndiaye", "D.D. Heckmann"], "venue": "AI Tools SeminarUniversity of Saarland, WS, vol. 6, no. 07, 2007.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "The WEKA data mining software: an update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "ACM SIGKDD Explorations Newsletter, vol. 11, no. 1, pp. 10\u201318, 2009.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Artificial intelligence: A modern approach, 2/E", "author": ["S. Russell"], "venue": "Pearson Education India,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2003}, {"title": "Parsing natural scenes and natural language with recursive neural networks", "author": ["R. Socher", "C.C. Lin", "A. Ng", "C. Manning"], "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML-11), pp. 129\u2013136, 2011.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning multiple layers of representation", "author": ["G.E. Hinton"], "venue": "Trends in cognitive sciences, vol. 11, no. 10, pp. 428\u2013434, 2007.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "An efficient learning procedure for deep boltzmann machines", "author": ["R. Salakhutdinov", "G. Hinton"], "venue": "Neural Computation, vol. 24, no. 8, pp. 1967\u20132006, 2012.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1967}, {"title": "Principal component analysis", "author": ["I. Jolliffe"], "venue": "Wiley Online Library,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "But while a probabilistic approach \u2014 currently expressed in Machine Learning (ML) and Probabilistic Graphical Models (PGMs) [1]\u2014 is required for certain aspects of such tasks, a great deal of agent programming is better handled by declarative programming (e.", "startOffset": 124, "endOffset": 127}, {"referenceID": 1, "context": "Bridges between them are being built based on distribution semantics [2] or markov random fields [3].", "startOffset": 69, "endOffset": 72}, {"referenceID": 2, "context": "Bridges between them are being built based on distribution semantics [2] or markov random fields [3].", "startOffset": 97, "endOffset": 100}, {"referenceID": 3, "context": "From that common ground there are two possible paths towards the interplay of symbolic and probabilistic AI: the extension of PGMs with logical and relational representations (done by Statistical Relational Learning (SRL)) [4, 5] and the extension of logic programming languages with probability, in Probabilistic Logic Programming (PLP) [6, 7, 8].", "startOffset": 223, "endOffset": 229}, {"referenceID": 4, "context": "From that common ground there are two possible paths towards the interplay of symbolic and probabilistic AI: the extension of PGMs with logical and relational representations (done by Statistical Relational Learning (SRL)) [4, 5] and the extension of logic programming languages with probability, in Probabilistic Logic Programming (PLP) [6, 7, 8].", "startOffset": 223, "endOffset": 229}, {"referenceID": 5, "context": "From that common ground there are two possible paths towards the interplay of symbolic and probabilistic AI: the extension of PGMs with logical and relational representations (done by Statistical Relational Learning (SRL)) [4, 5] and the extension of logic programming languages with probability, in Probabilistic Logic Programming (PLP) [6, 7, 8].", "startOffset": 338, "endOffset": 347}, {"referenceID": 6, "context": "From that common ground there are two possible paths towards the interplay of symbolic and probabilistic AI: the extension of PGMs with logical and relational representations (done by Statistical Relational Learning (SRL)) [4, 5] and the extension of logic programming languages with probability, in Probabilistic Logic Programming (PLP) [6, 7, 8].", "startOffset": 338, "endOffset": 347}, {"referenceID": 7, "context": "From that common ground there are two possible paths towards the interplay of symbolic and probabilistic AI: the extension of PGMs with logical and relational representations (done by Statistical Relational Learning (SRL)) [4, 5] and the extension of logic programming languages with probability, in Probabilistic Logic Programming (PLP) [6, 7, 8].", "startOffset": 338, "endOffset": 347}, {"referenceID": 8, "context": "Concerning agents programming JASON [9] is a popular AGENTSPEAK(L) (ASL) [10] interpreter and framework, triggering a considerable amount of research (e.", "startOffset": 36, "endOffset": 39}, {"referenceID": 9, "context": "Concerning agents programming JASON [9] is a popular AGENTSPEAK(L) (ASL) [10] interpreter and framework, triggering a considerable amount of research (e.", "startOffset": 73, "endOffset": 77}, {"referenceID": 10, "context": "[11, 12]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 11, "context": "[11, 12]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 12, "context": "Despite some work concerning intention selection [13] the default selection function implementation in JASON is a simple process based in roundrobin scheduling: intentions form a stack and at each time-step the head action of the top intention is selected; that intention is then sent to the bottom of the stack.", "startOffset": 49, "endOffset": 53}, {"referenceID": 13, "context": "This somewhat simplistic approach to selection is good enough for many tasks, including winning planning competitions [14, 15].", "startOffset": 118, "endOffset": 126}, {"referenceID": 14, "context": "This somewhat simplistic approach to selection is good enough for many tasks, including winning planning competitions [14, 15].", "startOffset": 118, "endOffset": 126}, {"referenceID": 16, "context": "This assertion is hinted by a simple experiment plotted in figure 2: the GOLDMINERS is a virtual scenario used in the 2006 Multi-Agent Programming Contest [17] edition, now part of JASON\u2019s examples.", "startOffset": 155, "endOffset": 159}, {"referenceID": 17, "context": "Currently the problem of extending ASL data structures with probabilistic features is being addressed by different authors [18, 19, 20, 21, 22] but isn\u2019t yet fully solved.", "startOffset": 123, "endOffset": 143}, {"referenceID": 18, "context": "Currently the problem of extending ASL data structures with probabilistic features is being addressed by different authors [18, 19, 20, 21, 22] but isn\u2019t yet fully solved.", "startOffset": 123, "endOffset": 143}, {"referenceID": 19, "context": "Currently the problem of extending ASL data structures with probabilistic features is being addressed by different authors [18, 19, 20, 21, 22] but isn\u2019t yet fully solved.", "startOffset": 123, "endOffset": 143}, {"referenceID": 20, "context": "Currently the problem of extending ASL data structures with probabilistic features is being addressed by different authors [18, 19, 20, 21, 22] but isn\u2019t yet fully solved.", "startOffset": 123, "endOffset": 143}, {"referenceID": 21, "context": "Currently the problem of extending ASL data structures with probabilistic features is being addressed by different authors [18, 19, 20, 21, 22] but isn\u2019t yet fully solved.", "startOffset": 123, "endOffset": 143}, {"referenceID": 14, "context": "Two teams are plotted, the basic reference \u201cdummy\u201d that barely uses BDI features and the \u201csmart\u201d team, fully BDI, (designed by [15]) that won the 2006 \u201cMulti-agent Programming Contest\u201d [16] featuring the GOLDMINERS scenario.", "startOffset": 127, "endOffset": 131}, {"referenceID": 15, "context": "Two teams are plotted, the basic reference \u201cdummy\u201d that barely uses BDI features and the \u201csmart\u201d team, fully BDI, (designed by [15]) that won the 2006 \u201cMulti-agent Programming Contest\u201d [16] featuring the GOLDMINERS scenario.", "startOffset": 185, "endOffset": 189}, {"referenceID": 22, "context": "WEKA [23, 24, 25, 26] or SAMIAM2) to process low level noisy signals \u2014 with BNs, influence diagrams, monte-carlo markov chains, expectation-maximization, etc;", "startOffset": 5, "endOffset": 21}, {"referenceID": 23, "context": "WEKA [23, 24, 25, 26] or SAMIAM2) to process low level noisy signals \u2014 with BNs, influence diagrams, monte-carlo markov chains, expectation-maximization, etc;", "startOffset": 5, "endOffset": 21}, {"referenceID": 24, "context": "WEKA [23, 24, 25, 26] or SAMIAM2) to process low level noisy signals \u2014 with BNs, influence diagrams, monte-carlo markov chains, expectation-maximization, etc;", "startOffset": 5, "endOffset": 21}, {"referenceID": 25, "context": "WEKA [23, 24, 25, 26] or SAMIAM2) to process low level noisy signals \u2014 with BNs, influence diagrams, monte-carlo markov chains, expectation-maximization, etc;", "startOffset": 5, "endOffset": 21}, {"referenceID": 26, "context": "The original environment of the GOLDMINERS competition is partially observable, stochastic, sequential, dynamic and discrete (see [27] about this classification).", "startOffset": 130, "endOffset": 134}, {"referenceID": 15, "context": "Agents had only a local view on their environment, their perceptions could be incomplete, and their actions could fail [in [16]].", "startOffset": 123, "endOffset": 127}, {"referenceID": 14, "context": "The leader chooses the best offer and allocate the corresponding agent to collect that piece of gold [in [15, 12]].", "startOffset": 105, "endOffset": 113}, {"referenceID": 11, "context": "The leader chooses the best offer and allocate the corresponding agent to collect that piece of gold [in [15, 12]].", "startOffset": 105, "endOffset": 113}, {"referenceID": 27, "context": "symbolic level, either introducing relevant concepts from unsupervised feature learning [28] using Deep Neural Networks (DNN) [29, 30] or summarizing ML techniques like Principal Component Analysis (PCA) [31].", "startOffset": 88, "endOffset": 92}, {"referenceID": 28, "context": "symbolic level, either introducing relevant concepts from unsupervised feature learning [28] using Deep Neural Networks (DNN) [29, 30] or summarizing ML techniques like Principal Component Analysis (PCA) [31].", "startOffset": 126, "endOffset": 134}, {"referenceID": 29, "context": "symbolic level, either introducing relevant concepts from unsupervised feature learning [28] using Deep Neural Networks (DNN) [29, 30] or summarizing ML techniques like Principal Component Analysis (PCA) [31].", "startOffset": 126, "endOffset": 134}, {"referenceID": 30, "context": "symbolic level, either introducing relevant concepts from unsupervised feature learning [28] using Deep Neural Networks (DNN) [29, 30] or summarizing ML techniques like Principal Component Analysis (PCA) [31].", "startOffset": 204, "endOffset": 208}], "year": 2017, "abstractText": "Agent programming is mostly a symbolic discipline and, as such, draws little benefits from probabilistic areas as machine learning and graphical models. However, the greatest objective of agent research is the achievement of autonomy in dynamical and complex environments \u2014 a goal that implies embracing uncertainty and therefore the entailed representations, algorithms and techniques. This paper proposes an innovative and conflict free two layer approach to agent programming that uses already established methods and tools from both symbolic and probabilistic artificial intelligence. Moreover, this framework is illustrated by means of a widely used agent programming example, GOLDMINERS.", "creator": "LaTeX with hyperref package"}}}