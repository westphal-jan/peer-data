{"id": "1409.3879", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2014", "title": "Unsupervised learning of clutter-resistant visual representations from natural videos", "abstract": "Populations of neurons in inferotemporal cortex (IT) maintain an explicit code for object identity that also tolerates transformations of object appearance e.g., position, scale, viewing angle [1, 2, 3]. Though the learning rules are not known, recent results [4, 5, 6] suggest the operation of an unsupervised temporal-association-based method e.g., Foldiak's trace rule [7]. Such methods exploit the temporal continuity of the visual world by assuming that visual experience over short timescales will tend to have invariant identity content. Thus, by associating representations of frames from nearby times, a representation that tolerates whatever transformations occurred in the video may be achieved. Many previous studies verified that such rules can work in simple situations without background clutter, but the presence of visual clutter has remained problematic for this approach. Here we show that temporal association based on large class-specific filters (templates) avoids the problem of clutter. Our system learns in an unsupervised way from natural videos gathered from the internet, and is able to perform a difficult unconstrained face recognition task on natural images (Labeled Faces in the Wild [8]).", "histories": [["v1", "Fri, 12 Sep 2014 22:35:08 GMT  (3277kb,D)", "https://arxiv.org/abs/1409.3879v1", null], ["v2", "Fri, 24 Apr 2015 00:33:14 GMT  (3306kb,D)", "http://arxiv.org/abs/1409.3879v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["qianli liao", "joel z leibo", "tomaso poggio"], "accepted": false, "id": "1409.3879"}, "pdf": {"name": "1409.3879.pdf", "metadata": {"source": "CRF", "title": "Unsupervised learning of clutter-resistant visual representations from natural videos", "authors": ["Qianli Liao", "Joel Z Leibo", "Tomaso Poggio"], "emails": [], "sections": [{"heading": null, "text": "This work was supported by the Center for Brains, Minds and Machines (CBMM), funded by the NSF STC award CCF - 1231216.ar Xiv: 140 9.38 79v2 ["}, {"heading": "1 Introduction", "text": "In nature videos and naturalistic vision, the essential characteristics of images tend to be those that remain stable for a certain period of time. Much of what is marginal in images tends to fluctuate more rapidly. Previous efforts to use this principle of temporal continuity as a prior assumption that enabled unattended learning of useful visual representations have demonstrated a system that, to the best of our knowledge, is the first to use temporal continuity to learn from cluttered nature videos to become a visual representation that can compete with challenging computer vision benchmarks.In contrast to the current \"big data\" trend, which uses systems trained with millions of labeled examples to make significant advances in object recognition [14, 15] our proposal aims to develop one of the strategies used by the human visual cortex to see from far less hierarchically ordered data.For this purpose, we are biologically dependent on a situation that proves to be biologically usable in nature video and naturalistic vision."}, {"heading": "2 Theoretical motivation", "text": "Thus, as proposed by [12], the appropriate learning rule to take advantage of the principle of temporal continuity is greatly simplified in this case: each HW module is associated with a template book Tk. It is an abstraction of connectivity that Hubel and Wiesel construct as the basis for complex cell reception fields from simple cell inputs in primary visual cortex [17]. Each HW module consists of a single complex cell and all its monkeys simple cells1. Each of the tk cells designated as a template is a vector representing an image or patch of the cell."}, {"heading": "3 Clutter resistance", "text": "One might think that this approach to learning invariance is hopelessly hampered by clutter. Figure 1 illustrates the problem. It shows the results of a face pair matching experiment with synthetic facial images from the partial tasks of the Unrestricted Face Recognition (SUFR) benchmark [19]: For two images of unknown individuals, the task is to decide whether or not they represent the same person. However, this is the same task used by [8], although the training methodology differs. The data set contained 400 faces with 10,000 images representing different orientations (in depth) and different positions in the visual field for each. The reported results were averaged over 10 cross-validation folds. Each fold contained 360 training and 40 test factors. The training set consisted of 360 videos (transformation sequences) - one for each training person."}, {"heading": "4 Architectures and simulation methods", "text": "In order to alleviate the confusion problem, we propose a hierarchical model, which is shown in Figure 2. The architecture consists of a feed hierarchy of HW modules. The final output is the signature \u00b5 (I), a vector of responses from HW modules at the highest level. Figure 2: Illustrations of the two models used in this paper. The left model is the face model. It uses tightly cropped faces as the second layer. The model on the right is the model for detecting dogs and cats. It uses tightly cropped cat and dog patches as the second layer. The low features of the face model are single-layered, but that of the latter model is two-layered - a hierarchical HMAX-like architecture. Empirically, one layer works better for faces as faces are more subtle and require higher resolution."}, {"heading": "4.1 Intuition", "text": "The architecture we propose is based on a finding of [20]. This work concerned the replacement of the traditional pipeline of face recognition and alignment with a single end-to-end hierarchy that could identify faces in crowded natural images such as the original, uncalculated, labeled faces in the wild data (as opposed to the more commonly used LFWa [21] dataset). [20] It has been observed that since most of the characteristics of faces are internal (and faces are convex), simple cell responses are rarely disturbed by the presence of clutter next to the face. Rather, almost all errors associated with clutter could be attributed to \"false positives,\" i.e. to eerically high simple cell responses in the background. To see why one considers a small template of just a few pixels, say 2 \u00d7 2. Such a small template will be activated by many non-faces, and more importantly, the problem becomes less severe as its size increases."}, {"heading": "4.2 Biological motivation", "text": "We have not managed to achieve what we set out to achieve, \"he told the German Press Agency in an interview with\" Welt am Sonntag. \""}, {"heading": "4.3 Summary of architecture details", "text": "For the training, (1) the features of layer 1 of all the above video images and large image fields are calculated, the latter becoming layer 2 templates. (2) Calculate layer 2 features of all video images. Use these features for the layer 3 templates. Sample fields are shown in the second layers of Figure 2. They were generated by scanning large image fields on a Face / Cats & Dogs dataset. Their low feature representations were used as second layer templates. Details on both architectures are included in the supplementary information."}, {"heading": "4.4 Training videos and data", "text": "In our experiments, the face model learns from 375 videos of faces from YouTube. The lion and tiger model learns from 224 videos of dogs and cats from YouTube. These videos may contain other things than faces, cats and dogs. See Figure 4. Simple cells: Each frame corresponds to a single cell (in the third layer of our model). To this end, videos are scanned at slow rates: 0.5, 1 or 2, 4 etc. Frames / second. So there are 0.5, 1 or 2, 4 etc. Simple cells on average. How are the complex cells placed over time? Each complex cell has a pool domain that overlaps or does not overlap with other complex cells. Placement of complex cells over time is a parameter that depends on the experiments."}, {"heading": "4.5 Evaluation Process", "text": "To test our HW architecture, we run them on both images and compare them by the angle between their signatures (top-level representations), that is, we take the normalized point product < \u00b5 (xa), \u00b5 (xb) >, if it crosses a threshold, our method shows that xa and xb have the same identity, otherwise they are different from each other. We use the training set to select the optimal classification. Lion and tiger class In an x image, the task is to determine whether it represents a lion or a tiger. In this case, we trained an SVM on the final output of our feature extraction pipeline."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Subordinate level identification of faces", "text": "The model was trained with 375 nature videos collected by YouTube and tested on the unaligned Labeled Faces in the Wild dataset. [20] This problem, too, was treated with a similar approach to ours. However, their system was much more complicated by using location-specific hashing and much less biological. Moreover, it was not trained with the uncontrolled method we focus on here. Examples of training and test images are shown in Figure 4. Figure 3 shows the model's performance for different decisions in the temporal association window. It shows that longer time association windows perform better. This result confirms the main hypothesis that this paper is about: a hierarchy with a layer of high-resolution class-specific templates can be used to mitigate the tangle warning problem sufficiently to allow learning class-specific deviations in a subsequent shift.We also tested the facial recognition model on a more difficult dataset - Littered tolerance to JW-20."}, {"heading": "5.2 Basic level categorization: lions and tigers", "text": "The goal of temporal association learning is to generate an invariant representation for the image transformations that occur naturally when objects move relative to their viewer. So far, we have focused on a subordinate task: face recognition. Such tasks, in which very similar objects must be distinguished from each other, are considered more critically dependent on invariance by YouTube. Specifically, it is assumed that they require more complicated class-specific invariances that could be learned in a different way than through natural videos, such as rotation in depth or the transformation of a frown into a smile. In contrast, the basic categorization at the discriminatory level may be based on discriminatory features that appear similar from every point of view, rather than on sophisticated invariance of class-specific transformations. It follows that temporal association should be a more effective strategy in the subordinate case. To further explore this direction, we applied our model to a basic level of categorization task of lions (5) and data collection."}, {"heading": "6 Discussion", "text": "This approach to neuroscience research is based on the idea that neurobiological models of parts of the brain that are thought to perform computational functions (such as object recognition) should actually be able to perform these functions. Furthermore, the same training data should be used that is available to the developing infant visual system. In the case of invariant object / face recognition, the exact amount of \"label-like\" information available is debatable, but it is certainly less than the amount of marked data used to train modern systems such as [14]. We consider the most important contribution of this work to be that it is possible - at least for faces - to learn with minimal supervision, a representation robust enough to function in the real world."}, {"heading": "A Architecture details", "text": "An example of the dimensions in which we move is the height, x denotes the width, z denotes the thickness / characteristic size, and i denotes the number of layers. Our model is architecturally similar to that of HMAX and Convolutional Networks. All of these architectures can be described with this notation by applying a function: L () to the input image (\"L\" means low-level features). The function L () transforms the input image (\"Y0,\" \"\" X, \"\" \"\" X, \"\" \"\" \"X,\" \"\" \"\" \"\", \"\" \"\" \"\" \",\" \"\" \"\" \"\" \",\" \"\" \"\" \",\" \"\" \"\", \"\" \"\", \"\" \",\" \"\", \"\" \",\" \"\", \"\" \"\", \"\", \"\" \",\" \",\" \"\" \"\", \"\" \",\" \",\" \"\" \",\" \"\", \"\" \",\" \"\" \"\" \",\" \"\", \"\" \"\", \"\" \",\" \"\" \"\" \",\" \"\" \"\" \"\", \"\" \"\" \",\" \"\" \"\", \"\" \"\", \"\" \"\" \",\" \"\" \"\" \",\" \"\" \"\", \"\" \"\" \"\", \"\" \"\", \"\" \"\", \"\" \"\" \"\" \",\" \"\" \",\" \"\" \"\" \"\", \"\" \"\" \",\" \"\" \"\" \",\" \"\" \"\", \"\" \",\" \"\" \"\" \"\" \",\" \"\" \"\", \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \",\" \"\" \"\", \"\" \"\" \"\" \"\" \",\" \"\" \"\" \",\" \"\" \",\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \""}, {"heading": "B Face selectivity of the second layer", "text": "We tested the selectivity of our model compared to non-facial frames using a simple mechanism - the bundling of layer-2 reactions (Figure 6)."}], "references": [{"title": "Fast Readout of Object Identity from Macaque Inferior Temporal Cortex", "author": ["C.P. Hung", "G. Kreiman", "T. Poggio", "J.J. DiCarlo"], "venue": "Science, vol. 310, pp. 863\u2013866, Nov. 2005.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "A neural code for three-dimensional object shape in macaque inferotemporal cortex", "author": ["Y. Yamane", "E.T. Carlson", "K.C. Bowman", "Z. Wang", "C.E. Connor"], "venue": "Nature neuroscience, vol. 11, no. 11, pp. 1352\u20131360, 2008.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Functional Compartmentalization and Viewpoint Generalization Within the Macaque Face-Processing System", "author": ["W.A. Freiwald", "D. Tsao"], "venue": "Science, vol. 330, no. 6005, p. 845, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Unsupervised natural experience rapidly alters invariant object representation in visual cortex", "author": ["N. Li", "J.J. DiCarlo"], "venue": "Science, vol. 321, pp. 1502\u20137, Sept. 2008.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Unsupervised Natural Visual Experience Rapidly Reshapes Size-Invariant Object Representation in Inferior Temporal Cortex", "author": ["N. Li", "J.J. DiCarlo"], "venue": "Neuron, vol. 67, no. 6, pp. 1062\u20131075, 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Neuronal learning of invariant object representation in the ventral visual stream is not dependent on reward", "author": ["N. Li", "J.J. DiCarlo"], "venue": "The Journal of Neuroscience, vol. 32, no. 19, pp. 6611\u20136620, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning invariance from transformation sequences", "author": ["P. F\u00f6ldi\u00e1k"], "venue": "Neural Computation, vol. 3, no. 2, pp. 194\u2013200, 1991.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1991}, {"title": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "author": ["G.B. Huang", "M. Mattar", "T. Berg", "E. Learned-Miller"], "venue": "Workshop on faces in real-life images: Detection, alignment and recognition (ECCV), (Marseille, Fr), 2008.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Slow feature analysis: Unsupervised learning of invariances", "author": ["L. Wiskott", "T. Sejnowski"], "venue": "Neural computation, vol. 14, no. 4, pp. 715\u2013770, 2002.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning viewpoint invariant perceptual representations from cluttered images", "author": ["M. Spratling"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 27, no. 5, pp. 753\u2013761, 2005.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2005}, {"title": "Invariant object recognition and pose estimation with slow feature analysis", "author": ["M. Franzius", "N. Wilbert", "L. Wiskott"], "venue": "Neural Computation, vol. 23, no. 9, pp. 2289\u20132323, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning and disrupting invariance in visual recognition with a temporal association rule", "author": ["L. Isik", "J.Z. Leibo", "T. Poggio"], "venue": "Front. Comput. Neurosci., vol. 6, no. 37, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Invariant visual object and face recognition: neural and computational bases, and a model, VisNet", "author": ["E. Rolls"], "venue": "Frontiers in Computational Neuroscience, vol. 6, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "Advances in neural information processing systems, vol. 25, (Lake Tahoe, CA), pp. 1106\u20131114, 2012.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "arXiv preprint arXiv:1312.6229, 2013.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised Learning of Invariant Representations in Hierarchical Architectures", "author": ["F. Anselmi", "J.Z. Leibo", "J. Mutch", "L. Rosasco", "A. Tacchetti", "T. Poggio"], "venue": "arXiv:1311.4158v3 [cs.CV], 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Receptive fields, binocular interaction and functional architecture in the cat\u2019s visual cortex", "author": ["D. Hubel", "T. Wiesel"], "venue": "The Journal of Physiology, vol. 160, no. 1, p. 106, 1962.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1962}, {"title": "Learning invariant representations and applications to face verification", "author": ["Q. Liao", "J.Z. Leibo", "T. Poggio"], "venue": "Advances in Neural Information Processing Systems (NIPS), (Lake Tahoe, CA), 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Subtasks of Unconstrained Face Recognition", "author": ["J.Z. Leibo", "Q. Liao", "T. Poggio"], "venue": "International Joint Conference on Computer Vision, Imaging and Computer Graphics, VISAPP, (Lisbon, Portugal), SCITEPRESS, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Can a biologically-plausible hierarchy effectively replace face detection, alignment, and recognition pipelines", "author": ["Q. Liao", "J.Z. Leibo", "Y. Mroueh", "T. Poggio"], "venue": "arXiv preprint arXiv:1311.4082, 2014.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Multiple One-Shots for Utilizing Class Label Information", "author": ["Y. Taigman", "L. Wolf", "T. Hassner"], "venue": "British Machine Vision Conference, pp. 1\u201312, 2009.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Hierarchical models of object recognition in cortex", "author": ["M. Riesenhuber", "T. Poggio"], "venue": "Nature Neuroscience, vol. 2, pp. 1019\u20131025, Nov. 1999.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1999}, {"title": "Robust Object Recognition with Cortex-Like Mechanisms", "author": ["T. Serre", "L. Wolf", "S. Bileschi", "M. Riesenhuber", "T. Poggio"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 29, no. 3, pp. 411\u2013426, 2007.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Simplified neuron model as a principal component analyzer", "author": ["E. Oja"], "venue": "Journal of mathematical biology, vol. 15, no. 3, pp. 267\u2013273, 1982.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1982}, {"title": "Magic materials: a theory of deep hierarchical architectures for learning sensory representations.", "author": ["F. Anselmi", "J.Z. Leibo", "L. Rosasco", "J. Mutch", "A. Tacchetti", "T. Poggio"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "The Invariance Hypothesis and the Ventral Stream", "author": ["J.Z. Leibo"], "venue": "PhD thesis, Massachusetts Institute of Technology,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Local higher-order statistics (lhs) for texture categorization and facial analysis", "author": ["G. Sharma", "S. ul Hussain", "F. Jurie"], "venue": "European Conference on Computer Vision (ECCV), 2012.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Lfw results using a combined nowak plus merl recognizer", "author": ["G.B. Huang", "M.J. Jones", "E. Learned-Miller"], "venue": "Workshop on Faces in\u2019Real-Life\u2019Images: Detection, Alignment, and Recognition, 2008.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient processing of mrfs for unconstrained-pose face recognition", "author": ["S.R. Arashloo", "J. Kittler"], "venue": "Biometrics: Theory, Applications and Systems, 2013.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning visual similarity measures for comparing never seen objects", "author": ["E. Nowak", "F. Jurie"], "venue": "Computer Vision and Pattern Recognition, 2007. CVPR\u201907. IEEE Conference on, pp. 1\u20138, IEEE, 2007.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "Face recognition using local quantized patterns", "author": ["S. Hussain", "T. Napol\u00e9on", "F. Jurie"], "venue": "Proc. British Machine Vision Conference (BMCV), vol. 1, (Guildford, UK), pp. 52\u201361, 2012.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-region probabilistic histograms for robust and scalable identity inference", "author": ["C. Sanderson", "B.C. Lovell"], "venue": "Advances in Biometrics, pp. 199\u2013208, Springer, 2009.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "Towards pose robust face recognition", "author": ["D. Yi", "Z. Lei", "S.Z. Li"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pp. 3539\u20133545, IEEE, 2013.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Fusing robust face region descriptors via multiple metric learning for face recognition in the wild", "author": ["Z. Cui", "W. Li", "D. Xu", "S. Shan", "X. Chen"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2013.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Approximations in the hmax model", "author": ["S. Chikkerur", "T. Poggio"], "venue": "MIT-CSAIL-TR-2011, 2011.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": ", position, scale, viewing angle [1, 2, 3].", "startOffset": 33, "endOffset": 42}, {"referenceID": 1, "context": ", position, scale, viewing angle [1, 2, 3].", "startOffset": 33, "endOffset": 42}, {"referenceID": 2, "context": ", position, scale, viewing angle [1, 2, 3].", "startOffset": 33, "endOffset": 42}, {"referenceID": 3, "context": "Though the learning rules are not known, recent results [4, 5, 6] suggest the operation of an unsupervised temporal-association-based method e.", "startOffset": 56, "endOffset": 65}, {"referenceID": 4, "context": "Though the learning rules are not known, recent results [4, 5, 6] suggest the operation of an unsupervised temporal-association-based method e.", "startOffset": 56, "endOffset": 65}, {"referenceID": 5, "context": "Though the learning rules are not known, recent results [4, 5, 6] suggest the operation of an unsupervised temporal-association-based method e.", "startOffset": 56, "endOffset": 65}, {"referenceID": 6, "context": ", Foldiak\u2019s trace rule [7].", "startOffset": 23, "endOffset": 26}, {"referenceID": 7, "context": "Our system learns in an unsupervised way from natural videos gathered from the internet, and is able to perform a difficult unconstrained face recognition task on natural images: Labeled Faces in the Wild [8].", "startOffset": 205, "endOffset": 208}, {"referenceID": 6, "context": ", [7, 9, 10, 11, 12, 13].", "startOffset": 2, "endOffset": 24}, {"referenceID": 8, "context": ", [7, 9, 10, 11, 12, 13].", "startOffset": 2, "endOffset": 24}, {"referenceID": 9, "context": ", [7, 9, 10, 11, 12, 13].", "startOffset": 2, "endOffset": 24}, {"referenceID": 10, "context": ", [7, 9, 10, 11, 12, 13].", "startOffset": 2, "endOffset": 24}, {"referenceID": 11, "context": ", [7, 9, 10, 11, 12, 13].", "startOffset": 2, "endOffset": 24}, {"referenceID": 12, "context": ", [7, 9, 10, 11, 12, 13].", "startOffset": 2, "endOffset": 24}, {"referenceID": 13, "context": "Quite unlike the current \u201cbig data\u201d trend, which has used systems trained with millions of labeled examples to produce significant advances in object recognition [14, 15], our proposal is aimed at understanding one of the strategies used by human visual cortex to learn to see from far less labeled data.", "startOffset": 162, "endOffset": 170}, {"referenceID": 14, "context": "Quite unlike the current \u201cbig data\u201d trend, which has used systems trained with millions of labeled examples to produce significant advances in object recognition [14, 15], our proposal is aimed at understanding one of the strategies used by human visual cortex to learn to see from far less labeled data.", "startOffset": 162, "endOffset": 170}, {"referenceID": 7, "context": "Yet the simple model developed here is able to operate directly on the totally unconstrained data: the original unaligned labeled faces in the wild (LFW) dataset [8].", "startOffset": 162, "endOffset": 165}, {"referenceID": 15, "context": "Our approach is motivated by a theory of invariance in hierarchical architectures [16].", "startOffset": 82, "endOffset": 86}, {"referenceID": 11, "context": "Thus, as proposed by [12], the appropriate learning rule to take advantage of the temporal continuity principle is in this case greatly simplified: just associate temporally adjacent frames.", "startOffset": 21, "endOffset": 25}, {"referenceID": 15, "context": "Using the notation of [16], our system is a Hubel-Wiesel (HW)-architecture.", "startOffset": 22, "endOffset": 26}, {"referenceID": 16, "context": "It is an abstraction of the connectivity that Hubel and Wiesel conjectured gives rise to complex cell receptive fields from simple cell inputs in primary visual cortex [17].", "startOffset": 168, "endOffset": 172}, {"referenceID": 15, "context": "The theory of [16] concerns the case where P is a function that characterizes the distribution of \u3008x, \u00b7\u3009 via its moments, e.", "startOffset": 14, "endOffset": 18}, {"referenceID": 15, "context": "The main theorem of [16] says that the signature defined by equation (1) will be invariant, i.", "startOffset": 20, "endOffset": 24}, {"referenceID": 15, "context": "Another theorem from [16] says that in a more general case where T does not have a group structure, the signature will be approximately invariant.", "startOffset": 21, "endOffset": 25}, {"referenceID": 15, "context": ", simple cells might be dendrites and complex cells the soma [16].", "startOffset": 61, "endOffset": 65}, {"referenceID": 15, "context": "See [16] for details on this \u201cpartially observed group\u201d case.", "startOffset": 4, "endOffset": 8}, {"referenceID": 17, "context": "The model is almost the same as that of [18], but without doing PCA.", "startOffset": 40, "endOffset": 44}, {"referenceID": 17, "context": "Simulations based on the theory showed that having the entire orbit of each template is not necessary, all that is needed are samples from it [18].", "startOffset": 142, "endOffset": 146}, {"referenceID": 6, "context": "Temporal association methods like ours have previously been shown to work in simple uncluttered images [7, 9, 12, 13].", "startOffset": 103, "endOffset": 117}, {"referenceID": 8, "context": "Temporal association methods like ours have previously been shown to work in simple uncluttered images [7, 9, 12, 13].", "startOffset": 103, "endOffset": 117}, {"referenceID": 11, "context": "Temporal association methods like ours have previously been shown to work in simple uncluttered images [7, 9, 12, 13].", "startOffset": 103, "endOffset": 117}, {"referenceID": 12, "context": "Temporal association methods like ours have previously been shown to work in simple uncluttered images [7, 9, 12, 13].", "startOffset": 103, "endOffset": 117}, {"referenceID": 18, "context": "It shows the results from a face pair-matching experiment with synthetic face images from the Subtasks of Unconstrained Face Recognition (SUFR) benchmark [19]: given two images of unknown individuals, the task is to decide if they depict the same person or not.", "startOffset": 154, "endOffset": 158}, {"referenceID": 7, "context": "This is the same task used by [8] though the training procedure differs.", "startOffset": 30, "endOffset": 33}, {"referenceID": 19, "context": "The architecture we propose is based on an insight of [20].", "startOffset": 54, "endOffset": 58}, {"referenceID": 20, "context": "That work was concerned with replacing the traditional detection-alignment-recognition pipeline used for face recognition with a single end-to-end hierarchy that could identify faces in cluttered natural images like the original unaligned labeled faces in the wild data (as opposed to the more commonly used LFWa [21] dataset).", "startOffset": 313, "endOffset": 317}, {"referenceID": 19, "context": "[20] observed that, since most of the distinguishing features of faces are internal (and faces are convex), simple cell responses will rarely be disrupted by the presence of clutter next to the face.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "The first \u201clow-level features\u201d layer used Gabor templates in a manner similar to the C1 layer of HMAX [22, 23].", "startOffset": 102, "endOffset": 110}, {"referenceID": 22, "context": "The first \u201clow-level features\u201d layer used Gabor templates in a manner similar to the C1 layer of HMAX [22, 23].", "startOffset": 102, "endOffset": 110}, {"referenceID": 15, "context": "This is one of the main results of the spectral version of [16]\u2019s theory.", "startOffset": 59, "endOffset": 63}, {"referenceID": 23, "context": "That theory considers more biologically-plausible HW-modules that use principal components of the template books since they arise naturally as a consequence of normalized Hebbian plasticity [24].", "startOffset": 190, "endOffset": 194}, {"referenceID": 24, "context": "See [25] for details of the spectral theory.", "startOffset": 4, "endOffset": 8}, {"referenceID": 2, "context": "The face-specific part of the system resembles the macaque face-recognition hierarchy [3].", "startOffset": 86, "endOffset": 89}, {"referenceID": 26, "context": "LHS (aligned) [27] 73.", "startOffset": 14, "endOffset": 18}, {"referenceID": 27, "context": "4% MERL [28] 70.", "startOffset": 8, "endOffset": 12}, {"referenceID": 19, "context": "52% SIFT-BoW+SVM [20] 57.", "startOffset": 17, "endOffset": 21}, {"referenceID": 28, "context": "53% MRF-MLBP (aligned) [29] 80.", "startOffset": 23, "endOffset": 27}, {"referenceID": 29, "context": "[30] 72.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "I-LPQ (aligned) [31] 86.", "startOffset": 16, "endOffset": 20}, {"referenceID": 31, "context": "[32] 72.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "PAF (aligned) [33] 87.", "startOffset": 14, "endOffset": 18}, {"referenceID": 33, "context": "77% APEM (fusion) [34] 81.", "startOffset": 18, "endOffset": 22}, {"referenceID": 2, "context": "That is, its cells respond nearly identically to pairs of face images flipped over their vertical midline [3].", "startOffset": 106, "endOffset": 109}, {"referenceID": 24, "context": "This intriguing result may be explained by the spectral theory in [25] and [26]-chapter5.", "startOffset": 66, "endOffset": 70}, {"referenceID": 25, "context": "This intriguing result may be explained by the spectral theory in [25] and [26]-chapter5.", "startOffset": 75, "endOffset": 79}, {"referenceID": 19, "context": "[20] also considered this problem with an approach similar to ours.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "We also tested the face recognition model on a more difficult dataset\u2014LFW-Jittered [20] to assess the model\u2019s tolerance to affine transformations (table 2).", "startOffset": 83, "endOffset": 87}, {"referenceID": 19, "context": "Model LFW LFW-J HOG+SVM [20] 74.", "startOffset": 24, "endOffset": 28}, {"referenceID": 19, "context": "Table 2: We report the performance of our model on the LFW-J (jittered) dataset created by [20].", "startOffset": 91, "endOffset": 95}, {"referenceID": 19, "context": "The HOG baseline is from [20].", "startOffset": 25, "endOffset": 29}, {"referenceID": 13, "context": "But it is surely less than the amount of labeled data used to train state of the art systems like [14].", "startOffset": 98, "endOffset": 102}, {"referenceID": 18, "context": "Preparation: We randomly chose 5500 images from the SUFR-W [19] dataset.", "startOffset": 59, "endOffset": 63}, {"referenceID": 13, "context": "This is similar to a convolutional layer in a convolutional neural network (CNN) like [14] with three differences: (1) we have multiple scales; (2) our templates (i.", "startOffset": 86, "endOffset": 90}, {"referenceID": 19, "context": "This procedure is adopted by [20] and similar to the one employed by [35].", "startOffset": 29, "endOffset": 33}, {"referenceID": 34, "context": "This procedure is adopted by [20] and similar to the one employed by [35].", "startOffset": 69, "endOffset": 73}, {"referenceID": 24, "context": "It may be biologically plausible in the sense of the spectral theory of [25].", "startOffset": 72, "endOffset": 76}], "year": 2015, "abstractText": "Populations of neurons in inferotemporal cortex (IT) maintain an explicit code for object identity that also tolerates transformations of object appearance e.g., position, scale, viewing angle [1, 2, 3]. Though the learning rules are not known, recent results [4, 5, 6] suggest the operation of an unsupervised temporal-association-based method e.g., Foldiak\u2019s trace rule [7]. Such methods exploit the temporal continuity of the visual world by assuming that visual experience over short timescales will tend to have invariant identity content. Thus, by associating representations of frames from nearby times, a representation that tolerates whatever transformations occurred in the video may be achieved. Many previous studies verified that such rules can work in simple situations without background clutter, but the presence of visual clutter has remained problematic for this approach. Here we show that temporal association based on large class-specific filters (templates) avoids the problem of clutter. Our system learns in an unsupervised way from natural videos gathered from the internet, and is able to perform a difficult unconstrained face recognition task on natural images: Labeled Faces in the Wild [8]. This work was supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF 1231216. ar X iv :1 40 9. 38 79 v2 [ cs .C V ] 2 4 A pr 2 01 5", "creator": "LaTeX with hyperref package"}}}