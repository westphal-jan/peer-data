{"id": "1409.4276", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2014", "title": "A Fast Quartet Tree Heuristic for Hierarchical Clustering", "abstract": "The Minimum Quartet Tree Cost problem is to construct an optimal weight tree from the $3{n \\choose 4}$ weighted quartet topologies on $n$ objects, where optimality means that the summed weight of the embedded quartet topologies is optimal (so it can be the case that the optimal tree embeds all quartets as nonoptimal topologies). We present a Monte Carlo heuristic, based on randomized hill climbing, for approximating the optimal weight tree, given the quartet topology weights. The method repeatedly transforms a dendrogram, with all objects involved as leaves, achieving a monotonic approximation to the exact single globally optimal tree. The problem and the solution heuristic has been extensively used for general hierarchical clustering of nontree-like (non-phylogeny) data in various domains and across domains with heterogeneous data. We also present a greatly improved heuristic, reducing the running time by a factor of order a thousand to ten thousand. All this is implemented and available, as part of the CompLearn package. We compare performance and running time of the original and improved versions with those of UPGMA, BioNJ, and NJ, as implemented in the SplitsTree package on genomic data for which the latter are optimized.", "histories": [["v1", "Fri, 12 Sep 2014 15:55:25 GMT  (65kb)", "http://arxiv.org/abs/1409.4276v1", "LaTeX, 40 pages, 11 figures; this paper has substantial overlap witharXiv:cs/0606048in cs.DS"]], "COMMENTS": "LaTeX, 40 pages, 11 figures; this paper has substantial overlap witharXiv:cs/0606048in cs.DS", "reviews": [], "SUBJECTS": "cs.LG cs.CE cs.DS", "authors": ["rudi l cilibrasi", "paul m b vitanyi"], "accepted": false, "id": "1409.4276"}, "pdf": {"name": "1409.4276.pdf", "metadata": {"source": "CRF", "title": "A Fast Quartet Tree Heuristic for Hierarchical Clustering", "authors": ["Rudi Cilibrasi", "Paul M.B. Vit\u00e1nyi"], "emails": ["cilibrar@gmail.com.", "Paul.Vitanyi@cwi.nl."], "sections": [{"heading": null, "text": "In fact, the optimal tree incorporates all the quartets as non-optimal topologies. We present a Monte Carlo heuristic problem based on randomized mountaineering to approach the optimal weight tree, given the topology of the quartet. The method repeatedly transforms a dendrogram, with all objects involved in the leaves, and achieves a monotonous approach to the exact single globally optimal tree. The heuristic problem and solution has been extensively used for the general hierarchical clustering of non-tree-like species."}, {"heading": "A. Hierarchical Clustering and the Quartet Method", "text": "In cluster analysis, there are essentially two methods of hierarchical clustering. In the bottom-up approach, each element of data forms its own cluster, and pairs of clusters are merged as you ascend the hierarchy. In the top-down approach, the set of all data represents the initial cluster, and columns are executed recursively as you move down the hierarchy. In general, mergers and columns are determined in greedy ways. Thus, the main disadvantages of bottom-up and top-down methods are, firstly, that they do not scale well because the time complexity in terms of the number of objects is non-linear, and, secondly, that they can never undo what was done before. Thus, they lack robustness and uniqueness, as the results depend on previous decisions. In contrast, the method we propose here is robust and there are unique results in constraint."}, {"heading": "B. Related Work", "text": "In fact, it is so that most of them are able to identify themselves, and that they are able to identify themselves. In fact, it is so that they are able to identify themselves. In fact, it is so that they are able to identify themselves. In fact, it is so that they are able to identify themselves. In fact, it is so that they are able to identify themselves. In fact, it is so that they are able to identify themselves. In fact, it is so that they are not able to identify themselves. In fact, it is so that they are able to identify themselves."}, {"heading": "C. Present Work", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "D. Origin and Computational Complexity", "text": "The MQTC problem and heuristics were originally proposed in [11], [12], [13]. Furthermore, the emphasis is on compression-based distances, but to present the results in tree form, we focused on a quartet method for tree reconstruction. We also believed that such a quartet tree is more sensitive and objective than other methods. This approach is too slow when it is accurate or global, and too uncertain when it is statistically incremental. It also addressed only biological phylogeny. Therefore, we developed a new approach aimed at generalized hierarchical clustering, which is not top-down or bottom-up, but top-down."}, {"heading": "E. Materials and Scoring", "text": "The data samples that we have used, here or in relation to previous work, were retrieved from standard databases on the Internet, which were generated by ourselves, or from research groups in the field of investigation. In contrast to biological phylogeny methods, we have no match values on the branches: We generate the best tree possible, globally balanced all requirements. The quality of the results depends on how well the hierarchical tree represents the information in the group of weighted quartet topologies. The MQTC clustering heuristic generates a tree along with a quality value. The latter is called a standardized benefit score or S (T) value in sequence (definition 3.3). In certain natural data sets, such as H5N1 genomics sequences, consistently high values are returned, even for large groups of objects of 100 or more nodes."}, {"heading": "II. THE QUARTET METHOD", "text": "Considering a set of n objects, we consider each subset of four elements (objects) from our set of n elements; there are (n 4) such sets. Such a set is called a quartet. From each quartet {u, v, w, x} we construct a tree of kindness 3, which means that the tree consists of two subtrees of two leaves each. Let's call such a tree a quartet topology. (i) A toptet of {u, v, w, x} by uv | wx. There are three ways to divide the trees {u, v, w, x} into two subsets of two elements each: (i) a toptet of {u, v, w, w, w, x, x} by uv, x."}, {"heading": "III. MINIMUM QUARTET TREE COST", "text": "The reasoning for the MQC optimization problem reflects the genesis of the method in biological phylogeny that affects other quartets. Assuming that biological species evolved through evolution over time, and N is a subset of species that now exist, there is a phylogeny TP that represents this evolution. The set of quartet topologies that are consistent with this tree has a quartet topology per quartet that is the true utility. The quartet topologies in TP are those that we assume to belong to the true quartet topologies, and weights are used to express our relative certainty about the individual quartet topologies in TP. However, the data can be corrupted so that this assumption is no longer true. In the general case of hierarchical clustering, we do not even have a primary knowledge that certain quartet topologies are objectively true and need to be embedded. Rather, we are in the position that quarteologies can somehow indicate relative importance to each other."}, {"heading": "A. Computational Hardness", "text": "The Hardness of Quartet Puzzling is informally mentioned in the literature [44], [34], [36], but we provide explicit proofs. To express the notion of computational difficulty, the term \"non-deterministic polynomial time (NP)\" is used. If a problem is severe with respect to n objects, it means that the best known algorithm for this (and a broad class of significant problems) requires computation time that is at least exponentially in n. That is, it is impracticable in practice. Let N be a set of n objects, let T be a tree from which the n sheets are labeled by the objects, and let Q be the set of quartet topologies and QT the set of quartet topologies. Definition 3.6: The MQC decision is the following: GIVE: A set of quartet topologies P Q, and an integral k."}, {"heading": "IV. MONTE CARLO HEURISTIC", "text": "That is, we have a set of n objects and a cost function C.Definition 4.1: We define a simple mutation on a labeled undirected tree as one of the following possible transformations: 1) A leaf change: we randomly select two leaves that have no siblings and no interchangeability. 2) A subtree change: We randomly select two internal nodes u, w, or an internal node u and a leaf w so that the shortest path length between u and w is at least three steps. That is, a subtree change is a shortest path in the tree."}, {"heading": "A. Algorithm", "text": "The algorithm is given in Figure 3. We comment on the various steps: Comment on Step 2: A tree is compatible with exactly 1 3 of all quartet topologies (1 for each quartet). A random tree is probably compatible with about 1 3 of the best quartet topologies - but due to dependencies this number is not precision.Comment on Step 3: This T0 is used as a basis for further search.Comment on Step 4: This number k is probably the number of simple mutations that we will form the next k mutation.The probability mass function p (k) for k 2 is p (k) for the maximum probability (k log2) with c / (k log2 k) with c \u2248 2.1. In practice, we have a \"shifted\" fat-tail mass function 1 / (k + 2) (log k + 2) for k mass function 1.Comment on step: trees that are located near the original tree (in terms of the number of simple mutation steps between them being examined)."}, {"heading": "B. Performance", "text": "The main question, therefore, is the convergence speed of the algorithm with respect to the value of S (T) and a termination of the algorithms that we have declared an acceptable approximation if we have an approximate improvement. (By randomly selecting a sequence of simple mutations, longer sequences with a decreasing probability, we will essentially run a problem of simulated approximation [28] algorithm at random temperatures. However, since there is an unequal probability for each tree in T that is monotonously transformed into each other tree, there is zero probability that we will forever be trapped in a local optimum that is not a global optimum. This is trivial: Lemma 4.4: (i) The algorithm approaches the optimal solution in each run. (ii) The termination-free algorithm ultimately solves the MQTC optimization problem with probability 1 (but we generally do not know when the optimum was reached in a particular run) of the termination algorithm (hence the main question is the S in relation to the termination speed)."}, {"heading": "C. Termination Condition", "text": "The termination condition is of two types, and which type is used determines the number of objects we can handle. Simple termination condition: We simply execute the algorithm until it appears as if no better trees are found in a reasonable amount of time. Here, we typically finish when no improvement in the S (T) value is achieved within 100,000 trees studied. This criterion is simple enough to allow us to set hierarchically cluster data to 80 objects in a few hours, even without the improvement in section V, and at least up to 300 objects with the improvement. This is far beyond the 15-30 objects in the previous exact (non-incremental) methods (see Introduction).Condition: In this more complex method, we select a number of 2 \u2264 r 6 runs, and we run for calls to the algorithm in parallel. Each time an S (T) value in run i = 1., r is in this process, it is increased with other rushes (T) in all the algorithm."}, {"heading": "D. Tree Building Statistics", "text": "We used the CompLearn package, [9] to analyze a \"10 mammals\" example in which the Zlib compression results in a 10-10 distance matrix, similar to the examples in Section VII-B. The algorithm begins with four randomly initialized trees, and tries to randomly improve and terminate each of them if they match. Thus, each run produces an output tree, a maximum number of trees associated with this tree, and has a total number of trees, T, examined before it is completed. Figure 5 shows a graph showing a histogram of T over a thousand runs of the distance matrix. The x-axis represents a number of trees examined in a single run of the program, measured in thousands of trees and bundled in 1,000-wide histogram bars. The maximum number of trees studied is about 12,000 trees showing a histogram of T over a thousand runs of the distance matrix."}, {"heading": "E. Controlled Experiments", "text": "With natural data sets, say genomic data, one can have a prejudice (or prejudice) that primates should be clustered together, and so there should be a cost. (The genome of a rodent may resemble more than that of a monotreme, or vice versa - the question that can be used as a benchmark for evaluating our experimental results, however, can only be intuitive or traditional. In Section VII-A, the experiments show that our program actually does what it is supposed to do - at least in those artificial situations where we know what the correct answer is. V. IMPROVED RUNNING TIMERecall that we do."}, {"heading": "VI. COMPRESSION-BASED DISTANCE", "text": "In order to make unbiased comparisons between phylogeny reconstruction algorithms that use distance matrices as input, we use the compression-based NCD distance. This metric distance was developed by us in [30], [32], as a normalized version of the \"information metrics\" of [2], [33]. The mathematics used is based on the Kolmogorov complexity theory [33], which comes into contact with the real compression software. Rough, two objects are considered close if one specifies the information in the other, the idea is that if two parts are similar, then one can describe them in the other."}, {"heading": "A. CompLearn Toolkit", "text": "The MQTC heuristics described in Section IV, V ignore the problem area in question by simply using the distances according to the NCD of (VI.1) and the derived topology costs of the quartet (V.1), and clustering the objects in question fully automatically. Publicly, the method has been published as open source software: the CompLearn Toolkit [9] is a set of simple tools that apply compression techniques to the process of discovering and learning patterns in completely different areas and clustering them hierarchically using the MQTC Heuristics. In fact, CompLearn is so general that it does not require any background knowledge of a particular subject area, there are no domain-specific parameters to be specified, and only a handful of general settings. As of Compn version 1.1.3, the accelerations and improvements in Section V have been implemented."}, {"heading": "B. Previous Experiments", "text": "With the CompLearn package, we investigated hypotheses about mammalian evolution by reconstructing the phylogeny from the mitochondrial genomes of 24 species, which were downloaded from the GenBank database on the Internet. In another experiment, we used the mitochondrial genomes of moulds and yeasts. We made the SARS virus publicly available after its sequenced genome, with respect to potentially similar viruses. The NCD removal matrix was compressed with the compressor bzip2. The resulting trees T (with S) = 0.988 were very similar to the definitive trees based on macrobio genomics analyses that later appeared in the New England Journal of Medicine."}, {"heading": "VII. COMPARING AGAINST SPLITSTREE", "text": "We compared the performance of the MQTC heuristically, as implemented in the ComplitsTree package, with that of a leading application for calculating phylogenetic trees, a program called SplitsTree [22]. Other methods include [14], [39], [1]. Our experiments were initially conducted with CompLearn version 0.9.7 before the improvements in Section V. But with the improvements in Section V in CompLearn version 1.1.3 and later, sentences of say 34 objects were reviewed, which were often terminated in about 8 cpu seconds. Below, we use sets of 32 objects. We select SplitsTree version 4.6 for comparison and chose three methods for tree reconstruction as benchmarks: NJ, BioNJ, and UPGMA. To enable comparison, we need an implementation of tree reconstruction that takes a distance matrix as input. This requirement excluded some other options and motivated our choice. To evaluate the quality of the trees that ComplitsTree has generated, we have split the tree archically."}, {"heading": "A. Testing on Artificial Data 100 Times", "text": "This year it is more than ever before in the history of the city."}, {"heading": "B. Testing on Natural Data 100 Times", "text": "In the biological setting of the data, (parts) of the genomes of the currently existing species are irrelevant (each with similar genes), and the purpose is to reconstruct the evolutionary tree that has led to these species. Thus, the species are labels of the leaves, and the tree is traditionally binary branching with each branching representing a splitting into lines. Internal nodes and the root of the tree correspond to extinct species (possibly a still existing species in a leaf that is directly connected to the internal node). The root of the tree is generally determined by adding an object that is known to be less related to all other objects than the original objects related to each other. Where the unrelated object joins the tree, we insert the root. In this setting, the direction from root to the leaves represents an evolution in time, and the assumption is that there is a real tree that we have to discover. However, we can also use the method of hierarchical clustering, which does not lead to a tree forming."}, {"heading": "VIII. CONCLUSION", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "A. Sufficiency of the Set of Simple Mutations", "text": "The question that arises is to what extent it is an internal node, in which an internal node is connected to an internal node, and where an internal node is connected to an internal node, in which an internal node is connected to an internal node, and where an internal node is connected to an internal node, and where an internal node is connected to an internal node, in which an internal node can be converted to an internal node from one node to another, in which only the sheets are labeled. The proof is by induction at the number of nodes. Base case: n = 3. It is an internal node, so that the discussion we connect to the internal nodes, but the internal nodes are not labeled, so that only the sheets are labeled. There is an internal node, so that the theorem are two internal nodes, so that there are two internal nodes."}, {"heading": "ACKNOWLEDGEMENT", "text": "We thank Maarten Keijzer for the improvements in heuristics and their implementation, which are described in section V."}], "references": [{"title": "Clustered SplitsNetworks", "author": ["L. Bao", "S. Bereg"], "venue": "in: Combinatorial Optimization and Applications, Lect. Notes Comput. Sci., Vol. 5165, Springer, Berlin", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Information Distance", "author": ["C.H. Bennett", "P. G\u00e1cs", "M. Li", "P.M.B. Vit\u00e1nyi", "W. Zurek"], "venue": "IEEE Trans. Information Theory, 44:4", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "Chain letters and evolutionary histories", "author": ["C.H. Bennett", "M. Li", "B. Ma"], "venue": "Scientific American,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Constructing phylogenies from quartets: Elucidation of eutherian superordinal relationships", "author": ["A. Ben-Dor", "B. Chor", "D. Graur", "R. Ophir", "D. Peleg"], "venue": "J. Computational Biology, 5:3", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1998}, {"title": "Quartet cleaning: improved algorithms and simulations", "author": ["V. Berry", "T. Jiang", "P. Kearney", "M. Li", "T. Wareham"], "venue": "Algorithms, in: Proc. 7th European Symp. (ESA99), Lect. Notes Comp. Sci., Vol. 1643, Springer, Berlin", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1999}, {"title": "The recovery of trees from measures of dissimilarity", "author": ["P. Buneman"], "venue": "in: F. Hodson, D. Kenadall, P. Tautu (Eds.), Proc. of the Anlo-Romanian conference, The Royal Society of London and the Academy of the Socialist Republic of Romania, The University Press, Edinburgh, Scotland, UK", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1971}, {"title": "Calculating sums of infinite series", "author": ["B. Braden"], "venue": "Am. Math. Monthly, 99:7", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1992}, {"title": "Shared information and program plagiarism detection", "author": ["X. Chen", "B. Francia", "M. Li", "B. McKinnon", "A. Seker"], "venue": "IEEE Trans. Information Theory, 50:7", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Statistical Inference Through Data Compression", "author": ["R. Cilibrasi"], "venue": "PhD Thesis, ILLC DS-2007-01, University of Amsterdam", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "R", "author": ["R. Cilibrasi", "P.M.B. Vitanyi"], "venue": "de Wolf, Algorithmic clustering of music based on string compression, Computer Music J., 28:4", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Clustering by compression", "author": ["R. Cilibrasi", "P.M.B. Vitanyi"], "venue": "IEEE Trans. Information Theory, 51:4", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "The Google Similarity Distance", "author": ["R.L. Cilibrasi", "P.M.B. Vitanyi"], "venue": "IEEE Trans. Knowledge and Data Engineering, 19:3", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Trees constructed from empirical relations", "author": ["H. Colonius", "H.H. Schulze"], "venue": "Braunschweiger Berichte as dem Institut f\u00fcr Psychologie, 1", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1977}, {"title": "Tree structures for proximity data", "author": ["H. Colonius", "H.H. Schulze"], "venue": "British J. Math. Stat. Psych., 34", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1981}, {"title": "Clustering fetal heart rate tracings by compression", "author": ["C. Costa Santos", "J. Bernardes", "P.M.B. Vitanyi", "L. Antunes"], "venue": "in: Proc. 19th IEEE Symp. Computer-Based Medical Systems", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Pattern Classification", "author": ["R.O. Duda", "P.E. Hart", "D.G. Stork"], "venue": "second edition, Wiley Interscience", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2001}, {"title": "Evolutionary trees from DNA sequences: a maximum likelihood approach", "author": ["J. Felsenstein"], "venue": "J. Molecular Evolution, 17", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1981}, {"title": "BIONJ: an improved version of the NJ algorithm based on a simple model of sequence data", "author": ["O. Gascuel"], "venue": "Mol. Biol. Evol., 14", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1997}, {"title": "Application of Phylogenetic Networks in Evolutionary Studies", "author": ["D.H. Huson", "D. Bryant"], "venue": "Mol. Biol. Evol., 23:2", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Hierarchical clustering schemes", "author": ["S.C. Johnson"], "venue": "Psychometrika, 32:3", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1967}, {"title": "A polynomial time approximation scheme for inferring evolutionary trees from quartet topologies and its application", "author": ["T. Jiang", "P. Kearney", "M. Li"], "venue": "SIAM J. Computing, 30:6", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "Ordinal quartet method", "author": ["P.E. Kearney"], "venue": "in: Proc. 2nd Int. Conf. Comput. Molecular Biology", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1998}, {"title": "Toward parameter-free data mining", "author": ["E. Keogh", "S. Lonardi", "C.A. Rtanamahatana"], "venue": "in: Proc. 10th ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining, Seattle, Washington, USA", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2004}, {"title": "Science", "author": ["S. Kirkpatrick", "C.D. Gelatt", "M.P. Vecchi"], "venue": "220", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1983}, {"title": "et.al., A Novel Coronavirus Associated with Severe Acute Respiratory Syndrome", "author": ["T.G. Ksiazek"], "venue": "New England J. Medicine, Published at www.nejm.org April", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2003}, {"title": "An information-based sequence distance and its application to whole mitochondrial genome phylogeny", "author": ["M. Li", "J.H. Badger", "X. Chen", "S. Kwong", "P. Kearney", "H. Zhang"], "venue": "Bioinformatics, 17:2", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2001}, {"title": "Algorithmic Complexity, in: International Encyclopedia of the Social & Behavioral Sciences, N.J", "author": ["M. Li", "P.M.B. Vit\u00e1nyi"], "venue": "Smelser, P.B. Baltes (Eds.), Pergamon,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2001}, {"title": "The similarity metric", "author": ["M. Li", "X. Chen", "X. Li", "B. Ma", "P.M.B. Vit\u00e1nyi"], "venue": "IEEE Trans. Information Theory, 50:12", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2004}, {"title": "An Introduction to Kolmogorov Complexity and its Applications", "author": ["M. Li", "P.M.B. Vit\u00e1nyi"], "venue": "Springer, New York, third ed.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}, {"title": "Quartet methods for phylogeny reconstruction from gene", "author": ["T. Liu", "J. Tang", "B.M.E. Moret"], "venue": "orders. Dept. CS and Engin., Univ. South-Carolina,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2005}, {"title": "J", "author": ["N. Metropolis", "A.W. Rosenbluth", "M.N. Rosenbluth", "A.H. Teller", "E. Teller"], "venue": "Chem. Phys., 21", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1953}, {"title": "Quartet supertrees", "author": ["R. Piaggio-Talice", "J. Gordon Burleigh", "O. Eulenstein"], "venue": "Chapter 4 in: O.R.P. Beninda-Edmonds (Ed.), Phylogenetic Supertrees: Combining Information to Reveal the Tree of Life, Computational Biology, Vol. 3 (A. Dress, series Ed.), Kluwer Academic Publishers", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2004}, {"title": "Performance of supertree methods on various datasets decompositions", "author": ["U. Roshan", "B.M.E. Moret", "T. Warnow", "T.L. Williams"], "venue": "in: O.R.P. Beninda-Edmonds (Ed.), Phylogenetic Supertrees: Combining Information to Reveal the Tree of Life, Computational Biology, Vol. 3 (A. Dress, series Ed.), Kluwer Academic Publishers", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2004}, {"title": "The neighbor-joining method: a new method for reconstructing phylogenetic trees", "author": ["N. Saitou", "M. Nei"], "venue": "Mol. Biol. Evol., 4", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1987}, {"title": "Short Quartet Puzzling: A new quartet-based phylogeny reconstruction algorithm", "author": ["S. Snir", "T. Warnow", "S. Rao"], "venue": "J. Comput. Biol., 15:1", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2008}, {"title": "The complexity of reconstructing trees form qualitative characters and subtrees", "author": ["M. Steel"], "venue": "J. Classification, 9", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1992}, {"title": "A", "author": ["K. Strimmer"], "venue": "von Haeseler, Quartet Puzzling: A quartet maximum-likelihood method for reconstructing tree topologies, Mol. Biol. Evol., 13:7", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1996}, {"title": "A discipline of evolutionary programming", "author": ["P.M.B. Vitanyi"], "venue": "Theor. Comp. Sci., 241:1-2", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2000}, {"title": "Analyzing worms and network traffic using compression", "author": ["S. Wehner"], "venue": "J. Comput. Security, 15", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2007}, {"title": "Integer linear programming as a tool for constructing trees from quartet data", "author": ["J. Weyer-Menkoff", "C. Devauchelle", "A. Grossmann", "S. Gr\u00fcnewald"], "venue": "Comput Biol Chem., 29:3", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 15, "context": "Since it is not likely that natural data determines unequivocal disjoint clusters, it is common to hierarchically cluster the data [19].", "startOffset": 131, "endOffset": 135}, {"referenceID": 19, "context": "The results of hierarchical clustering are usually presented in a dendrogram [23].", "startOffset": 77, "endOffset": 81}, {"referenceID": 36, "context": "A much-used heuristic called the Quartet Puzzling problem was proposed in [41].", "startOffset": 74, "endOffset": 78}, {"referenceID": 16, "context": "There are two main avenues that have been taken: (i) Incrementally grow the tree in random order by stepwise addition of objects in the locally optimal way, repeat this for different object orders, and add agreement values on the branches, like DNAML [20], or Quartet Puzzling [41].", "startOffset": 251, "endOffset": 255}, {"referenceID": 36, "context": "There are two main avenues that have been taken: (i) Incrementally grow the tree in random order by stepwise addition of objects in the locally optimal way, repeat this for different object orders, and add agreement values on the branches, like DNAML [20], or Quartet Puzzling [41].", "startOffset": 277, "endOffset": 281}, {"referenceID": 3, "context": "But the number of permutations is about 2, so why would the incrementally locally optimal trees derived from 1000 random permutations be a representative sample from which we can conclude anything about the globally optimal tree? (ii) Approximate the global optimum monotonically or compute it, using a geometric algorithm or dynamic programming [4], linear programming [44], or semi-definite programming [39].", "startOffset": 346, "endOffset": 349}, {"referenceID": 39, "context": "But the number of permutations is about 2, so why would the incrementally locally optimal trees derived from 1000 random permutations be a representative sample from which we can conclude anything about the globally optimal tree? (ii) Approximate the global optimum monotonically or compute it, using a geometric algorithm or dynamic programming [4], linear programming [44], or semi-definite programming [39].", "startOffset": 370, "endOffset": 374}, {"referenceID": 34, "context": "But the number of permutations is about 2, so why would the incrementally locally optimal trees derived from 1000 random permutations be a representative sample from which we can conclude anything about the globally optimal tree? (ii) Approximate the global optimum monotonically or compute it, using a geometric algorithm or dynamic programming [4], linear programming [44], or semi-definite programming [39].", "startOffset": 405, "endOffset": 409}, {"referenceID": 39, "context": "2), cannot handle more than 15\u201330 objects [44], [34], [36], [5], [39] directly, even while using farms of desktops.", "startOffset": 42, "endOffset": 46}, {"referenceID": 29, "context": "2), cannot handle more than 15\u201330 objects [44], [34], [36], [5], [39] directly, even while using farms of desktops.", "startOffset": 48, "endOffset": 52}, {"referenceID": 31, "context": "2), cannot handle more than 15\u201330 objects [44], [34], [36], [5], [39] directly, even while using farms of desktops.", "startOffset": 54, "endOffset": 58}, {"referenceID": 4, "context": "2), cannot handle more than 15\u201330 objects [44], [34], [36], [5], [39] directly, even while using farms of desktops.", "startOffset": 60, "endOffset": 63}, {"referenceID": 34, "context": "2), cannot handle more than 15\u201330 objects [44], [34], [36], [5], [39] directly, even while using farms of desktops.", "startOffset": 65, "endOffset": 69}, {"referenceID": 32, "context": "To handle more objects one needs to construct a supertree from the constituent quartet trees for subsets of the original data sets, [37], as in [34], [36], incurring again the bottom-up problem of being unable to correct earlier decisions.", "startOffset": 132, "endOffset": 136}, {"referenceID": 29, "context": "To handle more objects one needs to construct a supertree from the constituent quartet trees for subsets of the original data sets, [37], as in [34], [36], incurring again the bottom-up problem of being unable to correct earlier decisions.", "startOffset": 144, "endOffset": 148}, {"referenceID": 31, "context": "To handle more objects one needs to construct a supertree from the constituent quartet trees for subsets of the original data sets, [37], as in [34], [36], incurring again the bottom-up problem of being unable to correct earlier decisions.", "startOffset": 150, "endOffset": 154}, {"referenceID": 21, "context": "The algorithm does not address the problem of how to obtain the quartet topology weights from sequence data [25], [30], [32], but takes as input the weights of all quartet topologies and executes the step of how to reconstruct the hierarchical clustering from there.", "startOffset": 108, "endOffset": 112}, {"referenceID": 25, "context": "The algorithm does not address the problem of how to obtain the quartet topology weights from sequence data [25], [30], [32], but takes as input the weights of all quartet topologies and executes the step of how to reconstruct the hierarchical clustering from there.", "startOffset": 114, "endOffset": 118}, {"referenceID": 27, "context": "The algorithm does not address the problem of how to obtain the quartet topology weights from sequence data [25], [30], [32], but takes as input the weights of all quartet topologies and executes the step of how to reconstruct the hierarchical clustering from there.", "startOffset": 120, "endOffset": 124}, {"referenceID": 9, "context": "The MQTC problem and heuristic were originally proposed in [11], [12], [13].", "startOffset": 59, "endOffset": 63}, {"referenceID": 10, "context": "The MQTC problem and heuristic were originally proposed in [11], [12], [13].", "startOffset": 65, "endOffset": 69}, {"referenceID": 11, "context": "The MQTC problem and heuristic were originally proposed in [11], [12], [13].", "startOffset": 71, "endOffset": 75}, {"referenceID": 8, "context": "sequences, consistently high S(T ) values are returned even for large sets of objects of 100 or more nodes, [10].", "startOffset": 108, "endOffset": 112}, {"referenceID": 9, "context": "In other nontree-structured natural data sets however, as treated in [11], [12], the S(T ) value deteriorates more and more with increasing number of elements being put in the same tree.", "startOffset": 69, "endOffset": 73}, {"referenceID": 10, "context": "In other nontree-structured natural data sets however, as treated in [11], [12], the S(T ) value deteriorates more and more with increasing number of elements being put in the same tree.", "startOffset": 75, "endOffset": 79}, {"referenceID": 20, "context": "Commonly the goal in the quartet method is to find (or approximate as closely as possible) the tree that embeds the maximal number of consistent (possibly weighted) quartet topologies from a given set P \u2286 Q of quartet topologies [24] (Figure 2).", "startOffset": 229, "endOffset": 233}, {"referenceID": 39, "context": "The hardness of Quartet Puzzling is informally mentioned in the literature [44], [34], [36], but we provide explicit proofs.", "startOffset": 75, "endOffset": 79}, {"referenceID": 29, "context": "The hardness of Quartet Puzzling is informally mentioned in the literature [44], [34], [36], but we provide explicit proofs.", "startOffset": 81, "endOffset": 85}, {"referenceID": 31, "context": "The hardness of Quartet Puzzling is informally mentioned in the literature [44], [34], [36], but we provide explicit proofs.", "startOffset": 87, "endOffset": 91}, {"referenceID": 35, "context": "In [40] it is shown that the MQC decision problem is NP\u2013hard.", "startOffset": 3, "endOffset": 7}, {"referenceID": 4, "context": "The less general complete MQC decision problem requires P to contain precisely one quartet topology per quartet (that is, per each subset of 4 elements out of the n elements), and is proved to be NP\u2013hard as well in [5].", "startOffset": 215, "endOffset": 218}, {"referenceID": 4, "context": "In [5] a PTAS for a restricted version of the MQC optimization problem, namely the \u201ccomplete\u201d MQC optimization problem defined above, is exhibited.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "Since [5] has shown that a PTAS for the MQC optimization problem does not exist unless P=NP, it also holds for this restricted version of the MQTC optimization problem that a PTAS does not exist unless P=NP, The full MQTC optimization problem is at least as hard to approximate by a PTAS, from which the theorem follows.", "startOffset": 6, "endOffset": 9}, {"referenceID": 5, "context": "Note first that the set of quartet topologies uniquely determines a tree in T , [6].", "startOffset": 80, "endOffset": 83}, {"referenceID": 12, "context": "For an explicit example of this, we use that a complete set corresponding to a tree in T must satisfy certain transitivity properties, [15], [16]: Lemma 3.", "startOffset": 135, "endOffset": 139}, {"referenceID": 13, "context": "For an explicit example of this, we use that a complete set corresponding to a tree in T must satisfy certain transitivity properties, [15], [16]: Lemma 3.", "startOffset": 141, "endOffset": 145}, {"referenceID": 6, "context": "By [7] it is known that 1/c \u2248 2.", "startOffset": 3, "endOffset": 6}, {"referenceID": 23, "context": "However, by randomly selecting a sequence of simple mutations, longer sequences with decreasing probability, we essentially run a of simulated annealing [28] algorithm at random temperatures.", "startOffset": 153, "endOffset": 157}, {"referenceID": 37, "context": "Metropolis chain is rapidly mixing [42], a notoriously hard and generally unsolved problem.", "startOffset": 35, "endOffset": 39}, {"referenceID": 5, "context": "This works since the set of embedded quartet topologies uniquely determines the quartet tree by [6].", "startOffset": 96, "endOffset": 99}, {"referenceID": 30, "context": "Speedup by MMC: A Metropolis Markov Chain (MMC) [35] is implemented inside the mutation chains of the algorithm.", "startOffset": 48, "endOffset": 52}, {"referenceID": 25, "context": "This metric distance was co-developed by us in [30], [31], [32], as a normalized version of the \u201cinformation metric\u201d of [2], [33].", "startOffset": 47, "endOffset": 51}, {"referenceID": 26, "context": "This metric distance was co-developed by us in [30], [31], [32], as a normalized version of the \u201cinformation metric\u201d of [2], [33].", "startOffset": 53, "endOffset": 57}, {"referenceID": 27, "context": "This metric distance was co-developed by us in [30], [31], [32], as a normalized version of the \u201cinformation metric\u201d of [2], [33].", "startOffset": 59, "endOffset": 63}, {"referenceID": 1, "context": "This metric distance was co-developed by us in [30], [31], [32], as a normalized version of the \u201cinformation metric\u201d of [2], [33].", "startOffset": 120, "endOffset": 123}, {"referenceID": 28, "context": "This metric distance was co-developed by us in [30], [31], [32], as a normalized version of the \u201cinformation metric\u201d of [2], [33].", "startOffset": 125, "endOffset": 129}, {"referenceID": 28, "context": "The mathematics used is based on Kolmogorov complexity theory [33], which is approximated using real-world compression software.", "startOffset": 62, "endOffset": 66}, {"referenceID": 10, "context": "The better Z is, the better the results are, [12].", "startOffset": 45, "endOffset": 49}, {"referenceID": 25, "context": "1) and a precursor have initially been applied to, among others, alignmentfree whole genome phylogeny, [30], [31], [32], chain letter phylogeny [3], constructing language trees [32], and plagiarism detection [8].", "startOffset": 103, "endOffset": 107}, {"referenceID": 26, "context": "1) and a precursor have initially been applied to, among others, alignmentfree whole genome phylogeny, [30], [31], [32], chain letter phylogeny [3], constructing language trees [32], and plagiarism detection [8].", "startOffset": 109, "endOffset": 113}, {"referenceID": 27, "context": "1) and a precursor have initially been applied to, among others, alignmentfree whole genome phylogeny, [30], [31], [32], chain letter phylogeny [3], constructing language trees [32], and plagiarism detection [8].", "startOffset": 115, "endOffset": 119}, {"referenceID": 2, "context": "1) and a precursor have initially been applied to, among others, alignmentfree whole genome phylogeny, [30], [31], [32], chain letter phylogeny [3], constructing language trees [32], and plagiarism detection [8].", "startOffset": 144, "endOffset": 147}, {"referenceID": 27, "context": "1) and a precursor have initially been applied to, among others, alignmentfree whole genome phylogeny, [30], [31], [32], chain letter phylogeny [3], constructing language trees [32], and plagiarism detection [8].", "startOffset": 177, "endOffset": 181}, {"referenceID": 7, "context": "1) and a precursor have initially been applied to, among others, alignmentfree whole genome phylogeny, [30], [31], [32], chain letter phylogeny [3], constructing language trees [32], and plagiarism detection [8].", "startOffset": 208, "endOffset": 211}, {"referenceID": 22, "context": "A variant has been experimentally tested on all time sequence data used in all the major data-mining conferences in the last decade [27].", "startOffset": 132, "endOffset": 136}, {"referenceID": 10, "context": "Using the CompLearn package, in [12] we studied hypotheses concerning mammalian evolution, by reconstructing the phylogeny from the mitochondrial genomes of 24 species.", "startOffset": 32, "endOffset": 36}, {"referenceID": 24, "context": "988) was very similar to the definitive tree based on medical-macrobio-genomics analysis, appearing later in the New England Journal of Medicine, [29].", "startOffset": 146, "endOffset": 150}, {"referenceID": 8, "context": "In [10], 100 different H5N1 sample genomes were downloaded from the NCBI/NIH database online, to analyze the geographical spreading of the Bird Flu H5N1 Virus in a large example.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "We also tested gross classification of files based on heterogeneous data of markedly different file types: genomes, novel excerpts, music files in MIDI format, Linux x86 ELF executables, and compiled Java class files, [12].", "startOffset": 218, "endOffset": 222}, {"referenceID": 9, "context": "In [11], MIDI data were used to cluster classical music, distinguish between genres like pop, rock, and classical, and do music classification.", "startOffset": 3, "endOffset": 7}, {"referenceID": 38, "context": "In [43], the CompLearn package was used to analyze network traffic and to cluster computer worms and viruses.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "CompLearn was used to analyze medical clinical data in clustering fetal heart rate tracings [18].", "startOffset": 92, "endOffset": 96}, {"referenceID": 9, "context": "For instance, in many of the references in Google scholar to [11], [12], [13].", "startOffset": 61, "endOffset": 65}, {"referenceID": 10, "context": "For instance, in many of the references in Google scholar to [11], [12], [13].", "startOffset": 67, "endOffset": 71}, {"referenceID": 11, "context": "For instance, in many of the references in Google scholar to [11], [12], [13].", "startOffset": 73, "endOffset": 77}, {"referenceID": 18, "context": "We compared the performance of the MQTC heuristic as implemented in the CompLearn package against that of a leading application to compute phylogenetic trees, a program called SplitsTree [22].", "startOffset": 187, "endOffset": 191}, {"referenceID": 34, "context": "Other methods include [14], [39], [1].", "startOffset": 28, "endOffset": 32}, {"referenceID": 0, "context": "Other methods include [14], [39], [1].", "startOffset": 34, "endOffset": 37}, {"referenceID": 33, "context": "Both NJ [38] and BioNJ [21] are neighbor-joining methods.", "startOffset": 8, "endOffset": 12}, {"referenceID": 17, "context": "Both NJ [38] and BioNJ [21] are neighbor-joining methods.", "startOffset": 23, "endOffset": 27}], "year": 2014, "abstractText": "The Minimum Quartet Tree Cost problem is to construct an optimal weight tree from the 3 (", "creator": "LaTeX with hyperref package"}}}