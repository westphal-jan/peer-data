{"id": "1409.4504", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Sep-2014", "title": "Voting for Deceptive Opinion Spam Detection", "abstract": "Consumers' purchase decisions are increasingly influenced by user-generated online reviews. Accordingly, there has been growing concern about the potential for posting deceptive opinion spam fictitious reviews that have been deliberately written to sound authentic, to deceive the readers. Existing approaches mainly focus on developing automatic supervised learning based methods to help users identify deceptive opinion spams.", "histories": [["v1", "Tue, 16 Sep 2014 05:12:50 GMT  (15kb)", "http://arxiv.org/abs/1409.4504v1", "arXiv admin note: text overlap witharXiv:1204.2804by other authors"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1204.2804by other authors", "reviews": [], "SUBJECTS": "cs.CL cs.SI", "authors": ["tao wang", "hua zhu"], "accepted": false, "id": "1409.4504"}, "pdf": {"name": "1409.4504.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["pwangtao@gmail.com,", "huaz@whu.edu.cn"], "sections": [{"heading": null, "text": "ar Xiv: 140 9.45 04v1 [cs.CL] 1 6SE p20 14"}, {"heading": "1 Introduction", "text": "Consumers are increasingly relying on user-generated online reviews when making a purchase decision (Cone, 2011; Jinsos, 2012). Unfortunately, the simplicity of posting potentially anonymous content on the Web is just one example of creating opportunities and incentives for unscrupulous companies to publish misleading reviews that are deliberately authentic in order to deceive the reader (Ott et al., 2011). For example, a hotel manager might post fake positive reviews to promote his own hotel, or fake negative reviews to demotorize a competing hotel. Accordingly, it appears to be widespread and growing concern for both companies and the public (Meyer, 2009; Miller, 2009; Streitfeld, 2010). Below are two reviews that one deceives and the other is trustworthy. My husband and I arrived for a three-night stay."}, {"heading": "2 Related Work", "text": "Jindal and Liu (2008) first examined the deceptive opinion problem and trained models on features based on the review text, the reviewer, and the product to identify double opinions, i.e. opinions that occur more than once in the corpus with similar contexts. Wu et al. (2010) propose an alternative strategy to detect misleading opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) collected 40 truthful and 42 misleading hotel reviews and compared the linguistic differences between them manually. Ott et al. (2013) created a gold standard collection by employing Turks to write fake reviews, and the follow-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013; Li et al., 2014) identified a gold standard collection by falsifying reviews."}, {"heading": "3 Data Processing", "text": "Before building an n-gram model, we symbolized the text of each review and used porter-stemming algorithms to eliminate the influence of different forms of a word. An n-gram model is a kind of 2-probabilistic language model for predicting the next element in such a sequence in the form of an n-1 Markov model. In our experiment, we established a Uni- and Bigram model.tf-idf TF-IDF, short for the frequency of the document, is a numerical statistic intended to reflect how important a word is to a document in a collection or corpus.The tf-idf value increases proportionally to the number of times a word appears in the document, but is balanced by the frequency of the word in the corpus, which contributes to some words generally being more common than others."}, {"heading": "4 Model", "text": "The power of dimension reduction lies in the fact that it can facilitate later processing, improve computing power, filter useless noise, and restore the underlying causes. In our project, we use LSI for text classification. LSI is based on the assumption that there is an underlying semantic structure in text data and that the relationship between terms and documents can be rewritten in this semantic structural form. Text documents are represented as vectors in a vector space. It is essentially based on SVD, which breaks the original relationship of data into linear independent components, with the original term vectors represented by left singular vectors and document vectors by right singular vectors."}, {"heading": "4.1 Classification", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2 Naive Bayes", "text": "Naive Bayes classifiers are among the most successful known algorithms for learning how to classify text documents. As we know, text classifiers often do not use a deep representation of language: Often a document is presented as a bag of words. It is a very simple representation of documents: it only knows which words are contained in the document and throws away the word order. NB classifiers simply rely on this representation. For a document D and a class C. In our project we have only two classes: fake or real. We classify d as the class with the highest posterior probability P (C - D), which can be expressed anew with Bayes theorem: p (c | d) = p (d | c) p (c) p (d) (2) CMAP = argmaxcP (c | d) = argmaxc P (d) p (d) p (d | c) P (c) (3)."}, {"heading": "4.3 Support Vector Machine", "text": "Support Vector Machines (SVM) (Joachims, 1999) are supervised learning algorithms for pattern recognition and classification of data. Faced with a set of binary training data, an SVM training algorithm builds a model for calculating a hyperplane that separates data into one category or another. SVM's goal is to find a hyperplane that clearly classifies data and simultaneously maximizes the distance of the support vectors to the hyperplane. When implementing SVM, we first process each original document into a vector of features. Such text feature vectors often have a high dimension, but SVM supports quite well the overfit protection, so that performance does not have much impact when the number of features increases."}, {"heading": "4.4 Voting", "text": "The selection scheme, also called the weighted combination of the multiple hypothesis, is used to improve performance when one has different approaches to a particular problem. Although some classifiers are quite powerful, there can still be a misclassification of correct points. On the other hand, we want simple models that free the user from annoying algorithm design. Uncertainty of dimensional selection and quality evaluation complicates classification. This method is more robust than hard-classified text and achieves better performance compared to individual models."}, {"heading": "5 Experimental Results", "text": "In order to better understand the models learned through these automated approaches, we decide to show what SVD captures in LSI analysis. We find the group of words that have the greatest impact on latent concepts. We see that the second concept contributes most to the separation of the fake ratings. We list in the table the highest values that burden the positive (truthful) and negative polar (fake) data of the second concept. We use Sprinkled LSI and LSI to reduce the term-document matrix in various dimensions from 50 to 700. We use SVM to classify the data. The results show that as the dimension increases, so does the training accuracy of two methods, because we have higher functions that give us more information. In addition, test accuracy and precision increases when the dimensions are from 0 to 500. As the dimension continues to increase, the training accuracy increases, while the test accuracy decreases."}, {"heading": "6 Conclusion", "text": "In this paper, we use various methods to analyze and improve the classification of forged ratings based on the work of Myle Ott and Yejin Choi. It shows that the detection of forged ratings by automatic approaches goes far beyond the use of human judges. We first build n-gram models and POS models in combination with SVM and Naive Bayes to detect the deceptive opinion. Similar to Myle Ott and Yejin Chois, n-gram based test categories perform best, suggesting that keyword-based approaches may be necessary in detecting forged ratings. We also used LSI to reduce dimensions and some theoretical analyses. Unlike Myle Ott and Yejin Choi, our result shows that second-person pronouns, rather than the form of the first person, tend to be used in fraudulent ratings. The forged ratings also have the character of lacking concrete nouns and Yejin Choi. In addition, we compare the adjectives of SI and adjectives."}], "references": [{"title": "A reference collection for web spam", "author": ["Debora Donato", "Luca Becchetti", "Paolo Boldi", "Stefano Leonardi", "Massimo Santini", "Sebastiano Vigna"], "venue": "In ACM Sigir Forum,", "citeRegEx": "Castillo et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Castillo et al\\.", "year": 2006}, {"title": "Mailrank: using ranking for spam detection", "author": ["J\u00f6rg Diederich", "Wolfgang Nejdl"], "venue": "In Proceedings of the 14th ACM international conference on Information and knowledge management,", "citeRegEx": "Chirita et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Chirita et al\\.", "year": 2005}, {"title": "Detecting deceptive opinions with profile compatibility", "author": ["Feng", "Hirst2013] Vanessa Wei Feng", "Graeme Hirst"], "venue": "In Proceedings of the 6th International Joint Conference on Natural Language Processing,", "citeRegEx": "Feng et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2013}, {"title": "Syntactic stylometry for deception detection", "author": ["Feng et al.2012] Song Feng", "Ritwik Banerjee", "Yejin Choi"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume", "citeRegEx": "Feng et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2012}, {"title": "Opinion spam and analysis", "author": ["Jindal", "Liu2008] Nitin Jindal", "Bing Liu"], "venue": "In Proceedings of the international conference on Web search and web data mining,", "citeRegEx": "Jindal et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Jindal et al\\.", "year": 2008}, {"title": "Finding unusual review patterns using unexpected rules", "author": ["Jindal et al.2010] Nitin Jindal", "Bing Liu", "Ee-Peng Lim"], "venue": "In Proceedings of the 19th ACM international conference on Information and knowledge management,", "citeRegEx": "Jindal et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jindal et al\\.", "year": 2010}, {"title": "Making large scale svm learning practical", "author": ["Thorsten Joachims"], "venue": null, "citeRegEx": "Joachims.,? \\Q1999\\E", "shortCiteRegEx": "Joachims.", "year": 1999}, {"title": "Learning to identify review spam", "author": ["Li et al.2011] Fangtao Li", "Minlie Huang", "Yi Yang", "Xiaoyan Zhu"], "venue": "In Proceedings of the Twenty-Second international joint conference on Artificial IntelligenceVolume Volume Three,", "citeRegEx": "Li et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Li et al\\.", "year": 2011}, {"title": "Topicspam: a topic-model based approach for spam detection", "author": ["Li et al.2013a] Jiwei Li", "Claire Cardie", "Sujian Li"], "venue": "ACL", "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Identifying manipulated offerings on review portals", "author": ["Li et al.2013b] Jiwei Li", "Myle Ott", "Claire Cardie"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Towards a general rule for identifying deceptive opinion spam", "author": ["Li et al.2014] Jiwei Li", "Myle Ott", "Claire Cardie", "Eduard Hovy"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Detecting product review spammers using rating behaviors", "author": ["Lim et al.2010] Ee-Peng Lim", "Viet-An Nguyen", "Nitin Jindal", "Bing Liu", "Hady Wirawan Lauw"], "venue": "In Proceedings of the 19th ACM international conference on Information and knowledge", "citeRegEx": "Lim et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lim et al\\.", "year": 2010}, {"title": "Web spam identification through language model analysis", "author": ["Martinez-Romo", "Araujo2009] Juan MartinezRomo", "Lourdes Araujo"], "venue": null, "citeRegEx": "Martinez.Romo et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Martinez.Romo et al\\.", "year": 2009}, {"title": "Fake reviews prompt belkin apology", "author": ["David Meyer"], "venue": null, "citeRegEx": "Meyer.,? \\Q2009\\E", "shortCiteRegEx": "Meyer.", "year": 2009}, {"title": "Company settles case of reviews it faked", "author": ["C Miller"], "venue": null, "citeRegEx": "Miller.,? \\Q2009\\E", "shortCiteRegEx": "Miller.", "year": 2009}, {"title": "Detecting group review spam", "author": ["Bing Liu", "Junhui Wang", "Natalie Glance", "Nitin Jindal"], "venue": "In Proceedings of the 20th international conference companion on World wide web,", "citeRegEx": "Mukherjee et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2011}, {"title": "Spotting fake reviewer groups in consumer reviews", "author": ["Bing Liu", "Natalie Glance"], "venue": "In Proceedings of the 21st international conference on World Wide Web,", "citeRegEx": "Mukherjee et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2012}, {"title": "Spotting opinion spammers using behavioral footprints", "author": ["Abhinav Kumar", "Bing Liu", "Junhui Wang", "Meichun Hsu", "Malu Castellanos", "Riddhiman Ghosh"], "venue": "In Proceedings of the 19th ACM SIGKDD interna-", "citeRegEx": "Mukherjee et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2013}, {"title": "Finding deceptive opinion spam by any stretch of the imagination", "author": ["Ott et al.2011] Myle Ott", "Yejin Choi", "Claire Cardie", "Jeffrey T. Hancock"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Lan-", "citeRegEx": "Ott et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ott et al\\.", "year": 2011}, {"title": "Estimating the prevalence of deception in online review communities", "author": ["Ott et al.2012] Myle Ott", "Claire Cardie", "Jeff Hancock"], "venue": "In Proceedings of the 21st international conference on World Wide Web,", "citeRegEx": "Ott et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ott et al\\.", "year": 2012}, {"title": "Negative deceptive opinion spam", "author": ["Ott et al.2013] Myle Ott", "Claire Cardie", "Jeffrey T. Hancock"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Ott et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ott et al\\.", "year": 2013}, {"title": "Historian orlando figes agrees to pay damages for fake reviews", "author": ["A Topping"], "venue": "The Guardian.,", "citeRegEx": "Topping.,? \\Q2010\\E", "shortCiteRegEx": "Topping.", "year": 2010}, {"title": "Review graph based online store review spammer detection", "author": ["Wang et al.2011] Guan Wang", "Sihong Xie", "Bing Liu", "Philip S Yu"], "venue": "In Data Mining (ICDM),", "citeRegEx": "Wang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "Distortion as a validation criterion in the identification of suspicious reviews", "author": ["Wu et al.2010] Guangyu Wu", "Derek Greene", "Barry Smyth", "P\u00e1draig Cunningham"], "venue": "In Proceedings of the First Workshop on Social Media Analytics,", "citeRegEx": "Wu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2010}, {"title": "Comparison of deceptive and truthful travel reviews. In Information and communication technologies in tourism", "author": ["Yoo", "Gretzel2009] Kyung-Hyan Yoo", "Ulrike Gretzel"], "venue": null, "citeRegEx": "Yoo et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yoo et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 18, "context": "Unfortunately, the ease of posting content to the Web, potentially anonymously, create opportunities and incentives for unscrupulous businesses to post deceptive opinion spam fraudulent or fictitious reviews that are deliberately written to sound authentic, in order to deceive the reader (Ott et al., 2011).", "startOffset": 289, "endOffset": 307}, {"referenceID": 13, "context": "Accordingly, there appears to be widespread and growing concern among both businesses and the public (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010).", "startOffset": 101, "endOffset": 161}, {"referenceID": 14, "context": "Accordingly, there appears to be widespread and growing concern among both businesses and the public (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010).", "startOffset": 101, "endOffset": 161}, {"referenceID": 21, "context": "Accordingly, there appears to be widespread and growing concern among both businesses and the public (Meyer, 2009; Miller, 2009; Streitfeld, 2012; Topping, 2010).", "startOffset": 101, "endOffset": 161}, {"referenceID": 5, "context": "rithms to help users identify deceptive opinion spam (Jindal and Liu, 2008; Jindal et al., 2010; Li et al., 2011; Lim et al., 2010; Ott et al., 2011; Wang et al., 2011; Wu et al., 2010).", "startOffset": 53, "endOffset": 185}, {"referenceID": 7, "context": "rithms to help users identify deceptive opinion spam (Jindal and Liu, 2008; Jindal et al., 2010; Li et al., 2011; Lim et al., 2010; Ott et al., 2011; Wang et al., 2011; Wu et al., 2010).", "startOffset": 53, "endOffset": 185}, {"referenceID": 11, "context": "rithms to help users identify deceptive opinion spam (Jindal and Liu, 2008; Jindal et al., 2010; Li et al., 2011; Lim et al., 2010; Ott et al., 2011; Wang et al., 2011; Wu et al., 2010).", "startOffset": 53, "endOffset": 185}, {"referenceID": 18, "context": "rithms to help users identify deceptive opinion spam (Jindal and Liu, 2008; Jindal et al., 2010; Li et al., 2011; Lim et al., 2010; Ott et al., 2011; Wang et al., 2011; Wu et al., 2010).", "startOffset": 53, "endOffset": 185}, {"referenceID": 22, "context": "rithms to help users identify deceptive opinion spam (Jindal and Liu, 2008; Jindal et al., 2010; Li et al., 2011; Lim et al., 2010; Ott et al., 2011; Wang et al., 2011; Wu et al., 2010).", "startOffset": 53, "endOffset": 185}, {"referenceID": 23, "context": "rithms to help users identify deceptive opinion spam (Jindal and Liu, 2008; Jindal et al., 2010; Li et al., 2011; Lim et al., 2010; Ott et al., 2011; Wang et al., 2011; Wu et al., 2010).", "startOffset": 53, "endOffset": 185}, {"referenceID": 5, "context": "One option for producing gold-standard labels, for example, would be to rely on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012).", "startOffset": 115, "endOffset": 160}, {"referenceID": 16, "context": "One option for producing gold-standard labels, for example, would be to rely on the judgements of human annotators (Jindal et al., 2010; Mukherjee et al., 2012).", "startOffset": 115, "endOffset": 160}, {"referenceID": 0, "context": "Recent studies, however, shows that unlike other kinds of spam, such as Web (Castillo et al., 2006; Martinez-Romo and Araujo, 2009) and e-mail spam (Chirita et al.", "startOffset": 76, "endOffset": 131}, {"referenceID": 1, "context": ", 2006; Martinez-Romo and Araujo, 2009) and e-mail spam (Chirita et al., 2005), deceptive opinion spam is neither easily ignored nor easily identified by human readers (Ott et al.", "startOffset": 56, "endOffset": 78}, {"referenceID": 18, "context": ", 2005), deceptive opinion spam is neither easily ignored nor easily identified by human readers (Ott et al., 2011).", "startOffset": 97, "endOffset": 115}, {"referenceID": 18, "context": "(2011) (Ott et al., 2011) solicit deceptive reviews from workers on Amazon Mechanical Turk, and built a dataset containing 400 deceptive and 400 truthful reviews, which they use to train and evaluate supervised SVM classifiers1.", "startOffset": 7, "endOffset": 25}, {"referenceID": 18, "context": "Due to the difficulty in manually labeling deceptive opinion, Ott et al. (2011) (Ott et al.", "startOffset": 62, "endOffset": 80}, {"referenceID": 18, "context": "Our work in this paper started from the dataset, 400 truthful and 400 deceptive reviews, from (Ott et al., 2011; Li et al., 2013a), a large-scale, publicly available dataset for deceptive opinion spam research.", "startOffset": 94, "endOffset": 130}, {"referenceID": 19, "context": "created a gold-standard collection by employing Turkers to write fake reviews, and follow-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013; Li et al., 2014).", "startOffset": 126, "endOffset": 219}, {"referenceID": 20, "context": "created a gold-standard collection by employing Turkers to write fake reviews, and follow-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013; Li et al., 2014).", "startOffset": 126, "endOffset": 219}, {"referenceID": 10, "context": "created a gold-standard collection by employing Turkers to write fake reviews, and follow-up research was based on their data (Ott et al., 2012; Ott et al., 2013; Li et al., 2013b; Feng and Hirst, 2013; Li et al., 2014).", "startOffset": 126, "endOffset": 219}, {"referenceID": 16, "context": "Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard.", "startOffset": 0, "endOffset": 17}, {"referenceID": 16, "context": "Wu et al. (2010) propose an alternative strategy to detect deceptive opinion spam in the absence of a gold standard. Yoo and Gretzel (2009) gathered 40 truthful and 42 deceptive hotel reviews and manually compare the linguistic differences between them.", "startOffset": 0, "endOffset": 140}, {"referenceID": 7, "context": ", 2013; Li et al., 2013b; Feng and Hirst, 2013; Li et al., 2014). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance.", "startOffset": 8, "endOffset": 98}, {"referenceID": 7, "context": ", 2013; Li et al., 2013b; Feng and Hirst, 2013; Li et al., 2014). For example, Song et al. (2012) looked into syntactic features from Context Free Grammar parse trees to improve the classifier performance. A step further, Feng and Hirst (2013) make use of degree of compatibility between the personal experiment and a collection of reference reviews about the same product rather than simple textual features.", "startOffset": 8, "endOffset": 244}, {"referenceID": 17, "context": "In addition to exploring text or linguistic features in deception, some existing work looks into customers\u2019 behavior to identify deception (Mukherjee et al., 2013).", "startOffset": 139, "endOffset": 163}, {"referenceID": 6, "context": "Support Vector Machines(SVM) (Joachims, 1999) are supervised learning algorithms that used to recognize patterns and classify data.", "startOffset": 29, "endOffset": 45}], "year": 2014, "abstractText": "Consumers\u2019 purchase decisions are increasingly influenced by user-generated online reviews. Accordingly, there has been growing concern about the potential for posting deceptive opinion spam fictitious reviews that have been deliberately written to sound authentic, to deceive the readers. Existing approaches mainly focus on developing automatic supervised learning based methods to help users identify deceptive opinion spams. this work, we used the LSI and Sprinkled LSI technique to reduce the dimension for deception detection. We make our contribution to demonstrate what LSI is capturing in latent semantic space and reveal how deceptive opinions can be recognized automatically from truthful opinions. Finally, we proposed a voting scheme which integrates different approaches to further improve the classification performance.", "creator": "LaTeX with hyperref package"}}}