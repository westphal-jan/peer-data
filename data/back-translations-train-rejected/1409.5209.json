{"id": "1409.5209", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Sep-2014", "title": "Pedestrian Detection with Spatially Pooled Features and Structured Ensemble Learning", "abstract": "Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured output learning.", "histories": [["v1", "Thu, 18 Sep 2014 07:14:33 GMT  (387kb,D)", "https://arxiv.org/abs/1409.5209v1", "14 pages"], ["v2", "Wed, 15 Oct 2014 02:35:33 GMT  (387kb,D)", "http://arxiv.org/abs/1409.5209v2", "17 pages"], ["v3", "Sun, 28 Jun 2015 10:15:37 GMT  (857kb,D)", "http://arxiv.org/abs/1409.5209v3", "19 pages"]], "COMMENTS": "14 pages", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["sakrapee paisitkriangkrai", "chunhua shen", "anton van den hengel"], "accepted": false, "id": "1409.5209"}, "pdf": {"name": "1409.5209.pdf", "metadata": {"source": "CRF", "title": "Pedestrian Detection with Spatially Pooled Features and Structured Ensemble Learning", "authors": ["Sakrapee Paisitkriangkrai", "Chunhua Shen", "Anton van den Hengel"], "emails": ["chunhua.shen@adelaie.edu.au)."], "sections": [{"heading": null, "text": "Index terms - recognition of pedestrians, promotion, ensemble learning, spatial pooling, structured learning.F"}, {"heading": "1 INTRODUCTION", "text": "It is one of several basic topics in the field of computer visualization. The task of pedestrian detection is to identify the visible pedestrians in a particular area by gaining knowledge gained by analyzing a number of marked pedestrians and non-pedestrians. However, the problem is complicated by the inevitable variation in appearance, lighting and pose, and by occlusion. In a recent literature study on pedestrian detection, the authors evaluated several pedestrian detectors and concluded that the combination of several features can increase pedestrian performance [1]. Handcrafted low visual features have been applied to several computer applications and have shown promising results [2]."}, {"heading": "1.1 Main contributions", "text": "The main contributions of our work can be summarized as follows: \u2022 We propose a novel approach to extract low levels based on spatial poolings for the problem of pedestrian recognition. \u2022 We show that spatial poolings are able to focus on the development of concepts. \u2022 We show that spatial conditions are able to adapt to the needs of people. \u2022 The method is of particular interest to the accuracy of pedestrians."}, {"heading": "1.2 Related work", "text": "This year, the time has come for an agreement to be reached, and it will only take a few days."}, {"heading": "1.3 Notation", "text": "Vectors are denoted by bold lowercase letters, e.g. x, matrices are denoted by bold uppercase letters, e.g. X and sentences are denoted by calligraphic uppercase letters, e.g. X. All vectors are assumed to be column vectors. (i, j) input of X is xij. Let {x + i} mi = 1 be a set of study examples for pedestrians, {x \u2212 j} nj = 1 be a set of study examples for non-pedestrians, and x Rd be a d-dimensional feature vector. The tuple of all study samples is written as S = (S +, S \u2212), where S + (x +, \u00b7, x + m). Xm and S \u2212 \u2212 (x \u2212 1, \u00b7 n) are study examples for non-pedestrians, and x \u2212 n)."}, {"heading": "2 OUR APPROACH", "text": "Despite some important work on object detection, the most practical and successful pedestrian detector is still the sliding window-based Viola and Jones method [5]. Their method consists of two main components: feature extraction and the AdaBoost classifier. For pedestrian detection, the most commonly used features are HOG [2] and HOG + LBP [4]. Dolla \u0301 r et al. suggest Aggregated Channel Features (ACF), which combine gradient histogram (a variant of HOG), gradient, and LUV [37]. ACF uses the same channel features as ChnFtrs [35], which are demonstrably better than HOG [34], [35].To train the classifier, the method known as boot strapping is often used, harvesting hard negative examples and retraining the classifier. Bootstrapping can be repeated several times."}, {"heading": "2.1 Spatially pooled features", "text": "It has been proven that spatial networking is invariant over various image transformations and can demonstrate improved robustness over noise. [16], [23], [24], [23], [24], [24] Several empirical results have shown that a pooling process can greatly improve detection performance, while merging multiple visual descriptors incorporated in nearby locations into some statistics that better summarize characteristics across a particular region of interest. While the new feature representation preserves visual information about a local neighborhood while discarding irrelevant details and noises, combining these features with unmonitored learning methods has resulted in state-of-the-art image recognition performance across multiple object recognition tasks. Although these learning methods have shown promising results about craftsmanship characteristics, computing these characteristics from learned dictionaries is still a time-consuming process for many real-world applications, we are improving the overall performance of this learning section by adopting them from lower functionality."}, {"heading": "2.2 Optimizing partial AUC", "text": "Before proposing our approach, we briefly review the concept of SVM tightpAUC (\u03b2 \u03b2) = \u03b2 (\u03b2 \u03b2) constant (\u03b2 \u03b2) [32], in which our ensemble learning approach is built. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 The area below the empirical ROC curve (AUC) can be defined as, AUC = 1mn m \u2211 i = 1 n \u2211 j = 1 (f (x + i) > f (x \u2212 j). (1) The goal is to learn a scoring function f, f: Rd \u2192 R, which maximizes AUC, or equivalent, minimizes the empirical risk f = 1 (f), RAUC (f) = 1 \u2212 AUC. (2) For the partial AUC (pAUC) in the false positive range [\u03b1], \u03b2] the empirical pAUC risk can be written as [32]: RpAUC risk can be written as (f) = 1c: RAUC (1f)."}, {"heading": "2.3 Region proposals generation", "text": "The evaluation of our pedestrian detector outlined in the previous subsections can be efficiently calculated using integral channel characteristics [35]. However, the detector is still not efficient enough to be used in a sliding window-based framework. To improve the evaluation time, we adopt a cascading approach in which classifiers are arranged based on their complexity. In this paper, we adopt a two-step approach in which we extract the fast characteristics in the first stage and our proposed characteristics with pAUCEnsT in the second stage. In other words, our proposed detector is evaluated only on test samples that go through the first stage."}, {"heading": "3 EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Spatially pooled features", "text": "This year we will be in a position to put ourselves at the top, \"he said."}, {"heading": "3.2 Ensemble classifier", "text": "This year, it has reached the stage where it will be able to solve the problems mentioned, but not yet able to solve the problems mentioned in order to solve them."}, {"heading": "3.3 Pedestrian detection", "text": "We evaluate the performance of our pedestrian detector based on 32 pixels. We train the pedestrian detector based on three different image qualities based on the KITTI Vision Benchmark Suite [66] and the Caltech USA pedestrian dataset was captured by two high-resolution stereo camera systems mounted on a vehicle. The vehicle was driven around a medium-sized city and saved in portable network graphics (PNG) format. The dataset consists of 7481 training images and 7518 test images. To obtain positive training data for the KITTI dataset, we collected 2111 fully visible pedestrians from 7481 training images. We augment the positive training data by reversing the pedestrian axis. Negative patches are collected from the KITTI training set with pedestrians, cyclists and \"don't care regions.\""}, {"heading": "4 CONCLUSION", "text": "In this paper, we have proposed an approach to enhancing the effectiveness of low visual characteristics and formulated a new learning method for object recognition, combining the proposed approach with efficient application generation leading to an effective classifier that optimizes the average error rate. Extensive experiments demonstrate the effectiveness of the proposed approach for both synthetic data and visual recognition tasks. We plan to explore the possibility of applying the proposed approach to the multi-scale detector of [70] in order to improve the detection results of low-resolution pedestrian images."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work was partially supported by the Data to Decisions Cooperative Research Centre. C. Shen's participation was partially supported by a Future Fellowship from the Australian Research Council. C. Shen is the corresponding Author.16APPENDIX"}, {"heading": "4.1 Convergence analysis of Algorithm 1", "text": "In this appendix, we offer a theoretical analysis of the convergence characteristic for structured ensemble learning in this paper.The main result is as follows: Proposition 3. With each iteration of algorithm 1, the objective value decreases. Proof: We assume that the current solution is a finite subset of weak learners and their corresponding coefficients. If this happens, the current solution w is already the optimal solution - you are not able to find another weak learner to decrease the objective value. Now, if the corresponding w solution is not zero, we have added another free variable to the primary master problem and need the objective value. With the next proposition, we show that the convergence of algorithm 1 is a guaranteed problem."}], "references": [{"title": "Pedestrian detection: An evaluation of the state of the art", "author": ["P. Doll\u00e1r", "C. Wojek", "B. Schiele", "P. Perona"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 4, pp. 743\u2013761, 2012. 1, 3, 12, 13", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., vol. 1, 2005. 1, 4, 10, 13, 14", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Pedestrian detection via classification on Riemannian manifolds", "author": ["O. Tuzel", "F. Porikli", "P. Meer"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 10, pp. 1713\u20131727, 2008. 1, 2, 5, 10, 11", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "An HOG-LBP human detector with partial occlusion handling", "author": ["X. Wang", "T.X. Han", "S. Yan"], "venue": "Proc. IEEE Int. Conf. Comp. Vis., 2009. 1, 2, 4, 5, 10, 11", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Robust real-time face detection", "author": ["P. Viola", "M.J. Jones"], "venue": "Int. J. Comp. Vis., vol. 57, no. 2, pp. 137\u2013154, 2004. 1, 4, 9, 10, 12, 13", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "Linear spatial pyramid matching using sparse coding for image classification", "author": ["J. Yang", "K. Yu", "Y. Gong", "T. Huang"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2009. 1, 6", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Pedestrian detection with unsupervised multi-stage feature learning", "author": ["P. Sermanet", "K. Kavukcuoglu", "S. Chintala", "Y. LeCun"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2013. 1, 3", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Exploring weak stabilization for motion feature extraction", "author": ["D. Park", "C.L. Zitnick", "D. Ramanan", "P. Doll\u00e1r"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2013. 1, 4, 13", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Regionlets for generic object detection", "author": ["X. Wang", "M. Yang", "S. Zhu", "Y. Lin"], "venue": "Proc. IEEE Int. Conf. Comp. Vis., 2013. 1", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Efficient pedestrian detection by directly optimizing the partial area under the ROC curve", "author": ["S. Paisitkriangkrai", "C. Shen", "A. van den Hengel"], "venue": "Proc. IEEE Int. Conf. Comp. Vis., 2013. 2, 3, 9, 10, 11, 17", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Strengthening the effectiveness of pedestrian detection with spatially pooled features", "author": ["\u2014\u2014"], "venue": "Proc. Eur. Conf. Comp. Vis., 2014. 2, 3, 10", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Bing: Binarized normed gradients for objectness estimation at 300fps", "author": ["M.-M. Cheng", "Z. Zhang", "W.-Y. Lin", "P. Torr"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2014. 3, 10", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Object detection with discriminatively trained part based models", "author": ["P. Felzenszwalb", "R. Girshick", "D. McAllester", "D. Ramanan"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 32, no. 9, pp. 1627\u2013 1645, 2010. 3, 13", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Modeling mutual visibility relationship with a deep model in pedestrian detection", "author": ["W. Ouyang", "X. Zeng", "X. Wang"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2013. 3, 13", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Localityconstrained linear coding for image classification", "author": ["J. Wang", "J. Yang", "K. Yu", "F. Lv", "T. Huang", "Y. Gong"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2010. 3", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "The devil is in the details: an evaluation of recent feature encoding methods", "author": ["K. Chatfield", "V. Lempitsky", "A. Vedaldi", "A. Zisserman"], "venue": "Proc. of British Mach. Vis. Conf., 2011. 3, 5, 6", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "Proc. Adv. Neural Inf. Process. Syst., 2012. 3", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Return of the devil in the details: Delving deep into convolutional nets", "author": ["K. Chatfield", "K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "Proc. British Conf. Mach. Vis., 2014. 3", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, vol. 86, no. 11, p. 22782324, 1998. 3", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1998}, {"title": "Learning deep architectures for ai", "author": ["Y. Bengio"], "venue": "Foundations and trends R  \u00a9 in Machine Learning, vol. 2, no. 1, pp. 1\u2013127, 2009. 3", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Deep convolutional neural fields for depth estimation from a single image", "author": ["F. Liu", "C. Shen", "G. Lin"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2015. 3", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "The treasure beneath convolutional layers: cross convolutional layer pooling for image classification", "author": ["L. Liu", "C. Shen", "A. van den Hengel"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2015. 3", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "The importance of encoding versus training with sparse coding and vector quantization", "author": ["A. Coates", "A. Ng"], "venue": "Proc. Int. Conf. Mach. Learn., 2011. 3, 5", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Ask the locals: multi-way local pooling for image recognition", "author": ["Y. Boureau", "N.L. Roux", "F. Bach", "J. Ponce", "Y. LeCun"], "venue": "Proc. IEEE Int. Conf. Comp. Vis., 2011. 3, 5", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Fast and robust classification using asymmetric AdaBoost and a detector cascade", "author": ["P. Viola", "M. Jones"], "venue": "Proc. Adv. Neural Inf. Process. Syst. MIT Press, 2002, pp. 1311\u20131318. 3, 11, 12", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2002}, {"title": "Fast pedestrian detection using a cascade of boosted covariance features", "author": ["S. Paisitkriangkrai", "C. Shen", "J. Zhang"], "venue": "IEEE Trans. Circuits & Syst. for Vid. Tech., vol. 18, no. 8, 2008. 3", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "Cost-sensitive boosting", "author": ["H. Masnadi-Shirazi", "N. Vasconcelos"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 33, no. 2, pp. 294\u2013309, 2011. 3, 11", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2011}, {"title": "The linear combinations of biomarkers which maximize the partial area under the roc curves", "author": ["M.-J. Hsu", "H.-M. Hsueh"], "venue": "Comp. Stats., vol. 28, no. 2, pp. 1\u201320, 2012. 3", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "A boosting method for maximizing the partial area under the roc curve", "author": ["O. Komori", "S. Eguchi"], "venue": "BMC Bioinformatics, vol. 11, no. 1, p. 314, 2010. 3, 11", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Combining diagnostic test results to increase accuracy", "author": ["M.S. Pepe", "M.L. Thompson"], "venue": "Biostatistics, vol. 1, no. 2, pp. 123\u2013140, 2000. 3", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2000}, {"title": "A structural svm based approach for optimizing partial AUC", "author": ["H. Narasimhan", "S. Agarwal"], "venue": "Proc. Int. Conf. Mach. Learn., 2013. 3, 8, 11", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "SVM  pAUC: a new support vector method for optimizing partial AUC based on a tight convex upper bound", "author": ["\u2014\u2014"], "venue": "ACM Int. Conf. on Knowl. disc. and data mining, 2013. 3, 6, 7, 8, 9, 11, 12", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}, {"title": "Asymmetric support vector machines: low false-positive learning under the user tolerance", "author": ["S.-H. Wu", "K.-P. Lin", "C.-M. Chen", "M.-S. Chen"], "venue": "Proc. of Intl. Conf. on Knowledge Discovery and Data Mining, 2008. 3, 11", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}, {"title": "Seeking the strongest rigid detector", "author": ["R. Benenson", "M. Mathias", "T. Tuytelaars", "L.V. Gool"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2013. 4, 10, 13, 14", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Integral channel features", "author": ["P. Doll\u00e1r", "Z. Tu", "P. Perona", "S. Belongie"], "venue": "Proc. of British Mach. Vis. Conf., 2009. 4, 10, 12, 13", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "Discriminative models for multi-class object layout", "author": ["C. Desai", "D. Ramanan", "C. Fowlkes"], "venue": "Int. J. Comp. Vis., vol. 95, pp. 1\u201312, 2011. 4", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "Fast feature pyramids for object detection", "author": ["P. Doll\u00e1r", "R. Appel", "S. Belongie", "P. Perona"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. PP, no. 99, p. 1, 2014. 4, 11, 13", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "New features and insights for pedestrian detection", "author": ["S. Walk", "N. Majer", "K. Schindler", "B. Schiele"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., San Francisco, US, 2010. 4, 13", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2010}, {"title": "Multiresolution grayscale and rotation invariant texture classification with local binary patterns", "author": ["T. Ojala", "M. Pietikainen", "T. Maenpaa"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 24, no. 7, pp. 971\u2013987, 2002. 5", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2002}, {"title": "Region covariance: A fast descriptor for detection and classification", "author": ["O. Tuzel", "F. Porikli", "P. Meer"], "venue": "Proc. Eur. Conf. Comp. Vis., 2006. 5", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2006}, {"title": "Beyond spatial pyramids: Receptive field learning for pooled image features", "author": ["Y. Jia", "C. Huang", "T. Darrell"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2012. 5", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "Multipath sparse coding using hierarchical matching pursuit", "author": ["L. Bo", "X. Ren", "D. Fox"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2013. 6", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2013}, {"title": "Linear programming boosting via column generation", "author": ["A. Demiriz", "K. Bennett", "J. Shawe-Taylor"], "venue": "Mach. Learn., vol. 46, no. 1\u20133, pp. 225\u2013254, 2002. 7", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2002}, {"title": "Boosting learning algorithm for pattern recognition and beyond", "author": ["O. Komori", "S. Eguchi"], "venue": "IEICE Trans. Infor. and Syst., vol. 94, no. 10, pp. 1863\u20131869, 2011. 8", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1863}, {"title": "Cutting-plane training of structural svms", "author": ["T. Joachims", "T. Finley", "C.-N.J. Yu"], "venue": "Mach. Learn., vol. 77, no. 1, pp. 27\u201359, 2009. 8, 9, 11", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2009}, {"title": "Quickly boosting decision trees pruning underachieving features early", "author": ["R. Appel", "T. Fuchs", "P. Doll\u00e1r", "P. Perona"], "venue": "Proc. Int. Conf. Mach. Learn., 2013. 8", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2013}, {"title": "Training linear svms in linear time", "author": ["T. Joachims"], "venue": "Proc. of Intl. Conf. on Knowledge Discovery and Data Mining, 2006. 9", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2006}, {"title": "Measuring the objectness of image windows", "author": ["B. Alexe", "T. Deselaers", "V. Ferrari"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 11, pp. 2189\u20132202, 2012. 10", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2012}, {"title": "Selective search for object recognition", "author": ["J. Uijlings", "K. van de Sande", "T. Gevers", "A.W. Smeulders"], "venue": "Int. J. Comp. Vis., vol. 104, no. 2, pp. 154\u2013171, 2013. 10", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2013}, {"title": "The Elements of Statistical Learning: Prediction, Inference and Data Mining", "author": ["T. Hastie", "R. Tibshirani", "J. Friedman"], "venue": null, "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2009}, {"title": "Additive logistic regression: a statistical view of boosting", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": "Ann. Stat., vol. 28, no. 2, pp. 337\u2013407, 2000. 10", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2000}, {"title": "A mobile vision system for robust multi-person tracking", "author": ["A. Ess", "B. Leibe", "K. Schindler", "L. van Gool"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2008. 10", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2008}, {"title": "Multi-cue onboard pedestrian detection", "author": ["C. Wojek", "S. Walk", "B. Schiele"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2009. 10", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2009}, {"title": "Evaluation of different biological data and computational classification methods for use in protein interaction prediction", "author": ["Y. Qi", "Z. Bar-Joseph", "J. Klein-Seetharaman"], "venue": "Proteins: Struct., Func., and Bioinfor., vol. 63, no. 3, pp. 490\u2013500, 2006. 11", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2006}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin"], "venue": "J. Mach. Learn. Res., vol. 9, pp. 1871\u20131874, 2008. 11", "citeRegEx": "55", "shortCiteRegEx": null, "year": 1871}, {"title": "Fast asymmetric learning for cascade face detection", "author": ["J. Wu", "S.C. Brubaker", "M.D. Mullin", "J.M. Rehg"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 3, pp. 369\u2013382, 2008. 12", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2008}, {"title": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., New York City, USA, 2006. 12", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2006}, {"title": "CENTRIST: A visual descriptor for scene categorization", "author": ["J. Wu", "J.M. Rehg"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 33, no. 8, pp. 1489\u20131501, 2011. 12", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2011}, {"title": "Hierarchical adaptive structural svm for domain adaptation", "author": ["J. Xu", "S. Ramos", "D. Vazquez", "A. Lopez"], "venue": "arXiv preprint arXiv:1408.5400, 2014. 13", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2014}, {"title": "Joint 3d estimation of objects and scene layout", "author": ["A. Geiger", "C. Wojek", "R. Urtasun"], "venue": "Proc. Adv. Neural Inf. Process. Syst., 2011. 13", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2011}, {"title": "Laser-based segment classification using a mixture of bag-of-words", "author": ["J. Behley", "V. Steinhage", "A. Cremers"], "venue": "Proc. Int. Conf. Intel. Robots and Syst., 2013. 13", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2013}, {"title": "Robust multiresolution pedestrian detection in traffic scenes", "author": ["J. Yan", "X. Zhang", "Z. Lei", "S. Liao", "S.Z. Li"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2013. 13", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2013}, {"title": "Single-pedestrian detection aided by multi-pedestrian detection", "author": ["W. Ouyang", "X. Wang"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2013. 13", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2013}, {"title": "Detection evolution with multi-order contextual co-occurrence.", "author": ["G. Chen", "Y. Ding", "J. Xiao", "T. Han"], "venue": "in Proc. IEEE Conf. Comp. Vis. Patt. Recogn.,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2013}, {"title": "Multiresolution models for object detection", "author": ["D. Park", "D. Ramanan", "C. Fowlkes"], "venue": "Proc. Eur. Conf. Comp. Vis., 2010. 13", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2010}, {"title": "Are we ready for autonomous driving? The KITTI vision benchmark suite", "author": ["A. Geiger", "P. Lenz", "R. Urtasun"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2012. 12", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2012}, {"title": "Beyond pixels: Exploring new representations and applications for motion analysis", "author": ["C. Liu"], "venue": "Ph.D. dissertation, Massachusetts Institute of Technology, 2009. 13", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2009}, {"title": "Human detection using oriented histograms of flow and appearance", "author": ["N. Dalal", "B. Triggs", "C. Schmid"], "venue": "Proc. Eur. Conf. Comp. Vis., 2006. 13", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2006}, {"title": "Robust object detection via soft cascade", "author": ["L. Bourdev", "J. Brandt"], "venue": "Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2005. 14", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "In a recent literature survey on pedestrian detection, the authors evaluated several pedestrian detectors and concluded that combining multiple features can significantly boost the performance of pedestrian detection [1].", "startOffset": 217, "endOffset": 220}, {"referenceID": 1, "context": "Hand-crafted low-level visual features have been applied to several computer vision applications and shown promising results [2], [3], [4], [5].", "startOffset": 125, "endOffset": 128}, {"referenceID": 2, "context": "Hand-crafted low-level visual features have been applied to several computer vision applications and shown promising results [2], [3], [4], [5].", "startOffset": 130, "endOffset": 133}, {"referenceID": 3, "context": "Hand-crafted low-level visual features have been applied to several computer vision applications and shown promising results [2], [3], [4], [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 4, "context": "Hand-crafted low-level visual features have been applied to several computer vision applications and shown promising results [2], [3], [4], [5].", "startOffset": 140, "endOffset": 143}, {"referenceID": 5, "context": "Inspired by the recent success of spatial pooling on object recognition and pedestrian detection problems [6], [7], [8], [9], we propose to perform the spatial pooling operation to create the new feature type for the task of pedestrian detection.", "startOffset": 106, "endOffset": 109}, {"referenceID": 6, "context": "Inspired by the recent success of spatial pooling on object recognition and pedestrian detection problems [6], [7], [8], [9], we propose to perform the spatial pooling operation to create the new feature type for the task of pedestrian detection.", "startOffset": 111, "endOffset": 114}, {"referenceID": 7, "context": "Inspired by the recent success of spatial pooling on object recognition and pedestrian detection problems [6], [7], [8], [9], we propose to perform the spatial pooling operation to create the new feature type for the task of pedestrian detection.", "startOffset": 116, "endOffset": 119}, {"referenceID": 8, "context": "Inspired by the recent success of spatial pooling on object recognition and pedestrian detection problems [6], [7], [8], [9], we propose to perform the spatial pooling operation to create the new feature type for the task of pedestrian detection.", "startOffset": 121, "endOffset": 124}, {"referenceID": 0, "context": "0 false positives per image [1].", "startOffset": 28, "endOffset": 31}, {"referenceID": 2, "context": "We show that spatial pooling applied to commonly-used features such as covariance features [3] and LBP descriptors [4] improves accuracy of pedestrian detection.", "startOffset": 91, "endOffset": 94}, {"referenceID": 3, "context": "We show that spatial pooling applied to commonly-used features such as covariance features [3] and LBP descriptors [4] improves accuracy of pedestrian detection.", "startOffset": 115, "endOffset": 118}, {"referenceID": 9, "context": "Early versions of our work [10] introduced a pAUCbased node classifier for cascade classification, which optimizes the detection rate in the FPR range around [0.", "startOffset": 27, "endOffset": 31}, {"referenceID": 10, "context": "and the low-level visual features based on spatial pooling [11].", "startOffset": 59, "endOffset": 63}, {"referenceID": 9, "context": "risk compared to [10].", "startOffset": 17, "endOffset": 21}, {"referenceID": 11, "context": "A region proposals generation, known as binarized normed gradients (BING) [12], is applied to speed up the evaluation time of detector.", "startOffset": 74, "endOffset": 78}, {"referenceID": 9, "context": "This leads to a further improvement in accuracy and evaluation time as compared to [10], [11].", "startOffset": 83, "endOffset": 87}, {"referenceID": 10, "context": "This leads to a further improvement in accuracy and evaluation time as compared to [10], [11].", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "Our new detection framework outperforms all reported pedestrian detectors (at the time of submission), including several complex detectors such as LatSVM [13] (a part-based approach which models unknown parts as latent variables), ConvNet [7] (deep hierarchical models) and DBN-Mut [14] (discriminative deep model with mutual visibility relationship).", "startOffset": 154, "endOffset": 158}, {"referenceID": 6, "context": "Our new detection framework outperforms all reported pedestrian detectors (at the time of submission), including several complex detectors such as LatSVM [13] (a part-based approach which models unknown parts as latent variables), ConvNet [7] (deep hierarchical models) and DBN-Mut [14] (discriminative deep model with mutual visibility relationship).", "startOffset": 239, "endOffset": 242}, {"referenceID": 13, "context": "Our new detection framework outperforms all reported pedestrian detectors (at the time of submission), including several complex detectors such as LatSVM [13] (a part-based approach which models unknown parts as latent variables), ConvNet [7] (deep hierarchical models) and DBN-Mut [14] (discriminative deep model with mutual visibility relationship).", "startOffset": 282, "endOffset": 286}, {"referenceID": 0, "context": "We refer readers to [1] for an excellent review on pedestrian detection frameworks and benchmark data sets.", "startOffset": 20, "endOffset": 23}, {"referenceID": 0, "context": "In this section, we briefly discuss some relevant work on object detection and review several recent state-of-the-art pedestrian detectors that are not covered in [1].", "startOffset": 163, "endOffset": 166}, {"referenceID": 14, "context": ", Pascal VOC, Scene-15, Caltech, ImageNet [15], [16], [17], [18].", "startOffset": 42, "endOffset": 46}, {"referenceID": 15, "context": ", Pascal VOC, Scene-15, Caltech, ImageNet [15], [16], [17], [18].", "startOffset": 48, "endOffset": 52}, {"referenceID": 16, "context": ", Pascal VOC, Scene-15, Caltech, ImageNet [15], [16], [17], [18].", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": ", Pascal VOC, Scene-15, Caltech, ImageNet [15], [16], [17], [18].", "startOffset": 60, "endOffset": 64}, {"referenceID": 18, "context": "The use of spatial pooling has long been part of recognition architectures such as convolutional networks [19], [20], [21], [22].", "startOffset": 106, "endOffset": 110}, {"referenceID": 19, "context": "The use of spatial pooling has long been part of recognition architectures such as convolutional networks [19], [20], [21], [22].", "startOffset": 112, "endOffset": 116}, {"referenceID": 20, "context": "The use of spatial pooling has long been part of recognition architectures such as convolutional networks [19], [20], [21], [22].", "startOffset": 118, "endOffset": 122}, {"referenceID": 21, "context": "The use of spatial pooling has long been part of recognition architectures such as convolutional networks [19], [20], [21], [22].", "startOffset": 124, "endOffset": 128}, {"referenceID": 22, "context": "Spatial pooling is general and can be applied to various coding methods, such as sparse coding, orthogonal matching pursuit and soft threshold [23].", "startOffset": 143, "endOffset": 147}, {"referenceID": 14, "context": "propose to compute an image representation based on sparse codes of SIFT features with multi-scale spatial max pooling [15].", "startOffset": 119, "endOffset": 123}, {"referenceID": 23, "context": "transform the pooling process to be more selective by applying pooling in both image space and descriptor space [24].", "startOffset": 112, "endOffset": 116}, {"referenceID": 24, "context": "Classifiers that are optimal under the symmetric cost, and thus treat false positives and negatives equally, cannot exploit this information [25], [26].", "startOffset": 141, "endOffset": 145}, {"referenceID": 25, "context": "Classifiers that are optimal under the symmetric cost, and thus treat false positives and negatives equally, cannot exploit this information [25], [26].", "startOffset": 147, "endOffset": 151}, {"referenceID": 24, "context": "Viola and Jones introduced the asymmetry property in Asymetric AdaBoost (AsymBoost) [25].", "startOffset": 84, "endOffset": 88}, {"referenceID": 26, "context": "Masnadi-Shirazi and Vasconcelos [27] proposed a cost-sensitive boosting algorithm based on the statistical interpretation of boosting.", "startOffset": 32, "endOffset": 36}, {"referenceID": 27, "context": "Several algorithms that directly optimize the pAUC score have been proposed in bioinformatics [28], [29].", "startOffset": 94, "endOffset": 98}, {"referenceID": 28, "context": "Several algorithms that directly optimize the pAUC score have been proposed in bioinformatics [28], [29].", "startOffset": 100, "endOffset": 104}, {"referenceID": 29, "context": "Dodd and Pepe propose a regression modeling framework based on the pAUC score [30].", "startOffset": 78, "endOffset": 82}, {"referenceID": 28, "context": "Komori and Eguchi optimize the pAUC using boosting-based algorithms [29].", "startOffset": 68, "endOffset": 72}, {"referenceID": 30, "context": "Narasimhan and Agarwal develop structural SVM based methods which directly optimize the pAUC score [31], [32].", "startOffset": 99, "endOffset": 103}, {"referenceID": 31, "context": "Narasimhan and Agarwal develop structural SVM based methods which directly optimize the pAUC score [31], [32].", "startOffset": 105, "endOffset": 109}, {"referenceID": 28, "context": "They demonstrate that their approaches significantly outperform several existing algorithms, including pAUCBoost [29] and asymmetric SVM [33].", "startOffset": 113, "endOffset": 117}, {"referenceID": 32, "context": "They demonstrate that their approaches significantly outperform several existing algorithms, including pAUCBoost [29] and asymmetric SVM [33].", "startOffset": 137, "endOffset": 141}, {"referenceID": 30, "context": "It is important to emphasize here the difference between our approach and that of [31].", "startOffset": 82, "endOffset": 86}, {"referenceID": 30, "context": "In [31] the authors train a linear structural SVM while our approach learns the ensemble of classifiers.", "startOffset": 3, "endOffset": 7}, {"referenceID": 6, "context": "train a pedestrian detector using a convolutional network model [7].", "startOffset": 64, "endOffset": 67}, {"referenceID": 33, "context": "investigate different lowlevel aspects of pedestrian detection [34].", "startOffset": 63, "endOffset": 67}, {"referenceID": 7, "context": "propose new motion features for detecting pedestrians in a video sequence [8].", "startOffset": 74, "endOffset": 77}, {"referenceID": 34, "context": "By factoring out camera motion and combining their proposed motion features with channel features [35], the new detector achieves a five-fold reduction in false positives over previous best results on the Caltech pedestrian benchmark.", "startOffset": 98, "endOffset": 102}, {"referenceID": 35, "context": "[36].", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "Although both our approach and [36] cast the problem as a structured prediction and apply the cutting plane optimization, the underlying assumptions and resulting models are quite different.", "startOffset": 31, "endOffset": 35}, {"referenceID": 35, "context": "The formulation of [36] focuses on incorporating geometric configurations between multiple object classes instead of optimizing the detection rate within a prescribed false positive range.", "startOffset": 19, "endOffset": 23}, {"referenceID": 35, "context": "In addition, it is not trivial to extend the formulation of [36] to boosting setting.", "startOffset": 60, "endOffset": 64}, {"referenceID": 4, "context": "Despite several important work on object detection, the most practical and successful pedestrian detector is still the sliding-window based method of Viola and Jones [5].", "startOffset": 166, "endOffset": 169}, {"referenceID": 1, "context": "For pedestrian detection, the most commonly used features are HOG [2] and HOG+LBP [4].", "startOffset": 66, "endOffset": 69}, {"referenceID": 3, "context": "For pedestrian detection, the most commonly used features are HOG [2] and HOG+LBP [4].", "startOffset": 82, "endOffset": 85}, {"referenceID": 36, "context": "propose Aggregated Channel Features (ACF) which combine gradient histogram (a variant of HOG), gradients and LUV [37].", "startOffset": 113, "endOffset": 117}, {"referenceID": 34, "context": "ACF uses the same channel features as ChnFtrs [35], which is shown to outperform HOG [34], [35].", "startOffset": 46, "endOffset": 50}, {"referenceID": 33, "context": "ACF uses the same channel features as ChnFtrs [35], which is shown to outperform HOG [34], [35].", "startOffset": 85, "endOffset": 89}, {"referenceID": 34, "context": "ACF uses the same channel features as ChnFtrs [35], which is shown to outperform HOG [34], [35].", "startOffset": 91, "endOffset": 95}, {"referenceID": 37, "context": "It is shown in [38] that at least two bootstrapping iterations are required for the classifier to achieve good performance.", "startOffset": 15, "endOffset": 19}, {"referenceID": 36, "context": "Finally, we discuss our modifications to [37] in order to achieve state-of-theart detection results on Caltech pedestrian detection benchmark data sets.", "startOffset": 41, "endOffset": 45}, {"referenceID": 15, "context": "robustness to noise [16], [23], [24].", "startOffset": 20, "endOffset": 24}, {"referenceID": 22, "context": "robustness to noise [16], [23], [24].", "startOffset": 26, "endOffset": 30}, {"referenceID": 23, "context": "robustness to noise [16], [23], [24].", "startOffset": 32, "endOffset": 36}, {"referenceID": 2, "context": "In this paper, we follow the feature representation as proposed in [3].", "startOffset": 67, "endOffset": 70}, {"referenceID": 2, "context": "(M = \u221a I2 x + I 2 y ), edge orientation as in [3] (O1 = arctan(|Iy|/|Ix|)) and an additional edge orientation O2 in which,", "startOffset": 46, "endOffset": 49}, {"referenceID": 38, "context": "Local Binary Pattern (LBP) is a texture descriptor that represents the binary code of each image patch into a feature histogram [39].", "startOffset": 128, "endOffset": 132}, {"referenceID": 38, "context": "The LBP descriptor has shown to achieve good performance in many texture classification [39].", "startOffset": 88, "endOffset": 92}, {"referenceID": 3, "context": "In this work, we adopt an extension of LBP, known as the uniform LBP, which can better filter out noises [4].", "startOffset": 105, "endOffset": 108}, {"referenceID": 22, "context": "We use max-pooling as it has been shown to outperform average pooling in image classification [23], [24].", "startOffset": 94, "endOffset": 98}, {"referenceID": 23, "context": "We use max-pooling as it has been shown to outperform average pooling in image classification [23], [24].", "startOffset": 100, "endOffset": 104}, {"referenceID": 39, "context": "Note that extracting covariance features in each patch can be computed efficiently using the integral image trick [40].", "startOffset": 114, "endOffset": 118}, {"referenceID": 2, "context": "Our sp-Cov differs from covariance features in [3] in the following aspects: 1.", "startOffset": 47, "endOffset": 50}, {"referenceID": 40, "context": "Considering pooling over a set of arbitrary rectangular regions as in [41] is likely to further improve the performance of our features.", "startOffset": 70, "endOffset": 74}, {"referenceID": 2, "context": "Instead of normalizing the covariance descriptor of each patch based on the whole detection window [3], we calculate the correlation coefficient within each patch.", "startOffset": 99, "endOffset": 102}, {"referenceID": 41, "context": "Multi-scale patches have also been used in [42].", "startOffset": 43, "endOffset": 47}, {"referenceID": 5, "context": "Discussion Although we make use of spatial pooling, our approach differs significantly from the unsupervised feature learning pipeline, which has been successfully applied to image classification problem [6], [42].", "startOffset": 204, "endOffset": 207}, {"referenceID": 41, "context": "Discussion Although we make use of spatial pooling, our approach differs significantly from the unsupervised feature learning pipeline, which has been successfully applied to image classification problem [6], [42].", "startOffset": 209, "endOffset": 213}, {"referenceID": 5, "context": "In other words, our proposed approach removes the dictionary learning and feature encoding from the conventional unsupervised feature learning [6], [42].", "startOffset": 143, "endOffset": 146}, {"referenceID": 41, "context": "In other words, our proposed approach removes the dictionary learning and feature encoding from the conventional unsupervised feature learning [6], [42].", "startOffset": 148, "endOffset": 152}, {"referenceID": 5, "context": "The advantage of our approach over conventional feature learning is that our features have much less dimensions than the size of visual words often used in generic image classification [6].", "startOffset": 185, "endOffset": 188}, {"referenceID": 15, "context": "Using too few visual words can significantly degrade the recognition performance as reported in [16] and using too many visual words would lead to very high-dimensional features and thus make the classifier training become computationally infeasible.", "startOffset": 96, "endOffset": 100}, {"referenceID": 31, "context": "Structured learning approach Before we propose our approach, we briefly review the concept of SVM tight pAUC [\u03b1, \u03b2] [32], in which our ensemble learning approach is built upon.", "startOffset": 116, "endOffset": 120}, {"referenceID": 31, "context": "For the partial AUC (pAUC) in the false positive range [\u03b1, \u03b2], the empirical pAUC risk can be written as [32]:", "startOffset": 105, "endOffset": 109}, {"referenceID": 31, "context": "We can summarize the above problem as the following convex optimization problem [32]:", "startOffset": 80, "endOffset": 84}, {"referenceID": 42, "context": "We use the idea of column generation to derive an ensemble-like algorithm similar to LPBoost [43].", "startOffset": 93, "endOffset": 97}, {"referenceID": 43, "context": "For decision stumps and decision trees, the last equation in (15) is always valid since the weak learner set H is negation-closed [44].", "startOffset": 130, "endOffset": 134}, {"referenceID": 30, "context": "As in [31], [45], we use the cutting plane method to solve this problem.", "startOffset": 6, "endOffset": 10}, {"referenceID": 44, "context": "As in [31], [45], we use the cutting plane method to solve this problem.", "startOffset": 12, "endOffset": 16}, {"referenceID": 30, "context": "Narasimhan and Agarwal show how this combinatorial problem can be solved efficiently in a polynomial time [31].", "startOffset": 106, "endOffset": 110}, {"referenceID": 31, "context": "Interested reader may refer to [32].", "startOffset": 31, "endOffset": 35}, {"referenceID": 45, "context": "We train the decision tree using the fast implementation of [46], in which feature values are quantized into 256 bins.", "startOffset": 60, "endOffset": 64}, {"referenceID": 46, "context": "Step \u00ac in Algorithm 2 costs O ( tmax(m + n) ) time since the linear kernel scales linearly with the number of training samples [47].", "startOffset": 127, "endOffset": 131}, {"referenceID": 31, "context": "Using the efficient algorithm of [32], step \u00ad costs O ( n log n+ (m+n\u03b2) log(m+n\u03b2) ) \u2264", "startOffset": 33, "endOffset": 37}, {"referenceID": 44, "context": "As shown in [45], the number of iterations of Algorithm 2 is upper bounded by the value which is independent of the number of training samples.", "startOffset": 12, "endOffset": 16}, {"referenceID": 4, "context": "Discussion Our final ensemble classifier has a similar form as the AdaBoost-based object detector of [5].", "startOffset": 101, "endOffset": 104}, {"referenceID": 4, "context": "Based on Algorithm 1, step \u00ac and \u00ad of our algorithm are identical to the first two steps of AdaBoost adopted in [5].", "startOffset": 112, "endOffset": 115}, {"referenceID": 9, "context": "We point out here the major difference between the ensemble classifier proposed in this paper and our earlier work [10].", "startOffset": 115, "endOffset": 119}, {"referenceID": 9, "context": "in [10] is computed over all the negative instances instead of subsets of negative instances ranked in positions j\u03b1 + 1, \u00b7 \u00b7 \u00b7 , j\u03b2 (corresponding to the FPR range [\u03b1, \u03b2] one is interested in).", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "As a result, the new formulation is not only faster to train but also perform slightly better on the pAUC measure than [10].", "startOffset": 119, "endOffset": 123}, {"referenceID": 34, "context": "The evaluation of our pedestrian detector outlined in the previous subsections can be computed efficiently with the use of integral channel features [35].", "startOffset": 149, "endOffset": 153}, {"referenceID": 4, "context": "In order to improve the evaluation time, we adopt a cascaded approach in which classifiers are arranged based on their complexity [5].", "startOffset": 130, "endOffset": 133}, {"referenceID": 11, "context": "Recently the binarized normed gradients (BING) feature with a linear SVM classifier has been shown to speed up the classical sliding window object detection paradigm by discarding a large set of background patches [12].", "startOffset": 214, "endOffset": 218}, {"referenceID": 47, "context": "On Pascal VOC2007, it achieves a comparable object detection rate to recently proposed Objectness [48] and Selective Search [49], while being three orders of magnitudes faster than these approaches.", "startOffset": 98, "endOffset": 102}, {"referenceID": 48, "context": "On Pascal VOC2007, it achieves a comparable object detection rate to recently proposed Objectness [48] and Selective Search [49], while being three orders of magnitudes faster than these approaches.", "startOffset": 124, "endOffset": 128}, {"referenceID": 11, "context": "The detector of [12] is adopted in the first stage of our two-stage detector to filter out a large number of background patches.", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "Implementation The original BING detector of [12] was trained for generic object detection.", "startOffset": 45, "endOffset": 49}, {"referenceID": 1, "context": "This template has the same aspect ratio as the one adopted in [2].", "startOffset": 62, "endOffset": 65}, {"referenceID": 1, "context": "INRIA [2] 14.", "startOffset": 6, "endOffset": 9}, {"referenceID": 51, "context": "8% ETH [52] 42.", "startOffset": 7, "endOffset": 11}, {"referenceID": 52, "context": "[53] 48.", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "1 [50] and level-3 decision trees as weak classifiers.", "startOffset": 2, "endOffset": 6}, {"referenceID": 50, "context": "We apply shrinkage to AdaBoost as it has been shown to improve the final classification accuracy [51].", "startOffset": 97, "endOffset": 101}, {"referenceID": 10, "context": "We use the depth-3 decision tree as it offers better generalization performance as shown in [11].", "startOffset": 92, "endOffset": 96}, {"referenceID": 3, "context": "Since we did not combine sp-LBP with HOG as in [4], sp-LBP performs slightly worse than sp-Cov.", "startOffset": 47, "endOffset": 50}, {"referenceID": 2, "context": "Compared with other pedestrian detectors In this experiment, we compare the performance of our proposed sp-Cov with the original covariance descriptor proposed in [3].", "startOffset": 163, "endOffset": 166}, {"referenceID": 2, "context": "[3] calculates the covariance distance in the Riemannian manifold.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "As eigen-decomposition is performed, the approach of [3] is computationally expensive.", "startOffset": 53, "endOffset": 56}, {"referenceID": 2, "context": "The new weak learner is not only simpler than [3] but also highly effective.", "startOffset": 46, "endOffset": 49}, {"referenceID": 2, "context": "We compare our previously trained detector with the original covariance descriptor [3] in Fig.", "startOffset": 83, "endOffset": 86}, {"referenceID": 1, "context": "We plot HOG [2] and HOG+LBP [4] as the baseline.", "startOffset": 12, "endOffset": 15}, {"referenceID": 3, "context": "We plot HOG [2] and HOG+LBP [4] as the baseline.", "startOffset": 28, "endOffset": 31}, {"referenceID": 33, "context": "Similar to the result reported in [34], where the authors show that HOG+Boosting reduces the average miss-rate over HOG+SVM by more than 30%, we observe that applying our sp-Cov features as the channel features significantly", "startOffset": 34, "endOffset": 38}, {"referenceID": 2, "context": "3: ROC curves of our sp-Cov features and the conventional covariance detector [3] on INRIA test images.", "startOffset": 78, "endOffset": 81}, {"referenceID": 36, "context": "Next we compare the proposed sp-Cov with ACF features (M+O+LUV) [37].", "startOffset": 64, "endOffset": 68}, {"referenceID": 24, "context": "effectiveness of our ensemble classifier on a synthetic data set similar to the one evaluated in [25].", "startOffset": 97, "endOffset": 101}, {"referenceID": 3, "context": "In our implementation, we use an extension of LBP, known as the uniform LBP, which can better filter out noises [4].", "startOffset": 112, "endOffset": 115}, {"referenceID": 30, "context": "Results marked by \u2020 were reported in [31].", "startOffset": 37, "endOffset": 41}, {"referenceID": 9, "context": "1] [10] 56.", "startOffset": 3, "endOffset": 7}, {"referenceID": 31, "context": "1] [32] 52.", "startOffset": 3, "endOffset": 7}, {"referenceID": 30, "context": "1] [31] 51.", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "1]\u2020 [29] 48.", "startOffset": 4, "endOffset": 8}, {"referenceID": 32, "context": "1]\u2020 [33] 44.", "startOffset": 4, "endOffset": 8}, {"referenceID": 44, "context": "51% SVMAUC [45] 39.", "startOffset": 11, "endOffset": 15}, {"referenceID": 26, "context": "[27] and Asymmetric AdaBoost (AsymBoost) [25].", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[27] and Asymmetric AdaBoost (AsymBoost) [25].", "startOffset": 41, "endOffset": 45}, {"referenceID": 53, "context": "The problem we consider here is a protein-protein interaction prediction [54], in which the task is to predict whether a pair of proteins interact or not.", "startOffset": 73, "endOffset": 77}, {"referenceID": 30, "context": "We use a subset of 85 features as in [31].", "startOffset": 37, "endOffset": 41}, {"referenceID": 54, "context": "We train a linear classifier as our weak learner using LIBLINEAR [55].", "startOffset": 65, "endOffset": 69}, {"referenceID": 4, "context": "02) [5] 20 0.", "startOffset": 4, "endOffset": 7}, {"referenceID": 55, "context": "02) [56] 20 0.", "startOffset": 4, "endOffset": 8}, {"referenceID": 24, "context": "02) [25] 20 0.", "startOffset": 4, "endOffset": 8}, {"referenceID": 31, "context": "1] [32], as a result of introducing a non-linearity into the original problem.", "startOffset": 3, "endOffset": 7}, {"referenceID": 55, "context": "This phenomenon has also been observed in face detection as reported in [56].", "startOffset": 72, "endOffset": 76}, {"referenceID": 55, "context": "Comparison to other asymmetric boosting Here we compare pAUCEnsT against existing asymmetric boosting algorithms, namely, AdaBoost with Fisher LDA postprocessing [56] and AsymBoost [25].", "startOffset": 162, "endOffset": 166}, {"referenceID": 24, "context": "Comparison to other asymmetric boosting Here we compare pAUCEnsT against existing asymmetric boosting algorithms, namely, AdaBoost with Fisher LDA postprocessing [56] and AsymBoost [25].", "startOffset": 181, "endOffset": 185}, {"referenceID": 56, "context": "For scenes, we divide the 15-scene data sets used in [57] into 2 groups: indoor and outdoor scenes.", "startOffset": 53, "endOffset": 57}, {"referenceID": 57, "context": "We use CENTRIST as our feature descriptors and build 50 visual code words using the histogram intersection kernel [58].", "startOffset": 114, "endOffset": 118}, {"referenceID": 4, "context": "For faces, we use face data sets from [5] and randomly extract 5000 negative patches from background images.", "startOffset": 38, "endOffset": 41}, {"referenceID": 65, "context": "We train the pedestrian detector on the KITTI vision benchmark suite [66] and Caltech-USA pedestrian data set [1].", "startOffset": 69, "endOffset": 73}, {"referenceID": 0, "context": "We train the pedestrian detector on the KITTI vision benchmark suite [66] and Caltech-USA pedestrian data set [1].", "startOffset": 110, "endOffset": 113}, {"referenceID": 34, "context": "We use five different types of features: color (LUV), magnitude, orientation bins [35], the proposed sp-Cov and the proposed sp-LBP.", "startOffset": 82, "endOffset": 86}, {"referenceID": 58, "context": "5: Precision-recall curves of our approach and state-of-the-art detectors (DA-PDM [59], LSVM-MDPM-sv [60], LSVM-MDPM-us [13] and mBoW [61]) on the KITTI pedestrian detection test set.", "startOffset": 82, "endOffset": 86}, {"referenceID": 59, "context": "5: Precision-recall curves of our approach and state-of-the-art detectors (DA-PDM [59], LSVM-MDPM-sv [60], LSVM-MDPM-us [13] and mBoW [61]) on the KITTI pedestrian detection test set.", "startOffset": 101, "endOffset": 105}, {"referenceID": 12, "context": "5: Precision-recall curves of our approach and state-of-the-art detectors (DA-PDM [59], LSVM-MDPM-sv [60], LSVM-MDPM-us [13] and mBoW [61]) on the KITTI pedestrian detection test set.", "startOffset": 120, "endOffset": 124}, {"referenceID": 60, "context": "5: Precision-recall curves of our approach and state-of-the-art detectors (DA-PDM [59], LSVM-MDPM-sv [60], LSVM-MDPM-us [13] and mBoW [61]) on the KITTI pedestrian detection test set.", "startOffset": 134, "endOffset": 138}, {"referenceID": 7, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 78, "endOffset": 81}, {"referenceID": 61, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 98, "endOffset": 102}, {"referenceID": 61, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 111, "endOffset": 115}, {"referenceID": 62, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 132, "endOffset": 136}, {"referenceID": 36, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 150, "endOffset": 154}, {"referenceID": 63, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 161, "endOffset": 165}, {"referenceID": 62, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 182, "endOffset": 186}, {"referenceID": 13, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 196, "endOffset": 200}, {"referenceID": 33, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 209, "endOffset": 213}, {"referenceID": 64, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 225, "endOffset": 229}, {"referenceID": 37, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 247, "endOffset": 251}, {"referenceID": 36, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 257, "endOffset": 261}, {"referenceID": 1, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 267, "endOffset": 270}, {"referenceID": 4, "context": "6: ROC curves of our approach and several state-of-the-art detectors (ACF+SDt [8], MT-DPM+Context [62], MT-DPM [62], MultiResC+2Ped [63], ACF-Caltech [37], MOCO [64], MF+Motion+2Ped [63], DBN-Mut [14], Roerei [34], MultiResC [65], MultiFtr+Motion [38], ACF [37], HOG [2] and VJ [5]) on the Caltech pedestrian test set.", "startOffset": 278, "endOffset": 281}, {"referenceID": 34, "context": "To obtain final detection results, greedy nonmaxima suppression is applied with the default parameter as described in the Addendum of [35].", "startOffset": 134, "endOffset": 138}, {"referenceID": 1, "context": "6b in [2]), i.", "startOffset": 6, "endOffset": 9}, {"referenceID": 7, "context": "We exclude occluded pedestrians from the Caltech training set [8].", "startOffset": 62, "endOffset": 65}, {"referenceID": 34, "context": "We use six different types of features: color (LUV), magnitude, orientation bins [35], histogram of flow6 [68], sp-Cov and sp-LBP.", "startOffset": 81, "endOffset": 85}, {"referenceID": 67, "context": "We use six different types of features: color (LUV), magnitude, orientation bins [35], histogram of flow6 [68], sp-Cov and sp-LBP.", "startOffset": 106, "endOffset": 110}, {"referenceID": 0, "context": "[1],", "startOffset": 0, "endOffset": 3}, {"referenceID": 66, "context": "We use the optical flow implementation of [67] which can be downloaded at http://people.", "startOffset": 42, "endOffset": 46}, {"referenceID": 33, "context": "Similar observation has also been reported in [34], in which the authors apply a multi-scale model for pedestrian detection.", "startOffset": 46, "endOffset": 50}, {"referenceID": 1, "context": "6b in [2]).", "startOffset": 6, "endOffset": 9}, {"referenceID": 68, "context": "Next we compare the performance and evaluation time of our two-stage detector with a soft cascade [69].", "startOffset": 98, "endOffset": 102}, {"referenceID": 9, "context": "Note that, since the structured ensemble learning method in [10], the analysis here can be easily adapted so that it applies to [10].", "startOffset": 60, "endOffset": 64}, {"referenceID": 9, "context": "Note that, since the structured ensemble learning method in [10], the analysis here can be easily adapted so that it applies to [10].", "startOffset": 128, "endOffset": 132}], "year": 2015, "abstractText": "Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. In order to achieve a high object detection performance, we propose a new approach to extract low-level visual features based on spatial pooling. Incorporating spatial pooling improves the translational invariance and thus the robustness of the detection process. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the proposed structured ensemble learning method with spatially pooled features. The result is the current best reported performance on the Caltech-USA pedestrian detection dataset.", "creator": "LaTeX with hyperref package"}}}