{"id": "1409.5223", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Sep-2014", "title": "Why Local Search Excels in Expression Simplification", "abstract": "Simplifying expressions is important to make numerical integration of large expressions from High Energy Physics tractable. To this end, Horner's method can be used. Finding suitable Horner schemes is assumed to be hard, due to the lack of local heuristics. Recently, MCTS was reported to be able to find near optimal schemes. However, several parameters had to be fine-tuned manually. In this work, we investigate the state space properties of Horner schemes and find that the domain is relatively flat and contains only a few local minima. As a result, the Horner space is appropriate to be explored by Stochastic Local Search (SLS), which has only two parameters: the number of iterations (computation time) and the neighborhood structure. We found a suitable neighborhood structure, leaving only the allowed computation time as a parameter. We performed a range of experiments. The results obtained by SLS are similar or better than those obtained by MCTS. Furthermore, we show that SLS obtains the good results at least 10 times faster. Using SLS, we can speed up numerical integration of many real-world large expressions by at least a factor of 24. For High Energy Physics this means that numerical integrations that took weeks can now be done in hours.", "histories": [["v1", "Thu, 18 Sep 2014 08:21:25 GMT  (287kb,D)", "http://arxiv.org/abs/1409.5223v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ben ruijl", "aske plaat", "jos vermaseren", "jaap van den herik"], "accepted": false, "id": "1409.5223"}, "pdf": {"name": "1409.5223.pdf", "metadata": {"source": "CRF", "title": "Why Local Search Excels in Expression Simplification", "authors": ["Ben Ruijl", "Aske Plaat", "Jos Vermaseren", "Jaap van den Herik"], "emails": [], "sections": [{"heading": null, "text": "Index Terms - Simplification of Expressions, Horner, Stochastic Local Search, Simulated Annealing, MCTSF"}, {"heading": "1 INTRODUCTION", "text": "In fact, the fact is that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times. \""}, {"heading": "2 BACKGROUND", "text": "To provide some background information, we will now describe two methods to reduce the number of operations, namely Horner schemes and the elimination of the general supposition [6], [8], followed by some comments on their interaction and the scaling of computing time."}, {"heading": "2.1 Horner schemes", "text": "Horner's rule is a classic way to reduce the number of multiplications in a polynomial by raising variables outside of parentheses [1], [9]. In multivariate polynomials, the order in which the variables are raised outside of parentheses is called the Horner scheme. For example: x2z + x3y + x3yz \u2192 x2 (z + x (1 + z)))) (1) Here, you could first decrease the order y (i.e. x2z + x3yz and x) and then the variable y. The number of multiplications is now increased from 9 to 4. However, the order x, y is chosen arbitrarily. You could also decrease the order y, x: x2z + x3y + x3yz \u2192 x2z + y (x3 (1 + z)) (2), for which the number of multiplications is 6. Obviously, this is a suboptimal horner scheme."}, {"heading": "2.2 Common subexpression elimination", "text": "The number of operations can be further reduced by the application of Common Subexpression Elimination (CSEE), a method known in the area of compiler construction [3], where it is applied to much smaller expressions than in high-energy physics, and in the area of computer shaft [10], where it manages the occurrence of common subtrees by using transposition tables. Figure 1 shows an example of a common subexpression in a tree representation of an expression. Shaded subexpression b (a + e) appears twice, and its removal means the removal of superfluous addition and multiplication. CSEE is able to reduce both the number of multiplications and the number of addition of an expression, while Horner schemes are only able to reduce the number of multiplications. + \u00d7 b + a e \u00b7 b + a eFigure 1: A common subexpression (schatative) in a representative and tree associative."}, {"heading": "2.3 Interplay", "text": "We note that there is an interplay between Horner schemes and CSEE: A particular \"optimal\" Horner scheme can reduce the number of multiplications the most, but can uncover less common partial expressions than a \"mediocre\" Horner scheme. Therefore, we need to find a way to obtain a Horner scheme that reduces the number of operations the most after both Horner and CSEE have been applied. Finding suitable Horner schemes is not a trivial task, for at least four reasons. First, there are no known local Heuristics. For the Traveling Salesman Problem (TSP), the distance between two cities can be used as a hayristic [11], and more specific Heuristics are able to solve symmetrical TSP instances with thousands of cities (a historical example is a TSP with 7,397 cities [12], [13]). Secondly, the Horner scheme is applied to a particular suristic scheme that has a unique expression attached to it (i.e. a Horner scheme that has nine cities)."}, {"heading": "2.4 Scaling", "text": "The difficulty of finding a good Horner scheme is related to the size of the permutation space, i.e. the number of variables, but also to the distribution of variables in the terms. The composition of the variables influences the flatness of the state space and the occurrence of saddle points and local minima, as we will see in Section 5.3.3 In [2] and [6], Monte Carlo Tree Search (MCTS) was successfully used to find a best candidate for all available Horner schemes. In this paper (we are rethinking) which algorithm is best suited to the Horner scheme problem. We will discuss six candidate algorithms for optimizing Horner schemes."}, {"heading": "3 RELATED ALGORITHMS", "text": "In fact, most of them are able to survive on their own, and most of them are able to survive on their own. Most of them are not able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are not able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own."}, {"heading": "4 EXPERIMENTAL SETUP", "text": "We use eight large benchmark expressions, four from mathematics and four from the real world of high energy physics (HEP) for our calculations. In Table 1, statistics are presented for the expressions. We show the number of variables, terms, operations and the evaluation time of applying a Horner scheme and the CSEE.variable term operations evaluation. Time (s) res (7.4) 13 2561 29 163 0.001 res (7.5) 14 11 379 142 711 0.03 res (7.6) 15 43 165 587 880 0.13 res (9.8) 19 4 793 296 83 778 591 25.0 HEP (\u03c3) 15 5716 47 424 0.008 HEP (F13) 24 105 058 1 068 153 0.4 HEP (F24) 31 836 009 7 722 027 3.0 HEP (b) 107 193 767 1 817 520 2.0 Table 1: The number of variables, terms, operations and the evaluation time of a single hormone (SE8)."}, {"heading": "5 RESULTS", "text": "In this section, we present the results of our measurements on the benchmark polynomials. In Section 5.1, we measure the difference between stochastic local search and simulated annealing. In Section 5.2, we examine the effects of the two parameters of SLS: the number of iterations and the neighborhood structure. In Section 5.3, we examine two state properties, namely the occurrence of local minima and the flatness of the state space. In Section 5.4, we compare the performance of the Horner schemes found by SLS with the results of MCTS."}, {"heading": "5.1 SLS vs. SA", "text": "The number of operations is only slightly affected by the initial temperature, and the number of operations is only slightly affected by the initial temperature. (D) The number of operations is only slightly higher than the number of operations for a given initial temperature Ti, compared with Ti = 0. (D) Each data point is the average of more than 100 S runs with 1000 iterations and a swap neighborhood structure. We show the expressions HEP (F), HEP (F) res (7.5), and HEP (B). The number of operations is only slightly affected by the initial temperature, as the best improvement is over Ti = 0%. Local search is only moved to a neighbor if the number of iterations N (F), and HEP (B), and the number of operations is only slightly affected by the initial temperature, as the best improvement over Ti = 5%.Local search only leads to one neighbor."}, {"heading": "5.2 Neighborhood structure", "text": "The most important parameters of SLS are the neighbourhood structures, which also include larger structures, since they determine the shape of the search space and thus affect search performance. In this context, it should be noted that the neighbourhood structures either have a significant effect on the quality of the above-mentioned objects, which are close to swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap-swap"}, {"heading": "5.2.1 Results for res(7,6) and HEP(\u03c3)", "text": "We see that the shift of a single variable (\"1 shift\") involves the best performance with a low number of iterations N, followed by 2 consecutive swap structures (\"2 swap 3 swap structures\"), but that all neighbourhood structures are converged. Thus, from 7 100 200 300 500 600 800 900 000 N 45000 46000 48000 49000 51000 E (m in, 4) 1 swap 3 swap structures 1 shift many shifts with many shifts in the mirror Figure 5: The expected number of operations of the minimum of four SLS runs with N iterations for the res (7.6) expression. The 1 shift is best for the 2 swap structures. All neighbourhood structures converge at N = 900.100 200 300 400 500 600 700 800 700 900 900."}, {"heading": "5.2.3 Combined results", "text": "For the four benchmark expressions shown above and for the other three benchmark expressions, we note that the relative improvement in the choice of the best neighbourhood structure compared to the worst neighbourhood structure is never more than 10%. Furthermore, we observe that there are two groups of neighbourhood structures when the state space is sufficiently large: a group with minor state changes (\"18 100 200 300 400 500 600 700 800 900 1000 N 140000 150000 170000 180000 E (m in, 4) 1 swap 2 swap 3 swap mirror swaps 1 shift of many shifts mirror shifts Figure 8: The expected number of operations of the minimum of four SLS runs with N iterations for the expression HEP (b). The 2 swap performs best for low N. 1 swap, 2 swap, 3 swap and 1 shift convergence at N = 1000. The other neighbourhood structures perform a worse.swap ', 3 Swap,' group ',' one structural shift with many HEP shifts (two HEP) and one large shift with many HEP shifts."}, {"heading": "5.3 State space properties", "text": "The fact that SLS works so well is surprising; two well-known obstacles are (1) a local search can get stuck in local minimums that produce inferior results, and (2) the Horner Schema problem has no local heuristics, so there are no guidelines for the best possible initial search. Remarkably, SLS only needs 1000 iterations for a 107-variable expression (HEP (b) to get good results, while a TSP benchmark problem with a comparable spatial size of the state, kroA100 [25] with 100 variables, takes over a million iterations to adjust using a manually tuned SA search. A thousand iterations are also a small number compared to the size of the state. The average distance between two arbitrary states is 98 swaps. A thousand iteration SLS search accepts about 300 suggested swaps, so at least 33% of all accepted steps should move toward a global minimum."}, {"heading": "5.3.1 Local minima and saddle points", "text": "To get an idea of the number of local minimums, we measure how often the simulation gets stuck: If there are many local minimums, we expect the simulation to get stuck frequently. In Figure 9, we show the distribution of HEP (F13) for 1000, 10 000 and 100 000 SLS runs, respectively. For 1000 and 10 000 runs, we see two peaks: one at the global minimum near 51 000 and one at the apparent local minimum near 62 000 iterations. As the number of iterations increases, the weight shifts from the apparent local minimum to the global minimum: at 1000 iterations, there is a 27.5% chance of arriving in the region of the global minimum, whereas this is 36.25% at 10 000 iterations. Obviously, the local minimum is \"leaky\": given sufficient time, the search can escape. The figure on the right with 100 000 iterations confirms the possibility of escape: the apparent local minimum has completely disappeared."}, {"heading": "5.3.2 Flatness of the state space", "text": "In fact, it is such that most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to move, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to fight, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "5.4 Performance of SLS vs MCTS", "text": "In the following, we compared the results of the Stochastic Local Search with the previous results of MCTS, for which we obtained eight benchmark expressions (7.4), rates (7.6), rates (9.8), rates (2.0), rates (2.0) and rates (2.0)."}, {"heading": "6 CONCLUSIONS", "text": "Over the past forty years, many algorithms have been developed to solve tough optimization problems. Each new algorithm introduces complexity in the form of parameters that need to be manually adjusted to the problem. It is tempting to use the latest successful and complex algorithms, but sometimes convenient features of the problem class can be overlooked or left unused. An analysis of the problem area can help determine which algorithm is most suitable. In the case of Horner schemes, we have found that one of the most basic algorithms, Stochastic Local Search, delivers the best results. Stochastic Local Search offers a search method with two parameters: the number of iterations (computation time) and half of simulations with a neighborhood structure that make minor changes to the state that is minor."}, {"heading": "7 DISCUSSION / FUTURE WORK", "text": "Currently, our algorithms assume that the expressions are commutative, but our implementation could be extended to apply to generic expressions with non-commutative variables, which is especially useful in physics, where tensors are common objects. Horner's rule can only be applied to commutative variables, but dragging outside brackets maintains the order of non-commutative objects. For example, in Figure 1, the two highlighted parts are not common subcompressions if the variables are not commutative (a + e cannot be moved to the left of c). To allow non-cumulative objects, CSEE should only compare contiguous subsets.Additional work can be done in looking for other ways of reducing them. For example, expressing certain variables as linear combinations of other problem combinations can reduce results other than ordinary operations by comparing these variables well with each other suspensions."}, {"heading": "APPENDIX A", "text": "EXPECTED VALUE OF MINIMUM \u2212 \u2212 For wider accessibility, we provide the following derivation of the expected value of the minimum of n samples used for Gl. 3.We draw n numbers X0,.., Xn \u2212 1 from the discrete probability distribution D, where Dt is the probability of the result Vt, L is the number of results, where t is an index from 0 to L \u2212 1 and Va < Vb iff a < b (hence D can be considered a histogram).We want to know if E (min (X0,., Xn \u2212 1) is an index from 0 to L \u2212 1 and Va < Vb iff iff a < b (i.e. D can be considered a histogram).We want to know if E (min (X0,., Xn \u2212 1) the value of P (Xn,., Xn \u2212 n) is a value of & ltdp (Xn) & lt."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work is partially supported by ERC Advanced Grant No. 320651, \"HEPGAME.\""}], "references": [{"title": "A New Method of Solving Numerical Equations of All Orders by Continuous Approximation", "author": ["W. Horner"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1959}, {"title": "Improving multivariate Horner schemes with Monte Carlo Tree Search", "author": ["J. Kuipers", "A. Plaat", "J. Vermaseren", "J. van den Herik"], "venue": "Computer Physics Communications, vol. 184, no. 11, pp. 2391\u20132395, 2013. [Online]. Available: http://www.sciencedirect. com/science/article/pii/S0010465513001689", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Greedy Algorithms for Optimizing Multivariate Horner Schemes", "author": ["M. Ceberio", "V. Kreinovich"], "venue": "SIGSAM Bull., vol. 38, no. 1, pp. 8\u201315, Mar. 2004. [Online]. Available: http://doi.acm.org/10.1145/980175.980179", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Efficient Selectivity and Backup Operators in Monte- Carlo Tree Search", "author": ["R. Coulom"], "venue": "Proceedings of the 5th International Conference on Computers and Games, ser. CG\u201906. Berlin, Heidelberg: Springer-Verlag, 2007, pp. 72\u201383. [Online]. Available: http: //dl.acm.org/citation.cfm?id=1777826.1777833", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Combining Simulated Annealing and Monte Carlo Tree Search for Expression Simplification", "author": ["B. Ruijl", "J. Vermaseren", "A. Plaat", "H.J. van den Herik"], "venue": "Proceedings of ICAART Conference 2014, vol. 1, no. 1, pp. 724\u2013731, 2014. [Online]. Available: http://arxiv.org/abs/1312.0841", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "1989\u2013present) Form source code", "author": ["J. Vermaseren"], "venue": "https://github.com/vermaseren/form", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1989}, {"title": "HEPGAME and the Simplification of Expressions", "author": ["B. Ruijl", "J. Vermaseren", "A. Plaat", "H.J. van den Herik"], "venue": "2014, in press. [Online]. Available: http://arxiv.org/abs/1405.6369", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "The Art of Computer Programming, Volume 2 (3rd Ed.)", "author": ["D.E. Knuth"], "venue": "Seminumerical Algorithms", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Algorithms for Games", "author": ["G.M. Adelson-Velsky", "V.L. Arlazarov", "M.V. Donskoy"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1988}, {"title": "Future paths for integer programming and links to artificial intelligence", "author": ["F. Glover"], "venue": "Computers & Operations Research, vol. 13, no. 5, pp. 533 \u2013 549, 1986, applications of Integer Programming. [Online]. Available: http://www.sciencedirect. com/science/article/pii/0305054886900481", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1986}, {"title": "An Effective Heuristic Algorithm for the Traveling-Salesman Problem", "author": ["S. Lin", "B.W. Kernighan"], "venue": "Operations Research, vol. 21, no. 2, pp. 498\u2013516, 1973. [Online]. Available: http://dx.doi.org/ 10.2307/169020", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1973}, {"title": "An effective implementation of the lin-kernighan traveling salesman heuristic", "author": ["K. Helsgaun"], "venue": "European Journal of Operational Research, vol. 126, pp. 106\u2013130, 2000.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2000}, {"title": "Optimization by simulated annealing", "author": ["S. Kirkpatrick", "C.D. Gelatt", "M.P. Vecchi"], "venue": "Science, vol. 220, pp. 671\u2013680, 1983.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1983}, {"title": "Ant colony system: A cooperative learning approach to the traveling salesman problem", "author": ["M. Dorigo", "L.M. Gambardella"], "venue": "Trans. Evol. Comp, vol. 1, no. 1, pp. 53\u201366, Apr. 1997. [Online]. Available: http://dx.doi.org/10.1109/4235.585892", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1997}, {"title": "Genetic Algorithms in Search, Optimization and Machine Learning, 1st ed", "author": ["D.E. Goldberg"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1989}, {"title": "Local Search in Combinatorial Optimization, 1st ed", "author": ["E. Aarts", "J.K. Lenstra", "Eds"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1997}, {"title": "Jitta, \u201cAdaptive simulated annealing for maximum temperature.", "author": ["M. Miki", "T. Hiroyasu"], "venue": "in SMC. IEEE,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "Computing the initial temperature of simulated annealing", "author": ["W. Ben-Ameur"], "venue": "Comput. Optim. Appl., vol. 29, no. 3, pp. 369\u2013 385, Dec. 2004. [Online]. Available: http://dx.doi.org/10.1023/B: COAP.0000044187.23143.bd", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "A Survey of Monte Carlo Tree Search Methods", "author": ["C. Browne", "E. Powley", "D. Whitehouse", "S. Lucas", "P. Cowling", "P. Rohlfshagen", "S. Tavener", "D. Perez", "S. Samothrakis", "S. Colton"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on, vol. 4, no. 1, pp. 1\u201343, 2012.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Bandit based Monte-Carlo Planning", "author": ["L. Kocsis", "C. Szepesv\u00e1ri"], "venue": "In: ECML-06. LNCS 4212. Springer, 2006, pp. 282\u2013293.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Efficient evaluation of large polynomials", "author": ["C.E. Leiserson", "L. Li", "M.M. Maza", "Y. Xie"], "venue": "Proceedings of the Third International Congress Conference on Mathematical Software, ser. ICMS\u201910. Berlin, Heidelberg: Springer-Verlag, 2010, pp. 342\u2013353. [Online]. Available: http://dl.acm.org/citation.cfm?id=1888390.1888464", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Application of the simulated annealing algorithm to the combinatorial optimisation problem with permutation property: An investigation of generation mechanism", "author": ["P. Tian", "J. Ma", "D.-M. Zhang"], "venue": "European Journal of Operational Research, vol. 118, no. 1, pp. 81 \u2013 94, 1999. [Online]. Available: http://www. sciencedirect.com/science/article/pii/S0377221798003087", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1999}], "referenceMentions": [{"referenceID": 0, "context": "This reduces the number of multiplications [1], [2].", "startOffset": 43, "endOffset": 46}, {"referenceID": 1, "context": "This reduces the number of multiplications [1], [2].", "startOffset": 48, "endOffset": 51}, {"referenceID": 2, "context": "The problem of finding an optimal Horner scheme is NP-hard [4].", "startOffset": 59, "endOffset": 62}, {"referenceID": 3, "context": "Recent successes with Monte Carlo Tree Search (MCTS) [5] have shown that the number of operations of expressions can be reduced by at least a factor of 16 for a set of large, real-world, expressions [2].", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "Recent successes with Monte Carlo Tree Search (MCTS) [5] have shown that the number of operations of expressions can be reduced by at least a factor of 16 for a set of large, real-world, expressions [2].", "startOffset": 199, "endOffset": 202}, {"referenceID": 4, "context": "The suggested algorithm SA-UCT (Simulated Annealing - Upper Confidence Bounds applied to Trees) alleviates the tuning problem, but does not eliminate it [6].", "startOffset": 153, "endOffset": 156}, {"referenceID": 5, "context": "the open source symbolic manipulation system FORM [7].", "startOffset": 50, "endOffset": 53}, {"referenceID": 4, "context": "To provide some background, we will now describe two methods to reduce the number of operations, namely Horner schemes and common subexpression elimination [6], [8], followed by some remark on their interplay and the scaling of the computation time.", "startOffset": 156, "endOffset": 159}, {"referenceID": 6, "context": "To provide some background, we will now describe two methods to reduce the number of operations, namely Horner schemes and common subexpression elimination [6], [8], followed by some remark on their interplay and the scaling of the computation time.", "startOffset": 161, "endOffset": 164}, {"referenceID": 0, "context": "Horner\u2019s rule is a classic method to reduce the number of multiplications in a polynomial by lifting variables outside brackets [1], [9].", "startOffset": 128, "endOffset": 131}, {"referenceID": 7, "context": "Horner\u2019s rule is a classic method to reduce the number of multiplications in a polynomial by lifting variables outside brackets [1], [9].", "startOffset": 133, "endOffset": 136}, {"referenceID": 2, "context": "The problem of selecting an optimal ordering is NP-hard [4].", "startOffset": 56, "endOffset": 59}, {"referenceID": 1, "context": "(number of operations up to 7 722 027) [2].", "startOffset": 39, "endOffset": 42}, {"referenceID": 8, "context": "This method is well known in the field of compiler construction [3], where it is applied to much smaller expressions than in high energy physics, and in the field of computer chess [10] where it handles the occurrence of common", "startOffset": 181, "endOffset": 185}, {"referenceID": 9, "context": "For the Traveling Salesman Problem (TSP), the distance between two cities can be used as a heuristic [11], and more specialized heuristics are able to solve symmetric TSP instances with thousands of cities (a historic example is a TSP with 7397 cities [12], [13]).", "startOffset": 101, "endOffset": 105}, {"referenceID": 10, "context": "For the Traveling Salesman Problem (TSP), the distance between two cities can be used as a heuristic [11], and more specialized heuristics are able to solve symmetric TSP instances with thousands of cities (a historic example is a TSP with 7397 cities [12], [13]).", "startOffset": 252, "endOffset": 256}, {"referenceID": 11, "context": "For the Traveling Salesman Problem (TSP), the distance between two cities can be used as a heuristic [11], and more specialized heuristics are able to solve symmetric TSP instances with thousands of cities (a historic example is a TSP with 7397 cities [12], [13]).", "startOffset": 258, "endOffset": 262}, {"referenceID": 1, "context": "In [2], and [6], Monte Carlo Tree Search (MCTS) has been successfully used to find a best candidate of all available Horner schemes.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "In [2], and [6], Monte Carlo Tree Search (MCTS) has been successfully used to find a best candidate of all available Horner schemes.", "startOffset": 12, "endOffset": 15}, {"referenceID": 12, "context": "In order to determine which of these algorithms is best suited for Horner schemes, we briefly discuss the characteristics of a selection of six frequently used algorithms: (Stochastic) Local Search [14], Simulated Annealing [15], Tabu Search [11], Ant Colony Optimization [16], Evolutionary Algorithms [17], and, Monte Carlo Tree Search [5].", "startOffset": 224, "endOffset": 228}, {"referenceID": 9, "context": "In order to determine which of these algorithms is best suited for Horner schemes, we briefly discuss the characteristics of a selection of six frequently used algorithms: (Stochastic) Local Search [14], Simulated Annealing [15], Tabu Search [11], Ant Colony Optimization [16], Evolutionary Algorithms [17], and, Monte Carlo Tree Search [5].", "startOffset": 242, "endOffset": 246}, {"referenceID": 13, "context": "In order to determine which of these algorithms is best suited for Horner schemes, we briefly discuss the characteristics of a selection of six frequently used algorithms: (Stochastic) Local Search [14], Simulated Annealing [15], Tabu Search [11], Ant Colony Optimization [16], Evolutionary Algorithms [17], and, Monte Carlo Tree Search [5].", "startOffset": 272, "endOffset": 276}, {"referenceID": 14, "context": "In order to determine which of these algorithms is best suited for Horner schemes, we briefly discuss the characteristics of a selection of six frequently used algorithms: (Stochastic) Local Search [14], Simulated Annealing [15], Tabu Search [11], Ant Colony Optimization [16], Evolutionary Algorithms [17], and, Monte Carlo Tree Search [5].", "startOffset": 302, "endOffset": 306}, {"referenceID": 3, "context": "In order to determine which of these algorithms is best suited for Horner schemes, we briefly discuss the characteristics of a selection of six frequently used algorithms: (Stochastic) Local Search [14], Simulated Annealing [15], Tabu Search [11], Ant Colony Optimization [16], Evolutionary Algorithms [17], and, Monte Carlo Tree Search [5].", "startOffset": 337, "endOffset": 340}, {"referenceID": 15, "context": "(A) Local Search [18], [14] is a state space exploration method that starts from an initial state and moves to a neighbor of the current state.", "startOffset": 17, "endOffset": 21}, {"referenceID": 12, "context": "(B) Simulated Annealing (SA) [15] is a classic method that is inspired by the removal of crystal defects by the cooling of metals (annealing).", "startOffset": 29, "endOffset": 33}, {"referenceID": 16, "context": "For instance, in [19] and [20] suggestions have been made to tune the initial temperature.", "startOffset": 17, "endOffset": 21}, {"referenceID": 17, "context": "For instance, in [19] and [20] suggestions have been made to tune the initial temperature.", "startOffset": 26, "endOffset": 30}, {"referenceID": 9, "context": "(C) Tabu Search performs a local search and keeps track of previous visits [11].", "startOffset": 75, "endOffset": 79}, {"referenceID": 9, "context": "In classic Tabu Search, the best neighbor that has not been visited earlier is selected and is added to the tabu list [11].", "startOffset": 118, "endOffset": 122}, {"referenceID": 13, "context": "(D) Ant Colony Optimization [16] has been successful in optimizing various problems, such as TSP instances.", "startOffset": 28, "endOffset": 32}, {"referenceID": 14, "context": "(E) Evolutionary algorithms work by using mutations and genetic recombinations [17].", "startOffset": 79, "endOffset": 83}, {"referenceID": 3, "context": "(F) Monte Carlo Tree Search (MCTS) [5], [21] has been used successfully in finding high-performance Horner", "startOffset": 35, "endOffset": 38}, {"referenceID": 18, "context": "(F) Monte Carlo Tree Search (MCTS) [5], [21] has been used successfully in finding high-performance Horner", "startOffset": 40, "endOffset": 44}, {"referenceID": 1, "context": "schemes [2].", "startOffset": 8, "endOffset": 11}, {"referenceID": 19, "context": "A commonly used criterion for the selection of the best child, UCT (Upper Confidence bounds applied to Trees), introduces an exploration-exploitation constant Cp that has to be fine-tuned manually [22] (other selection criteria have a similar trade-off parameter).", "startOffset": 197, "endOffset": 201}, {"referenceID": 4, "context": "The introduction of Simulated Annealing UCT (SA-UCT), alleviates the tuning of Cp, but does not eliminate it [6].", "startOffset": 109, "endOffset": 112}, {"referenceID": 1, "context": "In fact, in [2] a parameter is introduced to select whether the Horner schemes should be built forward or backward (the first variables in the scheme are the last to be applied).", "startOffset": 12, "endOffset": 15}, {"referenceID": 4, "context": "The backward approach tries to improve results for expressions where the order of the final variables is more sensitive to improvements than the order of the first variables [6].", "startOffset": 174, "endOffset": 177}, {"referenceID": 20, "context": "The expressions called res(7,4), res(7,5), res(7,6), and res(9,8) are resolvents and are defined by res(m,n) = resx( \u2211m i=0 aix , \u2211n i=0 bix ), as described in [23].", "startOffset": 160, "endOffset": 164}, {"referenceID": 15, "context": "A Stochastic Local Search has two parameters: the number of iterations N , and the neighborhood structure, which defines the transition function [18].", "startOffset": 145, "endOffset": 149}, {"referenceID": 12, "context": "It has four additional parameters, namely the initial temperature Ti, the final temperature Tf , the acceptance scheme, and the cooling scheme [15].", "startOffset": 143, "endOffset": 147}, {"referenceID": 10, "context": "For all expressions except HEP(b), we see a region where the improvement is largest: for HEP(\u03c3) it is approximately [1000, 7000], for HEP(F13) it is [12 000, 17 000] and for res(7,5) it is [5000, 20 000].", "startOffset": 149, "endOffset": 165}, {"referenceID": 14, "context": "For all expressions except HEP(b), we see a region where the improvement is largest: for HEP(\u03c3) it is approximately [1000, 7000], for HEP(F13) it is [12 000, 17 000] and for res(7,5) it is [5000, 20 000].", "startOffset": 149, "endOffset": 165}, {"referenceID": 17, "context": "For all expressions except HEP(b), we see a region where the improvement is largest: for HEP(\u03c3) it is approximately [1000, 7000], for HEP(F13) it is [12 000, 17 000] and for res(7,5) it is [5000, 20 000].", "startOffset": 189, "endOffset": 203}, {"referenceID": 16, "context": "Several methods have been suggested to tune the initial temperature, such as [19] and [20], but they often take several hundred iterations to obtain reliable values (which is quite expensive in our case).", "startOffset": 77, "endOffset": 81}, {"referenceID": 17, "context": "Several methods have been suggested to tune the initial temperature, such as [19] and [20], but they often take several hundred iterations to obtain reliable values (which is quite expensive in our case).", "startOffset": 86, "endOffset": 90}, {"referenceID": 21, "context": "In [24] it is observed that the neighborhood structure can have a significant impact on the quality of the solutions for the Traveling Salesman Problem, the Quadratic Assignment Problem, and the Flow-shop Scheduling Problem.", "startOffset": 3, "endOffset": 7}, {"referenceID": 1, "context": "The results of all the MCTS runs except for res(9,8), and HEP(b) are taken from [2].", "startOffset": 80, "endOffset": 83}, {"referenceID": 4, "context": ", the scheme is applied backwards [6]).", "startOffset": 34, "endOffset": 37}, {"referenceID": 1, "context": "Additional optimizations that are mentioned in [2], such as \u2018greedy\u2019 optimizations, can just as well be applied to the results of SLS.", "startOffset": 47, "endOffset": 50}, {"referenceID": 4, "context": "The fact that SLS outperforms MCTS when the number of variables is greater than 23, may be due to the fact that there are not sufficient iterations for the branches to reach the bottom, making the choice of the last variables essentially random (see section 3 and [6]).", "startOffset": 264, "endOffset": 267}, {"referenceID": 1, "context": "The MCTS results for all expressions except res(9,8) and HEP(b) are from [2].", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "lease of the open source symbolic manipulation system FORM [7].", "startOffset": 59, "endOffset": 62}], "year": 2014, "abstractText": "Simplifying expressions is important to make numerical integration of large expressions from High Energy Physics tractable. To this end, Horner\u2019s method can be used. Finding suitable Horner schemes is assumed to be hard, due to the lack of local heuristics. Recently, MCTS was reported to be able to find near optimal schemes. However, several parameters had to be fine-tuned manually. In this work, we investigate the state space properties of Horner schemes and find that the domain is relatively flat and contains only a few local minima. As a result, the Horner space is appropriate to be explored by Stochastic Local Search (SLS), which has only two parameters: the number of iterations (computation time) and the neighborhood structure. We found a suitable neighborhood structure, leaving only the allowed computation time as a parameter. We performed a range of experiments. The results obtained by SLS are similar or better than those obtained by MCTS. Furthermore, we show that SLS obtains the good results at least 10 times faster. Using SLS, we can speed up numerical integration of many real-world large expressions by at least a factor of 24. For High Energy Physics this means that numerical integrations that took weeks can now be done in hours.", "creator": "LaTeX with hyperref package"}}}