{"id": "1409.5317", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Sep-2014", "title": "A Bayesian model for recognizing handwritten mathematical expressions", "abstract": "Recognizing handwritten mathematics is a challenging classification problem, requiring simultaneous identification of all the symbols comprising an input as well as the complex two-dimensional relationships between symbols and subexpressions. Because of the ambiguity present in handwritten input, it is often unrealistic to hope for consistently perfect recognition accuracy. We present a system which captures all recognizable interpretations of the input and organizes them in a parse forest from which individual parse trees may be extracted and reported. If the top-ranked interpretation is incorrect, the user may request alternates and select the recognition result they desire. The tree extraction step uses a novel probabilistic tree scoring strategy in which a Bayesian network is constructed based on the structure of the input, and each joint variable assignment corresponds to a different parse tree. Parse trees are then reported in order of decreasing probability. Two accuracy evaluations demonstrate that the resulting recognition system is more accurate than previous versions (which used non-probabilistic methods) and other academic math recognizers.", "histories": [["v1", "Thu, 18 Sep 2014 14:45:24 GMT  (141kb,D)", "http://arxiv.org/abs/1409.5317v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["scott maclean", "george labahn"], "accepted": false, "id": "1409.5317"}, "pdf": {"name": "1409.5317.pdf", "metadata": {"source": "CRF", "title": "A Bayesian model for recognizing handwritten mathematical expressions", "authors": ["Scott MacLean", "George Labahn"], "emails": ["smaclean@uwaterloo.ca", "glabahn@uwaterloo.ca"], "sections": [{"heading": "1 Introduction", "text": "Many software packages exist that are based on mathematical expressions, and such software is generally produced for one of two purposes: either to create two-dimensional renderings of mathematical expressions for printing or display on screen (e.g. LATEX, MathML), or to perform mathematical operations on the expressions (e.g. Maple, Mathematica, Sage, and various numerical and symbolic calculators), in both cases the mathematical expressions themselves must be entered by the user in a linearized textual format specific to each software package. This method of entering mathematical expressions is unsatisfactory for two main reasons. First, it requires users to learn a different syntax for each software package they use. Second, the linearized text formats obscure the two-dimensional structure that exists in the typical way that users draw mathematical expressions on paper."}, {"heading": "1.1 MathBrush", "text": "This year, it will be able to fix and fix the mentioned bugs."}, {"heading": "2 Existing research", "text": "There is an extensive and increasingly extensive literature on the problem of mathematical recognition. Many current systems and approaches are summarized in the CROHME reports [11, 12]. We will comment directly on some newer approaches using probabilistic methods."}, {"heading": "2.1 Alvaro et al", "text": "The system developed by Alvaro et al. [1] placed first in the CROHME 2011 recognition contest [11]. It is based on earlier work by Yamamoto et al. [18]. A grammar models the formal structure of mathematical expressions. Symbols and the relationships between them are modeled stochastically using manually defined probability functions. In this scheme, writing is considered a generative stochastic process determined by the grammar rules and probability distributions. That is, one generates a bounding box for the entire expression, selects a grammatical rule to be applied, and stochastically generates bounding boxes for each of the RHS elements according to the relational distribution. In other words, one generates a grammatical box for the entire expression, selects a grammar rule to be applied, and stochastically generates the bounding boxes for each of the RHS elements according to the relational distribution. This symbol is selected explicitly until a grammatical rule is applied."}, {"heading": "2.2 Awal et al", "text": "Although the system described by Awal et al. [3] was included in the 2011 CROHME competition, its developers were directly associated with the competition and were therefore not official entrants. However, their system achieved higher scores than the winning system by Alvaro et al., so it is worth examining its construction.A dynamic programming algorithm initially suggests probable groupings of strokes into symbols, although it is not clear which cost function the dynamic program minimizes. Each of the symbol groups is recognized using neural networks, the results of which are converted into a probability distribution across symbol classes. The structure of mathematical expression is modeled by a context-free grammar, with each rule being linear either in the horizontal of the vertical direction. However, spatial relationships between symbols and supressions are represented as two independent Gaussians in differences in position and size between sub-expressions, with these probabilities being considered independent variables along with those from symbol recognition."}, {"heading": "2.3 Shi, Li, and Soong", "text": "In collaboration with Microsoft Research Asia, Shi, Li and Soong proposed a uniform HMM-based method for recognizing mathematical expressions. [14] Treating the input dashes as a temporally ordered sequence, they use dynamic programming to determine the most likely points at which the sequence is divided into different symbol groups, the most likely symbols representing each of these groups, and the most likely spatial relationship between temporally adjacent symbols. Some local relationships are taken into account by treating symbol and relationship sequences like Markov chains, a process that results in a DAG that can be easily converted into an expression tree. To calculate symbol probabilities, a grid-based method for measuring dot density and stroke direction is used to obtain a feature vector. These vectors are likely to be generated by a mixture of Gaussians with a component for each known symbol type. Relation probabilities are also predefined as Gaussian mixtures of line structures, where the Linions are extracted from the unit."}, {"heading": "3 Relational grammars and parsing", "text": "Relational grammars are the primary means by which the MathBrush recognizer associates mathematical semantics with parts of input. We have previously described a blurred relational grammar formalism that explicitly models recognition as a process by which an observed, ambiguous input is interpreted as a particular structured expression [9]. In this work, we define grammar in a slightly more abstract way, so that it has no intrinsic link to blurred sentences and can be used with a variety of evaluation functions. For further details, interested readers are referred to [9] and [7]."}, {"heading": "3.1 Grammar definition and terminology", "text": "Relational context-free grammars are defined as follows: 1. Definition: A context-free grammar G is a tuple (\u03a3, N, S, O, R, P), where \u2022 \u03a3 is a set of end symbols, \u2022 N is a set of non-terminal symbols, \u2022 S \u0435N is the initial symbol, \u2022 O is a set of observables, \u2022 R is a set of relations to I, the set of interpretations of G (see below), \u2022 P is a set of productions, each in the form A0 r \u21d2 A1A2 \u00b7 \u00b7 \u00b7 Ak, where A0, r \u0440R, undA1,..., Ak, N, the basic elements of a GFG are present in this definition as \u03a3, N, S and P, although the form of an RCFG production is somewhat more complex than that of a GFG production. However, there are also some less familiar components."}, {"heading": "3.1.1 Observables, Expressions and interpretations", "text": "The O sentence of the observable is the set of all possible inputs - in our case, each observable structure is a set of inkstrokes, and each inkstroke is an ordered sequence of dots in R2.An expression is the generalization of a string to the RCFG case. The form of an expression reflects the form of the relationship of grammar productions. Each terminal symbol is a terminal expression. An expression e can also be formed by concatenating several expressions e1,. ek by a relation r-R. Such an r concatenation is e1r- \u00b7 rect.The representable sentence G, written L (G), is the set of all formally derivable expressions using the non-terminals, terminals and productions of a grammar G. L (G) generalizes the notion of language generated by a grammar to RCFGs. An interpretation is then a pair (e, o), where e-L (G) is an expressive expression generated by a hierarchical structure, which is a hierarchical expression."}, {"heading": "3.1.2 Relations and productions", "text": "The relations in R model the spatial relations between sub-expressions. In mathematics, these relations often determine the semantic interpretation of an expression (e.g., a and x written side by side as ax means something quite different from the diagonal arrangement ax). An important feature of these grammatical relations is that they act on interpretations - pairs of expressions and observables. This allows the classifiers of relations to use knowledge of how certain expressions or symbols match when interpreting geometric features of observables. Thus, an expression such as the one shown in Figure 2 can be interpreted either as P x + a or px + a depending on the identity of its symbols. We use five relations that are compared with each other. The four arrows indicate the general direction of writing between two sub-expressions and indicate an inclusion notation as used in square roots.The productions in P are similar to context-free grammar productions."}, {"heading": "3.2 Parsing with Unger\u2019s method", "text": "Compared to traditional CFGs, there are two main sources of ambiguity and difficulty in parsing RCFGs: the symbols in the input are unknown, both in terms of what parts of the input represent a symbol and what the identity of each symbol is; and since the input is two-dimensional, there is no simple linear order in which the input strokes are traversed. Furthermore, there may be ambiguities arising from the uncertainty of the kinship classification: we cannot know with certainty which grammatical relationship links two sub-expressions. We manage and organize these sources of uncertainty by using a data structure called a parse forest to represent all recognizable parses of the input. A park forest is a graphical structure in which each node represents all the parses of a certain subset of the input."}, {"heading": "3.2.1 Restricting feasible partitions", "text": "To achieve reasonable performance when parsing with RCFGs, it is necessary to limit the possibilities of partitioning and recombining input observables (otherwise, partitions of input would have to be considered using all 2n subsets). If parsing an observable o using a manufacturing A0r \u21d2 A1 \u00b7 \u00b7 Ak, o is divided either by horizontal or vertical sections based on the direction of the relation r. For example, if we analyze manufacturing [ADD] \u2192 [TERM] + [EXPR] using a manufacturing A0r \u21d2 A1 \u00b7 Ak, o, we would notice that the relationship \u2192 requires horizontal or vertical sections based on the direction of the relationship r."}, {"heading": "3.2.2 Unger\u2019s method", "text": "Unger's method is a fairly brutal algorithm for analyzing CFGs [17]. It can easily be extended to a tabular RCFG parser. First, the grammar is rewritten so that each production is either terminal (form A0 \u21d2 \u03b1, where \u03b1 \u03a3) or nonterminal (form A0r \u21d2 A1 \u00b7 \u00b7 Ak, where each Ai-N is), so there is no mixing of terminal and non-terminal symbols within productions. Then our variant of the Unger method constructs a parsetic forest by applying the following rules recursively, where p is a production and o an input is observable: 1. If p is a terminal production, then it is checked that o is recognizable by a symbol recognition mechanism."}, {"heading": "3.3 Parse tree extraction", "text": "To find a parse-tree of the overall input problem, we just have to start at the root-scoring priority of the required queue (S, O) of the parse-forest (S is the starting symbol of the grammar) and, whenever we have the highest scoring priority at an OR node, we follow the shortcuts to all the kids of the node. The problem then is how to enumerate these paths so that the most meaningful expressions are found, and so on. Our approach is to equip each of the nodes in the parse-forest with a priority list, the parse-tree-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-score-or-or-or-score-score-score-or-score-score-or-or-or-or-or-or-or-to"}, {"heading": "4 A Bayesian scoring function", "text": "On a high level, the scoring function sc (e, o) of an interpretation of any subset o of the entire input is organized as a Bayesian network specially designed for o."}, {"heading": "4.1 Model organization", "text": "It is about the question of to what extent it is actually about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way, in which it is about a way and in which it is about a way, in which it is about which it is about a way and in which it is about which it is about a way, in which it is about which it is about a way, in which it is about which it is about which it is about which it is about which it is about a way and in which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which"}, {"heading": "4.2 Expression variables", "text": "The distribution of expression variables, Eo \"| o\" o \"o\" o \"o\" o \"o\" o \"o\" o \"o\" o \"o\" o \"o\" o \"o\" o \"o\" o \"o\" o \"o\" o \"o\" o \"o\" fo \"is deterministic.\" In a valid common assignment (i.e. one derived from a parse tree), any non-nil expression variable Eo is a subexpression of Eo, \"and the non-nil relation variables indicate how these subexpressions are put together. This information fully determines which expression Eo\" must be, so that the expression is assigned probability 1."}, {"heading": "4.3 Symbol variables", "text": "The distribution of the symbol variables, So | go, so, is based on the impact group value G (o) and the symbol recognition value S (\u03b1, o) (These values are described below.) The zero probability of So is assigned to asP (So = nil | go, so) = 1 \u2212 NN + 1, where N = log (1 + G (o) max\u03b1 {S (\u03b1, o)} and the remaining probability mass is distributed proportionally to S (o, \u03b1): P (So = \u03b1 | go, so)."}, {"heading": "4.3.1 Stroke grouping score", "text": "The hit group function G (o) is based on intuitions about the properties of a group of strokes (\u03b2 = overlap) that indicate that the strokes belong to the same symbol. These intuitions can be summarized by the following logical predicate: using the variables defined in Table 1: G = (Din) (Lin) (Lin) (Lin) (Lout) (\u00ac Lout) (\u00ac Lout) (Cout). Using the DeMorgan law, this predicate can be rewritten as: G = (\u00ac Din) (Lin) (Lin) (\u00ac Cout) = (\u00ac Din) (\u00ac Din) (\u00ac Xin) (Xin) (Xout), where X \u00b2) \u2212 C \u2212 \u2212 (in this approach is quantitative, we measure several aspects of o, one for each of the RHS variables defined above: \u2022 d = min {dist (s), s \u00b2, s \u00b2 (minimum), where the s2 is the curve."}, {"heading": "4.3.2 Symbol recognition score", "text": "The symbol recognition value S (\u03b1, o) for detecting an input subset o as end symbol \u03b1 uses a combination of four distance-based matching techniques within a template matching scheme. In this scheme, the input strokes in o are matched with model strokes from a stored training example of \u03b1, resulting in a match distance. This process is repeated for each of the training examples of \u03b1, and the two smallest match distances are averaged for each technique, resulting in four minimum distances d1, d2, d3, d4. Distances are then combined in a weighted Sums\u03b1 = 4 \u2211 i = 1 wiQi (di), where Qi: R \u2192 [0, 1] is the quantile function for distributing the values of the ith technique. These quantiles are approximated by piecemeal linear functions and serve to normalize the results of the various distance functions so that they can be combined arithmetically."}, {"heading": "4.4 Relation variables", "text": "The distribution of the relation variables, Ro1, o2 - Eo1, fo1, fo2, is similar to the symbol variable in the sense that it is based on the results of a subordinate detection method, with some of the probability mass reserved for the nil mapping. In particular, we let R (r) specify the extent to which the observatories o1 and o2 seem to satisfy the grammar relationship. Then, we will putP (Ro1, o2 = nil, fo1, fo2) = 1 \u2212 NN + 1, where N = Log (1 + maxr) R (r), and distribute the remaining probability mass to R (r)."}, {"heading": "4.5 \u201cSymbol-bag\u201d variables", "text": "The role of the Bo symbol pocket variable is to apply a prior distribution to the terminal symbols that appear in the input, and to adjust this distribution based on the symbols that currently exist. As these symbols are not known with certainty, such an adjustment can only be imperfect. We have collected symbol occurrences and quotas from the Infty Project Corpus [15] and from the LATEX sources of the University of Waterloo course notes for introductory algebra and calculation courses. The symbol appearance rate r (\u03b1) is the number of expressions in which the symbol appears, and the co-occurrence rate c (\u03b1, \u03b2) is the number of expressions that both \u03b1 and \u03b2.In theory, each Bo variable is equally distributed and satisfactorily P Bo = nil that we observe."}, {"heading": "5 Accuracy evaluation", "text": "We conducted two accuracy assessments of the MathBrush detection mechanism: the first replicates the CROHME assessments of 2011 and 2012 [11, 12], which focus exclusively on the first placed expression. To evaluate the effectiveness of the correction mechanism of our detection mechanism, we also repeated a user-oriented assessment originally designed to test an earlier version of the detection mechanism [9]."}, {"heading": "5.1 CROHME evaluation", "text": "In this section, we compared the accuracy of the machining with its previous versions as well as with the other versions. The data is divided into two parts, each of which requires training; the first part comprises a relatively small selection of mathematical terms, while the second contains a larger selection of terms."}, {"heading": "5.2 Evaluation on Waterloo corpus", "text": "In the past, it has been shown that most of them are people with a migrant background who are unable to acquire their identity."}, {"heading": "6 Conclusions and future work", "text": "As shown in the evaluation above, the MathBrush Recognizer is competitive with other state-of-the-art academic recognition systems, and its accuracy improves over time as work on the project continues. At a high level, the Recognizer organizes its input using relational context-free grammars that naturally represent the concept of recognition through interpretations - a grammatically derivative expression paired with an observable series of input movements. By introducing some constraints on how inputs can be divided, we derive an efficient parsing algorithm derived from Unger's method. The output of this algorithm is a parse forest that simultaneously represents all recognizable parses of input in a relatively compact data structure. Individual parse trees can be obtained from the parse forest through the extraction algorithm described in Section 3.3."}], "references": [{"title": "Recognition of printed mathematical expressions using two-dimensional stochastic context-free grammars", "author": ["Francisco \u00c1lvaro", "Joan-Andreu S\u00e1nchez", "Jos\u00e9-Miguel Bened\u0301\u0131"], "venue": "In Proc. of the Int\u2019l. Conf. on Document Analysis and Recognition,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Syntax-Directed Recognition of Hand-Printed Two-Dimensional Mathematics", "author": ["Robert H. Anderson"], "venue": "PhD thesis, Harvard University,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1968}, {"title": "The problem of handwritten mathematical expression recognition evaluation", "author": ["A.-M. Awal", "H. Mouch\u00e8re", "C. Viard-Gaudin"], "venue": "In Proc. of the Int\u2019l. Conf. on Frontiers in Handwriting Recognition,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Online computation of similarity between handwritten characters", "author": ["Oleg Golubitsky", "Stephen M. Watt"], "venue": "In Proc. Document Recognition and Retrieval XVI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Mathbrush: A system for doing math on pen-based devices", "author": ["G. Labahn", "E. Lank", "S. MacLean", "M. Marzouk", "D. Tausky"], "venue": "In Proc. of the Eighth IAPR Workshop on Document Analysis Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Is the ipad useful for sketch input?: a comparison with the tablet pc", "author": ["S. MacLean", "D. Tausky", "G. Labahn", "E. Lank", "M. Marzouk"], "venue": "In Proceedings of the Eighth Eurographics Symposium on Sketch-Based Interfaces and Modeling,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Automated recognition of handwritten mathematics", "author": ["Scott MacLean"], "venue": "PhD thesis, University of Waterloo,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Elastic matching in linear time and constant space", "author": ["Scott MacLean", "George Labahn"], "venue": "In Proc., Ninth IAPR Int\u2019l. Workshop on Document Analysis Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "A new approach for recognizing handwritten mathematics using relational grammars and fuzzy sets", "author": ["Scott MacLean", "George Labahn"], "venue": "International Journal on Document Analysis and Recognition (IJDAR),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Foundations of Statistical Natural Language Processing", "author": ["Christopher D. Manning", "Hinrich Schuetze"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1999}, {"title": "CROHME2011: Competition on recognition of online handwritten mathematical expressions", "author": ["H. Mouch\u00e8re", "C. Viard-Gaudin", "U. Garain", "D.H. Kim", "J.H. Kim"], "venue": "In Proc. of the 11th Int\u2019l. Conference on Document Analysis and Recognition,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Competition on recognition of online mathematical expressions (CROHME 2012)", "author": ["H. Mouch\u00e8re", "C. Viard-Gaudin", "U. Garain", "D.H. Kim", "J.H. Kim"], "venue": "In Proc. of the 13th Int\u2019l. Conference on Frontiers in Handwriting Recognition,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "CROHME \u2013 Third international competition on recognition of online mathematical expressions", "author": ["H. Mouch\u00e8re", "C. Viard-Gaudin", "R. Zanibbi", "U. Garain", "D.H. Kim", "J.H. Kim"], "venue": "In Proc. of the 12th Int\u2019l. Conference on Document Analysis and Recognition,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "A unified framework for symbol segmentation and recognition of handwritten mathematical expressions", "author": ["Yu Shi", "HaiYang Li", "F.K. Soong"], "venue": "In Document Analysis and Recognition, Ninth International Conference on,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "A ground-truthed mathematical character and symbol image database", "author": ["Masakazu Suzuki", "Seiichi Uchida", "Akihiro Nomura"], "venue": "Document Analysis and Recognition, International Conference on,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "A neural network model for online handwritten mathematical symbol recognition", "author": ["Arit Thammano", "Sukhumal Rugkunchon"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "A global parser for context-free phrase structure grammars", "author": ["Stephen H. Unger"], "venue": "Commun. ACM,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1968}, {"title": "On-line recognition of handwritten mathematical expression based on stroke-based stochastic context-free grammar", "author": ["R. Yamamoto", "S. Sako", "T. Nishimoto", "S. Sagayama"], "venue": "In The Tenth International Workshop on Frontiers in Handwriting Recognition,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}], "referenceMentions": [{"referenceID": 1, "context": "Academic interest in the problem of recognizing hand-drawn math expressions originated with Anderson\u2019s doctoral research in the late 1960\u2019s [2].", "startOffset": 140, "endOffset": 143}, {"referenceID": 10, "context": "Interest has waxed and waned in the intervening decades, and recent years have witnessed renewed attention to the topic, potentially spurred on by the nascent Competition on Recognition of Handwritten Mathematical Expressions (CROHME) [11, 12].", "startOffset": 235, "endOffset": 243}, {"referenceID": 11, "context": "Interest has waxed and waned in the intervening decades, and recent years have witnessed renewed attention to the topic, potentially spurred on by the nascent Competition on Recognition of Handwritten Mathematical Expressions (CROHME) [11, 12].", "startOffset": 235, "endOffset": 243}, {"referenceID": 4, "context": "1 MathBrush Our work is done in the context of the MathBrush pen-based math system [5].", "startOffset": 83, "endOffset": 86}, {"referenceID": 8, "context": "We have previously reported techniques for capturing and reporting these multiple interpretations [9], and some of those ideas remain the foundation of the work presented in this paper.", "startOffset": 98, "endOffset": 101}, {"referenceID": 10, "context": "Many recent systems and approaches are summarized in the CROHME reports [11, 12].", "startOffset": 72, "endOffset": 80}, {"referenceID": 11, "context": "Many recent systems and approaches are summarized in the CROHME reports [11, 12].", "startOffset": 72, "endOffset": 80}, {"referenceID": 0, "context": "1 Alvaro et al The system developed by Alvaro et al [1] placed first in the CROHME 2011 recognition contest [11].", "startOffset": 52, "endOffset": 55}, {"referenceID": 10, "context": "1 Alvaro et al The system developed by Alvaro et al [1] placed first in the CROHME 2011 recognition contest [11].", "startOffset": 108, "endOffset": 112}, {"referenceID": 17, "context": "It is based on earlier work of Yamamoto et al [18].", "startOffset": 46, "endOffset": 50}, {"referenceID": 9, "context": "However, stochastic grammars are known to biased toward short parse trees (those containing few derivation steps) [10].", "startOffset": 114, "endOffset": 118}, {"referenceID": 2, "context": "2 Awal et al While the system described by Awal et al [3] was included in the CROHME 2011 contest, its developers were directly associated with the contest and were thus not official participants.", "startOffset": 54, "endOffset": 57}, {"referenceID": 13, "context": "3 Shi, Li, and Soong Working with Microsoft Research Asia, Shi, Li, and Soong proposed a unified HMM-based method for recognizing math expressions [14].", "startOffset": 147, "endOffset": 151}, {"referenceID": 8, "context": "We previously described a fuzzy relational grammar formalism which explicitly modeled recognition as a process by which an observed, ambiguous input is interpreted as a certain, structured expression [9].", "startOffset": 200, "endOffset": 203}, {"referenceID": 8, "context": "Interested readers are referred to [9] and [7] for more details.", "startOffset": 35, "endOffset": 38}, {"referenceID": 6, "context": "Interested readers are referred to [9] and [7] for more details.", "startOffset": 43, "endOffset": 46}, {"referenceID": 16, "context": "2 Unger\u2019s method Unger\u2019s method is a fairly brute-force algorithm for parsing CFGs [17].", "startOffset": 83, "endOffset": 87}, {"referenceID": 8, "context": "These procedures for obtaining the best and next-best parse trees at OR- and AND-nodes are similar to those we described previously [9].", "startOffset": 132, "endOffset": 135}, {"referenceID": 0, "context": "where Qi : R\u2192 [0, 1] is the quantile function for the distribution of values emitted by the ith technique.", "startOffset": 14, "endOffset": 20}, {"referenceID": 7, "context": "The four distance-based techniques used are as follows: \u2022 A fast elastic matching variant [8] which finds a matching between the points of the input and model strokes and minimizes the sum of distances between matched points.", "startOffset": 90, "endOffset": 93}, {"referenceID": 3, "context": "\u2022 A functional approximation technique [4] which models stroke coordinates as parametric functions expressed as truncated Legendre-Sobolev series.", "startOffset": 39, "endOffset": 42}, {"referenceID": 15, "context": "\u2022 An offline technique [16] based on rasterizing strokes, treating filled pixels as points in Euclidean space, and computing the Hausdorff distance between those point sets.", "startOffset": 23, "endOffset": 27}, {"referenceID": 14, "context": "We collected symbol occurence and co-occurence rates from the Infty project corpus [15] as well as from the LTEX sources of University of Waterloo course notes for introductory algebra and calculus courses.", "startOffset": 83, "endOffset": 87}, {"referenceID": 10, "context": "The first replicates the 2011 and 2012 CROHME evaluations [11, 12], which focus on the top-ranked expression only.", "startOffset": 58, "endOffset": 66}, {"referenceID": 11, "context": "The first replicates the 2011 and 2012 CROHME evaluations [11, 12], which focus on the top-ranked expression only.", "startOffset": 58, "endOffset": 66}, {"referenceID": 8, "context": "To evaluate the efficacy of our recognizer\u2019s correction mechanism, we also replicated a user-focused evaluation which was initially developed to test an earlier version of the recognizer [9].", "startOffset": 187, "endOffset": 190}, {"referenceID": 8, "context": "In previous work, we compared the accuracy of a version of the MathBrush recognizer against that of the 2011 entrants [9].", "startOffset": 118, "endOffset": 121}, {"referenceID": 11, "context": "We also participated in the 2012 competition, placing second behind a corporate entrant [12].", "startOffset": 88, "endOffset": 92}, {"referenceID": 10, "context": "For details, refer to the competition paper [11].", "startOffset": 44, "endOffset": 48}, {"referenceID": 8, "context": ")\u201d refers to the recognizer described in this paper, \u201cUniversity of Waterloo (2012)\u201d refers to the version submitted to the CROHME 2012 competition, and \u201cUniversity of Waterloo (2011)\u201d refers to the version used for a previous publication [9].", "startOffset": 239, "endOffset": 242}, {"referenceID": 10, "context": "The remaining rows are reproduced from the CROHME reports [11, 12].", "startOffset": 58, "endOffset": 66}, {"referenceID": 11, "context": "The remaining rows are reproduced from the CROHME reports [11, 12].", "startOffset": 58, "endOffset": 66}, {"referenceID": 11, "context": "With respect to the Vision Objects recognizer, a short description may be found in the CROHME reports [12, 13].", "startOffset": 102, "endOffset": 110}, {"referenceID": 12, "context": "With respect to the Vision Objects recognizer, a short description may be found in the CROHME reports [12, 13].", "startOffset": 102, "endOffset": 110}, {"referenceID": 8, "context": "2 Evaluation on Waterloo corpus In previous work, we proposed a user-oriented accuracy metric that measured how accurate an expression was recognized by counting how many corrections needed to be made to the results [9].", "startOffset": 216, "endOffset": 219}, {"referenceID": 5, "context": "We therefore augmented the relation classifier training data with larger transcriptions from a 2011 collection study [6].", "startOffset": 117, "endOffset": 120}, {"referenceID": 6, "context": "Further evidence of this \u201cover-training\u201d of the 2011 system is pointed out by MacLean [7].", "startOffset": 86, "endOffset": 89}], "year": 2014, "abstractText": "Recognizing handwritten mathematics is a challenging classification problem, requiring simultaneous identification of all the symbols comprising an input as well as the complex two-dimensional relationships between symbols and subexpressions. Because of the ambiguity present in handwritten input, it is often unrealistic to hope for consistently perfect recognition accuracy. We present a system which captures all recognizable interpretations of the input and organizes them in a parse forest from which individual parse trees may be extracted and reported. If the top-ranked interpretation is incorrect, the user may request alternates and select the recognition result they desire. The tree extraction step uses a novel probabilistic tree scoring strategy in which a Bayesian network is constructed based on the structure of the input, and each joint variable assignment corresponds to a different parse tree. Parse trees are then reported in order of decreasing probability. Two accuracy evaluations demonstrate that the resulting recognition system is more accurate than previous versions (which used non-probabilistic methods) and other academic math recognizers.", "creator": "LaTeX with hyperref package"}}}