{"id": "1409.5752", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Sep-2014", "title": "On the Impact of Multiobjective Scalarizing Functions", "abstract": "Recently, there has been a renewed interest in decomposition-based approaches for evolutionary multiobjective optimization. However, the impact of the choice of the underlying scalarizing function(s) is still far from being well understood. In this paper, we investigate the behavior of different scalarizing functions and their parameters. We thereby abstract firstly from any specific algorithm and only consider the difficulty of the single scalarized problems in terms of the search ability of a (1+lambda)-EA on biobjective NK-landscapes. Secondly, combining the outcomes of independent single-objective runs allows for more general statements on set-based performance measures. Finally, we investigate the correlation between the opening angle of the scalarizing function's underlying contour lines and the position of the final solution in the objective space. Our analysis is of fundamental nature and sheds more light on the key characteristics of multiobjective scalarizing functions.", "histories": [["v1", "Fri, 19 Sep 2014 18:41:36 GMT  (237kb)", "http://arxiv.org/abs/1409.5752v1", "appears in Parallel Problem Solving from Nature - PPSN XIII, Ljubljana : Slovenia (2014)"]], "COMMENTS": "appears in Parallel Problem Solving from Nature - PPSN XIII, Ljubljana : Slovenia (2014)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["bilel derbel", "dimo brockhoff", "arnaud liefooghe", "s\\'ebastien verel"], "accepted": false, "id": "1409.5752"}, "pdf": {"name": "1409.5752.pdf", "metadata": {"source": "CRF", "title": "On the Impact of Multiobjective Scalarizing Functions", "authors": ["Bilel Derbel", "Dimo Brockhoff", "Arnaud Liefooghe", "S\u00e9bastien Verel"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 140 9.57 52v1 [cs.AI] 19 Sep 2014"}, {"heading": "1 Introduction", "text": "Multi-objective optimization problems often occur in practice and evolutionary multi-objective optimization (EMO) algorithms are independently solvable (EA operators have proven to be well applicable to them - especially if the problem under investigation is not linear and / or derivatives of objective functions are not available or meaningless. In addition to the broad class of paretodominance-based algorithms such as NSGA-II or SPEA2, a current interest in so-called decomposition-based algorithms can be observed, which break down the multi-objective problem into a series of objective \"optimization problems.\" Examples of such algorithms include MSOPS [1], MOEA / D [2], and their many variants. We refer [3] for a current overview of the topic. The main idea behind these algorithms is to define a set of (desired) search directions in objective space and to define the scalarizing functions that correspond to these directions."}, {"heading": "2 Scalarizing Functions", "text": "We consider the maximization of two objectives f1, f2, that the search points x-X typically point to an objective vector f (x) = (x), f2 (x)) = (z1, z2) in so-called objective space f (x). However, a solution x is dominated by another solution if f1 (x), f2 (y), f2 (x), and for at least one i, fi (y) > fi (x). The set of all solutions that are not dominated by others is called Pareto and its image is called Pareto front.Many ways to split a multi-objective optimization into a number of) individual objective scalarization functions exist, including prominent examples of weighted sums (WS), weighted chebychev (T), or augmented weighted chebychev (suction)."}, {"heading": "3 Experimental Design", "text": "This section presents the experimental setting that allows us to analyze the scalarizing approaches presented above on biobjective \u03c1MNK landscapes. The \u03c1MNKlandscape family represents a problem-free model used for the construction of multiobjective multimodal landscapes with objective correlation [11]. A biobjective \u03c1MNKlandscape aims to maximize an objective function vector f: {0, 1} n \u2192 [0, 1] 2. A correlation parameter \u03c1 defines the degree of conflict between the objectives. We examine a random instance for each one in Table 2.We examine the two scalarizing functions snorm and suction in Table 1 with different parameter settings for the weighting coefficient vector and \u03b5 parameters, as in Table 2. The WS (resp. T) function corresponds to the norm with \u03b5 = 1 (resp. T) and \u03b5 = 0, respectively."}, {"heading": "4 Single Search Behavior", "text": "This section is dedicated to the study of optimization paths, followed by individual independent (1 + \u03bb) -EA runs for each direction angle \u03b4 and parameter \u03b5 of a scaled problem. In particular, we examine the definitive approaches that the (1 + \u03bb) -EA has achieved in terms of diversity and convergence, and give a sound explanation of how search behavior relates to the lines of identical function values of the scaling functions."}, {"heading": "4.1 Diversity: Final Angle", "text": "In Fig. 1 (left) we examine the average angle of the final solution obtained by the algorithm when using the f1 axis with the help of Snorm. The final angle of the solution x is defined as \u03c6 (x) = arctan (f2 (x) / f1 (x). However, it informs about the actual direction that the search process follows. We can see that the final solutions are in symmetrical positions with respect to the direction angle \u03c0 / 4. This is coherent with the symmetrical nature of \u03c1MNKlandscapes [11]. For WS (\u03b5 = 1), each individual direction angle points to a different final angle than the drawn angle. For T (\u03b5 = 0), the extreme directional angles ultimately reach \"similar\" regions of objective space. These regions actually correspond to the lexicographically optimal points of the Pareto front, which is shifted due to the choice of the utopian point that goes beyond."}, {"heading": "4.2 Convergence: Relative Deviation to Best", "text": "In the following, we will examine the effects of the scaling function parameters on the performance of the (1 + \u03bb) -EA with respect to the convergence to the pareto front. To this end, for each of the directional angles \u03b4 we will calculate the objective vector z, T, which corresponds to the best (minimum) fitness value with respect to T, for all the experimental parameter combinations and for all the simulations we examined. For both functions, we will consider the objective vector z, which corresponds to the best obtained for each directional angle, and each \u03b5 value. We will then calculate the relative deviation of z with respect to the ultimate viewing angle T, which we define as follows: \u2206 (z) = (T (z) -T (z) -D (z) -D (z) -D, T). Note that this relative deviation factor is not calculated with respect to the T function, which is to be considered the reference angle of the solution quality."}, {"heading": "4.3 Understanding the Impact of the Opening Angle", "text": "In this section, we argue that the dynamics of the previously observed search process are rather independent of the scaling function taking into account or its parameters. Instead, we show that the search process is guided by the positioning of the lines of identical function values in objective space - described by the opening angle, i.e., the angle between the line of identical function values and the f1 axis (cf. Proposition 1).Figure 2 shows three typical examples of the (1 + \u03bb) -EA in objective space for different parameter settings. The typical initial solution maps around the point z = (0.5) in objective space, which is the average objective vector for a random solution of the MNK landscapes. The evolution of the current solution can be explained by combining two effects, the first being given by the independent bit-flip mutation operator, which generates more offspring in a particular direction, due to the underlying properties of the MNK landscape taking into account the second function."}, {"heading": "5 Global Search Behavior", "text": "In the previous section, we considered each individual (1 + \u03bb) -EA separately. However, the goal of a universal decomposition-based algorithm is indexed to calculate a set of solutions that approximate the entire Pareto front. In this section, we will examine the quality of the quantity that is calculated when combining the solutions through different configurations of the scalarization functions. A natural way to do this is to use the same \u03b5 value for all directional angles.Figure 4 illustrates the relative performance, in terms of hypervolume difference and multiplicative epsilon indicators [12], when considering such an adjustment and aggregation of the solutions from the different weight vectors.The hypervolume reference point is determined at the origin, and the reference set is the best known approximation for the instance taking into account. Over all MNK landscapes considered, we found that the two indicator values minimize."}, {"heading": "6 Open(ing) (Re)search Lines", "text": "We have presented a comprehensive empirical study that sheds more light on the effects of scalarization functions within the decomposition-based multi-objective optimization. Our results showed that, given the weighting coefficient vector and the relative importance of the weighted sum and the Chebychev term in the function, the opening of the lines of equal functional values that explicitly guide the search towards a particular region of objective space is crucial. While our results are critical in terms of a rather simple setting in which multiple scalarization processes operate independently, they take a fundamental step toward understanding scalarization processes in order to achieve complete convergence, these lines play a crucial role in achieving diversification."}], "references": [{"title": "Multiple Single Objective Pareto Sampling", "author": ["E.J. Hughes"], "venue": "CEC.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2003}, {"title": "MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition", "author": ["Q. Zhang", "H. Li"], "venue": "IEEE TEC 11(6)", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Generalized Decomposition", "author": ["I. Giagkiozis", "R.C. Purshouse", "P.J. Fleming"], "venue": "EMO.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Nonlinear Multiobjective Optimization", "author": ["K. Miettinen"], "venue": "Kluwer, Boston, MA, USA", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1999}, {"title": "Adaptation of scalarizing functions in MOEA/D: An adaptive scalarizing function-based multiobjective evolutionary algorithm", "author": ["H. Ishibuchi", "Y. Sakane", "N. Tsukamoto", "Y. Nojima"], "venue": "EMO.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "A study on the specification of a scalarizing function in MOEA/D for many-objective knapsack problems", "author": ["H. Ishibuchi", "N. Akedo", "Y. Nojima"], "venue": "LION7.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Using trade-off information in decision-making algorithms", "author": ["I. Kaliszewski"], "venue": "Computers & Operations Research 27(2)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2000}, {"title": "On the Properties of the R2 Indicator", "author": ["D. Brockhoff", "T. Wagner", "H. Trautmann"], "venue": "Genetic and Evolutionary Computation Conference (GECCO 2012).", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "An Augmented Weighted Tchebycheff Method With Adaptively Chosen Parameters for Discrete Bicriteria Optimization Problems", "author": ["K. D\u00e4chert", "J. Gorski", "K. Klamroth"], "venue": "Computers & Operations Research 39(12)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "On the impact of scalarizing functions on evolutionary multiobjective optimization", "author": ["B. Derbel", "D. Brockhoff", "A. Liefooghe", "S. Verel"], "venue": " Research Report RR-8512, INRIA Lille - Nord Europe", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "On the structure of multiobjective combinatorial search space: MNK-landscapes with correlated objectives", "author": ["S. Verel", "A. Liefooghe", "L. Jourdan", "C. Dhaenens"], "venue": "Eur J Oper Res 227(2)", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Performance Assessment of Multiobjective Optimizers: An Analysis and Review", "author": ["E. Zitzler", "L. Thiele", "M. Laumanns", "C.M. Fonseca", "V. Grunert da Fonseca"], "venue": "IEEE TEC 7(2)", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Examples of such algorithms include MSOPS [1], MOEA/D [2], and their many variants.", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "Examples of such algorithms include MSOPS [1], MOEA/D [2], and their many variants.", "startOffset": 54, "endOffset": 57}, {"referenceID": 2, "context": "We refer to [3] for a recent overview on the topic.", "startOffset": 12, "endOffset": 15}, {"referenceID": 3, "context": "[4] for an overview.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Especially with respect to decomposition-based EMO algorithms, it has been reported that the choice of the scalarizing function and their parameters has an impact on the search process [3].", "startOffset": 185, "endOffset": 188}, {"referenceID": 4, "context": "Moreover, it has been noted that adapting the scalarizing function\u2019s parameters during the search can allow improvement over having a constant set of scalarizing functions [5].", "startOffset": 172, "endOffset": 175}, {"referenceID": 5, "context": "[6], to the best of our knowledge, all of them investigate it on a concrete EMO algorithm and on the quality of the resulting solution sets when more than one scalarizing function is optimized (typically as mentioned above, in a dependent manner).", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Many ways of decomposing a multiobjective optimization problem into a (set of) single-objective scalarizing functions exist, including the prominent examples of weighted sum (WS), weighted Chebychev (T), or augmented weighted Chebychev (Saug) [4].", "startOffset": 243, "endOffset": 246}, {"referenceID": 3, "context": "For most of them, theoretical results, especially about which Pareto-optimal solutions are attainable, exist [4,7] but they are typically of too general nature to allow for statements on the actual search performance of (stochastic) optimization algorithms.", "startOffset": 109, "endOffset": 114}, {"referenceID": 6, "context": "For most of them, theoretical results, especially about which Pareto-optimal solutions are attainable, exist [4,7] but they are typically of too general nature to allow for statements on the actual search performance of (stochastic) optimization algorithms.", "startOffset": 109, "endOffset": 114}, {"referenceID": 0, "context": "In the following, we also consider a case of Sgen that combines WS and T with a single parameter \u03b5: the normalized Snorm(z) = (1\u2212 \u03b5)T(z)+ \u03b5WS(z) where \u03b1 = 1\u2212 \u03b5 and \u03b5 \u2208 [0, 1].", "startOffset": 168, "endOffset": 174}, {"referenceID": 0, "context": "For optimizing in a given search direction (d1, d2) in objective space, we follow [1,8] and set \u03bbi = 1/di.", "startOffset": 82, "endOffset": 87}, {"referenceID": 7, "context": "For optimizing in a given search direction (d1, d2) in objective space, we follow [1,8] and set \u03bbi = 1/di.", "startOffset": 82, "endOffset": 87}, {"referenceID": 8, "context": "For the question of how small \u03b5 should be chosen to find all Paretooptimal solutions in exact biobjective discrete optimization, we refer to [9].", "startOffset": 141, "endOffset": 144}, {"referenceID": 3, "context": "As mentioned above, one important property of a scalarizing function turns out to be the shape of its sets of equal function values, which are known for the WS, T, and Saug functions [4].", "startOffset": 183, "endOffset": 186}, {"referenceID": 7, "context": "We think that it is necessary to state those opening angles explicitly in order to gain a deeper intuitive understanding of the above scalarizing approaches and related concepts such as the R2 indicator [8] or more complicated scalarizing algorithms such as MOEA/D [2].", "startOffset": 203, "endOffset": 206}, {"referenceID": 1, "context": "We think that it is necessary to state those opening angles explicitly in order to gain a deeper intuitive understanding of the above scalarizing approaches and related concepts such as the R2 indicator [8] or more complicated scalarizing algorithms such as MOEA/D [2].", "startOffset": 265, "endOffset": 268}, {"referenceID": 9, "context": "The following proposition, proven in the accompanying report [10], states these opening angles \u03b8i between the equi-utility lines and the f1-axis, see also Fig.", "startOffset": 61, "endOffset": 65}, {"referenceID": 0, "context": "9} \u03bb = n \u03b4 = j \u00b7 10 \u00b7 \u03c02 , j \u2208 [[1, 99]] m = 2 bit-flip rate = 1/n Snorm: \u03b5 = l \u00b7 10 ; l \u2208 [[0, 100]] n = 128 stopped after Saug : \u03b5 = l \u00b7 10 ; l \u2208 [[0, 10]]; k \u2208 [[\u22121, 2]] k = 4 n iterations", "startOffset": 32, "endOffset": 39}, {"referenceID": 9, "context": "9} \u03bb = n \u03b4 = j \u00b7 10 \u00b7 \u03c02 , j \u2208 [[1, 99]] m = 2 bit-flip rate = 1/n Snorm: \u03b5 = l \u00b7 10 ; l \u2208 [[0, 100]] n = 128 stopped after Saug : \u03b5 = l \u00b7 10 ; l \u2208 [[0, 10]]; k \u2208 [[\u22121, 2]] k = 4 n iterations", "startOffset": 149, "endOffset": 156}, {"referenceID": 10, "context": "The family of \u03c1MNKlandscapes constitutes a problem-independent model used for constructing multiobjective multimodal landscapes with objective correlation [11].", "startOffset": 155, "endOffset": 159}, {"referenceID": 0, "context": "A bi-objective \u03c1MNKlandscape aims at maximizing an objective function vector f : {0, 1} \u2192 [0, 1].", "startOffset": 90, "endOffset": 96}, {"referenceID": 9, "context": "More exhaustive results can be found in [10].", "startOffset": 40, "endOffset": 44}, {"referenceID": 0, "context": "\u03b5 \u2208 [0 ,1 ]", "startOffset": 4, "endOffset": 11}, {"referenceID": 0, "context": "\u03b5 \u2208 [0 ,1 ] 6 7 8 9 10 11", "startOffset": 4, "endOffset": 11}, {"referenceID": 10, "context": "This is coherent with the symmetric nature of \u03c1MNKlandscapes [11].", "startOffset": 61, "endOffset": 65}, {"referenceID": 11, "context": "4 illustrates the relative performance, in terms of hypervolume difference and multiplicative epsilon indicators [12], when considering such a setting and aggregating the solutions from the different weight vectors.", "startOffset": 113, "endOffset": 117}], "year": 2014, "abstractText": "Recently, there has been a renewed interest in decomposition-based approaches for evolutionary multiobjective optimization. However, the impact of the choice of the underlying scalarizing function(s) is still far from being well understood. In this paper, we investigate the behavior of different scalarizing functions and their parameters. We thereby abstract firstly from any specific algorithm and only consider the difficulty of the single scalarized problems in terms of the search ability of a (1+\u03bb)-EA on biobjective NK-landscapes. Secondly, combining the outcomes of independent single-objective runs allows for more general statements on set-based performance measures. Finally, we investigate the correlation between the opening angle of the scalarizing function\u2019s underlying contour lines and the position of the final solution in the objective space. Our analysis is of fundamental nature and sheds more light on the key characteristics of multiobjective scalarizing functions.", "creator": "gnuplot 4.6 patchlevel 1"}}}