{"id": "1409.6440", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Sep-2014", "title": "A non-linear learning & classification algorithm that achieves full training accuracy with stellar classification accuracy", "abstract": "A fast Non-linear and non-iterative learning and classification algorithm is synthesized and validated. This algorithm named the \"Reverse Ripple Effect(R.R.E)\", achieves 100% learning accuracy but is computationally expensive upon classification. The R.R.E is a (deterministic) algorithm that super imposes Gaussian weighted functions on training points. In this work, the R.R.E algorithm is compared against known learning and classification techniques/algorithms such as: the Perceptron Criterion algorithm, Linear Support Vector machines, the Linear Fisher Discriminant and a simple Neural Network. The classification accuracy of the R.R.E algorithm is evaluated using simulations conducted in MATLAB. The R.R.E algorithm's behaviour is analyzed under linearly and non-linearly separable data sets. For the comparison with the Neural Network, the classical XOR problem is considered.", "histories": [["v1", "Tue, 23 Sep 2014 08:17:07 GMT  (1916kb)", "http://arxiv.org/abs/1409.6440v1", "45 Pages"], ["v2", "Fri, 31 Oct 2014 17:46:07 GMT  (1916kb)", "http://arxiv.org/abs/1409.6440v2", "43 Pages"]], "COMMENTS": "45 Pages", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["rashid khogali"], "accepted": false, "id": "1409.6440"}, "pdf": {"name": "1409.6440.pdf", "metadata": {"source": "META", "title": "A non-linear learning & classification algorithm that achieves full training accuracy with stellar classification accuracy", "authors": ["Rashid Khogali", "Anastasios N. Venetsanopoulos"], "emails": ["rkhogali@ryerson.ca,", "khogali@alumni.utoronto.ca"], "sections": [{"heading": null, "text": "This is a raw manuscript proposed and submitted by the author of the EE8209 course instructor in winter 2012. EE8209 course instructor: Prof. Anastasios N. Venetsanopoulos.Copyright \u00a9 2014, by the author. All rights reserved. Content Pg. 1 Introduction 11.1 Algorithm Validation 12 Introduction of (R.R.E) Algorithm 12.1 Brainstorming 1 2.2 Preliminary Definitions 2 2.3 The Monotonically Decreasing Weight Function 2 2.4 Introducing Cost (P) 3 Introducing Variance 4 2.6 Introducing the Auxiliary Sensitivity Factor (RP) 4 2.7 Prediction Capabilities of Discriminant Function 5 2.8 Naming & Defining the Classification Datector (P).4 Introducing Cost (P) 3 Introducing Variance 4 2.6 Introducing the Auxiliary Sensitivity Factor (RP) 4 2.6 R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.2.8 R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.2.8 R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.2.8 R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R.R."}, {"heading": "1 Introduction", "text": "In this study, a non-iterative algorithm called the \"Reverse Ripple Algorithm (R.R.E)\" is synthesized and validated using numerical simulations performed in MATLAB. The R.R.E algorithm is a classification algorithm that achieves 100% learning / training accuracy and stellar classification accuracy even with limited training data. This algorithm achieves excellent results when data is categorically separable (linear and non-linear separable), and the algorithm is modifiable to be able to: \u2022 classify based on cost \u2022 classify based on multi-category case \u2022 operate in an unattended mode after limited monitoring of training data."}, {"heading": "1.1 Algorithm Validation", "text": "The R.R.E algorithm is compared with the P.C.A (Perceptron Criterion Algorithm [7]) and then compared with Linear Support Vector Machines [2] for two types of data sets. Finally, it is compared with a Neural Network ([3], [6]) of comparable complexity for a non-linear separable case (XOR problem). Due to time constraints, bootstrapping, dredging and boosting validation techniques were not used, instead a variant of S-fold cross-validation techniques was used to validate the algorithm against the P.C.A. See [1] and [3] for details on the Perceptron Criterion Algorithm, Linear Support Vector Machines, the Linear Fisher Discriminant ([5]) and Neural Networks."}, {"heading": "2 Introducing the (R.R.E) Algorithm", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Brainstorming", "text": "Let's try to overlay all the monotonously decreasing weight functions at all training points, intuitively this makes sense as it increases the weight to properly classify a test point that is radially close to a known training point. The idea is that we use training points as evidence and assign a modified distance (dissimilarity) between a test point and training points in the neighborhood as our criteria for categorizing a test point. The smaller the distance or dissimilarity is, the more likely it is that a test point belongs to a region that is dominated or heavily populated by the training data in question, and the greater the distance, the less likely the training point belongs to that region; this explains why the weight functions monotonically have to be decreased due to our intuition. We also know that our training set is initially small, so the deviations in our weight functions should be huge in order to afford the known entropy / known information we need to maximize on the basis of our weight choices, even if it means that we are very remote from the regions of the training we can afford."}, {"heading": "2.2 Preliminary Definitions", "text": "Due to the limited scope of the work, we consider only the case of the two categories, but the reader is advised that the algorithm can be easily extended to the case of the multi-category. Let 1T and 2T be the totality of all training points associated with category 1W and category 2W, respectively, with 1Txi and 2Tx j and kV representing the totality of all test / verification data where kk Vx."}, {"heading": "2.3 The Monotonically Decreasing Weight Function", "text": "Let (x) Wm be the monotonously decreasing weight function. \u2022 A good idea is to consider (x) Wm as Gaussian, but other desirable choices would be the decay exponential function or the hyperbolic function. \u2212 If we treat a particular training point as Bernoulli R.V. in terms of categorization (w1 or w2), we can believe without prior information that the sum of many future test points converging in the vicinity or vicinity of that training point will become more and more like the normal distribution. Also (x) Wm = 2xe \u2212. Next, we will overlay (x) Wm at all training points (x).From signal processing, this operation is a revolutionary operation between (x) Wm and a delta explicitly centered on points.Superposition is a great idea because we can impose (x) Wm at all training points (x) Wm."}, {"heading": "2.4 Introducing Cost (P)", "text": "s keep it simple: Assuming linear fixed costs, p1 in connection with the choice of w1 and linear fixed costs p2 in connection with the choice of category w2, we can modify our discrimination function as follows: =) (kxG 2p, \u2212 \u2212 i xxxx ik T ike) () (- 1p, \u2212 j xxxx jk T jke) () (, 1Txi, 2Tx j and kk Vx. Notice that p2 inputs the influence factor for category 1 and vice versa, because high linear costs of category 2 should increase the selection of category 1. Depending on the type of costs, they can also be introduced simultaneously or separately in the exponential argument, but we will ignore this for the time being, but bear in mind that we can introduce several types of costs at the same time with varying degrees of influence."}, {"heading": "2.5 Introducing Variance", "text": "The reason why we divide into and jn instead of using ji nn + is that we have to give both categories a fair chance if the training data is biased (we indirectly mitigate (potential) errors in the example model). Next, we leave f (n) any increasing function of n. We try to grow f (n) with n. The exact functional family for n, which does a good job, is currently unknown and suggests that it could possibly be derived empirically. So let f (n) in its implicit form. By introducing a dynamic variant as opposed to adopting a fixed variant, we modify the discrimination function as follows:"}, {"heading": "2.6 Introducing the Auxiliary Sensitivity Factor (\u03bb)", "text": "If we are not worried about overadjustment, but want our discrimination function to produce results that come arbitrarily close to our training data, we can apply sensitivity 1 > > \u03bb. In the modified discrimination function below: (1) (2) (2) (2) (1), 1Txi, 2Tx, j and kk Vx. The greater this work is, the less we use mutual information between adjacent data points and each training point like a delta function, enabling us to retrieve any training value from adjacent training values with minimal disruption. For much of this work, we will eliminate the sensitivity factor and for the time being assume a uniform value to avoid overadjustment. We will reintroduce it in Section 3.5 to demonstrate that the algorithm is capable of achieving a learning accuracy of 100%."}, {"heading": "2.7 Prediction Capabilities of Discriminant Function", "text": "The discriminatory function of the R.R.E algorithm has a quantitative interpretation. At uniform categorical costs, when evaluated at a test point, it gives us approximately the number of training points (and / or fractions of a training point) that are \"close\" to a test point. The greater the absolute value of the discriminatory function evaluated at a test point, the better the confidence level of the prediction / classification. In fact, given this insight, we may choose to reject output values of the discrimination functions that do not reach a reliable threshold, with the threshold being derived empirically depending on the application. Implementing this threshold would improve the accuracy of the classification, but introduces a rejection clause - which requires further consideration."}, {"heading": "2.8 Naming & Defining the Classification Algorithm", "text": "We call the algorithm the \"reverse ripple effect\" algorithm (R.R.E) because each training point is superimposed with a Gaussian function like a \"water ripple,\" but unlike a water ripple, its variance decreases as more training points are inserted. i.e Radial Gaussian variance thus decreases \"inversely\" as opposed to a real ripple that actually propagates in water over time. \u2022 The R.R.E algorithm is a multi-part algorithm. For most classification applications, we only need a part (A) followed by a part (C)."}, {"heading": "2.9 Potential Optimization", "text": "2.9.1: The possible need for \"filtering\" training data The memory requirements of the discrimination function grow linearly with each training point used. Classification becomes mathematically expensive if the training set 21 TT U is large. One way to fix this without much elaboration is: according to Part A or Part B of the algorithm, it will be temporarily removed from the discrimination function for each training point, perform the discrimination function, and verify that it correctly classifies all original training points, including the remote training point. If so, then the remote training point was redundant, so that we can safely permanently eliminate it from our discrimination function. We must iteratively perform this for all training points and our last reduced training points that remain in the discrimination function, as this filtering process may not be unique because this filtering process is sensitive to the order in which we select the training points we want to filter. This filter exercise has a number that is supported by a training point (O) during the number of training points."}, {"heading": "2.10 R.R.E Algorithm Impervious to Noisy Training Environments", "text": "We define the training environments in such a way that there is a high cross-sectional correlation or, better yet, similarity between the training points of different categories. (D) We define the training environments in such a way that there is a high cross-sectional correlation or similarity between the training points of different categories. (D) We expand our training environment by extending the training points we know and, in the rare case where a new training point has a classification that conflicts with the classification of training points, we simply expand the point m times. m For the worse case scenario, we will usually state 2 that it was originally used to remove the wrong pre-existing training point and the other will guarantee the correct classification into the question. This is very powerful because the training points can be cancelled if m = 1 and newer, more correct training is carried out if 2 = 2."}, {"heading": "2.11 R.R.E Algorithm Validation", "text": "The R.R.E algorithm is compared to the P.C.A (Perceptron Criterion Algorithm) in Section 3, using two types of data sets; then it is compared to Linear Support Vector Machines in Section 4 for two types of data sets; and finally, in Section 5, it is compared to a neural network of comparable complexity under a simple, non-linear separable case (XOR problem)."}, {"heading": "3 Comparing R.R.E to P.C.A", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1: Using \u201ciris_setosa_versicolor\u201d Dataset", "text": "In fact, it is a way in which people are able to decide for themselves what they want and what they want. (...) In fact, it is a way in which people are able to decide for themselves what they want. (...) In fact, it is a way in which people are able to decide for themselves what they want. (...) It is a way in which people are able to decide for themselves what they want. (...) It is as if people are able to decide for themselves what they want. (...) It is a way in which people are able to decide for themselves what they want. (...) It is a way in which people are able to decide for themselves what they want. (...)"}, {"heading": "3.3 Applying P.C.A to the \u201ciris_setosa_versicolor\u201d Dataset", "text": "iSe rf\u00fc ide rf\u00fc ide for the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green the green"}, {"heading": "3.4: Using \u201cIris_Versicolor_VirginicaV2\u201d Dataset", "text": "In Sections 3.1-3.3, the R.R.E and P.C.A were implemented on a dataset that was favorable to P.C.A (since the data is somewhat linearly correlated along each category), yet the R.R.E achieved better overall classification results. In this section, we compare both algorithms with a dataset that is not so friendly - a dataset that is divisible but not linearly separable, as a convincing argument that the R.R.E can achieve 100% learning / training accuracy, while the P.C.A cannot. We use the \"Iris _ Versicolor _ VirginicaV2,\" a slight modification of Iris _ Versicolor _ Virginica, \"so that the 10 overlapping categorical datasets were adjusted marginally so as not to overlap."}, {"heading": "3.5: Applying R.R.E Algorithm to the \u201cIris_Versicolor_VirginicaV2\u201d dataset", "text": "(1) (1) (1) (1) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (1) (1) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (1) (1) (2) (1) (2) (1) (2) (2) (2) (2) (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1)) (1) (1) (1) (1) (1) (1) (1) () (1) (1) () (1) (1) () (1) (1) () () (1) (1) (1) () (1) (1) ((1) (1) () (1) () (1) (1 () (1) (() (1) (2) ((1) (2) (1) (() (1 ((1) (2) (1) ((1) (((1) (2) (1 ((((1) (2) (1) (1) ((1) ((((1) (1) (1) (1 (((((((((1))) (((1) (2) (1) (1) ((1) (1) ((((1) (1) ((((((1) (1)) (1) (((((1)) ((((1)) ("}, {"heading": "3.6: Applying P.C.A to the \u201cIris VersicolorVirginicaV2\u201d Dataset", "text": "We used 100% of the data set as our training data to calculate the weight vector a r. We used a learning rate of 01.0 (.) (= \u03b7\u03b7 k, a threshold or criterion of \u03b8 = 0 and a starting weight initiala r = [0, 0, 1] T. We obtained a final weight vector from Tfinala] 5.1680 13.228, - 56.5, [= r without complete convergence after 3000 iterations. Note that we cannot converge because the data are not separable linearly. We achieved a learning / training accuracy of 56%. To capture the learning behavior of P.C.A under the conditions of Section 3.3, the criterion function above iterations is shown below. Note the non-convergence; the oscillating behavior is not because the learning rate is too high, but because the data are not separable linearly."}, {"heading": "3.7: Overall Comparison", "text": "The table below summarizes the results of Sections 3.2 and 3.3 plus it contains results of the extrapolated configurations (different training data on test data ratios) that were not mentioned. The table below summarizes the results of Sections 3.5 and 3.6, where we have shown that if the data set is separable but not linearly separable, R.R.E can achieve 100% learning / training accuracy, while the P.C.A can achieve 100% training accuracy Comparison between R.R.E and P.C.A using the entire \"Iris _ Versicolor _ VirginicaV2\" data set for training. Algorithm Training AccuracyR.R.R.E 100% training dataP.C.A 56% Overall, we see that P.C.A requires training n iterations to match the advanced weight vector with a training computational complexity of O (n)."}, {"heading": "4 Comparing R.R.E to Linear Support Vector Machines using \u201cSupport1\u201d & \u201cSupport2\u201d Datasets", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1: Preliminary", "text": "The figure below visually shows the \"Support1\" dataset. This dataset is a modified version of the \"iris _ setosa _ versicolor\" dataset, where an outlier has been removed so that the data can be separated linearly in order to correctly implement the linear carrier vector machine in the next section. See Appendix B3 for a tabular listing of all the normalized and extended row vectors contained in the dataset."}, {"heading": "4.2: Applying R.R.E Algorithm to the \u201cSupport1\u201d Dataset", "text": "The objective of this section is to achieve an optimum margin between the categories by achieving a learning / training accuracy of 100%. Using our discriminatory function below () (1) () (2) (1) (1) (2) (1) (2) (1) (2) (1) (2) (2) (2) (2) (2) (2) (1) (2) (2) (2)) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) ((2) (2) (2) (2) ((2) (2) (2) (2) ((2) (2) ((2) (2) (2) (2) ((2) (2) (2) ((2) (2) (2) (2) ((2) (2) ((2) (2) (2) (2) ((2) (2) (2) (2) (2) (2) (2) (2) ("}, {"heading": "4.3: Applying Linear S.V.M to the \u201cSupport1\u201d Dataset", "text": "Step 1: Determining the support vectors To use the linear S.V.M., we must first identify the support vectors (Step 2: Extending and normalizing the support vectors Our support vectors from category one are: TV] 3.5 [1.1 = and TV] 3.3,4.5 [2.1 = Our support vector from category two is: TV] 3.4.5 [1.2 = After augmentation and normalization of our support vectors we get: T] 0.3, 0.5, 0.1 [1 =, T] 3.3, 4.5, 0.1 [2 = and T] 0.3, 4.5, 0.1 [, 3 \u2212 \u2212 \u2212 Step 3: Structure of the standardized core matrix Our normalized kernel matrix is Tjiun-solved."}, {"heading": "4.4: Applying R.R.E Algorithm to the \u201cSupport2\u201d Dataset Versus L.S.V.M & Fisher Linear Discriminant", "text": "In Section 4.3, we used a data set (\"Support1\") that enabled us to conveniently use linear S.V.M. We now turn our attention to a data scenario that compromises the functionality of both Fisher Linear Discriminant and Linear S.V.M. We use R.R.E. under the conditions set forth in 4.2. The \"support2\" data was constructed from the ground up: A visual representation of this data can be seen below: R.R.E creates a symmetrical decision interface below it: After implementing R.R.E, we get the contour diagrams of the feature space shown below: The above result shows how powerful R.R.E is because it is able to generate both linear and non-linear optimal margins. If a linear S.V.M is applied to \"suppot2\" data, it would provide insufficient results because the data is non-separable."}, {"heading": "5 Comparing R.R.E to a 2-2-1 Neural Network in application to the popular XOR Problem", "text": "The popular XOR problem is a classic problem that cannot be solved with linear classifiers / perceptrons. We try to solve the XOR problem using the R.R.E algorithm and then compare the results with a solution of a neural network of modest complexity. We use a neural network as a \"benchmark\" because it is commonly used to solve linearly inseparable classification problems. We use a 2- 2-1 neural network because it is simple but computationally sufficient to solve the XOR problem."}, {"heading": "5.1: Applying R.R.E Algorithm to the XOR problem", "text": "() () () () () () () () () () () () () () () () () () () ()) () () () () () ()) () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () ()) () () () () () () () () () ()) () () () () () () () ()) () () () () ()) () () () ()) () () () ()) () () () ()) () () ()) () () () () ()) () () ()) () () ()) () () ()) () () () ()) () () () ()) () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()"}, {"heading": "5.2: Solving the XOR problem using a 2-2-1 Neural Network", "text": "A 2-2-1 neural network was constructed from the first principles using the batch-back propagation algorithm to solve the XOR problem under the following conditions: -The two default batch inputs are: x1 = [-1, -1,1,1] x2 = [-1,1, -1.1] - The desired (batch) target is [-1,1,1, -1]. - We used a learning rate \u03b7 = 0.1, a threshold (\u03b8) of 0.001 and a hyperbolic tan sigmoidal activation function. - The arbitrarily selected initial hidden weights are: = 3,.04.02.05, 0.03.01.0jiW (Input to hidden layer weights, hats indicate bias weights) = 9, 2,.031.027.0kjW (Hidden to output layer weights, hats indicate bias weights) After executing the script for the neural network, we verify that the network actually meets the final weights according to the surface size XR-32."}, {"heading": "5.3: Overall Comparison", "text": "Achieving Targets Note that it is pointless to calculate the percentage errors of each algorithm, since the zouts in the table above can be made arbitrarily close to the target values by adjusting certain parameters. For the neural network, we can make our threshold / criterion very small and adjust our learning rate accordingly. For the R.R.E algorithm, we can use redundant training (duplication), we can also use a higher helper sensitivity factor (\u03bb = 3 to reach all | Zout | = 1) or alternatively, we can use a higher series deviation reduction function f (n). Minimum training abilities A significant point is that both algorithms achieve acceptable results through different mechanisms, but the R.R.E consistently requires a minimum training of only one step, whereas the neural network usually requires more iterations (epochs)."}, {"heading": "6 Conclusion", "text": "We see that R.R.E is a powerful algorithm, but unlike many other learning algorithms, it is not iterative and shifts all of its training calculation to its discrimination function, where it becomes computationally expensive as it classifies. Although R.R.E achieves excellent results on various fronts, work needs to be done to reduce the computational complexity of its discrimination function. A proposal to solve this problem would be to use the \"training data filtering\" as proposed in Section 2.9.1. Another option would be to use a subset of training points / terms to be included in the discrimination function - an intuitive suggestion would be to use the training points that have the slightest discrepancy with the test point in question, as they have the greatest impact, but that would mean that we would need to develop a robust system, possibly a look-up table that can efficiently store, find and compare all training points with a test point before they are included in the discrimination function."}, {"heading": "7 Acknowledgments", "text": "I thank Prof. Anastasios N. Venetsanopoulos1 for proofreading a preliminary version of this manuscript and for providing a valuable graduate course (EE8209) in Intelligent Systems, which provided me with the background to this project. Course EE8209 kindly provided three sets of data. I thank Dr. Alp Kucukelbir for generously taking the time to read this manuscript (in September 2014) and suggest constructive comments that still need to be implemented."}, {"heading": "8 Bibliography", "text": "[2] Cortes, C.; Vapnik, V. (1995). \"Support-Vector networks\". \"Pattern learning 20 (3): 273 doi: 10.1007 / BF00994018. [3] Duda, R. O.; Hart, P. E.; Stork, D. H. (2000)\" 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000"}], "references": [{"title": "Pattern Recognition and Machine Learning", "author": ["Bishop", "Christopher M"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "Pattern Classification (2nd ed.)", "author": ["R.O. Duda", "P.E. Hart", "D.H. Stork"], "venue": "Wiley Interscience", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "The Use of Multiple Measurements in Taxonomic Problems", "author": ["R.A. Fisher"], "venue": "Annals of Eugenics", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1936}, {"title": "A Logical Calculus of Ideas Immanent in Nervous Activity", "author": ["McCulloch", "Warren", "Walter Pitts"], "venue": "Bulletin of Mathematical Biophysics", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1943}], "referenceMentions": [{"referenceID": 1, "context": "It is then compared to Linear Support Vector Machines [2] on two types of data sets as well.", "startOffset": 54, "endOffset": 57}, {"referenceID": 2, "context": "Lastly, it is compared to a Neural Network ([3],[6]) of comparable complexity for a non-linearly separable case (XOR problem).", "startOffset": 44, "endOffset": 47}, {"referenceID": 4, "context": "Lastly, it is compared to a Neural Network ([3],[6]) of comparable complexity for a non-linearly separable case (XOR problem).", "startOffset": 48, "endOffset": 51}, {"referenceID": 0, "context": "See [1]and [3] for details on the Perceptron Criterion Algorithm, Linear Support Vector machines, the Linear Fisher Discriminant ([5]) and Neural Networks.", "startOffset": 4, "endOffset": 7}, {"referenceID": 2, "context": "See [1]and [3] for details on the Perceptron Criterion Algorithm, Linear Support Vector machines, the Linear Fisher Discriminant ([5]) and Neural Networks.", "startOffset": 11, "endOffset": 14}, {"referenceID": 3, "context": "See [1]and [3] for details on the Perceptron Criterion Algorithm, Linear Support Vector machines, the Linear Fisher Discriminant ([5]) and Neural Networks.", "startOffset": 130, "endOffset": 133}, {"referenceID": 0, "context": ") ) ( = =\u03b7 \u03b7 k , a threshold or criterion of \u03b8=0 and an initial weight initial a r = [0, 0, 1].", "startOffset": 85, "endOffset": 94}, {"referenceID": 0, "context": ") ) ( = =\u03b7 \u03b7 k , a threshold or criterion of \u03b8=0 and an initial weight initial a r = [0, 0, 1].", "startOffset": 85, "endOffset": 94}, {"referenceID": 0, "context": "-The two given batch inputs are: x1 =[-1,-1,1,1] x2=[-1,1,-1,1]", "startOffset": 37, "endOffset": 48}, {"referenceID": 0, "context": "-The two given batch inputs are: x1 =[-1,-1,1,1] x2=[-1,1,-1,1]", "startOffset": 37, "endOffset": 48}, {"referenceID": 0, "context": "-The two given batch inputs are: x1 =[-1,-1,1,1] x2=[-1,1,-1,1]", "startOffset": 52, "endOffset": 63}, {"referenceID": 0, "context": "-The two given batch inputs are: x1 =[-1,-1,1,1] x2=[-1,1,-1,1]", "startOffset": 52, "endOffset": 63}, {"referenceID": 0, "context": "- The desired (batch) target is [-1,1,1,-1].", "startOffset": 32, "endOffset": 43}, {"referenceID": 0, "context": "- The desired (batch) target is [-1,1,1,-1].", "startOffset": 32, "endOffset": 43}], "year": 2014, "abstractText": "A fast Non-linear and non-iterative learning and classification algorithm is synthesized and validated. This algorithm named the \"Reverse Ripple Effect(R.R.E)\", achieves 100% learning accuracy but is computationally expensive upon classification. The R.R.E is a (deterministic) algorithm that super imposes Gaussian weighted functions on training points. In this work, the R.R.E algorithm is compared against known learning and classification techniques/algorithms such as: the Perceptron Criterion algorithm, Linear Support Vector machines, the Linear Fisher Discriminant and a simple Neural Network. The classification accuracy of the R.R.E algorithm is evaluated using simulations conducted in MATLAB. The R.R.E algorithm's behaviour is analyzed under linearly and non-linearly separable data sets. For the comparison with the Neural Network, the classical XOR problem is considered. This is a raw manuscript proposed and submitted by the author to the EE8209 Course Instructor in Winter 2012. EE8209 Course Instructor: Prof. Anastasios N. Venetsanopoulos. Copyright \u00a9 2014, by the author. All rights reserved.", "creator": "PrimoPDF http://www.primopdf.com"}}}