{"id": "1409.7165", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Sep-2014", "title": "Heterogeneous Metric Learning with Content-based Regularization for Software Artifact Retrieval", "abstract": "The problem of software artifact retrieval has the goal to effectively locate software artifacts, such as a piece of source code, in a large code repository. This problem has been traditionally addressed through the textual query. In other words, information retrieval techniques will be exploited based on the textual similarity between queries and textual representation of software artifacts, which is generated by collecting words from comments, identifiers, and descriptions of programs. However, in addition to these semantic information, there are rich information embedded in source codes themselves. These source codes, if analyzed properly, can be a rich source for enhancing the efforts of software artifact retrieval. To this end, in this paper, we develop a feature extraction method on source codes. Specifically, this method can capture both the inherent information in the source codes and the semantic information hidden in the comments, descriptions, and identifiers of the source codes. Moreover, we design a heterogeneous metric learning approach, which allows to integrate code features and text features into the same latent semantic space. This, in turn, can help to measure the artifact similarity by exploiting the joint power of both code and text features. Finally, extensive experiments on real-world data show that the proposed method can help to improve the performances of software artifact retrieval with a significant margin.", "histories": [["v1", "Thu, 25 Sep 2014 06:33:57 GMT  (576kb)", "http://arxiv.org/abs/1409.7165v1", "to appear in IEEE International Conference on Data Mining (ICDM), Shen Zhen, China, December 2014"]], "COMMENTS": "to appear in IEEE International Conference on Data Mining (ICDM), Shen Zhen, China, December 2014", "reviews": [], "SUBJECTS": "cs.LG cs.IR cs.SE", "authors": ["liang wu", "hui xiong", "liang du", "bo liu", "guandong xu", "yong ge", "yanjie fu", "yuanchun zhou", "jianhui li"], "accepted": false, "id": "1409.7165"}, "pdf": {"name": "1409.7165.pdf", "metadata": {"source": "CRF", "title": "Heterogeneous Metric Learning with Content-based Regularization for Software Artifact Retrieval", "authors": ["Liang Wu", "Hui Xiong", "Liang Du", "Bo Liu", "Guandong Xu", "Yong Ge", "Yanjie Fu", "Yuanchun Zhou", "Jianhui Li"], "emails": ["lijh}@cnic.cn", "yanjie.fu}@rutgers.edu", "duliang@ios.ac.cn", "liubo@research.nec.com.cn", "guandong.xu@uts.edu.au", "yong.ge@uncc.edu"], "sections": [{"heading": null, "text": "This year is the highest in the history of the country."}, {"heading": "II. PROPOSED APPROACH", "text": "Since the code contains useful hints for linking text, code and between them, our goal is to calculate the similarity between code and queries directly and to use the similarity further to improve the query results. To allow calculation in different attribute spaces for code and text, two transformation matrices are constructed to map the text queries and code files into the same semantic space. Therefore, in this section we first present the definition of the problem and then describe the framework we propose. Then, two types of code factors are discussed. Finally, the HMLCR model and its optimization are presented."}, {"heading": "A. Problem Definition", "text": "The query was considered a general information retrieval task, where the queries are written in natural languages, and the code consists of two parts that contain both source code and text information consisting of comments, identifier names, and so on. Here, we refer to the code as D = {(xc1, x d 1, l1), \u00b7 \u00b7 \u00b7, (x c m, x d m, lm)}, which contains m code programs, each of which consists of source code xc and text information xd. Each code has a label li that represents the specific function of the code. Labels are generated either manually or according to certain disciplines of a specific domain. For most projects, each code file has a unique identifier, but in some real-world applications the label is used to denote the function of a code file. Thus, different programs can share an identical identifier. The query set is referred to either as Q = {(lxd1, l1), \u00b7 \u00b7 x, \u00b7 n."}, {"heading": "B. Overview", "text": "Figure 1 presents the framework of our proposed approach. Word features are first extracted from the textual content of code. Since words cannot fully reveal functional information from program code, we propose additional code functions to overcome the bottleneck. Code functions are obtained by extracting code relations and iteratively combining adjacent program expressions based on their structure. As code and word features are heterogeneous, two transformation matrices U and V are constructed in the training process, as illustrated in Figure 1, by the HMLCR model. Although it is difficult to characterize the intrinsic structure of the ensemble, the two transformation matrices can be considered heterogeneous distance metrics between the text properties and code activities, and are used to enable direct comparison of the similarity between heterogeneous features U and V. Although it is difficult to characterize the intrinsic structure of the ensemble, and to place heterogeneous data in the new space."}, {"heading": "C. Feature Extraction for Code Programs.", "text": "This year it is more than ever before."}, {"heading": "D. Heterogeneous Metric Learning with Content-based Regularization", "text": "This year is the highest in the history of the country."}, {"heading": "III. EXPERIMENT", "text": "In this section, we first present the experimental settings and the data set, then describe the evaluation metrics we use. Next, we discuss some important results of the experiments. Finally, some case studies are presented and discussed."}, {"heading": "A. Dataset", "text": "The model was built into commercial software and tested to index programs through textual descriptions, but the result cannot be disclosed due to intelligent property issues. Thus, we obtain datasets from two real open source software, the platform of Eclipse1 and Filezilla2, and make the experimental results so reproducible. Eclipse is a popular open source IDE for many programming languages mainly written in Java. The project includes about 7,000 classes with about 89,000 methods in about 2.4 million lines of code (MLOC). Filezilla is an open source FTP client for Windows, Mac OS X and GNU / Linux. The project is written in C and is much smaller than Eclipse with about 8,012 methods in 410 KLOC. To test our model, we extract titles of Eclipse error reports and Filezilla change logs as queries for code."}, {"heading": "B. Evaluation Metrics", "text": "In order to measure the accuracy of the proposed approach, we use three methods to evaluate the results of the query: the first is the precision of n (P @ n), which does not take into account the position of the true positives, since another measurement is used to model the usefulness of the returned results in relation to rankings. P @ n is calculated in Equation 10.P @ n = | {relevant code files} \u01c0 {retrieved code files} | n (10) As in the field of software development, the traceability module is often designed for professionals who are more patient to click on the results of the lower ranking. Therefore, it is more important to retrieve all code files, i.e. to use Recall at n (R @ n) as a second evaluation metric. Similar to P @ n, the positions of the results are not taken into account to calculate the p-values of the query."}, {"heading": "C. Settings", "text": "To investigate the effectiveness of the proposed approach, we have introduced several methods from the field of software development and multimedia information retrieval as our baselines. \u2022 COS: Cosmic similarity is based on the method [1], [19] which calculates the cosmic similarity between the textual representation of code and queries. \u2022 LM: This method incorporates language modeling to calculate the similarity between the textual representation of code and queries. \u2022 LSI: The latent semantic indexing method which first compresses the textual representation of code and queries and then calculates their similarity. [7] CFA: Cross-modal factor analysis model first proposed in."}, {"heading": "D. Experimental Results", "text": "In this section we describe the retrieval performance of the proposed model and baselines. Table II illustrates the precision at the top 1, 2, 4 and 5 for Eclipse dataset. The best result is achieved by the proposed approach and the precision at the first and second positions is obviously improved. An interesting observation is that the CFA + CR method, which incorporates content-based regularization (CR) into the crossmodal factor analysis model, which achieves the second-best result. The observation, on the one hand, shows the usefulness of the term as a multimedia and the adoption of heterogeneous metric learning methods to model it; on the other hand, it demonstrates the effectiveness of content-based regulation, since the method significantly exceeds the original CFA method. Similar results are observed in Filezillas's P @ n results, as in Table III. A difference is that the result of the CFA + CR analysis base line of the CFA is the result of the CFA + the Fixity-based regulation, which is the result of the Fixilla P @ n results of the Fixity-based Fixity."}, {"heading": "E. Case Study", "text": "To further explain the changes made by the proposed method, HMLCR, several automatically generated cases are presented in Table VIII. There is a manually selected case in each row of the table. In each case, a code feature, and the corresponding textual features are given for comparison. Textual features are the best rated words used by CFA and HMLCR. There are mainly two types of features, code relation properties and code snippet features in this work. Since common code patterns are more difficult to understand, we select some class name features from code relationships for simplicity. The evaluation of each word is calculated on the basis of the transformation matrices U and V. Since U describes the similarity between words and themes, and V describes the similarity between code features and themes, UV T can be regarded as the similarity between text and code features."}, {"heading": "IV. RELATED WORK", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "V. CONCLUSION AND FUTURE WORK", "text": "In this paper, which is based on the requirements of retrieving software artifacts, we propose a novel approach to calculating the similarity between code and text. First, we formulated the problem and then proposed a novel method of feature extraction for code programs. Two types of code functions were proposed to utilize the functional and operational information of source codes that differ from the textual properties inherited from traditional methods. To calculate the similarity between codes and words, we introduced a novel, heterogeneous, metric approach to map the heterogeneous media in a unified space. Since the code functions contain useful textual content, content-based regularization was further proposed to capture the content of the source code. Content-based regularization distinguishes our work from the existing multimodal retrieval techniques. Data sets derived from two open source projects are used to validate the findings of our experiment heterogeneous information."}, {"heading": "ACKNOWLEDGEMENT", "text": "We thank the support of the National Natural Science Foundation of China 91224006, the Strategic Priority Research Program of the Chinese Academy of Sciences XDA06010202 and XDA05050601), the \"12th Five-Year Plan\" in Support of Science and Technology 2012BAK17B01 and 2013BAD15B02, the joint project of Foshan and the Chinese Academy of Sciences under grant number 2012YS23, the China National 973 Program 2014CB340301."}], "references": [{"title": "Recovering traceability links between code and documentation", "author": ["G. Antoniol", "G. Canfora", "G. Casazza", "A. De Lucia", "E. Merlo"], "venue": "Software Engineering, IEEE Transactions on, 28(10):970\u2013983", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "et al", "author": ["R. Baeza-Yates", "B. Ribeiro-Neto"], "venue": "Modern information retrieval, volume 463. ACM press New York", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Matching words and pictures", "author": ["K. Barnard", "P. Duygulu", "D. Forsyth", "N. De Freitas", "D.M. Blei", "M.I. Jordan"], "venue": "The Journal of Machine Learning Research, 3:1107\u20131135", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "Extraction and visualization of traceability relationships between documents and source code", "author": ["X. Chen"], "venue": "Proceedings of the IEEE/ACM international conference on Automated software engineering, pages 505\u2013510. ACM", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Best practices for automated traceability", "author": ["J. Cleland-Huang", "R. Settimi", "E. Romanova", "B. Berenbach", "S. Clark"], "venue": "Computer, 40(6):27\u201335", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Hipikat: Recommending pertinent software development artifacts", "author": ["D. Cubranic", "G.C. Murphy"], "venue": "Software Engineering, 2003. Proceedings. 25th International Conference on, pages 408\u2013418. IEEE", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Adams re-trace: traceability link recovery via latent semantic indexing", "author": ["A. De Lucia", "R. Oliveto", "G. Tortora"], "venue": "Proceedings of the 30th international conference on Software engineering, pages 839\u2013842. ACM", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Indexing by latent semantic analysis", "author": ["S.C. Deerwester", "S.T. Dumais", "T.K. Landauer", "G.W. Furnas", "R.A. Harshman"], "venue": "Journal of The American Society for Information Science and Technology, 41(6):391\u2013 407", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1990}, {"title": "Heterogeneous metric learning for cross-modal multimedia retrieval", "author": ["J. Deng", "L. Du", "Y.-D. Shen"], "venue": "Web Information Systems Engineering\u2013WISE 2013, pages 43\u201356. Springer Berlin Heidelberg", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Cerberus: Tracing requirements to source code using information retrieval", "author": ["M. Eaddy", "A.V. Aho", "G. Antoniol", "Y.-G. Gu\u00e9h\u00e9neuc"], "venue": "dynamic analysis, and program analysis. In Program Comprehension, 2008. ICPC 2008. The 16th IEEE International Conference on, pages 53\u201362. IEEE", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "A scenario-driven approach to trace dependency analysis", "author": ["A. Egyed"], "venue": "Software Engineering, IEEE Transactions on, 29(2):116\u2013132", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "On the use of relevance feedback in ir-based concept location", "author": ["G. Gay", "S. Haiduc", "A. Marcus", "T. Menzies"], "venue": "Software Maintenance, 2009. ICSM 2009. IEEE International Conference on, pages 351\u2013360. IEEE", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Automatic image annotation and retrieval using cross-media relevance models", "author": ["J. Jeon", "V. Lavrenko", "R. Manmatha"], "venue": "Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pages 119\u2013126. ACM", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2003}, {"title": "Xtraque: traceability for product line systems", "author": ["W. Jirapanthong", "A. Zisman"], "venue": "Software & Systems Modeling, 8(1):117\u2013144", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Multimedia content processing through cross-modal association", "author": ["D. Li", "N. Dimitrova", "M. Li", "I.K. Sethi"], "venue": "Proceedings of the eleventh ACM international conference on Multimedia, pages 604\u2013611. ACM", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2003}, {"title": "Feature location via information retrieval based filtering of a single scenario execution trace", "author": ["D. Liu", "A. Marcus", "D. Poshyvanyk", "V. Rajlich"], "venue": "Proceedings of the 22nd IEEE/ACM international conference on Automated software engineering, pages 234\u2013243. ACM", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Bug localization using latent dirichlet allocation", "author": ["S.K. Lukins", "N.A. Kraft", "L.H. Etzkorn"], "venue": "Information and Software Technology, 52(9):972\u2013990", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Introduction to information retrieval", "author": ["C.D. Manning", "P. Raghavan", "H. Sch\u00fctze"], "venue": "volume 1. Cambridge University Press, Cambridge", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Recovering documentation-to-sourcecode traceability links using latent semantic indexing", "author": ["A. Marcus", "J.I. Maletic"], "venue": "Software Engineering, 2003. Proceedings. 25th International Conference on, pages 125\u2013135. IEEE", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Augmented bug localization using past bug information", "author": ["B.D. Nichols"], "venue": "Proceedings of the 48th Annual Southeast Regional Conference, page 61. ACM", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "A new approach to cross-modal multimedia retrieval", "author": ["N. Rasiwasia", "J. Costa Pereira", "E. Coviello", "G. Doyle", "G.R. Lanckriet", "R. Levy", "N. Vasconcelos"], "venue": "Proceedings of the international conference on Multimedia, pages 251\u2013260. ACM", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Bridging the gap: Query by semantic example", "author": ["N. Rasiwasia", "P.J. Moreno", "N. Vasconcelos"], "venue": "Multimedia, IEEE Transactions on, 9(5):923\u2013938", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Kernels and regularization on graphs", "author": ["A.J. Smola", "R. Kondor"], "venue": "Learning theory and kernel machines, pages 144\u2013158. Springer Berlin Heidelberg", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "Locating user functionality in old code", "author": ["N. Wilde", "J.A. Gomez", "T. Gust", "D. Strasburg"], "venue": "Software Maintenance, 1992. Proceerdings., Conference on, pages 200\u2013205. IEEE", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1992}, {"title": "Learning similarity function between objects in heterogeneous spaces", "author": ["W. Wu", "J. Xu", "H. Li"], "venue": "Microsoft Research Technique Report", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Heterogeneous metric learning with joint graph regularization for cross-media retrieval", "author": ["X. Zhai", "Y. Peng", "J. Xiao"], "venue": "Twenty-Seventh AAAI Conference on Artificial Intelligence", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Distance metric learning with application to clustering with side-information", "author": ["E.P. Xing", "M.I. Jordan", "S. Russell", "A. Ng"], "venue": "Advances in neural information processing systems, pages 505\u2013512", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2002}, {"title": "Distance Metric Learning for Large Margin Nearest Neighbor Classification", "author": ["Kilian Weinberger", "John Blitzer", "Lawrence Saul"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2006}, {"title": "Information-theoretic metric learning", "author": ["Jason V. Davis", "Brian Kulis", "Prateek Jain", "Suvrit Sra", "Inderjit S. Dhillon"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "Adapting Visual Category Models to New Domains", "author": ["Kate Saenko", "Brian Kulis", "Mario Fritz", "Trevor Darrell"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}, {"title": "Traceability", "author": ["J.D. Palmer"], "venue": "Software Requirements Engineering, Second Edition, IEEE Computer Society Press, pages 412\u2013422", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2000}, {"title": "Experiences in discovering", "author": ["C. Jensen", "W. Scacchi"], "venue": "modeling, and reenacting open source software development processes. In Unifying the Software Process Spectrum, pages 449\u2013462. Springer Berlin Heidelberg", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}, {"title": "Program slicing", "author": ["M. Weiser"], "venue": "Proceedings of the 5th international conference on Software engineering, pages 439\u2013449. IEEE Press", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1981}], "referenceMentions": [{"referenceID": 30, "context": "It gives essential support in understanding the relationships within and across software requirements, design and implementation [31].", "startOffset": 129, "endOffset": 133}, {"referenceID": 0, "context": "Along this stream of research, vector space model and stochastic language model are first adopted [1], [5].", "startOffset": 98, "endOffset": 101}, {"referenceID": 4, "context": "Along this stream of research, vector space model and stochastic language model are first adopted [1], [5].", "startOffset": 103, "endOffset": 106}, {"referenceID": 6, "context": "Subsequently, several other information retrieval models, as well as their variants and ensembles, are also experimented to improve the accuracy of the software artifact retrieval task[7], [19], [4].", "startOffset": 184, "endOffset": 187}, {"referenceID": 18, "context": "Subsequently, several other information retrieval models, as well as their variants and ensembles, are also experimented to improve the accuracy of the software artifact retrieval task[7], [19], [4].", "startOffset": 189, "endOffset": 193}, {"referenceID": 3, "context": "Subsequently, several other information retrieval models, as well as their variants and ensembles, are also experimented to improve the accuracy of the software artifact retrieval task[7], [19], [4].", "startOffset": 195, "endOffset": 198}, {"referenceID": 27, "context": "Although homogeneous distance metric learning [28], [29] has been proposed to learn a good metric to compare two objects and has played a significant role in statistical classification and information retrieval, it requires the objects to share identical features and are comparable.", "startOffset": 46, "endOffset": 50}, {"referenceID": 28, "context": "Although homogeneous distance metric learning [28], [29] has been proposed to learn a good metric to compare two objects and has played a significant role in statistical classification and information retrieval, it requires the objects to share identical features and are comparable.", "startOffset": 52, "endOffset": 56}, {"referenceID": 20, "context": "Similar ideas have been proposed to solve the problem of cross modal multimedia retrieval, such as using text as queries to retrieve music and using text to retrieve pictures [21], [26], [3], [9].", "startOffset": 175, "endOffset": 179}, {"referenceID": 25, "context": "Similar ideas have been proposed to solve the problem of cross modal multimedia retrieval, such as using text as queries to retrieve music and using text to retrieve pictures [21], [26], [3], [9].", "startOffset": 181, "endOffset": 185}, {"referenceID": 2, "context": "Similar ideas have been proposed to solve the problem of cross modal multimedia retrieval, such as using text as queries to retrieve music and using text to retrieve pictures [21], [26], [3], [9].", "startOffset": 187, "endOffset": 190}, {"referenceID": 8, "context": "Similar ideas have been proposed to solve the problem of cross modal multimedia retrieval, such as using text as queries to retrieve music and using text to retrieve pictures [21], [26], [3], [9].", "startOffset": 192, "endOffset": 195}, {"referenceID": 32, "context": "A similar line of methods that are also designed for this goal of removing the useless expressions has been proposed and studied well in the area of software engineering, which is formally named as program slicing method [33].", "startOffset": 221, "endOffset": 225}, {"referenceID": 26, "context": "Distance metric learning [27] has attracted much attention in the last decade.", "startOffset": 25, "endOffset": 29}, {"referenceID": 21, "context": "In the area of cross modal multimedia retrieval, researchers proposed heterogeneous distance metric learning methods to compare different media [22], [21], [26], [15], [13], [25], [3], [9].", "startOffset": 144, "endOffset": 148}, {"referenceID": 20, "context": "In the area of cross modal multimedia retrieval, researchers proposed heterogeneous distance metric learning methods to compare different media [22], [21], [26], [15], [13], [25], [3], [9].", "startOffset": 150, "endOffset": 154}, {"referenceID": 25, "context": "In the area of cross modal multimedia retrieval, researchers proposed heterogeneous distance metric learning methods to compare different media [22], [21], [26], [15], [13], [25], [3], [9].", "startOffset": 156, "endOffset": 160}, {"referenceID": 14, "context": "In the area of cross modal multimedia retrieval, researchers proposed heterogeneous distance metric learning methods to compare different media [22], [21], [26], [15], [13], [25], [3], [9].", "startOffset": 162, "endOffset": 166}, {"referenceID": 12, "context": "In the area of cross modal multimedia retrieval, researchers proposed heterogeneous distance metric learning methods to compare different media [22], [21], [26], [15], [13], [25], [3], [9].", "startOffset": 168, "endOffset": 172}, {"referenceID": 24, "context": "In the area of cross modal multimedia retrieval, researchers proposed heterogeneous distance metric learning methods to compare different media [22], [21], [26], [15], [13], [25], [3], [9].", "startOffset": 174, "endOffset": 178}, {"referenceID": 2, "context": "In the area of cross modal multimedia retrieval, researchers proposed heterogeneous distance metric learning methods to compare different media [22], [21], [26], [15], [13], [25], [3], [9].", "startOffset": 180, "endOffset": 183}, {"referenceID": 8, "context": "In the area of cross modal multimedia retrieval, researchers proposed heterogeneous distance metric learning methods to compare different media [22], [21], [26], [15], [13], [25], [3], [9].", "startOffset": 185, "endOffset": 188}, {"referenceID": 22, "context": "It improves the smoothness of the mappings by penalizing the functions that change abruptly on the joint data graph [23].", "startOffset": 116, "endOffset": 120}, {"referenceID": 14, "context": "Note that the matrices U and V are initialized (line 1) based on the Cross-modal Factor Analysis algorithm[15].", "startOffset": 106, "endOffset": 110}, {"referenceID": 31, "context": "The approach of using bug reports and change logs is frequently adopted in the area of software engineering, which is based on change reenactment [32].", "startOffset": 146, "endOffset": 150}, {"referenceID": 17, "context": "Another measure method we employ is the normalized Discounted Cumulative Gain(nDCG)[18].", "startOffset": 83, "endOffset": 87}, {"referenceID": 0, "context": "\u2022 COS: The cosine similarity based method [1], [19] which calculates the cosine similarity between the textual representation of code and queries.", "startOffset": 42, "endOffset": 45}, {"referenceID": 18, "context": "\u2022 COS: The cosine similarity based method [1], [19] which calculates the cosine similarity between the textual representation of code and queries.", "startOffset": 47, "endOffset": 51}, {"referenceID": 0, "context": "\u2022 LM: This method adopts language modeling to calculate the similarity between the textual representation of code and queries [1], [5].", "startOffset": 126, "endOffset": 129}, {"referenceID": 4, "context": "\u2022 LM: This method adopts language modeling to calculate the similarity between the textual representation of code and queries [1], [5].", "startOffset": 131, "endOffset": 134}, {"referenceID": 6, "context": "\u2022 LSI: The latent semantic indexing method that first compresses the textual representation of code and queries and then calculate their similarity [7], [25].", "startOffset": 148, "endOffset": 151}, {"referenceID": 24, "context": "\u2022 LSI: The latent semantic indexing method that first compresses the textual representation of code and queries and then calculate their similarity [7], [25].", "startOffset": 153, "endOffset": 157}, {"referenceID": 14, "context": "\u2022 CFA: Cross-modal Factor Analysis model, which is first proposed in [15] and is designed to discover the associations between the feature space of different media.", "startOffset": 69, "endOffset": 73}, {"referenceID": 5, "context": "Retrieving the code files by a query written in natural languages is first introduced in the area of software engineering and has been applied in a variety of tasks, such as development [6] and maintenance [24] of software, localization of concepts [12] and features [16], tracing requirements back to source code [10] and identify the corresponding code of a bug[17], [20].", "startOffset": 186, "endOffset": 189}, {"referenceID": 23, "context": "Retrieving the code files by a query written in natural languages is first introduced in the area of software engineering and has been applied in a variety of tasks, such as development [6] and maintenance [24] of software, localization of concepts [12] and features [16], tracing requirements back to source code [10] and identify the corresponding code of a bug[17], [20].", "startOffset": 206, "endOffset": 210}, {"referenceID": 11, "context": "Retrieving the code files by a query written in natural languages is first introduced in the area of software engineering and has been applied in a variety of tasks, such as development [6] and maintenance [24] of software, localization of concepts [12] and features [16], tracing requirements back to source code [10] and identify the corresponding code of a bug[17], [20].", "startOffset": 249, "endOffset": 253}, {"referenceID": 15, "context": "Retrieving the code files by a query written in natural languages is first introduced in the area of software engineering and has been applied in a variety of tasks, such as development [6] and maintenance [24] of software, localization of concepts [12] and features [16], tracing requirements back to source code [10] and identify the corresponding code of a bug[17], [20].", "startOffset": 267, "endOffset": 271}, {"referenceID": 9, "context": "Retrieving the code files by a query written in natural languages is first introduced in the area of software engineering and has been applied in a variety of tasks, such as development [6] and maintenance [24] of software, localization of concepts [12] and features [16], tracing requirements back to source code [10] and identify the corresponding code of a bug[17], [20].", "startOffset": 314, "endOffset": 318}, {"referenceID": 16, "context": "Retrieving the code files by a query written in natural languages is first introduced in the area of software engineering and has been applied in a variety of tasks, such as development [6] and maintenance [24] of software, localization of concepts [12] and features [16], tracing requirements back to source code [10] and identify the corresponding code of a bug[17], [20].", "startOffset": 363, "endOffset": 367}, {"referenceID": 19, "context": "Retrieving the code files by a query written in natural languages is first introduced in the area of software engineering and has been applied in a variety of tasks, such as development [6] and maintenance [24] of software, localization of concepts [12] and features [16], tracing requirements back to source code [10] and identify the corresponding code of a bug[17], [20].", "startOffset": 369, "endOffset": 373}, {"referenceID": 0, "context": "[1] first proposed to adopt Information Retrieval (IR) techniques to solve the problem.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Naive Bayes and TF-IDF [2] are used in their systems.", "startOffset": 23, "endOffset": 26}, {"referenceID": 7, "context": "More advanced approaches like Latent Semantic Indexing [8] are incorporated to increase the accuracy [19], [4].", "startOffset": 55, "endOffset": 58}, {"referenceID": 18, "context": "More advanced approaches like Latent Semantic Indexing [8] are incorporated to increase the accuracy [19], [4].", "startOffset": 101, "endOffset": 105}, {"referenceID": 3, "context": "More advanced approaches like Latent Semantic Indexing [8] are incorporated to increase the accuracy [19], [4].", "startOffset": 107, "endOffset": 110}, {"referenceID": 10, "context": "The researchers focus more on exploiting the domain specific rules to further improve their systems [11], [14] and better visualize the results [4].", "startOffset": 100, "endOffset": 104}, {"referenceID": 13, "context": "The researchers focus more on exploiting the domain specific rules to further improve their systems [11], [14] and better visualize the results [4].", "startOffset": 106, "endOffset": 110}, {"referenceID": 3, "context": "The researchers focus more on exploiting the domain specific rules to further improve their systems [11], [14] and better visualize the results [4].", "startOffset": 144, "endOffset": 147}, {"referenceID": 4, "context": "Some successful applications are summarized in [5].", "startOffset": 47, "endOffset": 50}, {"referenceID": 21, "context": "In [22], they predefined a concept dictionary and proposed a model to map the visual features to the concepts.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "A similar work is proposed in [21], while in this work the concepts are replaced with the automatically produced word clusters.", "startOffset": 30, "endOffset": 34}, {"referenceID": 31, "context": "In [32], [13], they seek to find the relatedness between the images and keywords.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "In [32], [13], they seek to find the relatedness between the images and keywords.", "startOffset": 9, "endOffset": 13}, {"referenceID": 29, "context": "Distance metric learning has also been used to transfer object recognition models to new domains, linking between visual features [30].", "startOffset": 130, "endOffset": 134}, {"referenceID": 24, "context": "A more general research topic is to find a heterogeneous distance metric between objects in different spaces [25].", "startOffset": 109, "endOffset": 113}, {"referenceID": 25, "context": "In [26], the joint graph regularization is incorporated.", "startOffset": 3, "endOffset": 7}], "year": 2014, "abstractText": "The problem of software artifact retrieval has the goal to effectively locate software artifacts, such as a piece of source code, in a large code repository. This problem has been traditionally addressed through the textual query. In other words, information retrieval techniques will be exploited based on the textual similarity between queries and textual representation of software artifacts, which is generated by collecting words from comments, identifiers, and descriptions of programs. However, in addition to these semantic information, there are rich information embedded in source codes themselves. These source codes, if analyzed properly, can be a rich source for enhancing the efforts of software artifact retrieval. To this end, in this paper, we develop a feature extraction method on source codes. Specifically, this method can capture both the inherent information in the source codes and the semantic information hidden in the comments, descriptions, and identifiers of the source codes. Moreover, we design a heterogeneous metric learning approach, which allows to integrate code features and text features into the same latent semantic space. This, in turn, can help to measure the artifact similarity by exploiting the joint power of both code and text features. Finally, extensive experiments on real-world data show that the proposed method can help to improve the performances of software artifact retrieval with a significant margin.", "creator": "LaTeX with hyperref package"}}}