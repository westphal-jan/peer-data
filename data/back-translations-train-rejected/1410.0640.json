{"id": "1410.0640", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Oct-2014", "title": "Term-Weighting Learning via Genetic Programming for Text Classification", "abstract": "This paper describes a novel approach to learning term-weighting schemes (TWSs) in the context of text classification. In text mining a TWS determines the way in which documents will be represented in a vector space model, before applying a classifier. Whereas acceptable performance has been obtained with standard TWSs (e.g., Boolean and term-frequency schemes), the definition of TWSs has been traditionally an art. Further, it is still a difficult task to determine what is the best TWS for a particular problem and it is not clear yet, whether better schemes, than those currently available, can be generated by combining known TWS. We propose in this article a genetic program that aims at learning effective TWSs that can improve the performance of current schemes in text classification. The genetic program learns how to combine a set of basic units to give rise to discriminative TWSs. We report an extensive experimental study comprising data sets from thematic and non-thematic text classification as well as from image classification. Our study shows the validity of the proposed method; in fact, we show that TWSs learned with the genetic program outperform traditional schemes and other TWSs proposed in recent works. Further, we show that TWSs learned from a specific domain can be effectively used for other tasks.", "histories": [["v1", "Thu, 2 Oct 2014 18:38:11 GMT  (161kb)", "https://arxiv.org/abs/1410.0640v1", null], ["v2", "Fri, 3 Oct 2014 19:47:03 GMT  (161kb)", "http://arxiv.org/abs/1410.0640v2", null], ["v3", "Mon, 6 Oct 2014 20:48:29 GMT  (161kb)", "http://arxiv.org/abs/1410.0640v3", null]], "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["hugo jair escalante", "mauricio a garc\\'ia-lim\\'on", "alicia morales-reyes", "mario graff", "manuel montes-y-g\\'omez", "eduardo f morales"], "accepted": false, "id": "1410.0640"}, "pdf": {"name": "1410.0640.pdf", "metadata": {"source": "CRF", "title": "Term-Weighting Learning via Genetic Programming for Text Classification", "authors": ["Hugo Jair Escalante", "Mauricio A. Gar\u0107\u0131a-Lim\u00f3n", "Alicia Morales-Reyes", "Mario Graff", "Manuel Montes-y-G\u00f3mez", "Eduardo F. Morales"], "emails": ["hugojair@inaoep.mx", "mauricio.garcia.cs@gmail.com", "a.morales@inaoep.mx", "mgraffg@gmail.com", "mmontesg@inaoep.mx", "emorales@inaoep.mx"], "sections": [{"heading": null, "text": "ar Xiv: 141 0.06 40v3 [cs.NThis paper describes a novel approach to learning term weighting programs (TWS) in the context of text classification. In text mining, a TWS determines the way documents are represented in a vector space model before a classifier is applied. While standard TWS has achieved acceptable performance (e.g. Boolean and term frequency schemes), the definition of TWS has traditionally been an art. In addition, it is still a difficult task to determine what is the best TWS for a given problem, and it is not yet clear whether better schemes than those currently available can be generated by combining known TWS. In this article, we propose a genetic program aimed at learning effective TWSs that can improve the performance of current schemes in text classification."}, {"heading": "1. Introduction", "text": "In fact, most of them will be able to abide by the rules that they have given themselves, and that they will be able to abide by the rules that they have given themselves. (...) It is not as if they would abide by the rules. (...) It is as if they were able to break the rules. (...) It is as if they were able to break the rules. (...) It is as if they were able to break the rules. (...) \"(...)\" (...) \"(...)\" (...) (() (() (()) (() () () () () () () () () () () () () () () () () () () () () () ()) () () () () ()) () () () () ()) () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()) () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () () () () () (() () () (() () ((() () () (() () (() (() ((() () ((() (() () () () () ((() () ((() () () (() () () (((() () () ((() () (((() () () (() (() (((() (() ((()"}, {"heading": "2. Text classification with the Bag of Words", "text": "Most of them are able to abide by the rules they have imposed on themselves. (...) Most of them are able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are able to understand themselves. (...) Most of them are not able to understand themselves. (...)"}, {"heading": "3. Related work", "text": "In fact, the fact is that most of them are able to outdo themselves and that they are able to outdo themselves. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "4. Learning term-weighting schemes via GP", "text": "As mentioned before, the traditional approach to defining TWS has been reasonably successful so far. However, it is not yet known whether we can automate the TWS definition process and obtain TWSs with better classification performance in telecom tasks. In this context, we propose a genetic programming solution that aims to automatically learn effective TWSs. We provide the genetic program with a pool of TDR and TR weights, as well as other TWSs, and let a program search for TWS that maximizes an estimate of the classification performance. So, instead of defining TWSs based on our own experience of text mining, we let a computer build an effective TWS itself. The advantage of this approach is that it can allow for each TWS problem to learn a specific TWS or learn TWSs from a data set (e.g. a small one) and translate them into another collection (e.g. a huge one)."}, {"heading": "4.1. Genetic programming", "text": "Genetic Programming (GP) (Langdon and Poli, 2001) is an evolutionary technique that follows the reproductive cycle of other evolutionary algorithms such as genetic algorithms (see Figure 1): An initial population is generated (randomly or according to a predefined criterion), then individuals are selected, recombined, mutated, and then returned to the solution pool. GP's characteristic feature compared to other evolutionary algorithms is that complex data structures are used to represent solutions (individuals), such as trees or diagrams. As a result, GP can be used to solve complex learning / modelling problems. Below, we describe the GP approach to learning TWSs for TC."}, {"heading": "4.2. TWS learning with genetic programming", "text": "We face the problem of learning TWS as an optimization method, where we want to find a TWS that maximizes the classification performance of a TWS-trained classifier. We define a valid TWS as a combination of: (1) other TWS, (2) TR, and (3) TDR factors, and limit the way such components can be combined by a set of arithmetic operators. We use GP as an optimization strategy in which each individual corresponds to a tree-coded TWS. The proposed genetic program examines the search space of TWS, which can be generated by combining TWSs, TRs, and TDRs with a predefined group of operators. The rest of this section describes the components of the proposed genetic program, namely representation, terminals, and function group, genetic operators, and fitness functions."}, {"heading": "4.2.1. Representation", "text": "Solutions to our problem are encoded as trees, defining terminal nodes as building blocks of TWS. On the other hand, we have internal tree nodes instantiated by arithmetic operators that combine the building blocks to generate new TWS. Figure 2 graphically illustrates this."}, {"heading": "4.2.2. Terminals and function set", "text": "As mentioned before, traditional TWSs are usually formed by two factors: a term document relevance (TDR) weight and a term relevance (TR) factor. The most commonly used TDR are the term frequencies (TF) as they combine with the vocabulary. We look at TDR indicators, but we also look at the standard TWSs with many alternatives. In this paper, we analyze the most common and effective TWSs as building blocks."}, {"heading": "4.2.3. Genetic operators", "text": "As explained above, in the GP, a population of individuals is initialized and developed according to some operators aimed at improving the quality of the population. To initialize, we used the standard rammed-half-and-half strategy (Yews and Smith, 2010), which generates half the population with (balanced) trees of maximum depth, and the other half with trees of varying depth. As genetic operators, we also used standard mechanisms: we looked at the subtree crossover and the point mutation. The role of the crossover is to take two promising solutions and combine their information to produce two offspring, with the goal that the offspring perform better than the parents. The subtree crossover works by selecting two parent solutions / trees (in our case via a tournament) and randomly selecting an internal node in each of the parent trees. Two offspring are generated by replacing the subtrees under the identified nodes in the parent nodes, which is replaced by the internal mutation function of the GP."}, {"heading": "4.2.4. Fitness function", "text": "As already mentioned, the goal of the proposed GP approach is to generate a TWS that receives a competitive classification performance. In this direction, the quality of an individual is evaluated by the classification performance of a predictable model that uses the representation generated by the TWS. Specifically, in order to solve the problem, the tree is first evaluated to generate a TWS with the training set. Once the training documents are represented by the appropriate TWS, we perform a k \u2212 fold cross-validation procedure to assess the effectiveness of the solution. In k \u2212 fold cross-validation, the training set is divided into k disjoint subsets, and k rounds of training and testing are performed; in each round k \u2212 1, sub-sets are used as a training set and 1 subset for testing, the process is repeated k times with another subset for testing. The average classification performance is used directly as a fitness function."}, {"heading": "4.3. Summary", "text": "When we are faced with a TC problem, we start by estimating all the terminals for the training set described in Table 1. The terminals are fed into the genetic program along with the functional set. We used the GPLAB toolbox to implement the genetic program with standard parameters (Silva and Almeida, 2003). The genetic program searches for the tree that maximizes the k-fold cross-validation performance of an efficient SVM, using only training data. After a fixed number of generations, the genetic program provides the best solution to date, the best TWS. Training and testing (which were not used during the search process) are displayed according to these TWS data sets. Note that all monitored term weights in Table 1 are estimated only from the training set (e.g. the information gain for terms is estimated only using the marked training data); to display the test data, we use the calculated term weights. Next, the LM results are evaluated in the training sets proposed."}, {"heading": "5. Experiments and results", "text": "This section provides an empirical evaluation of the proposed TWL approach. The aim of the experimental study is to evaluate the effectiveness of the learnt TWS and to compare its performance with existing schemes. Additionally, we evaluate the generalisation performance of learnt schemes and their effectiveness under different framework conditions."}, {"heading": "5.1. Experimental settings", "text": "For the experiment, we used a set of benchmark datasets containing three types of data (AA, a non-thematic task-up function) and a screen resolution (IC). We have three types of tasks that we want to use to evaluate systems."}, {"heading": "5.2. Evaluation of TWS Learning via Genetic Programming", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "5.3. Varying vocabulary size", "text": "For the experiments in Section 5.2 of each TWS, learning was learned by using only the top 2000 most common terms during the search process. (This reduction in vocabulary allowed us to significantly speed up the search process, but it is worth asking what the performance of the TWSs would be in the use of an increasing number of terms. We aim to answer such a question in this section. For this experiment, we are looking at three sets of data, one of each type of task: thematic TC, AA, and IC. The datasets considered were the Reuters8 (R8) for thematic TC, the CCA benchmark for AA, and Caltech-101 for IC. These datasets are the representative datasets from each task: Reuters-8 is among the most commonly used TC datasets, CCA is widely used for AA as well as Caltech-101 the benchmark in image categorization."}, {"heading": "5.4. Generalization of the learned term-weights", "text": "In this context, it has to be said that the individual countries are a country in which most of them are not able to play by the rules. (...) In other countries of the world, it is the case that it is a country in which most of them are unable to play by the rules. (...) In other countries of the world, it is the case that the rules of the market do not apply. (...) In other countries of the world, it is the case that the rules of the market, the rules of the market and the rules of the market and the rules of the market and the rules of the market do not apply. (...) In other countries of the world, it is the case that the rules of the market, the rules of the market and the rules of the market and the rules of the market and the rules of the market and the rules of the market and the rules of the market do not apply. (...) The rules of the market and the rules of the market and the rules of the market. (...) The rules of the market and the rules of the market and the rules of the market. (...) The rules of the market and the rules of the market. (... The rules of the market and the rules of the rules of the market. (...) The rules of the market and the rules of the market. (... The rules of the market and the rules of the market."}, {"heading": "6. Conclusions", "text": "We have proposed a genetic programming solution that combines standard TWS, term document and term relevance weights to produce effective TWSs. We reported experimental results in 16 known datasets covering thematic TWSs, author attributions and image classification tasks. The performance of the proposed method is evaluated under various scenarios. Experimental results show that the proposed approach learns very effective TWSs that exceed standard TWSs. The main results of this work can be summarized as follows: \u2022 TWSs that perform significantly better than standard TWSs and those that are proposed in related work. \u2022 Defining the appropriate TWSs is critical for image classification tasks, an ignored problem in the field of computer vision. \u2022 Author assignment selects monitored TWSs for comparing TWTC data, with the TWTC method mainly not being used."}], "references": [{"title": "Text classification using machine learning methods-a survey", "author": ["B. Agarwal", "N. Mittal"], "venue": "Proceedings of the Second International Conference on Soft Computing for Problem Solving (SocProS 2012). Vol. 236 of Advances in Intelligent Systems and Computing", "citeRegEx": "Agarwal and Mittal,? \\Q2014\\E", "shortCiteRegEx": "Agarwal and Mittal", "year": 2014}, {"title": "Analytical evaluation of term weighting schemes for text categorization", "author": ["H. Altyncay", "Z. Erenel"], "venue": "Pattern Recognition Letters 31,", "citeRegEx": "Altyncay and Erenel,? \\Q2010\\E", "shortCiteRegEx": "Altyncay and Erenel", "year": 2010}, {"title": "Selective block minimization for faster convergence of limited memory large-scale linear models", "author": ["K.W. Chang", "D. Roth"], "venue": "ACM SIGKDD Conference on Knowledge Discovery and Data Mining", "citeRegEx": "Chang and Roth,? \\Q2011\\E", "shortCiteRegEx": "Chang and Roth", "year": 2011}, {"title": "Visual categorization with bags of keypoints. In: International workshop on statistical learning in computer vision", "author": ["G. Csurka", "C.R. Dance", "L. Fan", "J. Willamowski", "C. Bra"], "venue": null, "citeRegEx": "Csurka et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Csurka et al\\.", "year": 2004}, {"title": "Evolving general term-weighting schemes for information retrieval: Tests on larger collections", "author": ["R. Cummins", "C. O\u2019Riordan"], "venue": "Artificial Intelligence Review", "citeRegEx": "Cummins and O.Riordan,? \\Q2005\\E", "shortCiteRegEx": "Cummins and O.Riordan", "year": 2005}, {"title": "Evolving local and global weighting schemes in information retrieval", "author": ["R. Cummins", "C. O\u2019Riordan"], "venue": "Information Retrieval", "citeRegEx": "Cummins and O.Riordan,? \\Q2006\\E", "shortCiteRegEx": "Cummins and O.Riordan", "year": 2006}, {"title": "Evolved term-weighting schemes in information retrieval: An analysis of the solution space", "author": ["R. Cummins", "C. O\u2019Riordan"], "venue": "Artificial Intelligence", "citeRegEx": "Cummins and O.Riordan,? \\Q2007\\E", "shortCiteRegEx": "Cummins and O.Riordan", "year": 2007}, {"title": "Supervised term weighting for automated text categorization", "author": ["F. Debole", "F. Sebastiani"], "venue": "Proceedings of the 2003 ACM Symposium on Applied Computing. SAC \u201903. ACM,", "citeRegEx": "Debole and Sebastiani,? \\Q2003\\E", "shortCiteRegEx": "Debole and Sebastiani", "year": 2003}, {"title": "Budgetedsvm: A toolbox for scalable svm approximations", "author": ["N. Djuric", "L. Lan", "S. Vucetic", "Z. Wang"], "venue": "Journal of Machine Learning Research", "citeRegEx": "Djuric et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Djuric et al\\.", "year": 2013}, {"title": "Introduction to Evolutionary Computing", "author": ["A.E. Eiben", "J.E. Smith"], "venue": null, "citeRegEx": "Eiben and Smith,? \\Q2010\\E", "shortCiteRegEx": "Eiben and Smith", "year": 2010}, {"title": "Particle swarm model selection for authorship verification", "author": ["H.J. Escalante", "M. Montes", "L. Villasenor"], "venue": "Proceedings of the 14th Iberoamerican Congress on Pattern Recognition", "citeRegEx": "Escalante et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Escalante et al\\.", "year": 2009}, {"title": "Local histograms of character n-grams for authorship attribution", "author": ["H.J. Escalante", "T. Solorio", "M.M. y Gomez"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Escalante et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Escalante et al\\.", "year": 2011}, {"title": "The effects of fitness functions on genetic programming based ranking discovery for web search", "author": ["W. Fan", "E.A. Fox", "P. Pathak", "H. Wu"], "venue": "Journal of the american Society for Information Science and Technology", "citeRegEx": "Fan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2004}, {"title": "A generic ranking function discovery framework by genetic programming for information retrieval", "author": ["W. Fan", "M.D. Gordon", "P. Pathak"], "venue": "Information Processing and Management", "citeRegEx": "Fan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2004}, {"title": "Learning generative visual models from few training examples: an incremental bayesian approach tested on 101 object categories", "author": ["L. Fei-Fei", "R. Fergus", "P. Perona"], "venue": "Workshop on GenerativeModel Based Vision", "citeRegEx": "Fei.Fei et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Fei.Fei et al\\.", "year": 2004}, {"title": "The Text Mining Handbook Advanced Approaches in Analyzing Unstructured Data. ABS Ventures", "author": ["R. Feldman", "J. Sanger"], "venue": null, "citeRegEx": "Feldman and Sanger,? \\Q2006\\E", "shortCiteRegEx": "Feldman and Sanger", "year": 2006}, {"title": "An extensive empirical study of feature selection metrics for text classification", "author": ["G. Forman"], "venue": "J. of Mach. Learn. Res", "citeRegEx": "Forman,? \\Q2003\\E", "shortCiteRegEx": "Forman", "year": 2003}, {"title": "Text categorization with support vector machines", "author": ["T. Joachims"], "venue": null, "citeRegEx": "Joachims,? \\Q2008\\E", "shortCiteRegEx": "Joachims", "year": 2008}, {"title": "That\u2019s what she said: Double entendre", "author": ["C. Kiddon", "Y. Brun"], "venue": null, "citeRegEx": "Kiddon and Brun,? \\Q2011\\E", "shortCiteRegEx": "Kiddon and Brun", "year": 2011}, {"title": "Authorship verification as a one-class classifi", "author": ["M. 401\u2013412. Koppel", "J. Schler"], "venue": null, "citeRegEx": "Koppel and Schler,? \\Q2004\\E", "shortCiteRegEx": "Koppel and Schler", "year": 2004}, {"title": "Supervised and traditional term", "author": ["C.L. Tan", "J. Su", "Y. Lu"], "venue": "Machine Learning", "citeRegEx": "M. et al\\.,? \\Q2009\\E", "shortCiteRegEx": "M. et al\\.", "year": 2009}, {"title": "The effect of author set size and data size", "author": ["K. Springer. Luyckx", "W. Daelemans"], "venue": null, "citeRegEx": "Luyckx and Daelemans,? \\Q2010\\E", "shortCiteRegEx": "Luyckx and Daelemans", "year": 2010}, {"title": "Feature selection for unbalanced class", "author": ["D. Mladenic", "M. Grobelnik"], "venue": "Literary and Linguistic Computing,", "citeRegEx": "Mladenic and Grobelnik,? \\Q1999\\E", "shortCiteRegEx": "Mladenic and Grobelnik", "year": 1999}, {"title": "On the difficulty of automatically detecting irony", "author": ["A. Reyes", "P. Rosso"], "venue": null, "citeRegEx": "86", "shortCiteRegEx": "86", "year": 2014}, {"title": "Term-weighting approaches in automatic text retrieval", "author": ["G. Salton", "C. Buckley"], "venue": "Information Processing and Management,", "citeRegEx": "Salton and Buckley,? \\Q1988\\E", "shortCiteRegEx": "Salton and Buckley", "year": 1988}, {"title": "Machine learning in automated text categorization", "author": ["F. Sebastiani"], "venue": "ACM Computer Surveys", "citeRegEx": "Sebastiani,? \\Q2008\\E", "shortCiteRegEx": "Sebastiani", "year": 2008}, {"title": "Gplab-a genetic programming toolbox for matlab", "author": ["S. Silva", "J. Almeida"], "venue": "Proceedings of the Nordic MATLAB conference", "citeRegEx": "Silva and Almeida,? \\Q2003\\E", "shortCiteRegEx": "Silva and Almeida", "year": 2003}, {"title": "Video google: A text retrieval approach to object matching in videos", "author": ["J. Sivic", "A. Zisserman"], "venue": "In: International Conference on Computer Vision", "citeRegEx": "Sivic and Zisserman,? \\Q2003\\E", "shortCiteRegEx": "Sivic and Zisserman", "year": 2003}, {"title": "GMM based language identification system using robust features", "author": ["S.Manchala", "V.K. Prasad", "V. Janaki"], "venue": "International Journal of Speech Technology", "citeRegEx": "S.Manchala et al\\.,? \\Q2014\\E", "shortCiteRegEx": "S.Manchala et al\\.", "year": 2014}, {"title": "A survey of modern authorship attribution methods", "author": ["E. Stamatatos"], "venue": "Journal of the American Society for Information Science and Technology", "citeRegEx": "Stamatatos,? \\Q2009\\E", "shortCiteRegEx": "Stamatatos", "year": 2009}, {"title": "Learning to rank", "author": ["A. Trotman"], "venue": "Information Retrieval", "citeRegEx": "Trotman,? \\Q2005\\E", "shortCiteRegEx": "Trotman", "year": 2005}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["P. Turney", "P. Pantel"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Turney and Pantel,? \\Q2010\\E", "shortCiteRegEx": "Turney and Pantel", "year": 2010}, {"title": "VLFeat: An open and portable library of computer vision algorithms", "author": ["A. Vedaldi", "B. Fulkerson"], "venue": null, "citeRegEx": "Vedaldi and Fulkerson,? \\Q2008\\E", "shortCiteRegEx": "Vedaldi and Fulkerson", "year": 2008}, {"title": "Bag-ofwords representation for biomedical time series classification", "author": ["J. Wanga", "P. Liub", "M.F. Shea", "S. Nahavandia", "A. Kouzanid"], "venue": "Biomedical Signal Processing and Control", "citeRegEx": "Wanga et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wanga et al\\.", "year": 2013}, {"title": "A comparative study on feature selection in text categorization", "author": ["Y. Yang", "J.O. Pedersen"], "venue": "Proceedins of the 14th International Conference on Machine Learning", "citeRegEx": "Yang and Pedersen,? \\Q1997\\E", "shortCiteRegEx": "Yang and Pedersen", "year": 1997}, {"title": "Local features and kernels for classification of texture and object categories: A comprehensive study", "author": ["J. Zhang", "M. Marszablek", "S. Lazebnik", "C. Schmid"], "venue": "International Journal of Computer Vision", "citeRegEx": "Zhang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2007}, {"title": "Scaling up kernel svm on limited resources: A low-rank linearization approach", "author": ["K. Zhang", "L. Lan", "Z. Wang", "F. Moerchen"], "venue": "Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS)", "citeRegEx": "Zhang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 25, "context": ", n\u00e4\u0131ve Bayes and support vector machines) are applied (Sebastiani, 2008).", "startOffset": 55, "endOffset": 73}, {"referenceID": 24, "context": "This type of representation is known as the vector space model (VSM) (Salton and Buckley, 1988).", "startOffset": 69, "endOffset": 95}, {"referenceID": 31, "context": "Under the VSM one assumes a document is a point in aN -dimensional space and documents that are closer in that space are similar to each other (Turney and Pantel, 2010).", "startOffset": 143, "endOffset": 168}, {"referenceID": 3, "context": "In fact, the BOW representation has been successfully adopted for processing other media besides text, including, images (Csurka et al., 2004), videos (Sivic and Zisserman, 2003), speech signals (S.", "startOffset": 121, "endOffset": 142}, {"referenceID": 27, "context": ", 2004), videos (Sivic and Zisserman, 2003), speech signals (S.", "startOffset": 16, "endOffset": 43}, {"referenceID": 28, "context": ", 2004), videos (Sivic and Zisserman, 2003), speech signals (S.Manchala et al., 2014), and time series (Wanga et al.", "startOffset": 60, "endOffset": 85}, {"referenceID": 33, "context": ", 2014), and time series (Wanga et al., 2013) among others.", "startOffset": 25, "endOffset": 45}, {"referenceID": 15, "context": "term-weighting scheme (TWS), which is in charge of determining how relevant a term is for describing the content of a document (Feldman and Sanger, 2006; Altyncay and Erenel, 2010; Lan et al., 2009; Debole and Sebastiani, 2003).", "startOffset": 127, "endOffset": 227}, {"referenceID": 1, "context": "term-weighting scheme (TWS), which is in charge of determining how relevant a term is for describing the content of a document (Feldman and Sanger, 2006; Altyncay and Erenel, 2010; Lan et al., 2009; Debole and Sebastiani, 2003).", "startOffset": 127, "endOffset": 227}, {"referenceID": 7, "context": "term-weighting scheme (TWS), which is in charge of determining how relevant a term is for describing the content of a document (Feldman and Sanger, 2006; Altyncay and Erenel, 2010; Lan et al., 2009; Debole and Sebastiani, 2003).", "startOffset": 127, "endOffset": 227}, {"referenceID": 25, "context": "Although, TC is a widely studied topic with very important developments in the last two decades (Sebastiani, 2008; Feldman and Sanger, 2006), it is somewhat surprising that little attention has been paid to the development of new TWSs to better represent the content of documents for TC.", "startOffset": 96, "endOffset": 140}, {"referenceID": 15, "context": "Although, TC is a widely studied topic with very important developments in the last two decades (Sebastiani, 2008; Feldman and Sanger, 2006), it is somewhat surprising that little attention has been paid to the development of new TWSs to better represent the content of documents for TC.", "startOffset": 96, "endOffset": 140}, {"referenceID": 16, "context": ", B, TF or TF-IDF ) and put more effort in other processes, like feature selection (Forman, 2003; Yang and Pedersen, 1997), or the learning process itself (Agarwal and Mittal, 2014; Aggarwal, 2012; Escalante et al.", "startOffset": 83, "endOffset": 122}, {"referenceID": 34, "context": ", B, TF or TF-IDF ) and put more effort in other processes, like feature selection (Forman, 2003; Yang and Pedersen, 1997), or the learning process itself (Agarwal and Mittal, 2014; Aggarwal, 2012; Escalante et al.", "startOffset": 83, "endOffset": 122}, {"referenceID": 0, "context": ", B, TF or TF-IDF ) and put more effort in other processes, like feature selection (Forman, 2003; Yang and Pedersen, 1997), or the learning process itself (Agarwal and Mittal, 2014; Aggarwal, 2012; Escalante et al., 2009).", "startOffset": 155, "endOffset": 221}, {"referenceID": 10, "context": ", B, TF or TF-IDF ) and put more effort in other processes, like feature selection (Forman, 2003; Yang and Pedersen, 1997), or the learning process itself (Agarwal and Mittal, 2014; Aggarwal, 2012; Escalante et al., 2009).", "startOffset": 155, "endOffset": 221}, {"referenceID": 25, "context": "The most studied TC problem is the so called thematic TC (or simply text categorization) (Sebastiani, 2008), which means that classes are associated to different themes or topics (e.", "startOffset": 89, "endOffset": 107}, {"referenceID": 29, "context": "Nonthematic TC includes the problems of authorship attribution (Stamatatos, 2009), opinion mining and sentiment analysis (Pang et al.", "startOffset": 63, "endOffset": 81}, {"referenceID": 19, "context": ", 2002), authorship verification (Koppel and Schler, 2004), author profiling (Koppel et al.", "startOffset": 33, "endOffset": 58}, {"referenceID": 18, "context": "among several others (Reyes and Rosso, 2014; Kiddon and Brun, 2011).", "startOffset": 21, "endOffset": 67}, {"referenceID": 29, "context": ", BOW using character n-grams or part-of-speech tags (Stamatatos, 2009)).", "startOffset": 53, "endOffset": 71}, {"referenceID": 3, "context": "Nowadays, images (Csurka et al., 2004), videos (Sivic and Zisserman, 2003), audio (S.", "startOffset": 17, "endOffset": 38}, {"referenceID": 27, "context": ", 2004), videos (Sivic and Zisserman, 2003), audio (S.", "startOffset": 16, "endOffset": 43}, {"referenceID": 28, "context": ", 2004), videos (Sivic and Zisserman, 2003), audio (S.Manchala et al., 2014), and other types of data (Wanga et al.", "startOffset": 51, "endOffset": 76}, {"referenceID": 33, "context": ", 2014), and other types of data (Wanga et al., 2013) are represented throughout analogies to the BOW.", "startOffset": 33, "endOffset": 53}, {"referenceID": 3, "context": "In image classification, for example, visual descriptors extracted from images are clustered and the centers of the clusters are considered as visual words (Csurka et al., 2004; Zhang et al., 2007).", "startOffset": 156, "endOffset": 197}, {"referenceID": 35, "context": "In image classification, for example, visual descriptors extracted from images are clustered and the centers of the clusters are considered as visual words (Csurka et al., 2004; Zhang et al., 2007).", "startOffset": 156, "endOffset": 197}, {"referenceID": 14, "context": "Accordingly, in this work we also perform experiments on learning TWSs for a standard computer vision problem (Fei-Fei et al., 2004).", "startOffset": 110, "endOffset": 132}, {"referenceID": 25, "context": "TC is a problem that has been approached mostly as a supervised learning task, where the goal is to learn a model capable of associating documents to categories (Sebastiani, 2008; Feldman and Sanger, 2006; Agarwal and Mittal, 2014).", "startOffset": 161, "endOffset": 231}, {"referenceID": 15, "context": "TC is a problem that has been approached mostly as a supervised learning task, where the goal is to learn a model capable of associating documents to categories (Sebastiani, 2008; Feldman and Sanger, 2006; Agarwal and Mittal, 2014).", "startOffset": 161, "endOffset": 231}, {"referenceID": 0, "context": "TC is a problem that has been approached mostly as a supervised learning task, where the goal is to learn a model capable of associating documents to categories (Sebastiani, 2008; Feldman and Sanger, 2006; Agarwal and Mittal, 2014).", "startOffset": 161, "endOffset": 231}, {"referenceID": 25, "context": "Many TWSs have been proposed so far, including unsupervised (Sebastiani, 2008; Salton and Buckley, 1988; Feldman and Sanger, 2006) and supervised schemes (Debole and Sebastiani, 2003; Lan et al.", "startOffset": 60, "endOffset": 130}, {"referenceID": 24, "context": "Many TWSs have been proposed so far, including unsupervised (Sebastiani, 2008; Salton and Buckley, 1988; Feldman and Sanger, 2006) and supervised schemes (Debole and Sebastiani, 2003; Lan et al.", "startOffset": 60, "endOffset": 130}, {"referenceID": 15, "context": "Many TWSs have been proposed so far, including unsupervised (Sebastiani, 2008; Salton and Buckley, 1988; Feldman and Sanger, 2006) and supervised schemes (Debole and Sebastiani, 2003; Lan et al.", "startOffset": 60, "endOffset": 130}, {"referenceID": 7, "context": "Many TWSs have been proposed so far, including unsupervised (Sebastiani, 2008; Salton and Buckley, 1988; Feldman and Sanger, 2006) and supervised schemes (Debole and Sebastiani, 2003; Lan et al., 2009), see Section 3.", "startOffset": 154, "endOffset": 201}, {"referenceID": 25, "context": "information retrieval tasks and latter adopted for TC (Sebastiani, 2008; Salton and Buckley, 1988).", "startOffset": 54, "endOffset": 98}, {"referenceID": 24, "context": "information retrieval tasks and latter adopted for TC (Sebastiani, 2008; Salton and Buckley, 1988).", "startOffset": 54, "endOffset": 98}, {"referenceID": 7, "context": "On the other hand, supervised TWSs aim at incorporating discriminative information into the representation of documents (Debole and Sebastiani, 2003).", "startOffset": 120, "endOffset": 149}, {"referenceID": 34, "context": "In this way, the discrimination power of each term is taken into account for the document representation; in this case through the information gain value (Yang and Pedersen, 1997).", "startOffset": 154, "endOffset": 179}, {"referenceID": 15, "context": ", B, TF and TF-IDF ) have been adopted for TC systems (Feldman and Sanger, 2006; Aggarwal, 2012).", "startOffset": 54, "endOffset": 96}, {"referenceID": 24, "context": "Their popularity derives from the fact that these schemes have proved to be very effective in information retrieval (Salton and Buckley, 1988; Baeza-Yates and Ribeiro-Neto, 1999; Turney and Pantel, 2010) and in many TC problems as well as (Sebastiani, 2008; Feldman and Sanger, 2006; Agarwal and Mittal, 2014; Aggarwal, 2012; Aggarwal and Zhai, 2012).", "startOffset": 116, "endOffset": 203}, {"referenceID": 31, "context": "Their popularity derives from the fact that these schemes have proved to be very effective in information retrieval (Salton and Buckley, 1988; Baeza-Yates and Ribeiro-Neto, 1999; Turney and Pantel, 2010) and in many TC problems as well as (Sebastiani, 2008; Feldman and Sanger, 2006; Agarwal and Mittal, 2014; Aggarwal, 2012; Aggarwal and Zhai, 2012).", "startOffset": 116, "endOffset": 203}, {"referenceID": 25, "context": "Their popularity derives from the fact that these schemes have proved to be very effective in information retrieval (Salton and Buckley, 1988; Baeza-Yates and Ribeiro-Neto, 1999; Turney and Pantel, 2010) and in many TC problems as well as (Sebastiani, 2008; Feldman and Sanger, 2006; Agarwal and Mittal, 2014; Aggarwal, 2012; Aggarwal and Zhai, 2012).", "startOffset": 239, "endOffset": 350}, {"referenceID": 15, "context": "Their popularity derives from the fact that these schemes have proved to be very effective in information retrieval (Salton and Buckley, 1988; Baeza-Yates and Ribeiro-Neto, 1999; Turney and Pantel, 2010) and in many TC problems as well as (Sebastiani, 2008; Feldman and Sanger, 2006; Agarwal and Mittal, 2014; Aggarwal, 2012; Aggarwal and Zhai, 2012).", "startOffset": 239, "endOffset": 350}, {"referenceID": 0, "context": "Their popularity derives from the fact that these schemes have proved to be very effective in information retrieval (Salton and Buckley, 1988; Baeza-Yates and Ribeiro-Neto, 1999; Turney and Pantel, 2010) and in many TC problems as well as (Sebastiani, 2008; Feldman and Sanger, 2006; Agarwal and Mittal, 2014; Aggarwal, 2012; Aggarwal and Zhai, 2012).", "startOffset": 239, "endOffset": 350}, {"referenceID": 7, "context": "This observation was noticed by Debole & Sebastiani and other authors that have introduced supervised TWSs (Debole and Sebastiani, 2003; Lan et al., 2009).", "startOffset": 107, "endOffset": 154}, {"referenceID": 7, "context": "In (Debole and Sebastiani, 2003) TWSs were defined by combining the unsupervised TF scheme with the following term-relevance criteria: information gain (TF-IG), which measures the reduction of entropy when using a term as classifier (Yang and Pedersen, 1997); \u03c7 (TF-CHI ), makes an independence test regarding a term and the classes (Sebastiani, 2008); and gain-ratio (TF-GR) measuring the gain-ratio when using the term as classifier (Debole and Sebastiani, 2003).", "startOffset": 3, "endOffset": 32}, {"referenceID": 34, "context": "In (Debole and Sebastiani, 2003) TWSs were defined by combining the unsupervised TF scheme with the following term-relevance criteria: information gain (TF-IG), which measures the reduction of entropy when using a term as classifier (Yang and Pedersen, 1997); \u03c7 (TF-CHI ), makes an independence test regarding a term and the classes (Sebastiani, 2008); and gain-ratio (TF-GR) measuring the gain-ratio when using the term as classifier (Debole and Sebastiani, 2003).", "startOffset": 233, "endOffset": 258}, {"referenceID": 25, "context": "In (Debole and Sebastiani, 2003) TWSs were defined by combining the unsupervised TF scheme with the following term-relevance criteria: information gain (TF-IG), which measures the reduction of entropy when using a term as classifier (Yang and Pedersen, 1997); \u03c7 (TF-CHI ), makes an independence test regarding a term and the classes (Sebastiani, 2008); and gain-ratio (TF-GR) measuring the gain-ratio when using the term as classifier (Debole and Sebastiani, 2003).", "startOffset": 333, "endOffset": 351}, {"referenceID": 7, "context": "In (Debole and Sebastiani, 2003) TWSs were defined by combining the unsupervised TF scheme with the following term-relevance criteria: information gain (TF-IG), which measures the reduction of entropy when using a term as classifier (Yang and Pedersen, 1997); \u03c7 (TF-CHI ), makes an independence test regarding a term and the classes (Sebastiani, 2008); and gain-ratio (TF-GR) measuring the gain-ratio when using the term as classifier (Debole and Sebastiani, 2003).", "startOffset": 435, "endOffset": 464}, {"referenceID": 7, "context": "The conclusions from (Debole and Sebastiani, 2003) were that small improvements can be obtained with supervised TWSs over unsupervised ones.", "startOffset": 21, "endOffset": 50}, {"referenceID": 7, "context": ", 2009) the proposed TF-RF scheme obtained better performance than unsupervised TWSs and even outperformed the schemes proposed in (Debole and Sebastiani, 2003).", "startOffset": 131, "endOffset": 160}, {"referenceID": 1, "context": "In (Altyncay and Erenel, 2010) the RF term-relevance factor was compared with alternative weights, including mutual information, odds ratio and \u03c7; in that workRF outperformed the other term-importance criteria.", "startOffset": 3, "endOffset": 30}, {"referenceID": 24, "context": "B Boolean xi,j = {#(ti,dj)>0} Indicates the prescense/abscense of terms (Salton and Buckley, 1988)", "startOffset": 72, "endOffset": 98}, {"referenceID": 24, "context": "TF TermFrequency xi,j = #(ti, dj) Accounts for the frequency of occurrence of terms (Salton and Buckley, 1988)", "startOffset": 84, "endOffset": 110}, {"referenceID": 24, "context": "IDF TF - Inverse Document Frequency xi,j = #(ti, dj) \u00d7 log( N df(tj ) ) An TF scheme that penalizes the frequency of terms across the collection (Salton and Buckley, 1988)", "startOffset": 145, "endOffset": 171}, {"referenceID": 7, "context": "(Debole and Sebastiani, 2003)", "startOffset": 0, "endOffset": 29}, {"referenceID": 7, "context": "CHI TF - Chisquare xi,j = #(ti, dj) \u00d7 CHI(tj) TF scheme that weights term occurrence by its \u03c7 statistic (Debole and Sebastiani, 2003)", "startOffset": 104, "endOffset": 133}, {"referenceID": 1, "context": "Comprehensive and extensive comparative studies using supervised TRs for feature selection have been reported (Altyncay and Erenel, 2010; Forman, 2003; Yang and Pedersen, 1997; Mladenic and Grobelnik, 1999).", "startOffset": 110, "endOffset": 206}, {"referenceID": 16, "context": "Comprehensive and extensive comparative studies using supervised TRs for feature selection have been reported (Altyncay and Erenel, 2010; Forman, 2003; Yang and Pedersen, 1997; Mladenic and Grobelnik, 1999).", "startOffset": 110, "endOffset": 206}, {"referenceID": 34, "context": "Comprehensive and extensive comparative studies using supervised TRs for feature selection have been reported (Altyncay and Erenel, 2010; Forman, 2003; Yang and Pedersen, 1997; Mladenic and Grobelnik, 1999).", "startOffset": 110, "endOffset": 206}, {"referenceID": 22, "context": "Comprehensive and extensive comparative studies using supervised TRs for feature selection have been reported (Altyncay and Erenel, 2010; Forman, 2003; Yang and Pedersen, 1997; Mladenic and Grobelnik, 1999).", "startOffset": 110, "endOffset": 206}, {"referenceID": 30, "context": "Similar approaches based on genetic programming to learn TWSs have been proposed in (Cummins and O\u2019Riordan, 2006, 2007, 2005; Trotman, 2005; Oren, 2002; Fan et al., 2004a), however, these researchers have focused on the information retrieval problem, which differs significantly from TC.", "startOffset": 84, "endOffset": 171}, {"referenceID": 9, "context": "For initialization we used the standard ramped-half-and-half strategy (Eiben and Smith, 2010), which generates half of the population with (balanced) trees of maximum depth, and the other half with trees of variable depth.", "startOffset": 70, "endOffset": 93}, {"referenceID": 25, "context": "The average across classes is reported (also called, macro-average f1), this way of estimating the f1-measure is known to be particularly useful when tackling unbalanced data sets (Sebastiani, 2008).", "startOffset": 180, "endOffset": 198}, {"referenceID": 25, "context": "Support vector machines (SVM) comprise a type of models that have proved to be very effective for TC (Sebastiani, 2008; Joachims, 2008).", "startOffset": 101, "endOffset": 135}, {"referenceID": 17, "context": "Support vector machines (SVM) comprise a type of models that have proved to be very effective for TC (Sebastiani, 2008; Joachims, 2008).", "startOffset": 101, "endOffset": 135}, {"referenceID": 36, "context": "Therefore, we opted for efficient implementations of SVMs that have been proposed recently (Zhang et al., 2012; Djuric et al., 2013).", "startOffset": 91, "endOffset": 132}, {"referenceID": 8, "context": "Therefore, we opted for efficient implementations of SVMs that have been proposed recently (Zhang et al., 2012; Djuric et al., 2013).", "startOffset": 91, "endOffset": 132}, {"referenceID": 8, "context": "Among the methods available in (Djuric et al., 2013) we used the low-rank linearized SVM (LLSMV) (Zhang et al.", "startOffset": 31, "endOffset": 52}, {"referenceID": 36, "context": ", 2013) we used the low-rank linearized SVM (LLSMV) (Zhang et al., 2012).", "startOffset": 52, "endOffset": 72}, {"referenceID": 2, "context": "LLSVM is a linearized version of non-linear SVMs, which can be trained efficiently with the so called block minimization framework (Chang and Roth, 2011).", "startOffset": 131, "endOffset": 153}, {"referenceID": 8, "context": ", (Djuric et al., 2013; Zhang et al., 2012).", "startOffset": 2, "endOffset": 43}, {"referenceID": 36, "context": ", (Djuric et al., 2013; Zhang et al., 2012).", "startOffset": 2, "endOffset": 43}, {"referenceID": 26, "context": "We used the GPLAB toolbox for implementing the genetic program with default parameters (Silva and Almeida, 2003).", "startOffset": 87, "endOffset": 112}, {"referenceID": 25, "context": "The considered data sets are the most used ones for the evaluation of TC systems (Sebastiani, 2008).", "startOffset": 81, "endOffset": 99}, {"referenceID": 29, "context": "writing style of authors, hence, it has been shown that different representations and attributes are necessary for facing this task (Stamatatos, 2009).", "startOffset": 132, "endOffset": 150}, {"referenceID": 29, "context": "Accordingly, indexing terms in AA data sets were 3-grams of characters, that is, sequences of 3-characters found in documents, these terms have proved to be the most effective ones in AA (Stamatatos, 2009; Escalante et al., 2011; Luyckx and Daelemans, 2010).", "startOffset": 187, "endOffset": 257}, {"referenceID": 11, "context": "Accordingly, indexing terms in AA data sets were 3-grams of characters, that is, sequences of 3-characters found in documents, these terms have proved to be the most effective ones in AA (Stamatatos, 2009; Escalante et al., 2011; Luyckx and Daelemans, 2010).", "startOffset": 187, "endOffset": 257}, {"referenceID": 21, "context": "Accordingly, indexing terms in AA data sets were 3-grams of characters, that is, sequences of 3-characters found in documents, these terms have proved to be the most effective ones in AA (Stamatatos, 2009; Escalante et al., 2011; Luyckx and Daelemans, 2010).", "startOffset": 187, "endOffset": 257}, {"referenceID": 14, "context": "We considered the collection under the standard experimental settings (15 images per class for training and 15 images for testing), two subsets of the CALTECH-101 data set were used: a small one with only 5 categories and the whole data set with 102 classes (101 object categories plus background) (Fei-Fei et al., 2004).", "startOffset": 298, "endOffset": 320}, {"referenceID": 32, "context": "Images were represented under the Bag-of-Visual-Words formulation using dense sift descriptors (PHOW features): descriptors extracted from images were clustered using k\u2212means, the centers of the clusters are the visual words (indexing terms), images are then represented by accounting the occurrence of visual words, the VLFEAT toolbox was used for processing images (Vedaldi and Fulkerson, 2008).", "startOffset": 367, "endOffset": 396}, {"referenceID": 29, "context": "AA studies suggest using a small amount of the most-frequent terms when approaching an AA problem (Stamatatos, 2009; Escalante et al., 2011; Luyckx and Daelemans, 2010).", "startOffset": 98, "endOffset": 168}, {"referenceID": 11, "context": "AA studies suggest using a small amount of the most-frequent terms when approaching an AA problem (Stamatatos, 2009; Escalante et al., 2011; Luyckx and Daelemans, 2010).", "startOffset": 98, "endOffset": 168}, {"referenceID": 21, "context": "AA studies suggest using a small amount of the most-frequent terms when approaching an AA problem (Stamatatos, 2009; Escalante et al., 2011; Luyckx and Daelemans, 2010).", "startOffset": 98, "endOffset": 168}], "year": 2014, "abstractText": "This paper describes a novel approach to learning term-weighting schemes (TWSs) in the context of text classification. In text mining a TWS determines the way in which documents will be represented in a vector space model, before applying a classifier. Whereas acceptable performance has been obtained with standard TWSs (e.g., Boolean and term-frequency schemes), the definition of TWSs has been traditionally an art. Further, it is still a difficult task to determine what is the best TWS for a particular problem and it is not clear yet, whether better schemes, than those currently available, can be generated by combining known TWS. We propose in this article a genetic program that aims at learning effective TWSs that can improve the performance of current schemes in text classification. The genetic program learns how to combine a set of basic units to give rise to discriminative TWSs. We report an extensive experimental study comprising data sets from thematic and non-thematic text classification as well as from image classification. Our study shows the validity of the proposed method; in fact, we show that TWSs learned with the genetic program outperform traditional schemes and other Corresponding author. Email addresses: hugojair@inaoep.mx (Hugo Jair Escalante), mauricio.garcia.cs@gmail.com (Mauricio A. Gar\u0107\u0131a-Lim\u00f3n), a.morales@inaoep.mx (Alicia Morales-Reyes), mgraffg@gmail.com (Mario Graff), mmontesg@inaoep.mx (Manuel Montes-y-G\u00f3mez), emorales@inaoep.mx (Eduardo F. Morales) Preprint submitted to Elsevier October 8, 2014 TWSs proposed in recent works. Further, we show that TWSs learned from a specific domain can be effectively used for other tasks.", "creator": "LaTeX with hyperref package"}}}