{"id": "1410.0736", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Oct-2014", "title": "HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition", "abstract": "Existing deep convolutional neural network (CNN) architectures are trained as N-way classifiers to distinguish between N output classes. This work builds on the intuition that not all classes are equally difficult to distinguish from a true class label. Towards this end, we introduce hierarchical branching CNNs, named as Hierarchical Deep CNN (HD-CNN), wherein classes that can be easily distinguished are classified in the higher layer coarse category CNN, while the most difficult classifications are done on lower layer fine category CNN. We propose utilizing a multinomial logistic loss and a novel temporal sparsity penalty for HD-CNN training. Together they ensure each branching component deals with a subset of categories confusing to each other. This new network architecture adopts coarse-to-fine classification strategy and module design principle. The proposed model achieves superior performance over standard models. We demonstrate state-of-the-art results on CIFAR100 benchmark.", "histories": [["v1", "Fri, 3 Oct 2014 01:17:20 GMT  (1483kb,D)", "http://arxiv.org/abs/1410.0736v1", null], ["v2", "Fri, 19 Dec 2014 07:51:51 GMT  (4582kb,D)", "http://arxiv.org/abs/1410.0736v2", "Submission to ICLR 2015"], ["v3", "Sat, 28 Feb 2015 03:11:49 GMT  (4638kb,D)", "http://arxiv.org/abs/1410.0736v3", "Revised based on ICLR 2015 reviews"], ["v4", "Sat, 16 May 2015 03:36:32 GMT  (1000kb,D)", "http://arxiv.org/abs/1410.0736v4", "Add new results on ImageNet using VGG-16-layer building block net"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["zhicheng yan", "hao zhang", "robinson piramuthu", "vignesh jagadeesh", "dennis decoste", "wei di", "yizhou yu"], "accepted": false, "id": "1410.0736"}, "pdf": {"name": "1410.0736.pdf", "metadata": {"source": "CRF", "title": "HD-CNN: Hierarchical Deep Convolutional Neural Network for Image Classification", "authors": ["Zhicheng Yan", "Vignesh Jagadeesh", "Dennis Decoste", "Wei Di", "Robinson Piramuthu"], "emails": ["zyan3@illinois.edu,[vjagadeesh,", "rpiramuthu]@ebay.com"], "sections": [{"heading": "1. Introduction", "text": "The main reasons for this comeback are the increasing availability of large-format data sets and the related advances in parallel processing of resources. In this sense, CNN is able to bring itself up to date by discussing a very specific problem in classification. The question we are asking ourselves is: Is it possible to develop new architectures by arranging the basic neural structures in order to achieve significant gains in classification? Base neural networks could be a very specific problem in classification."}, {"heading": "2. Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Convolutional Neural Network", "text": "Convolutionary neural networks offer state-of-the-art performance in a variety of computer visualization tasks, including image classification [14], object recognition [6, 10], image analysis [4], face recognition [24], pose estimation [25, 19] and image annotations [8], etc. Recently, there has been considerable interest in improving specific components in the CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17]. These changes either facilitate rapid and stable network training [27] or expand the network's ability to learn more complex and highly nonlinear functions [9, 22, 17]. In this work, we are not redesigning a specific part within an existing CNN model. Instead, we are designing a novel generic CNN architecture that is able to wrap an existing CNN model as a building block."}, {"heading": "2.2. Image Classification", "text": "The architecture proposed by this work is fairly general and can be applied to computer vision tasks where CNN is applicable. In order to keep the discussion focused and to illustrate a proof of concept of our ideas, we adopt the problem of image classification. The classic image classification systems in Vision use handmade features such as SIFT [18] and SURF [1] to use a spatially uniform bag of words [15] as a model for image classification. More recently, the ground-breaking paper by Krizhevsky et al. [14] has been achieved with massive improvements in the Imagenet challenge of using a CNN. Subsequently, there have been several efforts to improve this basic model for the task of image classification. Impressive performance on the CIFAR dataset has been achieved by examining recently proposed Network in Network [17], Maxout networks and variants [9, 22] and the exploitation of tree-based priors [23] in the training of CNs as well as the use of CNs archivers."}, {"heading": "3.1. Notations", "text": "The following descriptions are used for discussion. A dataset consists of Nt Training Samples = 1.1 Full processing categories = 1.1 Full processing layers Nt i = 1 and Ns Test Samples {xsi, ysi} Ns i = 1. xi and yi denote the predicted image data and labels. There are C fine categories in the datasets {Sk} Ck = 1. We will identify the rough image categories as elaborated in Section 4.1.3.2. It mainly comprises three parts, namely a single rough category component B, which is similar to the standard deep CNN model, Hierarchical Deep Convolutional Neural Network (HD-CNN) achieves end-to-end classification as seen in Figure 2. It essentially comprises a single rough category component B, several branched fine categories components {F j} C \u2032 j = 1, and a single probable middle layer. On the left side of Fig 2 is the single rough category."}, {"heading": "4.1.1 Identifying Coarse Categories", "text": "For most classification datasets, the given designations {yi} Ni = 1 Fine Level Categories = Fine Level Categories and we do not have any predictions about the number of rough categories or the affiliation to each Fine Level Category. Therefore, we develop a simple but effective strategy to identify them. \u2022 First, we divide the training samples {xti, yti} Nt i = 1 in total parts Train and Train Oval. We build a standardized deep CNN model with the train part and evaluate it on the train part. \u2022 Second, we draw the confusion matrix F of size C \u00b7 C from the train part. A distance matrix D is called D = 1 \u2212 F. We zero D's diagonal elements and transform it by calculating D = 0.5 \u0445 (D + DT). The entry Dij measures how easy it is to distinguish category i from category j. \u2022 Third, Laplacian eigenscale category [2] is used to lower dimension."}, {"heading": "4.1.2 Pretraining the Coarse Category Component", "text": "To train the rough category component, we first replace fine category labels {yti} with rough category labels using the P: y 7 \u2192 y \u2032 mapping. The full set of training samples {xti, y \u2032 t i} Nt i = 1 is used to train a standard deep CNN model that displays a probability distribution across the rough categories. Afterwards, we copy the learned parameters from the standard deep CNN to the rough category component of HD-CNN."}, {"heading": "4.1.3 Pretraining the Fine Category Components", "text": "The branching of fine components of category {F j} C \u2032 j = 1 is also pre-trained independently of each other. Firstly, before we pre-train each branching component, we train a standard deep CNN model F p from scratch using all training samples {xti, yti} Nt i = 1. Secondly, we initialize each branching component F j by copying the learned parameters from F p to F j and finely tuned F j, using only training images with fine labels yti so that P (yti) = j. By using the images within the same rough category j for fine tuning, each branching component F i is adjusted to achieve better performance for the fine categories within the rough category j, and must not be discriminatory for other fine categories. 4.2. Fine tuning HD CNNAfter both the coarse component of the category and the branched fine component of the fine category, we are adequately prepared for the overall multi-time logistics function of the CNN."}, {"heading": "5. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Overview", "text": "To demonstrate that HD-CNN is a generic architecture, we are experimenting with two different modular networks based on the CIFAR100 dataset. In both cases, HD-CNN alone can achieve superior performance over the modular network. We are implementing HD-CNN on the widely used Caffe [11] project and are planning to publish our code. We are following [9] to pre-process the datasets (e.g. global contrast normalization and ZCA whitening). For CIFAR100, we are using randomly cut-out image fields of size 26 x 26 and their horizontal reflections for training, testing, using multiview tests [14]. Specifically, we are extracting five 26 x 26 fields (the 4 corner fields and the middle field) as well as their horizontal reflections and average predictions. We are following [14] to update the network parameters by backscattering. We are using small components to increase the learning rate by a factor of 250 with a large training component."}, {"heading": "5.2. CIFAR100", "text": "The CIFAR100 dataset consists of 100 classes of natural images. There are 50,000 training images and 10,000 test images. To identify broad categories, we randomly select 10,000 images from the training set as a traction part and the rest as a traction part."}, {"heading": "5.2.1 CNN Building Block", "text": "We use a standard CNN network CIFAR100-CNN as a building block. The CIFAR100-CNN network consists of 3 Convolutionary Layers, 1 Fully Connected Layer and 1 SOFTMAX Layer. There are 64 filters in each Convolutionary Layer. Rectified Linear Units (ReLU) are used as activation units. Bundling of layers and reaction normalization layers are also used between Convolutionary Layers. The complete CIFAR100-CNN architecture is shown in Table 1. We identify four broad categories and the fine categories within each coarse category are shown in Table 3.We compare the test accuracy of an HD CNN with four branched components using the CIFAR100-CNN component. Branching components divide layers from conv1 to standardized 1, but have independent layers from conv2 to probability. We compare the test accuracy of a standard CIFAR100CNN network with a branching of CIFAR100-CNN components to reach the CIF51-CNN component count in the CNN-5K category."}, {"heading": "5.2.2 NIN Building Block", "text": "In [17], a NIN network with three stacked mlpconv layers achieves a state-of-the-art test accuracy of 64.32%. The definition files of the network are publicly available1. The entire architecture known as CIFAR100-NIN is shown in Table 2. We use CIFAR100-NIN as a building block and build an HD CNN with five branching components. Branching components share layers from conven1 to conven2, but have independent layers from cccp3 to test.We achieve a test accuracy of 65.33%, which improves the current best method NIN [17] by 0.61% and sets new state 1https components: / mavenlin / cuda-convennet / master / cifar-100 _ defof-the-art-results of a single network on CIFAR100. We compare the performance of HD-CNN with an average of five branched models."}, {"heading": "6. Conclusions", "text": "HD-CNN is a flexible Deep CNN architecture that can be improved over existing Deep CNN models. It uses rough to fine classification strategies and the principle of network module design. It can achieve state-of-the-art performance on CIFAR100."}], "references": [{"title": "Surf: Speeded up robust features", "author": ["H. Bay", "T. Tuytelaars", "L. Van Gool"], "venue": "ECCV 2006, pages 404\u2013417. Springer", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["M. Belkin", "P. Niyogi"], "venue": "Neural computation, 15(6):1373\u20131396", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 3642\u20133649. IEEE", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning hierarchical features for scene labeling", "author": ["C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(8):1915\u2013 1929", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Clustering by passing messages between data points", "author": ["B.J. Frey", "D. Dueck"], "venue": "Science, 315:972\u2013976", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Scaling multiclass support vector machines using inter-class confusion", "author": ["S. Godbole", "S. Sarawagi", "S. Chakrabarti"], "venue": "Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201902, pages 513\u2013518, New York, NY, USA", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "Deep convolutional ranking for multilabel image annotation", "author": ["Y. Gong", "Y. Jia", "T. Leung", "A. Toshev", "S. Ioffe"], "venue": "CoRR, abs/1312.4894", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "ICML", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Spatial pyramid pooling in deep convolutional networks for visual recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "Computer Vision\u2013ECCV 2014, pages 346\u2013361. Springer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Caffe: An open source convolutional architecture for fast feature embedding", "author": ["Y. Jia"], "venue": "http://caffe. berkeleyvision.org/", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G. Hinton"], "venue": "Computer Science Department, University of Toronto, Tech. Rep", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G.E. Hinton"], "venue": "Masters thesis, Department of Computer Science, University of Toronto", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, pages 1097\u20131105", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "author": ["S. Lazebnik", "C. Schmid", "J. Ponce"], "venue": "Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, volume 2, pages 2169\u20132178. IEEE", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Sparse deep belief net model for visual area v2", "author": ["H. Lee", "C. Ekanadham", "A.Y. Ng"], "venue": "Advances in neural information processing systems, pages 873\u2013880", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2008}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "CoRR, abs/1312.4400", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Object recognition from local scale-invariant features", "author": ["D.G. Lowe"], "venue": "Computer Vision, 1999. Proceedings. Seventh IEEE International Conference on, volume 2, pages 1150\u2013 1157. IEEE", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "Multi-source deep learning for human pose estimation", "author": ["W. Ouyang", "X. Chu", "X. Wang"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2329\u20132336", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Cnn features off-the-shelf: an astounding baseline for recognition", "author": ["A.S. Razavian", "H. Azizpour", "J. Sullivan", "S. Carlsson"], "venue": "arXiv preprint arXiv:1403.6382", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Overfeat: Integrated recognition", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "localization and detection using convolutional networks. In International Conference on Learning Representations ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Improving deep neural networks with probabilistic maxout units", "author": ["J.T. Springenberg", "M. Riedmiller"], "venue": "arXiv preprint arXiv:1312.6116", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Discriminative transfer learning with tree-based priors", "author": ["N. Srivastava", "R. Salakhutdinov"], "venue": "Advances in Neural Information Processing Systems, pages 2094\u20132102", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Deepface: Closing the gap to human-level performance in face verification", "author": ["Y. Taigman", "M. Yang", "M. Ranzato", "L. Wolf"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1701\u20131708", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Deeppose: Human pose estimation via deep neural networks", "author": ["A. Toshev", "C. Szegedy"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Cnn: Single-label to multi-label", "author": ["Y. Wei", "W. Xia", "J. Huang", "B. Ni", "J. Dong", "Y. Zhao", "S. Yan"], "venue": "arXiv preprint arXiv:1406.5726", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "International Conference on Learning Representations (ICLR)", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "Computer Vision\u2013ECCV 2014, pages 818\u2013833. Springer", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 16, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 95, "endOffset": 110}, {"referenceID": 20, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 95, "endOffset": 110}, {"referenceID": 27, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 95, "endOffset": 110}, {"referenceID": 2, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 95, "endOffset": 110}, {"referenceID": 20, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 129, "endOffset": 140}, {"referenceID": 9, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 129, "endOffset": 140}, {"referenceID": 5, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 129, "endOffset": 140}, {"referenceID": 24, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 158, "endOffset": 162}, {"referenceID": 23, "context": "For instance, convolutional networks now hold state of the art results in image classification [17, 21, 28, 3], object detection [21, 10, 6], pose estimation [25], face recognition [24] and a variety of other tasks.", "startOffset": 181, "endOffset": 185}, {"referenceID": 13, "context": "The question we address is: Given a base neural network, is it possible to induce new architectures by arranging the base neural network in a certain sequence to achieve considerable gains in classification accuracy? The base neural network could be a vanilla CNN [14] or a more sophisticated variant like the Network Apple Orange Bus", "startOffset": 264, "endOffset": 268}, {"referenceID": 16, "context": "in Network [17], and the novel architecture we propose for approaching this problem is named as HD-CNN.", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": "In the CIFAR100 [13] dataset, it is relatively easy to tell an Apple from Bus while telling an Apple from Orange is harder.", "startOffset": 16, "endOffset": 20}, {"referenceID": 13, "context": "HD-CNN is different from the simple model averaging technique [14].", "startOffset": 62, "endOffset": 66}, {"referenceID": 13, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 133, "endOffset": 137}, {"referenceID": 5, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 156, "endOffset": 163}, {"referenceID": 9, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 156, "endOffset": 163}, {"referenceID": 3, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 178, "endOffset": 181}, {"referenceID": 23, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 200, "endOffset": 204}, {"referenceID": 24, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 222, "endOffset": 230}, {"referenceID": 18, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 222, "endOffset": 230}, {"referenceID": 7, "context": "Convolutional neural networks hold state-of-the-art performance in a variety of computer vision tasks, including image classifcation [14], object detection [6, 10], image parsing[4], face recognition [24], pose estimation [25, 19] and image annotation [8] and so on.", "startOffset": 252, "endOffset": 255}, {"referenceID": 26, "context": "There has recently been considerable interest in enhancing specific components in CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17].", "startOffset": 125, "endOffset": 129}, {"referenceID": 8, "context": "There has recently been considerable interest in enhancing specific components in CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17].", "startOffset": 148, "endOffset": 155}, {"referenceID": 21, "context": "There has recently been considerable interest in enhancing specific components in CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17].", "startOffset": 148, "endOffset": 155}, {"referenceID": 16, "context": "There has recently been considerable interest in enhancing specific components in CNN architecture, including pooling layers [27], activation units [9, 22], nonlinear layers [17].", "startOffset": 174, "endOffset": 178}, {"referenceID": 26, "context": "These changes either facilitate fast and stable network training [27], or expand the network\u2019s capacity of learning more complicated and highly nonlinear functions [9, 22, 17].", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "These changes either facilitate fast and stable network training [27], or expand the network\u2019s capacity of learning more complicated and highly nonlinear functions [9, 22, 17].", "startOffset": 164, "endOffset": 175}, {"referenceID": 21, "context": "These changes either facilitate fast and stable network training [27], or expand the network\u2019s capacity of learning more complicated and highly nonlinear functions [9, 22, 17].", "startOffset": 164, "endOffset": 175}, {"referenceID": 16, "context": "These changes either facilitate fast and stable network training [27], or expand the network\u2019s capacity of learning more complicated and highly nonlinear functions [9, 22, 17].", "startOffset": 164, "endOffset": 175}, {"referenceID": 17, "context": "Classical image classification systems in vision use handcrafted features like SIFT [18] and SURF [1] to cap-", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "Classical image classification systems in vision use handcrafted features like SIFT [18] and SURF [1] to cap-", "startOffset": 98, "endOffset": 101}, {"referenceID": 14, "context": "ture spatially consistent bag of words [15] model for image classification.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "[14] showed massive improvement gains on the imagenet challenge while using a CNN.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Impressive performance on the CIFAR dataset has been achieved using recently proposed Network in Network [17], Maxout networks and variants [9, 22], and exploiting tree based priors [23] while training CNNs.", "startOffset": 105, "endOffset": 109}, {"referenceID": 8, "context": "Impressive performance on the CIFAR dataset has been achieved using recently proposed Network in Network [17], Maxout networks and variants [9, 22], and exploiting tree based priors [23] while training CNNs.", "startOffset": 140, "endOffset": 147}, {"referenceID": 21, "context": "Impressive performance on the CIFAR dataset has been achieved using recently proposed Network in Network [17], Maxout networks and variants [9, 22], and exploiting tree based priors [23] while training CNNs.", "startOffset": 140, "endOffset": 147}, {"referenceID": 22, "context": "Impressive performance on the CIFAR dataset has been achieved using recently proposed Network in Network [17], Maxout networks and variants [9, 22], and exploiting tree based priors [23] while training CNNs.", "startOffset": 182, "endOffset": 186}, {"referenceID": 19, "context": "Further, several authors have investigated the use of CNNs as feature extractors [20] on which discriminative classifiers are trained for predicting class labels.", "startOffset": 81, "endOffset": 85}, {"referenceID": 25, "context": "The recent work by [26] proposes to optimize a multi-label loss function that exploits the structure in output label space.", "startOffset": 19, "endOffset": 23}, {"referenceID": 6, "context": "In [7], the authors used a fast initial na\u0131\u0308ve bayes training sweep to find the hardest classes from the confusion matrix and then trained SVMs to separate each of the hardest class pairs.", "startOffset": 3, "endOffset": 6}, {"referenceID": 27, "context": "blobs, corners) [28] which are useful for classifying all fine categories.", "startOffset": 16, "endOffset": 20}, {"referenceID": 15, "context": "In [16], a similar temporal sparsity term is adopted to regularize the learning of sparse restricted Boltzmann machines in an unsupervised setting.", "startOffset": 3, "endOffset": 7}, {"referenceID": 5, "context": "Pretraining is proven to be effective for overcoming the difficulty of insufficient training data [6].", "startOffset": 98, "endOffset": 101}, {"referenceID": 1, "context": "\u2022 Third, Laplacian eigenmap [2] is used to obtain lowdimensional feature representations {fi}i=1 for the fine categories.", "startOffset": 28, "endOffset": 31}, {"referenceID": 4, "context": "\u2022 Last, Affinity Propagation [5] is employed to cluster C fine categories into C \u2032 coarse categories.", "startOffset": 29, "endOffset": 32}, {"referenceID": 11, "context": "We evaluate HD-CNN on the benchmark dataset CIFAR100 [12].", "startOffset": 53, "endOffset": 57}, {"referenceID": 10, "context": "We implement HD-CNN on the widely deployed Caffe [11] project and plan to release our code.", "startOffset": 49, "endOffset": 53}, {"referenceID": 8, "context": "We follow [9] to preprocess the datasets (e.", "startOffset": 10, "endOffset": 13}, {"referenceID": 13, "context": "For CIFAR100, we use randomly cropped image patch of size 26 \u00d7 26 and their horizontal reflections for training, For testing, we use multiview testing [14].", "startOffset": 151, "endOffset": 155}, {"referenceID": 13, "context": "We follow [14] to update the network parameter by back propagation.", "startOffset": 10, "endOffset": 14}, {"referenceID": 22, "context": "ConvNet + Tree based priors [23] 63.", "startOffset": 28, "endOffset": 32}, {"referenceID": 16, "context": "Network in nework [17] 64.", "startOffset": 18, "endOffset": 22}, {"referenceID": 16, "context": "In [17], a NIN network with three stacked mlpconv layers achieves state-of-the-art testing accuracy 64.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "33% which improves the current best method NIN [17] by 0.", "startOffset": 47, "endOffset": 51}], "year": 2014, "abstractText": "Existing deep convolutional neural network (CNN) architectures are trained as N-way classifiers to distinguish between N output classes. This work builds on the intuition that not all classes are equally difficult to distinguish from a true class label. Towards this end, we introduce hierarchical branching CNNs, named as Hierarchical Deep CNN (HD-CNN), wherein classes that can be easily distinguished are classified in the higher layer coarse category CNN, while the most difficult classifications are done on lower layer fine category CNN. We propose utilizing a multinomial logistic loss and a novel temporal sparsity penalty for HD-CNN training. Together they ensure each branching component deals with a subset of categories confusing to each other. This new network architecture adopts coarseto-fine classification strategy and module design principle. The proposed model achieves superior performance over standard models. We demonstrate state-of-the-art results on CIFAR100 benchmark.", "creator": "LaTeX with hyperref package"}}}