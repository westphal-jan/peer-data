{"id": "1410.1103", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Oct-2014", "title": "Online Ranking with Top-1 Feedback", "abstract": "We consider a setting where a system learns to rank a fixed set of m items. The goal is produce a good ranking for users with diverse interests who interact with the system for T rounds in an online fashion. We consider a novel top-1 feedback model for this problem: at the end of each round, the relevance score for only the top ranked object is revealed to the system. However, the performance of the system is judged on the entire ranked list. We provide a comprehensive set of results regarding learnability under this challenging setting. For popular ranking measures such as PairwiseLoss and DCG, we prove that the minimax regret is of order T^{2/3}. Moreover, the minimax regret is achievable using an efficient algorithmic strategy that only spends O(m log m) time per round. The same algorithmic strategy achieves O(T^{2/3}) regret for Precision@k. Surprisingly, we show that for normalized versions of these ranking measures, namely AUC, NDCG and MAP, no online ranking algorithm can have sub-linear regret.", "histories": [["v1", "Sun, 5 Oct 2014 00:51:59 GMT  (180kb,D)", "http://arxiv.org/abs/1410.1103v1", null], ["v2", "Tue, 4 Aug 2015 18:10:14 GMT  (864kb,D)", "http://arxiv.org/abs/1410.1103v2", "The previous version is being replaced by the conference version, which appeared in 18th International Conference on Artificial Intelligence and Statistics (AISTATS 2015). in Volume 38 of JMLR Workshop and Conference Proceedings (2015)"], ["v3", "Sun, 6 Mar 2016 20:42:02 GMT  (121kb,D)", "http://arxiv.org/abs/1410.1103v3", "Previous version being replaced by conference version. Appeared in AISTATS 2015"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sougata chaudhuri", "ambuj tewari"], "accepted": false, "id": "1410.1103"}, "pdf": {"name": "1410.1103.pdf", "metadata": {"source": "CRF", "title": "Online Ranking with Top-1 Feedback", "authors": ["Sougata Chaudhuri", "Ambuj Tewari"], "emails": ["sougata@umich.edu", "tewaria@umich.edu", "Precision@k."], "sections": [{"heading": "1 Introduction", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "2 Notation and Preliminaries", "text": "We have a fixed set of m objects numbered {\u03c31, 2,.., m}. A permutation \u03c3 gives an assignment of objects to their ranks and their inverted \u03c3 \u2212 1 returns an assignment of ranks to objects. Thus \u03c3 (i) = j means that object i is placed at position j, while \u03c3 \u2212 1 (i) = j means that object j is placed at position i. For a binary relevance vector r (0, 1} m, r (i) relevance level of the object i. We denote {1,., n} by [n]. The learner can choose actions (permutations) from m!, while the nature / opponent can choose from 2m results (relevance vectors) if relevance levels are limited to binary levels. The actions of the learner (or opponent) are determined by {\u03c3i: i [m!] (resp."}, {"heading": "3 Ranking Measures", "text": "We consider ranking measures, which can be expressed in the form f (\u03c3) = r, where the function f: Rm \u2192 Rm is composed of m copies of a univariate, monotonous, scalar estimated function (< f: R \u2192 R. Monotonic (increasing) function. Thus, f (\u03c3) = [fs (\u03c3 (j))) means, whenever \u03c3 (i), Finnish (j), and j. Monotonic (decreasing) measures are similarly defined, the following popular measures can be defined in the form f: PairwiseLoss & SumLoss: PairwiseLoss as: PL (r) = NormaliseLoss."}, {"heading": "4 Summary of Results", "text": "Result 1: The minimax regret under DCG and PairwiseLoss (and thus SumLoss) corresponds to the result (T 2 / 3). Result 2: An efficient algorithm with running time O (m logm) per step, however, achieves the minimax regret under DCG and PairwiseLoss and also has a regret of O (T 2 / 3) for Precision @ k. However, the precise minimax regret under Precision @ k, k \u2265 2 remains an open problem. Result 3: The minimax regret for any of the standardized versions - NDCG, MAP and AUC - is the result (T). Therefore, there is no algorithm that achieves sublinear regret for the measured results.Result 3: The minimax regret for any of the standardized versions - NDCG, MAP and AUC - are not relevant to any normed DCG, NCG and NAUC versions."}, {"heading": "5 Relevant Definitions from Partial Monitoring", "text": "We develop all results in the context of SumLoss. We then extend the results to other ranking metrics. Our main results on repentance limits are based on some of the theory for abstract partial monitoring games developed in [4, 10]. To understand this, we reproduce the relevant notations and definitions in the context of SumLoss.Loss and Feedback Matrices: The online learning game with the SumLoss metrics and feedback indicating the relevance of the best rated object can be expressed in the form of a pair of loss matrix and feedback matrices. The loss matrix L is a m! \u00b7 2m dimensional matrix, with lines indicating the actions of the learner (permutations) and columns representing the actions of the opponent (relevance vectors). The entry in cell (i, j) of L indicates losses suffered when the learner plays action (.ei)."}, {"heading": "6 Minimax Regret for SumLoss", "text": "The minimax repentance of SumLoss is confirmed by the proof that: a) SumLoss satisfies global observability and b) it does not satisfy local observability."}, {"heading": "6.1 Global Observability", "text": "s actions (\u03c3i, \u03c3j), it is true that \"i \u2212\" j-j-k actions (m!) Col (S > k) (where Col refers to the column space).The global observation condition essentially states that the (vector) loss between each pair of actions of the learner must belong to the vector space encompassed by (transposed) signal matrices corresponding to all possible actions of the learner. We derive the following theorem to the global observability for SumLoss (proof in appendix).Theorem 1. The global observation condition according to definition 3, holds w.r.t. loss matrix L and feedback matrix H, which is defined for SumLoss, proves for each action 1.m."}, {"heading": "6.2 Local Observability", "text": "Definition 4: Two Pareto-optimal (learner) actions i and j are also called adjacent actions if Ci-Cj is a (2 \u2212 2) dimensional polytopic (where Ci is a probability cell of the action \u03c3i). The adjacent action of two adjacent (learner) actions i and j is called locally observable if \"i \u2212\" j-j-k-N + i, jCol (S > k): The condition of local observability applies if each pair of adjacent (learner) actions is locally observable. We now show that local observability conditions for L, H fail under SumLoss. First, we propose the following Lemmata describing Pareto-optimal actions and adjacent actions for SumLers.Lemma 2."}, {"heading": "6.3 Minimax Regret Bound", "text": "First, we get a lower limit by combining our Theorem 4 with Theorem 4 in [4] Episode 5. There is an online SumLoss game with top-1 feedback, so for each online algorithm there is an opponent strategy that generates relevance vectors that guarantees the following learning activities. An immediate sequence of Theorem 1 and Theorem 3.1 in [7] yields an efficient algorithm (inspired by the algorithm originally stated in [16]."}, {"heading": "7 Efficient Algorithm for Obtaining Minimax Regret under Sum-", "text": "The running time of the algorithm per turn is O (m logm). The key idea we use in our algorithm is to divide the time into phases. Within each phase, we divide a small number of laps for pure exploration (this allows us to estimate the average relevance of the vector for this phase), using the average vector as a complete information vector for the next phase, we follow the actions according to the distribution proposed by the Perturbed Leader (FTPL) (this is the exploitation of previous experience). One of the main reasons for exploiting FTPL in our algorithm is that the structure of our problem distribution can be maintained implicitly via m objects, rather than explicitly maintaining the distribution over m!"}, {"heading": "8 Regret Bounds for PairwiseLoss, DCG and Prec@k", "text": "As shown in Equation 2, the regret of SumLoss is the same as the regret of PairwiseLoss = functions of PairwiseLoss. Thus, SumLoss can be replaced by PairwiseLoss in Cor. 5 and Thm. 7 to get exactly the same results for remorse. Moreover, all results of SumLoss can be extended to DCG. In addition, the results can also be extended to discrete, non-binary relevance vectors. The main differences between SumLoss and DCG are the following: the former is a loss function, the latter is a win function. Also f (bracketed) 6 = unit in DCG (Def. in Sec.2) and if r. {0, 1, 1,."}, {"heading": "9 Non-Existence of Sublinear Regret Bounds for NDCG, MAP", "text": "and AUCAs listed in paragraph 3, NDCG, MAP and AUC are normalized versions of the measures DCG, Precision @ k and PairwiseLoss. We have the following problem for all these normalized ranking measures. Lemma 11. The condition of global observability according to definition 1 fails for NDCG, MAP and AUC. Combining the above problem with Theorem 2 of [4], one comes to the conclusion that there can be no algorithm that has sublinear regret for one of the following measures: NDCG, MAP or AUC, with Top-1 feedback. Theorem 12. There is an online game for NDCG with Top-1 feedback, so that for each online algorithm there is an opponent strategy that guarantees that the following maxMax T value T = 1 NDCG (3, rt) \u2212 E [T value NDCG = 1 (further) is substituted by AUDG (t), or only if the CT value is subordinated."}, {"heading": "10 Empirical Results", "text": "We performed simulation studies to compare the regret rates of SumLoss and DCG when feedback is received only for the best-rated object (by applying Algorithm1) and the full relevance vector is revealed at the end of each round (by applying FPL of [13]). Relevance vectors were limited to taking binary values. We simulated relevance vectors for a fixed set of 10 objects (m = 10). We initially fixed half of the relevant objects and the other half irrelevant as the true relevance vector. Subsequently, binary relevance vectors were simulated for the opponent by adding small Gaussian noise to the true relevance vector. \u2212 Thus, there were predominantly small differences between the relevance vectors that are relevant and other half irrelevant, simulating the fact that in the real world the majority of users will agree on the relevance of most objects, with small differences. Total rate Rate Rate Rate Rate Relevance rate = 10000 Rate-Rate-Rate-Rate-Rate-Rate-Rate-were generated for the average rate-Rate-Rate-Rate-Rate-Rate-Rate-Rate-Rate-Rate-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rum-Rate-Rum-Rum-Rum-Rum-Rate-Rum-Rum-Rate-was determined by the real-Rate-Rate-Rate-Rum-Rate-Rate-Rum-Rate-Rate-Rum-Rate-Rate-Rate-Rate-was determined by the average-Rate-Rum-Rate-Rate-Rate-Rate-Rate-Rum-Rate-Rate-Rate-were generated."}, {"heading": "11 Conclusion", "text": "The only exception is Precision @ k, where the possibility of an O (T 1 / 2) regret algorithm remains open. Note that Precision @ k is really strange, because top-1 feedback is actually full feedback for k = 1. The most interesting future extension of this work is to go beyond the ranking of fixed objects and consider different document lists associated with queries. This falls into the category of partial monitoring with page information. Very little relevant work has been done in the general environment and our current work may lay the groundwork for an interesting application in this area. Another extension is to investigate whether an algorithm with sublinear regret can be defined for NDCG, MAP or AUC if the regret is defined relative to a constant factor (greater than 1) times the best performance in retrospect."}, {"heading": "12 Regret for SumLoss", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "12.1 Proof of Lemma 2", "text": "Proof. For each p-shaped action we have \"i \u00b7 p = \u2211 2m j = 1 pj (\u03c3i \u00b7 rj) = \u03c3i \u00b7 (\u2211 2mj = 1 pjrj) = \u03c3i \u00b7 Er [r], where the expectation is taken in reverse order, that is, the object with the highest expected relevance is placed at number 1 and so on. Formally, li \u00b7 p is minimized when He [r (\u03c3 \u2212 1i (1)] \u2265 Er [r (\u03c3 \u2212 1 i (2)] \u2265 Er [r (conditioning \u2212 1 i (m)].Thus, for the action i the probability cell is defined as Ci = {p \u2212 2 (1)."}, {"heading": "12.2 Proof of Lemma 3", "text": "Proof. From Lemma 2 we know that each of the actions of the learner is pareto-optimal and that Ci, connected with the action \u03c3i, has a structure... > Er [r (\u03c3 \u2212 1 i (m)]. Let it apply: \u03c3 \u2212 1i (k) = a, \u03c3 \u2212 1 i (k + 1) = b. Let it also be true that \u03c3 \u2212 1 j (k) = b, \u03c3 \u2212 1 j (k + 1) = a and \u03c3 \u2212 1i (n) = expanded \u2212 1 j (n), \u30fb n 6 = {k, k + 1}. This indicates the sufficient condition specified in Lemma. 3 for the {\u03c3i, \u03c3j} as neighbours. Then Ci \u0445 Cj = {p) is considered to be \u00b2 \u00b2 j = 1 pj = 1, \u043c (1 \u2212 i) as fulfilled."}, {"heading": "12.3 Proof of Theorem 4", "text": "Proof. We will explicitly show that the condition of local observability fails by taking into account the case if the number of objects m = 3. Specifically, the action pair {\u03c31, \u03c32} in Tables 1 and 2 are neighbouring actions using Lemma 3. Furthermore, since every action \u03c3k is pareto-optimal, each Ck is 2-1-dimensional. Since C1-C2 2 is 2 2-dimensional (by definition 4), the neighbouring action palette {\u03c31, \u03c32} is exact \u03c31 and \u03c32 and contains no other actions. According to the definition of the signal matrices S\u03c31, S\u03c32 and the entries' 1, '2 in Tables 1 and 2, we have S\u03c31 = S\u03c32 = [1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1]' 1 \u2212 1 0 0] (8) It is clear that \"1 \u2212 '2 / Col (S-1) > does not meet a definition."}, {"heading": "13 Efficient Algorithm for Obtaining Regret", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "13.1 Proof of Lemma 8", "text": "Proof. We can write r-t = \u2211 m-j = 1 rij (j) ej, where ej is the standard base vector along the coordinate j. Then ei1,..., im (r-t) = \u2211 m-j = 1eij (rij (j) ej) = \u2211 m-j = 1 \u2211 t-k = 1rk (j) ej t = ravg1: t."}, {"heading": "13.2 Proof of Theorem 7", "text": "Instead of top-1-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector"}, {"heading": "14 Regret Bounds for DCG and Prec@k", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "14.1 Extension of Results of SumLoss to DCG", "text": "We give pointers in the direction of proving the following results: a) Local observability condition does not hold for DCG (in combination with theorem 4 in [4], proves that the lower limit of regret is the DCG (T 2 / 3). b) The efficient algorithm of Sec.7 applies to DCG, with the regret of O (T 2 / 3), which is complicated for non-binary relevance vectors.Let adversary be able to choose r {0, 1,. All results are applicable to non-binary relevance vectors. This allows us to skip the proof of global observability, which is complicated for non-binary relevance vectors.Let adversary be able be able to choose r {0, 1,."}, {"heading": "14.2 Extension of Results of SumLoss to Prec@k", "text": "Since Prec @ k = f (\u03c3) \u00b7 r, where f (\u00b7) has properties listed in Sec. 3, extends all results of SumLoss trivially to Prec @ k, except the results to local observability, the reason for this is that f (\u00b7) of SumLoss is strictly monotonous, f (\u00b7) of Prec @ k is monotonous, but not strictly. The winning function depends only on the objects in the top k position of the ranking, regardless of the order. A careful analysis shows that Lemma 3 is not monotonous in the case of Prec @ k. Therefore, we cannot define the adjacent plot of the optimal action pairs of Pareto and therefore cannot prove or refute the local observability. However, the structure of the neighbors in Prec @ k remains an open question. However, the non-strict monotony of Prec @ k is required to M (y) = bow maximical behavior f () of Corollyc (c) does not result in a strict monotony of Prec @ (3)."}, {"heading": "15 Non-Existence of sublinear regret bounds for NDCG, MAP", "text": "and AUC extensionsWe show via simple calculations that for the case m = 3, global observability condition has not hold for NDCG, when relevant vectors are restricted to take binary values. The intuition behind failure to satisfy global observability condition is that the NDCG (\u03c3, r) = f (\u03c3) \u00b7 g (r), where g (r) = r / Z (r) (r) (see Sec.3). Therefore, g (\u00b7) cannot be defined by univariate, scalar functions, making it impossible to define the difference between two lines as a linear combination of (transposed) signal matrices.Proof. The following calculations are easy to perform: The first and last row of Table 1, when calculated for NDCG, is: \"\u03c31 = [1, 1 / 2, log22 / log23 / log23 / log23 / 2)."}], "references": [{"title": "Diversifying search results", "author": ["Rakesh Agrawal", "Sreenivas Gollapudi", "Alan Halverson", "Samuel Ieong"], "venue": "In Proceedings of the Second ACM International Conference on Web Search and Data Mining,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Improved bounds for online learning over the permutahedron and other ranking polytopes", "author": ["Nir Ailon"], "venue": "In AISTATS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Modern information retrieval, volume 463", "author": ["R. Baeza-Yates", "B. Ribeiro-Neto"], "venue": "ACM press New York.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Partial monitoring\u2013classification, regret bounds, and algorithms, 2013", "author": ["G\u00e1bor Bart\u00f3k", "Dean Foster", "D\u00e1vid P\u00e1l", "Alexander Rakhlin", "Csaba Szepesv\u00e1ri"], "venue": "Best viewed in color. Code available on request", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Minimax regret of finite partial-monitoring games in stochastic environments", "author": ["G\u00e1bor Bart\u00f3k", "D\u00e1vid P\u00e1l", "Csaba Szepesv\u00e1ri"], "venue": "Journal of Machine Learning Research-Proceedings Track,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "From external to internal regret", "author": ["Avrim Blum", "Yishay Mansour"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Regret minimization under partial monitoring", "author": ["Nicolo Cesa-Bianchi", "G\u00e1bor Lugosi", "Gilles Stoltz"], "venue": "Mathematics of Operations Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "AUC optimization vs. error rate minimization", "author": ["Corinna Cortes", "Mehryar Mohri"], "venue": "In NIPS, page 10,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "On the consistency of ranking algorithms", "author": ["John C Duchi", "Lester W Mackey", "Michael I Jordan"], "venue": "In Proceedings of the 27th International Conference on Machine Learning (ICML-", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "No internal regret via neighborhood watch", "author": ["Dean P Foster", "Alexander Rakhlin"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Cumulated gain-based evaluation of IR techniques", "author": ["K. J\u00e4rvelin", "J. Kek\u00e4l\u00e4inen"], "venue": "ACM Transactions on Information Systems (TOIS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "IR evaluation methods for retrieving highly relevant documents", "author": ["Kalervo J\u00e4rvelin", "Jaana Kek\u00e4l\u00e4inen"], "venue": "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Efficient algorithms for online decision problems", "author": ["Adam Kalai", "Santosh Vempala"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Combinatorial partial monitoring game with linear feedback and its applications", "author": ["Tian Lin", "Bruno Abrahao", "Robert Kleinberg", "John Lui"], "venue": "In Proceedings of ICML 2014 Cycle", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Letor: Benchmark dataset for research on learning to rank for information retrieval", "author": ["Tie-Yan Liu", "Jun Xu", "Tao Qin", "Wenying Xiong", "Hang Li"], "venue": "In Proceedings of SIGIR 2007 workshop on learning to rank for information retrieval,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Discrete prediction games with arbitrary feedback and loss", "author": ["Antonio Piccolboni", "Christian Schindelhauer"], "venue": "In Computational Learning Theory,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "Redundancy, diversity and interdependent document relevance", "author": ["Filip Radlinski", "Paul N Bennett", "Ben Carterette", "Thorsten Joachims"], "venue": "In ACM SIGIR Forum,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}], "referenceMentions": [{"referenceID": 11, "context": "Learning occurs in an online setting: at each round, the system outputs a ranked list of the objects and the quality of ranking is measured by one of several popular ranking measures (like DCG [12] or MAP [3]), taking into account the users preferences encoded as relevance vectors.", "startOffset": 193, "endOffset": 197}, {"referenceID": 2, "context": "Learning occurs in an online setting: at each round, the system outputs a ranked list of the objects and the quality of ranking is measured by one of several popular ranking measures (like DCG [12] or MAP [3]), taking into account the users preferences encoded as relevance vectors.", "startOffset": 205, "endOffset": 208}, {"referenceID": 16, "context": "The idea of ranking for diverse preferences has been motivated from a branch of work, sometimes called \u201cranking with diversity\u201d [18, 17, 1] .", "startOffset": 128, "endOffset": 139}, {"referenceID": 0, "context": "The idea of ranking for diverse preferences has been motivated from a branch of work, sometimes called \u201cranking with diversity\u201d [18, 17, 1] .", "startOffset": 128, "endOffset": 139}, {"referenceID": 6, "context": "The appropriate framework to study the problem is that of partial monitoring [7].", "startOffset": 77, "endOffset": 80}, {"referenceID": 13, "context": "A very recent paper shows another practical application of the idea where feedback is neither full information nor bandit [14].", "startOffset": 122, "endOffset": 126}, {"referenceID": 3, "context": "Recent advances in the classification of partial monitoring games tell us that the minimax regret, in an adversarial setting, is governed by a property of the loss and feedback functions called observability [4, 10].", "startOffset": 208, "endOffset": 215}, {"referenceID": 9, "context": "Recent advances in the classification of partial monitoring games tell us that the minimax regret, in an adversarial setting, is governed by a property of the loss and feedback functions called observability [4, 10].", "startOffset": 208, "endOffset": 215}, {"referenceID": 8, "context": "We instantiate these general observability notions for the top-1 feedback case and prove that, for some ranking measures, namely PairwiseLoss [9], DCG and Precision@k [15], global observability holds.", "startOffset": 142, "endOffset": 145}, {"referenceID": 14, "context": "We instantiate these general observability notions for the top-1 feedback case and prove that, for some ranking measures, namely PairwiseLoss [9], DCG and Precision@k [15], global observability holds.", "startOffset": 167, "endOffset": 171}, {"referenceID": 7, "context": "For example, the normalized versions of PairwiseLoss, DCG and Precision@k are called AUC [8], NDCG [11] and MAP respectively.", "startOffset": 89, "endOffset": 92}, {"referenceID": 10, "context": "For example, the normalized versions of PairwiseLoss, DCG and Precision@k are called AUC [8], NDCG [11] and MAP respectively.", "startOffset": 99, "endOffset": 103}, {"referenceID": 1, "context": "It has been shown in [2] that SumLoss differs from PairwiseLoss only by an r-dependent constant and hence the regret under the two measures are equal:", "startOffset": 21, "endOffset": 24}, {"referenceID": 4, "context": "Had the relevance vectors been stochastic in nature, the results would have held; however, efficient algorithm already exists in stochastic case [5] .", "startOffset": 145, "endOffset": 148}, {"referenceID": 3, "context": "developed in [4, 10].", "startOffset": 13, "endOffset": 20}, {"referenceID": 9, "context": "developed in [4, 10].", "startOffset": 13, "endOffset": 20}, {"referenceID": 3, "context": "The following definitions, given for abstract problems in [4], has been refined to fit our problem context.", "startOffset": 58, "endOffset": 61}, {"referenceID": 3, "context": "First, we get a lower bound by combining our Theorem 4 with Theorem 4 in [4].", "startOffset": 73, "endOffset": 76}, {"referenceID": 6, "context": "1 in [7] gives an in-efficient algorithm (inspired by the algorithm originally given in [16]) obtaining O(T 2/3(log T )1/3) regret.", "startOffset": 5, "endOffset": 8}, {"referenceID": 15, "context": "1 in [7] gives an in-efficient algorithm (inspired by the algorithm originally given in [16]) obtaining O(T 2/3(log T )1/3) regret.", "startOffset": 88, "endOffset": 92}, {"referenceID": 6, "context": "The algorithm in Figure 1 of [7] achieves O(T 2/3(log T )1/3) regret bound for SumLoss.", "startOffset": 29, "endOffset": 32}, {"referenceID": 6, "context": "However, the algorithm in [7] is intractable in our setting since the number of learner\u2019s actions is exponential in number of objects m.", "startOffset": 26, "endOffset": 29}, {"referenceID": 12, "context": "Using the average vector as a full information vector for next phase, rest of the rounds in next phase follow the actions according to the distribution suggested by Follow the Perturbed Leader (FTPL) [13] (this is exploitation of previous experience).", "startOffset": 200, "endOffset": 204}, {"referenceID": 5, "context": "Our algorithm is motivated by the reduction from bandit-feedback to full feedback given in [6].", "startOffset": 91, "endOffset": 94}, {"referenceID": 5, "context": "However, the algorithm in [6] cannot be directly applied to our problem, because we are not in the bandit setting and hence do not know loss of any action.", "startOffset": 26, "endOffset": 29}, {"referenceID": 3, "context": "Combining the above lemma with Theorem 2 of [4], we conclude that there cannot exist any algorithm which has sublinear regret for any of the following measures: NDCG, MAP or AUC, with top-1 feedback.", "startOffset": 44, "endOffset": 47}, {"referenceID": 12, "context": "We conducted simulation studies to compare regret rates of SumLoss and DCG, when feedback is received only for top ranked object (by applying Algorithm1 ) and full relevance vector is revealed at end of each round (by applying FPL of [13]).", "startOffset": 234, "endOffset": 238}], "year": 2017, "abstractText": "We consider a setting where a system learns to rank a fixed set of m items. The goal is produce a good ranking for users with diverse interests who interact with the system for T rounds in an online fashion. We consider a novel top-1 feedback model for this problem: at the end of each round, the relevance score for only the top ranked object is revealed to the system. However, the performance of the system is judged on the entire ranked list. We provide a comprehensive set of results regarding learnability under this challenging setting. For popular ranking measures such as PairwiseLoss and DCG, we prove that the minimax regret is \u0398(T ). Moreover, the minimax regret is achievable using an efficient algorithmic strategy that only spends O(m logm) time per round. The same algorithmic strategy achieves O(T ) regret for Precision@k. Surprisingly, we show that for normalized versions of these ranking measures, namely AUC, NDCG and MAP, no online ranking algorithm can have sub-linear regret.", "creator": "LaTeX with hyperref package"}}}