{"id": "1410.1228", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Oct-2014", "title": "Interactive Fingerprinting Codes and the Hardness of Preventing False Discovery", "abstract": "We show a tight bound on the number of adaptively chosen statistical queries that a computationally efficient algorithm can answer accurately given $n$ samples from an unknown distribution. A statistical query asks for the expectation of a predicate over the underlying distribution, and an answer to a statistical query is accurate if it is \"close\" to the correct expectation over the distribution. This question was recently considered by Dwork et al., who showed that $\\tilde{\\Omega}(n^2)$ queries can be answer efficiently, and also by Hardt and Ullman, who showed that answering $\\tilde{O}(n^3)$ queries is computationally hard. We close the gap between the two bounds by proving a new, nearly-optimal hardness result. Specifically, we show that, under a standard hardness assumption, there is no computationally efficient algorithm that given $n$ samples from an unknown distribution can give valid answers to $O(n^2)$ adaptively chosen statistical queries. An implication of our results is that computationally efficient algorithms for answering arbitrary, adaptively chosen statistical queries may as well be differentially private. We obtain our results via an optimal construction of a new combinatorial object that we call an interactive fingerprinting code, which may be of independent interest.", "histories": [["v1", "Sun, 5 Oct 2014 23:55:22 GMT  (38kb,D)", "http://arxiv.org/abs/1410.1228v1", null], ["v2", "Fri, 20 Feb 2015 19:29:47 GMT  (41kb,D)", "http://arxiv.org/abs/1410.1228v2", null]], "reviews": [], "SUBJECTS": "cs.CR cs.DS cs.LG", "authors": ["thomas steinke", "jonathan ullman"], "accepted": false, "id": "1410.1228"}, "pdf": {"name": "1410.1228.pdf", "metadata": {"source": "CRF", "title": "Interactive Fingerprinting Codes and the Hardness of Preventing False Discovery", "authors": ["Thomas Steinke", "Jonathan Ullman"], "emails": ["tsteinke@seas.harvard.edu.", "jullman@cs.columbia.edu."], "sections": [{"heading": null, "text": "Harvard University School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616. Email: tsteinke @ seas.harvard.edu. \u2020 Harvard University Center for Research on Computation and Society and Columbia University. Supported by NSF grant CNS-1237235 and a Simons Society of Fellows Junior Fellowship. Email: jullman @ cs.columbia.edu.ar Xiv: 141 0.12 28v1 [cs.CR] 5 October 2Contents"}, {"heading": "1 Introduction 1", "text": "1.1 Discussion of Results........................................................................................................................."}, {"heading": "2 Interactive Fingerprinting Codes 5", "text": ".)......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "3 Hardness of False Discovery 22", "text": "3.1 The statistical query model..........................................................................................................................."}, {"heading": "4 Hardness of Avoiding Blatant Non Privacy 28", "text": "4.1 Blatant non-confidentiality and sampling accuracy.........................................................................................................."}, {"heading": "1 Introduction", "text": "Empirical research is typically conducted by making multiple \"queries\" (e.g. summary statistics, hypotheses tests, or learning algorithms) that are not based on a finite sample from a particular population. \"False discovery\" occurs when the results of queries in the sample do not reflect the population at large, for example when a particular irrelevant gene is considered predictive of cancer based on the sample. For decades, statisticians have developed methods to prevent false discoveries, such as the \"Bonferroni Correction\" [Bon36, Dun61] and the widely used and highly influential method by Benjamin Amini and Hochberg [BH95] to control the \"false detection rate.\" Nevertheless, false discovery persists across all empirical sciences, and both popular and scientific articles report an increasing number of invalid research results. Typically, false discovery is attributed to the misuse of statistics."}, {"heading": "1.1 Discussion of Results", "text": "Theorem 1.1 (informal). Assuming that there are one-way functions, there is no computationally efficient oracle that n samples apply to O (n2) adaptively selected queries. As in [HU14], our hardness result applies whenever the dimensionality of the data grows faster with sample size than logarithmic, so that 2d is no longer polynomic in n.2. This requirement is rather mild and also necessary. If n 2d then the empirical distribution of n samples at statistical distance is close to the underlying distribution, then any statistical query can be answered accurately in the sample. Therefore, the dimensionality of the data has a significant influence on the hardness of the problem. [HU14] also showed that if the dimensionality d is significantly greater than n, we cannot even hope for a computer-infinite oracle."}, {"heading": "1.1.1 Techniques", "text": "This year, we will be in a position to take the lead, \"he said in an interview with the Deutsche Presse-Agentur.\" We have never lost so much time as this year, \"he said.\" We have never lost so much time, \"he said,\" but we have never lost so much time. \""}, {"heading": "1.2 Applications to Data Privacy", "text": "The adversary consulted for the prevention of false discoveries, carries out effectively a reconstruction attack on the database of samples. (Roughly said: If there is an adversary who can reconstruct the set of samples S from the answers of the oracle, then the oracle is called \"blatantly non-private\" - it reveals essentially all the data it holds, and therefore cannot guarantee to the holders of the data any reasonable concept of privacy. Since the pioneering work of Dinur and Nissim [DN03], such reconstruction attacks are used to computerize strong limitations of the accuracy of the data-preserving oracles.With the help of interactive fingerprinting codes, combined with the framework of [HU14], we obtain the following results. (HU14] show similar results in which our O (n2) limits are replaced with privacy. (n3) Theorem 1,4 (computerible).Theorem 1.4 (The existence of every computrible, each functionality, each functionality)."}, {"heading": "1.3 Related Work", "text": "This year, it will be able to explore the aforementioned hreeeisrcnlrVo in order to stir them up and stir them up in order to stir them up."}, {"heading": "2 Interactive Fingerprinting Codes", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "2.1 Definition and Existence", "text": "We are now ready to formally define interactive fingerprint codes. < < < < < / p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p"}, {"heading": "2.2 The Construction", "text": "Our construction and analysis is based on the optimal (non-interactive) fingerprint codes of Tardos [Tar08] = \u00b2 and the robust variant of Bun et al. [BUV14]. The code is essentially the same, but columns are generated and shown to the opponent individually, and the tracking is modified to interactively identify the user. We start with some definitions and notations. For 0 \u2264 a < b \u2264 1, leave Da, b the distribution with support (a, b) and probability density function \u00b5 (p) = Ca, b / \u221a p (1 \u2212 p), where Ca, b is a normalizing constants. 4 For 1 \u00b2 (0.1 / 2), let D\u03b1 be the distribution to [0.1], which gives a sample of D\u03b1, 1 \u2212 \u03b1 with probability 1 \u2212 1, and for probability 1 \u2212 2, the probability is 1 \u2212 p."}, {"heading": "2.3 Analysis Overview", "text": "Intuitively, the amount of sji, which we call the user's score i, measures the \"correlation\" between the answers (a1, \u00b7 \u00b7 \u00b7, aj) of P and the i-th code word (c1i, \u00b7 \u00b7 \u00b7, c j i), using a certain measure of correlation that takes into account the selection p1,..., pj. If sji ever exceeds the threshold \u03c3, which means that the answers are significantly correlated with the i-th code word, then we accuse the user i. Our goal, therefore, is to show two things: solidity that the score of an innocent user (i.e. i < S1) never exceeds the threshold, since the answers cannot be correlated with the unknown i-th code word. And completeness, that the score of each guilty user (i.e. i-S1) will eventually exceed the threshold, which means that the answers must be correlated with the i-th."}, {"heading": "2.3.1 Soundness", "text": "If I am innocent, then since P does not see the code word (c1i, \u00b7 \u00b7, c j i) of the i-th user, there cannot be too much correlation. In this case, one can show that sji is the sum of the j independent random variables, each with the mean 0 and the variance 1, considering the answers a1,..., aj as fixed and the randomness higher than the choice of the unknown code word. Similar to Gaussian random variables, one would expect sji \u2264 = \u0445 (\u221a'log (1 / \u043c) with a probability of at least 1 \u2212 \u043c. Formally, the fact that the value is not limited in each round prevents the use of a Chernoff limit. Nevertheless, in Section 2.4, we prove the solidity with a Chernoff-like tail, which is limited for sji."}, {"heading": "2.3.2 Completeness", "text": "To prove completeness, we must show that for guilty users we have i-S1 sji > \u03c3 for some j-S1 users with a high probability. In sections 2.5.1 and 2.5.3, we prove that if P gives consistent answers in a fraction of 1-\u03b2 rounds, the sum of points for each guilty user is large. Specifically, in Theorem 2.15, we prove that the score s'i-i-i-s-s'i-s (\") with a high probability is high. This step is not too different from the analysis of Tardos and Bun et al. [Tar08, BUV14] for the non-interactive case. To show that for each i-S1 case the equation is sufficient to prove that the equation at some point sji > yields that we are not sufficient from the analysis of non-interactive words and Bun et al. [Tar08, BUV14] for the non-interactive case."}, {"heading": "2.3.3 Establishing Correlation", "text": "Proving the equation (1) is the key to the analysis. Our proof of it combines and simplifies the analyses of [Tar08] and [BUV14]. For this high overview we ignore the question of robustness and fix \u03b2 = 0.First we prove that the correlation is held in rounds and then we show that it is held in high probability using an Azuma-like concentration limit. (Again, since the random variables that are added are not limited, we are forced to use a tailor-made analysis to prove the concentration.) We show that it is held in expectation for each round. (In Proposition 2.12 we show that the concentration grows in expectation. ['] For each round the probability grows. [' s j \u2212 s j \u2212 s j \u2212 s j j \u2212 i = E-j i = E-j i-s-j-j-j-j is taken in expectation of the equation (1), (3) where expectations about the randomness of cj, cj, and j-j are taken."}, {"heading": "2.4 Proof of Soundness", "text": "We first show that no user is falsely accused unless with probability. This boils down to detecting a concentration limit. Then, another concentration limit shows that with a high probability, at most a fraction of users are falsely accused. These concentration limits are essentially standard. However, we show the concentration of variables of the form \"p\" (c), which can be quite large when p \"0 or p.\" This technical problem prevents us from directly applying the standard concentration limits. Instead, we open the standard proofs and verify the desired concentration. We take the usual approach of generating the moment and use it to give a tail limit. \"Lemma\" 2.3. For p \"p.\""}, {"heading": "2.5 Proof of Completeness", "text": "To show that the fingerprint code identifies guilty users, we must set the values of i-S1 s'i. First we tie their expectations and then their tails."}, {"heading": "2.5.1 Biased Fourier Analysis", "text": "In this section, we assume that the opponent P is always consistent - that is, we have no consistency and no consistency (1). In this section, the \"correlation\" between the bits given to the user i and the performance of the opponent is calculated. We must show that the consistency of the opponent implies that there is a correlation between the bits (1). In this section, we deviate from the correlation in [Tar08] to provide a more intuitive proof of the correlation. We have the following consistency, which implies the correlation between the bits and performance."}, {"heading": "2.5.2 Robustness", "text": "We demand that the finger print code is robust against conflicting answers. We show that the correlation with the existence of contradictions is still good. For f: {\u00b1 1} n \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u2212 \u00b2 \u2212 \u00b2 \u2212 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2, define a random variable dependence (f) on the existence of contradictions (f) = f (c) \u00b7 p \u00b2 \u00b2 p (n) throup (ci) + \u03b3I (p) \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 f (c), 2p p p \u2212 1), p \u00b2 (f), p \u00b2 (c) \u00b7 n \u00b2 p \u00b2 p \u00b2 \u00b2 \u00b2 \u00b2, whereby I am the indicator function and \u03b3 (0.1 / 2) \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 p \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 p (p) \u00b2 \u00b2 \u00b2 p (p), 2p p p \u2212 1), p \u00b2 (f), p \u00b2 (c) \u00b7 n \u00b2 p (c) \u00b2 \u00b2 \u00b2 \u00b2 p, n \u00b2 p, n \u00b2 \u00b2 p, p, p \u00b2, p \u00b2, p, p \u00b2, p, p \u00b2, p, p \u00b2, p, p \u00b2, p, p, p \u00b2, p, p, p \u00b2, p, p, p, p \u00b2, p, p, p, p, p \u00b2, p, p, p, p, p, p \u00b2, p, p, p, p, p, p, p \u00b2, p, p, p, p, p, p, p, p, p, p, p \u00b2, p, p, p, p, p, p, p, p, p, p, p, p, p, p \u00b2, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p \u00b2, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p."}, {"heading": "2.5.3 Concentration", "text": "So far we have shown that the fingerprint code is a good correlation or the opponent is not consistent in expectation. However, we have to do this with high probability. So we now show that the sums of the variables are not able to apply standard results directly. So, instead, we have to open the evidence and make sure that the concentration limits are adhered to. We proceed by shifting the moment-generation function of the variables (f) and then detecting an Azuma-like concentration! These calculations are not new or instructive."}, {"heading": "2.5.4 Bounding the Score", "text": "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "3 Hardness of False Discovery", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 The Statistical Query Model", "text": "Given a distribution D over {0,1} d, we would like to answer statistical queries about D. A statistical query on {0,1} d is specified by a function q: {0,1} d \u2192 [\u2212 1,1] and (abusive notation) is defined on q (D) = E x \u2190 RD [q (x)]. Our goal is to design an oracle O that uses statistical queries on D only using iid queries x1,..., xn \u2190 R D. Our focus is on the case where the queries are chosen adaptively and contrary. Specifically, O is a state algorithm that collects a collection of queries on x1,.... xn \u00b2 d, takes a statistical query q as input and returns a real answer to q1 that is adequate."}, {"heading": "3.2 Encryption Schemes", "text": "Our attack is based on the existence of a semantically secure encryption scheme for private keys. An encryption scheme is a triple efficient algorithm (Gen, Enc, Dec) with the following syntax: \u2022 Gen is a randomized algorithm that takes a security parameter \u03bb as input and prints a ciphertext ct. Formally, sk \u2190 R is gene (1\u03bb). \u2022 Dec is a randomized algorithm that takes a secret key and a ciphertext as input and prints a decrypted message m \u00b2. Formally, ct is \u2190 R Enc (sk, m). \u2022 Dec is a deterministic algorithm that takes a secret key and a ciphertext ct as input and prints a decrypted message m \u00b2. If the ciphertext was an encryption that is an encryption of m under the key sk, then m \u00b2 is a formal encryption that takes a secret key and a ciphertext ct ct ct ct ct as input and then outputs a decrypted message m \u00b2. If the cipheretext was an encryption that is an encryption of m under the key sk, then m \u00b2 is a formal encryption, then m \u00b2 is a formal encryption that is a minimum encryption of c \u00b2 we can follow with encryption of c \u00b2 sk (if m \u00b2), then m \u00b2 is (m = m)."}, {"heading": "3.3 Description of the Attack", "text": "The opponent is given in Figure 4. Figure 4 (Gen, Enc, Dec) is an encryption scheme, and F is an n-collusion-resistant interactive fingerprint code for N users of the length '=' (N), which is used for a \u03b2-fraction of errors with a false probability of accusation \u03b4 = 1 / 8. Note that Attackn, d is well defined only for the pairs n, d, N, and for the 1 + dlog2 (2000n) e \u2264 d, so there is a suitable choice of \u03bb N. In this section, we will assume that n = n (d) is a polynomial in d and that d is a sufficiently large unspecified constant to ensure that Attackn, d is well defined."}, {"heading": "3.4 Analysis of the Attack", "text": "J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J"}, {"heading": "3.5 An Information-Theoretic Lower Bound", "text": "As in [HU14], we observe that the techniques underlying our calculation result can also be used to prove an information-theoretical lower limit if the dimension of the data is large. At a high level, the fact is used that the encryption scheme we rely on must meet only relatively weak security properties, especially security for most O (n2) messages. This security feature can actually be achieved against mathematically unlimited opponents, provided that the length of the secret keys is O (n2). As a result, our lower limit can be held at mathematically unlimited oracles, but since the secret keys have a length O (n2), we need d = O (n2). We refer the reader to [HU14] for a slightly more detailed discussion and simply give the following result. Theorem 3.10: There is a function '(2000n, \u03b2) = O (n2 / (1 2 \u2212 \u03b2) 4), so that there is no O\u03b2 (200)."}, {"heading": "4 Hardness of Avoiding Blatant Non Privacy", "text": "In this section, we show how our arguments also imply that mathematically efficient oracles that guarantee accuracy for adaptively selected statistical queries must be blatantly non-private."}, {"heading": "4.1 Blatant Non Privacy and Sample Accuracy", "text": "Before we can define blatant non-privacy, we must define a term of accuracy that is more appropriate for the application to privacy. Unlike definition 3.1, where accuracy is defined in terms of distribution, here we define accuracy in terms of the sample itself. With this change in mind, we model blatant non-privacy over the following game.Definition 4.1. An oracle O is (\u03b1, \u03b2, \u03b3) sample accurate for \"adaptively selected queries, the n samples in {0.1} d, if for each opponent Apriv, P NonPrivacyn, d, '[O, April] [For (1 \u2212 \u03b2)\" decisions that pass jas (x, qj) \u2212 qj (x) \u2212 qj (x) selected n samples, if q (x) = 1n, [n] q [n] q (xi) the average is over the sample."}, {"heading": "4.2 Lower Bounds", "text": "In this section we show the following theoreminiken: \"We have no answer to this question.\" \"We have no answer to this question.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \"No.\" \".\" \"No.\" \"\" No. \"\" \"No.\" \"\". \"\" \"No.\" \"\" \"No.\" \"\" \"No.\" \"\" \"\" No. \".\" \"\" \"No.\". \".\" \"\" \"No.\". \"\" \".\" \"\" \".\" \"\" \"\" No. \"\" \".\" \"\" \".\" \"\" \"\".. \"\" \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"..\" \"..\". \".\" \"\" \"..\" \"\". \".\". \".\". \".\" \".\". \".\". \".\" \"\". \"\". \"\" \".\". \"\" \".\" \"\". \"\" \"\". \"\". \".\". \"\". \"\" \".\". \"\". \"\". \".\". \".\". \".\". \".\" \".\". \".\". \"\" \".\". \".\" \".\" \".\" \".\". \".\". \".\". \".\". \"\". \".\". \".\". \".\" \".\". \".\" \".\". \".\". \".\". \"\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\". \".\" \".\". \".\" \".\". \".\" \".\". \".\". \"\". \".\". \".\". \"\". \".\". \".\". \".\". \".\". \"\". \".\". \"...\". \".\"... \".......\"... \""}, {"heading": "4.3 An Information-Theoretic Lower Bound", "text": "Theorem 4.12. There is a function \"(2n) = O (n2), so that there is no oracle O (also no mathematically unlimited) that is (1 / 1000,0) -accurate for\" (2n) adaptively selected queries that have given n samples in {0,1} d where d \u2265 \"(2n). The proof is essentially identical to what is outlined in Section 3.5."}, {"heading": "Acknowledgements", "text": "We would like to thank Moritz Hardt and Salil Vadhan for their insightful discussions in the early stages of this work."}, {"heading": "A Security Reductions from Sections 3 and 4", "text": "In this section, we can be a little modular in the formal definition of the security of an encryption scheme. Security is defined by a pair of oracular E0 and E1. E1 (skN) takes as input the index of a key i (N) and a message to Enc (ski, m), whereas E0 (sk1, skN) is identical."}], "references": [{"title": "Controlling the false discovery rate: a practical and powerful approach to multiple testing", "author": ["Yoav Benjamini", "Yosef Hochberg"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "Benjamini and Hochberg.,? \\Q1995\\E", "shortCiteRegEx": "Benjamini and Hochberg.", "year": 1995}, {"title": "Bonferroni. Teoria statistica delle classi e calcolo delle probabilita", "author": ["Carlo Emilio"], "venue": "Pubbl. d. R. Ist. Super. di Sci. Econom. e Commerciali di Firenze.,", "citeRegEx": "Emilio,? \\Q1936\\E", "shortCiteRegEx": "Emilio", "year": 1936}, {"title": "Collusion-secure fingerprinting for digital data", "author": ["Dan Boneh", "James Shaw"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Boneh and Shaw.,? \\Q1998\\E", "shortCiteRegEx": "Boneh and Shaw.", "year": 1998}, {"title": "Fingerprinting codes and the price of approximate differential privacy", "author": ["Mark Bun", "Jonathan Ullman", "Salil P. Vadhan"], "venue": "In STOC,", "citeRegEx": "Bun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bun et al\\.", "year": 2014}, {"title": "Tracing traitors", "author": ["Benny Chor", "Amos Fiat", "Moni Naor"], "venue": "In CRYPTO,", "citeRegEx": "Chor et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Chor et al\\.", "year": 1994}, {"title": "Guilt-free data exploration (tentative title)", "author": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "venue": null, "citeRegEx": "Dwork et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2014}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "In TCC,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "Revealing information while preserving privacy", "author": ["Irit Dinur", "Kobbi Nissim"], "venue": "In PODS, pages 202\u2013210", "citeRegEx": "Dinur and Nissim.,? \\Q2003\\E", "shortCiteRegEx": "Dinur and Nissim.", "year": 2003}, {"title": "On the complexity of differentially private data release: efficient algorithms and hardness results", "author": ["Cynthia Dwork", "Moni Naor", "Omer Reingold", "Guy N. Rothblum", "Salil P. Vadhan"], "venue": "In STOC,", "citeRegEx": "Dwork et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2009}, {"title": "Multiple comparisons among means", "author": ["Olive Jean Dunn"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Dunn.,? \\Q1961\\E", "shortCiteRegEx": "Dunn.", "year": 1961}, {"title": "On some classical results in probability theory", "author": ["N. Etemadi"], "venue": "Sankhya: The Indian Journal of Statistics, Series A (1961-2002),", "citeRegEx": "Etemadi.,? \\Q1985\\E", "shortCiteRegEx": "Etemadi.", "year": 1985}, {"title": "Dynamic traitor tracing", "author": ["Amos Fiat", "Tamir Tassa"], "venue": "J. Cryptology,", "citeRegEx": "Fiat and Tassa.,? \\Q2001\\E", "shortCiteRegEx": "Fiat and Tassa.", "year": 2001}, {"title": "Preventing false discovery in interactive data analysis is hard", "author": ["Moritz Hardt", "Jonathan Ullman"], "venue": "In FOCS. IEEE, October", "citeRegEx": "Hardt and Ullman.,? \\Q2014\\E", "shortCiteRegEx": "Hardt and Ullman.", "year": 2014}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["Michael J. Kearns"], "venue": "In STOC, pages 392\u2013401", "citeRegEx": "Kearns.,? \\Q1993\\E", "shortCiteRegEx": "Kearns.", "year": 1993}, {"title": "Analysis of Boolean Functions", "author": ["Ryan O\u2019Donnell"], "venue": null, "citeRegEx": "O.Donnell.,? \\Q2014\\E", "shortCiteRegEx": "O.Donnell.", "year": 2014}, {"title": "Optimal probabilistic fingerprint codes", "author": ["G\u00e1bor Tardos"], "venue": "J. ACM,", "citeRegEx": "Tardos.,? \\Q2008\\E", "shortCiteRegEx": "Tardos.", "year": 2008}, {"title": "Answering n2+o(1) counting queries with differential privacy is hard", "author": ["Jonathan Ullman"], "venue": "In STOC, pages 361\u2013370", "citeRegEx": "Ullman.,? \\Q2013\\E", "shortCiteRegEx": "Ullman.", "year": 2013}, {"title": "Private multiplicative weights beyond linear queries", "author": ["Jonathan Ullman"], "venue": "CoRR, abs/1407.1571,", "citeRegEx": "Ullman.,? \\Q2014\\E", "shortCiteRegEx": "Ullman.", "year": 2014}], "referenceMentions": [], "year": 2017, "abstractText": "We show a tight bound on the number of adaptively chosen statistical queries that a computationally efficient algorithm can answer accurately given n samples from an unknown distribution. A statistical query asks for the expectation of a predicate over the underlying distribution, and an answer to a statistical query is accurate if it is \u201cclose\u201d to the correct expectation over the distribution. This question was recently considered by Dwork et al. [DFH+14], who showed that \u03a9\u0303(n2) queries can be answer efficiently, and also by Hardt and Ullman [HU14], who showed that answering \u00d5(n3) queries is computationally hard. We close the gap between the two bounds by proving a new, nearly-optimal hardness result. Specifically, we show that, under a standard hardness assumption, there is no computationally efficient algorithm that given n samples from an unknown distribution can give valid answers toO(n2) adaptively chosen statistical queries. An implication of our results is that computationally efficient algorithms for answering arbitrary, adaptively chosen statistical queries may as well be differentially private. We obtain our results via an optimal construction of a new combinatorial object that we call an interactive fingerprinting code, which may be of independent interest. \u2217Harvard University School of Engineering and Applied Sciences. Supported by NSF grant CCF-1116616. Email: tsteinke@seas.harvard.edu. \u2020Harvard University Center for Research on Computation and Society and Columbia University. Supported by NSF Grant CNS-1237235 and a Simons Society of Fellows Junior Fellowship. Email: jullman@cs.columbia.edu. ar X iv :1 41 0. 12 28 v1 [ cs .C R ] 5 O ct 2 01 4", "creator": "LaTeX with hyperref package"}}}