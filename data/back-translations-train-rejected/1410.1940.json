{"id": "1410.1940", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Oct-2014", "title": "GLAD: Group Anomaly Detection in Social Media Analysis- Extended Abstract", "abstract": "Traditional anomaly detection on social media mostly focuses on individual point anomalies while anomalous phenomena usually occur in groups. Therefore it is valuable to study the collective behavior of individuals and detect group anomalies. Existing group anomaly detection approaches rely on the assumption that the groups are known, which can hardly be true in real world social media applications. In this paper, we take a generative approach by proposing a hierarchical Bayes model: Group Latent Anomaly Detection (GLAD) model. GLAD takes both pair-wise and point-wise data as input, automatically infers the groups and detects group anomalies simultaneously. To account for the dynamic properties of the social media data, we further generalize GLAD to its dynamic extension d-GLAD. We conduct extensive experiments to evaluate our models on both synthetic and real world datasets. The empirical results demonstrate that our approach is effective and robust in discovering latent groups and detecting group anomalies.", "histories": [["v1", "Tue, 7 Oct 2014 23:11:37 GMT  (1162kb,D)", "http://arxiv.org/abs/1410.1940v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.SI", "authors": ["qi yu", "xinran he", "yan liu"], "accepted": false, "id": "1410.1940"}, "pdf": {"name": "1410.1940.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Xinran He"], "emails": ["qiyu@usc.edu", "xinranhe@usc.edu", "yanliu.cs@usc.edu"], "sections": [{"heading": null, "text": "Keywords: detection of anomalies; social media analysis; hierarchical Bayes modelling"}, {"heading": "1 Introduction", "text": "In fact, most of them will be able to play by the rules they have imposed on themselves."}, {"heading": "2 Related Work", "text": "This year is the highest in the history of the country."}, {"heading": "3 Definition of Group Anomaly", "text": "In fact, most of them are able to move in a direction in which they are able to move, in which they are able to move."}, {"heading": "4.1 Model Specification", "text": "We assume that each activity of the person p is associated with a group identity Gpa and a role identity Rpa. Group identity finds the natural cluster of a person that is influenced by the paired observations. Rolle identifies the cluster of activities within the group, while others suggest that people in the same community should share common activity traits. We circumvent the controversy by recognizing the arguments of both sides. Since we model the activities as a blending model, \"role\" is the blending component that categorizes the characteristics of each activity. From the paired data perspective, we assume that every communication from person p to q has a group membership zp."}, {"heading": "4.2 Model Inference", "text": "We develop an approximate inference technology based on variable Bayesian methods [12] and an EM algorithm = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "5 GLAD", "text": "GLAD models a social network of activities X = {X1, X2,..., XN} and communication Y = {Y1,1, Y1,2,..., YN, N}, where Xp is the aggregation of activities for each person. Xp, RV consists of V entries denoting a characteristic vector of V dimensions. each person p joins a group according to the probability distribution of membership. It is associated with a group identity Gp and a role identity Rp. We incorporate the paired observations of the person p {Yp,:} directly from the group identity Gp as Bernoulli random variables. And we further assume that the activities Xp follow a multinomic distribution with Ap studies. GLAD integrates MSB and LDA in a more compact way. It allows not only the common group membership distribution between the two components, but also the group membership identity to emphasize the interdependencies between points and LDA."}, {"heading": "5.1 Inference and Learning", "text": "The normalizing term of posterior distribution includes the calculation of the marginal probability of the data for which we use variable EM algorithms [12]. Name the set of model parameters as follows: \"# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "6 dynamic GLAD", "text": "We are now generalizing the GLAD model to accommodate the dynamics of social media. We call the dynamic extension of GLAD the d-GLAD model. To match our description of GLAD in Section 5, we start with the model specification and then provide the model inference algorithm that uses both the Bayesian variant method and the Monte Carlo scanning technique."}, {"heading": "6.1 Model Specification", "text": "The generalization of GLAD to d-GLAD stems from the template models [14], which use the model for a particular timestamp as a template, duplicate it over time, and sequentially connect temporal components. Similarly, we can adapt GLAD to the dynamic setting by making a copy of GLAD for each time. To simplify the model, we assume that the latent factors, including the role Rp, the group Gp, and the mixing rate {\u03b81: M} will change over time, but the affiliation distribution {\u03c0p} and model parameters will be fixed. We model the temporal evolution of the role mixing rate for each group with a series of multivariate Gaussian distributions."}, {"heading": "6.2 Inference and Learning", "text": "The variational conclusion of d-GLAD is similar to the GLAD model with the exception of the longitudinal factor \u03b8 (1: T) 1: M. Then we apply the variational Kalman filter technique [3] to derive the sequential latent variables and learn the model parameters from it. The transition for the mixing rate of each group is Gaussian algorithm 4 Generative Process of DGLADfor t = 1 \u2192 T do for m = 1 \u2192 M doDraw steel (t) m Gaussian (t \u2212 1), end for the individual p = 1, end for the individual p = 1 \u2192 N doDraw affiliation distribution \u03c0 (t) p: 1 p Draw G (t) p: 1 p Multinomial (t)."}, {"heading": "7 Experiments", "text": "In order to evaluate the effectiveness of our model, we conduct in-depth experiments with synthetic and real data sets. We investigate the applications of our approach by analyzing scientific publications and Senate election documents."}, {"heading": "7.1 Baselines", "text": "To our knowledge, all existing algorithms are two-stage approaches: (i) Identify groups, (ii) Detect group anomalies. We summarize these algorithms in Table 1. We use the following approaches as basic methods compared to GLAD and d-GLAD: 1. MMSB-LDA: First, use the MMSB model to learn a group membership distribution for each node, and then assign the node to the group with the highest probability. Finally, train an LDA model for each group and derive the role identity.2. MMSB-MGM: Group is learned using the same method as MMSB-LDA. For the role conclusion, train a multimodal MGM instead of LDA.3. Graph-LDA: Run a standard model for group membership to gain group membership, and then train an LDA model for each group membership.Min-Graph-GM: Then train a group MGM for each group member."}, {"heading": "7.2 Synthetic Dataset", "text": "We are experimenting with two types of synthetic datasets. One is a synthetic dataset with injected group anomalies, the other is a benchmark dataset generated by a simulator with individual anomaly labels."}, {"heading": "7.2.1 Synthetic Data with Anomaly Injection", "text": "We generate a network of 500 nodes using GLAD in algorithm 1. To evaluate the abnormal detection performance, we set the mixing rates of abnormal groups as [0.9, 0.1] and normal groups as [0.1, 0.9]. We vary the number of groups from 5 to 50 and inject 20% abnormal groups. The rest 80% of the groups is normal. Knowing the normal and abnormal mixing rates, we calculate the abnormal score of each group by directly calculating the differences between the inferred mixing rate and the normal mixing rate. During the test procedure, we rank the groups in terms of their abnormal score and retrieve top 20% groups. For all methods, we set the number of groups and the number of roles we perceive on the ground. We compare the learned groups of three groups with the basic truth: GLAD, MMSB and Graph, for the case of 5 groups."}, {"heading": "7.2.2 Benchmark Data with Anomaly Labels", "text": "The benchmark dataset is generated by a simulator from a federally funded program and includes email communications records and work activities of 258 employees of the company. Each employee is characterized by 6 types of activity. The marked dataset contains 39 individual anomalies, 5 of which cannot be detected by any existing algorithms. We define the number of groups as the optimal setting achieved by cross-validation, and calculate the anomaly value of each group by MCMC sample. We treat all members in the most anomalous group as individual anomalies and compare them with the anomaly labels. Although the anomaly labels are point anomalies and not group anomalies, the anomaly detection result reflects the potential of our approach to address other types of difficult anomaly detection issues. The precision, recall and F1 score over 20 runs on the benchmark dataset show that the comparative model achieves low precision and precision."}, {"heading": "7.3 Real World Datasets", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.3.1 Scientific Publications", "text": "This year, it will take just one year for them to be able to leave the country."}, {"heading": "7.3.2 US Senate Voting", "text": "The recordings of the 109th Congress contain only 100 votes of Senators, spanning two sessions from January 1, 2005 to December 31, 2006. We divide the 24 months recordings into eight time frames, each time period denoting a 3-month interval. Then, we use the method [13] to construct a network of original yes / no votes. For the nodes, we collect the statistics of the votes in six dimensions, namely the joint resolution of the House of Representatives (hjres), the House of Representatives (hr), the nomination of the President (pn), the simple resolution (s), the current Senate resolution (sjres) and the joint resolution of the Senate (sjres). We rate GLAD on individual aggregated networks and d-GLAD on the 8 time frames that vary in time."}, {"heading": "8 Conclusion", "text": "In this paper, we are conducting a follow-up study of the Group Latent Anomaly Detection (GLAD) model by analyzing an alternative construction of the unified model. We are loosely linking the MMSB model to the LDA model assuming the common group membership distribution both selectively and in pairs. We are also providing the variable Bayesian inference algorithm for model inference. We are conducting a simulation experiment to verify the benefits of the shared model compared to the two-stage approaches."}, {"heading": "9 Acknowledgments", "text": "The research was funded by the Defense Advanced Research Projects Agency (DARPA) under the Anomaly Detection at Multiple Scales (ADAMS) program, contract number W911NF-11-C-0200, and NSF research grant IIS-1134990. The views and conclusions expressed by the authors are those of the authors and should not be interpreted to represent official policy of the funding agency or the US government."}], "references": [{"title": "Mixed membership stochastic blockmodels", "author": ["E.M. Airoldi", "D.M. Blei", "S.E. Fienberg", "E.P. Xing"], "venue": "Journal of Machine Learning Research, 9", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Anomaly detection in large graphs", "author": ["L. Akoglu", "M. McGlohon", "C. Faloutsos"], "venue": "In CMU-CS-09-173 Technical Report. Citeseer", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Dynamic topic models", "author": ["D.M. Blei", "J.D. Lafferty"], "venue": "Proceedings of the 23rd international conference on Machine learning, pages 113\u2013120. ACM", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "the Journal of machine Learning research, 3:993\u20131022", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Network analysis in the social sciences", "author": ["S.P. Borgatti", "A. Mehra", "D.J. Brass", "G. Labianca"], "venue": "science, 323(5916):892\u2013895", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Anomaly detection: A survey", "author": ["V. Chandola", "A. Banerjee", "V. Kumar"], "venue": "ACM Computing Surveys (CSUR), 41(3):15", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic topic models with biased propagation on heterogeneous information networks", "author": ["H. Deng", "J. Han", "B. Zhao", "Y. Yu", "C.X. Lin"], "venue": "Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1271\u20131279. ACM", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "A tutorial on particle filtering and smoothing: Fifteen years later", "author": ["A. Doucet", "A.M. Johansen"], "venue": "Handbook of Nonlinear Filtering", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Community detection in graphs", "author": ["S. Fortunato"], "venue": "Physics Reports 486, 75-174 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Identification of outliers", "author": ["D.M. Hawkins"], "venue": "Chapman and Hall", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1980}, {"title": "Bayesian anomaly detection methods for social networks", "author": ["N.A. Heard", "D.J. Weston", "K. Platanioti", "D.J. Hand"], "venue": "The Annals of Applied Statistics", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "An introduction to variational methods for graphical models", "author": ["M.I. Jordan", "Z. Ghahramani", "T.S. Jaakkola", "L.K. Saul"], "venue": "Machine learning, 37(2):183\u2013233", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1999}, {"title": "et al", "author": ["M. Kolar", "L. Song", "A. Ahmed", "E.P. Xing"], "venue": "Estimating time-varying networks. The Annals of Applied Statistics, 4(1):94\u2013123", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Probabilistic graphical models: principles and techniques", "author": ["D. Koller", "N. Friedman"], "venue": "MIT press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Empirical analysis of an evolving social", "author": ["G. Kossinets"], "venue": "network. Science,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "One-class support measure machines for group anomaly detection", "author": ["K. Muandet", "B. Sch\u00f6lkopf"], "venue": "arXiv preprint arXiv:1303.0309", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic multimedia cross-modal correlation discovery", "author": ["J.-Y. Pan", "H.-J. Yang", "C. Faloutsos", "P. Duygulu"], "venue": "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 653\u2013658. ACM", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "Scan statistics on enron graphs", "author": ["C.E. Priebe", "J.M. Conroy", "D.J. Marchette", "Y. Park"], "venue": "Computational & Mathematical Organization Theory, 11(3):229\u2013247", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Arnetminer: Extraction and mining of academic social networks", "author": ["J. Tang", "J. Zhang", "L. Yao", "J. Li", "L. Zhang", "Z. Su"], "venue": "KDD\u201908, pages 990\u2013998", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Random walk with restart: fast solutions and applications", "author": ["H. Tong", "C. Faloutsos", "J.-Y. Pan"], "venue": "Knowledge and Information Systems, 14(3):327\u2013346", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "A tutorial on spectral clustering", "author": ["U. Von Luxburg"], "venue": "Statistics and computing, 17(4):395\u2013416", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Hierarchical probabilistic models for group anomaly detection", "author": ["L. Xiong", "B. Poczos", "J. Schneider", "A. Connolly", "J. Vanderplas"], "venue": "AI and Statistics, pages 789\u2013797", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Group anomaly detection using flexible genre models", "author": ["L. Xiong", "B. P\u00f3czos", "J.G. Schneider"], "venue": "NIPS, pages 1071\u20131079", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 9, "context": "By definition, anomaly detection aims to find \u201can observation that deviates so much from other observations as to arouse suspicion that it was generated by a different mechanism\u201d [10].", "startOffset": 179, "endOffset": 183}, {"referenceID": 1, "context": "Several algorithms have been developed specifically for social media anomaly detection such as power-law models [2], spectral decomposition [21], scan statistics [18], and random walk [17, 20].", "startOffset": 112, "endOffset": 115}, {"referenceID": 20, "context": "Several algorithms have been developed specifically for social media anomaly detection such as power-law models [2], spectral decomposition [21], scan statistics [18], and random walk [17, 20].", "startOffset": 140, "endOffset": 144}, {"referenceID": 17, "context": "Several algorithms have been developed specifically for social media anomaly detection such as power-law models [2], spectral decomposition [21], scan statistics [18], and random walk [17, 20].", "startOffset": 162, "endOffset": 166}, {"referenceID": 16, "context": "Several algorithms have been developed specifically for social media anomaly detection such as power-law models [2], spectral decomposition [21], scan statistics [18], and random walk [17, 20].", "startOffset": 184, "endOffset": 192}, {"referenceID": 19, "context": "Several algorithms have been developed specifically for social media anomaly detection such as power-law models [2], spectral decomposition [21], scan statistics [18], and random walk [17, 20].", "startOffset": 184, "endOffset": 192}, {"referenceID": 1, "context": "For example, [2] proposes an \u201cOddBall\u201d algorithm to spot anomalous nodes in a graph.", "startOffset": 13, "endOffset": 16}, {"referenceID": 21, "context": "This problem has found its applications in galaxy identification [22], high energy particle physics [16], anomalous image detection and turbulence vorticity modeling [23].", "startOffset": 65, "endOffset": 69}, {"referenceID": 15, "context": "This problem has found its applications in galaxy identification [22], high energy particle physics [16], anomalous image detection and turbulence vorticity modeling [23].", "startOffset": 100, "endOffset": 104}, {"referenceID": 22, "context": "This problem has found its applications in galaxy identification [22], high energy particle physics [16], anomalous image detection and turbulence vorticity modeling [23].", "startOffset": 166, "endOffset": 170}, {"referenceID": 4, "context": "For example, teams with the same composition of member skills can perform very differently depending on the patterns of relationships among the members [5].", "startOffset": 152, "endOffset": 155}, {"referenceID": 5, "context": "At the individual level, the activities might appear to be normal [6].", "startOffset": 66, "endOffset": 69}, {"referenceID": 14, "context": "(iii) Empirical studies in social media analysis suggest the dynamic nature of individual network positions [15].", "startOffset": 108, "endOffset": 112}, {"referenceID": 21, "context": "The Multinomial Genre Model (MGM) proposed in [22] first investigates the problem following the paradigm of Latent Dirichlet Allocation (LDA) [4].", "startOffset": 46, "endOffset": 50}, {"referenceID": 3, "context": "The Multinomial Genre Model (MGM) proposed in [22] first investigates the problem following the paradigm of Latent Dirichlet Allocation (LDA) [4].", "startOffset": 142, "endOffset": 145}, {"referenceID": 22, "context": "[23] further extends MGM to Flexible Genre Model (FGM) with more flexibility in the generation of topics.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] uses the same definition of group anomaly from [22].", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[16] uses the same definition of group anomaly from [22].", "startOffset": 52, "endOffset": 56}, {"referenceID": 21, "context": "For example, in [22], the Sloan Digital Sky Survey (SDSS) dataset needs to be preprocessed before feeding into MGM.", "startOffset": 16, "endOffset": 20}, {"referenceID": 22, "context": "For the application on turbulence data, the FGM model [23] considers the vertices in a local cubic region as a group.", "startOffset": 54, "endOffset": 58}, {"referenceID": 15, "context": "In SMM [16], the authors treat the high energy particles generated from the same collision event as a group.", "startOffset": 7, "endOffset": 11}, {"referenceID": 8, "context": "In community detection literature [9], some argue that a community is the one that has dense communications within clusters while others suggest that people in", "startOffset": 34, "endOffset": 37}, {"referenceID": 0, "context": "Our model unifies the ideas from both the Mixture Membership Stochastic Block (MMSB) model [1] and the Latent Dirichlet Allocation (LDA) model [4].", "startOffset": 91, "endOffset": 94}, {"referenceID": 3, "context": "Our model unifies the ideas from both the Mixture Membership Stochastic Block (MMSB) model [1] and the Latent Dirichlet Allocation (LDA) model [4].", "startOffset": 143, "endOffset": 146}, {"referenceID": 11, "context": "2 Model Inference We develop an approximate inference technique based on variational Bayesian methods [12] and an EM algorithm for model inference.", "startOffset": 102, "endOffset": 106}, {"referenceID": 0, "context": "The marginal likelihood of the data p(v|\u0398) = \u222b h p(v, h|\u0398)dh requires to integrate over all the latent variables in the equation above, which is intractable [1].", "startOffset": 157, "endOffset": 160}, {"referenceID": 11, "context": "The normalizing term of the posterior distribution involves the calculation of the marginal likelihood of the data for which we resort to variational EM algorithms [12].", "startOffset": 164, "endOffset": 168}, {"referenceID": 0, "context": "Computing the maximizer for the marginal likelihood of the data p(v|\u0398) = \u222b h p(v, h|\u0398)dh requires the integration over all the latent variables in the equation above, which is intractable [1].", "startOffset": 188, "endOffset": 191}, {"referenceID": 11, "context": "Therefore, we apply the variational Bayesian approach [12] to perform the inference approximately.", "startOffset": 54, "endOffset": 58}, {"referenceID": 0, "context": "The resulting parameter updating functions for \u03b1 and B are the same as those of MMSB [1] and the parameters \u03b2 and \u03b8 can be estimated as follows:", "startOffset": 85, "endOffset": 88}, {"referenceID": 13, "context": "1 Model Specification Generalization of GLAD to d-GLAD stems from the template models [14], which use the model for a particular time stamp as a template, duplicate it over time and connect temporal components sequentially.", "startOffset": 86, "endOffset": 90}, {"referenceID": 2, "context": "Similar idea can be seen from the generalization of LDA to the dynamic topic model [3].", "startOffset": 83, "endOffset": 86}, {"referenceID": 2, "context": "Then we apply the variational Kalman Filter technique [3] to infer the sequential latent variables and learn the model parameters.", "startOffset": 54, "endOffset": 57}, {"referenceID": 7, "context": "The inference of the transitional part {\u03b8 } is based on the Particle Filtering method [8].", "startOffset": 86, "endOffset": 89}, {"referenceID": 10, "context": "Table 1: Two stage models in existing work Algorithm Stage-1 Stage-2 Heard 2010 [11] spectrum Poisson process Xiong 2011-a [22] clustering Mixture Genre Model Xiong 2011-b [23] clustering Flexible Genre Model Muandet 2013 [16] simulator One class SMM", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "Table 1: Two stage models in existing work Algorithm Stage-1 Stage-2 Heard 2010 [11] spectrum Poisson process Xiong 2011-a [22] clustering Mixture Genre Model Xiong 2011-b [23] clustering Flexible Genre Model Muandet 2013 [16] simulator One class SMM", "startOffset": 123, "endOffset": 127}, {"referenceID": 22, "context": "Table 1: Two stage models in existing work Algorithm Stage-1 Stage-2 Heard 2010 [11] spectrum Poisson process Xiong 2011-a [22] clustering Mixture Genre Model Xiong 2011-b [23] clustering Flexible Genre Model Muandet 2013 [16] simulator One class SMM", "startOffset": 172, "endOffset": 176}, {"referenceID": 15, "context": "Table 1: Two stage models in existing work Algorithm Stage-1 Stage-2 Heard 2010 [11] spectrum Poisson process Xiong 2011-a [22] clustering Mixture Genre Model Xiong 2011-b [23] clustering Flexible Genre Model Muandet 2013 [16] simulator One class SMM", "startOffset": 222, "endOffset": 226}, {"referenceID": 6, "context": "We create a dataset from a pre-processed Digital Bibliography and Library Project (DBLP) dataset from [7].", "startOffset": 102, "endOffset": 105}, {"referenceID": 6, "context": "In Table 4, we show the top ten most representative words for the four topics, which well reproduce the topic results reported in [7].", "startOffset": 130, "endOffset": 133}, {"referenceID": 18, "context": "GLAD model, we process another ACM dataset downloaded from ArnetMiner [19].", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "Then we apply the method of [13] to construct a network from original yay/nay votes.", "startOffset": 28, "endOffset": 32}], "year": 2014, "abstractText": "Traditional anomaly detection on social media mostly focuses on individual point anomalies while anomalous phenomena usually occur in groups. Therefore it is valuable to study the collective behavior of individuals and detect group anomalies. Existing group anomaly detection approaches rely on the assumption that the groups are known, which can hardly be true in real world social media applications. In this paper, we take a generative approach by proposing a hierarchical Bayes model: Group Latent Anomaly Detection (GLAD) model. GLAD takes both pair-wise and point-wise data as input, automatically infers the groups and detects group anomalies simultaneously. To account for the dynamic properties of the social media data, we further generalize GLAD to its dynamic extension d-GLAD. We conduct extensive experiments to evaluate our models on both synthetic and real world datasets. The empirical results demonstrate that our approach is effective and robust in discovering latent groups and detecting group anomalies.", "creator": "LaTeX with hyperref package"}}}