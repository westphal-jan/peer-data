{"id": "1410.3463", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Oct-2014", "title": "Mining Block I/O Traces for Cache Preloading with Sparse Temporal Non-parametric Mixture of Multivariate Poisson", "abstract": "Existing caching strategies, in the storage domain, though well suited to exploit short range spatio-temporal patterns, are unable to leverage long-range motifs for improving hitrates. Motivated by this, we investigate novel Bayesian non-parametric modeling(BNP) techniques for count vectors, to capture long range correlations for cache preloading, by mining Block I/O traces. Such traces comprise of a sequence of memory accesses that can be aggregated into high-dimensional sparse correlated count vector sequences.", "histories": [["v1", "Mon, 13 Oct 2014 14:26:28 GMT  (109kb)", "http://arxiv.org/abs/1410.3463v1", null]], "reviews": [], "SUBJECTS": "cs.OS cs.LG cs.SY", "authors": ["lavanya sita tekumalla", "chiranjib bhattacharyya"], "accepted": false, "id": "1410.3463"}, "pdf": {"name": "1410.3463.pdf", "metadata": {"source": "CRF", "title": "Mining Block I/O Traces for Cache Preloading with Sparse Temporal Non-parametric Mixture of Multivariate Poisson", "authors": ["Lavanya Sita Tekumalla", "Chiranjib Bhattacharyya"], "emails": [], "sections": [{"heading": null, "text": "In fact, most people are able to recognize themselves and understand how they have behaved. (...) In fact, it is not that they are able to identify themselves. (...) It is not that they are able to put themselves in the center. (...) It is not that they are able to put themselves in the center. (...) It is not that they are able to put themselves in the center. (...) It is not that they are able to put themselves in the center. (...) It is not that they are able to take responsibility for themselves. \"(...)"}, {"heading": "3 A framework for Cache Preloading based on mining Block I/O traces", "text": "In this section, we briefly describe the caching problem and describe our framework for cache preloading.s The cachehits # cachehits # cachehits # cachehits # cachehits # cachehits # cachemis.2 The cache preading strategy: Our strategy involves observing part of the time and deriving a model of the time in which we cachehits # cachehits # cachehits # cachehits # cachemisst.2 The cache preading strategy: Our strategy involves observing part of the time in which we cachehits # cachehits # cachemisst.2 The cache preading strategy: Our strategy involves observing part of the time and deriving part of the time."}, {"heading": "3.4 The Operating Phase (Prediction for", "text": "Preloading): After observing {X1,. XTlr} aggregated by Dlr, the learning phase learns a latent variable model. In the operating phase, while we observe Dop, the data after the time interval t \"+ 1 gradually becomes a sequence {X\" 1,.. X \"t.\" At this point, we want the model to predict the best possible selection of blocks to load into the cache for interval t \"+ 1 with knowledge of aggregated data. This prediction occurs in two steps. In the first step, our HMM-based model Sparse-HMM-DPMMVP infers hidden state Z\" t \"+ 1 from observations {X\" 1,.., X \"t\"}, using an alternative algorithm in Viterbi style as follows. (3,1) (X \"t\" r \"), a hidden state Z.\""}, {"heading": "4 Mixture Models with Multivariate Poisson for correlated count vector sequences", "text": "We will now describe non-parametric temporal models for correlated counter vectors based on the MVP [9] mixtures. MVP [9] distributions are natural models for understanding multidimensional counter data. So far, there has been no work on exploring DP-based mixing models for counter data or modelling their temporal dependencies. Therefore, we will first parallel the development of non-parametric MVP mixtures modelled on DP-based multinomic mixtures [16]. To this end, we propose DP-MVP, a DP-based MVP mixture, and propose a time extension of HMM-DP-MMVP modelled on HDP-HMM [16] for multinomic mixtures. However, a more interesting challenge lies in the development of algorithms of scalable complexity for high-dimensional correlated counter vectors. We will address this problem in our next section (5) by implementing the sparse data that utilizes the MVP [1]."}, {"heading": "Gj \u223c DP (\u03b1,G0), j = 1 . . . J where G0 \u223c DP (\u03b1,H)", "text": "HMMs are popular models of temporal data. However, for most applications there are no clear guidelines for determining the number of HMM states. A DP-based HMM model, HDP-HMM, [16] alleviates this need. Note X1,.., XT for data examples. Furthermore, we introduce the notation [L] = {1,.., L} for all L-Z. HDP-HMM is defined as following. \u03b2-GEM (.), \u03b1k-DP (\u03b1k, \u03b2), and \u03b8k | H-H \u0445 H, k = 1, 2,.. Zt | Zt \u2212 1, and Xt | Zt-fZt-IP (\u0445k), t-Y [T] Basic distributions commonly used for H are multivariate Gaussian and multinomial distributions."}, {"heading": "4.2 DP Mixture of Multivariate Poisson", "text": "(DP-MMVP): In this section we define DP-MMVP, a DP-based non-parametric mixing model for capturing correlated number vectors. We propose to use a DP-based earlier, G-DP (\u03b1, H), where H is an appropriately selected gamma conjugate before the parameters of MVP. We define DP-MMMVP as following. (T) Gamma (a) Gamma (a), b), \u0445j \u2264 l [M], k = 1,... \u03b2 (T) GEM (\u03b1) and G = temporary k = 1\u03b2kKKKD (\u03b2).kjl (T) Xt | Zt (MDP P), MV (ZT),. (T)."}, {"heading": "5 Modeling with Sparse Multivariate Poisson:", "text": "Complete covariance MVP, defined with (M 2) latent variables (in Y), is mathematically expensive to infer for higher dimensions. However, trace-based vectors Xt are often very sparse, with only a few significant components and most components close to 0. Whereas sparse multinomial [19] and sparse Gaussian [7] mixtures have been worked on, there has been no work on sparse MVP mixtures. We propose SMVP by extending the MVP to modelling sparse counter vectors. We then extend it to Sparse-DP-MVP for a non-parametric mixing setting and finally propose the time extension Sparse-HMM-DP-MVP."}, {"heading": "5.1 Sparse Multivariate Poisson distribution", "text": "(SMVP): We present SMVP as follows: We look at an indicator b = 0, 1) M, which means that the MVP (VP) -1, 2 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1 (VP) -1)."}, {"heading": "Appendix B: Inference Elaborated", "text": "In this section of the supplement, we will differentiate the consequences for the DP-MMVP definition in the MVP definition. (...) We will describe the consequences for the DP-MMVP definition in Section 10.2. (...) Then, in Section 10.3, we will describe the consequences for the Sparse HMVP definition in Section 10.1, followed by the HMM-MMVP definition. (...) The existence of Yt, j, l latent variables in the definition of the MVP definition. (...) We will differentiate the consequences for the MVP definition of the MVP definition in relation to the MVP definition. (...) The large number of Yt, j, l variables also leads to a higher definition of the MVP definition. (...)"}, {"heading": "10.3 Inference : Sparse-HMM-DP-MMVP:", "text": "(K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K): (K (K): (K): (K): (K (K): (K): (K): (K): (K): (K): (K): (K (K): (K): (K (K): (K): (K): (K): (K): (K): (K): (K"}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "Existing caching strategies, in the storage do-<lb>main, though well suited to exploit short range spatio-<lb>temporal patterns, are unable to leverage long-range<lb>motifs for improving hitrates. Motivated by this,<lb>we investigate novel Bayesian non-parametric model-<lb>ing(BNP) techniques for count vectors, to capture long<lb>range correlations for cache preloading, by mining Block<lb>I/O traces. Such traces comprise of a sequence of<lb>memory accesses that can be aggregated into high-<lb>dimensional sparse correlated count vector sequences.<lb>While there are several state of the art BNP algo-<lb>rithms for clustering and their temporal extensions for<lb>prediction, there has been no work on exploring these<lb>for correlated count vectors. Our first contribution ad-<lb>dresses this gap by proposing a DP based mixture model<lb>of Multivariate Poisson (DP-MMVP) and its temporal<lb>extension(HMM-DP-MMVP) that captures the full co-<lb>variance structure of multivariate count data. However,<lb>modeling full covariance structure for count vectors is<lb>computationally expensive, particularly for high dimen-<lb>sional data. Hence, we exploit sparsity in our count<lb>vectors, and as our main contribution, introduce the<lb>Sparse DP mixture of multivariate Poisson(Sparse-DP-<lb>MMVP), generalizing our DP-MMVP mixture model,<lb>also leading to more efficient inference. We then discuss<lb>a temporal extension to our model for cache preloading.<lb>We take the first step towards mining historical<lb>data, to capture long range patterns in storage traces for<lb>cache preloading. Experimentally, we show a dramatic<lb>improvement in hitrates on benchmark traces and lay<lb>the groundwork for further research in storage domain<lb>to reduce latencies using data mining techniques to<lb>capture long range motifs.", "creator": "LaTeX with hyperref package"}}}