{"id": "1410.3726", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Oct-2014", "title": "Scene Image is Non-Mutually Exclusive - A Fuzzy Qualitative Scene Understanding", "abstract": "Ambiguity or uncertainty is a pervasive element of many real world decision making processes. Variation in decisions is a norm in this situation when the same problem is posed to different subjects. Psychological and metaphysical research had proven that decision making by human is subjective. It is influenced by many factors such as experience, age, background, etc. Scene understanding is one of the computer vision problems that fall into this category. Conventional methods relax this problem by assuming scene images are mutually exclusive; and therefore, focus on developing different approaches to perform the binary classification tasks. In this paper, we show that scene images are non-mutually exclusive, and propose the Fuzzy Qualitative Rank Classifier (FQRC) to tackle the aforementioned problems. The proposed FQRC provides a ranking interpretation instead of binary decision. Evaluations in term of qualitative and quantitative using large numbers and challenging public scene datasets have shown the effectiveness of our proposed method in modeling the non-mutually exclusive scene images.", "histories": [["v1", "Tue, 14 Oct 2014 15:19:43 GMT  (2896kb,D)", "http://arxiv.org/abs/1410.3726v1", "Accepted in IEEE Transactions on Fuzzy Systems"]], "COMMENTS": "Accepted in IEEE Transactions on Fuzzy Systems", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.IR", "authors": ["chern hong lim", "anhar risnumawan", "chee seng chan"], "accepted": false, "id": "1410.3726"}, "pdf": {"name": "1410.3726.pdf", "metadata": {"source": "CRF", "title": "Scene Image is Non-Mutually Exclusive - A Fuzzy Qualitative Scene Understanding", "authors": ["Chern Hong Lim", "Anhar Risnumawan", "Chee Seng Chan"], "emails": ["(cs.chan@um.edu.my)."], "sections": [{"heading": null, "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "II. RELATED WORK", "text": "This year, the time has come for an agreement to be reached, and it will only take a few days."}, {"heading": "III. FUZZY QUALITATIVE RANK CLASSIFIER", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Basic Notation", "text": "The general framework of the proposed FQRC consists of four levels: 1) Pre-Processing; 2) Learning Model; 3) Inference and 4) Ranking Interpretation, as in Fig. 2. Let I = {I1, I2,.., IN} designates the images of the N Scene. During the pre-processing phase, any existing feature representation such as texture component, color spectrum and point of interest can be used as input for our learning model. In this essay, we have used the attributes [16] as image attributes. Let T denotes a feature extraction function, T: I \u2192 xk, where xk is a set of feature values belonging to the k-th class, k: 1, 2,.., K}, of the input space X, K is the number of class labels. Input data, xk: X, is defined as xk = {x1, x2,., xJ} k, where a feature value is Z, Sample: J, Sample: J and Sample: J."}, {"heading": "B. Motivation", "text": "The task of a classifier (we call it a function f) is to find a way based on the observations to match a sample to a specified class term, using the data generated by the input-output pairs according to an unknown distribution P (x, y), so that f can classify invisible samples (x, y), (x1, y1),., (xN, yN), which can be obtained with the input-output pairs according to an unknown distribution P (x, y), so that f can classify invisible samples (x, y), (x1, y1),., (xN), yN), (X, yN), which can be obtained, is the one that minimizes the margin of error represented by a risk function (2). However, it is important to note that we cannot calculate the risk R (f) directly, since the probability of P (x, y) nown.r is insignificant."}, {"heading": "C. Learning the FQRC", "text": "In our learning model, we learn the non-mutually exclusive scene data with parametric approximation of the membership function, in which the membership distribution of a normal convex number is approximated by the 4-tuple. This blurred representation of qualitative values is more general than ordinary (crisp) interval representations, since it can represent not only the problem indicated by a well-defined real interval, but also the knowledge embedded in the soft boundaries of the interval. [19] Thus, the blurred representation is largely removed (if not completely resolved), the boundary interpretation problem that is achieved by describing a gradual rather than an abrupt change in the degree of membership. It is therefore closer to the healthy perception of the non-mutually exclusive problem. According to [19] - [25], such a representation of the 4-tuple fuzzy number is a better qualitative representation than the high-resolution representation."}, {"heading": "IV. FUZZY MEMBERSHIP FUNCTION AND STABILITY ANALYSIS", "text": "Before we move on to the final phase of the FQRC, we provide the intuition to use the quadruple membership of our proposed framework to solve the non-mutually exclusive problem. Furthermore, the stability analysis of our general framework is discussed."}, {"heading": "A. Fuzzy membership function", "text": "In this section we will discuss the intuitive idea of using quadruple blurred membership functions in our framework. Let's define our loss function as \"(fi (x), y) = 0, if y = maxk (1),..., K) r i (x) 1, otherwise (13), where ri (x) = {ri1,., riK | rik [0, 1]} is the output of the key length of function i, the scalar output rik is defined in (12) and \u2211 K = 1 r i = 1. Supply we have endless g functions, then our goal is to find a function f (x) that minimizes the loss function, f (x) = arg min y (1), K) g min y i = 1\" (fi (14), y), y) To get the interpretation of (14), we will use the concept of maximum entropy."}, {"heading": "B. Stability Analysis", "text": "In this section, we discuss the robustness of the proposed framework with regard to stability analysis. In particular, the concept of stability is applied by Bousquet and Elisseeff (30), as it guarantees a \"good\" learning machine by deriving generalization error limits. In fact, the error limits are derived from stability (1). Specifically, stability measures how much the performance will change for small changes in training data. It was said that an algorithm is stable, whose performance does not depend on a single sample, tends to have a generalization error close to the empirical error limited by a constant. We define stability as follows: Definition 4.1 (Stability): Leave (yi) = zi (Z) a sample from a series of samples Z and (Z)."}, {"heading": "V. RANKING INTERPRETATION", "text": "Ranking system is a very common but important information technology in many applications, and recently it has received more attention to the application as a result of the output of the computer vision algorithm [16], [32]. By the general definition, a ranking is a relationship between a number of elements, so that the first either \"ranks higher than,\" ranks lower than, \"or\" ranks equal \"the second. In the previous section, we received the normalized product, rk, as our final output. However, these values do not provide us with meaningful information to understand the scene images. To interpret the results in a useful way, we introduce a ranking framework that acts in Table I to decode our results into a ranking order."}, {"heading": "VI. EXPERIMENTS", "text": "We tested our approach with two public image sets - the Outdoor Scene Recognition (OSR) dataset [1] and the Multi-Label Scene (MLS) dataset [9], [10]. The OSR dataset contains 2688 color scene images, 256x256 pixels from a total of 8 outdoor scene classes (\"Tallbuilding, T,\" Insidecity, I, \"\" S, \"\" Highway, H, \"\" Coast, C, \"\" Mountain, M \"and\" Forest, F. \""}, {"heading": "A. Scene Images are non-Mutually Exclusive", "text": "Psychological and metaphysical [12] evidence that there is an influence of human factors (background, experience, age, etc.) in decision-making. In this experiment, we would like to show that scene understanding research falls into this category and that scenery is in fact not mutually exclusive. To this end, an online survey was created with an appropriate number of scenery images randomly selected from the OSR dataset. The online survey was conducted for one month and conducted by a group of people aged 12 to 60 from different backgrounds and countries, whose task is to select a class that best reflects the given scene, without prior knowledge of what the ground truth is. We show some examples of the results of the online survey in Fig. 6. For a complete result, interested readers are encouraged to look at this website2. From here, we can clearly state that there is a variation of an answer (scene class) for each scenery picture."}, {"heading": "B. Effectiveness of FQRC", "text": "The results are compared in the following respects: 2http: / / web.fsktm.um.edu. Here we can clearly see that the results of both solutions are almost similar in terms of ranking and electoral distributions, for example in Fig 7 (d), majority voting \"Tallbuilding\" (84.2%) and the consequences of \"Insidecity\" (15.4%), which is almost close to reading FQRC, where \"Tallbuilding\" is 76% and \"Insidecity\" 22.7%."}, {"heading": "C. Feasibility of FQRC", "text": "In this case, it is a way in which people are able to determine for themselves how they want to behave."}, {"heading": "D. Comparison to state-of-the-art binary classifiers in single label classification task", "text": "One of the strengths of FQRC is that it provides the ability to perform a unilateral classification like other binary classifications and rankings as shown in the above areas. In order to verify this, we must verify the FQRCs in individual areas of the FQRCs, such as in the USA, in the USA, in the USA, in Europe, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA and in the USA, in the USA, in the USA, in the USA and in the USA, in the USA, in the USA, in the USA, in the USA, in the USA and in the USA and in the USA, in the USA and in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA and in the USA, in the USA, in the USA, in the USA and in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA and in the USA, in the USA and in the USA, in the USA, in the USA and in the USA and in the USA, in the USA and in the USA, in the USA, in the USA and in the USA, in the USA and in the USA, in the USA and in the USA, in the USA and in the USA, in the USA and in the USA, in the USA and in the USA, in the USA and in the USA and in the USA"}, {"heading": "E. Comparison to state-of-the-art multi-label scene classification approaches", "text": "In order to demonstrate the effectiveness and efficiency of our proposed method, in this experiment we compare the FQRC with the most advanced multi-label scene classification approaches [9], [10]. This comparison is made with the MLS dataset. However, the comparison is made under two aspects: the computational complexity and accuracy of the results 1) Computational Complexity: First, we show the complexity of our method compared to both approaches with the results presented in Table IX. In this context, N denotes the number of classes, M is the number of characteristics, and T is the number of data. The training complexity of [10] consists of three parts; previously, conditional probability and the main function of the training, while [9] requires a classification for each base class, which increases the computational costs compared to the FQRC. To verify the complexity of these methods, the computational time comparison with the results in Table X."}, {"heading": "VII. CONCLUSION", "text": "Unfortunately, almost all existing work focused on understanding scene images assumed that images were mutually exclusive, and related work that did not, as in [9], [10] employed human experts to manually re-label the image in order to obtain multi-level training data for further processing, which is impractical and distorted. Our goal is to raise community awareness of this very important but largely neglected issue. To achieve this, we conducted an online survey of people from different backgrounds and successively proposed the ranking classifier (FQRC), which uses a blurred qualitative principle as resolution, and the results of extensive experiments have shown the effectiveness, feasibility and efficiency of our proposed approach compared to the other state-of-the-art approaches. Our future work will focus on expanding work using a blurred loss function [35] and the normalized sum of memberships, as well as investigating the effects of the different learning model as membership."}], "references": [{"title": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "author": ["A. Oliva", "A. Torralba"], "venue": "Int. J. of Comput. Vis., vol. 42, no. 3, pp. 145\u2013175, 2001.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2001}, {"title": "A bayesian hierarchical model for learning natural scene categories", "author": ["L. Fei-Fei", "P. Perona"], "venue": "IEEE Int. Conf. Comput. Vis. Pattern Recognit.,, vol. 2, no. 15, pp. 524\u2013531, 2005.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Scene classification via plsa", "author": ["A. Bosch", "A. Zisserman", "X. Munoz"], "venue": "Eur. Conf. Comput. Vis., pp. 517\u2013530, 2006.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Semantic modeling of natural scenes for content-based image retrieval", "author": ["J. Vogel", "B. Schiele"], "venue": "Int. J. of Comput. Vis., vol. 72, no. 2, pp. 133\u2013157, 2007.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Fuzzy sets", "author": ["L. Zadeh"], "venue": "Information and Control, vol. 8, no. 3, pp. 338 \u2013 353, 1965.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1965}, {"title": "Theory of extended fuzzy discreteevent systems for handling ranges of knowledge uncertainties and subjectivity", "author": ["X. Du", "H. Ying", "F. Lin"], "venue": "IEEE Trans. Fuzzy Syst., vol. 17, no. 2, pp. 316\u2013328, 2009.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Fuzzy discrete-event systems under fuzzy observability and a test algorithm", "author": ["D. Qiu", "F. Liu"], "venue": "IEEE Trans. Fuzzy Syst., vol. 17, no. 3, pp. 578\u2013589, 2009.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "A fuzzy qualitative approach for scene classification", "author": ["C.H. Lim", "C.S. Chan"], "venue": "IEEE Int. Conf. Fuzzy Syst., 2012, pp. 1\u20138.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning multi-label scene classification", "author": ["M. Boutell", "J. Luo", "X. Shen", "C. Brown"], "venue": "Pattern Recognit., vol. 37, no. 9, pp. 1757\u20131771, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Ml-knn: A lazy learning approach to multi-label learning", "author": ["M.-L. Zhang", "Z.-H. Zhou"], "venue": "Pattern Recognit., vol. 40, no. 7, pp. 2038 \u2013 2048, 2007.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Multi-label classification: An overview", "author": ["G. Tsoumakas", "I. Katakis"], "venue": "Int. J. of Data Warehousing and Mining, vol. 3, no. 3, pp. 1\u201313, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "The ontogeny of common sense", "author": ["L. Forguson", "A. Gopnik"], "venue": "Developing Theories of Mind, pp. 226\u2013243, 1998.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1998}, {"title": "Modeling scenes with local descriptors and latent aspects", "author": ["P. Quelhas", "F. Monay", "J.-M. Odobez", "D. Gatica-Perez", "T. Tuytelaars", "L. Van Gool"], "venue": "Int. Conf. Comput. Vis., 2005, pp. 883\u2013890.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "Mining multi-label data", "author": ["G. Tsoumakas", "I. Katakis", "I. Vlahavas"], "venue": "Data mining and knowledge discovery handbook. Springer, 2010, pp. 667\u2013685.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Scene analysis system using a combined fuzzy logic-based technique", "author": ["J.-Y. Chang", "C.-W. Cho"], "venue": "Journal of the Chinese Institute of Engineers, vol. 25, no. 3, pp. 297\u2013307, 2002.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Relative attributes", "author": ["D. Parikh", "K. Grauman"], "venue": "Int. Conf. Comput. Vis., 2011, pp. 503\u2013510.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations", "author": ["H. Chernoff"], "venue": "The Annals of Mathematical Statistics, vol. 23, no. 4, pp. 493\u2013507, 1952.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1952}, {"title": "Statistical learning theory: models, concepts, and results", "author": ["U. von Luxburg", "B. Sch\u00f6lkopf"], "venue": "arXiv preprint arXiv:0810.4752, 2008.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy qualitative trigonometry", "author": ["H. Liu", "G.M. Coghill", "D.P. Barnes"], "venue": "Int. J. of Approximate Reasoning, vol. 51, no. 1, pp. 71\u201388, 2009.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Fuzzy qualitative simulation", "author": ["Q. Shen", "R. Leitch"], "venue": "IEEE Transactions on Systems, Man And Cybernetics, vol. 23, no. 4, pp. 1038\u20131061, 1993.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1993}, {"title": "Fuzzy qualitative robot kinematics", "author": ["H. Liu", "D.J. Brown", "G.M. Coghill"], "venue": "IEEE Trans. Fuzzy Syst., vol. 16, no. 3, pp. 808\u2013822, 2008.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "A fuzzy qualitative framework for connecting robot qualitative and quantitative representations", "author": ["H. Liu"], "venue": "IEEE Trans. Fuzzy Syst., vol. 16, no. 6, pp. 1522\u20131530, 2008.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy qualitative human motion analysis", "author": ["C.S. Chan", "H. Liu"], "venue": "IEEE Trans. Fuzzy Syst., vol. 17, no. 4, pp. 851\u2013862, 2009.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Recognition of human motion from qualitative normalised templates", "author": ["C.S. Chan", "H. Liu", "D.J. Brown"], "venue": "Journal of Intelligent and Robotic Systems, vol. 48, no. 1, pp. 79\u201395, 2007.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "A fuzzy qualitative approach to human motion recognition", "author": ["C.S. Chan", "H. Liu", "D.J. Brown", "N. Kubota"], "venue": "IEEE Int. Conf. Fuzzy Syst., 2008, pp. 1242\u20131249.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Data-based choice of histogram bin width", "author": ["M. Wand"], "venue": "The American Statistician, vol. 51, no. 1, pp. 59\u201364, 1997.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1997}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "IEEE Int. Conf. Comput. Vis. Pattern Recognit.,, vol. 1. IEEE, 2005, pp. 886\u2013893.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}, {"title": "A method for selecting the bin size of a time histogram", "author": ["H. Shimazaki", "S. Shinomoto"], "venue": "Neural Computation, vol. 19, no. 6, pp. 1503\u20131527, 2007.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2007}, {"title": "Fuzzy clustering by quadratic regularization", "author": ["S. Miyamoto", "K. Umayahara"], "venue": "IEEE Int. Conf. Fuzzy Syst., vol. 2. IEEE, 1998, pp. 1394\u20131399.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1998}, {"title": "Stability and generalization", "author": ["O. Bousquet", "A. Elisseeff"], "venue": "The Journal of Machine Learning Research, vol. 2, pp. 499\u2013526, 2002.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2002}, {"title": "Everything old is new again: a fresh look at historical approaches in machine learning", "author": ["R.M. Rifkin"], "venue": "Ph.D. dissertation, Massachusetts Institute of Technology, 2002.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2002}, {"title": "Whittlesearch : Image search with relative attribute feedback", "author": ["A. Kovashka", "D. Parikh", "K. Grauman"], "venue": "IEEE Int. Conf. Comput. Vis. Pattern Recognit.,, 2012.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Large margin dags for multiclass classification", "author": ["J. Platt", "N. Cristianini", "J. Shawe-Taylor"], "venue": "Advances in neural information processing syst., vol. 12, no. 3, pp. 547\u2013553, 2000.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2000}, {"title": "Fuzzy least squares support vector machines for multiclass problems", "author": ["D. Tsujinishi", "S. Abe"], "venue": "Neural Networks, vol. 16, no. 56, pp. 785 \u2013 792, 2003.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2003}, {"title": "Interval type-2 fuzzy sets constructed from several membership functions: Application to the fuzzy thresholding algorithm", "author": ["M. Pagola", "C. Lopez-Molina", "J. Fernandez", "E. Barrenechea", "H. Bustince"], "venue": "IEEE Trans. Fuzzy Syst., vol. 21, no. 2, pp. 230\u2013244, 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Intentionally, most state-of-the-art approaches in scene understanding domain [1]\u2013[4] are exemplar-based and assume that scene images are mutually exclusive, P (A \u2229 B) = 0.", "startOffset": 78, "endOffset": 81}, {"referenceID": 3, "context": "Intentionally, most state-of-the-art approaches in scene understanding domain [1]\u2013[4] are exemplar-based and assume that scene images are mutually exclusive, P (A \u2229 B) = 0.", "startOffset": 82, "endOffset": 85}, {"referenceID": 4, "context": "Inspired by the fuzzy set theory proposed by Lotfi Zadeh [5], we argue that scene images are non-mutually exclusive where different people are likely to respond inconsistently.", "startOffset": 57, "endOffset": 60}, {"referenceID": 5, "context": "This notion became popular among researchers and technologists due to wide spectrum of applications [6], [7].", "startOffset": 100, "endOffset": 103}, {"referenceID": 6, "context": "This notion became popular among researchers and technologists due to wide spectrum of applications [6], [7].", "startOffset": 105, "endOffset": 108}, {"referenceID": 7, "context": "The notable ones are [8]\u2013[10], where a multilabel scene classification framework is proposed.", "startOffset": 21, "endOffset": 24}, {"referenceID": 9, "context": "The notable ones are [8]\u2013[10], where a multilabel scene classification framework is proposed.", "startOffset": 25, "endOffset": 29}, {"referenceID": 10, "context": "This is a tedious job that leads to a large number of classes with the sparse number of sample [11].", "startOffset": 95, "endOffset": 99}, {"referenceID": 11, "context": "Secondly, the annotated image\u2019s classes are potentially bias as different people tend to respond inconsistently [12] and finally, it does not able to handle multi-dimension data.", "startOffset": 112, "endOffset": 116}, {"referenceID": 0, "context": "from different ethnics and age using the OSR dataset [1].", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "In advance, FQRC provides a resolution toward conventional solutions which either perform binary classification [1]\u2013[4] or require human intervention [9], [10].", "startOffset": 112, "endOffset": 115}, {"referenceID": 3, "context": "In advance, FQRC provides a resolution toward conventional solutions which either perform binary classification [1]\u2013[4] or require human intervention [9], [10].", "startOffset": 116, "endOffset": 119}, {"referenceID": 8, "context": "In advance, FQRC provides a resolution toward conventional solutions which either perform binary classification [1]\u2013[4] or require human intervention [9], [10].", "startOffset": 150, "endOffset": 153}, {"referenceID": 9, "context": "In advance, FQRC provides a resolution toward conventional solutions which either perform binary classification [1]\u2013[4] or require human intervention [9], [10].", "startOffset": 155, "endOffset": 159}, {"referenceID": 12, "context": "It differs from the conventional object detection or classification tasks, to the extent that a scene is composed of several entities that are often organized in an unpredictable layout [13].", "startOffset": 186, "endOffset": 190}, {"referenceID": 0, "context": "Oliva and Torralba [1] proposed a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represents the dominant spatial structure of a scene - the spatial envelope as scene representation.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "Fei-Fei and Perona [2] proposed the Bayesian hierarchical model extended from latent dirichlet allocation (LDA) to learn natural scene categories.", "startOffset": 19, "endOffset": 22}, {"referenceID": 2, "context": "[3] inspired from the previous work and proposed probabilistic latent semantic analysis (pLSA) incorporate with KNN for scene classification.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Vogel and Schiele [4] used the occurring frequency of different concepts (water, rock, etc.", "startOffset": 18, "endOffset": 21}, {"referenceID": 10, "context": "To the best of our knowledge, there are numerous multi-label classification research [11], [14]; however, only a few were focused in the domain of scene understanding.", "startOffset": 85, "endOffset": 89}, {"referenceID": 13, "context": "To the best of our knowledge, there are numerous multi-label classification research [11], [14]; however, only a few were focused in the domain of scene understanding.", "startOffset": 91, "endOffset": 95}, {"referenceID": 8, "context": "[9] proposed an approach using SVM with cross-training to build the classifier for every base class.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Inspired by [9], Zhang and Zhou [10] introduced multi-label lazy learning K-nearest neighbor (ML-KNN) as their classification algorithm.", "startOffset": 12, "endOffset": 15}, {"referenceID": 9, "context": "Inspired by [9], Zhang and Zhou [10] introduced multi-label lazy learning K-nearest neighbor (ML-KNN) as their classification algorithm.", "startOffset": 32, "endOffset": 36}, {"referenceID": 10, "context": "It also leads to large number of classes with sparse sample [11].", "startOffset": 60, "endOffset": 64}, {"referenceID": 7, "context": "In what constitutes the closer work to ours in the fuzzy domain, Lim and Chan [8] proposed a fuzzy qualitative framework and Cho and Chang [15] employed a simple fuzzy logic with two monocular images to understand the scene images.", "startOffset": 78, "endOffset": 81}, {"referenceID": 14, "context": "In what constitutes the closer work to ours in the fuzzy domain, Lim and Chan [8] proposed a fuzzy qualitative framework and Cho and Chang [15] employed a simple fuzzy logic with two monocular images to understand the scene images.", "startOffset": 139, "endOffset": 143}, {"referenceID": 7, "context": "In this paper, we extend the work of [8] by learning the 4tuple membership function from the training data.", "startOffset": 37, "endOffset": 40}, {"referenceID": 8, "context": "It relaxes the difficulty of obtaining multi-label training data as to [9], [10] where the training steps require human intervention in manually annotate the multi-label training data.", "startOffset": 71, "endOffset": 74}, {"referenceID": 9, "context": "It relaxes the difficulty of obtaining multi-label training data as to [9], [10] where the training steps require human intervention in manually annotate the multi-label training data.", "startOffset": 76, "endOffset": 80}, {"referenceID": 15, "context": "In this paper, we have employed the attributes [16] as our image features.", "startOffset": 47, "endOffset": 51}, {"referenceID": 16, "context": "Theoretically, the importance of the non-mutually exclusive data can be derived from the inequality Chernoff bound [17]:", "startOffset": 115, "endOffset": 119}, {"referenceID": 17, "context": "However, this is not true because of uniform convergence of function space F [18].", "startOffset": 77, "endOffset": 81}, {"referenceID": 17, "context": "Luxburg and Scholkopf [18] stated that the empirical risk Remp(f) can be inaccurate when N \u2192 \u221e since Chernoff bound only holds for a fixed function f which does not depend on the training data.", "startOffset": 22, "endOffset": 26}, {"referenceID": 18, "context": "This fuzzy representation of qualitative values is more general than ordinary (crisp) interval representations, since it can represents not only the information stated by a well-determined real interval but also the knowledge embedded in the soft boundaries of the interval [19].", "startOffset": 274, "endOffset": 278}, {"referenceID": 18, "context": "According to [19]\u2013[25], such representation of the 4-tuple fuzzy number is a better qualitative representation as the representation has high resolution and good compositionality.", "startOffset": 13, "endOffset": 17}, {"referenceID": 24, "context": "According to [19]\u2013[25], such representation of the 4-tuple fuzzy number is a better qualitative representation as the representation has high resolution and good compositionality.", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "This is opposed to [9], [10] which require human intervention in manually annotate the training data as prior information.", "startOffset": 19, "endOffset": 22}, {"referenceID": 9, "context": "This is opposed to [9], [10] which require human intervention in manually annotate the training data as prior information.", "startOffset": 24, "endOffset": 28}, {"referenceID": 25, "context": "Some theoreticians have attempted to determine an optimal number of bins [26]\u2013[28], but these methods generally make strong assumptions about the shape of distribution.", "startOffset": 73, "endOffset": 77}, {"referenceID": 27, "context": "Some theoreticians have attempted to determine an optimal number of bins [26]\u2013[28], but these methods generally make strong assumptions about the shape of distribution.", "startOffset": 78, "endOffset": 82}, {"referenceID": 0, "context": ", r K |r k \u2208 [0, 1]} is the output of the inference of function i, the scalar output r k is defined in (12) and \u2211K k=1 r i k = 1.", "startOffset": 13, "endOffset": 19}, {"referenceID": 0, "context": "More specifically, the structure of maximum entropy problem is to find a probability assignment (or membership function \u03bcjk \u2208 [0, 1]) which avoid bias agreeing with any given information.", "startOffset": 126, "endOffset": 132}, {"referenceID": 28, "context": "Inspired by Miyamoto and Umayahara [29], we utilize the maximum entropy to get the interpretation of 4tuple.", "startOffset": 35, "endOffset": 39}, {"referenceID": 0, "context": "In details, the 4-tuple membership function with \u03bcjk = 1 (mutually exclusive part) models the classifier while the transition of membership function [0, 1] (non-mutually exclusive part) implicitly models the regularization.", "startOffset": 149, "endOffset": 155}, {"referenceID": 29, "context": "In particular, the concept of stability brought by Bousquet and Elisseeff [30] is employed as it gives guarantee of a \u201cgood\u201d learning machine by deriving generalization error bounds.", "startOffset": 74, "endOffset": 78}, {"referenceID": 29, "context": "The constant \u03b2 should be on the order of O( 1 N ) [30].", "startOffset": 50, "endOffset": 54}, {"referenceID": 28, "context": "In order to get the stability of our method, the loss function (13) must be \u03c3-admissible for any \u03c3 (it is also need to be convex) [29]\u2013[31].", "startOffset": 130, "endOffset": 134}, {"referenceID": 30, "context": "In order to get the stability of our method, the loss function (13) must be \u03c3-admissible for any \u03c3 (it is also need to be convex) [29]\u2013[31].", "startOffset": 135, "endOffset": 139}, {"referenceID": 29, "context": "In addition, [30] has shown that for an algorithm with regularization, f + \u03bbR, it contributes to the bounded constant by 1 \u03bb\u03b2b.", "startOffset": 13, "endOffset": 17}, {"referenceID": 30, "context": "Thus, a naive bound on the stability of the multiclass system is 2K \u03b3\u03bbN [31].", "startOffset": 72, "endOffset": 76}, {"referenceID": 29, "context": "In order to get the generalization error bound, we use the Bousquet and Elisseeff [30] theorem.", "startOffset": 82, "endOffset": 86}, {"referenceID": 29, "context": "1 (Bousquet and Elisseeff [30]): A \u03b2-stable function f satisfying 0 \u2264 `(fS , z) \u2264 M for all training sets S and for all z \u2208 Z .", "startOffset": 26, "endOffset": 30}, {"referenceID": 15, "context": "RANKING INTERPRETATION Ranking system is a very common yet important information representation technique in many applications, and recently it has received more attention on applying it in inferring the output of the computer vision algorithm [16], [32].", "startOffset": 244, "endOffset": 248}, {"referenceID": 31, "context": "RANKING INTERPRETATION Ranking system is a very common yet important information representation technique in many applications, and recently it has received more attention on applying it in inferring the output of the computer vision algorithm [16], [32].", "startOffset": 250, "endOffset": 254}, {"referenceID": 0, "context": "The value of rdiff = [0 1] which is the difference between \u2228rk with rk is used to determine the level of particular image compare to the other scene images.", "startOffset": 21, "endOffset": 26}, {"referenceID": 0, "context": "We tested our approach with two public scene image datasets - the Outdoor Scene Recognition (OSR) dataset [1] and the Multi-Label Scene (MLS) dataset [9], [10].", "startOffset": 106, "endOffset": 109}, {"referenceID": 8, "context": "We tested our approach with two public scene image datasets - the Outdoor Scene Recognition (OSR) dataset [1] and the Multi-Label Scene (MLS) dataset [9], [10].", "startOffset": 150, "endOffset": 153}, {"referenceID": 9, "context": "We tested our approach with two public scene image datasets - the Outdoor Scene Recognition (OSR) dataset [1] and the Multi-Label Scene (MLS) dataset [9], [10].", "startOffset": 155, "endOffset": 159}, {"referenceID": 8, "context": "According to [9], [10], the multi-label data in the MLS dataset were manually annotated by three human observers as part of the pre-requirement during the training stage.", "startOffset": 13, "endOffset": 16}, {"referenceID": 9, "context": "According to [9], [10], the multi-label data in the MLS dataset were manually annotated by three human observers as part of the pre-requirement during the training stage.", "startOffset": 18, "endOffset": 22}, {"referenceID": 15, "context": "In the feature extraction stage for the OSR dataset, we have employed 6 different attributes [16] to represent the scene images.", "startOffset": 93, "endOffset": 97}, {"referenceID": 8, "context": "In the meantime, for MLS dataset, we employed the feature vector, R as to [9], [10].", "startOffset": 74, "endOffset": 77}, {"referenceID": 9, "context": "In the meantime, for MLS dataset, we employed the feature vector, R as to [9], [10].", "startOffset": 79, "endOffset": 83}, {"referenceID": 11, "context": "Psychological and metaphysical [12] proved that there is an influence of human factors (background, experience, age, etc.", "startOffset": 31, "endOffset": 35}, {"referenceID": 8, "context": "By using the example given by [9], let\u2019s assume we have classes c1, c2, c3 and c4.", "startOffset": 30, "endOffset": 33}, {"referenceID": 8, "context": "\u03b1, \u03b2 and \u03b3 are constraint parameters as explained in [9].", "startOffset": 53, "endOffset": 56}, {"referenceID": 32, "context": "KNN X SVM X [33] X X [9] X X X FQRC X X X X", "startOffset": 12, "endOffset": 16}, {"referenceID": 8, "context": "KNN X SVM X [33] X X [9] X X X FQRC X X X X", "startOffset": 21, "endOffset": 24}, {"referenceID": 7, "context": "1) FQRC with 2 attributes and 4 scene classes (Multi-label & Multi-class): From the comparison results show in Table V, it can be observed that one drawback of [8] is it provides similar results on certain images, which is very absurd as all the corresponding images are so different from each other and imply that each of the images has its own value of attributes, which should be different from other images.", "startOffset": 160, "endOffset": 163}, {"referenceID": 7, "context": "Apart from that, the confident values inferred from our approach are more reasonable compared to [8], for example, in Fig.", "startOffset": 97, "endOffset": 100}, {"referenceID": 7, "context": "2) FQRC with 6 attributes and 4 scene classes (Multidimension): In this testing, our proposed framework shows the strength of performing multi-dimensional classification compare to [8] where we employ 6 attributes instead of 2 to perform the classification tasks.", "startOffset": 181, "endOffset": 184}, {"referenceID": 7, "context": "Scene FQRC [8]", "startOffset": 11, "endOffset": 14}, {"referenceID": 32, "context": "To verify this, here, we compare the FQRC against the state-of-the-art binary classifiers such as K-nearest neighbor (KNN), Directed Acyclic Graph SVM (DAGSVM) [33], and Fuzzy least squares SVM (LSSVM) [34].", "startOffset": 160, "endOffset": 164}, {"referenceID": 33, "context": "To verify this, here, we compare the FQRC against the state-of-the-art binary classifiers such as K-nearest neighbor (KNN), Directed Acyclic Graph SVM (DAGSVM) [33], and Fuzzy least squares SVM (LSSVM) [34].", "startOffset": 202, "endOffset": 206}, {"referenceID": 32, "context": "As for DAGSVM [33] and LSSVM [34], DAGSVM runs with RBF as kernel and margin parameter, C = 100 using SMO training while LSSVM is implemented based on linear SVM with C = 2000 and incorporates with the least square solution.", "startOffset": 14, "endOffset": 18}, {"referenceID": 33, "context": "As for DAGSVM [33] and LSSVM [34], DAGSVM runs with RBF as kernel and margin parameter, C = 100 using SMO training while LSSVM is implemented based on linear SVM with C = 2000 and incorporates with the least square solution.", "startOffset": 29, "endOffset": 33}, {"referenceID": 8, "context": "Comparison to state-of-the-art multi-label scene classification approaches In order to show the effectiveness and efficiency of our proposed method, in this experiment, we compare the FQRC with the state-of-the-art multi-label scene classification approaches [9], [10].", "startOffset": 259, "endOffset": 262}, {"referenceID": 9, "context": "Comparison to state-of-the-art multi-label scene classification approaches In order to show the effectiveness and efficiency of our proposed method, in this experiment, we compare the FQRC with the state-of-the-art multi-label scene classification approaches [9], [10].", "startOffset": 264, "endOffset": 268}, {"referenceID": 9, "context": "The training complexity of [10] consists of three parts; prior, conditional probability, and the main function of training, while [9] requires to train a classifier for every base class.", "startOffset": 27, "endOffset": 31}, {"referenceID": 8, "context": "The training complexity of [10] consists of three parts; prior, conditional probability, and the main function of training, while [9] requires to train a classifier for every base class.", "startOffset": 130, "endOffset": 133}, {"referenceID": 8, "context": "TABLE IX COMPLEXITY OF FQRC COMPARED TO [9] AND [10]", "startOffset": 40, "endOffset": 43}, {"referenceID": 9, "context": "TABLE IX COMPLEXITY OF FQRC COMPARED TO [9] AND [10]", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "[10] O(N) +O(T ) + (O(3TN) +O(N)) O(2N)", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[9] O(NT 3) O(N)", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "From the result, we notice that, our method use the shortest time to train the model which is almost 6x faster than [10] and 227x faster than [9].", "startOffset": 116, "endOffset": 120}, {"referenceID": 8, "context": "From the result, we notice that, our method use the shortest time to train the model which is almost 6x faster than [10] and 227x faster than [9].", "startOffset": 142, "endOffset": 145}, {"referenceID": 9, "context": "Nonetheless, [10] suffered from finding the optimal number of nearest neighbor involved in the classification step.", "startOffset": 13, "endOffset": 17}, {"referenceID": 8, "context": "TABLE X COMPUTATIONAL TIME OF FQRC COMPARED TO [9] AND [10] ON MLS DATASET", "startOffset": 47, "endOffset": 50}, {"referenceID": 9, "context": "TABLE X COMPUTATIONAL TIME OF FQRC COMPARED TO [9] AND [10] ON MLS DATASET", "startOffset": 55, "endOffset": 59}, {"referenceID": 9, "context": "[10] 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "5025 [9] 37.", "startOffset": 5, "endOffset": 8}, {"referenceID": 8, "context": "It means we eliminate those testing data that are categorized as base class in [9] according to the ground truth and use only the test data in multi-label class.", "startOffset": 79, "endOffset": 82}, {"referenceID": 9, "context": "TABLE XI \u03b1-EVALUATION OF FQRC COMPARED TO [10] AND [9]", "startOffset": 42, "endOffset": 46}, {"referenceID": 8, "context": "TABLE XI \u03b1-EVALUATION OF FQRC COMPARED TO [10] AND [9]", "startOffset": 51, "endOffset": 54}, {"referenceID": 9, "context": "5 \u03b1 = 1 \u03b1 = 2 [10] 1 0.", "startOffset": 14, "endOffset": 18}, {"referenceID": 8, "context": "20 [9] 1 0.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "Based on [9], \u03b1 is the forgiveness rate because it reflects how much to forgive the errors made in predicting labels.", "startOffset": 9, "endOffset": 12}, {"referenceID": 8, "context": "In summary, we have tested the performances of FQRC compared to [9], [10] using MLS scene dataset and obtained superior results.", "startOffset": 64, "endOffset": 67}, {"referenceID": 9, "context": "In summary, we have tested the performances of FQRC compared to [9], [10] using MLS scene dataset and obtained superior results.", "startOffset": 69, "endOffset": 73}, {"referenceID": 10, "context": "This is impractical because it may lead to a large number of classes with sparse sample in the dataset [11].", "startOffset": 103, "endOffset": 107}, {"referenceID": 8, "context": "For instance, the class name \u201cField + Fall foliage + Mountain\u201d has only one image in [9].", "startOffset": 85, "endOffset": 88}, {"referenceID": 11, "context": "We showed this scenario in our real-world online survey results as well as psychological and metaphysical studies [12].", "startOffset": 114, "endOffset": 118}, {"referenceID": 8, "context": "Thirdly, [9], [10] only output binary results in multi-label classification task while our proposed approach provides ranking information.", "startOffset": 9, "endOffset": 12}, {"referenceID": 9, "context": "Thirdly, [9], [10] only output binary results in multi-label classification task while our proposed approach provides ranking information.", "startOffset": 14, "endOffset": 18}, {"referenceID": 8, "context": "Related works that do not perform this such as in [9], [10] employed human expert to re-label the image manually in order to obtain multi-label class training data for further processing, which is impractical and bias.", "startOffset": 50, "endOffset": 53}, {"referenceID": 9, "context": "Related works that do not perform this such as in [9], [10] employed human expert to re-label the image manually in order to obtain multi-label class training data for further processing, which is impractical and bias.", "startOffset": 55, "endOffset": 59}, {"referenceID": 34, "context": "Our future work will focus on extending the work with the use a fuzzy loss function [35] and normalized sum of memberships, as well as the investigate the effects of different membership function as the learning model.", "startOffset": 84, "endOffset": 88}], "year": 2014, "abstractText": "Ambiguity or uncertainty is a pervasive element of many real world decision making processes. Variation in decisions is a norm in this situation when the same problem is posed to different subjects. Psychological and metaphysical research had proven that decision making by human is subjective. It is influenced by many factors such as experience, age, background, etc. Scene understanding is one of the computer vision problems that fall into this category. Conventional methods relax this problem by assuming scene images are mutually exclusive; and therefore, focus on developing different approaches to perform the binary classification tasks. In this paper, we show that scene images are non-mutually exclusive, and propose the Fuzzy Qualitative Rank Classifier (FQRC) to tackle the aforementioned problems. The proposed FQRC provides a ranking interpretation instead of binary decision. Evaluations in term of qualitative and quantitative using large numbers and challenging public scene datasets have shown the effectiveness of our proposed method in modeling the non-mutually exclusive scene images.", "creator": "LaTeX with hyperref package"}}}