{"id": "1411.0895", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Nov-2014", "title": "Tied Probabilistic Linear Discriminant Analysis for Speech Recognition", "abstract": "Acoustic models using probabilistic linear discriminant analysis (PLDA) capture the correlations within feature vectors using subspaces which do not vastly expand the model. This allows high dimensional and correlated feature spaces to be used, without requiring the estimation of multiple high dimension covariance matrices. In this letter we extend the recently presented PLDA mixture model for speech recognition through a tied PLDA approach, which is better able to control the model size to avoid overfitting. We carried out experiments using the Switchboard corpus, with both mel frequency cepstral coefficient features and bottleneck feature derived from a deep neural network. Reductions in word error rate were obtained by using tied PLDA, compared with the PLDA mixture model, subspace Gaussian mixture models, and deep neural networks.", "histories": [["v1", "Tue, 4 Nov 2014 13:11:06 GMT  (12kb)", "http://arxiv.org/abs/1411.0895v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["liang lu", "steve renals"], "accepted": false, "id": "1411.0895"}, "pdf": {"name": "1411.0895.pdf", "metadata": {"source": "CRF", "title": "Tied Probabilistic Linear Discriminant Analysis for Speech Recognition", "authors": ["Liang Lu", "Steve Renals"], "emails": ["s.renals}@ed.ac.uk"], "sections": [{"heading": null, "text": "In recent years, it has become clear that the problem is not only a problem, but also a problem that has essentially evolved over the last 25 years. To a large extent, this is due to the use of acoustic models based on hidden Markov models (HMM), which are based on mausoleum coefficients (MFCCs) and perspective linear predictions (PLP). To a large extent, this is due to the use of acoustic models based on hidden Markov models (HMM) with mausoleum blending models (GMM), which are well suited to the representation of features that have decorative components and are relatively low."}, {"heading": "II. PLDA-BASED ACOUSTIC MODEL", "text": "The PLDA-based acoustic model is a generative model in which the distribution via acoustic characteristic vectors yt-Rd from the j-th HMM state at the time t is expressed as follows: yt-j = Uxjt + Gzj + b-jt, \u0441jt-N (0, 0). (1) zj-Rq is the state variable (equivalent to the identity variable between classes in JFA) divided by the entirety of the acoustic frames generated by the j-th state, and xjt-Rp is the frame variable (equivalent to the channel variable within the class in JFA) that explains the frame-related variability. Usually, the dimensionality of these two latent variables is smaller than that of the characteristic vector yt, i.e. p, q-d. U-Rd-p and G-Rd-q are two low-level matrices that extend over the subspaces to cover the most important formable ones."}, {"heading": "A. PLDA Mixture Model", "text": "A single PLDA blending model [12] has a limited modeling capacity because it only approximates a single Gaussian distribution. An M-component PLDA blending model [12] results in the following component distribution: yt | j, m = Umxjmt + Gmzjm + bm + jmt, (3) jmt \u0445 N (0, m) (4) If c is to be the component indicator variable, then the previous (weight) of each component is P (c = m | j) = \u03c0jm. Given the latent variables xjmt and zjm, the state-level distribution is divided by characteristics: p (yt | j) = \u2211 m\u03c0jmN (yt; Umx-jmt + Gmz-jm + bm, \u0441m).x-jmt and z-jm are point estimates of the latents. Since the projection matrices Um and Gm are divided globally, a large number of components can be used, e.g. to increase the capacity of M = 400."}, {"heading": "B. Tied PLDA", "text": "Alternatively, the state variables zjm can be bound across components, resulting in the following component distribution: yt | j, m = Umxjmt + Gmzj + bm + ergo jmt, (5) ergo: weight division according to SGMM [18]: yt | j, k, m = Umxjkmt + Gmzjk + bm + ergo jkmt, (7) ergo-up \"strategy can be used analogously to the SGMM sub-state division [18]: yt | j, k, m = Umxjkmt + Gmzjk + ergo jkmt, (0) ergo-up\" strategy can be applied, analogous to the SGMM state division [18]: yt | j, k, m = Umxjkmt + Gmzjk + ergo jkmt, (18) ergo-up \"strategy can be used, analogous to the SGMM state splitting [18]: variable state splitting according to GMDA model, we can calculate the state splitting according to GMDA and Sexpandable GMM."}, {"heading": "III. MAXIMUM LIKELIHOOD TRAINING", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. Likelihoods", "text": "For bound PLDA, the probability can be calculated according to Equation (9) by using the MAP estimates of the latent variables xjkmt and zjk, which are called point estimation in [12]. \u2212 In practice, however, this approach does not work well due to the great uncertainty of estimating xjkmt, i.e. the large variance of its posterior distribution. \u2212 Another approach is to marginalize the observation variable xjkmt, which is called uncertainty estimate in [12]. \u2212 Using N (0, I) as the previous method used in model training for consistency (cf. Equation (15), this probability function can asp (yt | j) = [mkwjkm] p (yt | asikmt, j, m) p (j, k, m) P (xjkmt) dxjkmt = 1 yejkmN (yt; Gmz (m) m, Umm + This method is similar to the method J1, P)."}, {"heading": "B. Model update", "text": "We used the variation marking to learn the model in which Mbps and zjkmtU (mtU) (mtU) (mtU) (mtU) (mtU) (mtU) (mtU) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt)) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt)) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt)) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt) (mt)) (mt) (mt) (mt) (mt) (mt)) (mt) (mt) (mt)) (mt) (mt) (mt)) (mt) (mt) (mt) (mt) (mt) (mt) (mt)) (mt) (mt) (mt) (mt) (mt) (mt"}, {"heading": "IV. EXPERIMENTS", "text": "We conducted experiments with the Switchboard Corpus1 [27], using the Hub-5 Eval 2000 data [28], which contained the Switchboard (SWB) and CallHome (CHM) evaluation subgroups, and the Kaldi speech recognition toolkit [29], which we expanded to include an implementation of the PLDA-based acoustic model. In the following experiments, we used the maximum probability estimate without speaker adaptation or adaptive training, using the pronunciation dictionary provided by the transcriptions of the Mississippi State [30], and a trigram language model was used for decoding."}, {"heading": "A. MFCC features", "text": "To take advantage of longer context information, we also conducted experiments with spliced MFCC 0 of different context window sizes for the GMM and SGMM systems, followed by a global LDA transformation to reduce the feature dimensionality to 40, and a global semi-bound covariance matrix that transforms [31] to decorate the features. PLDA systems directly used the concatenated MFCCs with different context window sizes, without de-correlation and reduction of dimensionality. Table I shows the results of using a 33-hour subset of training data, and the number of active model parameters PLPLPLPL3. In this case, there are about 2,400 bundled three-dimensional states in the GMM systems, representing about 30,000 Gaussian.The GMDA GMDA and GMDA components have a similar number of GMDA components."}, {"heading": "B. Bottleneck features", "text": "The DNN system has six hidden layers, each containing 1024 hidden units using 33 hours of training data, and the number of hidden units increases to 1200 if the amount of training data is 109 hours. The bottleneck DNN system (BN hybrid) used the same training data and the same type of off-site input - while reducing the fifth hidden layer to 26 hours. Using a larger bottleneck layer proved unhelpful [19]. We linked the bottleneck and the MFCC coefficient (BN MFCC) and then used it to retrain our GMM and PLDA systems. We used LDA to reduce the dimensionality of the linked features from 65 to 40, followed by STC to de-correlate the features for GMM and SGMM systems."}, {"heading": "V. CONCLUSIONS", "text": "Building on our previous work on acoustic modeling with the PLDA mixing model, we have presented a bound PLDA-based acoustic model that can be better scaled to the amount of training data. Experiments show that this model can achieve higher recognition accuracy while enjoying the flexibility to use acoustic features of various dimensions as a PLDA mixing model. Other types of acoustic characteristics can be explored more freely with this acoustic model. Along this line, we have shown that the bottleneck feature of a DNN without front-end function transformation can be used to reduce dimensions and uncorrelate. Future work will include speaker customization and discriminatory training for this model, and we are also interested in learning speech representations in an unattended manner with a deep auto-encoder for this model. The source code and recipe used in this work are available at http: / homepages.da / inftac..uk /."}], "references": [{"title": "Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences", "author": ["Steven Davis", "Paul Mermelstein"], "venue": "Acoustics, Speech and Signal Processing, IEEE Transactions on, vol. 28, no. 4, pp. 357\u2013366, 1980.  5", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1980}, {"title": "Perceptual linear predictive (plp) analysis of speech", "author": ["Hynek Hermansky"], "venue": "the Journal of the Acoustical Society of America, vol. 87, no. 4, pp. 1738\u20131752, 1990.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1990}, {"title": "A review of large-vocabulary continuous-speech recognition", "author": ["Steve Young"], "venue": "Signal Processing Magazine, IEEE, vol. 13, no. 5, pp. 45, 1996.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "Large-vocabulary continuous speech recognition: advances and applications", "author": ["J-L Gauvain", "Lori Lamel"], "venue": "Proceedings of the IEEE, vol. 88, no. 8, pp. 1181\u20131200, 2000.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "The application of hidden markov models in speech recognition", "author": ["M. Gales", "S. Young"], "venue": "Foundations and Trends in Signal Processing, vol. 1, no. 3, pp. 195\u2013304, 2008.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition", "author": ["GE Dahl", "D Yu", "L Deng", "A Acero"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 1, pp. 30\u201342, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["Geoffrey Hinton", "Li Deng", "Dong Yu", "George E Dahl", "Abdel-rahman Mohamed", "Navdeep Jaitly", "Andrew Senior", "Vincent Vanhoucke", "Patrick Nguyen", "Tara N Sainath", "Brain Kingsbury"], "venue": "Signal Processing Magazine, IEEE, vol. 29, no. 6, pp. 82\u201397, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Connectionist speech recognition: a hybrid", "author": ["Herve A Bourlard", "Nelson Morgan"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1994}, {"title": "Connectionist probability estimators in HMM speech recognition", "author": ["Steve Renals", "Nelson Morgan", "Herv\u00e9 Bourlard", "Michael Cohen", "Horacio Franco"], "venue": "IEEE Transactions on Speech and Audio Processing, vol. 2, no. 1, pp. 161\u2013174, 1994.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1994}, {"title": "Probabilistic and bottle-neck features for LVCSR of meetings", "author": ["Franti\u0161ek Gr\u00e9zl", "Martin Karafi\u00e1t", "Stanislav Kont\u00e1r", "J Cernocky"], "venue": "Proc. ICASSP. IEEE, 2007, vol. 4.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Improved bottleneck features using pretrained deep neural networks", "author": ["Dong Yu", "Michael L Seltzer"], "venue": "INTERSPEECH, 2011, pp. 237\u2013 240.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic linear discriminant analysis for acoustic modelling", "author": ["L Lu", "S Renals"], "venue": "IEEE Signal Processing Letters, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Probabilistic linear discriminant analysis for inferences about identity", "author": ["Simon JD Prince", "James H Elder"], "venue": "Proc. ICCV. IEEE, 2007, pp. 1\u20138.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Joint factor analysis versus eigenchannels in speaker recognition", "author": ["P. Kenny", "G. Boulianne", "P. Ouellet", "P. Dumouchel"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 15, no. 4, pp. 1435\u20131447, 2007.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Bayesian speaker verification with heavy tailed priors", "author": ["Patrick Kenny"], "venue": "Speaker and Language Recognition Workshop (IEEE Odyssey), 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Front-end factor analysis for speaker verification", "author": ["Najim Dehak", "Patrick J Kenny", "R\u00e9da Dehak", "Pierre Dumouchel", "Pierre Ouellet"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 19, no. 4, pp. 788\u2013798, 2011.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Fullcovariance UBM and heavy-tailed PLDA in i-vector speaker verification", "author": ["Pavel Matejka", "Ondrej Glembek", "Fabio Castaldo", "Md Jahangir Alam", "Oldrich Plchot", "Patrick Kenny", "Lukas Burget", "Jan Cernocky"], "venue": "Proc. ICASSP. IEEE, 2011, pp. 4828\u20134831.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "The subspace Gaussian mixture model\u2014A structured model for speech recognition", "author": ["D Povey", "L Burget", "M Agarwal", "P Akyazi", "F Kai", "A Ghoshal", "O Glembek", "N Goel", "M Karafi\u00e1t", "A Rastrow", "RC Rose", "P Schwarz", "S Thomas"], "venue": "Computer Speech & Language, vol. 25, no. 2, pp. 404\u2013439, 2011.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic linear discriminant analysis with bottleneck features for speech recognition", "author": ["L Lu", "S Renals"], "venue": "Proc. INTERSPEECH, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Comparison of scoring methods used in speaker recognition with joint factor analysis", "author": ["Ondrej Glembek", "Lukas Burget", "Najim Dehak", "Niko Brummer", "Patrick Kenny"], "venue": "Proc. ICASSP. IEEE, 2009, pp. 4057\u20134060.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Variational bayesian joint factor analysis models for speaker verification", "author": ["Xianyu Zhao", "Yuan Dong"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing,, vol. 20, no. 3, pp. 1032\u20131042, 2012.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Probabilistic models for inference about identity", "author": ["Peng Li", "Yun Fu", "Umar Mohammed", "James H Elder", "Simon JD Prince"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 34, no. 1, pp. 144\u2013157, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "A bayesian predictive classification approach to robust speech recognition", "author": ["Qiang Huo", "Chin-Hui Lee"], "venue": "Speech and Audio Processing, IEEE Transactions on, vol. 8, no. 2, pp. 200\u2013204, 2000.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Uncertainty decoding with SPLICE for noise robust speech recognition", "author": ["J Droppo", "A Acero", "L Deng"], "venue": "Proc. ICASSP. IEEE, 2002.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2002}, {"title": "Joint uncertainty decoding for noise robust speech recognition", "author": ["H Liao", "MJF Gales"], "venue": "Proc. INTERSPEECH. Citeseer, 2005.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2005}, {"title": "Joint uncertainty decoding for noise robust subspace Gaussian mixture models", "author": ["L Lu", "KK Chin", "A Ghoshal", "S Renals"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, 2013.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "SWITCH- BOARD: Telephone speech corpus for research and development", "author": ["John J Godfrey", "Edward C Holliman", "Jane McDaniel"], "venue": "Proc. ICASSP. IEEE, 1992, pp. 517\u2013520.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1992}, {"title": "Research methodologies, observations and outcomes in (conversational) speech data collection", "author": ["Christopher Cieri", "David Miller", "Kevin Walker"], "venue": "Proceedings of the second international conference on Human Language Technology Research. Morgan Kaufmann Publishers Inc., 2002, pp. 206\u2013211.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2002}, {"title": "The Kaldi speech recognition toolkit", "author": ["D Povey", "A Ghoshal", "G Boulianne", "L Burget", "O Glembek", "N Goel", "M Hannemann", "P Motl\u0131cek", "Y Qian", "P Schwarz", "J Silovsk\u00fd", "G Semmer", "K Vesel\u00fd"], "venue": "Proc. ASRU, 2011.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Resegmentation of SWITCHBOARD", "author": ["Neeraj Deshmukh", "Aravind Ganapathiraju", "Andi Gleeson", "Jonathan Hamaker", "Joseph Picone"], "venue": "Proc. ICSLP, 1998.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1998}, {"title": "Semi-tied covariance matrices for hidden Markov models", "author": ["MJF Gales"], "venue": "IEEE Transactions on Speech and Audio Processing, vol. 7, no. 3, pp. 272\u2013281, 1999.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1999}], "referenceMentions": [{"referenceID": 0, "context": "INTRODUCTION ACOUSTIC models for speech recognition have advanced substantially over the past 25 years, but the front-end feature processing has been largely unchanged, based on mel frequency cepstral coefficients (MFCCs) [1] and perceptual linear prediction (PLP) features [2].", "startOffset": 222, "endOffset": 225}, {"referenceID": 1, "context": "INTRODUCTION ACOUSTIC models for speech recognition have advanced substantially over the past 25 years, but the front-end feature processing has been largely unchanged, based on mel frequency cepstral coefficients (MFCCs) [1] and perceptual linear prediction (PLP) features [2].", "startOffset": 274, "endOffset": 277}, {"referenceID": 2, "context": "To a large degree this has been due to the use of acoustic models based on hidden Markov models (HMMs) with Gaussian mixture models (GMMs) [3]\u2013[5], which are well matched to feature representations which have decorrelated components and are relatively low-dimensional.", "startOffset": 139, "endOffset": 142}, {"referenceID": 4, "context": "To a large degree this has been due to the use of acoustic models based on hidden Markov models (HMMs) with Gaussian mixture models (GMMs) [3]\u2013[5], which are well matched to feature representations which have decorrelated components and are relatively low-dimensional.", "startOffset": 143, "endOffset": 146}, {"referenceID": 5, "context": "Deep neeural network (DNN) acoustic models [6] address these limitations and have achieved significant reductions in word error rate (WER) across many speech recogniiton datasets [7].", "startOffset": 43, "endOffset": 46}, {"referenceID": 6, "context": "Deep neeural network (DNN) acoustic models [6] address these limitations and have achieved significant reductions in word error rate (WER) across many speech recogniiton datasets [7].", "startOffset": 179, "endOffset": 182}, {"referenceID": 7, "context": "Compared to the hybrid neural network / hidden Markov model (HMM) architecture studied in the early 1990s [8], [9], DNNs typically use more hidden layers and a wider output layer.", "startOffset": 106, "endOffset": 109}, {"referenceID": 8, "context": "Compared to the hybrid neural network / hidden Markov model (HMM) architecture studied in the early 1990s [8], [9], DNNs typically use more hidden layers and a wider output layer.", "startOffset": 111, "endOffset": 114}, {"referenceID": 9, "context": "Moreover, DNNs can be also used as a good feature extractor, for instance through the inference of bottleneck features which may append the features used in GMM-based speech recognition systems [10], [11].", "startOffset": 194, "endOffset": 198}, {"referenceID": 10, "context": "Moreover, DNNs can be also used as a good feature extractor, for instance through the inference of bottleneck features which may append the features used in GMM-based speech recognition systems [10], [11].", "startOffset": 200, "endOffset": 204}, {"referenceID": 11, "context": "We have addressed the limitations of GMMs through an acoustic model based on probabilistic linear discriminant analysis (PLDA) [12], which can employ higher dimensional, correlated feature vectors.", "startOffset": 127, "endOffset": 131}, {"referenceID": 12, "context": "of linear discriminant analysis (LDA) [13], which has been very well studied for speaker recognition in the joint factor analysis (JFA) [14] and i-vector [15]\u2013[17] frameworks.", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "of linear discriminant analysis (LDA) [13], which has been very well studied for speaker recognition in the joint factor analysis (JFA) [14] and i-vector [15]\u2013[17] frameworks.", "startOffset": 136, "endOffset": 140}, {"referenceID": 14, "context": "of linear discriminant analysis (LDA) [13], which has been very well studied for speaker recognition in the joint factor analysis (JFA) [14] and i-vector [15]\u2013[17] frameworks.", "startOffset": 154, "endOffset": 158}, {"referenceID": 16, "context": "of linear discriminant analysis (LDA) [13], which has been very well studied for speaker recognition in the joint factor analysis (JFA) [14] and i-vector [15]\u2013[17] frameworks.", "startOffset": 159, "endOffset": 163}, {"referenceID": 11, "context": "A PLDA acoustic model factorizes the acoustic variability using HMM state dependent variables which are expected to be consistent across different acoustic conditions, and observation dependent variables which characterise per frame level acoustic changes [12].", "startOffset": 256, "endOffset": 260}, {"referenceID": 17, "context": "Similarly to a subspace GMM (SGMM) [18], the factorisation is based on the inference of subspaces.", "startOffset": 35, "endOffset": 39}, {"referenceID": 11, "context": "We have previously investigated using a PLDA mixture model for acoustic modelling [12], [19].", "startOffset": 82, "endOffset": 86}, {"referenceID": 18, "context": "We have previously investigated using a PLDA mixture model for acoustic modelling [12], [19].", "startOffset": 88, "endOffset": 92}, {"referenceID": 17, "context": "In this letter we mitigate the problem by tying the PLDA state variables in PLDA, an approach analogous to the use of tied state vectors in SGMMs [18].", "startOffset": 146, "endOffset": 150}, {"referenceID": 11, "context": "An M component PLDA mixture model [12] results in the following component distribution: yt|j,m = Umxjmt +Gmzjm + bm + \u01ebjmt, (3) \u01ebjmt \u223c N (0,\u039bm) (4) If c to be the component indicator variable, then the prior (weight) of each component is P (c = m|j) = \u03c0jm.", "startOffset": 34, "endOffset": 38}, {"referenceID": 11, "context": "M = 400 [12].", "startOffset": 8, "endOffset": 12}, {"referenceID": 17, "context": "In this case, a \u201cmixing-up\u201d strategy can be used, analogous to SGMM sub-state splitting [18]: yt|j, k,m = Umxjkmt +Gmzjk + bm + \u01ebjkmt, (7) \u01ebjkmt \u223c N (0,\u039bm) , (8) where k denotes the sub-state index, and zjk is the substate variable.", "startOffset": 88, "endOffset": 92}, {"referenceID": 11, "context": "Likelihoods For tied PLDA, the likelihood may be computed according to equation (9) by make use of the MAP estimates of the latent variables xjkmt and zjk , referred to as the point estimate in [12].", "startOffset": 194, "endOffset": 198}, {"referenceID": 11, "context": "Another approach is to marginalise out the observation variable xjkmt, which is referred as the uncertainty estimate in [12].", "startOffset": 120, "endOffset": 124}, {"referenceID": 19, "context": "This method is similar to the channel integration evaluation method used for JFA based speaker recognition [20], [21].", "startOffset": 107, "endOffset": 111}, {"referenceID": 20, "context": "This method is similar to the channel integration evaluation method used for JFA based speaker recognition [20], [21].", "startOffset": 113, "endOffset": 117}, {"referenceID": 19, "context": "Note that the likelihood can be efficiently computed without inverting matrices UmUm + \u039bm directly, but by using the Woodbury matrix inversion lemma as in [20], [22]:", "startOffset": 155, "endOffset": 159}, {"referenceID": 21, "context": "Note that the likelihood can be efficiently computed without inverting matrices UmUm + \u039bm directly, but by using the Woodbury matrix inversion lemma as in [20], [22]:", "startOffset": 161, "endOffset": 165}, {"referenceID": 20, "context": "It is also possible to marginalise out the state variable zjk alone or jointly with xjkmt similar to the methods used in [21].", "startOffset": 121, "endOffset": 125}, {"referenceID": 22, "context": "This model-based uncertainty approach is similar to Bayesian predictive classification (BPC) for GMM-based acoustic models [23], in contrast to feature space uncertainty approaches used for noise robust speech recognition [24]\u2013[26].", "startOffset": 123, "endOffset": 127}, {"referenceID": 23, "context": "This model-based uncertainty approach is similar to Bayesian predictive classification (BPC) for GMM-based acoustic models [23], in contrast to feature space uncertainty approaches used for noise robust speech recognition [24]\u2013[26].", "startOffset": 222, "endOffset": 226}, {"referenceID": 25, "context": "This model-based uncertainty approach is similar to Bayesian predictive classification (BPC) for GMM-based acoustic models [23], in contrast to feature space uncertainty approaches used for noise robust speech recognition [24]\u2013[26].", "startOffset": 227, "endOffset": 231}, {"referenceID": 18, "context": "A joint model training algorithm could be obtained without making use of this assumption: however, it may be computationally infeasible in practice [19].", "startOffset": 148, "endOffset": 152}, {"referenceID": 11, "context": "the PLDA mixture model [12], the EM auxiliary function to update Um in tied PLDA is", "startOffset": 23, "endOffset": 27}, {"referenceID": 11, "context": "For computational efficiency, a background model based on a mixtures of factor analysers is used to select a small subset of the components for each frame for training and decoding, which is described in more detail in [12].", "startOffset": 219, "endOffset": 223}, {"referenceID": 26, "context": "EXPERIMENTS We performed experiments using the Switchboard corpus1 [27].", "startOffset": 67, "endOffset": 71}, {"referenceID": 27, "context": "The Hub-5 Eval 2000 data [28] is used as the test set, which contains the Switchboard (SWB) and CallHome (CHM) evaluation subsets.", "startOffset": 25, "endOffset": 29}, {"referenceID": 28, "context": "The experiments were performed using the Kaldi speech recognition toolkit2 [29], which we extended with an implementation of the PLDA-based acoustic model.", "startOffset": 75, "endOffset": 79}, {"referenceID": 29, "context": "We used the pronunciation lexicon that was supplied by the Mississippi State transcriptions [30] and a trigram language model was used for decoding.", "startOffset": 92, "endOffset": 96}, {"referenceID": 30, "context": "To take advantage of longer context information, for the GMM and SGMM systems we have also performed experiments using spliced MFCC 0 of differing context window size, followed by a global LDA transformation to reduce the feature dimensionality to be 40, and a global semi-tied covariance (STC) matrix transform [31] to decorrelate the features.", "startOffset": 312, "endOffset": 316}, {"referenceID": 18, "context": "Using a larger bottleneck layer was not found to be helpful [19].", "startOffset": 60, "endOffset": 64}], "year": 2014, "abstractText": "Acoustic models using probabilistic linear discriminant analysis (PLDA) capture the correlations within feature vectors using subspaces which do not vastly expand the model. This allows high dimensional and correlated feature spaces to be used, without requiring the estimation of multiple high dimension covariance matrices. In this letter we extend the recently presented PLDA mixture model for speech recognition through a tied PLDA approach, which is better able to control the model size to avoid overfitting. We carried out experiments uisng the Switchboard corpus, with both mel frequency cepstral coefficient features and bottleneck feature derived from a deep neural network. Reductions in word error rate were obtained by using tied PLDA, compared with the PLDA mixture model, subspace Gaussian mixture models, and deep neural networks.", "creator": "LaTeX with hyperref package"}}}