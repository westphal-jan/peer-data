{"id": "1411.1490", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Nov-2014", "title": "Efficient Representations for Life-Long Learning and Autoencoding", "abstract": "It has been a long-standing goal in machine learning, as well as in AI more generally, to develop life-long learning systems that learn many different tasks over time, and reuse insights from tasks learned, \"learning to learn\" as they do so. In this work we pose and provide efficient algorithms for several natural theoretical formulations of this goal. Specifically, we consider the problem of learning many different target functions over time, that share certain commonalities that are initially unknown to the learning algorithm. Our aim is to learn new internal representations as the algorithm learns new target functions, that capture this commonality and allow subsequent learning tasks to be solved more efficiently and from less data. We develop efficient algorithms for two very different kinds of commonalities that target functions might share: one based on learning common low-dimensional and unions of low-dimensional subspaces and one based on learning nonlinear Boolean combinations of features. Our algorithms for learning Boolean feature combinations additionally have a dual interpretation, and can be viewed as giving an efficient procedure for constructing near-optimal sparse Boolean autoencoders under a natural \"anchor-set\" assumption.", "histories": [["v1", "Thu, 6 Nov 2014 03:51:39 GMT  (24kb)", "https://arxiv.org/abs/1411.1490v1", null], ["v2", "Thu, 4 Dec 2014 22:59:04 GMT  (51kb,D)", "http://arxiv.org/abs/1411.1490v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["maria-florina balcan", "avrim blum", "santosh vempala"], "accepted": false, "id": "1411.1490"}, "pdf": {"name": "1411.1490.pdf", "metadata": {"source": "CRF", "title": "Efficient Representations for Life-Long Learning and Autoencoding", "authors": ["Maria-Florina Balcan", "Avrim Blum"], "emails": ["ninamf@cs.cmu.edu", "avrim@cs.cmu.edu", "vempala@cc.gatech.edu"], "sections": [{"heading": null, "text": "ar Xiv: 141 1.14 90v2 [cs.LG] 4 Dec 201 4"}, {"heading": "1 Introduction", "text": "1. D eeisrrVnlrsrteeeaeeeteerrteeeeeeoiiiiiiiiiiiiiiiiiietlrsrrrteeeeoVrrrrsrteeeeeersrrteee\u00fcgznlrsrrrsrrrrleiiiiiiueegnlrrrrrrteeteeteerrteerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrllllrrrrteeteeteerrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "1.1 Related Work", "text": "Baxter [7, 6] has developed some of the earliest foundations for transfer learning by providing sample complexity results to achieve a low average error in such constellations. Other related sample complexity results appear in [8].Recent work by [19, 16] looks at the problem of learning multiple linear separators that share a common low-dimensional subspace in the batch constellation where all tasks are pre-assigned. They provide specific guarantees for a natural ERM algorithm with trace regulation. Work has also been done to apply the group lasso method to stack multi-task learning that solves a specific multi-task optimization problem [20]. In contrast to these results, our setting is more challenging as we aim to achieve small errors in all tasks and do so online without retaining all training data from past learning tasks."}, {"heading": "2 Preliminaries", "text": "We assume that we have M-learning problems (binary classification) that arrive online over time. Learning problems spread over a common instance space X of dimension n (e.g. we consider X = < n and X = {0, 1} n), but each has its own target function and potentially its own distribution Di over X. Formally, learning problem i is defined by a distribution Pi over X \u00d7 Y, where Y = {\u2212 1, 1} is the label space and Di is the boundary area over X of Pi and the goal of the learning algorithm in problem i is to create a hypotheses function hi of minor errors, where err (hi) = errPi (hi) = P (x, y) \u0445 Pi [hi (x) 6 = y]."}, {"heading": "3 Life-long Learning of Halfspaces", "text": "Here we look at the natural case, which we see as a network with a middle layer of hidden linear units."}, {"heading": "3.1 Halfspaces with more complex common structure", "text": "In this section, we look at lifelong learning of semispaces with more complex common structures, corresponding to a multi-layered network of linear metafeatures. It is initially not obvious how multiple levels of linear nodes could help: if the target vectors encompass a k-dimensional subspace, then they can be represented with a multi-layered linear network, each level would have to have at least k-dimensional space, and the number of nodes in the network would not tell the whole story: sample complexity of learning can also be reduced by thrift. Specifically, we now assume that the target functions all lie in a k-dimensional space and that others lie within this k-dimensional space, with each target located in one of the r-dimensional spaces, where there are of course different models in which there are really different types of learning problems, but they share some commonalities over the common k-dimensional subspace (given by the common k-dimensional subspace.4) We can consider this as the first of two hidden layers:"}, {"heading": "4 Life-long Learning of Monomials", "text": "In fact, we are able to go in search of a solution that is capable of finding a solution to all the problems."}, {"heading": "4.1 Solving the Consistency Problem", "text": "We show that we have a problem for monomial metafeatures: \"We can't do it.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\" \"..\" \"..\" \"..\" \"..\" \"..\" \"..\" \"..\" \"..\" \"..\" \"\".. \"\".. \"\" \"..\" \"\".. \"\" \"..\" \"\".. \"\" \"..\" \"\".. \"\" \"..\" \"\".. \"\" \"..\" \"\".. \"\" \"..\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"\".. \"\" \"..\" \"\" \"..\" \"\" \"\".. \"\" \"\" \"..\" \"\" \"..\" \"\" \"..\" \""}, {"heading": "4.2 An Abstract Online Problem", "text": "Building on algorithm 3 and Lemma 4, we now describe an algorithm for the following abstract online setting. At each stage-step-r, we propose a set of M-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-goal-"}, {"heading": "4.3 Applications", "text": "As an immediate application of the above abstract online problem, since conjunctions above {0, 1} n are exactly in the equivalence query model with at most n equivalence queries (and conjunctions above {0, 1} k can be learned from at most k equivalence queries), we can immediately learn the following: Let TS be a sequence of m conjunctions, each conjunction of a subset of metafeatures m1,.. mk satisfaction of the anchor variable condition. Then this sequence can only be total using O (mk + n3) equivalence queries. As a further application of the above abstract online problem, we now show that we can learn DS with good sample complexity over any product distribution. Theorem 4 Assume that all Dr = D is a product distribution, that we satisfy the metafeatures mi, the anchor variables assumptions, and all target functions are balanced."}, {"heading": "4.4 Sparse Boolean Autoencoders and Relaxing the Anchor-Variable Assumption", "text": "The above results (and in particular Lemma 4) have an interesting interpretation, such as the construction of a minimum space for the aggregation of examples for the aggregation of examples for the aggregation of examples for the aggregation of examples for the aggregation of examples for the aggregation of examples for the aggregation of examples for the aggregation of examples for the aggregation of examples for the aggregation of examples for the aggregation of examples for the aggregation of examples at the output level, and the aggregation of examples for the aggregation of examples at the output level. We can represent each hidden node in such a network as a \"piece\" of an image with the property that each Tr should be equal, that all Tr-OR of all the pieces contained therein (i.e."}, {"heading": "5 Life-long Learning of Polynomials", "text": "If we are able to solve the problem that we have had in the US and the EU in recent years, it is only a matter of time before we have learned it in the US and the EU. (...) If we do it in the EU, we will not only learn but also learn in the EU and in the EU. (...) If we do it in the EU and in the EU, we will do it in the EU, in the EU and in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU, in the EU"}, {"heading": "6 Discussion and Open Problems", "text": "In this paper, we present algorithms for learning new internal representations when presented online with a range of learning problems that have different types of common ground. In the case of linear threshold functions with linear subspaces, we need log-concave distributions to ensure that errors can be limited both upwards and downwards by a \"nice\" angle function: the lower limit helps ensure that the range of accurate hypotheses is close to the range of their corresponding true targets (although one must be careful with the accumulation of errors), and the upper limit ensures that a sufficiently close approximation to the range of true targets is almost as good as the range itself. It is an interesting question whether these results can be extended to distributions that do not have such properties, while maintaining the streaming character of the algorithms (i.e. remembering only the rules learned and not the data from which they were generated)."}, {"heading": "A Proofs for halfspaces with more complex common structure", "text": "We now provide the algorithm and the proof for theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 3.Theorem 3.Theorem 3.Theorem.3.Theorem 3.Theorem 3.Theorem 3.Theorem.Theorem 3.Theorem 3.Theorem 3.Theorem 3.orem 3.Theorem.Theorem 3.Theorem 3.Theorem 3.orem 3.Theorem 3.orem 3.Theorem 2.Theorem 3.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 3.Theorem 2.Theorem 3.Theorem 2.Theorem 3.Theorem 2.Theorem 3.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.Theorem 2.The"}], "references": [{"title": "Convex multi-task feature learning", "author": ["A. Argyriou", "T. Evgeniou", "M. Pontil"], "venue": "Machine Learning Journal", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning topic models - going beyond SVD", "author": ["Sanjeev Arora", "Rong Ge", "Ankur Moitra"], "venue": "In 53rd Annual IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "New algorithms for learning incoherent and overcomplete dictionaries", "author": ["Sanjeev Arora", "Rong Ge", "Ankur Moitra"], "venue": "In Proceedings of The 27th Conference on Learning Theory (COLT),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "The power of localization for efficiently learning linear separators with noise", "author": ["Pranjal Awasthi", "Maria-Florina Balcan", "Philip M. Long"], "venue": "In Symposium on Theory of Computing (STOC),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Active and passive learning of linear separators under log-concave distributions", "author": ["M.-F. Balcan", "P.M. Long"], "venue": "Proceedings of the 26th Annual Conference on Learning Theory", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "A model of inductive bias learning", "author": ["J. Baxter"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2000}, {"title": "A bayesian/information theoretic model of learning to learn via multiple task sampling", "author": ["Jonathan Baxter"], "venue": "Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1997}, {"title": "Exploiting task relatedness for multiple task learning", "author": ["S. Ben-David", "R. Schuller"], "venue": "COLT", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Deep learning of representations", "author": ["Y. Bengio"], "venue": "Looking forward,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "On the expressive power of deep architectures", "author": ["Y. Bengio", "O. Delalleau"], "venue": "ALT", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Linear algorithms for online multitask classification", "author": ["G. Cavallanti", "N. Cesa-Bianchi", "C. Gentile"], "venue": "Journal of Machine Learning Research", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Computers and Intractability: A Guide to the Theory of NP-Completeness", "author": ["Michael R. Garey", "David S. Johnson"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1979}, {"title": "How babies think", "author": ["A. Gopnik", "A. Meltzoff", "P. Kuhl"], "venue": "Orion", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Baum\u2019s algorithm learns intersections of halfspaces with respect to log-concave distributions", "author": ["A.R. Klivans", "P.M. Long", "A. Tang"], "venue": "RANDOM", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning task grouping and overlap in multi-task learning", "author": ["A. Kumar", "H. Daume III"], "venue": "NIPS", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "On-line learning of linear functions", "author": ["Nick Littlestone", "Philip M. Long", "Manfred K. Warmuth"], "venue": "Computational Complexity,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1995}, {"title": "The geometry of logconcave functions and sampling algorithms", "author": ["L\u00e1szl\u00f3 Lov\u00e1sz", "Santosh Vempala"], "venue": "Random Structures & Algorithms,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Excess risk bounds for multitask learning with trace norm regularization", "author": ["A. Maurer", "M. Pontil"], "venue": "Proceedings of the 26th Annual Conference on Learning Theory", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "A complete analysis of the l 1, p group-lasso", "author": ["Volker Roth", "Julia E Vogt"], "venue": "In Proceedings of the 29th International Conference on Machine Learning", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Learning sparse multivariate polynomials over a field with queries and counterexamples", "author": ["R.E. Schapire", "L.M. Sellie"], "venue": "Proceedings of the 6th Annual Conference on Computational Learning Theory", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1993}, {"title": "Lecture notes for 18.409: The behavior of algorithms in practice. Lecture 2: On the condition", "author": ["D. Spielman"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "Explanation-Based Neural Network Learning: A Lifelong Learning Approach", "author": ["S. Thrun"], "venue": "Kluwer Academic Publishers, Boston, MA", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1996}, {"title": "editors", "author": ["S. Thrun", "L.Y. Pratt"], "venue": "Learning To Learn. Kluwer Academic Publishers, Boston, MA", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1997}, {"title": "Lifelong robot learning", "author": ["Sebastian Thrun", "Tom M. Mitchell"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1995}, {"title": "A neuroidal architecture for cognitive computation", "author": ["L.G. Valiant"], "venue": "Journal of the ACM", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2000}, {"title": "A random-sampling-based algorithm for learning intersections of halfspaces", "author": ["S. Vempala"], "venue": "JACM, 57(6)", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Mathematical Theories of Interaction with Oracles", "author": ["L. Yang"], "venue": "PhD thesis, CMU Dept. Machine Learning", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 12, "context": "Yet if we wish to produce machine learning systems that persist in the world, we need methods for continually learning many tasks over time and that, like humans [13], improve their ability to learn as they do so, needing less data (per task) as they learn more.", "startOffset": 162, "endOffset": 166}, {"referenceID": 21, "context": "A natural approach for tackling this goal (called \u201clife-long learning\u201d [23, 25] or \u201ctransfer learning\u201d [1, 19] or \u201clearning to learn\u201d [7, 24]) is to use information from previously-learned tasks to improve the underlying representation used by the learning algorithm, under the hope or belief that some kinds of commonalities across tasks exist.", "startOffset": 71, "endOffset": 79}, {"referenceID": 23, "context": "A natural approach for tackling this goal (called \u201clife-long learning\u201d [23, 25] or \u201ctransfer learning\u201d [1, 19] or \u201clearning to learn\u201d [7, 24]) is to use information from previously-learned tasks to improve the underlying representation used by the learning algorithm, under the hope or belief that some kinds of commonalities across tasks exist.", "startOffset": 71, "endOffset": 79}, {"referenceID": 0, "context": "A natural approach for tackling this goal (called \u201clife-long learning\u201d [23, 25] or \u201ctransfer learning\u201d [1, 19] or \u201clearning to learn\u201d [7, 24]) is to use information from previously-learned tasks to improve the underlying representation used by the learning algorithm, under the hope or belief that some kinds of commonalities across tasks exist.", "startOffset": 103, "endOffset": 110}, {"referenceID": 17, "context": "A natural approach for tackling this goal (called \u201clife-long learning\u201d [23, 25] or \u201ctransfer learning\u201d [1, 19] or \u201clearning to learn\u201d [7, 24]) is to use information from previously-learned tasks to improve the underlying representation used by the learning algorithm, under the hope or belief that some kinds of commonalities across tasks exist.", "startOffset": 103, "endOffset": 110}, {"referenceID": 6, "context": "A natural approach for tackling this goal (called \u201clife-long learning\u201d [23, 25] or \u201ctransfer learning\u201d [1, 19] or \u201clearning to learn\u201d [7, 24]) is to use information from previously-learned tasks to improve the underlying representation used by the learning algorithm, under the hope or belief that some kinds of commonalities across tasks exist.", "startOffset": 134, "endOffset": 141}, {"referenceID": 22, "context": "A natural approach for tackling this goal (called \u201clife-long learning\u201d [23, 25] or \u201ctransfer learning\u201d [1, 19] or \u201clearning to learn\u201d [7, 24]) is to use information from previously-learned tasks to improve the underlying representation used by the learning algorithm, under the hope or belief that some kinds of commonalities across tasks exist.", "startOffset": 134, "endOffset": 141}, {"referenceID": 8, "context": "These commonalities could be a single low-dimensional or sparse representation, a collection of multiple low-dimensional or sparse representations, or some combination or hierarchy, such as in Deep Learning [9, 10].", "startOffset": 207, "endOffset": 214}, {"referenceID": 9, "context": "These commonalities could be a single low-dimensional or sparse representation, a collection of multiple low-dimensional or sparse representations, or some combination or hierarchy, such as in Deep Learning [9, 10].", "startOffset": 207, "endOffset": 214}, {"referenceID": 0, "context": "This case has been considered in the \u201cbatch\u201d setting in which one has data available for all target functions at the same time and therefore can solve a joint optimization problem [1, 19].", "startOffset": 180, "endOffset": 187}, {"referenceID": 17, "context": "This case has been considered in the \u201cbatch\u201d setting in which one has data available for all target functions at the same time and therefore can solve a joint optimization problem [1, 19].", "startOffset": 180, "endOffset": 187}, {"referenceID": 1, "context": "We give an efficient algorithm for finding the fewest product-based metafeatures for a given set of target monomials under an \u201canchor-variable\u201d assumption analogous to the anchor-word assumption of [2], and prove bounds on its performance for learning a series of target functions arriving online.", "startOffset": 198, "endOffset": 201}, {"referenceID": 6, "context": "Baxter [7, 6] developed some of the earliest foundations for transfer learning, by providing sample complexity results for achieving low average error in such settings.", "startOffset": 7, "endOffset": 13}, {"referenceID": 5, "context": "Baxter [7, 6] developed some of the earliest foundations for transfer learning, by providing sample complexity results for achieving low average error in such settings.", "startOffset": 7, "endOffset": 13}, {"referenceID": 7, "context": "Other related sample complexity results appear in [8].", "startOffset": 50, "endOffset": 53}, {"referenceID": 17, "context": "Recent work of [19, 16] considers the problem of learning multiple linear separators that share a common low-dimensional subspace in the batch setting where all tasks are given up front.", "startOffset": 15, "endOffset": 23}, {"referenceID": 14, "context": "Recent work of [19, 16] considers the problem of learning multiple linear separators that share a common low-dimensional subspace in the batch setting where all tasks are given up front.", "startOffset": 15, "endOffset": 23}, {"referenceID": 18, "context": "There has also been work on applying the Group Lasso method to batch multi-task learning which solves a specific multi-task optimization problem [20].", "startOffset": 145, "endOffset": 149}, {"referenceID": 10, "context": "[11] considers multi-task learning where explicit known relationships among tasks are exploited for faster learning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Discussion in [26] hints toward the type of the algorithms we analyze in Section 3, but without formal analysis about how the error accumulation could harm the sample complexity (which, as we will see, is one of the central challenges in this setting).", "startOffset": 14, "endOffset": 18}, {"referenceID": 21, "context": ", [23, 25]).", "startOffset": 2, "endOffset": 10}, {"referenceID": 23, "context": ", [23, 25]).", "startOffset": 2, "endOffset": 10}, {"referenceID": 16, "context": ", [18]), the above procedure will be successful and learn the target functions with much fewer labeled examples in total than by learning each function separately.", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": "Proof: The proof of the lower bound appears in [5].", "startOffset": 47, "endOffset": 50}, {"referenceID": 25, "context": "The proof of the upper bound is implicit in the earlier work of [27] \u2013 we provide it here for completeness.", "startOffset": 64, "endOffset": 68}, {"referenceID": 13, "context": "It is known [15] that for some constants k3, k4 we have g(z) \u2264 k3e4.", "startOffset": 12, "endOffset": 16}, {"referenceID": 20, "context": ", [22]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": "In this case the sample complexity would be \u03a9(mn/ ) even under log-concave distributions [5].", "startOffset": 89, "endOffset": 92}, {"referenceID": 3, "context": "However, for log-concave distributions, there exist algorithms running in time poly(k, 1/ ) that find a near-optimal linear separator: in particular, one of error under the assumption that the optimal separator has error \u03b7 = / log(1/ ) [4], and with near-optimal sample complexity [14, 28].", "startOffset": 236, "endOffset": 239}, {"referenceID": 26, "context": "However, for log-concave distributions, there exist algorithms running in time poly(k, 1/ ) that find a near-optimal linear separator: in particular, one of error under the assumption that the optimal separator has error \u03b7 = / log(1/ ) [4], and with near-optimal sample complexity [14, 28].", "startOffset": 281, "endOffset": 289}, {"referenceID": 11, "context": "That is, given a collection of conjunctions, it is NP-hard to determine whether there exist k monomials such that each can be written as a product of subsets of those monomials (it is called the \u201cset-basis problem\u201d [12]).", "startOffset": 215, "endOffset": 219}, {"referenceID": 19, "context": "Efficiently learning polynomials requires membership queries (under the assumption that juntas are hard to learn) in addition to equivalence queries or random examples even in the single task setting [21].", "startOffset": 200, "endOffset": 204}, {"referenceID": 19, "context": "When learning from scratch we use an algorithm of Schapire and Sellie [21] that learns polynomials exactly.", "startOffset": 70, "endOffset": 74}, {"referenceID": 15, "context": "If the target function has an L1 norm bounded by B and its monomials can indeed be written as products of our metafeatures, then by considering all products of metafeatures and running an L1-based algorithm for learning linear functions [17], we can achieve low mean squared error using only O(B2 log(2k)) = O(B2k) examples.", "startOffset": 237, "endOffset": 241}, {"referenceID": 19, "context": "\u2022 Otherwise, run the algorithm of Schapire and Sellie [21] to learn the target Tr for problem r exactly based on the original feature representation with equivalence and membership queries.", "startOffset": 54, "endOffset": 58}, {"referenceID": 2, "context": "It would be interesting to see whether an analog of the anchor-set assumption could be applied to dictionary learning problems such as in [3].", "startOffset": 138, "endOffset": 141}], "year": 2014, "abstractText": "It has been a long-standing goal in machine learning, as well as in AI more generally, to develop lifelong learning systems that learn many different tasks over time, and reuse insights from tasks learned, \u201clearning to learn\u201d as they do so. In this work we pose and provide efficient algorithms for several natural theoretical formulations of this goal. Specifically, we consider the problem of learning many different target functions over time, that share certain commonalities that are initially unknown to the learning algorithm. Our aim is to learn new internal representations as the algorithm learns new target functions, that capture this commonality and allow subsequent learning tasks to be solved more efficiently and from less data. We develop efficient algorithms for two very different kinds of commonalities that target functions might share: one based on learning common low-dimensional and unions of low-dimensional subspaces and one based on learning nonlinear Boolean combinations of features. Our algorithms for learning Boolean feature combinations additionally have a dual interpretation, and can be viewed as giving an efficient procedure for constructing near-optimal sparse Boolean autoencoders under a natural \u201canchor-set\u201d assumption. ar X iv :1 41 1. 14 90 v2 [ cs .L G ] 4 D ec 2 01 4", "creator": "LaTeX with hyperref package"}}}