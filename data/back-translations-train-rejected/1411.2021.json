{"id": "1411.2021", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2014", "title": "Partitioning Well-Clustered Graphs: Spectral Clustering Works!", "abstract": "We study a suitable class of well-clustered graphs that admit good k-way partitions and present the first almost-linear time algorithm for with almost-optimal approximation guarantees partitioning such graphs. A good k-way partition is a partition of the vertices of a graph into disjoint clusters (subsets) $\\{S_i\\}_{i=1}^k$, such that each cluster is better connected on the inside than towards the outside. This problem is a key building block in algorithm design, and has wide applications in community detection and network analysis.", "histories": [["v1", "Fri, 7 Nov 2014 20:23:50 GMT  (48kb)", "https://arxiv.org/abs/1411.2021v1", "32 pages"], ["v2", "Tue, 17 Nov 2015 17:08:00 GMT  (39kb)", "http://arxiv.org/abs/1411.2021v2", "28 pages. A preliminary version of this paper appeared in the 28th Annual Conference on Learning Theory (COLT 2015)"], ["v3", "Tue, 31 Jan 2017 15:07:33 GMT  (44kb)", "http://arxiv.org/abs/1411.2021v3", "A preliminary version of this paper appeared in COLT'15; the full version is to appear in SIAM Journal on Computing"]], "COMMENTS": "32 pages", "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["richard peng", "he sun", "luca zanetti"], "accepted": false, "id": "1411.2021"}, "pdf": {"name": "1411.2021.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Richard Peng", "He Sun", "Luca Zanetti"], "emails": ["(rpeng@cc.gatech.edu)", "(h.sun@bristol.ac.uk)", "(luca.zanetti@bristol.ac.uk)"], "sections": [{"heading": null, "text": "ar Xiv: 141 1.20 21v3 [cs.DS] Jan 31, 2017We also give an almost linear time algorithm for partitioning well-clustered graphs based on the calculation of matrix exponential and approximate adjacent data.Keywords: graph partitioning, spectral clustering, k-mean, heat core. A preliminary version of this paper appeared in the 28th Annual Conference of Learning Theory (COLT 2015). \u2020 Georgia Institute of Technology, Atlanta, USA. (rpeng @ cc.gatech.edu) \u2021 University of Bristol, Bristol, UK. (h.sun @ bristol.ac.uk) Questions, comments or corrections to this document may be addressed to this e-mail address. \u00a7 University of Bristol, Bristol, UK. (luca.zanetti @ bristol.ac.uk)"}, {"heading": "1 Introduction 1", "text": "1.1 Our results..................................................................................................................."}, {"heading": "2 Preliminaries 4", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3 Connection Between Eigenvectors and Indicator Vectors of Clusters 5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4 Analysis of Spectral Clustering 10", "text": "4.1 k-Means Clustering.................................................................... 10 4.2 Analysis of Spectral Embedding.................................................................................................."}, {"heading": "5 Partitioning Well-Clustered Graphs in Nearly-Linear Time 17", "text": "5.1 The seed step....................................................................................................................................."}, {"heading": "1 Introduction", "text": "The division of a graph into two or more parts is one of the most fundamental problems in combinatorial optimization and has extensive applications in various disciplines of computer science (max.).One of the most frequently studied graph splitting problems is the problem of edge expansion, i.e., the search for an intersection with few overlapping edges normalized by the size of the smaller side of the intersection. Formally, this is an undirected graph. For each graph defined, the conductivity of the fixed S is defined: vol (S) 6vol (S) vol (S) vol (S), where vol (S) occurs, where the total weight of edge incidence to linkages occurs in S, and leave the conductivity of the fixed S: vol (S) 6vol (G) / 2. The margin expansion problem asks for a fixed S (S).The margin expansion problem is for a fixed (S) of the fixed S (S) vol (S) vol (S)."}, {"heading": "1.1 Our Results", "text": "In fact, it is so that it is a way in which people are able to put themselves in the world. (...) In fact, it is so that they are able to put themselves in the world. (...) In fact, it is so that they are able to put themselves in the world. (...) It is so that they are able to put themselves in the world. (...) It is as if they are able to put themselves in the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world, the world of the world of the world, the world of the world, the world of the world of the world, the world of the world of the world, the world of the world, the world of the world of the world in the world, the world of the world in the world, in the world of the world, in the world of the world, in the world of the world of the world, in the world of the world in the world, in the world of the world in the world, in the world in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world, in the world in the world in the world in the world in the world, in the world in the world, in the world in the world in the world, in the world in the world in the world in the world, in the world in the world, in the world in the world in the world, in the world in the world in the world, in the world in the world in the world, in the world in the world, in the world in the world in the world in the world, in the world in the world in"}, {"heading": "1.2 Related Work", "text": "Clustering can be formulated in many ways, and the study of algorithms in many such formulations is an area of active work [7, 8, 17, 25]. Among these, our work is most closely related to spectral clustering, which is, however, closely related to normalized or low guidelines [36]. The k-way expansion we study is always within a factor of k-way standardized cuts. Theoretical studies of graph division are often based on the augmentation of the fractional relativization of these intersection problems with additional constraints in the form of semi-defined programs or Lasserre hierarchy. The goal of our study is to maintain similar boundaries with practical tools such as k-means and heat-kernel embeddingdingdingdingding.Oveis Gharan and Trevisan [32] formulate the notion of clusters in terms of inner and outer guideline."}, {"heading": "2 Preliminaries", "text": "G = (V, E) is an undirected and unweighted graph with n vertices and m edges. For each set of S'V, let vol (S), let us represent the row of neighbors of a vertex u by N (u), and its degree is the set of edges between S and T, also known as E (S, T), {u, v, and v \"T.\" For simplicity, let us write S = E (S, V\\ S) for each set of S \u2212 V. For two sets of X and Y, the symmetric difference of X and Y is defined as X-Y, (X\\ Y) as a gap (Y\\ X). We work extensively with algebraic objects related to G. We use D to define the n \u00b7 n diagonal matrix with Duu = du for u."}, {"heading": "3 Connection Between Eigenvectors and Indicator Vectors of", "text": "ClustersIn this section, we examine the relationships between the multiple sections of a graph and the eigenvectors of the normalized Laplacian matrix. Given clusters S1. Sk, define the indicator of the cluster Si bygi (u) = 1, if u-Si, 0, if u-Si, (3,1) and define the corresponding normalized indicator vector bygi = D1 / 2gi. (3,2) A fundamental result in spectral theory states that G k has coherent components if and only if the smallest eigenvalues are 0, implying that the spaces of f1, \u00b7 fk and g-D1, \u00b7 k and g-Si are the same. Generalizations of this result expect that these two spaces are still similar if these k components of G are loosely connected, in the sense that (i) any independent vector can be expressed by a linear combination."}, {"heading": "4 Analysis of Spectral Clustering", "text": "In this section, we will analyze an algorithm based on the classical spectral cluster paradigm, and give an approximation guarantee for this method on well-bundled graphs. We will show that any k mean algorithm can be used AlgoMean (X, k) with some approximation guarantee for the k path partitioning problem. (In addition, it is sufficient to use AlgoMean in a black box manner with a dot set X Rk. This section is structured as follows. We will first give a quick overview of spectral and k mean clustering in Section 4.1, in which we will use the structure theorem to analyze the spectral embedding in Section 4.3."}, {"heading": "4.2 Analysis of the Spectral Embedding", "text": "The first step of spectral clustering is the definition of vertices of a graph in points in Euclidean space, by spectral embedding (4,2).This section analyzes the properties of this embedding. Let's define the normalization factor in relation to its center, and the embedded points from different clusters of G. These properties imply that a simple k-mean algorithm is capable of producing a good clustering2.We first define k points p (1 6 i k), wohep (i), 1% vol (1) vol (1) i,., \u03b2 (k) i) i."}, {"heading": "4.3 Approximation Guarantees of Spectral Clustering", "text": "We are assuming that A1,..., Ak.,..,..,...,....,......,..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "4.4 Proof of Theorem 4.5", "text": "This means that the COST value of A1,., Ak is high, which leads to a contradiction., Lemma 4.6. Suppose for each permutation:,.,., k. \"is that there is an index so that vol (Ai) is high, which leads to a contradiction., Lemma 4.6., Suppose for each permutation:., k.\" is that there is an index that vol (Ai) is high, which leads to a contradiction.,."}, {"heading": "5 Partitioning Well-Clustered Graphs in Nearly-Linear Time", "text": "In this section, we present an almost linear time algorithm for partitioning well-grouped graphs and prove theorem 1.3. At a high level, our algorithm follows the general framework of k-mean algorithms and consists of two steps: the sowing step and the grouping step. The sowing step selects k candidates so that each is close to the actual center of a different cluster. The grouping step assigns the remaining vertices to their individual closest candidates. All sowing steps for the sowing and grouping steps assume that we have an embedding of k candidates. (u) u The following two conditions are met: (1 \u2212 110 log n) \u00b7 F (u) 2 6 x (u) 6 x-F (u) 2 + 1n5, (5,1) we assume that we have an embedding of k candidates. (u)"}, {"heading": "5.1 The Seeding Step", "text": "We have shown in section 4.2 that the approximate center p (i) for each 6 6 6 6 6 k \u00b2 (Si) -1 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Sampling) -2 (Sampling) -2 (Si) -2 (Sampling) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2 (Si) -2) -2 (Sampling) -3 (Sampling) -3 (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3) (3)."}, {"heading": "5.2 The Grouping Step", "text": "After seeding step, with constant probability, we get a set of k vertices C = {c1, \u00b7 \u00b7, ck}, and these k vertices belong to k different clusters. Now, we assign each remaining vertices u to a cluster Si, if we are closer to x (ci) compared to all other points x (cj) with cj, x (u). A naive implementation of this step requires a set of points P-Rd and a point q-Rd, we find a point p-P so that for all p-NNS data structures (16) whose formal description is as follows: Problem 1 (\u03b5-nearby neighbor problem)."}, {"heading": "5.3 Approximation Analysis of the Algorithm", "text": "The next sample parses the symmetrical difference between the optimal partition and the power of the algorithm. \u2212 Log: (1) Log: (1) Log: (1) Log: (1) Log: (1) Log: (1) Log: (1) Log: (1) Log: (1) Log: (1) Log: (1) Log: (1) Log: (2) Log: (1) Log: (1) Log: (1) Log: (2) Log: (1) Log: (1) Log: (1) Log: (2) Log: (1) Log: (2) Log: (1) Log: (1) Log: (1) Log: (1) (1) Log: (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1): (1) (1) (1) (1) (1) (1): (1) (1)) (1) (1) (1): (1)) (1) (1) (1)) (1: (1)) (1: (1)) (1) (1: (1) (1)) (1: (1) (1)) (1 (1)) (1: (1)) (1 (1)) (1 (1: (1) (1) (1) (1)) (1 (1: (1) (1))) (1 (1 (1)) (1: (1: (1) (1) (1) (1) (1) (1)) (1) (1: (1) (1) (1) (1) (1)) (1) (1: (1: (1) (1)) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1: (1) (1) (1) (1) (1) (1) (1)) (1)"}, {"heading": "5.4 Fast computation of the required embedding", "text": "In this section we will present an almost linear time algorithm to calculate all required distances used in the setting and grouping steps. (5.9) Our algorithm is based on the so-called heat core of a graph. (5.9) We consider the heat core as a geometrical embedding from V [G] to Rn defined byxt (u), 1), 1 (e \u2212 t \u00b7 t \u00b7 t \u00b7 t \u00b7 t \u00b7 t \u00b7 t \u00b7 t \u00b7 f1 (u), 1 \u00b7 t \u00b7 t \u00b7 f1 (u), \u00b7 t \u00b7 t \u00b7 t \u00b7 f1 (u), \u00b7 t \u00b7 t \u00b7 t \u00b7 f1 (u), \u00b7 t \u00b7 t \u00b7 t \u00b7 f1 (u), \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 t \u00b7 ifif (e \u2212 t \u00b7), e \u00b7 t \u00b7 t \u00b7 t \u00b7 ifif (5.10), (5.10) and define the heat core as a geometrical embedding from V [G] to Rn (defined byxt)."}, {"heading": "5.5 Proof of Theorem 1.3", "text": "We have proved in Section 5.4 that if it allows us to achieve the right values at any point, we have the ability to increase them. (...) We have proved in Section 5.4 that if it allows us to achieve the right values at any point. (...) We have the ability that we take the right steps at that point. (...) We have the opportunities that we have. (...) We have the opportunities that we have. (...) We have the opportunities that we have. (...) We have the opportunities. (...) We have the opportunities. (...) (...). (...) We have the opportunities. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...).). (...). (...).). (...).). (...).). (...). (...).). (...).). (...).). (...).). (...).). (...).). (...).). (...).). (...).). (...)..). (...).). (...). (...). (...).).). (...).). (...). (...).). (...).). (...). (...). (...).).). (...).). (...).).). (...). (...). (...).).). (...).).). (...). (...). (...).). (...).).). (...).).). (...). (...).). (...).."}, {"heading": "Acknowledgements", "text": "Part of this work was done while He Sun and Luca Zanetti were at the Max Planck Institute for Informatics and while He Sun was visiting the Simons Institute for the Theory of Computing at UC Berkeley. We would like to thank Luca Trevisan for revealing comments on an earlier version of our paper and Gary Miller for very helpful discussions on heat nuclei on diagrams. We would also like to thank Pavel Kolev and Kurt Mehlhorn [19] for pointing out an omission in an early version of Lemma 4.6. This omission was fixed locally without causing the statement of the main results."}], "references": [{"title": "A local algorithm for finding well-connected clusters", "author": ["Zeyuan Allen-Zhu", "Silvio Lattanzi", "Vahab S. Mirrokni"], "venue": "In 30th International Conference on Machine Learning", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Subexponential algorithms for unique games and related problems", "author": ["Sanjeev Arora", "Boaz Barak", "David Steurer"], "venue": "In 51st Annual IEEE Symposium on Foundations of Computer Science", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "The multiplicative weights update method: a meta-algorithm and applications", "author": ["Sanjeev Arora", "Elad Hazan", "Satyen Kale"], "venue": "Theory of Computing,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "A combinatorial, primal-dual approach to semidefinite programs", "author": ["Sanjeev Arora", "Satyen Kale"], "venue": "Annual ACM Symposium on Theory of Computing", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Expander flows, geometric embeddings and graph partitioning", "author": ["Sanjeev Arora", "Satish Rao", "Umesh V. Vazirani"], "venue": "J. ACM,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "k-means++: The advantages of careful seeding", "author": ["David Arthur", "Sergei Vassilvitskii"], "venue": "In 18th Annual ACM-SIAM Symposium on Discrete Algorithms", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Center-based clustering under perturbation stability", "author": ["Pranjal Awasthi", "Avrim Blum", "Or Sheffet"], "venue": "Information Processing Letters,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "A theoretical approach to the clustering selection problem. In Proceedings of the 4th MultiClust Workshop on Multiple Clusterings, Multi-view Data, and Multi-source Knowledge-driven Clustering, page", "author": ["Shai Ben-David"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "A local graph partitioning algorithm using heat kernel pagerank", "author": ["Fan R.K. Chung"], "venue": "Internet Mathematics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Image segmentation by clustering", "author": ["Guy B. Coleman", "Harry C. Andrews"], "venue": "Proceedings of the IEEE,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1979}, {"title": "An elementary proof of a theorem of Johnson and Lindenstrauss", "author": ["Sanjoy Dasgupta", "Anupam Gupta"], "venue": "Random Structures & Algorithms,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "The rotation of eigenvectors by a perturbation", "author": ["Chandler Davis", "William M. Kahan"], "venue": "iii. SIAM Journal on Numerical Analysis,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1970}, {"title": "Spectral concentration, robust k-center, and simple clustering", "author": ["Tamal K. Dey", "Alfred Rossi", "Anastasios Sidiropoulos"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Community detection in graphs", "author": ["Santo Fortunato"], "venue": "Physics Reports,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Matrix Analysis", "author": ["Roger A. Horn", "Charles R. Johnson"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Approximate nearest neighbors: towards removing the curse of dimensionality", "author": ["Piotr Indyk", "Rajeev Motwani"], "venue": "In 30th Annual ACM Symposium on Theory of Computing", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1998}, {"title": "On clusterings: Good, bad and spectral", "author": ["Ravi Kannan", "Santosh Vempala", "Adrian Vetta"], "venue": "Journal of the ACM,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "An almostlinear-time algorithm for approximate max flow in undirected graphs, and its multicommodity generalizations", "author": ["Jonathan A. Kelner", "Yin Tat Lee", "Lorenzo Orecchia", "Aaron Sidford"], "venue": "In 25th Annual ACM-SIAM Symposium on Discrete Algorithms", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "A note on spectral clustering", "author": ["Pavel Kolev", "Kurt Mehlhorn"], "venue": "CoRR, abs/1509.09188,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Improved Spectral Sparsification and Numerical Algorithms for SDD Matrices", "author": ["Ioannis Koutis", "Alex Levin", "Richard Peng"], "venue": "In 29th International Symposium on Theoretical Aspects of Computer Science", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Improved Cheeger\u2019s inequality: analysis of spectral partitioning algorithms through higher order spectral gap", "author": ["Tsz Chiu Kwok", "Lap Chi Lau", "Yin Tat Lee", "Shayan Oveis Gharan", "Luca Trevisan"], "venue": "In 45th Annual ACM Symposium on Theory of Computing", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Multi-way spectral partitioning and higher-order Cheeger inequalities", "author": ["James R. Lee", "Shayan Oveis Gharan", "Luca Trevisan"], "venue": "In 44th Annual ACM Symposium on Theory of Computing", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Multicommodity max-flow min-cut theorems and their use in designing approximation algorithms", "author": ["Frank T. Leighton", "Satish Rao"], "venue": "Journal of the ACM,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1999}, {"title": "Many sparse cuts via higher eigenvalues", "author": ["Anand Louis", "Prasad Raghavendra", "Prasad Tetali", "Santosh Vempala"], "venue": "In 44th Annual ACM Symposium on Theory of Computing", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Correlation clustering with noisy partial information", "author": ["Konstantin Makarychev", "Yury Makarychev", "Aravindan Vijayaraghavan"], "venue": "In 28th Conference on Learning Theory (COLT\u201915),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "Sparsest cuts and bottlenecks in graphs", "author": ["David W. Matula", "Farhad Shahrokhi"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1990}, {"title": "Spectral partitioning of random graphs", "author": ["Frank McSherry"], "venue": "In 42nd Annual IEEE Symposium on Foundations of Computer Science", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2001}, {"title": "On spectral clustering: Analysis and an algorithm", "author": ["Andrew Y. Ng", "Michael I. Jordan", "Yair Weiss"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2002}, {"title": "Approximating the exponential, the Lanczos method and an \u00d5(m)-time spectral algorithm for balanced separator", "author": ["Lorenzo Orecchia", "Sushant Sachdeva", "Nisheeth K Vishnoi"], "venue": "In 44th Annual ACM Symposium on Theory of Computing", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "On partitioning graphs via single commodity flows", "author": ["Lorenzo Orecchia", "Leonard J. Schulman", "Umesh V. Vazirani", "Nisheeth K. Vishnoi"], "venue": "In 40th Annual ACM Symposium on Theory of Computing", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "The effectiveness of Lloyd-type methods for the k-means problem", "author": ["Rafail Ostrovsky", "Yuval Rabani", "Leonard J. Schulman", "Chaitanya Swamy"], "venue": "Journal of the ACM,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Partitioning into expanders", "author": ["Shayan Oveis Gharan", "Luca Trevisan"], "venue": "In 25th Annual ACM-SIAM Symposium on Discrete Algorithms", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "Spectral clustering and the high-dimensional stochastic blockmodel", "author": ["Karl Rohe", "Sourav Chatterjee", "Bin Yu"], "venue": "The Annals of Statistics,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1878}, {"title": "Lectures on finite markov chains", "author": ["L. Saloff-Coste"], "venue": "Lectures on Probability Theory and Statistics,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1997}, {"title": "Breaking the multicommodity flow barrier for O( \u221a log n)-approximations to sparsest cut", "author": ["Jonah Sherman"], "venue": "In 50th Annual IEEE Symposium on Foundations of Computer Science", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2009}, {"title": "Normalized cuts and image segmentation", "author": ["Jianbo Shi", "Jitendra Malik"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2000}, {"title": "Graph sparsification by effective resistances", "author": ["Daniel A. Spielman", "Nikhil Srivastava"], "venue": "SIAM Journal on Computing,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1913}, {"title": "Spectral sparsification of graphs", "author": ["Daniel A. Spielman", "Shang-Hua Teng"], "venue": "SIAM Journal on Computing,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "Approximation algorithms for unique games", "author": ["Luca Trevisan"], "venue": "Theory of Computing,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2008}, {"title": "A tutorial on spectral clustering", "author": ["Ulrike von Luxburg"], "venue": "Statistics and Computing,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2007}, {"title": "A simple SVD algorithm for finding hidden partitions", "author": ["Van Vu"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2014}], "referenceMentions": [{"referenceID": 25, "context": "This problem is known to be NP-hard [26], and the current best approximation algorithm achieves an approximation ratio of O (\u221a log n ) [5].", "startOffset": 36, "endOffset": 40}, {"referenceID": 4, "context": "This problem is known to be NP-hard [26], and the current best approximation algorithm achieves an approximation ratio of O (\u221a log n ) [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 9, "context": "In computer vision, most image segmentation procedures are based on region-based merge and split [10], which in turn rely on partitioning graphs into multiple subsets [36].", "startOffset": 97, "endOffset": 101}, {"referenceID": 35, "context": "In computer vision, most image segmentation procedures are based on region-based merge and split [10], which in turn rely on partitioning graphs into multiple subsets [36].", "startOffset": 167, "endOffset": 171}, {"referenceID": 38, "context": "On a theoretical side, decomposing vertex/edge sets into multiple disjoint subsets is used in designing approximation algorithms for Unique Games [39], and efficient algorithms for graph problems [18, 23, 38].", "startOffset": 146, "endOffset": 150}, {"referenceID": 17, "context": "On a theoretical side, decomposing vertex/edge sets into multiple disjoint subsets is used in designing approximation algorithms for Unique Games [39], and efficient algorithms for graph problems [18, 23, 38].", "startOffset": 196, "endOffset": 208}, {"referenceID": 22, "context": "On a theoretical side, decomposing vertex/edge sets into multiple disjoint subsets is used in designing approximation algorithms for Unique Games [39], and efficient algorithms for graph problems [18, 23, 38].", "startOffset": 196, "endOffset": 208}, {"referenceID": 37, "context": "On a theoretical side, decomposing vertex/edge sets into multiple disjoint subsets is used in designing approximation algorithms for Unique Games [39], and efficient algorithms for graph problems [18, 23, 38].", "startOffset": 196, "endOffset": 208}, {"referenceID": 21, "context": "Despite widespread use of various graph partitioning schemes over the past decades, the quantitative relationship between the k-way expansion constant and the eigenvalues of the graph Laplacians were unknown until a sequence of very recent results [22, 24].", "startOffset": 248, "endOffset": 256}, {"referenceID": 23, "context": "Despite widespread use of various graph partitioning schemes over the past decades, the quantitative relationship between the k-way expansion constant and the eigenvalues of the graph Laplacians were unknown until a sequence of very recent results [22, 24].", "startOffset": 248, "endOffset": 256}, {"referenceID": 21, "context": "[22] proved the following higher-order Cheeger inequality: \u03bbk 2 6 \u03c1(k) 6 O(k) \u221a \u03bbk, (1.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 39, "context": "[40] and Section D in [14].", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[40] and Section D in [14].", "startOffset": 22, "endOffset": 26}, {"referenceID": 1, "context": "([2], Theorem 2.", "startOffset": 1, "endOffset": 4}, {"referenceID": 11, "context": "1), and can be considered as a stronger version of the well-known Davis-Kahan theorem [12].", "startOffset": 86, "endOffset": 90}, {"referenceID": 20, "context": "Specifically, it omits much of the machinery used in the proofs of higher-order and improved Cheeger inequalities [21, 22].", "startOffset": 114, "endOffset": 122}, {"referenceID": 21, "context": "Specifically, it omits much of the machinery used in the proofs of higher-order and improved Cheeger inequalities [21, 22].", "startOffset": 114, "endOffset": 122}, {"referenceID": 27, "context": "[28, 40].", "startOffset": 0, "endOffset": 8}, {"referenceID": 39, "context": "[28, 40].", "startOffset": 0, "endOffset": 8}, {"referenceID": 33, "context": "The heat kernel of a graph is a well-studied mathematical concept and is related to, for example, the study of random walks [34].", "startOffset": 124, "endOffset": 128}, {"referenceID": 28, "context": "Since the heat kernel distances between vertices can be approximated in nearly-linear time [29], this approach avoids the computation of eigenvectors for a large value of k.", "startOffset": 91, "endOffset": 95}, {"referenceID": 35, "context": "For instance, it is easy to see that \u03c1(k) and the normalized cut [36] studied in machine learning, which is defined as the sum of the conductance of all returned clusters, differ by at most a factor of k, and the normalized cut value of a k-way partition from spectral clustering can be derived from our results.", "startOffset": 65, "endOffset": 69}, {"referenceID": 6, "context": "[7, 8, 17, 25].", "startOffset": 0, "endOffset": 14}, {"referenceID": 7, "context": "[7, 8, 17, 25].", "startOffset": 0, "endOffset": 14}, {"referenceID": 16, "context": "[7, 8, 17, 25].", "startOffset": 0, "endOffset": 14}, {"referenceID": 24, "context": "[7, 8, 17, 25].", "startOffset": 0, "endOffset": 14}, {"referenceID": 35, "context": "Among these, our work is most closely related to spectral clustering, which is closely related to normalized or low conductance cuts [36].", "startOffset": 133, "endOffset": 137}, {"referenceID": 31, "context": "Oveis Gharan and Trevisan [32] formulate the notion of clusters with respect to the inner and outer conductance: a cluster S should have low outer conductance, and the conductance of the induced subgraph by S should be high.", "startOffset": 26, "endOffset": 30}, {"referenceID": 12, "context": "[13] studies the properties of the spectral embedding for graphs having a gap between \u03bbk and \u03bbk+1 and presents a k-way partition algorithm, which is based on k-center clustering and is similar in spirit to our work.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "The heat kernel has been used in previous algorithms on local partitioning [9], balanced separators [29].", "startOffset": 75, "endOffset": 78}, {"referenceID": 28, "context": "The heat kernel has been used in previous algorithms on local partitioning [9], balanced separators [29].", "startOffset": 100, "endOffset": 104}, {"referenceID": 29, "context": "It also plays a key role in current efficient approximation algorithms for finding low conductance cuts [30, 35].", "startOffset": 104, "endOffset": 112}, {"referenceID": 34, "context": "It also plays a key role in current efficient approximation algorithms for finding low conductance cuts [30, 35].", "startOffset": 104, "endOffset": 112}, {"referenceID": 2, "context": "However, most of these theoretical guarantees are through the matrix multiplicative weights update framework [3, 4].", "startOffset": 109, "endOffset": 115}, {"referenceID": 3, "context": "However, most of these theoretical guarantees are through the matrix multiplicative weights update framework [3, 4].", "startOffset": 109, "endOffset": 115}, {"referenceID": 26, "context": "For instance, in the Stochastic Block Model (SBM) [27], the input graph with k clusters is generated according to probabilities p and q with p > q: an edge between any two vertices within the same cluster is placed with probability p, and an edge between any two vertices from different clusters is placed with probability q.", "startOffset": 50, "endOffset": 54}, {"referenceID": 26, "context": "It is proven that spectral algorithms give the correct clustering for certain ranges of p and q [27, 33, 41].", "startOffset": 96, "endOffset": 108}, {"referenceID": 32, "context": "It is proven that spectral algorithms give the correct clustering for certain ranges of p and q [27, 33, 41].", "startOffset": 96, "endOffset": 108}, {"referenceID": 40, "context": "It is proven that spectral algorithms give the correct clustering for certain ranges of p and q [27, 33, 41].", "startOffset": 96, "endOffset": 108}, {"referenceID": 11, "context": "For this reason, standard perturbation theorems used in the analysis of algorithms for SBMs, such as the Davis-Kahan theorem [12], cannot be always applied, and ad-hoc arguments specific for graphs, like our structure theorem (Theorem 1.", "startOffset": 125, "endOffset": 129}, {"referenceID": 1, "context": "2 of [2].", "startOffset": 5, "endOffset": 8}, {"referenceID": 14, "context": "4, [15]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "We point out that it was shown in [21] that the first k eigenvectors can be approximated by a (2k + 1)-step function.", "startOffset": 34, "endOffset": 38}, {"referenceID": 21, "context": "Notice that this embedding is similar with the one used in [22], with the only difference that F (u) is not normalized and so it is not necessarily a unit vector.", "startOffset": 59, "endOffset": 63}, {"referenceID": 10, "context": "[11]), we can also always assume that the dimension of the embedding {x(u)}u\u2208V [G] is d = O(log n).", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6, 31]).", "startOffset": 0, "endOffset": 7}, {"referenceID": 30, "context": "[6, 31]).", "startOffset": 0, "endOffset": 7}, {"referenceID": 15, "context": "To speed it up, we apply \u03b5-approximate nearest neighbor data structures (\u03b5-NNS) [16], whose formal description is as follows: Problem 1 (\u03b5-approximate nearest neighbor problem).", "startOffset": 80, "endOffset": 84}, {"referenceID": 15, "context": "5 ([16]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "8 uses the algorithm for approximating the matrix exponential in [29] as a subroutine, whose performance is summarised in Theorem 5.", "startOffset": 65, "endOffset": 69}, {"referenceID": 28, "context": "9 ([29]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 19, "context": "[20] and [37]), we obtain an O(\u03b5\u22122 \u00b7 log n) \u00d7 n Gaussian matrix Q, such that with high probability it holds for all u, v that (1\u2212 \u03b5) \u2016Z (\u03beu \u2212 \u03bev)\u2016 6 \u2016QZ (\u03beu \u2212 \u03bev)\u2016 6 (1 + \u03b5) \u2016Z (\u03beu \u2212 \u03bev)\u2016 .", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "[20] and [37]), we obtain an O(\u03b5\u22122 \u00b7 log n) \u00d7 n Gaussian matrix Q, such that with high probability it holds for all u, v that (1\u2212 \u03b5) \u2016Z (\u03beu \u2212 \u03bev)\u2016 6 \u2016QZ (\u03beu \u2212 \u03bev)\u2016 6 (1 + \u03b5) \u2016Z (\u03beu \u2212 \u03bev)\u2016 .", "startOffset": 9, "endOffset": 13}, {"referenceID": 28, "context": "We can then run the approximate exponential algorithm from [29] O(log n) times, where each time we use a different row of Q as input.", "startOffset": 59, "endOffset": 63}, {"referenceID": 28, "context": "A similar intuition which views the heat kernel embedding as a weighted combination of multiple eigenvectors was discussed in [29].", "startOffset": 126, "endOffset": 130}, {"referenceID": 18, "context": "We also would like to thank Pavel Kolev, and Kurt Mehlhorn [19] for pointing out an omission in an early version of Lemma 4.", "startOffset": 59, "endOffset": 63}], "year": 2017, "abstractText": "In this paper we study variants of the widely used spectral clustering that partitions a graph into k clusters by (1) embedding the vertices of a graph into a low-dimensional space using the bottom eigenvectors of the Laplacian matrix, and (2) grouping the embedded points into k clusters via k-means algorithms. We show that, for a wide class of graphs, spectral clustering gives a good approximation of the optimal clustering. While this approach was proposed in the early 1990s and has comprehensive applications, prior to our work similar results were known only for graphs generated from stochastic models. We also give a nearly-linear time algorithm for partitioning well-clustered graphs based on computing a matrix exponential and approximate nearest neighbor data structures.", "creator": "LaTeX with hyperref package"}}}