{"id": "1411.2057", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2014", "title": "Online Collaborative-Filtering on Graphs", "abstract": "A common phenomena in modern recommendation systems is the use of feedback from one user to infer the `value' of an item to other users. This results in an exploration vs. exploitation trade-off, in which items of possibly low value have to be presented to users in order to ascertain their value. Existing approaches to solving this problem focus on the case where the number of items are small, or admit some underlying structure -- it is unclear, however, if good recommendation is possible when dealing with content-rich settings with unstructured content.", "histories": [["v1", "Fri, 7 Nov 2014 22:52:19 GMT  (185kb,D)", "http://arxiv.org/abs/1411.2057v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["siddhartha banerjee", "sujay sanghavi", "sanjay shakkottai"], "accepted": false, "id": "1411.2057"}, "pdf": {"name": "1411.2057.pdf", "metadata": {"source": "CRF", "title": "Online Collaborative Filtering on Graphs", "authors": ["Siddhartha Banerjee", "Sujay Sanghavi", "Sanjay Shakkottai"], "emails": ["sidb@stanford.edu", "sanghavi@mail.utexas.edu,", "shakkott@mail.utexas.edu"], "sections": [{"heading": null, "text": "Online Collaborative Filtering on Graphs Siddhartha BanerjeeDepartment of Management Science and Engineering, Stanford University, Stanford, CA 94025 sidb @ stanford.eduSujay Sanghavi, Sanjay Shakkottai Department of ECE, The University of Texas at Austin, Austin, TX 78705sanghavi @ mail.utexas.edu, shakkott @ mail.utexas.eduA common phenomenon in modern recommendation systems is the use of feedback from a user to derive the \"value\" ofan item to other users, resulting in an exploration vs. exploitation trade-off in which items of potentially low value need to be presented to users to determine their value. Existing approaches to solving this problem focus on the case where the number of items is small, or admit some underlying structure - it is unclear whether good recommendations are possible in dealing with content-rich set unstructured content."}, {"heading": "1. Introduction", "text": "This year, as never before in the history of the city, where it has come to the point where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a, a place, a place, a place, a place, a, a place, a place, a place, a place, a, a, a place, a place, a place, a, a, a place, a, a, a place, a, a, a, a, a place, a, a, a place, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a"}, {"heading": "1.1. Summary of Our Contributions", "text": "In fact, the fact is that most of us will be able to move to another world in which we are able to change the world and in which we are able to change the world."}, {"heading": "2. The Finite-Population Setting", "text": "First, we look at an environment with a limited population, where the number of users and articles is determined and users arrive randomly, which is a good model for certain problems in curating content such as news aggregators (e.g. Google News), where a large number of articles appear together (at the beginning of a day) and expire at the end of the day - in the meantime, users appear randomly throughout the day. In addition, it allows us to present our main ideas in a more concise form, avoiding the technical aspects of the Infinite setting while conveying the key ideas and challenges."}, {"heading": "2.1. System Model", "text": "Access Graph: G (NU, NI, E) represents the (given) two-sided reward for access Graph (u) for access Graph (with | NU | = nU and | NI | = nI). For a user u-NU we define his neighborhood as N (u): = {i-NI | (u, i), and degree du = | N (u) |; similarly for a user i-NI we can use N (i) and di. Items are always present in the system while users enter the system according to a uniform random permutation.Item Exploration: Each item has an associated non-negative value V (i), which is unknown from the outset; as always when presented to a user, V (i) is revealed exactly. Upon arrival, a user is presented with a series of r items from N (u)."}, {"heading": "2.2. Exploration via Balanced Item-Partitions:", "text": "For each user, a balanced item partition is a solution to the problem: \"We have a semi-matching M, we define the user load as dM (u).\" The algorithm partition M is a solution for optimizing the problem: \"We have a semi-matching M, we define the user load as dM (u).M\" We define the user load as dM (u).M \"We define the user load as dM (u).M\" We define the user load as dM (u).M \"Then a balanced item partition for optimizing the problem."}, {"heading": "2.3. Exploration via Inverse-Degree Sampling:", "text": "Although we have a good competitive relationship, BPExp has several disadvantages: 1. Pre-processing to generate a balanced item partition is technically expensive for large graphs. 2. The pre-processing stage is inherently centralized and requires extensive coordination between users. This can be impractical (due to complexity, privacy concerns, etc.).3 The main idea is that upon arrival, a user selects an adjacent element for exploration with a probability that is proportional to the degree of the item partition. This can be done with minimal local knowledge of the graphics (in fact, the graphic information is often publicly available, e.g. Folger onFacebook / Google +).The resulting competition rate is weaker - especially the Makespan d graphics (in fact, the graphics are often publicly available to friends on Facebook / Google +)."}, {"heading": "3. The Infinite-Horizon Setting", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. System Model", "text": "We are now looking at a setting in which the system evolves over time with the arrivals and departures of users - this is a more natural model for social network news feeds and some content curation sites such as Digg / Reddit, where content is posted in a more continuous manner. Access Diagram: We get an underlying element in social networks, access to user-generated content is limited by the \"follower\" graphics - a user can only see updates from people he follows. On the other hand, a content curation site can be viewed as a graph between users and article topics, with edges incident on a user encoding the personalized topics it is interested in."}, {"heading": "3.2. Uniform Latest-Item Exploration", "text": "Considering our results for the Infinite Population, it is the first idea for the Infinite Horizon setting (i). (i) We assume that we will apply the IDExp algorithms for the Infinite Population (i). (i) We assume that we cannot define the Opening Policies as the first Opening Class in this context. (i) We assume that the first Opening Class according to Ti is from an adjacent user (i.e.) S1) = min {s and Ti the arrival times of the visit and the position i (s). (i) Then we can define the first Opening Class according to Ti. (i.e.) S1) = min {s, i (s).N (s)})."}, {"heading": "4. Converse Results", "text": "In fact, it is in such a way that we will see ourselves in a position to be in a position to be in a position to be in a position to be in a position to be in another world, in which we are in a position to be in another world, in which we are in a position to be in another world, in which we are in a position to be in a world, in which we are in a position to enter into another world, in which we are in a position to be in another world, in which we are in a position, in which we are in a position, in which we are in a position, in which we are in a world, in which we enter into a world, in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we, in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are, in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which are in which we are in which we are in which we are in which we are we are in which are in which we are in which are in which we are in which we are in which we are in which we are in which we are in which are in which we are in which we are in which we are in which are in which we are in which we live in which we are in which we are in which we are in which we are in which we are in which we are in which we are in which are in which we are in which are in which we are in which are in which we are in which are in which are in which are in which we are in which"}, {"heading": "4.1. Proof Outlines of Converse Results:", "text": "The most important technique we use to achieve reverse results is Yao's minimax principle (see Motwani and Raghavan (1997): Essentially, it states that the competitive ratio of the optimal deterministic algorithm for a given random input (where the measurement value via inputs is known to the algorithm) is an upper limit for the competitive ratio. In the case of theorems 4, 5, the underlying graph is the complete two-sided graph for nU \u00b7 nI nodes: For an i evenly selected by NI, we now set V (u, i) = 1, and V (u, i) = 0 for all other (u, i) pairs. Note that the above choice implies that the reward function V is a binary, unified reward function. Theorem 5 is more involved - essentially, we show that the competitive relationship above is linked by the simplified \"search problem,\" which is limited to the 1997 node, an item and the node being selected."}, {"heading": "5. Discussion and Extensions", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Inferring Item Values from Multiple Ratings", "text": "First, we have assumed that the algorithm knows the value of an element once it has been examined by at least one user. (However, as we mentioned in Section 1, a more general condition would be that once an element is viewed by at least one user, its value is known to the algorithm within a multiplicative factor of (1), for some users (1) visiting another user. (This generalizes the case considered so far, which corresponds to f = 1 and (1) = 0 - we will now show how we can modify our algorithms to handle this more general setting. We will now define an element to be examined before exploring if it is presented to at least f users - the set of pre-researched items is still explI. To provide competitive ratio guarantees for this setting, we modify the algorithms as follows: \u2022 For each user (or visit s in the Intuitive Horizon setting), the algorithm is chosen."}, {"heading": "5.2. More General Reward Models", "text": "In the work so far, we have mainly focused on the universal reward scenario, where the reward given by item i to all adjacent users is V (i). This model is studied to facilitate exposure and notation; however, our evidence permits more general reward functions: Personalization: item i has an intrinsic value V (i), but gives the adjacent user u a reward of V (u, i) = fui (V (i)), where fui (\u00b7) are known to the algorithm (non-negative, invertable) functions, which can detect different preferences of a user over other items. Collaborative Ranking: In several areas, the reward earned on the recommendation of an item may not be quantifiable - however, the algorithm may still be successful if it is able to determine a ranking of the items examined from user feedback. This is reminiscent of the secretary problem allowed by Babaim (2008) and Jagaial (2008), as well as some of the others."}, {"heading": "6. Related Work", "text": "There are two major classes of problems that are listed under the title \"Bandit Problems - Temporary Bandits and Limitless Bandits.\" (Or Markovian) bandits.Markovian bandits (Eg. Gittins (1979) focus on the underlying settings in which each is based on a reward, with most of the work in this space not capturing the dynamics of the user and the exploration exploit trade-off. (2010), Jagabathula and Shah (2008); in contrast, our model captures the fact that there is a selection of what user data can be collected, and this selection affects performance. Bandit algorithms: Bandit models refer to settings in which the selection of an action (or an arm) from a series of actions produces both a reward and feedback about the system. There are two major classes of problems that go under the title Bandit Problems - Temporary Bandit Problems - Bandits-Temporary Horizon and Bandits-Problems."}, {"heading": "7. Proofs of Competitive-Ratio Guarantees", "text": "First, we briefly recall some definitions from before. (In the finitepulation model, we get a diagram G (NU, NI, E) user NU and items NI (| NU | = nU, | NI | = nI). In the infinity horizon model, the definitions remain essentially the same, except that instead of the items, we have a series of items that we use as item classes NC (where | NC | = nC). Furthermore, we can define the neighborhood of a user visit as items of neighboring classes in the system (and similar for items). (In the finite population model, when a user arrives, the referral algorithm A presents r items {iA1 (u)."}, {"heading": "7.1. A Preliminary Lemma", "text": "We first specify and prove a problem that we apply in all our proofs - it includes the idea that it is enough to be competitive to ensure that for each user with approximately equal probability, the algorithm recommends the corresponding article with the highest value. For easier representation, we specify the problem for setting the endless population. In setting the end horizon, we can achieve an identical result with the user u, which is replaced by user visits, and depending on the items that are currently present in the system during the visit. Gived algorithm A and reward function V, for any pair (u, i) where I define N (u) we define 1Au \u2192 i as a random variable that is 1 when user u is shown by algorithm A, and otherwise 0. Then we have: LEMMA 1. Gived [LEMMA 1. 1. Gived graphics and reward function V, then for any algorithm that we have (RAE)."}, {"heading": "7.2. Performance Analysis: Finite-Population Setting", "text": "Before presenting our proofs, remember that our algorithms share the following structure: \u2022 We randomly divide the r-recommendations between exploration and exploitation recommendations (i.e., the number of exploration slots R1 and R2). \u2022 For the exploitation step, the algorithm levers of our assumption (i.e., the number of exploration slots R1 and R2 can always be identified. \u2022 For the exploration step, we have proposed 3 different exploration guidelines (in algorithms 1,2 and 3), which are designed to use the topology and randomness of user arrivals to ensure balanced exploration: for all adjacent user-item pairs, we can reduce the probability that the item will be explored before the user reaches the system. We also need an additional definition: in the finite population setting, we define a user-item pattern to be an arrival pattern."}, {"heading": "7.3. Performance Analysis: Infinite-Horizon Setting", "text": "Finally, we turn to the infinite horizon setting based on picking (and before it expires), picking (and thus picking), remembering that we now have a graph between users NU and item classes NC, with user visits X-N + and items I-N +. Each item I has a consecutive item class C (i) (according to the underlying independent poisson processes), a lifetime procedure (equal for all items), and a reward function V (i). More precisely, for each item class C, we define Vc (k) to be the first visit of a neighboring user u N (i) after item i has reached the system (and before it expires). Complementarily, we define the latest item set L (s)."}, {"heading": "Appendix A: Converse Results", "text": "s Minimax principle (referring to Motwani and Raghavan (1997)): the competitive ratio of the optimal deterministic algorithm for a given randomized input is an upper limit for the competitive ratio. Note that the algorithms are aware of the input distribution. (u, i) Upper limit: the competitive ratio for the full bipartite graph: Proof of Theorem 4. Consider the full bipartite graph G (NU, NI, E), i.e., E = (u, i) Upper limit: NU, i, NI}, with the full bipartite graph: Proof Theorem 4. Consider the full bipartite graph G (NI, NI, E), i.e."}, {"heading": "Appendix B: Inferring Item-Values from Multiple Ratings", "text": "The proof for Theorem 8 As before, for k [r], we define 1ULExp-fs (I \u0445 k (s) to be 1 if the user corresponding to the visit s is presented with the kth highest-rated object available. Suppose the value of an article is exactly known after f-explorations. Then, from Lemma 1, we have this for each visit s, E [Rr (s)] \u2265 E [mink] E [r] E [1 ULExp-f s (s) R (s) R (s) r (s), where the inner expectation lies above the randomness in the algorithm, and the outer expectation is above the randomness in the sample path. Since we now assume that algorithms know the value of pre-explored objects (defined now as those that have been explored at least f times), we have their value within a multiplicative factor of (1 \u00b1 k (plk), then we have the Explk value if we assume that I have the oration."}, {"heading": "Acknowledgments", "text": "This work was supported by NSF grants CNS-1017525 and CNS-1320175 as well as the grant from the Army Research Office W911NF-11-1-0265."}], "references": [{"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["Auer", "Peter", "Nicol\u00f2 Cesa-Bianchi", "Paul Fischer."], "venue": "Machine Learning 47(2-3) 235\u2013256. 3, 17", "citeRegEx": "Auer et al\\.,? 2002", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Online auctions and generalized secretary problems", "author": ["Babaioff", "Moshe", "Nicole Immorlica", "David Kempe", "Robert Kleinberg."], "venue": "SIGecom Exchanges 7(2). 16, 17", "citeRegEx": "Babaioff et al\\.,? 2008", "shortCiteRegEx": "Babaioff et al\\.", "year": 2008}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["Bubeck", "S\u00e9bastien", "Nicol\u00f2 Cesa-Bianchi."], "venue": "Foundations and Trends R", "citeRegEx": "Bubeck et al\\.,? 2008", "shortCiteRegEx": "Bubeck et al\\.", "year": 2008}, {"title": "Competitive weighted matching in transversal matroids", "author": ["Dimitrov", "Nedialko B.", "C. Greg Plaxton."], "venue": "ICALP (1). 397\u2013408. 17", "citeRegEx": "Dimitrov et al\\.,? 2008", "shortCiteRegEx": "Dimitrov et al\\.", "year": 2008}, {"title": "Efficient optimal learning for contextual bandits", "author": ["Dud\u0131\u0301k", "Miroslav", "Daniel Hsu", "Satyen Kale", "Nikos Karampatziakis", "John Langford", "Lev Reyzin", "Tong Zhang"], "venue": "UAI. 169\u2013178", "citeRegEx": "Dud\u0131\u0301k et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dud\u0131\u0301k et al\\.", "year": 2011}, {"title": "Faster algorithms for semi-matching problems", "author": ["J. Fakcharoenphol", "B. Laekhanukit", "D. Nanongkai."], "venue": "Automata, Languages and Programming 176\u2013187. 7", "citeRegEx": "Fakcharoenphol et al\\.,? 2010", "shortCiteRegEx": "Fakcharoenphol et al\\.", "year": 2010}, {"title": "Bandit processes and dynamic allocation indices", "author": ["Gittins", "John C."], "venue": "Journal of the Royal Statistical Society. Series B (Methodological) 148\u2013177. 17", "citeRegEx": "Gittins and C.,? 1979", "shortCiteRegEx": "Gittins and C.", "year": 1979}, {"title": "Bounds for certain multiprocessing anomalies", "author": ["Graham", "Ronald L."], "venue": "Bell System Tech. J. 45. 1563\u20131581. 7, 21", "citeRegEx": "Graham and L.,? 1966", "shortCiteRegEx": "Graham and L.", "year": 1966}, {"title": "Semi-matchings for bipartite graphs and load balancing", "author": ["N. Harvey", "R. Ladner", "L. Lov\u00e1sz", "T. Tamir."], "venue": "Algorithms and data structures 294\u2013306. 7", "citeRegEx": "Harvey et al\\.,? 2003", "shortCiteRegEx": "Harvey et al\\.", "year": 2003}, {"title": "Inferring rankings under constrained sensing", "author": ["S. Jagabathula", "D. Shah."], "venue": "Advances in Neural Information Processing Systems 21 753\u2013760. 4, 16, 17", "citeRegEx": "Jagabathula and Shah.,? 2008", "shortCiteRegEx": "Jagabathula and Shah.", "year": 2008}, {"title": "Matrix completion from noisy entries", "author": ["R.H. Keshavan", "A. Montanari", "S. Oh."], "venue": "The Journal of Machine Learning Research 11 2057\u20132078. 4, 16", "citeRegEx": "Keshavan et al\\.,? 2010", "shortCiteRegEx": "Keshavan et al\\.", "year": 2010}, {"title": "Regret bounds for sleeping experts and bandits", "author": ["R. Kleinberg", "A. Niculescu-Mizil", "Y. Sharma."], "venue": "Machine learning 80(2-3) 245\u2013272. 17", "citeRegEx": "Kleinberg et al\\.,? 2010", "shortCiteRegEx": "Kleinberg et al\\.", "year": 2010}, {"title": "Asymptotically efficient adaptive allocation rules", "author": ["Lai", "Tze Leung", "Herbert Robbins."], "venue": "Advances in applied mathematics 6(1) 4\u201322. 17", "citeRegEx": "Lai et al\\.,? 1985", "shortCiteRegEx": "Lai et al\\.", "year": 1985}, {"title": "Adwords and generalized on-line matching", "author": ["Mehta", "Aranyak", "Amin Saberi", "Umesh Vazirani", "Vijay Vazirani."], "venue": "FOCS \u201905: Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science. 264\u2013273. 17", "citeRegEx": "Mehta et al\\.,? 2005", "shortCiteRegEx": "Mehta et al\\.", "year": 2005}, {"title": "Randomized Algorithms", "author": ["Motwani", "Rajeev", "Prabhakar Raghavan."], "venue": "Cambridge University Press. 14, 28", "citeRegEx": "Motwani et al\\.,? 1997", "shortCiteRegEx": "Motwani et al\\.", "year": 1997}, {"title": "Predicting the popularity of online content", "author": ["Szabo", "Gabor", "Bernardo A Huberman."], "venue": "Communications of the ACM 53(8) 80\u201388. 3", "citeRegEx": "Szabo et al\\.,? 2010", "shortCiteRegEx": "Szabo et al\\.", "year": 2010}, {"title": "Patterns of temporal variation in online media", "author": ["Yang", "Jaewon", "Jure Leskovec."], "venue": "Proceedings of the fourth ACM international conference on Web search and data mining. ACM, 177\u2013186. 4", "citeRegEx": "Yang et al\\.,? 2011", "shortCiteRegEx": "Yang et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "d reward from some distribution with unknown mean (Auer et al. (2002); see also Bubeck and Cesa-Bianchi (2008) for a survey of the field).", "startOffset": 51, "endOffset": 70}, {"referenceID": 0, "context": "d reward from some distribution with unknown mean (Auer et al. (2002); see also Bubeck and Cesa-Bianchi (2008) for a survey of the field).", "startOffset": 51, "endOffset": 111}, {"referenceID": 9, "context": "Furthermore, work on static recommendation (Keshavan et al. (2010), Jagabathula and Shah (2008)) also provide guarantees for learning item-value from a few ratings under alternate structural assumptions; these observations tie in well with our model.", "startOffset": 44, "endOffset": 67}, {"referenceID": 9, "context": "(2010), Jagabathula and Shah (2008)) also provide guarantees for learning item-value from a few ratings under alternate structural assumptions; these observations tie in well with our model.", "startOffset": 8, "endOffset": 36}, {"referenceID": 8, "context": "The above problem is known in different communities as the minimum makespan problem (Graham (1966)), or optimal semi-matching problem (Harvey et al. (2003)) \u2013 we henceforth refer to d\u2217(G) as the makespan", "startOffset": 135, "endOffset": 156}, {"referenceID": 5, "context": "O(m \u221a n logn) (Fakcharoenphol et al. (2010)), where m= |E|, n= nU +nI .", "startOffset": 15, "endOffset": 44}, {"referenceID": 1, "context": "This is reminiscent of the Secretary problem (Babaioff et al. (2008)), and also allows for techniques such as in (Jagabathula and Shah (2008)).", "startOffset": 46, "endOffset": 69}, {"referenceID": 1, "context": "This is reminiscent of the Secretary problem (Babaioff et al. (2008)), and also allows for techniques such as in (Jagabathula and Shah (2008)).", "startOffset": 46, "endOffset": 142}, {"referenceID": 1, "context": "This is reminiscent of the Secretary problem (Babaioff et al. (2008)), and also allows for techniques such as in (Jagabathula and Shah (2008)). Probabilistic Predictability: In many cases, we may be only able to identify the top item for a user with some probability Ppred; for example, in collaborative filtering algorithms such as matrix completion (Keshavan et al. (2010)).", "startOffset": 46, "endOffset": 375}, {"referenceID": 10, "context": "Instead, the dominant view is one of taking the user feedback data as a static given (Keshavan et al. (2010),", "startOffset": 86, "endOffset": 109}, {"referenceID": 0, "context": ", r = 1) \u2013 then a bandit algorithm will sample all items at-least once (in particular, the standard UCB algorithm of Auer et al. (2002) will sample each arm once just during initialization), thereby getting a competitive-ratio of \u03b3 =O(1/n)\u2192 0.", "startOffset": 117, "endOffset": 136}, {"referenceID": 0, "context": ", r = 1) \u2013 then a bandit algorithm will sample all items at-least once (in particular, the standard UCB algorithm of Auer et al. (2002) will sample each arm once just during initialization), thereby getting a competitive-ratio of \u03b3 =O(1/n)\u2192 0. On the other hand, the algorithms we present in this work achieve a competitive-ratio of 1 8 . A notion of an access graph is incorporated in some bandit models such as the Contextual Bandits (Dud\u0131\u0301k et al. (2011)) or Sleeping Bandits (Kleinberg et al.", "startOffset": 117, "endOffset": 458}, {"referenceID": 0, "context": ", r = 1) \u2013 then a bandit algorithm will sample all items at-least once (in particular, the standard UCB algorithm of Auer et al. (2002) will sample each arm once just during initialization), thereby getting a competitive-ratio of \u03b3 =O(1/n)\u2192 0. On the other hand, the algorithms we present in this work achieve a competitive-ratio of 1 8 . A notion of an access graph is incorporated in some bandit models such as the Contextual Bandits (Dud\u0131\u0301k et al. (2011)) or Sleeping Bandits (Kleinberg et al. (2010)) models, the graph and user dynamics are assumed arbitrary.", "startOffset": 117, "endOffset": 504}, {"referenceID": 0, "context": ", r = 1) \u2013 then a bandit algorithm will sample all items at-least once (in particular, the standard UCB algorithm of Auer et al. (2002) will sample each arm once just during initialization), thereby getting a competitive-ratio of \u03b3 =O(1/n)\u2192 0. On the other hand, the algorithms we present in this work achieve a competitive-ratio of 1 8 . A notion of an access graph is incorporated in some bandit models such as the Contextual Bandits (Dud\u0131\u0301k et al. (2011)) or Sleeping Bandits (Kleinberg et al. (2010)) models, the graph and user dynamics are assumed arbitrary. The graph is not used to inform the algorithm design except in that it constrains what items can be shown \u2013 essentially this corresponds to having arbitrary access-constraints, which leads to the results being pessimistic. In our setup, on the other hand, imposing natural stochastic assumptions on user/item dynamics leads to much stronger competitive-ratio guarantees. Online Matching and its Variants: Although having the appearance of a bandit problem, our setting is in fact much closer in spirit to certain online optimization problems on graphs. Online auction design problems (Mehta et al. (2005)) incorporate the fact that an item can be displayed to multiple users, constrained by an underlying graph.", "startOffset": 117, "endOffset": 1169}, {"referenceID": 0, "context": ", r = 1) \u2013 then a bandit algorithm will sample all items at-least once (in particular, the standard UCB algorithm of Auer et al. (2002) will sample each arm once just during initialization), thereby getting a competitive-ratio of \u03b3 =O(1/n)\u2192 0. On the other hand, the algorithms we present in this work achieve a competitive-ratio of 1 8 . A notion of an access graph is incorporated in some bandit models such as the Contextual Bandits (Dud\u0131\u0301k et al. (2011)) or Sleeping Bandits (Kleinberg et al. (2010)) models, the graph and user dynamics are assumed arbitrary. The graph is not used to inform the algorithm design except in that it constrains what items can be shown \u2013 essentially this corresponds to having arbitrary access-constraints, which leads to the results being pessimistic. In our setup, on the other hand, imposing natural stochastic assumptions on user/item dynamics leads to much stronger competitive-ratio guarantees. Online Matching and its Variants: Although having the appearance of a bandit problem, our setting is in fact much closer in spirit to certain online optimization problems on graphs. Online auction design problems (Mehta et al. (2005)) incorporate the fact that an item can be displayed to multiple users, constrained by an underlying graph. However, in such problems the node weights (bids) are known, which often allows greedy algorithms to be constant-factor competitive. Related problems include the generalized secretary problem (Babaioff et al. (2008)) and online transversal-matroid selection (Dimitrov and Plaxton (2008)); both are", "startOffset": 117, "endOffset": 1492}, {"referenceID": 0, "context": ", r = 1) \u2013 then a bandit algorithm will sample all items at-least once (in particular, the standard UCB algorithm of Auer et al. (2002) will sample each arm once just during initialization), thereby getting a competitive-ratio of \u03b3 =O(1/n)\u2192 0. On the other hand, the algorithms we present in this work achieve a competitive-ratio of 1 8 . A notion of an access graph is incorporated in some bandit models such as the Contextual Bandits (Dud\u0131\u0301k et al. (2011)) or Sleeping Bandits (Kleinberg et al. (2010)) models, the graph and user dynamics are assumed arbitrary. The graph is not used to inform the algorithm design except in that it constrains what items can be shown \u2013 essentially this corresponds to having arbitrary access-constraints, which leads to the results being pessimistic. In our setup, on the other hand, imposing natural stochastic assumptions on user/item dynamics leads to much stronger competitive-ratio guarantees. Online Matching and its Variants: Although having the appearance of a bandit problem, our setting is in fact much closer in spirit to certain online optimization problems on graphs. Online auction design problems (Mehta et al. (2005)) incorporate the fact that an item can be displayed to multiple users, constrained by an underlying graph. However, in such problems the node weights (bids) are known, which often allows greedy algorithms to be constant-factor competitive. Related problems include the generalized secretary problem (Babaioff et al. (2008)) and online transversal-matroid selection (Dimitrov and Plaxton (2008)); both are", "startOffset": 117, "endOffset": 1563}], "year": 2014, "abstractText": "A common phenomena in modern recommendation systems is the use of feedback from one user to infer the \u2018value\u2019 of an item to other users. This results in an exploration vs. exploitation trade-off, in which items of possibly low value have to be presented to users in order to ascertain their value. Existing approaches to solving this problem focus on the case where the number of items are small, or admit some underlying structure \u2013 it is unclear, however, if good recommendation is possible when dealing with content-rich settings with unstructured content. We consider this problem under a simple natural model, wherein the number of items and the number of item-views are of the same order, and an \u2018access-graph\u2019 constrains which user is allowed to see which item. Our main insight is that the presence of the access-graph in fact makes good recommendation possible \u2013 however this requires the exploration policy to be designed to take advantage of the access-graph. Our results demonstrate the importance of \u2018serendipity\u2019 in exploration, and how higher graph-expansion translates to a higher quality of recommendations; it also suggests a reason why in some settings, simple policies like Twitter\u2019s \u2018Latest-First\u2019 policy achieve a good performance. From a technical perspective, our model presents a way to study exploration-exploitation tradeoffs in settings where the number of \u2018trials\u2019 and \u2018strategies\u2019 are large (potentially infinite), and more importantly, of the same order. Our algorithms admit competitive-ratio guarantees which hold for the worst-case user, under both finite-population and infinite-horizon settings, and are parametrized in terms of properties of the underlying graph. Conversely, we also demonstrate that improperly-designed policies can be highly sub-optimal, and that in many settings, our results are order-wise optimal.", "creator": "LaTeX with hyperref package"}}}