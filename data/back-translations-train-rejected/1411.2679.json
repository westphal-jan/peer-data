{"id": "1411.2679", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2014", "title": "Inferring User Preferences by Probabilistic Logical Reasoning over Social Networks", "abstract": "We propose a framework for inferring the latent attitudes or preferences of users by performing probabilistic first-order logical reasoning over the social network graph. Our method answers questions about Twitter users like {\\em Does this user like sushi?} or {\\em Is this user a New York Knicks fan?} by building a probabilistic model that reasons over user attributes (the user's location or gender) and the social network (the user's friends and spouse), via inferences like homophily (I am more likely to like sushi if spouse or friends like sushi, I am more likely to like the Knicks if I live in New York). The algorithm uses distant supervision, semi-supervised data harvesting and vector space models to extract user attributes (e.g. spouse, education, location) and preferences (likes and dislikes) from text. The extracted propositions are then fed into a probabilistic reasoner (we investigate both Markov Logic and Probabilistic Soft Logic). Our experiments show that probabilistic logical reasoning significantly improves the performance on attribute and relation extraction, and also achieves an F-score of 0.791 at predicting a users likes or dislikes, significantly better than two strong baselines.", "histories": [["v1", "Tue, 11 Nov 2014 01:53:21 GMT  (106kb,D)", "http://arxiv.org/abs/1411.2679v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.AI cs.CL cs.LG", "authors": ["jiwei li", "alan ritter", "dan jurafsky"], "accepted": false, "id": "1411.2679"}, "pdf": {"name": "1411.2679.pdf", "metadata": {"source": "CRF", "title": "Inferring User Preferences by Probabilistic Logical Reasoning over Social Networks", "authors": ["Jiwei Li", "Alan Ritter", "Dan Jurafsky"], "emails": ["jiweil@stanford.edu", "Ritter.1492@osu.edu", "jurafsky@stanford.edu", "permissions@acm.org."], "sections": [{"heading": null, "text": "Categories and topic descriptions H.0 [Informationssysteme]: GeneralKeywords Logical Reasoning, User Attribute Inference, Social Networks"}, {"heading": "1. INTRODUCTION", "text": "In fact, most of them are able to survive on their own, without being able to survive on their own."}, {"heading": "2. EXTRACTING PROBABILISTIC LOGICAL PREDICATES", "text": "Given the news flows of Twitter users, our first task is to extract information about user attributes, relationships and preferences in logical form; these are then entered into our global logical inference network. We represent these facts by two types of statement logic objects: predicates and functions. Functions represent mappings from one object to another and return an object, as in KAPITALOF (FRANCE) = PARIS. Predicates represent whether there is a relationship between two objects and return a Boolean value. For example, if UstrA and UstrB are friends on Twitter, the predicate ISFRIEND (USRA, USRB) = TRUE applies. Predicates and functions can be transformed among themselves. Given the function WIFEOF (USRA) = USRB, the predicate ISCOUPLE (RUSA, USRB) = UTRE will of course apply to all functions later on, as we will show in construction procedures."}, {"heading": "2.1 Dataset", "text": "We used a random sample of Twitter users - after discarding users with fewer than 10 tweets - of 0.5 million Twitter users. We searched their published tweets and their network using the Twit-ter API1, resulting in a record of about 75 million tweets."}, {"heading": "2.2 User Attributes", "text": "In the next sections, we will first briefly describe how to make predictions for user attributes (location, education, gender) and user relationships (friend, spouse) and then focus in detail on extracting user preferences (such as / dislikes). Our goal is to connect one of the 50 states of the United States to each user. While there is a significant amount of work to determine the location of a particular published tweet (e.g. [10, 17, 78]), there is less focus on user preferences. In this paper, we employ a rules-based approach to user identification. We have selected all geo-tagged tweets from a particular user and say that an entity e corresponds to the location of the current user if it meets i the following criteria to ensure high precision (although with a natural corresponding decline in memory): 1. Users I posted more than 10 tweets from the site e."}, {"heading": "2.3 User Relations", "text": "The user-user relationships we consider in this work include FRIEND (USRA, USRB), SPOUSE (USRA, USRB), and LIVE COLLECTION (USRA, USRB). Friend: Twitter supports two types of patterns, FOLLOWING and FOLLOWED. We consider two people to be friends when they follow each other (i.e. bidirectionally following each other), so if the relationship holds FRIEND (USRA, USRB), UserA must be followed both by UserB. Friendship relationship is extracted directly from the Twitter network. Spouse / Friend / Girlfriend: For the spouse relationship, we turn again to Li et al.'s. System [48]. For two given Twitter users and their published content, the system provides a score spouse in the range of [0.1] indicating how likely the SPOUSE relationship (USR1, USR2) is to be classified as an early use."}, {"heading": "2.4 User Preferences: Like and Dislike", "text": "\"We have to deal with the preferences and attitudes of users,\" he says, \"but we also have to deal with the question of what we can do.\" Unless there is another way to change the world: \"There is another world in which we can identify with others,\" he says. \"There is another way to understand the world:\" There is another world in which we can identify with others. \"\" There is another world in which we can identify with others. \"\" There is another world in which we can identify with others. \"\" There is another world in which we can identify with others. \"\" There is another world in which we can't identify with others. \"There is another world in which we can't identify.\" There is another world in which we can't identify with others. \"There is another world in which we can't identify with others.\" There is another world in which we can't identify. \""}, {"heading": "3. LOGIC NETWORKS", "text": "In this section we describe MLN and PSL, which are widely used in the field of relational learning and logical thinking."}, {"heading": "3.1 Markov Logic", "text": "Markov logic [71] is a probabilistic logic framework that encodes weighted logic formulas of the first order in a Markov network. Translated into logic, the expressions of people from Illinois such as the Chicago Bears football team are first converted into symbols with logical connectors and quantifiers. In MLN, each of the predicates (e.g. LIVE and LIKE) corresponds to a node, and each formula is associated with a weighted value wi. The framework optimizes the following probability: P (X) = 1Z value (xi) ni (x) (2), where \"xi\" = exp (wi) = exp (wi) = exp (wi). \"Z stands for the normalization factor and\" xi \"for the states of nodes in the network. In our early example, x could assume the following 4 values, i.e.,\" (q.), lp. \""}, {"heading": "3.2 Probabilistic Soft Logic", "text": "PSL [4, 37] is a different kind of logical argumentation architecture. It first associates each predicate l with a soft truth value I (l). Based on such soft truth values, PSL performs logical conjunction and disjunction in the following ways: I (l1) = max {0, I (l1) + I (l2) \u2212 1} I (l1) = min {1, I (l1) + I (l2) (4) Next, a given formula l1 \u21d2 l2 is called fulfilled when I (l1) \u2264 I (l2). PSL defines a variable d (r), the \"distance to satisfaction,\" in order to determine how far rule r is from the truth content. d (r) is optimized by max {0, I (l2) \u2212 I (l1), ifI (SPOUSE (USR1, USR2) \u2212 Z formula = RUS1 (RUS1) (RUS1) = 0.6) (RUS1)."}, {"heading": "4. LOGIC REASONING ON SOCIAL NETWORKS", "text": "Based on our extraction algorithm in Section 2, each user i is associated with a list of attributes and preferences and related by various relationships with other users on a network. Function symbols are converted into predictors for graph construction where all nodes in the graph assume binary values (i.e. true or false)."}, {"heading": "4.1 Assumptions and Simplifications", "text": "Since it might be difficult to scale existing algorithms to the size of the users and attributes we are looking at, we make some assumptions to enable faster learning and quicker conclusions: Cropped edges: If the relationships hold LIKE (USRA, ENTITY1), LIKE (USRB, ENTITY2), and FRIEND (USRA, USRB), but ENTITIY1 and ENTITY2 come from different, like-minded categories, we would say LIKE (USR1, ENTITY1), and FRIEND (USR1, USR2) independently, meaning that there would be no edge connections between the nodes LIKE (ENTITY1) and LIKE (ENTITY2) in the Markov network. For example, if usrA likes Pisces and usrB like football, since Pisces and football belong to different entity categories, we would treat these two predictions as separate."}, {"heading": "4.2 Modeling Missing Values", "text": "This year, it is time to set out to find a solution that paves the way to the future."}, {"heading": "5. EXPERIMENTS", "text": "We now turn to our experiments on using global logical network conclusions to expand the individual local detectors to derive user attributes, user relationships, and finally user preferences, based on the data sets extracted in the previous section, in which each user is presented with a set of extracted attribute values (such as / dislike, location, gender) and users are connected via the social network. We use 90% of the data as a training corpus, and reserve 10% for tests from which we extract test data for each relationship, attribute, or preference, as described below. In any case, our goal is to understand whether the global likely logical conclusion across the social network improves over base classifiers such as SVNs that use only local characteristics."}, {"heading": "5.1 User Attributes: Location", "text": "The evaluation is based on the subset of users for whom our rules-based approach in Section 2 has identified a gold standard location with high accuracy. We report on two settings. The FRIEND-LATENT setting makes common predictions for user locations across the network, while the more precise FRIEND-OBSERVED setting predicts the locations of each user taking into account all other attributes, relationships and preferences. Baselines we use include: \u2022 Random: Assigning locations from the distribution base. \u2022 Unified: Assigning the most populous state in the US (Califor-nia) to each user. \u2022 SVM and Naive Bayes: Train multi-class classifiers, with features using the predicted attributes and Network11We drawing on a similar idea in [47]."}, {"heading": "5.2 User Attributes: Gender", "text": "We evaluate gender using a data set of 10,000 users (half male, half female) derived from the users whose gold-standard gender was assigned in Section 2 with sufficient precision by the social security informed system. We focus only on NEIGH-OBSERVE13The values are weighted for probable attributes (e.g. education).14 This is a classification problem with 50 classes; the accuracy for random assignment without prior knowledge is 0.02%.Setting. The SVM baseline takes individual and network characteristics as described in Section 5.1. Table 5 shows the results. Using logical networks across all the attributes, relationships and preferences mentioned, the accuracy of our algorithm is 0.782%. Of course, the performance of the algorithm could very likely be even higher if we included additional characteristics designed directly for the gender identification task (such as the 12 entries mentioned, and the diversity of attributes)."}, {"heading": "5.3 Predicting Relations Between Users", "text": "We tested the relationship prediction by identifying the three relationships defined in Section 2: FRIEND, SPOUSE, and LIVE AMELOCATION. Positive training data are selected by user pairs between which a certain type of relationship exists, while random user pairs are used as negative examples. We weighted negative examples to match the natural distribution statistics in Table 10. For relationship evaluation, we focus only on the NEIGH-OBSERVE setting. Decisions are made by comparing the conditional probability that a particular relationship contains other types of information, such as Pr (SPOUSE (A, B) | \u00b7) and 1-Pr (SPOUSE (A, B) | \u00b7). Baselines we use include: \u2022 SVM: We use co-occurrences of attributes as characteristics: LIKE-ENTITY1 (A) and LIKITYB-KITYB (2)."}, {"heading": "5.4 Predicing Preference: Likes or Dislikes", "text": "In fact, most people who are able to survive themselves, to survive themselves and to survive themselves, are not able because they are able to survive themselves, but because they are able to survive themselves, and because they are able to survive themselves, \"he told the Deutsche Presse-Agentur.\" I don't think I am able to survive myself, \"he said.\" I believe that I am able to survive myself. \""}, {"heading": "6. RELATED WORK", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they are able to move, in which they move, in which they move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they are able"}, {"heading": "7. CONCLUSION AND DISCUSSION", "text": "Our two-step process first extracts logical predicates, each of which is associated with probability, from social networks and then performs logical thinking. We evaluated our system for predicting user attributes (gender, education, location), user relationships (friend, spouse, like-minded), and user preferences (liking or dislike of different entities). Our results show that the use of likely logical argumentation15 summarized by the saying \"featherbirds converge\" [2] across the network improves the accuracy of the resulting predictions and demonstrates the effectiveness of the proposed framework. Of course, the current system is particularly weak in memory, as many real user attributes or relationships are simply never explicitly expressed on platforms such as Twitter. Also, the \"gold standard\" firm logic is not really gold standard. A promising perspective is the integration of user information or relationships for different types of social media sites; providing comprehensive, standardized information directly to Facebook users."}, {"heading": "8. ADDITIONAL AUTHORS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9. REFERENCES", "text": "[1] A. Agarwal, B. Xie, I. Vovsha, O. Rambow, andR. Passonneau. Sentiment analysis of twitter data. In Proceedings of the Workshop on Languages in Social Media, pp. 30-38. Association for Computational Linguistics, 2011. [2] F. Al Zamal, W. Liu, and D. Ruths. Homophily and latent attribute inference: Inferring latent attributes of twitter users from neighbors. [3] N. Banerjee, D. Chakraborty, K. Dasgupta, S. Mittal, A. Joshi, A. Rai, and S. Madan. User interests in social media sites: an exploration with micro-blogs. In Proceedings of the 18th ACM conference on Information and knowledge management, pp. 1823-1826. ACM, 2009."}], "references": [{"title": "Sentiment analysis of twitter data", "author": ["A. Agarwal", "B. Xie", "I. Vovsha", "O. Rambow", "R. Passonneau"], "venue": "Proceedings of the Workshop on Languages in Social Media, pages 30\u201338. Association for Computational Linguistics,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Homophily and latent attribute inference: Inferring latent attributes of twitter users from neighbors", "author": ["F. Al Zamal", "W. Liu", "D. Ruths"], "venue": "ICWSM,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "User interests in social media sites: an exploration with micro-blogs", "author": ["N. Banerjee", "D. Chakraborty", "K. Dasgupta", "S. Mittal", "A. Joshi", "S. Nagar", "A. Rai", "S. Madan"], "venue": "Proceedings of the 18th ACM conference on Information and knowledge management, pages 1823\u20131826. ACM,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic soft logic for semantic textual similarity", "author": ["I. Beltagy", "K. Erk", "R. Mooney"], "venue": "Proceedings of Association for Computational Linguistics (ACL-14),", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural probabilistic language models", "author": ["Y. Bengio", "H. Schwenk", "J.-S. Sen\u00e9cal", "F. Morin", "J.-L. Gauvain"], "venue": "Innovations in Machine Learning, pages 137\u2013186. Springer,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Semantic parsing on freebase from question-answer pairs", "author": ["J. Berant", "A. Chou", "R. Frostig", "P. Liang"], "venue": "EMNLP, pages 1533\u20131544,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Probabilistic similarity logic", "author": ["M. Brocheler", "L. Mihalkova", "L. Getoor"], "venue": "arXiv preprint arXiv:1203.3469,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Computing marginal distributions over continuous markov networks for statistical relational learning", "author": ["M. Broecheler", "L. Getoor"], "venue": "Advances in Neural Information Processing Systems, pages 316\u2013324,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Discriminating gender on twitter", "author": ["J.D. Burger", "J. Henderson", "G. Kim", "G. Zarrella"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1301\u20131309. Association for Computational Linguistics,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "You are where you tweet: a content-based approach to geo-locating twitter users", "author": ["Z. Cheng", "J. Caverlee", "K. Lee"], "venue": "Proceedings of the 19th ACM international conference on Information and knowledge management, pages 759\u2013768. ACM,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Identifying sources of opinions with conditional random fields and extraction patterns", "author": ["Y. Choi", "C. Cardie", "E. Riloff", "S. Patwardhan"], "venue": "Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 355\u2013362. Association for Computational Linguistics,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Gender inference of twitter users in non-english contexts", "author": ["M. Ciot", "M. Sonderegger", "D. Ruths"], "venue": "EMNLP, pages 1136\u20131145,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Political polarization on twitter", "author": ["M. Conover", "J. Ratkiewicz", "M. Francisco", "B. Gon\u00e7alves", "F. Menczer", "A. Flammini"], "venue": "ICWSM,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Clp (bn): Constraint logic programming for probabilistic knowledge", "author": ["V.S. Costa", "D. Page", "M. Qazi", "J. Cussens"], "venue": "Proceedings of the Nineteenth conference on Uncertainty in Artificial Intelligence, pages 517\u2013524. Morgan Kaufmann Publishers Inc.,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "Constructing biological knowledge bases by extracting information from text sources", "author": ["M. Craven", "J. Kumlien"], "venue": "In ISMB,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Fully unsupervised discovery of concept-specific relationships by web mining", "author": ["D. Davidov", "A. Rappoport", "M. Koppel"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Inferring the location of twitter messages based on user relationships", "author": ["C.A. Davis Jr.", "G.L. Pappa", "D.R.R. de Oliveira", "F. de L Arcanjo"], "venue": "Transactions in GIS,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Feature weighting in content based recommendation system using social network analysis", "author": ["S. Debnath", "N. Ganguly", "P. Mitra"], "venue": "Proceedings of the 17th international conference on World Wide Web, pages 1041\u20131042. ACM,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Finding bursty topics from microblogs", "author": ["Q. Diao", "J. Jiang", "F. Zhu", "E.-P. Lim"], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 536\u2013544. Association for Computational Linguistics,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-relational record linkage", "author": ["P. Domingos"], "venue": "In Proceedings of the KDD-2004 Workshop on Multi-Relational Data Mining. Citeseer,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "Efficient identification of web communities", "author": ["G.W. Flake", "S. Lawrence", "C.L. Giles"], "venue": "Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 150\u2013160. ACM,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2000}, {"title": "Learning probabilistic relational models", "author": ["N. Friedman", "L. Getoor", "D. Koller", "A. Pfeffer"], "venue": "IJCAI, volume 99, pages 1300\u20131309,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1999}, {"title": "Twitter sentiment classification using distant supervision", "author": ["A. Go", "R. Bhayani", "L. Huang"], "venue": "CS224N Project Report, Stanford, pages 1\u201312,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "System and method for utilizing social networks for collaborative filtering, Mar", "author": ["M. Goeksel", "C.P. Lam"], "venue": "30", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Probabilistic logic networks", "author": ["B. Goertzel", "C. Pennachin", "N. Geisweiller"], "venue": "Engineering General Intelligence, Part 2, pages 275\u2013291. Springer,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Social media recommendation based on people and tags", "author": ["I. Guy", "N. Zwerdling", "I. Ronen", "D. Carmel", "E. Uziel"], "venue": "Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, pages 194\u2013201. ACM,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations", "author": ["R. Hoffmann", "C. Zhang", "X. Ling", "L. Zettlemoyer", "D.S. Weld"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 541\u2013550. Association for Computational Linguistics,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Social group modeling with probabilistic soft logic", "author": ["B. Huang", "S.H. Bach", "E. Norris", "J. Pujara", "L. Getoor"], "venue": "NIPS Workshop on Social Network and Social Media Analysis: Methods, Models, and Applications,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Probabilistic soft logic for trust analysis in social networks", "author": ["B. Huang", "A. Kimmig", "L. Getoor", "J. Golbeck"], "venue": "International Workshop on Statistical Relational AI, pages 1\u20138,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "Corpus-based semantic lexicon induction with web-based corroboration", "author": ["S.P. Igo", "E. Riloff"], "venue": "Proceedings of the Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics, pages 18\u201326. Association for Computational Linguistics,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic reasoning in terminological logics", "author": ["M. Jaeger"], "venue": "KR, 94:305\u2013316,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1994}, {"title": "A matrix factorization technique with trust propagation for recommendation in social networks", "author": ["M. Jamali", "M. Ester"], "venue": "Proceedings of the fourth ACM conference on Recommender systems, pages 135\u2013142. ACM,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Making large scale svm learning practical", "author": ["T. Joachims"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1999}, {"title": "Referral web: combining social networks and collaborative filtering", "author": ["H. Kautz", "B. Selman", "M. Shah"], "venue": "Communications of the ACM, 40(3):63\u201365,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1997}, {"title": "Extracting opinions, opinion holders, and topics expressed in online news media text", "author": ["S.-M. Kim", "E. Hovy"], "venue": "Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 1\u20138. Association for Computational Linguistics,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2006}, {"title": "A short introduction to probabilistic soft logic", "author": ["A. Kimmig", "S. Bach", "M. Broecheler", "B. Huang", "L. Getoor"], "venue": "Proceedings of the NIPS Workshop on Probabilistic Programming: Foundations and Applications, pages 1\u20134,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "On social networks and collaborative recommendation", "author": ["I. Konstas", "V. Stathopoulos", "J.M. Jose"], "venue": "Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, pages 195\u2013202. ACM,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2009}, {"title": "Twitter sentiment analysis: The good the bad and the omg", "author": ["E. Kouloumpis", "T. Wilson", "J. Moore"], "venue": "ICWSM, 11:538\u2013541,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2011}, {"title": "Learning arguments and supertypes of semantic relations using recursive patterns", "author": ["Z. Kozareva", "E. Hovy"], "venue": "Proceedings of the 48th Annual Meeting of the Association  for Computational Linguistics, pages 1482\u20131491. Association for Computational Linguistics,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "Not all seeds are equal: Measuring the quality of text mining seeds", "author": ["Z. Kozareva", "E. Hovy"], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 618\u2013626. Association for Computational Linguistics,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2010}, {"title": "Scaling semantic parsers with on-the-fly ontology matching", "author": ["T. Kwiatkowski", "E. Choi", "Y. Artzi", "L. Zettlemoyer"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2013}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F.C. Pereira"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2001}, {"title": "The em algorithm for graphical association models with missing data", "author": ["S.L. Lauritzen"], "venue": "Computational Statistics & Data Analysis, 19(2):191\u2013201,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1995}, {"title": "Combined distributional and logical semantics", "author": ["M. Lewis", "M. Steedman"], "venue": "TACL, 1:179\u2013192,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2013}, {"title": "Timeline generation: tracking individuals on twitter", "author": ["J. Li", "C. Cardie"], "venue": "Proceedings of the 23rd international conference on World wide web, pages 643\u2013652. International World Wide Web Conferences Steering Committee,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Major life event extraction from twitter based on congratulations/condolences speech acts", "author": ["J. Li", "A. Ritter", "C. Cardie", "E. Hovy"], "venue": "Proceedings of Empirical Methods in Natural Language Processing,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2014}, {"title": "Weakly supervised user profile extraction from twitter", "author": ["J. Li", "A. Ritter", "E. Hovy"], "venue": "ACL,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2014}, {"title": "Pet: a statistical model for popular events tracking in social communities", "author": ["C.X. Lin", "B. Zhao", "Q. Mei", "J. Han"], "venue": "Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 929\u2013938. ACM,", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2010}, {"title": "Smoothing techniques for adaptive online language models: topic tracking in tweet streams", "author": ["J. Lin", "R. Snow", "W. Morgan"], "venue": "Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 422\u2013429. ACM,", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2011}, {"title": "Statistical analysis with missing data", "author": ["R.J. Little", "D.B. Rubin"], "venue": null, "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2002}, {"title": "Use of social network information to enhance collaborative filtering performance", "author": ["F. Liu", "H.J. Lee"], "venue": "Expert Systems with Applications, 37(7):4772\u20134778,", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2010}, {"title": "Efficient weight learning for markov logic networks", "author": ["D. Lowd", "P. Domingos"], "venue": "Knowledge Discovery in Databases: PKDD 2007, pages 200\u2013211. Springer,", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2007}, {"title": "Birds of a feather: Homophily in social networks", "author": ["M. McPherson", "L. Smith-Lovin", "J.M. Cook"], "venue": "Annual review of sociology, pages 415\u2013444,", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2001}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov", "M. Karafi\u00e1t", "L. Burget", "J. Cernock\u1ef3", "S. Khudanpur"], "venue": "INTERSPEECH, pages 1045\u20131048,", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2010}, {"title": "Extensions of recurrent neural network language model", "author": ["T. Mikolov", "S. Kombrink", "L. Burget", "J. Cernocky", "S. Khudanpur"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pages 5528\u20135531. IEEE,", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2011}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["M. Mintz", "S. Bills", "R. Snow", "D. Jurafsky"], "venue": "Proceedings of the Joint Conference of the 47th Annual  Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003\u20131011. Association for Computational Linguistics,", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2009}, {"title": "You are who you know: inferring user profiles in online social networks", "author": ["A. Mislove", "B. Viswanath", "K.P. Gummadi", "P. Druschel"], "venue": "Proceedings of the third ACM international conference on Web search and data mining, pages 251\u2013260. ACM,", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2010}, {"title": "Universal grammar", "author": ["R. Montague"], "venue": "Theoria, 36(3):373\u2013398,", "citeRegEx": "59", "shortCiteRegEx": null, "year": 1970}, {"title": "Inductive logic programming: Theory and methods", "author": ["S. Muggleton", "L. De Raedt"], "venue": "The Journal of Logic Programming, 19:629\u2013679,", "citeRegEx": "60", "shortCiteRegEx": null, "year": 1994}, {"title": "Stochastic logic programs", "author": ["S. Muggleton"], "venue": "Advances in inductive logic programming,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 1996}, {"title": "Relational dependency networks", "author": ["J. Neville", "D. Jensen"], "venue": "The Journal of Machine Learning Research, 8:653\u2013692,", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2007}, {"title": "Tuffy: Scaling up statistical inference in markov logic networks using an rdbms", "author": ["F. Niu", "C. R\u00e9", "A. Doan", "J. Shavlik"], "venue": "Proceedings of the VLDB Endowment, 4(6):373\u2013384,", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2011}, {"title": "Improved part-of-speech tagging for online conversational text with word clusters", "author": ["O. Owoputi", "B. O\u2019Connor", "C. Dyer", "K. Gimpel", "N. Schneider", "N.A. Smith"], "venue": "In HLT-NAACL,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2013}, {"title": "Twitter as a corpus for sentiment analysis and opinion mining", "author": ["A. Pak", "P. Paroubek"], "venue": "LREC,", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2010}, {"title": "A machine learning approach to twitter user classification", "author": ["M. Pennacchiotti", "A.-M. Popescu"], "venue": "ICWSM, 11:281\u2013288,", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2011}, {"title": "Extracting events and event descriptions from twitter", "author": ["A.-M. Popescu", "M. Pennacchiotti", "D. Paranjpe"], "venue": "Proceedings of the 20th international conference companion on World wide web, pages 105\u2013106. ACM,", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2011}, {"title": "A multi-pass sieve for coreference resolution", "author": ["K. Raghunathan", "H. Lee", "S. Rangarajan", "N. Chambers", "M. Surdeanu", "D. Jurafsky", "C. Manning"], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 492\u2013501. Association for Computational Linguistics,", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2010}, {"title": "Detecting latent user properties in social media", "author": ["D. Rao", "D. Yarowsky"], "venue": "Proc. of the NIPS MLSN Workshop,", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2010}, {"title": "Classifying latent user attributes in twitter", "author": ["D. Rao", "D. Yarowsky", "A. Shreevats", "M. Gupta"], "venue": "Proceedings of the 2nd international workshop on Search and mining user-generated contents, pages 37\u201344. ACM,", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2010}, {"title": "Markov logic networks", "author": ["M. Richardson", "P. Domingos"], "venue": "Machine learning, 62(1-2):107\u2013136,", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2006}, {"title": "Relation extraction with matrix factorization and universal schemas", "author": ["S. Riedel", "L. Yao", "A. McCallum", "B.M. Marlin"], "venue": null, "citeRegEx": "72", "shortCiteRegEx": "72", "year": 2013}, {"title": "Learning dictionaries for information extraction by multi-level bootstrapping", "author": ["E. Riloff", "R. Jones"], "venue": "In AAAI/IAAI,", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 1999}, {"title": "Open domain event extraction from twitter", "author": ["A. Ritter", "O. Etzioni", "S. Clark"], "venue": "In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2012}, {"title": "Modeling  missing data in distant supervision for information", "author": ["A. Ritter", "L. Zettlemoyer", "Mausam", "O. Etzioni"], "venue": "extraction. TACL,", "citeRegEx": "75", "shortCiteRegEx": "75", "year": 2013}, {"title": "A machine-oriented logic based on the resolution principle", "author": ["J.A. Robinson"], "venue": "Journal of the ACM (JACM), 12(1):23\u201341,", "citeRegEx": "76", "shortCiteRegEx": null, "year": 1965}, {"title": "Finding your friends and following them to where you are", "author": ["A. Sadilek", "H. Kautz", "J.P. Bigham"], "venue": "Proceedings of the fifth ACM international conference on Web search and data mining, pages 723\u2013732. ACM,", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2012}, {"title": "Semantic sentiment analysis of twitter", "author": ["H. Saif", "Y. He", "H. Alani"], "venue": "The Semantic Web\u2013ISWC 2012, pages 508\u2013524. Springer,", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2012}, {"title": "Item-based collaborative filtering recommendation algorithms", "author": ["B. Sarwar", "G. Karypis", "J. Konstan", "J. Riedl"], "venue": "Proceedings of the 10th international conference on World Wide Web, pages 285\u2013295. ACM,", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2001}, {"title": "Learning first-order horn clauses from web text", "author": ["S. Schoenmackers", "O. Etzioni", "D.S. Weld", "J. Davis"], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1088\u20131098. Association for Computational Linguistics,", "citeRegEx": "81", "shortCiteRegEx": null, "year": 2010}, {"title": "Discriminative training of markov logic networks", "author": ["P. Singla", "P. Domingos"], "venue": "AAAI, volume 5, pages 868\u2013873,", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2005}, {"title": "Entity resolution with markov logic", "author": ["P. Singla", "P. Domingos"], "venue": "Data Mining, 2006. ICDM\u201906. Sixth International Conference on, pages 572\u2013582. IEEE,", "citeRegEx": "83", "shortCiteRegEx": null, "year": 2006}, {"title": "What\u00e2\u0102\u0179s in a name: A study of names, gender inference, and gender behavior in facebook", "author": ["C. Tang", "K. Ross", "N. Saxena", "R. Chen"], "venue": "Database Systems for Adanced Applications, pages 344\u2013356. Springer,", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2011}, {"title": "Discriminative probabilistic models for relational data", "author": ["B. Taskar", "P. Abbeel", "D. Koller"], "venue": "Proceedings of the Eighteenth conference on Uncertainty in artificial intelligence, pages 485\u2013492. Morgan Kaufmann Publishers Inc.,", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2002}, {"title": "Programming with personalized pagerank: A locally groundable first-order probabilistic logic", "author": ["W.Y. Wang", "K. Mazaitis", "W.W. Cohen"], "venue": "Proceedings of the 22nd ACM International Conference on Information and Knowledge Management (CIKM 2013),", "citeRegEx": "86", "shortCiteRegEx": null, "year": 2013}, {"title": "Proppr: Efficient first-order probabilistic logic programming for structure discovery, parameter learning, and scalable inference", "author": ["W.Y. Wang", "K. Mazaitis", "W.W. Cohen"], "venue": "Proceedings of the AAAI 2014 Workshop on Statistical Relational AI (StarAI 2014),", "citeRegEx": "87", "shortCiteRegEx": null, "year": 2014}, {"title": "Structure learning via parameter learning", "author": ["W.Y. Wang", "K. Mazaitis", "W.W. Cohen"], "venue": "Proceedings of the 23rd ACM International Conference on Information and Knowledge Management (CIKM 2014),", "citeRegEx": "88", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient inference and learning in a large knowledge base: Reasoning with extracted information using a locally groundable first-order probabilistic logic", "author": ["W.Y. Wang", "K. Mazaitis", "N. Lao", "T. Mitchell", "W.W. Cohen"], "venue": "progress,", "citeRegEx": "89", "shortCiteRegEx": null, "year": 2014}, {"title": "Annotating expressions of opinions and emotions in language", "author": ["J. Wiebe", "T. Wilson", "C. Cardie"], "venue": "Language resources and evaluation, 39(2-3):165\u2013210,", "citeRegEx": "90", "shortCiteRegEx": null, "year": 2005}, {"title": "Joint inference for fine-grained opinion extraction", "author": ["B. Yang", "C. Cardie"], "venue": "ACL (1), pages 1640\u20131649,", "citeRegEx": "91", "shortCiteRegEx": null, "year": 2013}, {"title": "Overlapping community detection at scale: a nonnegative matrix factorization approach", "author": ["J. Yang", "J. Leskovec"], "venue": "Proceedings of the sixth ACM international conference on Web search and data mining, pages 587\u2013596. ACM,", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 17, "context": "movie ratings), and often enriched by information from a social network [18, 25, 35, 38, 52].", "startOffset": 72, "endOffset": 92}, {"referenceID": 23, "context": "movie ratings), and often enriched by information from a social network [18, 25, 35, 38, 52].", "startOffset": 72, "endOffset": 92}, {"referenceID": 33, "context": "movie ratings), and often enriched by information from a social network [18, 25, 35, 38, 52].", "startOffset": 72, "endOffset": 92}, {"referenceID": 36, "context": "movie ratings), and often enriched by information from a social network [18, 25, 35, 38, 52].", "startOffset": 72, "endOffset": 92}, {"referenceID": 50, "context": "movie ratings), and often enriched by information from a social network [18, 25, 35, 38, 52].", "startOffset": 72, "endOffset": 92}, {"referenceID": 69, "context": "We propose to infer user preferences on domains like Twitter without explicit information by applying relational reasoning frameworks like Markov Logic Networks (MLN) [71] and Probabilistic Soft Logic (PSL) [26] to help infer these relational rules.", "startOffset": 167, "endOffset": 171}, {"referenceID": 24, "context": "We propose to infer user preferences on domains like Twitter without explicit information by applying relational reasoning frameworks like Markov Logic Networks (MLN) [71] and Probabilistic Soft Logic (PSL) [26] to help infer these relational rules.", "startOffset": 207, "endOffset": 211}, {"referenceID": 46, "context": "On the other hand, users of online social media frequently publish messages describing their preferences and activities, often explicitly mentioning attributes such as their JOB, RELIGION, or EDUCATION [48].", "startOffset": 202, "endOffset": 206}, {"referenceID": 14, "context": "for Twitter that combines supervision [15], semi-supervised data harvesting (e.", "startOffset": 38, "endOffset": 42}, {"referenceID": 38, "context": ", [40, 41]) and vector space models [5, 55] to automatically extract structured profiles from the text of users\u2019 messages.", "startOffset": 2, "endOffset": 10}, {"referenceID": 39, "context": ", [40, 41]) and vector space models [5, 55] to automatically extract structured profiles from the text of users\u2019 messages.", "startOffset": 2, "endOffset": 10}, {"referenceID": 4, "context": ", [40, 41]) and vector space models [5, 55] to automatically extract structured profiles from the text of users\u2019 messages.", "startOffset": 36, "endOffset": 43}, {"referenceID": 53, "context": ", [40, 41]) and vector space models [5, 55] to automatically extract structured profiles from the text of users\u2019 messages.", "startOffset": 36, "endOffset": 43}, {"referenceID": 69, "context": "Finally, we feed the extracted attributes and relations into relational reasoning frameworks, including Markov Logic Networks (MLN) [71] and Probabilistic Soft Logic (PSL) [26], to infer the relational rules among users, attributes and user relations that allow us to predict user preferences.", "startOffset": 132, "endOffset": 136}, {"referenceID": 24, "context": "Finally, we feed the extracted attributes and relations into relational reasoning frameworks, including Markov Logic Networks (MLN) [71] and Probabilistic Soft Logic (PSL) [26], to infer the relational rules among users, attributes and user relations that allow us to predict user preferences.", "startOffset": 172, "endOffset": 176}, {"referenceID": 9, "context": ", [10, 17, 78]), there is less focus on user-level inference.", "startOffset": 2, "endOffset": 14}, {"referenceID": 16, "context": ", [10, 17, 78]), there is less focus on user-level inference.", "startOffset": 2, "endOffset": 14}, {"referenceID": 75, "context": ", [10, 17, 78]), there is less focus on user-level inference.", "startOffset": 2, "endOffset": 14}, {"referenceID": 46, "context": "Job and education attributes are extracted by combining a rule based approach with an existing probabilistic system described in [48].", "startOffset": 129, "endOffset": 133}, {"referenceID": 46, "context": "We adopted the friend \u2212 shared strategy taken in [48] that if more than 10 percent of and at least 20 friends are shared by Google+ circles and Twitter followers, we assume that the two accounts point to the same person.", "startOffset": 49, "endOffset": 53}, {"referenceID": 46, "context": "[48] (for details about algorithms in [48], see Section 6).", "startOffset": 0, "endOffset": 4}, {"referenceID": 46, "context": "[48] (for details about algorithms in [48], see Section 6).", "startOffset": 38, "endOffset": 42}, {"referenceID": 8, "context": ", [9, 12, 66, 84]) studying whether high level tweet features (e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 11, "context": ", [9, 12, 66, 84]) studying whether high level tweet features (e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 64, "context": ", [9, 12, 66, 84]) studying whether high level tweet features (e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 81, "context": ", [9, 12, 66, 84]) studying whether high level tweet features (e.", "startOffset": 2, "endOffset": 17}, {"referenceID": 46, "context": "\u2019s system [48].", "startOffset": 10, "endOffset": 14}, {"referenceID": 0, "context": "For any two given Twitter users and their published contents, the system returns a score Sspouse in the range of [0,1] indicating how likely SPOUSE(USR1,USR2) relation is to hold.", "startOffset": 113, "endOffset": 118}, {"referenceID": 0, "context": "5, we use a continuous variable to denote the confidence, the value of which is computed by linearly projecting Sspouse into [0,1] space.", "startOffset": 125, "endOffset": 130}, {"referenceID": 0, "context": ", [1, 39, 65, 79]).", "startOffset": 2, "endOffset": 17}, {"referenceID": 37, "context": ", [1, 39, 65, 79]).", "startOffset": 2, "endOffset": 17}, {"referenceID": 63, "context": ", [1, 39, 65, 79]).", "startOffset": 2, "endOffset": 17}, {"referenceID": 76, "context": ", [1, 39, 65, 79]).", "startOffset": 2, "endOffset": 17}, {"referenceID": 10, "context": "Our work thus resembles other work on sentiment target extraction ([11, 36, 91]) using supervised classifiers or sequence models based on manually-labeled datasets.", "startOffset": 67, "endOffset": 79}, {"referenceID": 34, "context": "Our work thus resembles other work on sentiment target extraction ([11, 36, 91]) using supervised classifiers or sequence models based on manually-labeled datasets.", "startOffset": 67, "endOffset": 79}, {"referenceID": 88, "context": "Our work thus resembles other work on sentiment target extraction ([11, 36, 91]) using supervised classifiers or sequence models based on manually-labeled datasets.", "startOffset": 67, "endOffset": 79}, {"referenceID": 15, "context": "To deal with data sparsity issues, we collect training data by combining semi-supervised information harvesting techniques [16, 40, 41, 47] and the concept of distant supervision [15, 24, 57] as follows: Semi-supervised information harvesting: We applied the standard seed-based information-extraction method of obtaining training data recursively by using seed examples to extract patterns, which are used to harvest new examples, which are further used as new seeds to train new patterns.", "startOffset": 123, "endOffset": 139}, {"referenceID": 38, "context": "To deal with data sparsity issues, we collect training data by combining semi-supervised information harvesting techniques [16, 40, 41, 47] and the concept of distant supervision [15, 24, 57] as follows: Semi-supervised information harvesting: We applied the standard seed-based information-extraction method of obtaining training data recursively by using seed examples to extract patterns, which are used to harvest new examples, which are further used as new seeds to train new patterns.", "startOffset": 123, "endOffset": 139}, {"referenceID": 39, "context": "To deal with data sparsity issues, we collect training data by combining semi-supervised information harvesting techniques [16, 40, 41, 47] and the concept of distant supervision [15, 24, 57] as follows: Semi-supervised information harvesting: We applied the standard seed-based information-extraction method of obtaining training data recursively by using seed examples to extract patterns, which are used to harvest new examples, which are further used as new seeds to train new patterns.", "startOffset": 123, "endOffset": 139}, {"referenceID": 45, "context": "To deal with data sparsity issues, we collect training data by combining semi-supervised information harvesting techniques [16, 40, 41, 47] and the concept of distant supervision [15, 24, 57] as follows: Semi-supervised information harvesting: We applied the standard seed-based information-extraction method of obtaining training data recursively by using seed examples to extract patterns, which are used to harvest new examples, which are further used as new seeds to train new patterns.", "startOffset": 123, "endOffset": 139}, {"referenceID": 14, "context": "To deal with data sparsity issues, we collect training data by combining semi-supervised information harvesting techniques [16, 40, 41, 47] and the concept of distant supervision [15, 24, 57] as follows: Semi-supervised information harvesting: We applied the standard seed-based information-extraction method of obtaining training data recursively by using seed examples to extract patterns, which are used to harvest new examples, which are further used as new seeds to train new patterns.", "startOffset": 179, "endOffset": 191}, {"referenceID": 22, "context": "To deal with data sparsity issues, we collect training data by combining semi-supervised information harvesting techniques [16, 40, 41, 47] and the concept of distant supervision [15, 24, 57] as follows: Semi-supervised information harvesting: We applied the standard seed-based information-extraction method of obtaining training data recursively by using seed examples to extract patterns, which are used to harvest new examples, which are further used as new seeds to train new patterns.", "startOffset": 179, "endOffset": 191}, {"referenceID": 55, "context": "To deal with data sparsity issues, we collect training data by combining semi-supervised information harvesting techniques [16, 40, 41, 47] and the concept of distant supervision [15, 24, 57] as follows: Semi-supervised information harvesting: We applied the standard seed-based information-extraction method of obtaining training data recursively by using seed examples to extract patterns, which are used to harvest new examples, which are further used as new seeds to train new patterns.", "startOffset": 179, "endOffset": 191}, {"referenceID": 62, "context": "Entities extracted here should be nouns, which is determined by a Twitter-tuned POS package [64].", "startOffset": 92, "endOffset": 96}, {"referenceID": 32, "context": "The SVM classifiers are trained using the SVMlight package [34] with the following features: \u2022 Unigram, bigram features with corresponding part-of-speech tags and NER labels.", "startOffset": 59, "endOffset": 63}, {"referenceID": 87, "context": "\u2022 Dictionary-derived features based on a subjectivity lexicon [90].", "startOffset": 62, "endOffset": 66}, {"referenceID": 41, "context": "The CRF model [43] is trained using the CRF++ package based on the following features: \u2022 Current word, context words within a window of 3 words and their part-of-speech tags.", "startOffset": 14, "endOffset": 18}, {"referenceID": 39, "context": "Since semi-supervised approaches heavily rely on seed quality [41] and the patterns derived by the recursive framework may be strongly influenced by the starting seeds, adding in examples from distant supervision helps increase the diversity of positive training examples.", "startOffset": 62, "endOffset": 66}, {"referenceID": 55, "context": "com/p/crfpp/ For example, if datasets says relation ISCAPITAL holds between Britain and London, then all sentences with mention of \u201cBritain\" and \u201cLondon\" are treated as expressing ISCAPITAL relation [57, 75].", "startOffset": 199, "endOffset": 207}, {"referenceID": 73, "context": "com/p/crfpp/ For example, if datasets says relation ISCAPITAL holds between Britain and London, then all sentences with mention of \u201cBritain\" and \u201cLondon\" are treated as expressing ISCAPITAL relation [57, 75].", "startOffset": 199, "endOffset": 207}, {"referenceID": 22, "context": "Tweets with happy emoticons such as :-) : ) are of positive sentiment [24].", "startOffset": 70, "endOffset": 74}, {"referenceID": 53, "context": "Entity Clustering: We further cluster the extracted entities into different groups, with an goal of answering questions like \u2018if usr1 likes films, how likely would she like the film Titanic?\u2019 Towards this goal, we train a skip-gram neural language model [55, 56] based on the tweet dataset using word2vec where each word is represented as a real-valued, low-dimensional vector.", "startOffset": 254, "endOffset": 262}, {"referenceID": 54, "context": "Entity Clustering: We further cluster the extracted entities into different groups, with an goal of answering questions like \u2018if usr1 likes films, how likely would she like the film Titanic?\u2019 Towards this goal, we train a skip-gram neural language model [55, 56] based on the tweet dataset using word2vec where each word is represented as a real-valued, low-dimensional vector.", "startOffset": 254, "endOffset": 262}, {"referenceID": 69, "context": "Markov Logic [71] is a probabilistic logic framework which encodes weighted first-order logic formulas in a Markov network.", "startOffset": 13, "endOffset": 17}, {"referenceID": 51, "context": "Many approaches have been proposed for fast and effective learning for MLNs [53, 63, 82].", "startOffset": 76, "endOffset": 88}, {"referenceID": 61, "context": "Many approaches have been proposed for fast and effective learning for MLNs [53, 63, 82].", "startOffset": 76, "endOffset": 88}, {"referenceID": 79, "context": "Many approaches have been proposed for fast and effective learning for MLNs [53, 63, 82].", "startOffset": 76, "endOffset": 88}, {"referenceID": 79, "context": "In this work, we use the discriminative training approach [82], as will be demonstrated in Section 4.", "startOffset": 58, "endOffset": 62}, {"referenceID": 3, "context": "PSL [4, 37] is another sort of logic reasoning architecture.", "startOffset": 4, "endOffset": 11}, {"referenceID": 35, "context": "PSL [4, 37] is another sort of logic reasoning architecture.", "startOffset": 4, "endOffset": 11}, {"referenceID": 79, "context": "Discriminative Training for MLN: We use the approach described in [82] where we assume that we have a priori knowledge about which predicates will be evidence and which ones will be Figure 2: (a) Standard Approach (b) Revised version with missing values in MLN.", "startOffset": 66, "endOffset": 70}, {"referenceID": 42, "context": "Inspired by common existing approaches to deal with missing data [44, 51], we treat users\u2019 LIKE/DISLIKE preferences as latent variables, while what is observed is whether users explicitly mention their preferences in their posts.", "startOffset": 65, "endOffset": 73}, {"referenceID": 49, "context": "Inspired by common existing approaches to deal with missing data [44, 51], we treat users\u2019 LIKE/DISLIKE preferences as latent variables, while what is observed is whether users explicitly mention their preferences in their posts.", "startOffset": 65, "endOffset": 73}, {"referenceID": 0, "context": "The latent variables and observed variables are connected via a binary distribution parameterized by a [0,1] variable Sentity , indicating how likely a user would be to report the correspondent entity in their posts.", "startOffset": 103, "endOffset": 108}, {"referenceID": 80, "context": "The system can be optimized by incorporating a form of EM algorithm into MLN [83].", "startOffset": 77, "endOffset": 81}, {"referenceID": 46, "context": "As the objective function for joint inference would be difficult to optimize (especially since inference on MLN is hard) and existing algorithms may not able to scale up to the size of network we consider, we turn to a greedy approach inspired by recent work [48, 68]: attributes are initialized from the logic network based on given attributes where missing values are not considered.", "startOffset": 259, "endOffset": 267}, {"referenceID": 66, "context": "As the objective function for joint inference would be difficult to optimize (especially since inference on MLN is hard) and existing algorithms may not able to scale up to the size of network we consider, we turn to a greedy approach inspired by recent work [48, 68]: attributes are initialized from the logic network based on given attributes where missing values are not considered.", "startOffset": 259, "endOffset": 267}, {"referenceID": 45, "context": "We expect FRIENDOBSERVED to yield better results than the FRIEND-LATENT setting since the former benefits from gold network information [47].", "startOffset": 136, "endOffset": 140}, {"referenceID": 45, "context": "We draw on a similar idea in [47].", "startOffset": 29, "endOffset": 33}, {"referenceID": 11, "context": "Of course the performance of the algorithm could very likely be even higher if we were to additionally incorporating features designed directly for the gender ID task (such as entities mentioned, links, and especially the wide variety of writing style features used in work such as [12], which achieves gender ID accuracies of 0.", "startOffset": 282, "endOffset": 286}, {"referenceID": 17, "context": ", like/dislike, location, gender, etc) and network information (attributes from his friends along the network) \u2022 Collaborative Filtering (CF): CF [18, 25, 33, 35] accounts for a popular approach in recommendation system, which utilizes the information of the user-item matrix for recommendations.", "startOffset": 146, "endOffset": 162}, {"referenceID": 23, "context": ", like/dislike, location, gender, etc) and network information (attributes from his friends along the network) \u2022 Collaborative Filtering (CF): CF [18, 25, 33, 35] accounts for a popular approach in recommendation system, which utilizes the information of the user-item matrix for recommendations.", "startOffset": 146, "endOffset": 162}, {"referenceID": 31, "context": ", like/dislike, location, gender, etc) and network information (attributes from his friends along the network) \u2022 Collaborative Filtering (CF): CF [18, 25, 33, 35] accounts for a popular approach in recommendation system, which utilizes the information of the user-item matrix for recommendations.", "startOffset": 146, "endOffset": 162}, {"referenceID": 33, "context": ", like/dislike, location, gender, etc) and network information (attributes from his friends along the network) \u2022 Collaborative Filtering (CF): CF [18, 25, 33, 35] accounts for a popular approach in recommendation system, which utilizes the information of the user-item matrix for recommendations.", "startOffset": 146, "endOffset": 162}, {"referenceID": 77, "context": "We view the like/dislike entity prediction as entity recommendation problem and adopt the approach described in [80] by constructing user-user similarity matrix from weighted cosine similarity calculated from shared attributes and network information.", "startOffset": 112, "endOffset": 116}, {"referenceID": 77, "context": "As in [80], a regression model is trained to fill out {0, 1} value in user-entity matrix indicating whether a specific user likes/hates one specific entity.", "startOffset": 6, "endOffset": 10}, {"referenceID": 47, "context": "Information Extraction on Social Media : Much work has been devoted to automatic extraction of well-structured information profiles from online social media, which mainly fall into two major levels: at public level [49, 50, 90] or at user level.", "startOffset": 215, "endOffset": 227}, {"referenceID": 48, "context": "Information Extraction on Social Media : Much work has been devoted to automatic extraction of well-structured information profiles from online social media, which mainly fall into two major levels: at public level [49, 50, 90] or at user level.", "startOffset": 215, "endOffset": 227}, {"referenceID": 87, "context": "Information Extraction on Social Media : Much work has been devoted to automatic extraction of well-structured information profiles from online social media, which mainly fall into two major levels: at public level [49, 50, 90] or at user level.", "startOffset": 215, "endOffset": 227}, {"referenceID": 18, "context": "The former includes public event identification [19], event tracking [67] or event-referring expression extraction [74].", "startOffset": 48, "endOffset": 52}, {"referenceID": 65, "context": "The former includes public event identification [19], event tracking [67] or event-referring expression extraction [74].", "startOffset": 69, "endOffset": 73}, {"referenceID": 72, "context": "The former includes public event identification [19], event tracking [67] or event-referring expression extraction [74].", "startOffset": 115, "endOffset": 119}, {"referenceID": 2, "context": "The latter focus on user studies, examining users\u2019 interests [3], timeline [46], personal events [47] or individual attributes such as age [70, 69], gender [12], political polarity [13], locations [78], jobs and educations [48], student information (e.", "startOffset": 61, "endOffset": 64}, {"referenceID": 44, "context": "The latter focus on user studies, examining users\u2019 interests [3], timeline [46], personal events [47] or individual attributes such as age [70, 69], gender [12], political polarity [13], locations [78], jobs and educations [48], student information (e.", "startOffset": 75, "endOffset": 79}, {"referenceID": 45, "context": "The latter focus on user studies, examining users\u2019 interests [3], timeline [46], personal events [47] or individual attributes such as age [70, 69], gender [12], political polarity [13], locations [78], jobs and educations [48], student information (e.", "startOffset": 97, "endOffset": 101}, {"referenceID": 68, "context": "The latter focus on user studies, examining users\u2019 interests [3], timeline [46], personal events [47] or individual attributes such as age [70, 69], gender [12], political polarity [13], locations [78], jobs and educations [48], student information (e.", "startOffset": 139, "endOffset": 147}, {"referenceID": 67, "context": "The latter focus on user studies, examining users\u2019 interests [3], timeline [46], personal events [47] or individual attributes such as age [70, 69], gender [12], political polarity [13], locations [78], jobs and educations [48], student information (e.", "startOffset": 139, "endOffset": 147}, {"referenceID": 11, "context": "The latter focus on user studies, examining users\u2019 interests [3], timeline [46], personal events [47] or individual attributes such as age [70, 69], gender [12], political polarity [13], locations [78], jobs and educations [48], student information (e.", "startOffset": 156, "endOffset": 160}, {"referenceID": 12, "context": "The latter focus on user studies, examining users\u2019 interests [3], timeline [46], personal events [47] or individual attributes such as age [70, 69], gender [12], political polarity [13], locations [78], jobs and educations [48], student information (e.", "startOffset": 181, "endOffset": 185}, {"referenceID": 75, "context": "The latter focus on user studies, examining users\u2019 interests [3], timeline [46], personal events [47] or individual attributes such as age [70, 69], gender [12], political polarity [13], locations [78], jobs and educations [48], student information (e.", "startOffset": 197, "endOffset": 201}, {"referenceID": 46, "context": "The latter focus on user studies, examining users\u2019 interests [3], timeline [46], personal events [47] or individual attributes such as age [70, 69], gender [12], political polarity [13], locations [78], jobs and educations [48], student information (e.", "startOffset": 223, "endOffset": 227}, {"referenceID": 56, "context": ", major, year of matriculation) [58].", "startOffset": 32, "endOffset": 36}, {"referenceID": 46, "context": "The first step of proposed approach highly relies on attribute extraction algorithm described in [48] which extracts three categories of user attributes (i.", "startOffset": 97, "endOffset": 101}, {"referenceID": 46, "context": "[48] gathers training data based on the concept of distant supervision where Google+ treated used as \u201cknowledge base\" to provide supervision.", "startOffset": 0, "endOffset": 4}, {"referenceID": 52, "context": "Homophily: Our work is based on the fundamental homophily property of online users [54], which assumes that people sharing", "startOffset": 83, "endOffset": 87}, {"referenceID": 89, "context": "Such properties have been harnessed for applications like community detection [92] or friend recommendation [27].", "startOffset": 78, "endOffset": 82}, {"referenceID": 25, "context": "Such properties have been harnessed for applications like community detection [92] or friend recommendation [27].", "startOffset": 108, "endOffset": 112}, {"referenceID": 15, "context": "Data Harvesting: The techniques adopted in like/dislike attribute extraction are related to a strand of work in data harvesting/information extraction, the point of which is to use some seeds to harvest some data, which is used to learn additional rules or patterns to harvest more data [16, 31, 40, 41, 73].", "startOffset": 287, "endOffset": 307}, {"referenceID": 29, "context": "Data Harvesting: The techniques adopted in like/dislike attribute extraction are related to a strand of work in data harvesting/information extraction, the point of which is to use some seeds to harvest some data, which is used to learn additional rules or patterns to harvest more data [16, 31, 40, 41, 73].", "startOffset": 287, "endOffset": 307}, {"referenceID": 38, "context": "Data Harvesting: The techniques adopted in like/dislike attribute extraction are related to a strand of work in data harvesting/information extraction, the point of which is to use some seeds to harvest some data, which is used to learn additional rules or patterns to harvest more data [16, 31, 40, 41, 73].", "startOffset": 287, "endOffset": 307}, {"referenceID": 39, "context": "Data Harvesting: The techniques adopted in like/dislike attribute extraction are related to a strand of work in data harvesting/information extraction, the point of which is to use some seeds to harvest some data, which is used to learn additional rules or patterns to harvest more data [16, 31, 40, 41, 73].", "startOffset": 287, "endOffset": 307}, {"referenceID": 71, "context": "Data Harvesting: The techniques adopted in like/dislike attribute extraction are related to a strand of work in data harvesting/information extraction, the point of which is to use some seeds to harvest some data, which is used to learn additional rules or patterns to harvest more data [16, 31, 40, 41, 73].", "startOffset": 287, "endOffset": 307}, {"referenceID": 14, "context": "Distant supervision is another methodology for data harvesting [15, 28, 57] that relies on structured data sources as a source of supervision for data harvesting from raw text.", "startOffset": 63, "endOffset": 75}, {"referenceID": 26, "context": "Distant supervision is another methodology for data harvesting [15, 28, 57] that relies on structured data sources as a source of supervision for data harvesting from raw text.", "startOffset": 63, "endOffset": 75}, {"referenceID": 55, "context": "Distant supervision is another methodology for data harvesting [15, 28, 57] that relies on structured data sources as a source of supervision for data harvesting from raw text.", "startOffset": 63, "endOffset": 75}, {"referenceID": 57, "context": "Logic/Relational Reasoning: Logic reasoning, usually based on first-order logic representations, can be tracked back to the early days of AI [59, 76], and has been adequately explored since then (e.", "startOffset": 141, "endOffset": 149}, {"referenceID": 74, "context": "Logic/Relational Reasoning: Logic reasoning, usually based on first-order logic representations, can be tracked back to the early days of AI [59, 76], and has been adequately explored since then (e.", "startOffset": 141, "endOffset": 149}, {"referenceID": 5, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 13, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 24, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 30, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 40, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 43, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 69, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 70, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 78, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 83, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 84, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 85, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 86, "context": ", [6, 14, 26, 32, 42, 45, 71, 72, 77, 81, 86, 87, 88, 89]).", "startOffset": 2, "endOffset": 57}, {"referenceID": 6, "context": "A variety of reasoning models have been proposed, based on ideas or concepts from the fields of graphical models, relational logic, or programming languages [7, 8, 60], each of which has it own generalization capabilities in terms of different types of data.", "startOffset": 157, "endOffset": 167}, {"referenceID": 7, "context": "A variety of reasoning models have been proposed, based on ideas or concepts from the fields of graphical models, relational logic, or programming languages [7, 8, 60], each of which has it own generalization capabilities in terms of different types of data.", "startOffset": 157, "endOffset": 167}, {"referenceID": 58, "context": "A variety of reasoning models have been proposed, based on ideas or concepts from the fields of graphical models, relational logic, or programming languages [7, 8, 60], each of which has it own generalization capabilities in terms of different types of data.", "startOffset": 157, "endOffset": 167}, {"referenceID": 59, "context": "Frameworks include Stochastic Logic Programs [61] which combines logic programming and log-linear models, Probabilistic Relational Networks [23] which incorporates Bayesian networks for reasoning, Relational Markov Networks [85] that uses dataset queries as cliques and model the state of clique in a Markov network, Relational Dependency Networks [62] which combines Bayes networks and Markov networks, and probabilistic similarity logic [7] which jointly considers probabilistic reasoning about similarities and relational structure.", "startOffset": 45, "endOffset": 49}, {"referenceID": 21, "context": "Frameworks include Stochastic Logic Programs [61] which combines logic programming and log-linear models, Probabilistic Relational Networks [23] which incorporates Bayesian networks for reasoning, Relational Markov Networks [85] that uses dataset queries as cliques and model the state of clique in a Markov network, Relational Dependency Networks [62] which combines Bayes networks and Markov networks, and probabilistic similarity logic [7] which jointly considers probabilistic reasoning about similarities and relational structure.", "startOffset": 140, "endOffset": 144}, {"referenceID": 82, "context": "Frameworks include Stochastic Logic Programs [61] which combines logic programming and log-linear models, Probabilistic Relational Networks [23] which incorporates Bayesian networks for reasoning, Relational Markov Networks [85] that uses dataset queries as cliques and model the state of clique in a Markov network, Relational Dependency Networks [62] which combines Bayes networks and Markov networks, and probabilistic similarity logic [7] which jointly considers probabilistic reasoning about similarities and relational structure.", "startOffset": 224, "endOffset": 228}, {"referenceID": 60, "context": "Frameworks include Stochastic Logic Programs [61] which combines logic programming and log-linear models, Probabilistic Relational Networks [23] which incorporates Bayesian networks for reasoning, Relational Markov Networks [85] that uses dataset queries as cliques and model the state of clique in a Markov network, Relational Dependency Networks [62] which combines Bayes networks and Markov networks, and probabilistic similarity logic [7] which jointly considers probabilistic reasoning about similarities and relational structure.", "startOffset": 348, "endOffset": 352}, {"referenceID": 6, "context": "Frameworks include Stochastic Logic Programs [61] which combines logic programming and log-linear models, Probabilistic Relational Networks [23] which incorporates Bayesian networks for reasoning, Relational Markov Networks [85] that uses dataset queries as cliques and model the state of clique in a Markov network, Relational Dependency Networks [62] which combines Bayes networks and Markov networks, and probabilistic similarity logic [7] which jointly considers probabilistic reasoning about similarities and relational structure.", "startOffset": 439, "endOffset": 442}, {"referenceID": 5, "context": ", [6]), health modeling [21], group modeling [29], web link based clustering [22], object identification [20], trust analysis [30], and many more.", "startOffset": 2, "endOffset": 5}, {"referenceID": 27, "context": ", [6]), health modeling [21], group modeling [29], web link based clustering [22], object identification [20], trust analysis [30], and many more.", "startOffset": 45, "endOffset": 49}, {"referenceID": 20, "context": ", [6]), health modeling [21], group modeling [29], web link based clustering [22], object identification [20], trust analysis [30], and many more.", "startOffset": 77, "endOffset": 81}, {"referenceID": 19, "context": ", [6]), health modeling [21], group modeling [29], web link based clustering [22], object identification [20], trust analysis [30], and many more.", "startOffset": 105, "endOffset": 109}, {"referenceID": 28, "context": ", [6]), health modeling [21], group modeling [29], web link based clustering [22], object identification [20], trust analysis [30], and many more.", "startOffset": 126, "endOffset": 130}, {"referenceID": 1, "context": "summarized by the proverb \u201cbirds of a feather flock together\" [2].", "startOffset": 62, "endOffset": 65}], "year": 2014, "abstractText": "We propose a framework for inferring the latent attitudes or preferences of users by performing probabilistic first-order logical reasoning over the social network graph. Our method answers questions about Twitter users like Does this user like sushi? or Is this user a New York Knicks fan? by building a probabilistic model that reasons over user attributes (the user\u2019s location or gender) and the social network (the user\u2019s friends and spouse), via inferences like homophily (I am more likely to like sushi if spouse or friends like sushi, I am more likely to like the Knicks if I live in New York). The algorithm uses distant supervision, semi-supervised data harvesting and vector space models to extract user attributes (e.g. spouse, education, location) and preferences (likes and dislikes) from text. The extracted propositions are then fed into a probabilistic reasoner (we investigate both Markov Logic and Probabilistic Soft Logic). Our experiments show that probabilistic logical reasoning significantly improves the performance on attribute and relation extraction, and also achieves an F-score of 0.791 at predicting a users likes or dislikes, significantly better than two strong baselines.", "creator": "LaTeX with hyperref package"}}}