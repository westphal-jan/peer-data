{"id": "1411.5014", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Nov-2014", "title": "Music Data Analysis: A State-of-the-art Survey", "abstract": "Music accounts for a significant chunk of interest among various online activities. This is reflected by wide array of alternatives offered in music related web/mobile apps, information portals, featuring millions of artists, songs and events attracting user activity at similar scale. Availability of large scale structured and unstructured data has attracted similar level of attention by data science community. This paper attempts to offer current state-of-the-art in music related analysis. Various approaches involving machine learning, information theory, social network analysis, semantic web and linked open data are represented in the form of taxonomy along with data sources and use cases addressed by the research community.", "histories": [["v1", "Tue, 18 Nov 2014 14:19:28 GMT  (1661kb,D)", "http://arxiv.org/abs/1411.5014v1", "10 pages, 6 figures"]], "COMMENTS": "10 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.DB cs.LG cs.SD", "authors": ["shubhanshu gupta"], "accepted": false, "id": "1411.5014"}, "pdf": {"name": "1411.5014.pdf", "metadata": {"source": "CRF", "title": "Music Data Analysis: A State-of-the-art Survey", "authors": ["Shubhanshu Gupta"], "emails": ["gupta@daiict.ac.in"], "sections": [{"heading": null, "text": "Music is an essential part of the interest among the various online activities, reflected in a wide range of alternatives offered in music-related web / mobile applications and information portals that feature millions of artists, songs and events that attract user activity of a similar magnitude. Large-scale availability of structured and unstructured data has attracted a similar amount of attention in data science, and this paper attempts to provide the state-of-the-art in music-related analysis. Various approaches in machine learning, information theory, social networking analysis, the semantic web, and networked open data are presented in the form of taxonomy, along with data sources and use cases addressed by the research community."}, {"heading": "1 Introduction", "text": "With these developments, we are moving toward an interesting contrasting trend. In times of tough record sales (records, cassettes, records), it has been easy to track sales while it has been difficult or impossible to track the number of playbacks by listeners in their music systems. As music is increasingly published, distributed, played and discussed online, it has become possible to track different aspects individually by analyzing the data in near real time. However, with millions of songs, artists, events that are touched by potentially billions of listeners online, the resulting online activities open up huge research opportunities for data science. While we are interested in exploring research opportunities that include current big data technologies, we are initially trying to capture the current state of the art in music data analysis to clearly identify types of data sets, features, analytical techniques used by the research community to support various applications.Although we are trying to use case studies to select the results and representative data sets."}, {"heading": "2 Music Analysis Use Cases and", "text": ""}, {"heading": "2.1 Prediction and Recognition of Musical Aspects", "text": "Music data analysis is widely used to automatically predict or detect various musical aspects such as music style, genre, mood, emotion, beginning, melodic sequence, and prediction of a song's success. Appropriate musical characteristics associated with these aspects are identified, extracted, processed, and subjected to various analytical techniques to make predictions. This use case is particularly useful for automated song tagging, synthesis of new music, and determining the potential success a song could achieve."}, {"heading": "2.1.1 Style", "text": "In our survey, we came up with the idea that you should go in search of new ideas."}, {"heading": "2.1.2 Genre", "text": "The most frequently cited data sets for performing genre classifications are GTZAN, ISMIR genre, ISMIR rhythms, and Latin music databases, which are used for large-format music genre classifications. Significant performance gains are achieved by beat-aligned vector sequences for large amounts of data. Six motor combinations of echoes are used to capture the temporal domain."}, {"heading": "2.1.3 Mood", "text": "This year, it will only take one year for an agreement to be reached."}, {"heading": "2.1.4 Melodic Sequence", "text": "Figure 3: Approaches to analyzing music data applied to mood analysis.Comprehensive analysis of sequence structures in music, including other musical characteristics and polyphonic structures, serves as a starting point for musical pitches. The dataset consisted of 185 J.S.Bach choral melodies and it was found that the neural probability model has done a pretty good job of modelling musical sequences, but still does not know whether predictions can be improved if other musical characteristics such as note durations, intervals, etc. are introduced or not. Also, the current model has not been offered for modelling and analysis of polyphonic music, and therefore there is scope for extending the model by a larger and larger dataset instead of restricting it to the scope of monophonic melodies. [5]"}, {"heading": "2.1.5 Onset Detection", "text": "In addition to the different types and types of classification of music, it is sometimes also necessary to obtain information on various high-level tasks that fall under the paradigm of music information recovery, such as insertion detection. The insertion detection function helps to identify the starting points of various music-relevant events in an audio stream, such as attractiveness, score sequences and music transcription. Therefore, there is a peak-picking algorithm based on artificial neural networks (bidirectional recursive neural network, here) that is trained in a monitored manner for common insertion detection functions. The data set used for evaluation purposes consisted of 321 audio extracts covering different types of music genres performed on different instruments, with a total length of approximately 102 minutes and 25,927 commented settings [27]."}, {"heading": "2.1.6 Song Hit Prediction", "text": "Machine learning is also used to predict the success of songs even before they hit the market, which is known as pop song science. Accurate models are built to predict whether or not a song would be a top-10 dance hit for which a data set of dance hits was retrieved that contained 21,692 cases with five characteristics: song title, artist, position, top position, and date, and these cases were retrieved from 3,452 of 4,120 unique songs in the chart database. Five machine classification techniques, namely C4.5 decision tree, logistic regression (which falls under linear classifications) of the statistical classification method, and support vector machines (SVM), RIPPER rulebook, and naive Bayes are used to create hit classifications. Results have clearly shown that logistic regression techniques are best compared to all the other techniques that nowadays are naive music derived from and that Bavarian measure is observed to be effective."}, {"heading": "2.2 Classification", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.2.1 Music Classification", "text": "The basic tasks of music classification include music data collections (so-called instances), audio recordings, scores, cultural data (e.g. playlists, album reviews, billboard statistics, etc.), which also include metadata about instances such as artist ID, title, composer, artist, genre, date, etc. This music data collection is subject to trait extraction, with traits representing characteristic information about instances, and finally learning machine learning algorithms (classifiers and learners) to associate traits of instances with their music classification classs. jMIR, a powerful, flexible and accessible software, is designed to meet the need for standardized MIR research software to design, share and apply a wide range of automatic music classification techniques."}, {"heading": "2.2.2 Similarity", "text": "This year, the time has come for an agreement to be reached in just a few days."}, {"heading": "2.2.3 Emotion", "text": "This year, it has reached the point where it will be able to put itself at the top of the list."}, {"heading": "2.3 Audio Analysis", "text": "For similar reasons to jMIR, an open-source, cross-platform C + + library Essentia 2.0 is available for audio analysis and audio-based music information retrieval under the Affero GPL license. The library houses an extensive collection of reusable algorithms for implementing audio input / output functionality, standard digital signal processing blocks, statistical characterization of data, and a large number of spectral, temporal, tonal, and high-level musical descriptors. Essentia offers algo rithms for: basic processing of audio input / output filtering, for calculating low-level spectral descriptors, calculating time domain descriptors, calculating tonal descriptors, calculating rhythm descriptors, calculating SFX descriptors for detecting low-level spectral descriptors, calculating time domain descriptors, calculating rhythm descriptors, calculating high-level descriptors for detecting audio effects, and also providing the high-level detection of audio input / output algorithms, as well as the high-level detection of audio effects for the aforementioned input algorithms, and input algorithms."}, {"heading": "2.4 Recommendation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.4.1 Music Recommendation", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "2.4.2 Playlist Recommendation", "text": "Similar to SoCo, there is another system called MyMusic that uses social media sources to generate personalized music playlists, based on information extracted from social networks such as Facebook and Last.fm to perform the personalization tasks of defining a model of user interest based on user information related to music preferences on social networks. the social media-based playlist is enriched with new artists that the user already likes. And, in particular, two enrichment techniques are applied: in the first, the knowledge stored on DBpedia is used, while in the second, its playlists based on content-based similarity lie between the descriptions of artists. Afterwards, the final playlist is placed accordingly and presented to the user to listen to the songs and for feedback [19], it is also possible to contextualize these playlists, a set of songs based on the content-based similarity are evaluated between the descriptions of artists, and then the final playlist is presented to the user for listening to the songs and for feedback [28], it is also possible to contextualize these playlists, a set of songs based on the content-based similarity of millions that are used as a recommendation machine with the help of social networking."}, {"heading": "3 Discussion", "text": "In most cases, these records consist of a relatively small number of audio files in the form of MIDI sequences, user-generated tags, accompanying web pages or user contexts. While these types of music records are certainly a critical part of the music industry, many other aspects remain unaffected by such research efforts: music credit data, licensing and rights data, digital supply chain data, music sales and distribution data, cataloging, classification and archiving of data from music organizations, data on music-related standards, data on live events and data on studio recordings generated throughout the lifecycle of a music professional. These records can be maintained by different organizations at multiple levels of detail, accuracy and updating frequency with potential overlaps. Since most of these data sources are constantly updated with varying frequency, the task of integrating and managing records that are currently available at the level of data sets can be identified as important applications."}, {"heading": "4 Conclusions", "text": "In this paper, we have sought to provide an up-to-date overview of research efforts in the field of music data analysis. Our goal is to examine a report that examines different analytical approaches of the research community, focusing on unique musical characteristics, resulting in the presentation of a technological landscape of analytical techniques, including machine learning, the semantic web, social network analysis, information retrieval statistics, and information theory. Our analysis also identified opportunities for further exploration, keeping in mind the new opportunities offered by recent developments in the big data discipline."}], "references": [{"title": "Multidisciplinary Perspectives on Music Emotion Recognition : Implications for Content and Context-Based Models", "author": ["M. Barthet"], "venue": "(June):19\u201322", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Automatic tagging of audio: The state-of-the-art", "author": ["T. Bertin-Mahieux", "D. Eck", "M.I. Mandel"], "venue": "W. Wang, editor, Machine Audition: Principles, Algorithms and Systems, chapter 14, pages 334\u2013352. IGI Publishing", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Essentia: An Audio Analysis Library for Music Information Retrieval", "author": ["D. Bogdanov", "N. Wack", "E. G\u00f3mez", "S. Gulati"], "venue": "ISMIR, pages 2\u20137", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "A Neural Probabilistic Model for Predicting Melodic Sequences", "author": ["S. Cherla", "A. Garcez", "T. Weyde"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Machine Learning Approaches for Mood Classification of Songs toward Music Search Engine", "author": ["T.-T. Dang", "K. Shirai"], "venue": "In 2009 International Conference on Knowledge and Systems Engineering,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "A Machine Learning Approach to Musical Style Recognition A Machine Learning Approach to Musical Style Recognition", "author": ["R.B. Dannenberg", "B. Thom", "D. Watson"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1997}, {"title": "An e-Research approach to Web-scale music analysis", "author": ["D. De Roure", "K.R. Page", "B. Fields", "T. Crawford", "J.S. Downie", "I. Fujinaga"], "venue": "Philosophical transactions. Series A, Mathematical, physical, and engineering sciences, 369", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1949}, {"title": "Using machine-learning methods for musical style modeling", "author": ["S. Dubnov", "G. Assayag", "O. Lartillot", "G. Bejerano"], "venue": "Computer, (August):3\u201310", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Contextualize Your Listening : The Playlist as Recommendation Engine", "author": ["B. Fields"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Music recommendation and discovery in the long tail ", "author": ["C. Herrada"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Dance Hit Song Science", "author": ["D. Herremans", "D. Martens"], "venue": "pages 1\u20134", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Automated Music Emotion Recognition: A Systematic Evaluation", "author": ["A. Huq", "J.P. Bello", "R. Rowe"], "venue": "Journal of New Music Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Contextual music information retrieval and recommendation: State of the art and challenges", "author": ["M. Kaminskas", "F. Ricci"], "venue": "Computer Science Review, 6(2):89\u2013119", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Genre classification of symbolic music with SMBGT", "author": ["A. Kotsifakos", "E.E. Kotsifakos", "P. Papapetrou", "V. Athitsos"], "venue": "Proceedings of the 6th International Conference on PErvasive Technologies Related to Assistive Environments - PETRA \u201913, number Midi, pages 1\u20137, New York, New York, USA", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic music classification with jMIR", "author": ["C. McKay"], "venue": "PhD thesis, Citeseer", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Leveraging Social Media Sources to Generate Personalized Music Playlists", "author": ["C. Musto", "G. Semeraro", "P. Lops", "M. de Gemmis", "F. Narducci"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "dbrec Music Recommendations Using DBpedia", "author": ["A. Passant"], "venue": "1380:1\u201316", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Implementing situation-aware and user-adaptive music recommendation service in semantic web and real-time multimedia computing environment", "author": ["S. Rho", "S. Song", "Y. Nam", "E. Hwang", "M. Kim"], "venue": "Multimedia Tools and Applications,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Music Emotion Recognition : The Importance of Melodic Features", "author": ["B. Rocha", "R. Panda", "R.P. Paiva"], "venue": "", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "Exploring the music similarity space on the web", "author": ["M. Schedl", "T. Pohle", "P. Knees", "G. Widmer"], "venue": "ACM Transactions on Information Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Capturing the temporal domain in echonest features for improved classification effectiveness", "author": ["A. Schindler", "A. Rauber"], "venue": "Proc. Adaptive Multimedia Retrieval, pages 1\u201315", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "A FILTER- AND-REFINE INDEXING METHOD FOR FAST SIMILARITY SEARCH IN MILLIONS OF MUSIC TRACKS", "author": ["D. Schnitzer", "A. Flexer", "G. Widmer"], "venue": "(April):537\u2013542", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Enhanced peak picking for onset detection with recurrent neural networks", "author": ["B. Sebastian", "J. Schl"], "venue": "pages 1\u20134", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Enriching music mood annotation by semantic association reasoning", "author": ["J. Wang", "X. Anguera", "X. Chen", "D. Yang"], "venue": "In 2010 IEEE International Conference on Multimedia and Expo, number c,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "Combining Sources of Description for Approximating Music Similarity Ratings", "author": ["D. Wolff", "T. Weyde"], "venue": "M. Detyniecki, A. Gar\u0107\u0131a-Serrano, A. N\u00fcrnberger, and S. Stober, editors, Adaptive Multimedia Retrieval. Large-Scale Multimedia Retrieval and Evaluation, volume 7836 of Lecture Notes in Computer Science, pages 114\u2013124. Springer Berlin Heidelberg, Berlin, Heidelberg", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "All the training examples that rest in the dataset were used for classifying improvisational style rather than music feature selection and feature learning [7] .", "startOffset": 156, "endOffset": 159}, {"referenceID": 7, "context": "stricted dictionary of only those motifs that both, appear a significant number of times throughout the complete source sequence and at the same time, are meaningful for predicting the immediate future [9].", "startOffset": 202, "endOffset": 205}, {"referenceID": 20, "context": ") provided by the million song data-set [25].", "startOffset": 40, "endOffset": 44}, {"referenceID": 13, "context": "And one of the most prominent space left which can be worked upon is the analysis of polyphonic music instead of just MIDI [17].", "startOffset": 123, "endOffset": 127}, {"referenceID": 6, "context": "Adopting the e-science approach for data and compute intensive jobs, the e-Research infrastructure configured to perform NEMA (Network Environment for Music Analysis) genre classification workflow over Jamendo free music collection dataset that are converted into semantic representations [8].", "startOffset": 289, "endOffset": 292}, {"referenceID": 4, "context": "But if proper audio information like artist, sentiment words, more weightage on words in chorus and title parts, on combining with lyrics might fetch better accuracy and results of mood classification [6].", "startOffset": 201, "endOffset": 204}, {"referenceID": 23, "context": "observed that the accuracy of the mood annotation can improve by a large extent by the embellishment of the other meta data because of the proliferating context based social meta data information, burgeoning from the social media sites [29].", "startOffset": 236, "endOffset": 240}, {"referenceID": 3, "context": "melodies [5].", "startOffset": 9, "endOffset": 12}, {"referenceID": 22, "context": "The data set used for evaluation purpose consisted of 321 audio excerpts covering different types of musical genres, performed on various instruments and having a total length of approximately 102 minutes and 25, 927 annotated onsets [27].", "startOffset": 234, "endOffset": 238}, {"referenceID": 10, "context": "There has been some work in determining popularity of a song, based on acoustic, lyric, and human based features, but these factors too have not been able to deliver the results [13].", "startOffset": 178, "endOffset": 182}, {"referenceID": 14, "context": "ings, symbolic recordings and cultural data were combined, instead of using features from just one type of data [18].", "startOffset": 112, "endOffset": 116}, {"referenceID": 21, "context": "yield a better and accurate mapping of the original similarity space [26].", "startOffset": 69, "endOffset": 73}, {"referenceID": 19, "context": "ity estimation of music which is a specific, important task of music information research [24].", "startOffset": 90, "endOffset": 94}, {"referenceID": 24, "context": "MagnaTagATune dataset consists of features and tagging information of 25863 29-second audio clips generated from 5405 source MP3s [28], [30] .", "startOffset": 136, "endOffset": 140}, {"referenceID": 18, "context": "being achieved using SVM classifiers [23].", "startOffset": 37, "endOffset": 41}, {"referenceID": 0, "context": "It was found that CLR classifier using a Support Vector Ma-chine (SVM) outperformed all other approaches besides performing competitively with Decision Trees, BPMLL and MLkNN [1].", "startOffset": 175, "endOffset": 178}, {"referenceID": 11, "context": "Using all standardized features and a coarse-grid search for the best parameters, the regression SVR with RBF kernel performs the best [14].", "startOffset": 135, "endOffset": 139}, {"referenceID": 2, "context": "tection, instrument solo detection and acoustic analysis of stimuli for neuroimaging studies [3].", "startOffset": 93, "endOffset": 96}, {"referenceID": 16, "context": "to optimize the query process ; then comes computing the distances using the LDSD algorithm and representing them using its ontology; and to delineate the recommendations, building of a user-interface comes as a last step for browsing recommendations [20].", "startOffset": 251, "endOffset": 255}, {"referenceID": 17, "context": "It is used for expressing and processing necessary queries to the ontology [22].", "startOffset": 75, "endOffset": 79}, {"referenceID": 9, "context": "Then there is a music search engine, named Searchsounds, providing keyword based search, as well as the exploration of similar songs using audio similarity and thereby allowing users to discover music, even unknown to them [12].", "startOffset": 223, "endOffset": 227}, {"referenceID": 12, "context": "Since, it is not clear which of the two (CF or content-based approach) has a bigger impact on quality recommendation, its best to mix the two techniques in hybrid approach for music recommendation [15].", "startOffset": 197, "endOffset": 201}, {"referenceID": 1, "context": "HGMM, SVM, and Boosting are one of the three best performing algorithms on automatic tagging [2].", "startOffset": 93, "endOffset": 96}, {"referenceID": 15, "context": "Thereafter the final playlist is ranked accordingly and presented to the user for listen to the songs and for feedback [19],", "startOffset": 119, "endOffset": 123}, {"referenceID": 8, "context": "32 mean numbers of songs per playlists [11].", "startOffset": 39, "endOffset": 43}], "year": 2014, "abstractText": "Music accounts for a significant chunk of interest among various online activities. This is reflected by wide array of alternatives offered in music related web/mobile apps, information portals, featuring millions of artists, songs and events attracting user activity at similar scale. Availability of large scale structured and unstructured data has attracted similar level of attention by data science community. This paper attempts to offer current state-of-the-art in music related analysis. Various approaches involving machine learning, information theory, social network analysis, semantic web and linked open data are represented in the form of taxonomy along with data sources and use cases addressed by the research community.", "creator": "LaTeX with hyperref package"}}}