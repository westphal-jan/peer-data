{"id": "1411.6231", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2014", "title": "Compound Rank-k Projections for Bilinear Analysis", "abstract": "In many real-world applications, data are represented by matrices or high-order tensors. Despite the promising performance, the existing two-dimensional discriminant analysis algorithms employ a single projection model to exploit the discriminant information for projection, making the model less flexible. In this paper, we propose a novel Compound Rank-k Projection (CRP) algorithm for bilinear analysis. CRP deals with matrices directly without transforming them into vectors, and it therefore preserves the correlations within the matrix and decreases the computation complexity. Different from the existing two dimensional discriminant analysis algorithms, objective function values of CRP increase monotonically.In addition, CRP utilizes multiple rank-k projection models to enable a larger search space in which the optimal solution can be found. In this way, the discriminant ability is enhanced.", "histories": [["v1", "Sun, 23 Nov 2014 12:50:20 GMT  (1468kb)", "https://arxiv.org/abs/1411.6231v1", "10 pages"], ["v2", "Sun, 24 May 2015 07:58:29 GMT  (1467kb)", "http://arxiv.org/abs/1411.6231v2", "10 pages"], ["v3", "Wed, 3 Jun 2015 04:26:25 GMT  (3259kb)", "http://arxiv.org/abs/1411.6231v3", "Accepted by IEEE Transactions on Neural Networks and Learning Systems (IEEE T-NNLS), 2015"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["xiaojun chang", "feiping nie", "sen wang", "yi yang", "xiaofang zhou", "chengqi zhang"], "accepted": false, "id": "1411.6231"}, "pdf": {"name": "1411.6231.pdf", "metadata": {"source": "CRF", "title": "Compound Rank-k Projections for Bilinear Analysis", "authors": ["Xiaojun Chang", "Feiping Nie", "Sen Wang", "Yi Yang"], "emails": ["chengqi.zhang@uts.edu.au}", "nie@gmail.com"], "sections": [{"heading": null, "text": "That is, it is not as if this is a purely theoretical method of data representation and extraction. FLD aims to find a set of vectors to maximize the trace of the intermediate scatter matrix, while minimizing the scatter matrix within the class scatter matrix. Recent works on the fact that it is more natural and advantageous to represent an image with a classical scatter matrix than to represent a classical scatter matrix within the class scatter matrix."}], "references": [{"title": "Feature reduction via generalized uncorrelated linear discriminant analysis", "author": ["J. Ye", "R. Janardan", "Q. Li", "H. Park"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 18, no. 10, pp. 1312\u20131322, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Generalization performance of fisher linear discriminant based on markov sampling", "author": ["B. Zou", "L. Li", "Z. Xu", "T. Luo", "Y.Y. Tang"], "venue": "IEEE Trans. Neural Netw. Learn. Syst., vol. 24, no. 2, pp. 288\u2013300, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Feature extraction and uncorrelated discriminant analysis for high-dimensional data", "author": ["W.-H. Yang", "D.-Q. Dai", "H. Yan"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 20, no. 5, pp. 601\u2013614, 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning regularized lda by clustering", "author": ["Y. Pang", "S. Wang", "Y. Yuan"], "venue": "IEEE Trans. Neural Netw. Learn. Syst., 2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Eigenfaces vs. fisherfaces: Recognition using class specific linear projection", "author": ["P.N. Belhumeur", "J.P. Hespanha", "D. Kriegman"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 19, no. 7, pp. 711\u2013720, 1997.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1997}, {"title": "Thinking of images as what they are: Compound matrix regression for image classification", "author": ["Z. Ma", "Y. Yang", "F. Nie", "N. Sebe"], "venue": "IJCAI, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Efficient image classification via multiple rank regression", "author": ["C. Hou", "F. Nie", "D. Yi", "Y. Wu"], "venue": "IEEE Transactions on Image Processing, vol. 22, no. 1, pp. 340\u2013352, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Algebraic feature extraction for image recognition based on an optimal discriminant criterion", "author": ["K. Liu", "Y.-Q. Cheng", "J.-Y. Yang"], "venue": "Pattern Recog., vol. 26, no. 6, pp. 903\u2013911, 1993.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1993}, {"title": "Two-dimensional linear discriminant analysis", "author": ["J. Ye", "R. Janardan", "Q. Li"], "venue": "NIPS, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Non-iterative two-dimensional linear discriminant analysis", "author": ["K. Inoue", "K. Urahama"], "venue": "ICPR, 2006.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Local linear discriminant analysis framework using sample neighbors", "author": ["Z. Fan", "Y. Xu", "D. Zhang"], "venue": "IEEE Trans. Neural Netw., vol. 22, no. 7, pp. 1119\u20131132, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Formulating robust linear regression estimation as a one-class lda criterion: Discriminative hat matrix", "author": ["F. Dufrenois", "J.C. Noyer"], "venue": "IEEE Trans. Neural Netw. Learn. Syst., vol. 24, no. 2, pp. 262\u2013273, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Twodimensional fld for face recognition", "author": ["H. Xiong", "M.N.S. Swamy", "M.O. Ahmad"], "venue": "Pattern Recog., vol. 38, no. 7, pp. 1121\u20131124, 2005.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "A multimedia retrieval framework based on semi-supervised ranking and relevance feedback", "author": ["Y. Yang", "F. Nie", "D. Xu", "J. Luo", "Y. Zhuang", "Y. Pan"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 4, pp. 723\u2013742, 2012.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Linear image coding for regression and classification using the tensor-rank principle", "author": ["A. Shashua", "A. Levin"], "venue": "CVPR, 2001.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "2d-lda: A statistical linear discriminant analysis for image matrix", "author": ["M. Li", "B. Yuan"], "venue": "Pattern Recognit. Letters, vol. 26, no. 5, pp. 527\u2013532, 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Srda: An efficient algorithm for large-scale discriminant analysis", "author": ["D. Cai", "X. He", "J. Han"], "venue": "IEEE Trans. Kowl. Data Eng., vol. 20, no. 1, pp. 1\u201312, 2008.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning a propagable graph for semisupervised learning: classification and regression", "author": ["B. Ni", "S. Yan", "A. Kassim"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 24, no. 1, pp. 114\u2013126, 2012.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Multitask linear discriminant analysis for view invariant action recognition", "author": ["Y. Yan", "E. Ricci", "S. Ramanathan", "G. Liu", "N. Sebe"], "venue": "IEEE Transactions on Image Processing, vol. 42, no. 1, pp. 105\u2013114, 2009.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Clustered multi-task linear discriminant analysis for view invariant color-depth action recognition", "author": ["Y. Yan", "E. Ricci", "G. Liu", "R. Subramanian", "N. Sebe"], "venue": "ICPR, 2014.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Adaptive nonlinear discriminant analysis by regularized minimum squared errors", "author": ["H. Kim", "B.L. Drake", "H. Park"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 18, no. 5, pp. 603\u2013612, 2006.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Classification of hyperspectral images with regularized linear discriminant analysis", "author": ["T.V. Bandos", "L. Bruzzone", "G. Camps-Valls"], "venue": "IEEE Trans. Geos. Remo. Sens., vol. 47, no. 3, pp. 862\u2013 873, 2009.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Multi-label boosting for image annotation by structural grouping sparsity", "author": ["F. Wu", "Y. Han", "Q. Tian", "Y. Zhuang"], "venue": "ACM MM, 2010.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi-task sparse discriminant analysis (mtsda) with overlapping categories", "author": ["Y. Han", "F. Wu", "J. Jia", "Y. Zhuang", "B. Yu"], "venue": "AAAI, 2010.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Extracting the optimal dimensionality for local tensor discriminant analysis", "author": ["F. Nie", "S. Xiang", "Y. Song", "C. Zhang"], "venue": "Pattern Recognition, vol. 42, no. 1, pp. 105\u2013114, 2009.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Complexityreduced scheme for feature extraction with linear discriminant analysis", "author": ["Y. Hou", "L. Song", "H.-K. Min", "C.H. Park"], "venue": "IEEE Trans. Neural Netw. Learn. Syst., vol. 23, no. 6, pp. 1003\u20131009, 2012.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Feature extraction with deep neural networks by a generalized discriminant analysis", "author": ["A. Stuhlsatz", "J. Lippel", "T. Zielke"], "venue": "IEEE Trans. Neural Netw. Learn. Syst., vol. 23, no. 4, pp. 596\u2013608, 2012.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Regularized kernel discriminant analysis with a robust kernel for face recognition and verification", "author": ["S. Zafeiriou", "G. Tzimiropoulos", "M. Petrou", "T. Stathaki"], "venue": "IEEE Trans. Neural Netw. Learn. Syst., vol. 23, no. 3, pp. 526\u2013534, 2012.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Trace ratio problem revisited", "author": ["Y. Jia", "F. Nie", "C. Zhang"], "venue": "IEEE Trans. Neural Netw., vol. 20, no. 4, pp. 729\u2013735, 2009.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2009}, {"title": "Image clustering using local discriminant models and global integration", "author": ["Y. Yang", "D. Xu", "F. Nie", "S. Yan", "Y. Zhuang"], "venue": "IEEE Trans. Image Process., vol. 19, no. 10, pp. 2761\u20132773, 2010.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "Extracting the optimal dimensionality for local tensor discriminant analysis", "author": ["F. Nie", "S. Xiang", "Y. Song", "C. Zhang"], "venue": "Pattern Recognition, pp. 105\u2013114, 2009.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Twodimensional pca: a new approach to appearance-based face representation and recognition", "author": ["J. Yang", "D. Zhang", "A.F. Frangi", "J. yu Yang"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 16, no. 1, pp. 131\u2013137, 2004.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2004}, {"title": "Bilinear classifiers for visual recognition", "author": ["H. Pirsiavash", "D. Ramanan", "C. Fowlkes"], "venue": "NIPS, 2009.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "Tensor subspace analysis", "author": ["X. He", "D. Cai", "P. Niyogi"], "venue": "NIPS, 2005.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2005}, {"title": "Multiple rank multi-linear SVM for matrix data classification", "author": ["C. Hou", "F. Nie", "C. Zhang", "D. Yi", "Y. Wu"], "venue": "Pattern Recognition, vol. 47, no. 1, pp. 454\u2013469, 2014.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "A comprehensive head pose and gaze database", "author": ["U. Weidenbacher", "G. Layher", "P.-M. Strauss", "H. Neumann"], "venue": "Intelligent Environments, 2007.  JOURNAL OF  LTEX CLASS FILES, VOL. X, NO. X, XXXXXXX 20XX  12", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2007}, {"title": "Icdar 2013 competition on handwritten digit recognition (hdrc 2013)", "author": ["M. Diem", "S. Fiel", "A. Garz", "M. Keglevic", "F. Kleber", "R. Sablatnig"], "venue": "Proc. ICDAR, 2013.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2013}, {"title": "Estimating face orientation from robust detection of salient facial features", "author": ["N. Gourier", "D. Hall", "J.L. Crowley"], "venue": "Proc. ICPR Workshop on Visual Observation of Deictic Gestures, 2004.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "FLD is commonly utilized in the fields of computer vision and pattern recognition [1], [2], [3], [4].", "startOffset": 82, "endOffset": 85}, {"referenceID": 1, "context": "FLD is commonly utilized in the fields of computer vision and pattern recognition [1], [2], [3], [4].", "startOffset": 87, "endOffset": 90}, {"referenceID": 2, "context": "FLD is commonly utilized in the fields of computer vision and pattern recognition [1], [2], [3], [4].", "startOffset": 92, "endOffset": 95}, {"referenceID": 3, "context": "FLD is commonly utilized in the fields of computer vision and pattern recognition [1], [2], [3], [4].", "startOffset": 97, "endOffset": 100}, {"referenceID": 4, "context": "[5] use LDA to represent facial expression images efficiently.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "au representation [6], [7].", "startOffset": 18, "endOffset": 21}, {"referenceID": 6, "context": "au representation [6], [7].", "startOffset": 23, "endOffset": 26}, {"referenceID": 7, "context": "[8] propose to use an optimal discriminant criterion to extract algebraic features, calculating a set of optimal discriminant projection vectors according to a generalized Fisher criterion function.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9], aims to learn a single set of projection matrices and introduces an iterative algorithm.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10], however, have pointed out the iterative algorithm proposed in [9] does not necessarily guarantee the monotonicity of the objective function value, which is mainly caused by the singularity of the between-class scatter matrix.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[10], however, have pointed out the iterative algorithm proposed in [9] does not necessarily guarantee the monotonicity of the objective function value, which is mainly caused by the singularity of the between-class scatter matrix.", "startOffset": 68, "endOffset": 71}, {"referenceID": 9, "context": "In [10], they present a simple method, namely Selective Algorithm for 2DLDA, to select transformation matrices with a higher discriminant ability.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "Another limitation of all the existing discriminant analysis algorithms [1], [2], [3], [5], [11], [12], [9], [13], [14] is that their performance suffer from the balance between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 72, "endOffset": 75}, {"referenceID": 1, "context": "Another limitation of all the existing discriminant analysis algorithms [1], [2], [3], [5], [11], [12], [9], [13], [14] is that their performance suffer from the balance between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 77, "endOffset": 80}, {"referenceID": 2, "context": "Another limitation of all the existing discriminant analysis algorithms [1], [2], [3], [5], [11], [12], [9], [13], [14] is that their performance suffer from the balance between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 82, "endOffset": 85}, {"referenceID": 4, "context": "Another limitation of all the existing discriminant analysis algorithms [1], [2], [3], [5], [11], [12], [9], [13], [14] is that their performance suffer from the balance between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 87, "endOffset": 90}, {"referenceID": 10, "context": "Another limitation of all the existing discriminant analysis algorithms [1], [2], [3], [5], [11], [12], [9], [13], [14] is that their performance suffer from the balance between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 92, "endOffset": 96}, {"referenceID": 11, "context": "Another limitation of all the existing discriminant analysis algorithms [1], [2], [3], [5], [11], [12], [9], [13], [14] is that their performance suffer from the balance between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 98, "endOffset": 102}, {"referenceID": 8, "context": "Another limitation of all the existing discriminant analysis algorithms [1], [2], [3], [5], [11], [12], [9], [13], [14] is that their performance suffer from the balance between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 104, "endOffset": 107}, {"referenceID": 12, "context": "Another limitation of all the existing discriminant analysis algorithms [1], [2], [3], [5], [11], [12], [9], [13], [14] is that their performance suffer from the balance between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 109, "endOffset": 113}, {"referenceID": 13, "context": "Another limitation of all the existing discriminant analysis algorithms [1], [2], [3], [5], [11], [12], [9], [13], [14] is that their performance suffer from the balance between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 115, "endOffset": 119}, {"referenceID": 14, "context": "To overcome this problem, the authors [15] has proposed multiple rank-1 projection method based on the principal component.", "startOffset": 38, "endOffset": 42}, {"referenceID": 8, "context": "Different from [9], the convergence of our optimization approach is explicitly guaranteed.", "startOffset": 15, "endOffset": 18}, {"referenceID": 8, "context": "2) Compared to the classical 2-dimensional linear discriminant analysis methods [9], [13], [16], CRP benefits from the trade-off between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 80, "endOffset": 83}, {"referenceID": 12, "context": "2) Compared to the classical 2-dimensional linear discriminant analysis methods [9], [13], [16], CRP benefits from the trade-off between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 85, "endOffset": 89}, {"referenceID": 15, "context": "2) Compared to the classical 2-dimensional linear discriminant analysis methods [9], [13], [16], CRP benefits from the trade-off between the degree of freedom and the avoidance of the over-fitting problem.", "startOffset": 91, "endOffset": 95}, {"referenceID": 16, "context": "1 Classical LDA The conventional LDA aims to project the original high-dimensional data to a lower dimensional subspace for better classification performance [17], [18], [19], [20].", "startOffset": 158, "endOffset": 162}, {"referenceID": 17, "context": "1 Classical LDA The conventional LDA aims to project the original high-dimensional data to a lower dimensional subspace for better classification performance [17], [18], [19], [20].", "startOffset": 164, "endOffset": 168}, {"referenceID": 18, "context": "1 Classical LDA The conventional LDA aims to project the original high-dimensional data to a lower dimensional subspace for better classification performance [17], [18], [19], [20].", "startOffset": 170, "endOffset": 174}, {"referenceID": 19, "context": "1 Classical LDA The conventional LDA aims to project the original high-dimensional data to a lower dimensional subspace for better classification performance [17], [18], [19], [20].", "startOffset": 176, "endOffset": 180}, {"referenceID": 20, "context": "By finding the best transformation matrix W , data points from different classes become more separated while data points from the same class become more compact after the transformation [21], [22], [23], [24], [25].", "startOffset": 186, "endOffset": 190}, {"referenceID": 21, "context": "By finding the best transformation matrix W , data points from different classes become more separated while data points from the same class become more compact after the transformation [21], [22], [23], [24], [25].", "startOffset": 192, "endOffset": 196}, {"referenceID": 22, "context": "By finding the best transformation matrix W , data points from different classes become more separated while data points from the same class become more compact after the transformation [21], [22], [23], [24], [25].", "startOffset": 198, "endOffset": 202}, {"referenceID": 23, "context": "By finding the best transformation matrix W , data points from different classes become more separated while data points from the same class become more compact after the transformation [21], [22], [23], [24], [25].", "startOffset": 204, "endOffset": 208}, {"referenceID": 24, "context": "By finding the best transformation matrix W , data points from different classes become more separated while data points from the same class become more compact after the transformation [21], [22], [23], [24], [25].", "startOffset": 210, "endOffset": 214}, {"referenceID": 25, "context": "In a lower dimensional subspace, the between-class scatter matrix and the within-class scatter matrix are transformed to S\u0303b = W SbW and S\u0303w = W SwW , respectively, according to [26].", "startOffset": 178, "endOffset": 182}, {"referenceID": 26, "context": "This objective function can be solved by eigen-decomposition of (Sw) Sb in [27], [28], [29].", "startOffset": 75, "endOffset": 79}, {"referenceID": 27, "context": "This objective function can be solved by eigen-decomposition of (Sw) Sb in [27], [28], [29].", "startOffset": 81, "endOffset": 85}, {"referenceID": 28, "context": "This objective function can be solved by eigen-decomposition of (Sw) Sb in [27], [28], [29].", "startOffset": 87, "endOffset": 91}, {"referenceID": 29, "context": "The goal of 2DLDA is to seek a single set of transformation matrices, U and V , projecting the original data into a lower dimensional subspace [30].", "startOffset": 143, "endOffset": 147}, {"referenceID": 8, "context": "[9] propose an iterative algorithm.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] have pointed out that this iterative algorithm cannot guarantee the monotonicity of the objective function value f and it is hard to determine appropriate termination criteria.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "To promise the monotonicity, the authors adopt trace ratio and trace difference in [31].", "startOffset": 83, "endOffset": 87}, {"referenceID": 8, "context": "The time complexity of CRP is O((2 \u00d7 32)), which is significantly small compared to that of the classical LDA [9] O((1024)).", "startOffset": 110, "endOffset": 113}, {"referenceID": 4, "context": "We compare CRP with seven algorithms, including LDA [5], 2DPCA [32], 2DLDA [9], BilinearSVM [33], two non-iterative 2DLDA algorithms (S2DLDA and P2DLDA) [10] and Tensor LPP [34].", "startOffset": 52, "endOffset": 55}, {"referenceID": 31, "context": "We compare CRP with seven algorithms, including LDA [5], 2DPCA [32], 2DLDA [9], BilinearSVM [33], two non-iterative 2DLDA algorithms (S2DLDA and P2DLDA) [10] and Tensor LPP [34].", "startOffset": 63, "endOffset": 67}, {"referenceID": 8, "context": "We compare CRP with seven algorithms, including LDA [5], 2DPCA [32], 2DLDA [9], BilinearSVM [33], two non-iterative 2DLDA algorithms (S2DLDA and P2DLDA) [10] and Tensor LPP [34].", "startOffset": 75, "endOffset": 78}, {"referenceID": 32, "context": "We compare CRP with seven algorithms, including LDA [5], 2DPCA [32], 2DLDA [9], BilinearSVM [33], two non-iterative 2DLDA algorithms (S2DLDA and P2DLDA) [10] and Tensor LPP [34].", "startOffset": 92, "endOffset": 96}, {"referenceID": 9, "context": "We compare CRP with seven algorithms, including LDA [5], 2DPCA [32], 2DLDA [9], BilinearSVM [33], two non-iterative 2DLDA algorithms (S2DLDA and P2DLDA) [10] and Tensor LPP [34].", "startOffset": 153, "endOffset": 157}, {"referenceID": 33, "context": "We compare CRP with seven algorithms, including LDA [5], 2DPCA [32], 2DLDA [9], BilinearSVM [33], two non-iterative 2DLDA algorithms (S2DLDA and P2DLDA) [10] and Tensor LPP [34].", "startOffset": 173, "endOffset": 177}, {"referenceID": 8, "context": "Following [9], [16], [6], we use the gray pixel values of the images as the features.", "startOffset": 10, "endOffset": 13}, {"referenceID": 15, "context": "Following [9], [16], [6], we use the gray pixel values of the images as the features.", "startOffset": 15, "endOffset": 19}, {"referenceID": 5, "context": "Following [9], [16], [6], we use the gray pixel values of the images as the features.", "startOffset": 21, "endOffset": 24}, {"referenceID": 4, "context": "Following the work in [5], [35], we project the original data into a (c \u2212 1) dimensional subspace for all the compared algorithms.", "startOffset": 22, "endOffset": 25}, {"referenceID": 34, "context": "Following the work in [5], [35], we project the original data into a (c \u2212 1) dimensional subspace for all the compared algorithms.", "startOffset": 27, "endOffset": 31}, {"referenceID": 35, "context": "1 Datasets Description UUIm: The UUIm Head Pose and Gaze database [36] is used to evaluate the performance of head pose and", "startOffset": 66, "endOffset": 70}, {"referenceID": 36, "context": "CVL: The CVL dataset [37] is used to evaluate the performance of handwritten digit recognition.", "startOffset": 21, "endOffset": 25}, {"referenceID": 37, "context": "Pointing\u201904: The Pointing\u201904 dataset [38] is used for head pose estimation.", "startOffset": 37, "endOffset": 41}, {"referenceID": 31, "context": "4 Classification Performance Comparison In this experiment, we compare classification performance of our algorithm with other methods, including 2DPCA [32], 2DLDA [9], S2DLDA [10], P2DLDA [10], T-LPP [34], Bilinear SVM [33].", "startOffset": 151, "endOffset": 155}, {"referenceID": 8, "context": "4 Classification Performance Comparison In this experiment, we compare classification performance of our algorithm with other methods, including 2DPCA [32], 2DLDA [9], S2DLDA [10], P2DLDA [10], T-LPP [34], Bilinear SVM [33].", "startOffset": 163, "endOffset": 166}, {"referenceID": 9, "context": "4 Classification Performance Comparison In this experiment, we compare classification performance of our algorithm with other methods, including 2DPCA [32], 2DLDA [9], S2DLDA [10], P2DLDA [10], T-LPP [34], Bilinear SVM [33].", "startOffset": 175, "endOffset": 179}, {"referenceID": 9, "context": "4 Classification Performance Comparison In this experiment, we compare classification performance of our algorithm with other methods, including 2DPCA [32], 2DLDA [9], S2DLDA [10], P2DLDA [10], T-LPP [34], Bilinear SVM [33].", "startOffset": 188, "endOffset": 192}, {"referenceID": 33, "context": "4 Classification Performance Comparison In this experiment, we compare classification performance of our algorithm with other methods, including 2DPCA [32], 2DLDA [9], S2DLDA [10], P2DLDA [10], T-LPP [34], Bilinear SVM [33].", "startOffset": 200, "endOffset": 204}, {"referenceID": 32, "context": "4 Classification Performance Comparison In this experiment, we compare classification performance of our algorithm with other methods, including 2DPCA [32], 2DLDA [9], S2DLDA [10], P2DLDA [10], T-LPP [34], Bilinear SVM [33].", "startOffset": 219, "endOffset": 223}, {"referenceID": 8, "context": "The second one is 1-Nearest-Neighbor (1NN), which is used in [9], [16] to evaluate the effectiveness of the classical 2DLDA and other related algorithms.", "startOffset": 61, "endOffset": 64}, {"referenceID": 15, "context": "The second one is 1-Nearest-Neighbor (1NN), which is used in [9], [16] to evaluate the effectiveness of the classical 2DLDA and other related algorithms.", "startOffset": 66, "endOffset": 70}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 16.", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 16.", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 16.", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 16.", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 16.", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 16.", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 36.", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 36.", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 36.", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 36.", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 36.", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 36.", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 88.", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 88.", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 88.", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 88.", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 88.", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 88.", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 24.", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 24.", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 24.", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 24.", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 24.", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 24.", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 43.", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 43.", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 43.", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 43.", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 43.", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 43.", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 89.", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 89.", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 89.", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 89.", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 89.", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP UUIm 89.", "startOffset": 74, "endOffset": 78}, {"referenceID": 31, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 18, "endOffset": 22}, {"referenceID": 8, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 29, "endOffset": 32}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 40, "endOffset": 44}, {"referenceID": 9, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 52, "endOffset": 56}, {"referenceID": 33, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 63, "endOffset": 67}, {"referenceID": 32, "context": "Dataset LDA 2DPCA [32] 2DLDA [9] S2DLDA [10] P2DLDA [10] T-LPP [34] B-SVM [33] CRP", "startOffset": 74, "endOffset": 78}], "year": 2015, "abstractText": "In many real-world applications, data are represented by matrices or high-order tensors. Despite the promising performance, the existing two-dimensional discriminant analysis algorithms employ a single projection model to exploit the discriminant information for projection, making the model less flexible. In this paper, we propose a novel Compound Rank-k Projection (CRP) algorithm for bilinear analysis. CRP deals with matrices directly without transforming them into vectors, and it, therefore, preserves the correlations within the matrix and decreases the computation complexity. Different from the existing twodimensional discriminant analysis algorithms, objective function values of CRP increase monotonically. In addition, CRP utilizes multiple rank-k projection models to enable a larger search space in which the optimal solution can be found. In this way, the discriminant ability is enhanced. We have tested our approach on five datasets, including UUIm, CVL, Pointing\u201904, USPS and Coil20. Experimental results show that the performance of our proposed CRP performs better than other algorithms in terms of classification accuracy.", "creator": "LaTeX with hyperref package"}}}