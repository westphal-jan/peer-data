{"id": "1411.6305", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2014", "title": "Revenue Optimization in Posted-Price Auctions with Strategic Buyers", "abstract": "We study revenue optimization learning algorithms for posted-price auctions with strategic buyers. We analyze a very broad family of monotone regret minimization algorithms for this problem, which includes the previously best known algorithm, and show that no algorithm in that family admits a strategic regret more favorable than $\\Omega(\\sqrt{T})$. We then introduce a new algorithm that achieves a strategic regret differing from the lower bound only by a factor in $O(\\log T)$, an exponential improvement upon the previous best algorithm. Our new algorithm admits a natural analysis and simpler proofs, and the ideas behind its design are general. We also report the results of empirical evaluations comparing our algorithm with the previous state of the art and show a consistent exponential improvement in several different scenarios.", "histories": [["v1", "Sun, 23 Nov 2014 21:58:29 GMT  (179kb,D)", "http://arxiv.org/abs/1411.6305v1", "At NIPS 2014"]], "COMMENTS": "At NIPS 2014", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mehryar mohri", "andres mu\\~noz medina"], "accepted": false, "id": "1411.6305"}, "pdf": {"name": "1411.6305.pdf", "metadata": {"source": "CRF", "title": "Revenue Optimization in Posted-Price Auctions with Strategic Buyers", "authors": ["Mehryar Mohri", "Andres Mu\u00f1oz"], "emails": ["mohri@cims.nyu.edu", "munoz@cims.nyu.edu"], "sections": [{"heading": null, "text": "Then we introduce a new algorithm that achieves strategic repentance that differs from the lower limit by only one factor in O (log T), an exponential improvement over the previous best algorithm. Our new algorithm allows for natural analysis and simpler proofs, and the ideas behind its design are general. We also report the results of empirical evaluations that compare our algorithm with the previous state of the art and show a consistent exponential improvement in several different scenarios."}, {"heading": "1 Introduction", "text": "Over the past decade, however, the advent of online advertising has led to more algorithmic studies of the buyer, including the design of learning algorithms to maximize sales. These studies have been largely motivated by the widespread use of AdExchanges and the enormous amount of historical data it has collected - AdExchanges are advertising selling platforms using second price auctions with second price prices. (Mohri and Mun) Medina, 2014 et al., 2013] These studies have been largely motivated by the use of AdExchanges and the enormous amount of historical data associated with them."}, {"heading": "2 Setup", "text": "We look at the following game played by a buyer and a seller. A good, like a display problem, is repeatedly offered for sale by the seller to the buyer via T rounds. The buyer holds a private v-shaped valuation for this good. In each round t = 1,.., T, a price pt is offered by the seller and a decision on A {0, 1} is made by the buyer. At this time, the seller takes the value 1 if the buyer agrees to buy at this price, nothing else. We will say that a buyer is always at = 0, while pt < v. At the beginning of the game, the algorithm A, used by the seller to set the prices, is announced to the buyer. Thus, the buyer plays strategically against this algorithm. Knowledge of A is a standard assumption in mechanical design and also corresponds to the practice in adverges.For any other technology (0, 1), define the discounted surplus of the buyer as follows: Sur (A, v)."}, {"heading": "3 Monotone algorithms", "text": "The following conservative pricing strategy was introduced by Amin et al. [2013]. Let p1 = 1 and \u03b2 < 1. If the price is rejected in round t, the lower price pt + 1 = \u03b2pt will be offered in the next round. If at any point price pt is accepted, then this price will be offered for all remaining rounds. We will call this algorithm monotonous. The motivation behind its design is clear: for a suitable choice of \u03b2, the seller can slowly reduce the prices offered, forcing the buyer to reject many prices (which is not convenient for them) before receiving a favorable price. The authors present an O (T\u03b3 T) regret tied to this algorithm, with T\u03b3 = (1 \u2212). A more cautious analysis shows that this limit can be further extended to O (T + \u221a T) if the discount factor in the seller.Despite its sublinear regret, the monotonous algorithm remains in effect for certain decisions to be considered."}, {"heading": "4 A nearly optimal algorithm", "text": "Let's be an algorithm for revenue optimization used against a loyal buyer. Denote by T (T) the tree associated to A after T round. That is, T (T) is a full tree of height T with nodes n'T (T) marked with the price pn offered by A (n) the right and left children of n are marked by r (n) and l (n) respectively. The price offered by the buyer is the label of r (n), while the price of A if pn is rejected is the label of l (n). Finally, we will present the left and right subtrees of L (n) and R (n) respectively as the tree proposed by Kleinberg and Leighton. Since the buyer has a fixed rating, we will consider algorithms that only raise prices after rejection. This is formalized in the following definition."}, {"heading": "5 Lower bound", "text": "Theorem 2 ([Amin et al., 2013]) Let us specify \u03b3 > 0. For each algorithm A, there is a valuation v for the buyer, so that Reg (A, v) \u2265 112T\u03b3. This theorem is in fact given for the stochastic setting in which the valuation of the buyer is a random variable taken from a fixed distribution D. However, the proof of the theorem selects D as the point mass, which reduces the scenario to a fixed price. Theorem 3 ([Kleinberg and Leighton, 2003]). In the face of any algorithm A to be played against a truthful buyer, a value v [0, 1] exists so that Reg (A, v) \u2265 C log T for any universal constant C. The combination of these results immediately leads to the following. Episode 1. In the face of any algorithm A, there is a valuation v [0, 1] so that Reg (A, \u2265 C) immediately performs a combination of the following C.for this rare combination."}, {"heading": "6 Empirical results", "text": "In this section we present the result of simulations comparing the monotonous algorithm and our algorithm PFSr. Experiments were carried out as follows: In view of a buyer's rating v, a discrete set of false ratings v was selected from the sentence {.03,.06,.., v}. Both algorithms were performed against a buyer who led the seller to believe that his rating v was instead of v. The value of v, which achieves the best benefit for the buyer, was chosen and the regret for both algorithms is shown in Figure 2.We considered two sets of experiments. First, the value of the parameter \u03b3 was left unknown to both algorithms and the value of r was set to Log (T. This choice is motivated by the discussion following Theorem 1, since we can expect to achieve a logarithmic regret for large values of T. The first two diagrams (from left to right) in Figure 2 show these results. The apparent constancy in the value of optimized regret of PFST is only an episode of PFST, although the scale of PFST is a measurement."}, {"heading": "7 Conclusion", "text": "We presented a detailed analysis of the algorithms used to optimize sales to strategic buyers, reducing the gap between the upper and lower limits of strategic regret to a logarithmic factor. In addition, the algorithm we presented is easy to analyze and reduces to the true scenario in the limit of \u03b3 \u2192 0, an important characteristic that previous algorithms did not admit. We believe that our analysis contributes to a deeper understanding of this problem and can serve as a tool for investigating more complex scenarios, such as strategic behavior in repeated second-price auctions, VCG auctions, and general market strategies."}, {"heading": "Acknowledgments", "text": "We thank Kareem Amin, Afshin Rostamizadeh and Umar Syed for several discussions on the topic of this paper. This work was partly funded by the NSF Prize IIS-1117591."}, {"heading": "8 Appendix", "text": "Lemma 2 will show that F \u00b2 is explicitly 0 for all F \u00b2 implicit."}, {"heading": "8.1 Lower bound for monotone algorithms", "text": "Let's (pt) Tt = foreseen that the seller is facing a truthful buyer. (p) Let's (p) Tt = foreseen that he is facing a truthful buyer. (p) Let's (p) Tt = foreseen that the seller is facing a truthful buyer. (p) Let's (p) Tt = foreseen. (p) Let's assume that the seller is facing a truthful buyer. (v) Since the buyer is truthful, he must (v) = foreseen if and only if foreseen. (p \u2212 foreseen) The following inequality applies: E [v \u2212 foreseen] = foreseen."}, {"heading": "9 Simulations", "text": "Here we present the results of more comprehensive simulations for PFSr and the monotonous algorithm. Again, we consider two different scenarios. Figure 3 shows the experimental results for an agnostic scenario in which the value of the parameter \u03b3 remains unknown to both algorithms and in which the parameter r of PFSr is set to log (T. The results in Figure 4 correspond to the second scenario in which the discounting factor \u03b3 is known to the algorithms and in which the parameter \u03b2 for the monotonous algorithm is set to 1 \u2212 1 / \u221a TT\u03b3. The scale on the diagrams is logarithmic in the number of rounds and in remorse."}], "references": [{"title": "The continuum-armed bandit problem", "author": ["R. Agrawal"], "venue": "SIAM journal on control and optimization,", "citeRegEx": "Agrawal.,? \\Q1926\\E", "shortCiteRegEx": "Agrawal.", "year": 1926}, {"title": "Learning prices for repeated auctions with strategic buyers", "author": ["K. Amin", "A. Rostamizadeh", "U. Syed"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Amin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Amin et al\\.", "year": 2013}, {"title": "Online bandit learning against an adaptive adversary: from regret to policy regret", "author": ["R. Arora", "O. Dekel", "A. Tewari"], "venue": "In Proceedings of ICML,", "citeRegEx": "Arora et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2012}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire"], "venue": "SIAM J. Comput.,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Regret minimization for reserve prices in second-price auctions", "author": ["N. Cesa-Bianchi", "C. Gentile", "Y. Mansour"], "venue": "In Proceedings of SODA,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2013}, {"title": "Strategic bidder behavior in sponsored search auctions", "author": ["B. Edelman", "M. Ostrovsky"], "venue": "Decision Support Systems,", "citeRegEx": "Edelman and Ostrovsky.,? \\Q2007\\E", "shortCiteRegEx": "Edelman and Ostrovsky.", "year": 2007}, {"title": "A game-theoretic machine learning approach for revenue maximization in sponsored search", "author": ["D. He", "W. Chen", "L. Wang", "T. Liu"], "venue": "In Proceedings of IJCAI,", "citeRegEx": "He et al\\.,? \\Q2013\\E", "shortCiteRegEx": "He et al\\.", "year": 2013}, {"title": "The value of knowing a demand curve: Bounds on regret for online posted-price auctions", "author": ["R.D. Kleinberg", "F.T. Leighton"], "venue": "In Proceedings of FOCS,", "citeRegEx": "Kleinberg and Leighton.,? \\Q2003\\E", "shortCiteRegEx": "Kleinberg and Leighton.", "year": 2003}, {"title": "Algorithms for the multi-armed bandit problem", "author": ["V. Kuleshov", "D. Precup"], "venue": "Journal of Machine Learning,", "citeRegEx": "Kuleshov and Precup.,? \\Q2010\\E", "shortCiteRegEx": "Kuleshov and Precup.", "year": 2010}, {"title": "A theory of auctions and competitive bidding", "author": ["P. Milgrom", "R. Weber"], "venue": "Econometrica: Journal of the Econometric Society,", "citeRegEx": "Milgrom and Weber.,? \\Q1982\\E", "shortCiteRegEx": "Milgrom and Weber.", "year": 1982}, {"title": "Learning theory and algorithms for revenue optimization in second-price auctions with reserve", "author": ["M. Mohri", "A. Mu\u00f1oz Medina"], "venue": "In Proceedings of ICML,", "citeRegEx": "Mohri and Medina.,? \\Q2014\\E", "shortCiteRegEx": "Mohri and Medina.", "year": 2014}, {"title": "Non-zero-sum games. In Introduction to Game Theory, pages 115\u2013147", "author": ["P. Morris"], "venue": null, "citeRegEx": "Morris.,? \\Q1994\\E", "shortCiteRegEx": "Morris.", "year": 1994}, {"title": "Bayesian learning in repeated games of incomplete information", "author": ["J. Nachbar"], "venue": "Social Choice and Welfare,", "citeRegEx": "Nachbar.,? \\Q2001\\E", "shortCiteRegEx": "Nachbar.", "year": 2001}, {"title": "Prediction, optimization, and learning in repeated games", "author": ["J.H. Nachbar"], "venue": "Econometrica: Journal of the Econometric Society,", "citeRegEx": "Nachbar.,? \\Q1997\\E", "shortCiteRegEx": "Nachbar.", "year": 1997}, {"title": "Reserve prices in internet advertising auctions: A field experiment", "author": ["M. Ostrovsky", "M. Schwarz"], "venue": "In Proceedings of EC,", "citeRegEx": "Ostrovsky and Schwarz.,? \\Q2011\\E", "shortCiteRegEx": "Ostrovsky and Schwarz.", "year": 2011}, {"title": "Some aspects of the sequential design of experiments", "author": ["H. Robbins"], "venue": "In Herbert Robbins Selected Papers,", "citeRegEx": "Robbins.,? \\Q1985\\E", "shortCiteRegEx": "Robbins.", "year": 1985}, {"title": "Counterspeculation, auctions, and competitive sealed tenders", "author": ["W. Vickrey"], "venue": "The Journal of finance,", "citeRegEx": "Vickrey.,? \\Q2012\\E", "shortCiteRegEx": "Vickrey.", "year": 2012}], "referenceMentions": [{"referenceID": 5, "context": "In the past decade, however, the advent of online advertisement has prompted a more algorithmic study of auctions, including the design of learning algorithms for revenue maximization for generalized second-price auctions or second-price auctions with reserve [Cesa-Bianchi et al., 2013, Mohri and Mu\u00f1oz Medina, 2014, He et al., 2013]. These studies have been largely motivated by the widespread use of AdExchanges and the vast amount of historical data thereby collected \u2013 AdExchanges are advertisement selling platforms using second-price auctions with reserve price to allocate advertisement space. Thus far, the learning algorithms proposed for revenue maximization in these auctions critically rely on the assumption that the bids, that is, the outcomes of auctions, are drawn i.i.d. according to some unknown distribution. However, this assumption may not hold in practice. In particular, with the knowledge that a revenue optimization algorithm is being used, an advertiser could seek to mislead the publisher by under-bidding. In fact, consistent empirical evidence of strategic behavior by advertisers has been found by Edelman and Ostrovsky [2007]. This motivates the analysis presented in this paper of the interactions between sellers and strategic buyers, that is, buyers that may act non-truthfully with the goal of maximizing their surplus.", "startOffset": 261, "endOffset": 1158}, {"referenceID": 3, "context": "Kleinberg and Leighton [2003] precisely studied this continuous bandit setting under the assumption of an oblivious buyer, that is, one that does not exploit the seller\u2019s behavior (more precisely, the authors assume that at each round the seller interacts with a different buyer).", "startOffset": 0, "endOffset": 30}, {"referenceID": 0, "context": "However, as argued by Amin et al. [2013], when dealing with a strategic buyer, the usual definition of regret is no longer meaningful.", "startOffset": 22, "endOffset": 41}, {"referenceID": 0, "context": "However, as argued by Amin et al. [2013], when dealing with a strategic buyer, the usual definition of regret is no longer meaningful. Indeed, consider the following example: let the valuation of the buyer be given by v \u2208 [0, 1] and assume that an algorithm with sublinear regret such as Exp3 [Auer et al., 2002b] or UCB [Auer et al., 2002a] is used for T rounds by the seller. A possible strategy for the buyer, knowing the seller\u2019s algorithm, would be to accept prices only if they are smaller than some small value , certain that the seller would eventually learn to offer only prices less than . If v, the buyer would considerably boost her surplus while, in theory, the seller would have not incurred a large regret since in hindsight, the best fixed strategy would have been to offer price for all rounds. This, however is clearly not optimal for the seller. The stronger notion of policy regret introduced by Arora et al. [2012] has been shown to be the appropriate one for the analysis of bandit problems with adaptive adversaries.", "startOffset": 22, "endOffset": 936}, {"referenceID": 0, "context": "However, as argued by Amin et al. [2013], when dealing with a strategic buyer, the usual definition of regret is no longer meaningful. Indeed, consider the following example: let the valuation of the buyer be given by v \u2208 [0, 1] and assume that an algorithm with sublinear regret such as Exp3 [Auer et al., 2002b] or UCB [Auer et al., 2002a] is used for T rounds by the seller. A possible strategy for the buyer, knowing the seller\u2019s algorithm, would be to accept prices only if they are smaller than some small value , certain that the seller would eventually learn to offer only prices less than . If v, the buyer would considerably boost her surplus while, in theory, the seller would have not incurred a large regret since in hindsight, the best fixed strategy would have been to offer price for all rounds. This, however is clearly not optimal for the seller. The stronger notion of policy regret introduced by Arora et al. [2012] has been shown to be the appropriate one for the analysis of bandit problems with adaptive adversaries. However, for the example just described, a sublinear policy regret can be similarly achieved. Thus, this notion of regret is also not the pertinent one for the study of our scenario. We will adopt instead the definition of strategic-regret, which was introduced by Amin et al. [2013] precisely for the study of this problem.", "startOffset": 22, "endOffset": 1324}, {"referenceID": 0, "context": "This notion of regret also matches the concept of learning loss introduced by [Agrawal, 1995] when facing an oblivious adversary. Using this definition, Amin et al. [2013] presented both upper and lower bounds for the regret of a seller facing a strategic buyer and showed that the buyer\u2019s surplus must be discounted over time in order to be able to achieve sublinear regret (see Section 2).", "startOffset": 79, "endOffset": 172}, {"referenceID": 0, "context": "This notion of regret also matches the concept of learning loss introduced by [Agrawal, 1995] when facing an oblivious adversary. Using this definition, Amin et al. [2013] presented both upper and lower bounds for the regret of a seller facing a strategic buyer and showed that the buyer\u2019s surplus must be discounted over time in order to be able to achieve sublinear regret (see Section 2). However, the gap between the upper and lower bounds they presented is in O( \u221a T ). In the following, we analyze a very broad family of monotone regret minimization algorithms for this problem (Section 3), which includes the algorithm of Amin et al. [2013], and show that no algorithm in that family admits a strategic regret more favorable than \u03a9( \u221a T ).", "startOffset": 79, "endOffset": 648}, {"referenceID": 1, "context": "The performance of a seller\u2019s algorithm is measured by the notion of strategic-regret [Amin et al., 2013] defined as follows:", "startOffset": 86, "endOffset": 105}, {"referenceID": 1, "context": "3 Monotone algorithms The following conservative pricing strategy was introduced by Amin et al. [2013]. Let p1 = 1 and \u03b2 < 1.", "startOffset": 84, "endOffset": 103}, {"referenceID": 8, "context": "Figure 1 depicts the tree generated by an algorithm proposed by Kleinberg and Leighton [2003], which we will describe later.", "startOffset": 64, "endOffset": 94}, {"referenceID": 8, "context": "(a) (b) Figure 1: (a) Tree T (3) associated to the algorithm proposed in [Kleinberg and Leighton, 2003].", "startOffset": 73, "endOffset": 103}, {"referenceID": 8, "context": "Let us consider the following instantiation of algorithm A introduced in [Kleinberg and Leighton, 2003].", "startOffset": 73, "endOffset": 103}, {"referenceID": 8, "context": "Note that for r = 1 and \u03b3 \u2192 0 the upper bound coincides with that of [Kleinberg and Leighton, 2003].", "startOffset": 69, "endOffset": 99}, {"referenceID": 1, "context": "Let us compare the regret bound given by Theorem 1 with the one given by Amin et al. [2013]. The above discussion shows that for certain values of \u03b3, an exponentially better regret can be achieved by our algorithm.", "startOffset": 73, "endOffset": 92}, {"referenceID": 1, "context": "Theorem 2 ([Amin et al., 2013]).", "startOffset": 11, "endOffset": 30}, {"referenceID": 8, "context": "Theorem 3 ( [Kleinberg and Leighton, 2003]).", "startOffset": 12, "endOffset": 42}], "year": 2014, "abstractText": "We study revenue optimization learning algorithms for posted-price auctions with strategic buyers. We analyze a very broad family of monotone regret minimization algorithms for this problem, which includes the previously best known algorithm, and show that no algorithm in that family admits a strategic regret more favorable than \u03a9( \u221a T ). We then introduce a new algorithm that achieves a strategic regret differing from the lower bound only by a factor in O(log T ), an exponential improvement upon the previous best algorithm. Our new algorithm admits a natural analysis and simpler proofs, and the ideas behind its design are general. We also report the results of empirical evaluations comparing our algorithm with the previous state of the art and show a consistent exponential improvement in several different scenarios.", "creator": "LaTeX with hyperref package"}}}